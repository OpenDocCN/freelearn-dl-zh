- en: '8'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Real-World Use Case – Making Your Application Available on ChatGPT
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In earlier chapters, we learned quite a lot. We learned how to create and optimize
    prompts, how to create semantic and native functions and put them in Semantic
    Kernel, and how to use a planner to automatically decide which functions of the
    kernel to use to solve a user problem.
  prefs: []
  type: TYPE_NORMAL
- en: In the previous two chapters, we learned how to augment our kernel with **memories**,
    including memories built from external data, which allows us to build more personalized
    applications and use data that is recent and that we have control over to generate
    answers, instead of using only the data that was used to train the LLM, which
    is frequently not public.
  prefs: []
  type: TYPE_NORMAL
- en: In this final chapter, we will change gears. Instead of creating new functionality,
    we will learn how to make the functionality we have already created available
    for many more users. We will use the home automation application that we wrote
    in [*Chapter 5*](B21826_05.xhtml#_idTextAnchor106) and make it available through
    the OpenAI custom **GPT Store**, making it available to the hundreds of millions
    of users that already use ChatGPT, and use ChatGPT as the UI of our application.
  prefs: []
  type: TYPE_NORMAL
- en: Besides the obvious benefits of quickly being able to make an application available
    to hundreds of thousands of users, another benefit is that you don’t even need
    to build a **user interface** (**UI**) for your application. You can build the
    main functionality and use ChatGPT as the UI. Of course, this has limitations.
    The AI is text based and you have little control over it, but on the other hand,
    you can test and deploy your application a lot faster, and build a dedicated UI
    later.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’ll be covering the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Creating a custom GPT in the OpenAI store
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a web API wrapper for an application developed with Semantic Kernel
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Connecting the custom GPT with the OpenAI store through the web API wrapper
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of the chapter, you will have an application that is available to
    all ChatGPT users.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To complete this chapter, you will need to have a recent, supported version
    of your preferred Python or C# development environment:'
  prefs: []
  type: TYPE_NORMAL
- en: For Python, the minimum supported version is Python 3.10, and the recommended
    version is Python 3.11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For C#, the minimum supported version is .NET 8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this chapter, we will call OpenAI services. Given the amount that companies
    spend on training these LLMs, it’s no surprise that using these services is not
    free. You will need an **OpenAI API** key, obtained either directly through **OpenAI**
    or **Microsoft**, via the **Azure** **OpenAI** service.
  prefs: []
  type: TYPE_NORMAL
- en: If you are using .NET, the code for this chapter is at [https://github.com/PacktPublishing/Building-AI-Applications-with-Microsoft-Semantic-Kernel/tree/main/dotnet/ch8](https://github.com/PacktPublishing/Building-AI-Applications-with-Microsoft-Semantic-Kernel/tree/main/dotnet/ch8).
  prefs: []
  type: TYPE_NORMAL
- en: If you are using Python, the code for this chapter is at [https://github.com/PacktPublishing/Building-AI-Applications-with-Microsoft-Semantic-Kernel/tree/main/python/ch8](https://github.com/PacktPublishing/Building-AI-Applications-with-Microsoft-Semantic-Kernel/tree/main/python/ch8).
  prefs: []
  type: TYPE_NORMAL
- en: To create your custom GPT, you will need an account with OpenAI.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can install the required packages by going to the GitHub repository and
    using the following: `pip install -``r requirements.txt`.'
  prefs: []
  type: TYPE_NORMAL
- en: Custom GPT agents
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: On November 6, 2023, OpenAI introduced functionality that allows users to create
    custom, personalized versions of ChatGPT. These custom GPTs created by users can
    be shared with other users through OpenAI’s GPT Store. This allows users without
    programming experience to add functionality to ChatGPT by simply writing instructions
    in natural language, and it also allows users with programming experience to connect
    ChatGPT to their applications, making such applications available to hundreds
    of millions of users.
  prefs: []
  type: TYPE_NORMAL
- en: Initially, these were called “custom GPTs,” but now they are simply called GPTs.
    That may be confusing since the transformer technology used in most AI models
    is called **generative pre-trained transformer** (**GPT**), and the OpenAI implementation
    of these models is also called GPT with a version, such as GPT-3.5 or GPT 4.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, when we use the name “GPT,” unless otherwise noted, it means
    the custom GPTs that you can create inside of ChatGPT.
  prefs: []
  type: TYPE_NORMAL
- en: These GPTs can use custom prompts, such as the ones we use in semantic functions,
    and additional data, such as what we use in RAG models. You can add custom prompts
    and documents to your custom GPT by using a web interface, which we will show
    in the next subsection.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, you can also allow your GPT to call external functions through
    a web API. Many companies created these interfaces and connected them to custom
    GPTs, such as Wolfram (the creators of the scientific software Mathematica), design
    companies such as Canva and Adobe, and many others.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, as we did [*Chapter 5*](B21826_05.xhtml#_idTextAnchor106),
    imagine you work for a home automation company that has a product that allows
    someone to control their home through a device in their house, and now you want
    to allow them to do it with ChatGPT. We created the native function for this in
    [*Chapter 5*](B21826_05.xhtml#_idTextAnchor106), and in this chapter, we are going
    to use Microsoft Semantic Kernel tools to make that functionality available for
    ChatGPT users.
  prefs: []
  type: TYPE_NORMAL
- en: Before we start that more complex example, let’s first create a simpler custom
    GPT just to familiarize ourselves with the process.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a custom GPT
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To create a GPT, you can navigate to [https://chat.openai.com/gpts/](https://chat.openai.com/gpts/)
    and click the **Create** button on the top-right corner, or navigate directly
    to [https://chat.openai.com/gpts/editor](https://chat.openai.com/gpts/editor).
    This will open a web interface that allows you to create a GPT. As you’d expect,
    you can create the GPT simply by chatting with ChatGPT. You can add custom instructions,
    specify the tone of the answers, and much more.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.1 – Creating a GPT using the OpenAI editor](img/B21826_08_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.1 – Creating a GPT using the OpenAI editor
  prefs: []
  type: TYPE_NORMAL
- en: 'The **Configure** tab is where you will give your GPT a name and description,
    and where you can add custom actions that connect your GPT with external APIs:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.2 – The OpenAI UI to configure your GPT](img/B21826_08_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.2 – The OpenAI UI to configure your GPT
  prefs: []
  type: TYPE_NORMAL
- en: You can use the `I want to make a GPT that answers questions about Sherlock
    Holmes` and it answered back with `How about naming it Detective Guide? Does that
    sound good to you?`. I answered back with `Yes`, and the configuration was updated,
    adding `Detective Guide` as the name. Without asking, ChatGPT also automatically
    generated an appropriate profile picture for my GPT.
  prefs: []
  type: TYPE_NORMAL
- en: 'I did a few more configuration steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'I also uploaded the text files with the contents of the books, which you can
    find online and also in `/data/sherlock_holmes/`, and added this additional configuration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'After every configuration step, ChatGPT asks me if there’s anything more I
    want to add. At this point, I said `no`, which enabled the **Create** button on
    the top-right corner again. Once I pressed it, I got the option to share my GPT:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.3 – Sharing your GPT in the GPT Store](img/B21826_08_3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.3 – Sharing your GPT in the GPT Store
  prefs: []
  type: TYPE_NORMAL
- en: I chose **Publish to GPT Store**, which will make it available to all ChatGPT
    users. The completed version, created only with the preceding minimal instructions,
    can be accessed at [https://chat.openai.com/g/g-yJvyO2vHq-detective-guide](https://chat.openai.com/g/g-yJvyO2vHq-detective-guide).
  prefs: []
  type: TYPE_NORMAL
- en: 'This is what it looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.4 – The initial version of the Sherlock Holmes GPT, Detective Guide](img/B21826_08_4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.4 – The initial version of the Sherlock Holmes GPT, Detective Guide
  prefs: []
  type: TYPE_NORMAL
- en: One thing to notice is what little configuration I had to perform. I uploaded
    a few text files with the text of the books and wrote a few hundred words of configuration
    in natural language.
  prefs: []
  type: TYPE_NORMAL
- en: 'To test it, I asked `What''s Holmes attic theory?`, and its answer, shown in
    the following, answers the question and correctly identifies the book it comes
    from:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'In addition, because I asked the GPT to not answer questions outside of its
    knowledge domain, it tries to keep things on topic, as the following dialogue
    exemplifies:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.5 – Asking the GPT about astronomy and Sherlock Holmes’ astronomy
    knowledge](img/B21826_08_5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.5 – Asking the GPT about astronomy and Sherlock Holmes’ astronomy knowledge
  prefs: []
  type: TYPE_NORMAL
- en: If it’s so easy to create a custom GPT, why write any code?
  prefs: []
  type: TYPE_NORMAL
- en: When GPT models started to become mainstream, several entrepreneurs created
    applications that were nothing more than GPT-3.5 with a few additional instructions.
    These apps were released on the web, like what we just did with the Detective
    Guide.
  prefs: []
  type: TYPE_NORMAL
- en: 'If the functionality of your application can be replicated by adding a few
    additional instructions to ChatGPT, creating a custom GPT may be a good option
    for you. If you try to release it as a separate app and charge users, it’s possible
    for a competitor to replicate your success by simply creating a custom GPT and
    offering it to all ChatGPT users. Monetization for these GPTs is still unclear,
    but apparently, it will work in the same way as Spotify or Kindle Unlimited: GPTs
    that get enough users receive a fraction of the money paid by subscribers.'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are a few cases in which these custom GPTs in ChatGPT don’t work at all.
    For example, you can’t use it to add AI functionality to your existing application.
    You also don’t have a lot of control: custom GPTs don’t allow you to fine-tune
    your prompts, process the inputs and outputs of functions, monitor usage, change
    the sensitivity of search when retrieving documents, and so on, so you have a
    lot less control over the user experience.'
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have created a simple version of a custom GPT, let’s create one
    that supports actions. We are going to use the home automation native plugin that
    we created in [*Chapter 5*](B21826_05.xhtml#_idTextAnchor106) and pretend that
    we have a company that allows users to automate some functions in their house,
    such as turning the lights on and off and turning on the TV. We’re going to create
    a custom GPT that allows users to use ChatGPT to control the functionality of
    their house.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a custom GPT that supports actions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Like what we have done in the previous subsection, we start by navigating to
    [https://chat.openai.com/gpts/](https://chat.openai.com/gpts/) and clicking the
    **Create** button in the top-right corner, or navigating directly to [https://chat.openai.com/gpts/editor](https://chat.openai.com/gpts/editor).
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead of using the chat interface to create this custom GPT, I went directly
    to the **Configure** tab and added the following instructions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: I also named my GPT `SKB Home Automation Example`, where **SKB** stands for
    **Semantic Kernel Book**. You can leave most other options as their defaults,
    although you likely want to uncheck **Web Browsing** and **DALL-E Image Generation**
    under **Capabilities**, as these won’t be used.
  prefs: []
  type: TYPE_NORMAL
- en: Once you are done, you can click **Create** on the top-right side of the screen,
    and this will create a custom GPT, which you can choose to keep to yourself, share
    with a link, or share in the GPT Store.
  prefs: []
  type: TYPE_NORMAL
- en: 'Whatever you choose, now you can send requests to the GPT. Note that we have
    not connected our native plugin to the GPT yet, so if you ask the GPT to perform
    something, such as `open the garage door`, it will immediately hallucinate, as
    shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'ChatGPT makes up several things in this answer: an API, a `curl` command, an
    authentication method, whether you can send commands to an IP address, and so
    on. None of those things are true; it’s just trying its best to provide an answer.
    This problem will be solved when we connect ChatGPT with our real API, which we
    are going to do in the next section.'
  prefs: []
  type: TYPE_NORMAL
- en: A note about security
  prefs: []
  type: TYPE_NORMAL
- en: When you share your GPT and your API with hundreds of millions of users, there’s
    a real possibility that some of them will use it in ways that you have not thought
    about. We will not cover security in detail in this book, but this doesn’t mean
    that you should not think about it.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will connect an API to ChatGPT without any authentication,
    but for a production application, you should add authentication to the connection
    between GPT and your API. Most importantly, you should add monitoring to your
    API, so you can see if usage patterns are changing.
  prefs: []
  type: TYPE_NORMAL
- en: Even the most basic monitoring that just counts how many calls you have had
    per minute is likely sufficient to prevent the worst forms of abuse. Once you
    have monitoring, you can also add rate limiting, to prevent malicious users from
    overwhelming your API with repeated calls.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a web API wrapper for the native function
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'First, let’s define our native function. This is the same function I used in
    [*Chapter 5*](B21826_05.xhtml#_idTextAnchor106), but I used only `OperateLight`
    and `OperateGarageDoor` for brevity:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Now, we need to build a web API to make that function callable from the web
    by ChatGPT.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a web API wrapper in Python
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In Python, we are going to use the Flask library. In Flask, we’re going to
    create two routes: `operate_light` and `operate_garage_door`. First, we create
    an app:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Creating the app is simple, requiring just the calling of the `Flask` constructor
    and setting a `secret_key` property that can be used to sign cookies coming from
    your app. This app will not have cookies, so the secret key can be anything, including
    a random string.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we will define the routes for our API:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The structure of each route is the same: we create a kernel, add a GPT service
    to it, import the `HomeAutomation` plugin, and invoke the appropriate function,
    returning its answer.'
  prefs: []
  type: TYPE_NORMAL
- en: 'You can add these two lines of code to the application to allow for local testing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'To test the application locally, go to a command line and type the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'This will create a local web server:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, you can send commands to the local web server using `curl` if you are
    using bash, or `Invoke-RestMethod` if you are using PowerShell. Here, we are invoking
    the `operate_light` route with `"action": "on"` and `"``location": "bedroom"`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The result, as expected, is that the application responds successfully:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Now that we verified that the web application is working, we can deploy it on
    the web.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a web API wrapper in C#
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '.NET makes it easy to create a boilerplate web API application. You can use
    the following command and it will create a web API under the `SkHomeAutomation`
    directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Don’t forget to install the `Microsoft.SemanticKernel` package, too:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The `dotnet new webapi` command helpfully generates the code for a weather
    forecasting web application that provides a web API. One of the files it generates
    is a module called `WeatherForecast.cs`. You can delete this file, as we will
    replace it with our own functionality. To do so, copy the `HomeAutomation.cs`
    file from [*Chapter 5*](B21826_05.xhtml#_idTextAnchor106) to the root of this
    project. To make our life easier, add the following line to the beginning of the
    file, which will allow you to reference the `HomeAutomation` object more easily:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The last thing you need to do is to go into the `Controllers` directory. It
    will contain a `WeatherForecastController.cs` file. You can delete this file and
    replace it with the `HomeAutomationController.cs` file, which is here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '`HomeAutomationController` exposes the `operate_light` and `operate_garage_door`
    web API paths, and when those are called, it routes the request to the corresponding
    method of the `HomeAutomation` class that we created in [*Chapter 5*](B21826_05.xhtml#_idTextAnchor106),
    essentially exposing our Semantic Kernel application to the web, once it’s deployed.'
  prefs: []
  type: TYPE_NORMAL
- en: The next step, whether you created the application in C# or Python, is to deploy
    the application.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying your application to an Azure Web App
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To deploy your application on the web, you need to have an Azure account. Go
    to the Azure portal at [https://portal.azure.com](https://portal.azure.com), and
    from the home page, click **Create a Resource** and then **Create a Web App**.
    As you will see here, we can use the free tier for our test, but if you plan to
    deploy something like this for a real application, you should choose a different
    plan.
  prefs: []
  type: TYPE_NORMAL
- en: 'In *Figure 8**.6*, I show how I created mine: I created a new resource group
    called `skb-rg`, named my application `skb-home-automation`, which gives it the
    `skb-home-automation.azurewebsites.net` URL, and chose Python 3.11 (Python) or
    .NET 8 LTS (C#) for its runtime stack.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Under `skb-sp`, and chose the **Free F1** pricing plan. Once these configurations
    are done, click **Review + create** and your web application will be deployed
    in a few minutes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.6 – Creating a free web app to host our API](img/B21826_08_6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.6 – Creating a free web app to host our API
  prefs: []
  type: TYPE_NORMAL
- en: The simplest way to deploy your API to the web application is through GitHub.
    To do so, we need to create a new, clean GitHub repository for this web API and
    copy the contents of [https://github.com/PacktPublishing/Microsoft-Semantic-Kernel/tree/main/python/ch8](https://github.com/PacktPublishing/Microsoft-Semantic-Kernel/tree/main/python/ch8)
    to it. This needs to be a separate repository because you need to deploy the full
    repository to the web application. For example, you can put your copy at an address
    such as `https://github.com/<your-github-username>/skb-home-automation`.
  prefs: []
  type: TYPE_NORMAL
- en: In your web application, go to **Deployment Center**, and select **GitHub**
    as the source. In **Organization**, select your username. Choose the repository.
  prefs: []
  type: TYPE_NORMAL
- en: This will create and deploy the web API under your own account.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.7 – Deploying the web API using GitHub](img/B21826_08_7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.7 – Deploying the web API using GitHub
  prefs: []
  type: TYPE_NORMAL
- en: Once the web API is deployed, you can test it using `curl` or `Invoke-RestApi`.
    The only change is that instead of using localhost as the endpoint, you need to
    change it to the endpoint you deployed to. In my case, I chose `skb-home-automation.azurewebsites.net`
    (your case will be different). Please note that my version of the API will not
    be available for you; you must deploy your own.
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, we can submit the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The result will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Now that we have a web API that is working, we need to connect the API with
    ChatGPT.
  prefs: []
  type: TYPE_NORMAL
- en: Connecting the custom GPT with your custom GPT action
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To connect our web API with our custom GPT, we need to give it an OpenAPI specification.
    ChatGPT makes it very easy to generate one.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, go to our custom GPT, select the dropdown from its name, and select
    **Edit GPT**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.8 – Editing our GPT](img/B21826_08_8.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.8 – Editing our GPT
  prefs: []
  type: TYPE_NORMAL
- en: 'On the bottom of the **Configuration** tab, click on **Create new action**,
    under **Actions**. This will bring up the **Add** **actions** UI:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.9 –  Adding actions to our GPT](img/B21826_08_9.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.9 – Adding actions to our GPT
  prefs: []
  type: TYPE_NORMAL
- en: 'To add actions, you need to specify a schema using a language called **OpenAPI**.
    ChatGPT makes this extremely easy: clicking on **Get help from ActionGPT** will
    open a chat dialog with another custom GPT that can help you create OpenAPI specifications:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.10 – Using ActionsGPT](img/B21826_08_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.10 – Using ActionsGPT
  prefs: []
  type: TYPE_NORMAL
- en: 'In ActionsGPT, all you need to do is paste the code of our web API, and it
    will automatically generate the OpenAPI specification. What was automatically
    generated is in the following, but we’ll need to make a couple of changes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Notably, it doesn’t know the name of my server or the restrictions of the places
    where lights are installed. It also tries to guess the commands. Therefore, we
    must add the correct restrictions to the specification. Another detail to note
    is that I have the `x-openai-isConsequential: false` parameter for all endpoints.
    When that parameter is `true` or blank, ChatGPT will ask for confirmation for
    each command that is issued. For our purposes, we don’t need that, but your use
    case might require it, for example, when a user decides to make a payment.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The fixed version is here, with the changes highlighted in bold:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: You can paste this corrected version into the **Schema** box and click **Update**
    in the top-right corner. This will deploy the custom GPT with the connection to
    the native application you developed with Semantic Kernel.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, you will see an example of a real dialog with our custom GPT, where I
    ask it to operate several devices:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.11 – Using our SKB Home Automation custom GPT](img/B21826_08_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.11 – Using our SKB Home Automation custom GPT
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.12 – Using our SKB Home Automation custom GPT](img/B21826_08_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.12 – Using our SKB Home Automation custom GPT
  prefs: []
  type: TYPE_NORMAL
- en: 'First, I asked the GPT to open my garage door. It correctly called the API
    with the appropriate command. Next, I asked it a complex command: to close my
    garage door and turn off all the lights. As you can see from *Figure 8**.12*,
    it issued five commands. Looking at the log of the web API, you would be able
    to see that the commands were correctly sent:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'If I ask for a command that it cannot execute, it also correctly responds with
    what it can do:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.13 – Issuing an invalid command to the custom GPT](img/B21826_08_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.13 – Issuing an invalid command to the custom GPT
  prefs: []
  type: TYPE_NORMAL
- en: 'The two main consequences of connecting an application with a custom GPT are
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`turn off all my lights`, and ChatGPT will parse them and send them to your
    application. If users ask for functions that are not available in your application,
    ChatGPT tells them what can and cannot be done.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Your application gets wide distribution and access to all UI facilities provided
    by ChatGPT**: Everyone with access to ChatGPT can use your application, even from
    their phones. They can also use the application with their voices because ChatGPT
    supports voice commands.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this section, we have seen how to connect an app we wrote with ChatGPT, enabling
    it to be used by the hundreds of millions of ChatGPT users.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we connected an application with OpenAI’s ChatGPT by developing
    a custom GPT and adding custom actions to it. This can enable applications to
    get access to a planner that is based on the latest model available to ChatGPT
    users, which is usually a very advanced model.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, what we have learned allows you to deploy your application to hundreds
    of millions of users with minimal effort and get access to several new features
    available to ChatGPT users, such as natural language requests and voice requests.
    It also allows you to deploy your application to users more quickly, as you don’t
    have to develop a UI yourself – you can use ChatGPT as the UI as you develop and
    grow your application.
  prefs: []
  type: TYPE_NORMAL
- en: If you are a Python programmer, Microsoft Semantic Kernel provides a few additional
    features over what is already provided by the default OpenAI Python API. Among
    other things, you get the separation between prompt and code, native functions,
    planners, core plugins, and interfaces with memory. All of this can cut the time
    you will spend creating and maintaining your code. With the amount of change happening
    in AI these days, it’s great to be able to save some time.
  prefs: []
  type: TYPE_NORMAL
- en: If you are a C# developer, in addition to getting the benefits that the Python
    programmers get, you will also find that Microsoft Semantic Kernel is the best
    way of connecting a C# application to OpenAI models, as OpenAI does not provide
    a C# API. You can do a lot with REST APIs, as we have shown when we created DALL-E
    3 images in [*Chapter 4*](B21826_04.xhtml#_idTextAnchor086), but REST APIs are
    cumbersome and have changed in the last year. Using the Microsoft Semantic Kernel
    greatly simplifies things, and when changes happen, it’s likely that they will
    be incorporated in a future release.
  prefs: []
  type: TYPE_NORMAL
- en: For now, this concludes our journey with Microsoft Semantic Kernel. As a parting
    thought, Semantic Kernel and AI models are just tools. Your impact on the world
    depends on how you use these tools. In my career, I have been fortunate to be
    able to use technology, and lately, AI, for social good. I hope you can do the
    same.
  prefs: []
  type: TYPE_NORMAL
