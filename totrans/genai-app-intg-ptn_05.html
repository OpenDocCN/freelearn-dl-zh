<html><head></head><body>
<div><div><h1 class="chapterNumber">5</h1>
<h1 class="chapterTitle" id="_idParaDest-59">Integration Pattern: Batch Metadata Extraction</h1>
<p class="normal">In this chapter, we will explore a metadata extraction use case, which serves as an excellent entry point to understand the capabilities of <strong class="keyWord">Generative Artificial Intelligence</strong> (<strong class="keyWord">GenAI</strong>). This topic <a id="_idIndexMarker175"/>is particularly relevant across industries and thought-provoking.</p>
<p class="normal">To illustrate this use case, let us consider a scenario where we work with a financial services company that requires the extraction of data from a 10-K report. These reports, filed annually <a id="_idIndexMarker176"/>with the <strong class="keyWord">Securities and Exchange Commission</strong> (<strong class="keyWord">SEC</strong>) by publicly traded companies, provide a comprehensive overview of their financial performance, operations, and significant events. They are extensive documents that are over 100 pages long and contain a wealth of information, structured across different sections across different data modalities (tables, text, etc.).</p>
<p class="normal">In this chapter, our objective is to identify the specific dataset and critical data points that need to be extracted from this vast repository of information. This process requires a systematic approach to pinpoint the desired data points with precision.</p>
<p class="normal">Once the relevant data points have been identified, we will determine the appropriate storage location for this extracted data. This could involve a centralized database accessible to authorized individuals within the organization, or a cloud-based repository that facilitates seamless access and collaboration across teams and locations.</p>
<p class="normal">Regardless of the chosen storage solution, GenAI will play a pivotal role throughout this endeavor. With its ability to understand and process natural language, GenAI will prove invaluable in navigating the intricate structure of financial reports, extracting the essential data points with remarkable efficiency and accuracy.</p>
<p class="normal">We will cover the following main topics in this chapter:</p>
<ul>
<li class="bulletList"><strong class="keyWord">Use case definition</strong>: We will describe an example scenario of extracting metadata from a 10-K report for a financial services company, explaining the structure and importance of these reports.</li>
<li class="bulletList"><strong class="keyWord">Architecture</strong>: We will outline a cloud-based, serverless architecture using Google Cloud services to process 10-K reports, including storage, messaging, processing, and database components.</li>
<li class="bulletList"><strong class="keyWord">Entry point</strong>: We will explain how the batch processing pipeline is triggered, using Google Cloud Storage and Cloud Functions to initiate the content extraction process.</li>
<li class="bulletList"><strong class="keyWord">Prompt pre-processing</strong>: We will detail the creation of an initial prompt for the AI model, leveraging SEC guidance to identify key data points for extraction from 10-K reports.</li>
<li class="bulletList"><strong class="keyWord">Inference</strong>: We will discuss the submission of the prompt to Gemini Pro 1.5 via Vertex AI, showcasing how the model processes and extracts information from the 10-K report.</li>
<li class="bulletList"><strong class="keyWord">Result post processing</strong>: We will cover parsing the JSON output from the <strong class="keyWord">large language model</strong> (<strong class="keyWord">LLM</strong>) and the strategies to ingest the extracted data into databases, considering both relational and document database options.</li>
<li class="bulletList"><strong class="keyWord">Result presentation</strong>: We will consider how to present the extracted data, including the use of business intelligence tools, data visualization platforms, and custom applications.</li>
<li class="bulletList"><strong class="keyWord">Code sample</strong>: We will provide a practical implementation of the metadata extraction process, including setup, prompt creation, inference, and result handling.</li>
</ul>
<h1 class="heading-1" id="_idParaDest-60">Use case definition</h1>
<p class="normal">Extracting metadata <a id="_idIndexMarker177"/>from 10-K reports holds significant value for financial services companies and other stakeholders. These reports, mandated by the SEC, are a treasure trove of information that can provide valuable insights into a company’s financial health, operational performance, and strategic direction. However, the sheer volume, complexity of these documents, and lack of consistency across the way companies build their reports can make it challenging to manually extract and analyze the relevant data points.</p>
<p class="normal">Typical 10-K reports follow <a id="_idIndexMarker178"/>a standardized structure, comprising multiple sections that cover various aspects of a company’s operations. These sections may include a business overview, risk factors, management’s discussion and analysis, financial <a id="_idIndexMarker179"/>statements, and disclosures about corporate governance, among others. While the structure is consistent across companies, the specific data points and their presentation can vary, making it difficult to establish a one-size-fits-all approach to data extraction.</p>
<p class="normal">The 10-K includes five distinct sections:</p>
<ul>
<li class="bulletList"><strong class="keyWord">Business</strong>: This section <a id="_idIndexMarker180"/>provides an overview of the company’s main operations, including its products and services, key markets, competitive landscape, and other relevant details about its business model and operations.</li>
<li class="bulletList"><strong class="keyWord">Risk factors</strong>: In this <a id="_idIndexMarker181"/>section, the company outlines and discusses any, and all, risks it faces. This includes operational, financial, legal, regulatory, and industry-specific risks that could potentially impact its performance or future prospects.</li>
<li class="bulletList"><strong class="keyWord">Selected financial data</strong>: This <a id="_idIndexMarker182"/>section presents specific financial information about the company over the last five years, typically including key metrics such as revenue, net income, earnings per share, and other relevant financial data.</li>
<li class="bulletList"><strong class="keyWord">Management’s Discussion and Analysis </strong>(<strong class="keyWord">MD&amp;A</strong>): The fourth section offers senior <a id="_idIndexMarker183"/>management’s explanation and analysis of the company’s financial results, including a detailed discussion of the factors that influenced its performance, future strategies, and potential opportunities and challenges.</li>
<li class="bulletList"><strong class="keyWord">Financial statements and supplementary data</strong>: The final section furnishes the <a id="_idIndexMarker184"/>audited financial statements, including <a id="_idIndexMarker185"/>the income statement, balance sheets, statement of cash flows, and accompanying notes and disclosures. This section provides a comprehensive and detailed picture of the company’s financial position and performance during the reporting period.</li>
</ul>
<p class="normal">The biggest challenge to these documents is that specific data points and their presentation can vary, making it very difficult to establish a one-size-fits-all approach to data extraction. However, by leveraging GenAI’s natural language processing capabilities, financial services companies can efficiently navigate this structured format and extract relevant data points from each section, tailoring their approach to the unique characteristics of each company’s report.</p>
<p class="normal">The availability <a id="_idIndexMarker186"/>of structured metadata extracted from these documents opens up opportunities for financial services companies. For example, they can conduct an in-depth analysis of a company’s financial performance, benchmarking it against industry peers or historical trends. This analysis can inform investment decisions, risk assessments, and strategic planning efforts.</p>
<p class="normal">Another opportunity would be to leverage the extracted metadata to develop predictive models and identify patterns that may not be immediately apparent from manual analysis. These models can help anticipate potential risks, identify emerging trends, and uncover new investment opportunities.</p>
<p class="normal">Thinking further, the extracted metadata can be integrated into existing data repositories or business intelligence platforms, enabling seamless access and collaboration among various teams within the organization. This integration can foster cross-functional collaboration, enabling different departments, such as investment banking, asset management, and risk management, to leverage the same data for their respective analyses and decision-making processes.</p>
<p class="normal">In addition to financial services companies, the extracted metadata can also be valuable for regulatory bodies, academic researchers, and other stakeholders interested in studying corporate performance, industry trends, and the overall health of the financial markets.</p>
<p class="normal">By leveraging the power of GenAI to extract metadata from 10-K reports, financial services companies can unlock a wealth of insights, streamline their analysis processes, and make more informed decisions that drive business growth and mitigate risks.</p>
<h1 class="heading-1" id="_idParaDest-61">Architecture</h1>
<p class="normal">Though the scope of this book is not to provide a deep dive into the intricacies of a LLM processing architecture, we will briefly discuss what a cloud-based architecture for our metadata extraction<a id="_idIndexMarker187"/> use case might look like. For this example, we will leverage the capabilities of Google Cloud, as it offers a native AI platform called Vertex AI that allows us to seamlessly integrate leading models, including Google’s Gemini and third-party models such as Anthropic’s Claude, in an enterprise-compliant manner.</p>
<p class="normal">The approach we’ll adopt for this use case is to leverage a batch-optimized architecture, which is suitable for processing large volumes of data in an efficient and scalable manner. This kind of architecture aligns with cloud-native principles and is a serverless architecture that leverages various Google Cloud services.</p>
<p class="normal">This architecture will consist of an object store (Google Cloud Storage) to store the 10-K reports, a messaging queue (Google Cloud Pub/Sub) to coordinate the data flow, a processing <a id="_idIndexMarker188"/>component (Google Cloud Functions) to execute the LLM-based metadata extraction tasks, an LLM model (such as Google Gemini hosted on Vertex-AI) to perform the actual extraction, and a database (Google Big-Query) to store the extracted metadata.</p>
<p class="normal">Here’s a more detailed <a id="_idIndexMarker189"/>breakdown of how this architecture will function:</p>
<ol>
<li class="numberedList" value="1">The 10-K reports are stored in Google Cloud Storage, a highly scalable and durable object store.</li>
<li class="numberedList">A Cloud Function is triggered periodically (for example, daily or weekly) to initiate the metadata extraction process.</li>
<li class="numberedList">A Cloud Function will read a list of 10-K reports from Cloud Storage and publish messages to a Pub/Sub topic, effectively creating a queue of reports to be processed.</li>
<li class="numberedList">Another Cloud Function, subscribed to the Pub/Sub topic, is triggered for each message tied to a given report in the queue.</li>
<li class="numberedList">This second Cloud Function invokes the LLM model (for example, Google Gemini) hosted on Vertex-AI, passing the 10-K report content as input.</li>
<li class="numberedList">The LLM model processes the report, leveraging its natural language understanding capabilities to extract the relevant metadata.</li>
<li class="numberedList">The extracted metadata is then stored in a structured format (for example, BigQuery) for further analysis and consumption.</li>
</ol>
<p class="normal">This serverless architecture provides several benefits, including automatic scaling, cost-efficiency (pay-per-use pricing), and seamless integration with other Google Cloud services.</p>
<figure class="mediaobject"><img alt="" height="585" src="img/B22175_05_01.png" width="825"/></figure>
<p class="packt_figref">Figure 5.1: GenAI document data extraction pipeline</p>
<p class="normal">The following diagram showcases <a id="_idIndexMarker190"/>the architecture that will be leveraged in this example, following our GenAI integration framework discussed in <em class="chapterRef">Chapter 3</em>, <em class="italic">Designing Patterns for Interacting with Generative AI</em>:</p>
<figure class="mediaobject"><img alt="" height="139" src="img/B22175_05_02.png" width="825"/></figure>
<p class="packt_figref">Figure 5.2: The Application Integration Framework </p>
<h2 class="heading-2" id="_idParaDest-62">Entry point</h2>
<p class="normal">The entry point for our batch processing pipeline will <a id="_idIndexMarker191"/>be an object created in <strong class="keyWord">Google Cloud Storage</strong> (<strong class="keyWord">GCS</strong>), which <a id="_idIndexMarker192"/>will then trigger a Google Cloud Function to start the processing pipeline. This setup allows us to seamlessly integrate with existing workflows, where the 10-K reports are uploaded to a designated GCS bucket. By leveraging the event-driven nature of Cloud Functions, our system can automatically get into action as soon as a new report lands in the storage bucket.</p>
<p class="normal">Once triggered, the Cloud Function will initiate the content extraction process. For this step, we’ve decided to employ the powerful capabilities of Google’s Gemini Pro 1.5, a state-of-the-art GenAI multimodal model that supports processing PDF documents directly. Gemini Pro 1.5 will analyze the uploaded 10-K report, intelligently extracting not only the textual content but also the relevant data points we’re interested in, such as financial figures, company overviews, and key performance indicators.</p>
<p class="normal">By leveraging Gemini Pro 1.5’s advanced natural language processing and document understanding capabilities, we can obtain a comprehensive transcript of the report’s content. This transcript will serve as the foundation for further analysis and processing steps in our pipeline. Additionally, the extracted data points will be structured and organized in a format of our choosing (JSON, Markup, etc.), defined in the prompt, allowing us to seamlessly integrate them into our downstream systems to generate insightful summaries, visualizations, and other valuable outputs.</p>
<h2 class="heading-2" id="_idParaDest-63">Prompt pre-processing</h2>
<p class="normal">As a first step, we will start <a id="_idIndexMarker193"/>elaborating a prompt to extract the essential data points required to comprehensively understand a 10-K document. To guide our efforts, we will leverage a valuable resource provided <a id="_idIndexMarker194"/>by the SEC itself – a document titled <em class="italic">How to Read a 10k</em>, which is available on the SEC website (<a href="https://www.sec.gov/files/reada10k.pdf">https://www.sec.gov/files/reada10k.pdf</a>).</p>
<p class="normal">This SEC-provided document serves as a very useful roadmap, outlining the critical sections and information that investors and analysts should focus on when delving into a company’s 10-K filing. By carefully studying this resource, we can identify the key data points that are most relevant and insightful, ensuring that our GenAI system extracts the information that truly matters.</p>
<p class="normal">To kickstart our data extraction process, we will create a simple yet effective prompt for our GenAI model. This initial prompt will serve as a starting point, instructing the model to identify and extract the specific data points outlined in the <em class="italic">How to Read a 10k</em> document. While this initial prompt may be concise, it will lay the foundation for more sophisticated prompts and fine-tuning techniques as our project progresses. The goal is to iteratively refine our prompts, leveraging the power of <a id="_idIndexMarker195"/>GenAI to extract the most crucial information accurately and efficiently from these complex financial documents.</p>
<pre class="programlisting code"><code class="hljs-code">prompt = """
You are an expert business analyst. Your task is to evaluate documents. 
From the context document generate a JSON template with the important data points to be extracted from the document, also remember to add an attribute for the summary of the section. 
The output should be a well-formed JSON document. 
Context: 
reada10k.pdf
Response: 
"""
</code></pre>
<p class="normal">The following is example output from the previous prompt:</p>
<pre class="programlisting con"><code class="hljs-con">{
    "10k_template": {
        "part_I": {
            "item_1_business": {
                "description": "Company's main products and services, subsidiaries, and markets",
                "recent_events": null,
                "competition": null,
                "regulations": null,
                "labor_issues": null,
                "operating_costs": null,
                "seasonal_factors": null,
                "summary": null
            },
            "item_1a_risk_factors": {
                "risk_factors": [],
                "summary": null
            },
            "item_1b_unresolved_staff_comments": {
                "comments": [],
                "summary": null
            },
            "item_2_properties": {
                "properties": [],
                "summary": null
            },
            "item_3_legal_proceedings": {
                "proceedings": [],
                "summary": null
            },
            "item_4": {
                "reserved": true
            }
        },
        "part_II": {
            "item_5_market_for_registrants_common_equity": {
                "market_information": null,
                "number_of_holders": null,
                "dividends": null,
                "stock_repurchases": null,
                "summary": null
            },
            "item_6_selected_financial_data": {
                "financial_data": {},
                "summary": null
            },
            "item_7_managements_discussion_and_analysis": {
                "operations_and_financial_results": null,
                "liquidity_and_capital_resources": null,
                "trends_and_uncertainties": null,
                "critical_accounting_judgments": null,
                "off_balance_sheet_arrangements": null,
                "contractual_obligations": null,
                "summary": null
            },
            "item_7a_quantitative_and_qualitative_disclosures_about_market_risk": {
                "market_risk_exposures": null,
                "risk_management": null,
                "summary": null
            },
            "item_8_financial_statements_and_supplementary_data": {
                "income_statement": null,
                "balance_sheets": null,
                "statement_of_cash_flows": null,
                "statement_of_stockholders_equity": null,
                "notes_to_financial_statements": null,
                "auditors_report": null,
                "summary": null
            },
            "item_9_changes_in_and_disagreements_with_accountants": {
                "changes_in_accountants": null,
                "disagreements": null,
                "summary": null
            },
            "item_9a_controls_and_procedures": {
                "disclosure_controls_and_procedures": null,
                "internal_control_over_financial_reporting": null,
                "summary": null
            },
            "item_9b_other_information": {
                "other_information": null,
                "summary": null
            }
        },
        "part_III": {
            "item_10_directors_executive_officers_and_corporate_governance": {
                "directors_and_executive_officers": [],
                "code_of_ethics": null,
                "board_qualifications": null,
                "summary": null
            },
            "item_11_executive_compensation": {
                "compensation_policies_and_programs": null,
                "executive_compensation": {},
                "summary": null
            },
            "item_12_security_ownership": {
                "ownership_information": {},
                "equity_compensation_plans": null,
                "summary": null
            },
            "item_13_certain_relationships_and_related_transactions": {
                "relationships_and_transactions": [],
                "director_independence": null,
                "summary": null
            },
            "item_14_principal_accountant_fees_and_services": {
                "fees_for_services": {},
                "summary": null
            }
        },
        "part_IV": {
            "item_15_exhibits_financial_statement_schedules": {
                "exhibits": [],
                "financial_statement_schedules": null,
                "summary": null
            }
        }
    }
</code></pre>
<p class="normal">Now that we have a template of what to<a id="_idIndexMarker196"/> look for in the actual 10-K, we can create a prompt to extract those data points:</p>
<pre class="programlisting code"><code class="hljs-code">You are an expert business analyst specializing in 10-K documents.
Your task is to extract information from 10-K documents; to achieve this task, follow these steps:
Carefully analyze the document provided as context.
Use the template as a reference to understand which data points to extract.
Never make up information; if you don't remember something, go back to read the document. If the data is not available, add "Not available" as the value.
Return a well-formed JSON document following the template.
Always think step by step.
&lt;template&gt;
{
    "10k_template": {
        "part_I": {
            "item_1_business": {
                "description": "Company's main products and services, subsidiaries, and markets",
                "recent_events": null,
                "competition": null,
                "regulations": null,
                "labor_issues": null,
                "operating_costs": null,
                "seasonal_factors": null,
                "summary": null
            },
            "item_1a_risk_factors": {
                "risk_factors": [],
                "summary": null
            },
            "item_1b_unresolved_staff_comments": {
                "comments": [],
                "summary": null
            },
            "item_2_properties": {
                "properties": [],
                "summary": null
            },
            "item_3_legal_proceedings": {
                "proceedings": [],
                "summary": null
            },
            "item_4": {
                "reserved": true
            }
        },
        "part_II": {
            "item_5_market_for_registrants_common_equity": {
                "market_information": null,
                "number_of_holders": null,
                "dividends": null,
                "stock_repurchases": null,
                "summary": null
            },
            "item_6_selected_financial_data": {
                "financial_data": {},
                "summary": null
            },
            "item_7_managements_discussion_and_analysis": {
                "operations_and_financial_results": null,
                "liquidity_and_capital_resources": null,
                "trends_and_uncertainties": null,
                "critical_accounting_judgments": null,
                "off_balance_sheet_arrangements": null,
                "contractual_obligations": null,
                "summary": null
            },
            "item_7a_quantitative_and_qualitative_disclosures_about_market_risk": {
                "market_risk_exposures": null,
                "risk_management": null,
                "summary": null
            },
            "item_8_financial_statements_and_supplementary_data": {
                "income_statement": null,
                "balance_sheets": null,
                "statement_of_cash_flows": null,
                "statement_of_stockholders_equity": null,
                "notes_to_financial_statements": null,
                "auditors_report": null,
                "summary": null
            },
            "item_9_changes_in_and_disagreements_with_accountants": {
                "changes_in_accountants": null,
                "disagreements": null,
                "summary": null
            },
            "item_9a_controls_and_procedures": {
                "disclosure_controls_and_procedures": null,
                "internal_control_over_financial_reporting": null,
                "summary": null
            },
            "item_9b_other_information": {
                "other_information": null,
                "summary": null
            }
        },
        "part_III": {
            "item_10_directors_executive_officers_and_corporate_governance": {
                "directors_and_executive_officers": [],
                "code_of_ethics": null,
                "board_qualifications": null,
                "summary": null
            },
            "item_11_executive_compensation": {
                "compensation_policies_and_programs": null,
                "executive_compensation": {},
                "summary": null
            },
            "item_12_security_ownership": {
                "ownership_information": {},
                "equity_compensation_plans": null,
                "summary": null
            },
            "item_13_certain_relationships_and_related_transactions": {
                "relationships_and_transactions": [],
                "director_independence": null,
                "summary": null
            },
            "item_14_principal_accountant_fees_and_services": {
                "fees_for_services": {},
                "summary": null
            }
        },
        "part_IV": {
            "item_15_exhibits_financial_statement_schedules": {
                "exhibits": [],
                "financial_statement_schedules": null,
                "summary": null
            }
        }
    }
}
&lt;/template&gt;
&lt;document&gt;
&lt;/document&gt;
Response:
</code></pre>
<p class="normal">Note that the template has very specific<a id="_idIndexMarker197"/> instructions on what to do as well as what <em class="italic">not</em> to do. This is a best practice for prompting LLMs, as these models require such specific instructions in order to effectively give you precise information. A good analogy is to guide them as if they are a first-year student, offering clear instructions and providing as much context as possible.</p>
<h2 class="heading-2" id="_idParaDest-64">Inference</h2>
<p class="normal">For the inference, we are going to<a id="_idIndexMarker198"/> submit our prompt to Gemini Pro 1.5 available through Vertex-AI.</p>
<p class="normal">The Vertex AI Gemini API is tailored for developers and enterprises seeking to incorporate Gemini models into scaled deployments. This enterprise-grade offering provides a robust set of features designed to meet the demands of modern, high-performance applications. With the Vertex AI Gemini API, you can benefit from enhanced enterprise security measures, ensuring that your data and models are protected with industry-leading safeguards. Additionally, it offers data residency options, allowing you to comply with regional data storage and processing regulations:</p>
<pre class="programlisting code"><code class="hljs-code">{
    "10k_template": {
        "part_I": {
            "item_1_business": {
                "description": "Company's main products and services, subsidiaries, and markets",
                "recent_events": null,
                "competition": null,
                "regulations": null,
                "labor_issues": null,
                "operating_costs": null,
                "seasonal_factors": null,
                "summary": null
            },
            "item_1a_risk_factors": {
                "risk_factors": [],
                "summary": null
            },
            "item_1b_unresolved_staff_comments": {
                "comments": [],
                "summary": null
            },
            "item_2_properties": {
                "properties": [],
                "summary": null
            },
            "item_3_legal_proceedings": {
                "proceedings": [],
                "summary": null
            },
            "item_4": {
                "reserved": true
            }
        },
        "part_II": {
            "item_5_market_for_registrants_common_equity": {
                "market_information": null,
                "number_of_holders": null,
                "dividends": null,
                "stock_repurchases": null,
                "summary": null
            },
            "item_6_selected_financial_data": {
                "financial_data": {},
                "summary": null
            },
            "item_7_managements_discussion_and_analysis": {
                "operations_and_financial_results": null,
                "liquidity_and_capital_resources": null,
                "trends_and_uncertainties": null,
                "critical_accounting_judgments": null,
                "off_balance_sheet_arrangements": null,
                "contractual_obligations": null,
                "summary": null
            },
            "item_7a_quantitative_and_qualitative_disclosures_about_market_risk": {
                "market_risk_exposures": null,
                "risk_management": null,
                "summary": null
            },
            "item_8_financial_statements_and_supplementary_data": {
                "income_statement": null,
                "balance_sheets": null,
                "statement_of_cash_flows": null,
                "statement_of_stockholders_equity": null,
                "notes_to_financial_statements": null,
                "auditors_report": null,
                "summary": null
            },
            "item_9_changes_in_and_disagreements_with_accountants": {
                "changes_in_accountants": null,
                "disagreements": null,
                "summary": null
            },
            "item_9a_controls_and_procedures": {
                "disclosure_controls_and_procedures": null,
                "internal_control_over_financial_reporting": null,
                "summary": null
            },
            "item_9b_other_information": {
                "other_information": null,
                "summary": null
            }
        },
        "part_III": {
            "item_10_directors_executive_officers_and_corporate_governance": {
                "directors_and_executive_officers": [],
                "code_of_ethics": null,
                "board_qualifications": null,
                "summary": null
            },
            "item_11_executive_compensation": {
                "compensation_policies_and_programs": null,
                "executive_compensation": {},
                "summary": null
            },
            "item_12_security_ownership": {
                "ownership_information": {},
                "equity_compensation_plans": null,
                "summary": null
            },
            "item_13_certain_relationships_and_related_transactions": {
                "relationships_and_transactions": [],
                "director_independence": null,
                "summary": null
            },
            "item_14_principal_accountant_fees_and_services": {
                "fees_for_services": {},
                "summary": null
            }
        },
        "part_IV": {
            "item_15_exhibits_financial_statement_schedules": {
                "exhibits": [],
                "financial_statement_schedules": null,
                "summary": null
            }
        }
    }
}
</code></pre>
<p class="normal">Note that <a id="_idIndexMarker199"/>there are configurations available to play with in the API. You can check the specific call in the code provided in the GitHub repository of the book.</p>
<h2 class="heading-2" id="_idParaDest-65">Result post-processing</h2>
<p class="normal">Once the LLM has processed the 10-K reports, it will return the results in a structured JSON format. This JSON <a id="_idIndexMarker200"/>document will contain the extracted data points, organized in a hierarchical manner that aligns with the structure of the 10-K report itself. To effectively utilize these results, we will need to parse the JSON document and extract the relevant information.</p>
<p class="normal">The next step in our pipeline is to ingest the parsed data into a database for efficient storage and retrieval. The specific ingestion strategy will depend on the type of database we choose to employ. For example, if we opt for a relational database, we will need to map the extracted data points to appropriate table structures, ensuring proper normalization and adherence to data integrity principles.</p>
<p class="normal">Alternatively, if we decide to use a document database, the ingestion process will be more straightforward, as these databases are designed to store hierarchical data structures, such as JSON documents, natively. In this case, we can directly ingest the parsed JSON results, leveraging the database’s ability to efficiently store and query complex data structures.</p>
<p class="normal">Regardless of the database type chosen, it is crucial to design an ingestion strategy that ensures data consistency, scalability, and performance. This may involve implementing strategies such as bulk ingestion, indexing, and partitioning to optimize the database’s performance and ensure efficient retrieval of the extracted data points.</p>
<p class="normal">In addition to storing the extracted data points, we can also consider generating embeddings for the various sections of the 10-K reports. Embeddings are vector representations of text that capture semantic meaning, enabling efficient similarity searches and retrieval. By generating embeddings for the report sections, we can integrate our dataset with a vector search pipeline, allowing users to perform advanced queries based on semantic similarity.</p>
<p class="normal">For a deep <a id="_idIndexMarker201"/>dive into embeddings generation and vector search integration, we will cover the <strong class="keyWord">Retrieval Augmented Generation</strong> (<strong class="keyWord">RAG</strong>) example in a dedicated chapter. This chapter will provide detailed insights <a id="_idIndexMarker202"/>into the process of generating embeddings, constructing vector databases, and implementing efficient vector search algorithms, enabling you to create powerful search and retrieval capabilities for your GenAI applications.</p>
<h2 class="heading-2" id="_idParaDest-66">Result presentation</h2>
<p class="normal">When it comes to presenting the results obtained<a id="_idIndexMarker203"/> from processing the 10-K reports, it’s important to consider the fact that these results are ingested into a database. This means that the considerations you’ll need to make are similar to those you would have when developing an experience that leverages data available in a database.</p>
<p class="normal">One of the primary considerations is the need for a tool or platform that can effectively aggregate and analyze data stored in a database. This could be a <strong class="keyWord">business intelligence</strong> (<strong class="keyWord">BI</strong>) tool, a data visualization platform, or even a custom-built application tailored to your specific needs. The chosen tool should provide robust querying capabilities, enabling you to extract and combine data from various tables or collections within the database.</p>
<p class="normal">Additionally, the presentation layer should offer a range of visualization options, such as charts, graphs, and dashboards, to effectively communicate the insights derived from the data. These visualizations should be interactive, allowing users to explore the data from different perspectives, filter and sort the results, and drill down into specific areas of interest.</p>
<p class="normal">Furthermore, the presentation layer should be designed with scalability and performance in mind. As the volume of data grows over time, the ability to handle large datasets and provide responsive user experiences becomes crucial. This may involve implementing techniques such as caching, indexing, and optimizing database queries to ensure efficient data retrieval and rendering.</p>
<p class="normal">On the GitHub directory for this chapter, you will find the complete code and an analysis of how all the layers described in this chapter fit together.</p>
<h1 class="heading-1" id="_idParaDest-67">Summary</h1>
<p class="normal">In this chapter, we explored metadata extraction from financial documents, specifically 10-K reports filed by publicly traded companies. We walked through the experience of working with a financial services firm that needs to extract key data points from these massive 10-K annual reports, leveraging the data extraction capabilities of LLMs. </p>
<p class="normal">We defined the use case, and we leveraged the power of GenAI to navigate through the structured sections of a 10-K, pinpointing and extracting the most relevant information nuggets, following the guidance provided by a best practices document. We walked through the process, starting by crafting an effective prompt to guide the AI model. This involved studying an SEC resource that outlines the critical sections and data points that investors should focus on. Armed with this knowledge, we can iteratively refine our prompts to ensure accurate and efficient extraction.</p>
<p class="normal">Then, we proposed a cloud-native, serverless architecture on Google Cloud to handle the batch processing of these documents. This scalable setup can leverage various services like Cloud Storage, Pub/Sub, and Cloud Functions, allowing us to seamlessly integrate the AI model and store the extracted data.</p>
<p class="normal">The chapter also touched on post-processing steps, such as ingesting the extracted data into a database (relational or document-based), potentially generating embeddings for vector similarity searches, and presenting the results through BI tools or custom applications with interactive visualizations.</p>
<p class="normal">In summary, this chapter offered you a practical blueprint to utilize GenAI to enhance the extraction and analysis of critical information from complex financial documents. It demonstrated how you can leverage this technology to make more informed decisions and uncover valuable insights, thereby optimizing your operational efficiency and strategic capabilities.</p>
<p class="normal">In the next chapter, we will examine a summarization use case. This example will illustrate another instance of what a batch processing use case could look like. </p>
<h1 class="heading-1">Join our community on Discord</h1>
<p class="normal">Join our community’s Discord space for discussions with the authors and other readers:</p>
<p class="normal"><a href="Chapter_05.xhtml">https://packt.link/genpat</a></p>
<p class="normal"><img alt="" height="177" src="img/QR_Code134841911667913109.png" width="177"/></p>
</div>
</div></body></html>