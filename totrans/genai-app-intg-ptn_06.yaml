- en: '6'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Integration Pattern: Batch Summarization'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will explore the application of **Generative AI** (**GenAI**)
    to summarize documents, an invaluable capability across industries. However, before
    delving into a specific use case, it’s essential to recognize that search intelligence
    powered by GenAI supports multiple use cases beyond document summarization. These
    include test case generation, document search supporting text, audio, and video-based
    data, as well as various analysis business use cases. Our focus, however, will
    be on a compelling use case within the financial services sector, where document
    summarization can streamline processes and enhance regulatory compliance efforts.
  prefs: []
  type: TYPE_NORMAL
- en: To illustrate this use case, let’s consider a scenario where a financial services
    company is faced with the daunting task of reviewing a high volume of client applications.
    These applications often span multiple pages and encompass a wide range of information,
    including personal details, financial history, investment goals, and risk profiles.
  prefs: []
  type: TYPE_NORMAL
- en: Manually reviewing and distilling the key points from each application can be
    a time-consuming and error-prone process, especially when dealing with a large
    influx of submissions. This is where GenAI-driven summarization can be a game-changer,
    enabling efficient extraction of the most salient information while ensuring regulatory
    compliance by providing the ability not only to summarize but also to follow guidelines
    about what aspects to focus on, providing an elevated experience.
  prefs: []
  type: TYPE_NORMAL
- en: By leveraging GenAI models’ natural language understanding and generation capabilities,
    companies can develop a system that intelligently analyzes regulatory documents,
    identifies the critical details, and generates concise summaries.
  prefs: []
  type: TYPE_NORMAL
- en: These summaries can then be seamlessly integrated into downstream processes,
    such as risk assessment, portfolio construction, or client onboarding workflows.
  prefs: []
  type: TYPE_NORMAL
- en: It is important to note that this use case is not intended to replace the work
    of a compliance officer but to enhance them through GenAI while optimizing their
    work in terms of quality and efficiency.
  prefs: []
  type: TYPE_NORMAL
- en: The chapter will build on the example by referring to the GenAI integration
    framework proposed in *Chapter 4*, *Generative AI Batch and Real-time Integration
    Patterns*. It starts by defining the use case of summarizing client applications
    in the financial services industry to streamline processes and enhance regulatory
    compliance efforts. It then proposes a cloud-native, serverless architecture on
    Google Cloud for batch processing these client applications.
  prefs: []
  type: TYPE_NORMAL
- en: We will then delve into the entry point of the pipeline, which is an object
    created in **Google Cloud Storage** (**GCS**), triggering a cloud function to
    initiate the summarization process. It emphasizes the importance of prompt pre-processing,
    incorporating domain-specific knowledge and compliance guidelines into the prompts.
  prefs: []
  type: TYPE_NORMAL
- en: We will cover the inference phase, where the tailored prompts and client application
    content are submitted to Google Gemini on Vertex AI to generate concise summaries.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll discuss the result post-processing, ingesting the summaries into a database,
    and various approaches for presenting the summaries, such as dedicated applications
    or integration with existing systems. We’ll also provide the sample code for implementing
    the proposed solution on Google Cloud.
  prefs: []
  type: TYPE_NORMAL
- en: Use case definition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this example use case, we will work on a 10-K form summarization use case.
    The 10-K form aims to provide transparency into the company’s financial health,
    operations, and risk factors for investors and regulators. The details can span
    hundreds of pages for large, complex companies.
  prefs: []
  type: TYPE_NORMAL
- en: Summarizing the extensive 10-K annual filings from public companies can unlock
    significant value for financial services firms. These lengthy documents, often
    spanning hundreds of pages, contain critical information about a company’s business
    operations, financial performance, risk factors, and strategies. However, manually
    analyzing these filings is an extremely time-consuming and inefficient process.
    By leveraging advanced AI capabilities to generate concise summaries of 10-Ks,
    financial institutions can accelerate their analysis while ensuring consistent
    extraction of the most pertinent details. These summaries provide investment professionals
    with quick access to key financial metrics, competitive insights, potential risks,
    and future outlooks, enabling more informed investment decisions and portfolio
    monitoring.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, summarized 10-Ks can be seamlessly integrated into existing research
    workflows, regulatory compliance processes, and decision support systems within
    financial firms. This automated approach enhances scalability, allowing analysts
    to process large volumes of filings rapidly. It also mitigates the risk of human
    error or oversight that can occur during manual analysis. Consequently, financial
    services companies can leverage AI-driven 10-K summarization to gain a competitive
    edge through optimized investment analysis, improved risk management practices,
    and better-informed capital allocation strategies – ultimately contributing to
    enhanced returns and operational efficiency across their businesses.
  prefs: []
  type: TYPE_NORMAL
- en: Manually reviewing these forms can be a time-consuming and error-prone process,
    especially when dealing with a large volume of forms. Financial services professionals
    must carefully analyze each section, identify the key information, and ensure
    that the client’s needs and risk profiles are accurately understood.
  prefs: []
  type: TYPE_NORMAL
- en: By leveraging a GenAI-driven approach to summarization, financial institutions
    can streamline various manual processes, extracting the most salient information
    from each form while adhering to regulatory compliance standards. The summaries
    can then enable financial advisors and portfolio managers to quickly grasp the
    client’s situation and make informed decisions. The following diagram captures
    this by explaining the different components that will be used when designing the
    prompt.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B22175_06_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.1: 10-K summarization prompt generation diagram'
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, these summaries can be seamlessly integrated into downstream processes,
    such as risk assessment, portfolio construction, or client onboarding workflows,
    reducing the need for manual data entry and minimizing the risk of errors.
  prefs: []
  type: TYPE_NORMAL
- en: Compliance officers can also benefit from GenAI-driven summarization by incorporating
    specific rules and guidelines into the prompts. For example, the summarization
    model can be instructed to highlight potential red flags, such as inconsistencies
    in financial information or discrepancies between stated risk tolerance and investment
    objectives. By surfacing these issues promptly, compliance teams can proactively
    address them, ensuring adherence to regulatory requirements and mitigating potential
    risks.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, the summaries generated by GenAI models can serve as a valuable reference
    point for future client interactions, enabling financial advisors to quickly review
    the client’s situation and provide personalized advice or recommendations, ultimately
    leading to improved client experiences and stronger relationships.
  prefs: []
  type: TYPE_NORMAL
- en: Architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Building upon the architecture discussed in *Chapter 5*, *Integration Pattern:
    Batch Metadata Extraction,* for the first batch processing example, we will adopt
    a similar cloud-native, serverless approach on Google Cloud to handle the batch
    processing of client applications for summarization. This scalable setup leverages
    various services, allowing us to seamlessly integrate the AI model and store the
    generated summaries.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The architecture will consist of the following components:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Object store** (**Google Cloud Storage**): This highly scalable and durable
    object store will be used to store client applications, which can be in various
    formats, such as PDFs, Word documents, or structured data files.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Messaging queue** (**Google Cloud Pub/Sub**): A messaging queue will be employed
    to coordinate the data flow and manage the processing of client applications.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Processing component** (**Google Cloud Functions**): Cloud Functions will
    serve as the processing component, executing the summarization tasks and invoking
    the LLM.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**LLM** (**Google Gemini**): We will leverage a powerful LLM, such as Google
    Gemini, hosted on Vertex AI to perform the actual summarization.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Database** (**Google BigQuery** or **Cloud Firestore**): The generated summaries
    will be stored in a structured format, in either a relational database (BigQuery)
    or a document database (Cloud Firestore), depending on the specific requirements.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The interactions between these components are represented in the following
    diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B22175_06_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.2: Batch summarization use case architecture diagram'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s a breakdown of the flow of the architecture:'
  prefs: []
  type: TYPE_NORMAL
- en: Client applications are uploaded to Google Cloud Storage, triggering a cloud
    function as soon as the documents are in the bucket.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The cloud function reads the list of applications from Cloud Storage and publishes
    messages to a Pub/Sub topic, effectively creating a queue of applications to be
    processed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Another cloud function, subscribed to the Pub/Sub topic, is triggered for each
    message tied to a given application in the queue.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This second cloud function invokes the LLM (for example, Google Gemini) hosted
    on Vertex AI, passing the application content as input along with a tailored prompt.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The LLM processes the application, leveraging its natural language understanding
    capabilities to generate a concise summary while adhering to any specified rules
    or guidelines.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The generated summary is then stored in a structured format (for example, BigQuery
    or Cloud Firestore) for further analysis, integration, and consumption.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This serverless architecture provides several benefits, including automatic
    scaling, cost-efficiency (pay-per-use pricing), and seamless integration with
    other Google Cloud services. Additionally, it allows easy integration with existing
    workflows, enabling financial institutions to leverage GenAI-driven summarization
    without significant disruptions to their existing processes.
  prefs: []
  type: TYPE_NORMAL
- en: Entry point
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Similar to the previous chapter, the entry point for our batch processing pipeline
    will be an object created in **Google Cloud Storage** (**GCS**). As client applications
    are uploaded to a designated GCS bucket, a cloud function will be triggered, initiating
    the summarization process.
  prefs: []
  type: TYPE_NORMAL
- en: For this use case, we will leverage the powerful capabilities of Google Gemini,
    a state-of-the-art GenAI model renowned for its natural language understanding
    and generation abilities. Gemini will analyze the uploaded client application,
    intelligently extracting the most salient information and generating a concise
    summary.
  prefs: []
  type: TYPE_NORMAL
- en: To ensure regulatory compliance and adherence to specific guidelines, we will
    incorporate rules and instructions into the prompt provided to Gemini. These rules
    may include highlighting potential red flags, ensuring consistency between stated
    risk tolerance and investment objectives, or emphasizing specific sections of
    the application based on compliance requirements.
  prefs: []
  type: TYPE_NORMAL
- en: By combining Gemini’s advanced reasoning capabilities with tailored prompts
    and rules, we can generate summaries that not only capture the essence of the
    client’s application but also facilitate efficient review and decision-making
    processes while maintaining regulatory compliance.
  prefs: []
  type: TYPE_NORMAL
- en: Prompt pre-processing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will start by crafting an effective prompt to guide the GenAI model in generating
    accurate and compliant summaries. In this case, we will leverage insights from
    compliance officers and subject matter experts within the financial services industry
    to understand the critical information that needs to be captured in the summaries.
  prefs: []
  type: TYPE_NORMAL
- en: It is important to remark that the intent behind this prompt is to provide an
    example of what compliance guidelines may look like, but in no way does this represent
    a real-world compliance example nor is it intended to be used to analyze business
    profiles.
  prefs: []
  type: TYPE_NORMAL
- en: Based on these insights, we will develop a template or a set of guidelines that
    outline the key sections and data points to be included in the summaries. This
    template will serve as a foundation for our prompt, ensuring that the summaries
    generated by the GenAI model align with the specific requirements of the financial
    services company.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, we will incorporate rules and guidelines provided by compliance
    officers to ensure that the summaries adhere to relevant regulations and industry
    best practices. These rules may include instructions for highlighting potential
    discrepancies, inconsistencies, or areas of concern that require further review
    or investigation.
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, when designing our prompt and incorporating domain-specific
    knowledge and compliance guidelines, we can leverage the power of GenAI to generate
    summaries that are not only concise and accurate but also provide insights related
    to compliance and regulatory requirements, ultimately streamlining the application
    review process while reducing potential risks.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Inference
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For the inference phase, we will submit our prompt, along with the client application
    content, to the Google Gemini model available through Vertex AI. The Vertex AI
    platform provides a robust and scalable environment for deploying and managing
    GenAI models, ensuring high performance and enterprise-grade security.
  prefs: []
  type: TYPE_NORMAL
- en: In our example, we are using an example dataset of companies that signed up
    for our fictional financial services company. The inference code will work on
    the whole dataset, with delays to prevent consuming the available quota. Depending
    on your cloud provider or setup, you may have different inference quotas, which
    are generally related to **QPS** (**queries per second**) or **QPM** (**queries
    per minute**). In our example, we have a 6 QPM limit.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'When thinking about a more complex inference pipeline, we need to focus on
    the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: The cloud function, triggered by the arrival of a new client application in
    GCS, retrieves the application content and the tailored prompt.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The cloud function invokes the Gemini model on Vertex AI, passing the application
    content and prompt as input.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Gemini processes the application, leveraging its natural language understanding
    capabilities to generate a concise summary while adhering to the specified rules
    and guidelines outlined in the prompt.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The generated summary is returned to the cloud function for further processing
    and storage.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: By leveraging the power of Gemini and the scalability of Vertex AI, we can efficiently
    process large volumes of client applications, generating accurate and compliant
    summaries in a timely manner.
  prefs: []
  type: TYPE_NORMAL
- en: Result post-processing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once the LLM has processed the client applications, it will return the summaries
    in a structured format, such as JSON or a markup language. The next step in our
    pipeline is to ingest these summaries into a database for efficient storage and
    retrieval.
  prefs: []
  type: TYPE_NORMAL
- en: The specific ingestion strategy will depend on the database type we choose to
    employ. For example, if we opt for a relational database like BigQuery, we will
    need to map the summary data points to appropriate table structures, ensuring
    proper normalization and adherence to data integrity principles.
  prefs: []
  type: TYPE_NORMAL
- en: Alternatively, if we decide to use a document database like Cloud Firestore,
    the ingestion process will be more straightforward, as these databases are designed
    to store hierarchical data structures natively. In this case, we can directly
    ingest the summaries in their original format, leveraging the database’s ability
    to efficiently store and query complex data structures.
  prefs: []
  type: TYPE_NORMAL
- en: Regardless of the database type chosen, it is crucial to design an ingestion
    strategy that ensures data consistency, scalability, and performance. This may
    involve implementing strategies such as bulk ingestion, indexing, and partitioning
    to optimize the database’s performance and ensure efficient retrieval of the summaries.
  prefs: []
  type: TYPE_NORMAL
- en: Result presentation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When it comes to presenting the summaries generated from client applications,
    several factors need to be considered, including the target audience, the intended
    use case, and the integration with existing systems and workflows.
  prefs: []
  type: TYPE_NORMAL
- en: One approach is to develop a dedicated application or dashboard that allows
    financial advisors, portfolio managers, and compliance officers to easily access
    and review the summaries. This application could provide features such as filtering,
    sorting, and searching capabilities, enabling users to quickly locate and analyze
    summaries based on specific criteria, such as client risk profiles, investment
    goals, or potential red flags identified by the GenAI model.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, the application could offer visualization tools to present the
    summary data in a more intuitive and visually appealing manner. For example, charts
    and graphs could be used to depict the client’s financial profile, risk tolerance,
    and investment objectives, providing financial advisors with a comprehensive overview
    at a glance.
  prefs: []
  type: TYPE_NORMAL
- en: Another approach is to integrate the summaries directly into existing **customer
    relationship management** (**CRM**) systems or client onboarding workflows. This
    integration would allow financial advisors and compliance officers to access the
    summaries seamlessly within the tools and platforms they already use, minimizing
    disruptions to their existing processes.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, the summaries could be leveraged for automation and decision support
    purposes. For instance, rules-based systems or machine learning models could be
    trained to analyze the summaries and provide recommendations or risk assessments,
    further enhancing the efficiency and accuracy of the client onboarding and portfolio
    management processes.
  prefs: []
  type: TYPE_NORMAL
- en: Regardless of the presentation approach chosen, it is essential to ensure that
    the summaries are presented in a secure and compliant manner, adhering to industry
    regulations and data privacy standards. Access controls and authorization mechanisms
    should be implemented to ensure that sensitive client information is only accessible
    to authorized personnel.
  prefs: []
  type: TYPE_NORMAL
- en: On the GitHub directory for this chapter, you will find the complete code and
    an analysis of how all the pieces described in this chapter fit together. Pay
    special attention to how every component of the framework interacts with each
    other.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we explored the application of GenAI to summarize client applications
    in the financial services industry. We kicked things off by defining the problem
    statement, where financial institutions need to efficiently review and distill
    key information from lengthy client applications while ensuring regulatory compliance.
  prefs: []
  type: TYPE_NORMAL
- en: We highlighted the value of GenAI-driven summarization in this context, enabling
    the extraction of salient details, streamlining downstream processes, and facilitating
    better-informed decision-making while adhering to compliance standards.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we proposed a cloud-native, serverless architecture on Google Cloud to
    handle the batch processing of client applications for summarization. This scalable
    setup leverages various services, including Cloud Storage, Pub/Sub, Cloud Functions,
    and databases like BigQuery or Cloud Firestore, allowing for seamless integration
    of the AI model and storage of the generated summaries.
  prefs: []
  type: TYPE_NORMAL
- en: We then delved into the process of prompt pre-processing, emphasizing the importance
    of incorporating domain-specific knowledge and compliance guidelines into the
    prompts. By collaborating with subject matter experts and compliance officers,
    we can craft prompts that guide the GenAI model to generate accurate and compliant
    summaries.
  prefs: []
  type: TYPE_NORMAL
- en: The inference phase involved submitting the tailored prompts and client application
    content to Google Gemini on Vertex AI. Gemini’s advanced natural language understanding
    and generation capabilities, combined with the carefully crafted prompts, enable
    the generation of concise and insightful summaries.
  prefs: []
  type: TYPE_NORMAL
- en: We also covered the post-processing steps, such as ingesting the summaries into
    a database, and discussed various approaches for presenting the summaries, including
    dedicated applications, dashboards, or integration with existing CRM systems and
    workflows.
  prefs: []
  type: TYPE_NORMAL
- en: Overall, this chapter provides a practical framework for leveraging the power
    of GenAI to streamline the review and analysis of client applications in the financial
    services industry, while ensuring regulatory compliance and enabling more efficient
    and informed decision-making processes.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will explore a real-time use case that focuses on intent
    classification with GenAI.
  prefs: []
  type: TYPE_NORMAL
- en: Join our community on Discord
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join our community’s Discord space for discussions with the authors and other
    readers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/genpat](Chapter_06.xhtml)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code134841911667913109.png)'
  prefs: []
  type: TYPE_IMG
