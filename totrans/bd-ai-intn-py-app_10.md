# 10

# 精炼语义数据模型以提高准确性

为了在智能应用中有效地使用向量搜索进行语义长期记忆，你必须优化语义数据模型以满足应用的需求。由于语义数据模型使用向量嵌入模型和向量搜索，你必须优化嵌入数据的内容以及数据检索的方式。

精炼语义数据模型可以提高检索准确性和整体应用性能。在**检索增强生成**（**RAG**）应用中，一个有效的语义数据模型是构建强大检索系统的基石，它直接影响到生成输出的质量。本章的其余部分将探讨你可以如何精炼语义数据模型和检索的不同方法。

本章将涵盖以下主题：

+   尝试不同的嵌入模型

+   微调嵌入模型

+   在嵌入内容中包含元数据以最大化语义相关性

+   优化RAG用例的各种技术，包括查询变异、格式化导入数据以及高级检索系统

# 技术要求

运行本章中的代码需要以下技术要求：

+   安装了Python 3.x的编程环境

+   能够在本地运行开源嵌入模型`gte-base-en-v1.5`的编程环境

+   OpenAI API密钥。要创建API密钥，请参阅OpenAI文档中的[https://platform.openai.com/docs/quickstart/step-2-set-up-your-api-key](https://platform.openai.com/docs/quickstart/step-2-set-up-your-api-key)

# 嵌入

**向量嵌入**是语义数据模型的基础，作为想法和关系的机器可解释表示。嵌入是多维空间中对象的数学表示，作为连接智能应用中各种语义数据片段的粘合剂。向量之间的距离与语义相似性相关。你可以使用这个语义相似性分数来检索其他难以连接的相关信息。这个概念无论在特定用例中是否成立，无论是RAG、推荐系统、异常检测还是其他，都是正确的。

拥有一个更适合特定用例的嵌入模型可以提高准确性和性能。通过尝试不同的嵌入模型并在特定领域的数据上进行微调，可以帮助确定特定用例的最佳匹配，从而进一步增强其有效性。

## 尝试不同的嵌入模型

在构建智能应用时，你可以尝试不同的预训练嵌入模型。不同的模型在准确性、成本和效率方面有所不同。它们的性能会根据具体的应用和数据而显著变化。通过尝试多个模型，开发者可以确定最适合其用例的模型。

*表10.1*列出了截至2024年春季的一些流行嵌入模型，这些模型来自Hugging Face的**大规模测试嵌入基准**（**MTEB**）排行榜[1](B22495_10.xhtml#footnote-002)

[1](B22495_10.xhtml#footnote-002-backlink) MTEB排行榜上的信息是在2024年4月30日采集的。（[https://huggingface.co/spaces/mteb/leaderboard](https://huggingface.co/spaces/mteb/leaderboard)）

| **模型名称** | **开发者** | **是否开源** | **嵌入长度** | **平均分数**[2](B22495_10.xhtml#footnote-001)[2](B22495_10.xhtml#footnote-001-backlink) 此分数是各种基准的平均值。有关基准中使用的评估指标的更多信息，请参阅*MTEB：大规模文本嵌入基准*研究论文（[https://arxiv.org/abs/2210.07316](https://arxiv.org/abs/2210.07316)）。 |
| --- | --- | --- | --- | --- |
| `text-embedding-3-large` | OpenAI | 否 | 3072 | 64.59 |
| `cohere-embed-english-v3.0` | Cohere | 否 | 1024 | 64.47 |
| `gte-base-en-v1.5` | 阿里巴巴 | 是 | 768 | 64.11 |
| `sentence-t5-large` | Sentence Transformers | 是 | 768 | 57.06 |

表10.1：选定的嵌入模型

要正确比较不同的嵌入模型，你必须有一个一致的评估框架。这包括定义一组相关的评估数据集和指标。为了公平比较，所有模型应使用相同的评估集和指标。评估数据集应代表相关应用领域。评估框架将帮助你在时间上迭代和改进评估过程，结合初始实验的学习，逐步提高应用。

以下是一些用于使用嵌入模型进行信息检索的有用评估指标。这些指标来自Ragas，一个用于RAG评估的框架：

+   **上下文精确度**：评估检索到的结果是否包含您希望回答输入查询的地面事实。上下文中存在的相关项目在检索结果中排名较高。

+   **上下文实体召回**：评估一组地面真相中的实体在检索信息中预设的比例。

Ragas还支持其他RAG评估指标，你可以在Ragas文档（https://docs.ragas.io/en/stable/）中了解更多信息。

以下代码示例使用Ragas和LangChain评估不同嵌入模型在上下文实体召回指标上的表现。

首先，在终端中安装所需的依赖项：

[PRE0]

以下代码评估了OpenAI的`text-embedding-ada-002`和`text-embedding-3-large`嵌入模型在样本数据集上的Ragas上下文实体召回评估表现：

[PRE1]

此代码将以下结果输出到终端：

[PRE2]

如您从这些结果中可以看到，`text-embedding-3-large` 在这次评估中产生了更高的上下文实体召回率。上下文相关性分数在 `0` 和 `1` 之间归一化。

当为您的应用程序创建评估时，请考虑使用与您的用例相关的样本数据以获得更好的比较。此外，您可能还想包括至少 100 个示例的代表样本。

## 微调嵌入模型

除了尝试不同的预训练模型外，您还可以微调预训练的嵌入模型以优化它以适应您的用例。

在以下场景中微调嵌入模型可能有益：

+   **特定领域的数据**：如果应用程序处理可能无法使用现成模型很好地捕捉的特定领域数据，例如带有专业术语的法律文件或医疗记录，微调可以帮助模型更好地理解和表示特定领域概念。

+   **避免不希望的匹配**：在存在看似相似但应区分的概念的情况下，微调可以帮助模型区分它们。例如，您可以微调模型以区分 *苹果公司* 和 *苹果* *水果*。

然而，现成的嵌入模型对于许多任务来说通常表现得很出色，尤其是在结合本章后面讨论的元数据丰富化和 RAG 优化之后。

微调嵌入模型的可选方法可能因模型及其托管方式而异。托管模型提供商可能只公开其模型的一些方法，而使用开源模型可以提供更多灵活性。**SentenceTransformers** ([https://sbert.net/](https://sbert.net/)) 框架旨在用于使用和微调开源嵌入模型。

通常，微调涉及提供相似的句子对，可选地包括相似度的大小。或者，可以提供锚点、正面和负面示例来指导微调过程。*表 10.2* 提供了锚点、正面和负面示例的概述，这些示例在随后的代码示例中使用：

| **类型** | **定义** | **示例** |
| --- | --- | --- |
| 锚点 | 作为识别相似和不同示例起点的参考文本。 |

[PRE3]

|

| 正面 | 应该类似于锚示例表示的文本。 |
| --- | --- |

[PRE4]

|

| 负面 | 应该表示为与锚示例不同或不相似的文本。 |
| --- | --- |

[PRE5]

|

表 10.2：微调嵌入模型的方法

下面是一个使用 `SentenceTransformers` 和 `PyTorch` 库微调开源嵌入模型 `gte-base-en-v1.5` 的简短代码示例。

首先，在终端中安装依赖项：

[PRE6]

然后运行以下代码：

[PRE7]

此代码将输出类似以下结果到终端：

[PRE8]

如此例所示，仅仅进行的小幅微调就增加了相关句子之间的向量相似度。

如果您想了解更多关于微调嵌入模型的信息，Omar Espejel在Hugging Face的*Train and Fine-Tune Sentence Transformers Models*博客文章（[https://huggingface.co/blog/how-to-train-sentence-transformers](https://huggingface.co/blog/how-to-train-sentence-transformers)）是一个很好的起点。这篇文章更详细地探讨了使用与前面代码示例类似的方法来微调嵌入模型。

以下部分讨论了在选择合适的数据模型后，如何通过在文本中嵌入相关元数据来进一步增强语义数据模型。

# 嵌入元数据

在嵌入内容中包含**元数据**可以显著提高检索结果的质量，因为它为内容添加了更多的语义意义。元数据为内容创建了一个更丰富、更有意义的语义表示。元数据可以包括诸如内容类型、标签、标题和摘要等描述符。以下表格包含了一些在嵌入内容中包含的有用元数据示例：

| **类型** | **示例** |
| --- | --- |
| 内容类型 | 文章、食谱、产品评论等 |
| 标签 | “晚餐”，“意大利菜”，“素食” |
| 文档标题 | 烤大蒜番茄意面 |
| 文档摘要 | 一道简单的意面，以烤大蒜和樱桃番茄搭配轻柔的酱汁 |

表10.3：嵌入元数据的实用类型

您还可以包含特定于您应用程序的元数据类型。例如，考虑创建一个RAG聊天机器人，用户可以提出自然语言问题，并获得关于烹饪和食谱的生成答案。

您有以下*烤大蒜番茄意面*的食谱可以包含在您的食谱数据库中：

[PRE9]

在为食谱创建向量嵌入时，您可以在食谱文本之前包含以下元数据：

[PRE10]

通过将此元数据与嵌入文本一起包含，您为文本赋予了更多的语义意义，使其更有可能被用户查询捕获正确的内。这使得相关用户查询与文本的余弦相似度分数更高。

以下表格显示了使用`BAAI/bge-large-en-v1.5`嵌入模型在各种查询与带有和不带有元数据的文本之间的余弦相似度分数：

| **查询文本** | **无元数据的文本** **相似度分数** | **有元数据的文本** **相似度分数** | **元数据相似度** **分数提升** |
| --- | --- | --- | --- |

|

[PRE11]

| `0.7141546` | `0.7306514` | `0.016496778` |
| --- | --- | --- |

|

[PRE12]

| `0.71199816` | `0.76754296` | `0.055544794` |
| --- | --- | --- |

|

[PRE13]

| `0.60327804` | `0.6559261` | `0.052648067` |
| --- | --- | --- |

表10.4：比较带有和不带有嵌入元数据的文本向量余弦相似度

如 *表 10.4* 所示，带有前置元数据的文本对于一系列相关查询具有更高的余弦相似度。这意味着相关内容更有可能被展示并用于 RAG 聊天机器人。

## 格式化元数据

在包含元数据时，必须考虑其结构以优化处理和解释。应使用易于解析和操作的可读格式，例如 YAML ([https://yaml.org/spec/1.2.2/](https://yaml.org/spec/1.2.2/))、JSON ([https://www.json.org/json-en.html](https://www.json.org/json-en.html)) 或 TOML ([https://toml.io/](https://toml.io/))。

**YAML** 通常比其他数据格式（如 **JSON**）更高效。这意味着使用 YAML 可以节省处理额外标记的计算成本，并且用更少的 *分散* 标记来表示相同的概念，这些标记可能会稀释大型语言模型（LLM）解释输入并产生高质量输出的能力。YAML 还得到了广泛的应用，因此嵌入模型和 LLM 可以有效地与之协同工作。

以下表格展示了使用 GPT-4 分词器（[https://platform.openai.com/tokenizer](https://platform.openai.com/tokenizer)）对以 YAML 和 JSON 格式表示的相同数据进行比较的标记密度：

| **格式** | **内容** | **标记** **计数** |
| --- | --- | --- |
| YAML |

[PRE14]

[PRE15]

[PRE16]

[PRE17]

[PRE18]

[PRE19]

| 60 |
| --- |
| JSON |

[PRE20]

[PRE21]

[PRE22]

[PRE23]

[PRE24]

[PRE25]

[PRE26]

[PRE27]

[PRE28]

[PRE29]

[PRE30]

[PRE31]

| 89 |
| --- |

表 10.5：比较 YAML 和 JSON 中相同内容的标记长度

如 *表 10.5* 所示，YAML 相比 JSON 使用了大约三分之二的标记。标记使用的确切差异取决于数据和格式。YAML 通常证明比 JSON 是一个更高效的元数据格式。

如果在附加文本中包含元数据，请考虑将其作为 *前文* ([https://jekyllrb.com/docs/front-matter/](https://jekyllrb.com/docs/front-matter/)) 包含。在元数据前后使用 `---`。

下面是一个前文在 Markdown ([https://commonmark.org/help/](https://commonmark.org/help/)) 文本之前的例子：

[PRE32]

前文规范起源于 Jekyll 静态网站构建器 ([https://jekyllrb.com/docs/](https://jekyllrb.com/docs/))。它已经广泛应用于各个领域。鉴于其流行度，语言模型和嵌入模型应该能够理解其语义上下文作为文本其余部分的元数据。此外，还有库可以轻松地操作与主文本内容相关的前文，例如 Python 中的 `python-frontmatter`。

以下代码示例展示了如何向 Markdown 添加前文并打印结果。

首先，在终端中安装 `python-frontmatter` 包：

[PRE33]

使用 `python-frontmatter` 库向文本添加前文：

[PRE34]

这将在终端输出以下带有前文的文本：

[PRE35]

前面的例子展示了在语义检索中添加元数据格式（如前文）的有用性。

## 包含静态元数据

对于某些类型的内容或来源，包含所有文档都相同的静态元数据可能是有益的。这是一种计算成本低廉且易于在文档中一致性地包含元数据的方法。

对于一个食谱聊天机器人，您可以在元数据中包含食谱来源。例如：

[PRE36]

这确保了特定类型或特定来源的每一份文档都包含一致的基线元数据。然后，您可以像以下章节中讨论的那样，添加额外的动态元数据，这些元数据对每个特定文档是唯一的。包括静态元数据是提供额外语义上下文的一种低效方式，有助于检索和解释。

## 以编程方式提取元数据

您可以使用不依赖于AI模型的传统的软件开发技术从内容中提取元数据。

一种方法是从文档中提取标题，这可以通过使用**正则表达式**（**regex**）匹配标题模式或通过解析文档的**抽象语法树**（**AST**）来识别标题元素来完成。提取并包含标题作为元数据可能是有用的，因为标题通常总结或提供关于该部分内容的概述信息，从而有助于理解语义上下文并提高检索相关性。

从Markdown文档中提取标题可以创建一个包含类似以下元数据的文档：

[PRE37]

## 使用LLM生成元数据

您可以使用LLM为您的内容生成元数据。使用LLM生成元数据的潜在用例包括：

+   概括文本

+   从文本中提取关键短语或术语

+   将文本分类到类别中

+   识别文本的情感

+   识别命名实体

在选择LLM用于元数据生成时，您可能可以使用比用于您智能应用程序其他组件的语言模型更小（因此更快、更便宜）的语言模型。

您还可以使用传统的**自然语言处理**（**NLP**）技术来提供额外的元数据。例如，**计算n-gram**可以揭示文本中最频繁出现的术语或短语。其他NLP方法，如**词性标注**和**关键词标注**也可以提供有用的元数据。这些方法通常使用小型AI模型。

您可以使用Python NLP库，如`NLTK`或`spaCy`来提取元数据。虽然使用这些库通常比使用LLM更高效，但它们通常需要微调，因此除非您的应用程序运行在LLM的计算需求成本或资源受限的规模上，否则不值得使用它们。

以下代码使用OpenAI GPT-4o mini LLM提取元数据。它还使用Pydantic将响应格式化为JSON。

首先，在终端中安装依赖项：

[PRE38]

然后，执行以下代码：

[PRE39]

此代码在终端产生以下类似输出：

[PRE40]

正如您在这里看到的，LLMs允许您通过提示工程和最小的技术开销执行许多形式的NLP任务。

## 在查询嵌入和摄入内容嵌入中包含元数据

除了在将内容摄入向量存储时包含元数据之外，您还可以在搜索查询中使用的内容中包含元数据。通过在查询和检索内容上以类似的方式结构化元数据，您增加了使用向量相似性搜索获得相关匹配的可能性。

您可以使用与本章先前讨论的从数据源提取元数据相同的策略来提取查询的元数据。

例如，假设您正在查询之前提到的食谱聊天机器人。给定用户查询`apple pie recipe`，您可能希望使用以下查询进行向量搜索：

[PRE41]

如上所述的查询将使匹配具有类似结构嵌入元数据的食谱的可能性更高，如下所示：

[PRE42]

在查询中包含结构化元数据可以作为一种*语义过滤器*，以获得更精确的搜索结果。下一节将探讨其他提高RAG应用中数据模型准确性的技术。

# 优化检索增强生成

除了通过向量嵌入模型选择和元数据丰富来优化语义数据模型本身之外，还有方法可以进一步精炼和改进RAG应用。本节涵盖了优化RAG管道不同组件和阶段的策略。

优化关键领域包括查询处理、摄入数据的格式化、检索系统配置和应用级别的防护措施。有效地优化这些方面可以提高RAG应用的准确性、相关性和整体性能。

注意

本节涵盖了比第[*第8章*](B22495_08.xhtml#_idTextAnchor180)中讨论的*在AI应用中实现向量搜索*更高级的技术。

## 查询突变

在原始的RAG方法中，您使用直接的用户输入来创建用于向量搜索的嵌入，可能还辅以本章前面讨论的元数据。然而，您可以通过使用LLM突变用户输入来提高搜索性能。

查询突变的一些流行技术包括：

+   `My daughter is allergic to nuts. My son is allergic to dairy. What is a vegetarian dinner I can make for them?` 由LLM生成的回溯搜索查询可能是*Vegetarian dinner recipe without dairy* *or nuts*。

+   `西冷牛排食谱`，LLM生成的HyDE搜索查询可能是*预热您的烤架或烤盘至高温。用纸巾擦干西冷牛排，并慷慨地撒上盐和胡椒。淋上橄榄油，用双手均匀涂抹牛排。将牛排放在热烤架上，每面烤4-5分钟至五成熟，只翻一次面。使用即时读数温度计检查熟度（五成熟为135°F）。将牛排转移到切菜板上，静置5分钟后再顺着纹理切片。搭配您最喜欢的配菜，如烤土豆、烤蔬菜或*新鲜沙拉*享用多汁的西冷牛排。

+   `纯素食晚餐派对菜单`，LLM生成的多个搜索查询可能是*纯素食开胃菜*、*纯素食晚餐主菜*和*纯素食甜点*。

所有这些技术都可以针对您的应用程序领域进行优化。您甚至可以将它们结合起来，或者让LLM选择对特定用户查询最合适的技巧。

然而，在应用程序中引入另一个AI点也带来了挑战。查询突变可能并不总是按预期工作，在某些情况下可能会降低性能。此外，它还引入了另一个需要评估的组件，并产生了额外AI使用的成本。任何LLM查询突变都应该彻底评估，以减轻意外结果。

## 提取查询元数据以进行预过滤

除了在*嵌入元数据*部分讨论的执行语义过滤之外，您还可以在执行向量搜索之前对元数据进行编程过滤。这可以让您减少搜索的嵌入数量，仅检查与给定查询相关的总嵌入子集。

选择一个包含适合您应用程序需求的元数据过滤功能的向量数据库非常重要。元数据过滤功能在向量数据库之间差异很大。例如，MongoDB Atlas Vector Search在`$vectorSearch`聚合管道阶段支持多种预过滤选项。（[https://www.mongodb.com/docs/atlas/atlas-vector-search/vector-search-stage/#atlas-vector-search-pre-filter](https://www.mongodb.com/docs/atlas/atlas-vector-search/vector-search-stage/#atlas-vector-search-pre-filter)）。在[*第8章*](B22495_08.xhtml#_idTextAnchor180)，*在AI应用中实现向量搜索*，你学习了如何使用Atlas Vector Search Index设置这些预过滤选项。

您可以使用LLM从查询中提取元数据作为过滤器，就像您在*嵌入元数据*部分讨论的那样从摄取的内容中提取元数据一样。或者，您可以使用启发式方法来确定过滤标准。

例如，假设您正在构建一个烹饪聊天机器人，该机器人对食谱和一般烹饪信息（如某些菜系中流行的香料）的向量数据库执行RAG。如果您用户的查询包含单词`recipe`，则可以添加一个仅查看向量数据库中食谱项的元数据过滤器。您还可以创建所谓的*智能*过滤器，这些过滤器使用AI模型（如LLM）来确定要包含的数据子集。

这里是一个LLM函数的代码示例，该函数确定对搜索查询应用哪些过滤器（如果有的话）。它还使用Pydantic将响应格式化为JSON。

以下Python代码使用OpenAI LLM GPT-4o mini从查询中提取主题。它还使用Pydantic将响应格式化为JSON。然后，您可以使用提取的主题作为预过滤器，如[*第8章*](B22495_08.xhtml#_idTextAnchor180)中所述，*在AI应用程序中实现向量搜索*。

首先，在您的终端中安装所需的依赖项：

[PRE43]

然后，运行以下代码：

[PRE44]

这将在您的终端中输出以下内容：

[PRE45]

通过结合元数据过滤和向量搜索，您的RAG应用程序可以更高效、更准确地搜索。这种方法将搜索空间缩小到最符合上下文的数据，从而产生更精确和有用的结果。

## 格式化摄取数据

在将数据摄取以创建嵌入时，您必须考虑数据的格式。尽可能标准化数据格式可以导致更一致的结果。

对于较长的文本数据，例如技术文档或报告，您应该以一致的格式格式化摄取和嵌入的数据，该格式在密集的标记格式中包含适当的语义意义。Markdown是一个不错的选择，因为它与基于XML的格式（如HTML或PDF）相比，每个标记的信息密度更高。

例如，查看以下内容的总GPT-4标记器标记计数，该内容以纯文本、Markdown和HTML表示：

| **格式** | **内容** | **标记** **计数** |
| --- | --- | --- |
| 纯文本 |

[PRE46]

[PRE47]

[PRE48]

[PRE49]

[PRE50]

[PRE51]

[PRE52]

[PRE53]

| 81 |
| --- |
| Markdown |

[PRE54]

[PRE55]

[PRE56]

[PRE57]

[PRE58]

[PRE59]

[PRE60]

[PRE61]

| 83 |
| --- |
| HTML |

[PRE62]

[PRE63]

[PRE64]

[PRE65]

[PRE66]

[PRE67]

[PRE68]

[PRE69]

[PRE70]

[PRE71]

[PRE72]

[PRE73]

| 138 |
| --- |

表10.6：不同文本格式的标记计数

您格式化摄取数据的方式可以对检索质量和资源消耗产生有意义的影响。通常，纯文本或Markdown对于大多数基于文本的使用案例都是有效的格式。

## 高级检索系统

已经出现了各种高级检索系统，它们不仅限于检索与查询最接近的匹配项。

截至2024年8月撰写时，以下所有检索架构都是实验性的。在开发您的智能应用程序时，您可能应该从标准的向量搜索检索开始。在尝试这些高级检索系统之前，先优化标准的向量搜索检索，然后再使用过滤和添加语义元数据等技术。

高级检索系统包括：

+   **摘要检索**：从每个文档中提取摘要并将其存储在向量搜索索引中。当匹配到摘要的嵌入版本时，检索整个文档的内容。

+   **知识图谱检索**：在数据摄取期间，创建向量存储中文档之间关系的知识图谱。这些关系可以使用LLM创建。在检索期间，执行初始语义搜索。

+   **路由检索**：使用分类器确定用户查询应路由到不同数据存储中的哪个位置。

LlamaIndex在跟踪高级检索系统的最新研究方面做得非常出色。要了解更多关于LlamaIndex支持的各类高级检索模式，请参阅LlamaIndex查询引擎文档（[https://docs.llamaindex.ai/en/stable/examples/query_engine/knowledge_graph_rag_query_engine/](https://docs.llamaindex.ai/en/stable/examples/query_engine/knowledge_graph_rag_query_engine/)）。

# 摘要

在本章中，你探索了各种技术来优化你的语义数据模型，以提高向量搜索和RAG的检索准确性。你学习了如何改进用于信息检索和RAG的数据模型。通过微调嵌入，你可以调整预训练模型以提高搜索结果的准确性和相关性。使用嵌入元数据，你可以提高向量搜索质量。最后，RAG优化确保检索过程获取最相关的信息。

在下一章中，你将探讨解决AI应用开发中常见问题的方法。
