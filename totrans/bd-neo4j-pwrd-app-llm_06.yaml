- en: '5'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Implementing Powerful Search Functionalities with Neo4j and Haystack
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we embark on a journey to integrate Haystack with Neo4j, combining
    the capabilities of LLMs and graph databases to build an AI-powered search system.
    **Haystack** is an open-source framework that enables developers to create AI-powered
    applications by leveraging modern NLP techniques, machine learning models, and
    graph-based data. For our intelligent search, Haystack will serve as a cohesive
    platform for orchestrating LLMs, search engines, and databases, delivering highly
    contextualized and relevant search results.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Building upon the work from the previous chapter—where we cleaned and structured
    our Neo4j data—we will start by generating embeddings using OpenAI’s GPT models.
    These embeddings will enrich the graph, making it more powerful and capable of
    handling nuanced, context-aware search queries. Haystack will serve as the bridge
    between OpenAI’s models and the Neo4j graph database, allowing us to combine the
    strengths of both.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, you will learn how to set up and configure Haystack for seamless
    integration with Neo4j. We will walk you through building powerful search functionalities
    and finally deploying this fully functional search system, using Gradio on Hugging
    Face Spaces.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we are going to cover the following main topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: Generating embeddings with Haystack to enhance your Neo4j graph
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Connecting Haystack to Neo4j for advanced vector search
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building powerful search experiences
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fine-tuning your Haystack integration
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To successfully implement the integration of Haystack and Neo4j, and to build
    an AI-powered search system, you will need to ensure that your environment is
    properly set up. Here is a list of the technical requirements for this chapter:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: '**Python**: You will need Python `3.11` installed on your system. Python is
    used for scripting and interacting with the Neo4j database. You can download Python
    from the official Python website: [https://www.python.org/downloads/](https://www.python.org/downloads/).'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Neo4j AuraDB or local Neo4j instance**: You will need access to a Neo4j database
    to store and query your graph data. This can be either a locally installed Neo4j
    instance or a cloud-hosted Neo4j AuraDB instance. If you are following along from
    the previous chapter, where we talked about the `graph_build.py` script ([https://github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/blob/main/ch4/graph_build.py](https://github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/blob/main/ch4/graph_build.py)),
    you can continue using the same Neo4j instance that was set up and populated with
    data. This ensures continuity and allows you to build on top of the structured
    data that has already been imported.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cypher query language**: Familiarity with the Cypher query language is essential,
    as we will be using Cypher extensively to create and query the graph. You can
    find out more about Cypher syntax in the Cypher query language documentation:
    [https://neo4j.com/docs/cypher/](https://neo4j.com/docs/cypher/).'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Neo4j Python driver**: Install the Neo4j Python driver to connect to the
    Neo4j database using Python. You can install it via `pip`:'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-16
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '**Haystack**: We will be using Haystack v2.5.0.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Install Haystack using pip:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '**OpenAI API key**: To successfully generate embeddings using GPT-based models,
    you will need an OpenAI API key.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Obtain the API key by signing up for an account at OpenAI ([https://platform.openai.com/signup](https://platform.openai.com/signup))
    if you do not have one.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: '**Note**'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: A free-tier API key will not work for most use cases in this project. You will
    need an active paid OpenAI subscription to access the necessary endpoints and
    usage limits.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: Once you are logged in, navigate to the **API keys** section ([https://platform.openai.com/api-keys](https://platform.openai.com/api-keys))
    in your OpenAI dashboard and generate a new API key.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: 'You also need to install the OpenAI package using pip. Run the following command
    in your terminal:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**Gradio**: Gradio will be used to create a user-friendly chatbot interface.
    Install Gradio using pip:'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '**Hugging Face account**: To host your chatbot on Hugging Face Spaces, you
    will need a Hugging Face account. If you do not have one, sign up on the Hugging
    Face website: [https://huggingface.co/](https://huggingface.co/).'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Google Cloud Storage (optional)**: If you are storing your CSV files on Google
    Cloud Storage, ensure that your file paths are properly configured in the script.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**python-dotenv package**: Make sure to install the `python-dotenv` package
    to manage environment variables in your project:'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'All the code for this chapter is available in the following GitHub repository:
    [https://github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs](https://github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs).'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: Inside this repository, navigate to the folder named `ch6` to access the code
    examples and resources related to this chapter. This folder contains all the necessary
    scripts, files, and configurations required to implement the Neo4j and Haystack
    integration, as well as build the AI-powered search system using the movies dataset.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: Make sure to clone or download the repository so you can follow along with the
    code examples throughout this chapter.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: Generating embeddings with Haystack to enhance your Neo4j graph
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will focus on generating embeddings for the movie plots
    that we added to our Neo4j graph in the previous chapter. **Embeddings** are a
    critical part of modern search systems, as they convert text into high-dimensional
    vectors that enable similarity search. This enables the search engine to understand
    the contextual relationships between words and phrases, improving the accuracy
    and relevance of search results.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: We will integrate Haystack with OpenAI’s GPT-based models to generate these
    embeddings and store them in your Neo4j graph. This will enable a more accurate
    and context-aware search functionality.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: Initializing Haystack and OpenAI for embeddings
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before generating embeddings, you will need to ensure that Haystack is set
    up and integrated with OpenAI’s API to retrieve embeddings from their GPT-based
    models. Follow these steps to set up Haystack:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: 'Install the required libraries (if you have not already) by using the following
    command:'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Next, configure your OpenAI API key and ensure that it is set up in your `.env`
    file:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Initialize Haystack with OpenAI embeddings by creating a Python script that
    initializes Haystack and connects to OpenAI to generate the embeddings:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This configuration initializes Haystack with an in-memory document store and
    sets up the retriever using OpenAI embeddings.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: Generating embeddings for movie plots
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Next, we will generate embeddings for the movie plots stored in the Neo4j graph.
    The goal is to retrieve the plot descriptions, generate embeddings for them, and
    link these embeddings back to the respective movie nodes:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: '**Query movie plots from Neo4j**: First, you will need to query the movie plots
    from Neo4j. Use the following Cypher query to retrieve movie titles and plot summaries:'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This will return the `tmdbId` value and overview (that is, the plot summary)
    for each movie in the graph.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: '**Generate embeddings using OpenAI and Haystack:** Once the plot summaries
    are retrieved, generate embeddings using Haystack’s `OpenAITextEmbedder`:'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '**Store embeddings in Neo4j**: With the embeddings generated, the next step
    is to store them in your Neo4j graph. Each movie node will be updated with a property
    that stores its embedding:'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This will store the embeddings as a property called `embedding` in each `Movie`
    node in the Neo4j graph.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: '**Verify the embedding storage in Neo4j**: Once the embeddings are stored,
    you can verify their presence in Neo4j by querying a few nodes to check the `embedding`
    property:'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This query will return the titles and embeddings for a few movies, allowing
    you to verify that the embeddings were successfully stored.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: '**Note**'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: 'These are just the snippets of the code. The full version is available in the
    GitHub repository: [https://github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/blob/main/ch5/generate_embeddings.py](https://github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/blob/main/ch5/generate_embeddings.py).'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: We have now enriched our graph with these embeddings and thus added similarity
    search, which will allow us to perform more context-aware and intelligent queries.
    This step is crucial for enhancing the search experience and enabling advanced
    retrieval operations based on the meaning of text, rather than simple keyword
    matching.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: Now that our Neo4j graph has been enriched with vector embeddings, the next
    step is to connect Haystack to Neo4j for advanced vector search. In the upcoming
    section, we will focus on how to use these embeddings to perform efficient and
    accurate vector searches within Neo4j, enabling us to retrieve movies or nodes
    based on their vector similarity.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: Connecting Haystack to Neo4j for advanced vector search
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With the movie embeddings now stored in Neo4j, we need to configure a vector
    index on the `embedding` property, which will allow us to efficiently search for
    movies based on their vector similarity. By creating a vector index in Neo4j,
    we enable rapid retrieval of nodes that are close in the high-dimensional embedding
    space, making it possible to perform sophisticated queries, such as finding movies
    with similar plot summaries.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: Once the vector index has been created, it will be integrated with Haystack
    to perform vector-based retrieval from Neo4j. This search will be based on vector
    similarity mechanisms such as cosine similarity.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: Creating a vector search index in Neo4j
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You will first want to drop any existing vector index on the embedding property
    (if one exists) and then create a new one for performing vector searches. This
    is how you can do that using Cypher queries in your Python script:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Performing similarity search with Haystack and a Neo4j vector index
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: After creating a vector index on the Neo4j graph, you can leverage Haystack
    to perform similarity search queries based on movie plot embeddings. This approach
    allows you to compare the similarity between a given movie plot or any text query
    and existing movie overviews, returning the most relevant results based on their
    embeddings. In this example, we use the `OpenAITextEmbedder` model from the Haystack
    library to convert the text query into an embedding and then use it to search
    the Neo4j graph for movies with similar plots.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: 'This is how you generate the query embedding and perform the similarity search:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Running a vector search query with Haystack and Neo4j
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once the vector index has been created and the embeddings are stored in Neo4j,
    you can perform a vector-based search by passing a query or a sample movie plot.
    The system will generate an embedding for the query, compare it with the embeddings
    stored in Neo4j, and return the most related results.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example of a vector search using Haystack that displays the most
    similar movie plots without Cypher:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Now, we will integrate Neo4j Cypher queries with Haystack to run a vector search,
    enabling the retrieval of similar movie plots.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: Running a vector search query using Cypher and Haystack
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To run a vector search, we will use Cypher’s graph querying capabilities while
    performing similarity searches using vector embeddings generated by `OpenAITextEmbedder`.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: Unlike directly querying the vector index using Haystack, this approach combines
    Cypher’s flexibility to return more complex data, such as movie metadata (e.g.,
    cast and genres), along with embeddings, while still maintaining the efficiency
    of vector similarity search.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the steps involved in this process:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: '**Embed the query using OpenAITextEmbedder**: Convert the user’s text query
    (e.g., a movie plot) into a high-dimensional vector embedding.'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Search using Neo4j and Cypher**: Use Cypher to retrieve similar movies by
    comparing the query embedding with movie plot embeddings stored in Neo4j’s vector
    index.'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Return enriched data**: Fetch additional movie information, such as the title,
    overview, cast, genres, and score (similarity), for each result.'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'This is how you implement vector search:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: '**Define the Cypher query**: We start by defining a Cypher query that searches
    the Neo4j vector index (`overview_embeddings`) to retrieve the `top_k` most similar
    movies based on the cosine similarity between the query embedding and movie embeddings:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '**Generate the query embedding**: Using `OpenAITextEmbedder`, we convert the
    user’s input query (e.g., a movie plot) into an embedding. This embedding will
    be passed to the Neo4j vector index for comparison with the stored movie embeddings:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '**Run the vector search using the Haystack pipeline**: We set up the Haystack
    pipeline to manage the Haystack components:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`query_embedder` generates embeddings from the user query'
  id: totrans-93
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`retriever` runs the Cypher query on Neo4j using the query embedding and returns
    the most similar movies:'
  id: totrans-94
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-95
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '**Display the results**: Once the search is complete, we extract the results
    from the Neo4j graph and display the movie title, overview, and similarity score:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Using Cypher and Haystack offers several benefits, including the following:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: '**Cypher’s flexibility**: By combining Cypher with Haystack, we can not only
    query the embeddings but also retrieve additional graph-based information such
    as cast, genres, and relationships between entities.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Enriched results**: In addition to retrieving the most similar movies, you
    can easily extend the query to fetch related metadata (e.g., actors, genres, ratings)
    or refine the search with additional filtering conditions (e.g., release year,
    genre).'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Optimized for large graphs**: Neo4j’s vector index allows efficient querying
    of large datasets with complex relationships, while Haystack’s embedding models
    provide an accurate understanding of movie plots.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s take a look at an example use case next.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: Example use case
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Consider finding movies with plots such as *A hero must save the world from
    destruction*. By using the pipeline we just created, you can retrieve relevant
    results:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: This pipeline combines the best of both worlds—similarity search through vector
    embeddings and the rich data capabilities of graph querying with Cypher—allowing
    powerful, flexible searches over large datasets such as movies.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: '**Note**'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: 'These are just the snippets of the code. The full version is available in the
    GitHub repository: [https://github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/blob/main/ch5/vector_search.py](https://github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/blob/main/ch5/vector_search.py).'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: We have now connected Haystack to Neo4j and enabled advanced vector search functionality.
    With the vector index in place, Neo4j can now efficiently search for similar movie
    nodes based on their embeddings similarity. Haystack’s integration allows you
    to seamlessly perform these searches using `Neo4jDynamicDocumentRetriever`. This
    retriever performs a search for similar items in your graph by leveraging vector
    embeddings and Neo4j’s graph capabilities.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will explore how to build a search-driven chatbot that
    leverages the power of Haystack and Neo4j to deliver rich, context-aware responses.
    Using Gradio, we will create an intuitive chatbot interface that can interact
    with users and perform advanced searches through natural language queries. This
    will bring together the strengths of LLMs, vector search, and Neo4j to create
    a user-friendly, AI-powered search experience.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: Building a search-driven chatbot with Gradio and Haystack
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will integrate Gradio to build an interactive chatbot interface
    powered by Haystack and Neo4j. Gradio makes it easy to create a web-based interface
    for interacting with your chatbot. The chatbot will allow users to input queries,
    which will then trigger a vector-based search of movie embeddings stored in Neo4j.
    The chatbot will return detailed responses, including the movie titles, overviews,
    and similarity scores, providing an informative and user-friendly experience.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: Setting up a Gradio interface
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If you have not installed Gradio yet, do so by running the following:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '**Note**'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: The script in this chapter works fine with Gradio v `5.23.1`.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we will set up a basic Gradio interface that triggers our search pipeline
    and displays the results:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: This interface allows users to input text queries, and the chatbot will use
    the `perform_vector_search_cypher()` function to search for the most relevant
    movies.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: Integrating with Haystack and Neo4j
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To power the chatbot, we will connect it to Haystack’s embedding generation
    and Neo4j’s vector search capabilities. We will be using `OpenAITextEmbedder`
    to generate the embeddings for both the queries and the movie plots stored in
    Neo4j. The movie embeddings are stored in a vector index inside Neo4j, which we
    query for the most similar movies.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: 'This is how to integrate our chatbot with the previous Haystack setup:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Connecting Gradio to the full pipeline
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now, connect this Gradio chatbot with the Haystack and Neo4j pipeline you have
    already set up. The Gradio interface will call the `perform_vector_search_cypher()`
    function, which in turn utilizes `Neo4jDynamicDocumentRetriever` to search for
    similar movies based on the user’s query.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: 'Update the `main()` function to initialize the chatbot:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Running the chatbot
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To run the chatbot, simply execute your Python script. The Gradio interface
    will be launched in your browser, allowing you to interact with the chatbot in
    real time:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'A Gradio interface will launch in your browser, allowing you to interact with
    the chatbot in real time. You can enter queries such as this:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The chatbot will return movie plots that are similar to this query based on
    the vector search.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: '**Note**'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: 'These are just the snippets of the code. The full version is available in the
    GitHub repository: [https://github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/blob/main/ch5/search_chatbot.py](https://github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/blob/main/ch5/search_chatbot.py).'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: As we come to the end of this section, we have built a fully functional search-driven
    chatbot using Gradio, Haystack, and Neo4j. The chatbot leverages the embeddings
    stored in Neo4j to perform advanced vector-based searches, returning contextually
    relevant results to the user in the form of retrieving meaningful movie titles
    and actors from Neo4j in response to user queries.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: However, this is just the beginning. In the next section, we will dive deeper
    into fine-tuning your Haystack integration and also explore advanced techniques
    such as optimizing search performance, adjusting retrieval models, and refining
    the chatbot’s responses to create an even more seamless and efficient search-driven
    experience.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: Fine-tuning your Haystack integration
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is now time to explore how to fine-tune this integration for improved performance
    and user experience. While the current setup provides rich, contextually aware
    responses, there are several advanced techniques, you can implement to optimize
    the search process, improve retrieval accuracy, and make the chatbot’s interactions
    more seamless.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will focus on adjusting key components of Haystack, including
    experimenting with different embedding models, optimizing Neo4j queries for faster
    results, and improving how the chatbot displays its responses. These enhancements
    will help you scale your chatbot to handle more complex queries, improve response
    times, and deliver even more relevant search results.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: Experimenting with different embedding models
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Currently, we are using OpenAI’s `text-embedding-ada-002` model to generate
    embeddings. While this model has served as a reliable and performant choice across
    a wide range of tasks since its release, it’s worth noting that OpenAI has recently
    introduced new models—such as `text-embedding-3-small` and `text-embedding-3-large`—that
    offer significant improvements in both performance and cost-efficiency. For example,
    `text-embedding-3-small` achieves better results in multilingual and English-language
    tasks, while also being up to five times more cost-effective than `text-embedding-ada-002`.
    Although we have not switched models in this project for consistency, readers
    who are implementing similar pipelines may consider using `text-embedding-3-small`
    to improve efficiency without compromising performance—especially if embedding
    generation is a frequent or large-scale operation.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: However, Haystack supports various other models, and you can experiment with
    different ones to see which provides the most accurate or relevant results for
    your specific use case. For instance, you could switch to a more sophisticated
    OpenAI model with higher dimensions or try another embedding service supported
    by Haystack.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: 'This is how you can easily switch to a different model:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: You can also explore other models from OpenAI or even integrate different embedding
    services to see which performs best for your movie chatbot.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: Optimizing Neo4j for faster queries
  id: totrans-148
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While Neo4j is already efficient at handling graph-based queries, there are
    several optimizations you can apply, especially for large datasets. You can index
    additional properties to improve query performance.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: Indexing additional properties
  id: totrans-150
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In addition to the vector index on the embedding property, you can index other
    frequently queried properties, such as `title` or `tmdbId`, to speed up retrieval.
    This will ensure that whenever you filter or retrieve movies based on these properties,
    the search is quicker and more efficient:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: By indexing these properties, you can optimize lookups when the search is not
    solely based on embeddings, such as when filtering by title or retrieving a specific
    movie.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: To continuously improve the chatbot’s search experience, you can log user queries
    and analyze them over time. Let’s talk about this in detail.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: Logging and analyzing queries
  id: totrans-155
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Logging helps you track the most common search patterns. Based on logs of user
    queries and their analysis, you can adjust the indexing strategy, optimize the
    retriever, or tweak the embedding model for better accuracy.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: 'This is how to implement a simple logging mechanism:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Every time a user inputs a query, it will be logged for future analysis. You
    can then analyze these logs to make informed adjustments to the system, ensuring
    that it becomes more responsive and accurate over time.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: These techniques can help you significantly enhance the performance, accuracy,
    and user experience of your search-driven chatbot. Whether it is experimenting
    with different embedding models, optimizing Neo4j queries, or improving how the
    results are formatted, each adjustment brings you closer to a seamless and powerful
    user interaction.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 这些技术可以帮助您显著提升搜索驱动的聊天机器人的性能、准确性和用户体验。无论是尝试不同的嵌入模型、优化Neo4j查询，还是改进结果格式，每一次调整都让您更接近无缝且强大的用户交互。
- en: These advanced techniques allow your chatbot to scale effectively, handle more
    complex queries, and return even more relevant and engaging results.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 这些高级技术使您的聊天机器人能够有效扩展，处理更复杂的查询，并返回更加相关和吸引人的结果。
- en: Summary
  id: totrans-162
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we successfully built a fully functional search-driven chatbot
    by integrating Gradio, Haystack, and Neo4j. We began by enriching our Neo4j graph
    with movie embeddings generated by OpenAI’s models, enabling advanced vector-based
    search functionality. From there, we connected Haystack to Neo4j, allowing us
    to perform similarity searches on the embeddings stored in the graph. Finally,
    we wrapped it all up by creating a user-friendly chatbot interface with Gradio,
    which dynamically retrieves movie details such as titles and actors based on user
    queries.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们通过整合Gradio、Haystack和Neo4j成功构建了一个功能齐全的搜索驱动的聊天机器人。我们首先通过OpenAI的模型生成的电影嵌入丰富了我们的Neo4j图，从而实现了高级的基于向量的搜索功能。从那里，我们将Haystack连接到Neo4j，使我们能够在图中存储的嵌入上执行相似度搜索。最后，我们通过创建一个用户友好的聊天机器人界面（使用Gradio），根据用户查询动态检索电影详情，如标题和演员，来完成整个构建过程。
- en: In the next chapter we will focus on advanced search capabilities and search
    optimization with Haystack. We will also discuss query optimization for large
    graphs.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将重点关注Haystack的高级搜索能力和搜索优化。我们还将讨论大型图的查询优化。
