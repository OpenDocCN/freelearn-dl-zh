["```py\npip install diffusers==0.20.0\n```", "```py\n[height, weight, age, hobbies,...]\n```", "```py\n    from diffusers.utils import load_image\n    ```", "```py\n    image = load_image(\"dog.png\")\n    ```", "```py\n    display(image)\n    ```", "```py\n    import numpy as np\n    ```", "```py\n    # convert image object to array and \n    ```", "```py\n    # convert pixel data from 0 ~ 255 to 0 ~ 1\n    ```", "```py\n    image_array = np.array(image).astype(np.float32)/255.0\n    ```", "```py\n    # convert the number from 0 ~ 1 to -1 ~ 1\n    ```", "```py\n    image_array = image_array * 2.0 - 1.0\n    ```", "```py\n    # transform the image array from width,height,\n    ```", "```py\n    # channel to channel,width,height\n    ```", "```py\n    image_array_cwh = image_array.transpose(2,0,1)\n    ```", "```py\n    # add batch dimension\n    ```", "```py\n    image_array_cwh = np.expand_dims(image_array_cwh, axis = 0)\n    ```", "```py\n    # load image with torch\n    ```", "```py\n    import torch\n    ```", "```py\n    image_array_cwh = torch.from_numpy(image_array_cwh)\n    ```", "```py\n    image_array_cwh_cuda = image_array_cwh.to(\n    ```", "```py\n        \"cuda\",\n    ```", "```py\n        dtype=torch.float16\n    ```", "```py\n    )\n    ```", "```py\n    # Initialize VAE model\n    ```", "```py\n    import torch\n    ```", "```py\n    from diffusers import AutoencoderKL\n    ```", "```py\n    vae_model = AutoencoderKL.from_pretrained(\n    ```", "```py\n        \"runwayml/stable-diffusion-v1-5\",\n    ```", "```py\n        subfolder = \"vae\",\n    ```", "```py\n        torch_dtype=torch.float16\n    ```", "```py\n    ).to(\"cuda\")\n    ```", "```py\n    latents = vae_model.encode(\n    ```", "```py\n        image_array_cwh_cuda).latent_dist.sample()\n    ```", "```py\n    print(latents[0])\n    ```", "```py\n    print(latents[0].shape)\n    ```", "```py\n    import numpy as np\n    ```", "```py\n    from PIL import Image\n    ```", "```py\n    def latent_to_img(latents_input, scale_rate = 1):\n    ```", "```py\n        latents_2 = (1 / scale_rate) * latents_input\n    ```", "```py\n        # decode image\n    ```", "```py\n        with torch.no_grad():\n    ```", "```py\n            decode_image = vae_model.decode(\n    ```", "```py\n            latents_input, \n    ```", "```py\n            return_dict = False\n    ```", "```py\n            )[0][0]\n    ```", "```py\n        decode_image =  (decode_image / 2 + 0.5).clamp(0, 1)\n    ```", "```py\n        # move latent data from cuda to cpu\n    ```", "```py\n        decode_image = decode_image.to(\"cpu\")\n    ```", "```py\n        # convert torch tensor to numpy array\n    ```", "```py\n        numpy_img = decode_image.detach().numpy()\n    ```", "```py\n        # covert image array from (width, height, channel) \n    ```", "```py\n        # to (channel, width, height)\n    ```", "```py\n        numpy_img_t = numpy_img.transpose(1,2,0)\n    ```", "```py\n        # map image data to 0, 255, and convert to int number\n    ```", "```py\n        numpy_img_t_01_255 = \\ \n    ```", "```py\n            (numpy_img_t*255).round().astype(\"uint8\")\n    ```", "```py\n        # shape the pillow image object from the numpy array\n    ```", "```py\n        return Image.fromarray(numpy_img_t_01_255)\n    ```", "```py\n    pil_img = latent_to_img(latents_input)\n    ```", "```py\n    pil_img\n    ```", "```py\n    input_prompt = \"a running dog\"\n    ```", "```py\n    # input tokenizer and clip embedding model\n    ```", "```py\n    import torch\n    ```", "```py\n    from transformers import CLIPTokenizer,CLIPTextModel\n    ```", "```py\n    # initialize tokenizer\n    ```", "```py\n    clip_tokenizer = CLIPTokenizer.from_pretrained(\n    ```", "```py\n        \"runwayml/stable-diffusion-v1-5\",\n    ```", "```py\n        subfolder = \"tokenizer\",\n    ```", "```py\n        dtype     = torch.float16\n    ```", "```py\n    )\n    ```", "```py\n    input_tokens = clip_tokenizer(\n    ```", "```py\n        input_prompt,\n    ```", "```py\n        return_tensors = \"pt\"\n    ```", "```py\n    )[\"input_ids\"]\n    ```", "```py\n    input_tokens\n    ```", "```py\n    # initialize CLIP text encoder model\n    ```", "```py\n    clip_text_encoder = CLIPTextModel.from_pretrained(\n    ```", "```py\n        \"runwayml/stable-diffusion-v1-5\",\n    ```", "```py\n        subfolder=\"text_encoder\",\n    ```", "```py\n        # dtype=torch.float16\n    ```", "```py\n    ).to(\"cuda\")\n    ```", "```py\n    # encode token ids to embeddings\n    ```", "```py\n    prompt_embeds = clip_text_encoder(\n    ```", "```py\n        input_tokens.to(\"cuda\")\n    ```", "```py\n    )[0]\n    ```", "```py\n    print(prompt_embeds)\n    ```", "```py\n    print(prompt_embeds.shape)\n    ```", "```py\n    tensor([[[-0.3884,0.0229, -0.0522,..., -0.4899, -0.3066,0.0675],\n    ```", "```py\n        [ 0.0290, -1.3258,  0.3085,..., -0.5257,0.9768,0.6652],\n    ```", "```py\n        [ 1.4642,0.2696,0.7703,..., -1.7454, -0.3677,0.5046],\n    ```", "```py\n        [-1.2369,0.4149,1.6844,..., -2.8617, -1.3217,0.3220],\n    ```", "```py\n        [-1.0182,0.7156,0.4969,..., -1.4992, -1.1128, -0.2895]]],\n    ```", "```py\n        device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n    ```", "```py\n    # prepare neg prompt embeddings\n    ```", "```py\n    uncond_tokens = \"blur\"\n    ```", "```py\n    # get the prompt embedding length\n    ```", "```py\n    max_length = prompt_embeds.shape[1]\n    ```", "```py\n    # generate negative prompt tokens with the same length of prompt\n    ```", "```py\n    uncond_input_tokens = clip_tokenizer(\n    ```", "```py\n        uncond_tokens,\n    ```", "```py\n        padding = \"max_length\",\n    ```", "```py\n        max_length = max_length,\n    ```", "```py\n        truncation = True,\n    ```", "```py\n        return_tensors = \"pt\"\n    ```", "```py\n    )[\"input_ids\"]\n    ```", "```py\n    # generate the negative embeddings\n    ```", "```py\n    with torch.no_grad():\n    ```", "```py\n        negative_prompt_embeds = clip_text_encoder(\n    ```", "```py\n            uncond_input_tokens.to(\"cuda\")\n    ```", "```py\n        )[0]\n    ```", "```py\n    prompt_embeds = torch.cat([negative_prompt_embeds, \n    ```", "```py\n        prompt_embeds])\n    ```", "```py\n    from diffusers import EulerDiscreteScheduler as Euler\n    ```", "```py\n    # initialize scheduler from a pretrained checkpoint\n    ```", "```py\n    scheduler = Euler.from_pretrained(\n    ```", "```py\n        \"runwayml/stable-diffusion-v1-5\",\n    ```", "```py\n        subfolder = \"scheduler\"\n    ```", "```py\n    )\n    ```", "```py\n    import torch\n    ```", "```py\n    from diffusers import StableDiffusionPipeline\n    ```", "```py\n    from diffusers import EulerDiscreteScheduler as Euler\n    ```", "```py\n    text2img_pipe = StableDiffusionPipeline.from_pretrained(\n    ```", "```py\n        \"runwayml/stable-diffusion-v1-5\",\n    ```", "```py\n        torch_dtype = torch.float16\n    ```", "```py\n    ).to(\"cuda:0\")\n    ```", "```py\n    scheduler = Euler.from_config(text2img_pipe.scheduler.config)\n    ```", "```py\n    inference_steps = 20\n    ```", "```py\n    scheduler.set_timesteps(inference_steps, device = \"cuda\")\n    ```", "```py\n    timesteps = scheduler.timesteps\n    ```", "```py\n    for t in timesteps:\n    ```", "```py\n        print(t)\n    ```", "```py\n    ...\n    ```", "```py\n    tensor(999., device='cuda:0', dtype=torch.float64)\n    ```", "```py\n    tensor(946.4211, device='cuda:0', dtype=torch.float64)\n    ```", "```py\n    tensor(893.8421, device='cuda:0', dtype=torch.float64)\n    ```", "```py\n    tensor(841.2632, device='cuda:0', dtype=torch.float64)\n    ```", "```py\n    tensor(788.6842, device='cuda:0', dtype=torch.float64)\n    ```", "```py\n    tensor(736.1053, device='cuda:0', dtype=torch.float64)\n    ```", "```py\n    tensor(683.5263, device='cuda:0', dtype=torch.float64)\n    ```", "```py\n    tensor(630.9474, device='cuda:0', dtype=torch.float64)\n    ```", "```py\n    tensor(578.3684, device='cuda:0', dtype=torch.float64)\n    ```", "```py\n    tensor(525.7895, device='cuda:0', dtype=torch.float64)\n    ```", "```py\n    tensor(473.2105, device='cuda:0', dtype=torch.float64)\n    ```", "```py\n    tensor(420.6316, device='cuda:0', dtype=torch.float64)\n    ```", "```py\n    tensor(368.0526, device='cuda:0', dtype=torch.float64)\n    ```", "```py\n    tensor(315.4737, device='cuda:0', dtype=torch.float64)\n    ```", "```py\n    tensor(262.8947, device='cuda:0', dtype=torch.float64)\n    ```", "```py\n    tensor(210.3158, device='cuda:0', dtype=torch.float64)\n    ```", "```py\n    tensor(157.7368, device='cuda:0', dtype=torch.float64)\n    ```", "```py\n    tensor(105.1579, device='cuda:0', dtype=torch.float64)\n    ```", "```py\n    tensor(52.5789, device='cuda:0', dtype=torch.float64)\n    ```", "```py\n    tensor(0., device='cuda:0', dtype=torch.float64)\n    ```", "```py\nimport torch\nfrom diffusers import UNet2DConditionModel\nunet = UNet2DConditionModel.from_pretrained(\n    \"runwayml/stable-diffusion-v1-5\",\n    subfolder =\"unet\",\n    torch_dtype = torch.float16\n).to(\"cuda\")\n```", "```py\n    # prepare noise latents\n    ```", "```py\n    shape = torch.Size([1, 4, 64, 64])\n    ```", "```py\n    device = \"cuda\"\n    ```", "```py\n    noise_tensor = torch.randn(\n    ```", "```py\n        shape,\n    ```", "```py\n        generator = None,\n    ```", "```py\n        dtype     = torch.float16\n    ```", "```py\n    ).to(\"cuda\")\n    ```", "```py\n    # scale the initial noise by the standard deviation required by \n    ```", "```py\n    # the scheduler\n    ```", "```py\n    latents = noise_tensor * scheduler.init_noise_sigma\n    ```", "```py\n    guidance_scale = 7.5\n    ```", "```py\n    latents_sd = torch.clone(latents)\n    ```", "```py\n    for i,t in enumerate(timesteps):\n    ```", "```py\n        # expand the latents if we are doing classifier free guidance\n    ```", "```py\n        latent_model_input = torch.cat([latents_sd] * 2)\n    ```", "```py\n        latent_model_input = scheduler.scale_model_input(\n    ```", "```py\n            latent_model_input, t)\n    ```", "```py\n        # predict the noise residual\n    ```", "```py\n        with torch.no_grad():\n    ```", "```py\n            noise_pred = unet(\n    ```", "```py\n                latent_model_input,\n    ```", "```py\n                t,\n    ```", "```py\n                encoder_hidden_states=prompt_embeds,\n    ```", "```py\n                return_dict = False,\n    ```", "```py\n            )[0]\n    ```", "```py\n        # perform guidance\n    ```", "```py\n        noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)\n    ```", "```py\n        noise_pred = noise_pred_uncond + guidance_scale *\n    ```", "```py\n            (noise_pred_text - noise_pred_uncond)\n    ```", "```py\n        # compute the previous noisy sample x_t -> x_t-1\n    ```", "```py\n        latents_sd = scheduler.step(noise_pred, t,\n    ```", "```py\n            latents_sd, return_dict=False)[0]\n    ```", "```py\n    import numpy as np\n    ```", "```py\n    from PIL import Image\n    ```", "```py\n    def latent_to_img(latents_input):\n    ```", "```py\n        # decode image\n    ```", "```py\n        with torch.no_grad():\n    ```", "```py\n            decode_image = vae_model.decode(\n    ```", "```py\n                latents_input,\n    ```", "```py\n                return_dict = False\n    ```", "```py\n            )[0][0]\n    ```", "```py\n        decode_image =  (decode_image / 2 + 0.5).clamp(0, 1)\n    ```", "```py\n        # move latent data from cuda to cpu\n    ```", "```py\n        decode_image = decode_image.to(\"cpu\")\n    ```", "```py\n        # convert torch tensor to numpy array\n    ```", "```py\n        numpy_img = decode_image.detach().numpy()\n    ```", "```py\n        # covert image array from (channel, width, height) \n    ```", "```py\n        # to (width, height, channel)\n    ```", "```py\n        numpy_img_t = numpy_img.transpose(1,2,0)\n    ```", "```py\n        # map image data to 0, 255, and convert to int number\n    ```", "```py\n        numpy_img_t_01_255 = \\ \n    ```", "```py\n            (numpy_img_t*255).round().astype(\"uint8\")\n    ```", "```py\n        # shape the pillow image object from the numpy array\n    ```", "```py\n        return Image.fromarray(numpy_img_t_01_255)\n    ```", "```py\n    latents_2 = (1 / 0.18215) * latents_sd\n    ```", "```py\n    pil_img = latent_to_img(latents_2)\n    ```", "```py\nstrength = 0.7\n# scale the initial noise by the standard deviation required by the \n# scheduler\nlatents = latents_input*(1-strength) + \n    noise_tensor*scheduler.init_noise_sigma\n```"]