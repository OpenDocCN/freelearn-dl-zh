- en: '10'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '10'
- en: 'The Future of Generative Models: Beyond Scaling'
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成模型的未来：超越扩展
- en: For the past decade, the dominant paradigm in AI advancement has been *scaling*—increasing
    model sizes (parameter count), expanding training datasets, and applying more
    computational resources. This approach has delivered impressive gains, with each
    leap in model size bringing better capabilities. However, scaling alone is facing
    diminishing returns and growing challenges in terms of sustainability, accessibility,
    and addressing fundamental AI limitations. The future of generative AI lies beyond
    simple scaling, in more efficient architectures, specialized approaches, and hybrid
    systems that overcome current limitations while democratizing access to these
    powerful technologies.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去十年中，人工智能进步的主导范式一直是**扩展规模**——增加模型大小（参数数量）、扩大训练数据集，以及应用更多计算资源。这种方法带来了令人印象深刻的成果，每次模型规模的跃升都带来了更好的能力。然而，仅仅扩展规模正面临收益递减和日益增长的挑战，包括可持续性、可访问性以及解决基本的人工智能限制。生成式人工智能的未来在于超越简单的扩展，在于更高效的架构、专业的方法和混合系统，这些系统能够克服当前的局限性，同时使这些强大的技术更加民主化。
- en: Throughout this book, we have explored building applications using generative
    AI models. Our focus on agents has been central, as we’ve developed autonomous
    tools that can reason, plan, and execute tasks across multiple domains. For developers
    and data scientists, we’ve demonstrated techniques including tool integration,
    agent-based reasoning frameworks, RAG, and effective prompt engineering—all implemented
    through LangChain and LangGraph. As we conclude our exploration, it’s appropriate
    to consider the implications of these technologies and where the rapidly evolving
    field of agentic AI might lead us next. Hence, in this chapter, we’ll reflect
    on the current limitations of generative models—not just technical ones, but the
    bigger social and ethical challenges they raise. We’ll look at strategies for
    addressing these issues, and explore where the real opportunities for value creation
    lie—especially when it comes to customizing models for specific industries and
    use cases.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们探讨了使用生成式人工智能模型构建应用程序。我们关注代理人的核心地位，因为我们已经开发了可以在多个领域进行推理、规划和执行任务的自主工具。对于开发人员和数据科学家，我们已经展示了包括工具集成、基于代理的推理框架、RAG和有效的提示工程等技术，所有这些技术都是通过LangChain和LangGraph实现的。随着我们探索的结束，考虑这些技术的含义以及快速发展的代理人工智能领域可能将我们引向何方是合适的。因此，在本章中，我们将反思生成模型的当前局限性——不仅限于技术层面，还包括它们引发的更大的社会和伦理挑战。我们将探讨解决这些问题的策略，并探索真正的价值创造机会所在——特别是在为特定行业和用例定制模型时。
- en: We’ll also consider what generative AI might mean for jobs, and how it could
    reshape entire sectors—from creative fields and education to law, medicine, manufacturing,
    and even defense. Finally, we’ll tackle some of the hard questions around misinformation,
    security, privacy, and fairness—and think together about how these technologies
    should be implemented and regulated in the real world.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将考虑生成式人工智能对就业的影响，以及它如何重塑整个行业——从创意领域和教育到法律、医学、制造业甚至国防。最后，我们将探讨关于虚假信息、安全、隐私和公平的一些难题，并共同思考这些技术如何在现实世界中实施和监管。
- en: 'The main areas we’ll discuss in this chapter are:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们将讨论的主要内容包括：
- en: The current state of generative AI
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成式人工智能的现状
- en: The limitations of scaling and emerging alternatives
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 扩展的局限性及新兴的替代方案
- en: Economic and industry transformation
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 经济和行业转型
- en: Societal implications
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 社会意义
- en: The current state of generative AI
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成式人工智能的现状
- en: As discussed in this book, in recent years, generative AI models have attained
    new milestones in producing human-like content across modalities including text,
    images, audio, and video. Leading models like OpenAI’s GPT-4o, Anthropic’s Claude
    3.7 Sonnet, Meta’s Llama 3, and Google’s Gemini 1.5 Pro and 2.0 display impressive
    fluency in content generation, be it textual or creative visual artistry.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 正如本书所讨论的，近年来，生成式人工智能模型在文本、图像、音频和视频等多种模态上生产类似人类内容方面取得了新的里程碑。像OpenAI的GPT-4o、Anthropic的Claude
    3.7 Sonnet、Meta的Llama 3以及Google的Gemini 1.5 Pro和2.0等领先模型在内容生成方面表现出令人印象深刻的流畅性，无论是文本还是创意视觉艺术。
- en: A watershed moment in AI development occurred in late 2024 with the release
    of OpenAI’s o1 model, followed shortly by o3\. These models represent a fundamental
    shift in AI capabilities, particularly in domains requiring sophisticated reasoning.
    Unlike incremental improvements seen in previous generations, these models demonstrated
    extraordinary leaps in performance. They achieved gold medal level results in
    International Mathematics Olympiad competitions and matched PhD-level performance
    across physics, chemistry, and biology problems.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能发展的一个转折点发生在2024年末，随着OpenAI的o1模型的发布，紧接着是o3模型的推出。这些模型代表了人工智能能力的一个根本性转变，尤其是在需要复杂推理的领域。与之前几代产品中看到的渐进式改进不同，这些模型在性能上实现了非凡的飞跃。它们在国际数学奥林匹克竞赛中取得了金牌级别的成绩，并在物理、化学和生物学问题上的表现与博士水平相当。
- en: What distinguishes newer models like o1 and o3 is their iterative processing
    approach that builds upon the transformer architecture of previous generations.
    These models implement what researchers describe as *recursive* computation patterns
    that enable multiple processing passes over information rather than relying solely
    on a single forward pass. This approach allows the models to allocate additional
    computational resources to more challenging problems, though this remains bound
    by their fundamental architecture and training paradigms. While these models incorporate
    some specialized attention mechanisms for different types of inputs, they still
    operate within the constraints of large, homogeneous neural networks rather than
    truly modular systems. Their training methodology has evolved beyond simple next-token
    prediction to include optimization for intermediate reasoning steps, though the
    core approach remains grounded in statistical pattern recognition.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 与o1和o3等较新模型区分开来的是，它们基于前一代的transformer架构的迭代处理方法。这些模型实现了研究人员描述为*递归*的计算模式，允许对信息进行多次处理，而不是仅仅依赖于单次正向传递。这种方法允许模型将额外的计算资源分配给更具挑战性的问题，尽管这仍然受限于其基本架构和训练范式。虽然这些模型为不同类型的输入集成了某些专门的注意力机制，但它们仍然在大规模、同质化的神经网络约束内运行，而不是真正的模块化系统。它们的训练方法已经超越了简单的下一个标记预测，包括对中间推理步骤的优化，尽管核心方法仍然基于统计模式识别。
- en: The emergence of models marketed as having *reasoning capabilities* suggests
    a potential evolution in how these systems process information, though significant
    limitations persist. These models demonstrate improved performance on certain
    structured reasoning tasks and can follow more explicit chains of thought, particularly
    within domains well represented in their training data. However, as the comparison
    with human cognition indicates, these systems continue to struggle with novel
    domains, causal understanding, and the development of genuinely new concepts.
    This represents an incremental advancement in how businesses might leverage AI
    technology rather than a fundamental shift in capabilities. Organizations exploring
    these technologies should implement rigorous testing frameworks to evaluate performance
    on their specific use cases, with particular attention to edge cases and scenarios
    requiring true causal reasoning or domain adaptation.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 市场推广的具有*推理能力*的模型的出现，暗示了这些系统处理信息方式的潜在演变，尽管仍然存在重大局限性。这些模型在特定的结构化推理任务上表现出改进的性能，并能跟随更明确的思维链条，尤其是在其训练数据中表现良好的领域内。然而，正如与人类认知的比较所表明的，这些系统在处理新领域、因果理解和真正新概念的发展方面仍然面临挑战。这代表了企业在利用人工智能技术方面的一个渐进式进步，而不是能力的一个根本性转变。探索这些技术的组织应实施严格的测试框架来评估其特定用例的性能，特别关注边缘情况和需要真正因果推理或领域适应的场景。
- en: 'Models with enhanced reasoning approaches show promise but come with important
    limitations that should inform business implementations:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 具有增强推理方法的模型显示出希望，但伴随着重要的局限性，这些局限性应指导商业实施：
- en: '**Structured analysis approaches**: Recent research suggests these models can
    follow multi-step reasoning patterns for certain types of problems, though their
    application to strategic business challenges remains an area of active exploration
    rather than established capability.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**结构化分析方法**：最近的研究表明，这些模型可以遵循某些类型问题的多步推理模式，尽管将其应用于战略商业挑战仍然是一个活跃的探索领域，而不是一个确立的能力。'
- en: '**Reliability considerations**: While step-by-step reasoning approaches show
    promise on some benchmark tasks, research indicates these techniques can actually
    compound errors in certain contexts.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可靠性考虑**：虽然逐步推理方法在某些基准任务上显示出希望，但研究表明，这些技术在某些情况下实际上可能会放大错误。'
- en: '**Semi-autonomous agent systems**: Models incorporating reasoning techniques
    can execute some tasks with reduced human intervention, but current implementations
    require careful monitoring and guardrails to prevent error propagation and ensure
    alignment with business objectives.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**半自主代理系统**：结合推理技术的模型可以减少人为干预执行一些任务，但当前的实现需要仔细监控和限制措施，以防止错误传播并确保与业务目标一致。'
- en: Particularly notable is the rising proficiency in code generation, where these
    reasoning models can not only write code but also understand, debug, and iteratively
    improve it. This capability points toward a future where AI systems could potentially
    create and execute code autonomously, essentially programming themselves to solve
    new problems or adapt to changing conditions—a fundamental step toward more general
    artificial intelligence.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 尤其值得注意的是代码生成能力的提升，这些推理模型不仅能编写代码，还能理解、调试和迭代改进它。这种能力预示着一个未来，AI系统可能能够自主地创建和执行代码，本质上是通过编程自己来解决新问题或适应变化条件——这是迈向更通用人工智能的基本步骤。
- en: The potential business applications of models with reasoning approaches are
    significant, though currently more aspirational than widely implemented. Early
    adopters are exploring systems where AI assistants might help analyze market data,
    identify potential operational issues, and augment customer support through structured
    reasoning approaches. However, these implementations remain largely experimental
    rather than fully autonomous systems.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 基于推理方法的模型在潜在的商业应用方面具有重要意义，尽管目前更多地是抱负而非广泛实施。早期采用者正在探索可能帮助分析市场数据、识别潜在运营问题并通过结构化推理方法增强客户支持的AI助手系统。然而，这些实施仍然主要是实验性的，而不是完全自主的系统。
- en: Most current business deployments focus on narrower, well-defined tasks with
    human oversight rather than the fully autonomous scenarios sometimes portrayed
    in marketing materials. While research labs and leading technology companies are
    demonstrating promising prototypes, widespread deployment of truly reasoning-based
    systems for complex business decision-making remains an emerging frontier rather
    than an established practice. Organizations exploring these technologies should
    focus on controlled pilot programs with careful evaluation metrics to assess real
    business impact.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数当前的商业部署都集中在更窄、定义明确的任务上，并有人类监督，而不是像营销材料中有时描述的那样完全自主的场景。虽然研究实验室和领先的技术公司正在展示有希望的原型，但真正基于推理的复杂商业决策系统的广泛部署仍然是一个新兴的前沿领域，而不是一个成熟的实践。探索这些技术的组织应专注于受控的试点项目，并使用仔细评估的指标来评估真正的商业影响。
- en: For enterprises evaluating AI capabilities, reasoning models represent a significant
    step forward in making AI a reliable and capable tool for high-value business
    applications. This advancement transforms generative AI from primarily a content
    creation technology to a strategic decision support system capable of enhancing
    core business operations.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 对于正在评估AI能力的企业来说，推理模型代表了将AI转变为可靠且适用于高价值商业应用工具的重大进步。这一进步将生成式AI从主要的内容创作技术转变为战略决策支持系统，能够增强核心业务运营。
- en: These practical applications of reasoning capabilities help explain why the
    development of models like o1 represents such a pivotal moment in AI’s evolution.
    As we will explore in later sections, the implications of these reasoning capabilities
    vary significantly across industries, with some sectors positioned to benefit
    more immediately than others.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这些推理能力的实际应用有助于解释为什么像o1这样的模型的发展在人工智能的演变中是一个关键时刻。正如我们将在后面的章节中探讨的，这些推理能力的影响在各个行业之间差异很大，一些行业可能比其他行业更快地受益。
- en: What distinguishes these reasoning models is not just their performance but
    how they achieve it. While previous models struggled with multi-step reasoning,
    these systems demonstrate an ability to construct coherent logical chains, explore
    multiple solution paths, evaluate intermediate results, and construct complex
    proofs. Extensive evaluations reveal fundamentally different reasoning patterns
    from earlier models—resembling the deliberate problem-solving approaches of expert
    human reasoners rather than statistical pattern matching.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 区分这些推理模型的特点不仅在于它们的性能，还在于它们实现性能的方式。虽然之前的模型在多步推理上存在困难，但这些系统展示了构建连贯逻辑链、探索多种解决方案路径、评估中间结果和构建复杂证明的能力。广泛的评估揭示了与早期模型根本不同的推理模式——更类似于专家人类推理者的有意识问题解决方法，而不是统计模式匹配。
- en: 'The most significant aspect of these models for our discussion of scaling is
    that their capabilities weren’t achieved primarily through increased size. Instead,
    they represent breakthroughs in architecture and training approaches:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这些模型对我们讨论扩展规模最重要的方面是，它们的性能并非主要通过增加规模来实现。相反，它们代表了架构和训练方法的突破：
- en: '**Advanced reasoning architectures** that support recursive thinking processes'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高级推理架构**，支持递归思维过程'
- en: '**Process-supervised learning** that evaluates and rewards intermediate reasoning
    steps, not just final answers'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**过程监督学习**，评估和奖励中间推理步骤，而不仅仅是最终答案'
- en: '**Test-time computation allocation** that allows models to think longer about
    difficult problems'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**测试时计算分配**，允许模型对困难问题进行更长时间的思考'
- en: '**Self-play reinforcement learning** where models improve by competing against
    themselves'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自我博弈强化学习**，模型通过与自己竞争来提高'
- en: These developments challenge the simple scaling hypothesis by demonstrating
    that qualitative architectural innovations and novel training approaches can yield
    discontinuous improvements in capabilities. They suggest that the future of AI
    advancement may depend more on how models are structured to think than on raw
    parameter counts—a theme we’ll explore further in the Limitations of scaling section.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这些发展挑战了简单的扩展假设，通过展示定性架构创新和新的训练方法可以带来能力的跳跃式改进。这表明，AI发展的未来可能更多地取决于模型的结构如何思考，而不是原始参数数量——这是我们将在扩展规模的局限性部分进一步探讨的主题。
- en: The following tracks the progress of AI systems across various capabilities
    relative to human performance over a 25-year period. Human performance serves
    as the baseline (set to zero on the vertical axis), while each AI capability’s
    initial performance is normalized to -100\. The chart reveals the varying trajectories
    and timelines for different AI capabilities reaching and exceeding human-level
    performance. Note the particularly steep improvement curve for predictive reasoning,
    suggesting this capability remains in a phase of rapid advancement rather than
    plateauing. Reading comprehension, language understanding, and image recognition
    all crossed the human performance threshold between approximately 2015 and 2020,
    while handwriting and speech recognition achieved this milestone earlier.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 下表追踪了AI系统在25年期间相对于人类性能在各种能力上的进展。人类性能作为基准（在垂直轴上设置为零），而每个AI能力的初始性能被归一化到-100。图表揭示了不同AI能力达到并超越人类水平性能的不同轨迹和时间表。注意预测推理的曲线特别陡峭，这表明这一能力仍处于快速发展阶段，而不是趋于平缓。阅读理解、语言理解和图像识别都在大约2015年至2020年之间超过了人类性能阈值，而手写和语音识别则更早达到了这一里程碑。
- en: 'The comparison between human cognition and generative AI reveals several fundamental
    differences that persist despite remarkable progress between 2022 and 2025\. Here
    is a table summarizing the key strengths and deficiencies of current generative
    AI compared to human cognition:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 人类认知与生成式AI之间的比较揭示了几个在2022年至2025年之间尽管取得了显著进步但依然持续存在的根本性差异。以下是一个表格，总结了当前生成式AI与人类认知相比的关键优势和不足：
- en: '| **Category** | **Human Cognition** | **Generative AI** |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| **类别** | **人类认知** | **生成式AI** |'
- en: '| **Conceptual understanding** | Forms causal models grounded in physical and
    social experience; builds meaningful concept relationships beyond statistical
    patterns | Relies primarily on statistical pattern recognition without true causal
    understanding; can manipulate symbols fluently without deeper semantic comprehension
    |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| **概念理解** | 建立在物理和社会经验基础上的因果模型；在统计模式之外建立有意义的概念关系 | 主要依赖统计模式识别，缺乏真正的因果理解；可以流畅地操作符号，但没有更深层次的语义理解
    |'
- en: '| **Factual processing** | Integrates knowledge with significant cognitive
    biases; susceptible to various reasoning errors while maintaining functional reliability
    for survival | Produces confident but often hallucinated information; struggles
    to distinguish reliable from unreliable information despite retrieval augmentation
    |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| **事实处理** | 将知识与显著认知偏差相结合；在保持生存功能可靠性的同时，容易受到各种推理错误的影响 | 产生自信但往往幻觉的信息；尽管检索增强，但难以区分可靠和不可靠的信息
    |'
- en: '| **Adaptive learning and reasoning** | Slow acquisition of complex skills
    but highly sample-efficient; transfers strategies across domains using analogical
    thinking; can generalize from a few examples within familiar contexts | Requires
    massive datasets for initial training; reasoning abilities strongly bound by training
    distribution; increasingly capable of in-context learning but struggles with truly
    novel domains |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| **自适应学习和推理** | 慢速掌握复杂技能但样本效率高；通过类比思维在不同领域间转移策略；可以从熟悉环境中的几个例子中推广 | 需要大量数据集进行初始训练；推理能力强烈受限于训练分布；越来越擅长情境学习，但在真正新颖的领域方面存在困难
    |'
- en: '|'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '**Memory and state tracking**'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**记忆和状态跟踪**'
- en: '| Limited working memory (4-7 chunks); excellent at tracking relevant states
    despite capacity constraints; compensates with selective attention | Theoretically
    unlimited context window, but fundamental difficulties with coherent tracking
    of object and agent states across extended scenarios |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| 有限的短期记忆（4-7个块）；尽管容量有限，但擅长跟踪相关状态；通过选择性注意进行补偿 | 理论上具有无限大的上下文窗口，但在跨场景中连贯跟踪对象和代理状态方面存在根本性困难
    |'
- en: '| **Social understanding** | Naturally develops models of others’ mental states
    through embodied experience; intuitive grasp of social dynamics with varying individual
    aptitude | Limited capacity to track different belief states and social dynamics;
    requires specialized fine-tuning for basic theory of mind capabilities |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| **社会理解** | 通过具身经验自然发展他人心理状态模型；对社会动态有直观的理解，个体适应性各异 | 跟踪不同信念状态和社会动态的能力有限；需要专门的微调以实现基本的心智理论能力
    |'
- en: '| **Creative generation** | Generates novel combinations extending beyond prior
    experience; innovation grounded in recombination, but can push conceptual boundaries
    | Bounded by training distribution; produces variations on known patterns rather
    than fundamentally new concepts |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| **创造性生成** | 生成超出先前经验的创新组合；创新基于重组，但可以推动概念边界 | 受限于训练分布；产生已知模式的变体而不是根本性的新概念
    |'
- en: '| **Architectural properties** | Modular, hierarchical organization with specialized
    subsystems; parallel distributed processing with remarkable energy efficiency
    (~20 watts) | Largely homogeneous architectures with limited functional specialization;
    requires massive computational resources for both training and inference |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| **架构属性** | 模块化、分层组织，具有专用子系统；并行分布式处理，能源效率显著（约20瓦特） | 架构大体同质，功能专业化有限；训练和推理都需要大量计算资源
    |'
- en: 'Table 10.1: Comparison between human cognition and generative AI'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 表10.1：人类认知与生成式AI的比较
- en: While current AI systems have made extraordinary advances in producing high-quality
    content across modalities (images, videos, coherent text), they continue to exhibit
    significant limitations in deeper cognitive capabilities.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管当前的人工智能系统在跨模态（图像、视频、连贯文本）生成高质量内容方面取得了非凡的进步，但它们在更深层次的认知能力方面仍然存在显著的局限性。
- en: Recent research highlights particularly profound limitations in social intelligence.
    A December 2024 study by Sclar et al. found that even frontier models like Llama-3.1
    70B and GPT-4o show remarkably poor performance (as low as 0-9% accuracy) on challenging
    **Theory of Mind** (**ToM**) scenarios. This inability to model others’ mental
    states, especially when they differ from available information, represents a fundamental
    gap between human and AI cognition.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的研究突出了社会智能方面的特别深刻的局限性。Sclar等人于2024年12月进行的一项研究发现，即使是像Llama-3.1 70B和GPT-4o这样的前沿模型，在具有挑战性的**心智理论**（**ToM**）场景中的表现也相当糟糕（准确率低至0-9%）。这种无法模拟他人心理状态的能力，尤其是在他们与可用信息不同时，代表了人类与AI认知之间的一个根本性差距。
- en: Interestingly, the same study found that targeted fine-tuning with carefully
    crafted ToM scenarios yielded significant improvements (+27 percentage points),
    suggesting that some limitations may reflect inadequate training examples rather
    than insurmountable architectural constraints. This pattern extends to other capabilities—while
    scaling alone isn’t sufficient to overcome cognitive limitations, specialized
    training approaches show promise.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，同一项研究发现，通过精心设计的ToM场景进行针对性的微调可以获得显著的改进（+27个百分点），这表明某些局限性可能反映了不充分的训练示例，而不是不可逾越的架构限制。这种模式也扩展到其他能力——而仅仅通过扩展规模并不能克服认知限制，专门的训练方法显示出希望。
- en: The gap in state tracking capabilities is particularly relevant. Despite theoretically
    unlimited context windows, AI systems struggle with coherently tracking object
    states and agent knowledge through complex scenarios. Humans, despite limited
    working memory capacity (typically 3-4 chunks according to more recent cognitive
    research), excel at tracking relevant states through selective attention and effective
    information organization strategies.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在状态跟踪能力方面的差距尤为相关。尽管理论上具有无限大的上下文窗口，AI系统在通过复杂场景连贯跟踪物体状态和代理知识方面仍然存在困难。人类尽管工作记忆容量有限（根据最新的认知研究，通常是3-4个块），但通过选择性注意和有效的信息组织策略，在跟踪相关状态方面表现出色。
- en: While AI systems have made impressive strides in multimodal integration (text,
    images, audio, video), they still lack the seamless cross-modal understanding
    that humans develop naturally. Similarly, in creative generation, AI remains bounded
    by its training distribution, producing variations on known patterns rather than
    fundamentally new concepts.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管AI系统在多模态集成（文本、图像、音频、视频）方面取得了显著的进步，但它们仍然缺乏人类自然发展出的无缝跨模态理解。同样，在创造性生成方面，AI仍然受限于其训练分布，产生的是已知模式的变体，而不是根本性的新概念。
- en: From an architectural perspective, the human brain’s modular, hierarchical organization
    with specialized subsystems enables remarkable energy efficiency (~20 watts) compared
    to AI’s largely homogeneous architectures requiring massive computational resources.
    Additionally, AI systems can perpetuate and amplify biases present in their training
    data, raising ethical concerns beyond performance limitations.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 从建筑学的角度来看，人脑模块化、分层的组织结构以及专门的子系统使得其相较于需要大量计算资源的AI的相对同质化架构，具有令人瞩目的能源效率（约20瓦）。此外，AI系统可能会持续放大其训练数据中存在的偏差，从而在性能限制之外引发伦理问题。
- en: These differences suggest that while certain capabilities may improve through
    better training data and techniques, others may require more fundamental architectural
    innovations to bridge the gap between statistical pattern matching and genuine
    understanding.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这些差异表明，虽然某些能力可能通过更好的训练数据和技巧得到提升，但其他能力可能需要更根本的架构创新，以弥合统计模式匹配与真正理解之间的差距。
- en: 'Despite impressive advances in generative AI, fundamental gaps remain between
    human and AI cognition across multiple dimensions. Most critically, AI lacks:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在生成式AI方面取得了令人印象深刻的进步，但人类与AI在认知的多个维度上仍然存在根本性的差距。最重要的是，AI缺乏：
- en: Real-world grounding for knowledge
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 知识的现实世界基础
- en: Adaptive flexibility across contexts
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在不同情境下的适应性灵活性
- en: Truly integrated understanding beneath surface fluency
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 真正的深层流畅理解
- en: Energy-efficient processing
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 能源高效的加工
- en: Social and contextual awareness
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 社会和情境意识
- en: These limitations aren’t isolated issues but interconnected aspects of the same
    fundamental challenges in developing truly human-like artificial intelligence.
    Alongside technical advances, the regulatory landscape for AI is evolving rapidly,
    creating a complex global marketplace. The European Union’s AI Act, implemented
    in 2024, has created stringent requirements that have delayed or limited the availability
    of some AI tools in European markets. For instance, Meta AI became available in
    France only in 2025, two years after its US release, due to regulatory compliance
    challenges. This growing regulatory divergence adds another dimension to the evolution
    of AI beyond technical scaling, as companies must adapt their offerings to meet
    varying legal requirements while maintaining competitive capabilities.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这些局限性不是孤立的问题，而是真正类人人工智能开发中相同根本挑战的相互关联方面。随着技术进步，AI的监管环境正在迅速演变，创造了一个复杂的全球市场。欧盟的AI法案于2024年实施，它制定了严格的要求，导致一些AI工具在欧洲市场的可用性被推迟或受限。例如，Meta
    AI仅在2025年才在法国推出，比其在美国的发布晚了两年，这是由于监管合规挑战。这种日益增长的监管差异为AI的演变增添了另一个维度，因为公司必须调整其产品以符合不同的法律要求，同时保持竞争优势。
- en: The limitations of scaling and emerging alternatives
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 扩展的局限性和新兴的替代方案
- en: Understanding the limitations of the scaling paradigm and the emerging alternatives
    is crucial for anyone building or implementing AI systems today. As developers
    and stakeholders, recognizing where diminishing returns are setting in helps inform
    better investment decisions, technology choices, and implementation strategies.
    The shift beyond scaling represents both a challenge and an opportunity—a challenge
    to rethink how we advance AI capabilities, and an opportunity to create more efficient,
    accessible, and specialized systems. By exploring these limitations and alternatives,
    readers will be better equipped to navigate the evolving AI landscape, make informed
    architecture decisions, and identify the most promising paths forward for their
    specific use cases.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 理解扩展范式和新兴替代方案的局限性对于今天构建或实施AI系统的人来说至关重要。作为开发者和利益相关者，认识到收益递减何时开始出现有助于做出更好的投资决策、技术选择和实施策略。超越扩展的转型既是一个挑战，也是一个机遇——挑战我们重新思考如何推进AI能力，同时也是一个机遇，可以创建更高效、更易于访问和更专业的系统。通过探索这些局限性和替代方案，读者将更好地装备自己，以应对不断演变的AI领域，做出明智的架构决策，并确定针对其特定用例最有希望的路径。
- en: The scaling hypothesis challenged
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 扩展假设受到挑战
- en: The current doubling time in training compute of very large models is about
    8 months, outpacing established scaling laws such as Moore’s Law (transistor density
    at cost increases at a rate of currently about 18 months) and Rock’s Law (costs
    of hardware like GPUs and TPUs halve every 4 years).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 当前在训练超大型模型时的计算量翻倍时间大约为8个月，超过了如摩尔定律（晶体管密度在成本增加的情况下以目前大约18个月的速度增长）和洛克定律（如GPU和TPU等硬件的成本每4年减半）等既定的扩展定律。
- en: According to Leopold Aschenbrenner’s *Situational Awareness* document from June
    2024, AI training compute has been increasing by about 4.6x per year since 2010,
    while GPU FLOP/s are only increasing at about 1.35x per year. Algorithmic improvements
    are delivering performance gains at approximately 3x per year. This extraordinary
    pace of compute scaling reflects an unprecedented arms race in AI development,
    far beyond traditional semiconductor scaling norms.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 根据Leopold Aschenbrenner于2024年6月的“情境意识”文档，自2010年以来，AI训练计算量每年增加约4.6倍，而GPU FLOP/s的年增长率仅为约1.35倍。算法改进每年大约带来3倍的性能提升。这种计算扩展的非凡速度反映了AI发展中前所未有的军备竞赛，远远超出了传统半导体扩展规范。
- en: Gemini Ultra is estimated to have used approximately 5 × 10^25 FLOP in its final
    training run, making it (as of this writing) likely the most compute-intensive
    model ever trained. Concurrently, language model training datasets have grown
    by about 3.0x per year since 2010, creating massive data requirements.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: Gemini Ultra的最终训练运行估计使用了大约5 × 10^25 FLOP，这使得它（截至本文撰写时）可能是训练过的计算量最大的模型。同时，自2010年以来，语言模型训练数据集每年增长约3.0倍，创造了巨大的数据需求。
- en: 'By 2024-2025, a significant shift in perspective has occurred regarding the
    *scaling hypothesis*—the idea that simply scaling up model size, data, and compute
    would inevitably lead to **artificial general intelligence** (**AGI**). Despite
    massive investments (estimated at nearly half a trillion dollars) in this approach,
    evidence suggests that scaling alone is hitting diminishing returns for several
    reasons:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 到2024-2025年，关于**规模假设**——即仅仅通过扩大模型规模、数据和计算能力就能必然导致**通用人工智能**（**AGI**）的想法，已经发生了重大的视角转变。尽管在这一方法上投入了巨额资金（估计近半兆美元），但证据表明，仅靠规模扩张已经因为以下几个原因而开始遇到边际效益递减：
- en: First, performance has begun plateauing. Despite enormous increases in model
    size and training compute, fundamental challenges like hallucinations, unreliable
    reasoning, and factual inaccuracies persist even in the largest models. High-profile
    releases such as Grok 3 (with 15x the compute of its predecessor) still exhibit
    basic errors in reasoning, math, and factual information.
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，性能已经开始停滞不前。尽管模型规模和训练计算能力有了巨大的增加，但像幻觉、不可靠的推理和事实不准确这样的基本挑战即使在最大的模型中也依然存在。像Grok
    3（其计算能力是其前身15倍）这样的高调发布仍然表现出推理、数学和事实信息的基本错误。
- en: Second, the competitive landscape has shifted dramatically. The once-clear technological
    lead of companies like OpenAI has eroded, with 7-10 GPT-4 level models now available
    in the market. Chinese companies like DeepSeek have achieved comparable performance
    with dramatically less compute (as little as 1/50th of the training costs), challenging
    the notion that massive resource advantage translates to insurmountable technological
    leads.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二，竞争格局发生了巨大变化。像OpenAI这样的公司曾经明显的技术领先优势已经削弱，现在市场上已经有了7-10个GPT-4级别的模型。像DeepSeek这样的中国公司以显著较少的计算能力（训练成本仅为1/50）实现了相当的性能，挑战了资源优势巨大就能转化为不可逾越的技术领先的观点。
- en: Third, economic unsustainability has become apparent. The scaling approach has
    led to enormous costs without proportional revenue. Price wars have erupted as
    competitors with similar capabilities undercut each other, compressing margins
    and eroding the economic case for ever-larger models.
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第三，经济不可持续性变得明显。规模方法导致了巨大的成本，而没有相应的收入。价格战已经爆发，具有相似能力的竞争对手相互压价，压缩了利润空间，侵蚀了更大模型的经济学依据。
- en: Finally, industry recognition of these limitations has grown. Key industry figures,
    including Microsoft CEO Satya Nadella and prominent investors like Marc Andreessen,
    have publicly acknowledged that scaling laws may be hitting a ceiling, similar
    to how Moore’s Law eventually slowed down in chip manufacturing.
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，行业对这些局限性的认识已经增长。包括微软CEO萨提亚·纳德拉和著名投资者马克·安德森在内的关键行业人物，已经公开承认，规模定律可能已经触及天花板，类似于摩尔定律最终在芯片制造中放缓的情况。
- en: Big tech vs. small enterprises
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 大型科技公司与中小企业
- en: The rise of open source AI has been particularly transformative in this shifting
    landscape. Projects like Llama, Mistral, and others have democratized access to
    powerful foundation models, allowing smaller companies to build, fine-tune, and
    deploy their own LLMs without the massive investments previously required. This
    open source ecosystem has created fertile ground for innovation where specialized,
    domain-specific models developed by smaller teams can outperform general models
    from tech giants in specific applications, further eroding the advantages of scale
    alone.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 开源AI的兴起在这一转变的格局中尤其具有变革性。像Llama、Mistral等项目已经使强大的基础模型的可访问性民主化，允许较小的公司无需巨额投资就能构建、微调和部署他们自己的LLMs。这个开源生态系统为创新创造了肥沃的土壤，其中由小型团队开发的特定领域模型可以在特定应用中超越科技巨头的通用模型，进一步削弱了仅靠规模的优势。
- en: Several smaller companies have demonstrated this dynamic successfully. Cohere,
    with a team a fraction of the size of Google or OpenAI, has developed specialized
    enterprise-focused models that match or exceed larger competitors in business
    applications through innovative training methodologies focused on instruction-following
    and reliability. Similarly, Anthropic achieved command performance with Claude
    models that often outperformed larger competitors in reasoning and safety benchmarks
    by emphasizing constitutional AI approaches rather than just scale. In the open-source
    realm, Mistral AI has repeatedly shown that their carefully designed smaller models
    can achieve performance competitive with models many times their size.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 几家较小的公司已经成功地展示了这种动态。Cohere公司，其团队规模仅为Google或OpenAI的一小部分，通过专注于指令遵循和可靠性的创新训练方法，开发了专门针对企业的模型，这些模型在商业应用中与较大的竞争对手相匹配或超过。类似地，Anthropic通过强调宪法AI方法而不是仅仅规模，实现了Claude模型在推理和安全基准测试中经常超越较大竞争对手的卓越表现。在开源领域，Mistral
    AI反复证明，它们精心设计的较小模型可以实现与规模大得多模型相媲美的性能。
- en: What’s becoming increasingly evident is that the once-clear technological moat
    enjoyed by Big Tech firms is rapidly eroding. The competitive landscape has dramatically
    shifted in 2024-2025.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 越来越明显的是，大型科技公司曾经拥有的清晰的技术护城河正在迅速侵蚀。2024-2025年的竞争格局发生了戏剧性的变化。
- en: Multiple capable models have emerged. Where OpenAI once stood alone with ChatGPT
    and GPT-4, there are now 7-10 comparable models available in the market from companies
    like Anthropic, Google, Meta, Mistral, and DeepSeek, significantly reducing OpenAI’s
    perceived uniqueness and technological advantage.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 多个有能力的模型已经出现。在OpenAI曾经独自拥有ChatGPT和GPT-4的时候，现在市场上已经有来自Anthropic、Google、Meta、Mistral和DeepSeek等公司的7-10个类似模型，这显著降低了OpenAI的感知独特性和技术优势。
- en: Price wars and commoditization have intensified. As capabilities have equalized,
    providers have engaged in aggressive price cutting. OpenAI has repeatedly lowered
    prices in response to competitive pressure, particularly from Chinese companies
    offering similar capabilities at lower costs.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 价格战和商品化趋势加剧。随着能力的均衡，供应商们开始进行激进的降价。OpenAI为了应对竞争压力，尤其是来自提供类似能力但成本更低的中国的公司的压力，已经多次降低价格。
- en: Non-traditional players have demonstrated rapid catch-up. Companies like DeepSeek
    and ByteDance have achieved comparable model quality with dramatically lower training
    costs, demonstrating that innovative training methodologies can overcome resource
    disparities. Additionally, innovation cycles have shortened considerably. New
    technical advances are being matched or surpassed within weeks or months rather
    than years, making any technological lead increasingly temporary.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 非传统玩家已经展示了快速追赶的能力。DeepSeek和ByteDance等公司通过显著降低训练成本实现了与竞争对手相当的模式质量，证明了创新训练方法可以克服资源差异。此外，创新周期已经大幅缩短。新的技术进步在几周或几个月内就能得到匹配或超越，而不是几年，这使得任何技术领先都越来越短暂。
- en: Looking at the technology adoption landscape, we can consider two primary scenarios
    for AI implementation. In the centralized scenario, generative AI and LLMs are
    primarily developed and controlled by large tech firms that invest heavily in
    the necessary computational hardware, data storage, and specialized AI/ML talent.
    These entities produce general proprietary models that are often made accessible
    to customers through cloud services or APIs, but these one-size-fits-all solutions
    may not perfectly align with the requirements of every user or organization.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 观察技术采用格局，我们可以考虑AI实施的两种主要场景。在集中式场景中，生成式AI和LLMs主要由大量投资于必要的计算硬件、数据存储和专门AI/ML人才的大型科技公司开发和控制。这些实体生产通用专有模型，这些模型通常通过云服务或API向客户开放，但这些一刀切解决方案可能无法完美地满足每个用户或组织的需要。
- en: Conversely, in the self-service scenario, companies or individuals take on the
    task of fine-tuning their own AI models. This approach allows them to create models
    that are customized to the specific needs and proprietary data of the user, providing
    more targeted and relevant functionality. As costs decline for computing, data
    storage, and AI talent, custom fine-tuning of specialized models is already feasible
    for small and mid-sized companies.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，在自助服务场景中，公司或个人承担了微调自身AI模型的任务。这种方法使他们能够创建针对用户特定需求和专有数据的定制模型，提供更精准和相关的功能。随着计算、数据存储和AI人才成本的下降，对专业模型的定制微调对于小型和中型公司来说已经可行。
- en: A hybrid landscape is likely to emerge where both approaches fulfill distinct
    roles based on use cases, resources, expertise, and privacy considerations. Large
    firms might continue to excel in providing industry-specific models, while smaller
    entities could increasingly fine-tune their own models to meet niche demands.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 很可能会出现一个混合格局，其中两种方法根据用例、资源、专业知识和隐私考虑因素发挥不同的作用。大型公司可能会继续在提供行业特定模型方面表现出色，而较小的实体可能会越来越多地微调自己的模型以满足特定需求。
- en: If robust tools emerge to simplify and automate AI development, custom generative
    models may even be viable for local governments, community groups, and individuals
    to address hyper-local challenges. While large tech firms currently dominate generative
    AI research and development, smaller entities may ultimately stand to gain the
    most from these technologies.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 如果出现强大的工具来简化并自动化人工智能开发，定制生成模型甚至可能对地方政府、社区团体和个人解决超本地问题具有可行性。虽然大型科技公司目前主导着生成人工智能的研究和开发，但较小的实体最终可能从这些技术中获得最大的收益。
- en: Emerging alternatives to pure scaling
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 纯规模化之外的兴起替代方法
- en: 'As the limitations of scaling become more apparent, several alternative approaches
    are gaining traction. Many of these perspectives on moving beyond pure scaling
    draw inspiration from Leopold Aschenbrenner’s influential June 2024 paper *Situational
    Awareness: The Decade Ahead* ([https://situational-awareness.ai/](https://situational-awareness.ai/)),
    which provided a comprehensive analysis of AI scaling trends and their limitations
    while exploring alternative paradigms for advancement. These approaches can be
    organized into three main paradigms. Let’s look at each of them.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 随着规模化的局限性变得更加明显，几种替代方法正在获得关注。许多超越纯粹规模化的观点都受到了利奥波德·阿申布伦纳（Leopold Aschenbrenner）有影响力的2024年6月论文《情境意识：未来十年》([https://situational-awareness.ai/](https://situational-awareness.ai/))的启发，该论文全面分析了人工智能规模化的趋势及其局限性，同时探讨了进步的替代范式。这些方法可以归纳为三个主要范式。让我们逐一看看它们。
- en: Scaling up (traditional approach)
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 规模化提升（传统方法）
- en: 'The traditional approach to AI advancement has centered on scaling up—pursuing
    greater capabilities through larger models, more compute, and bigger datasets.
    This paradigm can be broken down into several key components:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能进步的传统方法一直集中在规模化提升——通过更大的模型、更多的计算和更大的数据集追求更大的能力。这个范式可以分解为几个关键组成部分：
- en: '**Increasing model size and complexity**: The predominant approach since 2017
    has been to create increasingly large neural networks with more parameters. GPT-3
    expanded to 175 billion parameters, while more recent models like GPT-4 and Gemini
    Ultra are estimated to have several trillion effective parameters. Each increase
    in size has generally yielded improvements in capabilities across a broad range
    of tasks.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**增加模型大小和复杂性**：自2017年以来，主要的方法一直是创建具有更多参数的越来越大型的神经网络。GPT-3扩展到1750亿个参数，而更近期的模型如GPT-4和Gemini
    Ultra据估计具有数万亿个有效参数。每次规模的增加通常都会在广泛的任务中带来能力的提升。'
- en: '**Expanding computational resources**: Training these massive models requires
    enormous computational infrastructure. The largest AI training runs now consume
    resources comparable to small data centers, with electricity usage, cooling requirements,
    and specialized hardware needs that put them beyond the reach of all but the largest
    organizations. A single training run for a frontier model can cost upwards of
    $100 million.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**扩展计算资源**：训练这些庞大的模型需要巨大的计算基础设施。现在最大的AI训练运行消耗的资源相当于小型数据中心，其电力消耗、冷却需求和专用硬件需求使得除了最大的组织之外的所有组织都无法触及。一个前沿模型的单一训练运行可能耗资超过1亿美元。'
- en: '**Gathering vast datasets**: As models grow, so too does their hunger for training
    data. Leading models are trained on trillions of tokens, essentially consuming
    much of the high-quality text available on the internet, books, and specialized
    datasets. This approach requires sophisticated data processing pipelines and significant
    storage infrastructure.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**收集庞大的数据集**：随着模型的增长，其对训练数据的渴望也在增加。领先的模型在万亿个标记上训练，实际上消耗了互联网、书籍和专用数据集中大部分高质量文本，这种方法需要复杂的数据处理管道和大量的存储基础设施。'
- en: '**Limitations becoming apparent**: While this approach has dominated AI development
    to date and produced remarkable results, it faces increasing challenges in terms
    of diminishing returns on investment, economic sustainability, and technical barriers
    that scaling alone cannot overcome.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**局限性日益显现**：虽然这种方法至今主导了人工智能的发展并产生了显著的结果，但它面临着越来越多的挑战，包括投资回报递减、经济可持续性和仅通过扩展无法克服的技术障碍。'
- en: Scaling down (efficiency innovations)
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**缩减（效率创新）**'
- en: 'The efficiency paradigm focuses on achieving more with less through several
    key techniques:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 效率范式通过几种关键技术来实现以更少的资源做更多的事情：
- en: '**Quantization** converts models to lower precision by reducing bit sizes of
    weights and activations. This technique can compress large model performance into
    smaller form factors, dramatically reducing computational and storage requirements.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**量化**通过减少权重和激活的位数将模型转换为较低的精度。这项技术可以将大型模型性能压缩到更小的形式，显著降低计算和存储需求。'
- en: '**Model distillation** transfers knowledge from large “teacher” models to smaller,
    more efficient “student” models, enabling deployment on more limited hardware.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型蒸馏**将知识从大型“教师”模型转移到更小、更高效的“学生”模型，使得在更有限的硬件上部署成为可能。'
- en: '**Memory-augmented architectures** represent a breakthrough approach. Meta
    FAIR’s December 2024 research on memory layers demonstrated how to improve model
    capabilities without proportional increases in computational requirements. By
    replacing some feed-forward networks with trainable key-value memory layers scaled
    to 128 billion parameters, researchers achieved over 100% improvement in factual
    accuracy while also enhancing performance on coding and general knowledge tasks.
    Remarkably, these memory-augmented models matched the performance of dense models
    trained with 4x more compute, directly challenging the assumption that more computation
    is the only path to better performance. This approach specifically targets factual
    reliability—addressing the hallucination problem that has persisted despite increasing
    scale in traditional architectures.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**记忆增强架构**代表了一种突破性的方法。Meta FAIR在2024年12月关于记忆层的研究展示了如何在不增加计算需求成比例的情况下提高模型能力。通过用可训练的关键值记忆层替换一些前馈网络，并将这些层扩展到1280亿个参数，研究人员实现了事实准确性的超过100%的提高，同时也在编码和一般知识任务上提升了性能。令人惊讶的是，这些记忆增强模型与使用4倍更多计算量训练的密集模型的表现相当，直接挑战了更多计算是通往更好性能的唯一途径的假设。这种方法专门针对事实可靠性——解决传统架构中尽管规模增加但持续存在的幻觉问题。'
- en: '**Specialized models** offer another alternative to general-purpose systems.
    Rather than pursuing general intelligence through scale, focused models tailored
    to specific domains often deliver better performance at lower costs. Microsoft’s
    Phi series, now advanced to phi-3 (April 2024), demonstrates how careful data
    curation can dramatically alter scaling laws. While models like GPT-4 were trained
    on vast, heterogeneous datasets, the Phi series achieved remarkable performance
    with much smaller models by focusing on high-quality textbook-like data.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**专用模型**为通用系统提供了另一种选择。这些模型不是通过规模来追求通用智能，而是针对特定领域进行定制，通常在较低的成本下提供更好的性能。微软的Phi系列，现已发展到phi-3（2024年4月），展示了精心数据整理如何显著改变扩展定律。虽然像GPT-4这样的模型是在庞大的、异构的数据集上训练的，但Phi系列通过专注于高质量的教科书式数据，使用更小的模型实现了显著的性能。'
- en: Scaling out (distributed approaches)
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**扩展（分布式方法）**'
- en: This distributed paradigm explores how to leverage networks of models and computational
    resources.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 这种分布式范式探讨了如何利用模型和计算资源网络。
- en: '**Test-time compute** shifts focus from training larger models to allocating
    more computation during inference time. This allows models to *reason* through
    problems more thoroughly. Google DeepMind’s Mind Evolution approach achieves over
    98% success rates on complex planning tasks without requiring larger models, demonstrating
    the power of evolutionary search strategies during inference. This approach consumes
    three million tokens due to very long prompts, compared to 9,000 tokens for normal
    Gemini operations, but achieves dramatically better results.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '**测试时计算**将重点从训练更大的模型转移到在推理时分配更多的计算。这使得模型能够更彻底地通过问题进行推理。谷歌DeepMind的Mind Evolution方法在复杂规划任务上实现了超过98%的成功率，而不需要更大的模型，展示了在推理期间进化搜索策略的力量。这种方法由于非常长的提示，消耗了三百万个标记，而正常的Gemini操作只需要9000个标记，但实现了显著更好的结果。'
- en: Recent advances in reasoning capabilities have moved beyond simple autoregressive
    token generation by introducing the concept of *thought*—sequences of tokens representing
    intermediate steps in reasoning processes. This paradigm shift enables models
    to mimic complex human reasoning through tree search and reflective thinking approaches.
    Research shows that encouraging models to think with more tokens during test-time
    inference significantly boosts reasoning accuracy.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 近期在推理能力方面的进步已经超越了简单的自回归标记生成，通过引入**思想**的概念——表示推理过程中中间步骤的标记序列。这种范式转变使得模型能够通过树搜索和反思性思维方法来模仿复杂的人类推理。研究表明，在测试时间推理过程中鼓励模型使用更多标记进行思考可以显著提高推理准确性。
- en: 'Multiple approaches have emerged to leverage this insight: Process-based supervision,
    where models generate step-by-step reasoning chains and receive rewards on intermediate
    steps. **Monte Carlo Tree Search** (**MCTS**) techniques that explore multiple
    reasoning paths to find optimal solutions, and revision models trained to solve
    problems iteratively, refining previous attempts.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 出现了多种方法来利用这一洞察：基于过程的监督，其中模型生成逐步推理链并从中间步骤获得奖励。**蒙特卡洛树搜索**（**MCTS**）技术通过探索多个推理路径来寻找最优解，以及训练用于迭代解决问题、改进先前尝试的修订模型。
- en: 'For example, the 2025 rStar-Math paper (*rStar-Math: Small LLMs Can Master
    Math Reasoning with Self-Evolved Deep Thinking*) demonstrated that a model can
    achieve reasoning capabilities comparable to OpenAI’s o1 without distillation
    from superior models, instead leveraging “deep thinking” through MCTS guided by
    an SLM-based process reward model. This represents a fundamentally different approach
    to improving AI capabilities than traditional scaling methods.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，2025年的rStar-Math论文（*rStar-Math：小型LLM可以通过自我进化的深度思考掌握数学推理*）证明了模型可以在不通过从更优模型中蒸馏的情况下，达到与OpenAI的o1相当的推理能力，而是通过SLM（基于强化学习的过程奖励模型）引导的MCTS进行“深度思考”。这代表了与传统扩展方法相比，提高AI能力的一种根本不同的方法。
- en: '**RAG** grounds model outputs in external knowledge sources, which helps address
    hallucination issues more effectively than simply scaling up model size. This
    approach allows even smaller models to access accurate, up-to-date information
    without having to encode it all in parameters.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '**RAG**将模型输出建立在外部知识源的基础上，这比简单地扩大模型规模更有效地解决了幻觉问题。这种方法允许即使是更小的模型也能访问准确、最新的信息，而无需将其全部编码到参数中。'
- en: '**Advanced memory mechanisms** have shown promising results. Recent innovations
    like Meta FAIR’s memory layers and Google’s Titans neural memory models demonstrate
    superior performance while dramatically reducing computational requirements. Meta’s
    memory layers use a trainable key-value lookup mechanism to add extra parameters
    to a model without increasing FLOPs. They improve factual accuracy by over 100%
    on factual QA benchmarks while also enhancing performance on coding and general
    knowledge tasks. These memory layers can scale to 128 billion parameters and have
    been pretrained to 1 trillion tokens.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '**高级记忆机制**显示出有希望的结果。最近的创新，如Meta FAIR的记忆层和Google的Titans神经网络记忆模型，在大幅降低计算需求的同时展现出卓越的性能。Meta的记忆层使用可训练的键值查找机制向模型添加额外的参数，而不会增加FLOPs。它们在事实性问答基准测试中提高了超过100%的事实准确性，同时也在编码和一般知识任务上提升了性能。这些记忆层可以扩展到1280亿个参数，并且已经预训练到1万亿个标记。'
- en: 'Other innovative approaches in this paradigm include:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个范式中的其他创新方法包括：
- en: '**Neural Attention Memory Models (NAMMs)** improve the performance and efficiency
    of transformers without altering their architectures. NAMMs can cut input contexts
    to a fraction of the original sizes while improving performance by 11% on LongBench
    and delivering a 10-fold improvement on InfiniteBench. They’ve demonstrated zero-shot
    transferability to new transformer architectures and input modalities.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**神经注意力记忆模型（NAMMs）**在不改变其架构的情况下提高了transformers的性能和效率。NAMMs可以将输入上下文缩小到原始大小的几分之一，同时在LongBench上提高11%的性能，并在InfiniteBench上实现10倍的性能提升。它们已经证明了零样本迁移到新的transformer架构和输入模态的能力。'
- en: '**Concept-level modeling**, as seen in Meta’s Large Concept Models, operates
    at higher levels of abstraction than tokens, enabling more efficient processing.
    Instead of operating on discrete tokens, LCMs perform computations in a high-dimensional
    embedding space representing abstract units of meaning (concepts), which correspond
    to sentences or utterances. This approach is inherently modality-agnostic, supporting
    over 200 languages and multiple modalities, including text and speech.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**概念级建模**，如 Meta 的大型概念模型所示，在比标记更高的抽象级别上运行，从而实现更有效的处理。LCMs 不是在离散标记上操作，而是在代表抽象意义单位（概念）的高维嵌入空间中进行计算，这些概念对应于句子或话语。这种方法本质上是无模态的，支持超过
    200 种语言和多种模态，包括文本和语音。'
- en: '**Vision-centric enhancements** like OLA-VLM optimize multimodal models specifically
    for visual tasks without requiring multiple visual encoders. OLA-VLM improves
    performance over baseline models by up to 8.7% in depth estimation tasks and achieves
    a 45.4% mIoU score for segmentation tasks (compared to a 39.3% baseline).'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**以视觉为中心的增强**，如 OLA-VLM，针对视觉任务优化多模态模型，无需多个视觉编码器。OLA-VLM 在深度估计任务中比基线模型提高了高达
    8.7% 的性能，并在分割任务中实现了 45.4% 的 mIoU 分数（与 39.3% 的基线相比）。'
- en: This shift suggests that the future of AI development may not be dominated solely
    by organizations with the most computational resources. Instead, innovation in
    training methodologies, architecture design, and strategic specialization may
    determine competitive advantage in the next phase of AI development.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 这种转变表明，人工智能发展的未来可能不会仅由拥有最多计算资源的组织主导。相反，训练方法、架构设计和战略专业化的创新可能在人工智能发展的下一阶段决定竞争优势。
- en: Evolution of training data quality
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练数据质量的发展
- en: The evolution of training data quality has become increasingly sophisticated
    and follows three key developments. First, leading models discovered that books
    provided crucial advantages over web-scraped content. GPT-4 was found to have
    extensively memorized literary works, including the *Harry Potter* series, Orwell’s
    *Nineteen Eighty-Four*, and *The Lord of the Rings* trilogy—sources with coherent
    narratives, logical structures, and refined language that web content often lacks.
    This helped explain why early models with access to book corpora often outperformed
    larger models trained primarily on web data.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据质量的发展变得越来越复杂，遵循三个关键发展。首先，领先的模型发现书籍在内容上比网络爬取的内容具有关键优势。GPT-4 被发现广泛记忆了文学作品，包括《哈利·波特》系列、奥威尔的《1984》和《指环王》三部曲——这些作品具有连贯的叙事、逻辑结构和精致的语言，而网络内容往往缺乏这些。这有助于解释为什么早期能够访问书籍语料库的模型往往优于主要在网络上训练的大型模型。
- en: 'Second, data curation has evolved into a multi-tiered approach:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 第二，数据整理已演变成多级方法：
- en: '**Golden datasets**: Traditional subject-expert-created collections representing
    the highest quality standard'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**黄金数据集**：代表最高质量标准的传统主题专家创建的集合'
- en: '**Silver datasets**: LLM-generated content that mimics expert-level instruction,
    enabling massive scaling of training examples'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**银级数据集**：模仿专家级指令的 LLM 生成内容，使训练示例的规模实现大规模扩展'
- en: '**Super golden datasets**: Rigorously validated collections curated by diverse
    experts with multiple verification layers'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**超级黄金数据集**：由众多专家严格验证的、具有多层验证层的精选集合'
- en: '**Synthetic reasoning data**: Specially generated datasets focusing on step-by-step
    problem-solving approaches'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**合成推理数据**：专注于逐步问题解决方法的特别生成的数据集'
- en: Third, quality assessment has become increasingly sophisticated. Modern data
    preparation pipelines employ multiple filtering stages, contamination detection,
    bias detection, and quality scoring. These improvements have dramatically altered
    traditional scaling laws—a well-trained 7-billion-parameter model with exceptional
    data quality can now outperform earlier 175-billion-parameter models on complex
    reasoning tasks.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 第三，质量评估变得越来越复杂。现代数据准备管道采用多个过滤阶段、污染检测、偏差检测和质量评分。这些改进极大地改变了传统的扩展定律——一个经过良好训练的
    70 亿参数模型，如果数据质量优异，现在可以在复杂推理任务上优于早期的 1750 亿参数模型。
- en: This data-centric approach represents a fundamental alternative to pure parameter
    scaling, suggesting that the future of AI may belong to more efficient, specialized
    models trained on precisely targeted data rather than enormous general-purpose
    systems trained on everything available.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 这种以数据为中心的方法代表了纯参数缩放的根本性替代方案，表明人工智能的未来可能属于更高效、更专业的模型，这些模型在精确针对的数据上训练，而不是在所有可用内容上训练的庞大通用系统。
- en: An emerging challenge for data quality is the growing prevalence of AI-generated
    content across the internet. As generative AI systems produce more of the text,
    images, and code that appears online, future models trained on this data will
    increasingly be learning from other AI outputs rather than original human-created
    content. This creates a potential feedback loop that could eventually lead to
    plateauing performance, as models begin to amplify patterns, limitations, and
    biases present in previous AI generations rather than learning from fresh human
    examples. This *AI data saturation* phenomenon underscores the importance of continuing
    to curate high-quality, verified human-created content for training future models.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 数据质量面临的一个新兴挑战是互联网上人工智能生成内容的日益普遍。随着生成式人工智能系统产生越来越多的在线文本、图像和代码，基于这些数据训练的未来模型将越来越多地学习来自其他人工智能输出的内容，而不是原始的人类创造内容。这可能导致潜在的反馈循环，最终可能导致性能停滞，因为模型开始放大先前人工智能生成中存在的模式、局限性和偏差，而不是从新鲜的人类例子中学习。这种*人工智能数据饱和*现象强调了继续为训练未来模型精心挑选高质量、经过验证的人类创造内容的重要性。
- en: Democratization through technical advances
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过技术进步实现民主化
- en: The rapidly decreasing costs of AI model training represent a significant shift
    in the landscape, enabling broader participation in cutting-edge AI research and
    development. Several factors are contributing to this trend, including optimization
    of training regimes, improvements in data quality, and the introduction of novel
    model architectures.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能模型训练成本的快速下降代表着技术领域的重大转变，使得更多人能够参与到前沿的人工智能研究和开发中。这一趋势的推动因素包括训练制度的优化、数据质量的提升以及新型模型架构的引入。
- en: 'Here are the key techniques and approaches that make generative AI more accessible
    and effective:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是使生成式人工智能更加易于访问和有效的关键技术和方法：
- en: '**Simplified model architectures**: Streamlined model design for easier management,
    better interpretability, and lower computational cost'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**简化的模型架构**：简化模型设计，便于管理，提高可解释性，降低计算成本'
- en: '**Synthetic data generation**: Artificial training data that augments datasets
    while preserving privacy'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**合成数据生成**：人工训练数据，在保留隐私的同时增强数据集'
- en: '**Model distillation**: Knowledge transfer from large models into smaller,
    more efficient ones for easy deployment'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型蒸馏**：将大型模型中的知识转移到更小、更高效的模型中，以便于部署'
- en: '**Optimized inference engines**: Software frameworks that increase the speed
    and efficiency of executing AI models on given hardware'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**优化的推理引擎**：软件框架，可以增加在给定硬件上执行人工智能模型的速度和效率'
- en: '**Dedicated AI hardware accelerators**: Specialized hardware like GPUs and
    TPUs that dramatically accelerate AI computations'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**专用AI硬件加速器**：如GPU和TPU等专用硬件，显著加速人工智能计算'
- en: '**Open-source and synthetic data**: High-quality public datasets that enable
    collaboration and enhance privacy while reducing bias'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**开源和合成数据**：高质量公开数据集，促进协作，增强隐私性，同时减少偏差'
- en: '**Federated learning**: Training on decentralized data to improve privacy while
    benefiting from diverse sources'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**联邦学习**：在去中心化数据上训练，提高隐私性，同时从多样化的数据源中获益'
- en: '**Multimodality**: Integration of language with image, video, and other modalities
    in top models'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多模态**：在顶级模型中将语言与图像、视频和其他模态集成'
- en: Among the technical advancements helping to drive down costs, quantization techniques
    have emerged as an essential contributor. Open-source datasets and techniques
    such as synthetic data generation further democratize access to AI training by
    providing high-quality and data-efficient model development and removing some
    reliance on vast, proprietary datasets. Open-source initiatives contribute to
    the trend by providing cost-effective, collaborative platforms for innovation.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在帮助降低成本的技术进步中，量化技术已成为一个重要的贡献者。开源数据集和如合成数据生成等技术进一步民主化了对人工智能训练的访问，通过提供高质量、数据高效的模式开发以及减少对庞大、专有数据集的依赖。开源倡议通过提供成本效益高、协作性强的创新平台来推动这一趋势。
- en: 'These innovations collectively lower barriers that have so far impeded real-world
    generative AI adoption in several important ways:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 这些创新共同降低了阻碍现实世界生成式AI应用的障碍，以几种重要方式：
- en: Financial barriers are reduced by compressing large model performance into far
    smaller form factors through quantization and distillation
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过量化蒸馏将大型模型性能压缩成远更小的形式，从而降低了财务障碍
- en: Privacy considerations can potentially be addressed through synthetic data techniques,
    though reliable, reproducible implementations of federated learning for LLMs specifically
    remain an area of ongoing research rather than proven methodology
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过合成数据技术可能解决隐私考虑因素，尽管对于LLMs的联邦学习的可靠、可重复的实现仍然是一个持续研究而非已验证的方法论领域
- en: The accuracy limitations hampering small models are relieved through grounding
    generation with external information
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过将生成与外部信息相结合，缓解了阻碍小型模型的准确性限制
- en: Specialized hardware significantly accelerates throughput while optimized software
    maximizes existing infrastructure efficiency
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 专用硬件显著加速了吞吐量，而优化的软件最大化了现有基础设施的效率
- en: By democratizing access by tackling constraints like cost, security, and reliability,
    these approaches unlock benefits for vastly expanded audiences, steering generative
    creativity from a narrow concentration toward empowering diverse human talents.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 通过解决成本、安全性和可靠性等限制，这些方法通过民主化访问，为广泛的人群解锁了利益，将生成式创造力从狭窄的集中转向赋能多样化的人类才能。
- en: The landscape is shifting from a focus on sheer model size and brute-force compute
    to clever, nuanced approaches that maximize computational efficiency and model
    efficacy. With quantization and related techniques lowering barriers, we’re poised
    for a more diverse and dynamic era of AI development where resource wealth is
    not the only determinant of leadership in AI innovation.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 景观正在从关注纯粹模型大小和蛮力计算转向聪明、细致的方法，这些方法最大化了计算效率和模型功效。随着量化及相关技术降低了障碍，我们正准备进入一个更加多元和动态的AI发展时代，其中资源财富不是AI创新领导力的唯一决定因素。
- en: New scaling laws for post-training phases
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 后训练阶段的新的扩展定律
- en: Unlike traditional pre-training scaling, where performance improvements eventually
    plateau with increased parameter count, reasoning performance consistently improves
    with more time spent *thinking* during inference. Several studies indicate that
    allowing models more time to work through complex problems step by step could
    enhance their problem-solving capabilities in certain domains. This approach,
    sometimes called *inference-time scaling*, is still an evolving area of research
    with promising initial results.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 与传统的预训练扩展不同，在预训练扩展中，性能改进最终会随着参数数量的增加而达到平台期，推理性能会随着推理过程中花费更多时间“思考”而持续提高。几项研究表明，允许模型有更多时间逐步解决复杂问题可以增强它们在某些领域的解决问题的能力。这种方法，有时被称为“推理时间扩展”，仍然是一个不断发展的研究领域，但已显示出有希望的结果。
- en: This emerging scaling dynamic suggests that while pre-training scaling may be
    approaching diminishing returns, post-training and inference-time scaling represent
    promising new frontiers. The relationship between these scaling laws and instruction-following
    capabilities is particularly notable—models must have sufficiently strong instruction-following
    abilities to demonstrate these test-time scaling benefits. This creates a compelling
    case for concentrating research efforts on enhancing inference-time reasoning
    rather than simply expanding model size.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 这种新兴的扩展动态表明，尽管预训练扩展可能接近边际收益递减，但后训练和推理时间扩展代表了有希望的新前沿。这些扩展定律与指令遵循能力之间的关系尤其引人注目——模型必须具备足够的指令遵循能力，才能展示这些测试时间扩展的好处。这为将研究努力集中在增强推理时间推理上而不是简单地扩大模型规模提供了有力的论据。
- en: Having examined the technical limitations of scaling and the emerging alternatives,
    we now turn to the economic consequences of these developments. As we’ll see,
    the shift from pure scaling to more efficient approaches has significant implications
    for market dynamics, investment patterns, and value creation opportunities.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在考察了扩展的技术限制和新兴替代方案之后，我们现在转向这些发展的经济后果。正如我们将看到的，从纯扩展转向更有效的方法对市场动态、投资模式和价值创造机会具有重大影响。
- en: Economic and industry transformation
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 经济与产业转型
- en: 'Integrating generative AI promises immense productivity gains through automating
    tasks across sectors, while potentially causing workforce disruptions due to the
    pace of change. According to PwC’s 2023 G*lobal Artificial Intelligence Impact
    Index* and JPMorgan’s 2024 *The Economic Impact of Generative AI* reports, AI
    could contribute up to $15.7 trillion to the global economy by 2030, boosting
    global GDP by up to 14%. This economic impact will be unevenly distributed, with
    China potentially seeing a 26% GDP boost and North America around 14%. The sectors
    expected to see the highest impact include (in order):'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在各个行业自动化任务，整合生成式AI承诺带来巨大的生产力提升，同时由于变革的速度，可能会因劳动力中断而造成影响。根据普华永道2023年G*lobal
    Artificial Intelligence Impact Index*和摩根大通2024年*The Economic Impact of Generative
    AI*的报告，到2030年，AI可能为全球经济贡献高达15.7万亿美元，将全球GDP提升至14%。这种经济影响将分布不均，中国可能看到GDP增长26%，北美大约14%。预计将看到最高影响的行业包括（按顺序）：
- en: Healthcare
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 医疗保健
- en: Automotive
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 汽车行业
- en: Financial services
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 金融服务业
- en: Transportation and logistics
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 交通运输与物流
- en: JPM’s report highlights that AI is more than simple automation—it fundamentally
    enhances business capabilities. Future gains will likely spread across the economy
    as technology sector leadership evolves and innovations diffuse throughout various
    industries.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: JPM的报告强调，AI不仅仅是简单的自动化——它从根本上增强了商业能力。未来的收益可能会随着技术部门领导力的演变以及创新在各个行业的扩散而遍布整个经济。
- en: 'The evolution of AI adoption can be better understood within the context of
    previous technological revolutions, which typically follow an S-curve pattern
    with three distinct phases, as described in Everett Rogers’ seminal work *Diffusion
    of Innovations*. While typical technological revolutions have historically followed
    these phases over many decades, Leopold Aschenbrenner’s *Situational Awareness:
    The Decade Ahead* (2024) argues that AI implementation may follow a compressed
    timeline due to its unique ability to improve itself and accelerate its own development.
    Aschenbrenner’s analysis suggests that the traditional S-curve might be dramatically
    steepened for AI technologies, potentially compressing adoption cycles that previously
    took decades into years:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: AI采用的演变可以在以往技术革命的大背景下更好地理解，这些革命通常遵循S曲线模式，有三个不同的阶段，正如Everett Rogers在其开创性作品《创新的扩散》中所描述的。虽然典型的技术革命在历史上通常需要数十年才能遵循这些阶段，但Leopold
    Aschenbrenner的《未来十年：情境意识》（2024）认为，由于AI自我改进和加速自身发展的独特能力，AI的实施可能遵循一个压缩的时间表。Aschenbrenner的分析表明，传统的S曲线可能对于AI技术来说会陡峭得多，可能将原本需要数十年的采用周期压缩到几年：
- en: '**Learning phase (5-30 years)**: Initial experimentation and infrastructure
    development'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**学习阶段（5-30年）**：初步实验和基础设施开发'
- en: '**Doing phase (10-20 years)**: Rapid scaling once enabling infrastructure matures'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**实施阶段（10-20年）**：一旦基础设施成熟，将快速扩展'
- en: '**Optimization phase (ongoing)**: Incremental improvements after saturation'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**优化阶段（持续进行）**：饱和后的渐进式改进'
- en: 'Recent analyses indicate that AI implementation will likely follow a more complex,
    phased trajectory:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 近期分析表明，AI的实施可能遵循一个更复杂、分阶段的轨迹：
- en: '**2030-2040**: Manufacturing, logistics, and repetitive office tasks could
    reach 70-90% automation'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**2030-2040**：制造业、物流和重复性办公任务可能达到70-90%的自动化'
- en: '**2040-2050**: Service sectors like healthcare and education might reach 40-60%
    automation as humanoid robots and AGI capabilities mature'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**2040-2050**：服务行业如医疗和教育可能达到40-60%的自动化，随着类人机器人以及AGI能力的成熟'
- en: '**Post-2050**: Societal and ethical considerations may delay full automation
    of roles requiring empathy'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**2050年后**：社会和伦理考虑可能延迟需要同理心的角色的全面自动化'
- en: 'Based on analyses from the World Economic Forum’s “Future of Jobs Report 2023”
    and McKinsey Global Institute’s research on automation potential across sectors,
    we can map the relative automation potential across key industries:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 根据世界经济论坛“2023年就业未来报告”和麦肯锡全球研究院对跨行业自动化潜力的研究，我们可以绘制出关键行业的相对自动化潜力图：
- en: 'Specific automation levels and projections reveal varying rates of adoption:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 特定的自动化水平和预测揭示了采用率的差异：
- en: '| **Sector** | **Automation Potential** | **Key Drivers** |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| **行业** | **自动化潜力** | **关键驱动因素** |'
- en: '| Manufacturing | High—especially in repetitive tasks and structured environments
    | Collaborative robots, machine vision, AI quality control |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| 制造业 | 高——特别是在重复性任务和结构化环境中 | 协作机器人、机器视觉、AI质量控制 |'
- en: '| Logistics/Warehousing | High—particularly in sorting, picking, and inventory
    | Autonomous mobile robots (AMRs), automated sorting systems |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| 物流/仓储 | 高——尤其是在分类、拣选和库存方面 | 自主导航移动机器人（AMRs）、自动化分类系统 |'
- en: '|'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Healthcare
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 医疗保健
- en: '| Medium—concentrated in administrative and diagnostic tasks | AI diagnostic
    assistance, robotic surgery, automated documentation |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| 中等——主要集中在行政和诊断任务 | 人工智能诊断辅助、机器人手术、自动化文档 |'
- en: '| Retail | Medium—primarily in inventory and checkout processes | Self-checkout,
    inventory management, automated fulfillment |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| 零售 | 中等——主要在库存和结账流程中 | 自助结账、库存管理、自动化履行 |'
- en: 'Table 10.2: State of sector-specific automation levels and projections'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 表10.2：特定行业自动化水平的状态和预测
- en: This data supports a nuanced view of automation timelines across different sectors.
    While manufacturing and *logistics* are progressing rapidly toward high levels
    of automation, service sectors with complex human interactions face more significant
    barriers.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 这份数据支持了对不同行业自动化时间表的细致看法。虽然制造业和*物流*正迅速向高度自动化迈进，但涉及复杂人际互动的服务行业面临更大的障碍。
- en: Earlier McKinsey estimates from 2023 suggested that LLMs could directly automate
    20% of tasks and indirectly transform 50% of tasks. However, implementation has
    proven more challenging than anticipated. The most successful deployments have
    been those that augment human capabilities rather than attempt full replacement.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 2023年早期麦肯锡的估计表明，大型语言模型（LLMs）可以直接自动化20%的任务，间接转型50%的任务。然而，实施证明比预期更具挑战性。最成功的部署是那些增强人类能力而不是试图完全替代的。
- en: Industry-specific transformations and competitive dynamics
  id: totrans-167
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 行业特定的转型和竞争动态
- en: The competitive landscape for AI providers has evolved significantly in 2024-2025\.
    Price competition has intensified as technical capabilities converge across vendors,
    putting pressure on profit margins throughout the industry. Companies face challenges
    in establishing sustainable competitive advantages beyond their core technology,
    as differentiation increasingly depends on domain expertise, solution integration,
    and service quality rather than raw model performance. Corporate adoption rates
    remain modest compared to initial projections, suggesting that massive infrastructure
    investments made under the scaling hypothesis may struggle to generate adequate
    returns in the near term.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 2024-2025年间，人工智能提供商的竞争格局发生了显著变化。随着技术能力在供应商之间趋同，价格竞争加剧，整个行业的利润空间受到压力。公司面临挑战，在核心技术之外建立可持续的竞争优势，因为差异化越来越依赖于领域专业知识、解决方案集成和服务质量，而不是原始模型性能。与最初的预测相比，企业采用率仍然保持适度，这表明在扩展假设下进行的巨大基础设施投资可能难以在短期内产生足够的回报。
- en: Leading manufacturing adopters—such as the Global Lighthouse factories—already
    automate 50-80% of tasks using AI-powered robotics, achieving ROI within 2-3 years.
    According to ABI Research’s 2023 Collaborative Robot Market Analysis ([https://www.abiresearch.com/press/collaborative-robots-pioneer-automation-revolution-market-to-reach-us7.2-billion-by-2030](https://www.abiresearch.com/press/collaborative-robots-pioneer-automation-revolution-market-to-reach-us7.2-billion-by-2030)),
    collaborative robots are experiencing faster deployment times than traditional
    industrial robots, with implementation periods averaging 30-40% shorter. However,
    these advances remain primarily effective in structured environments. The gap
    between pioneering facilities and the industry average (currently at 45-50% automation)
    illustrates both the potential and the implementation challenges ahead.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 领先的制造业采用者——如全球灯塔工厂——已经使用人工智能驱动的机器人自动化了50-80%的任务，在2-3年内实现了投资回报率。根据ABI Research的2023年协作机器人市场分析([https://www.abiresearch.com/press/collaborative-robots-pioneer-automation-revolution-market-to-reach-us7.2-billion-by-2030](https://www.abiresearch.com/press/collaborative-robots-pioneer-automation-revolution-market-to-reach-us7.2-billion-by-2030))，协作机器人的部署时间比传统工业机器人更快，实施周期平均缩短30-40%。然而，这些进步主要在结构化环境中有效。先驱设施与行业平均水平（目前为45-50%的自动化）之间的差距既说明了未来的潜力，也说明了实施挑战。
- en: In creative industries, we’re seeing progress in specific domains. Software
    development tools like GitHub Copilot are changing how developers work, though
    specific percentages of task automation remain difficult to quantify precisely.
    Similarly, data analysis tools are increasingly handling routine tasks across
    finance and marketing, though the exact extent varies widely by implementation.
    According to McKinsey Global Institute’s 2017 research, only about 5% of occupations
    could be fully automated by demonstrated technologies, while many more have significant
    portions of automatable activities (approximately 30% of activities automatable
    in 60% of occupations). This suggests that most successful implementations are
    augmenting rather than completely replacing human capabilities.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在创意产业中，我们看到了特定领域的进展。例如，GitHub Copilot这样的软件开发工具正在改变开发者的工作方式，尽管具体任务自动化的百分比仍然难以精确量化。同样，数据分析工具正在越来越多地处理金融和营销领域的常规任务，但具体实施的程度差异很大。根据麦肯锡全球研究院2017年的研究，只有大约5%的职业可以通过现有技术实现完全自动化，而许多职业有相当一部分的活动可以自动化（在60%的职业中，大约30%的活动可以自动化）。这表明，大多数成功的实施都是增强而不是完全取代人类能力。
- en: Job evolution and skills implications
  id: totrans-171
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 职业演变和技能影响
- en: As automation adoption progresses across industries, the impact on jobs will
    vary significantly by sector and timeline. Based on current adoption rates and
    projections, we can anticipate how specific roles will evolve.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 随着自动化在各个行业的采用不断推进，对就业的影响将在不同行业和时间段内显著不同。根据当前的采用率和预测，我们可以预测特定角色将如何演变。
- en: Near-term impacts (2025-2035)
  id: totrans-173
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 近期影响（2025-2035）
- en: As automation adoption progresses across industries, the impact on jobs will
    vary significantly by sector and timeline. While precise automation percentages
    are difficult to predict, we can identify clear patterns in how specific roles
    are likely to evolve.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 随着自动化在各个行业的采用不断推进，对就业的影响将在不同行业和时间段内显著不同。虽然精确的自动化百分比难以预测，但我们能识别出特定角色可能如何演变的清晰模式。
- en: According to McKinsey Global Institute research, only about 5% of occupations
    could be fully automated with current technologies, though about 60% of occupations
    have at least 30% of their constituent activities that could be automated. This
    suggests that job transformation—rather than wholesale replacement—will be the
    predominant pattern as AI capabilities advance. The most successful implementations
    to date have augmented human capabilities rather than fully replacing workers.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 根据麦肯锡全球研究院的研究，只有大约5%的职业可以通过当前技术实现完全自动化，尽管大约60%的职业至少有30%的活动可以自动化。这表明，随着人工智能能力的提升，职业转型——而不是全面替代——将成为主要模式。迄今为止最成功的实施都是增强人类能力而不是完全取代工人。
- en: The automation potential varies substantially across sectors. Manufacturing
    and logistics, with their structured environments and repetitive tasks, show higher
    potential for automation than sectors requiring complex human interaction like
    healthcare and education. This differential creates an uneven timeline for transformation
    across the economy.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 自动化的潜力在不同行业之间存在很大差异。制造业和物流业，由于其结构化环境和重复性任务，比需要复杂人际互动的行业（如医疗保健和教育）具有更高的自动化潜力。这种差异在经济的转型时间表上造成了不均衡。
- en: Medium-term impacts (2035-2045)
  id: totrans-177
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 中期影响（2035-2045）
- en: 'As service sectors reach 40-60% automation levels over the next decade, we
    can expect significant transformations in traditional professional roles:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 随着服务业在未来十年内达到40-60%的自动化水平，我们可以预期传统专业角色将发生重大转变：
- en: '**Legal profession**: Routine legal work like document review and draft preparation
    will be largely automated, fundamentally changing job roles for junior lawyers
    and paralegals. Law firms that have already begun this transition report maintaining
    headcount while significantly increasing caseload capacity.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**法律行业**：常规法律工作，如文件审查和起草，将大部分实现自动化，从根本上改变初级律师和律师助理的岗位职责。已经开始这一转变的律师事务所报告称，在显著增加案件处理能力的同时，保持了人员编制。'
- en: '**Education**: Teachers will utilize AI for course preparation, administrative
    tasks, and personalized student support. Students are already using generative
    AI to learn new concepts through personalized teaching interactions, asking follow-up
    questions to clarify understanding at their own pace. The teacher’s role will
    evolve toward mentorship, critical thinking development, and creative learning
    design rather than pure information delivery, focusing on aspects where human
    guidance adds the most value.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**教育**：教师将利用人工智能进行课程准备、行政任务和个性化学生支持。学生已经通过个性化的教学互动使用生成式人工智能来学习新概念，通过自己节奏的后续问题来澄清理解。教师的角色将向导师、批判性思维发展和创造性学习设计转变，而不是纯粹的信息传递，专注于人类指导最能增加价值的方面。'
- en: '**Healthcare**: While clinical decision-making will remain primarily human,
    diagnostic support, documentation, and routine monitoring will be increasingly
    automated, allowing healthcare providers to focus on complex cases and patient
    relationships.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**医疗保健**：虽然临床决策将主要依靠人类，但诊断支持、文档编制和常规监测将越来越自动化，使医疗服务提供者能够专注于复杂病例和患者关系。'
- en: Long-term shifts (2045 and beyond)
  id: totrans-182
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 长期转变（2045年及以后）
- en: 'As technology approaches more empathy-requiring roles, we can expect the following
    to be in demand:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 随着技术接近需要更多同理心的角色，我们可以期待以下需求：
- en: '**Specialized expertise**: Demand will grow significantly for experts in AI
    ethics, regulations, security oversight, and human-AI collaboration design. These
    roles will be essential for ensuring responsible outcomes as systems become more
    autonomous.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**专业专长**：对人工智能伦理、法规、安全监督和人类-人工智能协作设计方面的专家需求将显著增长。随着系统变得更加自主，这些角色对于确保负责任的结果至关重要。'
- en: '**Creative fields**: Musicians and artists will develop new forms of human-AI
    collaboration, potentially boosting creative expression and accessibility while
    raising new questions about attribution and originality.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**创意领域**：音乐家和艺术家将开发新的形式的人类-人工智能协作，可能提高创意表达和可及性，同时引发关于归属和原创性的新问题。'
- en: '**Leadership and strategy**: Roles requiring complex judgment, ethical reasoning,
    and stakeholder management will be among the last to see significant automation,
    potentially increasing their relative value in the economy.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**领导和战略**：需要复杂判断、道德推理和利益相关者管理的角色将是最后看到显著自动化的，这可能会增加它们在经济学中的相对价值。'
- en: Economic distribution and equity considerations
  id: totrans-187
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 经济分配和公平考虑
- en: 'Without deliberate policy interventions, the economic benefits of AI may accrue
    disproportionately to those with the capital, skills, and infrastructure to leverage
    these technologies, potentially widening existing inequalities. This concern is
    particularly relevant for:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 没有明确的政策干预，人工智能的经济效益可能会不成比例地流向那些拥有资本、技能和基础设施以利用这些技术的群体，这可能会加剧现有的不平等。这一担忧尤其适用于以下方面：
- en: '**Geographic disparities**: Regions with strong technological infrastructure
    and education systems may pull further ahead of less-developed areas.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**地理差异**：拥有强大技术基础设施和教育系统的地区可能会进一步领先于欠发达地区。'
- en: '**Skills-based inequality**: Workers with the education and adaptability to
    complement AI systems will likely see wage growth, while others may face displacement
    or wage stagnation.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于技能的不平等**：拥有教育和对AI系统具有补充能力的工人可能会看到工资增长，而其他人可能面临失业或工资停滞。'
- en: '**Capital concentration**: Organizations that successfully implement AI may
    capture disproportionate market share, potentially leading to greater industry
    concentration.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**资本集中**：成功实施人工智能的组织可能会获得不成比例的市场份额，可能导致行业集中度更高。'
- en: 'Addressing these challenges will require coordinated policy approaches:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这些挑战需要协调一致的政策方法：
- en: Investment in education and retraining programs to help workers adapt to changing
    job requirements
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 投资于教育和再培训计划，以帮助工人适应不断变化的就业需求
- en: Regulatory frameworks that promote competition and prevent excessive market
    concentration
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 促进竞争并防止过度市场集中的监管框架
- en: Targeted support for regions and communities facing significant disruption
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 针对面临重大中断的地区和社区提供有针对性的支持
- en: The consistent pattern across all timeframes is that while routine tasks face
    increasing automation (at rates determined by sector-specific factors), human
    expertise to guide AI systems and ensure responsible outcomes remains essential.
    This evolution suggests we should expect transformation rather than wholesale
    replacement, with technical experts remaining key to developing AI tools and realizing
    their business potential.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有时间段中的一致模式是，尽管常规任务面临越来越多的自动化（由特定行业因素决定的速率），但指导人工智能系统并确保负责任的结果的人类专业知识仍然至关重要。这种演变表明，我们应该期待转型而不是全面替代，技术专家在开发人工智能工具和实现其商业潜力方面仍然至关重要。
- en: By automating routine tasks, advanced AI models may ultimately free up human
    time for higher-value work, potentially boosting overall economic output while
    creating transition challenges that require thoughtful policy responses. The development
    of reasoning-capable AI will likely accelerate this transformation in analytical
    roles, while having less immediate impact on roles requiring emotional intelligence
    and interpersonal skills.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 通过自动化常规任务，高级人工智能模型最终可能释放出人类时间，用于更高价值的工作，从而可能提高整体经济产出，同时也会带来需要深思熟虑的政策响应的转型挑战。推理能力的人工智能的发展可能会加速分析角色的这种转变，而对需要情商和人际交往技能的角色影响较小。
- en: Societal implications
  id: totrans-198
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 社会意义
- en: As developers and stakeholders in the AI ecosystem, understanding the broader
    societal implications of these technologies is not just a theoretical exercise
    but a practical necessity. The technical decisions we make today will shape the
    impacts of AI on information environments, intellectual property systems, employment
    patterns, and regulatory landscapes tomorrow. By examining these societal dimensions,
    readers can better anticipate challenges, design more responsible systems, and
    contribute to shaping a future where generative AI creates broad benefits while
    minimizing potential harms. Additionally, being aware of these implications helps
    navigate the complex ethical and regulatory considerations that increasingly affect
    AI development and deployment.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 作为人工智能生态系统的开发者和利益相关者，理解这些技术的更广泛的社会影响不仅是一项理论练习，而是一项实际需要。我们今天做出的技术决策将塑造人工智能对信息环境、知识产权系统、就业模式和监管环境的影响。通过审视这些社会维度，读者可以更好地预测挑战，设计更负责任的系统，并有助于塑造一个未来，其中生成式人工智能创造广泛的好处，同时最大限度地减少潜在的危害。此外，了解这些影响有助于应对日益影响人工智能开发和部署的复杂伦理和监管考量。
- en: Misinformation and cybersecurity
  id: totrans-200
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 错误信息和网络安全
- en: AI presents a dual-edged sword for information integrity and security. While
    it enables better detection of false information, it simultaneously facilitates
    the creation of increasingly sophisticated misinformation at unprecedented scale
    and personalization. Generative AI can create targeted disinformation campaigns
    tailored to specific demographics and individuals, making it harder for people
    to distinguish between authentic and manipulated content. When combined with micro-targeting
    capabilities, this enables precision manipulation of public opinion across social
    platforms.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能在信息完整性和安全性方面是一把双刃剑。虽然它使检测虚假信息更好，但它同时促进了以前所未有的规模和个性化程度创建越来越复杂的虚假信息。生成式人工智能可以创建针对特定人口和个人的针对性虚假信息宣传活动，使人们更难区分真实和被操纵的内容。当与微定位能力结合使用时，这可以在社交平台上实现精确的意见操纵。
- en: Beyond pure misinformation, generative AI accelerates social engineering attacks
    by enabling personalized phishing messages that mimic the writing styles of trusted
    contacts. It can also generate code for malware, making sophisticated attacks
    accessible to less technically skilled threat actors.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 除了纯粹的错误信息之外，生成式人工智能通过使模仿可信联系人写作风格的个性化钓鱼信息成为可能，加速了社会工程攻击。它还可以生成恶意软件的代码，使复杂的攻击对技术能力较低的危险行为者变得可行。
- en: The deepfake phenomenon represents perhaps the most concerning development.
    AI systems can now generate realistic fake videos, images, and audio that appear
    to show real people saying or doing things they never did. These technologies
    threaten to erode trust in media and institutions while providing plausible deniability
    for actual wrongdoing (“it’s just an AI fake”).
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 深伪现象可能是最令人担忧的发展。现在的人工智能系统可以生成逼真的虚假视频、图像和音频，似乎显示真实的人说或做他们从未做过的事情。这些技术威胁着侵蚀对媒体和机构的信任，同时为实际的不法行为提供了合理的否认理由（“这只是人工智能的伪造”）。
- en: The asymmetry between creation and detection poses a significant challenge—it’s
    generally easier and cheaper to generate convincing fake content than to build
    systems to detect it. This creates a persistent advantage for those spreading
    misinformation.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 创作与检测之间的不对称性提出了重大挑战——通常生成令人信服的虚假内容比构建检测系统的成本更低、更容易。这为传播虚假信息的人创造了持续的竞争优势。
- en: The limitations in the scaling approach have important implications for misinformation
    concerns. While more powerful models were expected to develop better factual grounding
    and reasoning capabilities, persistent hallucinations even in the most advanced
    systems suggest that technical solutions alone may be insufficient. This has shifted
    focus toward hybrid approaches that combine AI with human oversight and external
    knowledge verification.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 规模化方法中的局限性对虚假信息问题具有重要意义。虽然人们期待更强大的模型能够发展出更好的事实基础和推理能力，但即使在最先进的系统中也持续出现的幻觉表明，仅靠技术解决方案可能是不够的。这促使人们转向结合AI与人类监督和外部知识验证的混合方法。
- en: 'To address these threats, several complementary approaches are needed:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 为了应对这些威胁，需要几种互补的方法：
- en: '**Technical safeguards**: Content provenance systems, digital watermarking,
    and advanced detection algorithms'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**技术保障**：内容溯源系统、数字水印和高级检测算法'
- en: '**Media literacy**: Widespread education on identifying manipulated content
    and evaluating information sources'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**媒体素养**：广泛教育识别被操纵的内容和评估信息来源'
- en: '**Regulatory frameworks**: Laws addressing deepfakes and automated disinformation'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监管框架**：针对深度伪造和自动化虚假信息的法律'
- en: '**Platform responsibility**: Enhanced content moderation and authentication
    systems'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**平台责任**：增强内容审查和身份验证系统'
- en: '**Collaborative detection networks**: Cross-platform sharing of disinformation
    patterns'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**协作检测网络**：跨平台共享虚假信息模式'
- en: The combination of AI’s generative capabilities with internet-scale distribution
    mechanisms presents unprecedented challenges to information ecosystems that underpin
    democratic societies. Addressing this will require coordinated efforts across
    technical, educational, and policy domains.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 将AI的生成能力与互联网规模的分发机制相结合，对支撑民主社会的信息生态系统提出了前所未有的挑战。解决这个问题需要技术、教育和政策领域的协调努力。
- en: Copyright and attribution challenges
  id: totrans-213
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 版权和归属挑战
- en: Generative AI raises important copyright questions for developers. Recent court
    rulings ([https://www.reuters.com/world/us/us-appeals-court-rejects-copyrights-ai-generated-art-lacking-human-creator-2025-03-18/](https://www.reuters.com/world/us/us-appeals-court-rejects-copyrights-ai-generated-art-lacking-human-creator-2025-03-18/))
    have established that AI-generated content without significant human creative
    input cannot receive copyright protection. The U.S. Court of Appeals definitively
    ruled in March 2025 that “human authorship is required for registration” under
    copyright law, confirming works created solely by AI cannot be copyrighted.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI为开发者提出了重要的版权问题。最近的法院裁决([https://www.reuters.com/world/us/us-appeals-court-rejects-copyrights-ai-generated-art-lacking-human-creator-2025-03-18/](https://www.reuters.com/world/us/us-appeals-court-rejects-copyrights-ai-generated-art-lacking-human-creator-2025-03-18/))确立了AI生成的、缺乏显著人类创造性输入的内容不能获得版权保护。美国上诉法院在2025年3月明确裁定，根据版权法，“注册需要人类作者”，从而确认仅由AI创作的作品不能获得版权。
- en: The ownership question depends on human involvement. AI-only outputs remain
    uncopyrightable, while human-directed AI outputs with creative selection may be
    copyrightable, and AI-assisted human creation retains standard copyright protection.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 所有权问题取决于人类参与。仅由AI生成的输出不受版权保护，而由人类指导且具有创造性选择的AI输出可能受版权保护，AI辅助的人类创作仍享有标准版权保护。
- en: The question of training LLMs on copyrighted works remains contested. While
    some assert this constitutes fair use as a transformative process, recent cases
    have challenged this position. The February 2025 Thomson Reuters ruling ([https://www.lexology.com/library/detail.aspx?g=8528c643-bc11-4e1d-b4ab-b467cd641e4c](https://www.lexology.com/library/detail.aspx?g=8528c643-bc11-4e1d-b4ab-b467cd641e4c))
    rejected the fair use defense for AI trained on copyrighted legal materials.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 在版权作品中训练LLM的问题仍然存在争议。虽然有些人认为这构成了作为转换过程的合理使用，但最近的案例对此提出了挑战。2025年2月，路透社的裁决([https://www.lexology.com/library/detail.aspx?g=8528c643-bc11-4e1d-b4ab-b467cd641e4c](https://www.lexology.com/library/detail.aspx?g=8528c643-bc11-4e1d-b4ab-b467cd641e4c))驳回了在受版权保护的法律材料上训练的AI的合理使用辩护。
- en: These issues significantly impact creative industries where established compensation
    models rely on clear ownership and attribution. The challenges are particularly
    acute in visual arts, music, and literature, where generative AI can produce works
    stylistically similar to specific artists or authors.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 这些问题显著影响了创意产业，在这些产业中，既定的补偿模式依赖于清晰的产权和归属。在视觉艺术、音乐和文学等领域，这些挑战尤为突出，因为生成式AI可以创作出风格上与特定艺术家或作者相似的作品。
- en: Proposed solutions include content provenance systems tracking training sources,
    compensation models distributing royalties to creators whose work informed the
    AI, technical watermarking to distinguish AI-generated content, and legal frameworks
    establishing clear attribution standards.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 建议的解决方案包括内容来源系统跟踪训练来源、补偿模型将版税分配给其作品为AI提供信息的创作者、技术水印以区分AI生成内容，以及建立明确的归属标准的法律框架。
- en: When implementing LangChain applications, developers should track and attribute
    source content, implement filters to prevent verbatim reproduction, document data
    sources used in fine-tuning, and consider retrieval-augmented approaches that
    properly cite sources.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 在实施LangChain应用时，开发者应跟踪和归属源内容，实施过滤器以防止逐字复制，记录用于微调的数据来源，并考虑适当的引用来源的检索增强方法。
- en: International frameworks vary, with the EU’s AI Act of 2024 establishing specific
    data mining exceptions with copyright holder opt-out rights beginning August 2025\.
    This dilemma underscores the urgent need for legal frameworks that can keep pace
    with technological advances and navigate the complex interplay between rights-holders
    and AI-generated content. As legal standards evolve, flexible systems that can
    adapt to changing requirements offer the best protection for both developers and
    users.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 国际框架各不相同，欧盟2024年的AI法案规定了特定的数据挖掘例外情况，并赋予版权持有者从2025年8月开始的选择退出权利。这一困境凸显了迫切需要能够跟上技术进步并处理权利持有者与AI生成内容之间复杂互动的法律框架。随着法律标准的演变，能够适应不断变化要求的灵活系统为开发者和用户提供了最佳的保护。
- en: Regulations and implementation challenges
  id: totrans-221
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 规章制度和实施挑战
- en: 'Realizing the potential of generative AI in a responsible manner involves addressing
    legal, ethical, and regulatory issues. The European Union’s AI Act takes a comprehensive,
    risk-based approach to regulating AI systems. It categorizes AI systems based
    on risk levels:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 以负责任的方式实现生成式AI的潜力，需要解决法律、伦理和监管问题。欧盟的AI法案对AI系统采取了全面、基于风险的监管方法。它根据风险水平对AI系统进行分类：
- en: '**Minimal risk**: Basic AI applications with limited potential for harm'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**低风险**：基本AI应用，潜在危害有限'
- en: '**Limited risk**: Systems requiring transparency obligations'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**有限风险**：需要透明度义务的系统'
- en: '**High risk**: Applications in critical infrastructure, education, employment,
    and essential services'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高风险**：应用于关键基础设施、教育、就业和基本服务'
- en: '**Unacceptable risk**: Systems deemed to pose fundamental threats to rights
    and safety'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**不可接受的风险**：被认为对权利和安全构成根本威胁的系统'
- en: High-risk AI applications like medical software and recruitment tools face strict
    requirements regarding data quality, transparency, human oversight, and risk mitigation.
    The law explicitly bans certain AI uses considered to pose “unacceptable risks”
    to fundamental rights, such as social scoring systems and manipulative practices
    targeting vulnerable groups. The AI Act also imposes transparency obligations
    on developers and includes specific rules for general-purpose AI models with high
    impact potential.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 高风险AI应用，如医疗软件和招聘工具，在数据质量、透明度、人工监督和风险缓解方面面临严格的要求。法律明确禁止某些被认为对基本权利构成“不可接受风险”的AI用途，例如针对弱势群体的社会评分系统和操纵性做法。AI法案还要求开发者遵守透明度义务，并针对具有高影响潜力的通用AI模型制定了具体规则。
- en: There is additionally a growing demand for algorithmic transparency, with tech
    companies and developers facing pressure to reveal more about the inner workings
    of their systems. However, companies often resist disclosure, arguing that revealing
    proprietary information would harm their competitive advantage. This tension between
    transparency and intellectual property protection remains unresolved, with open-source
    models potentially driving greater transparency while proprietary systems maintain
    more opacity.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，对算法透明度的需求也在不断增长，科技公司和发展者面临着揭示更多关于其系统内部运作的压力。然而，公司往往抵制披露，认为透露专有信息会损害其竞争优势。这种透明度与知识产权保护之间的紧张关系尚未解决，开源模型可能推动更大的透明度，而专有系统则保持更多的神秘性。
- en: Current approaches to content moderation, like the German Network Enforcement
    Act (NetzDG), which imposes a 24-hour timeframe for platforms to remove fake news
    and hate speech, have proven impractical.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 当前内容监管的方法，如德国网络执法法（NetzDG），要求平台在 24 小时内删除虚假新闻和仇恨言论，已被证明是不切实际的。
- en: The recognition of scaling limitations has important implications for regulation.
    Early approaches to AI governance focused heavily on regulating access to computational
    resources. However, recent innovations demonstrate that state-of-the-art capabilities
    can be achieved with dramatically less compute. This has prompted a shift in regulatory
    frameworks toward governing AI’s capabilities and applications rather than the
    resources used to train them.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 对扩展限制的认识对监管具有重要意义。早期的人工智能治理方法主要侧重于监管对计算资源的访问。然而，最近的技术创新表明，使用显著更少的计算资源就能实现最先进的性能。这促使监管框架转向治理
    AI 的能力和应用，而不是用于训练它们的资源。
- en: To maximize benefits while mitigating risks, organizations should ensure human
    oversight, diversity, and transparency in AI development. Incorporating ethics
    training into computer science curricula can help reduce biases in AI code by
    teaching developers how to build applications that are ethical by design. Policymakers,
    on the other hand, may need to implement guardrails preventing misuse while providing
    workers with support to transition as activities shift.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在降低风险的同时最大化收益，组织应确保在 AI 开发中有人工监督、多样性和透明度。将道德培训纳入计算机科学课程可以帮助通过教授开发者如何构建设计上就是道德的应用程序来减少
    AI 代码中的偏见。另一方面，政策制定者可能需要实施预防误用的护栏，同时为工人提供支持，以适应活动的转变。
- en: Summary
  id: totrans-232
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: As we conclude this exploration of generative AI with LangChain, we hope you’re
    equipped not just with technical knowledge but with a deeper understanding of
    where these technologies are heading. The journey from basic LLM applications
    to sophisticated agentic systems represents one of the most exciting frontiers
    in computing today.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们使用 LangChain 对生成式 AI 的探索即将结束，我们希望您不仅掌握了技术知识，而且对这些技术未来的发展方向有了更深入的理解。从基本的
    LLM 应用到复杂的代理系统，这一过程代表了当今计算领域最激动人心的前沿之一。
- en: The practical implementations we’ve covered throughout this book—from RAG to
    multi-agent systems, from software development agents to production deployment
    strategies—provide a foundation for building powerful, responsible AI applications
    today. Yet as we’ve seen in this final chapter, the field continues to evolve
    rapidly beyond simple scaling approaches toward more efficient, specialized, and
    distributed paradigms.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 本书涵盖的实用实现——从 RAG 到多代理系统，从软件开发代理到生产部署策略——为构建今天强大的、负责任的 AI 应用提供了基础。然而，正如我们在最后一章所看到的，该领域正迅速发展，超越了简单的扩展方法，朝着更高效、专业化和分布式的范式发展。
- en: We encourage you to apply what you’ve learned, to experiment with the techniques
    we’ve explored, and to contribute to this evolving ecosystem. The repository associated
    with this book ([https://github.com/benman1/generative_ai_with_langchain](https://github.com/benman1/generative_ai_with_langchain))
    will be maintained and updated as LangChain and the broader generative AI landscape
    continue to evolve.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 我们鼓励您应用所学知识，尝试我们探索的技术，并为这个不断发展的生态系统做出贡献。与本书相关的存储库（[https://github.com/benman1/generative_ai_with_langchain](https://github.com/benman1/generative_ai_with_langchain)）将随着
    LangChain 和更广泛的生成式 AI 领域的持续发展而维护和更新。
- en: The future of these technologies will be shaped by the practitioners who build
    with them. By developing thoughtful, effective, and responsible implementations,
    you can help ensure that generative AI fulfills its promise as a transformative
    technology that augments human capabilities and brings about meaningful challenges.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 这些技术的未来将由使用它们的实践者来塑造。通过开发深思熟虑、有效且负责任的实施方案，您可以帮助确保生成式AI实现其作为增强人类能力并带来有意义挑战的变革性技术的承诺。
- en: We’re excited to see what you build!
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 我们很期待看到您所构建的内容！
- en: Subscribe to our weekly newsletter
  id: totrans-238
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 订阅我们的每周通讯
- en: Subscribe to AI_Distilled, the go-to newsletter for AI professionals, researchers,
    and innovators, at [https://packt.link/Q5UyU](E_Chapter_10.xhtml).
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 订阅AI_Distilled，这是AI专业人士、研究人员和创新者的首选通讯，请访问[https://packt.link/Q5UyU](E_Chapter_10.xhtml)。
- en: '![](img/Newsletter_QRcode1.jpg)'
  id: totrans-240
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Newsletter_QRcode1.jpg)'
