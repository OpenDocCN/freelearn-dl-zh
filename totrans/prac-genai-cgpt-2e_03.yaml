- en: '2'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'OpenAI and ChatGPT: Beyond the Market Hype'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter provides an overview of OpenAI and its most notable development
    – ChatGPT – highlighting its history, technology, and capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: We will also explore OpenAI’s achievements in the field of Generative AI, beyond
    ChatGPT – from speech-to-text models to image generation – which will provide
    you with a broader awareness of the state of the art of some of the most advanced
    Generative AI technologies.
  prefs: []
  type: TYPE_NORMAL
- en: 'More specifically, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: What is OpenAI?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An overview of OpenAI model families
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting started with ChatGPT
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of this chapter, you will have a solid foundation on ChatGPT and
    how to use it and its technological capabilities, as well as a wired understanding
    of OpenAI’s model families.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To be able to test the example in this chapter, you will need an OpenAI account.
  prefs: []
  type: TYPE_NORMAL
- en: You may refer to the *Creating an OpenAI account* section if you need any help.
  prefs: []
  type: TYPE_NORMAL
- en: What is OpenAI?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: OpenAI is a research organization founded in 2015 by Elon Musk, Sam Altman,
    Greg Brockman, Ilya Sutskever, Wojciech Zaremba, and John Schulman. As stated
    on the OpenAI web page, its mission is “*to ensure that Artificial General Intelligence
    (AGI) [...] benefits all of humanity*” ([https://openai.com/index/planning-for-agi-and-beyond/](https://openai.com/index/planning-for-agi-and-beyond/).
    In recent years, OpenAI has formed strategic partnerships to further its research
    and deployment efforts. Notably, Microsoft has invested significantly in OpenAI,
    providing resources to support the development of advanced AI technologies. OpenAI
    continues to be a leading entity in AI research, striving to balance innovation
    with ethical considerations to ensure that the development of AI technologies
    aligns with the broader interests of society.
  prefs: []
  type: TYPE_NORMAL
- en: '**Artificial general intelligence** (**AGI**) is a conceptual type of AI capable
    of comprehending, learning, and utilizing knowledge across diverse tasks with
    a proficiency comparable to human intelligence. In contrast to narrow AI systems,
    which are tailored for specific purposes, AGI would demonstrate human-like cognitive
    adaptability, allowing it to perform any intellectual task that a human can accomplish.'
  prefs: []
  type: TYPE_NORMAL
- en: The origins of OpenAI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Since its establishment, OpenAI has focused its research on **deep reinforcement
    learning** (**DRL**), a subset of **machine learning** (**ML**) that combines
    **reinforcement learning** (**RL**) with **deep neural networks** (**DNNs**).
  prefs: []
  type: TYPE_NORMAL
- en: RL is an ML paradigm where an agent learns to make decisions by interacting
    with an environment. The agent receives feedback in the form of rewards or penalties
    based on its actions and aims to maximize cumulative rewards over time.
  prefs: []
  type: TYPE_NORMAL
- en: Deep RL is the integration of RL and deep neural networks, or DNNs (the latter
    is a type of artificial neural network with multiple layers between the input
    and output).
  prefs: []
  type: TYPE_NORMAL
- en: In DRL, DNNs are used to approximate value functions, policies, or models of
    the environment, enabling agents to handle complex, high-dimensional state and
    action spaces. By combining the strengths of RL and DNNs, DRL has been successfully
    applied to tasks such as playing video games, robotic control, and autonomous
    driving, where traditional methods struggle with scalability and feature extraction.
  prefs: []
  type: TYPE_NORMAL
- en: OpenAI’s first contribution in that field traces back to 2016 when the company
    released OpenAI Gym, a toolkit for researchers to develop and test RLalgorithms.
  prefs: []
  type: TYPE_NORMAL
- en: The primary goal of Gym (now called Gymnasium) was to standardize how environments
    are defined in AI research, making published research more easily reproducible
    and providing users with a simple interface for interacting with these environments.
    OpenAI kept researching and contributing in that field, but its most notable achievements
    are related to generative models – **Generative Pre-trained Transformers** (**GPTs**).
  prefs: []
  type: TYPE_NORMAL
- en: A **GPT** is an advanced AI model designed to process and generate human-like
    text. It operates by learning patterns, structures, and context from a vast dataset
    of written language during its training phase. This training enables GPT to predict
    and generate coherent and contextually relevant text, allowing it to understand
    and respond to prompts in a highly natural way.
  prefs: []
  type: TYPE_NORMAL
- en: The “Pre-trained” aspect refers to its initial training on a broad range of
    language data, equipping it with a general understanding of grammar, syntax, semantics,
    and various styles of communication. The “Generative” capability means it can
    create new text that aligns with the given input, rather than simply analyzing
    or classifying data.
  prefs: []
  type: TYPE_NORMAL
- en: The “Transformer” aspect refers to a specific architectural design, featuring
    an advanced mechanism – called “attention” – to efficiently understand relationships
    between words and phrases, enabling it to handle complex language tasks with a
    high degree of accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: The emergence of ChatGPT
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: OpenAI introduced their first GPT model in their paper *Improving Language Understanding
    by Generative Pre-Training* and christened it **GPT-1**,designed to demonstrate
    that a language model could be pre-trained on a large corpus of text and then
    fine-tuned for specific tasks, achieving significant improvements in various**natural
    language processing** (**NLP**) applications.
  prefs: []
  type: TYPE_NORMAL
- en: Fine-tuning is the process of adapting a pre-trained model to a new task. In
    fine-tuning, the parameters of the pre-trained model are altered, either by adjusting
    the existing parameters or by adding new parameters so that they fit the data
    for the new task. This is done by training the model on a smaller labeled dataset
    that is specific to the new task. The key idea behind fine-tuning is to leverage
    the knowledge learned from the pre-trained model and fine-tune it to the new task,
    rather than training a model from scratch.
  prefs: []
  type: TYPE_NORMAL
- en: Soon after, OpenAI researchers released, in 2019, its successor, GPT-2\. This
    version of the GPT was trained on a corpus called **WebText**, which at the time
    contained slightly over 8 million documents with a total of 40 GB of text from
    URLs shared in Reddit submissions with at least 3 upvotes. It had 1.2 billion
    parameters – ten times as many as its predecessor.
  prefs: []
  type: TYPE_NORMAL
- en: In the context of artificial neural networks – including GPTs – **parameter**
    refer to the internal variables that a model learns and adjusts during training.
    These parameters are crucial as they define how input data is processed through
    the network’s layers to produce the desired output.
  prefs: []
  type: TYPE_NORMAL
- en: Then, in 2020, OpenAI first announced and then released GPT-3, which, with its
    175 billion parameters (roughly 21 times the entire population of Earth!), dramatically
    improved benchmark results over GPT-2\. It was with the GPT-3 model – more precisely,
    with its fine-tuned version called GPT-3.5 – that we entered the era of ChatGPT
    in November 2022 (at its first release, ChatGPT was powered by GPT-3.5).
  prefs: []
  type: TYPE_NORMAL
- en: 'From that moment to today, OpenAI has released many new versions of its GPT
    series: GPT-4, GPT-4 Turbo, GPT-4 Vision (the first multimodal model), and GPT-4o,
    where the “o” stands for “Omni,” referring to its multimodal capabilities. At
    the time of writing this book (January 2025), the latest OpenAI chat models are
    part of the o1 family, which feature advanced reasoning capabilities that make
    them suitable for complex tasks or mathematical problems.'
  prefs: []
  type: TYPE_NORMAL
- en: Starting from the next section and in the upcoming chapters, we will mainly
    focus on OpenAI chat models available in ChatGPT with some examples of image generation
    as well.
  prefs: []
  type: TYPE_NORMAL
- en: An overview of OpenAI model families
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Over the last few years, OpenAI has made huge advancements in the field of
    model development, releasing newer model versions at great speed. In this section,
    we will look at the main models divided by domain:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Language models**: OpenAI’s GPTs are advanced language models designed to
    generate text based on given prompts. They are versatile and can be used for various
    NLP tasks, such as text completion, translation, summarization, and coding. This
    is the field where OpenAI demonstrates outstanding performance, thanks to its
    flagship model family: the GPTs. Since November 2022, when ChatGPT was launched,
    OpenAI has released the following models:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GPT-3.5-turbo, the model behind the first version of ChatGPT
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: GPT-4 (the first model to be able to process images as well) and GPT-4 Turbo
    (optimized for chats and assistants)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: GPT-4o and GPT-4o mini (different in the number of parameters trained), where
    the letter “o” stands for “Omni,” meaning that the model can receive diverse data
    as input (text, images, voice)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: o1 and o1 mini (different in the number of parameters), a model series that
    represents a significant advancement, particularly in enhanced reasoning capabilities
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: o3 series, built upon the capabilities of its predecessor (the o1 series), which
    has demonstrated superior performance on benchmarks ([https://beebom.com/openai-unveils-o3-model-cracks-arc-agi-benchmark/](https://beebom.com/openai-unveils-o3-model-cracks-arc-agi-benchmark/))
    and is very promising for future applications
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Image models**: OpenAI’s image models, like DALL-E, are designed to generate
    and manipulate images from textual descriptions. DALL-E models can create highly
    detailed and imaginative visuals, enabling users to produce unique artwork, design
    concepts, and more. For instance, DALL-E 3 (the latest version of the model at
    the time of writing) is capable of creating intricate and creative images based
    on detailed prompts, pushing the boundaries of what AI can do in the field of
    visual arts. These models are particularly useful in creative industries, digital
    marketing, and any field that benefits from high-quality, custom visuals (we are
    going to cover DALL-E in detail in *Chapter 8*).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Text-to-speech and speech-to-text models**: OpenAI’s Whisper is a **speech-to-text**
    (**STT**) system. It was introduced on September 21, 2022\. Trained on 680,000
    hours of multilingual and multitasking data, it excels in transcribing speech
    across various languages and translating non-English speech into English. In addition
    to that, OpenAI also developed **text-to-speech** (**TTS**) models to convert
    written text into spoken language, providing high-quality audio outputs that are
    intelligible, expressive, and natural-sounding, making them suitable for a wide
    range of applications, from customer service bots to educational tools.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**STT** technology converts spoken language into written text. It is commonly
    used in applications such as transcription services, voice assistants, and accessibility
    tools. Examples include converting dictated words into text on a computer or transcribing
    meeting recordings.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**TTS** technology converts written text into spoken words. It is widely used
    for accessibility (e.g., screen readers for visually impaired users), interactive
    voice response systems, and content narration. Examples include digital assistants
    reading messages or books aloud.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: These models are helpful for creating voice assistants, improving accessibility
    for visually impaired users, and generating automated announcements.
  prefs: []
  type: TYPE_NORMAL
- en: '**Text-to-video models**: With the announcement ofSora, OpenAI revealed its
    cutting-edge text-to-video model capable of generating realistic and imaginative
    video scenes from text descriptions. By adapting techniques from DALL-E and incorporating
    transformers, Sora can create high-fidelity videos up to one minute long. It excels
    in maintaining 3D consistency, object permanence, and simulating interactions
    within videos. While still facing challenges like accurately modeling complex
    physics, Sora holds significant potential for creative industries, offering new
    possibilities in video production and storytelling.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Embeddings models**: Embedding models from OpenAI transform text into numerical
    representations called vectors (or embeddings) that capture the semantic meaning
    and are projected in a multi-dimensional vector space.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In *Chapter 1*, we explored the role of embedding in **retrieval augmented generation**
    (**RAG**) scenarios and, more broadly, how this pattern is reshaping knowledge
    mining.
  prefs: []
  type: TYPE_NORMAL
- en: OpenAI’s embedding models, **text-embedding-ada-002** and **text-embedding-3-large**,
    offer state-of-the-art performance in tasks such as text similarity, text search,
    and code search by creating dense vector representations of text. These embeddings
    allow for the efficient and effective comparison of large text datasets, improving
    search accuracy and relevance.
  prefs: []
  type: TYPE_NORMAL
- en: '**Moderation models**: OpenAI’s moderation models are designed to detect and
    filter out inappropriate, harmful, or unsafe content in text. These models are
    integral to maintaining safe and respectful online environments by identifying
    potentially offensive or harmful language. The latest moderation model, released
    in September 2024, is **omni-moderation-latest**, built on top of GPT-4o, and
    it is capable of filtering both text and images. It helps developers and companies
    enforce community guidelines and prevent the spread of harmful content, thereby
    promoting safer digital interactions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Some of these models – specifically, language, image generation, and TTS/STT
    – can be used in ChatGPT, probably the most popular product that OpenAI has released
    as a consumer application. We are going to cover it in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Getting started with ChatGPT
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In November 2022, OpenAI released the web preview of its conversational AI system,
    ChatGPT, to the general public. This generated a huge amount of hype among subject
    matter experts, organizations, and general users – to the point that, after only
    5 days, the service reached 1 million users!
  prefs: []
  type: TYPE_NORMAL
- en: 'Before writing about ChatGPT, I will let it introduce itself, using a snapshot
    taken a few days after the launch:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B31559_02_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.1: ChatGPT introducing itself in November 2022'
  prefs: []
  type: TYPE_NORMAL
- en: It is important to note that ChatGPT is not a **large language model** (**LLM**)
    by itself, but rather an application through which users can interact with the
    underlying models. In fact, ChatGPT is, at its core, an AI-powered chatbot designed
    to simulate human-like conversations. It supports a variety of tasks, including
    writing, coding, and providing information on diverse topics. Powered by cutting-edge
    language models developed by OpenAI, ChatGPT has progressed through iterations
    like GPT-3, GPT-4, GPT-4o, and o1, continually improving its ability to understand
    and generate natural language.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to the integration of the latest and greatest models, ChatGPT also
    extended its capabilities by incorporating external tools (like web search) and
    becoming an actual developer platform to build your own “GPTs,” but we will cover
    all those topics in the upcoming chapters.
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned earlier, the first release of ChatGPT was built on top of an advanced
    language model – a fine-tuned version of GPT-3 specifically optimized for handling
    conversations. This fine-tuned version is called GPT-3.5 Turbo. The optimization
    process involved **reinforcement learning with human feedback** (**RLHF**) ([https://arxiv.org/pdf/2009.01325](https://arxiv.org/pdf/2009.01325)),
    a technique that leverages human input to train the model to exhibit desirable
    conversational behaviors.
  prefs: []
  type: TYPE_NORMAL
- en: We can define RLHF as an ML approach where an algorithm learns to perform a
    task by receiving feedback from a human. The algorithm is trained to make decisions
    that maximize a reward signal provided by the human, and the human provides additional
    feedback to improve the algorithm’s performance. This approach is useful when
    the task is too complex for traditional programming or when the desired outcome
    is difficult to specify in advance.
  prefs: []
  type: TYPE_NORMAL
- en: The relevant differentiator here is that ChatGPT has been trained with humans
    in the loop so that it is aligned with its users. By incorporating RLHF, ChatGPT
    has been designed to better understand and respond to human language in a natural
    and engaging way.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s now see how to start using ChatGPT.
  prefs: []
  type: TYPE_NORMAL
- en: Creating an OpenAI account
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: ChatGPT is available as a free application that anyone can use; however, since
    February 2023, OpenAI announced a series of paid programs, offering subscribers
    several advantages, including access to the latest models, the fastest response
    time, a great set of plugins, and the possibility to create your own Assistant
    in the GPTs playground. You can find an overview of the pricing at [openai.com/chatgpt/pricing/](http://openai.com/chatgpt/pricing/).
    In the upcoming chapters, I’ll be using the Plus version, but the majority of
    the hands-on examples can be replicated with the free version as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'Regardless of the version you choose, to follow along with the upcoming sections
    you will need an OpenAI account. To create an account on OpenAI, follow these
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Open a web browser and go to the OpenAI website at [https://platform.openai.com/signup/](https://platform.openai.com/signup/).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Provide your email address and create a password.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once your account is created, you can start using the free version of ChatGPT.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: ChatGPT Plus tour
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s have a quick tour of the ChatGPT user interface at the time of writing:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B31559_02_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.2: Landing page of ChatGPT at chatgpt.com'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s explore each numbered section in *Figure 2.2*:'
  prefs: []
  type: TYPE_NORMAL
- en: You can decide on the model to use behind ChatGPT. In my case, I have set GPT-4o,
    which is only available with a paid subscription. This is the model we are going
    to use throughout this book.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A set of pre-built prompts is proposed to help you familiarize yourself with
    the application.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The text box is the place where you can input your prompt. Note that there
    is a small voice icon in the right-hand corner: it indicates the possibility of
    interacting with the model with your voice rather than typing.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: On the left-hand sidebar, you can see the list of previous chats (mine are covered)
    you had with ChatGPT. This is an extremely useful tool, since in each chat, through
    the various rounds of interactions you had with the model, you created a context
    ChatGPT is aware of. This means that, if you want to continue a previously started
    conversation, you can open the related chat and start talking with the model without
    describing the whole scenario again.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A nice, recently added feature of ChatGPT Plus is the possibility of having
    Projects, which offer a streamlined way to organize files and chats for personal
    use, making it easier to manage tasks that span multiple conversations. By keeping
    chats, files, and custom instructions all in one place, Projects help maintain
    order and focus.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: ChatGPT Plus offers the possibility of creating GPTs, which are personalized
    assistants you can tailor for specific functions. You can decide to keep your
    GPT private or publish it in the GPTs store, where anyone can use and rate it.
    We are going to cover GPTs in *Chapter 9*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, ChatGPT in its Plus version now offers a set of tools that you can
    leverage while interacting with the model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'At the time of writing this book (January 2025), the provided tools are:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Attach files** to analyze custom file uploaded by the user'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Web Search** to integrate ChatGPT’s model knowledge with up-to-date information
    from the web'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DALL-E to create images based on a query in natural language
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Canvas feature to provide a side-by-side workspace, enabling users to collaboratively
    draft, edit, and receive feedback on writing and coding projects alongside ChatGPT
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Throughout this book, we will leverage ChatGPT Plus to showcase the capabilities
    of the latest models and features; nevertheless, the majority of the examples
    that we will cover can be achieved with the free version of ChatGPT as well (which
    is currently powered by GPT-3.5 Turbo).
  prefs: []
  type: TYPE_NORMAL
- en: The ongoing developments and improvements in ChatGPT’s architecture and training
    methods promise to push the boundaries of language processing even further.
  prefs: []
  type: TYPE_NORMAL
- en: The art of the possible with ChatGPT
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Starting from *Chapter 4*, we will cover many practical examples of how ChatGPT
    can be leveraged for both personal productivity and domain-specific tasks (like
    research, marketing, and coding). However, before landing there, let’s have a
    glimpse of the art of the possible with ChatGPT, starting with an example of the
    o1 model. A distinctive feature of the o1 models is their ability to reveal their
    “thinking” process. When you submit a query, a “thinking” indicator appears, and
    by clicking on it, you can view the steps the model took to arrive at its response.
    This is particularly helpful for gaining insight into how the model handles complex
    queries.
  prefs: []
  type: TYPE_NORMAL
- en: Image understanding and generation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The latest models available in ChatGPT are multimodal, meaning that they are
    capable of receiving diverse data (text and images).
  prefs: []
  type: TYPE_NORMAL
- en: In the context of Generative AI, **multimodality** refers to the ability of
    AI systems to handle, comprehend, and produce content across various forms of
    data, or modalities, including text, images, audio, and video. This functionality
    allows AI to integrate and interpret diverse inputs, resulting in more comprehensive
    and contextually relevant outputs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s consider the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B31559_02_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.3: Image understanding and text generation'
  prefs: []
  type: TYPE_NORMAL
- en: In this case, I asked ChatGPT to describe the provided picture, and the model
    was able to generate a detailed and scientific explanation of the reason for the
    two liquids not mixing with each other. This implies a deep understanding of the
    picture, as well as a general knowledge of physics.
  prefs: []
  type: TYPE_NORMAL
- en: 'Based on this first analysis, we can also go ahead and ask it to evaluate additional
    scenarios:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B31559_02_04.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.4: Going deeper into evaluation'
  prefs: []
  type: TYPE_NORMAL
- en: These are just a few examples of the current capabilities of ChatGPT. Once again,
    it is important to mention that ChatGPT can be consumed with different models,
    and some of them don’t exhibit all the available features (for example, GPT-3.5
    doesn’t take images as input). The decision of which model to use highly depends
    on the kind of task you want ChatGPT to address.
  prefs: []
  type: TYPE_NORMAL
- en: Mathematical thinking
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Originally, LLMs used to struggle when it came to solving mathematical tasks.
    Nevertheless, OpenAI’s o1 model series, introduced in September 2024, has demonstrated
    significant advancements in mathematical reasoning compared to its predecessor,
    GPT-4o. For example, the o1 model (while still in preview) achieved a success
    rate of 83% in the **International Mathematics Olympiad** (**IMO**) qualifying
    exam ([https://openai.com/index/introducing-openai-o1-preview/](https://openai.com/index/introducing-openai-o1-preview/)),
    a substantial improvement over GPT-4o’s 13%.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s consider the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B31559_02_05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.5: Mathematical ability of ChatGPT'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the model was not only able to read and understand the provided
    image but also correctly addressed the problem with smaller reasoning steps.
  prefs: []
  type: TYPE_NORMAL
- en: Analytical skills
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In the previous example, we provided the model with an image, but we can go
    further and attach a more complex, structured file to be quantitatively analyzed.
    For example, we can attach to ChatGPT (powered by GPT-4o) a `.xls` file and ask
    it to perform some financial analysis (in my case, I used a sample file available
    here: [https://learn.microsoft.com/en-us/power-bi/create-reports/sample-financial-download](https://learn.microsoft.com/en-us/power-bi/create-reports/sample-financial-download)).'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B31559_02_06.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.6: Analytical prowess exhibited by ChatGPT'
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to the above answer in text format, ChatGPT can also generate graphs:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B31559_02_07.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.7: Generating graphs using ChatGPT'
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that, to execute this particular task, ChatGPT leveraged a feature called
    Code Interpreter, which allows it to generate Python code to analyze data and
    run it directly against the uploaded file. An important thing to note is that
    you can visualize the generated code by clicking on the **[>_]** icon:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B31559_02_08.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.8: Code Interpreter'
  prefs: []
  type: TYPE_NORMAL
- en: The Code Interpreter feature is extremely powerful and versatile when it comes
    to structured data, and it can also be leveraged to import and train advanced
    ML models to then make predictions on data.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we went through the history of OpenAI, its research fields,
    and the latest developments, up to ChatGPT. We also had a glimpse of the art of
    the possible with ChatGPT, from reasoning over complex images to executing analytical
    tasks.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we begin *Part 2* of this book, where we will see ChatGPT
    in action in various domains and how to unlock its potential. You will learn how
    to get the highest value from ChatGPT by properly designing your prompts, how
    to boost your daily productivity, and how it can be a great project assistant
    for any consumer.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Radford, A. & Narasimhan, K. (2018). *Improving language understanding by generative
    pre-training*. [https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N.,
    Kaiser, L., & Polosukhin, I. (2017). *Attention Is All You Need*. arXiv. [https://doi.org/10.48550/arXiv.1706.03762](https://doi.org/10.48550/arXiv.1706.03762)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: OpenAI. *Fine-Tuning Guide*. OpenAI platform documentation. https:// [platform.openai.com/docs/guides/fine-tuning](http://platform.openai.com/docs/guides/fine-tuning)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Join our communities on Discord and Reddit
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Have questions about the book or want to contribute to discussions on Generative
    AI and LLMs? Join our Discord server at [https://packt.link/I1tSU](Chapter_2.xhtml)
    and our Reddit channel at [https://packt.link/jwAmA](Chapter_2.xhtml) to connect,
    share, and collaborate with like-minded enthusiasts.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Discord.png) ![](img/QR_Code757615820155951000.png)'
  prefs: []
  type: TYPE_IMG
