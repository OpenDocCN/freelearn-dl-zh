- en: '2'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '2'
- en: 'OpenAI and ChatGPT: Beyond the Market Hype'
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: OpenAI和ChatGPT：超越市场炒作
- en: This chapter provides an overview of OpenAI and its most notable development
    – ChatGPT – highlighting its history, technology, and capabilities.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章概述了OpenAI及其最显著的发展——ChatGPT，突出了其历史、技术和能力。
- en: We will also explore OpenAI’s achievements in the field of Generative AI, beyond
    ChatGPT – from speech-to-text models to image generation – which will provide
    you with a broader awareness of the state of the art of some of the most advanced
    Generative AI technologies.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将探讨OpenAI在生成AI领域的成就，超越ChatGPT——从语音到文本模型到图像生成，这将为你提供对一些最先进的生成AI技术现状的更广泛认识。
- en: 'More specifically, we will cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 更具体地说，我们将涵盖以下主题：
- en: What is OpenAI?
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是OpenAI？
- en: An overview of OpenAI model families
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI模型家族概述
- en: Getting started with ChatGPT
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开始使用ChatGPT
- en: By the end of this chapter, you will have a solid foundation on ChatGPT and
    how to use it and its technological capabilities, as well as a wired understanding
    of OpenAI’s model families.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将拥有关于ChatGPT及其使用方法以及其技术能力的基础知识，以及OpenAI模型家族的深入理解。
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: To be able to test the example in this chapter, you will need an OpenAI account.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 要测试本章中的示例，你需要一个OpenAI账户。
- en: You may refer to the *Creating an OpenAI account* section if you need any help.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你需要任何帮助，可以参考“创建OpenAI账户”部分。
- en: What is OpenAI?
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是OpenAI？
- en: OpenAI is a research organization founded in 2015 by Elon Musk, Sam Altman,
    Greg Brockman, Ilya Sutskever, Wojciech Zaremba, and John Schulman. As stated
    on the OpenAI web page, its mission is “*to ensure that Artificial General Intelligence
    (AGI) [...] benefits all of humanity*” ([https://openai.com/index/planning-for-agi-and-beyond/](https://openai.com/index/planning-for-agi-and-beyond/).
    In recent years, OpenAI has formed strategic partnerships to further its research
    and deployment efforts. Notably, Microsoft has invested significantly in OpenAI,
    providing resources to support the development of advanced AI technologies. OpenAI
    continues to be a leading entity in AI research, striving to balance innovation
    with ethical considerations to ensure that the development of AI technologies
    aligns with the broader interests of society.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI是一个成立于2015年的研究组织，由埃隆·马斯克、山姆·奥特曼、格雷格·布罗克曼、伊利亚·苏茨克维、沃伊切赫·扎伦巴和约翰·舒尔曼共同创立。正如OpenAI网页上所述，其使命是“*确保通用人工智能（AGI）[...]造福全人类*”
    ([https://openai.com/index/planning-for-agi-and-beyond/](https://openai.com/index/planning-for-agi-and-beyond/))。近年来，OpenAI已形成战略伙伴关系，以进一步推进其研究和部署工作。值得注意的是，微软对OpenAI进行了大量投资，为支持高级AI技术的发展提供了资源。OpenAI继续在AI研究中处于领先地位，努力在创新与道德考量之间取得平衡，以确保AI技术的发展与社会的更广泛利益相一致。
- en: '**Artificial general intelligence** (**AGI**) is a conceptual type of AI capable
    of comprehending, learning, and utilizing knowledge across diverse tasks with
    a proficiency comparable to human intelligence. In contrast to narrow AI systems,
    which are tailored for specific purposes, AGI would demonstrate human-like cognitive
    adaptability, allowing it to perform any intellectual task that a human can accomplish.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**通用人工智能**（**AGI**）是一种概念性的AI类型，能够以与人类智能相当的专业水平理解和利用跨不同任务的知识。与针对特定目的定制的窄AI系统不同，AGI将展现出类似人类的认知适应性，使其能够完成人类能够完成的任何智力任务。'
- en: The origins of OpenAI
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: OpenAI的起源
- en: Since its establishment, OpenAI has focused its research on **deep reinforcement
    learning** (**DRL**), a subset of **machine learning** (**ML**) that combines
    **reinforcement learning** (**RL**) with **deep neural networks** (**DNNs**).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 自成立以来，OpenAI一直专注于**深度强化学习**（**DRL**），这是**机器学习**（**ML**）的一个子集，它将**强化学习**（**RL**）与**深度神经网络**（**DNNs**）相结合。
- en: RL is an ML paradigm where an agent learns to make decisions by interacting
    with an environment. The agent receives feedback in the form of rewards or penalties
    based on its actions and aims to maximize cumulative rewards over time.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习（RL）是一种机器学习（ML）范式，其中智能体通过与环境的交互来学习做出决策。智能体根据其行为获得反馈，形式为奖励或惩罚，并旨在最大化累积奖励。
- en: Deep RL is the integration of RL and deep neural networks, or DNNs (the latter
    is a type of artificial neural network with multiple layers between the input
    and output).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 深度强化学习（Deep RL）是强化学习（RL）和深度神经网络（DNNs）或深度神经网络（the latter is a type of artificial
    neural network with multiple layers between the input and output) 的结合。
- en: In DRL, DNNs are used to approximate value functions, policies, or models of
    the environment, enabling agents to handle complex, high-dimensional state and
    action spaces. By combining the strengths of RL and DNNs, DRL has been successfully
    applied to tasks such as playing video games, robotic control, and autonomous
    driving, where traditional methods struggle with scalability and feature extraction.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在深度强化学习（DRL）中，深度神经网络（DNNs）被用来近似价值函数、策略或环境模型，使智能体能够处理复杂、高维的状态和动作空间。通过结合强化学习和DNNs的优势，DRL已成功应用于诸如玩电子游戏、机器人控制和自动驾驶等任务，在这些任务中，传统方法在可扩展性和特征提取方面存在困难。
- en: OpenAI’s first contribution in that field traces back to 2016 when the company
    released OpenAI Gym, a toolkit for researchers to develop and test RLalgorithms.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI在该领域的首次贡献可以追溯到2016年，当时公司发布了OpenAI Gym，这是一个用于研究人员开发和测试强化学习算法的工具包。
- en: The primary goal of Gym (now called Gymnasium) was to standardize how environments
    are defined in AI research, making published research more easily reproducible
    and providing users with a simple interface for interacting with these environments.
    OpenAI kept researching and contributing in that field, but its most notable achievements
    are related to generative models – **Generative Pre-trained Transformers** (**GPTs**).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: Gym（现称为Gymnasium）的主要目标是标准化在人工智能研究环境中定义的方法，使得发表的研究更容易重现，并为用户提供一个简单的界面来与这些环境交互。OpenAI在该领域持续研究和贡献，但其最显著的成就与生成模型——**生成预训练Transformer**（**GPTs**）相关。
- en: A **GPT** is an advanced AI model designed to process and generate human-like
    text. It operates by learning patterns, structures, and context from a vast dataset
    of written language during its training phase. This training enables GPT to predict
    and generate coherent and contextually relevant text, allowing it to understand
    and respond to prompts in a highly natural way.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**GPT**是一种高级人工智能模型，旨在处理和生成类似人类的文本。它通过在训练阶段从大量书面语言数据中学习模式、结构和上下文来运行。这种训练使GPT能够预测和生成连贯且上下文相关的文本，允许它以高度自然的方式理解和回应提示。'
- en: The “Pre-trained” aspect refers to its initial training on a broad range of
    language data, equipping it with a general understanding of grammar, syntax, semantics,
    and various styles of communication. The “Generative” capability means it can
    create new text that aligns with the given input, rather than simply analyzing
    or classifying data.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: “预训练”这一方面指的是它在广泛的语言数据上的初始训练，使其具备对语法、句法、语义和不同沟通风格的普遍理解。而“生成”能力意味着它可以创建与给定输入相符合的新文本，而不仅仅是分析或分类数据。
- en: The “Transformer” aspect refers to a specific architectural design, featuring
    an advanced mechanism – called “attention” – to efficiently understand relationships
    between words and phrases, enabling it to handle complex language tasks with a
    high degree of accuracy.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: “Transformer”这一方面指的是一种特定的架构设计，它包含一个高级机制——称为“注意力”——以高效地理解单词和短语之间的关系，使其能够以高精度处理复杂的语言任务。
- en: The emergence of ChatGPT
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ChatGPT的出现
- en: OpenAI introduced their first GPT model in their paper *Improving Language Understanding
    by Generative Pre-Training* and christened it **GPT-1**,designed to demonstrate
    that a language model could be pre-trained on a large corpus of text and then
    fine-tuned for specific tasks, achieving significant improvements in various**natural
    language processing** (**NLP**) applications.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI在其论文《通过生成预训练改进语言理解》中介绍了他们的第一个GPT模型，并将其命名为**GPT-1**，旨在证明语言模型可以在大型文本语料库上预训练，然后针对特定任务进行微调，从而在各种**自然语言处理**（**NLP**）应用中实现显著的改进。
- en: Fine-tuning is the process of adapting a pre-trained model to a new task. In
    fine-tuning, the parameters of the pre-trained model are altered, either by adjusting
    the existing parameters or by adding new parameters so that they fit the data
    for the new task. This is done by training the model on a smaller labeled dataset
    that is specific to the new task. The key idea behind fine-tuning is to leverage
    the knowledge learned from the pre-trained model and fine-tune it to the new task,
    rather than training a model from scratch.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 微调是将预训练模型适应新任务的过程。在微调过程中，预训练模型的参数被调整，要么通过调整现有参数，要么通过添加新参数，以便它们适合新任务的数据。这是通过在针对新任务的小型标记数据集上训练模型来完成的。微调背后的关键思想是利用从预训练模型中学到的知识，并将其微调到新任务，而不是从头开始训练模型。
- en: Soon after, OpenAI researchers released, in 2019, its successor, GPT-2\. This
    version of the GPT was trained on a corpus called **WebText**, which at the time
    contained slightly over 8 million documents with a total of 40 GB of text from
    URLs shared in Reddit submissions with at least 3 upvotes. It had 1.2 billion
    parameters – ten times as many as its predecessor.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 之后不久，OpenAI 研究人员在 2019 年发布了其继任者 GPT-2。这个版本的 GPT 在一个称为 **WebText** 的语料库上进行了训练，当时包含略超过
    800 万份文档，总共有 40 GB 的文本，这些文本来自 Reddit 提交中至少获得 3 个赞同的 URL。它有 12 亿个参数——是其前者的十倍。
- en: In the context of artificial neural networks – including GPTs – **parameter**
    refer to the internal variables that a model learns and adjusts during training.
    These parameters are crucial as they define how input data is processed through
    the network’s layers to produce the desired output.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在人工神经网络（包括 GPTs）的背景下，**参数**指的是模型在训练过程中学习和调整的内部变量。这些参数至关重要，因为它们定义了输入数据如何通过网络层进行处理以产生所需的输出。
- en: Then, in 2020, OpenAI first announced and then released GPT-3, which, with its
    175 billion parameters (roughly 21 times the entire population of Earth!), dramatically
    improved benchmark results over GPT-2\. It was with the GPT-3 model – more precisely,
    with its fine-tuned version called GPT-3.5 – that we entered the era of ChatGPT
    in November 2022 (at its first release, ChatGPT was powered by GPT-3.5).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在 2020 年，OpenAI 首先宣布然后发布了 GPT-3，该模型拥有 1750 亿个参数（大约是地球人口的 21 倍），显著提高了 GPT-2
    的基准测试结果。正是在 GPT-3 模型——更确切地说，是其经过微调的版本 GPT-3.5——的帮助下，我们在 2022 年 11 月进入了 ChatGPT
    时代（在首次发布时，ChatGPT 由 GPT-3.5 驱动）。
- en: 'From that moment to today, OpenAI has released many new versions of its GPT
    series: GPT-4, GPT-4 Turbo, GPT-4 Vision (the first multimodal model), and GPT-4o,
    where the “o” stands for “Omni,” referring to its multimodal capabilities. At
    the time of writing this book (January 2025), the latest OpenAI chat models are
    part of the o1 family, which feature advanced reasoning capabilities that make
    them suitable for complex tasks or mathematical problems.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 从那时起直到今天，OpenAI 已经发布了其 GPT 系列的许多新版本：GPT-4、GPT-4 Turbo、GPT-4 Vision（第一个多模态模型）和
    GPT-4o，其中“o”代表“Omni”，指的是其多模态能力。在撰写本书时（2025 年 1 月），最新的 OpenAI 聊天模型是 o1 家族的一部分，它们具有先进的推理能力，使其适合复杂任务或数学问题。
- en: Starting from the next section and in the upcoming chapters, we will mainly
    focus on OpenAI chat models available in ChatGPT with some examples of image generation
    as well.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 从下一节开始，在接下来的章节中，我们将主要关注 ChatGPT 中可用的 OpenAI 聊天模型，以及一些图像生成的示例。
- en: An overview of OpenAI model families
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: OpenAI 模型系列的概述
- en: 'Over the last few years, OpenAI has made huge advancements in the field of
    model development, releasing newer model versions at great speed. In this section,
    we will look at the main models divided by domain:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去几年中，OpenAI 在模型开发领域取得了巨大进步，以极高的速度发布了新的模型版本。在本节中，我们将按领域查看主要模型：
- en: '**Language models**: OpenAI’s GPTs are advanced language models designed to
    generate text based on given prompts. They are versatile and can be used for various
    NLP tasks, such as text completion, translation, summarization, and coding. This
    is the field where OpenAI demonstrates outstanding performance, thanks to its
    flagship model family: the GPTs. Since November 2022, when ChatGPT was launched,
    OpenAI has released the following models:'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**语言模型**：OpenAI 的 GPTs 是高级语言模型，旨在根据给定的提示生成文本。它们功能多样，可用于各种 NLP 任务，如文本补全、翻译、摘要和编码。这是
    OpenAI 展示卓越性能的领域，得益于其旗舰模型系列：GPTs。自 2022 年 11 月 ChatGPT 发布以来，OpenAI 已发布了以下模型：'
- en: GPT-3.5-turbo, the model behind the first version of ChatGPT
  id: totrans-36
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPT-3.5-turbo，ChatGPT 第一版背后的模型
- en: GPT-4 (the first model to be able to process images as well) and GPT-4 Turbo
    (optimized for chats and assistants)
  id: totrans-37
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPT-4（第一个能够处理图像的模型）和 GPT-4 Turbo（针对聊天和助手进行了优化）
- en: GPT-4o and GPT-4o mini (different in the number of parameters trained), where
    the letter “o” stands for “Omni,” meaning that the model can receive diverse data
    as input (text, images, voice)
  id: totrans-38
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPT-4o 和 GPT-4o mini（在训练的参数数量上有所不同），其中字母“o”代表“Omni”，意味着模型可以接收各种数据作为输入（文本、图像、声音）
- en: o1 and o1 mini (different in the number of parameters), a model series that
    represents a significant advancement, particularly in enhanced reasoning capabilities
  id: totrans-39
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: o1 和 o1 mini（在参数数量上有所不同），这是一个代表重大进步的模型系列，特别是在增强推理能力方面
- en: o3 series, built upon the capabilities of its predecessor (the o1 series), which
    has demonstrated superior performance on benchmarks ([https://beebom.com/openai-unveils-o3-model-cracks-arc-agi-benchmark/](https://beebom.com/openai-unveils-o3-model-cracks-arc-agi-benchmark/))
    and is very promising for future applications
  id: totrans-40
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于 o1 系列的前一代能力（o3 系列），该系列在基准测试中表现出色（[https://beebom.com/openai-unveils-o3-model-cracks-arc-agi-benchmark/](https://beebom.com/openai-unveils-o3-model-cracks-arc-agi-benchmark/)），并且对未来应用前景非常乐观。
- en: '**Image models**: OpenAI’s image models, like DALL-E, are designed to generate
    and manipulate images from textual descriptions. DALL-E models can create highly
    detailed and imaginative visuals, enabling users to produce unique artwork, design
    concepts, and more. For instance, DALL-E 3 (the latest version of the model at
    the time of writing) is capable of creating intricate and creative images based
    on detailed prompts, pushing the boundaries of what AI can do in the field of
    visual arts. These models are particularly useful in creative industries, digital
    marketing, and any field that benefits from high-quality, custom visuals (we are
    going to cover DALL-E in detail in *Chapter 8*).'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图像模型**：OpenAI 的图像模型，如 DALL-E，旨在根据文字描述生成和操作图像。DALL-E 模型可以创建高度详细和富有想象力的视觉图像，使用户能够创作独特的艺术作品、设计概念等。例如，DALL-E
    3（撰写本文时的最新版本）能够根据详细的提示创建复杂和富有创意的图像，推动人工智能在视觉艺术领域的边界。这些模型在创意产业、数字营销以及任何从高质量、定制视觉中受益的领域特别有用（我们将在
    *第 8 章* 中详细介绍 DALL-E）。'
- en: '**Text-to-speech and speech-to-text models**: OpenAI’s Whisper is a **speech-to-text**
    (**STT**) system. It was introduced on September 21, 2022\. Trained on 680,000
    hours of multilingual and multitasking data, it excels in transcribing speech
    across various languages and translating non-English speech into English. In addition
    to that, OpenAI also developed **text-to-speech** (**TTS**) models to convert
    written text into spoken language, providing high-quality audio outputs that are
    intelligible, expressive, and natural-sounding, making them suitable for a wide
    range of applications, from customer service bots to educational tools.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文本到语音和语音到文本模型**：OpenAI 的 Whisper 是一个 **语音到文本**（**STT**）系统。它于 2022 年 9 月 21
    日推出。该系统在 68 万小时的多种语言和多任务数据上进行了训练，擅长跨语言转录语音，并能将非英语语音翻译成英语。除此之外，OpenAI 还开发了 **文本到语音**（**TTS**）模型，将书面文字转换为口语，提供清晰、富有表现力和自然的声音输出，使其适用于广泛的用途，从客户服务机器人到教育工具。'
- en: '**STT** technology converts spoken language into written text. It is commonly
    used in applications such as transcription services, voice assistants, and accessibility
    tools. Examples include converting dictated words into text on a computer or transcribing
    meeting recordings.'
  id: totrans-43
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**STT** 技术将口语转换为书面文字。它常用于转录服务、语音助手和辅助工具等应用中。例如，将口述的词语转换为电脑上的文字或转录会议录音。'
- en: '**TTS** technology converts written text into spoken words. It is widely used
    for accessibility (e.g., screen readers for visually impaired users), interactive
    voice response systems, and content narration. Examples include digital assistants
    reading messages or books aloud.'
  id: totrans-44
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**TTS** 技术将书面文字转换为口语。它广泛应用于辅助工具（例如，为视障用户设计的屏幕阅读器）、交互式语音应答系统和内容朗读。例如，数字助手大声阅读消息或书籍。'
- en: These models are helpful for creating voice assistants, improving accessibility
    for visually impaired users, and generating automated announcements.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这些模型有助于创建语音助手、提高视障用户的可访问性以及生成自动公告。
- en: '**Text-to-video models**: With the announcement ofSora, OpenAI revealed its
    cutting-edge text-to-video model capable of generating realistic and imaginative
    video scenes from text descriptions. By adapting techniques from DALL-E and incorporating
    transformers, Sora can create high-fidelity videos up to one minute long. It excels
    in maintaining 3D consistency, object permanence, and simulating interactions
    within videos. While still facing challenges like accurately modeling complex
    physics, Sora holds significant potential for creative industries, offering new
    possibilities in video production and storytelling.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文本到视频模型**：随着 Sora 的发布，OpenAI 展示了其尖端文本到视频模型，能够根据文字描述生成逼真和富有想象力的视频场景。通过采用 DALL-E
    的技术和集成变压器，Sora 可以创建高达一分钟的逼真视频。它在保持 3D 一致性、物体持久性和模拟视频中的交互方面表现出色。尽管仍面临准确模拟复杂物理学的挑战，但
    Sora 在创意产业中具有重大潜力，为视频制作和叙事提供了新的可能性。'
- en: '**Embeddings models**: Embedding models from OpenAI transform text into numerical
    representations called vectors (or embeddings) that capture the semantic meaning
    and are projected in a multi-dimensional vector space.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**嵌入模型**：OpenAI的嵌入模型将文本转换为称为向量（或嵌入）的数值表示，这些向量捕捉语义意义并在多维向量空间中进行投影。'
- en: In *Chapter 1*, we explored the role of embedding in **retrieval augmented generation**
    (**RAG**) scenarios and, more broadly, how this pattern is reshaping knowledge
    mining.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在**第一章**中，我们探讨了嵌入在**检索增强生成**（**RAG**）场景中的作用，以及更广泛地，这种模式是如何重塑知识挖掘的。
- en: OpenAI’s embedding models, **text-embedding-ada-002** and **text-embedding-3-large**,
    offer state-of-the-art performance in tasks such as text similarity, text search,
    and code search by creating dense vector representations of text. These embeddings
    allow for the efficient and effective comparison of large text datasets, improving
    search accuracy and relevance.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI的嵌入模型**text-embedding-ada-002**和**text-embedding-3-large**通过创建文本的密集向量表示，在文本相似度、文本搜索和代码搜索等任务中提供最先进的性能。这些嵌入允许对大型文本数据集进行高效和有效的比较，提高搜索的准确性和相关性。
- en: '**Moderation models**: OpenAI’s moderation models are designed to detect and
    filter out inappropriate, harmful, or unsafe content in text. These models are
    integral to maintaining safe and respectful online environments by identifying
    potentially offensive or harmful language. The latest moderation model, released
    in September 2024, is **omni-moderation-latest**, built on top of GPT-4o, and
    it is capable of filtering both text and images. It helps developers and companies
    enforce community guidelines and prevent the spread of harmful content, thereby
    promoting safer digital interactions.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**审查模型**：OpenAI的审查模型旨在检测和过滤掉文本中的不适当、有害或不安全的内容。这些模型通过识别可能冒犯性或有害的语言，对于维护安全和尊重的在线环境至关重要。最新发布的审查模型，于2024年9月发布，名为**omni-moderation-latest**，建立在GPT-4o之上，并且能够过滤文本和图像。它帮助开发者和公司执行社区指南，防止有害内容的传播，从而促进更安全的数字互动。'
- en: Some of these models – specifically, language, image generation, and TTS/STT
    – can be used in ChatGPT, probably the most popular product that OpenAI has released
    as a consumer application. We are going to cover it in the next section.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一些模型——特别是语言、图像生成和TTS/STT——可以在ChatGPT中使用，这可能是OpenAI作为消费应用发布的最受欢迎的产品。我们将在下一节中对其进行介绍。
- en: Getting started with ChatGPT
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开始使用ChatGPT
- en: In November 2022, OpenAI released the web preview of its conversational AI system,
    ChatGPT, to the general public. This generated a huge amount of hype among subject
    matter experts, organizations, and general users – to the point that, after only
    5 days, the service reached 1 million users!
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 2022年11月，OpenAI向公众发布了其对话式人工智能系统ChatGPT的网页预览。这在主题专家、组织和普通用户中引发了巨大的炒作——以至于在仅仅5天后，该服务就达到了100万用户！
- en: 'Before writing about ChatGPT, I will let it introduce itself, using a snapshot
    taken a few days after the launch:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写关于ChatGPT的文章之前，我将先让它自我介绍，使用的是发布后几天拍摄的快照：
- en: '![](img/B31559_02_01.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B31559_02_01.png)'
- en: 'Figure 2.1: ChatGPT introducing itself in November 2022'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.1：ChatGPT于2022年11月自我介绍
- en: It is important to note that ChatGPT is not a **large language model** (**LLM**)
    by itself, but rather an application through which users can interact with the
    underlying models. In fact, ChatGPT is, at its core, an AI-powered chatbot designed
    to simulate human-like conversations. It supports a variety of tasks, including
    writing, coding, and providing information on diverse topics. Powered by cutting-edge
    language models developed by OpenAI, ChatGPT has progressed through iterations
    like GPT-3, GPT-4, GPT-4o, and o1, continually improving its ability to understand
    and generate natural language.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，ChatGPT本身不是一个**大型语言模型**（**LLM**），而是一个用户可以通过它来与底层模型交互的应用程序。实际上，ChatGPT的核心是一个由人工智能驱动的聊天机器人，旨在模拟类似人类的对话。它支持各种任务，包括写作、编码以及提供关于各种主题的信息。由OpenAI开发的尖端语言模型提供支持，ChatGPT通过GPT-3、GPT-4、GPT-4o和o1等迭代不断改进其理解和生成自然语言的能力。
- en: In addition to the integration of the latest and greatest models, ChatGPT also
    extended its capabilities by incorporating external tools (like web search) and
    becoming an actual developer platform to build your own “GPTs,” but we will cover
    all those topics in the upcoming chapters.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 除了集成最新的顶级模型外，ChatGPT还通过整合外部工具（如网络搜索）并成为实际的开发者平台来构建自己的“GPTs”，但所有这些主题我们将在接下来的章节中详细讨论。
- en: As mentioned earlier, the first release of ChatGPT was built on top of an advanced
    language model – a fine-tuned version of GPT-3 specifically optimized for handling
    conversations. This fine-tuned version is called GPT-3.5 Turbo. The optimization
    process involved **reinforcement learning with human feedback** (**RLHF**) ([https://arxiv.org/pdf/2009.01325](https://arxiv.org/pdf/2009.01325)),
    a technique that leverages human input to train the model to exhibit desirable
    conversational behaviors.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，ChatGPT的第一个版本是在一个高级语言模型之上构建的——一个针对处理对话进行了优化的GPT-3的精调版本。这个精调版本被称为GPT-3.5
    Turbo。优化过程涉及**强化学习与人类反馈**（**RLHF**）([https://arxiv.org/pdf/2009.01325](https://arxiv.org/pdf/2009.01325))，这是一种利用人类输入来训练模型以展示期望的对话行为的技巧。
- en: We can define RLHF as an ML approach where an algorithm learns to perform a
    task by receiving feedback from a human. The algorithm is trained to make decisions
    that maximize a reward signal provided by the human, and the human provides additional
    feedback to improve the algorithm’s performance. This approach is useful when
    the task is too complex for traditional programming or when the desired outcome
    is difficult to specify in advance.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将RLHF定义为一种机器学习方法，其中算法通过接收来自人类的反馈来学习执行任务。该算法被训练做出决策，以最大化人类提供的奖励信号，并且人类提供额外的反馈以改进算法的性能。当任务过于复杂而无法使用传统编程或当期望的结果难以提前指定时，这种方法很有用。
- en: The relevant differentiator here is that ChatGPT has been trained with humans
    in the loop so that it is aligned with its users. By incorporating RLHF, ChatGPT
    has been designed to better understand and respond to human language in a natural
    and engaging way.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的相关区别在于，ChatGPT是在人类参与下进行训练的，以便与用户保持一致。通过结合RLHF，ChatGPT被设计成能够以自然和吸引人的方式更好地理解和回应人类语言。
- en: Let’s now see how to start using ChatGPT.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看看如何开始使用ChatGPT。
- en: Creating an OpenAI account
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建OpenAI账户
- en: ChatGPT is available as a free application that anyone can use; however, since
    February 2023, OpenAI announced a series of paid programs, offering subscribers
    several advantages, including access to the latest models, the fastest response
    time, a great set of plugins, and the possibility to create your own Assistant
    in the GPTs playground. You can find an overview of the pricing at [openai.com/chatgpt/pricing/](http://openai.com/chatgpt/pricing/).
    In the upcoming chapters, I’ll be using the Plus version, but the majority of
    the hands-on examples can be replicated with the free version as well.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT是一个任何人都可以使用的免费应用程序；然而，自2023年2月起，OpenAI宣布了一系列付费计划，为订阅者提供了包括访问最新模型、最快响应时间、一套优秀的插件以及可能在GPTs游乐场中创建自己的助手等优势。您可以在[openai.com/chatgpt/pricing/](http://openai.com/chatgpt/pricing/)找到价格概览。在接下来的章节中，我将使用Plus版本，但大多数动手示例也可以使用免费版本复制。
- en: 'Regardless of the version you choose, to follow along with the upcoming sections
    you will need an OpenAI account. To create an account on OpenAI, follow these
    steps:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 无论您选择哪个版本，为了跟上接下来的部分，您需要一个OpenAI账户。要在OpenAI上创建账户，请按照以下步骤操作：
- en: Open a web browser and go to the OpenAI website at [https://platform.openai.com/signup/](https://platform.openai.com/signup/).
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开网页浏览器并访问OpenAI网站[https://platform.openai.com/signup/](https://platform.openai.com/signup/)。
- en: Provide your email address and create a password.
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提供您的电子邮件地址并创建一个密码。
- en: Once your account is created, you can start using the free version of ChatGPT.
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦您的账户创建完成，您就可以开始使用ChatGPT的免费版本。
- en: ChatGPT Plus tour
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ChatGPT Plus导览
- en: 'Let’s have a quick tour of the ChatGPT user interface at the time of writing:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们快速浏览一下撰写本文时的ChatGPT用户界面：
- en: '![](img/B31559_02_02.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B31559_02_02.png)'
- en: 'Figure 2.2: Landing page of ChatGPT at chatgpt.com'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.2：chatgpt.com的ChatGPT着陆页
- en: 'Let’s explore each numbered section in *Figure 2.2*:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探索*图2.2*中的每个编号部分：
- en: You can decide on the model to use behind ChatGPT. In my case, I have set GPT-4o,
    which is only available with a paid subscription. This is the model we are going
    to use throughout this book.
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您可以选择ChatGPT背后使用的模型。在我的情况下，我设置了GPT-4o，这个模型只有付费订阅才能获得。这是我们将在整本书中使用的模型。
- en: A set of pre-built prompts is proposed to help you familiarize yourself with
    the application.
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提供了一系列预构建的提示，以帮助您熟悉该应用程序。
- en: 'The text box is the place where you can input your prompt. Note that there
    is a small voice icon in the right-hand corner: it indicates the possibility of
    interacting with the model with your voice rather than typing.'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 文本框是您可以输入提示的地方。请注意，在右上角有一个小声音图标：它表示您可以使用语音而不是键入与模型进行交互的可能性。
- en: On the left-hand sidebar, you can see the list of previous chats (mine are covered)
    you had with ChatGPT. This is an extremely useful tool, since in each chat, through
    the various rounds of interactions you had with the model, you created a context
    ChatGPT is aware of. This means that, if you want to continue a previously started
    conversation, you can open the related chat and start talking with the model without
    describing the whole scenario again.
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在左侧侧边栏中，您可以查看与 ChatGPT 之前的聊天记录（我的已被覆盖）。这是一个极其有用的工具，因为在每次聊天中，通过您与模型的各种互动回合，您创建了一个
    ChatGPT 所了解的上下文。这意味着，如果您想继续之前开始的对话，您可以打开相关的聊天并开始与模型交谈，而无需再次描述整个场景。
- en: A nice, recently added feature of ChatGPT Plus is the possibility of having
    Projects, which offer a streamlined way to organize files and chats for personal
    use, making it easier to manage tasks that span multiple conversations. By keeping
    chats, files, and custom instructions all in one place, Projects help maintain
    order and focus.
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ChatGPT Plus 最近增加的一个不错的新功能是拥有项目，这提供了一种简化的方式来组织个人使用的文件和聊天，使其更容易管理跨越多个对话的任务。通过将聊天、文件和自定义指令都放在一个地方，项目有助于保持秩序和专注。
- en: ChatGPT Plus offers the possibility of creating GPTs, which are personalized
    assistants you can tailor for specific functions. You can decide to keep your
    GPT private or publish it in the GPTs store, where anyone can use and rate it.
    We are going to cover GPTs in *Chapter 9*.
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ChatGPT Plus 提供了创建 GPT 的可能性，这些是您可以针对特定功能定制的个性化助手。您可以选择保持您的 GPT 私密或将其发布在 GPTs
    商店中，任何人都可以使用并对其进行评分。我们将在 *第 9 章* 中介绍 GPTs。
- en: Finally, ChatGPT in its Plus version now offers a set of tools that you can
    leverage while interacting with the model.
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，ChatGPT 的 Plus 版本现在提供了一套工具，您可以在与模型交互时使用。
- en: 'At the time of writing this book (January 2025), the provided tools are:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本书时（2025 年 1 月），提供的工具包括：
- en: '**Attach files** to analyze custom file uploaded by the user'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**附加文件** 以分析用户上传的自定义文件'
- en: '**Web Search** to integrate ChatGPT’s model knowledge with up-to-date information
    from the web'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**网络搜索** 将 ChatGPT 的模型知识与来自网络的最新信息相结合'
- en: DALL-E to create images based on a query in natural language
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DALL-E 根据自然语言查询创建图像
- en: The Canvas feature to provide a side-by-side workspace, enabling users to collaboratively
    draft, edit, and receive feedback on writing and coding projects alongside ChatGPT
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 画布功能提供并排的工作空间，使用户能够与 ChatGPT 一起协作起草、编辑和接收写作和编码项目的反馈。
- en: Throughout this book, we will leverage ChatGPT Plus to showcase the capabilities
    of the latest models and features; nevertheless, the majority of the examples
    that we will cover can be achieved with the free version of ChatGPT as well (which
    is currently powered by GPT-3.5 Turbo).
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在整本书中，我们将利用 ChatGPT Plus 来展示最新模型和功能的能力；尽管如此，我们将涵盖的大多数示例也可以使用 ChatGPT 的免费版本实现（目前由
    GPT-3.5 Turbo 驱动）。
- en: The ongoing developments and improvements in ChatGPT’s architecture and training
    methods promise to push the boundaries of language processing even further.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT 的架构和训练方法的持续发展和改进有望进一步推动语言处理领域的边界。
- en: The art of the possible with ChatGPT
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ChatGPT 的可能性艺术
- en: Starting from *Chapter 4*, we will cover many practical examples of how ChatGPT
    can be leveraged for both personal productivity and domain-specific tasks (like
    research, marketing, and coding). However, before landing there, let’s have a
    glimpse of the art of the possible with ChatGPT, starting with an example of the
    o1 model. A distinctive feature of the o1 models is their ability to reveal their
    “thinking” process. When you submit a query, a “thinking” indicator appears, and
    by clicking on it, you can view the steps the model took to arrive at its response.
    This is particularly helpful for gaining insight into how the model handles complex
    queries.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 从 *第 4 章* 开始，我们将涵盖许多 ChatGPT 如何用于个人生产力和特定领域任务（如研究、营销和编码）的实际示例。然而，在到达那里之前，让我们先看看
    ChatGPT 的可能性艺术，从一个 o1 模型的例子开始。o1 模型的独特特征是它们能够揭示它们的“思考”过程。当您提交查询时，会出现一个“思考”指示器，通过点击它，您可以查看模型到达其响应所采取的步骤。这对于深入了解模型如何处理复杂查询非常有帮助。
- en: Image understanding and generation
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 图像理解和生成
- en: The latest models available in ChatGPT are multimodal, meaning that they are
    capable of receiving diverse data (text and images).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT中可用的最新模型是多模态的，这意味着它们能够接收多样化的数据（文本和图像）。
- en: In the context of Generative AI, **multimodality** refers to the ability of
    AI systems to handle, comprehend, and produce content across various forms of
    data, or modalities, including text, images, audio, and video. This functionality
    allows AI to integrate and interpret diverse inputs, resulting in more comprehensive
    and contextually relevant outputs.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在生成式AI的背景下，**多模态**指的是AI系统处理、理解和生成各种形式数据或模态的能力，包括文本、图像、音频和视频。这种功能使得AI能够整合和解释多样化的输入，从而产生更全面和上下文相关的输出。
- en: 'Let’s consider the following example:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑以下例子：
- en: '![](img/B31559_02_03.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B31559_02_03.png)'
- en: 'Figure 2.3: Image understanding and text generation'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.3：图像理解和文本生成
- en: In this case, I asked ChatGPT to describe the provided picture, and the model
    was able to generate a detailed and scientific explanation of the reason for the
    two liquids not mixing with each other. This implies a deep understanding of the
    picture, as well as a general knowledge of physics.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我要求ChatGPT描述提供的图片，该模型能够生成一个详细且科学的解释，说明了两种液体不混合在一起的原因。这表明了模型对图片的深入理解，以及物理学的一般知识。
- en: 'Based on this first analysis, we can also go ahead and ask it to evaluate additional
    scenarios:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 基于这次初步分析，我们也可以让它评估额外的场景：
- en: '![](img/B31559_02_04.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B31559_02_04.png)'
- en: 'Figure 2.4: Going deeper into evaluation'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.4：深入评估
- en: These are just a few examples of the current capabilities of ChatGPT. Once again,
    it is important to mention that ChatGPT can be consumed with different models,
    and some of them don’t exhibit all the available features (for example, GPT-3.5
    doesn’t take images as input). The decision of which model to use highly depends
    on the kind of task you want ChatGPT to address.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这些只是ChatGPT当前能力的一小部分例子。再次强调，ChatGPT可以与不同的模型一起使用，其中一些模型并不展示所有可用功能（例如，GPT-3.5不接收图像作为输入）。选择使用哪种模型高度取决于您希望ChatGPT解决的问题类型。
- en: Mathematical thinking
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数学思维
- en: Originally, LLMs used to struggle when it came to solving mathematical tasks.
    Nevertheless, OpenAI’s o1 model series, introduced in September 2024, has demonstrated
    significant advancements in mathematical reasoning compared to its predecessor,
    GPT-4o. For example, the o1 model (while still in preview) achieved a success
    rate of 83% in the **International Mathematics Olympiad** (**IMO**) qualifying
    exam ([https://openai.com/index/introducing-openai-o1-preview/](https://openai.com/index/introducing-openai-o1-preview/)),
    a substantial improvement over GPT-4o’s 13%.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 最初，LLMs在解决数学任务时遇到了困难。然而，OpenAI在2024年9月推出的o1模型系列，与它的前辈GPT-4o相比，在数学推理方面取得了显著的进步。例如，o1模型（尽管仍在预览中）在国际数学奥林匹克竞赛（IMO）的资格考试中取得了83%的成功率（[https://openai.com/index/introducing-openai-o1-preview/](https://openai.com/index/introducing-openai-o1-preview/)），这比GPT-4o的13%有大幅提升。
- en: 'Let’s consider the following example:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑以下例子：
- en: '![](img/B31559_02_05.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B31559_02_05.png)'
- en: 'Figure 2.5: Mathematical ability of ChatGPT'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.5：ChatGPT的数学能力
- en: As you can see, the model was not only able to read and understand the provided
    image but also correctly addressed the problem with smaller reasoning steps.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，该模型不仅能够阅读和理解提供的图像，而且还能通过较小的推理步骤正确地解决问题。
- en: Analytical skills
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分析能力
- en: 'In the previous example, we provided the model with an image, but we can go
    further and attach a more complex, structured file to be quantitatively analyzed.
    For example, we can attach to ChatGPT (powered by GPT-4o) a `.xls` file and ask
    it to perform some financial analysis (in my case, I used a sample file available
    here: [https://learn.microsoft.com/en-us/power-bi/create-reports/sample-financial-download](https://learn.microsoft.com/en-us/power-bi/create-reports/sample-financial-download)).'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的例子中，我们向模型提供了一个图像，但我们还可以进一步附加一个更复杂、结构化的文件进行定量分析。例如，我们可以向ChatGPT（由GPT-4o驱动）附加一个`.xls`文件，并要求它进行一些财务分析（在我的案例中，我使用了这里可用的样本文件：[https://learn.microsoft.com/en-us/power-bi/create-reports/sample-financial-download](https://learn.microsoft.com/en-us/power-bi/create-reports/sample-financial-download)）。
- en: '![](img/B31559_02_06.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B31559_02_06.png)'
- en: 'Figure 2.6: Analytical prowess exhibited by ChatGPT'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.6：ChatGPT展现的分析能力
- en: 'In addition to the above answer in text format, ChatGPT can also generate graphs:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 除了上述的文本格式答案外，ChatGPT还可以生成图表：
- en: '![](img/B31559_02_07.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B31559_02_07.png)'
- en: 'Figure 2.7: Generating graphs using ChatGPT'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.7：使用ChatGPT生成图表
- en: 'Note that, to execute this particular task, ChatGPT leveraged a feature called
    Code Interpreter, which allows it to generate Python code to analyze data and
    run it directly against the uploaded file. An important thing to note is that
    you can visualize the generated code by clicking on the **[>_]** icon:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，为了执行这个特定的任务，ChatGPT利用了一个名为Code Interpreter的功能，它允许它生成Python代码来分析数据并直接在上传的文件上运行。需要注意的是，你可以通过点击**[>_**]图标来可视化生成的代码：
- en: '![](img/B31559_02_08.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B31559_02_08.png)'
- en: 'Figure 2.8: Code Interpreter'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.8：Code Interpreter
- en: The Code Interpreter feature is extremely powerful and versatile when it comes
    to structured data, and it can also be leveraged to import and train advanced
    ML models to then make predictions on data.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到结构化数据时，Code Interpreter功能非常强大且多功能，它还可以被用来导入和训练高级机器学习模型，然后对数据进行预测。
- en: Summary
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we went through the history of OpenAI, its research fields,
    and the latest developments, up to ChatGPT. We also had a glimpse of the art of
    the possible with ChatGPT, from reasoning over complex images to executing analytical
    tasks.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们回顾了OpenAI的历史、研究领域以及最新的发展，直到ChatGPT。我们还通过ChatGPT一瞥了可能的技艺，从对复杂图像进行推理到执行分析任务。
- en: In the next chapter, we begin *Part 2* of this book, where we will see ChatGPT
    in action in various domains and how to unlock its potential. You will learn how
    to get the highest value from ChatGPT by properly designing your prompts, how
    to boost your daily productivity, and how it can be a great project assistant
    for any consumer.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将开始本书的**第二部分**，我们将看到ChatGPT在各个领域的应用以及如何释放其潜力。你将学习如何通过合理设计你的提示来获取ChatGPT的最高价值，如何提高你的日常生产力，以及它如何成为任何消费者的优秀项目助手。
- en: References
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: Radford, A. & Narasimhan, K. (2018). *Improving language understanding by generative
    pre-training*. [https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf)
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Radford, A. & Narasimhan, K. (2018). *Improving language understanding by generative
    pre-training*. [https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf)
- en: Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N.,
    Kaiser, L., & Polosukhin, I. (2017). *Attention Is All You Need*. arXiv. [https://doi.org/10.48550/arXiv.1706.03762](https://doi.org/10.48550/arXiv.1706.03762)
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N.,
    Kaiser, L., & Polosukhin, I. (2017). *Attention Is All You Need*. arXiv. [https://doi.org/10.48550/arXiv.1706.03762](https://doi.org/10.48550/arXiv.1706.03762)
- en: OpenAI. *Fine-Tuning Guide*. OpenAI platform documentation. https:// [platform.openai.com/docs/guides/fine-tuning](http://platform.openai.com/docs/guides/fine-tuning)
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI. *Fine-Tuning Guide*. OpenAI平台文档。https:// [platform.openai.com/docs/guides/fine-tuning](http://platform.openai.com/docs/guides/fine-tuning)
- en: Join our communities on Discord and Reddit
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们的Discord和Reddit社区
- en: Have questions about the book or want to contribute to discussions on Generative
    AI and LLMs? Join our Discord server at [https://packt.link/I1tSU](Chapter_2.xhtml)
    and our Reddit channel at [https://packt.link/jwAmA](Chapter_2.xhtml) to connect,
    share, and collaborate with like-minded enthusiasts.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 对本书有疑问或想参与关于生成式AI和LLMs的讨论？加入我们的Discord服务器[https://packt.link/I1tSU](Chapter_2.xhtml)和Reddit频道[https://packt.link/jwAmA](Chapter_2.xhtml)，以连接、分享和与志同道合的爱好者合作。
- en: '![](img/Discord.png) ![](img/QR_Code757615820155951000.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/Discord.png) ![图片](img/QR_Code757615820155951000.png)'
