- en: Web Deployments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we have been focused on getting something to work for the very first
    time and then making incremental updates. These updates are almost always geared
    toward better techniques and better usability. But, how do we expose them to the
    user? One way to do this is via REST endpoints.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we are going to cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Training a model, and writing some neater utils for data I/O
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building a predict function, separated from training
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exposing what we have covered using a Flask REST endpoint
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Web deployments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This is the hackathon version, and more experienced engineers will notice that
    we neglect a lot of best practices in favor of saving developer time. In my defense,
    I did add pretty usable logging.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will start from where we left off when we talked about text classification
    using machine learning methods. There are a few challenges that we left untouched:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Model persistence**: How can I write the model, data, and code to disk?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Model loading and prediction**: How can I load the model data *and code*
    from disk?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Flask for REST endpoints**: How can I expose the loaded model over the web?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If there is anything that you take away from this chapter, it should be the
    preceding three questions. If you have a clear and complete idea regarding how
    to tackle these three questions, your battle is won.
  prefs: []
  type: TYPE_NORMAL
- en: We will use a scikit-learn model and the same TF-IDF based pipelines we are
    familiar with for this demo.
  prefs: []
  type: TYPE_NORMAL
- en: Model persistence
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The first challenge is to write the model data and code it to disk. Let's start
    by training the pipeline first.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s get the imports out of the way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s write some utils for reading the data from text files and downloading
    them if absent:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start by setting up a download progress bar for our use. We will do
    this by building a small abstraction over the `tqdm` package:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s use the preceding `tqdm` progress information for defining a download
    utility:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Notice that the utility uses `os` instead of `pathlib`, which is preferred throughout
    the text otherwise. This is both for variety and the fact that `os` works equally
    well in Python 2, while `pathlib` is best used with Python 3.4 or later. As a
    reminder, this entire book assumes that you are using Python 3.6 code.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have a `get_data` utility in place, let''s write a `read_data`
    utility, which is customized to our specific dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: pandas DataFrames make our code much easier to read, manage, and debug. Additionally,
    this function actually uses a Python nested function to make it easier to increase
    code reuse. Notice that for both positive and negative reviews, we use the same
    internal function that does the I/O for us.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s import these utils now:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'I have defined a logger from the Python 3 `logging` module, with both the file
    handler and the console handler. Since that is a well-known and established best
    practice, I am going to skip that here and use the logger directly instead:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The `data_path` variable now contains the extracted folders and files from `aclImdb`.
    Notice that this extraction is not done by code, but is instead done by the user
    outside of this code.
  prefs: []
  type: TYPE_NORMAL
- en: This is because this extraction from `*.tar.gz` or `*.tgz` is OS-dependent.
    Another thing that you should have noticed by now is that we have moved away from
    notebooks with interspersed print statements and previews to Python scripts for
    this section.
  prefs: []
  type: TYPE_NORMAL
- en: 'We must download the compressed file – which is a little more than 110 MB –
    if it does not exist in the target location:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Extract the files while you''re offline before trying to read them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The `train` variable is now a DataFrame with two columns: the raw *text* and
    the *label*. The label is either `pos` or `neg`, which is short for positive or
    negative. The label indicates the overall sentiment of the review. We separate
    these into two variables: `X_train` and `y_train`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, let''s define the `Pipeline` of operations that we want to perform. The
    logistic regression model, which uses TF-IDF representations, is the simplest
    and fastest way to train the model, and has reasonably good performance. We will
    use that here, but you can (*and usually, should*) actually replace this with
    whatever has the best performance on your test data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Once we call the `.fit` function, we have trained our pipeline for text classification.
  prefs: []
  type: TYPE_NORMAL
- en: Those who are familiar with Python might remember pickle or cPickle. Pickle
    is a Python-native utility for saving objects and other Python data structures
    to disk in binary for later reuse. `joblib` is a pickle improvement!
  prefs: []
  type: TYPE_NORMAL
- en: '`joblib` is an improvement because it also caches the *code with data*, which
    is fantastic for our use case. We don''t have to worry about defining the pipeline
    in our web API layer. It is no longer tied to our specific model, which means
    that we can keep making better releases by simply changing the underlying `joblib.dump`
    file.'
  prefs: []
  type: TYPE_NORMAL
- en: 'As a tribute to the classic Python pickle, we are going to give a `.pkl` extension
    to this cached code and `model.pkl` data file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: That's it! We have now written our code and data logic into one single binary
    file.
  prefs: []
  type: TYPE_NORMAL
- en: How will we actually use this? Let's look at how next.
  prefs: []
  type: TYPE_NORMAL
- en: Model loading and prediction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The next challenge is actually to load the model from our pickled file and use
    it to make predictions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start by loading the model from disk:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The `model` variable should now expose all the functions that the original `lr_clf`
    object did. Of all those methods, we are interested in the `predict` function.
  prefs: []
  type: TYPE_NORMAL
- en: 'But before we use that, let''s load some files from disk for making predictions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now pass these variables in a list to the `predict` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: What does the `predictions` variable contain at this point?
  prefs: []
  type: TYPE_NORMAL
- en: Is it a list? Is it a numpy array? Or just an integer?
  prefs: []
  type: TYPE_NORMAL
- en: 'You can check for this by using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, the predictions is a list of integers, identical to the way we
    had read our `y_train` variable in the training file. Let's go ahead and incorporate
    what we have learned here into a web interface and REST Endpoints.
  prefs: []
  type: TYPE_NORMAL
- en: Flask for web deployments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s begin by getting the imports out of the way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'I am assuming that as a programmer, you can pick up Flask basics outside this
    book. Even then, for the sake of completeness, I am adding the main ideas that
    are relevant to us:'
  prefs: []
  type: TYPE_NORMAL
- en: The main web app is defined in the `Flask` module, which is imported from Flask
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`jsonify` converts any JSON-friendly dictionary into a JSON that can then be
    returned to the user'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`render_template` is how we expose HTML pages and web interfaces to our users'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s begin by declaring our app first:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we will use the `route` function to decorate our Python functions and
    expose them as REST endpoints. Let''s start by exposing a simple status endpoint
    that is always ON and return 200 for whenever the service is running:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: The `methods` variable is usually a list of strings with the values `GET` `POST`,
    or both. GET is used for HTTP(S) GET calls that require no information from the
    user, except that which is already contained in the GET call. The HTTP POST calls
    supply additional data from the client (such as the browser) to the server.
  prefs: []
  type: TYPE_NORMAL
- en: This can be accessed by hitting the `/status` endpoint in your browser.
  prefs: []
  type: TYPE_NORMAL
- en: Go ahead and try it.
  prefs: []
  type: TYPE_NORMAL
- en: Ouch! We forgot to run the app itself first.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s go ahead and run the app in debug mode. Debug mode allows us to add
    and edit code, and automatically load the code on every save:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Notice that we load the `model` variable from `joblib`, like we did earlier.
    This code segment is written at the end of an `api.py` file. This is remarkably
    sloppy, with no concurrency support, and isn't integrated with nginx – but all
    of that is fine for this demonstration.
  prefs: []
  type: TYPE_NORMAL
- en: What happens if we hit the `localhost:8000/status` endpoint from our browser
    now?
  prefs: []
  type: TYPE_NORMAL
- en: We get a status 200, and the data field contains our JSON with the version and
    *status* information. Great.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s go ahead and add our `/predict` endpoint. Here is the outline of the
    steps this function will undertake:'
  prefs: []
  type: TYPE_NORMAL
- en: It will check if this is indeed a POST method. If yes, it will extract the file
    information from the *file* key in `flask.request.files`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then, it will write this file to disk and read again, and then pass string text
    to `model.predict` as a single element of a list.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Finally, it will return the result to a web interface in HTML, after optionally
    deleting the file written to disk:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Quite obviously, the step for writing the file to disk is redundant if we are
    simply going to delete it later. In practice, I keep the files on disk since it
    helps with debugging and, in some cases, understanding how the API is being used
    in actual practice by its users.
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding snippet, you might have noticed that we return an `index.html`
    file with a `label` value. The label is set as part of `Jinja2` templates. The
    variable is used in the `index.html` itself and the value is updated when rendering
    the page.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is the `index.html` we will use:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'This is what the HTML looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d94796a9-e320-469e-af4b-6030a0bbe624.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The Prediction: pos is actually a result from the file I uploaded to this page
    earlier. This was marked by the `{%%}` syntax in the actual HTML:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'So, we have seen a few things in the Flask-based web deployment section:'
  prefs: []
  type: TYPE_NORMAL
- en: How do you receive uploaded files on the Flask webserver?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How do you upload the file using a web interface?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'And, as a bonus: Jinja templates to display the returned answer'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is worth mentioning that we could make this even more general by separating
    returns. This would be for use by humans, where we return HTML, and for use by
    machine, where we return JSON. I leave this function refactoring as an exercise
    for you.
  prefs: []
  type: TYPE_NORMAL
- en: Quite obviously, we could have done this with Django or any other web framework.
    The only reason I picked Flask is for demonstration purposes and because it is
    very lightweight, with no concern for model-view-controller separation.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The key takeaway from this chapter should be that any machine learning model
    can be deployed like any other piece of code. The only difference is that we have
    to make room for being able to load the model again from disk. To do this, first,
    we need to train a model and write the model code and weights to disk using `joblib`.
    Then, we need to build a predict function, which is separated from training. Finally,
    we expose what we have done by using Flash with Jinja2 HTML templates.
  prefs: []
  type: TYPE_NORMAL
