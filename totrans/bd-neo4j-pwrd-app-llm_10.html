<html><head></head><body><div><div><p>&#13;
    <h1 class="chapterNumber"><a id="_idTextAnchor058"/>8</h1>&#13;
    <h1 id="_idParaDest-123" class="chapterTitle">Constructing a Recommendation Graph with H&amp;M Personalization Dataset</h1>&#13;
    <p class="normal">While Neo4j is great for building knowledge graphs, it would be prudent to look at how we model the data. A good data persistence model can make data retrieval optimal and handle large loads better. In this chapter, we will take a step back to look <a id="_idIndexMarker342"/>at what constitutes a <strong class="keyWord">knowledge graph</strong> and how a different look at data modeling with a Neo4j data persistence approach can help build more powerful knowledge graphs. You might need to revisit the approaches defined in <a href="Preface.xhtml#_idTextAnchor012"><em class="italic">Chapter 3</em></a>, which will enable you to build a knowledge graph with Personalized Fashion Recommendations (H&amp;M personalization) data.</p>&#13;
    <p class="normal">We will cover these topics in this chapter as we tackle data modeling evolution:</p>&#13;
    <ul>&#13;
      <li class="bulletList">Modeling a recommendation graph with the H&amp;M Personalization dataset</li>&#13;
      <li class="bulletList">Optimizing for recommendations: Best practices in graph modeling</li>&#13;
    </ul>&#13;
    <h1 id="_idParaDest-124" class="heading-1">Technical requirements</h1>&#13;
    <p class="normal">You will need to be familiar with SQL and Cypher. We will be using SQLite and Neo4j to understand the various aspects of data modeling. We will use the following tools in this chapter:</p>&#13;
    <ul>&#13;
      <li class="bulletList">Neo4j Desktop (<a href="https://neo4j.com/docs/desktop-manual/current/">https://neo4j.com/docs/desktop-manual/current/</a>) or Neo4j Aura (<a href="https://neo4j.com/docs/aura/">https://neo4j.com/docs/aura/</a>)</li>&#13;
      <li class="bulletList">The H&amp;M dataset to create the recommendation system: This dataset is available at <a href="https://www.kaggle.com/c/h-and-m-personalized-fashion-recommendations/overview">https://www.kaggle.com/c/h-and-m-personalized-fashion-recommendations/overview</a> (Carlos García Ling, ElizabethHMGroup, FridaRim, inversion, Jaime Ferrando, Maggie, neuraloverflow, and xlsrln. H&amp;M Personalized Fashion Recommendations. 2022. Kaggle)</li>&#13;
    </ul>&#13;
    <p class="normal">Remember from <a href="Preface.xhtml#_idTextAnchor012"><em class="italic">Chapter 3</em></a> that a good graph data model makes the <em class="italic">retrieval</em> part of RAG flow more effective. It makes retrieving relevant data faster and easier. You may revisit <a href="Preface.xhtml#_idTextAnchor012"><em class="italic">Chapter 3</em></a> for a quick recap of graph data modeling. In this chapter, we model the data with time as a dimension. The chain of transactions with the time as a dimension makes data retrieval very efficient and performant. </p>&#13;
    <h1 id="_idParaDest-125" class="heading-1">Modeling the recommendation graph with the H&amp;M personalization dataset</h1>&#13;
    <p class="normal">In this section, we will create a graph data model with the real-life large-scale H&amp;M Personalization dataset. This graph data model will enable us to power up the recommendation engine that we will create in upcoming chapters.</p>&#13;
    <p class="normal">In 2022, H&amp;M posted <a id="_idIndexMarker343"/>customer transaction data along with other metadata related to customers, products, and so on, as part of a competition<a id="_idIndexMarker344"/> to build a recommendation engine. This dataset contains data from previous transactions, as well as from customer and product metadata. The available metadata spans simple data, such as garment type and customer age, to text data from product descriptions, to image data from garment images.</p>&#13;
    <p class="normal">We will discuss the dataset’s characteristics and load the data into a knowledge graph as we go, step by step.</p>&#13;
    <p class="normal">We will take a look at the data available in this dataset:</p>&#13;
    <ul>&#13;
      <li class="bulletList"><code class="inlineCode">images/:</code> This contains the images for a given <code class="inlineCode">article_id.</code> Not all articles in the dataset may have images associated with them. We will not be using this data to build the graph. Storing the images in a graph would not only be inefficient, but it is not necessary for the graph flow we are building.</li>&#13;
      <li class="bulletList"><code class="inlineCode">articles.csv:</code> This file contains the <a id="_idIndexMarker345"/>metadata for each article available for purchase. Each row represents<a id="_idIndexMarker346"/> one unique article with metadata such as the product family, color, style, section the article belongs to, and department.</li>&#13;
      <li class="bulletList"><code class="inlineCode">customers.csv:</code> This file contains the metadata for each customer in the dataset, including customer ID, age, fashion news frequency, active flag, H&amp;M club member status, and postal code.</li>&#13;
      <li class="bulletList"><code class="inlineCode">transactions_train.csv:</code> This file contains the transactions made by customers. If a customer made multiple purchases of the same item, that data might come as multiple rows – one row for each item purchased, with the transaction date, article ID, customer ID, price, and sales channel.</li>&#13;
    </ul>&#13;
    <p class="normal">We will take a look at the <strong class="keyWord">graph data model</strong> of this <a id="_idIndexMarker347"/>data in the next section and load the data for that model. When we build the knowledge graph for the H&amp;M personalization dataset recommendations, we will have a list of transactions made by customers, and representing these as a chain of transactions with time as a dimension might work very well for us. By adding our understanding of the data into the graph data model can make our recommendations more valuable. For instance, the transactions are a sequence of events; hence modeling them as a sequence makes more sense. Unlike traditional databases, Neo4j makes it possible to store these transactions as a graph that is connected sequentially using relationships.</p>&#13;
    <p class="normal">We can say, we are persisting our knowledge of data into the graph, thus creating a knowledge graph.</p>&#13;
    <h2 id="_idParaDest-126" class="heading-2">Building your recommendation graph</h2>&#13;
    <p class="normal">To build the recommendation<a id="_idIndexMarker348"/> model graph, we will take a look at the data within each of the files in the dataset and how they contribute to the graph. We will apply the process we <a id="_idIndexMarker349"/>discussed previously, in <a href="Preface.xhtml#_idTextAnchor012"><em class="italic">Chapter 3</em></a><em class="italic">,</em> to build the graph. Before loading the data, we need to use Neo4j Desktop<a id="_idIndexMarker350"/> and perform these steps:</p>&#13;
    <ol>&#13;
      <li class="numberedList" value="1">Create a local database. You can follow the instructions at <a href="https://neo4j.com/docs/desktop-manual/current/operations/create-dbms/">https://neo4j.com/docs/desktop-manual/current/operations/create-dbms/</a> to perform this operation.</li>&#13;
      <li class="numberedList">Copy the CSV files from the H&amp;M recommendation dataset to the <code class="inlineCode">import</code> directory of this database. If you are not sure how to do this, please visit <a href="https://community.neo4j.com/t/where-is-neo4j-home/6488/5">https://community.neo4j.com/t/where-is-neo4j-home/6488/5</a> for reference.</li>&#13;
    </ol>&#13;
    <p class="normal">Now let us load the data into the graph database.</p>&#13;
    <h2 id="_idParaDest-127" class="heading-2">Loading the customer data</h2>&#13;
    <p class="normal">The customer data contains <a id="_idIndexMarker351"/>these elements: customer ID, age, fashion news frequency, active flag, H&amp;M club member status, and postal code.</p>&#13;
    <p class="normal">The customer ID is the unique ID of the customer. To make sure we have unique nodes representing the customer, we need to have a <code class="inlineCode">UNIQUE</code> constraint. Also, we will make the postal code a node, as we might want to segregate customers by postal code easily.</p>&#13;
    <p class="normal">Before loading this data, we need to create these unique constraints, by connecting to the Neo4j database we created:</p>&#13;
    <pre class="programlisting code"><code class="hljs-code">CREATE CONSTRAINT customer_id_idx FOR (n:Customer) REQUIRE n.id IS UNIQUE ;&#13;
CREATE CONSTRAINT postal_code_idx FOR (n:PostalCode) REQUIRE n.code IS UNIQUE ;&#13;
</code></pre>&#13;
    <p class="normal">Once unique constraints are created, we can use this Cypher to load the data into the database:</p>&#13;
    <div>&#13;
      <p class="normal"><strong class="keyWord">Note</strong></p>&#13;
      <p class="normal">For the <code class="inlineCode">LOAD</code> <code class="inlineCode">CSV</code> queries, we need to <a id="_idIndexMarker352"/>prefix them with <code class="inlineCode">auto</code> to be <a id="_idIndexMarker353"/>able to run them in Neo4j Browser.</p>&#13;
    </p>&#13;
    <pre class="programlisting code"><code class="hljs-code">LOAD CSV WITH HEADERS FROM "file:///customers.csv" as row&#13;
WITH row&#13;
CALL {&#13;
    WITH row&#13;
    MERGE (c:Customer {id:row.customer_id})&#13;
    SET c.age = row.age&#13;
    FOREACH( ignoreME in CASE WHEN row.fashion_news_frequency = 'Regularly'  THEN [1] ELSE [] END |&#13;
        SET c:FN_REGULAR&#13;
    )&#13;
    FOREACH( ignoreME in CASE WHEN row.club_member_status = 'ACTIVE'  THEN [1] ELSE [] END |&#13;
        SET c:CLUB_ACTIVE&#13;
    )&#13;
    FOREACH( ignoreME in CASE WHEN row.club_member_status = 'PRE-CREATE'  THEN [1] ELSE [] END |&#13;
        SET c:CLUB_PRE_CREATE&#13;
    )&#13;
    FOREACH( ignoreME in CASE WHEN row.Active &lt;&gt; 'ACTIVE'  THEN [1] ELSE [] END |&#13;
        SET c:INACTIVE&#13;
    )&#13;
    MERGE(p:PostalCode {code:row.postal_code})&#13;
    MERGE(c)-[:LIVES_IN]-&gt;(p)&#13;
} IN TRANSACTIONS OF 1000 ROWS&#13;
</code></pre>&#13;
    <p class="normal">This script loads the customer <a id="_idIndexMarker354"/>data into the database, using 1,000 rows as one batch to commit. In this script, we can notice a couple of things:</p>&#13;
    <ul>&#13;
      <li class="bulletList">We have only one property, named <code class="inlineCode">age</code>, on the <code class="inlineCode">Customer</code> node, apart from the unique ID, <code class="inlineCode">customer_id</code></li>&#13;
      <li class="bulletList">We map the other properties of the customer data as labels on the <code class="inlineCode">Customer</code> node</li>&#13;
    </ul>&#13;
    <p class="normal">This approach follows the <em class="italic">consumption-based approach</em> to data modeling we discussed previously. Say we want to understand how the customers who are regular fashion news subscribers behave – this gives us <a id="_idIndexMarker355"/>an easy way to retrieve this information. Neo4j optimizes this type of retrieval using a label-based approach. We could make this <a id="_idIndexMarker356"/>customer behavior (fashion news subscription) a property and create an index to retrieve <a id="_idIndexMarker357"/>this data, but that would require more storage, as well as having an index lookup cost. Say we want to use the customers who are active club members and are regular fashion news consumers – this label-based approach gives us an edge to retrieve this information more effectively when compared to storing it as a property. Also, when we display this information as a graph, users can easily see the information in the labels, rather than looking for a property. It feels more natural to consume the data in this manner and queries also look more natural.</p>&#13;
    <p class="normal">Next, we will load the article data.</p>&#13;
    <h2 id="_idParaDest-128" class="heading-2">Loading the article data</h2>&#13;
    <p class="normal">The article data contains other <a id="_idIndexMarker358"/>categories that describe the article, apart from the unique article ID and description. We will make other attributes that describe articles nodes themselves.</p>&#13;
    <p class="normal">For this purpose, we need to create these unique constraints:</p>&#13;
    <pre class="programlisting code"><code class="hljs-code">CREATE CONSTRAINT product_code_idx FOR (n:Product) REQUIRE n.code IS UNIQUE ;&#13;
CREATE CONSTRAINT article_id_idx FOR (n:Article) REQUIRE n.id IS UNIQUE ;&#13;
CREATE CONSTRAINT product_type_id_idx FOR (n:ProductType) REQUIRE n.id IS UNIQUE ;&#13;
CREATE CONSTRAINT colour_group_idx FOR (n:ColorGroup) REQUIRE n.id IS UNIQUE ;&#13;
CREATE CONSTRAINT product_group_name_idx FOR (n:ProductGroup) REQUIRE n.name IS UNIQUE ;&#13;
CREATE CONSTRAINT graphical_appearance_id_idx FOR (n:GraphicalAppearance) REQUIRE n.id IS UNIQUE ;&#13;
CREATE CONSTRAINT perceived_colour_id_idx FOR (n:PerceivedColor) REQUIRE n.id IS UNIQUE ;&#13;
CREATE CONSTRAINT department_id_idx FOR (n:Department) REQUIRE n.id IS UNIQUE ;&#13;
CREATE CONSTRAINT section_id_idx FOR (n:Section) REQUIRE n.id IS UNIQUE ;&#13;
CREATE CONSTRAINT garment_group_id_idx FOR (n:GarmentGroup) REQUIRE n.id IS UNIQUE ;&#13;
CREATE CONSTRAINT article_index_id_idx FOR (n:Index) REQUIRE n.id IS UNIQUE ;&#13;
CREATE CONSTRAINT article_index_group_id_idx FOR (n:IndexGroup) REQUIRE n.id IS UNIQUE ;&#13;
</code></pre>&#13;
    <p class="normal">We can see that we have converted <a id="_idIndexMarker359"/>most of the attributes of the articles<a id="_idIndexMarker360"/> into nodes. This <a id="_idIndexMarker361"/>sort of normalizes the data represented in the graph. This Cypher will load the data into the graph:</p>&#13;
    <pre class="programlisting code"><code class="hljs-code">LOAD CSV WITH HEADERS FROM "file:///articles.csv" as row&#13;
WITH row&#13;
CALL {&#13;
    WITH row&#13;
</code></pre>&#13;
    <p class="normal">For each row, create an article, product, and product group and associate them:</p>&#13;
    <pre class="programlisting code"><code class="hljs-code">    MERGE(a:Article {id:row.article_id})&#13;
    SET a.desc = row.detail_desc&#13;
    MERGE(p:Product {code:row.product_code})&#13;
    SET p.name = row.prod_name&#13;
    MERGE(a)-[:OF_PRODUCT]-&gt;(p)&#13;
    MERGE(pt:ProductType {id:row.product_type_no})&#13;
    SET pt.name = row.product_type_name&#13;
    MERGE(p)-[:HAS_TYPE]-&gt;(pt)&#13;
    WITH row, a, p&#13;
    MERGE(pg:ProductGroup {name:row.product_group_name})&#13;
    MERGE(p)-[:HAS_GROUP]-&gt;(pg)&#13;
</code></pre>&#13;
    <p class="normal">Now add the graphical appearance and<a id="_idIndexMarker362"/> colors associated with <a id="_idIndexMarker363"/>the article:</p>&#13;
    <pre class="programlisting code"><code class="hljs-code">    WITH row, a&#13;
    MERGE(g:GraphicalAppearance {id:row.graphical_appearance_no})&#13;
    SET g.name = row.graphical_appearance_name&#13;
    MERGE (a)-[:HAS_GRAPHICAL_APPEARANCE]-&gt;(g)&#13;
    WITH row, a&#13;
    MERGE (c:ColorGroup {id: row.colour_group_code})&#13;
    SET c.name = row.colour_group_name&#13;
    MERGE (a)-[:HAS_COLOR]-&gt;(c)&#13;
    WITH row, a&#13;
    MERGE (pc:PerceivedColor {id: row.perceived_colour_value_id})&#13;
    SET pc.name = row.perceived_colour_value_name&#13;
    MERGE (a)-[:HAS_PERCEIVED_COLOR]-&gt;(pc)&#13;
    MERGE (pcm:PerceivedColor {id: row.perceived_colour_master_id})&#13;
    SET pcm.name = row.perceived_colour_master_name&#13;
    MERGE (pc)-[:HAS_MASTER]-&gt;(pcm)&#13;
</code></pre>&#13;
    <p class="normal">Now let us connect the<a id="_idIndexMarker364"/> department associated with it:</p>&#13;
    <pre class="programlisting code"><code class="hljs-code">    WITH row, a&#13;
    MERGE (d:Department {id:row.department_no})&#13;
    SET d.name = row.department_name&#13;
    MERGE (a)-[:HAS_DEPARTMENT]-&gt;(d)&#13;
    WITH row, a&#13;
    MERGE (i:Index {id: row.index_code})&#13;
    SET i.name = row.index_name&#13;
    MERGE (a)-[:HAS_INDEX]-&gt;(i)&#13;
    MERGE (ig:IndexGroup {id: row.index_group_no})&#13;
    SET ig.name = row.index_group_name&#13;
    MERGE (i)-[:HAS_GROUP]-&gt;(ig)&#13;
</code></pre>&#13;
    <p class="normal">Finally, let us connect<a id="_idIndexMarker365"/> the section the article<a id="_idIndexMarker366"/> belongs to and the garment group:</p>&#13;
    <pre class="programlisting code"><code class="hljs-code">    WITH row, a&#13;
    MERGE (s:Section {id: row.section_no})&#13;
    SET s.name = row.section_name&#13;
    MERGE (a)-[:HAS_SECTION]-&gt;(s)&#13;
    WITH row, a&#13;
    MERGE (gg:GarmentGroup {id: row.garment_group_no})&#13;
    SET gg.name = row.garment_group_name&#13;
    MERGE (a)-[:HAS_GARMENT_GROUP]-&gt;(gg)&#13;
} IN TRANSACTIONS OF 1000 ROWS&#13;
</code></pre>&#13;
    <p class="normal">From the Cypher query, we can see that, in the graph, we are persisting the normalized data, without duplicating values for <a id="_idIndexMarker367"/>various aspects that describe the article.</p>&#13;
    <p class="normal">We will load the transactions next.</p>&#13;
    <h2 id="_idParaDest-129" class="heading-2">Loading the transaction data</h2>&#13;
    <p class="normal">The <code style="font-weight: bold;" class="codeHighlighted">transaction_train.csv</code> data is in the order transactions have occurred. This makes it possible to load the data<a id="_idIndexMarker368"/> and preserve the sequence in the graph in an easy manner. We have this data in each row for transactions: transaction date, article ID, customer ID, price, and sales channel.</p>&#13;
    <p>&#13;
      <p class="normal"><strong class="keyWord">Note</strong></p>&#13;
      <p class="normal">We don’t have a unique ID for each of the transactions.</p>&#13;
    </p>&#13;
    <p class="normal">We can use this<a id="_idIndexMarker369"/> Cypher to load the<a id="_idIndexMarker370"/> data:</p>&#13;
    <pre class="programlisting code"><code class="hljs-code">LOAD CSV WITH HEADERS FROM "file:///transactions_train.csv" as row WITH row&#13;
CALL {&#13;
    WITH row&#13;
    MATCH (c:Customer {id:row.customer_id})&#13;
    MATCH (a:Article {id:row.article_id})&#13;
    WITH a, c, row&#13;
    CREATE (t:Transaction {date: row.t_dat, price: row.price, salesChannel: row.sales_channel_id})&#13;
    CREATE (t)-[:HAS_ARTICLE]-&gt;(a)&#13;
    WITH c, t&#13;
    CALL {&#13;
        WITH c, t&#13;
        WITH c, t&#13;
        WHERE exists((c)-[:START_TRANSACTION]-&gt;()) OR exists((c)-[:LATEST]-&gt;())&#13;
        MATCH (c)-[r:LATEST]-&gt;(lt)&#13;
        DELETE r&#13;
        CREATE (lt)-[:NEXT]-&gt;(t)&#13;
        CREATE (c)-[:LATEST]-&gt;(t)&#13;
        UNION&#13;
        WITH c, t&#13;
        WITH c,t&#13;
        WHERE NOT ( exists((c)-[:START_TRANSACTION]-&gt;()) OR exists((c)-[:LATEST]-&gt;()) )&#13;
        CREATE (c)-[:START_TRANSACTION]-&gt;(t)&#13;
        CREATE (c)-[:LATEST]-&gt;(t)&#13;
    }&#13;
} IN TRANSACTIONS OF 1000 ROWS&#13;
</code></pre>&#13;
    <p class="normal">From this Cypher, we <a id="_idIndexMarker371"/>can see that we take the first transaction we find for a given customer and connect it to the customer using a <em class="italic">START_TRANSACTION</em> relationship. We use a <em class="italic">LATEST</em> relationship to track the<a id="_idIndexMarker372"/> last transaction the customer made. As we keep getting more transactions for the customer, we keep moving the <em class="italic">LATEST</em> relationship to the newest<a id="_idIndexMarker373"/> transaction. We connect the earlier transaction that was connected using a <em class="italic">LATEST</em> relationship and the new transaction with a <em class="italic">NEXT</em> relationship. So, in this graph, we are representing the transactions made by customers as a transaction train, true to<a id="_idIndexMarker374"/> the name of the dataset file <code class="inlineCode">transaction_train.csv</code>.</p>&#13;
    <h2 id="_idParaDest-130" class="heading-2">Final graph</h2>&#13;
    <p class="normal">After loading all the<a id="_idIndexMarker375"/> data, our graph model will look as shown in <em class="italic">Figure 8.1</em>.</p>&#13;
    <figure class="mediaobject"><img src="img/B31107_08_01.png" alt="Figure 8.1 — Graph data model after loading the H&amp;M data" width="1663" height="917"/></figure>&#13;
    <p class="packt_figref">Figure 8.1 — Graph data model after loading the H&amp;M data</p>&#13;
    <p class="normal">We can see from this graph <a id="_idIndexMarker376"/>that the article attributes are fanned out into various individual nodes. The <strong class="screenText">Customer</strong> node is connected to the postal code and first and last transactions. <strong class="screenText">Transaction</strong> is associated with <strong class="screenText">Article</strong>. The <a id="_idIndexMarker377"/><strong class="screenText">Transaction</strong> nodes are also connected to any next transactions available for a given customer.</p>&#13;
    <p class="normal">Now that we have loaded <a id="_idIndexMarker378"/>the data, let us explore how we can further enhance the graph from this data, to add our own understanding of the data and ideas into the graph.</p>&#13;
    <h1 id="_idParaDest-131" class="heading-1">Optimizing for recommendations: best practices in graph modeling</h1>&#13;
    <p class="normal">We have a graph now, with<a id="_idIndexMarker379"/> data loaded the way we want to consume it and representing the context of the data. Still, the graph represents only the original context provided. Say we want to consume the data by season and year – we still need to build queries to retrieve it. Since Neo4j is schema optional, maybe we can do some post-processing and add extra relationships to consume the data in that way.</p>&#13;
    <p class="normal">In this Cypher script, we are creating seasonal relationships:</p>&#13;
    <ol>&#13;
      <li class="numberedList" value="1">For each customer, iterate through the transactions and assign a season value based on month and year:&#13;
        <pre class="programlisting code"><code class="hljs-code">MATCH (c:Customer)&#13;
WITH c&#13;
CALL {&#13;
    WITH c&#13;
    MATCH (c)-[:START_TRANSACTION]-&gt;(s)&#13;
    MATCH (c)-[:LATEST]-&gt;(e)&#13;
    WITH c,s,e&#13;
    MATCH p=(s)-[:NEXT*]-&gt;(e)&#13;
    WITH c, nodes(p) as nodes&#13;
    UNWIND nodes as node&#13;
</code></pre>&#13;
      </li>&#13;
      <li class="numberedList">For example, if the month is <code class="inlineCode">1</code> and the year is <code class="inlineCode">2020</code>, we assign <code class="inlineCode">WINTER_2019</code> as the season name for that transaction as the context:&#13;
        <pre class="programlisting code"><code class="hljs-code">    WITH c, node, node.date as d&#13;
    WITH c, node, toInteger(substring(d, 0,4)) as year, substring(d, 5,2) as month&#13;
    WITH c, node,&#13;
        CASE WHEN month="12" THEN year&#13;
             WHEN month="01" OR month="02" THEN year-1&#13;
            ELSE&#13;
                year&#13;
        END as year,&#13;
</code></pre>&#13;
      </li>&#13;
      <li class="numberedList">Collect transactions for each season value:&#13;
        <pre class="programlisting code"><code class="hljs-code">        CASE WHEN month="12" OR month="01" OR month="02" THEN "WINTER"&#13;
             WHEN month="03" OR month="04" OR month="05" THEN "SPRING"&#13;
             WHEN month="06" OR month="07" OR month="08" THEN "SUMMER"&#13;
             WHEN month="09" OR month="10" OR month="11" THEN "FALL"&#13;
        END as season&#13;
    WITH c, node, season+'_'+year as relName&#13;
</code></pre>&#13;
      </li>&#13;
      <li class="numberedList">Get the first record of the collection for each season value:&#13;
        <pre class="programlisting code"><code class="hljs-code">    WITH c, relName, head(collect(node)) as start&#13;
    WHERE relName is not null&#13;
</code></pre>&#13;
      </li>&#13;
      <li class="numberedList">Create a relationship between the customer and that transaction with the season value as the relationship name. We are using the <code class="inlineCode">apoc</code> method to create the relationship as<a id="_idIndexMarker380"/> the relationship name is dynamic:&#13;
        <pre class="programlisting code"><code class="hljs-code">CALL apoc.create.relationship(c, relName, {}, start) YIELD rel&#13;
    WITH 1 as out&#13;
    return DISTINCT out&#13;
} IN TRANSACTIONS OF 1000 ROWS&#13;
WITH 1 as r&#13;
RETURN DISTINCT r&#13;
</code></pre>&#13;
      </li>&#13;
    </ol>&#13;
    <p class="normal">Do note that this is a very basic approach. This shows we can create extra context in the graph based on our understanding of the data. These approaches make Neo4j very suitable for building knowledge graphs. When we make it easy to access data in this way, it can open up more ideas on how we can look at the same data differently to extract more <em class="italic">intelligence</em> in a simple manner that’s traceable and understandable at the same time.</p>&#13;
    <p class="normal">If you do not want to load the data manually, you can download the database snapshot from the following URL:  <a href="https://packt-neo4j-powered-applications.s3.us-east-1.amazonaws.com/Building+Neo4j-Powered+Applications+with+LLMs+Database+Dump+files.zip">https://packt-neo4j-powered-applications.s3.us-east-1.amazonaws.com/Building+Neo4j-Powered+Applications+with+LLMs+Database+Dump+files.zip</a></p>&#13;
    <p class="normal">We have now added <a id="_idIndexMarker381"/>more context to the data. Let’s look at the graph data model next.</p>&#13;
    <figure class="mediaobject"><img src="img/B31107_08_02.png" alt="Figure 8.2 — H&amp;M graph data model after enhancing with seasonal relationships" width="1395" height="810"/></figure>&#13;
    <p class="packt_figref">Figure 8.2 — H&amp;M graph data model after enhancing with seasonal relationships</p>&#13;
    <p class="normal">Let us use our<a id="_idIndexMarker382"/> understanding of the data to write a query to get articles bought by a random customer in the summer of 2019:</p>&#13;
    <pre class="programlisting code"><code class="hljs-code">MATCH (c:Customer)-[:SUMMER_2019]-&gt;(start), (c)-[:FALL_2019]-&gt;()&lt;-[:NEXT]-(end)&#13;
WITH c, start, end SKIP 100 LIMIT 1&#13;
MATCH p=(start)-[:NEXT*]-&gt;(end)&#13;
WITH nodes(p) as nodes, relationships(p) as rels&#13;
UNWIND nodes as node&#13;
MATCH p=(node)-[:HAS_ARTICLE]-&gt;(a)&#13;
RETURN a.desc as article&#13;
</code></pre>&#13;
    <p class="normal">With this query, we find <a id="_idIndexMarker383"/>customers who bought items both in the summer and fall of 2019, pick one customer from that list, and retrieve the article descriptions.</p>&#13;
    <p class="normal">The output of the query will look like this:</p>&#13;
    <figure class="mediaobject"><img src="img/B31107_08_03.png" alt="Figure 8.3 — Cypher query to retrieve SUMMER_2019 purchases for a customer" width="1190" height="570"/></figure>&#13;
    <p class="packt_figref">Figure 8.3 — Cypher query to retrieve SUMMER_2019 purchases for a customer</p>&#13;
    <p class="normal">By looking at the query, it is easy to understand what the query is doing. We use <code class="inlineCode">SUMMER_2019</code> as the starting point and a transaction before <code class="inlineCode">FALL_2019</code> relationship as the endpoint, traverse from the start point to the <a id="_idIndexMarker384"/>endpoint, and retrieve the articles of those transactions.</p>&#13;
    <p class="normal">We can see that we are completely relying on the graph traversals instead of property-based filters, which makes executing this query very efficient. Neo4j is built to execute these kinds of queries very efficiently.</p>&#13;
    <h1 id="_idParaDest-132" class="heading-1">Summary</h1>&#13;
    <p class="normal">In this chapter, we looked at how to look at a graph data model and how building a model based on how we consume it makes it easier to retrieve the data efficiently. We looked at the H&amp;M recommendations dataset and loaded it using those principles, and also augmented it using the properties and our understanding of that data. This added more context to the graph and also made it simple to query the data – queries are more readable and explainable to others in a simpler way.</p>&#13;
    <p class="normal">In the next chapter, we will build on this data, using an LLM to enhance it further, and will see how LLMs can provide us with more capable knowledge graphs.</p>&#13;
  </div>&#13;
</div></div></body></html>