- en: '12'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Ensuring Security and Privacy in Amazon Bedrock
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: GenAI has been making remarkable developments, enabling machines to produce
    human-like content across various domains, including text, images, and even code.
    However, there have been concerns about the risks and challenges of using GenAI
    models and how the data is handled. In this chapter, we are going to look at security,
    privacy, and **Guardrails for** **Amazon Bedrock**.
  prefs: []
  type: TYPE_NORMAL
- en: Ensuring data privacy and security is a top priority in today’s digital landscape,
    and Amazon Bedrock has implemented robust measures to address this concern. We
    are going to look at data localization, isolation, and encryption and learn ways
    to ensure that your data remains within your designated AWS region, never shared
    nor stored, and protected through robust encryption protocols. Then, we will understand
    how Amazon Bedrock is integrated with AWS IAM to provide granular control over
    access privileges, ensuring that only authorized personnel can interact with your
    resources.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, we are going to discuss ethical practices and guardrails, allowing
    you to implement safeguards aligned with safe and responsible AI policies, such
    as content filters, denied topics, word filters, and sensitive information filters.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are key topics that will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Security and privacy overview
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data encryption
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AWS IAM
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Securing the network
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Network flow
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ethical practices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Guardrails for Amazon Bedrock
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter requires you to have access to an AWS account. If you don’t have
    it already, you can go to [https://aws.amazon.com/getting-started/](https://aws.amazon.com/getting-started/)
    and create an AWS account.
  prefs: []
  type: TYPE_NORMAL
- en: Secondly, you will need to set up AWS Python SDK (Boto3), which you can do by
    going to [https://docs.aws.amazon.com/bedrock/latest/APIReference/welcome.html](https://docs.aws.amazon.com/bedrock/latest/APIReference/welcome.html).
  prefs: []
  type: TYPE_NORMAL
- en: 'You can carry out the Python setup in any way: install it on your local machine,
    or use AWS Cloud9, or utilize AWS Lambda, or leverage Amazon SageMaker.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: There will be a charge associated with the invocation and customization of the
    FMs of Amazon Bedrock. Please refer to [https://aws.amazon.com/bedrock/pricing/](https://aws.amazon.com/bedrock/pricing/)
    to learn more.
  prefs: []
  type: TYPE_NORMAL
- en: Security and privacy overview
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'One of the core security principles of Amazon Bedrock is that you, as a user
    of Amazon Bedrock, are always in control of your data. Your data is never shared
    with other users or customers and is never used to improve or train the FMs. Let
    us look at the intricate layers of protection that Amazon Bedrock provides:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Data localization**: The inference data or training data for model customization
    remains within the AWS region that you are using. This means that all API requests
    and data processing occur solely within the specified region, eliminating the
    risk of data migration or exposure beyond your designated boundaries. This regional
    isolation guarantees that your data never leaves the designated geographical boundaries,
    so you get an additional layer of protection and compliance with regional data
    regulations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data isolation**: Your inference or training data for model customization
    is stored in Amazon S3, but is never retained in the service-managed account,
    eliminating the possibility of accidental leaks, unauthorized access, or misuse
    by third parties, including model vendors or AWS itself. The only information
    stored pertains to operational metrics, such as usage data for billing purposes
    and metadata necessary for console functionality.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Encryption**: When it comes to encrypting data, Amazon Bedrock employs robust
    encryption protocols to safeguard the information. All the communications to,
    from, and within the service are encrypted in transit, with a minimum requirement
    of TLS 1.2 and a recommendation for TLS 1.3\. Additionally, Amazon Bedrock encourages
    the encryption of your customization training data stored in an Amazon S3 bucket
    and customized models using your own KMS keys, ensuring that only authorized parties
    with the correct credentials can access and utilize these resources.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**IAM**: Amazon Bedrock’s integration with AWS IAM empowers you with granular
    control over access privileges. You can selectively allow or deny access to specific
    models, specific API calls, model customization jobs, or Amazon Bedrock itself.
    This fine-grained access control ensures that only authorized personnel can interact
    with your resources, minimizing the risk of unauthorized access or accidental
    modifications.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Comprehensive monitoring and logging**: As we have seen in [*Chapter 11*](B22045_11.xhtml#_idTextAnchor207),
    transparency and auditability are essential components of data privacy and protection.
    Amazon Bedrock offers comprehensive monitoring and logging capabilities, so you
    can track usage metrics, build customized dashboards using Amazon CloudWatch,
    and monitor API activity through AWS CloudTrail. These features provide invaluable
    insights into your data’s usage, aiding in troubleshooting and ensuring compliance
    with regulatory requirements.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Compliance standards**: Amazon Bedrock is committed to meeting the industry
    standards with data privacy and protection. It has multiple accreditations, such
    as **GDPR** (**General Data Protection Regulation**), **HIPAA** (**Health Insurance
    Portability and Accountability Act**), **SOC** (**System and Organization Control**)
    **1**, **2** and **3**, **ISO** (**International Organization for Standardization**),
    **STAR** (**Security Trust Assurance and Risk**), and **PCI-DSS** (**Payment Card
    Industry Data Security Standard**). The comprehensive compliance posture enables
    you to leverage Amazon Bedrock with confidence, knowing that your data is protected
    and handled in accordance with industry best practices and regulatory mandates.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Next, let us look at protecting the data through data encryption.
  prefs: []
  type: TYPE_NORMAL
- en: Data encryption
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you have used AWS services before, you might be familiar with the **AWS Shared
    Responsibility Model**, where AWS manages and is responsible for securing underlying
    cloud infrastructure, and you are responsible for protecting the data and applications
    hosted on this infrastructure. If you would like to read through the AWS Shared
    Responsibility Model, you can go to [https://aws.amazon.com/compliance/shared-responsibility-model/](https://aws.amazon.com/compliance/shared-responsibility-model/).
  prefs: []
  type: TYPE_NORMAL
- en: 'When it comes to protecting the data, you can perform encryption on them using
    AWS KMS or you can also perform client-side encryption before writing to AWS resources.
    Let us look at the encryption of different resources that you can perform to safeguard
    your data:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Knowledge bases**: KMS can be used to encrypt data that is in transition
    for knowledge bases. During the creation or update of a data source, you can provide
    the KMS key ARN to encrypt the ingested data, ensuring the confidentiality of
    your knowledge base content. *Figure 12**.1* demonstrates **Advanced settings**
    that can be used for working with KMS.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 12.1 – KMS key for transient data storage](img/B22045_12_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.1 – KMS key for transient data storage
  prefs: []
  type: TYPE_NORMAL
- en: As shown in the preceding figure, when you create or update the data source
    of a knowledge base, you can specify whether to use the default AWS-managed KMS
    key or **Customize encryption settings** where you choose your own customer-managed
    KMS key. Encryption for knowledge bases can happen at various stages. During the
    data ingestion phase, Bedrock employs the KMS encryption key to secure the transient
    data storage. This temporary storage facilitates the secure ingestion of your
    data sources, ensuring that your information remains protected while in transition.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you set up OpenSearch as a vector index for knowledge bases, the information
    passed to this service is also encrypted using a KMS key, providing an additional
    layer of security. Furthermore, Bedrock extends its encryption capabilities to
    the following resources associated with your knowledge bases:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Data in S3 bucket**: By encrypting these sources with a KMS key, you can
    be assured that your valuable data remains confidential and inaccessible to unauthorized
    parties.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can allow Amazon Bedrock to decrypt the data from the S3 bucket by attaching
    the following IAM policy to the Amazon Bedrock service role:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Please note that you would need to update the resource in the policy with the
    ARN of the KMS key.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Third-party vector stores**: If you leverage external vector stores, Bedrock
    allows you to encrypt them using a KMS key, maintaining the security and integrity
    of your knowledge bases across multiple platforms.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For more details and the IAM permissions needed for knowledge base resources,
    you can check out [https://docs.aws.amazon.com/bedrock/latest/userguide/encryption-kb.html](https://docs.aws.amazon.com/bedrock/latest/userguide/encryption-kb.html).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Model customization**: When it comes to creating model customization resources,
    it is essential to understand how the platform handles the data during the process.
    Firstly, Amazon Bedrock does not use the training data to improve the base FMs
    and is also never accessible by any of the model providers. When creating the
    customization job, Amazon Bedrock creates a copy of the FM, and your data is used
    to fine-tune that copied model. Importantly, your training data is not used to
    train the base FMs themselves, nor it is shared or seen by model providers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Additionally, Amazon Bedrock takes measures to protect the confidentiality of
    your data. Once the fine-tuning process is completed, your training or validation
    data is not stored by the service. However, it’s worth noting that fine-tuned
    models may inadvertently reproduce portions of the training data during output
    generation. To mitigate this risk, it’s recommended to filter out any sensitive
    or confidential information from your training data before initiating the customization
    process.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Regarding the encryption options for customization jobs, by default, custom
    models are encrypted using AWS managed KMS key. Alternatively, you can use your
    own customer-managed KMS key, which provides more control over your data encryption.
    To use a customer-managed key, you would need to create the key, attach a resource-based
    policy granting appropriate permissions, and specify the key when creating the
    customization job:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This policy grants specific permissions related to KMS key management for two
    different roles: `account-id` and `user/role` placeholders with your actual AWS
    account ID and the appropriate IAM user or role names.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Bedrock agent encryption**: Regarding Agents for Amazon Bedrock, by default,
    an AWS-managed key is used by Amazon Bedrock. However, you can encrypt the agent
    resources with your own customer-managed key.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'First, you would need to attach an identity-based policy, such as the following,
    to the IAM user or the role, so Amazon Bedrock can perform encryption/decryption
    on the Bedrock agent resources:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In addition, make sure the KMS key has permissions as mentioned in the following
    link: https://docs.aws.amazon.com/bedrock/latest/userguide/encryption-agents.html.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Guardrails encryption**: By default, Amazon Bedrock uses an AWS-managed encryption
    key to protect your guardrails. However, you have the option to use your own customer-managed
    KMS key for enhanced control and customization. To create a customer-managed KMS
    key for your guardrail, you’ll need to have the necessary permissions in your
    AWS account. For more details on what permissions you would need to set after
    creating the customer-managed key, you can check out the following link: https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails-permissions.html.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that we have looked at the encryption options for Amazon Bedrock, let us
    look at how we can grant users and AWS resources required permissions to Amazon
    Bedrock.
  prefs: []
  type: TYPE_NORMAL
- en: AWS IAM
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Using IAM, you can provide secure access to only designated users or resources
    to Amazon Bedrock and its capabilities. IAM allows you to create user accounts
    and assign permissions to those accounts, determining what actions they can perform
    on specific resources. Here are some of the key points on how IAM works with Amazon
    Bedrock:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Identities**: IAM supports various types of identities, including IAM users,
    groups, and roles. Users represent individual people or applications, groups are
    collections of users, and roles are assumed by trusted entities to gain temporary
    access.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Authentication**: To use Amazon Bedrock securely, you must first prove your
    identity through authentication. This can be achieved by logging in as an AWS
    root user, an IAM user, or by assuming an IAM role. Additionally, you can authenticate
    using external identities, such as **SAML** (**Security Assertion Markup Language**)
    authentication **identity providers** (**IdPs**). These external identities are
    passed to IAM, which then grants you access to Amazon Bedrock. Your administrator
    will have set up special roles to enable this access.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Alternatively, you can use social media accounts, such as Google or Facebook,
    to authenticate and gain access to Amazon Bedrock. Again, your administrator will
    have configured the necessary roles and permissions to allow this form of authentication.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`bedrock`. For example, the actions can be `bedrock:InvokeModel` or `bedrock:InvokeModelWithResponseStream`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Policy resources**: Policies can specify Bedrock resources using ARNs to
    grant or deny access.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Policy condition keys**: Condition keys add an extra layer of control, allowing
    you to specify conditions under which a policy is applicable, such as resource
    tags.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cross-account access**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Roles can be used to grant access to Bedrock resources across different AWS
    accounts
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Forward access sessions** (**FAS**) enable Bedrock to perform actions in
    other services on your behalf while maintaining your permissions*   **Service
    roles**: Bedrock uses service roles, which are IAM roles that Bedrock assumes
    to perform actions on your behalf.*   **Temporary credentials**: Bedrock supports
    the use of temporary credentials, which are short-lived access keys that provide
    temporary access to AWS resources, ensuring enhanced security compared to long-term
    access keys. These credentials are automatically generated when you sign in to
    the AWS Management Console using methods such as **single sign-on** (**SSO**)
    or role switching. Alternatively, you can manually create temporary credentials
    using the AWS CLI or API, allowing you to access AWS resources without exposing
    your long-term access keys.*   **Attribute-based access control (ABAC)**: It’s
    a flexible approach to granting access permissions based on attributes or tags
    associated with users, roles, and resources. Instead of relying solely on predefined
    roles or groups, ABAC allows you to define access rules that consider dynamic
    attributes. For example, you could grant read access to a specific AWS S3 bucket
    only to users with a particular department tag, ensuring that data access is restricted
    based on the user’s organizational context. ABAC simplifies access management
    in rapidly evolving environments by eliminating the need for complex policy configurations.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: By understanding and properly configuring IAM for Amazon Bedrock, you can ensure
    that only authorized individuals and applications have access to your resources,
    minimizing the risk of data breaches and unauthorized access.
  prefs: []
  type: TYPE_NORMAL
- en: Let us look at some of the patterns of IAM policies that can be used with Amazon
    Bedrock.
  prefs: []
  type: TYPE_NORMAL
- en: Deny access
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'With IAM, you can allow or deny access to perform actions to the model. For
    example, a user or a role could be denied invocation to a particular model, but
    they can list the models:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: The preceding IAM policy shows the `Deny` action, where the invocation to a
    specific model has been denied. For instance, the infrastructure team may be granted
    the ability to provision computational capacity for a particular model while being
    restricted from performing inferences on that same model. Conversely, the data
    science team could be solely permitted to perform inferences on a pre-approved
    set of models.
  prefs: []
  type: TYPE_NORMAL
- en: Principle of least privilege
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The `dev`) team is working on a project where access is only needed for image-generation
    models and listing any FMs. You can then apply the following policy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: In this policy, the `bedrock:InvokeModel` action is allowed on the `arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-image-generator-v1`
    resource with the condition that the `Env` resource tag is set to `Dev`. Secondly,
    the `bedrock:ListFoundationModels` action is allowed on all resources (`*`) with
    the condition that the `Env` resource tag is set to `Dev`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The principle of least privilege minimizes the potential attack surface and
    reduces the risk of unintended access or data breaches. Let us look at the best
    practices and implementation steps to help you audit access and enforce the principle
    of least privilege:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Review and analyze** **access patterns**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Regularly review AWS CloudTrail logs to understand the actions performed by
    users and resources within your environment
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Use tools such as IAM Access Analyzer to generate policies based on actual usage
    patterns, ensuring that permissions align with real-world requirements
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Leverage IAM access advisor to identify unused permissions and remove them from
    policies, reducing the attack surface
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Implement granular** **permissions policies**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create fine-grained permissions policies that grant only the necessary actions
    and resources required for specific job roles or functions
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Consider using AWS-managed policies as a starting point for common job functions,
    and then customize them as needed
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Regularly review and trim overly permissive policies to adhere to the principle
    of least privilege
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Limit access to** **production environments**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ensure that users have limited access to production environments, granting access
    only when there is a valid use case
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Revoke production access promptly after the user completes the specific tasks
    requiring that level of access
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Leverage** **permissions boundaries**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implement permissions boundaries, which are managed policies that set the maximum
    permissions an identity-based policy can grant to an IAM entity
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Use permissions boundaries to enforce organizational-wide access controls and
    prevent unintended privilege escalation
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Utilize resource tags for** **access control**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implement an ABAC model using resource tags, which allows you to grant access
    based on resource attributes such as purpose, owner, or environment
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Combine resource tags with permissions policies to achieve fine-grained resource
    access without overly complex custom policies
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Implement service control policies in** **AWS Organizations**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use service control policies to centrally control the maximum available permissions
    for member accounts within your AWS organization
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Restrict root user permissions in member accounts using service control policies
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Consider using AWS Control Tower for prescriptive managed controls and defining
    your own custom controls
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Establish user life** **cycle policies**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Define and implement user life cycle policies that outline tasks to be performed
    when users are onboarded, change roles, or no longer require access to AWS
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Conduct periodic permission reviews during each step of the user life cycle
    to prevent permissions creep
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Schedule regular** **permission audits**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Establish a regular schedule to review user permissions and remove any unneeded
    or excessive permissions
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Leverage tools such as AWS Config and IAM Access Analyzer to assist in auditing
    user permissions and identifying potential issues
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Develop a job** **role matrix**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create a job role matrix that visualizes the various roles and access levels
    required within your AWS footprint
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Use groups to separate permissions based on user responsibilities within your
    organization, rather than applying permissions directly to individual users or
    roles
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: By following these best practices and implementing the necessary steps, you
    can effectively audit access and ensure that the principle of least privilege
    is enforced.
  prefs: []
  type: TYPE_NORMAL
- en: Model customization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When working with model customization, Amazon Bedrock needs to assume an AWS
    IAM role on your behalf to initiate the fine-tuning job. This requires you to
    establish a trust relationship between Amazon Bedrock and the IAM role you want
    to use.
  prefs: []
  type: TYPE_NORMAL
- en: To set up this trust relationship, you need to add a trust policy to the IAM
    role you wish to use for model customization. The trust policy grants Amazon Bedrock
    permission to assume the role and perform the necessary actions on your behalf.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s an example of the trust policy you need to add to your IAM role:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: This trust policy specifies that the AWS service bedrock.amazonaws.com (which
    represents Amazon Bedrock) is allowed to assume the role by calling the `sts:AssumeRole`
    action.
  prefs: []
  type: TYPE_NORMAL
- en: 'To add this trust policy to your IAM role, you can follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Open the AWS Management Console and navigate to the IAM service.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the left navigation pane, click **Roles**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Find the role you want to use for model customization or create a new role if
    needed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on the role name to open the role details.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the **Trust relationships** tab, click the **Edit trust** **policy** button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Replace the existing policy document with the provided trust policy.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click the **Update policy** button to save the changes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: By adding this trust policy, you establish a secure trust relationship between
    Amazon Bedrock and your IAM role, allowing Amazon Bedrock to assume the role and
    perform the necessary actions for model customization on your behalf.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, the necessary permissions required for the customization process involve
    accessing the training and validation data that is stored in the S3 bucket, and
    the output path where Amazon Bedrock should deliver the results of the fine-tuning
    job. To learn more about the permissions needed for model customization, you can
    go through the following link: https://docs.aws.amazon.com/bedrock/latest/userguide/model-customization-iam-role.html.'
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have looked at patterns of IAM policies needed for Amazon Bedrock,
    let us look at the aspect of network security.
  prefs: []
  type: TYPE_NORMAL
- en: Securing the network
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous sections, we looked at the data encryption techniques. Another
    measure to safeguard the data from a network perspective is to use **Amazon VPC**
    for model customization and creating a secure, isolated environment for your workloads.
    By doing so, you gain granular control over network traffic, enabling you to monitor
    and regulate all incoming and outgoing data flows using VPC Flow Logs. The following
    figure shows the VPC settings that you can specify while creating the fine-tuning
    or continued pre-training job.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.2 – VPC settings](img/B22045_12_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.2 – VPC settings
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, Amazon Bedrock integrates with AWS **PrivateLink**, so you can
    establish a private connection between your VPC and the Amazon Bedrock service.
    This connection is facilitated through the creation of a VPC interface endpoint,
    essentially a private entry point for traffic destined for Amazon Bedrock. In
    addition, Amazon Bedrock does not use public IP addresses or internet gateways,
    ensuring that your data never traverses the public internet, thus minimizing potential
    exposure to cyber threats.
  prefs: []
  type: TYPE_NORMAL
- en: To enhance security even further, you can implement endpoint policies, which
    are permissions that can be attached to your VPC interface endpoint. These policies
    enable you to precisely define the principals (AWS accounts, IAM users, and IAM
    roles) authorized to perform specific actions on designated resources. By crafting
    custom endpoint policies, you can exercise fine-grained control over the access
    granted to Amazon Bedrock from within your VPC, effectively hardening your security
    posture.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example VPC endpoint policy that grants access to anyone (`"Principal":
    "*"`) to perform `InvokeModel` and `InvokeModelWithResponseStream` of Bedrock:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: Now, let us look at what network flow looks like behind the scenes.
  prefs: []
  type: TYPE_NORMAL
- en: Network flow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have looked at how the encryption with Amazon works and how you can secure
    the network via AWS PrivateLink when you are in Amazon VPC. Now, let us look at
    the network and data flow work behind the scenes for both invocation and model
    customization jobs.
  prefs: []
  type: TYPE_NORMAL
- en: On-demand architecture
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With on-demand mode, you share the compute environment of the model with other
    users and are billed based on the usage, without any long-term commitments. *Figure
    12**.3* shows the overview of the on-demand network architecture employed by Amazon
    Bedrock.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.3 – On-demand compute environment architecture](img/B22045_12_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.3 – On-demand compute environment architecture
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us understand the figure in detail:'
  prefs: []
  type: TYPE_NORMAL
- en: In the middle, we have **Amazon Bedrock service account**, which acts as the
    entry point for all incoming requests. This account is managed and controlled
    by Amazon, ensuring secure and reliable access to the service. The Amazon Bedrock
    service is responsible for handling these incoming requests and routing them to
    the appropriate runtime inference environment. This environment is designed to
    process and execute the requested operations on the deployed models.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: On the right, we have **Model deployment account**, which is owned and operated
    by Amazon. Interestingly, there is one such account for each model provider and
    AWS region combination. This segregation ensures that no model vendor can access
    or tamper with the data or models of other vendors, enhancing security and privacy.
    Within the **Model deployment account**, we find the on-demand compute resources,
    which are dynamically provisioned and scaled based on the incoming workload. Additionally,
    this account hosts the base model in S3 bucket, which stores these FMs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The flow of an inference request is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: A user initiates a request, which is received by the API endpoint of the Amazon
    Bedrock service account.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The request is authenticated and authorized using the AWS IAM service.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once validated, the request is forwarded to the runtime inference environment.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The runtime inference component interacts with the relevant compute cluster
    within the model deployment account, fetching the required model and executing
    the requested operation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The result is then securely returned to the user via the Amazon Bedrock service
    account.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Throughout this process, several measures are in place to ensure data security
    and privacy:'
  prefs: []
  type: TYPE_NORMAL
- en: All internal traffic is encrypted using TLS 1.2 or higher encryption standards
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: No customer data is stored or persisted within the Amazon Bedrock service account
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Detailed logs and audit trails are maintained using AWS CloudTrail and Amazon
    CloudWatch services
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Model providers, including Amazon’s own models like Titan, cannot access or
    influence the customer’s data or models within the model deployment account
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, let us look at provisioned throughput capacity architecture.
  prefs: []
  type: TYPE_NORMAL
- en: Provisioned throughput architecture
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Provisioned throughput allows you to purchase the model units for base or customized
    models, designed for large-scale inference workloads requiring guaranteed throughput.
  prefs: []
  type: TYPE_NORMAL
- en: '**Model units** are a key concept in Amazon Bedrock’s provisioned throughput
    feature, designed to provide consistent and scalable performance for LLM inference.
    One can think of a model unit as a representation of fraction of the underlying
    GPU hardware resources allocated to run a specific model. It’s not a standardized
    measure across all models, but rather model-specific.'
  prefs: []
  type: TYPE_NORMAL
- en: These model units are purchased allocations of computational resources for a
    specific base model in Amazon Bedrock. Each model unit provides a guaranteed level
    of throughput, measured in tokens processed per minute. This applies to both input
    and output tokens. By using model units, you can ensure consistent performance
    for high-volume AI workloads, with the flexibility to scale resources based on
    your needs.
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 12**.4* shows the overview of the provisioned throughput architecture
    employed by Amazon Bedrock.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.4 – Provisioned throughput compute architecture](img/B22045_12_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.4 – Provisioned throughput compute architecture
  prefs: []
  type: TYPE_NORMAL
- en: 'Similar to the on-demand architecture, we have **Amazon Bedrock service account**
    acting as the entry point for incoming requests. This account is managed by Amazon,
    ensuring secure access to the service. Here is a breakdown of the preceding figure:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Within the **Model deployment account**, we find two distinct components: the
    **Base model S3 bucket** and the **Customized model S3 bucket**. The base model
    bucket stores the base models provided by Amazon and other vendors like AI21,
    Cohere, etc., while the customized model S3 bucket stores the custom models or
    copies of the baseline models tailored to individual requirements.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **Runtime inference** component is responsible for processing the incoming
    requests and determining the appropriate compute environment to handle the requested
    operation. This decision is based on whether the request is for a baseline model
    or a customized model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The inference can be performed on provisioned throughput mode by called `InvokeModel`
    API or `InvokeModelWithResponseStream` API and specifying the `modelId` as provisioned
    throughput model ARN. The flow of an inference request for a provisioned capacity
    compute environment is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: A customer initiates a request, which is received by the API endpoint of the
    Amazon Bedrock service account.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The request is authenticated and authorized using AWS IAM services.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once validated, the request is forwarded to the runtime inference component.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The runtime inference component analyzes the request and determines whether
    it is for a baseline model or a customized model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the request is for a customized model, the runtime inference component directs
    the request to the dedicated provisioned throughput compute environment associated
    with that customer or model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The provisioned throughput compute environment executes the requested operation
    on the specified customized model and returns the result.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The computed result is then securely returned to the customer via the Amazon
    Bedrock service account.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The provisioned capacity architecture shares several key features with the
    on-demand architecture, including the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Encrypted internal traffic using TLS 1.2 or higher encryption standards
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: No customer data storage or persistence within the Amazon Bedrock service account
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Detailed logging and auditing through AWS CloudTrail and Amazon CloudWatch services
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Strict isolation and access controls, ensuring that model providers cannot access
    or influence customer data or models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: From a developer’s perspective, the process of invoking a baseline model or
    a customized model is seamless if you are using on-demand or provisioned throughput
    mode.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let us look at the architecture overview of model customization.
  prefs: []
  type: TYPE_NORMAL
- en: Model customization architecture
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Model customization is where we are either fine-tuning or continued pre-training
    the base model tailored to the domain specific use-case. *Figure 12**.5* provides
    an overview of the model customization architecture employed by Amazon Bedrock.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.5 – Model customization architecture](img/B22045_12_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.5 – Model customization architecture
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us look at the steps:'
  prefs: []
  type: TYPE_NORMAL
- en: The process begins with the user initiating a request through the API endpoint
    of the Amazon Bedrock service account. This account is managed by Amazon and serves
    as a secure entry point for all incoming requests.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Amazon Bedrock service account routes the request to the training orchestration
    component, which orchestrates the customization process within the relevant model
    deployment account owned and operated by Amazon.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The training orchestration component initiates an Amazon SageMaker training
    job, which is responsible for the actual model customization process. Amazon SageMaker
    is an AWS ML service, where you can build, train, deploy, and monitor ML models.
    If you are interested in learning about SageMaker, here is an interesting book
    by Julien Simon: *Learn Amazon SageMaker: A guide to building, training, and deploying
    machine learning models for developers and data scientists*, available at https://www.amazon.com/Learn-Amazon-SageMaker-developers-scientists/dp/180020891X.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The training job in the model deployment account leverages the following resources:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The base model S3 bucket, which stores the baseline models provided by Amazon
    and other vendors from Meta, Cohere, and AI21.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The user’s training data, which is securely retrieved from an S3 bucket within
    the user’s account, optionally via a VPC connection for enhanced security.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: During the training process, the user’s training data is used to customize the
    selected base model, creating a tailored version specific to your requirements.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Upon completion of the training job, the customized model is encrypted and stored
    in the customized model S3 bucket within the model deployment account.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It’s important to note that at no point do model vendors have access to or visibility
    into the user’s training data or the resulting customized model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Additionally, the training job generates output metrics and logs, which are
    securely delivered to an S3 bucket specified by the user during the initial request.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The model customization architecture incorporates several security and privacy
    measures:'
  prefs: []
  type: TYPE_NORMAL
- en: Strict access controls and isolation ensure that model vendors cannot access
    your data or customized models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Your training data is securely retrieved from your account, either directly
    from an S3 bucket or via a VPC connection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Encryption is employed to protect the customized model during storage and transfer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Detailed logging and auditing are provided through CloudTrail, IAM, and CloudWatch
    services
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By leveraging this architecture, Amazon Bedrock allows you to tailor the base
    models to your specific needs while maintaining strict data privacy and security
    standards. The separation of responsibilities and the secure data handling mechanisms
    ensure that sensitive information remains protected throughout the customization
    process. For a more detailed exploration of how to adapt models to your unique
    requirements, please refer to [*Chapter 4*](B22045_04.xhtml#_idTextAnchor073).
  prefs: []
  type: TYPE_NORMAL
- en: Now, that we have looked at the security and network flow components, let us
    look at ethical practices, where we cover challenges and risks with GenAI.
  prefs: []
  type: TYPE_NORMAL
- en: Ethical practices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There have been rapid advancements in GenAI, but at the same time, they raise
    new challenges and risks. Some of these are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Would my data be used with the provider?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Could it hurt the legal rights of the company?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Will the model hallucinate and provide non-sensical, biased, or factually incorrect
    responses in production?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Would the GenAI models inadvertently use or reproduce intellectual property,
    such as copyrighted text or images, during training or generation?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let us cover these challenges and best practices that can be adopted.
  prefs: []
  type: TYPE_NORMAL
- en: Veracity
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Veracity**, or the truthfulness and accuracy of information generated by
    AI models, is a crucial aspect of ethical practices in the field of GenAI. When
    models produce outputs that are verifiably false or hallucinated, it can lead
    to the spread of misinformation and undermine trust in the technology. One common
    example of hallucinations is when an AI model is asked to provide information
    about a specific topic, such as academic papers by a particular author. Instead
    of searching for and retrieving actual citations, the model will tend to generate
    fictitious paper titles, topics, and co-author names that seem plausible but do
    not correspond to real published works.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To mitigate the risk of hallucinations and improve veracity, several best practices
    can be employed:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Prompt engineering**: Providing clear and specific instructions to the AI
    model can help guide it toward generating more accurate and truthful outputs.
    Well-crafted prompts that clearly define the desired output and provide relevant
    context can reduce the likelihood of hallucinations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Providing more context**: Techniques such as RAG, continued pre-training,
    fine-tuning, and the use of agents can help ground the model’s outputs in factual
    information by providing additional context and knowledge from external sources.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Inference parameter tuning**: Adjusting parameters such as temperature, Top
    P, and Top K, which control the randomness of the model’s outputs, can help strike
    a balance between creativity and factual accuracy, reducing the likelihood of
    hallucinations while still allowing for novel and useful generations. If you would
    like to learn more about these parameters, please go through [*Chapter 2*](B22045_02.xhtml#_idTextAnchor034).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By implementing these best practices and continuously validating the veracity
    of AI-generated content, we can promote trust in GenAI models and ensure their
    responsible and ethical deployment in various domains.
  prefs: []
  type: TYPE_NORMAL
- en: Intellectual property
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'One major challenge with early LLMs is their tendency to directly repeat or
    copy portions of the text data they were trained on. This raises privacy concerns,
    as the training data may contain sensitive or personal information. It also raises
    copyright issues, as the models could be reproducing copyrighted content without
    permission. The root cause of this problem lies in how these LLMs are trained.
    They are exposed to massive amounts of data from various sources, including books,
    websites, and databases, many of which are copyrighted works. However, this data
    is ingested without keeping track of sources or obtaining proper licenses. As
    a result, when generating text, the models may regurgitate verbatim sentences
    or passages from their training data, inadvertently exposing copyrighted content
    or private information. Addressing this requires more robust techniques for filtering
    training data, tracking sources, and properly licensing materials used to train
    these powerful language models. Here are some of the key considerations:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Transparency**: AI providers should be transparent about the training data
    used for their models, disclosing potential sources of copyrighted material, and
    acknowledging the limitations of their systems in handling intellectual property.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fair use**: While some use of copyrighted material for training AI models
    may fall under fair use exceptions, it is essential to carefully assess the extent
    and nature of such use to avoid potential infringement.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Licensing and permissions**: Whenever possible, AI developers should obtain
    appropriate licenses or permissions to use copyrighted material in their training
    data, ensuring proper attribution and compensation to the rights holders.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Content filtering**: Implementing robust content filtering mechanisms can
    help mitigate the risk of reproducing copyrighted material in the outputs of AI
    systems. This can involve techniques such as watermarking, fingerprinting, and
    other content recognition technologies.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Human oversight**: Incorporating human oversight and review processes can
    help identify and address potential instances of copyright infringement or unauthorized
    use of intellectual property in the outputs of AI systems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Safety and toxicity
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Toxicity and safety are also important considerations when developing and deploying
    AI systems, particularly those involving language generation models. Toxic outputs
    can perpetuate harm, spread misinformation, and undermine the trust and integrity
    of these systems. Therefore, implementing robust measures to mitigate toxicity
    and uphold safety is necessary. Here are some key points to address these concerns:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Content filtering**: Implementing strict filters to exclude advice or information
    related to individual medical, legal, political, or financial matters, as well
    as instructions for creating weapons or engaging in illegal activities, is essential.
    Such content could potentially cause direct harm or enable dangerous behavior
    if provided without proper oversight.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Guardrails**: Implementing guardrails, such as content filtering, bias detection,
    and toxic language identification, can help prevent the generation of harmful
    or inappropriate content. Continuously monitoring and updating these guardrails
    is necessary to adapt to evolving language patterns and potential misuse. In the
    next section, we will be covering the guardrails provided by Amazon Bedrock.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data curation**: Carefully curating and vetting the training data used for
    language models to minimize the propagation of biases, toxic language, or factual
    inaccuracies. Performing regular audits and updates to the training data can help
    improve model performance and safety over time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Watermarking and traceability**: Embedding watermarks or traceable identifiers
    within generated content can aid in attribution and accountability, discouraging
    misuse and enabling rapid response to incidents involving toxic or harmful content.
    For more details on watermark detection by Amazon Bedrock, refer to [*Chapter
    9*](B22045_09.xhtml#_idTextAnchor171).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Responsible AI policies**: Organizations should implement and establish robust
    responsible AI policies, guidelines, and best practices. These policies should
    prioritize ethical considerations, transparency, accountability, and the well-being
    of users and society.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We would recommend that you read through the blog post titled *Responsible
    AI in the generative era* by Michael Kearns: [https://www.amazon.science/blog/responsible-ai-in-the-generative-era](https://www.amazon.science/blog/responsible-ai-in-the-generative-era).
    This blog post talks about the challenges around issues such as fairness, toxicity,
    hallucinations, intellectual property violations, and so on, and the active work
    being done by the tech community to address these challenges, from carefully curating
    training data, developing guardrail models to filter outputs, watermarking approaches,
    and leveraging more focused use cases.'
  prefs: []
  type: TYPE_NORMAL
- en: Let us now look at the guardrails provided by Amazon Bedrock to address some
    of the concerns we discussed.
  prefs: []
  type: TYPE_NORMAL
- en: Guardrails for Amazon Bedrock
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'With Guardrails for Amazon Bedrock, organizations can implement safeguards
    that align with safe and responsible AI policies. These safeguards provide an
    additional layer of control, complementing the existing protections built in the
    FMs. You can implement these guardrails to all the FMs available within Amazon
    Bedrock, along with any fine-tuned models and Agents for Amazon Bedrock that you
    create. Let us look at some of the examples when the implementation of guardrails
    will be required by various industries:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Healthcare industry**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Guardrails can be used in medical chatbots or virtual assistants to prevent
    the exchange of information related to self-diagnosis, prescription drugs, or
    medical advice without proper authorization
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: In applications that analyze medical records or imaging data, guardrails can
    be employed to redact sensitive patient information and ensure compliance with
    privacy regulations such as HIPAA
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Legal industry**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Guardrails can be used in legal document analysis tools to prevent the disclosure
    of privileged communication between attorneys and clients
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: In legal research or contract review applications, guardrails can be implemented
    to prevent the generation of misleading or legally non-compliant content
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Financial industry**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Guardrails can be used in financial applications to prevent the generation of
    content related to stock recommendations, investment advice, or insider trading
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: In applications that process financial transactions or customer data, guardrails
    can be used to redact sensitive information like account numbers or credit card
    details
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Media and** **entertainment industry**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Guardrails can be used in content generation applications to prevent the creation
    of copyrighted material, hate speech, or explicit content that may violate content
    guidelines or community standards
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: In applications related to broadcast media, guardrails can be implemented to
    ensure adherence to strict regulatory guidelines, protect against copyright infringement,
    and maintain appropriate content standards
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Retail and** **e-commerce industry**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Guardrails can be implemented in e-commerce platforms to protect customer privacy
    by redacting personal information and preventing the unauthorized access or display
    of sensitive data such as payment details or shipping addresses
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: In product recommendation or customer service applications, guardrails can be
    used to prevent the promotion of harmful or illegal products, ensuring compliance
    with local regulations and industry standards
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, let us understand how Guardrails for Amazon Bedrock works.
  prefs: []
  type: TYPE_NORMAL
- en: How does Guardrails for Amazon Bedrock work?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Guardrails examines both the user input prompts and the corresponding model
    responses via four policy filters, as shown in *Figure 12**.6*.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.6 – How Guardrails for Amazon Bedrock works](img/B22045_12_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.6 – How Guardrails for Amazon Bedrock works
  prefs: []
  type: TYPE_NORMAL
- en: 'Guardrails for Amazon Bedrock is available under the **Safeguards** section
    of the Bedrock console. When you create a guardrail, you will be asked to configure
    four policy filters and a blocked message. The four policy filters in Guardrails
    for Amazon Bedrock are listed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Content filters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Denied topics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Word filters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sensitive information filters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Based on the policy filter that you select, both input prompts and model responses
    are rigorously vetted against every configured policy.
  prefs: []
  type: TYPE_NORMAL
- en: If any policy violation is detected, either in the input prompt or response,
    the Guardrails component intervenes by overriding the offending content. For more
    details, please check the *Blocked* *messaging* sub-section.
  prefs: []
  type: TYPE_NORMAL
- en: Let us dive deeper into each of the policy filters.
  prefs: []
  type: TYPE_NORMAL
- en: Content filters
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With **content filters**, you can configure thresholds to detect and block harmful
    content across various categories. You can adjust the filter strength for prompts
    and for responses enabling granular control over the strictness of content filtering,
    as shown in *Figure 12**.7*.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.7 – Configuring content filters](img/B22045_12_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.7 – Configuring content filters
  prefs: []
  type: TYPE_NORMAL
- en: Categories covered include hate speech, insults, sexual content, violence, misconduct,
    and prompt attacks, allowing you to address a wide range of potential risks. The
    higher the filter strength, the higher the likelihood of filtering out potentially
    harmful content within a given category, providing a flexible way to balance risk
    mitigation and content accessibility.
  prefs: []
  type: TYPE_NORMAL
- en: When implementing content filters, it’s essential to consider your use case,
    target audience, and ethical guidelines. A higher filter strength may be appropriate
    for applications serving vulnerable populations or dealing with sensitive topics,
    while a more relaxed approach could be suitable for certain creative or educational
    contexts. In addition, regularly reviewing and updating your filter configurations
    in response to evolving societal norms and organizational policies is recommended.
    By leveraging content filters, you can proactively mitigate the risks associated
    with harmful content generation, encouraging a more trustworthy and responsible
    AI ecosystem.
  prefs: []
  type: TYPE_NORMAL
- en: Denied topics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Denied topics** allow you to proactively prevent your application from engaging
    with or generating content related to specific subjects that may be deemed undesirable
    or inappropriate within your use case.'
  prefs: []
  type: TYPE_NORMAL
- en: You can define up to 30 denied topics by providing a concise name and a clear
    natural language description for each topic you wish to restrict. These serve
    as the foundation for detecting and blocking user inputs or model responses that
    fall within the defined topic boundaries, ensuring a consistent and reliable filtering
    mechanism.
  prefs: []
  type: TYPE_NORMAL
- en: When specifying a denied topic, it’s advisable to provide a comprehensive definition
    that captures the essence of the subject matter you aim to exclude, surrounding
    all relevant inquiries, guidance, or recommendations.
  prefs: []
  type: TYPE_NORMAL
- en: For example, in the healthcare domain, maintaining patient privacy and adhering
    to strict ethical guidelines is important. A hospital or medical institution could
    leverage denied topics to prevent the models from engaging in discussions or providing
    information related to specific topics that could potentially violate patient
    confidentiality or medical ethics.
  prefs: []
  type: TYPE_NORMAL
- en: One denied topic could be *Disclosing Patient Information*, with a definition
    along the lines of *Sharing or revealing personal details, medical records, or
    any identifying information about patients without* *proper authorization*.
  prefs: []
  type: TYPE_NORMAL
- en: Another relevant denied topic might be *Unauthorized Medical Advice*, defined
    as *Providing diagnostic assessments, treatment recommendations, or any form of
    medical guidance without being a licensed healthcare professional or having access
    to a patient’s complete* *medical history*.
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 12**.8* shows how to add denied topics.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.8 – Adding a denied topic](img/B22045_12_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.8 – Adding a denied topic
  prefs: []
  type: TYPE_NORMAL
- en: Word filters
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'By configuring **word filters**, you can effectively block undesirable words,
    phrases, and profanity from appearing in user inputs or model responses, promoting
    a positive and inclusive user experience. Here is how:'
  prefs: []
  type: TYPE_NORMAL
- en: The **profanity filter** offers a convenient way to block a predefined list
    of commonly recognized profane words. This list is based on a global definition
    of profanity and is subject to regular updates, ensuring that the filter remains
    aligned with evolving societal norms.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Additionally, you can customize the word filtering experience by specifying
    up to 10,000 custom words and phrases that should be blocked. This flexibility
    allows you to tailor the filters to your specific needs, such as excluding offensive
    terms, competitor names, or any other language that may be deemed inappropriate
    for your use case.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Custom words and phrases can be added through various convenient methods, including
    a manual entry in the console, uploading a local file (e.g., `.txt` or `.csv`),
    or populating the list from an Amazon S3 object, providing flexibility in managing
    your word filter list.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Figure 12**.9* shows how you can configure the word filter with different
    options.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.9 – Adding word filters](img/B22045_12_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.9 – Adding word filters
  prefs: []
  type: TYPE_NORMAL
- en: By using word filters, you can create a more controlled and inclusive environment
    for your users. For instance, an educational platform could block offensive language
    to promote a positive learning atmosphere, while a corporate application might
    filter out competitor names to maintain brand integrity and avoid potential conflicts.
  prefs: []
  type: TYPE_NORMAL
- en: Sensitive information filters
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Sensitive information filters** allow you to proactively identify and take
    appropriate actions on various types of PII and custom-defined sensitive data
    patterns.'
  prefs: []
  type: TYPE_NORMAL
- en: Guardrails offer a comprehensive list of predefined PII types, covering a wide
    range of sensitive information such as names, addresses, email addresses, phone
    numbers, credit card details, and social security numbers. These PII types are
    constantly updated to ensure compliance with evolving regulations and privacy
    norms. For a complete list, you can visit [https://docs.aws.amazon.com/bedrock/latest/userguide/Guardrails-sensitive-filters.html](https://docs.aws.amazon.com/bedrock/latest/userguide/Guardrails-sensitive-filters.html).
  prefs: []
  type: TYPE_NORMAL
- en: 'When sensitive information is detected, you can configure guardrails to either
    block or mask the content:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Block mode**: This prevents the sensitive information from being processed
    at all. If applied to the input, it stops the prompt containing sensitive data
    from reaching the model. If applied to the output, it prevents the model’s response
    containing sensitive information from reaching the user.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`123-45-6789` might be replaced with `[SSN]`. This ensures privacy while preserving
    the overall context of the content.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Additionally, you can define custom **regular expression** (**regex**) patterns
    to filter specific types of sensitive information relevant to your organization
    or use case. This flexibility allows you to protect proprietary data, such as
    serial numbers, booking IDs, or any other critical information that requires safeguarding.
    For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '`^ABC-\d{5}-[A-Z]{2}$` (matches patterns such as `ABC-12345-XY`)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`^BK-\d{6}-[A-Z]{3}$` (matches patterns such as `BK-123456-NYC`)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`^EMP-\d{4}-[A-Z]{2}$` (matches patterns such as `EMP-1234-AB`)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These custom patterns can be used alongside the predefined PII types to create
    a comprehensive sensitive information protection strategy tailored to your specific
    needs.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.10 – Adding sensitive information filters](img/B22045_12_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.10 – Adding sensitive information filters
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 12**.10* shows the configuration options you can specify for sensitive
    information filters.'
  prefs: []
  type: TYPE_NORMAL
- en: By leveraging sensitive information filters, you can ensure that your applications
    maintain the highest standards of privacy and data protection. For instance, a
    healthcare provider could configure guardrails to mask patient information in
    summaries, while a financial institution could block queries related to credit
    card details or account numbers, mitigating the risk of data breaches and maintaining
    regulatory compliance.
  prefs: []
  type: TYPE_NORMAL
- en: Blocked messaging
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once we have defined the policy filters, you can then next define the blocked
    messaging, when the guardrail blocks any input prompt or response from the model.
    In such cases, a pre-approved response is provided, tailored to the specific use
    case or organizational guidelines. *Figure 12**.11* shows what messaging you would
    like to display for both input prompts and model responses.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.11 – Blocked messaging](img/B22045_12_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.11 – Blocked messaging
  prefs: []
  type: TYPE_NORMAL
- en: This approach ensures that the end user receives a safe, appropriate, and compliant
    response, even in scenarios where the initial input or model output raises concerns.
  prefs: []
  type: TYPE_NORMAL
- en: Testing and deploying guardrails
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'By testing the guardrail, you can iteratively refine and test the models, ensuring
    they align with your intended use case and adhere to ethical standards. Here’s
    how it works:'
  prefs: []
  type: TYPE_NORMAL
- en: First, you create a guardrail, which initializes a working draft (`DRAFT`) version.
    Think of this as a sandbox environment where you can experiment without impacting
    live systems. This working draft is something you can continuously edit and tweak
    until you’re satisfied with its performance.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.12 – Test Guardrails for Amazon Bedrock](img/B22045_12_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.12 – Test Guardrails for Amazon Bedrock
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 12**.12* shows the test results of the working draft. Here, I have
    taken a simple example of soccer, where I have provided `soccer` as a denied topic.
    When I provide a prompt pertaining to soccer, the model blocks the response. You
    can also see from the figure the prompt and model response trace.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you’ve perfected the working draft, you can create a version – a snapshot
    of the guardrail’s configurations at that point in time. Additionally, these versions
    function as immutable checkpoints in the system. This immutability serves a critical
    purpose: it prevents potential immediate negative impacts on the runtime environment
    that could occur if a draft version were accidentally deployed to production.
    For instance, if an engineer inadvertently made a modification to a draft version
    directly through the console interface, these immutable checkpoints would ensure
    that such changes don’t affect the live production environment. This safeguard
    helps maintain system stability and prevents unintended consequences from impromptu
    modifications.'
  prefs: []
  type: TYPE_NORMAL
- en: It’s important to note that any changes made to the working draft will automatically
    update the live application if the draft is being used in the application. You
    must explicitly incorporate the desired version into your application to reflect
    the latest guardrail configurations.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have created, tested and deployed guardrails, let us look at how
    we can use it.
  prefs: []
  type: TYPE_NORMAL
- en: Using guardrails
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Guardrails can be used in various ways:'
  prefs: []
  type: TYPE_NORMAL
- en: '`InvokeModel`, `InvokeModelWithResponseStream`, and `Converse` APIs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Knowledge base**: You can include guardrails when querying your knowledge
    base in the Amazon Bedrock console or via APIs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Guardrail to your agent**: Associate a guardrail with your agent when creating
    or updating an agent in the Amazon Bedrock console or API.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Figure 12**.13* shows the response with and without using Guardrails within
    Amazon Bedrock Playground.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.13 – Using Guardrails in Amazon Bedrock Playground](img/B22045_12_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.13 – Using Guardrails in Amazon Bedrock Playground
  prefs: []
  type: TYPE_NORMAL
- en: 'With Amazon Bedrock APIs, you can specify `guardrailIdentifier` and `guardrailIdentifier`
    as shown in the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: When running the preceding code, you can see that the response would be similar
    to what is shown in *Figure 12**.14*.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.14 – Response with Guardrails](img/B22045_12_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.14 – Response with Guardrails
  prefs: []
  type: TYPE_NORMAL
- en: You can see that the prompt provided in the code relates to medical treatment,
    for which we have configured Denied Topics filter in `Guardrail`. The code snippet
    includes `guardrailIdentifier` and `guardrailVersion` to enable Bedrock Guardrails,
    which can intervene and modify the model’s output based on the filter that is
    configured.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, when using a guardrail with model inference, you can selectively
    evaluate user input by tagging specific content within the input text. This feature
    allows you to apply guardrails to certain parts of the input while leaving other
    parts unprocessed.
  prefs: []
  type: TYPE_NORMAL
- en: For example, imagine you’re creating a conversational AI assistant for a banking
    application. While you want your assistant to provide helpful information to users,
    you also need to ensure it doesn’t reveal sensitive account details or encourage
    risky financial behavior. By selectively evaluating user input, you can apply
    guardrails to specific sections of the conversation, like user queries, while
    leaving system prompts and conversation history untouched.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s how you could implement this:'
  prefs: []
  type: TYPE_NORMAL
- en: Use input tags to mark user queries, for example, `<amazon-bedrock-guardrails-guardContent_abc>How
    much money is in my` `savings account?</amazon-bedrock-guardrails-guardContent_abc>`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configure a dynamic tag suffix (for example, `abc`) in the `amazon-bedrock-guardrailConfig`
    to prevent prompt injection attacks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Any content outside the tags such as system prompts and conversation history
    won’t be processed by guardrails.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For user queries within the tags, guardrails will ensure the AI assistant’s
    response doesn’t reveal sensitive financial information or promote irresponsible
    money management.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This approach not only enhances security and control but also optimizes performance
    and reduces costs, as guardrails only evaluate the tagged user input instead of
    the entire prompt.
  prefs: []
  type: TYPE_NORMAL
- en: When using guardrails with streaming responses, you can either configure it
    to **synchronous mode** or **asynchronous mode**. The synchronous mode introduces
    some latency as the guardrail buffers and applies policies to response chunks
    before sending them to the user, ensuring better accuracy. Alternatively, the
    asynchronous mode sends response chunks immediately while applying policies in
    the background, sacrificing accuracy for lower latency.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can enable asynchronous mode by including `"streamProcessingMode": "ASYNCHRONOUS"`
    in `amazon-bedrock-guardrailConfig`. Here is how:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'For conversational applications built with `Converse` API, you can use guardrails
    to block inappropriate content entered by the user or generated by the model.
    When calling the `Converse` or `ConverseStream` operations, include the guardrail
    configuration in the `guardrailConfig` parameter. Here is how:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is an example code on how you can guard the conversation by using guardrails
    on `Converse` API : [https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails-use-converse-api.html#converse-api-guardrail-example](https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails-use-converse-api.html#converse-api-guardrail-example).'
  prefs: []
  type: TYPE_NORMAL
- en: Guardrails for Amazon Bedrock is a feature that allows organizations to implement
    safeguards and policy filters to ensure the safe and responsible use of AI models.
    It provides four policy filters – content filters, denied topics, word filters,
    and sensitive information filters – to block or redact unwanted content, topics,
    words, and sensitive information from both user inputs and model outputs. Guardrails
    helps maintain compliance with regulations, protect user privacy, and prevent
    the generation of harmful or unethical content.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter began by emphasizing the importance of data privacy and protection
    for organizations in today’s digital landscape. It highlighted Amazon Bedrock’s
    robust security measures, which ensure that users maintain complete control over
    their data, along with key aspects such as data localization, isolation, encryption,
    and access management through IAM.
  prefs: []
  type: TYPE_NORMAL
- en: 'The chapter then dove deeper into responsible AI practices, addressing challenges
    such as veracity, intellectual property rights, safety, and toxicity. It provided
    guidance on implementing content filtering, guardrails, data curation, watermarking,
    traceability, and establishing robust responsible AI policies. Additionally, the
    chapter introduced Guardrails for Amazon Bedrock, which offers four policy filters:
    content filters, denied topics, word filters, and sensitive information filters.
    These filters enable organizations to implement safeguards aligning with their
    safe and responsible AI policies, promoting ethical AI deployment across various
    industries.'
  prefs: []
  type: TYPE_NORMAL
- en: Congratulations! You have reached the end of this book. By now, you have gained
    deep hands-on knowledge of Amazon Bedrock. From understanding the foundational
    concepts to practical implementations and real-world use cases, we have covered
    a wide range of topics that will provide you with the knowledge and skills to
    build scalable and innovative GenAI applications.
  prefs: []
  type: TYPE_NORMAL
- en: Throughout the chapters, we have explored the power of prompt engineering, continuous
    pre-training, fine-tuning models, and RAG, along with the development of intelligent
    agents with Amazon Bedrock.
  prefs: []
  type: TYPE_NORMAL
- en: We explored various architectural patterns, such as text generation, summarization,
    question answering, entity extraction, code generation, and image creation. Additionally,
    we addressed crucial aspects of monitoring, security, and privacy, ensuring that
    you can confidently navigate the intricate world of GenAI with Amazon Bedrock
    while adhering to ethical standards and best practices. You now have a comprehensive
    understanding of Amazon Bedrock, its capabilities, and the techniques required
    to harness its full potential.
  prefs: []
  type: TYPE_NORMAL
