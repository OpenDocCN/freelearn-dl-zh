- en: '5'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '5'
- en: Building Intelligent Agents
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建智能代理
- en: 'As generative AI adoption grows, we start using LLMs for more open and complex
    tasks that require knowledge about fresh events or interaction with the world.
    This is what is generally called agentic applications. We’ll define what an agent
    is later in this chapter, but you’ve likely seen the phrase circulating in the
    media: *2025 is the year of agentic AI*. For example, in a recently introduced
    RE-Bench benchmark that consists of complex open-ended tasks, AI agents outperform
    humans in some settings (for example, with a thinking budget of 30 minutes) or
    on some specific class of tasks (like writing Triton kernels).'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 随着生成式AI的采用率增长，我们开始使用LLM来完成更多开放和复杂的任务，这些任务需要了解新鲜事件或与世界交互。这通常被称为代理应用。我们将在本章后面定义代理是什么，但您可能已经在媒体上看到了这个短语：*2025年是代理AI的年份*。例如，在最近引入的RE-Bench基准测试中，它由复杂的开放性任务组成，在某些设置（例如，有30分钟的思考预算）或某些特定类别的任务（如编写Triton内核）中，AI代理的表现优于人类。
- en: To understand how these agentic capabilities are built in practice, we’ll start
    by discussing tool calling with LLMs and how it is implemented on LangChain. We’ll
    look in detail at the ReACT pattern, and how LLMs can use tools to interact with
    the external environment and improve their performance on specific tasks. Then,
    we’ll touch on how tools are defined in LangChain, and which pre-built tools are
    available. We’ll also talk about developing your own custom tools, handling errors,
    and using advanced tool-calling capabilities. As a practical example, we’ll look
    at how to generate structured outputs with LLM using tools versus utilizing built-in
    capabilities offered by model providers.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解这些代理能力在实际中的构建方式，我们将首先讨论使用LLM进行工具调用以及如何在LangChain上实现，我们将详细探讨ReACT模式，以及LLM如何使用工具与外部环境交互并提高在特定任务上的性能。然后，我们将讨论在LangChain中定义工具以及哪些预构建工具可用。我们还将讨论开发自己的自定义工具、处理错误和使用高级工具调用功能。作为一个实际例子，我们将探讨如何使用工具与模型提供者提供的内置功能相比，使用LLM生成结构化输出。
- en: Finally, we’ll talk about what agents are and look into more advanced patterns
    of building agents with LangGraph before we then develop our first ReACT agent
    with LangGraph—a research agent that follows a plan-and-solve design pattern and
    uses tools such as web search, *arXiv*, and *Wikipedia*.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将讨论代理是什么，并在开发我们的第一个ReACT代理之前，使用LangGraph探讨构建代理的更高级模式——ReACT代理是一种遵循计划-求解设计模式的代理，并使用诸如网络搜索、*arXiv*和*维基百科*等工具。
- en: 'In a nutshell, the following topics will be covered in this chapter:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，本章将涵盖以下主题：
- en: What is a tool?
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是工具？
- en: Defining built-in LangChain tools and custom tools
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义内置LangChain工具和自定义工具
- en: Advanced tool-calling capabilities
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高级工具调用功能
- en: Incorporating tools into workflows
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将工具集成到工作流程中
- en: What are agents?
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是代理？
- en: You can find the code for this chapter in the `chapter5/` directory of the book’s
    GitHub repository. Please visit [https://github.com/benman1/generative_ai_with_langchain/tree/second_edition](https://github.com/benman1/generative_ai_with_langchain/tree/second_edition)
    for the latest updates.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在本书GitHub仓库的`chapter5/`目录中找到本章的代码。请访问[https://github.com/benman1/generative_ai_with_langchain/tree/second_edition](https://github.com/benman1/generative_ai_with_langchain/tree/second_edition)以获取最新更新。
- en: See [*Chapter 2*](E_Chapter_2.xhtml#_idTextAnchor044) for setup instructions.
    If you have any questions or encounter issues while running the code, please create
    an issue on GitHub or join the discussion on Discord at [https://packt.link/lang](https://packt.link/lang).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 请参阅[*第二章*](E_Chapter_2.xhtml#_idTextAnchor044)以获取设置说明。如果您在运行代码时遇到任何问题或有任何疑问，请在GitHub上创建问题或在Discord上加入讨论，链接为[https://packt.link/lang](https://packt.link/lang)。
- en: Let’s begin with tools. Rather than diving straight into defining what an agent
    is, it’s more helpful to first explore how enhancing LLMs with tools actually
    works in practice. By walking through this step by step, you’ll see how these
    integrations unlock new capabilities. So, what exactly are tools, and how do they
    extend what LLMs can do?
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从工具开始。与其直接定义代理是什么，不如首先探索如何通过工具增强LLM在实际中是如何工作的。通过逐步进行，您将看到这些集成如何解锁新的功能。那么，工具究竟是什么，它们是如何扩展LLM所能做到的事情的？
- en: What is a tool?
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是工具？
- en: LLMs are trained on vast general corpus data (like web data and books), which
    gives them broad knowledge but limits their effectiveness in tasks that require
    domain-specific or up-to-date knowledge. However, because LLMs are good at reasoning,
    they can interact with the external environment through tools—APIs or interfaces
    that allow the model to interact with the external world. These tools enable LLMs
    to perform specific tasks and receive feedback from the external world.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs是在庞大的通用语料库数据（如网络数据和书籍）上训练的，这使它们拥有广泛的知识，但在需要特定领域或最新知识的任务中限制了它们的有效性。然而，由于LLMs擅长推理，它们可以通过工具与外部环境交互——API或接口允许模型与外部世界交互。这些工具使LLMs能够执行特定任务并从外部世界获得反馈。
- en: 'When using tools, LLMs perform three specific generation tasks:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用工具时，大型语言模型（LLMs）执行三个特定的生成任务：
- en: Choose a tool to use by generating special tokens and the name of the tool.
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过生成特殊标记和工具名称来选择要使用的工具。
- en: Generate a payload to be sent to the tool.
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成要发送给工具的有效载荷。
- en: Generate a response to a user based on the initial question and a history of
    interactions with tools (for this specific run).
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据初始问题和与工具的交互历史（针对这次特定运行）生成对用户的响应。
- en: 'Now it’s time to figure out how LLMs invoke tools and how we can make LLMs
    tool-aware. Consider a somewhat artificial but illustrative question: *What is
    the square root of the current US president’s age multiplied by 132*? This question
    presents two specific challenges:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候弄清楚LLMs如何调用工具以及我们如何使LLMs具备工具意识了。考虑一个有些人为但具有说明性的问题：*当前美国总统年龄的平方根乘以132是多少*？这个问题提出了两个具体挑战：
- en: It references current information (as of March 2025) that likely falls outside
    the model’s training data.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它引用了截至2025年3月的信息，这很可能超出了模型训练数据。
- en: It requires a precise mathematical calculation that LLMs might not be able to
    answer correctly just by autoregressive token generation.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它需要一个精确的数学计算，LLMs可能无法仅通过自回归标记生成正确回答。
- en: 'Rather than forcing an LLM to generate an answer solely based on its internal
    knowledge, we’ll give an LLM access to two tools: a search engine and a calculator.
    We expect the model to determine which tools it needs (if any) and how to use
    them.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会强迫LLM仅基于其内部知识生成答案，而是将两个工具：搜索引擎和计算器，提供给LLM。我们期望模型确定它需要哪些工具（如果有的话）以及如何使用它们。
- en: 'For clarity, let’s start with a simpler question and mock our tools by creating
    dummy functions that always give the same response. Later in this chapter, we’ll
    implement fully functional tools and invoke them:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 为了清晰起见，让我们从一个更简单的问题开始，并通过创建始终给出相同响应的虚拟函数来模拟我们的工具。在本章的后面部分，我们将实现完全功能性的工具并调用它们：
- en: '[PRE0]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Let’s make sure that when the LLM has enough internal knowledge, it replies
    directly to the user:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们确保当LLM拥有足够的内部知识时，它可以直接回复用户：
- en: '[PRE1]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Finally, let’s give the model output of a tool by incorporating it into a prompt:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们通过将其纳入提示来提供工具的输出：
- en: '[PRE2]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'As a last observation, if the search result is not successful, the LLM will
    try to refine the query:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 作为最后的观察，如果搜索结果不成功，LLM将尝试细化查询：
- en: '[PRE4]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'With that, we have demonstrated how tool calling works. Please note that we’ve
    provided prompt examples for demonstration purposes only. Another foundational
    LLM might require some prompt engineering, and our prompts are just an illustration.
    And good news: using tools is easier than it seems from these examples!'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这一点，我们已经展示了工具调用的原理。请注意，我们仅为了演示目的提供了提示示例。另一个基础LLM可能需要一些提示工程，我们的提示只是作为一个示例。好消息是：使用工具比这些示例看起来要简单得多！
- en: As you can note, we described everything in our prompt, including a tool description
    and a tool-calling format. These days, most LLMs provide a better API for tool
    calling since modern LLMs are post-trained on datasets that help them excel in
    such tasks. The LLMs’ creators know how these datasets were constructed. That’s
    why, typically, you don’t incorporate a tool description yourself in the prompt;
    you just provide both a prompt and a tool description as separate arguments, and
    they are combined into a single prompt on the provider’s side. Some smaller open-source
    LLMs expect tool descriptions to be part of the raw prompt, but they would expect
    a well-defined format.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，我们在提示中描述了所有内容，包括工具描述和工具调用格式。如今，大多数LLM都提供了更好的工具调用API，因为现代LLM在帮助它们在这些任务上表现出色的数据集上进行过后训练。LLM的创造者知道这些数据集是如何构建的。这就是为什么，通常情况下，你不需要在提示中自己包含工具描述；你只需提供提示和工具描述作为单独的参数，它们将在提供商的一侧组合成一个单一的提示。一些较小的开源LLM期望工具描述是原始提示的一部分，但它们会期望一个定义良好的格式。
- en: LangChain makes it easy to develop pipelines where an LLM invokes different
    tools and provides access to many helpful built-in tools. Let’s look at how tool
    handling works with LangChain.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain使得开发一个LLM调用不同工具并提供访问许多有用内置工具的管道变得容易。让我们看看LangChain中工具处理是如何工作的。
- en: Tools in LangChain
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LangChain中的工具
- en: With most modern LLMs, to use tools, you can provide a list of tool descriptions
    as a separate argument. As always in LangChain, each particular integration implementation
    maps the interface to the provider’s API. For tools, this happens through LangChain’s
    `tools` argument to the `invoke` method (and some other useful methods such as
    `bind_tools` and others, as we will learn in this chapter).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大多数现代LLM，要使用工具，你可以提供一个工具描述列表作为单独的参数。在LangChain中，每个特定的集成实现都将接口映射到提供商的API。对于工具，这通过LangChain的`tools`参数到`invoke`方法（以及我们将在本章中学习的其他一些有用的方法，如`bind_tools`等）来实现。
- en: When defining a tool, we need to specify its schema in OpenAPI format. We provide
    a *title* and a *description* of the tool and also specify its parameters (each
    parameter has a *type*, *title*, and *description*). We can inherit such a schema
    from various formats, which LangChain translates into OpenAPI format. As we go
    through the next few sections, we’ll illustrate how we can do this from functions,
    docstrings, Pydantic definitions, or by inheriting from a `BaseTool` class and
    providing descriptions directly. For an LLM, a tool is anything that has an OpenAPI
    specification—in other words, it can be called by some external mechanism.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 当定义一个工具时，我们需要以OpenAPI格式指定其模式。我们提供工具的**标题**和**描述**，并指定其参数（每个参数都有一个**类型**、**标题**和**描述**）。我们可以从各种格式继承这样的模式，LangChain将其转换为OpenAPI格式。随着我们进入下一节，我们将展示如何从函数、文档字符串、Pydantic定义或通过从`BaseTool`类继承并直接提供描述来完成这项工作。对于LLM来说，任何具有OpenAPI规范的东西都可以被视为工具——换句话说，它可以被某种外部机制调用。
- en: The LLM itself doesn’t bother about this mechanism, it only produces instructions
    for when and how to call a tool. For LangChain, a tool is also something that
    can be called (and we will see later that tools are inherited from `Runnables`)
    when we execute our program.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 'LLM本身并不关心这个机制，它只产生何时以及如何调用工具的指令。对于LangChain来说，工具也是当我们执行程序时可以调用（我们将在后面看到工具是从`Runnables`继承的）的东西。 '
- en: 'The wording that you use in the *title* and *description* fields is extremely
    important, and you can treat it as a part of the prompt engineering exercise.
    Better wording helps LLMs make better decisions on when and how to call a specific
    tool. Please note that for more complex tools, writing a schema like this can
    become tedious, and we’ll see a simpler way to define tools later in this chapter:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 你在**标题**和**描述**字段中使用的措辞非常重要，你可以将其视为提示工程练习的一部分。更好的措辞有助于LLM在何时以及如何调用特定工具方面做出更好的决策。请注意，对于更复杂的工具，编写这样的模式可能会变得繁琐，我们将在本章后面看到一种更简单的方式来定义工具：
- en: '[PRE6]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'If we inspect the `result.content` field, it would be empty. That’s because
    the LLM has decided to call a tool, and the output message has a hint for that.
    What happens under the hood is that LangChain maps a specific output format of
    the model provider into a unified tool-calling format:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们检查`result.content`字段，它将是空的。这是因为LLM已经决定调用一个工具，输出消息对此有一个提示。在底层发生的事情是LangChain将模型提供商的特定输出格式映射到一个统一的工具调用格式：
- en: '[PRE7]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Keep in mind that some model providers might return non-empty content even in
    the case of tool calling (for example, there might be reasoning traces on why
    the model decided to call a tool). You need to look at the model provider specification
    to understand how to treat such cases.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，一些模型提供者即使在工具调用的案例中也可能返回非空内容（例如，可能有模型决定调用工具的原因的推理痕迹）。你需要查看模型提供者规范来了解如何处理此类情况。
- en: 'As we can see, an LLM returned an array of tool-calling dictionaries—each of
    them contains a unique identifier, the name of the tool to be called, and a dictionary
    with arguments to be provided to this tool. Let’s move to the next step and invoke
    the model again:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，一个 LLM 返回了一个工具调用字典的数组——每个字典都包含一个唯一标识符、要调用的工具的名称以及要提供给此工具的参数字典。让我们进行下一步，再次调用模型：
- en: '[PRE8]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '`ToolMessage` is a special message on LangChain that allows you to feed the
    output of a tool execution back to the model. The `content` field of such a message
    contains the tool’s output, and a special field `tool_call_id` maps it to the
    specific tool calling that was generated by the model. Now, we can send the whole
    sequence (consisting of the initial output, the step with tool calling, and the
    output) back to the model as a list of messages.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '`ToolMessage` 是 LangChain 上的一个特殊消息，允许你将工具执行的结果反馈给模型。此类消息的 `content` 字段包含工具的输出，一个特殊的字段
    `tool_call_id` 将其映射到模型生成的特定工具调用。现在，我们可以将整个序列（包括初始输出、工具调用步骤和输出）作为一个消息列表发送回模型。'
- en: 'It might be odd to always pass a list of tools to the LLM (since, typically,
    such a list is fixed for a given workflow). For that reason, LangChain `Runnables`
    offer a `bind` method that memorizes arguments and adds them to every further
    invocation. Take a look at the following code:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 总是向 LLM 传递工具列表可能有些奇怪（因为，通常，对于给定的工作流程，这样的列表是固定的）。因此，LangChain 的 `Runnables` 提供了一个
    `bind` 方法，该方法会记住参数并将它们添加到每个后续调用中。请看以下代码：
- en: '[PRE9]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'When we call `llm.bind(tools=[search_tool])`, LangChain creates a new object
    (assigned here to `llm_with_tools`) that automatically includes `[search_tool]`
    in every subsequent call to a copy of the initial `llm` one. Essentially, you
    no longer need to pass the tools argument with each `invoke` method. So, calling
    the preceding code is the same as doing:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们调用 `llm.bind(tools=[search_tool])` 时，LangChain 会创建一个新的对象（此处分配给 `llm_with_tools`），该对象会自动将
    `[search_tool]` 包含在后续对初始 `llm` 的每个副本的调用中。本质上，你不再需要在每个 `invoke` 方法中传递工具参数。因此，调用前面的代码与以下操作相同：
- en: '[PRE10]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This is because bind has “memorized” your tools list for all future invocations.
    It’s mainly a convenience feature—ideal if you want a fixed set of tools for repeated
    calls rather than specifying them every time. Now let’s see how we can utilize
    tool calling even more, and improve LLM reasoning!
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这是因为 `bind` 已经“记住”了你的工具列表，以便在所有未来的调用中使用。这主要是一个便利功能——如果你想要一组固定的工具用于重复调用，而不是每次都指定它们，那么它非常理想。现在让我们看看我们如何更有效地利用工具调用，并提高
    LLM 的推理能力！
- en: ReACT
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ReACT
- en: 'As you have probably thought already, LLMs can call multiple tools before generating
    the final reply to the user (and the next tool to be called or a payload sent
    to this tool might depend on the outcome from the previous tool calls). This was
    proposed by a ReACT approach introduced in 2022 by researchers from Princeton
    University and Google Research: *Reasoning and ACT* ([https://arxiv.org/abs/2210.03629](https://arxiv.org/abs/2210.03629)).
    The idea is simple—we should give the LLM access to tools as a way to interact
    with an external environment, and let the LLM run in a loop:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所想，LLM 在生成最终回复给用户之前可以调用多个工具（下一个要调用的工具或发送给此工具的有效负载可能取决于之前工具调用的结果）。这是 2022 年由普林斯顿大学和谷歌研究团队提出的一种
    ReACT 方法（*推理和行动*）[https://arxiv.org/abs/2210.03629](https://arxiv.org/abs/2210.03629)
    所提出的。这个想法很简单——我们应该让 LLM 通过工具访问外部环境，并让 LLM 在循环中运行：
- en: '**Reason**: Generate a text output with observations about the current situation
    and a plan to solve the task.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**推理**：生成关于当前情况的文本输出和解决任务的计划。'
- en: '**Act**: Take an action based on the reasoning above (interact with the environment
    by calling a tool, or respond to the user).'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**行动**：根据上述推理采取行动（通过调用工具与环境交互，或响应用户）。'
- en: It has been demonstrated that ReACT can help reduce hallucination rates compared
    to CoT prompting, which we discussed in [*Chapter 3*](E_Chapter_3.xhtml#_idTextAnchor107).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 已经证明，与我们在 [*第 3 章*](E_Chapter_3.xhtml#_idTextAnchor107) 中讨论的 CoT 提示相比，ReACT
    可以帮助降低幻觉率。
- en: '![Figure 5.1: ReACT pattern](img/B32363_05_01.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.1：ReACT 模式](img/B32363_05_01.png)'
- en: 'Figure 5.1: ReACT pattern'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.1：ReACT 模式
- en: 'Let’s build a ReACT application ourselves. First, let’s create mocked search
    and calculator tools:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们亲自构建一个 ReACT 应用程序。首先，让我们创建模拟的搜索和计算工具：
- en: '[PRE11]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'In the next section, we’ll see how we can build actual tools. For now, let’s
    define a schema for the calculator tool and make the LLM aware of both tools it
    can use. We’ll also use building blocks that we’re already familiar with—`ChatPromptTemplate`
    and `MessagesPlaceholder`—to prepend a predetermined system message when we call
    our graph:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将看到我们如何构建实际工具。现在，让我们为计算器工具定义一个模式，并让 LLM 了解它可以使用这两个工具。我们还将使用我们已熟悉的构建块——`ChatPromptTemplate`
    和 `MessagesPlaceholder`——在调用我们的图时预先添加一个预定系统消息：
- en: '[PRE13]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Now that we have an LLM that can call tools, let’s create the nodes we need.
    We need one function that calls an LLM, another function that invokes tools and
    returns tool-calling results (by appending `ToolMessages` to the list of messages
    in the state), and a function that will determine whether the orchestrator should
    continue calling tools or whether it can return the result to the user:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有一个可以调用工具的 LLM，让我们创建我们需要的节点。我们需要一个调用 LLM 的函数，另一个调用工具并返回工具调用结果（通过将 `ToolMessages`
    添加到状态中的消息列表中）的函数，以及一个将确定协调器是否应该继续调用工具或是否可以将结果返回给用户的函数：
- en: '[PRE14]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Now let’s bring everything together in a LangGraph workflow:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们在 LangGraph 工作流程中将所有这些整合在一起：
- en: '[PRE15]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: This demonstrates how the LLM made several calls to handle a complex question—first,
    to `Google Search` and then two calls to `Calculator`—and each time, it used the
    previously received information to adjust its actions. This is the ReACT pattern
    in action.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这展示了 LLM 如何通过多次调用处理复杂问题——首先调用 `Google Search`，然后两次调用 `Calculator`——并且每次都使用之前接收到的信息来调整其行为。这就是
    ReACT 模式在起作用。
- en: 'With that, we’ve learned how the ReACT pattern works in detail by building
    it ourselves. The good news is that LangGraph offers a pre-built implementation
    of a ReACT pattern, so you don’t need to implement it yourself:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 通过构建它，我们已经详细了解了 ReACT 模式的工作原理。好消息是 LangGraph 提供了预构建的 ReACT 模式实现，因此您不需要自己实现它：
- en: '[PRE16]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: In [*Chapter 6*](E_Chapter_6.xhtml#_idTextAnchor274), we’ll see some additional
    adjustments you can use with the `create_react_agent` function.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [*第 6 章*](E_Chapter_6.xhtml#_idTextAnchor274) 中，我们将看到一些可以使用 `create_react_agent`
    函数进行的额外调整。
- en: Defining tools
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义工具
- en: So far, we have defined tools as OpenAPI schemas. But to run the workflow end
    to end, LangGraph should be able to call tools itself during the execution. Hence,
    in this section, let’s discuss how we define tools as Python functions or callables.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经将工具定义为 OpenAPI 模式。但为了端到端运行工作流程，LangGraph 应该能够在执行过程中自己调用工具。因此，在本节中，让我们讨论我们如何将工具定义为
    Python 函数或可调用对象。
- en: 'A LangChain tool has three essential components:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 工具有三个基本组件：
- en: '`Name`: A unique identifier for the tool'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`名称`：工具的唯一标识符'
- en: '`Description`: Text that helps the LLM understand when and how to use the tool'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`描述`：帮助 LLM 理解何时以及如何使用工具的文本'
- en: '`Payload schema`: A structured definition of the inputs the tool accepts'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`有效载荷模式`：工具接受的输入的结构化定义'
- en: It allows an LLM to decide when and how to call a tool. Another important distinction
    of a LangChain tool is that it can be executed by an orchestrator, such as LangGraph.
    The base interface for a tool is `BaseTool`, which inherits from a `RunnableSerializable`
    itself. That means it can be invoked or batched as any `Runnable`, or serialized
    or deserialized as any `Serializable`.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 它允许 LLM 决定何时以及如何调用工具。LangChain 工具的另一个重要区别是它可以由协调器（如 LangGraph）执行。工具的基本接口是 `BaseTool`，它本身继承自
    `RunnableSerializable`。这意味着它可以像任何 `Runnable` 一样被调用或批处理，或者像任何 `Serializable` 一样被序列化或反序列化。
- en: Built-in LangChain tools
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 内置 LangChain 工具
- en: LangChain has many tools already available across various categories. Since
    tools are often provided by third-party vendors, some tools require paid API keys,
    some of them are completely free, and some of them have a free tier. Some tools
    are grouped together in toolkits—collections of tools that are supposed to be
    used together when working on a specific task. Let’s see some examples of using
    tools.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 已经在各个类别中提供了许多工具。由于工具通常由第三方供应商提供，一些工具需要付费 API 密钥，一些是完全免费的，还有一些提供免费层。一些工具被分组在工具包中——当处理特定任务时应该一起使用的工具集合。让我们看看一些使用工具的例子。
- en: Tools give an LLM access to search engines, such as Bing, DuckDuckGo, Google,
    and Tavily. Let’s take a look at `DuckDuckGoSearchRun` as this search engine doesn’t
    require additional registration and an API key.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 工具给 LLM 提供了访问搜索引擎，如 Bing、DuckDuckGo、Google 和 Tavily。让我们看看 `DuckDuckGoSearchRun`，因为这个搜索引擎不需要额外的注册和
    API 密钥。
- en: Please see [*Chapter 2*](E_Chapter_2.xhtml#_idTextAnchor044) for setup instructions.
    If you have any questions or encounter issues while running the code, please create
    an issue on GitHub or join the discussion on Discord at [https://packt.link/lang](https://packt.link/lang).
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 请参阅[*第 2 章*](E_Chapter_2.xhtml#_idTextAnchor044)以获取设置说明。如果您在运行代码时有任何问题或遇到问题，请在
    GitHub 上创建问题或在 Discord 上加入[https://packt.link/lang](https://packt.link/lang)的讨论。
- en: 'As with any tool, this tool has a name, description, and schema for input arguments:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 与任何工具一样，这个工具有一个名称、描述和输入参数的架构：
- en: '[PRE17]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The argument schema, `arg_schema`, is a Pydantic model and we’ll see why it’s
    useful later in this chapter. We can explore its fields either programmatically
    or by going to the documentation page—it expects only one input field, a query:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 参数架构 `arg_schema` 是一个 Pydantic 模型，我们将在本章后面看到它为什么有用。我们可以通过程序方式或通过访问文档页面来探索其字段——它期望只有一个输入字段，一个查询：
- en: '[PRE19]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Now we can invoke this tool and get a string output back (results from the
    search engine):'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以调用这个工具并返回一个字符串输出（来自搜索引擎的结果）：
- en: '[PRE20]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'We can also invoke the LLM with tools, and let’s make sure that the LLM invokes
    the search tool and does not answer directly:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用工具调用 LLM，并确保 LLM 调用搜索工具而不是直接回答：
- en: '[PRE21]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Our tool is now a callable that LangGraph can call programmatically. Let’s
    put everything together and create our first agent. When we stream our graph,
    we get updates to the state. In our case, these are only messages:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的工具现在是一个 LangGraph 可以程序调用的可调用函数。让我们把所有东西放在一起，创建我们的第一个代理。当我们流式传输我们的图时，我们得到状态的更新。在我们的情况下，这些只是消息：
- en: '[PRE22]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '![Figure 5.2: A pre-built ReACT workflow on LangGraph](img/B32363_05_02.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.2：LangGraph 上的预构建 ReACT 工作流程](img/B32363_05_02.png)'
- en: 'Figure 5.2: A pre-built ReACT workflow on LangGraph'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.2：LangGraph 上的预构建 ReACT 工作流程
- en: That’s exactly what we saw earlier as well—an LLM is calling tools until it
    decides to stop and return the answer to the user. Let’s test it out!
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 这正是我们之前看到的——一个 LLM 调用工具，直到它决定停止并返回答案给用户。让我们测试一下！
- en: 'When we stream LangGraph, we get new events that are updates to the graph’s
    state. We’re interested in the `message` field of the state. Let’s print out the
    new messages added:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们流式传输 LangGraph 时，我们得到更新图状态的新的事件。我们对状态的 `message` 字段感兴趣。让我们打印出新添加的消息：
- en: '[PRE23]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '[PRE24]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Our agent is represented by a list of messages since this is the input and
    output that the LLM expects. We’ll see that pattern again when we dive deeper
    into agentic architectures and discuss it in the next chapter. For now, let’s
    briefly mention other types of tools that are already available on LangChain:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们的代理由消息列表表示，因为这是 LLM 期望的输入和输出。当我们深入研究代理架构时，我们将在下一章中再次看到这个模式。现在，让我们简要地提到 LangChain
    上已经可用的其他类型工具：
- en: '**Tools that enhance the LLM’s knowledge besides using a search engine**:'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**除了使用搜索引擎外，增强 LLM 知识的工具**：'
- en: 'Academic research: arXiv and PubMed'
  id: totrans-104
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学术研究：arXiv 和 PubMed
- en: 'Knowledge bases: Wikipedia and Wikidata'
  id: totrans-105
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 知识库：维基百科和 Wikidata
- en: 'Financial data: Alpha Vantage, Polygon, and Yahoo Finance'
  id: totrans-106
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 财务数据：Alpha Vantage、Polygon 和 Yahoo Finance
- en: 'Weather: OpenWeatherMap'
  id: totrans-107
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 天气：OpenWeatherMap
- en: 'Computation: Wolfram Alpha'
  id: totrans-108
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算：Wolfram Alpha
- en: '**Tools that enhance your productivity**: You can interact with Gmail, Slack,
    Office 365, Google Calendar, Jira, Github, etc. For example, `GmailToolkit` gives
    you access to `GmailCreateDraft`, `GmailSendMessage`, `GmailSearch`, `GmailGetMessage`,
    and `GmailGetThread` tools that allow you to search, retrieve, create, and send
    messages with your Gmail account. As you can see, not only can you give the LLM
    additional context about the user but, with some of these tools, LLMs can take
    actions that actually influence the outside environment, such as creating a pull
    request on GitHub or sending a message on Slack!'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**增强您生产力的工具**：您可以与 Gmail、Slack、Office 365、Google Calendar、Jira、Github 等进行交互。例如，`GmailToolkit`
    给您提供了访问 `GmailCreateDraft`、`GmailSendMessage`、`GmailSearch`、`GmailGetMessage`
    和 `GmailGetThread` 工具的权限，这些工具允许您使用 Gmail 账户搜索、检索、创建和发送消息。正如您所看到的，您不仅可以为 LLM 提供关于用户的额外上下文，而且通过一些这些工具，LLM
    可以采取实际影响外部环境的行为，例如在 GitHub 上创建拉取请求或在 Slack 上发送消息！'
- en: '**Tools that give an LLM access to a code interpreter**: These tools give LLMs
    access to a code interpreter by remotely launching an isolated container and giving
    LLMs access to this container. These tools require an API key from a vendor providing
    the sandboxes. LLMs are especially good at coding, and it’s a widely used pattern
    to ask an LLM to solve some complex task by writing code that solves it instead
    of asking it to generate tokens that represent the solution of the task. Of course,
    you should execute code generated by LLMs with caution, and that’s why isolated
    sandboxes play a huge role. Some examples are:'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提供LLM访问代码解释器的工具**：这些工具通过远程启动隔离容器并允许LLM访问该容器，使LLM能够访问代码解释器。这些工具需要来自提供沙箱的供应商的API密钥。LLM在编码方面特别擅长，因此请求LLM通过编写解决复杂任务的代码来解决问题，而不是生成表示任务解决方案的标记，这是一种广泛使用的模式。当然，您应该谨慎执行由LLM生成的代码，这就是为什么隔离沙箱扮演着巨大角色的原因。以下是一些示例：'
- en: 'Code execution: Python REPL and Bash'
  id: totrans-111
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代码执行：Python REPL和Bash
- en: 'Cloud services: AWS Lambda'
  id: totrans-112
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 云服务：AWS Lambda
- en: 'API tools: GraphQL and Requests'
  id: totrans-113
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: API工具：GraphQL和Requests
- en: 'File operations: File System'
  id: totrans-114
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文件操作：文件系统
- en: '**Tools that give an LLM access to databases by writing and executing SQL code**:
    For example, `SQLDatabase` includes tools to get information about the database
    and its objects and execute SQL queries. You can also access Google Drive with
    `GoogleDriveLoader` or perform operations with usual file system tools from a
    `FileManagementToolkit`.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**通过编写和执行SQL代码使LLM访问数据库的工具**：例如，`SQLDatabase`包括获取有关数据库及其对象的信息和执行SQL查询的工具。您还可以使用`GoogleDriveLoader`访问Google
    Drive，或使用`FileManagementToolkit`中的常规文件系统工具执行操作。'
- en: '**Other tools**: These comprise tools that integrate third-party systems and
    allow the LLM to gather additional information or act. There are also tools that
    can integrate data retrieval from Google Maps, NASA, and other platforms and organizations.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**其他工具**：这些包括集成第三方系统的工具，允许LLM收集更多信息或执行操作。还有一些工具可以集成从Google Maps、NASA和其他平台和组织的数据检索。 '
- en: '**Tools for using other AI systems or automation**:'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用其他AI系统或自动化的工具**：'
- en: 'Image generation: DALL-E and Imagen'
  id: totrans-118
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图片生成：DALL-E和Imagen
- en: 'Speech synthesis: Google Cloud TTS and Eleven Labs'
  id: totrans-119
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语音合成：Google Cloud TTS和Eleven Labs
- en: 'Model access: Hugging Face Hub'
  id: totrans-120
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型访问：Hugging Face Hub
- en: 'Workflow automation: Zapier and IFTTT'
  id: totrans-121
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 工作流程自动化：Zapier和IFTTT
- en: 'Any external system with an API can be wrapped as a tool if it enhances an
    LLM like this:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 任何具有API的外部系统都可以被封装成工具，如果它能增强像这样的LLM（大型语言模型）：
- en: Provides relevant domain knowledge to the user or the workflow
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为用户或工作流程提供相关的领域知识
- en: Allows an LLM to take actions on the user’s behalf
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 允许LLM代表用户执行操作
- en: 'When integrating such tools with LangChain, consider these key aspects:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 当将此类工具与LangChain集成时，请考虑以下关键方面：
- en: '**Authentication**: Secure access to the external system'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**身份验证**：确保外部系统的安全访问'
- en: '**Payload schema**: Define proper data structures for input/output'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**有效载荷模式**：定义适当的输入/输出数据结构'
- en: '**Error handling**: Plan for failures and edge cases'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**错误处理**：计划失败和边缘情况'
- en: '**Safety considerations**: For example, when developing a SQL-to-text agent,
    restrict access to read-only operations to prevent unintended modifications'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全考虑**：例如，在开发SQL到文本代理时，限制只读操作以防止意外修改'
- en: 'Therefore, an important toolkit is the `RequestsToolkit`, which allows one
    to easily wrap any HTTP API:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，一个重要的工具包是`RequestsToolkit`，它允许用户轻松封装任何HTTP API：
- en: '[PRE25]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Let’s take a free open-source currency API ([https://frankfurter.dev/](https://frankfurter.dev/)).
    It’s a random free API we took from the Internet for illustrative purposes only,
    just to show you how you can wrap any existing API as a tool. First, we need to
    put together an API spec based on the OpenAPI format. We truncated the spec but
    you can find the full version on our GitHub:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用一个免费的开放源代码货币API（[https://frankfurter.dev/](https://frankfurter.dev/)）。这是一个仅用于说明目的的随机免费API，只是为了向您展示您如何将任何现有的API封装成工具。首先，我们需要根据OpenAPI格式创建一个API规范。我们截断了规范，但您可以在我们的GitHub上找到完整版本：
- en: '[PRE27]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '[PRE28]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Now let’s build and run our ReACT agent; we’ll see that the LLM can query the
    third-party API and provide fresh answers on currency exchange rates:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来构建和运行我们的ReACT代理；我们将看到LLM可以查询第三方API并提供关于货币汇率的最新答案：
- en: '[PRE29]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '[PRE30]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Observe that, this time, we use a `stream_mode="values"` option, and in this
    option, each time, we get a full current state from the graph.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到，这次我们使用了`stream_mode="values"`选项，在这个选项中，每次我们都会从图中获取完整当前状态。
- en: 'There are over 50 tools already available. You can find a full list on the
    documentation page: [https://python.langchain.com/docs/integrations/tools/](https://python.langchain.com/docs/integrations/tools/).'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 已经有超过 50 个工具可用。您可以在文档页面上找到完整的列表：[https://python.langchain.com/docs/integrations/tools/](https://python.langchain.com/docs/integrations/tools/)。
- en: Custom tools
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自定义工具
- en: We looked at the variety of built-in tools offered by LangGraph. Now it’s time
    to discuss how you can create your own custom tools, besides the example we looked
    at when we wrapped the third-party API with the `RequestsToolkit` by providing
    an API spec. Let’s get down to it!
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我们探讨了 LangGraph 提供的内置工具的多样性。现在，让我们讨论如何创建自己的自定义工具，除了我们之前在用 `RequestsToolkit`
    封装第三方 API 时提供的 API 规范的例子。让我们开始吧！
- en: Wrapping a Python function as a tool
  id: totrans-143
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将 Python 函数封装成工具
- en: 'Any `Python` function (or callable) can be wrapped as a tool. As we remember,
    a tool on LangChain should have a name, a description, and an argument schema.
    Let’s build our own calculator based on the Python `numexr` library—a fast numerical
    expression evaluator based on NumPy ([https://github.com/pydata/numexpr](https://github.com/pydata/numexpr)).
    We’re going to use a special `@tool` decorator that will wrap our function as
    a tool:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 任何 `Python` 函数（或可调用对象）都可以被封装成工具。正如我们所记得的，LangChain 上的工具应该有一个名称、一个描述和一个参数架构。让我们基于
    Python 的 `numexr` 库（一个基于 NumPy 的快速数值表达式评估器）构建自己的计算器——[https://github.com/pydata/numexpr](https://github.com/pydata/numexpr)。我们将使用一个特殊的
    `@tool` 装饰器来将我们的函数封装成工具：
- en: '[PRE31]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '[PRE32]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Let’s explore the calculator object we have! Notice that LangChain auto-inherited
    the name, the description, and args schema from the docstring and type hints.
    Please note that we used a few-shot technique (discussed in [*Chapter 3*](E_Chapter_3.xhtml#_idTextAnchor107))
    to teach LLMs how to prepare the payload for our tool by adding two examples in
    the docstring:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探索一下我们拥有的计算器对象！请注意，LangChain 自动从文档字符串和类型提示中继承了名称、描述和 args 架构。请注意，我们使用了少样本技术（在第
    [*第 3 章*](E_Chapter_3.xhtml#_idTextAnchor107) 中讨论）来教 LLM 如何通过在文档字符串中添加两个示例来为我们的工具准备有效负载：
- en: '[PRE33]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Let’s try out our new tool to evaluate an expression with complex numbers,
    which extend real numbers with a special imaginary unit `i` that has a property
    `i**2=-1`:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试使用我们的新工具来评估一个包含复数的表达式，这些复数通过一个特殊的虚数单位 `i` 扩展了实数，该单位具有属性 `i**2=-1`：
- en: '[PRE34]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '[PRE35]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'With just a few lines of code, we’ve successfully extended our LLM’s capabilities
    to work with complex numbers. Now we can put together the example we started with:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 只需几行代码，我们就成功地扩展了我们的 LLM 的能力，使其能够处理复数。现在我们可以将我们开始时的例子组合起来：
- en: '[PRE36]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'We haven’t provided the full output here in the book (you can find it on our
    GitHub), but if you run this snippet, you should see that the LLM was able to
    query tools step by step:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 我们没有在这里提供完整的输出（您可以在我们的 GitHub 上找到），但如果您运行此代码片段，您应该会看到 LLM 能够逐步查询工具：
- en: It called the search engine with the query `"current US president"`.
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它使用查询 `"current US president"` 调用搜索引擎。
- en: Then, it again called the search engine with the query `"donald trump age"`.
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，它再次使用查询 `"donald trump age"` 调用搜索引擎。
- en: As the last step, the LLM called the calculator tool with the expression `"sqrt(78*132)"`.
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 作为最后一步，LLM 使用表达式 `"sqrt(78*132)"` 调用计算器工具。
- en: Finally, it returned the correct answer to the user.
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，它向用户返回了正确的答案。
- en: At every step, the LLM reasoned based on the previously collected information
    and then acted with an appropriate tool—that’s the essence of the ReACT approach.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个步骤中，LLM 都基于之前收集到的信息进行推理，然后使用适当的工具采取行动——这就是 ReACT 方法的关键。
- en: Creating a tool from a Runnable
  id: totrans-160
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 从可运行对象创建工具
- en: 'Sometimes, LangChain might not be able to derive a passing description or args
    schema from a function, or we might be using a complex callable that is difficult
    to wrap with a decorator. For example, we can use another LangChain chain or LangGraph
    graph as a tool. We can create a tool from any `Runnable` by explicitly specifying
    all needed descriptions. Let’s create a calculator tool from a function in an
    alternative fashion, and we will tune the retry behavior (in our case, we’re going
    to retry three times and add an exponential backoff between consecutive attempts):'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，LangChain 可能无法从一个函数中推导出通过的描述或 args 架构，或者我们可能正在使用一个复杂的可调用对象，难以用装饰器封装。例如，我们可以使用另一个
    LangChain 链或 LangGraph 图作为工具。我们可以通过显式指定所有需要的描述来从任何 `Runnable` 创建工具。让我们以另一种方式创建一个计算器工具，并且我们将调整重试行为（在我们的情况下，我们将重试三次，并在连续尝试之间添加指数退避）：
- en: Please note that we use the same function as above but we removed the `@tool`
    decorator.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们使用与上面相同的函数，但去掉了 `@tool` 装饰器。
- en: '[PRE37]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '[PRE38]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Observe that we defined our function in a similar way to how we define LangGraph
    nodes—it takes a state (which now is a Pydantic model) and a config. Then, we
    wrapped this function as `RunnableLambda` and added retries. It might be useful
    if we want to keep our Python function as a function without wrapping it with
    a decorator, or if we want to wrap an external API (hence, description and arguments
    schema can’t be auto-inherited from the docstrings). We can use any Runnable (for
    example, a chain or a graph) to create a tool, and that allows us to build multi-agent
    systems since now one LLM-based workflow can invoke another LLM-based one. Let’s
    convert our Runnable to a tool:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们定义我们的函数的方式与定义 LangGraph 节点的方式类似——它接受一个状态（现在是一个 Pydantic 模型）和一个配置。然后，我们将这个函数包装成
    `RunnableLambda` 并添加了重试机制。如果我们想保持我们的 Python 函数作为一个函数而不使用装饰器包装，或者如果我们想包装外部 API（因此，描述和参数模式不能从文档字符串中自动继承），这可能是有用的。我们可以使用任何可运行的（例如，一个链或一个图）来创建一个工具，这使我们能够构建多智能体系统，因为现在一个基于
    LLM 的工作流程可以调用另一个基于 LLM 的工作流程。让我们将我们的可运行对象转换为工具：
- en: '[PRE39]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Let’s test our new `calculator` function with the LLM:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用 LLM 测试我们新的 `calculator` 函数：
- en: '[PRE40]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'As you can note, LangChain didn’t inherit the `args` schema fully; that’s why
    it created artificial names for arguments like `__arg1`. Let’s change our tool
    to accept a Pydantic model instead, in a similar fashion to how we define LangGraph
    nodes:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所注意到的，LangChain 并没有完全继承 `args` 模式；这就是为什么它为参数创建了如 `__arg1` 这样的人工名称。让我们以定义
    LangGraph 节点类似的方式修改我们的工具，以接受一个 Pydantic 模型：
- en: '[PRE41]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Now the full schema is a proper one:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 现在完整的模式是一个合适的模式：
- en: '[PRE42]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Let’s test it together with an LLM:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们与 LLM 一起测试它：
- en: '[PRE43]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'We can call our calculator tool and pass it to the LangGraph configuration
    in runtime:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在运行时调用我们的计算器工具并将其传递给 LangGraph 配置：
- en: '[PRE44]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: With that, we have learned how we can easily convert any Runnable to a tool
    by providing additional details to LangChain to ensure an LLM can correctly handle
    this tool.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这样，我们已经学会了如何通过向 LangChain 提供额外的详细信息，轻松地将任何可运行对象转换为工具，以确保 LLM 可以正确处理这个工具。
- en: Subclass StructuredTool or BaseTool
  id: totrans-178
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 继承 StructuredTool 或 BaseTool
- en: 'Another method to define a tool is by creating a custom tool by subclassing
    the `BaseTool` class. As with other approaches, you must specify the tool’s name,
    description, and argument schema. You’ll also need to implement one or two abstract
    methods: `_run` for synchronous execution and, if necessary, `_arun` for asynchronous
    behavior (if it differs from simply wrapping the sync version). This option is
    particularly useful when your tool needs to be stateful (for example, to maintain
    long-lived connection clients) or when its logic is too complex to be implemented
    as a single function or `Runnable`.'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 定义工具的另一种方法是创建一个通过继承 `BaseTool` 类的自定义工具。与其他方法一样，你必须指定工具的名称、描述和参数模式。你还需要实现一个或两个抽象方法：`_run`
    用于同步执行，如果需要，`_arun` 用于异步行为（如果它与简单地包装同步版本不同）。这个选项特别有用，当你的工具需要保持状态（例如，维护长期连接客户端）或者其逻辑过于复杂，不能作为一个单一函数或
    `Runnable` 实现。
- en: 'If you want more flexibility than a `@tool` decorator gives you but don’t want
    to implement your own class, there’s an intermediate approach. You can also use
    the `StructuredTool.from_function` class method, which allows you to explicitly
    specify tools’ meta parameters such as description or `args_schema` with a few
    lines of code only:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要比 `@tool` 装饰器提供的更多灵活性，但又不想实现自己的类，有一个中间方法。你还可以使用 `StructuredTool.from_function`
    类方法，它允许你仅用几行代码显式指定工具的元参数，如描述或 `args_schema`：
- en: '[PRE45]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: One last note about synchronous and asynchronous implementations is necessary
    at this point. If an underlying function besides your tool is a synchronous function,
    LangChain will wrap it for the tool’s asynchronous implementation by launching
    it in a separate thread. In most cases, it doesn’t matter, but if you care about
    the additional overhead of creating a separate thread, you have two options—either
    subclass from the `BaseClass` and override async implementation, or create a separate
    async implementation of your function and pass it to the `StructruredTool.from_function`
    as a `coroutine` argument. You can also provide only async implementation, but
    then you won’t be able to invoke your workflows in a synchronous manner.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，关于同步和异步实现还有一个最后的注意事项。如果除了你的工具之外，还有一个底层函数是同步函数，LangChain 将通过在单独的线程中启动它来为工具的异步实现包装它。在大多数情况下，这并不重要，但如果你关心创建单独线程的额外开销，你有两个选择——要么从
    `BaseClass` 继承并覆盖异步实现，要么创建你函数的单独异步实现并将其作为 `coroutine` 参数传递给 `StructruredTool.from_function`。你也可以只提供异步实现，但那样的话，你将无法以同步方式调用你的工作流程。
- en: To conclude, let’s take another look at three options that we have to create
    a LangChain tool, and when to use each of them.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，让我们再看看我们创建 LangChain 工具的三个选项，以及何时使用每个选项。
- en: '| **Method to create a tool** | **When to use** |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| **创建工具的方法** | **何时使用** |'
- en: '| @tool decorator | You have a function with clear docstrings and this function
    isn’t used anywhere in your code |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| @tool 装饰器 | 你有一个具有清晰文档字符串的函数，并且这个函数在你的代码中没有被使用 |'
- en: '| convert_runnable_to_tool | You have an existing Runnable, or you need more
    detailed controlled on how arguments or tool descriptions are passed to an LLM
    (you wrap an existing function by a RunnableLambda in that case) |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| 将可运行对象转换为工具 | 你有一个现有的可运行对象，或者你需要更详细地控制如何将参数或工具描述传递给 LLM（在这种情况下，你通过 `RunnableLambda`
    包装现有的函数） |'
- en: '| subclass from StructuredTool or BaseTool | You need full control over tool
    description and logic (for example, you want to handle sync and async requests
    differently) |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| 从 StructuredTool 或 BaseTool 继承 | 你需要完全控制工具描述和逻辑（例如，你想要以不同的方式处理同步和异步请求） |'
- en: 'Table 5.1: Options to create a LangChain tool'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5.1：创建 LangChain 工具的选项
- en: When an LLM generates payloads and calls tools, it might hallucinate or make
    other mistakes. Therefore, we need to carefully think about error handling.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 当 LLM 生成负载并调用工具时，它可能会出现幻觉或犯其他错误。因此，我们需要仔细考虑错误处理。
- en: Error handling
  id: totrans-190
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 错误处理
- en: We already discussed error handling in [*Chapter 3*](E_Chapter_3.xhtml#_idTextAnchor107),
    but it becomes even more important when you enhance an LLM with tools; you need
    logging, working with exceptions, and so on even more. One additional consideration
    is to think about whether you would like your workflow to continue and try to
    auto-recover if one of your tools fails. LangChain has a special `ToolException`
    that allows the workflow to continue its execution by handling the exception.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在 [*第 3 章*](E_Chapter_3.xhtml#_idTextAnchor107) 中讨论了错误处理，但当你增强一个 LLM 并使用工具时，它变得更加重要；你需要记录日志、处理异常等等。一个额外的考虑是，你是否希望你的工作流程在某个工具失败时继续执行并尝试自动恢复。LangChain
    有一个特殊的 `ToolException`，它允许工作流程通过处理异常来继续执行。
- en: '`BaseTool` has two special flags: `handle_tool_error` and `handle_validation_error`.
    Of course, since `StructuredTool` inherits from `BaseTool`, you can pass these
    flags to the `StructuredTool.from_function` class method. If this flag is set,
    LangChain would construct a string to return as a result of tools’ execution if
    either a `ToolException` or a Pydantic `ValidationException` (when validating
    input payload) happens.'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '`BaseTool` 有两个特殊标志：`handle_tool_error` 和 `handle_validation_error`。当然，由于 `StructuredTool`
    继承自 `BaseTool`，你可以将这些标志传递给 `StructuredTool.from_function` 类方法。如果设置了此标志，LangChain
    就会在工具执行过程中发生 `ToolException` 或 Pydantic `ValidationException`（当验证输入负载时）时构造一个字符串作为工具执行的结果。'
- en: 'To understand what happens, let’s take a look at the LangChain source code
    for the `_handle_tool_error` function:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解发生了什么，让我们看看 LangChain 源代码中 `_handle_tool_error` 函数的实现：
- en: '[PRE46]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: As we can see, we can set this flag to a Boolean, string, or callable (that
    converts a `ToolException` to a string). Based on this, LangChain would try to
    handle `ToolException` and pass a string to the next stage instead. We can incorporate
    this feedback into our workflow and add an auto-recover loop.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，我们可以将此标志设置为布尔值、字符串或可调用（将 `ToolException` 转换为字符串）。基于此，LangChain 将尝试处理
    `ToolException` 并将字符串传递到下一阶段。我们可以将此反馈纳入我们的工作流程并添加自动恢复循环。
- en: 'Let’s look at an example. We adjust our `calculator` function by removing a
    substitution `i->j` (a substitution from an imaginary unit in math to an imaginary
    unit in Python), and we also make `StructuredTool` auto-inherit descriptions and
    `arg_schema` from the docstring:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一个例子。我们通过移除一个替换`i->j`（从数学中的虚数单位到Python中的虚数单位的替换）来调整我们的`calculator`函数，并且我们还让`StructuredTool`自动继承文档字符串中的描述和`arg_schema`：
- en: '[PRE47]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '[PRE48]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: As we can see, now our execution of a calculator fails, but since the error
    description is not clear enough, the LLM decides to respond itself without using
    the tool. Depending on your use case, you might want to adjust the behavior; for
    example, provide more meaningful errors from the tool, force the workflow to try
    to adjust the payload for the tool, etc.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，现在我们的计算器执行失败，但由于错误描述不够清晰，LLM决定自行响应而不使用工具。根据你的用例，你可能想要调整行为；例如，从工具提供更有意义的错误，强制工作流程尝试调整工具的有效载荷等。
- en: LangGraph also offers a built-in `ValidationNode` that takes the last messages
    (by inspecting the `messages` key in the graph’s state) and checks whether it
    has tool calls. If that’s the case, LangGraph validates the schema of the tool
    call, and if it doesn’t follow the expected schema, it raises a `ToolMessage`
    with the validation error (and a default command to fix it). You can add a conditional
    edge that cycles back to the LLM and then the LLM would regenerate the tool call,
    similar to the pattern we discussed in [*Chapter 3*](E_Chapter_3.xhtml#_idTextAnchor107).
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: LangGraph还提供了一个内置的`ValidationNode`，它通过检查图的状态中的`messages`键来获取最后一条消息，并检查是否有工具调用。如果是这样，LangGraph将验证工具调用的模式，如果它不符合预期的模式，它将抛出一个包含验证错误（以及默认的修复命令）的`ToolMessage`。你可以添加一个条件边，使其循环回LLM，然后LLM会重新生成工具调用，类似于我们在[*第3章*](E_Chapter_3.xhtml#_idTextAnchor107)中讨论的模式。
- en: Now that we’ve learned what a tool is, how to create one, and how to use built-in
    LangChain tools, it’s time to take a look at additional instructions that you
    can pass to an LLM on how to use tools.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了什么是工具，如何创建一个工具，以及如何使用内置的LangChain工具，是时候看看你可以传递给LLM的关于如何使用工具的额外指令了。
- en: Advanced tool-calling capabilities
  id: totrans-202
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高级工具调用功能
- en: Many LLMs offer you some additional configuration options on tool calling. First,
    some models support parallel function calling—specifically, an LLM can call multiple
    tools at once. LangChain natively supports this since the `tool_calls` field of
    an `AIMessage` is a list. When you return `ToolMessage` objects as function call
    results, you should carefully match the `tool_call_id` field of a `ToolMessage`
    to the generated payload. This alignment is necessary so that LangChain and the
    underlying LLM can match them together when doing the next turn.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 许多LLM在工具调用上提供了一些额外的配置选项。首先，一些模型支持并行函数调用——具体来说，一个LLM可以同时调用多个工具。LangChain原生支持这一点，因为`AIMessage`的`tool_calls`字段是一个列表。当你将`ToolMessage`对象作为函数调用结果返回时，你应该仔细匹配`ToolMessage`的`tool_call_id`字段与生成的有效载荷。这种对齐是必要的，以便LangChain和底层LLM在执行下一个回合时可以将它们匹配起来。
- en: Another advanced capability is forcing an LLM to call a tool, or even to call
    a specific tool. Generally speaking, an LLM decides whether it should call a tool,
    and if it should, which tool to call from the list of provided tools. Typically,
    it’s handled by `tool_choice` and/or `tool_config` arguments passed to the `invoke`
    method, but implementation depends on the model’s provider. Anthropic, Google,
    OpenAI, and other major providers have slightly different APIs, and although LangChain
    tries to unify arguments, in such cases, you should double-check details by the
    model’s provider.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 另一项高级功能是强制LLM调用一个工具，甚至调用特定的工具。一般来说，LLM决定是否调用工具，如果应该调用，则从提供的工具列表中选择哪个工具。通常，这是通过传递给`invoke`方法的`tool_choice`和/或`tool_config`参数来处理的，但实现取决于模型的提供者。Anthropic、Google、OpenAI和其他主要提供者有略微不同的API，尽管LangChain试图统一参数，但在这种情况下，你应该通过模型的提供者仔细检查细节。
- en: 'Typically, the following options are available:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，以下选项是可用的：
- en: '`"auto"`: An LLM can respond or call one or many tools.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"auto"`: 一个LLM可以响应或调用一个或多个工具。'
- en: '`"any"`: An LLM is forced to respond by calling one or many tools.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"any"`: LLM被迫通过调用一个或多个工具来响应。'
- en: '`"tool"` or `"any"` with a provided list of tools: An LLM is forced to respond
    by calling a tool from the restricted list.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"tool"`或`"any"`与提供的工具列表：LLM被迫通过调用受限列表中的工具来响应。'
- en: '`"None"`: An LLM is forced to respond without calling a tool.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"None"`: LLM被迫响应而不调用任何工具。'
- en: Another important thing to keep in mind is that schemas might become pretty
    complex—i.e., they might have nullable fields or nested fields, include enums,
    or reference other schemas. Depending on the model’s provider, some definitions
    might not be supported (and you will see warning or compiling errors). Although
    LangChain aims to make switching across vendors seamless, for some complex workflows,
    this might not be the case, so pay attention to warnings in the error logs. Sometimes,
    compilations of a provided schema to a schema supported by the model’s provider
    are done on the best effort basis—for example, a field with a type of `Union[str,
    int]` is compiled to a `str` type if an underlying LLM doesn’t support `Union`
    types with tool calling. You’ll get a warning, but ignoring such a warning during
    a migration might change the behavior of your application unpredictably.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个需要记住的重要事情是，模式可能变得相当复杂——例如，它们可能有可空字段或嵌套字段，包括枚举，或引用其他模式。根据模型提供者的不同，一些定义可能不受支持（你将看到警告或编译错误）。尽管LangChain旨在使跨供应商的切换无缝，但对于一些复杂的流程，这可能并不适用，因此请注意错误日志中的警告。有时，将提供的模式编译为模型提供者支持的模式的编译是在尽力而为的基础上进行的——例如，如果底层LLM不支持具有工具调用的`Union`类型，则具有`Union[str,
    int]`类型的字段将编译为`str`类型。你会收到警告，但在迁移过程中忽略此类警告可能会不可预测地改变应用程序的行为。
- en: As a final note, it is worth mentioning that some providers (for example, OpenAI
    or Google) offer custom tools, such as a code interpreter or Google search, that
    can be invoked by the model itself, and the model will use the tool’s output to
    prepare a final generation. You can think of this as a ReACT agent on the provider’s
    side, where the model receives an enhanced response based on a tool it calls.
    This approach reduces latency and costs. In these cases, you typically supply
    the LangChain wrapper with a custom tool created using the provider’s SDK rather
    than one built with LangChain (i.e., a tool that doesn’t inherit from the `BaseTool`
    class), which means your code won’t be transferable across models.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一点值得注意的是，一些提供者（例如，OpenAI或Google）提供自定义工具，例如代码解释器或Google搜索，模型本身可以调用这些工具，并且模型将使用工具的输出来准备最终的生成。你可以将其视为提供方侧的ReACT代理，其中模型根据它调用的工具接收增强的响应。这种方法减少了延迟和成本。在这些情况下，你通常需要向LangChain包装器提供一个使用提供者SDK创建的自定义工具，而不是使用LangChain构建的工具（即不继承自`BaseTool`类的工具），这意味着你的代码无法跨模型迁移。
- en: Incorporating tools into workflows
  id: totrans-212
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将工具融入工作流程
- en: Now that we know how to create and use tools, let’s discuss how we can incorporate
    the tool-calling paradigm deeper into the workflows we’re developing.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道了如何创建和使用工具，让我们讨论如何将工具调用范式更深入地融入到我们正在开发的流程中。
- en: Controlled generation
  id: totrans-214
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 受控生成
- en: In [*Chapter 3*](E_Chapter_3.xhtml#_idTextAnchor107), we started to discuss
    a *controlled* generation, when you want an LLM to follow a specific schema. We
    can improve our parsing workflows not only by creating more sophisticated and
    reliable parsers but also by being more strict in forcing an LLM to adhere to
    a certain schema. Calling a tool requires controlled generation since the generated
    payload should follow a specific schema, but we can take a step back and substitute
    our expected schema with a forced tool calling that follows the expected schema.
    LangChain has a built-in mechanism to help with that—an LLM has the `with_structured_output`
    method that takes a schema as a Pydantic model, converts it to a tool, invokes
    the LLM with a given prompt by forcing it to call this tool, and parses the output
    by compiling to a corresponding Pydantic model instance.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第三章*](E_Chapter_3.xhtml#_idTextAnchor107)中，我们开始讨论了一种*受控生成*，即当你希望一个LLM遵循特定模式时。我们可以通过创建更复杂和可靠的解析器，以及更严格地强制LLM遵循某种模式来改进我们的解析工作流程。调用一个工具需要受控生成，因为生成的有效负载应该遵循特定模式，但我们可以退一步，用强制调用遵循预期模式的工具来替换我们期望的模式。LangChain有一个内置机制来帮助实现这一点——一个LLM有`with_structured_output`方法，它接受一个作为Pydantic模型的模式，将其转换为工具，通过强制它调用这个工具来使用给定的提示调用LLM，并通过编译到相应的Pydantic模型实例来解析输出。
- en: 'Later in this chapter, we’ll discuss a plan-and-solve agent, so let’s start
    preparing a building block. Let’s ask our LLM to generate a plan for a given action,
    but instead of parsing the plan, let’s define it as a Pydantic model (a `Plan`
    is a list of `Steps`):'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '在本章的后面部分，我们将讨论一个计划-解决代理，所以让我们开始准备一个构建块。让我们要求我们的LLM为给定的动作生成一个计划，但不是解析这个计划，而是将其定义为Pydantic模型（`Plan`是一个`Steps`列表）:'
- en: '[PRE49]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Keep in mind that we use nested models (one field is referencing another),
    but LangChain will compile a unified schema for us. Let’s put together a simple
    workflow and run it:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，我们使用嵌套模型（一个字段引用另一个字段），但 LangChain 会为我们编译一个统一的模式。让我们组合一个简单的流程并运行它：
- en: '[PRE50]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'If we inspect the output, we’ll see that we got a Pydantic model as a result.
    We don’t need to parse the output anymore; we got a list of specific steps out
    of the box (and later, we’ll see how we can use it further):'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们检查输出，我们会看到我们得到了一个 Pydantic 模型作为结果。我们不再需要解析输出；我们直接得到了一系列特定的步骤（稍后，我们将看到如何进一步使用它）：
- en: '[PRE51]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: Controlled generation provided by the vendor
  id: totrans-222
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 供应商提供的受控生成
- en: 'Another way is vendor-dependent. Some foundational model providers offer additional
    API parameters that can instruct a model to generate a structured output (typically,
    a JSON or enum). You can force the model to use JSON generation the same way as
    above using `with_structured_output`, but provide another argument, `method="json_mode"`
    (and double-check that the underlying model provider supports controlled generation
    as JSON):'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方式是供应商依赖的。一些基础模型提供商提供了额外的 API 参数，可以指示模型生成结构化输出（通常是 JSON 或枚举）。你可以像上面一样使用 `with_structured_output`
    强制模型使用 JSON 生成，但提供另一个参数，`method="json_mode"`（并确保底层模型提供商支持受控的 JSON 生成）：
- en: '[PRE52]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Note that the JSON schema doesn’t contain descriptions of the fields, hence
    typically, your prompts should be more detailed and informative. But as an output,
    we get a full-qualified Python dictionary:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，JSON 模式不包含字段的描述，因此通常，你的提示应该更加详细和具有信息性。但作为输出，我们得到了一个完整的 Python 字典：
- en: '[PRE53]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'You can instruct the LLM instance directly to follow controlled generation
    instructions. Note that specific arguments and functionality might vary from one
    model provider to another (for example, OpenAI models use a `response_format`
    argument). Let’s look at how to instruct Gemini to return JSON:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以直接指示 LLM 实例遵循受控生成指令。请注意，特定的参数和功能可能因模型提供商而异（例如，OpenAI 模型使用 `response_format`
    参数）。让我们看看如何指导 Gemini 返回 JSON：
- en: '[PRE54]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'We can also ask Gemini to return an enum—in other words, only one value from
    a set of values:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以让 Gemini 返回一个枚举值——换句话说，从一组值中只返回一个值：
- en: '[PRE55]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: LangChain abstracts the details of the model provider’s implementation with
    the `method="json_mode"` parameter or by allowing custom `kwargs` to be passed
    to the model. Some of the controlled generation capabilities are model-specific.
    Check your model’s documentation for supported schema types, constraints, and
    arguments.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 通过 `method="json_mode"` 参数或允许将自定义 `kwargs` 传递给模型来抽象模型提供商实现细节。一些受控生成功能是模型特定的。检查你的模型文档以了解支持的架构类型、约束和参数。
- en: ToolNode
  id: totrans-232
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ToolNode
- en: To simplify agent development, LangGraph has built-in capabilities such as `ToolNode`
    and `tool_conditions`. The `ToolNode` checks the last message in `messages` (you
    can redefine the key name). If this message contains tool calls, it invokes the
    corresponding tools and updates the state. On the other hand, `tool_conditions`
    is a conditional edge that checks whether `ToolNode` should be called (or finishes
    otherwise).
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化代理开发，LangGraph 内置了诸如 `ToolNode` 和 `tool_conditions` 等功能。`ToolNode` 检查 `messages`
    中的最后一条消息（你可以重新定义键名）。如果这条消息包含工具调用，它将调用相应的工具并更新状态。另一方面，`tool_conditions` 是一个条件边，用于检查是否应该调用
    `ToolNode`（或者以其他方式完成）。
- en: 'Now we can build our ReACT engine in minutes:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以在几分钟内构建我们的 ReACT 引擎：
- en: '[PRE56]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: Tool-calling paradigm
  id: totrans-236
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工具调用范式
- en: Tool calling is a very powerful design paradigm that requires a change in how
    you develop your applications. In many cases, instead of performing rounds of
    prompt engineering and many attempts to improve your prompts, think whether you
    could ask the model to call a tool instead.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 工具调用是一种非常强大的设计范式，它需要改变你开发应用程序的方式。在许多情况下，与其进行多轮提示工程和多次尝试改进你的提示，不如考虑是否可以要求模型调用工具。
- en: 'Let’s assume we’re working on an agent that deals with contract cancellations
    and it should follow certain business logic. First, we need to understand the
    contract starting date (and dealing with dates might be difficult!). If you try
    to come up with a prompt that can correctly handle cases like this, you’ll realize
    it might be quite difficult:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们正在开发一个处理合同取消的代理，它应该遵循某些业务逻辑。首先，我们需要了解合同的开始日期（处理日期可能很困难！）！如果你尝试提出一个可以正确处理此类情况的提示，你会发现这可能相当困难：
- en: '[PRE57]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Instead, force a model to call a tool (and maybe even through a ReACT agent!).
    For example, we have two very native tools in Python—`date` and `timedelta`:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，强迫模型调用一个工具（也许甚至通过一个ReACT代理！）例如，Python中有两个非常本地的工具——`date`和`timedelta`：
- en: '[PRE58]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: '[PRE59]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Now it works like a charm:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 现在它工作得像魔法一样：
- en: '[PRE60]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: '[PRE61]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: We learned how to use tools, or function calls, to enhance LLMs’ performance
    on complex tasks. This is one of the fundamental architectural patterns behind
    agents—now it’s time to discuss what an agent is.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 我们学习了如何使用工具或函数调用来增强LLMs在复杂任务上的性能。这是代理背后的基本架构模式之一——现在是我们讨论代理是什么的时候了。
- en: What are agents?
  id: totrans-247
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 代理是什么？
- en: Agents are one of the hottest topics of generative AI these days. People talk
    about agents a lot, but there are many different definitions of what an agent
    is. LangChain itself defines an agent as “*a system that uses an LLM to decide
    the control flow of an application*.” While we feel it’s a great definition that
    is worth citing, it missed some aspects.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 代理是目前生成式AI最热门的话题之一。人们经常谈论代理，但关于代理的定义有很多不同的说法。LangChain本身将代理定义为“*一个使用LLM来决定应用程序控制流的系统*。”虽然我们认为这是一个很好的定义，值得引用，但它遗漏了一些方面。
- en: 'As Python developers, you might be familiar with duck typing to determine an
    object’s behavior by the so-called duck test: “*If it walks like a duck and it
    quacks like a duck, then it must be a duck*.” With that concept in mind, let’s
    describe some properties of an agent in the context of generative AI:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 作为Python开发者，你可能熟悉鸭子类型，通过所谓的鸭子测试来确定对象的行为：“*如果它像鸭子走路，它像鸭子嘎嘎叫，那么它一定是一只鸭子*。”带着这个概念，让我们在生成式AI的背景下描述一些代理的性质：
- en: Agents help a user solve complex non-deterministic tasks without being given
    an explicit algorithm on how to do it. Advanced agents can even act on behalf
    of a user.
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代理帮助用户解决复杂的非确定性任务，而无需给出如何做的明确算法。高级代理甚至可以代表用户行动。
- en: To solve a task, agents typically perform multiple steps and iterations. They
    *reason* (generate new information based on available context), *act* (interact
    with the external environment), *observe* (incorporate feedback from the external
    environment), and *communicate* (interact and/or work collaboratively with other
    agents or humans).
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了解决一个任务，代理通常执行多个步骤和迭代。它们*推理*（根据可用上下文生成新信息），*行动*（与外部环境互动），*观察*（整合外部环境的反馈），以及*通信*（与其他代理或人类互动和/或协作）。
- en: Agents utilize LLMs for reasoning (and solving tasks).
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代理利用LLMs进行推理（和解决问题）。
- en: While agents have certain autonomy (and to a certain extent, they even figure
    out what is the best way to solve the task by thinking and learning from interacting
    with the environment), when running an agent, we’d still like to keep a certain
    degree of control of the execution flow.
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 虽然代理具有一定的自主性（并且在某种程度上，它们甚至可以通过与环境互动思考和学习的最佳方式来解决任务），但在运行代理时，我们仍然希望保持对执行流程的一定程度的控制。
- en: Retaining control over an agent’s behavior—an agentic workflow—is a core concept
    behind LangGraph. While LangGraph provides developers with a rich set of building
    blocks (such as memory management, tool invocation, and cyclic graphs with recursion
    depth control), its primary design pattern focuses on managing the flow and level
    of autonomy that LLMs exercise in executing tasks. Let’s start with an example
    and develop our agent.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 控制代理的行为——一个代理工作流程——是LangGraph背后的核心概念。虽然LangGraph为开发者提供了一套丰富的构建块（例如内存管理、工具调用和具有递归深度控制的循环图），但其主要设计模式侧重于管理LLMs在执行任务时发挥的流程和自主程度。让我们从一个例子开始，并开发我们的代理。
- en: Plan-and-solve agent
  id: totrans-255
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 计划并解决代理
- en: What do we as humans typically do when we have a complex task ahead of us? We
    plan! In 2023, Lei Want et al. demonstrated that plan-and-solve prompting improves
    LLM reasoning. It has been also demonstrated by multiple studies that LLMs’ performance
    tends to deteriorate as the complexity (in particular, the length and the number
    of instructions) of the prompt increases.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们面临一个复杂的任务时，我们作为人类通常会做什么？我们制定计划！在2023年，雷万特等人证明了计划并解决提示可以提高LLM的推理能力。也有多项研究表明，随着提示的复杂性（特别是长度和指令的数量）的增加，LLMs的性能往往会下降。
- en: Hence, the first design pattern to keep in mind is *task decomposition*—to decompose
    complex tasks into a sequence of smaller ones, keep your prompts simple and focused
    on a single task, and don’t hesitate to add examples to your prompts. In our case,
    we are going to develop a research assistant.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，需要记住的第一个设计模式是*任务分解*——将复杂任务分解成一系列更小的任务，使提示简单并专注于单一任务，并且不要犹豫在提示中添加示例。在我们的案例中，我们将开发一个研究助理。
- en: Faced with a complex task, let’s first ask the LLM to come up with a detailed
    plan to solve this task, and then use the same LLM to execute on every step. Remember,
    at the end of the day, LLMs autoregressively generate output tokens based on input
    tokens. Such simple patterns as ReACT or plan-and-solve help us to better use
    their implicit reasoning capabilities.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 面对复杂任务时，让我们首先让LLM提出一个详细的计划来解决这个任务，然后使用同一个LLM在每一步执行。记住，最终，LLM根据输入令牌自回归地生成输出令牌。像ReACT或计划-求解这样的简单模式帮助我们更好地利用它们的隐式推理能力。
- en: 'First, we need to define our planner. There’s nothing new here; we’re using
    building blocks that we have already discussed—chat prompt templates and controlled
    generation with a Pydantic model:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要定义我们的规划器。这里没有什么新的；我们正在使用我们已经讨论过的构建块——聊天提示模板和Pydantic模型的控制生成：
- en: '[PRE62]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: '[PRE63]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'For a step execution, let’s use a ReACT agent with built-in tools—DuckDuckGo
    search, retrievers from arXiv and Wikipedia, and our custom `calculator` tool
    we developed earlier in this chapter:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 对于步骤执行，让我们使用内置工具的ReACT代理——DuckDuckGo搜索、来自arXiv和Wikipedia的检索器，以及我们在本章早期开发的自定义`calculator`工具：
- en: '[PRE64]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Next, let’s define our workflow state. We need to keep track of the initial
    task and initially generated plan, and let’s add `past_steps` and `final_response`
    to the state:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们定义我们的工作流程状态。我们需要跟踪初始任务和最初生成的计划，并让我们将`past_steps`和`final_response`添加到状态中：
- en: '[PRE65]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'Now, it’s time to define our nodes and edges:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，是时候定义我们的节点和边了：
- en: '[PRE66]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'And put together the final graph:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 然后组合最终的图：
- en: '[PRE67]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: '[PRE68]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: '![Figure 5.3: Plan-and-solve agentic workflow](img/B32363_05_03.png)'
  id: totrans-271
  prefs: []
  type: TYPE_IMG
  zh: '![图5.3：计划-求解代理工作流程](img/B32363_05_03.png)'
- en: 'Figure 5.3: Plan-and-solve agentic workflow'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.3：计划-求解代理工作流程
- en: 'Now we can run the workflow:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以运行工作流程：
- en: '[PRE69]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: You can see the full output on our GitHub, and we encourage you to play with
    it yourself. It might be especially interesting to investigate whether you like
    the result more compared to a single LLM prompt with a given task.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在我们的GitHub上看到完整的输出，我们鼓励您亲自尝试。与给定任务的单一LLM提示相比，您可能更喜欢这个结果。
- en: Summary
  id: totrans-276
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we explored how to enhance LLMs by integrating tools and design
    patterns for tool invocation, including the ReACT pattern. We started by building
    a ReACT agent from scratch and then demonstrated how to create a customized one
    with just one line of code using LangGraph.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了如何通过集成工具和工具调用设计模式（包括ReACT模式）来增强LLM。我们首先从头开始构建了一个ReACT代理，然后展示了如何使用LangGraph仅用一行代码创建一个定制的代理。
- en: Next, we delved into advanced techniques for controlled generation—showing how
    to force an LLM to call any tool or a specific one, and instructing it to return
    responses in structured formats (such as JSON, enums, or Pydantic models). In
    that context, we covered LangChain’s `with_structured_output` method, which transforms
    your data structure into a tool schema, prompts the model to call the tool, parses
    the output, and compiles it into a corresponding Pydantic instance.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们深入探讨了控制生成的先进技术——展示如何强制LLM调用任何工具或特定工具，并指示它以结构化格式（如JSON、枚举或Pydantic模型）返回响应。在这种情况下，我们介绍了LangChain的`with_structured_output`方法，该方法将您的数据结构转换为工具模式，提示模型调用工具，解析输出，并将其编译为相应的Pydantic实例。
- en: 'Finally, we built our first plan-and-solve agent with LangGraph, applying all
    the concepts we’ve learned so far: tool calling, ReACT, structured outputs, and
    more. In the next chapter, we’ll continue discussing how to develop agents and
    look into more advanced architectural patterns.'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们使用LangGraph构建了我们第一个计划-求解代理，应用了我们迄今为止学到的所有概念：工具调用、ReACT、结构化输出等等。在下一章中，我们将继续讨论如何开发代理，并探讨更多高级架构模式。
- en: Questions
  id: totrans-280
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: What are the key benefits of using tools with LLMs, and why are they important?
  id: totrans-281
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用工具与LLM的关键好处是什么，为什么它们很重要？
- en: How does LangChain’s ToolMessage class facilitate communication between the
    LLM and the external environment?
  id: totrans-282
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: LangChain的ToolMessage类如何促进LLM和外部环境之间的通信？
- en: Explain the ReACT pattern. What are its two main steps? How does it improve
    LLM performance?
  id: totrans-283
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解释 ReACT 模式。它包含哪两个主要步骤？它是如何提升 LLM 性能的？
- en: How would you define a generative AI agent? How does this relate to or differ
    from LangChain’s definition?
  id: totrans-284
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你会如何定义一个生成式 AI 代理？这与 LangChain 的定义有何关联或区别？
- en: Explain some advantages and disadvantages of using the with_structured_output
    method compared to using a controlled generation directly.
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 与直接使用受控生成相比，使用 with_structured_output 方法有哪些优缺点？
- en: How can you programmatically define a custom tool in LangChain?
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你如何在 LangChain 中程序化定义一个自定义工具？
- en: Explain the purpose of the Runnable.bind() and bind_tools() methods in LangChain.
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解释 LangChain 中 Runnable.bind() 和 bind_tools() 方法的用途。
- en: How does LangChain handle errors that occur during tool execution? What options
    are available for configuring this behavior?
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: LangChain 如何处理工具执行过程中发生的错误？有哪些选项可以配置这种行为？
- en: Subscribe to our weekly newsletter
  id: totrans-289
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 订阅我们的每周通讯
- en: Subscribe to AI_Distilled, the go-to newsletter for AI professionals, researchers,
    and innovators, at [https://packt.link/Q5UyU](E_Chapter_5.xhtml).
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 订阅 AI_Distilled，这是人工智能专业人士、研究人员和革新者的首选通讯，请访问 [https://packt.link/Q5UyU](E_Chapter_5.xhtml)。
- en: '![](img/Newsletter_QRcode1.jpg)'
  id: totrans-291
  prefs: []
  type: TYPE_IMG
  zh: '![Newsletter_QRcode1.jpg](img/Newsletter_QRcode1.jpg)'
