# 3. 主题建模和主题提取

概述

本章描述了使用Amazon Comprehend分析文档来理解文档集中共同主题的使用。你将学习用于主题建模的算法的基本原理，**潜在狄利克雷分配**（**LDA**）。学习LDA将使你能够将主题建模应用于各种独特的业务案例。然后，你将对具有已知主题结构的两个文档执行主题建模。到本章结束时，你将能够通过Amazon Comprehend进行主题建模来提取和分析共同主题，并描述主题建模分析的基本原理。你还将能够对一组文档执行主题建模并分析结果。

# 简介

主题建模是企业系统理解非结构化信息的重要能力，范围从支持票到客户反馈和投诉，再到商业文件。主题建模有助于自动化处理客户反馈和邮件；它使企业能够对来自各种渠道的社会媒体帖子、评论和其他用户生成内容进行分类，并有效地响应。它使企业能够通过理解传入的多渠道交互中的主题和主题，以及通过将材料路由到最合适的团队来最有效地响应关键事项。主题建模帮助的两个其他领域是知识管理和品牌监控。

# 使用潜在狄利克雷分配（LDA）进行主题建模

一组文档的主题或**常见主题**可以使用Amazon Comprehend来确定。例如，你有一个电影评论网站，有两个论坛，你想要确定哪个论坛正在讨论两部新上映的电影（一部关于体育，另一部关于政治话题）。你可以提供论坛的文本数据给Amazon Comprehend，以发现每个论坛上讨论的最突出主题。

Amazon Comprehend用于执行主题建模的机器学习算法称为**潜在狄利克雷分配**（**LDA**）。LDA是一个基于学习的模型，用于确定文档集合中最重要的主题。

LDA的工作原理是，它将每个文档视为主题的组合，文档中的每个单词都与这些主题之一相关联。

例如，如果一份文档的第一段包含诸如**吃**、**鸡肉**、**餐厅**和**烹饪**等词语，那么你可以得出结论，该主题可以概括为**食物**。同样，如果文档的第二段包含诸如**票**、**火车**、**公里**和**假期**等词语，那么你可以得出结论，该主题是**旅行**。

## 基本LDA示例

LDA 后面有很多数学原理——例如 **期望最大化**、吉布斯抽样、先验和“词袋”上的概率分布。如果你想了解数学基础，可以从 Amazon 的 SageMaker 文档（[https://docs.aws.amazon.com/sagemaker/latest/dg/lda-how-it-works.html](https://docs.aws.amazon.com/sagemaker/latest/dg/lda-how-it-works.html)）开始。让我们更实际地看看 LDA，并通过一个例子来实证地理解它。

假设你有一篇包含六个句子的文档，你想推断出两个共同的主题。

句子如下：

+   他们彼此深爱着。

+   大多数人体验爱情时并没有意识到它有什么特别之处。

+   部分原因是战争；其余的是革命所造成的。

+   战争是生活中的一种人为的断裂，好像生活可以被推迟一段时间。多么荒谬！

+   我说的是生活，但我指的是你在伟大画作中看到的生活，被天才所改变，创造性地丰富。

+   只有现在人们才决定在自身中体验它，而不是在书籍和图片中，不是作为一种抽象，而是在实践中。

当你将这些句子输入到 LDA 算法中，指定主题数量为两个时，它将发现以下内容：

**句子-主题**

句子 1：主题 0

句子 2：主题 0

句子 3：主题 1

句子 4：主题 1

句子 5：主题 0

句子 6：主题 0

**主题术语**

主题 0：生活 12%，人们 8%，体验 8%，爱情 5%，等等

主题 1：62% 革命，23% 战争，其余 15%

当然，知道这些句子来自著名俄罗斯作家鲍里斯·帕斯捷尔纳克所著的《日瓦戈医生》一书，主题战争和生命/爱情似乎是有道理的。

尽管这个例子是对一个复杂算法的简单描述，但它给你一个想法。正如本章所讨论的，在各种商业场景中，一个文档或电子邮件或社交媒体帖子所涉及内容的指示对于下游系统来说非常有价值——能够自动执行这种分类的能力是无价的。

## 为什么使用 LDA？

当你想根据共同的主题对一组文档进行分组，而不考虑文档本身时，LDA 非常有用。LDA 可以通过分析文档中的单词来推断一般主题，从而创建主题。这通常用于建议框架、报告安排和记录摘要。总之，LDA 有很多用途。例如，你有 30,000 用户的电子邮件，并想确定最常见的主题，以便根据最普遍的主题提供针对特定群体的推荐内容。手动阅读，或者外包手动阅读，30,000 封电子邮件将需要大量的时间和金钱投入，而且准确性难以确认。然而，Amazon Comprehend 可以在几个步骤内无缝地以惊人的准确性提供 30,000 封电子邮件中最常见的主题。首先，将电子邮件转换为文本文件，上传到 S3 桶中，然后使用 Amazon Comprehend 模拟一个主题建模作业。输出是包含相应主题和术语的两个 CSV 文件。

# Amazon Comprehend—主题建模指南

如果你向 Comprehend 提供尽可能大的语料库，可以获得最准确的结果。更具体地说：

+   每个主题中应使用不少于 1,000 条记录。

+   每个文档应该像三句话那么长。

+   如果一个文档大部分是数字信息，你应该将其从语料库中排除。

目前，主题建模仅限于两种文档语言：**英语**和**西班牙语**。

主题建模作业允许两种输入数据格式类型（参见图 3.1）。这使用户能够处理大型文档集合（例如，报纸文章或科学期刊），以及短文档（例如，推文或社交媒体帖子）。

**输入格式选项：**

![图 3.1：AWS Comprehend—主题建模输入格式选项](img/B16061_03_01.jpg)

![img/B16061_03_01.jpg](img/B16061_03_01.jpg)

图 3.1：AWS Comprehend—主题建模输入格式选项

**输出格式选项：**

![图 3.2：AWS Comprehend—主题建模输出文件描述](img/B16061_03_02.jpg)

![img/B16061_03_02.jpg](img/B16061_03_02.jpg)

图 3.2：AWS Comprehend—主题建模输出文件描述

在 Amazon Comprehend 处理完你的文档集合后，建模输出两个 CSV 文件：`topic-terms.csv`（参见图 3.2）和 `doc-topics.csv`。

`topic-terms.csv` 文件提供了文档集合中主题的列表，包括术语、相应的主题及其权重。例如，如果你向 Amazon Comprehend 提供了两篇假设文档，**学习园艺**和**投资策略**，它可能会返回以下内容来描述集合中的两个主题：

![图 3.3：两个文档输入的示例主题建模输出（topic-terms.csv）](img/B16061_03_03.jpg)

![img/B16061_03_03.jpg](img/B16061_03_03.jpg)

图 3.3：两个文档输入的示例主题建模输出（topic-terms.csv）

`doc-topics.csv`文件提供了为主题建模作业提供的文档列表，以及每个文档中相应的主题及其比例。对于两个假设文档`learning_to_garden.txt`和`investment_strategies.txt`，你可以期待以下输出：

![图3.4：两个文档输入的样本主题建模输出（doc-topics.csv）

](img/B16061_03_04.jpg)

图3.4：两个文档输入的样本主题建模输出（doc-topics.csv）

## 练习3.01：使用Amazon Comprehend对具有已知主题的两个文档进行主题建模

在这个练习中，我们将使用两份文档（**罗密欧与朱丽叶**和**世界大战**）来更好地理解LDA。我们将使用Amazon Comprehend来发现这两份文档中的主要主题。在开始练习之前，只需查看数据管道架构的概述。文本文件存储在S3中，然后我们指导Comprehend在输入存储桶中查找文件。Comprehend分析文档，并将结果放回S3的输出存储桶中：

![图3.5：数据管道架构概述

](img/B16061_03_05.jpg)

图3.5：数据管道架构概述

完成已知主题结构的主题建模：

1.  首先，你需要进入S3控制台。请参阅*第一章*，*AWS简介*，以获取账户设置说明。访问[https://aws.amazon.com/](https://aws.amazon.com/)，点击`我的账户`然后点击`AWS管理控制台`。点击`服务`，然后在新的浏览器标签页中搜索或选择`S3`。你将看到以下截图所示的S3控制台：![图3.6：Amazon S3控制台

    ](img/B16061_03_06.jpg)

    图3.6：Amazon S3控制台

1.  我们需要一个输入和输出S3存储桶。让我们创建这两个存储桶。现在，点击`创建存储桶`按钮来创建一个存储桶：![图3.7：创建存储桶

    ](img/B16061_03_07.jpg)

    图3.7：创建存储桶

1.  对于存储桶名称，输入一个描述功能的唯一名称。在这里，使用名称`aws-ml-input-for-topic-modeling`。点击`创建`按钮：

    注意

    AWS中的存储桶名称必须唯一。因此，你可能会收到一个错误信息，说“存储桶名称已存在”。获取一个唯一名称的一个简单方法是将今天的日期（如果需要，加上时间）附加到存储桶名称上；例如，YYYYMMDDHHMM。在编写这一章时，我们创建了一个存储桶，名为`aws-ml-input-for-topic-modeling-20200301`。

    在以下窗口中点击`创建`将使用所有默认设置属性和权限，而点击`下一步`允许你根据需要调整这些设置。

    ![图3.8：创建存储桶名称输入

    ](img/B16061_03_08.jpg)

    图3.8：创建存储桶名称输入

1.  点击`下一步`，然后再次点击`下一步`以转到`配置选项`，再点击一次`下一步`以转到`设置权限`，最后在`审阅`选项卡中点击`创建存储桶`：

1.  现在，点击桶，然后点击`创建文件夹`按钮来创建一个文件夹：![图3.9：在S3中为主题建模输入创建文件夹

    ](img/B16061_03_09.jpg)

    图3.9：在S3中为主题建模输入创建文件夹

1.  现在，将文件夹名称输入为`known_structure`，然后点击`保存`按钮：![图3.10：保存`known_structure`文件夹名称

    ](img/B16061_03_10.jpg)

    图3.10：保存`known_structure`文件夹名称

1.  点击`保存`按钮后，你的文件夹将被生成。现在，点击`known_structure`文件夹：![图3.11：输入桶屏幕

    ](img/B16061_03_11.jpg)

    图3.11：输入桶屏幕

1.  现在，点击`上传`按钮：![图3.12：上传按钮

    ](img/B16061_03_12.jpg)

    图3.12：上传按钮

1.  现在，你将被提示向文件夹中添加文件。点击`添加文件`，或将文件拖放到屏幕上：![图3.13：添加文件按钮

    ](img/B16061_03_13.jpg)

    图3.13：添加文件按钮

1.  本章的文件位于GitHub仓库的`Chapter03`文件夹中，网址为[https://packt.live/3eba6rM](https://packt.live/3eba6rM)。正如我们在*第一章*，*AWS简介*中提到的，你应该已经将GitHub文件下载到本地子目录中。

    通过一个例子，我们已经将文件下载到`Documents/aws-book/The-Applied-AI-and-Natural-Language-Processing-with-AWS`目录。导航到`上传`，从你的本地磁盘选择以下两个文本文件。正如你可能猜到的，这个练习的文件位于`Exercise3.01`子目录中：

    文件选择完毕后，点击`打开`按钮上传文件：

    ![图3.14：从本地目录选择要上传的文件

    ](img/B16061_03_14.jpg)

    图3.14：从本地目录选择要上传的文件

    下面的图显示了文本文件的上传过程：

    ![图3.15：上传两个`known_structure`文本文件

    ](img/B16061_03_15.jpg)

    图3.15：上传两个`known_structure`文本文件

1.  在`设置权限`和`设置属性`选项卡中点击`下一步`。在`审查`选项卡中选择`上传`：![图3.16：Amazon S3上传文件

    ](img/B16061_03_16.jpg)

    图3.16：Amazon S3上传文件

1.  导航到`Amazon S3`主屏幕：![图3.17：Amazon S3

    ](img/B16061_03_17.jpg)

    图3.17：Amazon S3

1.  接下来，创建一个输出S3桶。使用相同的S3桶创建过程。为此，点击`创建桶`按钮：![图3.18：创建桶

    ](img/B16061_03_18.jpg)

    图3.18：创建桶

1.  现在，命名桶，然后点击`创建`按钮：![图3.19：为主题建模创建桶输出

    ](img/B16061_03_19.jpg)

    图3.19：为主题建模创建桶输出

1.  在`配置选项`下点击`下一步`，在`设置权限`下点击`下一步`，在`审查`窗口中点击`创建桶`。

    现在，你有了两个桶，一个用于输入，包含两个文本文件，另一个输出桶为空。现在让我们继续使用Amazon Comprehend。

1.  导航到Amazon Comprehend：[https://console.aws.amazon.com/comprehend/](https://console.aws.amazon.com/comprehend/). 如果您看到以下屏幕，请点击`启动Amazon Comprehend`：![图3.20：Amazon Comprehend主页

    ![图片](img/B16061_03_20.jpg)

    图3.20：Amazon Comprehend主页

1.  现在，在左侧工具栏中点击第一个`分析作业`选项（**不是**Amazon Comprehend Medical下的那个）：![图3.21：Amazon Comprehend组织屏幕

    ![图片](img/B16061_03_21.jpg)

    图3.21：Amazon Comprehend组织屏幕

1.  现在，点击`创建作业`按钮：![图3.22：Amazon Comprehend创建作业按钮

    ![图片](img/B16061_03_22.jpg)

    图3.22：Amazon Comprehend创建作业按钮

1.  在`名称`字段中输入`known_structure_topic_modeling_job`：![图3.23：主题建模作业名称

    ![图片](img/B16061_03_23.jpg)

    图3.23：主题建模作业名称

1.  在`分析类型`下拉框中选择`主题建模`：![图3.24：选择分析类型（主题建模）

    ![图片](img/B16061_03_24.jpg)

    图3.24：选择分析类型（主题建模）

1.  现在，滚动到`输入数据`选项卡，然后点击`浏览S3`：![图3.25：点击搜索以定位主题建模输入数据源

    ![图片](img/B16061_03_25.jpg)

    图3.25：点击搜索以定位主题建模输入数据源

1.  将显示S3存储桶列表：![图3.26：选择输入存储桶

    ![图片](img/B16061_03_26.jpg)

    图3.26：选择输入存储桶

1.  选择输入存储桶（在我的情况下，它是`aws-ml-input-for-topic-modeling-20200301`），然后点击存储桶。然后，文件夹将显示：![图3.27：选择输入文件夹

    ![图片](img/B16061_03_27.jpg)

    图3.27：选择输入文件夹

1.  点击`known_structure`旁边的单选按钮，然后点击`Choose`按钮，这将带您到以下屏幕：![图3.28：输入数据部分，已填写S3位置

    ![图片](img/B16061_03_28.jpg)

    图3.28：输入数据部分，已填写S3位置

1.  现在，从下拉菜单中选择`每个文件一个文档`：![图3.29：选择每个文件一个文档

    ![图片](img/B16061_03_29.jpg)

    图3.29：选择每个文件一个文档

1.  现在，为所需的`主题数量`输入`2`：![图3.30：输入2以执行主题建模

    ![图片](img/B16061_03_30.jpg)

    图3.30：输入2以执行主题建模

1.  接下来，在`输出数据`选项卡中点击`浏览S3`：![图3.31：输出数据选项卡和用于主题建模S3输出位置的浏览S3按钮

    ![图片](img/B16061_03_31.jpg)

    图3.31：输出数据选项卡和用于主题建模S3输出位置的浏览S3按钮

1.  选择输出存储桶（在我们的情况下，它是`aws-ml-output-for-topic-modeling-20200301`），然后点击`Choose`：![图3.32：选择输出S3存储桶

    ![图片](img/B16061_03_32.jpg)

    图3.32：选择输出S3存储桶

1.  确保输出数据标签页看起来与以下截图类似：![图3.33：带有输出存储桶名称的输出数据标签页

    ![图片](img/B16061_03_33.jpg)

    图3.33：带有输出存储桶名称的输出数据标签页

1.  滚动到“访问权限”标签页，然后选择“创建IAM角色”选项：![图3.34：选择创建IAM角色并提供访问权限

    输入和输出S3存储桶

    ![图片](img/B16061_03_34.jpg)

    图3.34：选择创建IAM角色并为输入和输出S3存储桶提供权限

    确认“输入和输出S3存储桶”列在“访问权限”下：

1.  在“名称后缀”字段中输入`myTopicModelingRole`，然后点击“创建作业”按钮：![图3.35：点击创建作业按钮

    ![图片](img/B16061_03_35.jpg)

    图3.35：点击创建作业按钮

1.  创建作业可能需要几分钟，您可能会看到消息“传播IAM角色，请留在页面上。”一旦创建完成，您将被重定向到Comprehend主屏幕，如下所示：![图3.36：Comprehend主屏幕

    ![图片](img/B16061_03_36.jpg)

    图3.36：Comprehend主屏幕

    注意

    请记住，点击“创建作业”也会启动作业。没有单独的“启动作业”按钮。此外，如果您想重新做作业，您将不得不使用“复制”按钮。

1.  在作业处理过程中，显示的状态将是“进行中”：![图3.37：显示进行中状态

    ![图片](img/B16061_03_37.jpg)

    图3.37：显示进行中状态

1.  在我们的账户上，完成这项工作大约需要4分钟。当状态变为“完成”时，点击主题建模作业名称：![图3.38：显示完成状态

    ![图片](img/B16061_03_38.jpg)

    图3.38：显示完成状态

1.  现在，滚动到“输出”部分：![图3.39：主题建模输出显示主屏幕

    ![图片](img/B16061_03_39.jpg)

    图3.39：主题建模输出显示主屏幕

1.  点击“数据位置”下的超链接：![图3.40：主题建模数据输出超链接位置

    ![图片](img/B16061_03_40.jpg)

    图3.40：主题建模数据输出超链接位置

    这将直接带您到S3存储桶：

    ![图3.41：S3中的主题建模输出文件

    ![图片](img/B16061_03_41.jpg)

    图3.41：S3中的主题建模输出文件

1.  点击“下载”并将文件保存在您的本地磁盘上。通常，“下载”文件夹是一个理想的位置：![图3.42：将主题建模输出文件下载到本地磁盘

    ![图片](img/B16061_03_42.jpg)

    图3.42：将主题建模输出文件下载到本地磁盘

1.  解压`output.tar.gz`，通常它将出现在output目录中：![图3.43：主题建模的输出文件

    ![图片](img/B16061_03_43.jpg)

    图3.43：主题建模的输出文件

1.  现在检查两个文件：`topic-terms.xlsx`和`doc-topics.xlsx`：

    注意

    你的 `topic-terms.csv` 和 `doc-topics.csv` 结果应与以下结果相同。如果你的结果不同，请使用本章剩余部分提供的输出文件，这些文件位于 *Chapter03/Exercise3.01/topic-terms.csv* [https://packt.live/3iHlH5y](https://packt.live/3iHlH5y) 和 *Chapter03/Exercise3.01/doc-topics.csv* [https://packt.live/2ZMTaTw](https://packt.live/2ZMTaTw)。

    以下为生成的输出。正如我们之前所指示的，我们希望有主题，Comprehend 已经将相关词汇分成了两个组/主题以及权重。它不知道这些主题是什么，但已经推断出词汇与两个主题中的一个的相似性：

    ![图 3.44：topic-terms.csv 结果

    ](img/B16061_03_44.jpg)

图 3.44：topic-terms.csv 结果

`doc-topics.csv` 显示文档与主题的亲和力。在这种情况下，它是非常确定的，但如果我们有更多主题，比例将显示每个文档中主题的强度：

![图 3.45：doc-topics.csv 结果

](img/B16061_03_45.jpg)

图 3.45：doc-topics.csv 结果

在这个练习中，我们使用了 Amazon Comprehend 来推断一组文档中嵌入的主题。虽然对于两个文档来说这更容易做到；当有数百个文档，且我们想要进行流程自动化时，Amazon Comprehend 非常有效。

## 练习 3.02：以编程方式执行已知结构分析

当我们查看一个或两个输出时，很容易；当我们想要扩展并分析具有不同主题的数百个文档时，我们需要使用 Comprehend 进行编程。这正是我们将在这个练习中做的。

在这个练习中，我们将以编程方式上传 CSV 文件（`doc-topics.csv` 和 `Topic-terms.csv`），在 S3 上合并主题列的 CSV 文件，并将输出打印到控制台。以下是执行已知结构分析的步骤：

注意

对于这一步，你将使用 Jupyter Notebook。你可以跟随练习并输入代码，或者从源代码文件夹 `local_csv_to_s3_for_analysis.ipynb` 中获取它，并将其粘贴到编辑器中。源代码可在以下 GitHub 仓库中找到：[https://packt.live/2BOqjWT](https://packt.live/2BOqjWT)。正如 *第 1 章* 中所解释的，*AWS 简介*，你应该已经将仓库下载到本地磁盘。

1.  首先，我们将使用以下命令导入 `boto3`：

    [PRE0]

1.  接下来，我们将使用以下命令导入 `pandas`：

    [PRE1]

1.  现在，我们将使用以下命令创建 S3 客户端对象：

    [PRE2]

1.  接下来，我们将创建一个具有唯一存储桶名称的变量。在这里，选定的存储桶名称是 `known-tm-analysis`，但你需要创建一个唯一的名称：

    [PRE3]

1.  接下来，创建一个新的存储桶：

    [PRE4]

1.  创建要导入的 CSV 文件名列表：

    [PRE5]

    注意

    确保上述步骤中提到的两个CSV文件（突出显示）存储在与您运行Jupyter Notebook代码相同的同一位置。另一种选择是指定在您的本地系统上存在的确切路径。

1.  现在，使用以下代码行迭代每个文件以上传到S3：

    [PRE6]

    注意

    还不要执行*步骤7*和*步骤8*。我们将在*步骤9*中展示整个`for`块的代码。

1.  接下来，检查文件名是否为`doc-topics.csv`：并获取`doc-topics.csv`文件对象，将其分配给`obj`变量。

    [PRE7]

1.  接下来，读取`csv`对象并将其分配给`doc_topics`变量。您可以看到包括以下*步骤7*和*步骤8*在内的整个代码块：

    [PRE8]

1.  现在，使用以下命令将主题列上的文件合并，以获取每份文档中最常见的术语：

    [PRE9]

1.  接下来，使用*Shift* + *Enter*键执行笔记本单元格：

1.  控制台输出是一个合并的DataFrame，它提供了具有相应术语的docnames以及术语的权重（参见图以下）：![图3.46：s3.create_bucket调用的输出

    ](img/B16061_03_46.jpg)

    图3.46：s3.create_bucket调用的输出

    ![图3.47：已知的结构主题建模合并结果

    ](img/B16061_03_47.jpg)

    图3.47：已知的结构主题建模合并结果

1.  为了验证CSV文件，导航到S3（如果新存储桶没有出现，请重新加载页面），新的存储桶已在S3中创建。点击存储桶以验证成功导入：![图3.48：已知的tm-analysis S3存储桶

    ](img/B16061_03_48.jpg)

图3.48：已知的tm-analysis S3存储桶

存储桶中将有两个CSV文件 - `doc-topics.csv`和`topic-terms.csv`：

![图3.49：上传到S3的主题建模结果

](img/B16061_03_49.jpg)

图3.49：上传到S3的主题建模结果

在这个练习中，我们学习了如何使用Comprehend进行编程。我们编程上传了两个CSV文件到S3，在列上合并它们，并将输出打印到控制台。

## 活动3.01：对一组未知主题的文档执行主题建模

在这个活动中，我们将对一组未知主题的文档执行主题建模。假设您的雇主希望您构建一个数据管道来分析存储在具有唯一ID文件名的单个文本文件中的负面电影评论。因此，您需要执行主题建模以确定哪些文件代表相应的主题。总的来说，负面评论对公司来说是一种损失，所以他们优先考虑负面评论而不是正面评论。公司的最终目标是将这些数据整合到反馈聊天机器人应用程序中。为了确保这一点，您需要一个包含负面评论的文件。这个活动的预期结果将是负面电影评论文件的主题建模结果。

**执行主题建模：**

1.  导航到以下链接（或您已下载GitHub文件的本地目录）以获取包含负面评论的文本数据文件：[https://packt.live/38Nw4jT](https://packt.live/38Nw4jT)。

1.  使用唯一名称为主题建模创建一个存储桶。

1.  为主题建模创建一个文件夹。

1.  导入Python库的依赖项，例如`os`和`boto3`。

1.  提及您的唯一存储桶名称。

1.  收集所有本地路径的工作目录并将它们转换为文本文件。

1.  为所有文本文件创建一个列表。

1.  遍历文件并将它们上传到S3。

1.  使用Amazon Comprehend在组织中创建一个作业。

1.  根据要求选择输入数据。这可能是指**我的文档**或**示例文档**。

1.  从数据源中选择文件。

1.  应用输入格式。

1.  提供要执行建模的主题数量。

1.  选择一个IAM角色并创建一个作业。

1.  下载输出文件并提取文件。

1.  生成的输出将包括两个CSV文件。

    **未知主题分析：**

1.  导入Python库的依赖项，例如`boto3`和`pandas`。

1.  创建一个S3客户端。

1.  使用唯一名称创建一个新的存储桶。

1.  创建一个CSV文件名列表以导入。

1.  检查文件名并将其分配给**obj**变量。

1.  读取**obj**变量。

1.  合并主题列上的文件。

1.  将合并的文件打印到控制台。

这是一个漫长的活动。然而，你能够管理1,000个文件，将它们上传到S3，使用Amazon Comprehend进行主题建模，然后将结果合并到一个包含超过40,000行的表中。在现实世界的情况下，你将处理数千份文档，而不仅仅是几份。这就是我们为什么使用Jupyter Notebook和Python来完成这个活动的原因。

然而，这只是一个多步骤自动化过程的第一步——对非结构化文档进行推理的重要且基本步骤。虽然Comprehend分析了文档并给出了主题列表，但确定如何处理这些主题仍然是我们的工作。

注意

该活动的解决方案可以在第291页找到。

# 摘要

在本章中，我们学习了如何分析AWS Comprehend的主题建模结果。你现在能够将S3用于存储数据并用于分析。我们还学习了如何在执行主题建模之前分析已知主题的文档以及主题未知文档的方法。我们知道后者需要额外的分析来确定相关主题。

我们没有构建分析主题列表并适当路由文档的下游系统。例如，你可能有一个将主题映射到用于知识管理的SharePoint文件夹的映射，或者一个根据检测到的主题通过电子邮件将文件路由到适当人员的流程。虽然更广泛的**机器人流程自动化**（RPA）主题超出了本书的范围，但你已经学会了如何使用Amazon Comprehend来实现流程自动化的主题和主题检测步骤。

本章所学知识的另一个应用是用于知识管理的文档聚类。在这种情况下，我们将主题数量限制为10个，然后根据主要主题对文档进行分类。例如，如果这些文档是新闻文章，这个过程将文章分为10个主题，这有助于在下游系统（如新的推荐引擎）中处理。

如你所见，主题建模可以应用于各种应用和系统。现在你已经拥有了使用Amazon Comprehend进行主题建模所需的技能。

在下一章中，我们将深入探讨聊天机器人的概念及其在自然语言处理中的应用。
