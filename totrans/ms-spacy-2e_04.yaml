- en: '4'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Mastering Rule-Based Matching
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Rule-based information extraction is indispensable for any **natural language
    processing** ( **NLP** ) pipeline. Certain types of entities, such as times, dates,
    and telephone numbers, have distinct formats that can be recognized by a set of
    rules without having to train statistical models.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, you will learn how to quickly extract information from text
    by matching patterns and phrases. You will use **morphological** **features**
    , **parts-of-speech** ( **POS** ) tags, **regular expressions** ( **regexes**
    ), and other spaCy features to form pattern objects to feed to **Matcher** objects.
    You will continue with fine-graining statistical models with rule-based matching
    to lift statistical models to better accuracies.
  prefs: []
  type: TYPE_NORMAL
- en: By the end of this chapter, you will know about a vital part of information
    extraction. You will also be able to extract entities of specific formats, as
    well as entities specific to your domain.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’re going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Token-based matching
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating patterns with **PhraseMatcher**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating patterns with **SpanRuler**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Combining spaCy models and matchers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The code of this chapter can be found at [https://github.com/PacktPublishing/Mastering-spaCy-Second-Edition](https://github.com/PacktPublishing/Mastering-spaCy-Second-Edition)
    . We are using **Python 3.10** and **spaCy 3.7.4** .
  prefs: []
  type: TYPE_NORMAL
- en: Token-based matching
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Some NLU tasks can be solved without the help of any statistical model. One
    of those ways is a **regex** , which we use to match a predefined set of patterns
    to our text.
  prefs: []
  type: TYPE_NORMAL
- en: A regex is a sequence of characters that specifies a search pattern. A regex
    describes a set of strings that follows the specified pattern. These patterns
    can include letters, digits, and characters with special meanings, such as **?**
    , **.** , and ***** . Python’s built-in library, **re** , provides great support
    to define and match regexes.
  prefs: []
  type: TYPE_NORMAL
- en: 'What does a regex look like, then? The following regex matches the following
    strings:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'This pattern can be read as follows: the string **Barack** can be followed
    optionally by the string **Hussein** (the **?** character in a regex means optional;
    that is, **0** or **1** occurrence) and should be followed by the string **Obama**
    . The inter-word spaces can be a single-space character, a tab, or any other whitespace
    character ( **\s** matches all sorts of whitespace characters, including the newline
    character).'
  prefs: []
  type: TYPE_NORMAL
- en: 'It’s not very readable, even for such a short and uncomplicated pattern, is
    it? Some downsides of regexes are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Difficult to read
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Difficult to debug
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Error-prone with space, punctuation, and number characters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For these reasons, many software engineers don’t like to work with regexes
    in their production code. spaCy provides a very clean, readable, production-level,
    and maintainable alternative: the **Matcher** class. The **Matcher** class can
    match our predefined rules to the sequence of tokens in **Doc** and **Span** objects.
    As we will see in this chapter, the rules can also refer to the token or its linguistic
    attributes.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s start with a basic example of how to call the **Matcher** class:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we import the library, the **Matcher** object, the **Span** token, and
    load the model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we instantiate the **Matcher** object passing the vocabulary of the model,
    define a pattern, and add it to the **Matcher** object with the label **morningGreeting**
    :'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, we can process the text. To visualize the **Span** objects with **displaCy**
    , we will add the **Span** objects to a list and attribute **doc.spans["sc"]**
    to this list. The **sc** instance is the default **span_key** value (group of
    arbitrary **Span** objects). Here is the code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, let’s show the spans with **displacy** :'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '*Figure 4* *.1* shows the result of the previous code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.1 – Span matches of our first Matcher pattern](img/B22441_04_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.1 – Span matches of our first Matcher pattern
  prefs: []
  type: TYPE_NORMAL
- en: 'You can read the **Matcher** pattern of the preceding *step 2* list as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: A token whose lowered text is **good**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A token whose lowered text is **morning**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A token that is punctuation (that is, the **IS_PUNCT** feature is **True** )
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A match result is a list of triplets in the form **(match id** , **start position**
    , and **end position)** . As you might have noticed, the whitespace between **Good**
    and **morning** didn’t matter at all. Indeed, we could have put two whitespaces
    in between, written down **Good morning** , and the result would be identical.
    Why? Because **Matcher** matches only tokens and token attributes.
  prefs: []
  type: TYPE_NORMAL
- en: 'A pattern always refers to a continuous sequence of token objects, and every
    item in bracelets corresponds to one token object. Let’s go back to the pattern
    in the preceding code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is always a three-token match. Can we add more than one pattern?
    The answer is yes. Let’s see it with an example, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the libraries and set the **Matcher** object just as before:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the two patterns and add them to the **Matcher** object:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Process the text, send the **doc** object to the **Matcher** object and store
    the **Span** objects in a list:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we can display the **Span** objects with displacy:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '*Figure 4* *.2* shows the result using the new pattern:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.2 – Span matches using two patterns](img/B22441_04_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.2 – Span matches using two patterns
  prefs: []
  type: TYPE_NORMAL
- en: 'In the preceding code example, **pattern1** and **pattern2** differ only by
    one token: **evening** / **morning** . Instead of writing two patterns, can we
    say evening or morning using the **IN** attribute. Let’s learn more about it in
    the next section.'
  prefs: []
  type: TYPE_NORMAL
- en: Extended syntax support
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Matcher** allows patterns to be more expressive by allowing some operators
    inside the curly braces. These operators are for extended comparison and look
    similar to Python’s **in** , **not in** , and **comparison** operators. You can
    see a full list of attributes in spaCy’s documentation, available at [https://spacy.io/api/matcher/#patterns](https://spacy.io/api/matcher/#patterns)
    . Previously we matched **good evening** and **good morning** with two different
    patterns. Now, we can match **good morning** / **evening** with one pattern with
    the help of **IN** as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Comparison operators usually go together with the **LENGTH** attribute. Here’s
    an example of finding long tokens:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '*Figure 4* *.3* shows the matches using this pattern:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.3 – Matches using LENGTH pattern](img/B22441_04_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.3 – Matches using LENGTH pattern
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will explore some of the most used token attributes
    used to create patterns.
  prefs: []
  type: TYPE_NORMAL
- en: Token attributes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s go over some useful token pattern keys with examples. We used **LOWER**
    in the preceding examples; it means the lowercase form of the token text. **ORTH**
    and **TEXT** are similar to **LOWER** : they mean an exact match of the token
    text, including the case. Here’s an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code will match **Bill** but not **bill** .
  prefs: []
  type: TYPE_NORMAL
- en: 'The next block of token attributes is **IS_ALPHA** , **IS_ASCII** , and **IS_DIGIT**
    . These features are handy for finding number tokens and ordinary words. The following
    pattern matches a sequence of two tokens, a number followed by an ordinary word:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code segment, **2 o''clock** didn’t match the pattern because
    **o''clock** contains an apostrophe, which is not an alphabetic character (alphabetic
    characters are digits, letters, and the underscore character). Let’s test the
    pattern using another sentence:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '*Figure 4* *.4* shows that **2 apples** matched because the **apples** token
    consists of letters:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.4 – Match using number and plain word pattern](img/B22441_04_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.4 – Match using number and plain word pattern
  prefs: []
  type: TYPE_NORMAL
- en: '**IS_LOWER** , **IS_UPPER** , and **IS_TITLE** are useful attributes for recognizing
    the token’s casing. **IS_UPPER** is **True** if the token is all uppercase letters,
    and **IS_TITLE** is **True** if the token starts with a capital letter. **IS_LOWER**
    is **True** if the token is all lowercase letters. Imagine we want to find emphasized
    words in a text; one way is to look for tokens with all uppercase letters. Uppercase
    tokens usually have significant weights in sentiment analysis models. Here is
    an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '**IS_PUNCT** , **IS_SPACE** , and **IS_STOP** are usually used in patterns
    that include some helper tokens and correspond to punctuation, space, and stopword
    tokens (stopwords are common words of a language that do not carry much information,
    such as *a* , *an* , and *the* in English). **IS_SENT_START** is another useful
    attribute; it matches sentence start tokens. Here’s a pattern for sentences that
    start with the word *can* and the second word has a capitalized first letter:'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this pattern, we will put two attributes into one brace. The first item
    in **pattern** means that a token that is the first token of the sentence and
    whose lowered text is **can** :'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we process the text and show the matches:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '*Figure 4* *.5* shows the matches of the preceding list:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.5 – Match using two tokens](img/B22441_04_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.5 – Match using two tokens
  prefs: []
  type: TYPE_NORMAL
- en: 'We can add as many attributes to the braces as we like. For instance, **{"IS_SENT_START":
    False, "IS_TITLE": True, "LOWER": "bill"}** is a completely v alid attribute dictionary,
    and it describes a token that is capitalized, not the first token of the sentence,
    and has the text **bill** . So, it is the set of **bill** instances that do not
    appear as the first word of a sentence.'
  prefs: []
  type: TYPE_NORMAL
- en: '**LIKE_NUM** , **LIKE_URL** , and **LIKE_EMAIL** are attributes that are related
    to token shape; – we discussed them in [*Chapter 3*](B22441_03.xhtml#_idTextAnchor045)
    . These attributes match tokens that look like numbers, URLs, and emails.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s see the **POS** , **TAG** , **DEP** , **LEMMA** , and **SHAPE**
    linguistic attributes. You saw these token attributes in the previous chapter;
    now, we’ll use them in token matching. The following code snippet spots sentences
    that start with an auxiliary verb:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '**MD** is the tag for modal and auxiliary verbs. The preceding code snippet
    is a standard way of finding yes/no question sentences. In such cases, we usually
    look for sentences that start with a modal or an auxiliary verb.'
  prefs: []
  type: TYPE_NORMAL
- en: 'When we want to extract the meaning of a word, we usually combine **TEXT/LEMMA**
    with **POS/TAG** . For instance, the word match is to go together when it’s a
    verb, or it can be a fire starter tool when it’s a noun. In this case, we make
    the distinction as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**{"LEMMA": "match", "** **POS": "VERB"}**'
  prefs: []
  type: TYPE_NORMAL
- en: '**{"LEMMA": "match", "** **POS": "NOUN"}**'
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, you can combine other linguistic features with token shape attributes
    to make sure that you extract only the pattern you mean to.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll see more examples of combining linguistic features with the **Matcher**
    class in the upcoming sections. Now, we’ll move on to another very practical feature
    of **Matcher** patterns: regex-like operators.'
  prefs: []
  type: TYPE_NORMAL
- en: Regex-like operators
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'At the beginning of the chapter, we pointed out that spaCy’s **Matcher** class
    offers a cleaner and more readable equivalent to regex operations, indeed much
    cleaner and much more readable. The most common regex operations are optional
    match ( **?** ), match at least once ( **+** ), and match 0 or more times ( *****
    ). You can see a full list of spaCy’s **Matcher** operators here: [https://spacy.io/api/matcher/#patterns](https://spacy.io/api/matcher/#patterns)
    . The very first example regex of this chapter was matching Barack Obama’s first
    name, with the middle name being optional. The regex was as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The **?** operator after **Hussein** means the pattern in the brackets is optional,
    hence this regex matches both **Barack Obama** and **Barack Hussein Obama** .
    We use the **?** operator in a **Matcher** pattern as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, by using **"OP": "?"** in the second list item, we made this token optional.
    The matcher picked **Barack Obama** in the first **doc** object and **Barack Hussein
    Obama** in the second one, as you can see in *Figure 4* *.6* :'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.6 – Matches using regex](img/B22441_04_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.6 – Matches using regex
  prefs: []
  type: TYPE_NORMAL
- en: 'We previously pointed out that the **+** and ***** operators have the same
    meaning as their regex counterparts. **+** means the token should occur at least
    once, and ***** means the token can occur 0 or more times. Let’s see some examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '*Figure 4* *.7* shows what happens when we use the **+** operator:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.7 – Matches using the + operator](img/B22441_04_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.7 – Matches using the + operator
  prefs: []
  type: TYPE_NORMAL
- en: In the pattern, the first token reads as any one of **hello** , **hi** , **hallo**
    should occur one or more times. Notice the greedy nature of the pattern (each
    **hello** instance gets a match). The second doc also has a match, but the third
    one doesn’t (since it does not have any of the **hello** , **hi** , or **hallo**
    words).
  prefs: []
  type: TYPE_NORMAL
- en: When we come to the results of the first doc objects matches, we see that there
    are not one but three distinct matches. This is completely normal because there
    are indeed three sequences matching the pattern. If you have a closer look at
    the match results, all of them match the pattern we created, because they all
    match the **(** **hello)+** pattern.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s do the same pattern with ***** and see what happens this time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '*Figure 4* *.8* shows the results:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.8 – Matches using the * operator](img/B22441_04_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.8 – Matches using the * operator
  prefs: []
  type: TYPE_NORMAL
- en: Now, punctuation marks alone without a greeting word are picked. This is not
    what you want in your NLP applications, probably.
  prefs: []
  type: TYPE_NORMAL
- en: The preceding example is a good example that we should be careful of while creating
    our patterns; sometimes, we get unwanted matches. For this reason, we usually
    consider using **IS_SENT_START** and take care of the rest with the ***** operator.
  prefs: []
  type: TYPE_NORMAL
- en: 'The spaCy **Matcher** class also accepts a very special pattern, a wildcard
    token pattern. A wildcard token will match any token. We usually use it for words
    we want to pick independent from their text or attributes or for words we ignore.
    Let’s see an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we wanted to capture the first names in the sentence. We achieved it
    by parsing out token sequences in the form **name is/was/be firstname** . The
    first token pattern, **LOWER: "name"** , matches the tokens whose lowered text
    is **name** . The second token pattern, **LEMMA: "be"** , matches the **is** ,
    **was** , and **be** tokens. The third token is the wildcard token, **{}** , which
    means any token. We pick up any token that comes after **name is/was/be** with
    this pattern. *Figure 4* *.9* shows the results:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.9 – Matches using wildcard token](img/B22441_04_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.9 – Matches using wildcard token
  prefs: []
  type: TYPE_NORMAL
- en: 'We also use a wildcard token when we want to ignore a token. Let’s make an
    example together:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: It’s just the opposite of the previous example. Here, we wanted to pick up **forward
    email** sequences, and we allowed that one token to come between **forward** and
    **email** . In this case, the semantically important part is the forwarding an
    email action; whose email is it doesn’t matter much.
  prefs: []
  type: TYPE_NORMAL
- en: We have mentioned regexes quite a lot in this chapter so far, so now, it’s time
    to see how spaCy’s **Matcher** class makes use of regex syntax.
  prefs: []
  type: TYPE_NORMAL
- en: Regex support
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When we match individual tokens, usually we want to allow some variations,
    such as common typos, UK/US English character differences, and so on. Regexes
    are very handy for this task, and spaCy **Matcher** offers full support for token-level
    regex matching. Let’s explore how we can use regexes for our applications:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Here, our second token pattern is **[Tt]ravell?ed** , which means the token
    can be capitalized or not. Also, there’s an optional **l** instance after the
    first **l** instance. Allowing twin vowels and ise/ize alteration is a standard
    way of dealing with British and American English variations.
  prefs: []
  type: TYPE_NORMAL
- en: Another way of using regexes is using them not only with text but also with
    POS tags. What does the following code segment do?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'We have extracted all the finite verbs (you can think of a finite verb as a
    non-modal verb). How did we do it? Our token pattern includes the regex **^V**
    , which means all fine-grained POS tags that start with V: **VB** , **VGD** ,
    **VBG** , **VBN** , **VBP** , and **VBZ** . Then, we extracted tokens with verbal
    POS tags.'
  prefs: []
  type: TYPE_NORMAL
- en: Matcher online demo
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'spaCy **Matcher** offers a tool on its online demo page: [https://explosion.ai/demos/matcher](https://explosion.ai/demos/matcher)
    . We can create patterns and test them against the text we want, interactively.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In *Figure 4* *.10* , we can see a match example. On the right side, we can
    select the attributes, values, and operators (such as **+** , ***** , **!** ,
    and **?** ). After making this selection, the demo outputs the corresponding pattern
    string on the right side, below the checkboxes. On the left side, we first choose
    the spaCy language model we want (in this example, English core small), then see
    the results:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.10 – spaCy’s Rule-based Matcher Explorer](img/B22441_04_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.10 – spaCy’s Rule-based Matcher Explorer
  prefs: []
  type: TYPE_NORMAL
- en: spaCy’s **Matcher** demo helps you to see why your pattern matched or didn’t
    match.
  prefs: []
  type: TYPE_NORMAL
- en: Creating patterns with PhraseMatcher
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While processing financial, medical, or legal text, we often have long lists
    and dictionaries and we want to scan the text against our lists. As we saw in
    the previous section, **Matcher** patterns are quite handcrafted; we coded each
    token individually. If you have a long list of phrases, **Matcher** is not very
    handy. It’s not possible to code all the terms one by one.
  prefs: []
  type: TYPE_NORMAL
- en: 'spaCy offers a solution for comparing text against long dictionaries – the
    **PhraseMatcher** class. The **PhraseMatcher** class helps us match long dictionaries.
    Let’s get started with a basic example of using **PhraseMatcher** to match terms
    defined in a list:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the library and the class and instantiate the **nlp** pipeline as usual:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now we can instantiate the **PhraseMatcher** object and call **nlp.make_doc()**
    on the terms one by one to create patterns:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, we check the matches:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This way, we match the patterns by their exact text values, as shown in *Figure
    4* *.11* :'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.11 – Matches using PhraseMatcher](img/B22441_04_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.11 – Matches using PhraseMatcher
  prefs: []
  type: TYPE_NORMAL
- en: What if we want to match them with other attributes? Here’s an example of matching
    by the **LOWER** attribute.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we create a **PhraseMatcher** instance, passing an additional argument,
    **attr=LOWER** . This way, **PhraseMatcher** uses the **token.lower** attribute
    during the match:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let’s display the results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: '*Figure 4* *.12* shows the match results:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.12 – Matches using the PhraseMatcher LOWER attribute](img/B22441_04_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.12 – Matches using the PhraseMatcher LOWER attribute
  prefs: []
  type: TYPE_NORMAL
- en: 'Another possible usage of **PhraseMatcher** is matching the **SHAPE** attribute.
    This matching strategy can be used on system logs, where IP numbers, dates, and
    other numerical values occur a lot. The good thing here is that you do not need
    to worry about how the numbers are tokenized; you just leave it to **PhraseMatcher**
    . Let’s see an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: '*Figure 4* *.13* shows the results:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.13 – Matches using the PhraseMatcher SHAPE attribute](img/B22441_04_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.13 – Matches using the PhraseMatcher SHAPE attribute
  prefs: []
  type: TYPE_NORMAL
- en: Handy, right? We matched the tokens and phrases successfully; now, let’s move
    on to **named entity recognition** ( **NER** ). Named entity extraction is an
    essential component of any NLP system, and most of the pipelines you’ll design
    will include an NER component. The next section is devoted to rule-based named
    entity extraction.
  prefs: []
  type: TYPE_NORMAL
- en: Creating patterns with SpanRuler
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: spaCy’s **SpanRuler** component allows us to add spans to the **Doc.spans**
    and/or **Doc.ents** dictionaries using token-based rules or exact phrase matches.
  prefs: []
  type: TYPE_NORMAL
- en: '**SpanRuler** is not a matcher; it’s a pipeline component that we can add to
    our pipeline via **nlp.add_pipe** . When it finds a match, the match is appended
    to **doc.ents** or **doc.spans** . If adding to **doc.ents** , **ent_type** will
    be the label we pass in the pattern. Let’s see it in action:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, define a pattern for the entity:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we add the **SpanRuler** component. By default, it adds the spans to **doc.spans**
    , and we want to add it to **doc.ents** , so we specify that in the config:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we can add the pattern to the component and process the text:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '*Figure 4* *.14* shows the entity we’ve matched:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.14 – Entity created with SpanRuler](img/B22441_04_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.14 – Entity created with SpanRuler
  prefs: []
  type: TYPE_NORMAL
- en: 'We can see in *Figure 4* *.14* that the **chime** token was added to the **Doc.ents**
    dictionary. If you don’t want to override the existing entities, you can set **overwrite**
    to **False** . Let’s try that:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: '*Figure 4* *.15* shows the result. Now, the entity added by the **ner** component
    is also present (you will learn more about components and pipelines in [*Chapter
    5*](B22441_05.xhtml#_idTextAnchor074) ):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.15 – Entities created with SpanRuler and the ner component](img/B22441_04_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.15 – Entities created with SpanRuler and the ner component
  prefs: []
  type: TYPE_NORMAL
- en: That’s it – easy, yet powerful. We added our own entity with just a couple of
    lines.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’ve seen how to use the **Matcher** class and **SpanRuler** to extract
    information, we’ll move on to an exclusive section of quick and very handy recipes.
  prefs: []
  type: TYPE_NORMAL
- en: Combining spaCy models and matchers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we’ll go through some recipes that will guide you through the
    entity extraction types you might encounter in your NLP journey. All the examples
    are ready-to-use and real-world recipes. Let’s start with number-formatted entities.
  prefs: []
  type: TYPE_NORMAL
- en: Extracting an IBAN
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: An **IBAN** is an important entity type that occurs in finance and banking frequently.
    We’ll learn how to parse it out.
  prefs: []
  type: TYPE_NORMAL
- en: An IBAN is an international number format for bank account numbers. It has the
    format of a two-digit country code followed by numbers.
  prefs: []
  type: TYPE_NORMAL
- en: 'How can we create a pattern for an IBAN? We start with two capital letters,
    followed by two digits. Then, any number of digits can follow. We can express
    the country code and the next two digits as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, **XX** corresponds to two capital letters, and **dd** is two digits.
    Then, the **XXdd** pattern matches the first block of the IBAN perfectly. How
    about the rest of the digit blocks? For the rest of the blocks, we need to match
    a block of one to four digits. The **\d{1,4}** regex means a token consisting
    of one to four digits. This pattern will match a digit block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'We have a number of these blocks, so the pattern to match the digit blocks
    of an IBAN is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we combine the first shape block with the rest of the blocks. Let’s check
    the full code of the pattern:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Define the pattern and add it to the **Matcher** object:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, let’s add the code to display the matches:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '*Figure 4* *.16* shows the result. You can always follow a similar strategy
    when parsing numeric entities: first, divide the entity into some meaningful parts/blocks,
    then try to determine the shape or the length of the individual blocks:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.16 – Extracting IBANs](img/B22441_04_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.16 – Extracting IBANs
  prefs: []
  type: TYPE_NORMAL
- en: 'We successfully parsed IBANs. Now, we’ll extract another type of common numeric
    entity: phone numbers.'
  prefs: []
  type: TYPE_NORMAL
- en: Extracting phone numbers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Phone numbers can have very different formats depending on the country, and
    matching phone numbers is often a tricky business. The best strategy here is to
    be specific about the country phone number format you want to parse. If there
    are several countries, you can add corresponding individual patterns to the matcher.
    If you have too many countries, then you can relax some conditions and go for
    a more general pattern (we’ll see how to do that).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s start with the US phone number format. A US number is written as (541)
    754-3010 domestically or +1 (541) 754-3010 internationally. We can form our pattern
    with an optional **+1** instance, then a three-digit area code, then two blocks
    of numbers separated with an optional **-** instance. Here is the pattern:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s see an example of the pattern:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we have some example sentences and the code to display the matches:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: '*Figure 4* *.17* shows the results. How about we make the pattern more general
    to apply to other countries as well? In this case, we can start with a one-to-three-digit
    country code, followed by some digit blocks. It will match a broader set of numbers,
    so it’s better to be careful not to match other numeric entities in your text:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.17 – Extracting phone numbers](img/B22441_04_17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.17 – Extracting phone numbers
  prefs: []
  type: TYPE_NORMAL
- en: We’ll move on to textual entities from numeric entities. Now, we’ll process
    social media text and extract different types of entities that can occur in social
    media text.
  prefs: []
  type: TYPE_NORMAL
- en: Extracting mentions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Imagine analyzing a dataset of social media posts about companies and products,
    and your task is to find out which companies are mentioned in which ways. The
    dataset will contain these sorts of sentences:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'What we’re looking for is, most probably, patterns of the **BusinessName is/was/be
    adverb*** adjective form. The following pattern would work:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: Here, we look for an organization type entity, followed by an **is/was/be**
    instance, then optional adverbs, and finally, an adjective.
  prefs: []
  type: TYPE_NORMAL
- en: 'What if you want to extract a specific business – let’s say, the company ACME?
    All you have to do is replace the first token with the specific company name:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: That’s it – easy peasy! After extracting the social media mentions, the next
    thing to do is to extract the hashtags.
  prefs: []
  type: TYPE_NORMAL
- en: Hashtag extraction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Processing social media text has some challenges. Social media text has an
    unusual token type: **hashtags** . They have a huge impact on the text’s meaning.
    The hashtag refers to the subject/object of the sentence.'
  prefs: []
  type: TYPE_NORMAL
- en: 'A hashtag consists of a **#** character at the beginning, then followed by
    a word of ASCII characters, with no inter-word spaces. Some examples are **#MySpace**
    , **#MondayMotivation** , and so on. The spaCy tokenizer tokenizes these words
    into two tokens:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'As a result, our pattern needs to match two tokens: the **#** character and
    the rest. The following pattern will match a hashtag easily:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'The following pattern extracts a hashtag:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let’s display the matches using the sentence **"Start working out** **now
    #WeekendShred"** :'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Pretty easy as well. *Figure 4* *.18* shows the result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.18 – Matches the hashTag pattern](img/B22441_04_18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.18 – Matches the hashTag pattern
  prefs: []
  type: TYPE_NORMAL
- en: Emoji is another unusual token and has the potential to assign the sentiment
    to a sentence. We can also extract emoji tokens using the spacymoji package (
    [https://spacy.io/universe/project/spacymoji](https://spacy.io/universe/project/spacymoji)
    ).
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s extract some entities. We’ll start with the common procedure of expanding
    named entities in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Expanding named entities
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Often, we would like to expand a named entity’s span to the left or to the right.
    Imagine you want to extract **PERSON** type named entities with titles so that
    you can deduce the gender or profession easily. spaCy’s **NER** class already
    extracts person names, so how about the titles?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'As you see, the word **Ms.** is not included in the named entity because it’s
    not a part of the person’s name. A quick solution is to make a new entity type
    called **TITLE** :'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let’s display the matches again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: '*Figure 4* *.19* shows the result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.19 – Expanding entities with Matcher](img/B22441_04_19.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.19 – Expanding entities with Matcher
  prefs: []
  type: TYPE_NORMAL
- en: This is a quick and very handy recipe. You’ll come across parsing titles a lot
    if you process wiki text or financial text.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned how to do rule-based matching with linguistic and
    token-level features. You learned about the **Matcher** class, spaCy’s rule-based
    matcher. We explored the **Matcher** class by using it with different token features,
    such as shape, lemma, text, and entity type.
  prefs: []
  type: TYPE_NORMAL
- en: Then, you learned about **SpanRuler** , another lifesaving class that you can
    achieve a lot with. You also learned how to extract named entities with the **SpanRuler**
    class.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we put together what you learned in this chapter and your previous
    knowledge and combined linguistic features with rule-based matching with several
    examples. You learned how to extract patterns, entities of specific formats, and
    entities specific to your domain.
  prefs: []
  type: TYPE_NORMAL
- en: With this chapter, you completed the linguistic features. In the next chapter,
    we’ll use all this knowledge to extract semantic representations from text using
    spaCy pipelines.
  prefs: []
  type: TYPE_NORMAL
