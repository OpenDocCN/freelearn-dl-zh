- en: '8'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '8'
- en: Dynamic RAG with Chroma and Hugging Face Llama
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于Chroma和Hugging Face Llama的动态RAG
- en: This chapter will take you into the pragmatism of dynamic RAG. In today’s rapidly
    evolving landscape, the ability to make swift, informed decisions is more crucial
    than ever. Decision-makers across various fields—from healthcare and scientific
    research to customer service management—increasingly require real-time data that
    is relevant only within the short period it is needed. A meeting may only require
    temporary yet highly prepared data. Hence, the concept of data permanence is shifting.
    Not all information must be stored indefinitely; instead, in many cases, the focus
    is shifting toward using precise, pertinent data tailored for specific needs at
    specific times, such as daily briefings or critical meetings.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将带您进入动态RAG的实用性。在当今快速发展的环境中，迅速做出明智决策的能力比以往任何时候都更加重要。从医疗保健和科学研究到客户服务管理，各个领域的决策者越来越需要只在所需短时间内相关的实时数据。一次会议可能只需要临时但高度准备好的数据。因此，数据永久性的概念正在转变。并非所有信息都必须无限期存储；相反，在许多情况下，重点正在转向使用针对特定时间特定需求的精确、相关数据，例如每日简报或关键会议。
- en: This chapter introduces an innovative and efficient approach to handling such
    data through the embedding and creation of temporary Chroma collections. Each
    morning, a new collection is assembled containing just the necessary data for
    that day’s meetings, effectively avoiding long-term data accumulation and management
    overhead. This data might include medical reports for a healthcare team discussing
    patient treatments, customer interactions for service teams strategizing on immediate
    issues, or the latest scientific research data for researchers making day-to-day
    experimental decisions. We will then build a Python program to support dynamic
    and efficient decision-making in daily meetings, applying a methodology using
    a hard science (any of the natural or physical sciences) dataset for a daily meeting.
    This approach will highlight the flexibility and efficiency of modern data management.
    In this case, the team wants to obtain pertinent scientific information without
    searching the web or interacting with online AI assistants. The constraint is
    to have a free, open-source assistant that anyone can use, which is why we will
    use Chroma and Hugging Face resources.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了一种创新且高效的方法，通过嵌入和创建临时的色度集合来处理此类数据。每天早上，都会组装一个新的集合，其中只包含当天会议所需的必要数据，从而有效避免长期数据积累和管理开销。这些数据可能包括医疗团队讨论患者治疗的医疗报告，服务团队针对即时问题进行策略规划的客户互动，或研究人员进行日常实验决策的最新科学研究数据。然后，我们将构建一个Python程序来支持日常会议中的动态和高效决策，应用一个使用硬科学（任何自然科学或物理科学）数据集的方法论进行每日会议。这种方法将突出现代数据管理的灵活性和效率。在这种情况下，团队希望获取相关的科学信息，而无需搜索网络或与在线人工智能助手互动。约束条件是拥有一个免费、开源的助手，任何人都可以使用，这就是为什么我们将使用Chroma和Hugging
    Face资源。
- en: The first step is to create a temporary Chroma collection. We will simulate
    the processing of a fresh dataset compiled daily, tailored to the specific agenda
    of upcoming meetings, ensuring relevance and conciseness. In this case, we will
    download the SciQ dataset from Hugging Face, which contains thousands of crowdsourced
    science questions, such as those related to physics, chemistry, and biology. Then,
    the program will embed the relevant data required for the day, guaranteeing that
    all discussion points are backed by the latest, most relevant data.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是创建一个临时的色度集合。我们将模拟处理每天编译的新数据集的处理过程，针对即将召开的会议的具体议程进行定制，确保相关性和简洁性。在这种情况下，我们将从Hugging
    Face下载SciQ数据集，该数据集包含数千个众包科学问题，例如与物理学、化学和生物学相关的问题。然后，程序将嵌入当天所需的相关数据，确保所有讨论点都有最新、最相关数据的支持。
- en: A user might choose to run queries before the meetings to confirm their accuracy
    and alignment with the day’s objective. Finally, as meetings progress, any arising
    questions trigger real-time data retrieval, augmented through **Large Language
    Model Meta AI** (**Llama**) technology to generate dynamic flashcards. These flashcards
    provide quick and precise responses to ensure discussions are both productive
    and informed. By the end of this chapter, you will have acquired the skills to
    implement open-source free dynamic RAG in a wide range of domains.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 用户可能会选择在会议前运行查询以确认其准确性和与当天目标的契合度。最后，随着会议的进行，任何出现的问题都会触发实时数据检索，通过**大型语言模型Meta
    AI**（**Llama**）技术增强以生成动态闪卡。这些闪卡提供快速精确的响应，以确保讨论既富有成效又信息丰富。到本章结束时，你将掌握在各个领域实施开源免费动态RAG的技能。
- en: 'To sum that up, this chapter covers the following topics:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，本章涵盖了以下主题：
- en: The architecture of dynamic RAG
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 动态RAG的架构
- en: Preparing a dataset for dynamic RAG
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为动态RAG准备数据集
- en: Creating a Chroma collection
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建Chroma集合
- en: Embedding and upserting data in a Chroma collection
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Chroma集合中嵌入和更新数据
- en: Batch-querying a collection
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 批量查询集合
- en: Querying a collection with a user request
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用用户请求查询集合
- en: Augmenting the input with the output of a query
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用查询的输出增强输入
- en: Configuring Hugging Face’s framework for Meta Llama
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置Hugging Face的Meta Llama框架
- en: Generating a response based on the augmented input
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据增强输入生成响应
- en: Let’s begin by going through the architecture of dynamic RAG.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从了解动态RAG的架构开始。
- en: The architecture of dynamic RAG
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 动态RAG的架构
- en: Imagine you’re in a dynamic environment in which information changes daily.
    Each morning, you gather a fresh batch of 10,000+ questions and validated answers
    from across the globe. The challenge is to access this information quickly and
    effectively during meetings without needing long-term storage or complicated infrastructure.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，你身处一个信息每日都在变化的环境中。每天早上，你从全球收集超过10,000个问题和验证过的答案。挑战在于在会议期间快速有效地获取这些信息，而不需要长期存储或复杂的设施。
- en: This dynamic RAG method allows us to maintain a lean, responsive system that
    provides up-to-date information without the burden of ongoing data storage. It’s
    perfect for environments where data relevance is short-lived but critical for
    decision-making.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这种动态RAG方法使我们能够保持一个精简、响应迅速的系统，提供最新的信息，而不需要持续的数据存储负担。它非常适合数据相关性短暂但决策关键的环境。
- en: 'We will be applying this to a hard science dataset. However, this dynamic approach
    isn’t limited to our specific example. It has broad applications across various
    domains, such as:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将把这个方法应用到硬科学数据集上。然而，这种动态方法并不仅限于我们的特定例子。它在各个领域都有广泛的应用，例如：
- en: '**Customer support**: Daily updated FAQs can be accessed in real-time to provide
    quick responses to customer inquiries.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**客户支持**：可以实时访问每日更新的常见问题解答，以快速响应用户咨询。'
- en: '**Healthcare**: During meetings, medical teams can use the latest research
    and patient data to answer complex health-related questions.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**医疗保健**：在会议期间，医疗团队可以使用最新的研究和患者数据来回答复杂与健康相关的问题。'
- en: '**Finance**: Financial analysts can query the latest market data to make informed
    decisions on investments and strategies.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**金融**：金融分析师可以查询最新的市场数据，以做出明智的投资和策略决策。'
- en: '**Education**: Educators can access the latest educational resources and research
    to answer questions and enhance learning.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**教育**：教育工作者可以获取最新的教育资源和研究，以回答问题并提升学习。'
- en: '**Tech support**: IT teams can use updated technical documentation to solve
    issues and guide users effectively.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**技术支持**：IT团队可以使用最新的技术文档来解决问题并有效地指导用户。'
- en: '**Sales and marketing**: Teams can quickly access the latest product information
    and market trends to answer client queries and strategize.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**销售与营销**：团队可以快速获取最新的产品信息和市场趋势，以回答客户咨询并制定策略。'
- en: This chapter implements one type of a dynamic RAG ecosystem. Your imagination
    is the limit, so feel free to apply this ecosystem to your own projects in different
    ways. For now, let’s see how the dynamic RAG components fit into the ecosystem
    we described in *Chapter 1*, *Why Retrieval Augmented Generation?*, in the *RAG
    ecosystem* section.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 本章实现了一种动态RAG生态系统的类型。你的想象力是无限的，所以请随意将这个生态系统以不同的方式应用到你的项目中。现在，让我们看看动态RAG组件如何与我们描述在*第一章*，*为什么是检索增强生成？*，在*RAG生态系统*部分中描述的生态系统相匹配。
- en: 'We will streamline the integration and use of dynamic information in real-time
    decision-making contexts, such as daily meetings, in Python. Here’s a breakdown
    of this innovative strategy for each component and its ecosystem component label:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将简化在实时决策环境中（如日常会议）集成和使用动态信息的流程，使用Python实现。以下是针对每个组件及其生态系统组件标签的创新策略的分解：
- en: '![A diagram of a diagram  Description automatically generated](img/B31169_08_01.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![一个图表的图表  自动生成的描述](img/B31169_08_01.png)'
- en: 'Figure 8.1: The dynamic RAG system'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.1：动态RAG系统
- en: '**Temporary Chroma collection creation (D1, D2, D3, E2)**: Every morning, a
    temporary Chroma collection is set up specifically for that day’s meeting. This
    collection is not meant to be saved post-meeting, serving only the day’s immediate
    needs and ensuring that data does not clutter the system in the long term.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**临时Chroma集合创建（D1，D2，D3，E2）**：每天早上，都会为当天的会议设置一个专门的临时Chroma集合。这个集合不是为了会议后保存，而是仅满足当天的即时需求，并确保长期不会使数据系统杂乱无章。'
- en: '**Embedding relevant data (D1, D2, D3, E2)**: The collection embeds critical
    data, such as customer support interactions, medical reports, or scientific facts.
    This embedding process tailors the content specifically to the meeting agenda,
    ensuring that all pertinent information is at the fingertips of the meeting participants.
    The data could include human feedback from documents and possibly other generative
    AI systems.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**嵌入相关数据（D1，D2，D3，E2）**：该集合嵌入关键数据，如客户支持交互、医疗报告或科学事实。此嵌入过程将内容特别定制到会议议程中，确保所有相关信息都可在会议参与者的指尖。数据可能包括来自文档的人类反馈以及可能的其他生成AI系统。'
- en: '**Pre-meeting data validation (D4)**: Before the meeting begins, a batch of
    queries is run against this temporary Chroma collection to ensure that all data
    is accurate and appropriately aligned with the meeting’s objectives, thereby facilitating
    a smooth and informed discussion.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**会议前的数据验证（D4）**：在会议开始之前，对这个临时Chroma集合运行一批查询，以确保所有数据都是准确的，并且与会议目标适当对齐，从而促进顺利和有信息的讨论。'
- en: '**Real-time query handling (G1, G2, G3, G4)**: During the meeting, the system
    is designed to handle spontaneous queries from participants. A single question
    can trigger the retrieval of specific information, which is then used to augment
    Llama’s input, enabling it to generate flashcards dynamically. These flashcards
    are utilized to provide concise, accurate responses during the meeting, enhancing
    the efficiency and productivity of the discussion.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实时查询处理（G1，G2，G3，G4）**：在会议期间，系统被设计为处理参与者提出的自发查询。一个问题可以触发特定信息的检索，然后用于增强Llama的输入，使其能够动态生成闪卡。这些闪卡在会议期间用于提供简洁、准确的信息，从而提高讨论的效率和生产力。'
- en: 'We will be using Chroma, a powerful, open-source, AI-native vector database
    designed to store, manage, and search embedded vectors in collections. Chroma
    contains everything we need to start, and we can run it on our machine. It is
    also very suitable for applications involving LLMs. Chroma collections are thus
    suitable for a temporary, cost-effective, and real-time RAG system. The dynamic
    RAG architecture of this chapter implemented with Chroma is innovative and practical.
    Here are some key points to consider in this fast-moving world:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用Chroma，这是一个强大、开源、AI原生向量数据库，旨在存储、管理和搜索集合中的嵌入向量。Chroma包含了我们启动所需的一切，我们可以在我们的机器上运行它。它也非常适合涉及LLMs的应用。因此，Chroma集合非常适合临时、成本效益高和实时的RAG系统。本章使用Chroma实现的动态RAG架构具有创新性和实用性。以下是这个快速变化的世界中需要考虑的一些关键点：
- en: '**Efficiency and cost-effectiveness**: Using Chroma for temporary storage and
    Llama for response generation ensures that the system is lightweight and doesn’t
    incur ongoing storage costs. This makes it ideal for environments where data is
    refreshed frequently and long-term storage isn’t necessary. It is very convincing
    for decision-makers who want lean systems.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**效率和成本效益**：使用Chroma进行临时存储和Llama进行响应生成确保系统轻量级，不会产生持续存储成本。这使得它非常适合数据频繁刷新且不需要长期存储的环境。这对希望系统精简的决策者来说非常有说服力。'
- en: '**Flexibility**: The system’s ephemeral nature allows for the integration of
    new data daily, ensuring that the most up-to-date information is always available.
    This can be particularly valuable in fast-paced environments in which information
    changes rapidly.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**灵活性**：系统的短暂性质允许每天集成新数据，确保始终可用最新信息。这在信息变化迅速的快节奏环境中尤其有价值。'
- en: '**Scalability**: The approach is scalable to other similar datasets, provided
    they can be embedded and queried effectively. This makes it adaptable to various
    domains beyond the given example. Scaling is not only increasing volumes of data
    but also the ability to apply a framework to a wide range of domains and situations.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可扩展性**：该方法可扩展到其他类似的数据集，前提是它们可以有效地嵌入和查询。这使得它适用于各种超出给定示例的领域。可扩展性不仅包括增加数据量，还包括将框架应用于广泛领域和情况的能力。'
- en: '**User-friendliness**: The system’s design is straightforward, making it accessible
    to users who may not be deeply technical but need reliable answers quickly. This
    simplicity can enhance user engagement and satisfaction. Making users happy with
    cost-effective, transparent, and lightweight AI will surely boost their interest
    in RAG-driven generative AI.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**用户友好性**：系统的设计简单直观，使得那些可能不是技术专家但需要快速获得可靠答案的用户能够使用。这种简单性可以增强用户参与度和满意度。通过提供成本效益、透明和轻量级的
    AI 来让用户满意，无疑会提高他们对 RAG 驱动的生成式 AI 的兴趣。'
- en: Let’s now begin building a dynamic RAG program.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们现在开始构建一个动态 RAG 程序。
- en: Installing the environment
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装环境
- en: The environment focuses on open-source and free resources that we can run on
    our machine or a free Google Colab account. This chapter will run these resources
    on Google Colab with Hugging Face and Chroma.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 环境专注于开源和免费资源，我们可以在我们的机器或免费的 Google Colab 账户上运行这些资源。本章将在 Google Colab 上使用 Hugging
    Face 和 Chroma 运行这些资源。
- en: We will first install Hugging Face.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先安装 Hugging Face。
- en: Hugging Face
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Hugging Face
- en: 'We will implement Hugging Face’s open-source resources to download a dataset
    for the Llama model. Sign up at [https://huggingface.co/](https://huggingface.co/)
    to obtain your Hugging Face API token. If you are using Google Colab, you can
    create a Google Secret in the sidebar and activate it. If so, you can comment
    the following cell—`# Save your Hugging Face token in a secure location`:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将实现 Hugging Face 的开源资源来下载 Llama 模型的数据集。请在 [https://huggingface.co/](https://huggingface.co/)
    上注册以获取您的 Hugging Face API 令牌。如果您使用 Google Colab，您可以在侧边栏中创建一个 Google Secret 并激活它。如果是这样，您可以注释以下单元格—`#
    将您的 Hugging Face 令牌保存在安全位置`：
- en: '[PRE0]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The program first retrieves the Hugging Face API token. Make sure to store
    it in a safe place. You can choose to use Google Drive or enter it manually. Up
    to now, the installation seems to have run smoothly. We now install `datasets`:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 程序首先检索 Hugging Face API 令牌。请确保将其保存在安全的地方。您可以选择使用 Google Drive 或手动输入。到目前为止，安装似乎运行顺利。我们现在安装
    `datasets`：
- en: '[PRE1]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: However, there are conflicts, such as `pyarrow`, with Google Colab’s pre-installed
    version, which is more recent. These conflicts between fast-moving packages are
    frequent. When Hugging Face updates its packages, this conflict will not appear
    anymore. But other conflicts may appear. This conflict will not stop us from downloading
    datasets. If it did, we would have to uninstall Google Colab packages and reinstall
    `pyarrow`, but other dependencies may possibly create issues. We must accept these
    challenges, as explained in the *Setting up the environment* section in *Chapter
    2*, *RAG Embedding Vector Stores with Deep Lake and OpenAI*.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，存在一些冲突，例如与 Google Colab 预安装的较新版本的 `pyarrow` 冲突。这些快速移动的包之间的冲突很常见。当 Hugging
    Face 更新其包时，这种冲突将不再出现。但可能还会出现其他冲突。这种冲突不会阻止我们下载数据集。如果它阻止了，我们就必须卸载 Google Colab 包并重新安装
    `pyarrow`，但其他依赖项可能会引发问题。我们必须接受这些挑战，正如在 *第 2 章* 的 *设置环境* 部分中解释的那样。
- en: 'We will now install Hugging Face’s `transformers` package:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将安装 Hugging Face 的 `transformers` 包：
- en: '[PRE2]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We also install accelerate to run PyTorch packages on GPUs, which is highly
    recommended for this notebook, among other features, such as mixed precision and
    accelerated processing times:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还安装了 accelerate 以在 GPU 上运行 PyTorch 包，这对于本笔记本来说非常推荐，其他特性还包括混合精度和加速处理时间：
- en: '[PRE3]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Finally, we will initialize `meta-llama/Llama-2-7b-chat-hf` as the tokenizer
    and chat model interactions. Llama is a series of transformer-based language models
    developed by Meta AI (formerly Facebook AI) that we can access through Hugging
    Face:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将 `meta-llama/Llama-2-7b-chat-hf` 初始化为分词器和聊天模型交互。Llama 是由 Meta AI（前身为 Facebook
    AI）开发的一系列基于 transformer 的语言模型，我们可以通过 Hugging Face 访问：
- en: '[PRE4]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We access the model through Hugging Face’s pipeline:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过 Hugging Face 的 pipeline 访问模型：
- en: '[PRE5]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Let’s go through the pipeline:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过 pipeline 进行检查：
- en: '`transformers.pipeline` is the function used to create a pipeline for text
    generation. This pipeline abstracts away much of the complexity we must avoid
    in this dynamic RAG ecosystem.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transformers.pipeline` 是用于创建文本生成管道的函数。此管道抽象掉了在这个动态 RAG 生态系统中必须避免的许多复杂性。'
- en: '`text-generation` specifies the type of task the pipeline is set up for. In
    this case, we want text generation.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text-generation` 指定了管道设置的作业类型。在这种情况下，我们想要进行文本生成。'
- en: '`model` specifies the model we selected.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` 指定了我们选择的模型。'
- en: '`torch_dtype=torch.float16` sets the data type for PyTorch tensors to `float16`.
    This is a key factor for dynamic RAG, which reduces memory consumption and can
    speed up computation, particularly on GPUs that support half-precision computations.
    Half-precision computations use 16 bits: half of the standard 32-bit precision,
    for faster, lighter processing. This is exactly what we need.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`torch_dtype=torch.float16` 将 PyTorch 张量的数据类型设置为 `float16`。这是动态 RAG 的一个关键因素，它减少了内存消耗并可以加快计算速度，尤其是在支持半精度计算的
    GPU 上。半精度计算使用 16 位：标准 32 位精度的二分之一，用于更快、更轻的处理。这正是我们所需要的。'
- en: '`device_map="auto"` instructs the pipeline to automatically determine the best
    device to run the model on (CPU, GPU, multi-GPU, etc.). This parameter is particularly
    important for optimizing performance and automatically distributing the model’s
    layers across available devices (like GPUs) in the most efficient manner possible.
    If multiple GPUs are available, it will distribute the load across them to maximize
    parallel processing. If you have access to a GPU, activate it to speed up the
    configuration of this pipeline.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`device_map="auto"` 指示管道自动确定运行模型的最佳设备（CPU、GPU、多 GPU 等）。此参数对于优化性能和在尽可能有效的方式下自动将模型的层分配到可用的设备（如
    GPU）特别重要。如果有多个 GPU 可用，它将在它们之间分配负载以最大化并行处理。如果你能访问 GPU，请激活它以加快此管道的配置。'
- en: Hugging Face is ready; Chroma is required next.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: Hugging Face 已准备就绪；接下来需要 Chroma。
- en: Chroma
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Chroma
- en: 'The following line installs Chroma, our open-source vector database:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 以下行安装了我们的开源向量数据库 Chroma：
- en: '[PRE6]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Take a close look at the following excerpt output, which displays the packages
    installed and, in particular, **Open Neural Network Exchange** (**ONNX**):'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 仔细查看以下摘录输出，它显示了安装的包，特别是 **开放神经网络交换** (**ONNX**)：
- en: '[PRE7]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: ONNX ([https://onnxruntime.ai/](https://onnxruntime.ai/)) is a key component
    in this chapter’s dynamic RAG scenario because it is fully integrated with Chroma.
    ONNX is a standard format for representing **machine learning** (**ML**) models
    designed to enable models to be used across different frameworks and hardware
    without being locked into one ecosystem.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: ONNX ([https://onnxruntime.ai/](https://onnxruntime.ai/)) 是本章动态 RAG 场景中的关键组件，因为它与
    Chroma 完全集成。ONNX 是一种用于表示 **机器学习** (**ML**) 模型的标准格式，旨在使模型能够在不同的框架和硬件上使用，而无需锁定在一个生态系统中。
- en: We will be using ONNX Runtime, which is a performance-focused engine for running
    ONNX models. It acts as a cross-platform accelerator for ML models, providing
    a flexible interface that allows integration with hardware-specific libraries.
    This makes it possible to optimize the models for various hardware configurations
    (CPUs, GPUs, and other accelerators). As for Hugging Face, it is recommended to
    activate a GPU if you have access to one for the program in this chapter. Also,
    we will select a model included within ONNX Runtime installation packages.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 ONNX Runtime，这是一个专注于性能的引擎，用于运行 ONNX 模型。它作为 ML 模型的跨平台加速器，提供了一个灵活的接口，允许与特定硬件的库集成。这使得优化各种硬件配置（CPU、GPU
    和其他加速器）成为可能。至于 Hugging Face，如果你能访问 GPU，建议在本章的程序中激活 GPU。此外，我们还将选择 ONNX Runtime
    安装包内包含的模型。
- en: We have now installed the Hugging Face and Chroma resources we need, including
    ONNX Runtime. Hugging Face’s framework is used throughout the model life cycle,
    from accessing and deploying pre-trained models to training and fine-tuning them
    within its ecosystem. ONNX, among its many features, can intervene in the post-training
    phase to ensure a model’s compatibility and efficient execution across different
    hardware and software setups. Models might be developed and fine-tuned using Hugging
    Face’s tools and then converted to the ONNX format for broad, optimized deployment
    using ONNX Runtime.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经安装了所需的 Hugging Face 和 Chroma 资源，包括 ONNX Runtime。Hugging Face 的框架在整个模型生命周期中使用，从访问和部署预训练模型到在其生态系统中对其进行训练和微调。ONNX
    在其众多功能中，可以在训练后阶段介入，以确保模型在不同硬件和软件设置中的兼容性和高效执行。模型可以使用 Hugging Face 的工具开发和微调，然后转换为
    ONNX 格式，以便使用 ONNX Runtime 进行广泛的优化部署。
- en: 'We will now use spaCy to compute the accuracy between the response we obtain
    when querying our vector store and the original completion text. The following
    command installs a medium-sized English language model from spaCy, tailored for
    general NLP tasks:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将使用 spaCy 来计算当我们查询我们的向量存储时获得的响应与原始完成文本之间的准确性。以下命令从 spaCy 安装了一个中等大小的英语语言模型，适用于通用
    NLP 任务：
- en: '[PRE8]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This model, labeled `en_core_web_md`, originates from web text in English and
    is balanced for speed and accuracy, which we need for dynamic RAG. It is efficient
    for computing text similarity. You may need to restart the session once the package
    is installed.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这个标记为 `en_core_web_md` 的模型源自英文网络文本，它在速度和准确性之间进行了平衡，这是我们动态 RAG 所需要的。它在计算文本相似度方面效率很高。安装包后，您可能需要重新启动会话。
- en: We have now successfully installed the open-source, optimized, cost-effective
    resources we need for dynamic RAG and are ready to start running the program’s
    core.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经成功安装了用于动态 RAG 的开源、优化、成本效益的资源，并准备好开始运行程序的核心。
- en: Activating session time
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 激活会话时间
- en: When working in real-life dynamic RAG projects, such as in this scenario, time
    is essential! For example, if the daily decision-making meeting is at 10 a.m.,
    the RAG preparation team might have to start preparing for this meeting at 8 a.m.
    to gather the data online, in processed company data batches, or in any other
    way necessary for the meeting’s goal.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际动态 RAG 项目中工作，例如在这个场景中，时间至关重要！例如，如果每日决策会议在上午 10 点，RAG 准备团队可能需要在上午 8 点开始准备这次会议，以便在线收集数据、处理公司数据批次或以任何其他必要的方式满足会议目标。
- en: First, activate a GPU if one is available. On Google Colab, for example, go
    to **Runtime** | **Change runtime type** and select a GPU if possible and available.
    If not, the notebook will take a bit longer but will run on a CPU. Then, go through
    each section in this chapter, running the notebook cell by cell to understand
    the process in depth.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，如果可用，激活一个 GPU。例如，在 Google Colab 上，转到 **Runtime** | **Change runtime type**
    并选择一个 GPU（如果可能且可用）。如果不使用 GPU，笔记本将运行得慢一些，但会在 CPU 上运行。然后，逐节阅读本章，逐个运行笔记本单元格，以深入了解整个过程。
- en: 'The following code activates a measure of the session time once the environment
    is installed all the way to the end of the notebook:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码在环境安装完成后，直到笔记本结束都会激活会话时间的测量：
- en: '[PRE9]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Finally, restart the session, go to **Runtime** again, and click on **Run all**.
    Once the program is finished, go to **Total session time**, the last section of
    the notebook. You will have an estimate of how long it takes for a preparation
    run. With the time left before a daily meeting, you can tweak the data, queries,
    and model parameters for your needs a few times.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，重新启动会话，再次转到 **Runtime**，然后点击 **Run all**。一旦程序完成，转到 **Total session time**，笔记本的最后部分。您将得到一个准备运行所需时间的估计。在每日会议前的剩余时间内，您可以多次调整数据、查询和模型参数以满足您的需求。
- en: This on-the-fly dynamic RAG approach will make any team that has these skills
    a precious asset in this fast-moving world. We will start the core of the program
    by downloading and preparing the dataset.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这种即时动态 RAG 方法将使任何拥有这些技能的团队在这个快速变化的世界中成为宝贵的资产。我们将通过下载和准备数据集来启动程序的核心。
- en: Downloading and preparing the dataset
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下载和准备数据集
- en: 'We will use the SciQ dataset created by Welbl, Liu, and Gardner (2017) with
    a method for generating high-quality, domain-specific multiple-choice science
    questions via *crowdsourcing*. The SciQ dataset consists of 13,679 multiple-choice
    questions crafted to aid the training of NLP models for science exams. The creation
    process involves two main steps: selecting relevant passages and generating questions
    with plausible distractors.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 Welbl、Liu 和 Gardner（2017）创建的 SciQ 数据集，该方法通过 *众包* 生成高质量的、特定领域的多项选择题。SciQ
    数据集包含 13,679 个多项选择题，旨在帮助训练用于科学考试的 NLP 模型。创建过程涉及两个主要步骤：选择相关段落和生成具有合理干扰项的问题。
- en: In the context of using this dataset for an augmented generation of questions
    through a Chroma collection, we will implement the `question`, `correct_answer`,
    and `support` columns. The dataset also contains `distractor` columns with wrong
    answers, which we will drop.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用此数据集通过 Chroma 集合进行增强生成问题的上下文中，我们将实现 `question`、`correct_answer` 和 `support`
    列。数据集还包含 `distractor` 列，其中包含错误答案，我们将删除这些列。
- en: 'We will integrate the prepared dataset into a retrieval system that utilizes
    query augmentation techniques to enhance the retrieval of relevant questions based
    on specific scientific topics or question formats for Hugging Face’s Llama model.
    This will allow for the dynamic generation of augmented, real-time completions
    for Llama, as implemented in the chapter’s program. The program loads the training
    data from the `sciq` dataset:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将集成准备好的数据集到一个检索系统中，该系统利用查询增强技术来增强基于特定科学主题或问题格式的相关问题的检索，用于 Hugging Face 的 Llama
    模型。这将允许动态生成增强的实时补全，如章节程序中实现的那样。程序从 `sciq` 数据集中加载训练数据：
- en: '[PRE10]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The dataset is filtered to detect the non-empty `support` and `correct_answer`
    columns:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集被过滤以检测非空的 `support` 和 `correct_answer` 列：
- en: '[PRE11]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We will now display the number of rows filtered:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将显示过滤后的行数：
- en: '[PRE12]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The output shows that we have 10,481 documents:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示我们有 10,481 个文档：
- en: '[PRE13]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We need to clean the DataFrame to focus on the columns we need. Let’s drop
    the distractors (wrong answers to the questions):'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要清理 DataFrame，以便关注我们需要的列。让我们删除干扰项（问题的错误答案）：
- en: '[PRE14]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We have the correct answer and the support content that we will now merge:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有正确答案和支持内容，我们现在将它们合并：
- en: '[PRE15]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The output shows the columns we need to prepare the data for retrieval in the
    completion columns, as shown in the excerpt of the DataFrame for a completion
    field in which `aerobic` is the correct answer because it is the connector and
    the rest of the text is the support content for the correct answer:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示了我们需要为检索准备数据的完成列，如下所示，DataFrame 中一个完成字段的摘录，其中 `aerobic` 是正确答案，因为它是一个连接词，其余文本是正确答案的支持内容：
- en: '[PRE16]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The program now displays the shape of the DataFrame:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 程序现在显示 DataFrame 的形状：
- en: '[PRE17]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The output shows we still have all the initial lines and four columns:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示我们仍然有所有初始行和四列：
- en: '[PRE18]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The following code will display the names of the columns:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码将显示列名：
- en: '[PRE19]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'As a result, the output displays the four columns we need:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，输出显示了我们需要的前四列：
- en: '[PRE20]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The data is now ready to be embedded and upserted.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 数据现在已准备好嵌入和更新。
- en: Embedding and upserting the data in a Chroma collection
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 Chroma 集合中嵌入和更新数据
- en: 'We will begin by creating the Chroma client and defining a collection name:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先创建 Chroma 客户端并定义一个集合名称：
- en: '[PRE21]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Before creating the collection and upserting the data to the collection, we
    need to verify whether the collection already exists or not:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建集合并将数据更新到集合之前，我们需要验证集合是否已经存在：
- en: '[PRE22]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The output will return `True` if the collection exists and `False` if it doesn’t:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将返回 `True` 如果集合存在，否则返回 `False`：
- en: '[PRE23]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'If the collection doesn’t exist, we will create a collection with `collection_name`
    defined earlier:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 如果集合不存在，我们将创建一个具有先前定义的 `collection_name` 的集合：
- en: '[PRE24]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Let’s peek into the structure of the dictionary of the collection we created:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们创建的集合字典的结构：
- en: '[PRE25]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The output displays the dictionary of each item of the collection:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示了集合中每个项目的字典：
- en: '[PRE26]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Let’s briefly go through the three key fields for our scenario:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们简要回顾一下我们场景中的三个关键字段：
- en: '`ids`: This field represents the unique identifiers for each item in the collection.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ids`：此字段表示集合中每个项目的唯一标识符。'
- en: '`embeddings`: Embeddings are the embedded vectors of the documents.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`embeddings`：嵌入是文档的嵌入向量。'
- en: '`documents`: This refers to the `completion` column in which we merged the
    correct answer and the support content.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`documents`：这指的是我们合并了正确答案和支持内容的`completion`列。'
- en: We now need a lightweight rapid LLM model for our dynamic RAG environment.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在需要一个轻量级的快速LLM模型用于我们的动态RAG环境。
- en: Selecting a model
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 选择模型
- en: 'Chroma will initialize a default model, which can be `all-MiniLM-L6-v2`. However,
    let’s make sure we are using this model and initialize it:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: Chroma将初始化一个默认模型，该模型可以是`all-MiniLM-L6-v2`。然而，让我们确保我们正在使用此模型并初始化它：
- en: '[PRE27]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: The `all-MiniLM-L6-v2` model was designed with an optimal, enhanced method by
    Wang et al. (2021) for model compression, focusing on distilling self-attention
    relationships between components of transformer models. This approach is flexible
    in the number of attention heads between teacher and student models, improving
    compression efficiency. The model is fully integrated into Chroma with ONNX, as
    explained in the *Installing the environment* section of this chapter.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '`all-MiniLM-L6-v2`模型是由Wang等人（2021）设计的，采用了一种最优的、增强的方法进行模型压缩，专注于蒸馏Transformer模型组件之间的自注意力关系。这种方法在教师模型和学生模型之间的注意力头数量上具有灵活性，提高了压缩效率。该模型已通过ONNX完全集成到Chroma中，如本章*安装环境*部分所述。'
- en: 'The magic of this `MiniLM` model is based on compression and knowledge distillation
    through a teacher model and the student model:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 这个`MiniLM`模型的魔力基于通过教师模型和学生模型进行的压缩和知识蒸馏：
- en: '**Teacher model**: This is the original, typically larger and more complex
    model such as BERT, RoBERTa, and XLM-R, in our case, that has been pre-trained
    on a comprehensive dataset. The teacher model possesses high accuracy and a deep
    understanding of the tasks it has been trained on. It serves as the source of
    knowledge that we aim to transfer.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**教师模型**：这是原始的、通常更大且更复杂的模型，例如BERT、RoBERTa和XLM-R，在我们的案例中，它已经在综合数据集上进行了预训练。教师模型具有高精度和对其训练任务的深入理解。它作为我们旨在转移的知识来源。'
- en: '**Student model**: This is our smaller, less complex model, `all-MiniLM-L6-v2`,
    which is trained to mimic the teacher model’s behavior, which will prove very
    effective for our dynamic RAG architecture. The goal is to have the student model
    replicate the performance of the teacher model as closely as possible but with
    significantly fewer parameters or computational expense.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**学生模型**：这是我们较小的、较简单的模型`all-MiniLM-L6-v2`，它被训练来模仿教师模型的行为，这将对我们动态RAG架构非常有效。目标是让学生模型尽可能接近地复制教师模型的性能，但参数或计算成本显著减少。'
- en: In our case, `all-MiniLM-L6-v2` will accelerate the embedding and querying process.
    We can see that in the age of superhuman LLM models, such as GPT-4o, we can perform
    daily tasks with smaller compressed and distilled models. Let’s embed the data
    next.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的案例中，`all-MiniLM-L6-v2`将加速嵌入和查询过程。我们可以看到，在超人类LLM模型的时代，如GPT-4o，我们可以使用更小、经过压缩和蒸馏的模型来执行日常任务。让我们接下来嵌入数据。
- en: Embedding and storing the completions
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 嵌入和存储补全内容
- en: 'Embedding and upserting data in a Chroma collection is seamless and concise.
    In this scenario, we’ll embed and upsert the whole `df` completions in a `completion_list`
    extracted from our `df` dataset:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在Chroma集合中嵌入和更新数据是无缝且简洁的。在这种情况下，我们将从我们的`df`数据集中提取的`completion_list`中嵌入和更新整个`df`补全内容：
- en: '[PRE28]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: We use the `collection_exists` status we defined when creating the collection
    to avoid loading the data twice. In this scenario, the collection is temporary;
    we just want to load it once and use it once. If you try to load the data in this
    temporary scenario a second time, you will get warnings. However, you can modify
    the code if you wish to try different datasets and methods, such as preparing
    a prototype at full speed for another project.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用在创建集合时定义的`collection_exists`状态来避免加载数据两次。在这种情况下，集合是临时的；我们只想加载一次并使用一次。如果你尝试在这种临时场景中第二次加载数据，你会收到警告。然而，如果你希望尝试不同的数据集和方法，例如为另一个项目快速准备原型，你可以修改代码。
- en: 'In any case, in this scenario, we first check if the collection exists and
    then upsert the `ids` and `documents` in the `complete_list` and store the `type`
    of data, which is `completion`, in the `metadatas` field:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何情况下，在这种情况下，我们首先检查集合是否存在，然后更新`complete_list`中的`ids`和`documents`，并在`metadatas`字段中存储数据的`type`，即`completion`。
- en: '[PRE29]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Finally, we measure the response time:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们测量响应时间：
- en: '[PRE30]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The output shows that, in this case, Chroma activated the default model through
    `onnx`, as explained in the introduction of this section and also in the *Installing
    the environment* section of this chapter:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示，在这种情况下，Chroma通过`onnx`激活了默认模型，正如本节引言中以及本章“安装环境”部分中所述：
- en: '[PRE31]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The output also shows that the processing time for 10,000+ documents is satisfactory:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 输出还显示，对于10,000多个文档的处理时间是令人满意的：
- en: '[PRE32]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The response time might vary and depends on whether you are using a GPU. When
    using an accessible GPU, the time fits the needs required for dynamic RAG scenarios.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 响应时间可能会有所不同，这取决于你是否在使用GPU。当使用可访问的GPU时，时间符合动态RAG场景所需的时间。
- en: With that, the Chroma vector store is now populated. Let’s take a peek at the
    embeddings.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 到此为止，Chroma向量存储已填充。让我们看看嵌入：
- en: Displaying the embeddings
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 显示嵌入
- en: 'The program now fetches the embeddings and displays the first one:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 程序现在获取嵌入并显示第一个：
- en: '[PRE33]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The output shows that our completions have been vectorized, as we can see in
    the first embedding:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示我们的完成内容已经被向量化，正如我们可以在第一个嵌入中看到的那样：
- en: '[PRE34]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The output also displays the embedding length, which is interesting:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 输出还显示了嵌入长度，这很有趣：
- en: '[PRE35]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: The `all-MiniLM-L6-v2` model reduces the complexity of text data by mapping
    sentences and paragraphs into a 384-dimensional space. This is significantly lower
    than the typical dimensionality of one-hot encoded vectors, such as the 1,526
    dimensions of the OpenAI `text-embedding-ada-002`. This shows that `all-MiniLM-L6-v2`
    uses dense vectors, which use all dimensions of the vector space to encode information
    to produce nuanced semantic relationships between different documents as opposed
    to sparse vectors.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '`all-MiniLM-L6-v2`模型通过将句子和段落映射到一个384维的空间来降低文本数据的复杂性。这比典型的one-hot编码向量的维数要低得多，例如OpenAI的`text-embedding-ada-002`有1,526维。这表明`all-MiniLM-L6-v2`使用密集向量，这些向量使用向量空间的所有维度来编码信息，以产生不同文档之间细微的语义关系，而不是稀疏向量。'
- en: Sparse vector models, such as the **bag-of-words** (**BoW**) model, can be effective
    in some cases. However, their main limitation is that they don’t capture the order
    of words or the context around them, which can be crucial for understanding the
    meaning of text when training LLMs.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 稀疏向量模型，如**词袋模型**（**BoW**），在某些情况下可能很有效。然而，它们的主要局限性是它们不捕获单词的顺序或它们周围的上下文，这在训练LLM时理解文本的意义可能是至关重要的。
- en: We have now embedded the documents into dense vectors in a smaller dimensional
    space than full-blown LLMs and will produce satisfactory results.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将文档嵌入到比完整的LLM更小的维度空间中的密集向量中，并将产生令人满意的结果。
- en: Querying the collection
  id: totrans-160
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 查询集合
- en: 'The code in this section executes a query against the Chroma vector store using
    its integrated semantic search functionality. It queries the vector representations
    of all the vectors in the Chroma collection questions in the initial dataset:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 本节中的代码使用Chroma向量存储的集成语义搜索功能执行查询。它查询初始数据集中Chroma集合问题中所有向量的向量表示：
- en: '[PRE36]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: The query requests one most relevant or similar document for each question with
    `n_results=1`, which you can modify if you wish.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 查询请求每个问题的一个最相关或相似的文档，`n_results=1`，你可以根据需要修改。
- en: 'Each question text is converted into a vector. Then, Chroma runs a vector similarity
    search by comparing the embedded vectors against our database of document vectors
    to find the closest match based on vector similarity:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 每个问题文本都被转换成一个向量。然后，Chroma通过比较嵌入向量与我们的文档向量数据库，根据向量相似度来运行向量相似度搜索，以找到最接近的匹配项：
- en: '[PRE37]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The output displays a satisfactory response time for the 10,000+ queries:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示了10,000多个查询的令人满意的响应时间：
- en: '[PRE38]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'We will now analyze the 10,000+ queries. We will use spaCy to evaluate a query’s
    result and compare it with the original completion. We first load the spaCy model
    we installed in the *Installing the environment* section of this chapter:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将分析10,000多个查询。我们将使用spaCy来评估查询结果，并将其与原始完成内容进行比较。我们首先加载本章“安装环境”部分中安装的spaCy模型：
- en: '[PRE39]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The program then creates a similarity function that takes two arguments (the
    original completion, `text1`, and the retrieved text, `text2`) and returns the
    similarity value:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 程序随后创建了一个相似度函数，该函数接受两个参数（原始完成内容`text1`和检索到的文本`text2`）并返回相似度值：
- en: '[PRE40]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'We will now perform a full validation run on the 10,000 queries. As can be
    seen in the following code block, the validation begins by defining the variables
    we will need:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将对10,000个查询进行完整的验证运行。如下面的代码块所示，验证首先定义了我们需要的变量：
- en: '`nbqd` to only display the first 100 and last 100 results.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nbqd` 用于仅显示前100条和最后100条结果。'
- en: '`acc_counter` measures the results with a similarity score superior to 0.5,
    which you can modify to fit your needs.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`acc_counter` 测量相似度分数高于 0.5 的结果，您可以根据需要修改它。'
- en: '`display_counter` to count the number of results we have displayed:'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`display_counter` 用于计算我们已显示的结果数量：'
- en: '[PRE41]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'The program goes through `nb` results, which, in our case, is the total length
    of our dataset:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 程序会遍历 `nb` 个结果，在我们的案例中，这是我们的数据集的总长度：
- en: '[PRE42]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: The code accesses the original completion and stores it in `original_completion`.
    Then, it retrieves the result and stores it in `retrieved_document`. Finally,
    it calls the similarity function we defined, `simple_text_similarity`. The original
    completion and the retrieved document store the similarity score in `similarity_score`.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 代码访问原始完成内容并将其存储在 `original_completion` 中。然后，它检索结果并将其存储在 `retrieved_document`
    中。最后，它调用我们定义的相似度函数 `simple_text_similarity`。原始完成内容和检索到的文档将相似度分数存储在 `similarity_score`
    中。
- en: 'Now, we introduce an accuracy metric. In this scenario, the threshold of the
    similarity score is set to `0.7`, which is reasonable:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们引入一个准确度指标。在这种情况下，相似度分数的阈值设置为 `0.7`，这是合理的：
- en: '[PRE43]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'If `similarity_score > 0.7`, then the accuracy counter, `acc_counter`, is incremented.
    The display counter, `display_counter`, is also incremented to only the first
    and last `nbqd` (maximum results to display) defined at the beginning of this
    function:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 `similarity_score > 0.7`，则准确率计数器 `acc_counter` 会增加。显示计数器 `display_counter`
    也会增加，仅对在函数开头定义的第一个和最后 `nbqd`（最大显示结果）进行计数：
- en: '[PRE44]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'The information displayed provides insights into the performance of the system:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 显示的信息提供了对系统性能的洞察：
- en: '[PRE45]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'The output displays four key variables:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示了四个关键变量：
- en: '`{q}` is the question asked, the query.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`{q}` 是提出的问题，即查询。'
- en: '`{retrieved_document}` is the document retrieved.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`{retrieved_document}` 是检索到的文档。'
- en: '`{original_completion}` is the original document in the dataset.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`{original_completion}` 是数据集中的原始文档。'
- en: '`{similarity_score:.2f}` is the similarity score between the original document
    and the document retrieved to measure the performance of each response.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`{similarity_score:.2f}` 是原始文档与检索到的文档之间的相似度分数，用于衡量每个响应的性能。'
- en: The first output provides the information required for a human observer to control
    the result of the query and trace it back to the source.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个输出提供了人类观察者控制查询结果并追踪其来源所需的信息。
- en: 'The first part of the output is the question, the query:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 输出的第一部分是问题，即查询：
- en: '[PRE46]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'The second part of the output is the retrieved document:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 输出的第二部分是检索到的文档：
- en: '[PRE47]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'The third part of the output is the original completion. In this case, we can
    see that the retrieved document provides relevant information but not the exact
    original completion:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 输出的第三部分是原始的完成内容。在这种情况下，我们可以看到检索到的文档提供了相关信息，但并非确切的原始完成内容：
- en: '[PRE48]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Finally, the output displays the similarity score calculated by spaCy:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，输出显示了由 spaCy 计算的相似度分数：
- en: '[PRE49]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: The score shows that although the original completion was not selected, the
    completion selected is relevant.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 分数显示，尽管原始完成内容未被选中，但选中的完成内容是相关的。
- en: 'When all the results have been analyzed, the program calculates the accuracy
    obtained for the 10,000+ queries:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 当所有结果都已分析完毕后，程序会计算10,000+个查询获得的准确率：
- en: '[PRE50]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'The calculation is based on the following:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 计算基于以下内容：
- en: '`Acc` is the overall accuracy obtained'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Acc` 是获得的整体准确率'
- en: '`acc_counter` is the total of `Similarity` `scores > 0.7`'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`acc_counter` 是大于 0.7 的 `Similarity` 分数的总和'
- en: '`nb` is the number of queries. In this case, `nb=len(df)`'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nb` 是查询数量。在这种情况下，`nb=len(df)`'
- en: '`acc=acc_counter/nb` calculates the overall accuracy of all the results'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`acc=acc_counter/nb` 计算所有结果的总体准确率'
- en: 'The code then displays the number of documents measured and the overall similarity
    score:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，代码显示测量的文档数量和总体相似度分数：
- en: '[PRE51]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'The output shows that all the questions returned relevant results:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示，所有返回的问题都得到了相关结果：
- en: '[PRE52]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: This satisfactory overall similarity score shows that the system works in a
    closed environment. But we need to go further and see what happens in the open
    environment of heated discussions in a meeting!
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 这个令人满意的总体相似度分数表明，系统在封闭环境中工作。但我们需要更进一步，看看在会议中热烈讨论的开放环境中会发生什么！
- en: Prompt and retrieval
  id: totrans-213
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提示和检索
- en: This section is the one to use during real-time querying meetings. You can adapt
    the interface to your needs. We’ll focus on functionality.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 这个部分是在实时查询会议期间要使用的部分。你可以根据需要调整界面。我们将关注功能。
- en: 'Let’s look at the first prompt:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看第一个提示：
- en: '[PRE53]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'You will notice that there are two commented variants under the first prompt.
    Let’s clarify this:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 你会注意到在第一个提示下面有两个被注释的变体。让我们澄清这一点：
- en: '`initial question` is the exact text that comes from the initial dataset. It
    isn’t likely that an attendee in the meeting or a user will ask the question that
    way. But we can use it to verify if the system is working.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`initial question`是从初始数据集中来的确切文本。与会者或用户不太可能以这种方式提问。但我们可以用它来验证系统是否正常工作。'
- en: '`variant 1` is similar to the initial question and could be asked.'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`variant 1`与初始问题相似，可以提出。'
- en: '`variant 2` diverges and may prove challenging.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`variant 2`发生了分歧，可能会带来挑战。'
- en: We will select `variant 1` for this section and we should obtain a satisfactory
    result.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将为本节选择`variant 1`，并应该获得令人满意的结果。
- en: We can see that, as for all AI programs, human control is mandatory! The more
    `variant 2` diverges with spontaneous questions, the more challenging it becomes
    for the system to remain stable and respond as we expect. This limit explains
    why, even if a dynamic RAG system can adapt rapidly, designing a solid system
    will require careful and continual improvements.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，对于所有人工智能程序来说，人类控制是强制性的！当`variant 2`与自发提出的问题差异越大时，系统保持稳定并按我们期望的方式响应的挑战就越大。这个限制解释了为什么，即使一个动态的RAG系统可以快速适应，设计一个稳固的系统也需要仔细和持续的改进。
- en: 'If we query the collection as we did in the previous section with one prompt
    only this time, we will obtain a response rapidly:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们像上一节那样只使用一个提示来查询集合，这次我们将快速获得响应：
- en: '[PRE54]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'The response time is rapid:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 响应时间很快：
- en: '[PRE55]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'The output shows that the retrieved document is relevant:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示检索到的文档是相关的：
- en: '[PRE56]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: We have successfully retrieved the result of our query. This semantic vector
    search might even be enough if the attendees of the meeting are satisfied with
    it. You will always have time to improve the configuration of RAG with Llama.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经成功检索到了查询结果。如果会议的与会者对它感到满意，这种语义向量搜索可能就足够了。你将始终有时间使用Llama改进RAG的配置。
- en: Hugging Face Llama will now take this response and write a brief NLP summary.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: Hugging Face Llama现在将采取这个响应并写一个简短的NLP摘要。
- en: RAG with Llama
  id: totrans-231
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: RAG与Llama
- en: 'We initialized `meta-llama/Llama-2-7b-chat-hf` in the *Installing the environment*
    section. We must now create a function to configure Llama 2’s behavior:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在*安装环境*部分初始化了`meta-llama/Llama-2-7b-chat-hf`。我们现在必须创建一个函数来配置Llama 2的行为：
- en: '[PRE57]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'You can tweak each parameter to your expectations:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以调整每个参数以满足你的期望：
- en: '`prompt`: The input text that the model uses to generate the output. It’s the
    starting point for the model’s response.'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt`：模型用来生成输出的输入文本。它是模型响应的起点。'
- en: '`do_sample`: A Boolean value (`True` or `False`). When set to `True`, it enables
    stochastic sampling, meaning the model will pick tokens randomly based on their
    probability distribution, allowing for more varied outputs.'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`do_sample`：一个布尔值（`True`或`False`）。当设置为`True`时，它启用随机采样，这意味着模型将根据它们的概率分布随机选择标记，从而产生更多样化的输出。'
- en: '`top_k`: This parameter limits the number of highest-probability vocabulary
    tokens to consider when selecting tokens in the sampling process. Setting it to
    `10` means the model will choose from the top 10 most likely next tokens.'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`top_k`：这个参数限制了在采样过程中选择标记时要考虑的最高概率词汇标记的数量。将其设置为`10`意味着模型将从最有可能的下一个标记的前10个中进行选择。'
- en: '`num_return_sequences`: Specifies the number of independently generated responses
    to return. Here, it is set to `1`, meaning the function will return one sequence
    for each prompt.'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_return_sequences`：指定要返回的独立生成的响应数量。在这里，它被设置为`1`，意味着对于每个提示，函数将返回一个序列。'
- en: '`eos_token_id`: This token marks the end of a sequence in tokenized form. Once
    it is generated, the model stops generating further tokens. The end-of-sequence
    token is an `id` that points to Llama’s `eos_token`.'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eos_token_id`：这个标记标记了序列在标记形式中的结束。一旦生成，模型就会停止生成更多的标记。序列结束标记是一个指向Llama的`eos_token`的`id`。'
- en: '`max_new_tokens`: Limits the number of new tokens the model can generate. Set
    to `100` here, it constrains the output to a maximum length of 100 tokens beyond
    the input prompt length.'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_new_tokens`：限制模型可以生成的新的标记数量。这里设置为 `100`，它将输出限制在输入提示长度之外的最多 100 个标记。'
- en: '`temperature`: This controls randomness in the sampling process. A temperature
    of `0.5` makes the model’s responses less random and more focused than a higher
    temperature but still allows for some diversity.'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`temperature`：这控制采样过程中的随机性。`0.5` 的温度使得模型的响应比更高温度时更不随机、更专注，但仍允许一些多样性。'
- en: '`repetition_penalty`: A modifier that discourages the model from repeating
    the same token. A penalty of `2.0` means any token already used is less likely
    to be chosen again, promoting more diverse and less repetitive text.'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`repetition_penalty`：一个修饰符，用于阻止模型重复相同的标记。`2.0` 的惩罚意味着已经使用的任何标记再次被选中的可能性较低，从而促进更多样化和更少重复的文本。'
- en: '`truncation`: When enabled, it ensures the output does not exceed the maximum
    length specified by `max_new_tokens` by cutting off excess tokens.'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`truncation`：当启用时，它确保输出不会超过由 `max_new_tokens` 指定的最大长度，通过截断多余的标记。'
- en: 'The prompt will contain the instruction for Llama in `iprompt` and the result
    obtained in the *Prompt and retrieval* section of the notebook. The result is
    appended to `iprompt`:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 提示将包含 Llama 的指令在 `iprompt` 中，以及笔记本的“提示和检索”部分中获得的结果。结果附加到 `iprompt`：
- en: '[PRE58]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'The augmented input for the Llama call is `lprompt`. The code will measure
    the time it takes and make the completion request:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: Llama 调用的增强输入是 `lprompt`。代码将测量所需时间并完成请求：
- en: '[PRE59]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'We now retrieve the generated text from the response and display the time it
    took for Llama to respond:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在从响应中检索生成的文本，并显示 Llama 响应所需的时间：
- en: '[PRE60]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'The output shows that Llama returned the completion in a reasonable time:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示 Llama 在合理的时间内返回了补全：
- en: '[PRE61]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Let’s wrap the response in a nice format to display it:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将响应包装在一个漂亮的格式中以便显示：
- en: '[PRE62]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'The output displays a technically reasonable completion:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示了一个技术上合理的补全：
- en: '[PRE63]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: The summary produced by Llama is technically acceptable. To obtain another,
    possibly better result, as long as the session is not closed, the user can run
    a query and an augmented generation several times with different Llama parameters.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: Llama 生成的摘要技术上是可以接受的。为了获得另一个，可能更好的结果，只要会话没有关闭，用户就可以多次运行查询和增强生成，使用不同的 Llama 参数。
- en: 'You can even try another LLM. Dynamic RAG doesn’t necessarily have to be 100%
    open-source. If necessary, we must be pragmatic and introduce whatever it takes.
    For example, the following prompt was submitted to ChatGPT with GPT-4o, which
    is the result of the query we used for Llama:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 您甚至可以尝试另一个 LLM。Dynamic RAG 不一定必须是 100% 开源的。如果需要，我们必须务实，引入任何必要的工具。例如，以下提示被提交到
    ChatGPT，使用的是 GPT-4o，这是 Llama 查询的结果：
- en: '[PRE64]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'The output of OpenAI GPT-4o surpasses Llama 2 in this case and produces a satisfactory
    output:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，OpenAI GPT-4o 的输出超过了 Llama 2，并产生了令人满意的结果：
- en: '[PRE65]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: If necessary, you can replace `meta-llama/Llama-2-7b-chat-hf` with GPT-4o, as
    implemented in *Chapter 4*, *Multimodal Modular RAG for Drone Technology*, and
    configure it to obtain this level of output. The only rule in dynamic RAG is performance.
    With that, we’ve seen that there are many ways to implement dynamic RAG.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要，您可以将 `meta-llama/Llama-2-7b-chat-hf` 替换为在 *第 4 章*，*多模态模块化 RAG 用于无人机技术*
    中实现的 GPT-4o，并配置它以获得这种输出级别。动态 RAG 的唯一规则是性能。有了这个，我们已经看到有许多方法可以实现动态 RAG。
- en: Once the session is over, we can delete it.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦会话结束，我们就可以删除它。
- en: Deleting the collection
  id: totrans-263
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 删除集合
- en: 'You can manually delete the collection with the following code:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用以下代码手动删除集合：
- en: '[PRE66]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'You can also close the session to delete the temporary dynamic RAG collection
    created. We can check and see whether the collection we created, `collection_name`,
    still exists or not:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以关闭会话以删除创建的临时动态 RAG 集合。我们可以检查我们创建的集合 `collection_name` 是否仍然存在：
- en: '[PRE67]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'If we are still working on a collection in a session, the response will be
    `True`:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们仍在会话中工作在一个集合上，响应将是 `True`：
- en: '[PRE68]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: If we delete the collection with code or by closing the session, the response
    will be `False`. Let’s take a look at the total session time.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们用代码或通过关闭会话删除集合，响应将是 `False`。让我们看看总会话时间。
- en: Total session time
  id: totrans-271
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总会话时间
- en: 'The following code measures the time between the beginning of the session and
    immediately after the *Installing the environment* section:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码测量会话开始和“安装环境”部分之后的间隔时间：
- en: '[PRE69]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'The output can have two meanings:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 输出可以有两个含义：
- en: It can measure the time we worked on the preparation of the dynamic RAG scenario
    with the daily dataset for the Chroma collection, querying, and summarizing by
    Llama.
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它可以衡量我们为Chroma集合、查询和Llama总结的每日数据集动态RAG场景所做的准备工作所需的时间。
- en: It can measure the time it took to run the whole notebook without intervening
    at all.
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它可以衡量在没有干预的情况下运行整个笔记本所需的时间。
- en: 'In this case, the session time is the result of a full run with no human intervention:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，会话时间是无人干预的完整运行的结果：
- en: '[PRE70]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: The whole process takes less than 15 minutes, which fits the constraints of
    the preparation time in a dynamic RAG scenario. It leaves room for a few runs
    to tweak the system before the meeting. With that, we have successfully walked
    through a dynamic RAG process and will now summarize our journey.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 整个过程不到15分钟，这符合动态RAG场景中准备时间的限制。这为会议前进行几次系统调整留出了空间。有了这个，我们已经成功走过了动态RAG的过程，现在我们将总结我们的旅程。
- en: Summary
  id: totrans-280
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In a fast-evolving world, gathering information rapidly for decision-making
    provides a competitive advantage. Dynamic RAG is one way to bring AI into meeting
    rooms with rapid and cost-effective AI. We built a system that simulated the need
    to obtain answers to hard science questions in a daily meeting. After installing
    and analyzing the environment, we downloaded and prepared the SciQ dataset, a
    science question-and-answer dataset, to simulate a daily meeting during which
    hard science questions would be asked. The attendees don’t want to spend their
    time searching the web and wasting their time when decisions must be made. This
    could be for a marketing campaign, fact-checking an article, or any other situation
    in which hard science knowledge is required.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个快速发展的世界中，快速收集信息以供决策提供竞争优势。动态RAG是将AI快速且经济高效地引入会议室的一种方式。我们构建了一个系统，模拟了在每日会议中获取对硬科学问题的答案的需求。在安装和分析环境后，我们下载并准备了SciQ数据集，一个科学问答数据集，以模拟在会议期间会提出硬科学问题的日常会议。与会者不希望在他们必须做出决策时浪费时间搜索网络。这可能是一个营销活动、核实文章或任何需要硬科学知识的其他情况。
- en: We created a Chroma collection vector store. We then embedded 10,000+ documents
    and inserted data and vectors into the Chroma vector store on our machine with
    `all-MiniLM-L6-v2`. The process proved cost-effective and sufficiently rapid.
    The collection was created locally, so there is no storage cost. The collection
    is temporary, so there is no useless space usage or cluttering. We then queried
    the collection to measure the accuracy of the system we set up. The results were
    satisfactory, so we processed the full dataset to confirm. Finally, we created
    the functionality for a user prompt and query function to use in real time during
    a meeting. The result of the query augmented the user’s input for `meta-llama/Llama-2-7b-chat-hf`,
    which transformed the query into a short summary.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建了一个Chroma集合向量存储。然后我们嵌入10,000+文档，并使用`all-MiniLM-L6-v2`将数据和向量插入到我们机器上的Chroma向量存储中。这个过程证明是成本效益高且足够快速的。集合是在本地创建的，因此没有存储成本。集合是临时的，所以没有无用的空间使用或杂乱。然后我们查询了集合，以衡量我们设置的系统的准确性。结果令人满意，所以我们处理了整个数据集以确认。最后，我们创建了用户提示和查询功能，以便在会议期间实时使用。查询结果增强了用户对`meta-llama/Llama-2-7b-chat-hf`的输入，将查询转换为一个简短的摘要。
- en: The dynamic RAG example we implemented would require more work before being
    released into production. However, it provides a path to open-source, lightweight,
    RAG-driven generative AI for rapid data collection, embedding, and querying. If
    we need to store the retrieval data and don’t want to create large vector stores,
    we can integrate our datasets in an OpenAI GPT-4o-mini model, for example, through
    fine-tuning, as we will see in the next chapter.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 我们实施的动态RAG示例在投入生产前需要更多的工作。然而，它为开源、轻量级的RAG驱动生成AI提供了快速数据收集、嵌入和查询的路径。如果我们需要存储检索数据，又不想创建大型向量存储，我们可以通过微调将我们的数据集集成到OpenAI
    GPT-4o-mini模型中，例如，正如我们将在下一章中看到的。
- en: Questions
  id: totrans-284
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: 'Answer the following questions with *Yes* or *No*:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 用*是*或*否*回答以下问题：
- en: Does the script ensure that the Hugging Face API token is never hardcoded directly
    into the notebook for security reasons?
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 脚本是否确保出于安全原因，Hugging Face API令牌永远不会直接硬编码到笔记本中？
- en: In the chapter’s program, is the `accelerate` library used here to facilitate
    the deployment of ML models on cloud-based platforms?
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在章节的程序中，这里使用的`accelerate`库是否用于促进ML模型在云平台上的部署？
- en: Is user authentication separate from the API token required to access the Chroma
    database in this script?
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这个脚本中，用户身份验证是否与访问Chroma数据库所需的API令牌分开？
- en: Does the notebook use Chroma for temporary storage of vectors during the dynamic
    retrieval process?
  id: totrans-289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个笔记本是否使用Chroma在动态检索过程中临时存储向量？
- en: Is the notebook configured to use real-time acceleration of queries through
    GPU optimization?
  id: totrans-290
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个笔记本是否配置为通过GPU优化实现查询的实时加速？
- en: Can this notebook’s session time measurements help in optimizing the dynamic
    RAG process?
  id: totrans-291
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个笔记本的会话时间测量能否帮助优化动态RAG过程？
- en: Does the script demonstrate Chroma’s capability to integrate with ML models
    for enhanced retrieval performance?
  id: totrans-292
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个脚本是否展示了Chroma与ML模型集成以增强检索性能的能力？
- en: Does the script include functionality for adjusting the parameters of the Chroma
    database based on session performance metrics?
  id: totrans-293
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个脚本是否包含根据会话性能指标调整Chroma数据库参数的功能？
- en: References
  id: totrans-294
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '*Crowdsourcing Multiple Choice Science Questions* by Johannes Welbl, Nelson
    F. Liu, Matt Gardner: [http://arxiv.org/abs/1707.06209](http://arxiv.org/abs/1707.06209).'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*《众包多选题科学问题》*，作者：Johannes Welbl, Nelson F. Liu, Matt Gardner: [http://arxiv.org/abs/1707.06209](http://arxiv.org/abs/1707.06209).'
- en: '*MiniLMv2: Multi-Head Self-Attention Relation Distillation for Compressing
    Pretrained Transformers* by Wenhui Wang, Hangbo Bao, Shaohan Huang, Li Dong, Furu
    Wei: [https://arxiv.org/abs/2012.15828](https://arxiv.org/abs/2012.15828).'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*《MiniLMv2：用于压缩预训练Transformer的多头自注意力关系蒸馏》*，作者：Wenhui Wang, Hangbo Bao, Shaohan
    Huang, Li Dong, Furu Wei: [https://arxiv.org/abs/2012.15828](https://arxiv.org/abs/2012.15828).'
- en: 'Hugging Face Llama model documentation: [https://huggingface.co/docs/transformers/main/en/model_doc/llama](https://huggingface.co/docs/transformers/main/en/model_doc/llama).'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hugging Face Llama模型文档：[https://huggingface.co/docs/transformers/main/en/model_doc/llama](https://huggingface.co/docs/transformers/main/en/model_doc/llama).
- en: 'ONNX: [https://onnxruntime.ai/](https://onnxruntime.ai/).'
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ONNX：[https://onnxruntime.ai/](https://onnxruntime.ai/).
- en: Further reading
  id: totrans-299
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: '*MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression of
    Pre-Trained Transformers* by Wenhui Wang, Furu Wei, Li Dong, Hangbo Bao, Nan Yang,
    Ming Zhou: [https://arxiv.org/abs/2002.10957](https://arxiv.org/abs/2002.10957).'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*《MiniLM：用于任务无关预训练Transformer压缩的深度自注意力蒸馏》*，作者：Wenhui Wang, Furu Wei, Li Dong,
    Hangbo Bao, Nan Yang, Ming Zhou: [https://arxiv.org/abs/2002.10957](https://arxiv.org/abs/2002.10957).'
- en: '*LLaMA: Open and Efficient Foundation Language Models* by Hugo Touvron, Thibaut
    Lavril, Gautier Lzacard, et al.: [https://arxiv.org/abs/2302.13971](https://arxiv.org/abs/2302.13971).'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*《LLaMA：开放且高效的基座语言模型》*，作者：Hugo Touvron, Thibaut Lavril, Gautier Lzacard, 等：[https://arxiv.org/abs/2302.13971](https://arxiv.org/abs/2302.13971).'
- en: 'Building an ONNX Runtime package: [https://onnxruntime.ai/docs/build/custom.html#custom-build-packages](https://onnxruntime.ai/docs/build/custom.html#custom-build-packages).'
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建ONNX Runtime包：[https://onnxruntime.ai/docs/build/custom.html#custom-build-packages](https://onnxruntime.ai/docs/build/custom.html#custom-build-packages).
- en: Join our community on Discord
  id: totrans-303
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们的Discord社区
- en: 'Join our community’s Discord space for discussions with the author and other
    readers:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 加入我们社区的Discord空间，与作者和其他读者进行讨论：
- en: '[https://www.packt.link/rag](https://www.packt.link/rag)'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.packt.link/rag](https://www.packt.link/rag)'
- en: '![](img/QR_Code50409000288080484.png)'
  id: totrans-306
  prefs: []
  type: TYPE_IMG
  zh: '![二维码](img/QR_Code50409000288080484.png)'
