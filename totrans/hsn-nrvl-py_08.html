<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Novelty Search Optimization Method</h1>
                </header>
            
            <article>
                
<p class="p1"><span class="s1">In this chapter, you will learn about an advanced solution search optimization method that can be used to create autonomous navigator agents. This method is called <strong>Novelty Search</strong> (<strong>NS</strong>). The main idea of this method is that an objective function can be defined using the novelty of the behavior exposed by the solver agent, rather than the distance to a goal in the solution search space.</span></p>
<p class="p1"><span class="s1">In this chapter, you will learn how to use NS-based search optimization methods with the neuroevolution algorithm to train successful maze navigation agents. By conducting the experiments presented in this chapter, you will also see that the <span>NS</span> method is superior to the conventional goal-oriented search optimization method for specific tasks. By</span><span class="s1"> the end of this chapter, you will have learned the basics of the <span>NS</span> optimization method. You will be able to define the fitness function using the novelty score and apply it to solve practical tasks related to your work or experiments.</span></p>
<p>The following topics will be covered in this chapter:</p>
<ul>
<li>The NS optimization method</li>
<li><span>NS</span> implementation basics</li>
<li>The fitness function with the novelty score</li>
<li>Experimenting with a simple maze configuration</li>
<li>Experimenting with a hard-to-solve maze configuration</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Technical requirements</h1>
                </header>
            
            <article>
                
<p class="p1"><span class="s1">The following technical requirements should be met in order to carry out the experiments described in this chapter:</span></p>
<ul class="ul1">
<li class="li1"><span class="s1">Windows 8/10, macOS 10.13 or newer, or modern Linux</span></li>
<li class="li1"><span class="s1">Anaconda Distribution version 2019.03 or newer</span></li>
</ul>
<p>The code for this chapter can be found at <a href="https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Python/tree/master/Chapter6">https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Python/tree/master/Chapter6</a></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The NS optimization method</h1>
                </header>
            
            <article>
                
<p class="p1"><span class="s1">The main idea behind NS is to reward the novelty of the produced solution rather than its progress to the final goal. This idea is inspired by natural evolution. When looking for a successful solution, it is not always obvious the exact steps that should be taken. Natural evolution continuously produces novel forms, with different phenotypes trying to exploit the surrounding environment and adapt to the changes. This has allowed an explosion of life forms on Earth and ignited qualitative leaps forward in the evolution of life. The same process allowed life forms to leave the sea and conquer the land. The extraordinary genesis of eukaryotes became the source of all higher life forms on the planet.<span class="Apple-converted-space"> </span>All these are examples of rewarding novelty during evolution. At the same time, there is no clear objective or final goal in natural evolution.</span></p>
<p class="p1"><span class="s1">As you learned in the previous chapter, conventional goal-oriented fitness functions are susceptible to local optima traps. This pathology produces pressure on the evolutionary process to converge to a single solution that often gets stuck in dead ends in a search space, with no local steps available that can improve the performance of the fitness function any further. Thus, as a result, the successful solution is left unexplored.</span></p>
<p class="p1"><span class="s1">On the other hand, NS drives evolution toward diversity. This drive helps the neuroevolution process to produce successful solver agents, even for tasks with a deceptive landscape of the fitness function values, such as maze navigation problems.</span></p>
<p class="p1"><span class="s1">A real-life example of such a deceptive problem is the task of navigating around an unknown city. If you visit old cities with irregular road maps, you need to use a different strategy to get from point A to point B than in modern cities with regular grid patterns of roads. In modern cities, traveling along roads that point in the direction of your destination is sufficient, but navigation in old cities is much more tricky. Heading toward the destination often leads you to dead ends (deceptive local optima). You need to employ a more explorative approach, trying novel and often counterintuitive directions that seemingly lead you away from your destination. So, finally, after another twist in the road, you reach your destination. However, note that from the start it was not obvious which turns to take based only on the distance to the final destination (that is, the goal-oriented fitness score). The stepping stones leading to the ultimate solution are often placed in counterintuitive places that seem to lead you away, but ultimately help you to succeed.</span></p>
<div class="p1 packt_infobox"><span class="s1">Please refer to <a href="f59c6396-55e5-4495-95c0-7af9a42c2f20.xhtml" target="_blank">Chapter 1</a>, <em>Overview of Neuroevolution Methods</em>, for more details about NS optimization.</span></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">NS implementation basics</h1>
                </header>
            
            <article>
                
<p class="p1"><span class="s1">NS implementation should include data structure to hold information about the explored novel item and the structure to maintain and manage a list of novel items. In our implementation, this functionality is encapsulated in three Python classes:</span></p>
<ul class="ul1">
<li class="li1"><kbd>NoveltyItem</kbd><span class="s1">: The structure that holds all relevant information about the novelty score of the individual that was evaluated during the evolution.</span></li>
<li class="li1"><kbd>NoveltyArchive</kbd><span class="s1">: The class that maintains a list of the relevant <kbd>NoveltyItem</kbd> instances. It provides methods to evaluate the novelty scores of individual genomes compared to the already collected <kbd>NoveltyItem</kbd> instances and the current population.</span></li>
<li class="li1"><kbd>ItemsDistance</kbd><span class="s1">: The auxiliary structure that holds the distance (novelty) metric value between the two <kbd>NoveltyItem</kbd> <span>instances</span>. It is used in calculations of the average k-nearest neighbor distance, which is used as a novelty score value in our experiment.</span></li>
</ul>
<div class="p1 packt_infobox"><span class="s1">For implementation details, refer to the <kbd>novelty_archive.py</kbd> <span>file </span>at <a href="https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Python/blob/master/Chapter6/novelty_archive.py">https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Python/blob/master/Chapter6/novelty_archive.py</a>.</span></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">NoveltyItem</h1>
                </header>
            
            <article>
                
<p class="p1"><span class="s1">This class is the main structure that holds information about the novelty score of each individual evaluated during the evolution. It has several fields that store relevant information, as we can see in the source code:</span></p>
<pre>    def __init__(self, generation=-1, genomeId=-1, fitness=-1, novelty=-1):<br/>        self.generation = generation<br/>        self.genomeId = genomeId<br/>        self.fitness = fitness<br/>        self.novelty = novelty<br/>        self.in_archive = False<br/>        self.data = []</pre>
<p class="p1"><span class="s1">The <kbd>generation</kbd> field holds the ID of the generation at which this item was created. Basically, <kbd>genomeId</kbd> is the ID of the genome that was evaluated, and <kbd>fitness</kbd> is a goal-oriented fitness score of the evaluated genome (the proximity to the maze exit). Furthermore, <kbd>novelty</kbd> is the novelty score given to the evaluated genome, as we discuss in the next section, and <kbd>data</kbd> is a list of data points representing the coordinates of specific maze positions that the maze solver agent visited during a simulation. This data list is used to estimate the distance between the current and other novelty items. The calculated distance after that can be used to estimate the novelty score associated with the specific novelty item.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">NoveltyArchive</h1>
                </header>
            
            <article>
                
<p class="p1"><span class="s1">This class maintains a list of relevant novelty items and provides methods to evaluate the novelty scores of individual genomes as well as of the entire population of genomes as a whole. It has the following fields defined in the constructor:</span></p>
<pre>    def __init__(self, threshold, metric):<br/>        self.novelty_metric = metric<br/>        self.novelty_threshold = threshold<br/>        self.novelty_floor = 0.25<br/>        self.items_added_in_generation = 0<br/>        self.time_out = 0<br/>        self.neighbors = KNNNoveltyScore<br/>        self.generation = 0<br/>        self.novel_items = []<br/>        self.fittest_items = []</pre>
<p class="p1"><span class="s1">Note that <kbd>novelty_metric</kbd> is a reference to the function that can be used to estimate the novelty metric or distance between two novelty items.</span></p>
<p class="p1"><span class="s1">Furthermore, <kbd>novelty_threshold</kbd> defines the current minimal novelty score value of <kbd>NoveltyItem</kbd> to be eligible for adding to this archive. This value is dynamic and is changed during execution to maintain the size of the archive within particular limits; <kbd>novelty_floor</kbd> is the minimal possible value of <kbd>novelty_threshold</kbd>. The <kbd>items_added_in_generation</kbd> and <kbd>time_out</kbd> fields are used to schedule the dynamics of the change of the <kbd>novelty_threshold</kbd> values. The <kbd>neighbors</kbd> field is a default number of <em>k-nearest neighbors</em> to use for a novelty score estimation. The generation is the current evolutionary generation. Basically, <kbd>novel_items</kbd> is a list of all the relevant <kbd>NoveltyItem</kbd> instances collected so far, and <kbd>fittest_items</kbd> is the list of the novel items having<span> the maximal goal-oriented fitness score among all</span>.</span></p>
<p class="p1"><span class="s1">The dynamics of the <kbd>novelty_threshold</kbd> field are determined by the following source code:</span></p>
<pre>    def _adjust_archive_settings(self):<br/>        if self.items_added_in_generation == 0:<br/>            self.time_out += 1<br/>        else:<br/>            self.time_out = 0<br/>        if self.time_out &gt;= 10:<br/>            self.novelty_threshold *= 0.95<br/>            if self.novelty_threshold &lt; self.novelty_floor:<br/>                self.novelty_threshold = self.novelty_floor<br/>            self.time_out = 0<br/>        if self.items_added_in_generation &gt;= 4:<br/>            self.novelty_threshold *= 1.2<br/>        self.items_added_in_generation = 0</pre>
<p class="p1"><span class="s1">The preceding function is invoked at the end of each evolutionary generation to adjust the <kbd>novelty_threshold</kbd> field value for the next generation. As already mentioned, this value determines how many novelty items should be added to the archive in the next generation. The dynamic adjustment of this property is necessary to match the difficulty of finding novel solutions using the NS method over time. At the beginning of the evolution, there were immense opportunities to find novel solutions with high novelty scores, since only a few paths were explored in the maze. However, toward the end of the evolution, it becomes harder because fewer unexplored paths remain. To compensate for this, if a novel path is not found in the last 2,500 evaluatio</span>ns (<span class="s1"><kbd>10</kbd> generations), the <kbd>novelty_threshold</kbd> value is lowered by 5%. On the other hand, to decrease the speed of adding a new <kbd>NoveltyItem</kbd> to the archive in the early stages of evolution, the <kbd>novelty_threshold</kbd> value is raised by 20%, if over four items were added in the last generation.</span></p>
<p class="p1"><span class="s1">The following source code shows how the <kbd>novelty_threshold</kbd> value is used to determine which <kbd>NoveltyItem</kbd> to add:</span></p>
<pre>    def evaluate_individual_novelty(self, genome, genomes, n_items_map, <br/>                                    only_fitness=False):<br/>        item = n_items_map[genome.key]<br/>        result = 0.0<br/>        if only_fitness:<br/>            result = self._novelty_avg_knn(item=item, genomes=genomes, <br/>                                           n_items_map=n_items_map)<br/>        else:<br/>            result = self._novelty_avg_knn(item=item, neighbors=1, <br/>                                           n_items_map=n_items_map)<br/>            if result &gt; self.novelty_threshold or \<br/>               len(self.novel_items) &lt; ArchiveSeedAmount:<br/>                self._add_novelty_item(item)<br/>        item.novelty = result<br/>        item.generation = self.generation<br/>        return result</pre>
<p class="p1"><span class="s1">The preceding code uses a function to evaluate the novelty score, which we will describe in the next section to estimate the novelty of the provided genome. If this function is invoked in the update archive mode (<kbd>only_fitness = False</kbd>), then the obtained novelty score (<kbd>result</kbd>) is compared with the current value of the <kbd>novelty_threshold</kbd> field. Based on the results of the comparison, the <kbd>NoveltyItem</kbd> object is added to the <kbd>NoveltyArchive</kbd> <span>object </span>or not. Furthermore, the <kbd>ArchiveSeedAmount</kbd> constant is introduced to do initial seeding of the archive with the <kbd>NoveltyItem</kbd> instances at the beginnings of the evolution when the archive is still empty.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The fitness function with the novelty score</h1>
                </header>
            
            <article>
                
<p class="p1"><span class="s1">Now we have defined the basic principles behind the NS method, we need to find a way to integrate it into the definition of the fitness function that will be used to guide the neuroevolution process. In other words, we need to define the novelty metric that can capture the amount of novelty that is introduced by a particular solver agent during the evolutionary process. There are several characteristics that can be used as novelty metrics for a solver agent:</span></p>
<ul class="ul1">
<li class="li1"><span class="s1">The novelty of the solver genotype structure—the <em>structural</em> novelty</span></li>
<li class="li1"><span class="s1">The stepping stones found in the search space of the solution—the <em>behavioral</em> novelty</span></li>
</ul>
<p class="p1"><span class="s1">Our primary interest in this chapter is to create a successful maze navigator agent. To successfully navigate through the maze, the agent must pay equal attention to most places in the maze. Such behavior can be achieved by rewarding agents who choose a unique exploration path compared to already known paths from the previously tested agents. In terms of the types of the previously mentioned novelty metrics, this means that we need to define a fitness function using a metric built around <em>behavioral</em> novelty.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The novelty score</h1>
                </header>
            
            <article>
                
<p class="p1"><span class="s1">The behavioral space of the maze solver agent is defined by its trajectory through the maze while running the maze-solving simulation. An effective novelty score implementation needs to compute the sparseness at any point in such a behavioral space. Thus, any area with a denser cluster of visited points of behavior space is less novel, giving fewer rewards to the solver agent.</span></p>
<p class="p1"><span class="s1">As mentioned in <a href="f59c6396-55e5-4495-95c0-7af9a42c2f20.xhtml" target="_blank">Chapter 1</a>, <em>O<span>verview of Neuroevolution Methods</span></em>, the most straightforward measure of sparseness at a point is the average distance from it to the <em>k-nearest neighbors</em>. The sparse areas have higher distance values, and the denser areas have lower distance values, correspondingly. The following formula gives the sparseness at point <img class="fm-editor-equation" src="assets/7b7415d4-4282-432b-90c8-72d43185f310.png" style="width:0.83em;height:0.83em;"/> of the behavioral space:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/d7a917c6-ca46-4d78-ad0d-26539f91feb6.png" style="width:14.42em;height:4.33em;"/></p>
<p class="p1"><span class="s1">Note <img class="fm-editor-equation" src="assets/35180e98-48b5-40c9-9d97-e521f6cd8278.png" style="width:1.08em;height:0.92em;"/> is the <img class="fm-editor-equation" src="assets/ef6e7309-eb38-4d1b-a9a2-b50ad4650c8f.png" style="width:2.83em;height:1.00em;"/> nearest neighbor of <img class="fm-editor-equation" src="assets/2b96ddaa-406a-4b2c-8add-7650fdd462d2.png" style="width:0.83em;height:0.83em;"/> as calculated by the distance (novelty) metric, <img class="fm-editor-equation" src="assets/ab46e610-e35c-413f-90a8-35554b3386a8.png" style="width:5.08em;height:1.58em;"/>.</span></p>
<p class="p1"><span class="s1"><span>The calculated by the above formula sparseness at the particular point in the behavioral space is a novelty score that can be used by the fitness function.</span> </span></p>
<p class="p1"><span class="s1">The Python code to find a novelty score is defined in the following function:</span></p>
<pre>    def _novelty_avg_knn(self, item, n_items_map, genomes=None, <br/>                         neighbors=None):<br/>        distances = None<br/>        if genomes is not None:<br/>            distances = self._map_novelty_in_population(item=item, <br/>                          genomes=genomes, n_items_map=n_items_map)<br/>        else:<br/>            distances = self._map_novelty(item=item)<br/>        distances.sort()<br/>        if neighbors is None:<br/>            neighbors = self.neighbors<br/><br/>        density, weight, distance_sum = 0.0, 0.0, 0.0<br/>        length = len(distances)<br/>        if length &gt;= ArchiveSeedAmount:<br/>            length = neighbors<br/>            if len(distances) &lt; length:<br/>                length = len(distances)<br/>            i = 0<br/>            while weight &lt; float(neighbors) and i &lt; length:<br/>                distance_sum += distances[i].distance<br/>                weight += 1.0<br/>                i += 1<br/>            if weight &gt; 0:<br/>                sparsity = distance_sum / weight<br/>        return sparsity</pre>
<p class="p1"><span class="s1">The preceding function has the following major implementation parts:</span></p>
<ol>
<li><span class="s1">First, we check whether the <kbd>_novelty_avg_knn</kbd> function provided with the argument holds a list of all the genomes in the current population. In that case, we start by populating the list of distances between behavioral characteristics of all genomes in the population, including all the <kbd>NoveltyItem</kbd> objects from <kbd>NoveltyArchive</kbd>. Otherwise, we use the provided novelty item (<kbd>item</kbd>) to find distances between it and all <kbd>NoveltyItem</kbd> objects from <kbd>NoveltyArchive</kbd>.</span></li>
</ol>
<pre style="padding-left: 60px">    distances = None<br/>    if genomes is not None:<br/>        distances = self._map_novelty_in_population(item=item, <br/>                         genomes=genomes, n_items_map=n_items_map)<br/>    else:<br/>        distances = self._map_novelty(item=item)</pre>
<ol start="2">
<li>After that, we sort a list of distances in ascending order to have the smallest distances first because we are interested in the points that are closest to the provided novel item in the behavioral space:</li>
</ol>
<pre style="padding-left: 60px">    distances.sort()</pre>
<ol start="3">
<li>Next, we initialize all the intermediate variables necessary for the k-nearest neighbors scores calculation, and test whether the number of distance values collected in the previous step is higher than the <kbd>ArchiveSeedAmount</kbd> constant value:</li>
</ol>
<pre style="padding-left: 60px">    if neighbors is None:<br/>        neighbors = self.neighbors<br/><br/>    density, weight, distance_sum = 0.0, 0.0, 0.0<br/>    length = len(distances)</pre>
<ol start="4">
<li>Now, we can check whether the length of the found distances list is less than the number of neighbors that we are asked to test against (<kbd>neighbors</kbd>). If so, we update the value of the related variable:</li>
</ol>
<pre style="padding-left: 60px">    if length &gt;= ArchiveSeedAmount:<br/>        length = neighbors<br/>        if len(distances) &lt; length:<br/>            length = len(distances)</pre>
<ol start="5">
<li>After all the local variables are set to the correct values, we can start the cycle that collects the sum of all distances and weights for each connection:</li>
</ol>
<pre style="padding-left: 30px">        i = 0<br/>        while weight &lt; float(neighbors) and i &lt; length:<br/>            distance_sum += distances[i].distance<br/>            weight += 1.0<br/>            i += 1</pre>
<ol start="6">
<li>When the preceding cycle exits because of the calculated weight value exceeding the specified number of neighbors, or if we already iterated over all distance values in the <kbd>distances</kbd> list, we are ready to calculate the novelty score for a given item as an average distance to the k-nearest neighbors:</li>
</ol>
<pre style="padding-left: 30px">        if weight &lt; 0:<br/>            sparsity = distance_sum / weight </pre>
<p class="p1"><span class="s1">The function then returns the estimated novelty score value.</span></p>
<div class="p1 packt_infobox"><span class="s1">For more implementation details, see the <kbd>novelty_archive.py</kbd> file at <a href="https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Python/blob/master/Chapter6/novelty_archive.py">https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Python/blob/master/Chapter6/novelty_archive.py</a>.<a href="https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Python/blob/master/Chapter6/novelty_archive.py"/></span></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The novelty metric</h1>
                </header>
            
            <article>
                
<div>
<p class="p1"><span class="s1">The novelty metric is a measure of how different the current solution is from the already known ones. It is used to calculate the novelty score when estimating the distance from the current point in the behavioral space to its <em>k-nearest neighbors</em>.</span></p>
<p class="p1"><span class="s1">In our experiment, the novelty metric measuring the difference in the behavior of the two agents is determined by the <em>item-wise distance</em> between the two trajectory vectors (one vector per agent). The trajectory vector contains the coordinates of the positions that were visited by the maze navigator agent during a simulation. The following formula gives the definition of the <span>metric</span>:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/a61b41a8-e092-4cca-8df7-32742826e827.png" style="width:16.17em;height:4.25em;"/></p>
<p class="p1"><span class="s1">Note <img class="fm-editor-equation" src="assets/cbb7ac77-245c-4bb4-9e7d-415935eedb59.png" style="width:0.83em;height:0.92em;"/> is the size of the trajectory vector, and <img class="fm-editor-equation" src="assets/ead12303-fc2d-4a5d-9a5c-10b6fa003efc.png" style="width:1.17em;height:1.00em;"/> and <img class="fm-editor-equation" src="assets/e8429ede-3355-4312-9e8c-8485763b8fda.png" style="width:1.17em;height:1.00em;"/> are the values at position <img class="fm-editor-equation" src="assets/15e07257-bf42-4ea2-ab1a-83055f6410b7.png" style="width:0.42em;height:1.08em;"/> of the compared trajectory vectors, <img class="fm-editor-equation" src="assets/dacf8b1f-2342-42a5-903b-1a8168bcd0a6.png" style="width:0.75em;height:1.00em;"/> and <img class="fm-editor-equation" src="assets/a2692ece-78af-4644-a161-903af7653c63.png" style="width:0.75em;height:0.75em;"/>.</span></p>
<p class="p1"><span class="s1">In a maze navigation experiment, we are mostly interested in the final position of the solver agent. Thus, the trajectory vector may </span><span>only</span><span> </span><span>contain the final coordinates of the agent after completing all the necessary steps in the maze navigation </span><span>simulation</span><span> </span><span>or when the maze exit is found.</span></p>
<p class="p1"><span class="s1">The Python code for the <span>novelty </span>metric value estimation is as follows:</span></p>
</div>
<pre>def maze_novelty_metric(first_item, second_item):<br/>    diff_accum = 0.0<br/>    size = len(first_item.data)<br/>    for i in range(size):<br/>        diff = abs(first_item.data[i] - second_item.data[i])<br/>        diff_accum += diff<br/>    <br/>    return diff_accum / float(size)</pre>
<p class="p1"><span class="s1">The preceding code takes two novelty items and finds the <em>item-wise</em> distance between the two trajectory vectors holding the positions of a corresponding solver agent during the simulation of a maze navigation.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Fitness function</h1>
                </header>
            
            <article>
                
<p class="p1"><span class="s1">The fitness function used in the experiments described in this chapter directly applies the novelty score defined previously as the fitness value of the genome. As a result, the neuroevolution process tries to maximize the novelty of the produced individuals by using such a fitness function.</span></p>
<p class="p1"><span class="s1">For different tasks in this experiment, we use various fitness factors:</span></p>
<ul class="ol1">
<li class="li1"><span class="s1">The novelty score is used to guide the neuroevolution process (solution search optimization). It is assigned as a fitness value to each genome and used for genome evaluation during generations of evolution.</span></li>
<li class="li1"><span class="s1">The goal-oriented fitness score (the distance to the maze exit) obtained from the maze simulator is used to test if the ultimate goal has been achieved (that is, the maze exit has been found)—also, this value is recorded for performance evaluation of each solver agent.</span></li>
</ul>
<p class="p1"><span class="s1">The source code of the fitness values evaluation is presented in two functions:</span></p>
<ul class="ul1">
<li class="li1"><span class="s1">The callback function to evaluate the fitness scores of the entire population (<kbd>eval_genomes</kbd>)</span></li>
<li class="li1"><span class="s1">The function to evaluate individual genomes through the maze solving simulation ( <kbd>eval_individual</kbd>)</span></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The population fitness evaluation function</h1>
                </header>
            
            <article>
                
<p class="p1"><span class="s1">The fitness evaluation function is a callback function that is registered with the NEAT-Python library, allowing this library to run an evaluation of population genomes against specific conditions of a particular task that needs to be solved. We implement this function to evaluate each genome in the current population using the maze-solving task, and to use the obtained novelty score as a genome fitness value.</span></p>
<p class="p1"><span class="s1">The NEAT-Python library doesn't allow us to send any signals about task completion from the callback function other than by specifying the specific fitness score value of the winner genome. This fitness value must be higher than the fitness threshold in the NEAT-Python hyperparameter configuration. However, with the NS algorithm, it is not possible to accurately estimate the upper limit of the novelty score that can be achieved by the winner genome. Furthermore, the winner genome can have the novelty score value that is below the values obtained by genomes earlier in the evolution process, when the solution search space was not so thoroughly explored.</span></p>
<p class="p1"><span class="s1">Thus, given that the novelty score is assigned to genomes as their fitness values, we need to come up with a workaround that allows us to use the standard termination criteria defined by the NEAT-Python library. We do this by using a specific indicative novelty score value that is big enough to be encountered during normal algorithm execution. This value determines the termination criterion that is provided through the NEAT-Python hyper</span><span class="s1">parameter configuration. We use <kbd>800000</kbd> as an indicative measure of the novelty score and its natural logarithm (about <kbd>13.59</kbd>) as the appropriate fitness threshold.</span></p>
<p class="p1"><span class="s1">The full source code of the function is as follows:</span></p>
<pre>def eval_genomes(genomes, config):<br/>    n_items_map = {}<br/>    solver_genome = None<br/>    for genome_id, genome in genomes:<br/>        found = eval_individual(genome_id=genome_id, <br/>                                genome=genome, <br/>                                genomes=genomes, <br/>                                n_items_map=n_items_map, <br/>                                config=config)<br/>        if found:<br/>            solver_genome = genome<br/>    trial_sim.archive.end_of_generation()<br/>    # Now evaluate fitness of each genome in population<br/>    for genome_id, genome in genomes:<br/>        fitness = trial_sim.archive.evaluate_individual_novelty(<br/>                   genome=genome,<br/>                   genomes=genomes,<br/>                   n_items_map=n_items_map,<br/>                   only_fitness=True)<br/>        if fitness &gt; 1:<br/>            fitness = math.log(fitness)<br/>        else:<br/>            fitness = 0<br/>        genome.fitness = fitness<br/><br/>    if solver_genome is not None:<br/>        solver_genome.fitness = math.log(800000) # ~=13.59</pre>
<p class="p1"><span class="s1">The significant parts of the implementation of the function are as follows:</span></p>
<ol>
<li><span class="s1">First, we create the dictionary to store evaluated novelty items (<kbd>n_items_map</kbd>) for each genome in the population, and cycle through all genomes in the population, evaluating their maze-solving performance:</span></li>
</ol>
<pre style="padding-left: 60px">    n_items_map = {}<br/>    solver_genome = None<br/>    for genome_id, genome in genomes:<br/>        found = eval_individual(genome_id=genome_id, <br/>                                genome=genome, <br/>                                genomes=genomes, <br/>                                n_items_map=n_items_map, <br/>                                config=config)<br/>        if found:<br/>            solver_genome = genome<br/>    trial_sim.archive.end_of_generation()</pre>
<ol start="2">
<li>After that, we cycle through all genomes in the population one more time to assign fitness scores to the genomes using estimated novelty scores. The process of novelty score estimation uses the <kbd>NoveltyItem</kbd> objects collected in <kbd>n_items_map</kbd> in the first cycle (described earlier) during the maze-solving simulation:</li>
</ol>
<pre style="padding-left: 60px">    for genome_id, genome in genomes:<br/>        fitness = trial_sim.archive.evaluate_individual_novelty(<br/>                   genome=genome,<br/>                   genomes=genomes,<br/>                   n_items_map=n_items_map,<br/>                   only_fitness=True)<br/>        if fitness &gt; 1:<br/>            fitness = math.log(fitness)<br/>        else:<br/>            fitness = 0<br/>        genome.fitness = fitness</pre>
<ol start="3">
<li>Finally, if a successful solver genome is found in the first cycle, we assign it with a fitness value equal to the indicative fitness score described earlier (<kbd>~13.59</kbd>):</li>
</ol>
<pre style="padding-left: 60px">    if solver_genome is not None:<br/>        solver_genome.fitness = math.log(800000) # ~13.59</pre>
<p class="p1"><span class="s1">Please note that we apply the natural logarithm to the obtained novelty score values and to the indicative novelty score to keep them in numerical proximity. As a result, we can properly render performance plots using statistics collected during the experiment.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The individual fitness evaluation function</h1>
                </header>
            
            <article>
                
<p class="p1"><span class="s1">This function is an essential part of the population fitness evaluation, and it is invoked from the <kbd>eval_genomes</kbd> function, discussed earlier, to evaluate the maze-solving performance of each genome in the population.</span></p>
<p class="p1"><span class="s1"> </span><span class="s1">The evaluation of the individual genome as a maze-solving agent through the maze navigation simulation is as follows:</span></p>
<pre>def eval_individual(genome_id, genome, genomes, n_items_map, config):<br/>    n_item = archive.NoveltyItem(<br/>                        generation=trial_sim.population.generation,<br/>                        genomeId=genome_id)<br/>    n_items_map[genome_id] = n_item<br/>    maze_env = copy.deepcopy(trial_sim.orig_maze_environment)<br/>    control_net = neat.nn.FeedForwardNetwork.create(genome, config)<br/>    goal_fitness = maze.maze_simulation_evaluate(<br/>                                    env=maze_env, <br/>                                    net=control_net, <br/>                                    time_steps=SOLVER_TIME_STEPS,<br/>                                    n_item=n_item,<br/>                                    mcns=MCNS)<br/><br/>    if goal_fitness == -1:<br/>        # The individual doesn't meet the min. fitness criterion<br/>        print("Individ with ID %d marked for extinction, MCNS %f" <br/>               % (genome_id, MCNS))<br/>        return False<br/><br/>    record = agent.AgentRecord(<br/>        generation=trial_sim.population.generation,<br/>        agent_id=genome_id)<br/>    record.fitness = goal_fitness<br/>    record.x = maze_env.agent.location.x<br/>    record.y = maze_env.agent.location.y<br/>    record.hit_exit = maze_env.exit_found<br/>    record.species_id = trial_sim.population.species \<br/>        .get_species_id(genome_id)<br/>    record.species_age = record.generation - \<br/>       trial_sim.population.species.get_species(genome_id).created<br/>    trial_sim.record_store.add_record(record)<br/><br/>    if not maze_env.exit_found:<br/>        record.novelty = trial_sim.archive \<br/>         .evaluate_individual_novelty(genome=genome, <br/>                       genomes=genomes, n_items_map=n_items_map)<br/><br/>    trial_sim.archive.update_fittest_with_genome(genome=genome, <br/>                                        n_items_map=n_items_map)<br/>    return maze_env.exit_found</pre>
<p class="p1"><span class="s1">Let's delve into the meaning of all the central parts of the implementation of the <kbd>eval_individual</kbd> function:</span></p>
<ol>
<li><span class="s1">First, we create the <kbd>NoveltyItem</kbd> object to hold information about the novelty score associated with a particular genome and save it under the <kbd>genome_id</kbd> key in the <kbd>n_items_map</kbd> dictionary:</span></li>
</ol>
<pre style="padding-left: 60px">    n_item = archive.NoveltyItem(<br/>                       generation=trial_sim.population.generation,<br/>                       genomeId=genome_id)<br/>    n_items_map[genome_id] = n_item</pre>
<ol start="2">
<li>After that, we create a deep copy of the original maze environment to avoid side effects during the simulation, and create the control ANN from the provided genome:</li>
</ol>
<pre style="padding-left: 60px">    maze_env = copy.deepcopy(trial_sim.orig_maze_environment)<br/>    control_net = neat.nn.FeedForwardNetwork.create(genome, config)</pre>
<ol start="3">
<li>Now, using a copy of the maze environment and the created control ANN, we execute the maze-solving simulation for a given number of simulation steps:</li>
</ol>
<pre style="padding-left: 60px">    goal_fitness = maze.maze_simulation_evaluate(<br/>                                    env=maze_env, <br/>                                    net=control_net, <br/>                                    time_steps=SOLVER_TIME_STEPS,<br/>                                    n_item=n_item,<br/>                                    mcns=MCNS)</pre>
<ol start="4">
<li>After the simulation is finished, the returned goal-based fitness score (proximity to the maze exit) and other simulation and genome parameters are stored in <kbd>AgentRecord</kbd>, which is then added to the record store:</li>
</ol>
<pre style="padding-left: 60px">    record = agent.AgentRecord(<br/>        generation=trial_sim.population.generation,<br/>        agent_id=genome_id)<br/>    record.fitness = goal_fitness<br/>    record.x = maze_env.agent.location.x<br/>    record.y = maze_env.agent.location.y<br/>    record.hit_exit = maze_env.exit_found<br/>    record.species_id = trial_sim.population.species \<br/>        .get_species_id(genome_id)<br/>    record.species_age = record.generation - \<br/>       trial_sim.population.species.get_species(genome_id).created<br/>    trial_sim.record_store.add_record(record)</pre>
<ol start="5">
<li>Finally, we estimate the novelty score of the given genome if it is not a winner, and update the list of the fittest genomes in <kbd>NoveltyArchive</kbd> with <kbd>NoveltyItem</kbd> of the current genome, if appropriate:</li>
</ol>
<pre style="padding-left: 60px">    if not maze_env.exit_found:<br/>        record.novelty = trial_sim.archive \<br/>         .evaluate_individual_novelty(genome=genome, <br/>              genomes=genomes, n_items_map=n_items_map)<br/><br/>    trial_sim.archive.update_fittest_with_genome(genome=genome, <br/>                                        n_items_map=n_items_map)</pre>
<p class="p1"><span class="s1">In this experiment, the fitness score of the genome is defined as two separate values, each serving a different purpose. The goal-oriented fitness score helps to test whether a solution has been found and collects useful performance statistics. The novelty-based fitness score guides the neuroevolution process in the direction of the maximal diversity of solver behavior, which means that the gradient of the solution search is directed toward exploring different behaviors, without any explicit objective.</span></p>
<div class="p1 packt_infobox"><span class="s1">For more details about the implementation, please refer to the <kbd>maze_experiment.py</kbd> file at <a href="https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Python/blob/master/Chapter6/maze_experiment.py"><span class="s2">https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Python/blob/master/Chapter6/maze_experiment.py.</span></a></span></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Experimenting with a simple maze configuration</h1>
                </header>
            
            <article>
                
<p class="p1"><span class="s1">We start our experiments using a simple maze configuration similar to the one described in the previous chapter. However, instead of the goal-oriented objective function, we use the NS optimization method to guide the neuroevolution process. We hope that with Novelty Search method it will be possible to find a successful maze solver with fewer epochs of evolution.</span></p>
<p>You can see the schema of the simple maze in the following plot:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-776 image-border" src="assets/f1a00fe6-4220-42ac-a268-9e614a672c5e.png" style="width:31.75em;height:14.17em;"/></p>
<div class="p1 packt_figref CDPAlignCenter CDPAlign"><span class="s1">The simple maze configuration</span></div>
<p class="p1"><span class="s1">The maze configuration is the same as in the previous chapter. However, we need to adjust the corresponding NEAT hyperparameters to meet the specifications of the NS optimization method.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Hyperparameter selection</h1>
                </header>
            
            <article>
                
<p class="p1"><span class="s1">The objective function used in the experiments described in this chapter is based on a novelty metric that has no clear upper-boundary value. As a result, the fitness threshold value cannot be estimated precisely. Thus, to signal that the winning solution was found, we use an indicative value that is big enough to not be encountered during the normal algorithm execution.</span></p>
<p class="p1"><span class="s1">We selected <kbd>800000</kbd> as the indicative novelty score value. However, to maintain the visual presentation of the fitness scores when plotting the results of an experiment, we scaled down the obtained novelty scores of the solver agents using the natural logarithm. Thus, the fitness threshold value used in the configuration file becomes <kbd>13.5</kbd>, which is a bit less than the maximum possible fitness score (<kbd>13.59</kbd>) to avoid issues with </span><span>rounding </span>float numbers<span>. Also, we increase the population size from the value described in the previous chapter (<kbd>250</kbd>) to make the solution search space deeper because we need to examine the maximum number of unique places in the maze:</span></p>
<pre>[NEAT]<br/>fitness_criterion = max<br/>fitness_threshold = 13.5<br/>pop_size = 500<br/>reset_on_extinction = False</pre>
<p class="p1"><span class="s1">We run more generations in each trial than we did in the experiment in the previous chapter. Therefore, we have increased the stagnation value to keep species around for longer:</span></p>
<pre>[DefaultStagnation]<br/>max_stagnation = 100</pre>
<p class="p1"><span class="s1">All other NEAT hyperparameters have <span>similar </span>values to the ones presented in the previous chapter. Please refer to the previous chapter for the rationales for selecting the specific hyperparameter values.</span></p>
<div class="p1 packt_infobox"><span class="s1">The complete list of hyperparameters used in the experiment can be found in the <kbd>maze_config.ini</kbd> file at <a href="https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Python/blob/master/Chapter6/maze_config.ini"><span class="s2">https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Python/blob/master/Chapter6/maze_config.ini</span></a>.</span></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Working environment setup</h1>
                </header>
            
            <article>
                
<p class="p1"><span class="s1">The working environment for the experiment should include all dependencies and can<span class="Apple-converted-space"> </span>be created using Anaconda with the following commands:</span></p>
<pre><strong>$ conda create --name maze_ns_neat python=3.5</strong><br/><strong>$ conda activate maze_ns_neat</strong><br/><strong>$ pip install neat-python==0.92 </strong><br/><strong>$ conda install matplotlib</strong><br/><strong>$ conda install graphviz</strong><br/><strong>$ conda install python-graphviz</strong></pre>
<p class="p1"><span class="s1">These commands create and activate a <kbd>maze_ns_neat</kbd> virtual environment with Python 3.5. After that, the NEAT-Python library with version 0.92 is installed, along with other dependencies used by our visualization utilities.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The experiment runner implementation</h1>
                </header>
            
            <article>
                
<p class="p1"><span class="s1">The experiment runner implementation used in this chapter is similar for the most part to the one used in the previous chapter but has significant differences, which we will discuss in this section.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The trials cycle</h1>
                </header>
            
            <article>
                
<p class="p1"><span class="s1">In this chapter, we introduce an upgrade to the experiment runner implementation. We implement support to run multiple trials sequentially until the solution is found. Such an upgrade dramatically simplifies working with the multiple experiment trials sequentially, especially taking into account that each trial can take a long time to execute.</span></p>
<p class="p3"><span class="s2">The main cycle of the experiment runner now looks like this (see <kbd>__main__</kbd> in the</span> <span class="s1"><kbd>maze_experiment.py</kbd> script</span><span class="s2">):</span></p>
<pre>    print("Starting the %s maze experiment (Novelty Search), for %d trials" <br/>          % (args.maze, args.trials))<br/>    for t in range(args.trials):<br/>        print("\n\n----- Starting Trial: %d ------" % (t))<br/>        # Create novelty archive<br/>        novelty_archive = archive.NoveltyArchive(<br/>                                  threshold=args.ns_threshold,<br/>                                  metric=maze.maze_novelty_metric)<br/>        trial_out_dir = os.path.join(out_dir, str(t))<br/>        os.makedirs(trial_out_dir, exist_ok=True)<br/>        solution_found = run_experiment( config_file=config_path, <br/>                                        maze_env=maze_env, <br/>                                        novelty_archive=novelty_archive,<br/>                                        trial_out_dir=trial_out_dir,<br/>                                        n_generations=args.generations,<br/>                                        args=args,<br/>                                        save_results=True,<br/>                                        silent=True)<br/>        print("\n------ Trial %d complete, solution found: %s ------\n" <br/>               % (t, solution_found))</pre>
<p class="p2"><span class="s1">The cycle runs the <kbd>args.trials</kbd> number of experiment trials, where <kbd>args.trials</kbd> is provided by the user from the command-line.<br/></span></p>
<p class="p2"><span class="s1">The first lines of the cycle create the <kbd>NoveltyArchive</kbd> object, which is a part of the Novelty Search algorithm. Later, during a specific trial, this object will be used to store all the relevant <kbd>NoveltyItems</kbd>:</span></p>
<pre>        novelty_archive = archive.NoveltyArchive(<br/>                       threshold=args.ns_threshold,<br/>                       metric=maze.maze_novelty_metric)</pre>
<p class="p1"><span class="s1">Note that</span> <kbd>maze.maze_novelty_metric</kbd> <span class="s1">is a reference to the function that is used to evaluate the novelty score of each solver agent. </span></p>
<p class="mce-root"/>
<p class="p1"><span class="s1">With the source code for this chapter, we provide implementations of two novelty metric functions:</span></p>
<ul class="ol1">
<li class="li1"><span class="s1">The item-wise distance novelty metric (<kbd>maze.maze_novelty_metric</kbd>)</span></li>
<li class="li1"><span class="s1">The Euclidean distance novelty metric (<kbd>maze.maze_novelty_metric_euclidean</kbd>)</span></li>
</ul>
<p class="p1"><span class="s1">However, in our experiments, we use the first implementation. The second implementation is intended for you to run additional experiments.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The experiment runner function</h1>
                </header>
            
            <article>
                
<p class="p1"><span class="s1">The runner function has many similarities to the runner function introduced in the previous chapter, but, at the same time, it has unique features that are specific to the NS optimization algorithm.</span></p>
<p class="p1"><span class="s1">Here, we consider the most significant parts of the implementation:</span></p>
<ol>
<li><span class="s1">It starts with selecting a specific seed value for a random number generator, based on the current system time:</span></li>
</ol>
<pre style="padding-left: 60px">    seed = int(time.time())<br/>    random.seed(seed)</pre>
<ol start="2">
<li>After that, it loads the NEAT algorithm configuration and creates an initial population of genomes:</li>
</ol>
<pre style="padding-left: 90px">config = neat.Config(neat.DefaultGenome, <br/>                     neat.DefaultReproduction, <br/>                     neat.DefaultSpeciesSet, <br/>                     neat.DefaultStagnation, <br/>                     config_file)<br/>p = neat.Population(config) </pre>
<ol start="3">
<li>To hold the intermediate results after each generation evaluation, we initialize a <kbd>trial_sim</kbd> global variable with the <kbd>MazeSimulationTrial</kbd> object.</li>
</ol>
<p style="padding-left: 60px"><span class="s1">We use a global variable so it can be accessed by the fitness evaluation callback function (<kbd>eval_genomes(genomes, config)</kbd>) that is passed to the NEAT-Python framework:</span></p>
<pre style="padding-left: 60px">    global trial_sim<br/>    trial_sim = MazeSimulationTrial(maze_env=maze_env, <br/>                                    population=p,<br/>                                    archive=novelty_archive)</pre>
<ol start="4">
<li>Also, traditionally, we register with the <kbd>Population</kbd> object the number of reporters to output algorithm results and to collect statistics:</li>
</ol>
<pre style="padding-left: 60px">    p.add_reporter(neat.StdOutReporter(True))<br/>    stats = neat.StatisticsReporter()<br/>    p.add_reporter(stats)</pre>
<ol start="5">
<li>Now we are ready to run the NEAT algorithm over a specified number of generations and evaluate the results:</li>
</ol>
<pre style="padding-left: 60px">    start_time = time.time()<br/>    best_genome = p.run(eval_genomes, n=n_generations)<br/>    elapsed_time = time.time() - start_time<br/>    # Display the best genome among generations.<br/>    print('\nBest genome:\n%s' % (best_genome))<br/>    solution_found = \<br/>        (best_genome.fitness &gt;= config.fitness_threshold)<br/>    if solution_found:<br/>        print("SUCCESS: The stable maze solver controller was found!!!")<br/>    else:<br/>        print("FAILURE: Failed to find the stable maze solver controller!!!")</pre>
<ol start="6">
<li>After that, the collected statistics and novelty archive records can be visualized and saved to the filesystem:</li>
</ol>
<pre style="padding-left: 60px">    node_names = {-1:'RF_R', -2:'RF_FR', -3:'RF_F', -4:'RF_FL', <br/>                    -5:'RF_L', -6: 'RF_B', -7:'RAD_F', -8:'RAD_L',<br/>                    -9:'RAD_B', -10:'RAD_R', 0:'ANG_VEL', 1:'VEL'}<br/>    visualize.draw_net(config, best_genome, view=show_results, <br/>                           node_names=node_names, <br/>                           directory=trial_out_dir, fmt='svg')<br/>    if args is None:<br/>        visualize.draw_maze_records(maze_env, <br/>                                trial_sim.record_store.records,<br/>                                view=show_results)<br/>    else:<br/>        visualize.draw_maze_records(maze_env, <br/>                           trial_sim.record_store.records, <br/>                           view=show_results, width=args.width, <br/>                           height=args.height,<br/>                           filename=os.path.join(trial_out_dir, <br/>                                           'maze_records.svg'))<br/>    visualize.plot_stats(stats, ylog=False, <br/>                          view=show_results,<br/>                          filename=os.path.join(trial_out_dir, <br/>                                           'avg_fitness.svg'))<br/>    visualize.plot_species(stats, view=show_results, <br/>                          filename=os.path.join(trial_out_dir, <br/>                                            'speciation.svg'))<br/>    # store NoveltyItems archive data<br/>    trial_sim.archive.write_fittest_to_file(<br/>                             path=os.path.join(trial_out_dir, <br/>                                     'ns_items_fittest.txt'))<br/>    trial_sim.archive.write_to_file(<br/>                             path=os.path.join(trial_out_dir, <br/>                                         'ns_items_all.txt'))</pre>
<ol start="7">
<li>Finally, we perform additional visualization routines introduced in this chapter that visualize the path of the maze-solver agents through the maze.</li>
</ol>
<p style="padding-left: 60px"><span class="s1">We do this by running a simulation of maze navigation against the controller ANN of the best solver agent found during the evolution. During this simulation run, all the path points visited by a solver agent are collected to be rendered later by the <kbd>draw_agent_path</kbd> function:</span></p>
<pre style="padding-left: 60px">    maze_env = copy.deepcopy(trial_sim.orig_maze_environment)<br/>    control_net = neat.nn.FeedForwardNetwork.create(<br/>                                            best_genome, config)<br/>    path_points = []<br/>    evaluate_fitness = maze.maze_simulation_evaluate(<br/>                                    env=maze_env, <br/>                                    net=control_net, <br/>                                    time_steps=SOLVER_TIME_STEPS,<br/>                                    path_points=path_points)<br/>    print("Evaluated fitness of best agent: %f" <br/>              % evaluate_fitness)<br/>    visualize.draw_agent_path(trial_sim.orig_maze_environment, <br/>                             path_points, best_genome,<br/>                             view=show_results, <br/>                             width=args.width,<br/>                             height=args.height,<br/>                             filename=os.path.join(trial_out_dir,<br/>                                        'best_solver_path.svg'))</pre>
<p class="p1"><span class="s1">In the end, the <kbd>run_experiment</kbd> function returns a Boolean value indicating whether a successful maze solver agent was found during the trial or not.</span></p>
<p class="mce-root"/>
<p class="mce-root"/>
<div class="p1 packt_infobox"><span class="s1">Please refer to the <kbd>run_experiment(config_file, maze_env, novelty_archive, trial_out_dir, args=None, n_generations=100, save_results=False, silent=False)</kbd> function in the <kbd>maze_experiment.py</kbd> file at <a href="https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Python/blob/master/Chapter6/maze_experiment.py">https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Python/blob/master/Chapter6/maze_experiment.py</a>.</span></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Running the simple maze navigation experiment with NS optimization</h1>
                </header>
            
            <article>
                
<p class="p1"><span class="s1">Make sure you copy all related Python scripts and configuration files (<kbd>maze_config.ini</kbd> and <kbd>medium_maze.txt)</kbd> into the local directory from the online repository that can be found at: <a href="https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Python/blob/master/Chapter6/"><span class="s2">https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Python/blob/master/Chapter6/</span></a>.</span></p>
<p class="p1"><span class="s1">Now enter this directory, and execute the following command in the Terminal application:</span></p>
<pre><strong>python maze_experiment.py -g 500 -t 10 -m medium --width 300 --height 150</strong></pre>
<p class="mce-root"/>
<div class="p1 packt_infobox"><span class="s1">Do not forget to activate the appropriate virtual environment </span><span class="s1">with the following command:<br/>
<kbd>conda activate maze_ns_neat</kbd></span></div>
<p class="p1"><span class="s1">The preceding command runs 10 trials of the maze navigation experiment with the simple maze configuration loaded from the <kbd>medium_maze.txt</kbd> file. The neuroevolution algorithm evaluates <kbd>500</kbd> generations of maze solvers in each trial, using the NEAT configuration data loaded from the <kbd>maze_config.ini</kbd> file. The width and height parameters specify the dimensions of the maze records subplot (see the <kbd>visualize.draw_maze_records</kbd> function implementation for more details).</span></p>
<p class="p1"><span class="s1">After <kbd>99</kbd> generations of the evolution, the successful maze solver agent is found in generation <kbd>100</kbd>. </span><span class="s2">There are general statistics about the population of genomes in the last generation<span> of evolution. In the console output of the completed Python program, you will see the following for the last generation of evolution:</span></span></p>
<pre><strong> ****** Running generation 100 ****** </strong><br/><br/><strong>Maze solved in 391 steps</strong><br/><strong>Population's average fitness: 1.28484 stdev: 0.90091</strong><br/><strong>Best fitness: 13.59237 - size: (2, 8) - species 1 - id 48354</strong><br/><br/><strong>Best individual in generation 100 meets fitness threshold - complexity: (2, 8)</strong></pre>
<p><span class="s2">After that, we display the configuration of the winner genome and general statistics about the trial:</span></p>
<pre><strong>Best genome:</strong><br/><strong>Key: 48354</strong><br/><strong>Fitness: 13.592367006650065</strong><br/><strong>Nodes:</strong><br/><strong>  0 DefaultNodeGene(key=0, bias=-2.1711339938349026, response=1.0, activation=sigmoid, aggregation=sum)</strong><br/><strong>  1 DefaultNodeGene(key=1, bias=6.576480565646596, response=1.0, activation=sigmoid, aggregation=sum)</strong><br/><strong>Connections:</strong><br/><strong>  DefaultConnectionGene(key=(-10, 1), weight=-0.5207773885939109, enabled=True)</strong><br/><strong>  DefaultConnectionGene(key=(-9, 0), weight=1.7778928210387814, enabled=True)</strong><br/><strong>  DefaultConnectionGene(key=(-7, 1), weight=-2.4940590667086524, enabled=False)</strong><br/><strong>  DefaultConnectionGene(key=(-6, 1), weight=-1.3708732457648565, enabled=True)</strong><br/><strong>  DefaultConnectionGene(key=(-4, 0), weight=4.482428082179011, enabled=True)</strong><br/><strong>  DefaultConnectionGene(key=(-4, 1), weight=-1.3103728328721098, enabled=True)</strong><br/><strong>  DefaultConnectionGene(key=(-3, 0), weight=-0.4583080031587811, enabled=True)</strong><br/><strong>  DefaultConnectionGene(key=(-3, 1), weight=4.643599450804774, enabled=True)</strong><br/><strong>  DefaultConnectionGene(key=(-2, 1), weight=-0.9055329546235956, enabled=True)</strong><br/><strong>  DefaultConnectionGene(key=(-1, 0), weight=-1.5899992185951817, enabled=False)</strong><br/><strong>SUCCESS: The stable maze solver controller was found!!!</strong><br/><strong>Record store file: out/maze_ns/medium/0/data.pickle</strong><br/><strong>Random seed: 1567086899</strong><br/><strong>Trial elapsed time: 7452.462 sec</strong><br/><strong>Plot figure width: 6.8, height: 7.0</strong><br/><strong>Maze solved in 391 steps</strong><br/><strong>Evaluated fitness of best agent: 1.000000</strong><br/><strong>Plot figure width: 7.8, height: 4.0</strong></pre>
<p class="p1"><span class="s1">The console output shows us that the winner genome that encodes the control ANN of the successful maze solver has only two node genes and eight connection genes. These genes correspond to the two output nodes in the controller ANN, with the eight connections used to establish links with the inputs. The resulting configuration of the controller ANN is shown here:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-777 image-border" src="assets/b05eed53-88f7-422e-b9c1-a227acc31092.png" style="width:80.83em;height:20.58em;"/></p>
<div class="p1 CDPAlignCenter CDPAlign packt_figref"><span class="s1">The configuration of the successful controller ANN</span></div>
<p class="p1"><span class="s1">The configuration of the successful controller ANN is better than the configuration described in the previous chapter, which was found using the <em>goal-oriented</em> search optimization method. In this experiment, the ANN configuration omits the hidden nodes completely, and the evolutionary process takes fewer generations finding it.</span></p>
<p class="p1"><span class="s1">Thus, we can assume that the Novelty Search optimization method is at least as effective as the goal-oriented method. This is even though the search optimization method is <span>not </span>based on the proximity to the final goal, but on rewarding novel behavior. The neuroevolution process produced a successful maze solver agent without any hints about the proximity to the final goal (maze exit), and that is just amazing.</span></p>
<p class="p1"><span class="s1">Also, it is interesting to look at the speciation graph during the evolution:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-778 image-border" src="assets/426942dd-7951-4b6b-b8bd-8852762afaf5.png" style="width:31.42em;height:24.33em;"/></p>
<div class="p1 CDPAlignCenter CDPAlign packt_figref"><span class="s1">The speciation graph</span></div>
<p class="p1"><span class="s1">In the speciation graph, we can see that the total number of species during the evolutionary process does not exceed nine. Furthermore, most of them are present from the very first generations of the evolution until a successful maze solver is found.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Agent record visualization</h1>
                </header>
            
            <article>
                
<p class="p1"><span class="s1">We used the method of visualizing agent records that was introduced in the previous chapter, and we introduced a new visualization method to visualize the path of the solver agent through the maze.<br/></span></p>
<p class="p1"><span class="s1">The visualization of agents records saved automatically for each completed trial as an <kbd>obj_medium_maze_records.svg</kbd> SVG file in the output directory of the<span> corresponding experiment</span>.</span></p>
<p class="p1"><span class="s1">In the following image, you can look at the <span>visualization of </span>agents records for the experiment described in this chapter:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-779 image-border" src="assets/c57f068f-d251-48d0-9763-d40b3c64bc10.png" style="width:26.83em;height:25.75em;"/></p>
<div class="p1 CDPAlignCenter CDPAlign packt_figref"><span class="s1">The visualization of <span>agents records</span></span></div>
<p class="p1"><span class="s1">The top subplot of the plot shows the final positions of the agents belonging to the fittest species that have a goal-oriented fitness score value above <strong>0.8</strong>. W</span><span class="s1">e were able to find eight species that explored almost all areas of the maze and were <span>finally </span>able to find the maze exit. At the same time, even the evolutionary losers (the bottom plot) demonstrated highly explorative behavior, evenly filling the first half of the maze area (compare this with the similar plot in the previous chapter).</span></p>
<p class="p1"><span class="s1">Also, it is important to note that eight of the total nine species created during the evolutionary process demonstrate the highest goal-oriented fitness scores; that is, they were almost able to reach the maze exit (and one of them ultimately reached it). This achievement is in stark contrast with the experiment in the previous chapter, where only half of all species (six from twelve) achieved the same results.</span></p>
<p class="p1"><span class="s1">However, the most exciting visualization allows us to look at the path of the successful maze solver agent that was able to find the maze exit:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-780 image-border" src="assets/fa1bb586-03f5-4f99-8cdf-fc088c4f51f0.png" style="width:29.75em;height:15.33em;"/></p>
<div class="p1 packt_figref CDPAlignCenter CDPAlign"><span class="s1">The path<span> through the maze</span> of the successful maze solver</span></div>
<p class="p1"><span class="s1">The visualization can be found in the <kbd>output</kbd> directory of the experiment in the <kbd>best_solver_path.svg</kbd> <span>file</span>.</span></p>
<p class="p1"><span class="s1">As you can see, a successful maze solver agent was able to find an almost optimal path through the maze, even though it does appear to get a little confused at the beginning.</span></p>
<p class="p1"><span class="s1">It's just amazing that such a convoluted path through the maze can be found without any reference to the location of the maze exit but only by rewarding the novelty of each intermediate solution that is found.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Exercise 1</h1>
                </header>
            
            <article>
                
<ol class="ol1">
<li class="li1"><span class="s1">Set the population size (<kbd>pop_size</kbd>) parameter in the <kbd>maze_config.ini</kbd> file to <kbd>250</kbd>. See if the maze solver can be found in this case.</span></li>
<li class="li1"><span class="s1">Change the value of the parameter specifying the probability of adding a new node (<kbd>node_add_prob</kbd>). Was the neuroevolution process able to find a solution, and is it optimal from a topological point of view?</span></li>
<li class="li1"><span class="s1">Change the initial genome configuration to have zero hidden nodes at the beginning (<kbd>num_hidden</kbd>). How does this affect the algorithm's performance?</span></li>
<li class="li1"><span class="s1">Try to use another novelty metric that is provided with the source code (<kbd>maze.maze_novelty_metric_euclidean</kbd>) and see what happens.</span></li>
</ol>
<ol class="ol1" start="5">
<li>Change the <kbd>location_sample_rate</kbd> command-line parameter from its default value (<kbd>4000</kbd>), which allows you to include only the final position of the maze solver into its behavioral vector. Try the values that are less than <kbd>400</kbd> (the number of maze simulation steps). For example, if we set this parameter to <kbd>100</kbd>, then the behavioral vector will include coordinates <span>a maximum of </span>four trajectory points for each solver agent. See how this parameter can influence algorithm performance. You can provide a value for this parameter by running the following command:</li>
</ol>
<pre style="padding-left: 60px"><strong>python maze_experiment.py -g 500 -t 10 -r 100 -m medium --width 300 --height 150</strong></pre>
<p>The preceding command runs the simple maze experiment with <span><kbd>location_sample_rate</kbd> set to <kbd>100</kbd>.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Experimenting with a hard-to-solve maze configuration</h1>
                </header>
            
            <article>
                
<p class="p1"><span class="s1">In the next experiment, we evaluate the effectiveness of the NS optimization method in a more complex task. In this task, we try to evolve a maze solving agent that can find a path through a maze with a complex configuration.</span></p>
<p class="p1"><span class="s1">For this experiment, we use the hard-to-solve maze configuration introduced in the previous chapter. Such an approach allows us to compare results obtained with the NS optimization method against the results obtained with the <em>goal-oriented</em> optimization method used in the previous chapter. The maze configuration is as follows:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-781 image-border" src="assets/ba8f0918-f64e-4432-aacc-6723715819de.png" style="width:15.08em;height:14.42em;"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref">The hard-to-solve maze configuration</div>
<p class="p1"><span class="s1">This maze configuration is identical to the one described in the previous chapter. Thus, you can refer to <a href="22365f85-3003-4b67-8e1e-cc89fa5e259b.xhtml" target="_blank">Chapter 5</a>, <em>Autonomous Maze Navigation</em>, for a detailed description.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Hyperparameter selection and working environment setup</h1>
                </header>
            
            <article>
                
<p class="p1"><span class="s1">The hyperparameters for this experiment are the same that we used for a simple maze experiment earlier in this chapter. We decided to leave the hyperparameters unchanged to test how well the algorithm generalizes by trying to find a solution to a task within the same domain, but with a different configuration.</span></p>
<p class="p1"><span class="s1">The working environment for this experiment is fully compatible with the environment already created for the simple maze experiment. Thus, we can use it as well.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Running the hard-to-solve maze navigation experiment</h1>
                </header>
            
            <article>
                
<p class="p1"><span class="s1">To run this experiment, we can use the same experiment runner that we developed for the simple maze experiment, with the only difference being that different command-line parameters should be provided at the start. You can start the hard maze experiment with the following command:</span></p>
<pre><strong>$ python maze_experiment.py -m hard -g 500 -t 10 --width 200 --height 200</strong></pre>
<p class="p1"><span class="s1">This command starts the hard-to-solve maze experiment for <kbd>10</kbd> trials with <kbd>500</kbd> generations each. The width and height parameters determine the dimensions of the subplot to draw the maze records collected during the experiment.</span></p>
<p class="p1"><span class="s1">Using the NEAT-Python library for the hard maze experiment, we were unable to find a successful maze solver within 10 trials, even with the NS optimization method. Nevertheless, the results obtained with the NS method are more promising than with the goal-oriented optimization method from the previous chapter. You can see this in the following plot, which depicts the final positions of the solver agents during the maze navigation simulation:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-782 image-border" src="assets/80175455-60ad-457a-9aeb-74a46b29a230.png" style="width:13.83em;height:29.75em;"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref">The agents records visualization</div>
<p class="p1"><span class="s1">The plot that visualizes the final positions of all evaluated agents demonstrates that, during this experiment, more areas of the maze were explored with the NS optimization method than with the goal-oriented method. Also, you can see that some species were almost at the finish line, only a few steps away from reaching the maze exit.</span></p>
<p class="p1"><span class="s1">The path of the most successful maze-solver agent is as follows:</span></p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/d697228a-ba57-4289-8c41-672d3bd5b1f2.png" style="width:10.83em;height:11.25em;"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref">The path through the maze of the most successful maze solver agent </div>
<p class="p1">The path through the maze taken by the most successful solver agent demonstrates that the agent was able to discover the crucial relations between sensor inputs and the maneuvers to perform. However, it still lacks precision in applying the control signal. Due to this flaw, some control actions lead to ineffective trajectory loops, consuming precious time steps allotted to solve the maze.</p>
<p class="p1"><span class="s1">Finally, it is interesting to take a look at the topology of the control ANN of the most successful maze solver:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-783 image-border" src="assets/e53507b6-a2b8-4baa-ac42-057c119551a0.png" style="width:31.92em;height:24.67em;"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref">The topology of the control ANN</div>
<p><span>You can see that all sensor inputs were involved in the decision-making, in contrast with the topology of the control ANN devised in the previous experiment in this chapter. Furthermore, the network topology includes two hidden nodes, which allows the agent to implement a complex control strategy to navigate through the hard-to-solve maze environment. </span></p>
<p><span>Despite our failure to evolve a successful maze solver agent with the Novelty Search optimization method in this experiment using the NEAT-Python library, it is rather an issue of ineffective NEAT implementation by the library than a failure of the Novelty Search method.</span></p>
<div class="packt_tip packt_infobox">I have made an implementation of the NEAT algorithm in the GO programming language that solves a hard maze navigation task with high efficiency. You can check it out on GitHub at <a href="https://github.com/yaricom/goNEAT_NS">https://github.com/yaricom/goNEAT_NS</a>.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Exercise 2</h1>
                </header>
            
            <article>
                
<p class="p1"><span class="s1">In the source code for this chapter, we also provide the experiment runner implementation based on the MultiNEAT Python library that we introduced in <a href="c673e180-4440-4eea-98f8-8800c77162c8.xhtml" target="_blank">Chapter 2</a>, <em>Python Libraries and Environment Setup</em>.</span></p>
<p class="p1"><span class="s1">You can try to use it to solve the hard maze task as follows:</span></p>
<ol>
<li><span class="s1">Update the current Anaconda environment by installing the MultiNEAT Python library with the following command:</span></li>
</ol>
<pre style="padding-left: 60px"><strong>$ conda install -c conda-forge multineat</strong></pre>
<ol start="2">
<li>Run the experiment runner implementation based on the MultiNEAT library:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ python maze_experiment_multineat.py -m hard -g 500 -t 10 --width 200 --height 200</strong></pre>
<p class="p1"><span class="s1">These commands install the MultiNEAT library in the current Anaconda environment and start 10 trials (with <kbd>500</kbd> generations each) of the hard maze experiment using an appropriate experiment runner.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p class="p1"><span class="s1">In this chapter, you learned about the <em>Novelty Search</em> optimization method and how it can be used to guide the neuroevolution process in deceptive problem space environments, such as maze navigation. We conducted the same maze navigation experiments as in the previous chapter. After that, we compared the results we obtained to determine if the NS method has advantages over the goal-oriented optimization method introduced in the previous chapter.</span></p>
<p class="p1"><span class="s1">You got the practical experience of writing source code using Python and experimented with tuning the important hyperparameters of the NEAT algorithm. Also, we introduced a new visualization method, allowing you to see the path of the agent through the maze. With this method, you can easily compare how different agents are trying to solve the maze navigation problem and whether the path through the maze that was found is optimal or not.</span></p>
<p class="p1"><span class="s1">The next chapter introduces more advanced <span>applications of the NEAT algorithm</span>. We start with the task of visual discrimination and introduce you to the HyperNEAT extension of the NEAT algorithm. The HyperNEAT method allows you to work with large-scale ANNs operating over thousands or millions of parameters. This scale of operations is impossible with the classic NEAT algorithm.</span></p>


            </article>

            
        </section>
    </body></html>