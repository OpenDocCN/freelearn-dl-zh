["```py\n    duckduckgo-search and youtube_search integrate search engine functionalities, allowing language models to retrieve real-time information from the web and YouTube, respectively\n    ```", "```py\n    import os\n    import getpass\n    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter Your OpenAI API Key:\")\n    from langchain.agents import load_tools\n    from langchain.chat_models import ChatOpenAI\n    # load the language model, you can use any model you like\n    llm = ChatOpenAI(model = \"gpt-4o\", temperature=0)\n    # load tools\n    tools = load_tools(['wikipedia', 'ddg-search','llm-math'],\n        llm=llm)\n    ```", "```py\n    from langchain.agents import initialize_agent\n    from langchain.agents import AgentType\n    # initialize agent\n    agent = initialize_agent(\n        tools,  \n        llm,  \n        agent=AgentType.ZERO_SHOT_REACT_ DESCRIPTION,  \n        verbose=True  \n    ) \n    ```", "```py\n    print(agent.agent.llm_chain.prompt.template)\n    ```", "```py\n    prompt = \"\"\"\n    You are an intelligent agent designed to solve complex queries by breaking them down systematically and using available tools strategically. Follow the ReAct (Reasoning and Acting) framework to approach each task.\n    ReAct Principles:\n    1\\. Reasoning: Always start by carefully analyzing the question and developing a clear, step-by-step thought process.\n    2\\. Tool Selection: Critically evaluate which tools will be most effective for addressing the specific query.\n    3\\. Iterative Interaction: Be prepared to cycle between reasoning and action multiple times, refining your approach as you gather more information.\n    4\\. Comprehensive Understanding: Aim to not just find an answer, but to truly comprehend the underlying context and nuances of the question.\n    5\\. Transparent Decision-Making: Clearly articulate your reasoning, actions, and thought process at each step.\n    Available Tools:\n    - Wikipedia: Retrieve factual information about people, places, historical events, and general knowledge topics.\n    - Google Search: Fetch current information, recent events, and up-to-date context.\n    - Calculator: Perform mathematical calculations and numerical analysis.\n    Interaction Format:\n    Question: The specific query to be solved\n    Thought: Detailed reasoning about the approach, breaking down the problem\n    Action: Selected tool (Wikipedia/Google Search/Calculator)\n    Action Input: Precise query for the selected tool\n    Observation: Results obtained from the tool\n    ... (Repeat reasoning, action, and observation as needed)\n    Thought: Final synthesized understanding\n    Final Answer: Comprehensive and well-reasoned response to the original question\n    Important Guidelines:\n    - Be methodical and explicit in your reasoning\n    - Use tools judiciously and avoid unnecessary actions\n    - Integrate information from multiple sources when appropriate\n    - Provide a clear, concise, and informative final answer\n    Begin!\n    Question: {input}\n    Thought:{agent_scratchpad}\n    \"\"\"\n    ```", "```py\n    tools[1].description = \"A date retrieval tool that provides the current date and time, useful for temporal queries, scheduling, age calculations, or understanding time-sensitive contexts.\"\n    tools[2].description = \"A powerful computational tool capable of performing various mathematical operations, including arithmetic calculations, algebraic computations, percentage calculations, unit conversions, and advanced mathematical functions.\"\n    ```", "```py\n    agent.run(\"What is the population of the largest city in Canada? How many days would it take for that city's population to count to 1 billion if each person counts one number per second without breaks? Then, compare this time to the average lifespan of a human in years, and explain which is longer.\")\n    ```", "```py\nfrom langchain import Wikipedia\nfrom langchain.agents import initialize_agent, Tool\nfrom langchain.agents import AgentType\nfrom langchain.agents.react.base import DocstoreExplorer\ndocstore = DocstoreExplorer(Wikipedia())\nsearch_tool = Tool(name=\"Search\",\n                   func=docstore.search,\n                   description=\"Search for latest information about any topic\"\n                   )\nlookup_tool = Tool(name=\"Lookup\",\n                   func=docstore.lookup,\n                   description=\"Lookup tool for get information from a keyword\"\n                   )\ntools = [search_tool, lookup_tool]\nllm = OpenAI(temperature=0)\nreact = initialize_agent(tools,\n                         llm,\n                         agent=AgentType.REACT_DOCSTORE,\n                         verbose=True)\nquestion = \"Who is the current governor of Texas and when was he born ?\"\nreact.run(question)\n```", "```py\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_core.runnables import chain\nfrom langchain.agents.format_scratchpad import format_log_to_str\nfrom langchain.agents.output_parsers import(\n    ReActSingleInputOutputParser)\nfrom langchain.tools import DuckDuckGoSearchRun\nfrom langchain_openai import ChatOpenAI\n# 1\\. Define Tools: In this simple example, we are using a search tool.\ntools = [DuckDuckGoSearchRun()]\n# 2\\. Construct the Prompt:  Instead of pulling from a hub, we'll define a basic prompt template.\ntemplate = \"\"\"Answer the following questions as best you can. You have access to the following tools:\n{tool_descriptions}\nUse the following format:\nQuestion: the input question you must answer\nThought: you should always think about what to do\nAction: the action to take, should be one of [{tool_names}]\nAction Input: the input to the action\nObservation: the result of the action\n... (this Thought/Action/Action Input/Observation can repeat N times)\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\nBegin!\nQuestion: {input}\n{agent_scratchpad}\"\"\"\nprompt = ChatPromptTemplate.from_template(template)\nprompt = prompt.partial(\n    tool_names=\", \".join([t.name for t in tools]),\n    tool_descriptions=\"\\n\".join(\n        [f\"{t.name}: {t.description}\" for t in tools]\n    ),\n)\n# 3\\. Instantiate the LLM:  We use ChatOpenAI, but any LLM can be used.\nllm = ChatOpenAI(temperature=0)\n#  We also configure it to stop when it sees '\\nObservation:'\nllm_with_stop = llm.bind(stop=[\"\\nObservation:\"])\n# 4\\. Construct the Agent Pipeline using LCEL:\nagent = (\n    {\n        \"input\": lambda x: x[\"input\"],\n        \"agent_scratchpad\": lambda x:\n            format_log_to_str(x[\"intermediate_steps\"]),\n    }\n    | prompt\n    | llm_with_stop\n    | ReActSingleInputOutputParser()\n)\n```", "```py\nfrom langchain.agents import AgentExecutor\nagent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\nresponse = agent_executor.invoke(\n    {\n        \"input\": \"Who is the current CEO of Microsoft and what is their age squared?\"\n    }\n)\nprint(response)\n```"]