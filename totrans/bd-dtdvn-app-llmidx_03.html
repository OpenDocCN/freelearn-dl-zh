<html><head></head><body><html:html>&#13;
 <html:head>&#13;
  <html:title>&#13;
   Ingesting Data into Our RAG Workflow&#13;
  </html:title>&#13;
 </html:head>&#13;
 <html:body>&#13;
  <html:div class="epub-source">&#13;
   <html:h1 id="_idParaDest-70">&#13;
    Ingesting Data into Our RAG Workflow&#13;
   </html:h1>&#13;
   <html:div id="_idContainer039">&#13;
    <html:p>&#13;
     We’ve taken a good look at the overall structure of LlamaIndex from afar. It’s now time to get much closer and understand the small details of this framework. It’s bound to get more technical but also more intriguing as we&#13;
     <html:span class="No-Break">&#13;
      go further.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Ready to go deeper down the rabbit hole?&#13;
     <html:span class="No-Break">&#13;
      Follow me!&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     In this chapter, we will learn about&#13;
     <html:span class="No-Break">&#13;
      the following:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:ul>&#13;
     <html:li>&#13;
      Using the LlamaHub connectors to ingest&#13;
      <html:span class="No-Break">&#13;
       our data&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      Taking advantage of the many text-chunking tools&#13;
      <html:span class="No-Break">&#13;
       in LlamaIndex&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      Infusing our nodes with metadata&#13;
      <html:span class="No-Break">&#13;
       and relationships&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      Keeping our data private and our&#13;
      <html:span class="No-Break">&#13;
       budget safe&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      Creating ingestion pipelines for better efficiency and&#13;
      <html:span class="No-Break">&#13;
       lower costs&#13;
      </html:span>&#13;
     </html:li>&#13;
    </html:ul>&#13;
    <html:a id="_idTextAnchor070">&#13;
    </html:a>&#13;
   </html:div>&#13;
  </html:div>&#13;
 </html:body>&#13;
</html:html>
<html:html>&#13;
 <html:head>&#13;
  <html:title>&#13;
   Technical requirements&#13;
  </html:title>&#13;
 </html:head>&#13;
 <html:body>&#13;
  <html:div class="epub-source">&#13;
   <html:h1 id="_idParaDest-71">&#13;
    Technical requirements&#13;
   </html:h1>&#13;
   <html:div id="_idContainer039">&#13;
    <html:p>&#13;
     You will need to install the following Python libraries in your environment to be able to run the examples included in&#13;
     <html:span class="No-Break">&#13;
      this chapter:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:ul>&#13;
     <html:li>&#13;
      <html:span class="No-Break">&#13;
       <html:strong class="bold">&#13;
        LangChain&#13;
       </html:strong>&#13;
      </html:span>&#13;
      <html:span class="No-Break">&#13;
       :&#13;
      </html:span>&#13;
      <html:a>&#13;
       <html:span class="No-Break">&#13;
        https://www.langchain.com/&#13;
       </html:span>&#13;
      </html:a>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:span class="No-Break">&#13;
       <html:strong class="bold">&#13;
        Py-Tree-Sitter&#13;
       </html:strong>&#13;
      </html:span>&#13;
      <html:span class="No-Break">&#13;
       :&#13;
      </html:span>&#13;
      <html:a>&#13;
       <html:span class="No-Break">&#13;
        https://pypi.org/project/tree-sitter/&#13;
       </html:span>&#13;
      </html:a>&#13;
     </html:li>&#13;
    </html:ul>&#13;
    <html:p>&#13;
     In addition, several LlamaIndex Integration packages will&#13;
     <html:span class="No-Break">&#13;
      be required:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:ul>&#13;
     <html:li>&#13;
      <html:strong class="bold">&#13;
       Entity&#13;
      </html:strong>&#13;
      <html:span class="No-Break">&#13;
       <html:strong class="bold">&#13;
        extractor&#13;
       </html:strong>&#13;
      </html:span>&#13;
      <html:span class="No-Break">&#13;
       :&#13;
      </html:span>&#13;
      <html:a>&#13;
       <html:span class="No-Break">&#13;
        https://pypi.org/project/llama-index-extractors-entity/&#13;
       </html:span>&#13;
      </html:a>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:strong class="bold">&#13;
       Hugging Face&#13;
      </html:strong>&#13;
      <html:span class="No-Break">&#13;
       <html:strong class="bold">&#13;
        LLMs&#13;
       </html:strong>&#13;
      </html:span>&#13;
      <html:span class="No-Break">&#13;
       :&#13;
      </html:span>&#13;
      <html:a>&#13;
       <html:span class="No-Break">&#13;
        https://pypi.org/project/llama-index-llms-huggingface/&#13;
       </html:span>&#13;
      </html:a>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:strong class="bold">&#13;
       Database&#13;
      </html:strong>&#13;
      <html:span class="No-Break">&#13;
       <html:strong class="bold">&#13;
        reader&#13;
       </html:strong>&#13;
      </html:span>&#13;
      <html:span class="No-Break">&#13;
       :&#13;
      </html:span>&#13;
      <html:a>&#13;
       <html:span class="No-Break">&#13;
        https://pypi.org/project/llama-index-readers-database/&#13;
       </html:span>&#13;
      </html:a>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:strong class="bold">&#13;
       Web&#13;
      </html:strong>&#13;
      <html:span class="No-Break">&#13;
       <html:strong class="bold">&#13;
        reader&#13;
       </html:strong>&#13;
      </html:span>&#13;
      <html:span class="No-Break">&#13;
       :&#13;
      </html:span>&#13;
      <html:a>&#13;
       <html:span class="No-Break">&#13;
        https://pypi.org/project/llama-index-readers-web/&#13;
       </html:span>&#13;
      </html:a>&#13;
     </html:li>&#13;
    </html:ul>&#13;
    <html:p>&#13;
     All the code examples in this chapter can be found in the&#13;
     <html:em class="italic">&#13;
      ch4&#13;
     </html:em>&#13;
     subfolder of this book’s GitHub&#13;
     <html:span class="No-Break">&#13;
      repository:&#13;
     </html:span>&#13;
     <html:a>&#13;
      <html:span class="No-Break">&#13;
       https://github.com/PacktPublishing/Building-Data-Driven-Applications-with-LlamaIndex&#13;
      </html:span>&#13;
     </html:a>&#13;
     <html:span class="No-Break">&#13;
      .&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor071">&#13;
    </html:a>&#13;
   </html:div>&#13;
  </html:div>&#13;
 </html:body>&#13;
</html:html>
<html:html>&#13;
 <html:head>&#13;
  <html:title>&#13;
   Ingesting data via LlamaHub&#13;
  </html:title>&#13;
 </html:head>&#13;
 <html:body>&#13;
  <html:div class="epub-source">&#13;
   <html:h1 id="_idParaDest-72">&#13;
    Ingesting data via LlamaHub&#13;
   </html:h1>&#13;
   <html:div id="_idContainer039">&#13;
    <html:p>&#13;
     As we saw in&#13;
     <html:a>&#13;
      <html:span class="No-Break">&#13;
       <html:em class="italic">&#13;
        Chapter 3&#13;
       </html:em>&#13;
      </html:span>&#13;
     </html:a>&#13;
     ,&#13;
     <html:em class="italic">&#13;
      Kickstarting Your Journey with LlamaIndex&#13;
     </html:em>&#13;
     , one of the first steps in a RAG workflow is to ingest and process our proprietary data. We already discovered&#13;
     <html:a id="_idIndexMarker200">&#13;
     </html:a>&#13;
     the concepts of documents and nodes, which are used to organize the data and prepare it for indexing. I’ve also briefly introduced&#13;
     <html:a id="_idIndexMarker201">&#13;
     </html:a>&#13;
     the LlamaHub data loaders as a way to easily ingest data into LlamaIndex. It’s time to examine these steps in more detail and gradually learn how to infuse LLM applications with our own, proprietary knowledge. Before we continue, though, I’d like to emphasize some very common challenges encountered at&#13;
     <html:span class="No-Break">&#13;
      this step:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:ol>&#13;
     <html:li>&#13;
      No matter how effective our RAG pipeline is, at the end of the day, the quality of the final result will largely depend on the quality of the initial data. To overcome this challenge, make sure you start by cleaning up your data first. Eliminate potential duplicates and errors. While not exactly duplicates, redundant information can also clutter your knowledge base and confuse the RAG system. Be on the lookout for ambiguous, biased, incomplete, or outdated information. I’ve seen many cases of poorly structured and insufficiently maintained knowledge repositories that were completely useless for users looking for quick and accurate answers. Ask yourself this question:&#13;
      <html:em class="italic">&#13;
       If I were to manually search through this data, how easy would it be to find the information I need?&#13;
      </html:em>&#13;
      Before moving on with building the pipeline, do yourself a favor and prepare your data thoroughly until you’re satisfied with the answer to&#13;
      <html:span class="No-Break">&#13;
       that question.&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      Our data is dynamic. An organizational knowledge repository is rarely a static, permanent data source. It evolves with the business, reflecting new insights, discoveries, and changes in the external environment. Recognizing this fluid nature is key to maintaining a relevant and effective system. To overcome this challenge, in a production RAG application, you’ll have to implement a systematic method for periodically reviewing and updating the content, ensuring that new information is incorporated and outdated or incorrect data&#13;
      <html:span class="No-Break">&#13;
       is removed.&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      Data comes in many flavors, shapes, and sizes. Sometimes, it’s structured, sometimes not. A well-built RAG system should be able to properly ingest all kinds of&#13;
      <html:a id="_idIndexMarker202">&#13;
      </html:a>&#13;
      formats and document types. While LlamaIndex provides a huge number of data loaders for many different APIs, databases, and document types, building an automated ingestion system can still prove to&#13;
      <html:a id="_idIndexMarker203">&#13;
      </html:a>&#13;
      be challenging. To overcome this particular challenge, later in this section, we’ll cover&#13;
      <html:strong class="bold">&#13;
       LlamaParse&#13;
      </html:strong>&#13;
      – an innovative hosted service designed to automatically ingest and process data from different&#13;
      <html:span class="No-Break">&#13;
       data sources.&#13;
      </html:span>&#13;
     </html:li>&#13;
    </html:ol>&#13;
    <html:p>&#13;
     Now that we know what kind of problems await along the way, let’s start our journey by first discussing the simplest ways of ingesting the data into the RAG pipeline – by using the available LlamaHub&#13;
     <html:span class="No-Break">&#13;
      data loaders.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor072">&#13;
    </html:a>&#13;
   </html:div>&#13;
  </html:div>&#13;
 </html:body>&#13;
</html:html>
<html:html>&#13;
 <html:head>&#13;
  <html:title>&#13;
   An overview of LlamaHub&#13;
  </html:title>&#13;
 </html:head>&#13;
 <html:body>&#13;
  <html:div class="epub-source">&#13;
   <html:h1 id="_idParaDest-73">&#13;
    An overview of LlamaHub&#13;
   </html:h1>&#13;
   <html:div id="_idContainer039">&#13;
    <html:p>&#13;
     LlamaHub is an extensive library of integrations that augments the capabilities of the core framework. Among many&#13;
     <html:a id="_idIndexMarker204">&#13;
     </html:a>&#13;
     other types of integrations, LlamaHub&#13;
     <html:a id="_idIndexMarker205">&#13;
     </html:a>&#13;
     contains numerous&#13;
     <html:strong class="bold">&#13;
      connectors&#13;
     </html:strong>&#13;
     – also known as&#13;
     <html:strong class="bold">&#13;
      data readers&#13;
     </html:strong>&#13;
     or&#13;
     <html:strong class="bold">&#13;
      data loaders&#13;
     </html:strong>&#13;
     – specially built to allow seamless integration of external data with LlamaIndex. There are over 180 readily available data readers spanning a wide range of data&#13;
     <html:a id="_idIndexMarker206">&#13;
     </html:a>&#13;
     sources and formats, and the list is&#13;
     <html:span class="No-Break">&#13;
      constantly increasing.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     These connectors act as a standard way to ingest data, extracting data from sources such as databases, APIs, files, and websites and converting it into LlamaIndex&#13;
     <html:code class="literal">&#13;
      Document&#13;
     </html:code>&#13;
     objects. This relieves you from the burden of writing customized parsers and connectors for every new data source. But of course, if you’re not satisfied with the existing connectors, you can always build your own and contribute to&#13;
     <html:span class="No-Break">&#13;
      the collection.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     LlamaHub empowers you to tap into diverse data sources with just a few lines of code. The resulting Document objects can then be parsed into nodes and indexed as required by your application. The unified output as LlamaIndex&#13;
     <html:code class="literal">&#13;
      Document&#13;
     </html:code>&#13;
     objects means your core business&#13;
     <html:a id="_idIndexMarker207">&#13;
     </html:a>&#13;
     logic does not have to worry about handling various data types. The complexity is abstracted by&#13;
     <html:span class="No-Break">&#13;
      the framework.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p class="callout-heading">&#13;
     Why do we need so many integrations?&#13;
    </html:p>&#13;
    <html:p class="callout">&#13;
     In&#13;
     <html:a>&#13;
      <html:span class="No-Break">&#13;
       <html:em class="italic">&#13;
        Chapter 2&#13;
       </html:em>&#13;
      </html:span>&#13;
     </html:a>&#13;
     ,&#13;
     <html:em class="italic">&#13;
      LlamaIndex: The Hidden Jewel - An Introduction to the LlamaIndex Ecosystem&#13;
     </html:em>&#13;
     , in the&#13;
     <html:em class="italic">&#13;
      Familiarizing ourselves with the structure of the LlamaIndex code repository&#13;
     </html:em>&#13;
     section, I explained the motives behind the framework’s modular architecture. Because of this modular architecture, many RAG components provided by LlamaIndex are not included in the core elements that are installed together with the rest of the framework. This means that before using any data loader for the first time, we have to install the corresponding integration package. Once the package has been installed, we’ll be able to import the reader into our code and use its functionality. Some readers also utilize specialized libraries and tools tailored to each data type. For example,&#13;
     <html:code class="literal">&#13;
      PDFReader&#13;
     </html:code>&#13;
     leverages Camelot and Tika for parsing PDF content.&#13;
     <html:code class="literal">&#13;
      AirbyteSalesforceReader&#13;
     </html:code>&#13;
     uses the Salesforce API client, and so on. This allows us to efficiently adapt to the format and interface of each source but may require us to install additional packages in our&#13;
     <html:span class="No-Break">&#13;
      development environment.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     All available readers are listed on the LlamaHub website and usually come with detailed documentation and usage samples. Therefore, I’ll briefly cover just a few examples to give a general idea of how you can use them in&#13;
     <html:span class="No-Break">&#13;
      your applications.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     I strongly encourage you to take your time and go through the entire list of data readers when building your LlamaIndex apps instead of spending valuable time building one from scratch. Chances are you’ll just be reinventing&#13;
     <html:span class="No-Break">&#13;
      the wheel.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     If you’re looking to consult the source code for the readers, you’ll find them all included in the Llama-index GitHub repository, under the&#13;
     <html:code class="literal">&#13;
      llama-index-integrations/readers&#13;
     </html:code>&#13;
     <html:span class="No-Break">&#13;
      subfolder:&#13;
     </html:span>&#13;
     <html:a>&#13;
      <html:span class="No-Break">&#13;
       https://github.com/run-llama/llama_index/tree/main/llama-index-integrations/readers&#13;
      </html:span>&#13;
     </html:a>&#13;
     <html:span class="No-Break">&#13;
      .&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     The LlamaHub documentation for each data reader lists its installation requirements and usage guidance, so before trying to use them, make sure you also install any additional dependencies required by specific connectors you want&#13;
     <html:span class="No-Break">&#13;
      to use.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor073">&#13;
    </html:a>&#13;
   </html:div>&#13;
  </html:div>&#13;
 </html:body>&#13;
</html:html>
<html:html>&#13;
 <html:head>&#13;
  <html:title>&#13;
   Using the LlamaHub data loaders to ingest content&#13;
  </html:title>&#13;
 </html:head>&#13;
 <html:body>&#13;
  <html:div class="epub-source">&#13;
   <html:h1 id="_idParaDest-74">&#13;
    Using the LlamaHub data loaders to ingest content&#13;
   </html:h1>&#13;
   <html:div id="_idContainer039">&#13;
    pip install llama-index-readers-web&#13;
    from llama_index.readers.web import SimpleWebPageReader&#13;
urls = ["https://docs.llamaindex.ai"]&#13;
documents = SimpleWebPageReader().load_data(urls)&#13;
for doc in documents:&#13;
    print(doc.text)&#13;
    pip install llama-index-readers-database&#13;
    from llama_index.readers.database import DatabaseReader&#13;
reader = DatabaseReader(&#13;
    uri="sqlite:///files/db/example.db"&#13;
)&#13;
query = "&#13;
    from llama_index.core import SimpleDirectoryReader&#13;
reader = SimpleDirectoryReader(&#13;
    input_dir="files",&#13;
    recursive=True&#13;
)&#13;
documents = reader.load_data()&#13;
for doc in documents:&#13;
    print(doc.metadata)&#13;
    files = ["&#13;
    from llama_parse import LlamaParse&#13;
from llama_index.core import SimpleDirectoryReader&#13;
from llama_index.core import VectorStoreIndex&#13;
    parser = LlamaParse(result_type="text")&#13;
file_extractor = {".pdf": parser}&#13;
reader = SimpleDirectoryReader(&#13;
    "./files/pdf",&#13;
    file_extractor=file_extractor&#13;
)&#13;
docs = reader.load_data()&#13;
    index = VectorStoreIndex.from_documents(docs)&#13;
qe = index.as_query_engine()&#13;
response = qe.query(&#13;
    "&#13;
    Started parsing the file under job_id &lt;…&gt;&#13;
&#13;
    <html:p>&#13;
     Apart from the&#13;
     <html:em class="italic">&#13;
      Wikipedia&#13;
     </html:em>&#13;
     reader that we discussed in the previous chapter, to get a better&#13;
     <html:a id="_idIndexMarker208">&#13;
     </html:a>&#13;
     understanding of how data readers work, let’s look at a few more examples of LlamaHub readers that we can use to&#13;
     <html:span class="No-Break">&#13;
      ingest data.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor074">&#13;
    </html:a>&#13;
    <html:h2 id="_idParaDest-75">&#13;
     Ingesting data from a web page&#13;
    </html:h2>&#13;
    <html:p>&#13;
     <html:code class="literal">&#13;
      SimpleWebPageReader&#13;
     </html:code>&#13;
     can extract text content from&#13;
     <html:span class="No-Break">&#13;
      web pages.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     To use it, we&#13;
     <html:a id="_idIndexMarker209">&#13;
     </html:a>&#13;
     must first install the&#13;
     <html:span class="No-Break">&#13;
      corresponding integration:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Once installed, it’s really easy&#13;
     <html:span class="No-Break">&#13;
      to use:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     This loads and displays the text content of the specified web pages&#13;
     <html:span class="No-Break">&#13;
      into documents.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     At its core,&#13;
     <html:code class="literal">&#13;
      SimpleWebPageReader&#13;
     </html:code>&#13;
     serves as a bridge between the vast, unstructured world of the internet and the structured environment of the LlamaIndex RAG pipeline. To better understand its inner workings, let’s explore what happens under the hood when it extracts text content from&#13;
     <html:span class="No-Break">&#13;
      web pages.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     When loading the data,&#13;
     <html:code class="literal">&#13;
      SimpleWebPageReader&#13;
     </html:code>&#13;
     iterates over a list of URLs provided by the user. For each URL, it performs a web request to fetch the page content. The response, initially in HTML format, can be transformed into plain text if the&#13;
     <html:code class="literal">&#13;
      html_to_text&#13;
     </html:code>&#13;
     flag is set to&#13;
     <html:code class="literal">&#13;
      True&#13;
     </html:code>&#13;
     . This transformation strips away the HTML tags and converts the web page content into a more digestible text format. However, remember what I’ve said about external dependencies for these readers? In this case, the HTML-to-text conversion feature requires the&#13;
     <html:code class="literal">&#13;
      html2text&#13;
     </html:code>&#13;
     package, which has to be&#13;
     <html:span class="No-Break">&#13;
      installed first.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Another significant aspect of this reader is its ability to attach metadata to the scraped documents. Through the&#13;
     <html:code class="literal">&#13;
      metadata_fn&#13;
     </html:code>&#13;
     parameter, we can pass a custom function that takes a URL as input and returns a dictionary of metadata. This flexibility allows for the enrichment of documents with additional information or any relevant tags that might be&#13;
     <html:a id="_idIndexMarker210">&#13;
     </html:a>&#13;
     useful in categorizing and understanding the context of the data better. Should the user provide a&#13;
     <html:code class="literal">&#13;
      metadata_fn&#13;
     </html:code>&#13;
     parameter, the reader then applies this function to the current URL to extract metadata, enriching the final&#13;
     <html:code class="literal">&#13;
      Document&#13;
     </html:code>&#13;
     object with this additional layer&#13;
     <html:span class="No-Break">&#13;
      of information.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p class="callout-heading">&#13;
     A practical use case for the metadata_fn function&#13;
    </html:p>&#13;
    <html:p class="callout">&#13;
     We could, for example, use a function that simply returns the current date and time. That way, we could ingest the same URL at different moments and build a chronological timeline highlighting different versions of that page at various points in time. This could prove useful in scenarios such as browsing a code repository or answering questions about a developing&#13;
     <html:span class="No-Break">&#13;
      news story.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Finally, each web page’s content, along with its URL and optionally added metadata, is encapsulated in a&#13;
     <html:code class="literal">&#13;
      Document&#13;
     </html:code>&#13;
     object. These objects are then collected into a list, providing a structured representation of the text content and metadata extracted from each&#13;
     <html:span class="No-Break">&#13;
      web page.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p class="callout-heading">&#13;
     One thing to keep in mind&#13;
    </html:p>&#13;
    <html:p class="callout">&#13;
     As its name suggests, this reader is a simple tool. While it can be effective for reading simple web pages, for more advanced cases such as pages requiring interaction (for example, navigating a login process or handling JavaScript-rendered content),&#13;
     <html:code class="literal">&#13;
      SimpleWebPageReader&#13;
     </html:code>&#13;
     might not be sufficient. Websites that dynamically generate content based on user interactions or rely heavily on client-side scripting can pose challenges that this basic scraper is not designed&#13;
     <html:span class="No-Break">&#13;
      to handle.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Through&#13;
     <html:code class="literal">&#13;
      SimpleWebPageReader&#13;
     </html:code>&#13;
     , the task of ingesting and structuring basic web content is simplified. The great thing about these readers is that they allow us to focus on building&#13;
     <html:a id="_idIndexMarker211">&#13;
     </html:a>&#13;
     and enhancing the logic of our RAG applications instead of spending precious time on building compatible ingestion tools for each type of data in our&#13;
     <html:span class="No-Break">&#13;
      knowledge base.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor075">&#13;
    </html:a>&#13;
    <html:h2 id="_idParaDest-76">&#13;
     Ingesting data from a database&#13;
    </html:h2>&#13;
    <html:p>&#13;
     Using databases is not only a common practice but also a highly efficient method for managing and retrieving structured information. Databases offer a robust platform for storing&#13;
     <html:a id="_idIndexMarker212">&#13;
     </html:a>&#13;
     a vast array of data types, from simple text to complex relationships between entities, making them an indispensable asset in&#13;
     <html:span class="No-Break">&#13;
      data management.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     The&#13;
     <html:code class="literal">&#13;
      DatabaseReader&#13;
     </html:code>&#13;
     connector allows querying many database systems. First, we need to install the necessary&#13;
     <html:span class="No-Break">&#13;
      integration package:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Here’s an example of how you can easily fetch the contents of an&#13;
     <html:span class="No-Break">&#13;
      SQLite database:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Under the hood,&#13;
     <html:code class="literal">&#13;
      DatabaseReader&#13;
     </html:code>&#13;
     connects to various databases to fetch data and transform it&#13;
     <html:a id="_idIndexMarker213">&#13;
     </html:a>&#13;
     into a format usable by the RAG pipeline. It supports connection through a&#13;
     <html:code class="literal">&#13;
      SQLDatabase&#13;
     </html:code>&#13;
     instance, a&#13;
     <html:strong class="bold">&#13;
      SQLAlchemy Engine&#13;
     </html:strong>&#13;
     , a connection URI, or a set of database credentials – provided through the&#13;
     <html:code class="literal">&#13;
      scheme&#13;
     </html:code>&#13;
     ,&#13;
     <html:code class="literal">&#13;
      host&#13;
     </html:code>&#13;
     ,&#13;
     <html:code class="literal">&#13;
      port&#13;
     </html:code>&#13;
     ,&#13;
     <html:code class="literal">&#13;
      user&#13;
     </html:code>&#13;
     ,&#13;
     <html:code class="literal">&#13;
      password&#13;
     </html:code>&#13;
     , and&#13;
     <html:code class="literal">&#13;
      dbname&#13;
     </html:code>&#13;
     arguments. Once set up, it executes a provided SQL query to retrieve data. After connecting to the database, the reader executes the provided&#13;
     <html:code class="literal">&#13;
      query&#13;
     </html:code>&#13;
     . The resulting rows are then converted into Document objects, with each row from the query result forming a single Document. The conversion process involves concatenating each column-value pair into a string, which is then assigned as the text of&#13;
     <html:span class="No-Break">&#13;
      a document.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     The example I have provided executes the SQL query against an SQLite database stored in the&#13;
     <html:code class="literal">&#13;
      ch4/files/db&#13;
     </html:code>&#13;
     folder, loads each returned row as a Document, and displays the results. You can find a more general example on the official project documentation&#13;
     <html:span class="No-Break">&#13;
      website:&#13;
     </html:span>&#13;
     <html:a>&#13;
      <html:span class="No-Break">&#13;
       https://docs.llamaindex.ai/en/stable/examples/data_connectors/DatabaseReaderDemo.html&#13;
      </html:span>&#13;
     </html:a>&#13;
     <html:span class="No-Break">&#13;
      .&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Alright – I think you understand the workflow now. As you’ve probably noticed, the approach for using LlamaHub readers is very straightforward. In all the examples, first, we install&#13;
     <html:a id="_idIndexMarker214">&#13;
     </html:a>&#13;
     the required integration package, as described on LlamaHub, and then use it to import and load data from the reader. Apart from the examples I have provided, you’ll find a huge number of data readers available on LlamaHub. From Office documents, Gmail accounts, videos and images, YouTube videos, and RSS feeds to GitHub repositories and Discord chats, pretty much every popular data format&#13;
     <html:span class="No-Break">&#13;
      is supported.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     But apart from reading individual files using dedicated data readers, in the next section, we will also explore more efficient methods that can be used for ingesting multiple documents&#13;
     <html:span class="No-Break">&#13;
      at once.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor076">&#13;
    </html:a>&#13;
    <html:h2 id="_idParaDest-77">&#13;
     Bulk-ingesting data from sources with multiple file formats&#13;
    </html:h2>&#13;
    <html:p>&#13;
     Loading data into LlamaIndex is a crucial first step. But sifting through the wide range of data&#13;
     <html:a id="_idIndexMarker215">&#13;
     </html:a>&#13;
     loaders in LlamaHub and figuring out how to configure each one can feel overwhelming early on. That’s why I’m going to show you two different methods that can greatly simplify and reduce the burden of data ingestion for your&#13;
     <html:span class="No-Break">&#13;
      RAG systems.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     We’ll start with the simple&#13;
     <html:span class="No-Break">&#13;
      method first.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:h3>&#13;
     Using SimpleDirectoryReader to ingest multiple data formats&#13;
    </html:h3>&#13;
    <html:p>&#13;
     When&#13;
     <html:a id="_idIndexMarker216">&#13;
     </html:a>&#13;
     you just want to get started fast or have a simple use case,&#13;
     <html:code class="literal">&#13;
      SimpleDirectoryReader&#13;
     </html:code>&#13;
     comes to the rescue. Think of this reader as your trusty pocketknife for bulk data ingestion. It’s easy to use, requires minimal setup, and automatically adapts to different file types. To load data, you simply point the reader to a folder or list of files. Loading a folder&#13;
     <html:a id="_idIndexMarker217">&#13;
     </html:a>&#13;
     containing PDFs, Word docs, plain text files, and CSVs is very straightforward. Here’s&#13;
     <html:span class="No-Break">&#13;
      a demonstration:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p class="callout-heading">&#13;
     Under the hood&#13;
    </html:p>&#13;
    <html:p class="callout">&#13;
     <html:code class="literal">&#13;
      SimpleDirectoryReader&#13;
     </html:code>&#13;
     has built-in methods to determine which reader works best for&#13;
     <html:a id="_idIndexMarker218">&#13;
     </html:a>&#13;
     each file type. You don’t need to worry about those details. It will automatically detect formats such as PDF, DOCX, CSV, plain text, and others based on the file extensions. Then, it chooses the best tool to extract the content into Document objects. For plain text files, it simply reads the text content. For binary files such as PDFs and Office docs, it uses libraries such as PyPDF and Pillow to extract&#13;
     <html:span class="No-Break">&#13;
      the text.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     <html:code class="literal">&#13;
      SimpleDirectoryReader&#13;
     </html:code>&#13;
     effortlessly handles the different files and returns the parsed content as documents. By default, it only processes files in the directory’s top level. To include subdirectories, you can set the&#13;
     <html:code class="literal">&#13;
      recursive&#13;
     </html:code>&#13;
     parameter&#13;
     <html:span class="No-Break">&#13;
      to&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      <html:code class="literal">&#13;
       True&#13;
      </html:code>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      .&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     You can also pass in a list of specific files to load,&#13;
     <html:span class="No-Break">&#13;
      like this:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     The result is a batch of Document objects ready for indexing in just a few lines of code. No&#13;
     <html:a id="_idIndexMarker219">&#13;
     </html:a>&#13;
     headaches setting up separate data readers for each file type. When you want quick and easy data ingestion without the complexity, let&#13;
     <html:code class="literal">&#13;
      SimpleDirectoryReader&#13;
     </html:code>&#13;
     handle the hard work! It’s versatile&#13;
     <html:span class="No-Break">&#13;
      and automated.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:h3>&#13;
     Parsing like a pro with the help of LlamaParse&#13;
    </html:h3>&#13;
    <html:p>&#13;
     While&#13;
     <html:code class="literal">&#13;
      SimpleDirectoryReader&#13;
     </html:code>&#13;
     is great for quick and easy data ingestion, sometimes, you need more advanced parsing capabilities, especially for complex file formats. Most of&#13;
     <html:a id="_idIndexMarker220">&#13;
     </html:a>&#13;
     the time, we have to deal with complex file structures containing a mix of data. For example, a PDF file may include images, charts, code snippets, mathematical formulas, and other elements alongside its text content. The naive readers included in the LlamaHub integration library will be overwhelmed by such cases. They would most probably fail to extract the entire content or – even worse – mess up the extracted data and complicate its&#13;
     <html:span class="No-Break">&#13;
      further processing.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     This is where&#13;
     <html:a id="_idIndexMarker221">&#13;
     </html:a>&#13;
     LlamaParse shines. Provided through the LlamaCloud enterprise platform (&#13;
     <html:a>&#13;
      https://cloud.llamaindex.ai/parse&#13;
     </html:a>&#13;
     ), this reader is implemented through a cutting-edge hosted service that integrates seamlessly with the other components of the framework. It uses multi-modal capabilities and LLM intelligence under the hood to provide industry-leading document parsing, including exceptional support for tricky formats such as PDFs containing tables, figures,&#13;
     <html:span class="No-Break">&#13;
      and equations.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     One of the standout features of&#13;
     <html:code class="literal">&#13;
      LlamaParse&#13;
     </html:code>&#13;
     is that it allows you to provide natural language instructions to guide the parsing by using the&#13;
     <html:code class="literal">&#13;
      parsing_instruction&#13;
     </html:code>&#13;
     parameter. Since you know your documents best, you can tell&#13;
     <html:code class="literal">&#13;
      LlamaParse&#13;
     </html:code>&#13;
     exactly what kind of output you need and how that information should be extracted from&#13;
     <html:span class="No-Break">&#13;
      the files.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p class="callout-heading">&#13;
     For instance:&#13;
    </html:p>&#13;
    <html:p class="callout">&#13;
     When parsing a technical whitepaper, you could instruct it to extract all the section headings, ignore the footnotes, and output any code snippets in markdown format.&#13;
     <html:code class="literal">&#13;
      LlamaParse&#13;
     </html:code>&#13;
     will follow your instructions to parse the&#13;
     <html:span class="No-Break">&#13;
      document accurately.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     In addition to the instruction-guided parsing mode,&#13;
     <html:code class="literal">&#13;
      LlamaParse&#13;
     </html:code>&#13;
     also offers a JSON output mode that provides rich structured data about the parsed document, including marking tables, headings, extracting images, and more. Also, for bulk-ingesting entire folders in one go,&#13;
     <html:code class="literal">&#13;
      LlamaParse&#13;
     </html:code>&#13;
     can be used in combination with&#13;
     <html:code class="literal">&#13;
      SimpleDirectoryReader&#13;
     </html:code>&#13;
     , as you will see in the next example. This gives you full flexibility to build custom RAG applications over a complex collection of documents. You could also accomplish this manually by using specialized data readers for each file format in your&#13;
     <html:a id="_idIndexMarker222">&#13;
     </html:a>&#13;
     collection of data. However, using&#13;
     <html:code class="literal">&#13;
      LlamaParse&#13;
     </html:code>&#13;
     will greatly simplify this process, improve the overall quality, and save you a lot&#13;
     <html:span class="No-Break">&#13;
      of time.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     <html:code class="literal">&#13;
      LlamaParse&#13;
     </html:code>&#13;
     supports a wide and expanding range of file types beyond just PDFs, including Word docs, PowerPoint, RTF, ePub, and many more. It offers a generous free tier to&#13;
     <html:span class="No-Break">&#13;
      get started.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     The necessary&#13;
     <html:code class="literal">&#13;
      LlamaParse&#13;
     </html:code>&#13;
     integration package should already be installed along with the LlamaIndex components, so no additional installation is required to run the code example in&#13;
     <html:span class="No-Break">&#13;
      this section.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     The next step is to create a free account on&#13;
     <html:a>&#13;
      https://cloud.llamaindex.ai&#13;
     </html:a>&#13;
     and obtain an API key. Once you have obtained the key, you can use it directly in your code, but for a more secure approach, I strongly encourage you to follow the same steps we followed in&#13;
     <html:a>&#13;
      <html:span class="No-Break">&#13;
       <html:em class="italic">&#13;
        Chapter 2&#13;
       </html:em>&#13;
      </html:span>&#13;
     </html:a>&#13;
     ,&#13;
     <html:em class="italic">&#13;
      LlamaIndex: The Hidden Jewel - An Introduction to the LlamaIndex Ecosystem&#13;
     </html:em>&#13;
     , and add the key as a variable in your local environment under the name&#13;
     <html:code class="literal">&#13;
      LLAMA_CLOUD_API_KEY&#13;
     </html:code>&#13;
     . To demonstrate the capabilities of this tool, I’ve designed a sample PDF with a more complex structure, as can be seen in&#13;
     <html:span class="No-Break">&#13;
      <html:em class="italic">&#13;
       Figure 4&#13;
      </html:em>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      <html:em class="italic">&#13;
       .1&#13;
      </html:em>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      :&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:div>&#13;
     <html:div class="IMG---Figure" id="_idContainer035">&#13;
      <html:img src="../Images/B21861_04_1.jpg"/>&#13;
     </html:div>&#13;
    </html:div>&#13;
    <html:p class="IMG---Caption" lang="en-US">&#13;
     Figure 4.1 – A sample PDF containing multiple articles, images, and tables&#13;
    </html:p>&#13;
    <html:p>&#13;
     Here’s a basic code example that uses&#13;
     <html:code class="literal">&#13;
      LlamaParse&#13;
     </html:code>&#13;
     to ingest&#13;
     <html:span class="No-Break">&#13;
      this PDF:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     The first part of the code imported the necessary modules. Next, we’ll configure&#13;
     <html:code class="literal">&#13;
      LlamaParse&#13;
     </html:code>&#13;
     and pass it to&#13;
     <html:code class="literal">&#13;
      SimpleDirectoryReader&#13;
     </html:code>&#13;
     as a&#13;
     <html:span class="No-Break">&#13;
      <html:code class="literal">&#13;
       file_extractor&#13;
      </html:code>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      argument:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Once the PDF&#13;
     <html:a id="_idIndexMarker223">&#13;
     </html:a>&#13;
     content has been ingested into a new Document object, it’s time to build an index and run a query against&#13;
     <html:span class="No-Break">&#13;
      our data:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     The output of this script should be similar to&#13;
     <html:span class="No-Break">&#13;
      the following:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p class="callout-heading">&#13;
     Important note&#13;
    </html:p>&#13;
    <html:p class="callout">&#13;
     One important consideration with using a hosted service such as&#13;
     <html:code class="literal">&#13;
      LlamaParse&#13;
     </html:code>&#13;
     is data privacy. Before submitting your proprietary data through the API, be sure to carefully review their privacy policy to ensure it aligns with your data protection requirements. While the service offers powerful parsing capabilities, it’s crucial to safeguard&#13;
     <html:span class="No-Break">&#13;
      sensitive information.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Keep in mind that this is a paid service. The great news, however, is that you can take advantage of their generous&#13;
     <html:strong class="bold">&#13;
      free tier&#13;
     </html:strong>&#13;
     . For higher volume needs, the current pricing can be found on the website. If you want to unlock the full potential of&#13;
     <html:code class="literal">&#13;
      LlamaParse&#13;
     </html:code>&#13;
     to build advanced&#13;
     <html:a id="_idIndexMarker224">&#13;
     </html:a>&#13;
     document retrieval systems or deploy it on your private cloud for maximal data security, that option is available&#13;
     <html:span class="No-Break">&#13;
      as well.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     For professional, production-ready applications,&#13;
     <html:code class="literal">&#13;
      LlamaParse&#13;
     </html:code>&#13;
     is a powerful tool that puts you in full control of parsing your data to maximize the quality of your knowledge base and&#13;
     <html:span class="No-Break">&#13;
      RAG applications.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Now that we’ve got the data, let’s make it easier to handle by breaking it down into&#13;
     <html:span class="No-Break">&#13;
      smaller pieces.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor077">&#13;
    </html:a>&#13;
   </html:div>&#13;
  </html:div>&#13;
 </html:body>&#13;
</html:html>
<html:html>&#13;
 <html:head>&#13;
  <html:title>&#13;
   Parsing the documents into nodes&#13;
  </html:title>&#13;
 </html:head>&#13;
 <html:body>&#13;
  <html:div class="epub-source">&#13;
   <html:h1 id="_idParaDest-78">&#13;
    Parsing the documents into nodes&#13;
   </html:h1>&#13;
   <html:div id="_idContainer039">&#13;
    from llama_index.core.node_parser import &lt;&#13;
    for node in nodes:&#13;
    print(f"Metadata {node.metadata} \nText: {node.text}")&#13;
    splitter = TokenTextSplitter(&#13;
    chunk_size = 70,&#13;
    chunk_overlap = 2,&#13;
    separator = " ",&#13;
    backup_separators = [".", "!", "?"]&#13;
)&#13;
nodes = splitter.get_nodes_from_documents(document)&#13;
    pip install tree_sitter&#13;
pip install tree_sitter_languages&#13;
    code_splitter = CodeSplitter.from_defaults(&#13;
    language = 'python',&#13;
    chunk_lines = 5,&#13;
    chunk_lines_overlap = 2,&#13;
    max_chars = 150&#13;
)&#13;
nodes = code_splitter.get_nodes_from_documents(document)&#13;
    parser = SentenceWindowNodeParser.from_defaults(&#13;
    window_size=2,&#13;
    window_metadata_key="text_window",&#13;
    original_text_metadata_key="original_sentence"&#13;
)&#13;
nodes = parser.get_nodes_from_documents(document)&#13;
    pip install langchain&#13;
    from langchain.text_splitter import CharacterTextSplitter&#13;
from llama_index.core.node_parser import LangchainNodeParser&#13;
parser = LangchainNodeParser(CharacterTextSplitter())&#13;
nodes = parser.get_nodes_from_documents(document)&#13;
    parser = SimpleFileNodeParser()&#13;
nodes = parser.get_nodes_from_documents(documents)&#13;
    my_tags = ["&#13;
    parser = MarkdownNodeParser.from_defaults()&#13;
nodes = parser.get_nodes_from_documents(document)&#13;
    json_parser = JSONNodeParser.from_defaults()&#13;
nodes = json_parser.get_nodes_from_documents(document)&#13;
    hierarchical_parser = HierarchicalNodeParser.from_defaults(&#13;
    chunk_sizes=[128, 64, 32],&#13;
    chunk_overlap=0,&#13;
)&#13;
nodes = hierarchical_parser.get_nodes_from_documents(document)&#13;
    node_parser = SentenceWindowNodeParser.from_defaults(&#13;
  include_prev_next_rel=True&#13;
)&#13;
    node1.relationships[PREVIOUS] = RelatedNodeInfo(node_id=node0.node_id)&#13;
    node2.relationships[NEXT] = RelatedNodeInfo(node_id=node3.node_id)&#13;
    <html:p>&#13;
     As we saw in&#13;
     <html:a>&#13;
      <html:span class="No-Break">&#13;
       <html:em class="italic">&#13;
        Chapter 3&#13;
       </html:em>&#13;
      </html:span>&#13;
     </html:a>&#13;
     ,&#13;
     <html:em class="italic">&#13;
      Kickstarting Your Journey with LlamaIndex&#13;
     </html:em>&#13;
     , the next step is to split the documents into nodes. In many cases, documents tend to be very large, so we need to break&#13;
     <html:a id="_idIndexMarker225">&#13;
     </html:a>&#13;
     them down into smaller units called nodes. Working at this granular level allows for better handling of our content while maintaining an accurate&#13;
     <html:a id="_idIndexMarker226">&#13;
     </html:a>&#13;
     representation of its internal structure. This is the basic mechanism that LlamaIndex uses to manage our proprietary data content&#13;
     <html:span class="No-Break">&#13;
      more easily.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Now is the&#13;
     <html:a id="_idIndexMarker227">&#13;
     </html:a>&#13;
     time to understand how nodes can be generated in LlamaIndex and what customization opportunities we have along the way. In the previous chapter, we talked about how to manually create nodes. But that was merely a way to simplify the explanation and help you better understand their mechanics. In a real application, most likely, we will want to use some automatic methods to generate them from the ingested documents. So, that’s what we’ll focus on&#13;
     <html:span class="No-Break">&#13;
      going forward.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     In this section, we will discover different ways of chunking a document. We’ll start by understanding&#13;
     <html:a id="_idIndexMarker228">&#13;
     </html:a>&#13;
     simple&#13;
     <html:strong class="bold">&#13;
      text splitters&#13;
     </html:strong>&#13;
     – which operate on raw text – and then we’ll cover&#13;
     <html:a id="_idIndexMarker229">&#13;
     </html:a>&#13;
     the more advanced&#13;
     <html:strong class="bold">&#13;
      node parsers&#13;
     </html:strong>&#13;
     – which are capable of interpreting more complex formats and following the document structure when extracting&#13;
     <html:span class="No-Break">&#13;
      the nodes.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor078">&#13;
    </html:a>&#13;
    <html:h2 id="_idParaDest-79">&#13;
     Understanding the simple text splitters&#13;
    </html:h2>&#13;
    <html:p>&#13;
     <html:strong class="bold">&#13;
      Text splitters&#13;
     </html:strong>&#13;
     <html:em class="italic">&#13;
      break down&#13;
     </html:em>&#13;
     the document into smaller pieces operating at the raw text level. They are useful when the content has a&#13;
     <html:em class="italic">&#13;
      flat&#13;
     </html:em>&#13;
     structure and does not come in a&#13;
     <html:span class="No-Break">&#13;
      specific format.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     To run the&#13;
     <html:a id="_idIndexMarker230">&#13;
     </html:a>&#13;
     following examples, make sure you add the necessary imports and the document reading logic, using&#13;
     <html:code class="literal">&#13;
      FlatReader&#13;
     </html:code>&#13;
     , at the beginning of your code for&#13;
     <html:span class="No-Break">&#13;
      all examples:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Also, if you want to see the actual nodes generated by the code, you can add something like this&#13;
     <html:em class="italic">&#13;
      after&#13;
     </html:em>&#13;
     running&#13;
     <html:span class="No-Break">&#13;
      the parsers:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Alright. Let’s see what’s in store in the&#13;
     <html:em class="italic">&#13;
      text&#13;
     </html:em>&#13;
     <html:span class="No-Break">&#13;
      <html:em class="italic">&#13;
       splitter&#13;
      </html:em>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      category.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:h3>&#13;
     SentenceSplitter&#13;
    </html:h3>&#13;
    <html:p>&#13;
     This one splits text&#13;
     <html:a id="_idIndexMarker231">&#13;
     </html:a>&#13;
     while maintaining sentence boundaries, providing&#13;
     <html:a id="_idIndexMarker232">&#13;
     </html:a>&#13;
     nodes containing groups of sentences. You saw an example of using this parser in&#13;
     <html:a>&#13;
      <html:span class="No-Break">&#13;
       <html:em class="italic">&#13;
        Chapter 3&#13;
       </html:em>&#13;
      </html:span>&#13;
     </html:a>&#13;
     ,&#13;
     <html:em class="italic">&#13;
      Kickstarting Your Journey with LlamaIndex&#13;
     </html:em>&#13;
     , in the&#13;
     <html:em class="italic">&#13;
      Automatically extracting nodes from documents using&#13;
     </html:em>&#13;
     <html:span class="No-Break">&#13;
      <html:em class="italic">&#13;
       splitters&#13;
      </html:em>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      section.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:h3>&#13;
     TokenTextSplitter&#13;
    </html:h3>&#13;
    <html:p>&#13;
     This splitter&#13;
     <html:a id="_idIndexMarker233">&#13;
     </html:a>&#13;
     breaks down text while respecting sentence&#13;
     <html:a id="_idIndexMarker234">&#13;
     </html:a>&#13;
     boundaries to create suitable nodes for further natural language processing. It operates at the&#13;
     <html:span class="No-Break">&#13;
      token level.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     A typical usage in code would look&#13;
     <html:span class="No-Break">&#13;
      like this:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Here are some notes on the parameters of&#13;
     <html:span class="No-Break">&#13;
      this splitter:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:ul>&#13;
     <html:li>&#13;
      <html:code class="literal">&#13;
       chunk_size&#13;
      </html:code>&#13;
      : This sets the maximum number of tokens for&#13;
      <html:span class="No-Break">&#13;
       each chunk&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:code class="literal">&#13;
       chunk_overlap&#13;
      </html:code>&#13;
      : This defines the overlap in tokens between&#13;
      <html:span class="No-Break">&#13;
       consecutive chunks&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:code class="literal">&#13;
       separator&#13;
      </html:code>&#13;
      : This is used to determine the primary&#13;
      <html:span class="No-Break">&#13;
       token boundary&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:code class="literal">&#13;
       backup_separators&#13;
      </html:code>&#13;
      : These can be used for additional splitting points if the primary separator doesn’t split the&#13;
      <html:span class="No-Break">&#13;
       text sufficiently&#13;
      </html:span>&#13;
     </html:li>&#13;
    </html:ul>&#13;
    <html:h3>&#13;
     CodeSplitter&#13;
    </html:h3>&#13;
    <html:p>&#13;
     This smart&#13;
     <html:a id="_idIndexMarker235">&#13;
     </html:a>&#13;
     splitter knows how to interpret source code. It splits text based on&#13;
     <html:a id="_idIndexMarker236">&#13;
     </html:a>&#13;
     programming language and is ideal for managing technical documentation or source code. Before running the example, make sure you install the&#13;
     <html:span class="No-Break">&#13;
      necessary libraries:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Let’s have a look at an example of how to use this splitter in&#13;
     <html:span class="No-Break">&#13;
      your code:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     As you&#13;
     <html:a id="_idIndexMarker237">&#13;
     </html:a>&#13;
     can see, there are several parameters you can tune with&#13;
     <html:a id="_idIndexMarker238">&#13;
     </html:a>&#13;
     <html:span class="No-Break">&#13;
      this splitter:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:ul>&#13;
     <html:li>&#13;
      <html:code class="literal">&#13;
       language&#13;
      </html:code>&#13;
      : This specifies the language of&#13;
      <html:span class="No-Break">&#13;
       the code&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:code class="literal">&#13;
       chunk_lines&#13;
      </html:code>&#13;
      : This defines the number of lines&#13;
      <html:span class="No-Break">&#13;
       per chunk&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:code class="literal">&#13;
       chunk_lines_overlap&#13;
      </html:code>&#13;
      : This defines the lines overlap&#13;
      <html:span class="No-Break">&#13;
       between chunks&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:code class="literal">&#13;
       max_chars&#13;
      </html:code>&#13;
      : This defines the maximum characters&#13;
      <html:span class="No-Break">&#13;
       per chunk&#13;
      </html:span>&#13;
     </html:li>&#13;
    </html:ul>&#13;
    <html:p class="callout-heading">&#13;
     Quick side note on CodeSplitter&#13;
    </html:p>&#13;
    <html:p class="callout">&#13;
     This splitter is&#13;
     <html:a id="_idIndexMarker239">&#13;
     </html:a>&#13;
     cleverly built around a concept called&#13;
     <html:strong class="bold">&#13;
      abstract syntax tree&#13;
     </html:strong>&#13;
     (&#13;
     <html:strong class="bold">&#13;
      AST&#13;
     </html:strong>&#13;
     ). An AST is a key idea in computer science that’s mainly used in creating programs that translate or interpret code. It’s like a branching diagram that shows the basic structure of the code written in a programming language. Each point on the diagram represents a different part or piece of the code. Because of this splitter’s awareness of AST, when you’re splitting code, you keep related statements together as much as possible, which is vital when you need to maintain the logical flow of code to understand or process&#13;
     <html:span class="No-Break">&#13;
      it later.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor079">&#13;
    </html:a>&#13;
    <html:h2 id="_idParaDest-80">&#13;
     Using more advanced node parsers&#13;
    </html:h2>&#13;
    <html:p>&#13;
     Text splitters&#13;
     <html:a id="_idIndexMarker240">&#13;
     </html:a>&#13;
     only provide basic logic for breaking down text, mostly by using simple rules. We also have more advanced tools for chunking text into nodes. These are designed to process various standard file formats or can be used for more specific types&#13;
     <html:span class="No-Break">&#13;
      of content.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Before we continue, keep in mind that all the node parsers that we will discuss here are derived from the generic class called&#13;
     <html:code class="literal">&#13;
      NodeParser&#13;
     </html:code>&#13;
     . Each parser has various parameters that can be&#13;
     <html:a id="_idIndexMarker241">&#13;
     </html:a>&#13;
     configured according to the use case, but at the base, three common elements can be customized for&#13;
     <html:span class="No-Break">&#13;
      all parsers:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:ul>&#13;
     <html:li>&#13;
      <html:code class="literal">&#13;
       include_metadata&#13;
      </html:code>&#13;
      : This determines whether the parser should take into account the metadata or not. By default, this is set&#13;
      <html:span class="No-Break">&#13;
       to&#13;
      </html:span>&#13;
      <html:span class="No-Break">&#13;
       <html:code class="literal">&#13;
        True&#13;
       </html:code>&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:code class="literal">&#13;
       Include_prev_next_rel&#13;
      </html:code>&#13;
      : This determines whether the parser should automatically include&#13;
      <html:strong class="bold">&#13;
       prev/next&#13;
      </html:strong>&#13;
      type relationships between nodes. Again, the default value&#13;
      <html:span class="No-Break">&#13;
       is&#13;
      </html:span>&#13;
      <html:span class="No-Break">&#13;
       <html:code class="literal">&#13;
        True&#13;
       </html:code>&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:code class="literal">&#13;
       Callback_manager&#13;
      </html:code>&#13;
      : This can&#13;
      <html:a id="_idIndexMarker242">&#13;
      </html:a>&#13;
      be used to define a specific&#13;
      <html:strong class="bold">&#13;
       callback function&#13;
      </html:strong>&#13;
      . These functions can be used for debugging, tracing, and cost analysis, among other functions. We will talk more about them in&#13;
      <html:a>&#13;
       <html:span class="No-Break">&#13;
        <html:em class="italic">&#13;
         Chapter 10&#13;
        </html:em>&#13;
       </html:span>&#13;
      </html:a>&#13;
      ,&#13;
      <html:em class="italic">&#13;
       Prompt Engineering Guidelines and&#13;
      </html:em>&#13;
      <html:span class="No-Break">&#13;
       <html:em class="italic">&#13;
        Best Practices&#13;
       </html:em>&#13;
      </html:span>&#13;
     </html:li>&#13;
    </html:ul>&#13;
    <html:p>&#13;
     Apart from these three general options, each parser provides specific parameters to customize. You can get a complete list of configurable parameters for each parser by consulting the&#13;
     <html:span class="No-Break">&#13;
      official documentation.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Let’s explore the node parsers available&#13;
     <html:span class="No-Break">&#13;
      in LlamaIndex.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:h3>&#13;
     SentenceWindowNodeParser&#13;
    </html:h3>&#13;
    <html:p>&#13;
     Based on the simple&#13;
     <html:strong class="bold">&#13;
      SentenceSplitter&#13;
     </html:strong>&#13;
     , this parser&#13;
     <html:a id="_idIndexMarker243">&#13;
     </html:a>&#13;
     splits text into individual&#13;
     <html:a id="_idIndexMarker244">&#13;
     </html:a>&#13;
     sentences and also&#13;
     <html:a id="_idIndexMarker245">&#13;
     </html:a>&#13;
     includes a&#13;
     <html:em class="italic">&#13;
      window&#13;
     </html:em>&#13;
     of surrounding sentences in the metadata of each node. It is useful for building more context around each sentence. During the querying process, that context will be fed into the LLM and allow for better responses. We can use it&#13;
     <html:span class="No-Break">&#13;
      like this:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     For this&#13;
     <html:a id="_idIndexMarker246">&#13;
     </html:a>&#13;
     parser, three specific parameters&#13;
     <html:a id="_idIndexMarker247">&#13;
     </html:a>&#13;
     can&#13;
     <html:span class="No-Break">&#13;
      be customized:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:ul>&#13;
     <html:li>&#13;
      <html:code class="literal">&#13;
       Window_size&#13;
      </html:code>&#13;
      : This defines the number of sentences on each side to include in&#13;
      <html:span class="No-Break">&#13;
       the window&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:code class="literal">&#13;
       window_metadata_key&#13;
      </html:code>&#13;
      : This defines the metadata key for the&#13;
      <html:span class="No-Break">&#13;
       window sentences&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:code class="literal">&#13;
       original_text_metadata_key&#13;
      </html:code>&#13;
      : This defines the metadata key for the&#13;
      <html:span class="No-Break">&#13;
       original sentence&#13;
      </html:span>&#13;
     </html:li>&#13;
    </html:ul>&#13;
    <html:h3>&#13;
     LangchainNodeParser&#13;
    </html:h3>&#13;
    <html:p>&#13;
     If you prefer&#13;
     <html:a id="_idIndexMarker248">&#13;
     </html:a>&#13;
     using the LangChain splitters, this parser allows&#13;
     <html:a id="_idIndexMarker249">&#13;
     </html:a>&#13;
     using any text splitter from the Langchain collection, extending the parsing options offered&#13;
     <html:span class="No-Break">&#13;
      by LlamaIndex.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     As a prerequisite for the next example, you’ll have to install the&#13;
     <html:span class="No-Break">&#13;
      <html:code class="literal">&#13;
       LangChain&#13;
      </html:code>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      library:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Here’s a simple example of how to use&#13;
     <html:span class="No-Break">&#13;
      this parser:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p class="callout-heading">&#13;
     A quick note on LangChain&#13;
    </html:p>&#13;
    <html:p class="callout">&#13;
     The LangChain framework is similar in purpose to LlamaIndex and provides a versatile toolkit specialized&#13;
     <html:a id="_idIndexMarker250">&#13;
     </html:a>&#13;
     in advanced natural language processing capabilities. Its collection of text segmentation, summarization, and language understanding models assist in splitting and digesting textual data into coherent chunks ready for indexing in a similar way to LlamaIndex. When dealing with large data sources requiring nuanced linguistic analysis, LangChain empowers users to finely control the breakdown and ingestion of text - ensuring context and clarity are retained for downstream retrieval and querying. As you can see, the two can complement each other in a RAG scenario. Want to know more? Check&#13;
     <html:span class="No-Break">&#13;
      out&#13;
     </html:span>&#13;
     <html:a>&#13;
      <html:span class="No-Break">&#13;
       https://www.langchain.com/&#13;
      </html:span>&#13;
     </html:a>&#13;
     <html:span class="No-Break">&#13;
      .&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Let’s see what other parsers we&#13;
     <html:span class="No-Break">&#13;
      have available.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:h3>&#13;
     SimpleFileNodeParser&#13;
    </html:h3>&#13;
    <html:p>&#13;
     This one automatically decides which of the following three node parsers should be used based&#13;
     <html:a id="_idIndexMarker251">&#13;
     </html:a>&#13;
     on file types. It can automatically handle these file formats&#13;
     <html:a id="_idIndexMarker252">&#13;
     </html:a>&#13;
     and transform them into nodes, simplifying the process of interacting with various types&#13;
     <html:span class="No-Break">&#13;
      of content:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     You can simply rely on&#13;
     <html:code class="literal">&#13;
      FlatReader&#13;
     </html:code>&#13;
     to load the file into your&#13;
     <html:code class="literal">&#13;
      Document&#13;
     </html:code>&#13;
     object;&#13;
     <html:code class="literal">&#13;
      SimpleFileNodeParser&#13;
     </html:code>&#13;
     will know what to do&#13;
     <html:span class="No-Break">&#13;
      from there.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:h3>&#13;
     HTMLNodeParser&#13;
    </html:h3>&#13;
    <html:p>&#13;
     This parser uses&#13;
     <html:strong class="bold">&#13;
      Beautiful Soup&#13;
     </html:strong>&#13;
     to parse HTML files and convert them into nodes based on&#13;
     <html:a id="_idIndexMarker253">&#13;
     </html:a>&#13;
     selected HTML tags. This parser simplifies&#13;
     <html:a id="_idIndexMarker254">&#13;
     </html:a>&#13;
     the HTML file by extracting text from standard text elements and merging adjacent nodes of the same type. The parser can be used&#13;
     <html:span class="No-Break">&#13;
      like this:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     As you&#13;
     <html:a id="_idIndexMarker255">&#13;
     </html:a>&#13;
     can see, you have the option to customize&#13;
     <html:a id="_idIndexMarker256">&#13;
     </html:a>&#13;
     the HTML&#13;
     <html:code class="literal">&#13;
      tags&#13;
     </html:code>&#13;
     from where you want to&#13;
     <html:span class="No-Break">&#13;
      retrieve content.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:h3>&#13;
     MarkdownNodeParser&#13;
    </html:h3>&#13;
    <html:p>&#13;
     This parser&#13;
     <html:a id="_idIndexMarker257">&#13;
     </html:a>&#13;
     processes raw&#13;
     <html:em class="italic">&#13;
      markdown&#13;
     </html:em>&#13;
     text and generates nodes reflecting its structure and content. The markdown node parser divides the content into&#13;
     <html:a id="_idIndexMarker258">&#13;
     </html:a>&#13;
     nodes for each header encountered in the file and incorporates the header hierarchy into the metadata. Here’s how to&#13;
     <html:span class="No-Break">&#13;
      use&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      <html:code class="literal">&#13;
       MarkdownNodeParser&#13;
      </html:code>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      :&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:h3>&#13;
     JSONNodeParser&#13;
    </html:h3>&#13;
    <html:p>&#13;
     This parser&#13;
     <html:a id="_idIndexMarker259">&#13;
     </html:a>&#13;
     is specialized in processing and querying&#13;
     <html:a id="_idIndexMarker260">&#13;
     </html:a>&#13;
     structured data in JSON format. In a similar way to the Markdown parser, the JSON parser can be used&#13;
     <html:span class="No-Break">&#13;
      like this:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor080">&#13;
    </html:a>&#13;
    <html:h2 id="_idParaDest-81">&#13;
     Using relational parsers&#13;
    </html:h2>&#13;
    <html:p>&#13;
     <html:strong class="bold">&#13;
      Relational parsers&#13;
     </html:strong>&#13;
     parse&#13;
     <html:a id="_idIndexMarker261">&#13;
     </html:a>&#13;
     information into nodes that are linked to&#13;
     <html:a id="_idIndexMarker262">&#13;
     </html:a>&#13;
     each other through relationships. Relationships add a whole new dimension to our data and allow for more advanced retrieval techniques in our&#13;
     <html:span class="No-Break">&#13;
      RAG workflow.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:h3>&#13;
     HierarchicalNodeParser&#13;
    </html:h3>&#13;
    <html:p>&#13;
     This parser organizes the nodes into hierarchies across multiple levels. It will generate a hierarchy&#13;
     <html:a id="_idIndexMarker263">&#13;
     </html:a>&#13;
     of nodes, starting with top-level nodes with larger section sizes, down to child nodes with smaller section sizes, where each&#13;
     <html:a id="_idIndexMarker264">&#13;
     </html:a>&#13;
     child node has a parent node with a larger section size (&#13;
     <html:span class="No-Break">&#13;
      <html:em class="italic">&#13;
       Figure 4&#13;
      </html:em>&#13;
     </html:span>&#13;
     <html:em class="italic">&#13;
      .1&#13;
     </html:em>&#13;
     ). By default, the parser uses&#13;
     <html:code class="literal">&#13;
      SentenceSplitter&#13;
     </html:code>&#13;
     to chunk text. The node hierarchy looks&#13;
     <html:span class="No-Break">&#13;
      like this:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:ul>&#13;
     <html:li>&#13;
      <html:em class="italic">&#13;
       Level 1&#13;
      </html:em>&#13;
      : Section&#13;
      <html:span class="No-Break">&#13;
       size 2,048&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:em class="italic">&#13;
       Level 2&#13;
      </html:em>&#13;
      : Section&#13;
      <html:span class="No-Break">&#13;
       size 512&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:em class="italic">&#13;
       Level 3&#13;
      </html:em>&#13;
      : Section&#13;
      <html:span class="No-Break">&#13;
       size 128&#13;
      </html:span>&#13;
     </html:li>&#13;
    </html:ul>&#13;
    <html:p>&#13;
     The top-level nodes, with larger sections, can provide high-level summaries, while the lower nodes can allow for a more detailed analysis of text sections. Have a look at&#13;
     <html:span class="No-Break">&#13;
      <html:em class="italic">&#13;
       Figure 4&#13;
      </html:em>&#13;
     </html:span>&#13;
     <html:em class="italic">&#13;
      .2&#13;
     </html:em>&#13;
     for a visual representation of&#13;
     <html:span class="No-Break">&#13;
      this concept:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:div>&#13;
     <html:div class="IMG---Figure" id="_idContainer036">&#13;
      <html:img src="../Images/B21861_04_2.jpg"/>&#13;
     </html:div>&#13;
    </html:div>&#13;
    <html:p class="IMG---Caption" lang="en-US">&#13;
     Figure 4.2 – Hierarchical nodes of 2,048, 512, and 128 chunk sizes&#13;
    </html:p>&#13;
    <html:p>&#13;
     In this way, the different node levels can be used to adjust the accuracy and depth of search results, allowing users to find information at different granularity levels. Here’s an example of how to use this parser in&#13;
     <html:span class="No-Break">&#13;
      your code:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     There&#13;
     <html:a id="_idIndexMarker265">&#13;
     </html:a>&#13;
     are two&#13;
     <html:a id="_idIndexMarker266">&#13;
     </html:a>&#13;
     specific parameters to customize for&#13;
     <html:span class="No-Break">&#13;
      this parser:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:ul>&#13;
     <html:li>&#13;
      <html:code class="literal">&#13;
       chunk_sizes&#13;
      </html:code>&#13;
      : The values in this list define your hierarchy levels based on&#13;
      <html:span class="No-Break">&#13;
       content size&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:code class="literal">&#13;
       chunk_overlap&#13;
      </html:code>&#13;
      : This defines the overlap size&#13;
      <html:span class="No-Break">&#13;
       between chunks&#13;
      </html:span>&#13;
     </html:li>&#13;
    </html:ul>&#13;
    <html:h3>&#13;
     UnstructuredElementNodeParser&#13;
    </html:h3>&#13;
    <html:p>&#13;
     I left this one last because it is used for more special situations. Sometimes, our documents&#13;
     <html:a id="_idIndexMarker267">&#13;
     </html:a>&#13;
     may include a mix of text and data tables, which can make parsing inefficient by&#13;
     <html:span class="No-Break">&#13;
      conventional methods.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     This parser&#13;
     <html:a id="_idIndexMarker268">&#13;
     </html:a>&#13;
     can process and split these documents into interpretable nodes, distinguishing between text sections and other embedded structures such as tables. We’ll talk about it in more detail toward the end of&#13;
     <html:span class="No-Break">&#13;
      this chapter.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor081">&#13;
    </html:a>&#13;
    <html:h2 id="_idParaDest-82">&#13;
     Confused about node parsers and text splitters?&#13;
    </html:h2>&#13;
    <html:p>&#13;
     You may have noticed that I use the two terms quite loosely. Categorizing parsing modules into&#13;
     <html:a id="_idIndexMarker269">&#13;
     </html:a>&#13;
     these two groups might initially cause some confusion. To simplify, a node&#13;
     <html:a id="_idIndexMarker270">&#13;
     </html:a>&#13;
     parser is a more sophisticated mechanism than a simple splitter. While both serve the same basic function and operate at different levels of complexity, they differ in&#13;
     <html:span class="No-Break">&#13;
      their implementations.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Text splitters such as&#13;
     <html:code class="literal">&#13;
      SentenceSplitter&#13;
     </html:code>&#13;
     can divide long flat texts into nodes, based on certain rules or limitations, such as&#13;
     <html:strong class="bold">&#13;
      chunk_size&#13;
     </html:strong>&#13;
     or&#13;
     <html:strong class="bold">&#13;
      chunk_overlap&#13;
     </html:strong>&#13;
     . The nodes could represent lines, paragraphs, or sentences, and may also include additional metadata or links to the&#13;
     <html:span class="No-Break">&#13;
      original document.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Node parsers&#13;
     <html:a id="_idIndexMarker271">&#13;
     </html:a>&#13;
     are more sophisticated and can involve additional data&#13;
     <html:a id="_idIndexMarker272">&#13;
     </html:a>&#13;
     processing logic. Beyond simply dividing text into nodes, they can perform extra tasks, such as analyzing the structure of HTML or JSON files and producing nodes enriched with&#13;
     <html:span class="No-Break">&#13;
      contextual information.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor082">&#13;
    </html:a>&#13;
    <html:h2 id="_idParaDest-83">&#13;
     Understanding chunk_size and chunk_overlap&#13;
    </html:h2>&#13;
    <html:p>&#13;
     As you have probably understood by now, text splitters are a basic but important component. They&#13;
     <html:a id="_idIndexMarker273">&#13;
     </html:a>&#13;
     control how text in documents gets split into nodes during parsing. For each text splitter type, LlamaIndex provides several parameters to customize the&#13;
     <html:a id="_idIndexMarker274">&#13;
     </html:a>&#13;
     text&#13;
     <html:span class="No-Break">&#13;
      splitting behavior.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Probably two of the most important parameters for a text splitter are&#13;
     <html:code class="literal">&#13;
      chunk_size&#13;
     </html:code>&#13;
     and&#13;
     <html:code class="literal">&#13;
      chunk_overlap&#13;
     </html:code>&#13;
     . The text splitters themselves, such as&#13;
     <html:code class="literal">&#13;
      SentenceSplitter&#13;
     </html:code>&#13;
     ,&#13;
     <html:code class="literal">&#13;
      TokenTextSplitter&#13;
     </html:code>&#13;
     ,&#13;
     <html:code class="literal">&#13;
      TextSplitter&#13;
     </html:code>&#13;
     , and others, take in the&#13;
     <html:code class="literal">&#13;
      chunk_size&#13;
     </html:code>&#13;
     and&#13;
     <html:code class="literal">&#13;
      chunk_overlap&#13;
     </html:code>&#13;
     arguments to control how they break text into smaller chunks during node creation.&#13;
     <html:code class="literal">&#13;
      chunk_size&#13;
     </html:code>&#13;
     controls the maximum length of text chunks in nodes. This is useful for ensuring nodes don’t take long for the LLM to process. Note that in LlamaIndex, the default&#13;
     <html:code class="literal">&#13;
      chunk_size&#13;
     </html:code>&#13;
     is 1,024, while the default&#13;
     <html:code class="literal">&#13;
      chunk_overlap&#13;
     </html:code>&#13;
     <html:span class="No-Break">&#13;
      is 20.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     <html:strong class="bold">&#13;
      chunk size&#13;
     </html:strong>&#13;
     is an important setting when building an RAG system. If chunks are too small, important context may be lost and the quality of the LLM response will be lower. On the other hand, large chunks increase the size of the prompts, increasing both computational cost and response generation time. An experimental approach was used when the default values were selected for&#13;
     <html:span class="No-Break">&#13;
      LlamaIndex:&#13;
     </html:span>&#13;
     <html:a>&#13;
      <html:span class="No-Break">&#13;
       https://blog.llamaindex.ai/evaluating-the-ideal-chunk-size-for-a-rag-system-using-llamaindex-6207e5d3fec5&#13;
      </html:span>&#13;
     </html:a>&#13;
     <html:span class="No-Break">&#13;
      .&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     <html:code class="literal">&#13;
      chunk_overlap&#13;
     </html:code>&#13;
     creates overlapping nodes by re-including some tokens from the previous Node. This helps provide context so that the LLM can understand the continuity of ideas when processing&#13;
     <html:span class="No-Break">&#13;
      adjacent Nodes.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     <html:span class="No-Break">&#13;
      <html:em class="italic">&#13;
       Figure 4&#13;
      </html:em>&#13;
     </html:span>&#13;
     <html:em class="italic">&#13;
      .3&#13;
     </html:em>&#13;
     provides a visual representation of&#13;
     <html:span class="No-Break">&#13;
      this concept:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:div>&#13;
     <html:div class="IMG---Figure" id="_idContainer037">&#13;
      <html:img src="../Images/B21861_04_3.jpg"/>&#13;
     </html:div>&#13;
    </html:div>&#13;
    <html:p class="IMG---Caption" lang="en-US">&#13;
     Figure 4.3 – chunk_size and chunk_overlap explained&#13;
    </html:p>&#13;
    <html:p>&#13;
     The concept&#13;
     <html:a id="_idIndexMarker275">&#13;
     </html:a>&#13;
     is similar to the way&#13;
     <html:code class="literal">&#13;
      SentenceWindowNodeParser&#13;
     </html:code>&#13;
     works – that is, it&#13;
     <html:a id="_idIndexMarker276">&#13;
     </html:a>&#13;
     extracts a&#13;
     <html:em class="italic">&#13;
      window&#13;
     </html:em>&#13;
     of context for each sentence. For example, with&#13;
     <html:code class="literal">&#13;
      chunk_size=100&#13;
     </html:code>&#13;
     and&#13;
     <html:code class="literal">&#13;
      chunk_overlap=10&#13;
     </html:code>&#13;
     , let’s say we had the&#13;
     <html:span class="No-Break">&#13;
      following text:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     <html:em class="italic">&#13;
      Gardening is not only a relaxing hobby but also an art form. Cultivating plants, designing landscapes, and nurturing nature bring a sense of accomplishment. Many find it therapeutic and rewarding, especially when they see their&#13;
     </html:em>&#13;
     <html:span class="No-Break">&#13;
      <html:em class="italic">&#13;
       garden flourish&#13;
      </html:em>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      .&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     It would get split into the&#13;
     <html:span class="No-Break">&#13;
      following areas:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:ul>&#13;
     <html:li>&#13;
      <html:em class="italic">&#13;
       Node 1 (first 100 characters)&#13;
      </html:em>&#13;
      : “Gardening is not only a relaxing hobby but also an art form. Cultivating plants, designing&#13;
      <html:span class="No-Break">&#13;
       landscapes, an”&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:em class="italic">&#13;
       Node 2 (starts from the 75th character, next 100 characters)&#13;
      </html:em>&#13;
      : “designing landscapes, and nurturing nature bring a sense of accomplishment. Many find it therapeutic&#13;
      <html:span class="No-Break">&#13;
       and re”&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:em class="italic">&#13;
       Node 3 (starts from the 150th character to the end of the text)&#13;
      </html:em>&#13;
      : “Many find it therapeutic and rewarding, especially when they see their&#13;
      <html:span class="No-Break">&#13;
       garden flourish.”&#13;
      </html:span>&#13;
     </html:li>&#13;
    </html:ul>&#13;
    <html:p>&#13;
     In this setup, the overlap between node 1 and node 2 is “&#13;
     <html:code class="literal">&#13;
      designing&#13;
     </html:code>&#13;
     landscapes, an,” whereas the overlap between node 2 and node 3 is “Many find it therapeutic&#13;
     <html:span class="No-Break">&#13;
      and re.”&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     These overlaps mean that one node re-includes parts of the previous node. This mechanism ensures continuity and context between the chunks, making each part more meaningful when&#13;
     <html:a id="_idIndexMarker277">&#13;
     </html:a>&#13;
     read in sequence. Of course, choosing the right values for&#13;
     <html:a id="_idIndexMarker278">&#13;
     </html:a>&#13;
     these two parameters is very important. The biggest impact will be on creating vector indexes. We’ll talk about them later, during&#13;
     <html:a>&#13;
      <html:span class="No-Break">&#13;
       <html:em class="italic">&#13;
        Chapter 5&#13;
       </html:em>&#13;
      </html:span>&#13;
     </html:a>&#13;
     ,&#13;
     <html:em class="italic">&#13;
      Indexing&#13;
     </html:em>&#13;
     <html:span class="No-Break">&#13;
      <html:em class="italic">&#13;
       with LlamaIndex&#13;
      </html:em>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      .&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Next, let’s have a quick overview of&#13;
     <html:span class="No-Break">&#13;
      node relationships.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor083">&#13;
    </html:a>&#13;
    <html:h2 id="_idParaDest-84">&#13;
     Including relationships with include_prev_next_rel&#13;
    </html:h2>&#13;
    <html:p>&#13;
     Let’s talk a bit&#13;
     <html:a id="_idIndexMarker279">&#13;
     </html:a>&#13;
     about another important parameter that can dictate the behavior of our parsers: the&#13;
     <html:code class="literal">&#13;
      include_prev_next_rel&#13;
     </html:code>&#13;
     option. When set to&#13;
     <html:code class="literal">&#13;
      True&#13;
     </html:code>&#13;
     , this option makes the parser automatically add&#13;
     <html:code class="literal">&#13;
      NEXT&#13;
     </html:code>&#13;
     and&#13;
     <html:code class="literal">&#13;
      PREVIOUS&#13;
     </html:code>&#13;
     relationships between consecutive nodes. Here’s&#13;
     <html:span class="No-Break">&#13;
      an example:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     This helps capture the sequencing between nodes. Then, later when querying, you can optionally retrieve previous or next nodes for more context using features such as&#13;
     <html:code class="literal">&#13;
      PrevNextNodePostprocessor&#13;
     </html:code>&#13;
     . More on that in&#13;
     <html:a>&#13;
      <html:span class="No-Break">&#13;
       <html:em class="italic">&#13;
        Chapter 6&#13;
       </html:em>&#13;
      </html:span>&#13;
     </html:a>&#13;
     ,&#13;
     <html:em class="italic">&#13;
      Querying Our Data, Part 1 –&#13;
     </html:em>&#13;
     <html:span class="No-Break">&#13;
      <html:em class="italic">&#13;
       Context Retrieval&#13;
      </html:em>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      .&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     The relationships get added to the&#13;
     <html:code class="literal">&#13;
      .relationships&#13;
     </html:code>&#13;
     dictionary on&#13;
     <html:span class="No-Break">&#13;
      each node.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     So, node 1 would now be&#13;
     <html:span class="No-Break">&#13;
      as follows:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Node 2 would be&#13;
     <html:span class="No-Break">&#13;
      as follows:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Capturing these sequences helps provide contextual continuity in long documents and brings a lot of other benefits that I listed in more detail in the&#13;
     <html:span class="No-Break">&#13;
      previous chapter.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Among other things, having a previous-next relationship enables&#13;
     <html:em class="italic">&#13;
      cluster retrieval&#13;
     </html:em>&#13;
     : you can get a cluster of related nodes by following the relationships to fetch nearby connected nodes. This provides a more focused context instead of randomly scattered nodes. Maintaining a&#13;
     <html:a id="_idIndexMarker280">&#13;
     </html:a>&#13;
     cohesive narrative thread through the content when following a story or a dialogue is another good reason for having these relationships&#13;
     <html:span class="No-Break">&#13;
      between nodes.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Next, let’s have a look at how to use these parsers and splitters in&#13;
     <html:span class="No-Break">&#13;
      our workflow.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor084">&#13;
    </html:a>&#13;
    <html:h2 id="_idParaDest-85">&#13;
     Practical ways of using these node creation models&#13;
    </html:h2>&#13;
    <html:p>&#13;
     How you implement the node parsers or text splitters in your code depends on how much you&#13;
     <html:a id="_idIndexMarker281">&#13;
     </html:a>&#13;
     want to customize the process but, in the end, it all comes down to three&#13;
     <html:span class="No-Break">&#13;
      main options:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:ol>&#13;
     <html:li>&#13;
      Using them standalone by calling&#13;
      from llama_index.core import Document&#13;
from llama_index.core.node_parser import SentenceWindowNodeParser&#13;
doc = Document(&#13;
    text="Sentence 1. Sentence 2. Sentence 3."&#13;
)&#13;
parser = SentenceWindowNodeParser.from_defaults(&#13;
    window_size=2  ,&#13;
    window_metadata_key="ContextWindow",&#13;
    original_text_metadata_key="node_text"&#13;
)&#13;
nodes = parser.get_nodes_from_documents([doc])&#13;
      Node ID: 0715876a-61e6-4e77-95ba-b93e10de1c67&#13;
Text: Sentence 2.&#13;
      {'ContextWindow': 'Sentence 1.  Sentence 2.  Sentence 3.', 'node_text': 'Sentence 2. '}&#13;
      <html:code class="literal">&#13;
       get_nodes_from_documents()&#13;
      </html:code>&#13;
      , like in&#13;
      <html:span class="No-Break">&#13;
       this example:&#13;
      </html:span>&#13;
      <html:p class="list-inset">&#13;
       This code will produce three nodes. If we look at the second node, for example, by running&#13;
       <html:code class="literal">&#13;
        print(nodes[1])&#13;
       </html:code>&#13;
       , we’ll get the&#13;
       <html:span class="No-Break">&#13;
        following output:&#13;
       </html:span>&#13;
      </html:p>&#13;
      <html:p class="list-inset">&#13;
       As you can see, the parser extracted the second sentence and allocated a random ID to the node. But if we take a peek at the node’s metadata by running&#13;
       <html:code class="literal">&#13;
        print(nodes[1].metadata)&#13;
       </html:code>&#13;
       , we’ll also see the context it gathered, using the keys&#13;
       <html:span class="No-Break">&#13;
        we specified:&#13;
       </html:span>&#13;
      </html:p>&#13;
      <html:p class="list-inset">&#13;
       This metadata&#13;
       <html:a id="_idIndexMarker282">&#13;
       </html:a>&#13;
       can later be used when building queries to provide more context for each sentence and improve the&#13;
       <html:span class="No-Break">&#13;
        LLM responses.&#13;
       </html:span>&#13;
      </html:p>&#13;
      <html:p class="list-inset">&#13;
       We’ll explore this in more detail during&#13;
       <html:a>&#13;
        <html:span class="No-Break">&#13;
         <html:em class="italic">&#13;
          Chapter 6&#13;
         </html:em>&#13;
        </html:span>&#13;
       </html:a>&#13;
       ,&#13;
       <html:em class="italic">&#13;
        Querying Our Data, Part 1 –&#13;
       </html:em>&#13;
       <html:span class="No-Break">&#13;
        <html:em class="italic">&#13;
         Context Retrieval&#13;
        </html:em>&#13;
       </html:span>&#13;
       <html:span class="No-Break">&#13;
        .&#13;
       </html:span>&#13;
      </html:p>&#13;
     </html:li>&#13;
     <html:li>&#13;
      Configuring them&#13;
      from llama_index.core import Settings, Document, &#13;
    VectorStoreIndex&#13;
from llama_index.core.node_parser import &#13;
    SentenceWindowNodeParser&#13;
doc = Document(&#13;
    text="Sentence 1. Sentence 2. Sentence 3."&#13;
)&#13;
text_splitter = SentenceWindowNodeParser.from_defaults(&#13;
    window_size=2  ,&#13;
    window_metadata_key="ContextWindow",&#13;
    original_text_metadata_key="node_text"&#13;
)&#13;
Settings.text_splitter = text_splitter&#13;
index = VectorStoreIndex.from_documents([doc])&#13;
      <html:span class="No-Break">&#13;
       in&#13;
      </html:span>&#13;
      <html:span class="No-Break">&#13;
       <html:code class="literal">&#13;
        Settings&#13;
       </html:code>&#13;
      </html:span>&#13;
      <html:span class="No-Break">&#13;
       .&#13;
      </html:span>&#13;
      <html:p class="list-inset">&#13;
       The second option is a bit more general and convenient when you need to automatically use the same parser for multiple purposes in&#13;
       <html:span class="No-Break">&#13;
        your app:&#13;
       </html:span>&#13;
      </html:p>&#13;
      <html:p class="list-inset">&#13;
       This time, after we define and configure our custom&#13;
       <html:code class="literal">&#13;
        text_splitter&#13;
       </html:code>&#13;
       , we pre-load it in&#13;
       <html:code class="literal">&#13;
        Settings&#13;
       </html:code>&#13;
       . From this point forward, whenever we call any function that relies on text splitting, our custom&#13;
       <html:code class="literal">&#13;
        text_splitter&#13;
       </html:code>&#13;
       will be used&#13;
       <html:span class="No-Break">&#13;
        by default.&#13;
       </html:span>&#13;
      </html:p>&#13;
      <html:p class="list-inset">&#13;
       Of course, this actual example is a bit of overkill. You’ve probably noticed that I’ve used a node&#13;
       <html:a id="_idIndexMarker283">&#13;
       </html:a>&#13;
       parser in place of a simple text splitter. The index we’re building with the nodes won’t benefit in any way from the additional context metadata created by the parser. I just wanted to emphasize my previous point regarding parsers&#13;
       <html:span class="No-Break">&#13;
        and splitters.&#13;
       </html:span>&#13;
      </html:p>&#13;
     </html:li>&#13;
     <html:li>&#13;
      Defining the parsers as a&#13;
      <html:strong class="bold">&#13;
       transformation&#13;
      </html:strong>&#13;
      step in an&#13;
      <html:span class="No-Break">&#13;
       <html:strong class="bold">&#13;
        ingestion pipeline&#13;
       </html:strong>&#13;
      </html:span>&#13;
      <html:span class="No-Break">&#13;
       .&#13;
      </html:span>&#13;
      <html:p class="list-inset">&#13;
       An ingestion pipeline is an automatic and structured process for ingesting data.  It’s running the&#13;
       <html:a id="_idIndexMarker284">&#13;
       </html:a>&#13;
       data through a series of steps (called&#13;
       <html:strong class="bold">&#13;
        transformations&#13;
       </html:strong>&#13;
       ) one&#13;
       <html:span class="No-Break">&#13;
        by one.&#13;
       </html:span>&#13;
      </html:p>&#13;
      <html:p class="list-inset">&#13;
       I will explain how this works and what it can be used for later in this chapter, in the&#13;
       <html:em class="italic">&#13;
        Using the ingestion pipeline to increase efficiency&#13;
       </html:em>&#13;
       section. You’ll also get to see the code for implementing the parser as a transformation in&#13;
       <html:span class="No-Break">&#13;
        the pipeline.&#13;
       </html:span>&#13;
      </html:p>&#13;
     </html:li>&#13;
    </html:ol>&#13;
    <html:p>&#13;
     Next, we’ll talk about metadata and how metadata can be used to improve our&#13;
     <html:span class="No-Break">&#13;
      RAG application.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor085">&#13;
    </html:a>&#13;
   </html:div>&#13;
  </html:div>&#13;
 </html:body>&#13;
</html:html>
<html:html>&#13;
 <html:head>&#13;
  <html:title>&#13;
   Working with metadata to improve the context&#13;
  </html:title>&#13;
 </html:head>&#13;
 <html:body>&#13;
  <html:div class="epub-source">&#13;
   <html:h1 id="_idParaDest-86">&#13;
    Working with metadata to improve the context&#13;
   </html:h1>&#13;
   <html:div id="_idContainer039">&#13;
    document.metadata = {&#13;
    "report_name": "Sales Report April 2022",&#13;
    "department": "Sales",&#13;
    "author": "Jane Doe"&#13;
}&#13;
    From llama_index.core import SimpleDirectoryReader&#13;
from llama_index.core.node_parser import SentenceSplitter&#13;
reader = SimpleDirectoryReader('files')&#13;
documents = reader.load_data()&#13;
parser = SentenceSplitter(include_prev_next_rel=True)&#13;
nodes = parser.get_nodes_from_documents(documents)&#13;
    from llama_index.core.extractors import SummaryExtractor&#13;
summary_extractor = SummaryExtractor(summaries=["prev", "self", &#13;
    "next"])&#13;
metadata_list = summary_extractor.extract(nodes)&#13;
print(metadata_list)&#13;
    from llama_index.core.extractors import QuestionsAnsweredExtractor&#13;
qa_extractor = QuestionsAnsweredExtractor(questions=5)&#13;
metadata_list = qa_extractor.extract(nodes)&#13;
print(metadata_list)&#13;
    from llama_index.core.extractors import TitleExtractor&#13;
title_extractor = TitleExtractor ()&#13;
metadata_list = title_extractor.extract(nodes)&#13;
print(metadata_list)&#13;
    from llama_index.core.extractors import EntityExtractor&#13;
entity_extractor = EntityExtractor (&#13;
    label_entities = True,&#13;
    device = "cpu"&#13;
)&#13;
metadata_list = entity_extractor.extract(nodes)&#13;
print(metadata_list)&#13;
    from llama_index.core.extractors import KeywordExtractor&#13;
key_extractor = KeywordExtractor (keywords=3)&#13;
metadata_list = key_extractor.extract(nodes)&#13;
print(metadata_list)&#13;
    from llama_index.core.extractors import BaseExtractor&#13;
from typing import List, Dict&#13;
class CustomExtractor(BaseExtractor):&#13;
    async def aextract(self, nodes) -&gt; List[Dict]:&#13;
        metadata_list = [&#13;
            {&#13;
                "node_length":  str(len(node.text))&#13;
            }&#13;
            for node in nodes&#13;
        ]&#13;
        return metadata_list&#13;
    document.excluded_llm_metadata_keys = ["file_name"]&#13;
    document.excluded_embed_metadata_keys = ["file_name"]&#13;
    document.metadata_template = "{key}::{value}"&#13;
    print(document.get_content(metadata_mode=MetadataMode.LLM))&#13;
    <html:p>&#13;
     What is&#13;
     <html:strong class="bold">&#13;
      metadata&#13;
     </html:strong>&#13;
     ? It’s simply&#13;
     <html:a id="_idIndexMarker285">&#13;
     </html:a>&#13;
     additional information we can attach to our documents&#13;
     <html:a id="_idIndexMarker286">&#13;
     </html:a>&#13;
     and nodes. This extra context helps LlamaIndex better understand our data. It provides additional context about data and can be customized in terms of visibility&#13;
     <html:span class="No-Break">&#13;
      and format.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     For example, let’s say you’ve&#13;
     <html:em class="italic">&#13;
      ingested&#13;
     </html:em>&#13;
     some PDF reports as documents. You could then simply add some metadata&#13;
     <html:span class="No-Break">&#13;
      like this:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     This metadata gives vital clues when querying the data later. In this example, we can use it to locate reports by&#13;
     <html:a id="_idIndexMarker287">&#13;
     </html:a>&#13;
     department or author. You can store anything useful as metadata – categories, timestamps, locations,&#13;
     <html:span class="No-Break">&#13;
      and more.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     And here’s a neat trick – any metadata you set on a document automatically flows down to child nodes! So, if I set an&#13;
     <html:code class="literal">&#13;
      author&#13;
     </html:code>&#13;
     field on a document, all nodes derived from that document will inherit the&#13;
     <html:code class="literal">&#13;
      author&#13;
     </html:code>&#13;
     metadata. This propagation saves time and prevents duplicating metadata&#13;
     <html:span class="No-Break">&#13;
      across nodes.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     There are multiple ways of&#13;
     <html:span class="No-Break">&#13;
      defining metadata:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:ol>&#13;
     <html:li>&#13;
      Setting the metadata values directly in the&#13;
      document = Document(&#13;
    text="",&#13;
    metadata={"author": "John Doe"}&#13;
)&#13;
     <html:code class="literal">&#13;
       Document&#13;
      </html:code>&#13;
      constructor&#13;
      <html:span class="No-Break">&#13;
       as follows:&#13;
      </html:span>&#13;
      </html:li>&#13;
     <html:li>&#13;
      Adding the metadata after&#13;
      document.metadata = {"category": "finance"}&#13;
     <html:span class="No-Break">&#13;
       document creation:&#13;
      </html:span>&#13;
      </html:li>&#13;
     <html:li>&#13;
      Automatically setting metadata in the ingestion process, when using data connectors such&#13;
      def set_metadata(filename):&#13;
    return {"file_name": filename}&#13;
documents = SimpleDirectoryReader(&#13;
    "./data",&#13;
    file_metadata=set_metadata("file1.txt")&#13;
).load_data()&#13;
     <html:span class="No-Break">&#13;
       as&#13;
      </html:span>&#13;
      <html:span class="No-Break">&#13;
       <html:code class="literal">&#13;
        SimpleDirectoryReader&#13;
       </html:code>&#13;
      </html:span>&#13;
      <html:span class="No-Break">&#13;
       :&#13;
      </html:span>&#13;
      </html:li>&#13;
     <html:li>&#13;
      Using standalone, dedicated extractors provided by LlamaIndex.&#13;
      <html:strong class="bold">&#13;
       Metadata&#13;
      </html:strong>&#13;
      <html:strong class="bold">&#13;
       extractors&#13;
      </html:strong>&#13;
      are a&#13;
      <html:a id="_idIndexMarker288">&#13;
      </html:a>&#13;
      powerful way to generate relevant metadata from text using the power of LLMs. This extracted metadata can then be attached to documents and nodes to provide&#13;
      <html:span class="No-Break">&#13;
       additional context&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      Defining the&#13;
      <html:a id="_idIndexMarker289">&#13;
      </html:a>&#13;
      extractor as a&#13;
      <html:em class="italic">&#13;
       transformation&#13;
      </html:em>&#13;
      step in an ingestion pipeline. Just like in the case of node parsers, extractors can also become part of the pipeline. We’ll cover this approach later in this chapter in the&#13;
      <html:em class="italic">&#13;
       Using the ingestion pipeline to increase&#13;
      </html:em>&#13;
      <html:span class="No-Break">&#13;
       <html:em class="italic">&#13;
        efficiency&#13;
       </html:em>&#13;
      </html:span>&#13;
      <html:span class="No-Break">&#13;
       section&#13;
      </html:span>&#13;
     </html:li>&#13;
    </html:ol>&#13;
    <html:p>&#13;
     But first, let’s put our magnifying glass on these specialized metadata extractors to better understand how&#13;
     <html:span class="No-Break">&#13;
      they work.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Before you go further, if you want to run the following code examples, make sure to include the necessary imports, document ingestion, and node parsing logic at the beginning of your code by adding the&#13;
     <html:span class="No-Break">&#13;
      following lines:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     This boilerplate code prepares your data – ingested from the&#13;
     <html:code class="literal">&#13;
      files&#13;
     </html:code>&#13;
     subfolder – and puts everything you need into&#13;
     <html:code class="literal">&#13;
      Nodes&#13;
     </html:code>&#13;
     . We’ll store our metadata in a variable called&#13;
     <html:code class="literal">&#13;
      metadata_list&#13;
     </html:code>&#13;
     . I’ve added&#13;
     <html:code class="literal">&#13;
      print(metadata_list)&#13;
     </html:code>&#13;
     at the end of each example so that we’ll see an output of the extracted metadata. Apart from describing their logic, I’ve also highlighted practical uses for each one of&#13;
     <html:span class="No-Break">&#13;
      the extractors.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor086">&#13;
    </html:a>&#13;
    <html:h2 id="_idParaDest-87">&#13;
     SummaryExtractor&#13;
    </html:h2>&#13;
    <html:p>&#13;
     This extractor generates summaries of the text contained by the node. Optionally, it can generate&#13;
     <html:a id="_idIndexMarker290">&#13;
     </html:a>&#13;
     summaries for the previous and next adjacent nodes. Here’s&#13;
     <html:span class="No-Break">&#13;
      an example:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     This extractor&#13;
     <html:a id="_idIndexMarker291">&#13;
     </html:a>&#13;
     generates concise summaries for each node or adjacent node. These are essential during the retrieve phase in an RAG architecture. This ensures that the search can consider the summary of the documents without having to process the entirety of&#13;
     <html:span class="No-Break">&#13;
      their content.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p class="callout-heading">&#13;
     Practical use case&#13;
    </html:p>&#13;
    <html:p class="callout">&#13;
     Imagine a customer support knowledge base on which&#13;
     <html:code class="literal">&#13;
      SummaryExtractor&#13;
     </html:code>&#13;
     can provide summaries of customer issues and resolutions. Then, when a new support request comes in, our app can retrieve the most relevant past cases to help generate a detailed and&#13;
     <html:span class="No-Break">&#13;
      contextual solution.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     You can customize the type of&#13;
     <html:code class="literal">&#13;
      summaries&#13;
     </html:code>&#13;
     to generate by setting the values in the summaries list and the actual prompt that will be used with the LLM by defining the prompt in the&#13;
     <html:span class="No-Break">&#13;
      <html:code class="literal">&#13;
       prompt_template&#13;
      </html:code>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      parameter.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor087">&#13;
    </html:a>&#13;
    <html:h2 id="_idParaDest-88">&#13;
     QuestionsAnsweredExtractor&#13;
    </html:h2>&#13;
    <html:p>&#13;
     This extractor&#13;
     <html:a id="_idIndexMarker292">&#13;
     </html:a>&#13;
     generates a specified number of questions&#13;
     <html:a id="_idIndexMarker293">&#13;
     </html:a>&#13;
     the node text&#13;
     <html:span class="No-Break">&#13;
      can answer.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     The following example should give you a&#13;
     <html:span class="No-Break">&#13;
      usage guideline:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     This extractor identifies questions that the text is uniquely positioned to answer, allowing the retrieval process to focus on nodes that explicitly address&#13;
     <html:span class="No-Break">&#13;
      specific inquiries.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p class="callout-heading">&#13;
     Practical use case&#13;
    </html:p>&#13;
    <html:p class="callout">&#13;
     For an FAQ system, the extractor identifies unique questions answered by articles, making it easier to find precise answers to&#13;
     <html:span class="No-Break">&#13;
      user queries.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     You can&#13;
     <html:a id="_idIndexMarker294">&#13;
     </html:a>&#13;
     customize the number of questions it&#13;
     <html:a id="_idIndexMarker295">&#13;
     </html:a>&#13;
     generates but also the actual prompt that will be used with the LLM – by setting the&#13;
     <html:code class="literal">&#13;
      prompt_template&#13;
     </html:code>&#13;
     parameter. There is also an&#13;
     <html:code class="literal">&#13;
      embedding_only&#13;
     </html:code>&#13;
     Boolean parameter that – if set to&#13;
     <html:code class="literal">&#13;
      True&#13;
     </html:code>&#13;
     – will make the metadata available only for embeddings. More on that in&#13;
     <html:a>&#13;
      <html:span class="No-Break">&#13;
       <html:em class="italic">&#13;
        Chapter 5&#13;
       </html:em>&#13;
      </html:span>&#13;
     </html:a>&#13;
     ,&#13;
     <html:em class="italic">&#13;
      Indexing&#13;
     </html:em>&#13;
     <html:span class="No-Break">&#13;
      <html:em class="italic">&#13;
       with LlamaIndex&#13;
      </html:em>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      .&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor088">&#13;
    </html:a>&#13;
    <html:h2 id="_idParaDest-89">&#13;
     TitleExtractor&#13;
    </html:h2>&#13;
    <html:p>&#13;
     This one&#13;
     <html:a id="_idIndexMarker296">&#13;
     </html:a>&#13;
     extracts a title for the text. Here’s&#13;
     <html:span class="No-Break">&#13;
      an example:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     <html:code class="literal">&#13;
      TitleExtractor&#13;
     </html:code>&#13;
     specializes in pulling out meaningful titles from larger texts, assisting in the&#13;
     <html:a id="_idIndexMarker297">&#13;
     </html:a>&#13;
     quick identification and retrieval of documents. In digital libraries, for example,&#13;
     <html:code class="literal">&#13;
      TitleExtractor&#13;
     </html:code>&#13;
     can help categorize documents by extracting titles from untitled texts, making retrieval more efficient when titles are used as search keywords. There are several parameters you can tweak for&#13;
     <html:span class="No-Break">&#13;
      this extractor:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:ul>&#13;
     <html:li>&#13;
      <html:code class="literal">&#13;
       nodes&#13;
      </html:code>&#13;
      : This sets the&#13;
      <html:a id="_idIndexMarker298">&#13;
      </html:a>&#13;
      number of nodes to use for&#13;
      <html:span class="No-Break">&#13;
       title extraction&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:code class="literal">&#13;
       node_template&#13;
      </html:code>&#13;
      : This changes the default prompt template that’s used for extracting&#13;
      <html:span class="No-Break">&#13;
       the titles&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:code class="literal">&#13;
       combine_template&#13;
      </html:code>&#13;
      : This changes the prompt template for combining multiple&#13;
      <html:a id="_idIndexMarker299">&#13;
      </html:a>&#13;
      node-level titles in a&#13;
      <html:span class="No-Break">&#13;
       document-wide title&#13;
      </html:span>&#13;
     </html:li>&#13;
    </html:ul>&#13;
    <html:p>&#13;
     Now, let’s look&#13;
     <html:span class="No-Break">&#13;
      at&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      <html:code class="literal">&#13;
       EntityExtractor&#13;
      </html:code>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      .&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor089">&#13;
    </html:a>&#13;
    <html:h2 id="_idParaDest-90">&#13;
     EntityExtractor&#13;
    </html:h2>&#13;
    <html:p>&#13;
     This will&#13;
     <html:a id="_idIndexMarker300">&#13;
     </html:a>&#13;
     extract entities such as people, locations, organizations, and more from&#13;
     <html:a id="_idIndexMarker301">&#13;
     </html:a>&#13;
     the node text by using the&#13;
     <html:strong class="bold">&#13;
      span-marker&#13;
     </html:strong>&#13;
     package. This&#13;
     <html:a id="_idIndexMarker302">&#13;
     </html:a>&#13;
     package is installed automatically together with the&#13;
     <html:code class="literal">&#13;
      EntityExtractor&#13;
     </html:code>&#13;
     integration, so no&#13;
     <html:a id="_idIndexMarker303">&#13;
     </html:a>&#13;
     additional installations are required. It provides the ability to perform&#13;
     <html:strong class="bold">&#13;
      named entity recognition&#13;
     </html:strong>&#13;
     (&#13;
     <html:strong class="bold">&#13;
      NER&#13;
     </html:strong>&#13;
     ) and relies on a&#13;
     <html:a id="_idIndexMarker304">&#13;
     </html:a>&#13;
     tokenizer provided by the&#13;
     <html:strong class="bold">&#13;
      Natural Language Toolkit&#13;
     </html:strong>&#13;
     (&#13;
     <html:strong class="bold">&#13;
      NLTK&#13;
     </html:strong>&#13;
     )&#13;
     <html:span class="No-Break">&#13;
      package:&#13;
     </html:span>&#13;
     <html:a>&#13;
      <html:span class="No-Break">&#13;
       https://www.nltk.org/&#13;
      </html:span>&#13;
     </html:a>&#13;
     <html:span class="No-Break">&#13;
      .&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p class="callout-heading">&#13;
     A quick note on NER&#13;
    </html:p>&#13;
    <html:p class="callout">&#13;
     NER is a technique that’s used by computers to identify and label specific entities in text, such as people’s names, company names, places, and dates. This helps the computer to better understand the content and provides useful context in an&#13;
     <html:span class="No-Break">&#13;
      RAG scenario.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Here’s a code example for using&#13;
     <html:span class="No-Break">&#13;
      this extractor:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     The extractor identifies named entities from the text, labels them, and adds them to the metadata, enabling a retrieval system to focus on nodes with&#13;
     <html:span class="No-Break">&#13;
      specific references.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p class="callout-heading">&#13;
     Practical use case&#13;
    </html:p>&#13;
    <html:p class="callout">&#13;
     Imagine a legal document archive having this metadata attached to each node. This extractor&#13;
     <html:a id="_idIndexMarker305">&#13;
     </html:a>&#13;
     could ease the retrieval of documents mentioning particular people, locations, or organizations, thus providing the best context for&#13;
     <html:span class="No-Break">&#13;
      our query.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     There’s a&#13;
     <html:a id="_idIndexMarker306">&#13;
     </html:a>&#13;
     long list of parameters that you can tune for&#13;
     <html:span class="No-Break">&#13;
      this extractor:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:ul>&#13;
     <html:li>&#13;
      <html:code class="literal">&#13;
       model_name&#13;
      </html:code>&#13;
      : This sets the name of the model to be used&#13;
      <html:span class="No-Break">&#13;
       by&#13;
      </html:span>&#13;
      <html:span class="No-Break">&#13;
       <html:code class="literal">&#13;
        SpanMarker&#13;
       </html:code>&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:code class="literal">&#13;
       prediction_threshold&#13;
      </html:code>&#13;
      : This changes the default 0.5 minimum prediction threshold for named entities. As you may have guessed, entity recognition is usually not a 100% accurate process. However, you can experiment with different values here until you find the&#13;
      <html:span class="No-Break">&#13;
       best compromise&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:code class="literal">&#13;
       span_joiner&#13;
      </html:code>&#13;
      : This changes the default string used to join&#13;
      <html:span class="No-Break">&#13;
       the spans&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:code class="literal">&#13;
       label_entities&#13;
      </html:code>&#13;
      : If set to&#13;
      <html:code class="literal">&#13;
       True&#13;
      </html:code>&#13;
      , it will make the extractor label every entity name with an entity type. This could be useful later, in the retrieval and querying phase. By default, this is set&#13;
      <html:span class="No-Break">&#13;
       to&#13;
      </html:span>&#13;
      <html:span class="No-Break">&#13;
       <html:code class="literal">&#13;
        False&#13;
       </html:code>&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:code class="literal">&#13;
       device&#13;
      </html:code>&#13;
      : This controls the device on which the model runs. It defaults to&#13;
      <html:code class="literal">&#13;
       cpu&#13;
      </html:code>&#13;
      , but if your system allows, it can be set&#13;
      <html:span class="No-Break">&#13;
       to&#13;
      </html:span>&#13;
      <html:span class="No-Break">&#13;
       <html:code class="literal">&#13;
        cuda&#13;
       </html:code>&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:code class="literal">&#13;
       entity_map&#13;
      </html:code>&#13;
      : This allows you to customize the labels for each entity type. The extractor comes with a predefined entity map that includes labels for people, organizations, places, events, and&#13;
      <html:span class="No-Break">&#13;
       many others&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:code class="literal">&#13;
       Tokenizer&#13;
      </html:code>&#13;
      : This allows you to change the default tokenizer function – which defaults to the&#13;
      <html:span class="No-Break">&#13;
       NLTK tokenizer&#13;
      </html:span>&#13;
     </html:li>&#13;
    </html:ul>&#13;
    <html:p>&#13;
     Now, let’s discuss how to extract keywords&#13;
     <html:span class="No-Break">&#13;
      with&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      <html:code class="literal">&#13;
       KeywordExtractor&#13;
      </html:code>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      .&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor090">&#13;
    </html:a>&#13;
    <html:h2 id="_idParaDest-91">&#13;
     KeywordExtractor&#13;
    </html:h2>&#13;
    <html:p>&#13;
     This extractor&#13;
     <html:a id="_idIndexMarker307">&#13;
     </html:a>&#13;
     extracts important keywords from the text. Let’s have a look at&#13;
     <html:span class="No-Break">&#13;
      an example:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     This one&#13;
     <html:a id="_idIndexMarker308">&#13;
     </html:a>&#13;
     identifies important words or phrases, making it an invaluable tool for retrieving the most relevant nodes based on&#13;
     <html:span class="No-Break">&#13;
      user queries.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p class="callout-heading">&#13;
     Practical use case&#13;
    </html:p>&#13;
    <html:p class="callout">&#13;
     Integrating&#13;
     <html:code class="literal">&#13;
      KeywordExtractor&#13;
     </html:code>&#13;
     into a content recommendation engine can significantly enhance its effectiveness. By aligning the keywords extracted from content nodes with the terms used in user searches, the engine can more accurately match and recommend content that aligns with user interests. This keyword-based matching ensures that recommendations are not only relevant but also tailored to the specific inquiries or topics users&#13;
     <html:span class="No-Break">&#13;
      are exploring.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     You can customize the number of keywords it generates by changing the&#13;
     <html:code class="literal">&#13;
      keywords&#13;
     </html:code>&#13;
     parameter to a&#13;
     <html:span class="No-Break">&#13;
      specific value.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor091">&#13;
    </html:a>&#13;
    <html:h2 id="_idParaDest-92">&#13;
     PydanticProgramExtractor&#13;
    </html:h2>&#13;
    <html:p>&#13;
     This extractor&#13;
     <html:a id="_idIndexMarker309">&#13;
     </html:a>&#13;
     extracts metadata using a&#13;
     <html:strong class="bold">&#13;
      Pydantic&#13;
     </html:strong>&#13;
     structure. Have&#13;
     <html:a id="_idIndexMarker310">&#13;
     </html:a>&#13;
     a look here for a complete example of using this&#13;
     <html:span class="No-Break">&#13;
      extractor:&#13;
     </html:span>&#13;
     <html:a>&#13;
      <html:span class="No-Break">&#13;
       https://docs.llamaindex.ai/en/stable/examples/metadata_extraction/PydanticExtractor.html#pydantic-extractor&#13;
      </html:span>&#13;
     </html:a>&#13;
     <html:span class="No-Break">&#13;
      .&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     This&#13;
     <html:em class="italic">&#13;
      Swiss Army knife&#13;
     </html:em>&#13;
     enables the creation of complex and structured metadata schemas with a single LLM call by making use of Pydantic models. One of the main advantages it has over other extractors is that it can pull multiple fields of data using a single LLM call making it a very efficient way to extract metadata. This data will be nicely organized in a model of&#13;
     <html:span class="No-Break">&#13;
      our design.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p class="callout-heading">&#13;
     A quick introduction to Pydantic models&#13;
    </html:p>&#13;
    <html:p class="callout">&#13;
     A&#13;
     <html:strong class="bold">&#13;
      Pydantic model&#13;
     </html:strong>&#13;
     is like a&#13;
     <html:a id="_idIndexMarker311">&#13;
     </html:a>&#13;
     blueprint or a set of rules that you define as a class in a Python program. It helps you make sure that the data you receive or work with follows certain rules and is in the right format. Think of it as a way to define how your data should look – Pydantic helps you enforce those rules and make sure the data fits in your&#13;
     <html:span class="No-Break">&#13;
      desired structure.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     For example, imagine you have a program that deals with user data such as names, ages, and email addresses. You can create a Pydantic model that specifies that a user’s name should&#13;
     <html:a id="_idIndexMarker312">&#13;
     </html:a>&#13;
     be a string, their age should be a number, and their&#13;
     <html:a id="_idIndexMarker313">&#13;
     </html:a>&#13;
     email address should be a valid email format. If input data doesn’t follow these rules, Pydantic will raise an error, telling you that the data is not correct. LlamaIndex embraces this mechanism whenever it needs to ensure the consistency and correctness of the data it handles, especially as it often works with complex structures and&#13;
     <html:span class="No-Break">&#13;
      interrelated data.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor092">&#13;
    </html:a>&#13;
    <html:h2 id="_idParaDest-93">&#13;
     MarvinMetadataExtractor&#13;
    </html:h2>&#13;
    <html:p>&#13;
     This&#13;
     <html:a id="_idIndexMarker314">&#13;
     </html:a>&#13;
     extractor extracts metadata using the&#13;
     <html:strong class="bold">&#13;
      Marvin AI engineering framework&#13;
     </html:strong>&#13;
     <html:span class="P---URL">&#13;
     </html:span>&#13;
     (https://www.askmarvin.ai/). Taking advantage of the&#13;
     <html:a id="_idIndexMarker315">&#13;
     </html:a>&#13;
     Marvin AI engineering framework, this extractor is&#13;
     <html:a id="_idIndexMarker316">&#13;
     </html:a>&#13;
     capable of trustworthy and scalable metadata extraction and augmentation. Its sophistication lies in providing type-safe schemas for text – similar to Pydantic models -  but also supporting business logic transformations. You can find a detailed example&#13;
     <html:span class="No-Break">&#13;
      here:&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      https://docs.llamaindex.ai/en/stable/examples/metadata_extraction/MarvinMetadataExtractorDemo.html&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      .&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor093">&#13;
    </html:a>&#13;
    <html:h2 id="_idParaDest-94">&#13;
     Defining your custom extractor&#13;
    </html:h2>&#13;
    <html:p>&#13;
     Just in case&#13;
     <html:a id="_idIndexMarker317">&#13;
     </html:a>&#13;
     none of these ready-made extractors satisfies&#13;
     <html:a id="_idIndexMarker318">&#13;
     </html:a>&#13;
     your needs, you can always define your own extractor function. Here is a simple example of how to define a&#13;
     <html:span class="No-Break">&#13;
      custom extractor:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     This basic&#13;
     <html:a id="_idIndexMarker319">&#13;
     </html:a>&#13;
     extractor measures the length in characters for&#13;
     <html:a id="_idIndexMarker320">&#13;
     </html:a>&#13;
     each node and saves these values in the metadata. Of course, you could replace that with any logic required by&#13;
     <html:span class="No-Break">&#13;
      your app.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Having so many tools and methods available at our disposal is a great thing. But then a new question arises:&#13;
     <html:em class="italic">&#13;
      do we need that much metadata?&#13;
     </html:em>&#13;
     Let’s find out&#13;
     <html:span class="No-Break">&#13;
      the answer.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor094">&#13;
    </html:a>&#13;
    <html:h2 id="_idParaDest-95">&#13;
     Is having all that metadata always a good thing?&#13;
    </html:h2>&#13;
    <html:p>&#13;
     Not necessarily. A key detail is that metadata gets injected into the text that’s sent to the LLM and&#13;
     <html:a id="_idIndexMarker321">&#13;
     </html:a>&#13;
     embedding model. This can potentially induce some bias in the models. This means that sometimes, you may not want all metadata to be visible. For example, filenames may help embeddings but may&#13;
     <html:em class="italic">&#13;
      distract&#13;
     </html:em>&#13;
     the LLM because the LLM might not understand them as filenames but as other entities instead, and also because the filenames may have no relevance in the context of the prompt. You can selectively hide metadata with the&#13;
     <html:span class="No-Break">&#13;
      following command:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     This hides&#13;
     <html:code class="literal">&#13;
      file_name&#13;
     </html:code>&#13;
     from the LLM. You can also hide metadata from embeddings if&#13;
     <html:span class="No-Break">&#13;
      you want:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Also, you can customize the metadata format&#13;
     <html:span class="No-Break">&#13;
      like this:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Here is a pro tip when dealing with metadata mode. LlamaIndex has an enum called&#13;
     <html:code class="literal">&#13;
      MetadataMode&#13;
     </html:code>&#13;
     that controls&#13;
     <html:span class="No-Break">&#13;
      metadata visibility:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:ul>&#13;
     <html:li>&#13;
      <html:code class="literal">&#13;
       MetadataMode.ALL&#13;
      </html:code>&#13;
      : Shows&#13;
      <html:span class="No-Break">&#13;
       all metadata&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:code class="literal">&#13;
       MetadataMode.LLM&#13;
      </html:code>&#13;
      : Only metadata visible to&#13;
      <html:span class="No-Break">&#13;
       the LLM&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:code class="literal">&#13;
       MetadataMode.EMBED&#13;
      </html:code>&#13;
      : Only metadata visible&#13;
      <html:span class="No-Break">&#13;
       to embeddings&#13;
      </html:span>&#13;
     </html:li>&#13;
    </html:ul>&#13;
    <html:p>&#13;
     You can test&#13;
     <html:a id="_idIndexMarker322">&#13;
     </html:a>&#13;
     the visibility of metadata with the&#13;
     <html:span class="No-Break">&#13;
      following command:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     So, in summary, metadata gives your data much-needed context. You have full control over its format and visibility to different models. These customizations let you mold metadata to match your&#13;
     <html:span class="No-Break">&#13;
      use case!&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     With that topic exhausted, it’s time to talk&#13;
     <html:span class="No-Break">&#13;
      about money.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor095">&#13;
    </html:a>&#13;
   </html:div>&#13;
  </html:div>&#13;
 </html:body>&#13;
</html:html>
<html:html>&#13;
 <html:head>&#13;
  <html:title>&#13;
   Estimating the potential cost of using metadata extractors&#13;
  </html:title>&#13;
 </html:head>&#13;
 <html:body>&#13;
  <html:div class="epub-source">&#13;
   <html:h1 id="_idParaDest-96">&#13;
    Estimating the potential cost of using metadata extractors&#13;
   </html:h1>&#13;
   <html:div id="_idContainer039">&#13;
    from llama_index.core import &#13;
ettings&#13;
from llama_index.core.extractors import QuestionsAnsweredExtractor&#13;
from llama_index.core.llms.mock import MockLLM&#13;
from llama_index.core.schema import TextNode&#13;
from llama_index.core.callbacks import (&#13;
    CallbackManager,&#13;
    TokenCountingHandler&#13;
)&#13;
llm = MockLLM(max_tokens=256)&#13;
counter = TokenCountingHandler(verbose=False)&#13;
callback_manager = CallbackManager([counter])&#13;
Settings.llm = llm&#13;
Settings.callback_manager = CallbackManager([counter])&#13;
sample_text = (&#13;
    "LlamaIndex is a powerful tool used "&#13;
    "to create efficient indices from data."&#13;
)&#13;
nodes= [TextNode(text=sample_text)]&#13;
extractor = QuestionsAnsweredExtractor(&#13;
    show_progress=False&#13;
)&#13;
Questions_metadata = extractor.extract(nodes)&#13;
print(f"Prompt Tokens: {counter.prompt_llm_token_count}")&#13;
print(f"Completion Tokens: {counter.completion_llm_token_count}")&#13;
print(f"Total Token Count: {counter.total_llm_token_count}")&#13;
    <html:p>&#13;
     A key consideration when utilizing the various metadata extractors in LlamaIndex is the associated&#13;
     <html:a id="_idIndexMarker323">&#13;
     </html:a>&#13;
     LLM compute costs. As mentioned earlier, most of these extractors rely on LLMs under the hood to analyze text and generate&#13;
     <html:span class="No-Break">&#13;
      descriptive metadata.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Repeatedly calling LLMs to process large volumes of text can quickly add up in charges. For example, if you are extracting summaries and keywords from thousands of document nodes using&#13;
     <html:code class="literal">&#13;
      SummaryExtractor&#13;
     </html:code>&#13;
     and&#13;
     <html:code class="literal">&#13;
      KeywordExtractor&#13;
     </html:code>&#13;
     , those constant LLM invocations will carry a&#13;
     <html:span class="No-Break">&#13;
      significant cost.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor096">&#13;
    </html:a>&#13;
    <html:h2 id="_idParaDest-97">&#13;
     Follow these simple best practices to minimize your costs&#13;
    </html:h2>&#13;
    <html:p>&#13;
     Let’s talk&#13;
     <html:a id="_idIndexMarker324">&#13;
     </html:a>&#13;
     about some common best practices for minimizing your&#13;
     <html:span class="No-Break">&#13;
      LLM costs:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:ul>&#13;
     <html:li>&#13;
      Batch content into fewer LLM calls instead of individual calls per node. This amortizes the overhead because you consume fewer tokens compared to multiple separate calls. Using the Pydantic extractor is very useful for this purpose since it generates multiple fields in a single&#13;
      <html:span class="No-Break">&#13;
       LLM call&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      Use cheaper LLM models with lower compute requirements if full accuracy is not necessary. However, be careful – you may introduce errors in your data, and these errors have the bad habit of propagating and&#13;
      <html:span class="No-Break">&#13;
       amplifying downstream&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      Cache previous extractions and reuse them without having to re-invoke LLMs every time. I’m going to show you how to accomplish that using&#13;
      <html:em class="italic">&#13;
       ingestion pipelines&#13;
      </html:em>&#13;
      later in this chapter, in the&#13;
      <html:em class="italic">&#13;
       Using the ingestion pipeline to increase&#13;
      </html:em>&#13;
      <html:span class="No-Break">&#13;
       <html:em class="italic">&#13;
        efficiency&#13;
       </html:em>&#13;
      </html:span>&#13;
      <html:span class="No-Break">&#13;
       section&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      Restrict metadata extraction only to select subsets of critical nodes rather than full coverage. This may be difficult to implement in an&#13;
      <html:span class="No-Break">&#13;
       automated scenario&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      Consider offline LLMs to eliminate cloud costs. Depending on your hardware, this may or may not be&#13;
      <html:span class="No-Break">&#13;
       a solution&#13;
      </html:span>&#13;
     </html:li>&#13;
    </html:ul>&#13;
    <html:p>&#13;
     While these guidelines should help you greatly reduce the extraction costs, it’s still a good idea to make sure you run some estimates before processing&#13;
     <html:span class="No-Break">&#13;
      large datasets.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor097">&#13;
    </html:a>&#13;
    <html:h2 id="_idParaDest-98">&#13;
     Estimate your maximal costs before running the actual extractors&#13;
    </html:h2>&#13;
    <html:p>&#13;
     Here is a&#13;
     <html:a id="_idIndexMarker325">&#13;
     </html:a>&#13;
     basic example of how we can estimate LLM&#13;
     <html:a id="_idIndexMarker326">&#13;
     </html:a>&#13;
     costs by using a&#13;
     <html:strong class="bold">&#13;
      MockLLM&#13;
     </html:strong>&#13;
     before running the extractor on the&#13;
     <html:span class="No-Break">&#13;
      real one:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     You’ll notice that we’re using some specialized tools to run the actual estimation. Let’s have a quick overview of the code.&#13;
     <html:code class="literal">&#13;
      MockLLM&#13;
     </html:code>&#13;
     – as its name implies – is a stand-in LLM that simulates the behavior of an LLM without any actual&#13;
     <html:span class="No-Break">&#13;
      API calls.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     When you create a&#13;
     <html:code class="literal">&#13;
      MockLLM&#13;
     </html:code>&#13;
     instance, you have the option to set a&#13;
     <html:code class="literal">&#13;
      max_tokens&#13;
     </html:code>&#13;
     parameter. This parameter represents the maximum number of tokens that the mock model is&#13;
     <html:a id="_idIndexMarker327">&#13;
     </html:a>&#13;
     supposed to generate for any given prompt, mirroring the behavior you’d expect from a real language model – but without actually generating any&#13;
     <html:span class="No-Break">&#13;
      meaningful content.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p class="callout-heading">&#13;
     How does the max_token parameter work?&#13;
    </html:p>&#13;
    <html:p class="callout">&#13;
     The goal here is to predict a&#13;
     <html:em class="italic">&#13;
      worst-case&#13;
     </html:em>&#13;
     scenario, but your actual cost will vary depending&#13;
     <html:a id="_idIndexMarker328">&#13;
     </html:a>&#13;
     on the LLM response size and in most regular scenarios should be lower than the&#13;
     <html:code class="literal">&#13;
      max_tokens&#13;
     </html:code>&#13;
     value. It’s still a very useful tool because it helps you understand how different metadata extraction strategies applied to different datasets can affect your total cost. For metadata extraction, this total cost will depend on the prompt and response size multiplied by the total number of calls the&#13;
     <html:span class="No-Break">&#13;
      extractor performs.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     <html:strong class="bold">&#13;
      CallbackManager&#13;
     </html:strong>&#13;
     is a debugging&#13;
     <html:a id="_idIndexMarker329">&#13;
     </html:a>&#13;
     mechanism that’s implemented in LlamaIndex that we will cover in more detail in&#13;
     <html:a>&#13;
      <html:span class="No-Break">&#13;
       <html:em class="italic">&#13;
        Chapter 10&#13;
       </html:em>&#13;
      </html:span>&#13;
     </html:a>&#13;
     ,&#13;
     <html:em class="italic">&#13;
      Prompt Engineering Guidelines and Best Practices&#13;
     </html:em>&#13;
     . In our example,&#13;
     <html:code class="literal">&#13;
      CallbackManager&#13;
     </html:code>&#13;
     is used in&#13;
     <html:a id="_idIndexMarker330">&#13;
     </html:a>&#13;
     combination with the&#13;
     <html:strong class="bold">&#13;
      TokenCountingHandler&#13;
     </html:strong>&#13;
     module, which is specialized in counting the tokens that are used for various operations involving an LLM. When defining&#13;
     <html:code class="literal">&#13;
      TokenCountingHandler&#13;
     </html:code>&#13;
     , you can also specify a&#13;
     <html:span class="No-Break">&#13;
      <html:code class="literal">&#13;
       tokenizer&#13;
      </html:code>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      parameter.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p class="callout-heading">&#13;
     What is the tokenizer and why do we need it?&#13;
    </html:p>&#13;
    <html:p class="callout">&#13;
     The&#13;
     <html:strong class="bold">&#13;
      tokenizer&#13;
     </html:strong>&#13;
     is responsible for&#13;
     <html:em class="italic">&#13;
      tokenization&#13;
     </html:em>&#13;
     of the text – that is, converting it into tokens – since LLMs work&#13;
     <html:a id="_idIndexMarker331">&#13;
     </html:a>&#13;
     with tokens and also measure their usage using tokens. When running a cost prediction for a specific prompt on a specific LLM, it’s important to use a tokenizer that is compatible with that specific LLM. Each LLM is often trained with a particular tokenizer, which determines how the text is split into tokens. Using the correct tokenizer is important if you want to make more accurate cost predictions. By default, LlamaIndex uses the&#13;
     <html:code class="literal">&#13;
      CL100K&#13;
     </html:code>&#13;
     tokenizer, which is specific for GPT-4. So, if you plan on using other LLMs, you may want to customize the tokenizer. More on this topic and on how we can optimize the costs of our RAG app will be covered in&#13;
     <html:a>&#13;
      <html:span class="No-Break">&#13;
       <html:em class="italic">&#13;
        Chapter 10&#13;
       </html:em>&#13;
      </html:span>&#13;
     </html:a>&#13;
     ,&#13;
     <html:em class="italic">&#13;
      Prompt Engineering Guidelines and&#13;
     </html:em>&#13;
     <html:span class="No-Break">&#13;
      <html:em class="italic">&#13;
       Best Practices&#13;
      </html:em>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      .&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Going back to our example, what happens under the hood is that when we run the extractor, it uses&#13;
     <html:code class="literal">&#13;
      MockLLM&#13;
     </html:code>&#13;
     – so, everything stays locally. Then,&#13;
     <html:code class="literal">&#13;
      TokenCountingHandler&#13;
     </html:code>&#13;
     <html:em class="italic">&#13;
      intercepts&#13;
     </html:em>&#13;
     both the prompt and the response from this&#13;
     <html:code class="literal">&#13;
      MockLLM&#13;
     </html:code>&#13;
     and counts the actual number of&#13;
     <html:span class="No-Break">&#13;
      tokens used.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     We will discuss a similar mechanism that can be used for estimating the costs of generating&#13;
     <html:a id="_idIndexMarker332">&#13;
     </html:a>&#13;
     certain types of Indexes and running queries later in&#13;
     <html:em class="italic">&#13;
      Chapters 5&#13;
     </html:em>&#13;
     <html:span class="No-Break">&#13;
      and&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      <html:em class="italic">&#13;
       6&#13;
      </html:em>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      .&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     In this example, I’ve shown you how to estimate the cost for only one type of extractor,&#13;
     <html:code class="literal">&#13;
      QuestionsAnsweredExtractor&#13;
     </html:code>&#13;
     . If you need to estimate the individual cost for more than one extractor in the same run, you can use the&#13;
     <html:code class="literal">&#13;
      token_counter.reset_counts()&#13;
     </html:code>&#13;
     method to reset the counters to zero before running the next&#13;
     <html:span class="No-Break">&#13;
      extraction round.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p class="callout-heading">&#13;
     The main lesson of this section&#13;
    </html:p>&#13;
    <html:p class="callout">&#13;
     While rich metadata unlocks many capabilities, overuse without conscious optimization can negatively impact operating costs and ruin your day. Make sure you take that into account. Apply best practices to minimize the costs and always estimate before running extractors on&#13;
     <html:span class="No-Break">&#13;
      large datasets.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Next, let’s talk about another very important aspect to consider&#13;
     <html:span class="No-Break">&#13;
      data privacy.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor098">&#13;
    </html:a>&#13;
   </html:div>&#13;
  </html:div>&#13;
 </html:body>&#13;
</html:html>
<html:html>&#13;
 <html:head>&#13;
  <html:title>&#13;
   Preserving privacy with metadata extractors, and not only&#13;
  </html:title>&#13;
 </html:head>&#13;
 <html:body>&#13;
  <html:div class="epub-source">&#13;
   <html:h1 id="_idParaDest-99">&#13;
    Preserving privacy with metadata extractors, and not only&#13;
   </html:h1>&#13;
   <html:div id="_idContainer039">&#13;
    pip install llama-index-llms-huggingface&#13;
    from llama_index.core.postprocessor import NERPIINodePostprocessor&#13;
from llama_index.llms.huggingface import HuggingFaceLLM&#13;
from llama_index.core.schema import NodeWithScore, TextNode&#13;
original = (&#13;
    "Dear Jane Doe. Your address has been recorded in "&#13;
    "our database. Please confirm it is valid: 8804 Vista "&#13;
    "Serro Dr. Cabo Robles, California(CA)."&#13;
)&#13;
node = TextNode(text=original)&#13;
processor = NERPIINodePostprocessor()&#13;
clean_nodes = processor.postprocess_nodes(&#13;
    [NodeWithScore(node=node)]&#13;
)&#13;
print(clean_nodes[0].node.get_text())&#13;
    Dear [PER_5]. Your address has been recorded in our database. Please confirm it is valid: 8804 [LOC_95] Dr. [LOC_111], [LOC_124]([LOC_135]).&#13;
    <html:p>&#13;
     Augmenting LLMs with your proprietary data – which, by the way, may belong to your customers in&#13;
     <html:a id="_idIndexMarker333">&#13;
     </html:a>&#13;
     many instances – can prove to be a challenging task in terms of&#13;
     <html:strong class="bold">&#13;
      data privacy&#13;
     </html:strong>&#13;
     . While a cloud based LLM solution can enrich your proprietary data and offer numerous advantages,&#13;
     <html:em class="italic">&#13;
      uncontrolled data sharing with external parties can quickly turn into a legal, security, and&#13;
     </html:em>&#13;
     <html:span class="No-Break">&#13;
      <html:em class="italic">&#13;
       regulatory nightmare&#13;
      </html:em>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      .&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Although the topic of data privacy is more stringent in the case of indexing and querying, utilizing metadata extractors can also raise potential privacy concerns to be aware of. Therefore, I believe a brief warning is&#13;
     <html:span class="No-Break">&#13;
      required already.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Since most extractors rely on processing content via LLMs to generate metadata, this means your actual data gets transmitted to and analyzed by external&#13;
     <html:span class="No-Break">&#13;
      cloud services.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     There is a risk&#13;
     <html:a id="_idIndexMarker334">&#13;
     </html:a>&#13;
     of exposure or mishandling of any personal or confidential information contained in this data, whether due to security lapses, insider risks at the LLM vendor, or&#13;
     <html:span class="No-Break">&#13;
      malicious activities.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p class="callout-heading">&#13;
     It’s not just OUR privacy at stake here&#13;
    </html:p>&#13;
    <html:p class="callout">&#13;
     Speaking of privacy issues, remember the example LlamaHub connectors we discussed earlier? Ingesting messages with&#13;
     <html:code class="literal">&#13;
      DiscordReader&#13;
     </html:code>&#13;
     transfers data from Discord servers. Given that Discord messages may contain private conversations, there is a potential privacy concern, especially if Discord’s terms of service and the expectations of the message senders are not taken into account. So, if your data includes private identities, healthcare details, financial information, and so on, allowing unrestrained extraction workflows could&#13;
     <html:span class="No-Break">&#13;
      be problematic.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Here are some ways to mitigate&#13;
     <html:span class="No-Break">&#13;
      privacy risks:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:ul>&#13;
     <html:li>&#13;
      Scrubbing personal data before ingestion into LlamaIndex using, for example,&#13;
      <html:code class="literal">&#13;
       PIINodePostprocessor&#13;
      </html:code>&#13;
      in combination with a local LLM. Check out the next section for a simple implementation guideline for&#13;
      <html:span class="No-Break">&#13;
       this option&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      Restricting metadata extraction to only non-sensitive subsets of nodes. Of course, this assumes that you manually classify the sensitivity of each Node. That would be impractical for automated&#13;
      <html:span class="No-Break">&#13;
       processing pipelines&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      Running LLMs locally instead of in the cloud where possible to limit external exposure. That depends, of course, on your available hardware and&#13;
      <html:span class="No-Break">&#13;
       model choice&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      Enabling encryption mechanisms if such features are available with certain LLM vendors. If privacy is a big concern in your implementation, you might want to consider&#13;
      <html:a id="_idIndexMarker335">&#13;
      </html:a>&#13;
      and read more about&#13;
      <html:strong class="bold">&#13;
       fully homomorphic encryption&#13;
      </html:strong>&#13;
      (&#13;
      <html:span class="No-Break">&#13;
       <html:strong class="bold">&#13;
        FHE&#13;
       </html:strong>&#13;
      </html:span>&#13;
      <html:span class="No-Break">&#13;
       ):&#13;
      </html:span>&#13;
      <html:a>&#13;
       <html:span class="No-Break">&#13;
        https://huggingface.co/blog/encrypted-llm&#13;
       </html:span>&#13;
      </html:a>&#13;
     </html:li>&#13;
    </html:ul>&#13;
    <html:p>&#13;
     These concerns and best practices apply to any type of interaction with an LLM. This subject has been discussed and analyzed in many available lectures and articles, so I’m not going&#13;
     <html:a id="_idIndexMarker336">&#13;
     </html:a>&#13;
     to go into further detail here. But that doesn’t mean it’s&#13;
     <html:span class="No-Break">&#13;
      not important!&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p class="callout-heading">&#13;
     Key message&#13;
    </html:p>&#13;
    <html:p class="callout">&#13;
     What you should understand is that using an LLM already poses a privacy risk for your data. Augmenting that LLM with an additional framework such as LlamaIndex means also augmenting the privacy&#13;
     <html:span class="No-Break">&#13;
      risks involved.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     In essence, additional diligence is needed when dealing with private data to ensure convenience does not override&#13;
     <html:span class="No-Break">&#13;
      security requirements.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor099">&#13;
    </html:a>&#13;
    <html:h2 id="_idParaDest-100">&#13;
     Scrubbing personal data and other sensitive information&#13;
    </html:h2>&#13;
    <html:p>&#13;
     In a world filled with nosy onlookers and data rulebooks, it’s crucial to be as cautious with your&#13;
     <html:a id="_idIndexMarker337">&#13;
     </html:a>&#13;
     data as a squirrel guarding its acorns in a crowded park! The good news is that there are solutions for ensuring privacy. And a convenient one&#13;
     <html:a id="_idIndexMarker338">&#13;
     </html:a>&#13;
     is already provided by the&#13;
     <html:span class="No-Break">&#13;
      LlamaIndex framework.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     <html:strong class="bold">&#13;
      Node post-processors&#13;
     </html:strong>&#13;
     can solve this problem&#13;
     <html:span class="No-Break">&#13;
      for us.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     In the&#13;
     <html:a id="_idIndexMarker339">&#13;
     </html:a>&#13;
     previous chapter, we discovered how node post-processors are used in a query engine. They are applied to the nodes that are returned from a retriever, before the response synthesis step, to apply different transformations on the nodes or node data itself. This is, at least, their most common&#13;
     <html:span class="No-Break">&#13;
      use case.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p class="callout-heading">&#13;
     But there’s also another reason to use them&#13;
    </html:p>&#13;
    <html:p class="callout">&#13;
     It turns out we can also use node processors outside of the query engine. Among other things, they can be used to clean up any sensitive data before extracting metadata using external LLMs,&#13;
     <html:span class="No-Break">&#13;
      for example.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     There are two methods available:&#13;
     <html:code class="literal">&#13;
      PIINodePostprocessor&#13;
     </html:code>&#13;
     and&#13;
     <html:code class="literal">&#13;
      NERPIINodePostprocessor&#13;
     </html:code>&#13;
     . The first one is designed to work with any local LLM that you may have on hand, while the other is customized for using a specialized NER model. In case&#13;
     <html:a id="_idIndexMarker340">&#13;
     </html:a>&#13;
     you’re not familiar with the acronym,&#13;
     <html:strong class="bold">&#13;
      PII&#13;
     </html:strong>&#13;
     stands for&#13;
     <html:strong class="bold">&#13;
      Personally&#13;
     </html:strong>&#13;
     <html:span class="No-Break">&#13;
      <html:strong class="bold">&#13;
       Identifiable Information&#13;
      </html:strong>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      .&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Here’s a simple example of using&#13;
     <html:code class="literal">&#13;
      NERPIINodePostprocessor&#13;
     </html:code>&#13;
     to clean up the data. This method uses a NER model from&#13;
     <html:strong class="bold">&#13;
      Hugging Face&#13;
     </html:strong>&#13;
     to do the job. Because I wanted to keep it simple, I didn’t specify a particular model. Therefore, you may expect a warning and the HuggingFaceLLM will probably default to using the&#13;
     <html:code class="literal">&#13;
      dbmdz/bert-large-cased-finetuned-conll03-english&#13;
     </html:code>&#13;
     model, as documented&#13;
     <html:span class="No-Break">&#13;
      here:&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      .&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Make sure&#13;
     <html:a id="_idIndexMarker341">&#13;
     </html:a>&#13;
     you install the corresponding integration&#13;
     <html:span class="No-Break">&#13;
      package first:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Also, on the first run, the code will download the model from Hugging Face and you’ll need to make sure you have at least 1.5 GB of free space available on&#13;
     <html:span class="No-Break">&#13;
      your machine.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Here is&#13;
     <html:span class="No-Break">&#13;
      the code:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     The output should be similar&#13;
     <html:span class="No-Break">&#13;
      to this:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Looking at the results, we can see that the names have been replaced with placeholders so that the&#13;
     <html:a id="_idIndexMarker342">&#13;
     </html:a>&#13;
     data can now be safely passed to any external LLM. The beauty of this method is that, on return, the answer can be processed back and the placeholders can be replaced with the original data, resulting in a seamless&#13;
     <html:span class="No-Break">&#13;
      user experience.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     The actual mapping between placeholders and real data will be stored in&#13;
     <html:code class="literal">&#13;
      clean_nodes[0].node.metadata&#13;
     </html:code>&#13;
     . This metadata will not be sent to the LLM and can later be used to produce the original names during&#13;
     <html:span class="No-Break">&#13;
      response synthesis.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Next, we’ll discuss how to improve the efficiency of the&#13;
     <html:span class="No-Break">&#13;
      ingestion pipeline.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor100">&#13;
    </html:a>&#13;
   </html:div>&#13;
  </html:div>&#13;
 </html:body>&#13;
</html:html>
<html:html>&#13;
 <html:head>&#13;
  <html:title>&#13;
   Using the ingestion pipeline to increase efficiency&#13;
  </html:title>&#13;
 </html:head>&#13;
 <html:body>&#13;
  <html:div class="epub-source">&#13;
   <html:h1 id="_idParaDest-101">&#13;
    Using the ingestion pipeline to increase efficiency&#13;
   </html:h1>&#13;
   <html:div id="_idContainer039">&#13;
    from llama_index.core import SimpleDirectoryReader&#13;
from llama_index.core.extractors import SummaryExtractor,QuestionsAnsweredExtractor&#13;
from llama_index.core.node_parser import TokenTextSplitter&#13;
from llama_index.core.ingestion import IngestionPipeline, IngestionCache&#13;
from llama_index.core.schema import TransformComponent&#13;
class CustomTransformation(TransformComponent):&#13;
  def __call__(self, nodes, **kwargs):&#13;
    # run any node transformation logic here&#13;
    return nodes&#13;
    reader = SimpleDirectoryReader('files')&#13;
documents = reader.load_data()&#13;
try:&#13;
    cached_hashes = IngestionCache.from_persist_path(&#13;
"./ingestion_cache.json"&#13;
)&#13;
    print("Cache file found. Running using cache")&#13;
except:&#13;
    cached_hashes = ""&#13;
    print("No cache file found. Running without cache")&#13;
    pipeline = IngestionPipeline(&#13;
    transformations = [&#13;
        CustomTransformation(),&#13;
        TokenTextSplitter(&#13;
            separator=" ",&#13;
            chunk_size=512,&#13;
            chunk_overlap=128),&#13;
        SummaryExtractor(),&#13;
        QuestionsAnsweredExtractor(&#13;
            questions=3&#13;
        )&#13;
    ],&#13;
    cache=cached_hashes&#13;
)&#13;
    nodes = pipeline.run(&#13;
    documents=documents,&#13;
    show_progress=True,&#13;
)&#13;
pipeline.cache.persist("./ingestion_cache.json")&#13;
print("All documents loaded")&#13;
    from llama_index.core import Settings&#13;
Settings.transformations = [&#13;
    CustomTransformation(),&#13;
    TokenTextSplitter(&#13;
        separator=" ",&#13;
        chunk_size=512,&#13;
        chunk_overlap=128&#13;
    ),&#13;
    SummaryExtractor(),&#13;
    QuestionsAnsweredExtractor(&#13;
        questions=3&#13;
    )&#13;
]&#13;
    <html:p>&#13;
     Starting with&#13;
     <html:code class="literal">&#13;
      version 0.9&#13;
     </html:code>&#13;
     , the LlamaIndex framework introduced a really neat concept: the&#13;
     <html:a id="_idIndexMarker343">&#13;
     </html:a>&#13;
     so-called&#13;
     <html:span class="No-Break">&#13;
      <html:strong class="bold">&#13;
       ingestion pipeline&#13;
      </html:strong>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      .&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p class="callout-heading">&#13;
     A simple analogy&#13;
    </html:p>&#13;
    <html:p class="callout">&#13;
     An ingestion pipeline is a bit like a conveyor belt in a factory. In the context of LlamaIndex, it’s a setup that takes your raw data and gets it ready to be integrated into your RAG workflow. It does&#13;
     <html:a id="_idIndexMarker344">&#13;
     </html:a>&#13;
     this by running the data through a series of steps – called&#13;
     <html:strong class="bold">&#13;
      transformations&#13;
     </html:strong>&#13;
     – one by one. The key idea is to break the ingestion process into a series of reusable transformations that are applied to input data. This helps standardize and customize ingestion flows for different use cases. Think of transformations as different workstations along this conveyor belt. As your raw data moves along, it hits different stations where something specific happens. It might be split into sentences at one station – that’s your&#13;
     <html:code class="literal">&#13;
      SentenceSplitter&#13;
     </html:code>&#13;
     – and have a title extracted at another – such as&#13;
     <html:span class="No-Break">&#13;
      using&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      <html:code class="literal">&#13;
       TitleExtractor&#13;
      </html:code>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      .&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     If the factory’s default workstations don’t quite cut it for you, no worries! Let’s say you have this special tool you want to use on your raw data. LlamaIndex makes it easy to plug in your custom tool –&#13;
     <html:strong class="bold">&#13;
      custom transformation&#13;
     </html:strong>&#13;
     . Just say what your tool does – for example, replacing acronyms with complete names using a dictionary – and LlamaIndex will happily add it&#13;
     <html:a id="_idIndexMarker345">&#13;
     </html:a>&#13;
     to your pipeline.&#13;
     <html:span class="No-Break">&#13;
      <html:em class="italic">&#13;
       Figure 4&#13;
      </html:em>&#13;
     </html:span>&#13;
     <html:em class="italic">&#13;
      .4&#13;
     </html:em>&#13;
     provides an ingestion&#13;
     <html:span class="No-Break">&#13;
      pipeline schematic:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:div>&#13;
     <html:div class="IMG---Figure" id="_idContainer038">&#13;
      <html:img src="../Images/B21861_04_4.jpg"/>&#13;
     </html:div>&#13;
    </html:div>&#13;
    <html:p class="IMG---Caption" lang="en-US">&#13;
     Figure 4.4 – An ingestion pipeline at work&#13;
    </html:p>&#13;
    <html:p>&#13;
     The most important thing about the ingestion pipeline is that&#13;
     <html:em class="italic">&#13;
      it remembers the data it has already processed&#13;
     </html:em>&#13;
     . It runs a hashing function on the combination of each node data and each transformation run. On any future runs of the same transformation on the same nodes, the hashes will be identical, so the cached, already processed data will be used instead of re-running&#13;
     <html:span class="No-Break">&#13;
      the transformation.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p class="callout-heading">&#13;
     What does this mean for me?&#13;
    </html:p>&#13;
    <html:p class="callout">&#13;
     If you send the same document through the pipeline again, it’s like having a fast-track lane where it skips the line because it’s already been handled. This is cool because it saves you both time and money by avoiding useless multiple processing of the&#13;
     <html:span class="No-Break">&#13;
      same data.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     By default, the cache is stored locally but you can customize the storage options and use any external database provider you prefer. Let’s cover an example of how the pipeline could be implemented. I will explain the code section by section to make it easier&#13;
     <html:span class="No-Break">&#13;
      to follow.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Let’s start with the first section of&#13;
     <html:span class="No-Break">&#13;
      the code:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     After taking care&#13;
     <html:a id="_idIndexMarker346">&#13;
     </html:a>&#13;
     of the required imports, to show you how to customize your pipeline, I have defined a class called&#13;
     <html:code class="literal">&#13;
      CustomTransformation&#13;
     </html:code>&#13;
     . This will&#13;
     <html:a id="_idIndexMarker347">&#13;
     </html:a>&#13;
     be fed into the pipeline later. In my example, no actual processing takes place, so this will return the&#13;
     <html:span class="No-Break">&#13;
      nodes unchanged.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Let’s continue with the&#13;
     <html:span class="No-Break">&#13;
      second section:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     The preceding code is&#13;
     <html:a id="_idIndexMarker348">&#13;
     </html:a>&#13;
     responsible for fetching all content of the&#13;
     <html:code class="literal">&#13;
      files&#13;
     </html:code>&#13;
     subfolder into documents. Next, the code checks if the cache file already exists and attempts to load it into memory. Remember, the cache file contains the hashes and the results generated by the previous runs. The first time you run the code, there will be no file, so the code won’t load any&#13;
     <html:span class="No-Break">&#13;
      cached values.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Let’s move on to the&#13;
     <html:span class="No-Break">&#13;
      third section:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     This is the part where we define our pipeline. As you can see, it will contain four transformations. The first is our&#13;
     <html:code class="literal">&#13;
      CustomTransformation&#13;
     </html:code>&#13;
     , followed by&#13;
     <html:code class="literal">&#13;
      TokenTextSplitter&#13;
     </html:code>&#13;
     , which is responsible for breaking each document into smaller chunks and generating nodes. The third transformation extracts the summaries metadata and the last one extracts a set of questions that each node&#13;
     <html:span class="No-Break">&#13;
      can answer.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     If you want to take a peek at the result, you could add&#13;
     <html:code class="literal">&#13;
      print(nodes[0])&#13;
     </html:code>&#13;
     at the end of the entire script. Notice that, in the&#13;
     <html:code class="literal">&#13;
      cache&#13;
     </html:code>&#13;
     parameter, we also specify the source of the cache for the pipeline. If that is empty, it will be ignored; otherwise, it will be used to avoid any&#13;
     <html:a id="_idIndexMarker349">&#13;
     </html:a>&#13;
     unnecessary processing by retrieving values from&#13;
     <html:span class="No-Break">&#13;
      the cache.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     And now, the&#13;
     <html:span class="No-Break">&#13;
      final part:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     This is where we run the pipeline with the&#13;
     <html:code class="literal">&#13;
      show_progress&#13;
     </html:code>&#13;
     option set to&#13;
     <html:code class="literal">&#13;
      True&#13;
     </html:code>&#13;
     . This will make the pipeline’s progress visible and help you better understand what’s happening in the background. In the end, we save the results in the cache file to avoid re-processing in the&#13;
     <html:span class="No-Break">&#13;
      next run.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p class="callout-heading">&#13;
     A quick side note:&#13;
    </html:p>&#13;
    <html:p class="callout">&#13;
     Even if you saved a cache file, any changes you make in your pipeline logic will not be cached and will have to be processed at the&#13;
     <html:span class="No-Break">&#13;
      next run.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     You should also know there is an alternative to manually defining and running the pipeline every time you want to ingest more data. Just like with the node parsers, we can define the transformations inside&#13;
     <html:code class="literal">&#13;
      Settings&#13;
     </html:code>&#13;
     <html:span class="No-Break">&#13;
      like this:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     In conclusion, an ingestion pipeline is a super-efficient way to get your data automatically&#13;
     <html:a id="_idIndexMarker350">&#13;
     </html:a>&#13;
     prepped and polished by running it through customizable sets of transformations until it’s just right for your app&#13;
     <html:span class="No-Break">&#13;
      or database.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     As we build up the PITS tutoring app, we’ll leverage ingestion pipelines and you’ll get the opportunity to experiment more with&#13;
     <html:span class="No-Break">&#13;
      this concept.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Next, let’s talk about more&#13;
     <html:span class="No-Break">&#13;
      complex scenarios.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor101">&#13;
    </html:a>&#13;
   </html:div>&#13;
  </html:div>&#13;
 </html:body>&#13;
</html:html>
<html:html>&#13;
 <html:head>&#13;
  <html:title>&#13;
   Handling documents that contain a mix of text and tabular data&#13;
  </html:title>&#13;
 </html:head>&#13;
 <html:body>&#13;
  <html:div class="epub-source">&#13;
   <html:h1 id="_idParaDest-102">&#13;
    Handling documents that contain a mix of text and tabular data&#13;
   </html:h1>&#13;
   <html:div id="_idContainer039">&#13;
    <html:p>&#13;
     Data is not always simple. Many real-world documents, such as research papers, financial reports, and others, contain a mix of unstructured text, as well as structured tabular data&#13;
     <html:a id="_idIndexMarker351">&#13;
     </html:a>&#13;
     in tables. Ingesting such heterogeneous&#13;
     <html:a id="_idIndexMarker352">&#13;
     </html:a>&#13;
     documents presents an additional challenge - we need to not only extract text but also identify, parse, and process tables embedded within the text. Because, sometimes you get tables, sometimes you get text and sometimes you have to deal with a mix&#13;
     <html:span class="No-Break">&#13;
      of both.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     LlamaIndex provides&#13;
     <html:code class="literal">&#13;
      UnstructuredElementNodeParser&#13;
     </html:code>&#13;
     to tackle such documents containing both free-form text as well as tables and other structured elements. It leverages the&#13;
     <html:code class="literal">&#13;
      Unstructured&#13;
     </html:code>&#13;
     library to analyze the document layout and delineate text sections&#13;
     <html:span class="No-Break">&#13;
      from tables.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     This parser works exclusively on HTML files and can extract two types&#13;
     <html:span class="No-Break">&#13;
      of nodes:&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:ul>&#13;
     <html:li>&#13;
      <html:strong class="bold">&#13;
       Text nodes&#13;
      </html:strong>&#13;
      : Containing&#13;
      <html:a id="_idIndexMarker353">&#13;
      </html:a>&#13;
      the&#13;
      <html:span class="No-Break">&#13;
       text&#13;
      </html:span>&#13;
      <html:span class="No-Break">&#13;
       <html:a id="_idIndexMarker354">&#13;
       </html:a>&#13;
      </html:span>&#13;
      <html:span class="No-Break">&#13;
       chunks&#13;
      </html:span>&#13;
     </html:li>&#13;
     <html:li>&#13;
      <html:strong class="bold">&#13;
       Table nodes&#13;
      </html:strong>&#13;
      : Containing&#13;
      <html:a id="_idIndexMarker355">&#13;
      </html:a>&#13;
      the table data and metadata, such&#13;
      <html:a id="_idIndexMarker356">&#13;
      </html:a>&#13;
      <html:span class="No-Break">&#13;
       as coordinates&#13;
      </html:span>&#13;
     </html:li>&#13;
    </html:ul>&#13;
    <html:p>&#13;
     Storing these elements as separate nodes allows more modular and meaningful processing later in the RAG workflow. The text can be indexed and searched normally with elements like keywords. The tables can be loaded into a&#13;
     <html:strong class="bold">&#13;
      pandas DataFrame&#13;
     </html:strong>&#13;
     or any structured database for SQL-based access. So, in complex cases involving mixed data types, leveraging&#13;
     <html:code class="literal">&#13;
      UnstructuredElementNodeParser&#13;
     </html:code>&#13;
     before ingestion enables better&#13;
     <html:span class="No-Break">&#13;
      data organization.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     You can find&#13;
     <html:a id="_idIndexMarker357">&#13;
     </html:a>&#13;
     a complete demo for using&#13;
     <html:code class="literal">&#13;
      UnstructuredElementNodeParser&#13;
     </html:code>&#13;
     in the official LlamaIndex&#13;
     <html:span class="No-Break">&#13;
      documentation:&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      https://docs.llamaindex.ai/en/stable/examples/query_engine/sec_tables/tesla_10q_table.html&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      .&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     With these new concepts in our toolbox, let’s continue building our&#13;
     <html:span class="No-Break">&#13;
      tutoring project.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor102">&#13;
    </html:a>&#13;
   </html:div>&#13;
  </html:div>&#13;
 </html:body>&#13;
</html:html>
<html:html>&#13;
 <html:head>&#13;
  <html:title>&#13;
   Hands-on – ingesting study materials into our PITS&#13;
  </html:title>&#13;
 </html:head>&#13;
 <html:body>&#13;
  <html:div class="epub-source">&#13;
   <html:h1 id="_idParaDest-103">&#13;
    Hands-on – ingesting study materials into our PITS&#13;
   </html:h1>&#13;
   <html:div id="_idContainer039">&#13;
    <html:p>&#13;
     It’s time for some practice. We now have everything we need to continue building our project. Let’s write the&#13;
     <html:span class="No-Break">&#13;
      <html:code class="literal">&#13;
       documend_uploader.py&#13;
      </html:code>&#13;
     </html:span>&#13;
     <html:span class="No-Break">&#13;
      module.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     This module&#13;
     <html:a id="_idIndexMarker358">&#13;
     </html:a>&#13;
     will take care of ingesting and preparing our available study material. The user can upload any available books, technical documentation, or existing articles to provide more context to&#13;
     <html:span class="No-Break">&#13;
      our tutor.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:ol>&#13;
     <html:li>&#13;
      First, we have&#13;
      from global_settings import STORAGE_PATH, CACHE_FILE&#13;
from logging_functions import log_action&#13;
from llama_index import SimpleDirectoryReader, VectorStoreIndex&#13;
from llama_index.ingestion import IngestionPipeline, IngestionCache&#13;
from llama_index.text_splitter import TokenTextSplitter&#13;
from llama_index.extractors import SummaryExtractor&#13;
from llama_index.embeddings import OpenAIEmbedding&#13;
     <html:span class="No-Break">&#13;
       the imports:&#13;
      </html:span>&#13;
      </html:li>&#13;
     <html:li>&#13;
      Next, we must define the main function that’s responsible for handling the ingestion process. You’ll notice that it uses an ingestion pipeline to both streamline the&#13;
      def ingest_documents():&#13;
    documents = SimpleDirectoryReader(&#13;
        STORAGE_PATH,&#13;
        filename_as_id = True&#13;
    ).load_data()&#13;
    for doc in documents:&#13;
        print(doc.id_)&#13;
        log_action(&#13;
            f"File '{doc.id_}' uploaded user",&#13;
            action_type="UPLOAD"&#13;
        )&#13;
      <html:a id="_idIndexMarker359">&#13;
      </html:a>&#13;
      code but also benefit&#13;
      <html:span class="No-Break">&#13;
       from caching:&#13;
      </html:span>&#13;
      <html:ul>&#13;
       <html:li>&#13;
        The function loads all readable documents available in&#13;
        <html:code class="literal">&#13;
         STORAGE_PATH&#13;
        </html:code>&#13;
        , which was defined&#13;
        <html:span class="No-Break">&#13;
         in&#13;
        </html:span>&#13;
        <html:span class="No-Break">&#13;
         <html:code class="literal">&#13;
          global_settings.py&#13;
         </html:code>&#13;
        </html:span>&#13;
        <html:span class="No-Break">&#13;
         .&#13;
        </html:span>&#13;
       </html:li>&#13;
       <html:li>&#13;
        For each document processed, a new event is stored in our log file using&#13;
        <html:code class="literal">&#13;
         log_action&#13;
        </html:code>&#13;
        <html:span class="No-Break">&#13;
         from&#13;
        </html:span>&#13;
        <html:span class="No-Break">&#13;
         <html:code class="literal">&#13;
          logging_functions.py&#13;
         </html:code>&#13;
        </html:span>&#13;
        <html:span class="No-Break">&#13;
         .&#13;
        </html:span>&#13;
       </html:li>&#13;
      </html:ul>&#13;
     </html:li>&#13;
     <html:li>&#13;
      Next, the function checks if there’s already cached pipeline data&#13;
          try:&#13;
        cached_hashes = IngestionCache.from_persist_path(&#13;
            CACHE_FILE&#13;
            )&#13;
        print("Cache file found. Running using cache")&#13;
    except:&#13;
        cached_hashes = ""&#13;
        print("No cache file found. Running without")&#13;
     <html:span class="No-Break">&#13;
       to use:&#13;
      </html:span>&#13;
      </html:li>&#13;
     <html:li>&#13;
      The next step&#13;
          pipeline = IngestionPipeline(&#13;
        transformations=[&#13;
            TokenTextSplitter(&#13;
                chunk_size=1024,&#13;
                chunk_overlap=20&#13;
            ),&#13;
            SummaryExtractor(summaries=['self']),&#13;
            OpenAIEmbedding()&#13;
        ],&#13;
        cache=cached_hashes&#13;
    )&#13;
    nodes = pipeline.run(documents=documents)&#13;
    pipeline.cache.persist(CACHE_FILE)&#13;
    return nodes&#13;
      <html:a id="_idIndexMarker360">&#13;
      </html:a>&#13;
      is to define and run the pipeline. If hashes from the cache file correspond, no operations should be processed; instead, the values will be directly loaded from&#13;
      <html:span class="No-Break">&#13;
       the cache:&#13;
      </html:span>&#13;
      <html:p class="list-inset">&#13;
       We run three transformations in&#13;
       <html:span class="No-Break">&#13;
        the pipeline:&#13;
       </html:span>&#13;
      </html:p>&#13;
      <html:ol>&#13;
       <html:li class="upper-roman">&#13;
        Basic chunking&#13;
        <html:span class="No-Break">&#13;
         using&#13;
        </html:span>&#13;
        <html:span class="No-Break">&#13;
         <html:code class="literal">&#13;
          TokenTextSplitter&#13;
         </html:code>&#13;
        </html:span>&#13;
        <html:span class="No-Break">&#13;
         .&#13;
        </html:span>&#13;
       </html:li>&#13;
       <html:li class="upper-roman">&#13;
        A metadata extractor that summarizes&#13;
        <html:span class="No-Break">&#13;
         each node.&#13;
        </html:span>&#13;
       </html:li>&#13;
       <html:li class="upper-roman">&#13;
        Embedding generation using&#13;
        <html:code class="literal">&#13;
         OpenAIEmbedding&#13;
        </html:code>&#13;
        . Don’t worry about this step for now. I will explain it thoroughly in&#13;
        <html:a>&#13;
         <html:span class="No-Break">&#13;
          <html:em class="italic">&#13;
           Chapter 5&#13;
          </html:em>&#13;
         </html:span>&#13;
        </html:a>&#13;
        ,&#13;
        <html:em class="italic">&#13;
         Indexing&#13;
        </html:em>&#13;
        <html:span class="No-Break">&#13;
         <html:em class="italic">&#13;
          with LlamaIndex&#13;
         </html:em>&#13;
        </html:span>&#13;
        <html:span class="No-Break">&#13;
         .&#13;
        </html:span>&#13;
       </html:li>&#13;
      </html:ol>&#13;
     </html:li>&#13;
     <html:li>&#13;
      In the end, the function&#13;
      <html:a id="_idIndexMarker361">&#13;
      </html:a>&#13;
      saves the current data in the cache file and returns the&#13;
      <html:span class="No-Break">&#13;
       processed nodes.&#13;
      </html:span>&#13;
     </html:li>&#13;
    </html:ol>&#13;
    <html:p>&#13;
     That’s it for now. We have now uploaded and prepared the study materials for future processing. We’ll continue with the indexing part in the&#13;
     <html:span class="No-Break">&#13;
      next chapter.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:a id="_idTextAnchor103">&#13;
    </html:a>&#13;
   </html:div>&#13;
  </html:div>&#13;
 </html:body>&#13;
</html:html>
<html:html>&#13;
 <html:head>&#13;
  <html:title>&#13;
   Summary&#13;
  </html:title>&#13;
 </html:head>&#13;
 <html:body>&#13;
  <html:div class="epub-source">&#13;
   <html:h1 id="_idParaDest-104">&#13;
    Summary&#13;
   </html:h1>&#13;
   <html:div id="_idContainer039">&#13;
    <html:p>&#13;
     LlamaHub offers a variety of pre-built data loaders, streamlining the process of importing data from various sources as documents. This eliminates the need for creating unique parsers for different&#13;
     <html:span class="No-Break">&#13;
      data formats.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     After data is imported, it undergoes further processing into nodes, and we discussed various customization&#13;
     <html:span class="No-Break">&#13;
      options available.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     There’s a broad range of options for metadata extraction, and the parsing process can be tailored to meet&#13;
     <html:span class="No-Break">&#13;
      specific requirements.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     Developing pipelines for data ingestion is an invaluable tool for enhancing the efficiency, both in terms of cost and time, of our RAG applications. It’s also vital to keep privacy considerations&#13;
     <html:span class="No-Break">&#13;
      in mind.&#13;
     </html:span>&#13;
    </html:p>&#13;
    <html:p>&#13;
     With data ingestion completed, let’s continue our journey and discover the indexing powers&#13;
     <html:span class="No-Break">&#13;
      of LlamaIndex.&#13;
     </html:span>&#13;
    </html:p>&#13;
   </html:div>&#13;
  </html:div>&#13;
 </html:body>&#13;
</html:html></body></html>