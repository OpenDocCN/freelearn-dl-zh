<html><head></head><body>
<div id="book-content">
<div id="sbo-rt-content"><div id="_idContainer055">
			<h1 id="_idParaDest-144" class="chapter-number"><a id="_idTextAnchor143"/>8</h1>
			<h1 id="_idParaDest-145"><a id="_idTextAnchor144"/>Real-World Use Case – Making Your Application Available on ChatGPT</h1>
			<p>In earlier chapters, we learned quite a lot. We learned how to create and optimize prompts, how to create semantic and native functions and put them in Semantic Kernel, and how to use a planner to automatically decide which functions of the kernel to use to solve a <span class="No-Break">user problem.</span></p>
			<p>In the previous two chapters, we learned how to augment<a id="_idIndexMarker525"/> our kernel with <strong class="bold">memories</strong>, including memories built from external data, which allows us to build more personalized applications and use data that is recent and that we have control over to generate answers, instead of using only the data that was used to train the LLM, which is frequently <span class="No-Break">not public.</span></p>
			<p>In this final chapter, we will change gears. Instead of creating new functionality, we will learn how to make the functionality we have already created available for many more users. We will use the home automation<a id="_idIndexMarker526"/> application that we wrote in <a href="B21826_05.xhtml#_idTextAnchor106"><span class="No-Break"><em class="italic">Chapter 5</em></span></a> and make it available through the OpenAI custom <strong class="bold">GPT Store</strong>, making it available to the hundreds of millions of users that already use ChatGPT, and use ChatGPT as the UI of <span class="No-Break">our application.</span></p>
			<p>Besides the obvious benefits of quickly being able to make an application available to hundreds of thousands of users, another benefit is that you don’t even need to build a <strong class="bold">user interface</strong> (<strong class="bold">UI</strong>) for <a id="_idIndexMarker527"/>your application. You can build the main functionality and use ChatGPT as the UI. Of course, this has limitations. The AI is text based and you have little control over it, but on the other hand, you can test and deploy your application a lot faster, and build a dedicated <span class="No-Break">UI later.</span></p>
			<p>In this chapter, we’ll be covering the <span class="No-Break">following topics:</span></p>
			<ul>
				<li>Creating a custom GPT in the <span class="No-Break">OpenAI store</span></li>
				<li>Creating a web API wrapper for an application developed with <span class="No-Break">Semantic Kernel</span></li>
				<li>Connecting the custom GPT with the OpenAI store through the web <span class="No-Break">API wrapper</span></li>
			</ul>
			<p>By the end of the chapter, you will have an application that is available to all <span class="No-Break">ChatGPT users.</span></p>
			<h1 id="_idParaDest-146"><a id="_idTextAnchor145"/>Technical requirements</h1>
			<p>To complete this chapter, you will need to have a recent, supported version of your preferred Python or C# <span class="No-Break">development environment:</span></p>
			<ul>
				<li>For Python, the minimum supported version is Python 3.10, and the recommended version is <span class="No-Break">Python 3.11</span></li>
				<li>For C#, the minimum supported version is .<span class="No-Break">NET 8</span></li>
			</ul>
			<p>In this chapter, we will call OpenAI services. Given the amount that companies spend on training these LLMs, it’s no surprise that using these services is not free. You will need an <strong class="bold">OpenAI API</strong> key, obtained either directly through <strong class="bold">OpenAI</strong> or <strong class="bold">Microsoft</strong>, via the <strong class="bold">Azure </strong><span class="No-Break"><strong class="bold">OpenAI</strong></span><span class="No-Break"> service.</span></p>
			<p>If you are using .NET, the code for this chapter is <span class="No-Break">at </span><a href="https://github.com/PacktPublishing/Building-AI-Applications-with-Microsoft-Semantic-Kernel/tree/main/dotnet/ch8"><span class="No-Break">https://github.com/PacktPublishing/Building-AI-Applications-with-Microsoft-Semantic-Kernel/tree/main/dotnet/ch8</span></a><span class="No-Break">.</span></p>
			<p>If you are using Python, the code for this chapter is <span class="No-Break">at </span><a href="https://github.com/PacktPublishing/Building-AI-Applications-with-Microsoft-Semantic-Kernel/tree/main/python/ch8"><span class="No-Break">https://github.com/PacktPublishing/Building-AI-Applications-with-Microsoft-Semantic-Kernel/tree/main/python/ch8</span></a><span class="No-Break">.</span></p>
			<p>To create your custom GPT, you will need an account <span class="No-Break">with OpenAI.</span></p>
			<p>You can install the required packages by going to the GitHub repository and using the following: <strong class="source-inline">pip install -</strong><span class="No-Break"><strong class="source-inline">r requirements.txt</strong></span><span class="No-Break">.</span></p>
			<h1 id="_idParaDest-147"><a id="_idTextAnchor146"/>Custom GPT agents</h1>
			<p>On <a id="_idIndexMarker528"/>November 6, 2023, OpenAI introduced functionality that allows users to create custom, personalized versions of ChatGPT. These custom GPTs created by users can be shared with other users through OpenAI’s GPT Store. This allows users without programming experience to add functionality to ChatGPT by simply writing instructions in natural language, and it also allows users with programming experience to connect ChatGPT to their applications, making such applications available to hundreds of millions <span class="No-Break">of users.</span></p>
			<p>Initially, these <a id="_idIndexMarker529"/>were called “custom GPTs,” but now they are simply called GPTs. That may be confusing since the transformer technology used in most AI models is <a id="_idIndexMarker530"/>called <strong class="bold">generative pre-trained transformer</strong> (<strong class="bold">GPT</strong>), and the OpenAI implementation of these models is also called GPT with a version, such as GPT-3.5 or <span class="No-Break">GPT 4.</span></p>
			<p>In this section, when we use the name “GPT,” unless otherwise noted, it means the custom GPTs that you can create inside <span class="No-Break">of ChatGPT.</span></p>
			<p>These GPTs can use custom prompts, such as the ones we use in semantic functions, and additional data, such as what we use in RAG models. You can add custom prompts and documents to your custom GPT by using a web interface, which we will show in the <span class="No-Break">next subsection.</span></p>
			<p>In addition, you can also allow your GPT to call external functions through a web API. Many companies created these interfaces and connected them to custom GPTs, such as Wolfram (the creators of the scientific software Mathematica), design companies such as Canva and Adobe, and <span class="No-Break">many others.</span></p>
			<p>In this section, as we did <a href="B21826_05.xhtml#_idTextAnchor106"><span class="No-Break"><em class="italic">Chapter 5</em></span></a>, imagine you work for a home automation company that has a product that allows someone to control their home through a device in their house, and now you want to allow them to do it with ChatGPT. We created the native function for this in <a href="B21826_05.xhtml#_idTextAnchor106"><span class="No-Break"><em class="italic">Chapter 5</em></span></a>, and in this chapter, we are going to use Microsoft Semantic Kernel tools to make that functionality available for <span class="No-Break">ChatGPT users.</span></p>
			<p>Before we start that more complex example, let’s first create a simpler custom GPT just to familiarize ourselves with <span class="No-Break">the process.</span></p>
			<h2 id="_idParaDest-148"><a id="_idTextAnchor147"/>Creating a custom GPT</h2>
			<p>To create a GPT, you <a id="_idIndexMarker531"/>can navigate to <a href="https://chat.openai.com/gpts/">https://chat.openai.com/gpts/</a> and click the <strong class="bold">Create</strong> button on the top-right corner, or navigate directly to <a href="https://chat.openai.com/gpts/editor">https://chat.openai.com/gpts/editor</a>. This will open a web interface that allows you to create a GPT. As you’d expect, you can create the GPT simply by chatting with ChatGPT. You can add custom instructions, specify the tone of the answers, and <span class="No-Break">much more.</span></p>
			<div>
				<div id="_idContainer042" class="IMG---Figure">
					<img src="image/B21826_08_1.jpg" alt="Figure 8.1 – Creating a GPT using the OpenAI editor" width="1006" height="494"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.1 – Creating a GPT using the OpenAI editor</p>
			<p>The <strong class="bold">Configure</strong> tab is where<a id="_idIndexMarker532"/> you will give your GPT a name and description, and where you can add custom actions that connect your GPT with <span class="No-Break">external APIs:</span></p>
			<div>
				<div id="_idContainer043" class="IMG---Figure">
					<img src="image/B21826_08_2.jpg" alt="Figure 8.2 – The OpenAI UI to configure your GPT" width="1419" height="1086"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.2 – The OpenAI UI to configure your GPT</p>
			<p>You can use<a id="_idIndexMarker533"/> the <strong class="bold">Create</strong> interface to fill the configuration interface. For an initial example, I will build a GPT that answers questions about the Sherlock Holmes books. The first thing I told ChatGPT was <strong class="source-inline">I want to make a GPT that answers questions about Sherlock Holmes</strong> and it answered back with <strong class="source-inline">How about naming it Detective Guide? Does that sound good to you?</strong>. I answered back with <strong class="source-inline">Yes</strong>, and the configuration was updated, adding <strong class="source-inline">Detective Guide</strong> as the name. Without asking, ChatGPT also automatically generated an appropriate profile picture for <span class="No-Break">my GPT.</span></p>
			<p>I did a few more <span class="No-Break">configuration steps:</span></p>
			<pre class="console">
I want it to be only about the canonical works by Arthur Conan Doyle, but I want it to be helpful for high school students that are trying to understand it better - the influence of the works in modern media and the context in which the work was written.</pre>			<p>I also uploaded the<a id="_idIndexMarker534"/> text files with the contents of the books, which you can find online and also in <strong class="source-inline">/data/sherlock_holmes/</strong>, and added this <span class="No-Break">additional configuration:</span></p>
			<pre class="console">
When providing answers about the books, I want the gpt to base the answers on the files I have uploaded and quote passages found in them.
Do not answer any questions that are not related to the Sherlock Holmes' books. If a user asks questions about other topics, answer that this is not your area of expertise.</pre>			<p>After every configuration step, ChatGPT asks me if there’s anything more I want to add. At this point, I said <strong class="source-inline">no</strong>, which enabled the <strong class="bold">Create</strong> button on the top-right corner again. Once I pressed it, I got the option to share <span class="No-Break">my GPT:</span></p>
			<div>
				<div id="_idContainer044" class="IMG---Figure">
					<img src="image/B21826_08_3.jpg" alt="Figure 8.3 – Sharing your GPT in the GPT Store" width="457" height="276"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.3 – Sharing your GPT in the GPT Store</p>
			<p>I chose <strong class="bold">Publish to GPT Store</strong>, which will make it available to all ChatGPT users. The completed version, created only with the preceding minimal instructions, can be accessed <span class="No-Break">at </span><a href="https://chat.openai.com/g/g-yJvyO2vHq-detective-guide"><span class="No-Break">https://chat.openai.com/g/g-yJvyO2vHq-detective-guide</span></a><span class="No-Break">.</span></p>
			<p>This is what it <span class="No-Break">looks like:</span></p>
			<div>
				<div id="_idContainer045" class="IMG---Figure">
					<img src="image/B21826_08_4.jpg" alt="Figure 8.4 – The initial version of the Sherlock Holmes GPT, Detective Guide" width="609" height="591"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.4 – The initial version of the Sherlock Holmes GPT, Detective Guide</p>
			<p>One thing to <a id="_idIndexMarker535"/>notice is what little configuration I had to perform. I uploaded a few text files with the text of the books and wrote a few hundred words of configuration in <span class="No-Break">natural language.</span></p>
			<p>To test it, I asked <strong class="source-inline">What's Holmes attic theory?</strong>, and its answer, shown in the following, answers the question and correctly identifies the book it <span class="No-Break">comes from:</span></p>
			<pre class="console">
Holmes' attic theory, a metaphorical description of how one should manage their mental storage, emphasizes the importance of selective knowledge acquisition. In "A Study in Scarlet," Holmes explains that he considers the brain to be like a little empty attic, which one must carefully furnish with only the tools that may aid one's work. He argues against cluttering the mind with irrelevant information, suggesting that such clutter can push out or obscure useful knowledge. According to Holmes, it is crucial to maintain a well-organized and selective collection of knowledge to ensure that one's mental capacity is efficiently utilized for one's purposes.
This theory sheds light on Holmes' approach to his detective work, where he values relevant, useful knowledge over a broad but shallow pool of information. It also underlines his practical view of intelligence, emphasizing application over accumulation. This perspective is central to understanding Holmes' character and his methods of deduction, which rely on connecting seemingly disparate facts stored neatly in his mental "attic" to solve complex cases.</pre>			<p>In addition, because I asked <a id="_idIndexMarker536"/>the GPT to not answer questions outside of its knowledge domain, it tries to keep things on topic, as the following <span class="No-Break">dialogue exemplifies:</span></p>
			<div>
				<div id="_idContainer046" class="IMG---Figure">
					<img src="image/B21826_08_5.jpg" alt="Figure 8.5 – Asking the GPT about astronomy and Sherlock Holmes’ astronomy knowledge" width="1425" height="868"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.5 – Asking the GPT about astronomy and Sherlock Holmes’ astronomy knowledge</p>
			<p class="callout-heading">If it’s so easy to create a custom GPT, why write any code?</p>
			<p class="callout">When GPT models started to become mainstream, several entrepreneurs created applications that were nothing more than GPT-3.5 with a few additional instructions. These apps were released on the web, like what we just did with the <span class="No-Break">Detective Guide.</span></p>
			<p class="callout">If the functionality of your application can be replicated by adding a few additional instructions to ChatGPT, creating a custom GPT may be a good option for you. If you try to release it as a separate app and charge users, it’s possible for a competitor to replicate your success by simply creating a custom GPT and offering it to all ChatGPT users. Monetization for these GPTs is still unclear, but apparently, it will work in the same way as Spotify or Kindle Unlimited: GPTs that get enough users receive a fraction of the money paid <span class="No-Break">by subscribers.</span></p>
			<p class="callout">There are a few cases in which these custom GPTs in ChatGPT don’t work at all. For example, you can’t use it to add AI functionality to your existing application. You also don’t have a lot of control: custom GPTs don’t allow you to fine-tune your prompts, process the inputs and outputs of functions, monitor usage, change the sensitivity of search when retrieving documents, and so on, so you have a lot less control over the <span class="No-Break">user experience.</span></p>
			<p>Now that we have created a simple version of a custom GPT, let’s create one that supports actions. We are going to use the home automation native plugin that we created in <a href="B21826_05.xhtml#_idTextAnchor106"><span class="No-Break"><em class="italic">Chapter 5</em></span></a> and pretend that we have a company that allows users to automate some functions in their house, such as turning the lights on and off and turning on the TV. We’re going to create a custom GPT that allows users to use ChatGPT to control the functionality of <span class="No-Break">their house.</span></p>
			<h2 id="_idParaDest-149"><a id="_idTextAnchor148"/>Creating a custom GPT that supports actions</h2>
			<p>Like what<a id="_idIndexMarker537"/> we have done in the previous subsection, we start by navigating to <a href="https://chat.openai.com/gpts/">https://chat.openai.com/gpts/</a> and clicking the <strong class="bold">Create</strong> button in the top-right corner, or navigating directly <span class="No-Break">to </span><a href="https://chat.openai.com/gpts/editor"><span class="No-Break">https://chat.openai.com/gpts/editor</span></a><span class="No-Break">.</span></p>
			<p>Instead of using the chat interface to create this custom GPT, I went directly to the <strong class="bold">Configure</strong> tab and added the <span class="No-Break">following instructions:</span></p>
			<pre class="console">
You are designed to assist users with specific home automation tasks through a web API, focusing on operating the garage door and turning lights on and off. If users inquire about functionalities outside these areas, you inform them that those actions are not supported. When you need more information to provide accurate assistance, you will ask for clarification directly. You strive to personalize your responses to fit users' specific contexts and ensure clarity in your explanations. Your interactions are professional and straightforward, aiming for clarity and efficiency in communication.
You only work with the SKB custom API and no other vendors. If a user asks about information about other vendors of home automation, say that you can't help them.</pre>			<p>I also named my GPT <strong class="source-inline">SKB Home Automation Example</strong>, where <strong class="bold">SKB</strong> stands for <strong class="bold">Semantic Kernel Book</strong>. You <a id="_idIndexMarker538"/>can leave most other options as their defaults, although you likely want to uncheck <strong class="bold">Web Browsing</strong> and <strong class="bold">DALL-E Image Generation</strong> under <strong class="bold">Capabilities</strong>, as these won’t <span class="No-Break">be used.</span></p>
			<p>Once you are done, you can click <strong class="bold">Create</strong> on the top-right side of the screen, and this will create a custom GPT, which you can choose to keep to yourself, share with a link, or share in the <span class="No-Break">GPT Store.</span></p>
			<p>Whatever you choose, now you can send requests to the GPT. Note that we have not connected our native plugin to the GPT yet, so if you ask the GPT to perform something, such as <strong class="source-inline">open the garage door</strong>, it will immediately hallucinate, as <span class="No-Break">shown here:</span></p>
			<pre class="console">
To open your garage door using the SKB Home Automation API, you would typically send a command through a web request. The specific details can depend on how your system is set up, but here's a general example of how you might do it:
1. Ensure Your Device is Connected: Make sure your smartphone or computer is connected to the internet and can communicate with your home network where your garage door is connected.
2. Use the Right Endpoint: The SKB API will have a specific endpoint for operating the garage door. This is often something like /api/garage_door/open, but you should refer to the SKB API documentation for the exact endpoint.
3. Send the Request: You can use various tools or a piece of code to send the request. If you're comfortable with command line tools, you might use curl in a terminal or command prompt like this:
   curl -X POST "http://yourhomeip:port/api/garage_door/open" -H "Authorization: Bearer YOUR_API_TOKEN"
   Replace yourhomeip:port with the IP address and port number of your SKB Home Automation system, and YOUR_API_TOKEN with your personal API token for authentication.
4. Check the Response: After sending the request, you should receive a response from the API. A successful response usually includes a message indicating that the command was received and the action (opening the garage door) is in progress or completed. If there's an error, the response will typically contain details to help troubleshoot the issue.
If you haven't set up your API token or aren't sure about the endpoint or how to send the request, let me know what step you're on, and I can provide more detailed instructions!</pre>			<p>ChatGPT makes up several things in this answer: an API, a <strong class="source-inline">curl</strong> command, an authentication method, whether you can send commands to an IP address, and so on. None of <a id="_idIndexMarker539"/>those things are true; it’s just trying its best to provide an answer. This problem will be solved when we connect ChatGPT with our real API, which we are going to do in the <span class="No-Break">next section.</span></p>
			<p class="callout-heading">A note about security</p>
			<p class="callout">When you share your GPT and your API with hundreds of millions of users, there’s a real possibility that some of them will use it in ways that you have not thought about. We will not cover security in detail in this book, but this doesn’t mean that you should not think <span class="No-Break">about it.</span></p>
			<p class="callout">In the next section, we will connect an API to ChatGPT without any authentication, but for a production application, you should add authentication to the connection between GPT and your API. Most importantly, you should add monitoring to your API, so you can see if usage patterns <span class="No-Break">are changing.</span></p>
			<p class="callout">Even the most basic monitoring that just counts how many calls you have had per minute is likely sufficient to prevent the worst forms of abuse. Once you have monitoring, you can also add rate limiting, to prevent malicious users from overwhelming your API with <span class="No-Break">repeated calls.</span></p>
			<h2 id="_idParaDest-150"><a id="_idTextAnchor149"/>Creating a web API wrapper for the native function</h2>
			<p>First, let’s <a id="_idIndexMarker540"/>define our native function. This is the same function I used in <a href="B21826_05.xhtml#_idTextAnchor106"><span class="No-Break"><em class="italic">Chapter 5</em></span></a>, but I used only <strong class="source-inline">OperateLight</strong> and <strong class="source-inline">OperateGarageDoor</strong> <span class="No-Break">for brevity:</span></p>
			<pre class="source-code">
import semantic_kernel as sk
from typing import Annotated
from semantic_kernel.functions.kernel_function_decorator import kernel_function
class HomeAutomation:
    def __init__(self):
        pass
    @kernel_function(
        description="Turns the lights of the living room, kitchen, bedroom or garage on or off.",
        name="OperateLight",
    )
    def OperateLight(self,
    location: Annotated[str, "The location where the lights are to be turned on or off. Must be either 'living room', 'kitchen', 'bedroom' or 'garage'"],
    action: Annotated[str, "Whether to turn the lights on or off"]) -&gt; Annotated[str,  "The output is a string describing whether the lights were turned on or off" ]:
        if location in ["kitchen", "living room", "bedroom", "garage"]:
            result = f"Changed status of the {location} lights to {action}."
            return result
        else:
            error = f"Invalid location {location} specified."
            return error
    @kernel_function(
        description="Opens or closes the garage door.",
        name="OperateGarageDoor",
    )
    def OperateGarageDoor(self,
            action:  Annotated[str, "Whether to open or close the garage door"]) -&gt; Annotated[str, "The output is a string describing whether the garage door was opened or closed" ]:
        result = f"Changed the status of the garage door to {action}."
        return result</pre>			<p>Now, we <a id="_idIndexMarker541"/>need to build a web API to make that function callable from the web <span class="No-Break">by ChatGPT.</span></p>
			<h3>Creating a web API wrapper in Python</h3>
			<p>In Python, we <a id="_idIndexMarker542"/>are<a id="_idIndexMarker543"/> going to use the Flask library. In Flask, we’re going to create two routes: <strong class="source-inline">operate_light</strong> and <strong class="source-inline">operate_garage_door</strong>. First, we create <span class="No-Break">an app:</span></p>
			<pre class="source-code">
from flask import Flask, render_template, request, jsonify
from dotenv import load_dotenv
from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion
import semantic_kernel as sk
from HomeAutomation import HomeAutomation
app = Flask(__name__)
app.secret_key = b'skb_2024'</pre>			<p>Creating the app is simple, requiring just the calling of the <strong class="source-inline">Flask</strong> constructor and setting a <strong class="source-inline">secret_key</strong> property that can be used to sign cookies coming from your app. This app will not have cookies, so the secret key can be anything, including a <span class="No-Break">random string.</span></p>
			<p>Now, we <a id="_idIndexMarker544"/>will <a id="_idIndexMarker545"/>define the routes for <span class="No-Break">our API:</span></p>
			<pre class="source-code">
@app.route('/operate_light', methods=['POST'])
async def operate_light():
    kernel = sk.Kernel()
    api_key, org_id = sk.openai_settings_from_dot_env()
    gpt4 = OpenAIChatCompletion("gpt-4-turbo-preview", api_key, org_id)
    kernel.add_service(gpt4)
    kernel.import_plugin_from_object(HomeAutomation(), "HomeAutomation")
    data = request.get_json()
    location = data['location']
    action = data['action']
    result = str(kernel.invoke(kernel.plugins["HomeAutomation"]["OperateLight"], location=location, action=action))
    return jsonify({'result': result})
@app.route('/operate_garage_door', methods=['POST'])
async def operate_garage_door():
    kernel = sk.Kernel()
    api_key, org_id = sk.openai_settings_from_dot_env()
    gpt4 = OpenAIChatCompletion("gpt-4-turbo-preview", api_key, org_id)
    kernel.add_service(gpt4)
    kernel.import_plugin_from_object(HomeAutomation(), "HomeAutomation")
    data = request.get_json()
    action = data['action']
    result = str(kernel.invoke(kernel.plugins["HomeAutomation"]["OperateGarageDoor"], action=action))
    return jsonify({'result': result})</pre>			<p>The <a id="_idIndexMarker546"/>structure of each route is the same: we create a kernel, add a GPT service to it, import the <strong class="source-inline">HomeAutomation</strong> plugin, and invoke the <a id="_idIndexMarker547"/>appropriate function, returning <span class="No-Break">its answer.</span></p>
			<p>You can add these two lines of code to the application to allow for <span class="No-Break">local testing:</span></p>
			<pre class="source-code">
if __name__ == '__main__':
    app.run()</pre>			<p>To test the application locally, go to a command line and type <span class="No-Break">the following:</span></p>
			<pre class="console">
flask run</pre>			<p>This will create a local <span class="No-Break">web server:</span></p>
			<pre class="console">
* Debug mode: off
WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.
 * Running on http://127.0.0.1:5000</pre>			<p>Now, you can send commands to the local web server using <strong class="source-inline">curl</strong> if you are using bash, or <strong class="source-inline">Invoke-RestMethod</strong> if you are using PowerShell. Here, we are invoking the <strong class="source-inline">operate_light</strong> route with <strong class="source-inline">"action": "on"</strong> and <strong class="source-inline">"</strong><span class="No-Break"><strong class="source-inline">location": "bedroom"</strong></span><span class="No-Break">:</span></p>
			<pre class="console">
Invoke-RestMethod -Uri http://localhost:5000/operate_light -Method Post -ContentType "application/json" -Body '{"action": "on", "location": "bedroom"}'</pre>			<p>The <a id="_idIndexMarker548"/>result, as expected, is that the application <a id="_idIndexMarker549"/><span class="No-Break">responds successfully:</span></p>
			<pre class="console">
Result
------
Changed status of the bedroom lights to on.</pre>			<p>Now that we verified that the web application is working, we can deploy it on <span class="No-Break">the web.</span></p>
			<h3>Creating a web API wrapper in C#</h3>
			<p>.NET makes it <a id="_idIndexMarker550"/>easy to create a boilerplate web API application. You <a id="_idIndexMarker551"/>can use the following command and it will create a web API under the <span class="No-Break"><strong class="source-inline">SkHomeAutomation</strong></span><span class="No-Break"> directory:</span></p>
			<pre class="console">
dotnet new webapi --use-controllers -o SkHomeAutomation</pre>			<p>Don’t forget to install the <strong class="source-inline">Microsoft.SemanticKernel</strong> <span class="No-Break">package, too:</span></p>
			<pre class="console">
dotnet add package Microsoft.SemanticKernel</pre>			<p>The <strong class="source-inline">dotnet new webapi</strong> command helpfully generates the code for a weather forecasting web application that provides a web API. One of the files it generates is a module called <strong class="source-inline">WeatherForecast.cs</strong>. You can delete this file, as we will replace it with our own functionality. To do so, copy the <strong class="source-inline">HomeAutomation.cs</strong> file from <a href="B21826_05.xhtml#_idTextAnchor106"><span class="No-Break"><em class="italic">Chapter 5</em></span></a> to the root of this project. To make our life easier, add the following line to the beginning of the file, which will allow you to reference the <strong class="source-inline">HomeAutomation</strong> object <span class="No-Break">more easily:</span></p>
			<pre class="source-code">
namespace SkHomeAutomation;</pre>			<p>The last thing you need to do is to go into the <strong class="source-inline">Controllers</strong> directory. It will contain a <strong class="source-inline">WeatherForecastController.cs</strong> file. You can delete this file and replace it with the <strong class="source-inline">HomeAutomationController.cs</strong> file, which <span class="No-Break">is here:</span></p>
			<pre class="source-code">
using Microsoft.AspNetCore.Mvc;
namespace SkHomeAutomation.Controllers;
using Microsoft.Extensions.Logging;
public class LightOperationData
{
    public string? location { get; set; }
    public string? action { get; set; }
}
public class GarageOperationData
{
    public string? action { get; set; }
}
[ApiController]
[Route("[controller]")]
public class HomeAutomationController : ControllerBase
{
    private readonly ILogger&lt;HomeAutomationController&gt;? _logger;
    private HomeAutomation ha;
    public HomeAutomationController(ILogger&lt;HomeAutomationController&gt; logger)
    {
        _logger = logger;
        ha = new HomeAutomation();
    }
    [HttpPost("operate_light")]
    public IActionResult OperateLight([FromBody] LightOperationData data)
    {
        if (data.location == null || data.action == null)
        {
            return BadRequest("Location and action must be provided");
        }
        return Ok( ha.OperateLight(data.action, data.location) );
    }
    [HttpPost("operate_garage_door")]
    public IActionResult OperateGarageDoor([FromBody] GarageOperationData data)
    {
        if (data.action == null)
        {
            return BadRequest("Action must be provided");
        }
        return Ok( ha.OperateGarageDoor(data.action) );
    }
}</pre>			<p><strong class="source-inline">HomeAutomationController</strong> exposes the <strong class="source-inline">operate_light</strong> and <strong class="source-inline">operate_garage_door</strong> web API paths, and when those are called, it routes the request to the<a id="_idIndexMarker552"/> corresponding method of the <strong class="source-inline">HomeAutomation</strong> class that we created in <a href="B21826_05.xhtml#_idTextAnchor106"><span class="No-Break"><em class="italic">Chapter 5</em></span></a>, essentially<a id="_idIndexMarker553"/> exposing our Semantic Kernel application to the web, once <span class="No-Break">it’s deployed.</span></p>
			<p>The next step, whether you created the application in C# or Python, is to deploy <span class="No-Break">the application.</span></p>
			<h2 id="_idParaDest-151"><a id="_idTextAnchor150"/>Deploying your application to an Azure Web App</h2>
			<p>To <a id="_idIndexMarker554"/>deploy your application on the web, you need to have an Azure account. Go to the Azure portal at <a href="https://portal.azure.com">https://portal.azure.com</a>, and from the home page, click <strong class="bold">Create a Resource</strong> and then <strong class="bold">Create a Web App</strong>. As you <a id="_idIndexMarker555"/>will see here, we can use the free tier for our test, but if you plan to deploy something like this for a real application, you should choose a <span class="No-Break">different plan.</span></p>
			<p>In <span class="No-Break"><em class="italic">Figure 8</em></span><em class="italic">.6</em>, I show how I created mine: I created a new resource group called <strong class="source-inline">skb-rg</strong>, named my application <strong class="source-inline">skb-home-automation</strong>, which gives it the <strong class="source-inline">skb-home-automation.azurewebsites.net</strong> URL, and chose Python 3.11 (Python) or .NET 8 LTS (C#) for its <span class="No-Break">runtime stack.</span></p>
			<p>Under <strong class="bold">Pricing plans</strong>, I created a new <strong class="bold">Linux Plan</strong> called <strong class="source-inline">skb-sp</strong>, and chose the <strong class="bold">Free F1</strong> pricing plan. Once these configurations are done, click <strong class="bold">Review + create</strong> and your web application will be deployed in a <span class="No-Break">few minutes:</span></p>
			<div>
				<div id="_idContainer047" class="IMG---Figure">
					<img src="image/B21826_08_6.jpg" alt="Figure 8.6 – Creating a free web app to host our API" width="1413" height="1749"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.6 – Creating a free web app to host our API</p>
			<p>The simplest <a id="_idIndexMarker556"/>way to deploy your API to the web application is through GitHub. To do so, we need to create a new, clean GitHub repository for this web API and copy the contents of <a href="https://github.com/PacktPublishing/Microsoft-Semantic-Kernel/tree/main/python/ch8">https://github.com/PacktPublishing/Microsoft-Semantic-Kernel/tree/main/python/ch8</a> to it. This needs to be a separate repository because you need to deploy the full repository to the web application. For example, you can put your copy at an address such <span class="No-Break">as </span><span class="No-Break"><strong class="source-inline">https://github.com/&lt;your-github-username&gt;/skb-home-automation</strong></span><span class="No-Break">.</span></p>
			<p>In your web application, go to <strong class="bold">Deployment Center</strong>, and select <strong class="bold">GitHub</strong> as the source. In <strong class="bold">Organization</strong>, select your username. Choose <span class="No-Break">the repository.</span></p>
			<p>This will create and deploy the web API under your <span class="No-Break">own account.</span></p>
			<div>
				<div id="_idContainer048" class="IMG---Figure">
					<img src="image/B21826_08_7.jpg" alt="Figure 8.7 – Deploying the web API using GitHub" width="1441" height="1390"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.7 – Deploying the web API using GitHub</p>
			<p>Once the web API is <a id="_idIndexMarker557"/>deployed, you can test it using <strong class="source-inline">curl</strong> or <strong class="source-inline">Invoke-RestApi</strong>. The only change is that instead of using localhost as the endpoint, you need to change it to the endpoint you deployed to. In my case, I chose <strong class="source-inline">skb-home-automation.azurewebsites.net</strong> (your case will be different). Please note that my version of the API will not be available for you; you must deploy <span class="No-Break">your own.</span></p>
			<p>Therefore, we <a id="_idIndexMarker558"/>can submit <span class="No-Break">the following:</span></p>
			<pre class="console">
Invoke-RestMethod -Uri https://skb-home-automation.azurewebsites.net/operate_light -Method Post -ContentType "application/json" -Body '{"action": "on", "location": "bedroom"}'</pre>			<p>The result will be <span class="No-Break">as follows:</span></p>
			<pre class="console">
Result
------
Changed status of the bedroom lights to on.</pre>			<p>Now that we have a web API that is working, we need to connect the API <span class="No-Break">with ChatGPT.</span></p>
			<h2 id="_idParaDest-152"><a id="_idTextAnchor151"/>Connecting the custom GPT with your custom GPT action</h2>
			<p>To connect our <a id="_idIndexMarker559"/>web API with our custom GPT, we need to give it an OpenAPI specification. ChatGPT makes it very easy to <span class="No-Break">generate one.</span></p>
			<p>First, go to our custom GPT, select the dropdown from its name, and select <span class="No-Break"><strong class="bold">Edit GPT</strong></span><span class="No-Break">:</span></p>
			<p class="IMG---Figure"> </p>
			<div>
				<div id="_idContainer049" class="IMG---Figure">
					<img src="image/B21826_08_8.jpg" alt="Figure 8.8 – Editing our GPT" width="351" height="384"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.8 – Editing our GPT</p>
			<p>On the <a id="_idIndexMarker560"/>bottom of the <strong class="bold">Configuration</strong> tab, click on <strong class="bold">Create new action</strong>, under <strong class="bold">Actions</strong>. This will bring up the <strong class="bold">Add </strong><span class="No-Break"><strong class="bold">actions</strong></span><span class="No-Break"> UI:</span></p>
			<p class="IMG---Figure"> </p>
			<div>
				<div id="_idContainer050" class="IMG---Figure">
					<img src="image/B21826_08_9.jpg" alt="Figure 8.9 –  Adding actions to our GPT" width="715" height="683"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.9 –  Adding actions to our GPT</p>
			<p>To add actions, you<a id="_idIndexMarker561"/> need to specify a schema using a language<a id="_idIndexMarker562"/> called <strong class="bold">OpenAPI</strong>. ChatGPT makes this extremely easy: clicking on <strong class="bold">Get help from ActionGPT</strong> will open a chat dialog with another custom GPT that can help you create <span class="No-Break">OpenAPI specifications:</span></p>
			<p class="IMG---Figure"> </p>
			<div>
				<div id="_idContainer051" class="IMG---Figure">
					<img src="image/B21826_08_10.jpg" alt="Figure 8.10 – Using ActionsGPT" width="738" height="583"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.10 – Using ActionsGPT</p>
			<p>In ActionsGPT, all <a id="_idIndexMarker563"/>you need to do is paste the code of our web API, and it will automatically generate the OpenAPI specification. What was automatically generated is in the following, but we’ll need to make a couple <span class="No-Break">of changes:</span></p>
			<pre class="console">
openapi: 3.0.0
info:
  title: Home Automation API
  description: This API allows controlling lights and garage doors in a home automation system.
  version: 1.0.0
servers:
  - url: http://yourserver.com
    description: Main server
paths:
  /operate_light:
    post:
      operationId: operateLight
      summary: Controls a light in the home automation system.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              required:
                - location
                - action
              properties:
                location:
                  type: string
                  description: The location of the light to be controlled.
                action:
                  type: string
                  description: The action to be performed on the light.
                  enum:
                    - turnOn
                    - turnOff
                    - toggle
      responses:
        '200':
          description: Operation result
          content:
            application/json:
              schema:
                type: object
                properties:
                  result:
                    type: string
                    description: The result of the light operation.
  /operate_garage_door:
    post:
      operationId: operateGarageDoor
      summary: Controls the garage door in the home automation system.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              required:
                - action
              properties:
                action:
                  type: string
                  description: The action to be performed on the garage door.
                  enum:
                    - open
                    - close
                    - stop
      responses:
        '200':
          description: Operation result
          content:
            application/json:
              schema:
                type: object
                properties:
                  result:
                    type: string
                    description: The result of the garage door operation.</pre>			<p>Notably, it doesn’t know<a id="_idIndexMarker564"/> the name of my server or the restrictions of the places where lights are installed. It also tries to guess the commands. Therefore, we must add the correct restrictions to the specification. Another detail to note is that I have the <strong class="source-inline">x-openai-isConsequential: false</strong> parameter for all endpoints. When that parameter is <strong class="source-inline">true</strong> or blank, ChatGPT will ask for confirmation for each command that is issued. For our purposes, we don’t need that, but your use case might require it, for example, when a user<a id="_idIndexMarker565"/> decides to make <span class="No-Break">a payment.</span></p>
			<p>The fixed version is here, with the changes highlighted <span class="No-Break">in bold:</span></p>
			<pre class="source-code">
openapi: 3.0.0
info:
  title: Home Automation API
  description: This API allows controlling lights and garage doors in a home automation system.
  version: 1.0.0
servers:
  <strong class="bold">- url: https://skb-home-automation.azurewebsites.net</strong>
    description: Main server
paths:
  /operate_light:
    post:
      operationId: operateLight
      summary: Controls a light in the home automation system.
      <strong class="bold">x-openai-isConsequential: false</strong>
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              required:
                - location
                - action
              properties:
                location:
                  type: string
                  description: The location of the light to be controlled.
                  <strong class="bold">enum:</strong>
<strong class="bold">                    - "kitchen"</strong>
<strong class="bold">                    - "living room"</strong>
<strong class="bold">                    - "bedroom"</strong>
<strong class="bold">                    - "garage"</strong>
                action:
                  type: string
                  description: The action to be performed on the light.
                  <strong class="bold">enum:</strong>
<strong class="bold">                    - "on"</strong>
<strong class="bold">                    - "off"</strong>
      responses:
        '200':
          description: Operation result
          content:
            application/json:
              schema:
                type: object
                properties:
                  result:
                    type: string
                    description: The result of the light operation.
  /operate_garage_door:
    post:
      operationId: operateGarageDoor
      summary: Controls the garage door in the home automation system.
      <strong class="bold">x-openai-isConsequential: false</strong>
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              required:
                - action
              properties:
                action:
                  type: string
                  description: The action to be performed on the garage door.
                  <strong class="bold">enum:</strong>
<strong class="bold">                    - "open"</strong>
<strong class="bold">                    - "close"</strong>
      responses:
        '200':
          description: Operation result
          content:
            application/json:
              schema:
                type: object
                properties:
                  result:
                    type: string
                    description: The result of the garage door operation.</pre>			<p>You can<a id="_idIndexMarker566"/> paste this corrected version into the <strong class="bold">Schema</strong> box and click <strong class="bold">Update</strong> in the top-right corner. This will deploy the custom GPT with the connection to the native application you developed with <span class="No-Break">Semantic Kernel.</span></p>
			<p>Here, you will see an example of a real dialog with our custom GPT, where I ask it to operate <span class="No-Break">several devices:</span></p>
			<div>
				<div id="_idContainer052" class="IMG---Figure">
					<img src="image/B21826_08_11.jpg" alt="Figure 8.11 – Using our SKB Home Automation custom GPT" width="722" height="219"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.11 – Using our SKB Home Automation custom GPT</p>
			<div>
				<div id="_idContainer053" class="IMG---Figure">
					<img src="image/B21826_08_12.jpg" alt="Figure 8.12 – Using our SKB Home Automation custom GPT" width="725" height="538"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.12 – Using our SKB Home Automation custom GPT</p>
			<p>First, I asked <a id="_idIndexMarker567"/>the GPT to open my garage door. It correctly called the API with the appropriate command. Next, I asked it a complex command: to close my garage door and turn off all the lights. As you can see from <span class="No-Break"><em class="italic">Figure 8</em></span><em class="italic">.12</em>, it issued five commands. Looking at the log of the web API, you would be able to see that the commands were <span class="No-Break">correctly sent:</span></p>
			<pre class="console">
2024-04-08T05:16:27.968713802Z: [INFO]  Changed the status of the garage door to close.
2024-04-08T05:16:30.939181143Z: [INFO]  Changed status of the kitchen lights to off.
2024-04-08T05:16:33.701639742Z: [INFO]  Changed status of the living room lights to off.
2024-04-08T05:16:36.377148658Z: [INFO]  Changed status of the bedroom lights to off.
2024-04-08T05:16:39.017400267Z: [INFO]  Changed status of the garage lights to off.</pre>			<p>If I ask for a<a id="_idIndexMarker568"/> command that it cannot execute, it also correctly responds with what it <span class="No-Break">can do:</span></p>
			<p class="IMG---Figure"> </p>
			<div>
				<div id="_idContainer054" class="IMG---Figure">
					<img src="image/B21826_08_13.jpg" alt="Figure 8.13 – Issuing an invalid command to the custom GPT" width="726" height="286"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.13 – Issuing an invalid command to the custom GPT</p>
			<p>The two main consequences of connecting an application with a custom GPT are <span class="No-Break">as follows:</span></p>
			<ul>
				<li><strong class="bold">Your application gets a state-of-the-art planner</strong>: Your users can make complex requests, such as issuing several commands at once, such as <strong class="source-inline">turn off all my lights</strong>, and ChatGPT will parse them and send them to your application. If users ask for functions that are not available in your application, ChatGPT tells them what can and cannot <span class="No-Break">be done.</span></li>
				<li><strong class="bold">Your application gets wide distribution and access to all UI facilities provided by ChatGPT</strong>: Everyone with access to ChatGPT can use your application, even from their phones. They can also use the application with their voices because ChatGPT supports <span class="No-Break">voice commands.</span></li>
			</ul>
			<p>In this section, we<a id="_idIndexMarker569"/> have seen how to connect an app we wrote with ChatGPT, enabling it to be used by the hundreds of millions of <span class="No-Break">ChatGPT users.</span></p>
			<h1 id="_idParaDest-153"><a id="_idTextAnchor152"/>Summary</h1>
			<p>In this chapter, we connected an application with OpenAI’s ChatGPT by developing a custom GPT and adding custom actions to it. This can enable applications to get access to a planner that is based on the latest model available to ChatGPT users, which is usually a very <span class="No-Break">advanced model.</span></p>
			<p>In addition, what we have learned allows you to deploy your application to hundreds of millions of users with minimal effort and get access to several new features available to ChatGPT users, such as natural language requests and voice requests. It also allows you to deploy your application to users more quickly, as you don’t have to develop a UI yourself – you can use ChatGPT as the UI as you develop and grow <span class="No-Break">your application.</span></p>
			<p>If you are a Python programmer, Microsoft Semantic Kernel provides a few additional features over what is already provided by the default OpenAI Python API. Among other things, you get the separation between prompt and code, native functions, planners, core plugins, and interfaces with memory. All of this can cut the time you will spend creating and maintaining your code. With the amount of change happening in AI these days, it’s great to be able to save <span class="No-Break">some time.</span></p>
			<p>If you are a C# developer, in addition to getting the benefits that the Python programmers get, you will also find that Microsoft Semantic Kernel is the best way of connecting a C# application to OpenAI models, as OpenAI does not provide a C# API. You can do a lot with REST APIs, as we have shown when we created DALL-E 3 images in <a href="B21826_04.xhtml#_idTextAnchor086"><span class="No-Break"><em class="italic">Chapter 4</em></span></a>, but REST APIs are cumbersome and have changed in the last year. Using the Microsoft Semantic Kernel greatly simplifies things, and when changes happen, it’s likely that they will be incorporated in a <span class="No-Break">future release.</span></p>
			<p>For now, this concludes our journey with Microsoft Semantic Kernel. As a parting thought, Semantic Kernel and AI models are just tools. Your impact on the world depends on how you use these tools. In my career, I have been fortunate to be able to use technology, and lately, AI, for social good. I hope you can do <span class="No-Break">the same.</span></p>
		</div>
	</div>
</div>
</body></html>