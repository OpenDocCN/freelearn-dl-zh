- en: '5'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '5'
- en: Fine-Tuning Generative Models for Specific Tasks
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 微调生成模型以适应特定任务
- en: In our narrative with StyleSprint, we described using a pre-trained generative
    AI model for creating engaging product descriptions. While this model showed adeptness
    in generating diverse content, StyleSprint’s evolving needs require a shift in
    focus. The new challenge is not just about producing content but also about engaging
    in specific, task-oriented interactions such as automatically answering customer’s
    specific questions about the products described.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的StyleSprint叙事中，我们描述了使用预训练的生成AI模型来创建引人入胜的产品描述。虽然这个模型在生成多样化内容方面表现出色，但StyleSprint不断变化的需求要求我们转变关注点。新的挑战不仅在于产生内容，还在于参与特定、面向任务的交互，例如自动回答客户对所描述产品的具体问题。
- en: In this chapter, we introduce the concept of fine-tuning, a vital step in adapting
    a pre-trained model to perform specific downstream tasks. For StyleSprint, this
    means transforming the model from a versatile content generator to a specialized
    tool capable of providing accurate and detailed responses to customer questions.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了微调的概念，这是将预训练模型适应特定下游任务的关键步骤。对于StyleSprint来说，这意味着将模型从多才多艺的内容生成器转变为能够提供准确和详细回答客户问题的专业工具。
- en: We will explore and define a range of scalable fine-tuning techniques, comparing
    them with other approaches such as in-context learning. We will demonstrate advanced
    fine-tuning methods, including parameter-efficient fine-tuning and prompt tuning,
    to demonstrate how they can fine-tune a model’s abilities for specific tasks such
    as Q&A.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将探索和定义一系列可扩展的微调技术，并将它们与其他方法如上下文学习进行比较。我们将展示高级微调方法，包括参数高效的微调和提示微调，以展示它们如何能够微调模型在特定任务如问答上的能力。
- en: By the end of this chapter, we will have trained a language model to answer
    questions and do so in a way that aligns with StyleSprint’s brand guidelines.
    However, before we explore the mechanics of fine-tuning and its importance in
    our application, we will revisit the history of fine-tuning in the context of
    LLMs.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，我们将训练一个语言模型来回答问题，并以符合StyleSprint品牌指南的方式回答。然而，在我们探讨微调的机制及其在我们应用中的重要性之前，我们将回顾LLMs背景下微调的历史。
- en: Foundation and relevance – an introduction to fine-tuning
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基础和相关性——微调简介
- en: Fine-tuning is the process of leveraging a model pre-trained on a large dataset
    and continuing the training process on a smaller, task-specific dataset to improve
    its performance on that task. It may also involve additional training that adapts
    a model to the nuances of a new domain. The latter is known as domain adaptation,
    which we will cover in [*Chapter 6*](B21773_06.xhtml#_idTextAnchor211). The former
    is typically referred to as task-specific fine-tuning, and it can be performed
    to accomplish several tasks, including Q&A, summarization, classification, and
    many others. For this chapter, we will focus on task-specific fine-tuning to improve
    a general-purpose model’s performance when answering questions.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 微调是将在大数据集上预训练的模型继续在较小、特定任务的数据集上进行训练的过程，以提高其在该任务上的性能。它还可能涉及适应新领域细微差别的额外训练。后者被称为领域自适应，我们将在[*第6章*](B21773_06.xhtml#_idTextAnchor211)中介绍。前者通常被称为特定任务微调，它可以执行多个任务，包括问答、摘要、分类等。对于本章，我们将专注于特定任务微调，以提高通用模型在回答问题时表现的能力。
- en: For StyleSprint, fine-tuning a model to handle a specific task such as answering
    customer inquiries about products introduces unique challenges. Unlike generating
    product descriptions, which primarily involves language generation using an out-of-the-box
    pre-trained model, answering customer questions requires the model to have an
    extensive understanding of product-specific data and should have a brand-aware
    voice. Specifically, the model must accurately interpret and respond to questions
    about product features, sizes, availability, user reviews, and many other details.
    It should also produce answers consistent with StyleSprint’s distinct brand tone.
    This task requires both generalized natural language proficiency (from pre-training)
    and robust knowledge of product metadata and customer feedback, accomplished through
    fine-tuning.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 对于StyleSprint来说，将模型微调以处理特定任务，如回答客户关于产品的询问，引入了独特的挑战。与主要涉及使用现成的预训练模型进行语言生成的产品描述不同，回答客户问题要求模型对产品特定数据有广泛的理解，并且应该有一个品牌意识的声音。具体来说，模型必须准确解释和回答有关产品功能、尺寸、可用性、用户评论和其他许多细节的问题。它还应该产生与StyleSprint独特的品牌语调一致的答案。这项任务需要从预训练中获得的一般自然语言能力以及关于产品元数据和客户反馈的稳健知识，这些是通过微调实现的。
- en: Models such as GPT initially learn to predict text through an unsupervised learning
    process that involves being trained on wide-ranging and vast datasets. This pre-training
    phase exposes the model to a diverse array of texts, enabling it to gain a broad
    understanding of language, including syntax, grammar, and context, without any
    specific task-oriented guidance. However, fine-tuning applies task-oriented, supervised
    learning to refine the model’s capabilities to accomplish the specified task –
    specifically, semi-supervised learning, which, as described by Radford et al.
    (2018), involves adapting the model to a specific supervised task by exposing
    it to a dataset comprising input sequences (`x1`, ..., `xm`) and corresponding
    labels (`y`).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 模型如GPT最初通过无监督学习过程学习预测文本，这个过程涉及在广泛和庞大的数据集上进行训练。这个预训练阶段使模型接触到各种文本，使其能够获得对语言的广泛理解，包括语法、语法和上下文，而不需要任何特定任务导向的指导。然而，微调通过任务导向的监督学习来细化模型的能力以完成特定任务——具体来说，是半监督学习，正如Radford等人（2018年）所描述的，它涉及通过使模型接触到包含输入序列（`x1`，...，`xm`）和相应标签（`y`）的数据集来调整模型以适应特定的监督任务。
- en: Throughout the chapter, we will detail the fine-tuning process, including how
    to selectively train the model on a curated dataset of product-related information
    and customer interactions, enabling it to respond with the informed, brand-aligned
    precision that customers expect. However, fine-tuning an LLM, which could have
    billions of parameters, would typically require an enormous number of resources
    and time. This is where advanced techniques such as **Parameter-Efficient Fine-Tuning**
    (**PEFT**) become particularly valuable in making fine-tuning accessible.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将详细介绍微调过程，包括如何选择性地在产品相关信息和客户互动的精选数据集上训练模型，使其能够以客户期望的知情、品牌一致的方式做出回应。然而，微调具有数十亿参数的LLM通常需要大量的资源和时间。这就是高级技术如**参数高效微调**（**PEFT**）在使微调变得可访问方面变得特别有价值。
- en: PEFT
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: PEFT
- en: Traditional fine-tuning methods become increasingly impractical as the model
    size grows due to the immense computational resources and time required to train
    and update all model parameters. For most businesses, including larger organizations,
    a classical approach to fine-tuning is cost-prohibitive and, effectively, a non-starter.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 随着模型规模的增大，传统的微调方法变得越来越不切实际，因为训练和更新所有模型参数需要巨大的计算资源和时间。对于大多数企业，包括大型组织，传统的微调方法成本高昂，实际上无法启动。
- en: Alternatively, PEFT methods modify only a small subset of a model’s parameters,
    reducing the computational burden while still achieving state-of-the-art performance.
    This method is advantageous for adapting large models to specific tasks without
    extensive retraining.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方法是仅修改模型参数的小子集，在保持最先进性能的同时减少计算负担。这种方法在将大型模型适应特定任务而不进行大量重新训练时具有优势。
- en: One such PEFT method is the **Low-Rank Adaptation** (**LoRA**) methodology,
    developed by Hu et al. (2021).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 有一种PEFT方法叫做**低秩自适应**（**LoRA**），由Hu等人（2021年）开发。
- en: LoRA
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LoRA
- en: 'The LoRA method focuses on selectively fine-tuning specific components within
    the Transformer architecture to enhance efficiency and effectiveness in LLMS.
    LoRA targets the weight matrices found in the self-attention module of the Transformer,
    which, as discussed in [*Chapter 3*](B21773_03.xhtml#_idTextAnchor081), are key
    to its functionality and include four matrices: wq (query), wk (key), wv (value),
    and wo (output). Although these matrices can be divided into multiple heads in
    a multi-head attention setting – where each *head* represents one of several parallel
    attention mechanisms that process inputs independently – LoRA treats them as singular
    matrices, simplifying the adaptation process.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: LoRA方法专注于选择性地微调Transformer架构中的特定组件，以增强LLMS的效率和有效性。LoRA针对Transformer的自注意力模块中发现的权重矩阵，正如在第[*3章*](B21773_03.xhtml#_idTextAnchor081)中讨论的那样，这些矩阵是其功能的关键，包括四个矩阵：wq（查询）、wk（键）、wv（值）和wo（输出）。尽管这些矩阵在多头注意力设置中可以被分为多个头——其中每个*头*代表几个并行注意力机制之一，这些机制独立处理输入——但LoRA将它们视为单个矩阵，简化了调整过程。
- en: LoRA’s approach involves adapting only the attention weights for downstream
    tasks, while the weights in the other component of the Transformer, the **feed-forward
    network** (**FFN**), are unchanged. This decision to focus exclusively on the
    attention weights and freeze the FFN is made for simplicity and parameter efficiency.
    By doing so, LoRA ensures a more manageable and resource-efficient fine-tuning
    process, avoiding the complexities and demands of retraining the entire network.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: LoRA的方法仅涉及调整下游任务的注意力权重，而Transformer的另一个组件——**前馈网络**（**FFN**）中的权重保持不变。专注于仅调整注意力权重并冻结FFN的决定是为了简化并提高参数效率。通过这样做，LoRA确保了一个更易于管理和资源高效的微调过程，避免了重新训练整个网络的复杂性和需求。
- en: This selective fine-tuning strategy enables LoRA to effectively tailor the model
    for specific tasks while maintaining the overall structure and strengths of the
    pre-trained model. This makes LoRA a practical solution for adapting LLMs to new
    tasks with a reduced computational burden without requiring comprehensive parameter
    updates across the entire model (Liu et al., 2021).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这种选择性的微调策略使得LoRA能够有效地调整模型以适应特定任务，同时保持预训练模型的整体结构和优势。这使得LoRA成为将LLMs适应新任务的一种实用解决方案，减少了计算负担，无需在整个模型中进行全面的参数更新（刘等人，2021）。
- en: Building upon the foundation of LoRA, **Adaptive Low-Rank Adaptation** (**AdaLoRA**),
    as introduced in a study by Liu et al. (2022), represents a further advancement
    in PEFT methods. The key difference between LoRA and AdaLoRA lies in (as the name
    suggests) its adaptiveness. While LoRA applies a consistent, low-rank approach
    to fine-tuning across the model, AdaLoRA tailors the updates to the needs of each
    layer, offering a more flexible and potentially more effective way to fine-tune
    large models for specific tasks.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 建立在LoRA基础之上，**自适应低秩调整**（**AdaLoRA**），如刘等人（2022）在研究中介绍的那样，代表了PEFT方法的一个进一步发展。LoRA和AdaLoRA之间的关键区别在于（正如其名称所暗示的）其适应性。虽然LoRA在模型微调过程中应用了一致的低秩方法，但AdaLoRA则根据每一层的需要调整更新，提供了一种更灵活且可能更有效的微调大型模型以适应特定任务的方法。
- en: AdaLoRA
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AdaLoRA
- en: AdaLoRA’s key innovation lies in its adaptive allocation of the **parameter
    budget** among the weight matrices of the pre-trained model. Many PEFT methods
    tend to distribute the parameter budget evenly across all pre-trained weight matrices,
    potentially neglecting the varying importance of different weight parameters.
    AdaLoRA overcomes this by assigning importance scores to these weight matrices
    and allocating the parameter budget accordingly. **Importance scores** in the
    context of AdaLoRA are metrics used to determine the significance (or importance)
    of different weight parameters in a model, guiding the allocation of the parameter
    budget more effectively during fine-tuning.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: AdaLoRA的关键创新在于其对预训练模型权重矩阵中**参数预算**的自适应分配。许多PEFT方法倾向于将参数预算平均分配到所有预训练权重矩阵中，可能忽略了不同权重参数的不同重要性。AdaLoRA通过为这些权重矩阵分配重要性分数并相应地分配参数预算来克服这一点。在AdaLoRA的上下文中，**重要性分数**是用于确定模型中不同权重参数的重要性（或重要性）的指标，在微调期间更有效地指导参数预算的分配。
- en: Note
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: '*Parameter budget* refers to the predefined limit on the number of additional
    parameters that can be introduced during the fine-tuning of a pre-trained model.
    This budget is set to ensure that the model’s complexity does not increase significantly,
    which can lead to challenges such as overfitting, increased computational costs,
    and longer training times.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**参数预算**是指在预训练模型微调过程中可以引入的额外参数数量的预定义限制。此预算的设置是为了确保模型的复杂性不会显著增加，这可能导致诸如过拟合、增加计算成本和更长的训练时间等挑战。'
- en: Additionally, AdaLoRA applies **singular value decomposition** (**SVD**) to
    efficiently organize the incremental updates made during the model’s fine-tuning
    process. SVD allows for the effective pruning of singular values associated with
    less critical updates, reducing the overall parameter budget required for fine-tuning.
    It is important to note that this method also avoids the need for computationally
    intensive exact computations, making the fine-tuning process more efficient.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，AdaLoRA将**奇异值分解**（**SVD**）应用于在模型微调过程中进行的增量更新的有效组织。SVD允许有效地剪枝与不太重要的更新相关的奇异值，从而减少微调所需的总体参数预算。值得注意的是，这种方法还避免了需要计算密集型精确计算的需求，使得微调过程更加高效。
- en: AdaLoRA has been empirically tested across various domains, including natural
    language processing, question-answering, and natural language generation. Extensive
    experiments have demonstrated its effectiveness in improving model performance,
    particularly in question-answering tasks. The adaptability and efficiency of AdaLoRA
    make it an ideal choice for applications requiring precise and efficient model
    adjustments for complex tasks.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: AdaLoRA已在包括自然语言处理、问答和自然语言生成在内的多个领域进行了实证测试。广泛的实验已经证明了它在提高模型性能方面的有效性，尤其是在问答任务中。AdaLoRA的适应性和效率使其成为需要精确和高效模型调整以完成复杂任务的理想选择。
- en: In the case of StyleSprint, AdaLoRA presents an opportunity to fine-tune its
    language model for answering customer questions without the considerable overhead
    that would be incurred by traditional fine-tuning, which would require adjusting
    all of the model parameters. By adopting AdaLoRA, StyleSprint can efficiently
    adapt its model to handle nuanced customer inquiries by adjusting significantly
    fewer parameters. Specifically, AdaLoRA’s adaptive allocation of parameter budgets
    means that StyleSprint can optimize its model for the specific nuances of customer
    queries without using extensive computational resources.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在StyleSprint的情况下，AdaLoRA提供了一个机会，可以在不产生传统微调所必需的大量开销的情况下微调其语言模型以回答客户问题，传统微调需要调整所有模型参数。通过采用AdaLoRA，StyleSprint可以高效地通过调整显著较少的参数来适应其模型以处理细微的客户询问。具体来说，AdaLoRA对参数预算的适应性分配意味着StyleSprint可以在不使用大量计算资源的情况下优化其模型以适应客户查询的具体细微差别。
- en: By the end of this chapter, we will have fine-tuned an LLM using AdaLoRA for
    our Q&A task. However, we should first decide whether fine-tuning is truly the
    right approach. Prompt-based LLMs offer a viable alternative known as in-context
    learning, where the model can learn from examples given in the prompt, meaning
    that the prompt would contain the customer’s question paired with a few key historical
    examples of how other questions were answered. The model can infer from the examples
    how to answer the question at hand in a way that is consistent with the examples.
    In the next section, we will explore the benefits and drawbacks of in-context
    learning to help us determine whether fine-tuning is the best approach to enable
    a model to answer very specific questions.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，我们将使用AdaLoRA微调一个LLM以完成我们的问答任务。然而，我们首先应该决定微调是否真的是正确的做法。基于提示的LLM提供了一个可行的替代方案，称为上下文学习，其中模型可以从提示中给出的示例中学习，这意味着提示将包含客户的提问以及一些关键的历史示例，说明其他问题的回答方式。模型可以从这些示例中推断出如何以与示例一致的方式回答当前的问题。在下一节中，我们将探讨上下文学习的利弊，以帮助我们确定微调是否是使模型能够回答非常具体问题的最佳方法。
- en: In-context learning
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在上下文学习
- en: In-context learning is a technique where the model generates responses based
    on a few examples provided in the input prompt. This method leverages the model’s
    pre-trained knowledge and the specific context or examples included in the prompt
    to perform tasks without the need for parameter updates or retraining. The general
    approach, detailed in *Language Models are Few-Shot Learners* by Brown et al.
    (2020), describes how the extensive pre-training of these models enables them
    to perform tasks and generate responses based on a limited set of examples paired
    with instructions embedded within prompts. Unlike traditional methods that require
    fine-tuning for each specific task, in-context learning allows the model to adapt
    and respond based on the additional context provided at inference.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在上下文学习是一种技术，其中模型根据输入提示中提供的少量示例生成响应。这种方法利用了模型的预训练知识和提示中包含的特定上下文或示例，以执行任务而无需参数更新或重新训练。布朗等人（2020年）在《语言模型是少量学习者》中详细描述了这些模型的广泛预训练如何使它们能够根据嵌入在提示中的指令和少量示例执行任务和生成响应。与传统方法不同，传统方法需要对每个特定任务进行微调，上下文学习允许模型根据推理时提供的附加上下文进行适应和响应。
- en: 'Central to in-context learning is the concept of few-shot prompting, which
    is critical for enabling models to adapt to and perform tasks without additional
    training data, relying instead on their pre-trained knowledge and the context
    provided within input prompts. For context, we’ll describe how an LLM typically
    works, which is known as the zero-shot approach, and contrast it to in-context
    learning, which uses the few-shot approach:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在上下文学习中，核心概念是少量提示，这对于使模型能够适应和执行任务而无需额外训练数据至关重要，而是依赖于它们预训练的知识和输入提示中提供的上下文。为了说明这一点，我们将描述一个LLM通常的工作方式，即零样本方法，并将其与使用少量方法的上下文学习进行对比：
- en: '`x`. The model calculates the likelihood of a potential output sequence, `y`,
    expressed as `P(y|x)`. This computation is performed without prior examples specific
    to the task, relying entirely on the model’s general pre-training. Meaning, the
    zero-shot approach has no specific context apart from its general knowledge. For
    example, if we were to ask *Are winter coats available in children’s sizes?*,
    the model could not provide a specific answer about StyleSprint’s inventory. It
    could only provide some generic answer.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`x`。模型计算潜在输出序列`y`的可能性，表示为`P(y|x)`。这种计算在没有特定于任务的先前示例的情况下进行，完全依赖于模型的通用预训练。这意味着零样本方法除了其通用知识外没有特定上下文。例如，如果我们问*Are
    winter coats available in children’s sizes?*，模型无法提供关于StyleSprint库存的具体答案。它只能提供一些通用的答案。'
- en: '`x`) to form an extended input sequence. So, our question *Are winter coats
    available in children’s sizes?* might be paired with a few examples such as the
    following:'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`x`)来形成一个扩展输入序列。因此，我们的问题*Are winter coats available in children’s sizes?*可能与以下示例配对：'
- en: '`Do you sell anything in` `children’s sizes?`'
  id: totrans-33
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Do you sell anything in` `children’s sizes?`'
- en: '`Any items for children are specifically listed on the “StyleSprint for` `Kids”
    page`.'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`Any items for children are specifically listed on the “StyleSprint for` `Kids”
    page`.'
- en: '`What do you offer` `for kids?`'
  id: totrans-35
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`What do you offer` `for kids?`'
- en: '`StyleSprint offers a variety of children’s fashions` `on its “StyleSprint
    for` `Kids” page`.'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`StyleSprint offers a variety of children’s fashions` `on its “StyleSprint
    for` `Kids” page`.'
- en: The LLM then computes the probability of generating a specific output sequence,
    `y`, given this extended input sequence, `x`. Mathematically, this can be conceptualized
    as the model estimating the joint probability distribution of `y` and `x` (where
    `x` includes both the prompt and the few-shot examples, as demonstrated previously).
    The model uses this joint probability distribution to generate a response consistent
    with the instructions paired with the examples given in the input sequence.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: LLM随后计算在给定扩展输入序列`x`的情况下生成特定输出序列`y`的概率。从数学上讲，这可以理解为模型估计`y`和`x`（其中`x`包括之前演示的提示和少量示例）的联合概率分布。模型使用这个联合概率分布来生成与输入序列中给出的示例配对的指令一致的响应。
- en: In both cases, the model’s ability to adapt its output based on the given context,
    whether with zero examples or a few, demonstrates the flexibility and sophistication
    of its underlying architecture and training. However, the few-shot approach allows
    the LLM to learn from the very specific examples provided.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两种情况下，模型根据给定上下文调整其输出的能力，无论是零个示例还是少量示例，都展示了其底层架构和训练的灵活性和复杂性。然而，少量方法允许LLM从提供的非常具体的示例中学习。
- en: Let’s consider how StyleSprint could apply in-context learning to answer customer
    queries. Performance using in-context learning (or the few-shot approach) consistently
    reflects significant gains over zero-shot behavior (Brown et al., 2020). We can
    expand our prior example to where a customer asks about the availability of a
    specific product. Again, the StyleSprint team could systematically append a few
    examples to each prompt as follows.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑 StyleSprint 如何应用情境学习来回答客户查询。使用情境学习（或少量示例方法）的性能始终显示出相对于零样本行为的显著提升（Brown
    等人，2020 年）。我们可以将先前的例子扩展到客户询问特定产品的可用性。同样，StyleSprint 团队可以系统地在每个提示中添加几个示例，如下所示。
- en: 'Here is the prompt: `Respond to the following {question} about` `product availability.`'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是提示：`请回答以下关于产品可用性的{问题}。`
- en: 'These are some examples:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是一些示例：
- en: 'Example 1:'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '示例 1:'
- en: '`Do you carry black` `leather handbags?`'
  id: totrans-43
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`你携带黑色皮革手提包吗？`'
- en: '`Give me a moment while I retrieve information about that` `particular item.`'
  id: totrans-44
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`请给我一点时间，我需要检索关于那个特定物品的信息。`'
- en: 'Example 2:'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '示例 2:'
- en: '`Do you have the silk scarves` `in blue?`'
  id: totrans-46
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`你有蓝色的丝绸围巾吗？`'
- en: '`Let me search our inventory for blue` `silk scarves.`'
  id: totrans-47
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`让我在我们的库存中搜索蓝色丝绸围巾。`'
- en: StyleSprint can provide examples that effectively help the model understand
    the nature of the inquiry and generate a response that is informative and aligned
    with the company’s policies and product offerings. In this example, we see that
    the responses are intended to be paired with a search component. This is a common
    approach and can be accomplished using a technique called **Retrieval Augmented
    Generation** (**RAG**), which is a component that facilitates retrieval of real-time
    data to inform the generated response. Combining a few-shot in-context learning
    approach with RAG could ensure that the system provides a logical and specific
    answer.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: StyleSprint 可以提供有效的示例，帮助模型理解查询的本质，并生成既具有信息性又符合公司政策和产品提供的信息响应。在这个例子中，我们看到响应旨在与搜索组件配对。这是一种常见的方法，可以使用称为
    **检索增强生成**（**RAG**）的技术来实现，这是一个促进实时数据检索以告知生成响应的组件。将少量示例情境学习方法与 RAG 结合使用可以确保系统提供逻辑性和具体的答案。
- en: In-context learning using a few-shot approach allows the model to rapidly adapt
    to various customer queries using a limited set of examples. When augmented with
    RAG, StyleSprint could potentially satisfy their use case and reduce the time
    and resources needed to fine-tune. However, this approach must be weighed against
    the depth of specialization and consistency of task-specific fine-tuning, which,
    as described, could also produce highly accurate answers that fit the brand tone.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 使用少量示例的情境学习允许模型快速适应各种客户查询，同时使用有限数量的示例。当与 RAG 结合使用时，StyleSprint 可能能够满足其用例并减少微调所需的时间和资源。然而，这种方法必须权衡专业化的深度和特定任务微调的一致性，正如所描述的，这也可能产生高度准确且符合品牌语调的答案。
- en: In the next section, we will formulate metrics that help us draw a direct comparison
    to guide StyleSprint in making an informed decision that best suits its customer
    service objectives and operational framework.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将制定有助于我们直接比较的指标，以指导 StyleSprint 做出最适合其客户服务目标和运营框架的明智决策。
- en: Fine-tuning versus in-context learning
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 微调与情境学习
- en: We learned how in-context learning could allow StyleSprint’s model to handle
    a diverse range of customer queries without requiring extensive retraining. Specifically,
    a few-shot approach combined with RAG could facilitate quick adaptation to new
    inquiries, as the model can generate responses based on a few examples. However,
    the effectiveness of in-context learning heavily relies on the quality and relevance
    of the examples provided in the prompts. Its success would also rely on the implementation
    of RAG. Moreover, without fine-tuning, responses may lack consistency or may not
    adhere as strictly to StyleSprint’s brand tone and customer service policies.
    Finally, depending entirely on a generative model without fine-tuning may inadvertently
    introduce bias, as discussed in [*Chapter 4*](B21773_04.xhtml#_idTextAnchor123).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们了解到情境学习如何使StyleSprint的模型能够处理各种客户查询，而无需进行大量重新训练。具体来说，少量方法与RAG的结合可以促进对新查询的快速适应，因为模型可以根据几个示例生成响应。然而，情境学习的效果在很大程度上取决于提示中提供的示例的质量和相关性。其成功也取决于RAG的实施。此外，没有微调，响应可能缺乏一致性，或者可能不会严格遵循StyleSprint的品牌语气和客户服务政策。最后，完全依赖生成模型而不进行微调可能会无意中引入偏差，如第4章所述[*](B21773_04.xhtml#_idTextAnchor123)。
- en: In practice, we have two very comparable and viable approaches. However, to
    make an informed decision, we should first perform a more in-depth comparison
    using quantitative methods.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，我们有两种非常相似且可行的方案。然而，为了做出明智的决定，我们应首先使用定量方法进行更深入的比较。
- en: 'To impartially assess the efficacy of in-context learning compared to fine-tuning,
    we can measure the quality and consistency of the generated responses. We can
    accomplish this using established and reliable metrics to compare outcomes from
    each of the approaches. Like prior evaluations, we will want to apply quantitative
    and qualitative methods applied across the following key dimensions:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 为了公正地评估情境学习与微调相比的效力，我们可以衡量生成响应的质量和一致性。我们可以使用既定且可靠的指标来比较每种方法的结果。与之前的评估一样，我们希望应用以下关键维度的定量和定性方法：
- en: '**Alignment with human judgment**: We can again apply semantic similarity to
    provide a quantitative measure of how often the model’s responses are correct
    or relevant based on a reference answer written by a human.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**与人类判断的一致性**：我们可以再次应用语义相似性，以提供基于人类编写的参考答案的定量指标，衡量模型响应的正确性或相关性。'
- en: StyleSprint’s brand communication experts can review a subset of the responses
    to provide a qualitative evaluation of the response accuracy and alignment with
    brand tone and voice.
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: StyleSprint的品牌传播专家可以审查一部分响应，以提供对响应准确性和与品牌语气和声音一致性的定性评估。
- en: '**Consistency and stability**: It is important to measure the degree to which
    questions are answered consistently each time despite minor variations in how
    the question is posed. Again, we can leverage semantic similarity to compare each
    new output to the prior when the input is held constant.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**一致性和稳定性**：重要的是要衡量每次回答问题时，尽管提问方式略有不同，但问题回答的一致程度。同样，当输入保持不变时，我们可以利用语义相似性来比较每个新输出与先前的输出。'
- en: In addition to evaluating the quality of model responses for each approach,
    we can also directly compare the operational and computational overhead required
    for each.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 除了评估每种方法的模型响应质量外，我们还可以直接比较每种方法所需的操作和计算开销。
- en: For fine-tuning, we will need to understand the overhead involved in training
    the model. While the PEFT method will significantly reduce the training effort,
    there could be considerably more infrastructure-related costs compared to in-context
    learning, which requires no additional training. Alternatively, for in-context
    learning, commoditized models such as OpenAI’s GPT-4 have a per-token cost model.
    StyleSprint must also consider the cost of tokens required to embed a sufficient
    number of few-shot examples in the prompt.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 对于微调，我们需要了解训练模型所涉及的开销。虽然PEFT方法将显著减少训练工作量，但与情境学习相比，可能存在相当多的基础设施相关成本，因为情境学习不需要额外的训练。另一方面，对于情境学习，如OpenAI的GPT-4这样的通用化模型有一个按令牌计费的成本模型。StyleSprint还必须考虑在提示中嵌入足够数量的少量示例所需的令牌成本。
- en: In both cases, StyleSprint will incur some operational costs to create best-in-class
    examples written by humans that can be used as a “gold standard” in either the
    few-shot approach or for additional model training.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两种情况下，StyleSprint将承担一些运营成本，以创建由人类编写的最佳示例，这些示例可以用作在少样本方法或额外模型训练中的“黄金标准”。
- en: By conducting these comparative tests and analyzing the results, StyleSprint
    will gain valuable insights into which approach – in-context learning or fine-tuning
    – best aligns with its operational goals and customer service standards. This
    data-driven evaluation will inform the decision on the optimal AI strategy for
    enhancing their customer service experience. We will implement these comparisons
    in the practice project that follows.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 通过进行这些比较测试并分析结果，StyleSprint将获得宝贵的见解，了解哪种方法——情境学习或微调——最能与其运营目标和客户服务标准相匹配。这种数据驱动的评估将指导他们决定最佳的AI策略，以增强客户服务体验。我们将在接下来的实践项目中实施这些比较。
- en: 'Practice project: Fine-tuning for Q&A using PEFT'
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实践项目：使用PEFT进行问答微调
- en: For our practice project, we will experiment with AdaLoRA to efficiently fine-tune
    a model for a customer query and compare it directly to the output of a **state-of-the-art**
    (**SOTA**) model using in-context learning. Like the previous chapter, we can
    rely on a prototyping environment such as Google Colab to complete the evaluation
    and comparison of the two approaches. We will demonstrate how to configure model
    training to use AdaLoRA as our PEFT method.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的实践项目，我们将尝试使用AdaLoRA高效地微调一个用于客户查询的模型，并将其与使用情境学习的**最先进**（**SOTA**）模型的输出直接比较。像上一章一样，我们可以依赖一个原型环境，如Google
    Colab，来完成两种方法的评估和比较。我们将展示如何配置模型训练以使用AdaLoRA作为我们的PEFT方法。
- en: Background regarding question-answering fine-tuning
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关于问答微调的背景
- en: Our project utilizes the Hugging Face training pipeline library, a widely recognized
    resource in the machine learning community. This library offers a variety of pre-built
    pipelines, including one for question-answering, which allows us to fine-tune
    pre-trained models with minimal setup. Hugging Face pipelines abstract much of
    the complexity involved in model training, making it accessible for developers
    to implement advanced natural language processing tasks directly and efficiently
    In particular, this pipeline behaves as an interface to a transformer model with
    a specific head for question-answering tasks. Recall that when we fine-tune a
    transformer model, we keep the architecture of the model – including the self-attention
    mechanism and the transformer layers – but we train the model’s parameters on
    a specific task, which, in this case, results in a model refined specifically
    to answer questions. Recall our practice project in [*Chapter 3*](B21773_03.xhtml#_idTextAnchor081)
    where the resulting model was a translator; we used a translator head to accomplish
    translation from English to French. For this project, the “head” is aligned to
    learn patterns in question-answering data.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的项目利用了Hugging Face训练管道库，这是机器学习社区中广为人知的资源。这个库提供了各种预构建的管道，包括一个用于问答的管道，这使得我们能够以最小的设置微调预训练模型。Hugging
    Face管道抽象了模型训练中涉及的大部分复杂性，使得开发者能够直接且高效地实现高级自然语言处理任务。特别是，这个管道作为一个接口，连接到具有特定问答任务头的transformer模型。回想一下，当我们微调一个transformer模型时，我们保持模型的架构——包括自注意力机制和transformer层——但我们仅在特定任务上训练模型的参数，在这种情况下，结果是针对问答任务进行了优化的模型。回想一下我们在[*第三章*](B21773_03.xhtml#_idTextAnchor081)中的实践项目，其中生成的模型是一个翻译器；我们使用翻译器头来完成从英语到法语的语言翻译。对于这个项目，“头”被调整为学习问答数据中的模式。
- en: 'However, when using a question-answer training pipeline, it is important to
    understand that the model does not simply memorize question-answer pairs, it learns
    the connection between questions and answers. Moreover, to answer appropriately,
    the model cannot rely entirely on training. It also requires additional context
    as input to compose a relevant answer. To understand this further, we decompose
    the model inferencing step as follows:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，当使用问答训练管道时，重要的是要理解模型不仅仅是记住问答对，它还学习问题与答案之间的联系。此外，为了给出适当的答案，模型不能完全依赖训练。它还需要额外的上下文作为输入来组成一个相关的答案。为了进一步理解这一点，我们将模型推理步骤分解如下：
- en: When feeding a question to a model, we must also include context relevant to
    the topic.
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当向模型输入问题时，我们还必须包括与主题相关的上下文。
- en: The model then determines the most relevant part of the context that answers
    the question. It does this by assigning probability scores to each token (word
    or sub-word) in the context.
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型随后确定上下文中回答问题的最相关部分。它是通过为上下文中的每个标记（单词或子词）分配概率分数来做到这一点的。
- en: 'The model “thinks” of the context as a potential source for the answer and
    assigns each token two scores: one score for being the **start** of the answer,
    and another for being the **end** of the answer.'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型“认为”上下文是答案的潜在来源，并为每个标记分配两个分数：一个分数用于作为答案的**开始**，另一个分数用于作为答案的**结束**。
- en: The token with the highest “start” score and “end” score is then chosen to form
    the answer **span**. The span is what is presented to the user.
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后选择具有最高“开始”分数和“结束”分数的标记来形成答案**跨度**。跨度就是向用户展示的内容。
- en: To provide a concrete example, if we ask the model, `Does StyleSprint have any
    leather jackets?` and provide a context of `StyleSprint sells a variety of coats,
    jackets and outerwear`, the model will process this context and identify that
    the most likely answer is something like `Yes, StyleSprint sells a variety of
    outerwear`. However, if the answer to a question is not included in the provided
    context, the model cannot generate a reliable answer. Additionally, if the context
    is too unspecific, the model may provide a more generic answer. Like in-context
    learning, the fine-tuned approach for question-answering requires relevant context.
    This means that, in practice, the model must be integrated with a search component
    that can retrieve additional context to pair with each question.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提供一个具体的例子，如果我们向模型提问，“StyleSprint有没有任何皮夹克？”并提供上下文“StyleSprint销售各种外套、夹克和外衣”，模型将处理这个上下文并确定最可能的答案是类似“是的，StyleSprint销售各种外衣”。然而，如果问题的答案不包含在提供的上下文中，模型无法生成可靠的答案。此外，如果上下文过于不具体，模型可能会提供一个更通用的答案。就像上下文学习一样，问答的微调方法也需要相关的上下文。这意味着在实践中，模型必须与能够检索与每个问题相关额外上下文的搜索组件集成。
- en: Consider our leather jacket example. When a question is received, the system
    could perform a search of its knowledge base and retrieve any contextual information
    relevant to a leather jacket (e.g., a paragraph about outerwear). Again, since
    the model was trained to answer questions in a way that aligns with the brand
    tone, it will extract the relevant information from the context provided to formulate
    an appropriate answer. Not only will integration with search provide the model
    with the context it needs but it will also allow the model to have up-to-date
    and real-time information.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 以我们的皮夹克例子为例。当接收到一个问题，系统可以对它的知识库进行搜索并检索与皮夹克相关的任何上下文信息（例如，关于外套的段落）。同样，由于模型被训练成以与品牌调性一致的方式回答问题，它将从提供的上下文中提取相关信息来制定适当的答案。不仅与搜索的集成将为模型提供所需的上下文，而且它还将允许模型拥有最新和实时信息。
- en: Additionally, we might incorporate a confidence threshold, where the model only
    gives an answer if it assigns a high enough probability to the start and end tokens.
    If the highest probability is below this threshold, we might say the model does
    not know, or request more information. Overall, the model efficacy relies heavily
    on the quality and size of the training data as well as the relevance of the context
    with regard to the questions posed.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们可能还会引入一个置信度阈值，只有当模型为开始和结束标记分配足够高的概率时，它才会给出答案。如果最高概率低于这个阈值，我们可能会说模型不知道，或者请求更多信息。总的来说，模型的有效性在很大程度上依赖于训练数据的质量和大小，以及上下文与提出的问题的相关性。
- en: Now that we have a better understanding of how fine-tuning for question-answering
    works and what to expect when using the question-answering pipeline from Hugging
    Face, we can begin to write our implementation.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经更好地理解了问答微调的工作原理以及在使用Hugging Face的问答管道时可以期待什么，我们可以开始编写我们的实现代码。
- en: Implementation in Python
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Python中的实现
- en: 'First and foremost, we install the required libraries:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们安装所需的库：
- en: '[PRE0]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Then, we import the question-answering modules from the transformers library.
    For our project, we will use Google’s **Flan T5 (small)**, which is considered
    a SOTA alternative to GPT 3.5\. As one of our goals continues to be to measure
    the performance versus efficiency trade-off, we begin with the smallest version
    of Flan T5, which has 80M parameters. This will enable faster training and more
    rapid iteration. However, please note that even a small model trained over a small
    number of epochs will require a high-RAM runtime environment:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们从transformers库中导入问答模块。对于我们的项目，我们将使用谷歌的**Flan T5（小型**），这被认为是GPT 3.5的SOTA替代品。我们的一个目标继续是衡量性能与效率之间的权衡，因此我们从Flan
    T5的最小版本开始，它有80M个参数。这将使训练更快，迭代更迅速。然而，请注意，即使在少量epoch上训练的小型模型也需要高RAM的运行环境：
- en: '[PRE1]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'With the pre-trained model instantiated, we can now configure the model to
    adapt its training process to use AdaLoRA, which, as we’ve learned, is specifically
    designed to allocate the parameter budget efficiently during the fine-tuning process:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在预训练模型实例化后，我们现在可以配置模型以适应其训练过程，使用AdaLoRA，正如我们所学的，它专门设计用于在微调过程中高效地分配参数预算：
- en: '[PRE2]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'As discussed, fine-tuning relies heavily on the quality and size of the training
    data. In the StyleSprint scenario, the company could aggregate question-answer
    pairs from its FAQ page, social media, and customer service transcripts. For this
    exercise, we will construct a simple dataset that looks similar to the following:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 正如讨论的那样，微调在很大程度上依赖于训练数据的质量和大小。在StyleSprint场景中，公司可以从其FAQ页面、社交媒体和客户服务记录中聚合问答对。为此练习，我们将构建一个类似于以下的数据集：
- en: '[PRE3]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'However, in order to integrate our dataset with the question-answer pipeline,
    we should first understand the `Trainer` class. The `Trainer` class in the Hugging
    Face transformers library expects the training and evaluation datasets to be in
    a specific format, usually as a PyTorch `Dataset` object, not just as simple lists
    of dictionaries. Further, each entry in the dataset needs to be tokenized and
    structured with the necessary fields such as `input_ids`, `attention_mask`, and,
    for question-answering tasks, `start_positions` and `end_positions`. Let us explore
    these in more detail:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，为了将我们的数据集与问答管道集成，我们首先应该了解`Trainer`类。Hugging Face transformers库中的`Trainer`类期望训练和评估数据集以特定格式提供，通常是一个PyTorch
    `Dataset`对象，而不仅仅是简单的字典列表。此外，数据集中的每个条目都需要进行标记化，并使用必要的字段结构化，如`input_ids`、`attention_mask`，对于问答任务，还需要`start_positions`和`end_positions`。让我们更详细地探讨这些内容：
- en: '`input_ids`: This is a sequence of integers that represent the input sentence
    in the model. Each word or sub-word in the sentence is converted into a unique
    integer or ID. Recall from earlier chapters that this process is known as `[101,`
    `354, 2459]`.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_ids`：这是一个表示模型中输入句子的整数序列。句子中的每个单词或子词都被转换成唯一的整数或ID。回想一下，在早期章节中，这个过程被称为`[101,`
    `354, 2459]`。'
- en: '`attention_mask`: An attention mask is a sequence of binary values where 1s
    indicate real tokens and 0s indicate padding tokens. In other words, in the places
    where 1s are present, the model will understand that those places need attention
    and the places with 0s will be ignored by the model. This is crucial when dealing
    with sentences of varying lengths and dealing with batches of sentences in training
    models.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`attention_mask`：注意力掩码是一个二进制值序列，其中1表示真实标记，0表示填充标记。换句话说，在1存在的地方，模型将理解这些地方需要注意力，而0存在的地方将被模型忽略。这在处理不同长度的句子和处理训练模型中的句子批次时至关重要。'
- en: '`start_positions` and `end_positions`: These are for question-answering tasks.
    They represent the indices of the start and end tokens of the answer in the tokenized
    form of the context. For example, in the context *Paris is the capital of France*,
    if the question is *What is the capital of France?* and the answer given is *Paris*,
    after tokenization, `start_position` and `end_position` will correspond to the
    index of *Paris* in the context.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`start_positions`和`end_positions`：这些用于问答任务。它们代表答案在上下文标记化形式中的起始和结束标记的索引。例如，在上下文*巴黎是法国的首都*中，如果问题是*法国的首都是什么？*，给出的答案是*巴黎*，在标记化后，`start_position`和`end_position`将对应于上下文中*巴黎*的索引。'
- en: 'With that understanding, we can create a class that adapts our dataset to meet
    the expectations of the trainer, as follows:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 有这样的理解后，我们可以创建一个类，使我们的数据集适应训练器的期望，如下所示：
- en: '[PRE4]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: For the complete custom dataset class code, visit this book’s GitHub repository
    at [https://github.com/PacktPublishing/Generative-AI-Foundations-in-Python](https://github.com/PacktPublishing/Generative-AI-Foundations-in-Python).
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看完整的自定义数据集类代码，请访问此书的GitHub仓库：[https://github.com/PacktPublishing/Generative-AI-Foundations-in-Python](https://github.com/PacktPublishing/Generative-AI-Foundations-in-Python)。
- en: 'With the training set prepared and our pipeline configured to apply the AdaLoRA
    method, we can finally move to the training step. For this project, we will configure
    the training to run for just a few epochs, but in the StyleSprint scenario, a
    much more robust training process would be required:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在准备完训练集并将我们的管道配置为应用AdaLoRA方法后，我们最终可以进入训练步骤。对于这个项目，我们将配置训练只运行几个周期，但在StyleSprint场景中，需要一个更加稳健的训练过程：
- en: '[PRE5]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: For our simple experiment, we do not expect a highly performant model; however,
    we can learn how to interpret the training output, which describes how well the
    model performed on the evaluation samples. The `Trainer` class will output a training
    summary that includes the loss metric.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的简单实验，我们并不期望模型有很高的性能；然而，我们可以学习如何解释训练输出，它描述了模型在评估样本上的表现。`Trainer`类将输出一个包含损失指标的训练摘要。
- en: Training loss
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 训练损失
- en: Training loss is a measure of how well the model is performing; a lower loss
    indicates better performance. In many deep learning models, especially those dealing
    with complex tasks such as language understanding, it’s common to start with a
    relatively high loss. The expectation is that this value should decrease as training
    progresses.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 训练损失是衡量模型表现好坏的一个指标；损失值越低，表示表现越好。在许多深度学习模型中，尤其是处理复杂任务（如语言理解）的模型，通常开始时损失值会相对较高。预期这个值应该随着训练的进行而降低。
- en: In the early stages of training, a high loss isn’t a cause for alarm as it commonly
    decreases as the model continues to learn. However, if the loss remains high,
    this signals that additional training may be needed. If the loss continues to
    be high after prolonged training, the learning rate and other hyperparameters
    may require adjustment, as an inappropriate learning rate can impact the model’s
    learning effectiveness. Moreover, the quality and quantity of your training data
    should be evaluated as insufficient data can hinder the training. For example,
    as we only use a few examples for the experiment, we expect a relatively high
    loss.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练的早期阶段，高损失值并不是一个需要警觉的原因，因为它通常会在模型继续学习的过程中降低。然而，如果损失值保持较高，这表明可能需要额外的训练。如果在长时间训练后损失值仍然很高，那么学习率和其他超参数可能需要调整，因为不适当的学习率可能会影响模型的学习效率。此外，应该评估训练数据的质量和数量，因为数据不足可能会阻碍训练。例如，由于我们只为实验使用了几个示例，我们预期损失值会相对较高。
- en: 'The next step is to use our newly fine-tuned model to infer or predict. We
    should also secure our trained model parameters so we can reuse it without retraining:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是使用我们新微调的模型进行推理或预测。我们还应该确保我们的训练模型参数安全，这样我们就可以在不重新训练的情况下重用它：
- en: '[PRE6]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: As discussed, we introduce context along with a question to the model, so that
    it can identify which fragment of the context responds most appropriately to the
    query. Consequently, we may want to consider integrating a vector search system
    (such as RAG) to automatically identify relevant documents from large datasets
    based on semantic similarities to a query. These search results may not provide
    specific answers, but the trained QA model can extract more precise answers from
    the results.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们将上下文和问题一起引入模型，以便它可以识别哪个上下文片段最恰当地响应查询。因此，我们可能希望考虑集成一个向量搜索系统（如RAG），根据与查询的语义相似性自动从大型数据集中识别相关文档。这些搜索结果可能不会提供具体的答案，但训练好的QA模型可以从结果中提取更精确的答案。
- en: With this hybrid approach, the vector search system first retrieves documents
    or text segments that are semantically related to the query. The QA model then
    analyzes this context to identify the precise answer that aligns with StyleSprint’s
    guidelines and expectations.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种混合方法，向量搜索系统首先检索与查询在语义上相关的文档或文本片段。然后，QA模型分析这个上下文以确定与StyleSprint的指南和期望相符的精确答案。
- en: Evaluation of results
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结果评估
- en: 'To evaluate our model outcomes, StyleSprint might apply the qualitative and
    quantitative approaches we have discussed in the chapter already. For the purpose
    of our experiment, we can measure the output of the model to a golden standard
    response using a simple measure for semantic similarity:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估我们的模型结果，StyleSprint可能会应用我们在本章中已经讨论过的定性和定量方法。为了我们的实验目的，我们可以使用一个简单的语义相似度度量来衡量模型输出的黄金标准响应：
- en: '[PRE7]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The results of our evaluation are as follows:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们评估的结果如下：
- en: '|  | PEFT Flan T5 | GPT 3.5T |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '|  | PEFT Flan T5 | GPT 3.5T |'
- en: '|  | Fine-tuned | In-context |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '|  | 微调 | 上下文 |'
- en: '| Semantic Similarity | 0.543 | 0.91 |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| 语义相似度 | 0.543 | 0.91 |'
- en: 'Table 5.1: Semantic similarity scores for fine-tuned Flan and GPT 3.5 Turbo,
    respectively'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 表5.1：微调后的Flan和GPT 3.5 Turbo的语义相似度分数
- en: Undoubtedly, the in-context learning arrived at an answer that was much closer
    to our gold standard reference. However, the fine-tuned model was not far behind.
    This tells us that with a more robust training dataset and considerably more epochs,
    the fine-tuned model could be comparable to GPT 3.5\. With more iteration and
    experimentation, StyleSprint could have a very robust fine-tuned model to answer
    very specific questions for its customers.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 无疑，上下文学习得出的答案与我们的黄金标准参考非常接近。然而，微调模型并不落后。这告诉我们，通过更健壮的训练数据集和相当多的epoch，微调模型可以与GPT
    3.5相媲美。通过更多的迭代和实验，StyleSprint可以拥有一个非常健壮的微调模型来回答客户的具体问题。
- en: Summary
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we focused on the strategic decision-making process between
    fine-tuning and in-context learning for StyleSprint’s AI-driven customer service
    system. While in-context learning, particularly few-shot learning, offers adaptability
    and resource efficiency, it may not consistently align with StyleSprint’s brand
    tone and customer service guidelines. This method relies heavily on the quality
    and relevance of the examples provided in the prompts, requiring careful crafting
    to ensure optimal outcomes.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们专注于StyleSprint的AI驱动客户服务系统中微调与上下文学习之间的战略决策过程。虽然上下文学习，尤其是少样本学习，提供了适应性和资源效率，但它可能并不始终与StyleSprint的品牌调性和客户服务指南保持一致。这种方法高度依赖于提示中提供的示例的质量和相关性，需要精心设计以确保最佳结果。
- en: On the other hand, PEFT methods such as AdaLoRA, offer a more focused approach
    to adapt a pre-trained model to the specific demands of customer service queries.
    PEFT methods modify only a small subset of a model’s parameters, reducing the
    computational burden while still achieving high performance. This efficiency is
    crucial for real-world applications where computational resources and response
    accuracy are both key considerations.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，PEFT方法如AdaLoRA，提供了一种更专注的方法来适应预训练模型以满足客户服务查询的特定需求。PEFT方法仅修改模型参数的一小部分，减少了计算负担，同时仍然实现高性能。这种效率对于现实世界应用至关重要，在这些应用中，计算资源和响应准确性都是关键考虑因素。
- en: Ultimately, the choice between in-context learning and fine-tuning is not just
    a technical decision but also a strategic one, deeply intertwined with the company’s
    operational goals, resource allocation, and the desired customer experience. The
    chapter suggests conducting comparative tests to assess the efficacy of both approaches,
    evaluating outcomes at scale through reliable metrics. This data-driven evaluation
    will inform StyleSprint’s decision on the optimal AI strategy for enhancing their
    customer service experience.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，在上下文学习与微调之间的选择，不仅仅是一个技术决策，也是一个战略决策，它与公司的运营目标、资源配置以及期望的客户体验紧密相连。本章建议进行对比测试，以评估两种方法的有效性，通过可靠的指标评估大规模的结果。这种数据驱动的评估将指导StyleSprint在提升客户服务体验方面做出最佳AI策略的决定。
- en: In summary, we now have a more complete understanding of the implications of
    fine-tuning versus in-context learning in LLMs, specifically in the context of
    customer service. It highlights the need for a company like StyleSprint to make
    a well-informed strategic decision, balancing the depth of specialization and
    consistency offered by fine-tuning against the adaptability and efficiency of
    in-context learning.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，我们现在对LLM中微调与上下文学习的含义有了更全面的理解，特别是在客户服务的背景下。它强调了像StyleSprint这样的公司做出明智战略决策的需要，在微调提供的深度专业化和一致性以及上下文学习的适应性和效率之间取得平衡。
- en: In the next chapter, we will explore PEFT for domain adaptation where the outcome
    of our training is a general-purpose model refined to understand a highly specific
    domain like finance or law.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: References
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This reference section serves as a repository of sources referenced within
    this book; you can explore these resources to further enhance your understanding
    and knowledge of the subject matter:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: Radford, A., Narasimhan, K., Salimans, T., and Sutskever, I. (2018). *Improving
    language understanding by generative* *pre-training*. OpenAI.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hu, E. J., Shen, Y., Wallis, P., Li, Y., Wang, S., Wang, L., and Chen, W. (2021).
    *LoRA: Low-Rank Adaptation of Large Language Models*. ArXiv. /abs/2106.09685'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang, Q., Chen, M., Bukharin, A., He, P., Cheng, Y., Chen, W., and Zhao, T.
    (2023). *Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning*. ArXiv.
    /abs/2303.10512
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Brown TB, Mann B, Ryder N, et al. 2020\. *Language Models are Few-Shot* *Learners*.
    ArXiv:2005.14165.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
