<html><head></head><body>
<div id="_idContainer069">
<h1 class="chapter-number" id="_idParaDest-78"><a id="_idTextAnchor159"/><span class="koboSpan" id="kobo.1.1">5</span></h1>
<h1 id="_idParaDest-79"><a id="_idTextAnchor160"/><span class="koboSpan" id="kobo.2.1">Picking Up and Putting Away Toys using Reinforcement Learning and Genetic Algorithms</span></h1>
<p><span class="koboSpan" id="kobo.3.1">This chapter is where the robots start to get challenging – and fun. </span><span class="koboSpan" id="kobo.3.2">What we want to do now is have the robot’s manipulator arm start picking up objects. </span><span class="koboSpan" id="kobo.3.3">Not only that, but instead of preprogramming arm moves and grasping actions, we want the robot to be able to learn how to pick up objects, and how to move its arm without </span><span class="No-Break"><span class="koboSpan" id="kobo.4.1">hitting itself.</span></span></p>
<p><span class="koboSpan" id="kobo.5.1">How would you teach a child to pick up toys in their room? </span><span class="koboSpan" id="kobo.5.2">Would you offer a reward for completing the task, such as “</span><em class="italic"><span class="koboSpan" id="kobo.6.1">If you pick up your toys, you will get a treat?</span></em><span class="koboSpan" id="kobo.7.1">” Or would you offer a threat of punishment, such as “</span><em class="italic"><span class="koboSpan" id="kobo.8.1">If you don’t pick up your toys, you can’t play games on your tablet.</span></em><span class="koboSpan" id="kobo.9.1">” This concept, offering positive feedback for good behavior and negative </span><a id="_idIndexMarker363"/><span class="koboSpan" id="kobo.10.1">feedback for undesirable actions, is called </span><strong class="bold"><span class="koboSpan" id="kobo.11.1">reinforcement learning</span></strong><span class="koboSpan" id="kobo.12.1">. </span><span class="koboSpan" id="kobo.12.2">That is one of the ways we will train our robot in </span><span class="No-Break"><span class="koboSpan" id="kobo.13.1">this chapter.</span></span></p>
<p><span class="koboSpan" id="kobo.14.1">If this sounds something like a game, where you get positive points for reaching a goal and lose points for missing a goal, then you are right. </span><span class="koboSpan" id="kobo.14.2">We have some concept of winning that we are trying to achieve, and we create some sort of point system to reinforce – that is to say, reward – behavior when the robot does what we want </span><span class="No-Break"><span class="koboSpan" id="kobo.15.1">it to.</span></span></p>
<p><span class="koboSpan" id="kobo.16.1">In this chapter, we will cover the </span><span class="No-Break"><span class="koboSpan" id="kobo.17.1">following topics:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.18.1">Designing </span><span class="No-Break"><span class="koboSpan" id="kobo.19.1">the software</span></span></li>
<li><span class="koboSpan" id="kobo.20.1">Setting up </span><span class="No-Break"><span class="koboSpan" id="kobo.21.1">the solution</span></span></li>
<li><span class="koboSpan" id="kobo.22.1">Introducing Q-learning for </span><span class="No-Break"><span class="koboSpan" id="kobo.23.1">grasping objects</span></span></li>
<li><span class="koboSpan" id="kobo.24.1">Introducing </span><strong class="bold"><span class="koboSpan" id="kobo.25.1">genetic algorithms</span></strong><span class="koboSpan" id="kobo.26.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.27.1">GAs</span></strong><span class="koboSpan" id="kobo.28.1">) for </span><span class="No-Break"><span class="koboSpan" id="kobo.29.1">path planning</span></span></li>
<li><span class="koboSpan" id="kobo.30.1">Alternative robot arm </span><span class="No-Break"><span class="koboSpan" id="kobo.31.1">ML approaches</span></span></li>
</ul>
<h1 id="_idParaDest-80"><a id="_idTextAnchor161"/><span class="koboSpan" id="kobo.32.1">Technical requirements</span></h1>
<p><span class="koboSpan" id="kobo.33.1">The exercise in this chapter does not require any new software or tools that we haven’t already seen in previous chapters. </span><span class="koboSpan" id="kobo.33.2">We will start by using Python and ROS 2. </span><span class="koboSpan" id="kobo.33.3">You will need an IDE for Python (IDLE or Visual Studio Code) to edit the </span><span class="No-Break"><span class="koboSpan" id="kobo.34.1">source code.</span></span></p>
<p><span class="koboSpan" id="kobo.35.1">Since this chapter is all about moving the robot arm, you will need a robot arm to execute the code. </span><span class="koboSpan" id="kobo.35.2">The one I used is the </span><strong class="bold"><span class="koboSpan" id="kobo.36.1">LewanSoul Robot xArm</span></strong><span class="koboSpan" id="kobo.37.1">, which I purchased from Amazon.com. </span><span class="koboSpan" id="kobo.37.2">This arm uses digital servos, which makes the programming much easier, and provides us with position feedback, so we know what position the arm is in. </span><span class="koboSpan" id="kobo.37.3">The arm I purchased can be found at </span><a href="http://tinyurl.com/xarmRobotBook"><span class="koboSpan" id="kobo.38.1">http://tinyurl.com/xarmRobotBook</span></a><span class="koboSpan" id="kobo.39.1"> at the time </span><span class="No-Break"><span class="koboSpan" id="kobo.40.1">of publication.</span></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.41.1">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.42.1">If you don’t want to buy a robot arm (or can’t), you can run this code against a simulation of a robot arm using ROS 2 and </span><strong class="bold"><span class="koboSpan" id="kobo.43.1">Gazebo</span></strong><span class="koboSpan" id="kobo.44.1">, a simulation engine. </span><span class="koboSpan" id="kobo.44.2">You can find instructions </span><span class="No-Break"><span class="koboSpan" id="kobo.45.1">at </span></span><a href="https://community.arm.com/arm-research/b/articles/posts/do-you-want-to-build-a-robot"><span class="No-Break"><span class="koboSpan" id="kobo.46.1">https://community.arm.com/arm-research/b/articles/posts/do-you-want-to-build-a-robot</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.47.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.48.1">You’ll find the code for this chapter in the GitHub repository for this book, </span><span class="No-Break"><span class="koboSpan" id="kobo.49.1">at </span></span><a href="https://github.com/PacktPublishing/Artificial-Intelligence-for-Robotics-2e"><span class="No-Break"><span class="koboSpan" id="kobo.50.1">https://github.com/PacktPublishing/Artificial-Intelligence-for-Robotics-2e</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.51.1">.</span></span></p>
<h1 id="_idParaDest-81"><a id="_idTextAnchor162"/><span class="koboSpan" id="kobo.52.1">Task analysis</span></h1>
<p><span class="koboSpan" id="kobo.53.1">Our tasks for this chapter are pretty straightforward. </span><span class="koboSpan" id="kobo.53.2">We will use a robot arm to pick up the toys we </span><a id="_idIndexMarker364"/><span class="koboSpan" id="kobo.54.1">identified in the previous chapter. </span><span class="koboSpan" id="kobo.54.2">This can be divided into the </span><span class="No-Break"><span class="koboSpan" id="kobo.55.1">following tasks:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.56.1">First, we build </span><a id="_idIndexMarker365"/><span class="koboSpan" id="kobo.57.1">an interface to control the robot arm. </span><span class="koboSpan" id="kobo.57.2">We are using </span><strong class="bold"><span class="koboSpan" id="kobo.58.1">ROS 2</span></strong><span class="koboSpan" id="kobo.59.1"> to connect the various parts of the robot together, so this interface is how the rest of the system sends commands and receives data from the arm. </span><span class="koboSpan" id="kobo.59.2">Then we get into teaching the arm to perform its function, which is picking up toys. </span><span class="koboSpan" id="kobo.59.3">The first level of capability is picking up or grasping toys. </span><span class="koboSpan" id="kobo.59.4">Each toy is slightly different, and the same strategy won’t work every time. </span><span class="koboSpan" id="kobo.59.5">Also, the toy might be in different orientations, so we have to adapt to how the toy is presented to the robot’s end effector (a fancy name for its hand). </span><span class="koboSpan" id="kobo.59.6">So rather than write a lot of custom code that may or may not work all the time, we want to create a structure so that the robot can learn </span><span class="No-Break"><span class="koboSpan" id="kobo.60.1">for itself.</span></span></li>
<li><span class="koboSpan" id="kobo.61.1">The next problem we face is to have the arm move. </span><span class="koboSpan" id="kobo.61.2">It’s not just that the arm has positions, but it also has to have a path from a start point to an end point. </span><span class="koboSpan" id="kobo.61.3">The arm is not a monolithic part – it’s composed of six different motors (as shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.62.1">Figure 5</span></em></span><em class="italic"><span class="koboSpan" id="kobo.63.1">.3</span></em><span class="koboSpan" id="kobo.64.1">) that each do something different. </span><span class="koboSpan" id="kobo.64.2">Two of the motors – the grip and the wrist – don’t move the arm at all; they only affect the hand. </span><span class="koboSpan" id="kobo.64.3">So our arm path is controlled by four motors. </span><span class="koboSpan" id="kobo.64.4">The other big problem is that the arm can collide with the body of the robot if we are not careful, so our path planning for the arm has to </span><span class="No-Break"><span class="koboSpan" id="kobo.65.1">avoid collisions.</span></span><p class="list-inset"><span class="koboSpan" id="kobo.66.1">We will use a </span><a id="_idIndexMarker366"/><span class="koboSpan" id="kobo.67.1">completely different technique for learning arm paths. </span><span class="koboSpan" id="kobo.67.2">A </span><strong class="bold"><span class="koboSpan" id="kobo.68.1">GA</span></strong><span class="koboSpan" id="kobo.69.1"> is a technique for machine learning that uses an analog of evolution to </span><em class="italic"><span class="koboSpan" id="kobo.70.1">evolve</span></em><span class="koboSpan" id="kobo.71.1"> complex behaviors out of </span><span class="No-Break"><span class="koboSpan" id="kobo.72.1">simple movements.</span></span></p></li>
</ul>
<p><span class="koboSpan" id="kobo.73.1">Now let’s talk a </span><a id="_idIndexMarker367"/><span class="koboSpan" id="kobo.74.1">bit first about what we have to work with. </span><span class="koboSpan" id="kobo.74.2">We have a </span><strong class="bold"><span class="koboSpan" id="kobo.75.1">mobile base</span></strong><span class="koboSpan" id="kobo.76.1"> with a six-degrees-of-freedom arm attached to it. </span><span class="koboSpan" id="kobo.76.2">We are fortunate that Albert’s robot arm is constructed </span><a id="_idIndexMarker368"/><span class="koboSpan" id="kobo.77.1">out of digital servo motors. </span><span class="koboSpan" id="kobo.77.2">We can tell where all of the parts of the arm are because we can read the position of the servo motors. </span><span class="koboSpan" id="kobo.77.3">We also know what we commanded the servo to do. </span><span class="koboSpan" id="kobo.77.4">Servo position is reported in units from 0 to 1,024 that represent from 0 degrees to 360 degrees of rotation. </span><span class="koboSpan" id="kobo.77.5">If we command a servo to move to position </span><strong class="source-inline"><span class="koboSpan" id="kobo.78.1">600</span></strong><span class="koboSpan" id="kobo.79.1">, and (after a short time interval to permit the motor to move) we see that the servo position is </span><strong class="source-inline"><span class="koboSpan" id="kobo.80.1">421</span></strong><span class="koboSpan" id="kobo.81.1">, then something is preventing the motor from reaching the goal we set for it. </span><span class="koboSpan" id="kobo.81.2">This information will be very valuable for training the </span><span class="No-Break"><span class="koboSpan" id="kobo.82.1">robot arm.</span></span></p>
<p><span class="koboSpan" id="kobo.83.1">We can use </span><strong class="bold"><span class="koboSpan" id="kobo.84.1">forward kinematics</span></strong><span class="koboSpan" id="kobo.85.1">, which </span><a id="_idIndexMarker369"/><span class="koboSpan" id="kobo.86.1">means summing up all the angles and levers of the arm to deduce where the hand is located (I’ll provide the code for that later in the chapter). </span><span class="koboSpan" id="kobo.86.2">We can use this hand location as our desired state – our </span><strong class="bold"><span class="koboSpan" id="kobo.87.1">reward criteria</span></strong><span class="koboSpan" id="kobo.88.1">. </span><span class="koboSpan" id="kobo.88.2">We will </span><a id="_idIndexMarker370"/><span class="koboSpan" id="kobo.89.1">give the robot points, or rewards, based on how close the hand is to the desired position and orientation we want. </span><span class="koboSpan" id="kobo.89.2">We want the robot to figure out what it takes to get to that position. </span><span class="koboSpan" id="kobo.89.3">We need to give the robot a way to test out different theories or actions that will result in the </span><span class="No-Break"><span class="koboSpan" id="kobo.90.1">arm moving.</span></span></p>
<p><span class="koboSpan" id="kobo.91.1">We will begin by just working with the robot hand, or to use the fancy robot term, the </span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.92.1">end effector</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.93.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.94.1">The following </span><a id="_idIndexMarker371"/><span class="koboSpan" id="kobo.95.1">diagram shows how we are trying to align our robot arm to pick up a toy by rotating </span><span class="No-Break"><span class="koboSpan" id="kobo.96.1">the wrist:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer064">
<span class="koboSpan" id="kobo.97.1"><img alt="Figure 5.1 – Storyboard for picking up a toy" src="image/B19846_05_1.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.98.1">Figure 5.1 – Storyboard for picking up a toy</span></p>
<p><span class="koboSpan" id="kobo.99.1">For grasping, we have three actions to work with. </span><span class="koboSpan" id="kobo.99.2">We position the arm to pick up the toy, we adjust the angle of the hand by rotating the hand with the wrist servo, and we close the hand in order to grasp the object. </span><span class="koboSpan" id="kobo.99.3">If the hand closes completely, then we missed the toy and the hand is empty. </span><span class="koboSpan" id="kobo.99.4">If the toy is keeping the gripper from closing because we picked it up, then we have success and have grabbed the toy. </span><span class="koboSpan" id="kobo.99.5">We’ll be using this process to teach the robot to use different hand positions to pick up toys based on </span><span class="No-Break"><span class="koboSpan" id="kobo.100.1">their shape.</span></span></p>
<h1 id="_idParaDest-82"><a id="_idTextAnchor163"/><span class="koboSpan" id="kobo.101.1">Designing the software</span></h1>
<p><span class="koboSpan" id="kobo.102.1">The first steps </span><a id="_idIndexMarker372"/><span class="koboSpan" id="kobo.103.1">in designing the robot arm control software are to establish a coordinate frame (how we measure movement), after which we set up our solution space by creating states (arm positions) and actions (movements that change positions). </span><span class="koboSpan" id="kobo.103.2">The following diagram shows the coordinate frame for the </span><span class="No-Break"><span class="koboSpan" id="kobo.104.1">robot arm:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer065">
<span class="koboSpan" id="kobo.105.1"><img alt="Figure 5.2 – Robot arm coordinate frame" src="image/B19846_05_2.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.106.1">Figure 5.2 – Robot arm coordinate frame</span></p>
<p><span class="koboSpan" id="kobo.107.1">Let’s define the coordinate frame of the robot – our reference that we use to measure movement – as shown in the preceding diagram. </span><span class="koboSpan" id="kobo.107.2">The X direction is toward the front of the robot, so movement forward and backward is along the X-axis. </span><span class="koboSpan" id="kobo.107.3">Horizontal movement (left or right) is along the Y-axis. </span><span class="koboSpan" id="kobo.107.4">Vertical movement (up and down) is in the Z direction. </span><span class="koboSpan" id="kobo.107.5">We place the zero point – the origin of our coordinates – down the center of the robot arm with zero Z (Z=0) on the floor. </span><span class="koboSpan" id="kobo.107.6">So, if I say the robot hand is moving positively in X, then it is moving away from the front of the robot. </span><span class="koboSpan" id="kobo.107.7">If the hand (the end of the arm) is moving in Y, then it is moving left </span><span class="No-Break"><span class="koboSpan" id="kobo.108.1">or right.</span></span></p>
<p><span class="koboSpan" id="kobo.109.1">Now we must </span><a id="_idIndexMarker373"/><span class="koboSpan" id="kobo.110.1">have a set of names that we will call the servo motors in the arm. </span><span class="koboSpan" id="kobo.110.2">We’ll do a bit of anthropomorphic naming, and give the arm parts anatomical titles. </span><span class="koboSpan" id="kobo.110.3">The motors are numbered in the control system and the servos on my robot arm </span><span class="No-Break"><span class="koboSpan" id="kobo.111.1">are labeled:</span></span></p>
<ul>
<li><em class="italic"><span class="koboSpan" id="kobo.112.1">Motor 1</span></em><span class="koboSpan" id="kobo.113.1"> opens and closes the gripper. </span><span class="koboSpan" id="kobo.113.2">We may also call the gripper </span><span class="No-Break"><span class="koboSpan" id="kobo.114.1">the hand.</span></span></li>
<li><em class="italic"><span class="koboSpan" id="kobo.115.1">Motor 2</span></em><span class="koboSpan" id="kobo.116.1"> is wrist rotate, which rotates </span><span class="No-Break"><span class="koboSpan" id="kobo.117.1">the hand.</span></span></li>
<li><em class="italic"><span class="koboSpan" id="kobo.118.1">Motor 3</span></em><span class="koboSpan" id="kobo.119.1"> is the wrist pitch (up and </span><span class="No-Break"><span class="koboSpan" id="kobo.120.1">down) direction.</span></span></li>
<li><span class="koboSpan" id="kobo.121.1">We’ll call </span><em class="italic"><span class="koboSpan" id="kobo.122.1">Motor 4</span></em><span class="koboSpan" id="kobo.123.1"> the elbow. </span><span class="koboSpan" id="kobo.123.2">The elbow flexes the arm in the middle, just as </span><span class="No-Break"><span class="koboSpan" id="kobo.124.1">you expect.</span></span></li>
<li><em class="italic"><span class="koboSpan" id="kobo.125.1">Motor 5</span></em><span class="koboSpan" id="kobo.126.1"> is the shoulder pitch servo, which moves the arm up and down, rotating around the Y-axis when the arm is pointing </span><span class="No-Break"><span class="koboSpan" id="kobo.127.1">straight ahead.</span></span></li>
<li><em class="italic"><span class="koboSpan" id="kobo.128.1">Motor 6</span></em><span class="koboSpan" id="kobo.129.1"> is at the base of the arm, so we’ll call it the shoulder yaw (right or left) servo. </span><span class="koboSpan" id="kobo.129.2">It rotates the entire arm about the Z-axis. </span><span class="koboSpan" id="kobo.129.3">I’ve decided not to move this axis, since the entire base of the robot can rotate due to the omni wheels. </span><span class="koboSpan" id="kobo.129.4">We’ll just move the arm up and down to simplify the problem. </span><span class="koboSpan" id="kobo.129.5">The navigation system we develop in </span><a href="B19846_08.xhtml#_idTextAnchor235"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.130.1">Chapter 8</span></em></span></a><span class="koboSpan" id="kobo.131.1"> will point the arm in the </span><span class="No-Break"><span class="koboSpan" id="kobo.132.1">correct direction.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.133.1">We will start by defining an interface to the robot arm that the rest of the robot control system </span><span class="No-Break"><span class="koboSpan" id="kobo.134.1">can use:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer066">
<span class="koboSpan" id="kobo.135.1"><img alt="Figure 5.3 – Robot arm motor nomenclature" src="image/B19846_05_3.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.136.1">Figure 5.3 – Robot arm motor nomenclature</span></p>
<p><span class="koboSpan" id="kobo.137.1">Here, pitch refers to up/down motion while yaw refers to </span><span class="No-Break"><span class="koboSpan" id="kobo.138.1">right/left motion.</span></span></p>
<p><span class="koboSpan" id="kobo.139.1">We’ll use </span><a id="_idIndexMarker374"/><span class="koboSpan" id="kobo.140.1">two terms that are common in the robot world to describe how we calculate where the arm is based on the data </span><span class="No-Break"><span class="koboSpan" id="kobo.141.1">we have:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.142.1">Forward Kinematics</span></strong><span class="koboSpan" id="kobo.143.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.144.1">FK</span></strong><span class="koboSpan" id="kobo.145.1">) is the process of starting at the base of the robot arm and </span><a id="_idIndexMarker375"/><span class="koboSpan" id="kobo.146.1">working out toward the gripper, calculating the position and orientation of each joint in turn. </span><span class="koboSpan" id="kobo.146.2">We take </span><a id="_idIndexMarker376"/><span class="koboSpan" id="kobo.147.1">the position of the joint and the angle it is at, and add the length of the arm between that joint and the next joint. </span><span class="koboSpan" id="kobo.147.2">The process of doing this calculation, which produces an X-Y-Z position and a pitch-roll-yaw orientation of the end of the robot’s fingers, is called forward kinematics because we calculate forward from the base and out to </span><span class="No-Break"><span class="koboSpan" id="kobo.148.1">the arm.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.149.1">Inverse Kinematics</span></strong><span class="koboSpan" id="kobo.150.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.151.1">IK</span></strong><span class="koboSpan" id="kobo.152.1">) takes a different approach. </span><span class="koboSpan" id="kobo.152.2">We know the position and orientation of either where the hand is, or where we want it to be. </span><span class="koboSpan" id="kobo.152.3">Then we calculate </span><a id="_idIndexMarker377"/><span class="koboSpan" id="kobo.153.1">backward up the arm to determine what joint angles would produce that hand position. </span><span class="koboSpan" id="kobo.153.2">IK is a bit trickier because there </span><a id="_idIndexMarker378"/><span class="koboSpan" id="kobo.154.1">may be more than one solution (combination of joint positions) that may produce a given hand result. </span><span class="koboSpan" id="kobo.154.2">Try this with your own arm. </span><span class="koboSpan" id="kobo.154.3">Grasp a doorknob. </span><span class="koboSpan" id="kobo.154.4">Now move your arm while keeping your hand on the doorknob. </span><span class="koboSpan" id="kobo.154.5">There are multiple combinations of your joints that result in your hand being in the same position and orientation. </span><span class="koboSpan" id="kobo.154.6">We won’t be using IK here in this book, but I wanted you to be familiar with the term, which is often used in robot arms to drive the position of robot end effectors (grippers </span><span class="No-Break"><span class="koboSpan" id="kobo.155.1">or hands).</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.156.1">For a more in-depth explanation of these concepts, you can refer </span><span class="No-Break"><span class="koboSpan" id="kobo.157.1">to </span></span><a href="https://control.com/technical-articles/robot-manipulation-control-with-inverse-and-forward-kinematics/"><span class="No-Break"><span class="koboSpan" id="kobo.158.1">https://control.com/technical-articles/robot-manipulation-control-with-inverse-and-forward-kinematics/</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.159.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.160.1">Next, let’s discuss how we can put the ar</span><a id="_idTextAnchor164"/><a id="_idTextAnchor165"/><a id="_idTextAnchor166"/><span class="koboSpan" id="kobo.161.1">m </span><span class="No-Break"><span class="koboSpan" id="kobo.162.1">in motion.</span></span></p>
<h1 id="_idParaDest-83"><a id="_idTextAnchor167"/><span class="koboSpan" id="kobo.163.1">Setting up the solution</span></h1>
<p><span class="koboSpan" id="kobo.164.1">We will call the act of setting the motors to a different position an </span><strong class="bold"><span class="koboSpan" id="kobo.165.1">action</span></strong><span class="koboSpan" id="kobo.166.1">, and we will call the </span><a id="_idIndexMarker379"/><span class="koboSpan" id="kobo.167.1">position of the robot arm and hand the </span><strong class="bold"><span class="koboSpan" id="kobo.168.1">state</span></strong><span class="koboSpan" id="kobo.169.1">. </span><span class="koboSpan" id="kobo.169.2">An action applied to a state results in the arm being in a </span><span class="No-Break"><span class="koboSpan" id="kobo.170.1">new state.</span></span></p>
<p><span class="koboSpan" id="kobo.171.1">We are going to have the robot associate states (a beginning position of the hand) and an action (the motor commands used when at that state) with the probability of generating either a positive or negative </span><strong class="bold"><span class="koboSpan" id="kobo.172.1">outcome</span></strong><span class="koboSpan" id="kobo.173.1"> – we will be training the robot to figure out which sets of actions result in maximizing the </span><strong class="bold"><span class="koboSpan" id="kobo.174.1">reward</span></strong><span class="koboSpan" id="kobo.175.1">. </span><span class="koboSpan" id="kobo.175.2">What’s a reward? </span><span class="koboSpan" id="kobo.175.3">It’s just an arbitrary value that we use to define whether the learning the robot accomplished was positive – something we wanted – or negative – something we did not want. </span><span class="koboSpan" id="kobo.175.4">If the action resulted in positive learning, then we increment the reward, and if it does not, then we decrement the reward. </span><span class="koboSpan" id="kobo.175.5">The robot will use an algorithm to both try and maximize the reward, and to incrementally learn </span><span class="No-Break"><span class="koboSpan" id="kobo.176.1">a task.</span></span></p>
<p><span class="koboSpan" id="kobo.177.1">Let’s understand this process better by exploring the role played by </span><span class="No-Break"><span class="koboSpan" id="kobo.178.1">machine learning.</span></span></p>
<h2 id="_idParaDest-84"><a id="_idTextAnchor168"/><span class="koboSpan" id="kobo.179.1">Machine learning for robot arms</span></h2>
<p><span class="koboSpan" id="kobo.180.1">Since incremental learning was also part of neural networks, we will use some of the same tools </span><a id="_idIndexMarker380"/><span class="koboSpan" id="kobo.181.1">we used before in our neural network to propagate a reward to each step in a chain of movements that result in the hand moving to some location. </span><span class="koboSpan" id="kobo.181.2">In reinforcement learning, this is called </span><strong class="bold"><span class="koboSpan" id="kobo.182.1">discounting the reward</span></strong><span class="koboSpan" id="kobo.183.1"> – distributing portions of rewards to the step in a multi-step process. </span><span class="koboSpan" id="kobo.183.2">Likewise, the combination of a state and an action is called a </span><strong class="bold"><span class="koboSpan" id="kobo.184.1">policy</span></strong><span class="koboSpan" id="kobo.185.1"> – because we are telling the robot, “when you are in this position, and want to go to that position, do</span><a id="_idTextAnchor169"/><span class="koboSpan" id="kobo.186.1"> this action.” </span><span class="koboSpan" id="kobo.186.2">Let’s understand this concept better by looking more closely at our process for learning with the </span><span class="No-Break"><span class="koboSpan" id="kobo.187.1">robot arm:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.188.1">We set our goal position of the robot hand, which is the position of the robot hand in X and Z coordinates in millimeters from the rotational center of </span><span class="No-Break"><span class="koboSpan" id="kobo.189.1">the arm.</span></span></li>
<li><span class="koboSpan" id="kobo.190.1">The robot will try a series of movements to try and get close to that goal. </span><span class="koboSpan" id="kobo.190.2">We will not be giving the robot the motor positions it needs to get to that goal – the robot must learn. </span><span class="koboSpan" id="kobo.190.3">The initial movements will be totally randomly generated. </span><span class="koboSpan" id="kobo.190.4">We will restrict the delta movement (analogous to the learning rate from the previous chapter) to some small size so we don’t get wild flailing of </span><span class="No-Break"><span class="koboSpan" id="kobo.191.1">the arm.</span></span></li>
<li><span class="koboSpan" id="kobo.192.1">At each incremental movement, we will score the movement based on whether or not the arm moved closer to the </span><span class="No-Break"><span class="koboSpan" id="kobo.193.1">goal position.</span></span></li>
<li><span class="koboSpan" id="kobo.194.1">The robot will remember these movements by associating the beginning state and the action (movement) with the </span><span class="No-Break"><span class="koboSpan" id="kobo.195.1">reward score.</span></span></li>
<li><span class="koboSpan" id="kobo.196.1">Later, we will train a neural network to generate probabilities of positive outcomes based on the inputs of starting state and movement action. </span><span class="koboSpan" id="kobo.196.2">This will allow the arm to learn which sequences of movement achieve positive results. </span><span class="koboSpan" id="kobo.196.3">Then we will be able to predict which movement will result in the arm moving correctly based on the </span><span class="No-Break"><span class="koboSpan" id="kobo.197.1">star</span><a id="_idTextAnchor170"/><span class="koboSpan" id="kobo.198.1">ting position.</span></span></li>
<li><span class="koboSpan" id="kobo.199.1">You can also surmise that we must add a reward for accomplishing the task quickly – we want the results to be efficient, and so we will add rewards for taking the shortest time to complete the task – or, you could say, we subtract a reward for each step needed to get to the goal so that the process with the fewest steps gets the </span><span class="No-Break"><span class="koboSpan" id="kobo.200.1">most reward.</span></span></li>
<li><span class="koboSpan" id="kobo.201.1">We calculate </span><a id="_idIndexMarker381"/><span class="koboSpan" id="kobo.202.1">rewards using the </span><strong class="bold"><span class="koboSpan" id="kobo.203.1">Q-function</span></strong><span class="koboSpan" id="kobo.204.1">, </span><span class="No-Break"><span class="koboSpan" id="kobo.205.1">as follows:</span></span></li>
</ol>
<p><em class="italic"><span class="koboSpan" id="kobo.206.1">Q = Q(s,a)+ (reward(s,a)  + g  * </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.207.1">max(Q(s’,a’))</span></em></span></p>
<p class="list-inset"><span class="koboSpan" id="kobo.208.1">where </span><em class="italic"><span class="koboSpan" id="kobo.209.1">Q</span></em><span class="koboSpan" id="kobo.210.1"> represents the reward the robot will get (or expects to get) from a particular action. </span><em class="italic"><span class="koboSpan" id="kobo.211.1">Q(s,a)</span></em><span class="koboSpan" id="kobo.212.1"> is the final reward that we expect overall for an action given the starting state. </span><em class="italic"><span class="koboSpan" id="kobo.213.1">reward(s,a)</span></em><span class="koboSpan" id="kobo.214.1"> is the reward for that action (the small, incremental step we take now). </span><em class="italic"><span class="koboSpan" id="kobo.215.1">g</span></em><span class="koboSpan" id="kobo.216.1"> is a discount function that rewards getting to the </span><a id="_idIndexMarker382"/><span class="koboSpan" id="kobo.217.1">goal quicker, that is, with a fewer number of steps (the more steps you have, the more </span><em class="italic"><span class="koboSpan" id="kobo.218.1">g</span></em><span class="koboSpan" id="kobo.219.1"> discounts (removes the reward)), and </span><em class="italic"><span class="koboSpan" id="kobo.220.1">max(Q(s’,a’))</span></em><span class="koboSpan" id="kobo.221.1"> selects the action that results in the largest reward out of the set of actions available at that state. </span><span class="koboSpan" id="kobo.221.2">In the equation, </span><em class="italic"><span class="koboSpan" id="kobo.222.1">s</span></em><span class="koboSpan" id="kobo.223.1"> and </span><em class="italic"><span class="koboSpan" id="kobo.224.1">a</span></em><span class="koboSpan" id="kobo.225.1"> represent the current state and action, and </span><em class="italic"><span class="koboSpan" id="kobo.226.1">s’</span></em><span class="koboSpan" id="kobo.227.1"> and </span><em class="italic"><span class="koboSpan" id="kobo.228.1">a’</span></em><span class="koboSpan" id="kobo.229.1"> represent the subsequent state and action, respectively. </span><span class="koboSpan" id="kobo.229.2">This is my version of Bellman’s equation for decision-making, with some adaptations for this particular problem. </span><span class="koboSpan" id="kobo.229.3">I added a discount for longer solutions (with more steps, thus taking longer to execute) to reward quicker arm movement (fewer steps), and left out the learning rate (alpha) as we are taking whole steps for each state (we don’t have intermediate states </span><span class="No-Break"><span class="koboSpan" id="kobo.230.1">to learn).</span></span></p>
<p><span class="koboSpan" id="kobo.231.1">Next, let’s understand how we can teach the robot arm how to</span><a id="_idTextAnchor171"/><a id="_idTextAnchor172"/> <span class="No-Break"><span class="koboSpan" id="kobo.232.1">learn movement.</span></span></p>
<h2 id="_idParaDest-85"><a id="_idTextAnchor173"/><span class="koboSpan" id="kobo.233.1">How do we pick actions?</span></h2>
<p><span class="koboSpan" id="kobo.234.1">What actions </span><a id="_idIndexMarker383"/><span class="koboSpan" id="kobo.235.1">can the robot arm perform? </span><span class="koboSpan" id="kobo.235.2">As shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.236.1">Figure 5</span></em></span><em class="italic"><span class="koboSpan" id="kobo.237.1">.3</span></em><span class="koboSpan" id="kobo.238.1">, we have six motors, and we have three options for </span><span class="No-Break"><span class="koboSpan" id="kobo.239.1">each motor:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.240.1">We can do nothing – that is, not move </span><span class="No-Break"><span class="koboSpan" id="kobo.241.1">at all</span></span></li>
<li><span class="koboSpan" id="kobo.242.1">We can move counterclockwise, which will make our motor </span><span class="No-Break"><span class="koboSpan" id="kobo.243.1">angle smaller</span></span></li>
<li><span class="koboSpan" id="kobo.244.1">We can move clockwise, which makes our motor </span><span class="No-Break"><span class="koboSpan" id="kobo.245.1">angle larger</span></span></li>
</ul>
<p class="callout-heading"><span class="koboSpan" id="kobo.246.1">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.247.1">Most servo motors treat positive position changes as clockwise rotation. </span><span class="koboSpan" id="kobo.247.2">Thus, if we command the rotation to change from 200 to 250 degrees, the motor will turn clockwise </span><span class="No-Break"><span class="koboSpan" id="kobo.248.1">50 degrees.</span></span></p>
<p><span class="koboSpan" id="kobo.249.1">Our action </span><a id="_idIndexMarker384"/><span class="koboSpan" id="kobo.250.1">space for each motion of the robot arm is to move each motor either clockwise, counterclockwise, or not at all. </span><span class="koboSpan" id="kobo.250.2">This gives us 729 combinations with 6 motors (</span><em class="italic"><span class="koboSpan" id="kobo.251.1">3</span></em><span class="superscript"><span class="koboSpan" id="kobo.252.1">6</span></span><span class="koboSpan" id="kobo.253.1"> possible actions). </span><span class="koboSpan" id="kobo.253.2">That is quite a lot. </span><span class="koboSpan" id="kobo.253.3">The software interface we are going to build refers to the robot arm motors by number with </span><em class="italic"><span class="koboSpan" id="kobo.254.1">1</span></em><span class="koboSpan" id="kobo.255.1"> being the hand and </span><em class="italic"><span class="koboSpan" id="kobo.256.1">6</span></em><span class="koboSpan" id="kobo.257.1"> being the shoulder </span><span class="No-Break"><span class="koboSpan" id="kobo.258.1">rotation motor.</span></span></p>
<p><span class="koboSpan" id="kobo.259.1">Let’s reduce this number and just consider the motions of three of the motors – the </span><strong class="bold"><span class="koboSpan" id="kobo.260.1">shoulder pitch</span></strong><span class="koboSpan" id="kobo.261.1"> (</span><em class="italic"><span class="koboSpan" id="kobo.262.1">Motor 5</span></em><span class="koboSpan" id="kobo.263.1">), </span><strong class="bold"><span class="koboSpan" id="kobo.264.1">elbow pitch</span></strong><span class="koboSpan" id="kobo.265.1"> (</span><em class="italic"><span class="koboSpan" id="kobo.266.1">Motor 4</span></em><span class="koboSpan" id="kobo.267.1">), and </span><strong class="bold"><span class="koboSpan" id="kobo.268.1">wrist pitch</span></strong><span class="koboSpan" id="kobo.269.1"> (</span><em class="italic"><span class="koboSpan" id="kobo.270.1">Motor 3</span></em><span class="koboSpan" id="kobo.271.1">). </span><span class="koboSpan" id="kobo.271.2">We’ll lock the shoulder yaw for now and just move the arm straight ahead, and since rotating the hand and moving the fingers does not change the position or orientation of the hand, we can ignore those, too. </span><span class="koboSpan" id="kobo.271.3">Now we have 27 combinations or policies to consider (</span><em class="italic"><span class="koboSpan" id="kobo.272.1">3</span></em><span class="superscript"><span class="koboSpan" id="kobo.273.1">3</span></span><span class="koboSpan" id="kobo.274.1">). </span><span class="koboSpan" id="kobo.274.2">We will note </span><a id="_idIndexMarker385"/><span class="koboSpan" id="kobo.275.1">this with an </span><strong class="bold"><span class="koboSpan" id="kobo.276.1">action matrix</span></strong><span class="koboSpan" id="kobo.277.1">. </span><span class="koboSpan" id="kobo.277.2">Each action will have three values. </span><span class="koboSpan" id="kobo.277.3">An action that reduces the angle of </span><em class="italic"><span class="koboSpan" id="kobo.278.1">Motor 5</span></em><span class="koboSpan" id="kobo.279.1"> holds </span><em class="italic"><span class="koboSpan" id="kobo.280.1">Motor 4</span></em><span class="koboSpan" id="kobo.281.1"> in place and increases </span><em class="italic"><span class="koboSpan" id="kobo.282.1">Motor 3</span></em><span class="koboSpan" id="kobo.283.1">, noted as </span><strong class="source-inline"><span class="koboSpan" id="kobo.284.1">[-1, 0, 1]</span></strong><span class="koboSpan" id="kobo.285.1">. </span><span class="koboSpan" id="kobo.285.2">We will use a value of just +/-1 or 0 in the action matrix to step the motors in small increments. </span><span class="koboSpan" id="kobo.285.3">The x-y coordinates of the hand can be computed from the sums of the angles of each joint times the length of </span><span class="No-Break"><span class="koboSpan" id="kobo.286.1">the arm.</span></span></p>
<p><span class="koboSpan" id="kobo.287.1">Here is a Python function to compute the position of the robot hand, given that each arm segment is 10 cm long. </span><span class="koboSpan" id="kobo.287.2">You can substitute the length of your robot arm segments. </span><span class="koboSpan" id="kobo.287.3">This function turns the motor angles representing the hand position from degrees into x-y coordinates </span><span class="No-Break"><span class="koboSpan" id="kobo.288.1">in centimeters:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.289.1">
def forward_kinematics(theta1, theta2, theta3, segment_length):
 # Convert degrees to radians
    theta1_rad = math.radians(theta1)
    theta2_rad = math.radians(theta2)
    theta3_rad = math.radians(theta3)
    # Calculate positions of each joint
    x1 = segment_length * math.cos(theta1_rad)
    y1 = segment_length * math.sin(theta1_rad)
    x2 = x1 + segment_length * math.cos(theta1_rad + theta2_rad)
    y2 = y1 + segment_length * math.sin(theta1_rad + theta2_rad)
    x3 = x2 + segment_length * math.cos(theta1_rad + theta2_rad + theta3_rad)
    y3 = y2 + segment_length * math.sin(theta1_rad + theta2_rad + theta3_rad)
return x3, y3</span></pre> <p><span class="koboSpan" id="kobo.290.1">The actions of the arm (possible movements) make up the action space of our robot arm, which is the set of all possible actions. </span><span class="koboSpan" id="kobo.290.2">What we will be doing in this chapter is investigating various ways of picking which action to perform and when in order to accomplish our tasks, and using machine</span><a id="_idTextAnchor174"/><span class="koboSpan" id="kobo.291.1"> learning to </span><span class="No-Break"><span class="koboSpan" id="kobo.292.1">do it.</span></span></p>
<p><span class="koboSpan" id="kobo.293.1">Another way </span><a id="_idIndexMarker386"/><span class="koboSpan" id="kobo.294.1">of looking at this process is that we are generating a </span><strong class="bold"><span class="koboSpan" id="kobo.295.1">decision tree</span></strong><span class="koboSpan" id="kobo.296.1">. </span><span class="koboSpan" id="kobo.296.2">You are probably familiar with the concept. </span><span class="koboSpan" id="kobo.296.3">We have a bit of </span><a id="_idIndexMarker387"/><span class="koboSpan" id="kobo.297.1">a unique application when applying this to a robot arm, because our arm is a series of joints connected together, and moving one moves all of the other joints farther out on the arm. </span><span class="koboSpan" id="kobo.297.2">When we move Motor 5, Motors 4 and 3 move position in space, and their angles and distances to the ground and to our goal change. </span><span class="koboSpan" id="kobo.297.3">Each possible motor move adds 27 new branches to our decision tree, and can generate 27 new arm positions. </span><span class="koboSpan" id="kobo.297.4">All we have to do is pi</span><a id="_idTextAnchor175"/><span class="koboSpan" id="kobo.298.1">ck which one </span><span class="No-Break"><span class="koboSpan" id="kobo.299.1">to keep.</span></span></p>
<p><span class="koboSpan" id="kobo.300.1">The rest of this chapter will deal with just how we go about selecting our motions. </span><span class="koboSpan" id="kobo.300.2">It’s time to start writing some code now. </span><span class="koboSpan" id="kobo.300.3">The first order of business is to create an interface to the robot arm that the rest of the robot </span><span class="No-Break"><span class="koboSpan" id="kobo.301.1">can use.</span></span></p>
<h1 id="_idParaDest-86"><a id="_idTextAnchor176"/><span class="koboSpan" id="kobo.302.1">Creating the interface to the arm</span></h1>
<p><span class="koboSpan" id="kobo.303.1">As previously </span><a id="_idIndexMarker388"/><span class="koboSpan" id="kobo.304.1">noted, we are using ROS 2 as </span><a id="_idIndexMarker389"/><span class="koboSpan" id="kobo.305.1">our interface service, which creates a </span><strong class="bold"><span class="koboSpan" id="kobo.306.1">Modular Open System Architecture</span></strong><span class="koboSpan" id="kobo.307.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.308.1">MOSA</span></strong><span class="koboSpan" id="kobo.309.1">). </span><span class="koboSpan" id="kobo.309.2">This turns our components into </span><em class="italic"><span class="koboSpan" id="kobo.310.1">plug-and-play</span></em><span class="koboSpan" id="kobo.311.1"> devices that can be added, removed, or modified, much like the apps on a smartphone. </span><span class="koboSpan" id="kobo.311.2">The secret to making that happen is to create a useful, generic interface, which we will </span><span class="No-Break"><span class="koboSpan" id="kobo.312.1">do now.</span></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.313.1">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.314.1">I’m creating my own interface to ROS 2 that is just for this book. </span><span class="koboSpan" id="kobo.314.2">We won’t be using any other ROS packages with this arm – just what we create, so I wanted the very minimum interface to get the </span><span class="No-Break"><span class="koboSpan" id="kobo.315.1">job done.</span></span></p>
<p><span class="koboSpan" id="kobo.316.1">We’ll be creating this interface in Python. </span><span class="koboSpan" id="kobo.316.2">Follow </span><span class="No-Break"><span class="koboSpan" id="kobo.317.1">these steps:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.318.1">First, create a </span><strong class="bold"><span class="koboSpan" id="kobo.319.1">package</span></strong><span class="koboSpan" id="kobo.320.1"> for the robot arm in ROS 2. </span><span class="koboSpan" id="kobo.320.2">A package is a portable organization unit for functionality in ROS 2. </span><span class="koboSpan" id="kobo.320.3">Since we have multiple programs and multiple functions for the robot arm, we can bundle </span><span class="No-Break"><span class="koboSpan" id="kobo.321.1">them together:</span></span><pre class="source-code">
<strong class="bold"><span class="koboSpan" id="kobo.322.1">cd ~/ros2_ws/src</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.323.1">ros2 pkg create –build-type ament-cmake ros_xarm</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.324.1">colcon build</span></strong></pre><p class="list-inset"><span class="koboSpan" id="kobo.325.1">These commands will create a directory structure in our </span><strong class="source-inline"><span class="koboSpan" id="kobo.326.1">src</span></strong><span class="koboSpan" id="kobo.327.1"> directory where we will store all of the parts </span><span class="No-Break"><span class="koboSpan" id="kobo.328.1">we need.</span></span></p></li> <li><span class="koboSpan" id="kobo.329.1">We need to install the drivers for xArm so we can use them </span><span class="No-Break"><span class="koboSpan" id="kobo.330.1">in Python:</span></span><pre class="source-code">
<strong class="bold"><span class="koboSpan" id="kobo.331.1">pip install xarm</span></strong></pre></li> <li><span class="koboSpan" id="kobo.332.1">Now we go to our new </span><span class="No-Break"><span class="koboSpan" id="kobo.333.1">source directory:</span></span><pre class="source-code">
<strong class="bold"><span class="koboSpan" id="kobo.334.1">cd ~/ros2_ws/src/ros_xarm/src</span></strong></pre><p class="list-inset"><span class="koboSpan" id="kobo.335.1">This is where we will put our code. </span><span class="koboSpan" id="kobo.335.2">Let’s call the interface to the robot arm </span><strong class="source-inline"><span class="koboSpan" id="kobo.336.1">xarm_mgr.py</span></strong><span class="koboSpan" id="kobo.337.1">, which is short for </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.338.1">xarm manager</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.339.1">.</span></span></p></li> <li><span class="koboSpan" id="kobo.340.1">Open the editor and let’s start coding. </span><span class="koboSpan" id="kobo.340.2">First, we need </span><span class="No-Break"><span class="koboSpan" id="kobo.341.1">some imports:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.342.1">
import rclpy
import xarm
import time
from rlcpy.node import Node
from std_msgs.msg import String, Int32MultiArray, Int32</span></pre><p class="list-inset"><strong class="source-inline"><span class="koboSpan" id="kobo.343.1">rclpy</span></strong><span class="koboSpan" id="kobo.344.1"> is the ROS 2 Python interface. </span><strong class="source-inline"><span class="koboSpan" id="kobo.345.1">xarm</span></strong><span class="koboSpan" id="kobo.346.1"> is the interface to the robot arm, while </span><strong class="source-inline"><span class="koboSpan" id="kobo.347.1">time</span></strong><span class="koboSpan" id="kobo.348.1"> of course is a time module that we will use to set timers. </span><span class="koboSpan" id="kobo.348.2">Finally, we use some standard ROS message formats with which </span><span class="No-Break"><span class="koboSpan" id="kobo.349.1">to communicate.</span></span></p></li> <li><span class="koboSpan" id="kobo.350.1">Next, we are </span><a id="_idIndexMarker390"/><span class="koboSpan" id="kobo.351.1">going to create some predefined named positions of the arm as shortcuts. </span><span class="koboSpan" id="kobo.351.2">This is a simple way to put the arm where we need it. </span><span class="koboSpan" id="kobo.351.3">I’ve defined five arm preset positions we </span><span class="No-Break"><span class="koboSpan" id="kobo.352.1">can call:</span></span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer067">
<span class="koboSpan" id="kobo.353.1"><img alt="Figure 5.4 – Robot arm positions" src="image/B19846_05_4.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.354.1">Figure 5.4 – Robot arm positions</span></p>
<p class="list-inset"><span class="koboSpan" id="kobo.355.1">Let’s describe these positions in </span><span class="No-Break"><span class="koboSpan" id="kobo.356.1">some detail:</span></span></p>
<ul>
<li><em class="italic"><span class="koboSpan" id="kobo.357.1">High Carry</span></em><span class="koboSpan" id="kobo.358.1"> is the position we want the arm to be at when we are carrying an object such as a toy. </span><span class="koboSpan" id="kobo.358.2">The arm is over the robot, and the hand is elevated. </span><span class="koboSpan" id="kobo.358.3">This helps to keep the toy from falling out of </span><span class="No-Break"><span class="koboSpan" id="kobo.359.1">the hand.</span></span></li>
<li><em class="italic"><span class="koboSpan" id="kobo.360.1">Neutral Carry</span></em><span class="koboSpan" id="kobo.361.1"> is the standard position when the robot is driving so that the arm is not in front of </span><span class="No-Break"><span class="koboSpan" id="kobo.362.1">the camera.</span></span></li>
<li><em class="italic"><span class="koboSpan" id="kobo.363.1">Pick Up</span></em><span class="koboSpan" id="kobo.364.1"> is a combination of </span><em class="italic"><span class="koboSpan" id="kobo.365.1">Grasp</span></em><span class="koboSpan" id="kobo.366.1"> and </span><em class="italic"><span class="koboSpan" id="kobo.367.1">Grasp Close</span></em><span class="koboSpan" id="kobo.368.1"> (which are not shown individually in the figure). </span><span class="koboSpan" id="kobo.368.2">The former is an arm position that puts the hand on the ground </span><a id="_idIndexMarker391"/><span class="koboSpan" id="kobo.369.1">so we can pick up an object. </span><span class="koboSpan" id="kobo.369.2">The arm is as far out in front of the robot as it will go and touches the ground. </span><span class="koboSpan" id="kobo.369.3">The latter just closes the end effector to grab </span><span class="No-Break"><span class="koboSpan" id="kobo.370.1">a toy.</span></span></li>
<li><em class="italic"><span class="koboSpan" id="kobo.371.1">Drop Off</span></em><span class="koboSpan" id="kobo.372.1"> is the arm position high above the robot to put a toy in the toy box, which is </span><span class="No-Break"><span class="koboSpan" id="kobo.373.1">quite tall.</span></span></li>
<li><em class="italic"><span class="koboSpan" id="kobo.374.1">Align</span></em><span class="koboSpan" id="kobo.375.1"> (not shown) is a utility mode to check the alignment of the arm. </span><span class="koboSpan" id="kobo.375.2">All the servos are set to their middle position and the arm should point at the ceiling in a straight line. </span><span class="koboSpan" id="kobo.375.3">If it does not, you need to adjust the arm using the utility that came </span><span class="No-Break"><span class="koboSpan" id="kobo.376.1">with it.</span></span></li>
</ul>
<p class="list-inset"><span class="koboSpan" id="kobo.377.1">Let’s see how we can set up the ROS interface. </span><span class="koboSpan" id="kobo.377.2">The numbers are the servo motor positions (angles) in units from </span><strong class="source-inline"><span class="koboSpan" id="kobo.378.1">0</span></strong><span class="koboSpan" id="kobo.379.1"> (fully counterclockwise) to </span><strong class="source-inline"><span class="koboSpan" id="kobo.380.1">1000</span></strong><span class="koboSpan" id="kobo.381.1"> (fully clockwise). </span><span class="koboSpan" id="kobo.381.2">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.382.1">9999</span></strong><span class="koboSpan" id="kobo.383.1"> code means to not change the servo in that position so we can create commands that don’t change the positions of parts of the arm, such as </span><span class="No-Break"><span class="koboSpan" id="kobo.384.1">the gripper:</span></span></p>
<pre class="source-code">
<strong class="bold"><span class="koboSpan" id="kobo.385.1">HighCarry=[9999,500,195,858,618,9999]</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.386.1">MidCarry=[9999, 500, 500, 807, 443, 9999]</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.387.1">Grasp = [100,500,151,553,117,9999]</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.388.1">GraspClose=[700,9999,9999,9999,9999,9999]</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.389.1">Align=[500,500,500,500,500,500]</span></strong></pre> <ol>
<li value="6"><span class="koboSpan" id="kobo.390.1">Now we can start defining our robot arm control class. </span><span class="koboSpan" id="kobo.390.2">We’ll start with the class definition and the </span><span class="No-Break"><span class="koboSpan" id="kobo.391.1">initialization function:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.392.1">
class xarmControl(Node):
    def __init__(self):
        super().__init__('xarm_manager') # node name
        self.publisher = self.create_publisher(Int32MultiArray, 'xarm_pos', 10)
        self.armAngPub = self.create_publisher(Int32MultiArray, 'xarm_angle', 10)</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.393.1">There is </span><a id="_idIndexMarker392"/><span class="koboSpan" id="kobo.394.1">quite a bit going on here to set up our ROS interface for the </span><span class="No-Break"><span class="koboSpan" id="kobo.395.1">robot arm:</span></span></p><ul><li><span class="koboSpan" id="kobo.396.1">First of all, we call up the object class structure (</span><strong class="source-inline"><span class="koboSpan" id="kobo.397.1">super</span></strong><span class="koboSpan" id="kobo.398.1">) to initialize our ROS 2 node with the </span><span class="No-Break"><span class="koboSpan" id="kobo.399.1">name </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.400.1">xarm_manager</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.401.1">.</span></span></li><li><span class="koboSpan" id="kobo.402.1">Then we create a publisher for the arm position information, helpfully called </span><strong class="source-inline"><span class="koboSpan" id="kobo.403.1">xarm_pos</span></strong><span class="koboSpan" id="kobo.404.1">. </span><span class="koboSpan" id="kobo.404.2">Here, POS stands for position. </span><span class="koboSpan" id="kobo.404.3">This publishes the arm position in servo units, which go from </span><strong class="source-inline"><span class="koboSpan" id="kobo.405.1">0</span></strong><span class="koboSpan" id="kobo.406.1"> (fully counterclockwise) to </span><strong class="source-inline"><span class="koboSpan" id="kobo.407.1">1000</span></strong><span class="koboSpan" id="kobo.408.1"> (fully clockwise). </span><span class="koboSpan" id="kobo.408.2">We also publish the arm angles in degrees, in case we need that information, as </span><strong class="source-inline"><span class="koboSpan" id="kobo.409.1">xarm_angle</span></strong><span class="koboSpan" id="kobo.410.1">. </span><span class="koboSpan" id="kobo.410.2">The center of the servo travel is 0 degrees (</span><strong class="source-inline"><span class="koboSpan" id="kobo.411.1">500</span></strong><span class="koboSpan" id="kobo.412.1"> in servo units). </span><span class="koboSpan" id="kobo.412.2">Counterclockwise positions are negative angles while clockwise positions are positive angles. </span><span class="koboSpan" id="kobo.412.3">I just used integer degrees (no decimal points) since we don’t need that level of precision for the arm. </span><span class="koboSpan" id="kobo.412.4">Our High Carry position in servo units is </span><strong class="source-inline"><span class="koboSpan" id="kobo.413.1">[666,501,195,867,617,500]</span></strong><span class="koboSpan" id="kobo.414.1">, and in servo angles is </span><strong class="source-inline"><span class="koboSpan" id="kobo.415.1">[41,0,-76,91,29,0]</span></strong><span class="koboSpan" id="kobo.416.1">. </span><span class="koboSpan" id="kobo.416.2">We publish our outputs and subscribe to </span><span class="No-Break"><span class="koboSpan" id="kobo.417.1">our inputs.</span></span></li></ul></li> <li><span class="koboSpan" id="kobo.418.1">Our inputs, or subscriptions, provide the outside interface to the arm. </span><span class="koboSpan" id="kobo.418.2">I thought through how the arm might be used, and came up with the interface I wanted to see. </span><span class="koboSpan" id="kobo.418.3">In our case, we have a very simple arm, and need only a few commands. </span><span class="koboSpan" id="kobo.418.4">First of all, we have a string command called </span><strong class="source-inline"><span class="koboSpan" id="kobo.419.1">RobotCmd</span></strong><span class="koboSpan" id="kobo.420.1">, which lets us create commands to control the mode or state of the robot. </span><span class="koboSpan" id="kobo.420.2">This will be used for a lot of commands for the robot, and not just for the arm. </span><span class="koboSpan" id="kobo.420.3">I’ve created several arm mode commands that we’ll cover in a few paragraphs. </span><span class="koboSpan" id="kobo.420.4">The usefulness of </span><strong class="source-inline"><span class="koboSpan" id="kobo.421.1">RobotCmd</span></strong><span class="koboSpan" id="kobo.422.1"> is we can send any string on this input and process it on the receiving end. </span><span class="koboSpan" id="kobo.422.2">It’s a very flexible and useful interface. </span><span class="koboSpan" id="kobo.422.3">Note that for each subscriber, we create a function call to a callback routine. </span><span class="koboSpan" id="kobo.422.4">When the data is published on the interface, the callback routine is called in our program (</span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.423.1">xarm_mgr.py</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.424.1">) automatically:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.425.1">
self.cmdSubscribe = self.create_subscription(String, 'RobotCmd', self.cmdCallback,10)</span></pre></li> <li><span class="koboSpan" id="kobo.426.1">The next </span><a id="_idIndexMarker393"/><span class="koboSpan" id="kobo.427.1">part of the interface allows us to move the base of the arm in yaw, and operate the hand and wrist independently. </span><span class="koboSpan" id="kobo.427.2">In this chapter, we are starting with training just the gripper, so it helps to have an independent interface to rotate, open, and close the gripper. </span><span class="koboSpan" id="kobo.427.3">Operating the hand does not change the coordinate position of the gripper, so this can be separated. </span><span class="koboSpan" id="kobo.427.4">Likewise, we move the hand in yaw – right and left – to line up with toys to be grasped. </span><span class="koboSpan" id="kobo.427.5">We are going to start with this function locked off, and we’ll add the yaw function later. </span><span class="koboSpan" id="kobo.427.6">This is controlled by the computer vision system that we designed in the previous chapter, so it needs a separate interface. </span><span class="koboSpan" id="kobo.427.7">We have the </span><strong class="source-inline"><span class="koboSpan" id="kobo.428.1">xarmWrist</span></strong><span class="koboSpan" id="kobo.429.1"> command to rotate the wrist, </span><strong class="source-inline"><span class="koboSpan" id="kobo.430.1">xarmEffector</span></strong><span class="koboSpan" id="kobo.431.1"> to open and close the gripper fingers, and </span><strong class="source-inline"><span class="koboSpan" id="kobo.432.1">xarmBase</span></strong><span class="koboSpan" id="kobo.433.1"> to move the base of the arm right </span><span class="No-Break"><span class="koboSpan" id="kobo.434.1">or left:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.435.1">
        self.wristSubscribe = self.create_subscription(Int32, 'xarmWrist', self.wristCallback,10)
        self.effSubscribe = self.create_subscription(Int32, 'xarmEffector', self.effCallback,10)
        self.baseSubscribe = self.create_subscription(Int32, 'xarmBase', self.baseCallback,10)</span></pre></li> <li><span class="koboSpan" id="kobo.436.1">The last command interface lets us move the arm to any position we specify. </span><span class="koboSpan" id="kobo.436.2">Normally, we command the arm to move using an array of numbers, like this: </span><strong class="source-inline"><span class="koboSpan" id="kobo.437.1">[100,500,151,553,117,500]</span></strong><span class="koboSpan" id="kobo.438.1">. </span><span class="koboSpan" id="kobo.438.2">I’ve added a </span><em class="italic"><span class="koboSpan" id="kobo.439.1">secret feature</span></em><span class="koboSpan" id="kobo.440.1"> to this command. </span><span class="koboSpan" id="kobo.440.2">Since we may want to move the arm without either changing the yaw angle (which comes from the vision system) or the hand position (which may or may not be holding a toy), we can send commands that move the arm but don’t </span><a id="_idIndexMarker394"/><span class="koboSpan" id="kobo.441.1">affect some of the servos, such as the hand. </span><span class="koboSpan" id="kobo.441.2">I used the value </span><strong class="source-inline"><span class="koboSpan" id="kobo.442.1">9999</span></strong><span class="koboSpan" id="kobo.443.1"> as the </span><em class="italic"><span class="koboSpan" id="kobo.444.1">don’t-move-this-servo</span></em><span class="koboSpan" id="kobo.445.1"> value. </span><span class="koboSpan" id="kobo.445.2">So if the arm position command reads </span><strong class="source-inline"><span class="koboSpan" id="kobo.446.1">[9999, 9999, 500, 807, 443, 9999]</span></strong><span class="koboSpan" id="kobo.447.1"> then the yaw position (</span><em class="italic"><span class="koboSpan" id="kobo.448.1">Motor 6</span></em><span class="koboSpan" id="kobo.449.1">) and the hand position (</span><em class="italic"><span class="koboSpan" id="kobo.450.1">Motors 0 </span></em><span class="koboSpan" id="kobo.451.1">and</span><em class="italic"><span class="koboSpan" id="kobo.452.1"> 1</span></em><span class="koboSpan" id="kobo.453.1">) </span><span class="No-Break"><span class="koboSpan" id="kobo.454.1">don’t change:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.455.1">
        self.baseSubscribe = self.create_subscription(
Int32MultiArray, 'newArmPos', self.moveArmCallback,10)</span></pre></li> <li><span class="koboSpan" id="kobo.456.1">Now that we have all of our publish and subscribe interfaces defined, we can open the USB interface to the robot arm and see whether it is responding. </span><span class="koboSpan" id="kobo.456.2">If not, we’ll throw an </span><span class="No-Break"><span class="koboSpan" id="kobo.457.1">error message:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.458.1">
        timer_period = 1.0 # seconds
        self.timer = self.create_timer(timer_period, self.timer_callback)
        self.i = 0 # counter
        try:
            self.arm = xarm.Controller('USB')
            print("ARM OPEN")
        except:
            self.get_logger().error("xarm_manager init NO ARM DETECTED")
            self.arm = None
            print("ERROR init: NO AR</span><a id="_idTextAnchor177"/><span class="koboSpan" id="kobo.459.1">M DETECTED")
        return</span></pre></li> </ol>
<p class="callout-heading"><span class="koboSpan" id="kobo.460.1">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.461.1">Here is the quick cheat guide to the servos in the </span><strong class="source-inline"><span class="koboSpan" id="kobo.462.1">xarmPos</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.463.1">command array:</span></span></p>
<p class="callout"><strong class="source-inline"><span class="koboSpan" id="kobo.464.1">[grip open/close, wrist rotate, wrist pitch, elbow pitch, shoulder pitch, </span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.465.1">shoulder yaw]</span></strong></span></p>
<ol>
<li value="11"><span class="koboSpan" id="kobo.466.1">Our next function in the source code is to set up a telemetry timer. </span><span class="koboSpan" id="kobo.466.2">We want to periodically publish the arm’s position for the rest of the robot to use. </span><span class="koboSpan" id="kobo.466.3">We’ll create a </span><a id="_idIndexMarker395"/><span class="koboSpan" id="kobo.467.1">timer callback that executes periodically at a rate we specify. </span><span class="koboSpan" id="kobo.467.2">Let’s start with once a second. </span><span class="koboSpan" id="kobo.467.3">This is an informational value and we are not using it for control – the servo controller takes care of that. </span><span class="koboSpan" id="kobo.467.4">This is the code </span><span class="No-Break"><span class="koboSpan" id="kobo.468.1">we need:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.469.1">
        timer_period = 1.0 # seconds
        self.timer = self.create_timer(timer_period, self.timer_callback)
        self.i = 0 # counter</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.470.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.471.1">timer_period</span></strong><span class="koboSpan" id="kobo.472.1"> is the interval between interrupts. </span><span class="koboSpan" id="kobo.472.2">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.473.1">self.timer</span></strong><span class="koboSpan" id="kobo.474.1"> class variable is a function pointer to the timer function, and we point it at another function, </span><strong class="source-inline"><span class="koboSpan" id="kobo.475.1">self.timer_callback</span></strong><span class="koboSpan" id="kobo.476.1">, which we’ll define in the next code block. </span><span class="koboSpan" id="kobo.476.2">Every second, the interrupt will go off and call the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.477.1">timer_callback</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.478.1"> routine.</span></span></p></li> <li><span class="koboSpan" id="kobo.479.1">Our next bit of code is part of the hardware interface. </span><span class="koboSpan" id="kobo.479.2">Since we are initializing the arm </span><a id="_idIndexMarker396"/><span class="koboSpan" id="kobo.480.1">controller, we need to open the hardware connection to the arm, which is a USB port using the </span><strong class="bold"><span class="koboSpan" id="kobo.481.1">human interface device</span></strong><span class="koboSpan" id="kobo.482.1"> (</span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.483.1">HID</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.484.1">) protocol:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.485.1">
        try:
            self.arm = xarm.Controller('USB')
            print("ARM OPEN")
        except:
            self.get_logger().error("xarm_manager init NO ARM DETECTED")
            self.arm = None
            print("ERROR init: NO ARM DETECTED")
        return</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.486.1">We first create a </span><strong class="source-inline"><span class="koboSpan" id="kobo.487.1">try</span></strong><span class="koboSpan" id="kobo.488.1"> block so we can handle any exceptions. </span><span class="koboSpan" id="kobo.488.2">The robot arm may not </span><a id="_idIndexMarker397"/><span class="koboSpan" id="kobo.489.1">be powered on, or it may not be connected, so we have to be prepared to handle this. </span><span class="koboSpan" id="kobo.489.2">We create an arm object (</span><strong class="source-inline"><span class="koboSpan" id="kobo.490.1">self.arm</span></strong><span class="koboSpan" id="kobo.491.1">) that will be our interface to the hardware. </span><span class="koboSpan" id="kobo.491.2">If the arm opens successfully, then we return. </span><span class="koboSpan" id="kobo.491.3">If not, we run through the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.492.1">except</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.493.1"> routine:</span></span></p><ul><li><span class="koboSpan" id="kobo.494.1">First, we log that we did not find the arm in the ROS error log. </span><span class="koboSpan" id="kobo.494.2">The ROS logging function is very versatile and provides a handy place to store information that you need </span><span class="No-Break"><span class="koboSpan" id="kobo.495.1">for debugging.</span></span></li><li><span class="koboSpan" id="kobo.496.1">Then we set the arm to a null object (</span><strong class="source-inline"><span class="koboSpan" id="kobo.497.1">None</span></strong><span class="koboSpan" id="kobo.498.1">) so that we don’t throw unnecessary errors later in the program, and we can test to see whether the arm </span><span class="No-Break"><span class="koboSpan" id="kobo.499.1">is connected.</span></span></li></ul></li> <li><span class="koboSpan" id="kobo.500.1">The next block of code is our timer callback that publishes telemetry about the arm. </span><span class="koboSpan" id="kobo.500.2">Remember that we defined two output messages, the arm position and arm angle. </span><span class="koboSpan" id="kobo.500.3">We can service them </span><span class="No-Break"><span class="koboSpan" id="kobo.501.1">both here:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.502.1">
    def timer_callback(self):
        msg = Int32MultiArray()
        # call arm and get positions
        armPos=[]
        for i in range(1,7):
            armPos.append(self.arm.getPosition(i))
        msg.data = armPos
        self.publisher.publish(msg)
        # get arm positions in degrees
        armPos=[]
        for i in range(1,7):
            armPos.append(int(self.arm.getPosition(i, True)))
        msg.data = armPos
        #print(armPos)
        self.armAngPub.publish(msg)</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.503.1">We are </span><a id="_idIndexMarker398"/><span class="koboSpan" id="kobo.504.1">using the </span><strong class="source-inline"><span class="koboSpan" id="kobo.505.1">Int32MultiArray</span></strong><span class="koboSpan" id="kobo.506.1"> datatype so that we can publish the arm position data as an array of integers. </span><span class="koboSpan" id="kobo.506.2">We collect the data from the arm by calling </span><strong class="source-inline"><span class="koboSpan" id="kobo.507.1">self.arm.getPosition(servoNumber)</span></strong><span class="koboSpan" id="kobo.508.1">. </span><span class="koboSpan" id="kobo.508.2">We append the output to our array, and when we are done, call the ROS publish routine </span><strong class="source-inline"><span class="koboSpan" id="kobo.509.1">(self.&lt;topic name&gt;.publish(msg))</span></strong><span class="koboSpan" id="kobo.510.1">. </span><span class="koboSpan" id="kobo.510.2">We do the same thing for the arm angle, which we can get by calling </span><strong class="source-inline"><span class="koboSpan" id="kobo.511.1">arm.getPosition(servoNumber, True)</span></strong><span class="koboSpan" id="kobo.512.1"> to return an angle instead of </span><span class="No-Break"><span class="koboSpan" id="kobo.513.1">servo units.</span></span></p></li> <li><span class="koboSpan" id="kobo.514.1">Now we can handle receiving commands from other programs. </span><span class="koboSpan" id="kobo.514.2">Next, we are going to be creating a control panel for the robot that can send commands and set modes for </span><span class="No-Break"><span class="koboSpan" id="kobo.515.1">the robot:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.516.1">
    def cmdCallback(self, msg):
        self.get_logger().info("xarm rec cmd %s" % msg.data)
        robotCmd = msg.data
        if robotCmd=="ARM HIGH_CARRY":
            self.setArm(HighCarry)
        if robotCmd=="ARM MID_CARRY":
            self.setArm(MidCarry)
        if robotCmd=="ARM GRASP_POS":
            self.setArm(Grasp)
        if robotCmd=="ARM GRASP_CLOSE":
            self.setArm(GraspClose)
        if robotCmd=="ARM ALIGN":
            self.setArm(Align)</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.517.1">This section </span><a id="_idIndexMarker399"/><span class="koboSpan" id="kobo.518.1">is pretty straightforward. </span><span class="koboSpan" id="kobo.518.2">We receive a string message containing a command, and we parse the message to see whether it is something this program recognizes. </span><span class="koboSpan" id="kobo.518.3">If so, we process the message and perform the appropriate command. </span><span class="koboSpan" id="kobo.518.4">If we get </span><strong class="source-inline"><span class="koboSpan" id="kobo.519.1">ARM MID_CARRY</span></strong><span class="koboSpan" id="kobo.520.1">, which is a command to position the arm to the middle position, then we send a </span><strong class="source-inline"><span class="koboSpan" id="kobo.521.1">setArm</span></strong><span class="koboSpan" id="kobo.522.1"> command using the </span><strong class="source-inline"><span class="koboSpan" id="kobo.523.1">MidCarry</span></strong><span class="koboSpan" id="kobo.524.1"> global variable, which has the servo positions for all </span><span class="No-Break"><span class="koboSpan" id="kobo.525.1">six motors.</span></span></p></li> <li><span class="koboSpan" id="kobo.526.1">Next, we write the code for the robot to receive and execute the wrist servo command, which rotates the gripper. </span><span class="koboSpan" id="kobo.526.2">This command goes to </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.527.1">Motor 2</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.528.1">:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.529.1">
    def wristCallback(self, msg):
        try:
            newArmPos = int(msg.data)
        except ValueError:
            self.get_logger().info("Invalid xarm wrist cmd %s" % msg.data)
            print("invalid wrist cmd ", msg.data)
            return
        # set limits
        newArmPos = float(min(90.0,newArmPos))
        newArmPos = float(max(-90.0,newArmPos))
        self.arm.setPosition(2,newArmPos, True)</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.530.1">This function call is executed when the </span><strong class="source-inline"><span class="koboSpan" id="kobo.531.1">xarmWrist</span></strong><span class="koboSpan" id="kobo.532.1"> topic is published. </span><span class="koboSpan" id="kobo.532.2">This command just moves the wrist rotation, which we would use to align the fingers of the hand to the object we are picking up. </span><span class="koboSpan" id="kobo.532.3">I added some exception handling for invalid values, along with limit checking on the range of the input, which I consider a </span><a id="_idIndexMarker400"/><span class="koboSpan" id="kobo.533.1">standard practice for external inputs. </span><span class="koboSpan" id="kobo.533.2">We don’t want the arm to do something weird with an invalid input, such as if someone was able to send a string on the </span><strong class="source-inline"><span class="koboSpan" id="kobo.534.1">xarmWrist</span></strong><span class="koboSpan" id="kobo.535.1"> topic instead of an integer. </span><span class="koboSpan" id="kobo.535.2">We also check whether the range of the data in the command is valid, which in this case is from </span><strong class="source-inline"><span class="koboSpan" id="kobo.536.1">0</span></strong><span class="koboSpan" id="kobo.537.1"> to </span><strong class="source-inline"><span class="koboSpan" id="kobo.538.1">1000</span></strong><span class="koboSpan" id="kobo.539.1"> servo units. </span><span class="koboSpan" id="kobo.539.2">If we get an out-of-bounds error, we clamp the command to the allowed range using the </span><strong class="source-inline"><span class="koboSpan" id="kobo.540.1">min</span></strong><span class="koboSpan" id="kobo.541.1"> and </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.542.1">max</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.543.1"> functions.</span></span></p></li> <li><span class="koboSpan" id="kobo.544.1">The end effector command and base command (which controls the left-right rotation of the entire arm) work exactly the </span><span class="No-Break"><span class="koboSpan" id="kobo.545.1">same way:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.546.1">
    def effCallback(self, msg):
    # set just the end effector position
        try:
            newArmPos = int(msg.data)
        except ValueError:
            self.get_logger().info("Invalid xarm effector cmd %s" % msg.data)
            return
        # set limits
        newArmPos = min(1000,newArmPos)
        newArmPos = max(0,newArmPos)
        self.arm.setPosition(1,newArmPos)
    def baseCallback(self, msg):
    # set just the base azimuth position
        try:
            newArmPos = int(msg.data)
        except ValueError:
            self.get_logger().info("Invalid xarm base cmd %s" % msg.data)
            return
        # set limits
        newArmPos = min(1000,newArmPos)
        newArmPos = max(0,newArmPos)
        self.arm.setPosition(6,newArmPos)</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.547.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.548.1">setArm</span></strong><span class="koboSpan" id="kobo.549.1"> command lets us send one comment to set the position of every servo motor at once, with one command. </span><span class="koboSpan" id="kobo.549.2">We send an array of six integers, and this program </span><a id="_idIndexMarker401"/><span class="koboSpan" id="kobo.550.1">relays that to the servo </span><span class="No-Break"><span class="koboSpan" id="kobo.551.1">motor controller.</span></span></p><p class="list-inset"><span class="koboSpan" id="kobo.552.1">As mentioned before, I put in a special value, </span><strong class="source-inline"><span class="koboSpan" id="kobo.553.1">9999</span></strong><span class="koboSpan" id="kobo.554.1">, that tells this bit of code to not move that motor. </span><span class="koboSpan" id="kobo.554.2">This lets us send commands to the arm that move some of the servos, or just one of them. </span><span class="koboSpan" id="kobo.554.3">This lets us move the up/down axis and left/right axis of the end of the arm independently, which </span><span class="No-Break"><span class="koboSpan" id="kobo.555.1">is important.</span></span></p><p class="list-inset"><span class="koboSpan" id="kobo.556.1">Another thing that is important is that while this bit of Python code executes almost instantly, the servo motors take a finite amount of time to move. </span><span class="koboSpan" id="kobo.556.2">We have to throw in some delays between the servo commands so that the servo controller can process them and send them to the right motor. </span><span class="koboSpan" id="kobo.556.3">I’ve discovered that the value </span><strong class="source-inline"><span class="koboSpan" id="kobo.557.1">0.1</span></strong><span class="koboSpan" id="kobo.558.1"> (1/10 of a second) between commands works. </span><span class="koboSpan" id="kobo.558.2">If you leave this value out, only one servo will move, and the arm will not process the rest of the commands. </span><span class="koboSpan" id="kobo.558.3">The servos use a serial interface in a daisy chain fashion, which means they relay messages to each other. </span><span class="koboSpan" id="kobo.558.4">Each servo is plugged into one other servo, which is a big improvement over all the servos being plugged </span><span class="No-Break"><span class="koboSpan" id="kobo.559.1">in individually.</span></span></p></li> <li><span class="koboSpan" id="kobo.560.1">We can finish </span><a id="_idIndexMarker402"/><span class="koboSpan" id="kobo.561.1">up our arm control code with </span><strong class="source-inline"><span class="koboSpan" id="kobo.562.1">MAIN</span></strong><span class="koboSpan" id="kobo.563.1"> – the executable part of </span><span class="No-Break"><span class="koboSpan" id="kobo.564.1">the program:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.565.1">
#######################MAIN####################################
rclpy.init()
print("Arm Control Active")
xarmCtr = xarmControl()
# spin ROS 2
rclpy.spin(xarmCtr)
# destroy node explicitly
xarmCtr.destroy_node()
rclpy.shutdown()</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.566.1">Here, we initialize </span><strong class="source-inline"><span class="koboSpan" id="kobo.567.1">rclpy</span></strong><span class="koboSpan" id="kobo.568.1"> (ROS 2 Python interface) to connect our program to the ROS infrastructure. </span><span class="koboSpan" id="kobo.568.2">Then we create an instance of our </span><strong class="source-inline"><span class="koboSpan" id="kobo.569.1">xarm</span></strong><span class="koboSpan" id="kobo.570.1"> control class we created. </span><span class="koboSpan" id="kobo.570.2">We’ll call it </span><strong class="source-inline"><span class="koboSpan" id="kobo.571.1">xarmCtr</span></strong><span class="koboSpan" id="kobo.572.1">. </span><span class="koboSpan" id="kobo.572.2">Then we just have to tell ROS 2 to execute. </span><span class="koboSpan" id="kobo.572.3">We don’t even need a loop. </span><span class="koboSpan" id="kobo.572.4">The program will perform publish and subscribe calls, and our timer sends out telemetry, which is all included in our </span><strong class="source-inline"><span class="koboSpan" id="kobo.573.1">xarmControl</span></strong><span class="koboSpan" id="kobo.574.1"> object. </span><span class="koboSpan" id="kobo.574.2">When we fall out of spin, we are done with the program, so we shut down the ROS node, and then </span><span class="No-Break"><span class="koboSpan" id="kobo.575.1">the program.</span></span></p></li> </ol>
<p><span class="koboSpan" id="kobo.576.1">Now we are ready to start training our robot arm! </span><span class="koboSpan" id="kobo.576.2">To do this, we are going to use three different methods to train our arm to pick up objects. </span><span class="koboSpan" id="kobo.576.3">In the first stage, we will just train the robot hand – the end effector – to grasp objects. </span><span class="koboSpan" id="kobo.576.4">We will use Q-learning, a type of RL, to accomplish this. </span><span class="koboSpan" id="kobo.576.5">We will have the robot try to pick up items, and we will reward, or give points, if the robot is successful and subtract points if it fails. </span><span class="koboSpan" id="kobo.576.6">The software will try to maximize </span><a id="_idIndexMarker403"/><span class="koboSpan" id="kobo.577.1">the reward to get the most points, just like playing a game. </span><span class="koboSpan" id="kobo.577.2">We will generate different policies, or action plans, to make </span><span class="No-Break"><span class="koboSpan" id="kobo.578.1">this happen.</span></span></p>
<h1 id="_idParaDest-87"><a id="_idTextAnchor178"/><span class="koboSpan" id="kobo.579.1">Introducing Q-learning for grasping objects</span></h1>
<p><span class="koboSpan" id="kobo.580.1">Training a robot </span><a id="_idIndexMarker404"/><span class="koboSpan" id="kobo.581.1">arm end effector to pick up an oddly shaped </span><a id="_idIndexMarker405"/><span class="koboSpan" id="kobo.582.1">object using the </span><strong class="bold"><span class="koboSpan" id="kobo.583.1">Q-learning</span></strong><span class="koboSpan" id="kobo.584.1"> RL technique involves several steps. </span><span class="koboSpan" id="kobo.584.2">Here’s a step-by-step explanation of </span><span class="No-Break"><span class="koboSpan" id="kobo.585.1">the process:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.586.1">Define the state space and </span><span class="No-Break"><span class="koboSpan" id="kobo.587.1">action space:</span></span><ul><li><strong class="bold"><span class="koboSpan" id="kobo.588.1">Define the state space</span></strong><span class="koboSpan" id="kobo.589.1">: This includes all the relevant information about the environment and the robot arm, such as the position and orientation of the object, the position and orientation of the end effector, and any other relevant </span><span class="No-Break"><span class="koboSpan" id="kobo.590.1">sensor data</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.591.1">Define the action space</span></strong><span class="koboSpan" id="kobo.592.1">: These are the possible actions the robot arm can take, such as rotating the end effector, moving it in different directions, or adjusting </span><span class="No-Break"><span class="koboSpan" id="kobo.593.1">its gripper</span></span></li></ul></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.594.1">Set up the Q-table</span></strong><span class="koboSpan" id="kobo.595.1">: Create a Q-table that represents the state-action pairs and initialize it with random values. </span><span class="koboSpan" id="kobo.595.2">The Q-table will have a row for each state and a column for each action. </span><span class="koboSpan" id="kobo.595.3">As we test each position that the arm moves to, we will store the reward that was computed by the Q-learning equation (introduced in the </span><em class="italic"><span class="koboSpan" id="kobo.596.1">Machine learning for robot arms</span></em><span class="koboSpan" id="kobo.597.1"> section) in this table so that we can refer to it later. </span><span class="koboSpan" id="kobo.597.2">We will search the Q-table by state and action to see which state-action pair results in the </span><span class="No-Break"><span class="koboSpan" id="kobo.598.1">largest reward.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.599.1">Define the reward function</span></strong><span class="koboSpan" id="kobo.600.1">: Define a reward function that provides feedback to the robot arm based on its actions. </span><span class="koboSpan" id="kobo.600.2">The reward function should encourage the arm to pick up the object successfully and discourage </span><span class="No-Break"><span class="koboSpan" id="kobo.601.1">undesirable behavior.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.602.1">Start the training loop</span></strong><span class="koboSpan" id="kobo.603.1">: Start the training loop, which consists of multiple episodes. </span><span class="koboSpan" id="kobo.603.2">Each episode represents one iteration of the </span><span class="No-Break"><span class="koboSpan" id="kobo.604.1">training process:</span></span><ul><li><span class="koboSpan" id="kobo.605.1">Reset the environment and set the </span><span class="No-Break"><span class="koboSpan" id="kobo.606.1">initial state</span></span></li><li><span class="koboSpan" id="kobo.607.1">Select an action based on the current state using an exploration-exploitation strategy such as epsilon-greedy, where you explore random actions with a certain probability (epsilon) or choose the action with the </span><span class="No-Break"><span class="koboSpan" id="kobo.608.1">highest Q-value</span></span></li><li><span class="koboSpan" id="kobo.609.1">Execute the selected action and observe the new state and </span><span class="No-Break"><span class="koboSpan" id="kobo.610.1">the reward</span></span></li><li><span class="koboSpan" id="kobo.611.1">Update the Q-value in the Q-table using the Q-learning update equation, which incorporates the reward, the maximum Q-value for the next state, and the learning rate (alpha) and discount factor (</span><span class="No-Break"><span class="koboSpan" id="kobo.612.1">gamma) parameters</span></span></li><li><span class="koboSpan" id="kobo.613.1">Update the current state to the </span><span class="No-Break"><span class="koboSpan" id="kobo.614.1">new state</span></span></li><li><span class="koboSpan" id="kobo.615.1">Repeat the previous steps until the episode terminates, either by successfully picking up the object or reaching a maximum number </span><span class="No-Break"><span class="koboSpan" id="kobo.616.1">of steps</span></span></li></ul></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.617.1">Exploration and exploitation</span></strong><span class="koboSpan" id="kobo.618.1">: Adjust the exploration rate (represented by epsilon) over time to gradually reduce exploration and favor exploitation of the learned </span><a id="_idIndexMarker406"/><span class="koboSpan" id="kobo.619.1">knowledge. </span><span class="koboSpan" id="kobo.619.2">This allows the robot arm to initially explore different actions and gradually focus on exploiting the learned information to </span><span class="No-Break"><span class="koboSpan" id="kobo.620.1">improve performance.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.621.1">Repeat training</span></strong><span class="koboSpan" id="kobo.622.1">: Continue the training loop for multiple episodes until the Q-values converge or the performance reaches a </span><span class="No-Break"><span class="koboSpan" id="kobo.623.1">satisfactory level.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.624.1">Perform testing</span></strong><span class="koboSpan" id="kobo.625.1">: After training, use the learned Q-values to make decisions on the actions to take in a testing environment. </span><span class="koboSpan" id="kobo.625.2">Apply the trained policy to the robot arm end effector, allowing it to pick up the oddly shaped object based on the </span><span class="No-Break"><span class="koboSpan" id="kobo.626.1">learned knowledge.</span></span></li>
</ol>
<p class="callout-heading"><span class="koboSpan" id="kobo.627.1">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.628.1">Implementing Q-learning for training a robot arm end effector requires a combination of software and hardware components, such as simulation environments, robotic arm controllers, and sensory input interfaces. </span><span class="koboSpan" id="kobo.628.2">The specifics of the implementation can vary depending on the robot arm platform and the tools and libraries </span><span class="No-Break"><span class="koboSpan" id="kobo.629.1">being used.</span></span></p>
<h2 id="_idParaDest-88"><a id="_idTextAnchor179"/><span class="koboSpan" id="kobo.630.1">Writing the code</span></h2>
<p><span class="koboSpan" id="kobo.631.1">Now we’ll </span><a id="_idIndexMarker407"/><span class="koboSpan" id="kobo.632.1">implement the seven-step process we just described by building the code that will train the arm, using the robot arm interface we made in the </span><span class="No-Break"><span class="koboSpan" id="kobo.633.1">previous section:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.634.1">First, we include our imports – the functions we’ll need to implement our </span><span class="No-Break"><span class="koboSpan" id="kobo.635.1">training code:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.636.1">
import rclpy
import time
import random
from rclpy.node import Node
from std_msgs.msg import String, Int32MultiArray, Int32
from sensor_msgs.msg import Image
from vision_msgs.msg import Detection2D
from vision_msgs.msg import ObjectHypothesisWithPose
from vision_msgs.msg import Detection2DArray
import math
import pickle</span></pre><p class="list-inset"><strong class="source-inline"><span class="koboSpan" id="kobo.637.1">rclpy</span></strong><span class="koboSpan" id="kobo.638.1"> is the ROS 2 Python interface. </span><span class="koboSpan" id="kobo.638.2">We use </span><strong class="source-inline"><span class="koboSpan" id="kobo.639.1">Detection2D</span></strong><span class="koboSpan" id="kobo.640.1"> to talk to the vision system from the previous chapter (YOLOV8). </span><span class="koboSpan" id="kobo.640.2">I’ll explain the </span><strong class="source-inline"><span class="koboSpan" id="kobo.641.1">pickle</span></strong><span class="koboSpan" id="kobo.642.1"> reference when we get </span><span class="No-Break"><span class="koboSpan" id="kobo.643.1">to it.</span></span></p></li> <li><span class="koboSpan" id="kobo.644.1">Next, let’s define some functions we’ll be </span><span class="No-Break"><span class="koboSpan" id="kobo.645.1">using later:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.646.1">
global learningRate = 0.1 # learning rate
def round4(x):
 return (math.round(x*4)/4)
# function to restrict a variable to a range. </span><span class="koboSpan" id="kobo.646.2">if x &lt; minx, x=min x,etc.
</span><span class="koboSpan" id="kobo.646.3">def rangeMinMax(x,minx,maxx):
 xx = max(minx,x)
 xx = min(maxx,xx)
 return xx
def sortByQ(listByAspect):
 return(listByAspect[2])</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.647.1">The learning rate is used in reinforcement learning just like in other machine learning algorithms to adjust how </span><a id="_idIndexMarker408"/><span class="koboSpan" id="kobo.648.1">fast the system makes changes as a result of inputs. </span><span class="koboSpan" id="kobo.648.2">We’ll start with </span><strong class="source-inline"><span class="koboSpan" id="kobo.649.1">0.1</span></strong><span class="koboSpan" id="kobo.650.1">. </span><span class="koboSpan" id="kobo.650.2">If this value is too big, we will have big jumps in our training that can cause erratic outputs. </span><span class="koboSpan" id="kobo.650.3">If it’s too small, we’ll have to do a lot of repetitions. </span><strong class="source-inline"><span class="koboSpan" id="kobo.651.1">actionSpace</span></strong><span class="koboSpan" id="kobo.652.1"> is the list of possible hand actions that we are teaching. </span><span class="koboSpan" id="kobo.652.2">These values are the angle of the wrist in degrees. </span><span class="koboSpan" id="kobo.652.3">Note that </span><strong class="source-inline"><span class="koboSpan" id="kobo.653.1">-90</span></strong><span class="koboSpan" id="kobo.654.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.655.1">+90</span></strong><span class="koboSpan" id="kobo.656.1"> are the same as far as grasping </span><span class="No-Break"><span class="koboSpan" id="kobo.657.1">is concerned.</span></span></p><p class="list-inset"><span class="koboSpan" id="kobo.658.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.659.1">round4</span></strong><span class="koboSpan" id="kobo.660.1"> function is used to round off the aspect ratio of the bounding box. </span><span class="koboSpan" id="kobo.660.2">When we detect a toy, as you may remember, the object recognition system draws a box around it. </span><span class="koboSpan" id="kobo.660.3">We use that bounding box as a clue to how the toy is oriented relative to the robot. </span><span class="koboSpan" id="kobo.660.4">We want a limited number of aspect angles to train for, so we’ll round this off to the </span><span class="No-Break"><span class="koboSpan" id="kobo.661.1">nearest </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.662.1">0.25</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.663.1">.</span></span></p><p class="list-inset"><span class="koboSpan" id="kobo.664.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.665.1">SortbyQ</span></strong><span class="koboSpan" id="kobo.666.1"> function is a custom sort key that we’ll use to sort our training to put the highest reward – represented by the letter </span><strong class="source-inline"><span class="koboSpan" id="kobo.667.1">Q</span></strong><span class="koboSpan" id="kobo.668.1"> – </span><span class="No-Break"><span class="koboSpan" id="kobo.669.1">first.</span></span></p></li> <li><span class="koboSpan" id="kobo.670.1">In this step, we’ll declare the class that will teach the robot to grasp objects. </span><span class="koboSpan" id="kobo.670.2">We’ll call the class </span><strong class="source-inline"><span class="koboSpan" id="kobo.671.1">LearningHand</span></strong><span class="koboSpan" id="kobo.672.1">, and we’ll make it a node in </span><span class="No-Break"><span class="koboSpan" id="kobo.673.1">ROS 2:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.674.1">
class LearningHand(Node):
    def __init__(self):
        super().__init__('armQLearn') # node name
        # we need to both publish and subscribe to the RobotCmd topic
self.armPosSub = self.create_subscription(Int32MultiArray, "xarm_pos", self.armPosCallback, 10)
        self.cmdSubscribe = self.create_subscription(String, 'RobotCmd', self.cmdCallback,10)
        self.cmdPub = self.create_publisher(String, 'RobotCmd', 10)
 self.wristPub = self.create_publisher(Int32,'xarmWrist', 10)
 # declare parameter for number of repetitions
 self.declare_parameter('ArmLearningRepeats', rclpy.Parameter.Type.INTEGER)
 # get the current value from configuration
 self.repeats = self.get_parameter('ArmLearningRepeats').get_parameter_value().int_value</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.675.1">Here we </span><a id="_idIndexMarker409"/><span class="koboSpan" id="kobo.676.1">initialize the object by passing up the </span><strong class="source-inline"><span class="koboSpan" id="kobo.677.1">init</span></strong><span class="koboSpan" id="kobo.678.1"> function to the parent class (with </span><strong class="source-inline"><span class="koboSpan" id="kobo.679.1">super</span></strong><span class="koboSpan" id="kobo.680.1">). </span><span class="koboSpan" id="kobo.680.2">We give the node the name </span><strong class="source-inline"><span class="koboSpan" id="kobo.681.1">armQLearn</span></strong><span class="koboSpan" id="kobo.682.1">, which is how the rest of the robot will </span><span class="No-Break"><span class="koboSpan" id="kobo.683.1">find it.</span></span></p><p class="list-inset"><span class="koboSpan" id="kobo.684.1">Our ROS interface subscribes to several topics. </span><span class="koboSpan" id="kobo.684.2">We need to talk to the robot arm, so we subscribe to </span><strong class="source-inline"><span class="koboSpan" id="kobo.685.1">xarm_pos</span></strong><span class="koboSpan" id="kobo.686.1"> (arm position). </span><span class="koboSpan" id="kobo.686.2">We need to subscribe (like every program that talks to the robot) to </span><strong class="source-inline"><span class="koboSpan" id="kobo.687.1">RobotCmd</span></strong><span class="koboSpan" id="kobo.688.1">, which is our master mode command channel. </span><span class="koboSpan" id="kobo.688.2">We also need to be able to send commands on </span><strong class="source-inline"><span class="koboSpan" id="kobo.689.1">RobotCmd</span></strong><span class="koboSpan" id="kobo.690.1">, so we create a publisher on that topic. </span><span class="koboSpan" id="kobo.690.2">Finally, we use a ROS parameter to set the value of how many repetitions we want for each </span><span class="No-Break"><span class="koboSpan" id="kobo.691.1">learning task.</span></span></p></li> <li><span class="koboSpan" id="kobo.692.1">This next block of code completes the setup for the </span><span class="No-Break"><span class="koboSpan" id="kobo.693.1">learning function:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.694.1">
 self.mode = "idle"
 self.armInterface = ArmInterface()
 # define the state space
 self.stateActionPairs = []
 # state space is the target aspect and the hand angle
 # aspect is length / width length along x axis(front back) width on y axis)
 aspects = [0.25, 0.5, 0.75, 1, 1.25, 1.5, 1.75]
 handAngles = [90, -45, 0, 45] # note +90 and -90 are the same angle
 for jj in range(0,len(aspects)):
   for ii in range(0,4):
     self.stateActionPairs.append([aspects[jj], handAngles[ii],0.0])</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.695.1">We set the </span><a id="_idIndexMarker410"/><span class="koboSpan" id="kobo.696.1">learning system mode to </span><strong class="source-inline"><span class="koboSpan" id="kobo.697.1">idle</span></strong><span class="koboSpan" id="kobo.698.1">, which just means “wait for the user to start learning.” </span><span class="koboSpan" id="kobo.698.2">We create the arm interface by instantiating the </span><strong class="source-inline"><span class="koboSpan" id="kobo.699.1">ArmInterface</span></strong><span class="koboSpan" id="kobo.700.1"> class object we imported. </span><span class="koboSpan" id="kobo.700.2">Next, we need to set up our learning matrix, which stores the possible aspects (things we can see) and the possible actions (things we can do). </span><span class="koboSpan" id="kobo.700.3">The last element, which we set to 0 here, is the </span><strong class="source-inline"><span class="koboSpan" id="kobo.701.1">Q</span></strong><span class="koboSpan" id="kobo.702.1"> value, which is where we store our </span><span class="No-Break"><span class="koboSpan" id="kobo.703.1">training results.</span></span></p></li> <li><span class="koboSpan" id="kobo.704.1">The following set of functions helps us to command </span><span class="No-Break"><span class="koboSpan" id="kobo.705.1">the arm:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.706.1">
 def sndCmd(self,msgStr):
     msg = String()
     msg.data = msgStr
     self.cmpPub.publish(msg)
 def setHandAngle(self,ang):
     msg = Int32()
     msg.data = ang
     self.wristPub.publish(msg)
 def armPosCallback(self,msg):
     self.currentArmPos = msg.data
 def setActionPairs(self,pairs):
     self.stateActionPairs = pairs</span></pre><p class="list-inset"><strong class="source-inline"><span class="koboSpan" id="kobo.707.1">sndCmd</span></strong><span class="koboSpan" id="kobo.708.1"> (send command) publishes on the </span><strong class="source-inline"><span class="koboSpan" id="kobo.709.1">RobotCmd</span></strong><span class="koboSpan" id="kobo.710.1"> topic and sets arm modes. </span><strong class="source-inline"><span class="koboSpan" id="kobo.711.1">SetHandAngle</span></strong><span class="koboSpan" id="kobo.712.1">, as you expect, sets the angle of the wrist servo. </span><strong class="source-inline"><span class="koboSpan" id="kobo.713.1">armPosCallback</span></strong><span class="koboSpan" id="kobo.714.1"> receives the arm’s current position, which is published by the arm </span><a id="_idIndexMarker411"/><span class="koboSpan" id="kobo.715.1">control program. </span><strong class="source-inline"><span class="koboSpan" id="kobo.716.1">setActionPairs</span></strong><span class="koboSpan" id="kobo.717.1"> allows us to create new action pairs </span><span class="No-Break"><span class="koboSpan" id="kobo.718.1">to learn.</span></span></p></li> <li><span class="koboSpan" id="kobo.719.1">Now we are ready to do the arm training. </span><span class="koboSpan" id="kobo.719.2">This is a combined human and robot activity, and is really a lot of fun to do. </span><span class="koboSpan" id="kobo.719.3">We’ll try the same aspect </span><span class="No-Break"><span class="koboSpan" id="kobo.720.1">20 times:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.721.1">
 def training(self, aspect):
   # get the aspect from the vision system
   #aspect = 1.0 # start here
   stateActionPairs.sort(key=sortByQ) # sort by Q value
   if len(stateActionPairs)&lt;1:
     #error - no aspects found!
</span><span class="koboSpan" id="kobo.721.2">     #
     self.get_logger().error("qLearningHand No Aspect for
     Training")
     return
   else:
     mySetup = stateActionPairs[0] # using the highest q value
     handAngle = mySetup[1]
     myOldQ = mySetup[2]</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.722.1">This initiates </span><a id="_idIndexMarker412"/><span class="koboSpan" id="kobo.723.1">the training program on the robot arm. </span><span class="koboSpan" id="kobo.723.2">We start by training based on aspect. </span><span class="koboSpan" id="kobo.723.3">We first look at our </span><strong class="source-inline"><span class="koboSpan" id="kobo.724.1">stateActionPairs</span></strong><span class="koboSpan" id="kobo.725.1"> to sort on the highest </span><strong class="source-inline"><span class="koboSpan" id="kobo.726.1">Q</span></strong><span class="koboSpan" id="kobo.727.1"> value for this aspect. </span><span class="koboSpan" id="kobo.727.2">We use our custom </span><strong class="source-inline"><span class="koboSpan" id="kobo.728.1">SortbyQ</span></strong><span class="koboSpan" id="kobo.729.1"> function to sort the list of </span><strong class="source-inline"><span class="koboSpan" id="kobo.730.1">stateActionPairs</span></strong><span class="koboSpan" id="kobo.731.1">. </span><span class="koboSpan" id="kobo.731.2">We set the hand angle to the angle with the highest </span><strong class="source-inline"><span class="koboSpan" id="kobo.732.1">Q</span></strong><span class="koboSpan" id="kobo.733.1">, or </span><span class="No-Break"><span class="koboSpan" id="kobo.734.1">expected reward.</span></span></p></li> <li><span class="koboSpan" id="kobo.735.1">This part of the program is the physical motion the robot arm will </span><span class="No-Break"><span class="koboSpan" id="kobo.736.1">go through:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.737.1">
     sndCmd("ARM MID_CARRY")
     timer.pause(1.0)
     sndCmd("ARM GRASP")
     time.sleep(1.0)
     setHandAngle(handAngle)
     time.sleep(0.3)
     # close the gripper
     sndCmd("ARM GRASP_CLOSE")
     time.sleep(0.5)
     # now raise the arm
     sndCmd("ARM MID_CARRY")
     time.sleep(1.0)</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.738.1">We start by telling the arm to move to the </span><em class="italic"><span class="koboSpan" id="kobo.739.1">Mid Carry</span></em><span class="koboSpan" id="kobo.740.1"> position – halfway up. </span><span class="koboSpan" id="kobo.740.2">Then we wait 1 second for the arm to complete its motion, and then we move the arm to the grasp position. </span><span class="koboSpan" id="kobo.740.3">The next step moves the wrist to the angle that we got from the </span><strong class="source-inline"><span class="koboSpan" id="kobo.741.1">Q</span></strong><span class="koboSpan" id="kobo.742.1"> function. </span><span class="koboSpan" id="kobo.742.2">Then we close the gripper with the </span><strong class="source-inline"><span class="koboSpan" id="kobo.743.1">ARM GRASP_CLOSE</span></strong><span class="koboSpan" id="kobo.744.1"> command. </span><span class="koboSpan" id="kobo.744.2">Now we raise the arm to see whether the gripper can lift the toy, using the </span><strong class="source-inline"><span class="koboSpan" id="kobo.745.1">ARM MID_CARRY</span></strong><span class="koboSpan" id="kobo.746.1"> instruction. </span><span class="koboSpan" id="kobo.746.2">If we are successful, the robot arm will now be holding toy. </span><span class="koboSpan" id="kobo.746.3">If not, the gripper will </span><span class="No-Break"><span class="koboSpan" id="kobo.747.1">be empty.</span></span></p></li> <li><span class="koboSpan" id="kobo.748.1">Now we </span><a id="_idIndexMarker413"/><span class="koboSpan" id="kobo.749.1">can check to see whether the gripper has an object </span><span class="No-Break"><span class="koboSpan" id="kobo.750.1">in it:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.751.1">
     #check to see if grip is OK
     handPos = self.currentArmPos[0]
     gripSuccess = False
     if handPos &gt; 650: ## fail
           gripSuccess = -1 # reward value of not gripping
     else: # success!
</span><span class="koboSpan" id="kobo.751.2">           gripSuccess = +1 # reward value of gripping</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.752.1">If the grip of the robot hand is correct, the toy will prevent the gripper from closing. </span><span class="koboSpan" id="kobo.752.2">We check the hand position (which the arm sends twice a second) to see the position. </span><span class="koboSpan" id="kobo.752.3">For my particular arm, the position that corresponds to 650 servo units or greater is completely closed. </span><span class="koboSpan" id="kobo.752.4">Your arm may vary, so check to see what the arm reports for a fully closed and empty gripper. </span><span class="koboSpan" id="kobo.752.5">We set the </span><strong class="source-inline"><span class="koboSpan" id="kobo.753.1">gripSuccess</span></strong><span class="koboSpan" id="kobo.754.1"> variable </span><span class="No-Break"><span class="koboSpan" id="kobo.755.1">as appropriate.</span></span></p></li> <li><span class="koboSpan" id="kobo.756.1">Now we do the machine learning part. </span><span class="koboSpan" id="kobo.756.2">We use my special modified Bellman equation introduced in the </span><em class="italic"><span class="koboSpan" id="kobo.757.1">Machine learning for robot arms</span></em><span class="koboSpan" id="kobo.758.1"> section to adjust the Q value for this </span><span class="No-Break"><span class="koboSpan" id="kobo.759.1">state-action pair:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.760.1">
 # the Bellman Equation
 ### Q(s, a) = Q(s, a) + α * [R + γ * max(Q(s', a')) - Q(s, a)]
 newQ = myOldQ + (learningRate*(gripSuccess))
 mySetup[2]=newQ</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.761.1">Since we are not using a future reward value (we get the complete reward from this one action of closing the gripper and raising the arm), we don’t need the expected future reward, only a present reward. </span><span class="koboSpan" id="kobo.761.2">We multiply the </span><strong class="source-inline"><span class="koboSpan" id="kobo.762.1">gripSuccess</span></strong><span class="koboSpan" id="kobo.763.1"> value (</span><strong class="source-inline"><span class="koboSpan" id="kobo.764.1">+1</span></strong><span class="koboSpan" id="kobo.765.1"> or </span><strong class="source-inline"><span class="koboSpan" id="kobo.766.1">-1</span></strong><span class="koboSpan" id="kobo.767.1">) by the learning rate and add this to the old Q score to get a new Q score. </span><span class="koboSpan" id="kobo.767.2">Each success increments the reward while any failure leads to </span><span class="No-Break"><span class="koboSpan" id="kobo.768.1">a decrement.</span></span></p></li> <li><span class="koboSpan" id="kobo.769.1">To finish </span><a id="_idIndexMarker414"/><span class="koboSpan" id="kobo.770.1">our learning function, we insert the updated Q value back into the learning table that matches the aspect angle and the wrist angle </span><span class="No-Break"><span class="koboSpan" id="kobo.771.1">we tested:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.772.1">
 foundStateActionPair = False
 # re insert back into q learning array
 for i in range (0,len(stateActionPairs):
     thisStateAction = stateActionPairs[i]
     if thisStateAction[0] == mySetup[0] and 
thisStateAction[1] == mySetup[0]:
         foundStateActionPair=True
         stateActionPairs[2]=mySetup[2] # store the new q value in the table
     if not foundStateActionPair:
         # we don't have this in the table - let's add it
         stateActionPairs.append(mySetup)
 input("Reset and Press Enter") # wait for enter key to continue</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.773.1">If this state-action pair is not in the table (which it should be), then we add it. </span><span class="koboSpan" id="kobo.773.2">I put this in just to keep the program from erroring out if we give a strange arm angle. </span><span class="koboSpan" id="kobo.773.3">Finally, we pause the program and wait for the user to hit the </span><em class="italic"><span class="koboSpan" id="kobo.774.1">Enter</span></em><span class="koboSpan" id="kobo.775.1"> key in order </span><span class="No-Break"><span class="koboSpan" id="kobo.776.1">to continue.</span></span></p></li> <li><span class="koboSpan" id="kobo.777.1">Let’s now look at the rest of the program, which is pretty straightforward. </span><span class="koboSpan" id="kobo.777.2">We have to do some housekeeping, service some calls, and make our main </span><span class="No-Break"><span class="koboSpan" id="kobo.778.1">training loop:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.779.1">
 def cmdCallBack(self,msg):
   robotCmd = msg.data
   if robotCmd == "GoLearnHand":
     self.mode = "start"
   if robotCmd == "StopLearnHand":
     self.mode = "idle"</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.780.1">This </span><strong class="source-inline"><span class="koboSpan" id="kobo.781.1">cmdCallBack</span></strong><span class="koboSpan" id="kobo.782.1"> receives commands from the </span><strong class="source-inline"><span class="koboSpan" id="kobo.783.1">RobotCmd</span></strong><span class="koboSpan" id="kobo.784.1"> topic. </span><span class="koboSpan" id="kobo.784.2">The only two commands we service in this program are </span><strong class="source-inline"><span class="koboSpan" id="kobo.785.1">GoLearnHand</span></strong><span class="koboSpan" id="kobo.786.1">, which starts the learning process, and </span><strong class="source-inline"><span class="koboSpan" id="kobo.787.1">StopLearnHand</span></strong><span class="koboSpan" id="kobo.788.1">, which lets you </span><span class="No-Break"><span class="koboSpan" id="kobo.789.1">stop training.</span></span></p></li> <li><span class="koboSpan" id="kobo.790.1">This section </span><a id="_idIndexMarker415"/><span class="koboSpan" id="kobo.791.1">is our arm interface to the robot arm and sets up the publish/subscribe interface we need to command </span><span class="No-Break"><span class="koboSpan" id="kobo.792.1">the arm:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.793.1">
class ArmInterface():
 init(self):
   self.armPosSub = self.create_subscription(Int32MultiArray, 'xarm_pos',self.armPosCallback, 10)
   self.armAngSub = self.create_subscription(Int32MultiArray, 'xarm_angle',self.armAngCallback, 10)
   self.armPosPub = self.create_publisher(Int32MultiArray, 'xarm')
 def armPosCallback(self,msg):
   self.armPos = msg.data
 def armAngCallback(self, msg):
   self.armAngle = msg.data
   # decoder ring: [grip, wrist angle, wrist pitch, elbow pitch, 
  sholder pitch, sholder yaw]
 def setArmPos(self,armPosArray):
   msg = Int32MultiArray
   msg.data = armPosArray
   self.armPosPub.publish(msg)</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.794.1">We subscribe to </span><strong class="source-inline"><span class="koboSpan" id="kobo.795.1">xarm_pos</span></strong><span class="koboSpan" id="kobo.796.1"> (arm position in servo units) and </span><strong class="source-inline"><span class="koboSpan" id="kobo.797.1">xarm_angle</span></strong><span class="koboSpan" id="kobo.798.1"> (arm position in degrees). </span><span class="koboSpan" id="kobo.798.2">I added the ability to set the robot arm position on the </span><strong class="source-inline"><span class="koboSpan" id="kobo.799.1">xarm</span></strong><span class="koboSpan" id="kobo.800.1"> topic, but you may not </span><span class="No-Break"><span class="koboSpan" id="kobo.801.1">need that.</span></span></p><p class="list-inset"><span class="koboSpan" id="kobo.802.1">For each </span><a id="_idIndexMarker416"/><span class="koboSpan" id="kobo.803.1">subscription we need a callback function. </span><span class="koboSpan" id="kobo.803.2">We have </span><strong class="source-inline"><span class="koboSpan" id="kobo.804.1">armPosCallback</span></strong><span class="koboSpan" id="kobo.805.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.806.1">armAngleCallback,</span></strong><span class="koboSpan" id="kobo.807.1"> which will be called when the arm publishes its position, which I set to happen at 2 Hertz, or twice a second. </span><span class="koboSpan" id="kobo.807.2">You can increase this rate in the </span><strong class="source-inline"><span class="koboSpan" id="kobo.808.1">xarm_mgr</span></strong><span class="koboSpan" id="kobo.809.1"> program if you feel </span><span class="No-Break"><span class="koboSpan" id="kobo.810.1">it necessary.</span></span></p></li> <li><span class="koboSpan" id="kobo.811.1">Now we get to the main program. </span><span class="koboSpan" id="kobo.811.2">For a lot of ROS programs, this main section is pretty brief. </span><span class="koboSpan" id="kobo.811.3">We have an extra routine we need to put here. </span><span class="koboSpan" id="kobo.811.4">To save the training function after we do our training, I came up with this solution – to </span><em class="italic"><span class="koboSpan" id="kobo.812.1">pickle</span></em><span class="koboSpan" id="kobo.813.1"> the state-action pairs and put them into </span><span class="No-Break"><span class="koboSpan" id="kobo.814.1">a file:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.815.1">
### MAIN ####
# persistent training file to opeate the arm
ArmTrainingFileName = "armTrainingFile.txt"
armIf = ArmInterface()
armTrainer = LearningHand()
#open and read the file after the appending:
try:
 f = open(ArmTrainingFileName, "r")
 savedActionPairs = pickle.load(f)
 armTrainer.setActionPairs(savedActionPairs)
 f.close()
except:
 print("No Training file found")
 self.get_logger().error("qLearningHand No Training File Found armTrainingFile.txt")</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.816.1">When we run this program, we need to load this file and set our action-pairs table to these saved values. </span><span class="koboSpan" id="kobo.816.2">I set up a </span><strong class="source-inline"><span class="koboSpan" id="kobo.817.1">try</span></strong><span class="koboSpan" id="kobo.818.1">/</span><strong class="source-inline"><span class="koboSpan" id="kobo.819.1">except</span></strong><span class="koboSpan" id="kobo.820.1"> block to send an error message when this training file is not found. </span><span class="koboSpan" id="kobo.820.2">This will happen the first time you run the program, but we’ll create a new file in just a moment for </span><span class="No-Break"><span class="koboSpan" id="kobo.821.1">next time.</span></span></p><p class="list-inset"><span class="koboSpan" id="kobo.822.1">We also </span><a id="_idIndexMarker417"/><span class="koboSpan" id="kobo.823.1">instantiate our class variables for the arm trainer and the arm interface, which creates the main part of our </span><span class="No-Break"><span class="koboSpan" id="kobo.824.1">training program.</span></span></p></li> <li><span class="koboSpan" id="kobo.825.1">This is the meat of our training loop. </span><span class="koboSpan" id="kobo.825.2">We set the aspect and number of trial repetitions that we </span><span class="No-Break"><span class="koboSpan" id="kobo.826.1">train on:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.827.1">
aspectTest = [1.0, 0.5, 1.5,2]
trainingKnt = 20
for jj in aspectTest:
 for ii in range(0,trainingKnt):
   print("Starting Training on Aspect ", jj)
   armTrainer.training(jj)</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.828.1">Start with the toy parallel to the front of the robot. </span><span class="koboSpan" id="kobo.828.2">Do 20 trials of picking it up, and then move the toy 45 degrees to the right for the next part. </span><span class="koboSpan" id="kobo.828.3">Then perform 20 more trials. </span><span class="koboSpan" id="kobo.828.4">Then the toy is moved to be 90 degrees to the robot. </span><span class="koboSpan" id="kobo.828.5">Run 20 trials. </span><span class="koboSpan" id="kobo.828.6">Finally set the toy at -45 degrees (to the left) for the final set and run 20 times. </span><span class="koboSpan" id="kobo.828.7">Welcome to </span><span class="No-Break"><span class="koboSpan" id="kobo.829.1">machine learning!</span></span></p></li> <li><span class="koboSpan" id="kobo.830.1">You’ll probably guess that the last thing we do is save our training data, </span><span class="No-Break"><span class="koboSpan" id="kobo.831.1">like this:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.832.1">
f = open("ArmTrainingFileName", "w")
# open file in write mode
pickle.dump(armTrainer.stateActionPairs,f)
print("Arm Training File Written")
f.close()</span></pre></li> </ol>
<p><span class="koboSpan" id="kobo.833.1">This completes our training program. </span><span class="koboSpan" id="kobo.833.2">Repeat this training for as many types of toys as you have, and you should have a trained arm that consistently picks up toys at a variety of angles </span><a id="_idIndexMarker418"/><span class="koboSpan" id="kobo.834.1">to the robot. </span><span class="koboSpan" id="kobo.834.2">Start with a selection of toys you want the robot to pick up. </span><span class="koboSpan" id="kobo.834.3">Set the angle of the toy to the robot at 0 – let’s say this is with the longest part of the toy parallel to the front of the robot. </span><span class="koboSpan" id="kobo.834.4">Then we send </span><strong class="source-inline"><span class="koboSpan" id="kobo.835.1">GoLearnHand</span></strong><span class="koboSpan" id="kobo.836.1"> on </span><strong class="source-inline"><span class="koboSpan" id="kobo.837.1">RobotCmd</span></strong><span class="koboSpan" id="kobo.838.1"> to put the robot arm in </span><span class="No-Break"><span class="koboSpan" id="kobo.839.1">learning mode.</span></span></p>
<p><span class="koboSpan" id="kobo.840.1">We have tried out Q-learning in a couple of different configurations, with a limited amount of success in training our robot. </span><span class="koboSpan" id="kobo.840.2">The main problem with Q-learning is that we have a very large number of possible states, or positions, that the robot arm can be in. </span><span class="koboSpan" id="kobo.840.3">This means that gaining a lot of knowledge about any one position by repeated trials is very difficult. </span><span class="koboSpan" id="kobo.840.4">Next, we are going to introduce a different approach using GAs to generate our </span><span class="No-Break"><span class="koboSpan" id="kobo.841.1">movement actions.</span></span></p>
<h1 id="_idParaDest-89"><a id="_idTextAnchor180"/><span class="koboSpan" id="kobo.842.1">Introducing GAs</span></h1>
<p><span class="koboSpan" id="kobo.843.1">Moving the robot arm requires the coordination of three motors simultaneously to create a </span><a id="_idIndexMarker419"/><span class="koboSpan" id="kobo.844.1">smooth movement. </span><span class="koboSpan" id="kobo.844.2">We need a mechanism to create different combinations of motor movement for the robot to test. </span><span class="koboSpan" id="kobo.844.3">We could just use random numbers, but that would be inefficient and could take thousands of trials to get to the level of training </span><span class="No-Break"><span class="koboSpan" id="kobo.845.1">we want.</span></span></p>
<p><span class="koboSpan" id="kobo.846.1">What if we had a way of trying different combinations of motor movement, and then pitting them against one another to pick the best one? </span><span class="koboSpan" id="kobo.846.2">It would be a sort of Darwinian </span><em class="italic"><span class="koboSpan" id="kobo.847.1">survival of the fittest</span></em><span class="koboSpan" id="kobo.848.1"> for arm movement scripts – such as a GA process. </span><span class="koboSpan" id="kobo.848.2">Let’s explore how we can apply this concept to our </span><span class="No-Break"><span class="koboSpan" id="kobo.849.1">use case.</span></span></p>
<h2 id="_idParaDest-90"><a id="_idTextAnchor181"/><span class="koboSpan" id="kobo.850.1">Understanding how the GA process works</span></h2>
<p><span class="koboSpan" id="kobo.851.1">Here are </span><a id="_idIndexMarker420"/><span class="koboSpan" id="kobo.852.1">the steps involved in our </span><span class="No-Break"><span class="koboSpan" id="kobo.853.1">GA process:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.854.1">We do a trial run to go from position 1 (neutral carry) to position 2 (pickup). </span><span class="koboSpan" id="kobo.854.2">The robot moves the arm 100 times before getting the hand into the right position. </span><span class="koboSpan" id="kobo.854.3">Why 100? </span><span class="koboSpan" id="kobo.854.4">We need a large enough sample space to allow the algorithm to explore different solutions. </span><span class="koboSpan" id="kobo.854.5">With a value of 50, the solution did not converge satisfactorily, while a value of 200 yielded the same result </span><span class="No-Break"><span class="koboSpan" id="kobo.855.1">as 100.</span></span></li>
<li><span class="koboSpan" id="kobo.856.1">We score each movement based on the percentage of goal accomplishment, indicating how much this movement contributed to </span><span class="No-Break"><span class="koboSpan" id="kobo.857.1">the goal.</span></span></li>
<li><span class="koboSpan" id="kobo.858.1">We take the 10 best moves and put them in </span><span class="No-Break"><span class="koboSpan" id="kobo.859.1">a database.</span></span></li>
<li><span class="koboSpan" id="kobo.860.1">We run the test again and do the same thing – now we have 10 more </span><em class="italic"><span class="koboSpan" id="kobo.861.1">best moves</span></em><span class="koboSpan" id="kobo.862.1"> and 20 moves in </span><span class="No-Break"><span class="koboSpan" id="kobo.863.1">the database.</span></span></li>
<li><span class="koboSpan" id="kobo.864.1">We take the five best from the first set and cross them with the five best from the second set – plus five moves chosen at random and five more made up of totally random moves. </span><span class="koboSpan" id="kobo.864.2">Crossing two solutions refers to the process of taking a segment from the first set and a segment from the second set. </span><span class="koboSpan" id="kobo.864.3">In genetic terms, this is like taking half the </span><em class="italic"><span class="koboSpan" id="kobo.865.1">DNA</span></em><span class="koboSpan" id="kobo.866.1"> from each of two </span><em class="italic"><span class="koboSpan" id="kobo.867.1">parents</span></em><span class="koboSpan" id="kobo.868.1"> to make a </span><span class="No-Break"><span class="koboSpan" id="kobo.869.1">new </span></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.870.1">child</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.871.1">.</span></span></li>
<li><span class="koboSpan" id="kobo.872.1">We run that sequence of moves, and then take the 10 best individual moves and </span><span class="No-Break"><span class="koboSpan" id="kobo.873.1">continue on.</span></span></li>
</ol>
<p><span class="koboSpan" id="kobo.874.1">Through the process of selection, we should quickly get down to a sequence that performs the task. </span><span class="koboSpan" id="kobo.874.2">It may not be optimal, but it will work. </span><span class="koboSpan" id="kobo.874.3">We are managing our </span><em class="italic"><span class="koboSpan" id="kobo.875.1">gene pool</span></em><span class="koboSpan" id="kobo.876.1"> (a list of trial solutions to our problem) to create a solution to a problem by successive approximation. </span><span class="koboSpan" id="kobo.876.2">We want to keep a good mix of possibilities that can be combined in different ways to solve the problem of moving our arm to </span><span class="No-Break"><span class="koboSpan" id="kobo.877.1">its goal.</span></span></p>
<p><span class="koboSpan" id="kobo.878.1">We can actually use </span><a id="_idIndexMarker421"/><span class="koboSpan" id="kobo.879.1">several methods of </span><strong class="bold"><span class="koboSpan" id="kobo.880.1">cross-breeding</span></strong><span class="koboSpan" id="kobo.881.1"> our movement sequences. </span><span class="koboSpan" id="kobo.881.2">What I described is a simple cross – half the first parent’s genetic material and half the second parent’s material (if you will pardon the biological metaphor). </span><span class="koboSpan" id="kobo.881.3">We could instead use quarters – ¼ first, ¼ second, ¼ first, ¼ second – to have two crosses. </span><span class="koboSpan" id="kobo.881.4">We could also randomly grab bits from one or the other. </span><span class="koboSpan" id="kobo.881.5">We will stick with the half/half strategy for now, but you are free to experiment to your heart’s content. </span><span class="koboSpan" id="kobo.881.6">In essence, in all of these options, we are taking a solution, breaking it in half, and randomly combining it with half of a solution from </span><span class="No-Break"><span class="koboSpan" id="kobo.882.1">another trial.</span></span></p>
<p><span class="koboSpan" id="kobo.883.1">You are </span><a id="_idIndexMarker422"/><span class="koboSpan" id="kobo.884.1">about to issue an objection: what if the movement takes less than 10 steps? </span><span class="koboSpan" id="kobo.884.2">Easy – when we get to the goal, we stop, and discard the </span><span class="No-Break"><span class="koboSpan" id="kobo.885.1">remaining steps.</span></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.886.1">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.887.1">We are not looking for a perfect or optimum task execution, but just something good enough to get the job done. </span><span class="koboSpan" id="kobo.887.2">For a lot of real-time robotics, we don’t have the luxury of time to create a perfect solution, so any solution that gets the job done </span><span class="No-Break"><span class="koboSpan" id="kobo.888.1">is adequate.</span></span></p>
<p><span class="koboSpan" id="kobo.889.1">Why did we add the five additional random sample moves, and five totally random moves? </span><span class="koboSpan" id="kobo.889.2">This also mimics natural selection – the power of mutation. </span><span class="koboSpan" id="kobo.889.3">Our genetic code (the DNA in our bodies) is not perfect, and sometimes inferior material gets passed along. </span><span class="koboSpan" id="kobo.889.4">We also experience random mutations from bad copies of genes, cosmic rays, and viruses. </span><span class="koboSpan" id="kobo.889.5">We are introducing some random factors to </span><em class="italic"><span class="koboSpan" id="kobo.890.1">bump</span></em><span class="koboSpan" id="kobo.891.1"> the tuning of our algorithm – the element of natural selection – in case we converge on a local minimum or miss some simple path because it has not occurred yet to our </span><span class="No-Break"><span class="koboSpan" id="kobo.892.1">previous movements.</span></span></p>
<p><span class="koboSpan" id="kobo.893.1">But why on Earth are we going to all this trouble? </span><span class="koboSpan" id="kobo.893.2">The GA process can do something very difficult for a piece of software – it can innovate or evolve new solutions out of primitive actions by basically trying stuff until it finds out what works and what does not. </span><span class="koboSpan" id="kobo.893.3">We have provided another machine learning process to add to our toolbox, but one that can create solutions we, the programmers, had </span><span class="No-Break"><span class="koboSpan" id="kobo.894.1">not preconceived.</span></span></p>
<p><span class="koboSpan" id="kobo.895.1">Now, let’s dive into the GA process. </span><span class="koboSpan" id="kobo.895.2">In the interest of transparency, we are going to build our own GA process </span><span class="No-Break"><span class="koboSpan" id="kobo.896.1">from scratch.</span></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.897.1">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.898.1">We’ll be building our own tools in this version, but there are some prebuilt toolsets that can help </span><a id="_idIndexMarker423"/><span class="koboSpan" id="kobo.899.1">you to create GAs, such as </span><strong class="bold"><span class="koboSpan" id="kobo.900.1">Distributed Evolutionary Algorithms in Python</span></strong><span class="koboSpan" id="kobo.901.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.902.1">DEAP</span></strong><span class="koboSpan" id="kobo.903.1">), which can be found at </span><a href="https://github.com/DEAP"><span class="koboSpan" id="kobo.904.1">https://github.com/DEAP</span></a><span class="koboSpan" id="kobo.905.1"> and installed by typing in </span><strong class="source-inline"><span class="koboSpan" id="kobo.906.1">pip </span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.907.1">install deap</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.908.1">.</span></span></p>
<h2 id="_idParaDest-91"><a id="_idTextAnchor182"/><span class="koboSpan" id="kobo.909.1">Building a GA process</span></h2>
<p><span class="koboSpan" id="kobo.910.1">We loosely adopt the concept of the </span><em class="italic"><span class="koboSpan" id="kobo.911.1">survival of the fittest</span></em><span class="koboSpan" id="kobo.912.1"> to decide which plans are the fittest </span><a id="_idIndexMarker424"/><span class="koboSpan" id="kobo.913.1">and get to survive and propagate. </span><span class="koboSpan" id="kobo.913.2">I’m giving you a sandbox in which to play genetic engineer, where you have access to all of the parts and nothing is hidden behind the curtain. </span><span class="koboSpan" id="kobo.913.3">You will fi</span><a id="_idTextAnchor183"/><span class="koboSpan" id="kobo.914.1">nd that for our problem, the code is not all </span><span class="No-Break"><span class="koboSpan" id="kobo.915.1">that complex:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.916.1">We’ll start by creating the </span><strong class="source-inline"><span class="koboSpan" id="kobo.917.1">computefitness</span></strong><span class="koboSpan" id="kobo.918.1"> function, the one that scores our genetic material. </span><strong class="bold"><span class="koboSpan" id="kobo.919.1">Fitness</span></strong><span class="koboSpan" id="kobo.920.1"> is our criteria for grading our algorithm. </span><span class="koboSpan" id="kobo.920.2">We can change the fitness to our heart’s content to tailor our output to our needs. </span><span class="koboSpan" id="kobo.920.3">In this case, we are making a path in space for the robot arm from the starting location to the ending goal location. </span><span class="koboSpan" id="kobo.920.4">We evaluate our path in terms of how close any point of the path comes to our goal. </span><span class="koboSpan" id="kobo.920.5">Just as in our previous programs, the movement of the robot is constituted as 27 combinations of the three motors going clockwise, counterclockwise, or not moving. </span><span class="koboSpan" id="kobo.920.6">We divide the movement into small steps, each three motor units (1.8 degrees) of so of motion. </span><span class="koboSpan" id="kobo.920.7">We string together a whole group of these steps to make a path. </span><span class="koboSpan" id="kobo.920.8">The fitness function steps along the path and computes the hand position at </span><span class="No-Break"><span class="koboSpan" id="kobo.921.1">each step.</span></span></li>
<li><span class="koboSpan" id="kobo.922.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.923.1">predictReward</span></strong><span class="koboSpan" id="kobo.924.1"> function makes a trial computation of where the robot hand has moved as a result of that step. </span><span class="koboSpan" id="kobo.924.2">Let’s say we move </span><em class="italic"><span class="koboSpan" id="kobo.925.1">Motor 1</span></em><span class="koboSpan" id="kobo.926.1"> clockwise three steps, leave </span><em class="italic"><span class="koboSpan" id="kobo.927.1">Motor 2</span></em><span class="koboSpan" id="kobo.928.1"> alone, and move </span><em class="italic"><span class="koboSpan" id="kobo.929.1">Motor 3</span></em><span class="koboSpan" id="kobo.930.1"> counterclockwise three steps. </span><span class="koboSpan" id="kobo.930.2">This causes the hand to move slightly up and out. </span><span class="koboSpan" id="kobo.930.3">We score each step individually by how close it comes to the goal. </span><span class="koboSpan" id="kobo.930.4">Our score is computed out of 100; 100 is exactly at the goal, and we take away one point for each 1/100th of the distance the arm is away from the goal, up to a maximum of 340 mm. </span><span class="koboSpan" id="kobo.930.5">Why 340? </span><span class="koboSpan" id="kobo.930.6">That is the total length of the arm. </span><span class="koboSpan" id="kobo.930.7">We score the total movement a bit differently than you might think. </span><span class="koboSpan" id="kobo.930.8">Totaling up the rewards make no difference, as we want the point of closest approach to the goal. </span><span class="koboSpan" id="kobo.930.9">So we pick the single step with the highest reward and save that value. </span><span class="koboSpan" id="kobo.930.10">We throw away any steps after that, since they will only take us further away. </span><span class="koboSpan" id="kobo.930.11">Thus we automatically prune our paths to end at </span><span class="No-Break"><span class="koboSpan" id="kobo.931.1">the goal.</span></span></li>
<li><span class="koboSpan" id="kobo.932.1">I used </span><a id="_idIndexMarker425"/><span class="koboSpan" id="kobo.933.1">the term </span><strong class="source-inline"><span class="koboSpan" id="kobo.934.1">allele</span></strong><span class="koboSpan" id="kobo.935.1"> to indicate a single step out of the total path, which I called </span><strong class="source-inline"><span class="koboSpan" id="kobo.936.1">chrom</span></strong><span class="koboSpan" id="kobo.937.1">, short </span><span class="No-Break"><span class="koboSpan" id="kobo.938.1">for chromosome:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.939.1">
def computeFitness(population, goal, learningRate, initialPos): 
  fitness = []
  gamma = 0.6 
  state=initialPos 
  index = 0
  for chrom in population:
    value=0
    for allele in chrom:
      action = ACTIONMAT[allele]
      indivFit, state =
      predictReward(state,goal,action,learningRate) value += 
      indivFit
      if indivFit &gt; 95:
        # we are at the goal – snip the DNA here 
        break
    fitness.append([value,index]) 
    index += 1
  return fitness</span></pre></li> <li><span class="koboSpan" id="kobo.940.1">How do we create our paths to start with? </span><span class="koboSpan" id="kobo.940.2">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.941.1">make_new_individual</span></strong><span class="koboSpan" id="kobo.942.1"> function builds our initial population of chromosomes, or paths, out of random numbers. </span><span class="koboSpan" id="kobo.942.2">Each chromosome contains a path made up of a number from 0 to 26 that represents all the valid combinations of motor commands. </span><span class="koboSpan" id="kobo.942.3">We set the path length to be a random number from 10 </span><span class="No-Break"><span class="koboSpan" id="kobo.943.1">to 60:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.944.1">
def make_new_individual():
  # individual length of steps 
  lenInd = random.randint(10,60)
  chrom = [] # chromosome description 
  for ii in range(lenInd):
    chrom.append(randint(26)) 
  return chrom</span></pre></li> <li><span class="koboSpan" id="kobo.945.1">We use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.946.1">roulette</span></strong><span class="koboSpan" id="kobo.947.1"> function to pick a portion of our population to continue. </span><span class="koboSpan" id="kobo.947.2">Each generation, we select from the top 50% of scoring individuals to donate their DNA </span><a id="_idIndexMarker426"/><span class="koboSpan" id="kobo.948.1">to create the next generation. </span><span class="koboSpan" id="kobo.948.2">We want the reward value of the path, or chromosome, to weigh the selection process; the higher the reward score, the better chance of having children. </span><span class="koboSpan" id="kobo.948.3">This is part of our </span><span class="No-Break"><span class="koboSpan" id="kobo.949.1">selection process:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.950.1">
# select an individual in proportion to its value
def roulette(items):
 total_weight = sum(item[0] 
 for item in items) 
 weight_to_target = random.uniform(0, total_weight) 
 for item in items:
  weight_to_target -= item[0] 
  if weight_to_target &lt;= 0: 
   return item
# main Program
INITIAL_POS = [127,127,127]
GOAL=[-107.39209423, -35.18324771]
robotArm=RobotArm() 
robotArm.setGoal(GOAL) 
population = 300
learningRate = 3
crossover_chance = .50
mutate_chance = .001 
pop = []</span></pre></li> <li><span class="koboSpan" id="kobo.951.1">We start by building our initial population out of random parts. </span><span class="koboSpan" id="kobo.951.2">Their original fitness will be very low: about 13% or less. </span><span class="koboSpan" id="kobo.951.3">We maintain a pool of 300 individual paths, which we </span><span class="No-Break"><span class="koboSpan" id="kobo.952.1">call chromosomes:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.953.1">
for i in range(population): pop.append(make_new_individual())
  trainingData=[] epochs = 100</span></pre></li> <li><span class="koboSpan" id="kobo.954.1">Here we set up the loop to go through 100 generations of our natural selection process. </span><span class="koboSpan" id="kobo.954.2">We begin by computing the fitness of each individual and adding that score to </span><a id="_idIndexMarker427"/><span class="koboSpan" id="kobo.955.1">a fitness list with an index pointing back to </span><span class="No-Break"><span class="koboSpan" id="kobo.956.1">the chromosome:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.957.1">
for jj in range(epochs):
  # evaluate the population
  fitnessList = computeFitness(pop,GOAL,learningRate, INITIAL_POS)</span></pre></li> <li><span class="koboSpan" id="kobo.958.1">We sort the fitness in inverse order to get the best individuals. </span><span class="koboSpan" id="kobo.958.2">The largest number should </span><span class="No-Break"><span class="koboSpan" id="kobo.959.1">be first:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.960.1">
fitnessList.sort(reverse=True)</span></pre></li> <li><span class="koboSpan" id="kobo.961.1">We keep the top 50% of the population and discard the bottom 50%. </span><span class="koboSpan" id="kobo.961.2">The bottom half is out of the gene pool as </span><span class="No-Break"><span class="koboSpan" id="kobo.962.1">being unfit:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.963.1">
fitLen = 150
fitnessList = fitnessList[0:fitLen] # survival of the fittest...</span></pre></li> <li><span class="koboSpan" id="kobo.964.1">We pull out </span><a id="_idIndexMarker428"/><span class="koboSpan" id="kobo.965.1">the top performer from the whole list and put it into the </span><strong class="bold"><span class="koboSpan" id="kobo.966.1">hall of fame</span></strong><span class="koboSpan" id="kobo.967.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.968.1">HOF</span></strong><span class="koboSpan" id="kobo.969.1">). </span><span class="koboSpan" id="kobo.969.2">This will eventually be the output of our process. </span><span class="koboSpan" id="kobo.969.3">In the </span><a id="_idIndexMarker429"/><span class="koboSpan" id="kobo.970.1">meantime, we use the HOF or </span><strong class="bold"><span class="koboSpan" id="kobo.971.1">HOF fitness</span></strong><span class="koboSpan" id="kobo.972.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.973.1">HOFF</span></strong><span class="koboSpan" id="kobo.974.1">) value as a measure of the fitness of </span><span class="No-Break"><span class="koboSpan" id="kobo.975.1">this generation:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.976.1">
 hoff = pop[fitnessList[0][1]]
 print("HOF = ",fitnessList[0])</span></pre></li> <li><span class="koboSpan" id="kobo.977.1">We store the HOFF value in a </span><strong class="source-inline"><span class="koboSpan" id="kobo.978.1">trainingData</span></strong><span class="koboSpan" id="kobo.979.1"> list so we can graph the results at the end of </span><span class="No-Break"><span class="koboSpan" id="kobo.980.1">the program:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.981.1">
trainingData.append(fitnessList[0][0])
newPop = []
for ddex in fitnessList:</span><a id="_idTextAnchor184"/><span class="koboSpan" id="kobo.982.1"> newPop.append(pop[ddex[1]])
  print ("Survivors: ",len(newPop))</span></pre></li> <li><span class="koboSpan" id="kobo.983.1">At this phase, we have deleted the bottom 50% of our population, removing the worst performers. </span><span class="koboSpan" id="kobo.983.2">Now we need to replace them with the children of the best performers of this generation. </span><span class="koboSpan" id="kobo.983.3">We are going to use crossover as our mating technique. </span><span class="koboSpan" id="kobo.983.4">There are several types of genetic mating that can produce successful offspring. </span><span class="koboSpan" id="kobo.983.5">Crossover is popular and a good place to start, as well as being easy </span><a id="_idIndexMarker430"/><span class="koboSpan" id="kobo.984.1">to code. </span><span class="koboSpan" id="kobo.984.2">All we are doing is picking a spot in the genome and taking the first half from one parent, and the second half from the other. </span><span class="koboSpan" id="kobo.984.3">We pick our parents to </span><em class="italic"><span class="koboSpan" id="kobo.985.1">mate</span></em><span class="koboSpan" id="kobo.986.1"> randomly from the </span><a id="_idIndexMarker431"/><span class="koboSpan" id="kobo.987.1">remaining population, weighted proportionally to their fitness. </span><span class="koboSpan" id="kobo.987.2">This is referred to as </span><strong class="bold"><span class="koboSpan" id="kobo.988.1">roulette wheel selection</span></strong><span class="koboSpan" id="kobo.989.1">. </span><span class="koboSpan" id="kobo.989.2">The better individuals are weighted more heavily and are more likely to be selected for breeding. </span><span class="koboSpan" id="kobo.989.3">We create 140 new individuals as children of </span><span class="No-Break"><span class="koboSpan" id="kobo.990.1">this generation:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.991.1">
# crossover
# pick to individuals at random # on the basis of fitness
numCross = population-len(newPop)-10 print ("New Pop Crossovers",numCross) # #
# add 5 new random individuals for kk in range(10):
newPop.append(make_new_individual()) 
for kk in range(int(numCross)):
 p1 = roulette(fitnessList)[1] 
 p2 = roulette(fitnessList)[1]
 chrom1 = pop[p1]
 chrom2 = pop[p2]
 lenChrom = min(len(chrom1),len(chrom2)) xover = 
 randint(lenChrom)
 # xover is the point where the chromosomes cross over newChrom 
 = chrom1[0:xover]+chrom2[xover:]</span></pre></li> <li><span class="koboSpan" id="kobo.992.1">Our next step is </span><strong class="bold"><span class="koboSpan" id="kobo.993.1">mutation</span></strong><span class="koboSpan" id="kobo.994.1">. </span><span class="koboSpan" id="kobo.994.2">In real natural selection, there is a small chance that DNA will get corrupted or changed by cosmic rays, miscopying of the sequence, or other factors. </span><span class="koboSpan" id="kobo.994.3">Some mutations are beneficial, and some are not. </span><span class="koboSpan" id="kobo.994.4">We create our version </span><a id="_idIndexMarker432"/><span class="koboSpan" id="kobo.995.1">of this process by having a small chance (1/100 or so) that one gene in our new child path is randomly changed into some </span><span class="No-Break"><span class="koboSpan" id="kobo.996.1">other value:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.997.1">
# now we do mutation bitDex = 0
for kk in range(len(newChrom)-1): 
  mutDraw = random.random()
  if mutDraw &lt; mutate_chance: # a mutation has occured! 
</span><span class="koboSpan" id="kobo.997.2">   bit = randint</span><a id="_idTextAnchor185"/><span class="koboSpan" id="kobo.998.1">(26) 
   newChrom[kk]=bit
   print ("mutation") 
newPop.append(newChrom)</span></pre></li> <li><span class="koboSpan" id="kobo.999.1">Now that we have done all our processing, we add this new child path to our population, and get ready for the next generation to be evaluated. </span><span class="koboSpan" id="kobo.999.2">We record some data and loop back to </span><span class="No-Break"><span class="koboSpan" id="kobo.1000.1">the start:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.1001.1">
# welcome the new baby from parent 1 (p1) and parent 2 (p2) print("Generation: ",jj,"New population = ",len(newPop)) pop=newPop
mp.plot(trainingData) mp.show()</span></pre></li> </ol>
<p><span class="koboSpan" id="kobo.1002.1">So, how did we do with our mad genetic experiment? </span><span class="koboSpan" id="kobo.1002.2">The following output chart speaks </span><span class="No-Break"><span class="koboSpan" id="kobo.1003.1">for itself:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer068">
<span class="koboSpan" id="kobo.1004.1"><img alt="Figure 5.5 – Learning curve for the ﻿GA solution" src="image/B19846_05_5.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.1005.1">Figure 5.5 – Learning curve for the GA solution</span></p>
<p><span class="koboSpan" id="kobo.1006.1">The GA, for all it seems like a bit of voodoo programming, works quite well as a machine learning tool for this specific case of training our robot arm. </span><span class="koboSpan" id="kobo.1006.2">Our solution peaked at 99.76% of the goal (about 2 mm) after just 90 generations or so, which is quite fast for an AI learning process. </span><span class="koboSpan" id="kobo.1006.3">You can see the smooth nature of the learning that shows that this approach </span><a id="_idIndexMarker433"/><span class="koboSpan" id="kobo.1007.1">can be used to solve path-planning problems for our robot arm. </span><span class="koboSpan" id="kobo.1007.2">I have to admit that I was quite skeptical about this process, bu</span><a id="_idTextAnchor186"/><span class="koboSpan" id="kobo.1008.1">t it seems to work quite well for this particular </span><span class="No-Break"><span class="koboSpan" id="kobo.1009.1">problem domain.</span></span></p>
<p><span class="koboSpan" id="kobo.1010.1">The programming really was not too hard, and you can spend some time improving the process by tweaking the parameters of the GA. </span><span class="koboSpan" id="kobo.1010.2">What if we had a smaller population? </span><span class="koboSpan" id="kobo.1010.3">What if w</span><a id="_idTextAnchor187"/><span class="koboSpan" id="kobo.1011.1">e changed the fitnes</span><a id="_idTextAnchor188"/><span class="koboSpan" id="kobo.1012.1">s criteria? </span><span class="koboSpan" id="kobo.1012.2">Get in there, muck about, and see what you </span><span class="No-Break"><span class="koboSpan" id="kobo.1013.1">can learn.</span></span></p>
<h1 id="_idParaDest-92"><a id="_idTextAnchor189"/><span class="koboSpan" id="kobo.1014.1">Alternative robot arm ML approaches</span></h1>
<p><span class="koboSpan" id="kobo.1015.1">The realm of robot arm control via machine learning is really just getting started. </span><span class="koboSpan" id="kobo.1015.2">There are a couple </span><a id="_idIndexMarker434"/><span class="koboSpan" id="kobo.1016.1">of research avenues I wanted to bring to your attention as you look for further study. </span><span class="koboSpan" id="kobo.1016.2">One way to approach our understanding of robot movement is to consider the balance between </span><em class="italic"><span class="koboSpan" id="kobo.1017.1">exploitation</span></em><span class="koboSpan" id="kobo.1018.1"> and </span><em class="italic"><span class="koboSpan" id="kobo.1019.1">exploration</span></em><span class="koboSpan" id="kobo.1020.1">. </span><span class="koboSpan" id="kobo.1020.2">Exploitation is getting the robot to its goal as quickly as possible. </span><span class="koboSpan" id="kobo.1020.3">Exploration is using the space around the robot to try new things. </span><span class="koboSpan" id="kobo.1020.4">The path-planning program may have been stuck on a local minimum (think of this as a blind alley), and there could be better, more optimal solutions available that had not </span><span class="No-Break"><span class="koboSpan" id="kobo.1021.1">been considered.</span></span></p>
<p><span class="koboSpan" id="kobo.1022.1">There is also more than one way to teach a robot. </span><span class="koboSpan" id="kobo.1022.2">We have been using a form of self-exploration in our training. </span><span class="koboSpan" id="kobo.1022.3">What if we could show the robot what to do and have it learn by example? </span><span class="koboSpan" id="kobo.1022.4">We could </span><a id="_idTextAnchor190"/><span class="koboSpan" id="kobo.1023.1">let the robot observe a human doing the same task, and have it try to emulate the results.</span><a id="_idTextAnchor191"/><span class="koboSpan" id="kobo.1024.1"> Let’s discuss some alternative methods in the </span><span class="No-Break"><span class="koboSpan" id="kobo.1025.1">following sections.</span></span></p>
<h2 id="_idParaDest-93"><a id="_idTextAnchor192"/><span class="koboSpan" id="kobo.1026.1">Google’s SAC-X</span></h2>
<p><span class="koboSpan" id="kobo.1027.1">Google is </span><a id="_idIndexMarker435"/><span class="koboSpan" id="kobo.1028.1">trying a slightly different approach to the robot arm problem. </span><span class="koboSpan" id="kobo.1028.2">In their </span><strong class="bold"><span class="koboSpan" id="kobo.1029.1">Scheduled Auxiliary Control</span></strong><span class="koboSpan" id="kobo.1030.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.1031.1">SAC- X</span></strong><span class="koboSpan" id="kobo.1032.1">) program, they surmise that it can be quite difficult to assign reward points to individual </span><a id="_idIndexMarker436"/><span class="koboSpan" id="kobo.1033.1">movements of the robot arm. </span><span class="koboSpan" id="kobo.1033.2">They break down a complex task into smaller auxiliary tasks, and give reward points for those supporting </span><a id="_idIndexMarker437"/><span class="koboSpan" id="kobo.1034.1">tasks to let the robot build up to a complicated challenge. </span><span class="koboSpan" id="kobo.1034.2">If we were stacking blocks with a robot arm, we might separate picking up the block as one task, moving with the block in hand as another, and so on. </span><span class="koboSpan" id="kobo.1034.3">Google referred to this as a </span><em class="italic"><span class="koboSpan" id="kobo.1035.1">sparse reward</span></em><span class="koboSpan" id="kobo.1036.1"> problem if reinforcement was only used on the main task, stacking a block on top of another. </span><span class="koboSpan" id="kobo.1036.2">You can imagine how, in the process of teaching a robot to stack blocks, there would be thous</span><a id="_idTextAnchor193"/><a id="_idTextAnchor194"/><a id="_idTextAnchor195"/><span class="koboSpan" id="kobo.1037.1">ands of failed attempts before a successful move resulted in </span><span class="No-Break"><span class="koboSpan" id="kobo.1038.1">a reward.</span></span></p>
<h2 id="_idParaDest-94"><a id="_idTextAnchor196"/><span class="koboSpan" id="kobo.1039.1">Amazon Robotics Challenge</span></h2>
<p><span class="koboSpan" id="kobo.1040.1">Amazon has </span><a id="_idIndexMarker438"/><span class="koboSpan" id="kobo.1041.1">millions and millions of boxes, parts, bits, and </span><a id="_idIndexMarker439"/><span class="koboSpan" id="kobo.1042.1">other things on its shelves. </span><span class="koboSpan" id="kobo.1042.2">The company needs to get the stuff from the shelves into small boxes so they can ship it to you as fast as possible when you order it. </span><span class="koboSpan" id="kobo.1042.3">For the last few years, Amazon has sponsored the </span><em class="italic"><span class="koboSpan" id="kobo.1043.1">Amazon Robotics Challenge</span></em><span class="koboSpan" id="kobo.1044.1">, where teams from universities were invited to use robot arms to pick up items off a shelf and, you guessed it, put them into </span><span class="No-Break"><span class="koboSpan" id="kobo.1045.1">a box.</span></span></p>
<p><span class="koboSpan" id="kobo.1046.1">When you </span><a id="_idIndexMarker440"/><span class="koboSpan" id="kobo.1047.1">consider that Amazon sells almost everything </span><a id="_idIndexMarker441"/><span class="koboSpan" id="kobo.1048.1">imaginable, this is a real challenge. </span><span class="koboSpan" id="kobo.1048.2">In 2017, a team from Queensland, Australia, won </span><a id="_idTextAnchor197"/><span class="koboSpan" id="kobo.1049.1">the challenge with a low-cost arm and a really good </span><span class="No-Break"><span class="koboSpan" id="kobo.1050.1">hand-tracking system.</span></span></p>
<h1 id="_idParaDest-95"><a id="_idTextAnchor198"/><span class="koboSpan" id="kobo.1051.1">Summary</span></h1>
<p><span class="koboSpan" id="kobo.1052.1">Our task for this chapter was to use machine learning to teach the robot how to use its robot arm. </span><span class="koboSpan" id="kobo.1052.2">We used two techniques with some variations. </span><span class="koboSpan" id="kobo.1052.3">We used a variety of reinforcement learning techniques, or Q-learning, to develop a movement path by selecting individual actions based on the robot’s arm state. </span><span class="koboSpan" id="kobo.1052.4">Each motion was scored individually as a reward, and as part of the overall path as a value. </span><span class="koboSpan" id="kobo.1052.5">The process stored the results of the learning in a Q-matrix that could be used to generate a path. </span><span class="koboSpan" id="kobo.1052.6">We improved our first cut of the reinforcement learning program by indexing, or encoding, the motions from a 27-element array of possible combinations of motors as numbers from 0 to 26, and likewise indexing the robot state to a state lookup table. </span><span class="koboSpan" id="kobo.1052.7">This resulted in a 40x speedup of the learning process. </span><span class="koboSpan" id="kobo.1052.8">Our Q-learning approach struggled with the large number of states that the robot arm could </span><span class="No-Break"><span class="koboSpan" id="kobo.1053.1">be in.</span></span></p>
<p><span class="koboSpan" id="kobo.1054.1">Our second technique was a GA. </span><span class="koboSpan" id="kobo.1054.2">We created individual random paths to make a population. </span><span class="koboSpan" id="kobo.1054.3">We created a fitness function to score each path against our goal and kept the top performers from each generation. </span><span class="koboSpan" id="kobo.1054.4">We then crossed genetic material from two somewhat randomly selected individuals to create a new child path. </span><span class="koboSpan" id="kobo.1054.5">The GA also simulated mutation by having a slight chance of random changes in the steps of a path. </span><span class="koboSpan" id="kobo.1054.6">The results for the GA showed no problem with the state space complexity</span><a id="_idTextAnchor199"/><span class="koboSpan" id="kobo.1055.1"> of our robot arm and generated a valid path after just a </span><span class="No-Break"><span class="koboSpan" id="kobo.1056.1">few generations.</span></span></p>
<p><span class="koboSpan" id="kobo.1057.1">Why do we go to all of this trouble? </span><span class="koboSpan" id="kobo.1057.2">We use machine learning techniques when other empirical methods are either difficult, not reliable, or don’t produce solutions in a reasonable amount of time. </span><span class="koboSpan" id="kobo.1057.3">We can also tackle much more complex tasks with these techniques that might be intractable to a brute-force or </span><span class="No-Break"><span class="koboSpan" id="kobo.1058.1">math-only solution.</span></span></p>
<p><span class="koboSpan" id="kobo.1059.1">In the next chapter, we’ll be adding a voice interface to the robot with natural language processing, so you can talk to the robot and it will listen – and </span><span class="No-Break"><span class="koboSpan" id="kobo.1060.1">talk back.</span></span></p>
<h1 id="_idParaDest-96"><a id="_idTextAnchor200"/><span class="koboSpan" id="kobo.1061.1">Questions</span></h1>
<ol>
<li><span class="koboSpan" id="kobo.1062.1">In Q-learning, what does the Q </span><span class="No-Break"><span class="koboSpan" id="kobo.1063.1">stand for?</span></span><p class="list-inset"><strong class="bold"><span class="koboSpan" id="kobo.1064.1">Hint</span></strong><span class="koboSpan" id="kobo.1065.1">: You will have to research </span><span class="No-Break"><span class="koboSpan" id="kobo.1066.1">this yourself.</span></span></p></li>
<li><span class="koboSpan" id="kobo.1067.1">What could we do to limit the number of states that the Q-learning algorithm has to </span><span class="No-Break"><span class="koboSpan" id="kobo.1068.1">search through?</span></span></li>
<li><span class="koboSpan" id="kobo.1069.1">What effect does changing the learning rate have on the </span><span class="No-Break"><span class="koboSpan" id="kobo.1070.1">learning process?</span></span></li>
<li><span class="koboSpan" id="kobo.1071.1">What function or parameter serves to penalize longer paths in the Q-learning equation? </span><span class="koboSpan" id="kobo.1071.2">What effect does increasing or decreasing this </span><span class="No-Break"><span class="koboSpan" id="kobo.1072.1">function have?</span></span></li>
<li><span class="koboSpan" id="kobo.1073.1">In the genetic algorithm, how would you go about penalizing longer paths so that shorter paths (fewer number of steps) would </span><span class="No-Break"><span class="koboSpan" id="kobo.1074.1">be preferred?</span></span></li>
<li><span class="koboSpan" id="kobo.1075.1">Look up the SARSA variation of Q-learning. </span><span class="koboSpan" id="kobo.1075.2">How would you implement the SARSA technique into </span><span class="No-Break"><span class="koboSpan" id="kobo.1076.1">program 2.</span></span></li>
<li><span class="koboSpan" id="kobo.1077.1">What effect does changing the learning rate in the genetic algorithm have? </span><span class="koboSpan" id="kobo.1077.2">What are the upper and lower bounds of the </span><span class="No-Break"><span class="koboSpan" id="kobo.1078.1">learning rat</span><a id="_idTextAnchor201"/><span class="koboSpan" id="kobo.1079.1">e?</span></span></li>
<li><span class="koboSpan" id="kobo.1080.1">In a genetic algorithm, what effect does reducing the </span><span class="No-Break"><span class="koboSpan" id="kobo.1081.1">population have?</span></span></li>
</ol>
<h1 id="_idParaDest-97"><a id="_idTextAnchor202"/><span class="koboSpan" id="kobo.1082.1">Further reading</span></h1>
<ul>
<li><em class="italic"><span class="koboSpan" id="kobo.1083.1">Python Deep Learning</span></em><span class="koboSpan" id="kobo.1084.1"> by Zocca, Spacagna, Slater, and Roelants, </span><span class="No-Break"><span class="koboSpan" id="kobo.1085.1">Packt Publishing</span></span></li>
<li><em class="italic"><span class="koboSpan" id="kobo.1086.1">Artificial Intelligence with Python</span></em><span class="koboSpan" id="kobo.1087.1"> by Prateek Joshi, </span><span class="No-Break"><span class="koboSpan" id="kobo.1088.1">Packt Publishing</span></span></li>
<li><em class="italic"><span class="koboSpan" id="kobo.1089.1">AI Junkie: Genetic Algorithm – A Brief Overview</span></em><span class="koboSpan" id="kobo.1090.1">, retrieved </span><span class="No-Break"><span class="koboSpan" id="kobo.1091.1">from </span></span><a href="http://www.ai-junkie.com/ga/intro/gat2.html"><span class="No-Break"><span class="koboSpan" id="kobo.1092.1">http://www.ai-junkie.com/ga/intro/gat2.html</span></span></a></li>
<li><em class="italic"><span class="koboSpan" id="kobo.1093.1">Basic Reinforcement Learning Tutorial 2: </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.1094.1">SARSA</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.1095.1">: </span></span><a href="https://github.com/vmayoral/basic_reinforcement_learning/tree/master/tutorial2"><span class="No-Break"><span class="koboSpan" id="kobo.1096.1">https://github.com/vmayoral/basic_reinforcement_learning/tree/master/tutorial2</span></span></a></li>
<li><em class="italic"><span class="koboSpan" id="kobo.1097.1">Google DeepMind Blog: Learning b</span><a id="_idTextAnchor203"/><a id="_idTextAnchor204"/><span class="koboSpan" id="kobo.1098.1">y Playing (Robot Arm (</span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.1099.1">SAC-X))</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.1100.1">: </span></span><a href="https://deepmind.com/blog/learning-playing/"><span class="No-Break"><span class="koboSpan" id="kobo.1101.1">https://deepmind.com/blog/learning-playing/</span></span></a></li>
</ul>
</div>
</body></html>