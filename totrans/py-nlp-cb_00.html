<html><head></head><body>
		<div><h1 id="_idParaDest-5" class="calibre7"><a id="_idTextAnchor004" class="calibre6 pcalibre pcalibre1"/>Preface</h1>
			<p class="calibre3">Python is the most widely used language for <strong class="bold">natural language processing</strong> (<strong class="bold">NLP</strong>) thanks to its extensive tools and libraries for analyzing text and extracting computer-usable data. This book will take you through a range of techniques for text processing, from basics such as parsing parts of speech to complex topics such as topic modeling, text classification, and visualization.</p>
			<p class="calibre3">Starting with an overview of NLP, the book presents recipes for dividing text into sentences, stemming and lemmatization, removing stopwords, and parts-of-speech tagging to help you to prepare your data. You will then learn about ways of extracting and representing grammatical information, such as dependency parsing and anaphora resolution; discover different ways of representing the semantics using bag of words, TF-IDF, word embeddings, and BERT; and develop skills for text classification using keywords, SVMs, LSTMs, and other techniques.</p>
			<p class="calibre3">As you advance, you will also see how to extract information from text, implement unsupervised and supervised techniques for topic modeling, and perform topic modeling of short texts, such as tweets. Additionally, the book covers visualizations of text data.</p>
			<p class="calibre3">Finally, this book introduces Transformer-based models and how to utilize them to perform another set of novel NLP tasks. These encoder-decoder-based models are deep neural-network-based models and have been trained on large text corpora. These models have performed or exceeded the state of the art on various NLP tasks. Especially novel are the decoder-based generative models, which have the capability to generate text based on the context provided to them. Some of these models have reasoning capabilities built into them. These models will take NLP into the next era and make it a part of mainstream technology applications.</p>
			<p class="calibre3">By the end of this NLP book, you will have developed the skills to use a powerful set of tools for text processing.</p>
			<div><h1 id="_idParaDest-6" class="calibre7"><a id="_idTextAnchor005" class="calibre6 pcalibre pcalibre1"/>Who this book is for</h1>
			<p class="calibre3">Data scientists, machine learning engineers, and developers familiar with basic programming and data science concepts can gain practical insights from this book. It serves as a primer to introduce the concepts of NLP and their practical applications.</p>
			<p class="calibre3">The roles that are the target of this book are the following:</p>
			<p class="calibre3"><strong class="bold">Data scientists</strong>: As a data scientist, you will gain an understanding of how to work with text. Intermediate knowledge of Python will help you to get the most out of this book. If you are already an NLP practitioner, this book will serve as a code reference when working on your projects.</p>
			<p class="calibre3"><strong class="bold">Software engineers and architects</strong>: Developers who want to build capability in the domain of NLP will be introduced to all the fundamental and advanced uses of NLP in text processing. This will help you level up on your knowledge and build yourself up to develop solutions using NLP when required.</p>
			<p class="calibre3"><strong class="bold">Product managers</strong>: Though this book contains code examples for the recipes, each of these recipes is accompanied by explanations of why certain steps are being performed and what the end output for those steps is. This makes it a useful resource for product managers who want to understand what is possible with a certain NLP recipe, which would enable them to envision novel solutions using it.</p>
			<div><h1 id="_idParaDest-7" class="calibre7"><a id="_idTextAnchor006" class="calibre6 pcalibre pcalibre1"/>What this book covers</h1>
			<p class="calibre3"><a href="B18411_01.xhtml#_idTextAnchor013" class="calibre6 pcalibre pcalibre1"><em class="italic">Chapter 1</em></a>, <em class="italic">Learning NLP Basics</em>, introduces the very basics of NLP. The recipes in this chapter show the basic preprocessing steps that are required for further NLP work. We show how to tokenize text, or divide it into sentences and words; assign parts of speech to individual words; lemmatize them, or get their canonical forms; and remove stopwords.</p>
			<p class="calibre3"><a href="B18411_02.xhtml#_idTextAnchor042" class="calibre6 pcalibre pcalibre1"><em class="italic">Chapter 2</em></a>, <em class="italic">Playing with Grammar</em>, shows how to get grammatical information from text. This information could be useful in determining relationships between different entities mentioned in the text. We start by showing how to determine whether a noun is singular or plural. We then show how to get a dependency parse that shows relationships between words in a sentence. Then, we demonstrate how to get noun chunks, or nouns with their dependent words, such as adjectives. After that, we look at parsing out the subjects and objects of a sentence. Finally, we show how to use a regular-expression-style matcher to extract grammatical phrases in a sentence.</p>
			<p class="calibre3"><a href="B18411_03.xhtml#_idTextAnchor067" class="calibre6 pcalibre pcalibre1"><em class="italic">Chapter 3</em></a>, <em class="italic">Representing Text – Capturing Semantics</em>, looks at different ways of representing text for further processing in NLP models. Since computers cannot deal with words directly, we need to encode them in vector form. In order to demonstrate the effectiveness of different methods of encoding, we first create a simple classifier and then use it with different encoding methods. We look at the following encoding methods: bag-of-words, N-gram model, TF-IDF, word embeddings, BERT, and OpenAI embeddings. We also show how to train your own bag-of-words model and demonstrate how to create a simple <strong class="bold">retrieval-augmented generation</strong> (<strong class="bold">RAG</strong>) solution.</p>
			<p class="calibre3"><a href="B18411_04.xhtml#_idTextAnchor106" class="calibre6 pcalibre pcalibre1"><em class="italic">Chapter 4</em></a>, <em class="italic">Classifying Texts</em>, shows various ways of carrying out text classification, one of the most common NLP tasks. First, we show how to preprocess the dataset in order to prepare it for classification. Then, we demonstrate different classifiers, including a rule-based classifier, an unsupervised classifier via K-means, training an SVM for classification, training a spaCy model for text classification, and, finally, using OpenAI GPT models to classify texts.</p>
			<p class="calibre3"><a href="B18411_05.xhtml#_idTextAnchor128" class="calibre6 pcalibre pcalibre1"><em class="italic">Chapter 5</em></a>, <em class="italic">Getting Started with Information Extraction</em>, shows how to extract information from text, another very important NLP task. We start off with using regular expressions for simple information extraction. We then look at how to use the Levenshtein distance to handle misspellings. Then, we show how to extract characteristic keywords from different texts. We look at how to extract named entities using spaCy, and how to train your own custom spaCy NER model. Finally, we show how to fine-tune a BERT NER model.</p>
			<p class="calibre3"><a href="B18411_06.xhtml#_idTextAnchor156" class="calibre6 pcalibre pcalibre1"><em class="italic">Chapter 6</em></a>, <em class="italic">Topic Modeling</em>, shows how to determine topics of text using various unsupervised methods, including LDA, community detection with BERT embeddings, K-means clustering, and BERTopic. Finally, we use contextualized topic models that work with multilingual models and inputs.</p>
			<p class="calibre3"><a href="B18411_07.xhtml#_idTextAnchor177" class="calibre6 pcalibre pcalibre1"><em class="italic">Chapter 7</em></a>, <em class="italic">Visualizing Text Data</em>, focuses on using various tools to create informative visualizations of text data and processing. We create graphic representations of the dependency parse, parts of speech, and named entities. We also create a confusion matrix plot and word clouds. Finally, we use pyLDAvis and BERTopic to visualize topics in a text.</p>
			<p class="calibre3"><a href="B18411_08.xhtml#_idTextAnchor205" class="calibre6 pcalibre pcalibre1"><em class="italic">Chapter 8</em></a>, <em class="italic">Transformers and Their Applications</em>, provides an introduction to Transformers. This chapter begins by demonstrating how to transform text into a format suitable for internal processing by a Transformer model. It then explores techniques for text classification using pre-trained Transformer models. Additionally, the chapter delves into text generation with Transformers, explaining how to tweak the generation parameters to produce coherent and natural-sounding text. Finally, it covers the application of Transformers in language translation.</p>
			<p class="calibre3"><a href="B18411_09.xhtml#_idTextAnchor231" class="calibre6 pcalibre pcalibre1"><em class="italic">Chapter 9</em></a>, <em class="italic">Natural Language Understanding</em>, covers NLP techniques that help infer the information contained in a piece of text. This chapter begins with a discussion on question-answering in both open and closed domains, followed by methods for answering questions from document sources using extractive and abstractive approaches. Subsequent sections cover text summarization and sentence entailment. The chapter concludes with explainability techniques, which demonstrate how models make classification decisions and how different parts of the text contribute to the assigned class labels.</p>
			<p class="calibre3"><a href="B18411_10.xhtml#_idTextAnchor277" class="calibre6 pcalibre pcalibre1"><em class="italic">Chapter 10</em></a>, <em class="italic">Generative AI and Large Language Models</em>, introduces open source <strong class="bold">Large Language Models</strong> (<strong class="bold">LLMs</strong>) such as Mistral and Llama, demonstrating how to use prompts to generate text based on simple human-defined requirements. It further explores techniques for generating Python code and SQL statements from natural language instructions. Finally, it presents methods for utilizing a sophisticated closed source LLM from OpenAI to orchestrate custom task agents. These agents collaborate to answer complex questions requiring web searches and basic arithmetic to arrive at an end solution.</p>
			<h2 id="_idParaDest-8" class="calibre5"><a id="_idTextAnchor007" class="calibre6 pcalibre pcalibre1"/>To get the most out of this book</h2>
			<p class="calibre3">You will need an understanding of the Python programming language and how to manage and install packages for it. Knowledge of Jupyter Notebook would be useful, though it is not required. For package management, the knowledge of <code>poetry</code> package management is recommended, though you can make the examples work via <code>pip</code> too. For recipes to be able to use GPUs (if present) in the system, ensure that the latest GPU device drivers are installed along with the CUDA/cuDNN dependencies.</p>
			<table id="table001" class="no-table-style">
				<colgroup class="calibre10">
					<col class="calibre11"/>
					<col class="calibre11"/>
				</colgroup>
				<tbody class="calibre12">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Software/hardware covered in </strong><strong class="bold">the book</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Operating </strong><strong class="bold">system requirements</strong></p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3">Python 3.10</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Windows, macOS, or Linux</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3">Poetry</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Windows, macOS, or Linux</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3">Jupyter Notebook (optional)</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Windows, macOS, or Linux</p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="calibre3"><strong class="bold">If you are using the digital version of this book, we advise you to type the code yourself or access the code from the book’s GitHub repository (a link is available in the next section). Doing so will help you avoid any potential errors related to the copying and pasting </strong><strong class="bold">of code.</strong></p>
			<h1 id="_idParaDest-9" class="calibre7"><a id="_idTextAnchor008" class="calibre6 pcalibre pcalibre1"/>Download the example code files</h1>
			<p class="calibre3">You can download the example code files for this book from GitHub at <a href="https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition" class="calibre6 pcalibre pcalibre1">https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition</a>. If there is an update to the code, it will be updated in the GitHub repository.</p>
			<p class="calibre3">We also have other code bundles from our rich catalog of books and videos available at <a href="https://github.com/PacktPublishing/" class="calibre6 pcalibre pcalibre1">https://github.com/PacktPublishing/</a>. Check them out!</p>
			<h1 id="_idParaDest-10" class="calibre7"><a id="_idTextAnchor009" class="calibre6 pcalibre pcalibre1"/>Conventions used</h1>
			<p class="calibre3">There are several text conventions used throughout this book.</p>
			<p class="calibre3"><code>Code in text</code>: Indicates code words in text, database table names, folder names, filenames, file extensions, pathnames, dummy URLs, user input, and <em class="italic">Twitter/X</em> handles. Here is an example: “Instantiate a tokenizer of the <code>bert-base-cased</code> type.”</p>
			<p class="calibre3">A block of code is set as follows:</p>
			<pre class="source-code">
from transformers import pipeline
import torch</pre>			<p class="calibre3">When we wish to draw your attention to a particular part of a code block, the relevant lines or items are set in bold:</p>
			<pre class="source-code">
from transformers import T5Tokenizer, T5ForConditionalGeneration
import torch
<strong class="bold1">device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</strong></pre>			<p class="calibre3">Any command-line input or output is written as follows:</p>
			<pre class="console">
Classification Results
{'accuracy': 0.88,
'precision': 0.92,
'recall': 0.84}</pre>			<p class="calibre3"><strong class="bold">Bold</strong>: Indicates a new term, an important word, or words that you see onscreen. For instance, words in menus or dialog boxes appear in <strong class="bold">bold</strong>. Here is an example: “Select <strong class="bold">System info</strong> from the <strong class="bold">Administration</strong> panel.”</p>
			<p class="callout-heading">Tips or important notes</p>
			<p class="callout">Appear like this.</p>
			<h1 id="_idParaDest-11" class="calibre7"><a id="_idTextAnchor010" class="calibre6 pcalibre pcalibre1"/>Get in touch</h1>
			<p class="calibre3">Feedback from our readers is always welcome.</p>
			<p class="calibre3"><strong class="bold">General feedback</strong>: If you have questions about any aspect of this book, email us at <a href="mailto:customercare@packtpub.com" class="calibre6 pcalibre pcalibre1">customercare@packtpub.com</a> and mention the book title in the subject of your message.</p>
			<p class="calibre3"><strong class="bold">Errata</strong>: Although we have taken every care to ensure the accuracy of our content, mistakes do happen. If you have found a mistake in this book, we would be grateful if you would report this to us. Please visit <a href="http://www.packtpub.com/support/errata" class="calibre6 pcalibre pcalibre1">www.packtpub.com/support/errata</a> and fill in the form.</p>
			<p class="calibre3"><strong class="bold">Piracy</strong>: If you come across any illegal copies of our works in any form on the internet, we would be grateful if you would provide us with the location address or website name. Please contact us at <a href="mailto:copyright@packt.com" class="calibre6 pcalibre pcalibre1">copyright@packt.com</a> with a link to the material.</p>
			<p class="calibre3"><strong class="bold">If you are interested in becoming an author</strong>: If there is a topic that you have expertise in and you are interested in either writing or contributing to a book, please visit <a href="http://authors.packtpub.com" class="calibre6 pcalibre pcalibre1">authors.packtpub.com</a>.</p>
			<h1 id="_idParaDest-12" class="calibre7"><a id="_idTextAnchor011" class="calibre6 pcalibre pcalibre1"/>Share Your Thoughts</h1>
			<p class="calibre3">Once you’ve read <em class="italic">Python Natural Language Processing Cookbook</em>, we’d love to hear your thoughts! Please <a href="https://packt.link/r/1-803-24574-3" class="calibre6 pcalibre pcalibre1">click here to go straight to the Amazon review page</a> for this book and share your feedback.</p>
			<p class="calibre3">Your review is important to us and the tech community and will help us make sure we’re delivering excellent quality content.</p>
			<h1 id="_idParaDest-13" class="calibre7"><a id="_idTextAnchor012" class="calibre6 pcalibre pcalibre1"/>Download a free PDF copy of this book</h1>
			<p class="calibre3">Thanks for purchasing this book!</p>
			<p class="calibre3">Do you like to read on the go but are unable to carry your print books everywhere?</p>
			<p class="calibre3">Is your eBook purchase not compatible with the device of your choice?</p>
			<p class="calibre3">Don’t worry, now with every Packt book you get a DRM-free PDF version of that book at no cost.</p>
			<p class="calibre3">Read anywhere, any place, on any device. Search, copy, and paste code from your favorite technical books directly into your application.</p>
			<p class="calibre3">The perks don’t stop there, you can get exclusive access to discounts, newsletters, and great free content in your inbox daily</p>
			<p class="calibre3">Follow these simple steps to get the benefits:</p>
			<ol class="calibre13">
				<li class="calibre14">Scan the QR code or visit the link below</li>
			</ol>
			<div><div><img src="img/B18411_QR_Free_PDF.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><a href="https://packt.link/free-ebook/978-1-80324-574-4" class="calibre6 pcalibre pcalibre1">https://packt.link/free-ebook/978-1-80324-574-4</a></p>
			<ol class="calibre13">
				<li value="2" class="calibre14">Submit your proof of purchase</li>
				<li class="calibre14">That’s it! We’ll send your free PDF and other benefits to your email directly</li>
			</ol>
		</div>
	</body></html>