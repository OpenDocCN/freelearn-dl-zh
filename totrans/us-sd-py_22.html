<html><head></head><body>
		<div><h1 id="_idParaDest-264" class="chapter-number"><a id="_idTextAnchor443"/>22</h1>
			<h1 id="_idParaDest-265"><a id="_idTextAnchor444"/>Exploring Beyond Stable Diffusion</h1>
			<p>The realm of Stable Diffusion is in a constant state of flux, with innovative models, methodologies, and research papers surfacing daily. Throughout the course of writing this book, the Stable Diffusion community has seen remarkable growth. Given the dynamic nature of this field, inevitably some developments are not covered within these pages.</p>
			<p>In the process of writing this book and delving into the intricacies of Stable Diffusion, I’ve often been asked, “<em class="italic">How do you begin to understand this complex subject?</em>” In this concluding chapter, I aim to share my learning journey and provide insights to help you stay abreast of the latest developments in Stable Diffusion and AI.</p>
			<p>In this chapter, we will discuss the following:</p>
			<ul>
				<li><strong class="bold">What sets this AI wave apart</strong>: Understanding the unique characteristics of the current AI revolution</li>
				<li><strong class="bold">The enduring value of mathematics and programming</strong>: Emphasizing the importance of core skills in the rapidly changing AI landscape</li>
				<li><strong class="bold">Staying current with AI innovations</strong>: Tips and strategies to keep up with the latest AI breakthroughs</li>
				<li><strong class="bold">Cultivating responsible, ethical, private, and secure AI</strong>: Exploring the best practices to develop AI that aligns with societal values and safety standards</li>
				<li><strong class="bold">Our evolving relationship with AI</strong>: Reflecting on the implications of AI for individuals, organizations, and society as a whole</li>
			</ul>
			<p>I hope that this chapter serves as a valuable resource for those eager to expand their knowledge of Stable Diffusion and AI. Curiosity is the key to unlocking deeper understanding and exploration in this exciting field.</p>
			<h1 id="_idParaDest-266"><a id="_idTextAnchor445"/>What sets this AI wave apart</h1>
			<p>In <a id="_idIndexMarker659"/>March 2016, AlphaGo [1] made history when it defeated the world-famous Go player Lee Sedol in a five-game match. This was a significant event because Go is a game that requires strategic thinking and intuition and it has been considered impossible for computers to master due to its complexity. AlphaGo’s victory was a testament to the advancements in AI and machine learning.</p>
			<p>AlphaGo’s success was based on a combination of deep neural networks and Monte Carlo tree search techniques. It was trained on thousands of professional Go games to learn patterns and strategies. Then, it played many games against itself to improve its skills and understanding of the game.</p>
			<p>This achievement marked a major milestone in the development of AI, demonstrating that machines can now outperform humans in tasks that require deep understanding and strategic decision-making.</p>
			<p>I was watching these games live and was astonished by the power of the machine. However, the model that powers AlphaGo is not short of limitations. Here are a few:</p>
			<ul>
				<li><strong class="bold">Specificity to Go</strong>: AlphaGo<a id="_idIndexMarker660"/> is specifically designed to play the game of Go. It doesn’t have the ability to transfer its knowledge to other games or domains. If we added one more row to the game board, AlphaGo would not be able to function as it should.</li>
				<li><strong class="bold">Explainability</strong>: It’s difficult to understand why AlphaGo makes certain decisions, which can make it hard to trust or rely on its output in critical situations.</li>
			</ul>
			<p>AlphaGo was trained only with GoPlay data, so its data scope is quite limited, which is the root cause of its “specification” feature. It is similar to <strong class="bold">Convolution Neural Network</strong> (<strong class="bold">CNN</strong>)-based image classification models. These models are trained by a set of predefined data; hence, they can only be<a id="_idIndexMarker661"/> performed on the scoped input data.</p>
			<p>In 2017, the paper “<em class="italic">Attention Is All You Need</em>” [2] introduced the transformer model. The authors demonstrated the effectiveness of the transformer model in a specific unsupervised task called machine translation. They trained the model to translate sentences from one language to another without any aligned sentence pairs or explicit supervision. Instead, they used an encoder-decoder structure to predict the next word with probability. In other words, the next “word” or “token” is the training label for the input, so the model tries to learn patterns or structures present in data without any explicit guidance about what to learn.</p>
			<p>The transformer model itself is no doubt still important (at least at the time of writing). But the idea and the implementation of training a model without predefined labels is genius.</p>
			<p>In recent years, some models have used only a decoder to train a model. Notably, GPT-3 uses a decoder-only architecture to generate text. Some other visual models use an attention mechanism to replace the CNN structure – for example, a <strong class="bold">Vision Transformer</strong> (<strong class="bold">ViT</strong>) [3] and the <a id="_idIndexMarker662"/><strong class="bold">Swin </strong><strong class="bold">transformer</strong> [4].</p>
			<p>In the case of Stable Diffusion, the model presented in this book integrates the attention mechanism within its UNet architecture as discussed in <a href="B21263_04.xhtml#_idTextAnchor081"><em class="italic">Chapter 4</em></a> and <a href="B21263_05.xhtml#_idTextAnchor097"><em class="italic">Chapter 5</em></a>. Stable Diffusion can take any image and captioned pair for training, without a limitation in its data scope. If we have enough hardware power, we can provide all images of the world and their associated description text to train a super diffusion model.</p>
			<p>As the Sora model <a id="_idIndexMarker663"/>from OpenAI has shown, with enough video data, associated description, massive GPU power, and a diffusion transformer-based model, a model can generate a video to somewhat mimic the real world.</p>
			<p>At the time of writing, we don’t know what the limit is of this attention-based auto-learning architect<a id="_idTextAnchor446"/>ure.</p>
			<h1 id="_idParaDest-267"><a id="_idTextAnchor447"/>The enduring value of mathematics and programming</h1>
			<p>As we <a id="_idIndexMarker664"/>witness the power demonstrated by AI, some might argue that, in the future, there will be no need to learn programming or math, as we can delegate any tasks to AI. However, this is far from the truth. This wave of AI revolution opens a new door to the future, but fundamentally, AI is still a program running on silicon chips, and it requires human beings to provide wisdom and knowledge.</p>
			<p>Current AI technology has been developed based on mathematical models such as probability theory, statistics, and linear algebra, which are essential for AI algorithms. For example, the latent-based diffusion model (Stable Diffusion) is an algorithm based on neural networks, which are inspired by the structure of the human brain. The most important part of deep learning is backpropagation, which is essentially calculus. Therefore, AI cannot exist without mathematics.</p>
			<p>In regards to programming skills, GPT and Diffusion models do not make programming skills redundant; on the contrary – programming finds new areas to conquer. Those who contribute to AI development are also those who write most of the code.</p>
			<p>Let’s assume you are misled by certain self-proclaimed experts and give up pursuing your programming capability. Several years later, when you open any GitHub AI projects, you will not only be unable to make any contributions but also won’t be able to read the code at all.</p>
			<p>Mathematic knowledge and programming skills will never become obsolete. They may change their forms over time, but the core concepts remain unchanged.</p>
			<p>As you are reading<a id="_idIndexMarker665"/> a book about using Stable Diffusion with Python, I bet you won't be satisfied with just being able to use the model and need to know how it works internally. To understand it, the best way is to create it, as Richard Feynman [7] said on his blackboard [5], as shown in <em class="italic">Figure 22</em><em class="italic">.1</em>:</p>
			<div><div><img src="img/B21263_22_01.jpg" alt="Figure 22.1 – Richard Feynman’s blackboard – “What I cannot create, I do not understand”"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 22.1 – Richard Feynman’s blackboard – “What I cannot create, I do not understand”</p>
			<p>It is also down to personal experience; I can only fully understand a topic after implementing it. As the old saying goes, we can’t learn to swim by reading a book about swimming.</p>
			<p>However, implementing a <a id="_idIndexMarker666"/>model will require an understanding of the theory, which requires an understanding of related mathematics and the programming skills to convert a complex formula to executable bits.</p>
			<p>Let’s assume we have set our mind on learning more about AI – where do we <a id="_idTextAnchor448"/>start?</p>
			<h1 id="_idParaDest-268"><a id="_idTextAnchor449"/>Staying current with AI innovations</h1>
			<p>As the<a id="_idIndexMarker667"/> transformer model has largely transformed the landscape, we can’t find the newest learning material from the Amazon bookstore, especially books written before 2022. It is important to find the most relevant high-quality information. Here are some channels that might be useful:</p>
			<ul>
				<li><strong class="bold">Follow the renowned paper authors</strong>: Usually, a productive or smart paper author may create or contribute to another model. Their GitHub account, X (formerly known as Twitter) account, or other channel updates are good ways to stay aware of their newest work.</li>
				<li><strong class="bold">Using X</strong>: When browsing through my<a id="_idIndexMarker668"/> X (formerly known as Twitter) <a id="_idIndexMarker669"/>feed, I often come across a mix of content, including humorous videos and images that can easily consume my mornings. To maximize the platform's usefulness, I've learned to utilize the <strong class="bold">Not interested in this post </strong>feature to tailor my feed towards displaying more relevant information. This requires discipline, as I need to resist the temptation to engage with entertaining threads and instead interact with AI-related posts that offer valuable insights. By consistently applying this strategy, X transforms into a valuable resource for staying up-to-date with the latest developments in the field.</li>
				<li><code>git pull</code> command<a id="_idIndexMarker670"/> is a useful way to catch up with the newest advancements in related fields.<p class="list-inset">For example, when <a id="_idIndexMarker671"/>we open the <code>diffusers</code> GitHub repository, and input the <code>git pull origin main</code> command, it will list out the latest changes to the main branch, and I can find out what code is merged into the main branch. By simply <em class="italic">ctrl</em> + clicking on the filenames, I can open the files that include the newest changes.</p><p class="list-inset">Often, the <code>git pull</code> command can provide the most valuable information about the cutting-edge advancements of Stable Diffusion. Usually, the code will include the paper URLs too.</p></li>
				<li><strong class="bold">Useful sites</strong>: Besides GitHub repositories, there are three websites or tools that are very useful for finding papers and models:<ul><li><strong class="bold">Papers with Code</strong> (<a href="https://paperswithcode.com/">https://paperswithcode.com/</a>): This website is a fantastic resource for staying <a id="_idIndexMarker672"/>up to date with the latest research. It provides a comprehensive list of academic papers, along with their associated code implementations, making it easy to understand and reproduce the results. You can filter papers by research area, task, and dataset, and the site also features leaderboards for state-of-the-art models across various tasks.</li><li><strong class="bold">GitHub Trending</strong>: GitHub<a id="_idIndexMarker673"/> is a platform where developers and researchers share their code, and the <strong class="bold">Trending</strong> section can be a goldmine for discovering new<a id="_idIndexMarker674"/> models and implementations. By filtering the results based on your area of interest (e.g., machine learning, deep learning, or natural language processing), you can find the most popular and recently updated repositories. This can help you stay informed about the latest advancements and best practices <a id="_idIndexMarker675"/>in the field.</li><li><strong class="bold">Hugging Face Model Hub</strong>: Hugging Face<a id="_idIndexMarker676"/> is a well-known platform for building and sharing <strong class="bold">natural language processing</strong> (<strong class="bold">NLP</strong>) models. Their <a id="_idIndexMarker677"/>Model Hub is<a id="_idIndexMarker678"/> a searchable repository of pre-trained models, which you can filter by task, language, and framework. By exploring the Model Hub, you can find cutting-edge models for a wide range of NLP tasks and easily integrate them into your own projects. Additionally, Hugging Face provides detailed documentation and tutorials, making it an excellent resource for both beginners and experienced practitioners.</li></ul></li>
			</ul>
			<p>While catching up with the newest developments, I found it is also important to stay focused and curious:</p>
			<ul>
				<li><strong class="bold">Maintain focus</strong>: It’s crucial for us to stay focused on current tasks or projects without getting too distracted by the latest AI advancements. While it’s important to keep up with industry trends, constantly shifting focus can lead to incomplete projects or a lack of depth in understanding. Here are a few strategies to maintain focus:<ul><li><strong class="bold">Prioritize learning</strong>: Identify what you need to learn right now for your project or career goals and focus on that.</li><li><strong class="bold">Set specific learning goals</strong>: Having clear objectives can help you stay on track.</li><li><strong class="bold">Allocate time for exploration</strong>: Set aside a specific time each week to explore new advancements. This way, you can satisfy your curiosity without derailing your focus.</li></ul></li>
				<li><strong class="bold">Stay curious while avoiding being overwhelmed</strong>: It’s essential to stay curious and open to new ideas and technologies in AI, but it’s equally important to manage this curiosity to avoid feeling overwhelmed. Here are four tips to do so:<ul><li><strong class="bold">Embrace a growth mindset</strong>: Understand<a id="_idIndexMarker679"/> that learning is a journey and it’s okay not to know everything right now.</li><li><strong class="bold">Use multiple learning methods</strong>: If one method is overwhelming, try another. For example, if reading research papers is too dense, try watching video lectures or participating in online courses. Alternatively, simply ask a large language model such as ChatGPT for help.</li><li><strong class="bold">Create a learning schedule</strong>: Plan your learning to ensure you have time to digest new information. Instead of cloning a repo immediately, make a note to schedule a time for it.</li><li><strong class="bold">Seek support</strong>: Join AI<a id="_idIndexMarker680"/> communities, forums, or discussions where you can ask questions and share your learning journey with others. This can make the learning process less daunting.</li></ul></li>
			</ul>
			<p>Balance is key when learning AI. It’s about finding the right blend of focus and curiosity<a id="_idTextAnchor450"/> that works for you.</p>
			<h1 id="_idParaDest-269"><a id="_idTextAnchor451"/>Cultivating responsible, ethical, private, and secure AI</h1>
			<p>As we <a id="_idIndexMarker681"/>move forward, AI will become an integral part of our lives, permeating nearly every aspect of our existence, much like electricity and the internet. Initially, these technologies were perceived as novelties, even potentially dangerous. High-voltage alternating current posed a lethal threat, while the internet became a conduit for misinformation. Despite these initial fears, we managed to mitigate the negative aspects of these technologies, harnessing their potential for the greater good.</p>
			<p>When groundbreaking technology emerges, it is almost impossible to suppress its spread. Instead of restricting access to these advancements, we should aim to integrate them responsibly into our lives.</p>
			<p>AI is no exception. Instances of AI being used for deceptive or fraudulent purposes are not uncommon. As AI becomes more democratized, powerful AI tools will become more accessible to everyone. The challenge lies in managing the potential misuse of AI. Much like a knife, which can be used to both prepare food and cause harm, the impact of AI largely depends on the user.</p>
			<p>To prepare for an AI-driven world, we need to increase our understanding of AI, its capabilities, and its limitations. We must learn to use it appropriately and instill ethical and moral values in ourselves and future generations. If possible, we should also establish laws governing its use.</p>
			<p>As AI developers, it’s crucial to maintain transparency in AI technology. When a large company releases a model that can generate harmful content, such as extreme rhetoric or excessive political correctness, an open community can voice concerns and initiate corrective measures. The same level of AI technology can be used to counteract these issues, essentially fighting fire with fire.</p>
			<p>In Stable Diffusion v1.5, a OpenAI CLIP (Contrastive Language-Image Pre-Training)-based safety checker model is available to ensure output is harmless. This model can perform this task automatically and effectively. Stable Diffusion XL also includes a watermarking module, which can embed hard-to-see watermarks in image backgrounds. This feature can protect image authorship by adding specific hidden information. If we keep AI technology open, we can always find ways to balance power and ensure that AI is used for the greater good.</p>
			<p>We are at the dawn of a new era, where AI will change the way we live, work, and interact with each other. It’s up to us to make sure this transformation brings about positive growth and development, by embracing AI and working together. But there is one thing that <a id="_idIndexMarker682"/>keeps haunting us – what if A<a id="_idTextAnchor452"/>I takes our jobs away?</p>
			<h1 id="_idParaDest-270"><a id="_idTextAnchor453"/>Our evolving relationship with AI</h1>
			<p>On April 24, 1907, lamplighters<a id="_idIndexMarker683"/> in New York City went on strike [6], leaving many streets unlit. Despite complaints from citizens and efforts from policemen, few lamps were successfully lit due to various challenges. This event marked a significant shift toward electric streetlights, which were simpler to maintain and had begun to replace gas lamps since their introduction in the late 19th century.</p>
			<p>By 1927, electric streetlights had completely taken over, leading to the disappearance of the lamplighters’ profession and the Lamplighters Union. The electrification process was unstoppable, no matter how unwilling the public and lamplighters were to adopt it.</p>
			<p>And AI is the new electric streetlight; it can be creative, it can be fully automated, it can work on one or several things well, and it may surpass human capabilities. Yes, the AI electric streetlights will replace the old gas lights that we are so used to and carefully maintain. So, will the lamplighters’ job be eliminated by the “AI” electric streetlight?</p>
			<p>Well, I’m afraid that, this time, it’s not so easy to move from gas lamp maintenance to electric lamp maintenance. However, the “AI” electric streetlights are not just replacing jobs but also creating a lot more. And the most important thing is that those jobs created by AI are much more interesting and meaningful than the ones before. To be honest, do we truly enjoy jobs that involve repetitive, mundane tasks, like those once performed by lamplighters? AI will replace boring work and free more of our brain power to explore more interesting, exciting areas that no one has done before. Let’s embrace the change, welcome the AI electric streetlights, and start our jour<a id="_idTextAnchor454"/>ney with them together!</p>
			<h1 id="_idParaDest-271"><a id="_idTextAnchor455"/>Summary</h1>
			<p>This chapter discussed topics beyond the scope of Stable Diffusion, focusing on the broader context of AI development and its implications for society. Here’s a quick summary of the main points:</p>
			<ul>
				<li>The current AI wave is unique because it utilizes attention-based auto-learning architectures, enabling models to transfer knowledge across domains</li>
				<li>Mathematics and programming skills remain essential for AI development, as they form the foundation of AI algorithms and enable researchers to build upon existing knowledge</li>
				<li>You need to stay informed about the latest AI developments through channels such as following paper authors, using X (Twitter), executing GitHub <code>pull</code> commands, and visiting useful websites</li>
				<li>Develop responsible, ethical, privacy-protected, and safe AI by promoting transparency, addressing potential misuse, and educating users about AI’s capabilities and limitations</li>
				<li>Embrace the transformative power of AI, recognizing that it may replace some jobs but will also create new opportunities for more interesting and meaningful work</li>
			</ul>
			<p>By exploring these topics, we can better understand the role of AI in our lives and contribute to its responsible development for t<a id="_idTextAnchor456"/>he benefit of everyone.</p>
			<h1 id="_idParaDest-272"><a id="_idTextAnchor457"/>References</h1>
			<ol>
				<li>AlphaGo: <a href="https://en.wikipedia.org/wiki/AlphaGo">https://en.wikipedia.org/wiki/AlphaGo</a></li>
				<li>Attention Is All You Need: <a href="https://arxiv.org/abs/1706.03762">https://arxiv.org/abs/1706.03762</a></li>
				<li>An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale: <a href="https://arxiv.org/abs/2010.11929">https://arxiv.org/abs/2010.11929</a></li>
				<li>Swin Transformer: Hierarchical Vision Transformer using Shifted Windows: <a href="https://arxiv.org/abs/2103.14030">https://arxiv.org/abs/2103.14030</a></li>
				<li>Richard Feynman’s blackboard at the time of his death: <a href="https://digital.archives.caltech.edu/collections/Images/1.10-29/">https://digital.archives.caltech.edu/collections/Images/1.10-29/</a></li>
				<li>LAMPLIGHTERS QUIT; CITY DARK IN SPOTS; Police Reserves Out in Harlem to Set the Gas Lamps Going. UNION CALLS OUT 400 MEN Only Formed a Short Time Ago, Whereupon the Gas Company Began Dismissals: <a href="https://www.nytimes.com/1907/04/25/archives/lamplighters-quit-city-dark-in-spots-police-reserves-out-in-harlem.html">https://www.nytimes.com/1907/04/25/archives/lamplighters-quit-city-dark-in-spots-police-reserves-out-in-harlem.html</a></li>
				<li>Richard Feynman: <a href="https://en.wikipedia.org/wiki/Richard_Feynman">https://en.wikipedia.org/wiki/Richard_Feynman</a></li>
			</ol>
		</div>
	</body></html>