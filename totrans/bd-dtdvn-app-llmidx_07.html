<html><head></head><body><html>&#13;
 <head>&#13;
  <title>&#13;
   Querying Our Data, Part 1 – Context Retrieval&#13;
  </title>&#13;
 </head>&#13;
 <body>&#13;
  <p>&#13;
   <h1 id="_idParaDest-133">&#13;
    Querying Our Data, Part 1 – Context Retrieval&#13;
   </h1>&#13;
   <div>&#13;
    <p>&#13;
     The focus of this chapter will be on understanding the querying capabilities of LlamaIndex in an RAG workflow. We’ll be covering the overall working of the querying system, mostly focusing on the retrieval capabilities of&#13;
     &#13;
      the framework.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     Here are the main sections that will be covered in&#13;
     &#13;
      this chapter:&#13;
     &#13;
    </p>&#13;
    <ul>&#13;
     <li>&#13;
      Learning about query mechanics –&#13;
      &#13;
       an overview&#13;
      &#13;
     </li>&#13;
     <li>&#13;
      Understanding the&#13;
      &#13;
       basic retrievers&#13;
      &#13;
     </li>&#13;
     <li>&#13;
      Building more advanced&#13;
      &#13;
       retrieval mechanisms&#13;
      &#13;
     </li>&#13;
     <li>&#13;
      Increasing efficiency with&#13;
      &#13;
       asynchronous retrieval&#13;
      &#13;
     </li>&#13;
     <li>&#13;
      Working with metadata filters, tools,&#13;
      &#13;
       and selectors&#13;
      &#13;
     </li>&#13;
     <li>&#13;
      Transforming queries and&#13;
      &#13;
       generating sub-queries&#13;
      &#13;
     </li>&#13;
     <li>&#13;
      Understanding the concepts of dense and&#13;
      &#13;
       sparse retrieval&#13;
      &#13;
     </li>&#13;
    </ul>&#13;
    <a id="_idTextAnchor133">&#13;
    </a>&#13;
   </p>&#13;
  </div>&#13;
 </body>&#13;
</html>
<html>&#13;
 <head>&#13;
  <title>&#13;
   Technical requirements&#13;
  </title>&#13;
 </head>&#13;
 <body>&#13;
  <p>&#13;
   <h1 id="_idParaDest-134">&#13;
    Technical requirements&#13;
   </h1>&#13;
   <div>&#13;
    <p>&#13;
     For this chapter, you will need to install the&#13;
     <code class="literal">&#13;
      Rank-BM25&#13;
     </code>&#13;
     package in your environment. You can find it&#13;
     &#13;
      at&#13;
     &#13;
     <a>&#13;
      &#13;
       https://pypi.org/project/rank-bm25/&#13;
      &#13;
     </a>&#13;
     &#13;
      .&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     Two additional integration packages are required to run the&#13;
     &#13;
      sample code:&#13;
     &#13;
    </p>&#13;
    <ul>&#13;
     <li>&#13;
      <em class="italic">&#13;
       OpenAI Question&#13;
      </em>&#13;
      &#13;
       <em class="italic">&#13;
        Generator&#13;
       </em>&#13;
      &#13;
      &#13;
       :&#13;
      &#13;
      <a>&#13;
       &#13;
        https://pypi.org/project/llama-index-question-gen-openai/&#13;
       &#13;
      </a>&#13;
     </li>&#13;
     <li>&#13;
      <em class="italic">&#13;
       BM25&#13;
      </em>&#13;
      &#13;
       <em class="italic">&#13;
        Retriever&#13;
       </em>&#13;
      &#13;
      &#13;
       :&#13;
      &#13;
      <a>&#13;
       &#13;
        https://pypi.org/project/llama-index-retrievers-bm25/&#13;
       &#13;
      </a>&#13;
     </li>&#13;
     <li>&#13;
      All the code samples for this chapter can be found in the ch6 subfolder of this book’s GitHub&#13;
      &#13;
       repository:&#13;
      &#13;
      <a>&#13;
       &#13;
        https://github.com/PacktPublishing/Building-Data-Driven-Applications-with-LlamaIndex&#13;
       &#13;
      </a>&#13;
      &#13;
       .&#13;
      &#13;
     </li>&#13;
    </ul>&#13;
    <a id="_idTextAnchor134">&#13;
    </a>&#13;
   </p>&#13;
  </div>&#13;
 </body>&#13;
</html>
<html>&#13;
 <head>&#13;
  <title>&#13;
   Learning about query mechanics – an overview&#13;
  </title>&#13;
 </head>&#13;
 <body>&#13;
  <p>&#13;
   <h1 id="_idParaDest-135">&#13;
    Learning about query mechanics – an overview&#13;
   </h1>&#13;
   <div>&#13;
    <p>&#13;
     In this chapter, we will finally begin to reap the fruits of our work so far. Document ingestion, parsing and segmenting, metadata extraction, and index building were all just preparatory steps for what we are about to&#13;
     <a id="_idIndexMarker516">&#13;
     </a>&#13;
     discuss:&#13;
     <strong class="bold">&#13;
      querying&#13;
     </strong>&#13;
     . At the heart of any RAG workflow is the idea of being able to bring relevant context into the prompt we use in the LLM query. So far, we have been concerned with constructing and organizing this context, but now, it is time to&#13;
     <a id="_idIndexMarker517">&#13;
     </a>&#13;
     use it and extract the best possible answers from our interactions with LLMs. In the following sections, we will discuss various techniques that LlamaIndex provides us for the query part. As usual, we will start with the simplest&#13;
     <a id="_idIndexMarker518">&#13;
     </a>&#13;
     query methods – called&#13;
     <em class="italic">&#13;
      naive&#13;
     </em>&#13;
     methods in jargon – and then discuss more advanced&#13;
     &#13;
      query variants.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     First, we need to&#13;
     <a id="_idIndexMarker519">&#13;
     </a>&#13;
     understand the&#13;
     <a id="_idIndexMarker520">&#13;
     </a>&#13;
     typical steps in the query&#13;
     <a id="_idIndexMarker521">&#13;
     </a>&#13;
     process:&#13;
     <strong class="bold">&#13;
      retrieval&#13;
     </strong>&#13;
     ,&#13;
     <strong class="bold">&#13;
      postprocessing&#13;
     </strong>&#13;
     , and&#13;
     &#13;
      <strong class="bold">&#13;
       response synthesis&#13;
      </strong>&#13;
     &#13;
     &#13;
      .&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     In&#13;
     <a>&#13;
      &#13;
       <em class="italic">&#13;
        Chapter 3&#13;
       </em>&#13;
      &#13;
     </a>&#13;
     <em class="italic">&#13;
      ,&#13;
     </em>&#13;
     <em class="italic">&#13;
      Kickstarting Your Journey with LlamaIndex&#13;
     </em>&#13;
     , in the&#13;
     <em class="italic">&#13;
      Indexes&#13;
     </em>&#13;
     section, we discussed the simplest way to go through the three steps – using&#13;
     <code class="literal">&#13;
      QueryEngine&#13;
     </code>&#13;
     but built very simply by running&#13;
     <code class="literal">&#13;
      index.as_query_engine()&#13;
     </code>&#13;
     . This is very simple but not necessarily always effective as this&#13;
     <em class="italic">&#13;
      naive&#13;
     </em>&#13;
     way of querying an index is just the tip of the iceberg. We will now explore the three mechanisms individually and understand how they work and the customizable options&#13;
     &#13;
      they offer.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     First, we’ll focus&#13;
     &#13;
      on&#13;
     &#13;
     &#13;
      <strong class="bold">&#13;
       retrievers&#13;
      </strong>&#13;
     &#13;
     &#13;
      .&#13;
     &#13;
    </p>&#13;
    <a id="_idTextAnchor135">&#13;
    </a>&#13;
   </p>&#13;
  </div>&#13;
 </body>&#13;
</html>
<html>&#13;
 <head>&#13;
  <title>&#13;
   Understanding the basic retrievers&#13;
  </title>&#13;
 </head>&#13;
 <body>&#13;
  <p>&#13;
   <h1 id="_idParaDest-136">&#13;
    Understanding the basic retrievers&#13;
   </h1>&#13;
   <div>&#13;
    from llama_index.core import SummaryIndex, SimpleDirectoryReader&#13;
documents = SimpleDirectoryReader("files").load_data()&#13;
summary_index = SummaryIndex.from_documents(documents)&#13;
retriever = summary_index.as_retriever(&#13;
    retriever_mode='embedding'&#13;
)&#13;
result = retriever.retrieve("Tell me about ancient Rome")&#13;
print(result[0].text)&#13;
    from llama_index.core import SummaryIndex, SimpleDirectoryReader&#13;
from llama_index.core.retrievers import SummaryIndexEmbeddingRetriever&#13;
documents = SimpleDirectoryReader("files").load_data()&#13;
summary_index = SummaryIndex.from_documents(documents)&#13;
retriever = SummaryIndexEmbeddingRetriever(&#13;
    index=summary_index&#13;
)&#13;
result = retriever.retrieve("Tell me about ancient Rome")&#13;
print(result[0].text)&#13;
    VectorStoreIndex.as_retriever()&#13;
    SummaryIndex.as_retriever(retriever_mode = 'default')&#13;
    SummaryIndex.as_retriever(retriever_mode='embedding')&#13;
    SummaryIndex.as_retriever(retriever_mode='llm')&#13;
    DocumentSummaryIndex.as_retriever(retriever_mode='llm')&#13;
    DocumentSummaryIndex.as_retriever(&#13;
    retriever_mode='embedding'&#13;
)&#13;
    TreeIndex.as_retriever(retriever_mode='select_leaf').&#13;
    TreeIndex.as_retriever(&#13;
    retriever_mode='select_leaf_embedding'&#13;
)&#13;
    TreeIndex.as_retriever(retriever_mode='all_leaf')&#13;
    TreeIndex.as_retriever(retriever_mode='root')&#13;
    KeywordTableIndex.as_retriever(retriever_mode='default')&#13;
    KeywordTableIndex.as_retriever(retriever_mode='simple')&#13;
    KeywordTableIndex.as_retriever(retriever_mode='rake')&#13;
    KnowledgeGraphIndex.as_retriever(retriever_mode='keyword')&#13;
    KnowledgeGraphIndex.as_retriever(&#13;
    retriever_mode='embedding'&#13;
)&#13;
    KnowledgeGraphIndex.as_retriever(retriever_mode='hybrid')&#13;
    import asyncio&#13;
from llama_index.core import KeywordTableIndex&#13;
from llama_index.core import SimpleDirectoryReader&#13;
async def retrieve(retriever, query, label):&#13;
    response = await retriever.aretrieve(query)&#13;
    print(f"{label} retrieved {str(len(response))} nodes")&#13;
async def main():&#13;
    reader = SimpleDirectoryReader('files')&#13;
    documents = reader.load_data()&#13;
    index = KeywordTableIndex.from_documents(documents)&#13;
    retriever1 = index.as_retriever(&#13;
retriever_mode='default'&#13;
)&#13;
    retriever2 = index.as_retriever(&#13;
        retriever_mode='simple'&#13;
)&#13;
    query = "Where is the Colosseum?"&#13;
    await asyncio.gather(&#13;
        retrieve(retriever1, query, '&lt;llm&gt;'),&#13;
        retrieve(retriever2, query, '&lt;simple&gt;')&#13;
    )&#13;
asyncio.run(main())&#13;
    <p>&#13;
     <strong class="bold">&#13;
      Retrieval mechanisms&#13;
     </strong>&#13;
     are a central&#13;
     <a id="_idIndexMarker522">&#13;
     </a>&#13;
     element in any RAG system. Although they work in different ways, all&#13;
     <a id="_idIndexMarker523">&#13;
     </a>&#13;
     types of retrievers are based on the same principle: they browse an index and select the relevant nodes to build the necessary context. Each index type offers several retrieval modes, each providing different features and customization options. Regardless of the retriever type, the result that will be returned is in the form of a&#13;
     <code class="literal">&#13;
      NodeWithScore&#13;
     </code>&#13;
     object – a structure that combines a node with an associated score. The score can be useful further in the RAG flow because it allows us to sort the returned nodes according to their relevance. However, keep in mind that while all retrievers return&#13;
     <code class="literal">&#13;
      NodeWithScore&#13;
     </code>&#13;
     , not all of them&#13;
     <a id="_idIndexMarker524">&#13;
     </a>&#13;
     associate a specific&#13;
     &#13;
      node score.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     As usual, LlamaIndex offers multiple alternatives to accomplish a task, so a retriever can be constructed in several&#13;
     <a id="_idIndexMarker525">&#13;
     </a>&#13;
     ways. The simplest path is direct construction from an&#13;
     <code class="literal">&#13;
      Index&#13;
     </code>&#13;
     object. Assuming that we have already dealt with document ingestion, the following code builds an index and then builds a retriever based on the structure of&#13;
     &#13;
      the index:&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     In the previous example, the generated retriever is of the&#13;
     <code class="literal">&#13;
      SummaryIndexRetriever&#13;
     </code>&#13;
     type. This is the default retriever for&#13;
     &#13;
      this index.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     The second option is direct instantiation, as shown in the&#13;
     &#13;
      following example:&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     In the next section, we’ll go through a list of retrieval options that are available for each index type. Next to each retriever type, I’ve specified how it can be instantiated from the corresponding index. I warn you&#13;
     <a id="_idIndexMarker526">&#13;
     </a>&#13;
     now that a lot of information has been condensed in the next section. However, it is useful information that you can bookmark and come back to later when you start&#13;
     <a id="_idIndexMarker527">&#13;
     </a>&#13;
     building real applications with the&#13;
     &#13;
      LlamaIndex framework.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     So, here’s the list of retrievers for each type&#13;
     &#13;
      of index.&#13;
     &#13;
    </p>&#13;
    <a id="_idTextAnchor136">&#13;
    </a>&#13;
    <h2 id="_idParaDest-137">&#13;
     The VectorStoreIndex retrievers&#13;
    </h2>&#13;
    <p>&#13;
     We have two retriever&#13;
     <a id="_idIndexMarker528">&#13;
     </a>&#13;
     options available for this index. Let’s have a look at how&#13;
     <a id="_idIndexMarker529">&#13;
     </a>&#13;
     they work and how to customize them for different&#13;
     &#13;
      use cases.&#13;
     &#13;
    </p>&#13;
    <h3>&#13;
     VectorIndexRetriever&#13;
    </h3>&#13;
    <p>&#13;
     The default retriever that’s used by&#13;
     <code class="literal">&#13;
      VectorStoreIndex&#13;
     </code>&#13;
     is&#13;
     <code class="literal">&#13;
      VectorIndexRetriever&#13;
     </code>&#13;
     . It can easily be&#13;
     <a id="_idIndexMarker530">&#13;
     </a>&#13;
     constructed using the&#13;
     &#13;
      following command:&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     As expected, since&#13;
     <code class="literal">&#13;
      VectorStoreIndex&#13;
     </code>&#13;
     is one of the most sophisticated and widely used indexes, this retriever is&#13;
     &#13;
      also complex.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     &#13;
      <em class="italic">&#13;
       Figure 6&#13;
      </em>&#13;
     &#13;
     <em class="italic">&#13;
      .1&#13;
     </em>&#13;
     exemplifies its&#13;
     &#13;
      operating mode:&#13;
     &#13;
    </p>&#13;
    <div>&#13;
     <div>&#13;
      <img src="img/B21861_06_1.jpg"/>&#13;
     </p>&#13;
    </div>&#13;
    <p class="IMG---Caption" lang="en-US">&#13;
     Figure 6.1 – Node retrieval using VectorIndexRetriever&#13;
    </p>&#13;
    <p>&#13;
     This retriever operates by converting queries into vectors and then performing&#13;
     <em class="italic">&#13;
      similarity-based&#13;
     </em>&#13;
     searches in the vector&#13;
     <a id="_idIndexMarker531">&#13;
     </a>&#13;
     space. Several parameters can be customized for different&#13;
     &#13;
      use cases:&#13;
     &#13;
    </p>&#13;
    <ul>&#13;
     <li>&#13;
      <code class="literal">&#13;
       similarity_top_k&#13;
      </code>&#13;
      : This defines the number of&#13;
      <em class="italic">&#13;
       top (k)&#13;
      </em>&#13;
      results returned by the retriever. This determines how many of the most similar results are returned for each query. For example, if we want a broader search, we can change the default value, which&#13;
      &#13;
       is&#13;
      &#13;
      &#13;
       <code class="literal">&#13;
        2&#13;
       </code>&#13;
      &#13;
      &#13;
       .&#13;
      &#13;
     </li>&#13;
     <li>&#13;
      <code class="literal">&#13;
       vector_store_query_mode&#13;
      </code>&#13;
      : This sets the query mode of the vector store. Different variants of external vector stores, such as&#13;
      <em class="italic">&#13;
       Pinecone&#13;
      </em>&#13;
      (&#13;
      <a>&#13;
       https://www.pinecone.io/&#13;
      </a>&#13;
      ),&#13;
      <em class="italic">&#13;
       OpenSearch&#13;
      </em>&#13;
      (&#13;
      <a>&#13;
       https://opensearch.org/&#13;
      </a>&#13;
      ), and others, support different query modes. This is the mechanism by which we can make best use of their&#13;
      &#13;
       search capabilities.&#13;
      &#13;
     </li>&#13;
     <li>&#13;
      <code class="literal">&#13;
       filters&#13;
      </code>&#13;
      : Remember that in&#13;
      &#13;
       <em class="italic">&#13;
        Chapter 3&#13;
       </em>&#13;
      &#13;
      , in the&#13;
      <em class="italic">&#13;
       Nodes&#13;
      </em>&#13;
      section, we saw how to add metadata to our nodes? Well, we can use this metadata to narrow down the search scope of the retriever. We will see a practical example of this in this chapter, where we will use metadata filters to implement a simple system for filtering nodes returned by&#13;
      &#13;
       an index.&#13;
      &#13;
     </li>&#13;
     <li>&#13;
      <code class="literal">&#13;
       alpha&#13;
      </code>&#13;
      : This one is useful when using a hybrid search mode (a combination of sparse and&#13;
      <strong class="bold">&#13;
       dense search&#13;
      </strong>&#13;
      ). We will&#13;
      <a id="_idIndexMarker532">&#13;
      </a>&#13;
      discuss the difference between sparse and dense search in more detail later in&#13;
      &#13;
       this chapter.&#13;
      &#13;
     </li>&#13;
     <li>&#13;
      <code class="literal">&#13;
       sparse_top_k&#13;
      </code>&#13;
      : The number of top&#13;
      <a id="_idIndexMarker533">&#13;
      </a>&#13;
      results for the&#13;
      <strong class="bold">&#13;
       sparse search&#13;
      </strong>&#13;
      . This is relevant in hybrid search modes. The previous mention applies&#13;
      &#13;
       here also.&#13;
      &#13;
     </li>&#13;
     <li>&#13;
      <code class="literal">&#13;
       doc_ids&#13;
      </code>&#13;
      : Similar to metadata filters, but slightly coarser,&#13;
      <code class="literal">&#13;
       doc_ids&#13;
      </code>&#13;
      can be used to restrict the search to a specific subset of documents. For example, suppose the organization uses a&#13;
      <a id="_idIndexMarker534">&#13;
      </a>&#13;
      common knowledge base that is shared by all departments. At the same time, however, the organization has a clear naming convention for documents. If the department’s name or code is found in the document name, we could use this parameter to limit a user’s query to documents in their&#13;
      &#13;
       department only.&#13;
      &#13;
     </li>&#13;
     <li>&#13;
      <code class="literal">&#13;
       node_ids&#13;
      </code>&#13;
      : This parameter is similar to&#13;
      <code class="literal">&#13;
       doc_ids&#13;
      </code>&#13;
      but refers to node IDs within the index. This can give us even more granular control over the information that’s returned by&#13;
      &#13;
       the retriever.&#13;
      &#13;
     </li>&#13;
     <li>&#13;
      <code class="literal">&#13;
       vector_store_kwargs&#13;
      </code>&#13;
      : This parameter can pass additional arguments that are specific to each vector store so that they can be sent at&#13;
      &#13;
       query time.&#13;
      &#13;
     </li>&#13;
    </ul>&#13;
    <p>&#13;
     As a secure design principle, security should be implemented as early as possible in the life cycle of an application. This is also true for an RAG application. For example, if we want to better control access to information, we should filter the information that’s processed by the application as early as possible. In an RAG flow, which means from the moment it is retrieved – if not earlier. There are ways to filter the information later in the query engine – for example, in post-processing or even in response synthesis – but it is much easier not to introduce risks in the first place by introducing information into the flow that is outside the user’s security context. There is also a cost issue. Since much of the processing in an RAG flow is based on LLM ingestion, the less information we process, the lower&#13;
     &#13;
      the cost.&#13;
     &#13;
    </p>&#13;
    <h3>&#13;
     VectorIndexAutoRetriever&#13;
    </h3>&#13;
    <p>&#13;
     All the parameters we discussed earlier regarding&#13;
     <code class="literal">&#13;
      VectorIndexRetriever&#13;
     </code>&#13;
     are very useful when we know exactly what we are looking for and understand the structure of the data very well. Unfortunately, in some situations, we will be dealing with complex structures or ambiguities in the&#13;
     &#13;
      indexed data.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     <code class="literal">&#13;
      VectorIndexAutoRetriever&#13;
     </code>&#13;
     is a more advanced form of retriever that can use an LLM to automatically set query parameters in a vector store based on a natural language description of the content and supporting metadata. This is particularly useful when users are unfamiliar with the&#13;
     <a id="_idIndexMarker535">&#13;
     </a>&#13;
     structure of the data or do not know how to formulate an effective query. In these situations, this retriever can transform vague or unclear queries into more structured queries and better leverage the capabilities of the vector store, thus increasing the chances of finding relevant results. Since a detailed discussion of this mechanism would take several pages and I am probably digressing too much from the main topic, if you want to learn more about how it works, I suggest that you consult the official documentation&#13;
     &#13;
      at&#13;
     &#13;
     <a>&#13;
      &#13;
       https://docs.llamaindex.ai/en/stable/examples/vector_stores/elasticsearch_auto_retriever.html&#13;
      &#13;
     </a>&#13;
     &#13;
      .&#13;
     &#13;
    </p>&#13;
    <h3>&#13;
     The SummaryIndex retrievers&#13;
    </h3>&#13;
    <p>&#13;
     There are three retriever options available for this&#13;
     <a id="_idIndexMarker536">&#13;
     </a>&#13;
     index. Let’s take&#13;
     &#13;
      a look.&#13;
     &#13;
    </p>&#13;
    <h3>&#13;
     SummaryIndexRetriever&#13;
    </h3>&#13;
    <p>&#13;
     This retriever can be built using the&#13;
     <a id="_idIndexMarker537">&#13;
     </a>&#13;
     &#13;
      following command:&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     This is the default retriever for&#13;
     <code class="literal">&#13;
      SummaryIndex&#13;
     </code>&#13;
     . As seen in&#13;
     &#13;
      <em class="italic">&#13;
       Figure 6&#13;
      </em>&#13;
     &#13;
     <em class="italic">&#13;
      .2&#13;
     </em>&#13;
     , it has a very simple approach – it returns all nodes in the index without applying any filtering&#13;
     &#13;
      or sorting:&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     <div>&#13;
      <img src="img/B21861_06_2.jpg"/>&#13;
     </p>&#13;
    </div>&#13;
    <p class="IMG---Caption" lang="en-US">&#13;
     Figure 6.2 – Retrieving nodes using SummaryIndexRetriever&#13;
    </p>&#13;
    <p>&#13;
     This is useful when we want to&#13;
     <a id="_idIndexMarker538">&#13;
     </a>&#13;
     get a complete view of the data in the index, without having to filter or sort the results. No relevance score is returned for&#13;
     &#13;
      the nodes.&#13;
     &#13;
    </p>&#13;
    <h3>&#13;
     SummaryIndexEmbeddingRetriever&#13;
    </h3>&#13;
    <p>&#13;
     We can build this one with the&#13;
     <a id="_idIndexMarker539">&#13;
     </a>&#13;
     &#13;
      following command:&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     This retriever relies on embeddings to retrieve nodes from&#13;
     <code class="literal">&#13;
      SummaryIndex&#13;
     </code>&#13;
     . While&#13;
     <code class="literal">&#13;
      SummaryIndex&#13;
     </code>&#13;
     itself stores nodes in plain text, this retriever uses an embedding model to convert these plain text nodes into embeddings when a query is made. Have a look at&#13;
     &#13;
      <em class="italic">&#13;
       Figure 6&#13;
      </em>&#13;
     &#13;
     <em class="italic">&#13;
      .3&#13;
     </em>&#13;
     to get a better view of its&#13;
     &#13;
      operating mode:&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     <div>&#13;
      <img src="img/B21861_06_3.jpg"/>&#13;
     </p>&#13;
    </div>&#13;
    <p class="IMG---Caption" lang="en-US">&#13;
     Figure 6.3 – Inner workings of SummaryIndexEmbeddingRetriever&#13;
    </p>&#13;
    <p>&#13;
     The embeddings are created dynamically as needed for retrieval, rather than being stored persistently with the index. The&#13;
     <code class="literal">&#13;
      similarity_top_k&#13;
     </code>&#13;
     parameter determines the number of nodes&#13;
     <a id="_idIndexMarker540">&#13;
     </a>&#13;
     to return, based on their similarity to the query. This retriever is useful for finding the most relevant nodes concerning a given query by using&#13;
     &#13;
      similarity computation.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     For each selected node, the retriever calculates a similarity score – based on embeddings – which is then returned alongside the node as&#13;
     <code class="literal">&#13;
      NodeWithScore&#13;
     </code>&#13;
     . This score is a reflection of the extent to which each node corresponds to&#13;
     &#13;
      the query.&#13;
     &#13;
    </p>&#13;
    <h3>&#13;
     SummaryIndexLLMRetriever&#13;
    </h3>&#13;
    <p>&#13;
     This retriever can be built using the&#13;
     <a id="_idIndexMarker541">&#13;
     </a>&#13;
     &#13;
      following command:&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     As its name suggests, this retriever uses an LLM to retrieve nodes from&#13;
     <code class="literal">&#13;
      SummaryIndex&#13;
     </code>&#13;
     . It uses a prompt to select the most relevant nodes. Check out&#13;
     &#13;
      <em class="italic">&#13;
       Figure 6&#13;
      </em>&#13;
     &#13;
     <em class="italic">&#13;
      .4&#13;
     </em>&#13;
     for an overview of&#13;
     &#13;
      its approach:&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     <div>&#13;
      <img src="img/B21861_06_4.jpg"/>&#13;
     </p>&#13;
    </div>&#13;
    <p class="IMG---Caption" lang="en-US">&#13;
     Figure 6.4 – SummaryIndexLLMRetriever in action&#13;
    </p>&#13;
    <p>&#13;
     If we wish, we can override the default prompt using the&#13;
     <code class="literal">&#13;
      choice_select_prompt&#13;
     </code>&#13;
     parameter. Queries are processed in&#13;
     <a id="_idIndexMarker542">&#13;
     </a>&#13;
     batches; the size of each batch is determined by the&#13;
     <code class="literal">&#13;
      choice_batch_size&#13;
     </code>&#13;
     parameter. Optionally, we can also provide the&#13;
     <code class="literal">&#13;
      format_node_batch_fn&#13;
     </code>&#13;
     and&#13;
     <code class="literal">&#13;
      parse_choice_select_answer_fn&#13;
     </code>&#13;
     functions as parameters. These are used to format the batch of nodes and parse the LLM responses. The&#13;
     <code class="literal">&#13;
      parse_choice_select_answer_fn&#13;
     </code>&#13;
     function is also responsible for calculating node-specific relevance scores. The scores are determined by parsing the LLM responses. These scores are then associated with the corresponding nodes and returned as&#13;
     <code class="literal">&#13;
      NodeWithScore&#13;
     </code>&#13;
     . If we don’t want to use the default LLM, that’s not a problem: the retriever accepts&#13;
     <code class="literal">&#13;
      service_context&#13;
     </code>&#13;
     as a parameter. In&#13;
     &#13;
      Chapter 3&#13;
     &#13;
     , we saw how to customize the default LLM&#13;
     &#13;
      using&#13;
     &#13;
     &#13;
      <code class="literal">&#13;
       ServiceContext&#13;
      </code>&#13;
     &#13;
     &#13;
      .&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     This type of retriever is useful in complex search systems where LLMs can provide contextual and detailed answers&#13;
     &#13;
      to queries.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     Next, we’ll talk about retrievers&#13;
     &#13;
      for&#13;
     &#13;
     &#13;
      <code class="literal">&#13;
       DocumentSummaryIndex&#13;
      </code>&#13;
     &#13;
     &#13;
      .&#13;
     &#13;
    </p>&#13;
    <a id="_idTextAnchor137">&#13;
    </a>&#13;
    <h2 id="_idParaDest-138">&#13;
     The DocumentSummaryIndex retrievers&#13;
    </h2>&#13;
    <p>&#13;
     For this index, we only have&#13;
     <a id="_idIndexMarker543">&#13;
     </a>&#13;
     two retrieval options. Let’s&#13;
     <a id="_idIndexMarker544">&#13;
     </a>&#13;
     take&#13;
     &#13;
      a look.&#13;
     &#13;
    </p>&#13;
    <h3>&#13;
     DocumentSummaryIndexLLMRetriever&#13;
    </h3>&#13;
    <p>&#13;
     We can build this with the&#13;
     &#13;
      following command:&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     This retriever uses an&#13;
     <a id="_idIndexMarker545">&#13;
     </a>&#13;
     LLM to select relevant summaries from an index of document summaries. You can get a better understanding of how it works by looking at&#13;
     &#13;
      <em class="italic">&#13;
       Figure 6&#13;
      </em>&#13;
     &#13;
     &#13;
      <em class="italic">&#13;
       .5&#13;
      </em>&#13;
     &#13;
     &#13;
      :&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     <div>&#13;
      <img src="img/B21861_06_5.jpg"/>&#13;
     </p>&#13;
    </div>&#13;
    <p class="IMG---Caption" lang="en-US">&#13;
     Figure 6.5 – How DocumentSummaryIndexLLMRetriever works&#13;
    </p>&#13;
    <p>&#13;
     This retriever processes queries in batches, with each batch containing a specified number of nodes to send to the LLM for evaluation. The&#13;
     <code class="literal">&#13;
      choice_batch_size&#13;
     </code>&#13;
     parameter can be used to specify the size of a batch. The retriever can use a custom prompt provided via the&#13;
     <code class="literal">&#13;
      choice_select_prompt&#13;
     </code>&#13;
     parameter to determine the relevance of the abstracts to the query. Results are sorted by relevance and returned according to the number specified by&#13;
     <code class="literal">&#13;
      choice_top_k&#13;
     </code>&#13;
     . The&#13;
     <code class="literal">&#13;
      format_node_batch_fn&#13;
     </code>&#13;
     and&#13;
     <code class="literal">&#13;
      parse_choice_select_answer_fn&#13;
     </code>&#13;
     functions can also be specified as parameters. The first function,&#13;
     <code class="literal">&#13;
      format_node_batch_fn&#13;
     </code>&#13;
     , prepares the information from nodes in a format suitable for the LLM. This may include combining text from multiple nodes, structuring the information in a particular way, or adding contextual elements to help the LLM understand and evaluate the content. The second function,&#13;
     <code class="literal">&#13;
      parse_choice_select_answer_fn&#13;
     </code>&#13;
     , can, for example, determine which nodes are most relevant to the query and extract relevance scores or other metrics associated with each node. By analyzing the LLM response, this function allows the retriever to decide which nodes are most relevant to the user’s query. To summarize,&#13;
     <code class="literal">&#13;
      DocumentSummaryIndexLLMRetriever&#13;
     </code>&#13;
     is useful for retrieving useful data from a large number of documents using the natural language processing power of LLMs. As a useful side note, it is good to know that this retriever also returns the relevance score that is&#13;
     <a id="_idIndexMarker546">&#13;
     </a>&#13;
     associated with each of&#13;
     &#13;
      the nodes.&#13;
     &#13;
    </p>&#13;
    <p class="callout-heading">&#13;
     Additional observation&#13;
    </p>&#13;
    <p class="callout">&#13;
     During my experimentation with this type of retriever, I noticed that the relevance scores that are assigned to each node by the LLM were consistently high, often reaching the maximum value of 10 (tested using GPT3.5-Turbo). For applications where nuanced differentiation between degrees of relevance is crucial, it might be beneficial to adjust the prompt or apply post-processing to the LLM’s responses to achieve a more balanced and nuanced distribution of relevance scores. This issue also underscores the importance of tailoring LLM prompts and response handling to suit the specific needs and contexts of different applications. We’ll talk more about prompt customization in&#13;
     <a>&#13;
      &#13;
       <em class="italic">&#13;
        Chapter 10&#13;
       </em>&#13;
      &#13;
     </a>&#13;
     &#13;
      .&#13;
     &#13;
    </p>&#13;
    <h3>&#13;
     DocumentSummaryIndexEmbeddingRetriever&#13;
    </h3>&#13;
    <p>&#13;
     To build this retriever, we can use&#13;
     <a id="_idIndexMarker547">&#13;
     </a>&#13;
     the&#13;
     &#13;
      following code:&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     This retriever relies on embeddings to retrieve summary nodes from the index.&#13;
     &#13;
      <em class="italic">&#13;
       Figure 6&#13;
      </em>&#13;
     &#13;
     <em class="italic">&#13;
      .6&#13;
     </em>&#13;
     exemplifies&#13;
     &#13;
      its operation:&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     <div>&#13;
      <img src="img/B21861_06_5.jpg"/>&#13;
     </p>&#13;
    </div>&#13;
    <p class="IMG---Caption" lang="en-US">&#13;
     Figure 6.6 – DocumentSummaryIndexEmbeddingRetriever&#13;
    </p>&#13;
    <p>&#13;
     It computes the&#13;
     <a id="_idIndexMarker548">&#13;
     </a>&#13;
     embeddings for the query and then finds the summaries with the highest similarity to the query. For this method to work, the index should have been built with the&#13;
     <code class="literal">&#13;
      embed_summaries&#13;
     </code>&#13;
     parameters set to&#13;
     <code class="literal">&#13;
      True&#13;
     </code>&#13;
     . The&#13;
     <code class="literal">&#13;
      similarity_top_k&#13;
     </code>&#13;
     parameter specifies the number of summary nodes to return based on similarity. The retriever does not return a relevance score associated with&#13;
     &#13;
      each node.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     It is effective for finding the most relevant summaries relative to a given query, using similarity calculation techniques based&#13;
     &#13;
      on embeddings.&#13;
     &#13;
    </p>&#13;
    <a id="_idTextAnchor138">&#13;
    </a>&#13;
    <h2 id="_idParaDest-139">&#13;
     The TreeIndex retrievers&#13;
    </h2>&#13;
    <p>&#13;
     This is a more complex&#13;
     <a id="_idIndexMarker549">&#13;
     </a>&#13;
     index type that constructs a tree graph of nodes, as&#13;
     <a id="_idIndexMarker550">&#13;
     </a>&#13;
     we saw in&#13;
     <a>&#13;
      &#13;
       <em class="italic">&#13;
        Chapter 5&#13;
       </em>&#13;
      &#13;
     </a>&#13;
     <em class="italic">&#13;
      ,  Indexing with LlamaIndex&#13;
     </em>&#13;
     , in the&#13;
     <em class="italic">&#13;
      Other index types in&#13;
     </em>&#13;
     &#13;
      <em class="italic">&#13;
       LlamaIndex&#13;
      </em>&#13;
     &#13;
     &#13;
      section.&#13;
     &#13;
    </p>&#13;
    <p class="callout-heading">&#13;
     Important note&#13;
    </p>&#13;
    <p class="callout">&#13;
     <code class="literal">&#13;
      TreeIndex&#13;
     </code>&#13;
     , by its very nature, is designed to reflect hierarchical relationships within data, making it a great tool for scenarios where data is naturally organized in a tree-like structure, such as filesystems, organizational charts, or product categories. That being said, the LlamaIndex implementation of this structure is a tree of summaries about the data. Regardless of any existing structure in the initial document, this index builds a parallel hierarchical structure by chunking it down and creating summaries at each level of the tree. Because of the recursive nature of&#13;
     <code class="literal">&#13;
      TreeSelectLeafRetriever&#13;
     </code>&#13;
     and&#13;
     <code class="literal">&#13;
      TreeSelectLeafEmbeddingRetriever&#13;
     </code>&#13;
     , navigating this structure at query time could be more computationally expensive than with other types of indexes. This recursive process adds computational overhead, especially for deep trees or&#13;
     &#13;
      large datasets.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     That being said, we have&#13;
     <a id="_idIndexMarker551">&#13;
     </a>&#13;
     several ways to&#13;
     &#13;
      query&#13;
     &#13;
     &#13;
      <code class="literal">&#13;
       TreeIndex&#13;
      </code>&#13;
     &#13;
     &#13;
      .&#13;
     &#13;
    </p>&#13;
    <h3>&#13;
     TreeSelectLeafRetriever&#13;
    </h3>&#13;
    <p>&#13;
     We can construct this retriever&#13;
     &#13;
      like this:&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     This is also the default retriever&#13;
     <a id="_idIndexMarker552">&#13;
     </a>&#13;
     that’s used by&#13;
     <code class="literal">&#13;
      TreeIndex&#13;
     </code>&#13;
     . Its purpose is to recursively navigate the index structure and identify the leaf nodes that are most relevant to the query being formulated. This can be seen in&#13;
     &#13;
      <em class="italic">&#13;
       Figure 6&#13;
      </em>&#13;
     &#13;
     &#13;
      <em class="italic">&#13;
       .7&#13;
      </em>&#13;
     &#13;
     &#13;
      :&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     <div>&#13;
      <img src="img/B21861_06_7.jpg"/>&#13;
     </p>&#13;
    </div>&#13;
    <p class="IMG---Caption" lang="en-US">&#13;
     Figure 6.7 – TreeSelectLeafRetriever configured with a child_branch_factor argument value of 1&#13;
    </p>&#13;
    <p>&#13;
     The&#13;
     <code class="literal">&#13;
      child_branch_factor&#13;
     </code>&#13;
     argument specifies the number of child nodes to be considered at each level of the tree. Setting a higher value can result in a more exhaustive search and increase the chance of finding the most relevant nodes. However, this has the disadvantage of increasing the computational cost and processing time. If no value is specified, the retriever defaults to a value of&#13;
     <code class="literal">&#13;
      1&#13;
     </code>&#13;
     . Another very useful parameter is&#13;
     <code class="literal">&#13;
      Verbose&#13;
     </code>&#13;
     , which, when set to&#13;
     <code class="literal">&#13;
      True&#13;
     </code>&#13;
     , causes the detailed selection process to be displayed. This is a very good way to understand how the retriever works or troubleshoot possible execution problems. The nodes that are returned by this retriever do not contain an associated&#13;
     <a id="_idIndexMarker553">&#13;
     </a>&#13;
     relevance score. As this retriever uses an LLM for node selection, several parameters can be used to customize&#13;
     &#13;
      the prompts:&#13;
     &#13;
    </p>&#13;
    <ul>&#13;
     <li>&#13;
      <code class="literal">&#13;
       query_template&#13;
      </code>&#13;
      : This is a prompt template that we can use to customize queries for&#13;
      &#13;
       the LLM&#13;
      &#13;
     </li>&#13;
     <li>&#13;
      <code class="literal">&#13;
       text_qa_template&#13;
      </code>&#13;
      : This is another template that’s used for text-based Q&amp;A queries. It is used to get specific answers from&#13;
      &#13;
       text nodes&#13;
      &#13;
     </li>&#13;
     <li>&#13;
      <code class="literal">&#13;
       refine_template&#13;
      </code>&#13;
      : This template is used to refine or enhance the initial answers that are obtained from the LLM. It can be used to add additional context or&#13;
      &#13;
       clarify answers&#13;
      &#13;
     </li>&#13;
     <li>&#13;
      <code class="literal">&#13;
       query_template_multiple&#13;
      </code>&#13;
      : An alternative prompt template that allows queries to be formulated for multiple nodes simultaneously. It is useful when using a&#13;
      <code class="literal">&#13;
       child_branch_factor&#13;
      </code>&#13;
      argument that’s higher&#13;
      &#13;
       than 1&#13;
      &#13;
     </li>&#13;
    </ul>&#13;
    <p>&#13;
     We’ll talk&#13;
     &#13;
      about&#13;
     &#13;
     &#13;
      <code class="literal">&#13;
       TreeSelectEmbeddingRetriever&#13;
      </code>&#13;
     &#13;
     &#13;
      .&#13;
     &#13;
    </p>&#13;
    <h3>&#13;
     TreeSelectLeafEmbeddingRetriever&#13;
    </h3>&#13;
    <p>&#13;
     This particular kind of retriever can be built using the&#13;
     &#13;
      following code:&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     As its name suggests, this retriever&#13;
     <a id="_idIndexMarker554">&#13;
     </a>&#13;
     navigates the index by using the similarity of the embeddings between the query and the node text to select the&#13;
     &#13;
      relevant nodes.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     This process is recursive, navigating all levels of the tree. It works almost identically to&#13;
     <code class="literal">&#13;
      TreeSelectLeafRetriever&#13;
     </code>&#13;
     , with the only difference being that it uses embeddings for&#13;
     &#13;
      node selection.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     The parameters we discussed earlier are also valid here, but there is an additional parameter:&#13;
     <code class="literal">&#13;
      embed_model&#13;
     </code>&#13;
     . This&#13;
     <a id="_idIndexMarker555">&#13;
     </a>&#13;
     can be used to specify a preferred embedding model. As with the previous retriever, the nodes that are returned by this retriever do not contain an associated&#13;
     &#13;
      relevance score.&#13;
     &#13;
    </p>&#13;
    <h3>&#13;
     TreeAllLeafRetriever&#13;
    </h3>&#13;
    <p>&#13;
     Here’s the fastest way to&#13;
     <a id="_idIndexMarker556">&#13;
     </a>&#13;
     construct&#13;
     &#13;
      this retriever:&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     You can find an explanatory diagram in&#13;
     &#13;
      <em class="italic">&#13;
       Figure 6&#13;
      </em>&#13;
     &#13;
     &#13;
      <em class="italic">&#13;
       .8&#13;
      </em>&#13;
     &#13;
     &#13;
      :&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     <div>&#13;
      <img src="img/B21861_06_8.jpg"/>&#13;
     </p>&#13;
    </div>&#13;
    <p class="IMG---Caption" lang="en-US">&#13;
     Figure 6.8 – Retrieving all nodes by using TreeAllLeafRetriever&#13;
    </p>&#13;
    <p>&#13;
     This retriever is useful for its ability to analyze a large amount of data, ensuring that no potentially relevant information is missed in the response generation process. In a similar way to&#13;
     <code class="literal">&#13;
      SummaryIndexRetriever&#13;
     </code>&#13;
     , this retriever extracts all nodes from the index and sorts them, regardless of their position in the hierarchy. This is akin to a bulk retrieval but without it returning any&#13;
     &#13;
      relevance score.&#13;
     &#13;
    </p>&#13;
    <h3>&#13;
     TreeRootRetriever&#13;
    </h3>&#13;
    <p>&#13;
     We can build this with the&#13;
     &#13;
      following command:&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     Unlike&#13;
     <code class="literal">&#13;
      TreeAllLeafRetriever&#13;
     </code>&#13;
     , this retriever focuses on retrieving responses directly from the root nodes of the tree. It&#13;
     <a id="_idIndexMarker557">&#13;
     </a>&#13;
     assumes that the index tree already stores the response. Unlike other methods that might parse information down the tree to extract relevant nodes,&#13;
     <code class="literal">&#13;
      TreeRootRetriever&#13;
     </code>&#13;
     relies on the fact that the answer is already at the root level.&#13;
     &#13;
      <em class="italic">&#13;
       Figure 6&#13;
      </em>&#13;
     &#13;
     <em class="italic">&#13;
      .9&#13;
     </em>&#13;
     provides a&#13;
     &#13;
      visual explanation:&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     <div>&#13;
      <img src="img/B21861_06_9.jpg"/>&#13;
     </p>&#13;
    </div>&#13;
    <p class="IMG---Caption" lang="en-US">&#13;
     Figure 6.9 – Retrieving from the root of the tree&#13;
    </p>&#13;
    <p>&#13;
     It is effective in cases where essential information is aggregated or synthesized at the top level of the data structure, such as data summaries, general conclusions, or answers to frequently asked questions. This retriever also does not return relevance scores associated&#13;
     &#13;
      with nodes.&#13;
     &#13;
    </p>&#13;
    <p class="callout-heading">&#13;
     Practical use case&#13;
    </p>&#13;
    <p class="callout">&#13;
     A practical example would be a&#13;
     <strong class="bold">&#13;
      clinical decision support system&#13;
     </strong>&#13;
     (&#13;
     <strong class="bold">&#13;
      CDSS&#13;
     </strong>&#13;
     ) in the medical field. Imagine such a&#13;
     <a id="_idIndexMarker558">&#13;
     </a>&#13;
     system having a&#13;
     <code class="literal">&#13;
      TreeIndex&#13;
     </code>&#13;
     retriever in which each root node represents a specific medical question and the corresponding answers or clinical advice are pre-computed and stored in these root nodes. For example, the root nodes may store a pre-computed answer such as&#13;
     <em class="italic">&#13;
      Common symptoms of COVID-19 include fever, dry cough, tiredness, and so on&#13;
     </em>&#13;
     . In this scenario, when a doctor or patient interrogates the system with the&#13;
     <em class="italic">&#13;
      Symptoms of a COVID-19 infection&#13;
     </em>&#13;
     query, this retriever will look at the appropriate root node and return the pre-computed answer without any additional&#13;
     <a id="_idIndexMarker559">&#13;
     </a>&#13;
     processing or having to traverse the tree to&#13;
     &#13;
      find information.&#13;
     &#13;
    </p>&#13;
    <h3>&#13;
     The KeywordTableIndex retrievers&#13;
    </h3>&#13;
    <p>&#13;
     The retrieval process from&#13;
     <code class="literal">&#13;
      KeywordTableIndex&#13;
     </code>&#13;
     starts by extracting the relevant keywords from the query given to the&#13;
     <a id="_idIndexMarker560">&#13;
     </a>&#13;
     retriever. Extraction can be done in several ways, depending on the retriever being used. Once the keywords have been extracted, the retriever counts their frequency in the different indexed. All retrievers that are available for this index operate as described in&#13;
     &#13;
      <em class="italic">&#13;
       Figure 6&#13;
      </em>&#13;
     &#13;
     <em class="italic">&#13;
      .10&#13;
     </em>&#13;
     . The only difference is the method that’s used to extract&#13;
     &#13;
      the keywords:&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     <div>&#13;
      <img src="img/B21861_06_10.jpg"/>&#13;
     </p>&#13;
    </div>&#13;
    <p class="IMG---Caption" lang="en-US">&#13;
     Figure 6.10 – KeywordTableIndex&#13;
    </p>&#13;
    <p>&#13;
     The nodes are sorted by the number of matching keywords, usually in descending order of relevance, and returned as a&#13;
     &#13;
      <code class="literal">&#13;
       NodeWithScore&#13;
      </code>&#13;
     &#13;
     &#13;
      response.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     It’s worth noting that queries against this type of index do not return a relevance score associated with&#13;
     &#13;
      the nodes.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     Let’s have a look at the available retrievers for&#13;
     &#13;
      this Index.&#13;
     &#13;
    </p>&#13;
    <h3>&#13;
     KeywordTableGPTRetriever&#13;
    </h3>&#13;
    <p>&#13;
     We can build this type of retriever&#13;
     <a id="_idIndexMarker561">&#13;
     </a>&#13;
     with the&#13;
     &#13;
      following command:&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     It uses an LLM query to identify relevant keywords in a query and then returns the nodes associated with&#13;
     &#13;
      those keywords.&#13;
     &#13;
    </p>&#13;
    <h3>&#13;
     KeywordTableSimpleRetriever&#13;
    </h3>&#13;
    <p>&#13;
     This retriever can be built&#13;
     &#13;
      as follows:&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     This is a simpler method that does&#13;
     <a id="_idIndexMarker562">&#13;
     </a>&#13;
     not use the LLM and is faster. However, it may be less efficient at identifying complex or contextual keywords. It uses a regular expression-based&#13;
     &#13;
      keyword extractor.&#13;
     &#13;
    </p>&#13;
    <h3>&#13;
     KeywordTableRAKERetriever&#13;
    </h3>&#13;
    <p>&#13;
     To define this, we can use the&#13;
     <a id="_idIndexMarker563">&#13;
     </a>&#13;
     &#13;
      following command:&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     Similar to the previous retriever, this one uses the&#13;
     <em class="italic">&#13;
      RAKE method&#13;
     </em>&#13;
     to efficiently extract relevant keywords. We discussed the RAKE method in&#13;
     <a>&#13;
      &#13;
       <em class="italic">&#13;
        Chapter 5&#13;
       </em>&#13;
      &#13;
     </a>&#13;
     ,&#13;
     <em class="italic">&#13;
      Indexing with LlamaIndex&#13;
     </em>&#13;
     , i&#13;
     <em class="italic">&#13;
      n the A simple usage model for&#13;
     </em>&#13;
     &#13;
      <em class="italic">&#13;
       KeywordTableIndex&#13;
      </em>&#13;
     &#13;
     &#13;
      section.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     There are also several common arguments that we can use to set up the retrievers&#13;
     &#13;
      of&#13;
     &#13;
     &#13;
      <code class="literal">&#13;
       KeywordTableIndex&#13;
      </code>&#13;
     &#13;
     &#13;
      :&#13;
     &#13;
    </p>&#13;
    <ul>&#13;
     <li>&#13;
      <code class="literal">&#13;
       query_keyword_extract_template&#13;
      </code>&#13;
      : This is used to change the default prompt that’s used to extract keywords from the text of a query. This can only be applied to the&#13;
      &#13;
       default mode.&#13;
      &#13;
     </li>&#13;
     <li>&#13;
      <code class="literal">&#13;
       max_keywords_per_query&#13;
      </code>&#13;
      : This specifies the maximum number of keywords that can be extracted from a single query. This parameter is important to control query complexity and to avoid overloading the system with too&#13;
      &#13;
       many keywords.&#13;
      &#13;
     </li>&#13;
     <li>&#13;
      <code class="literal">&#13;
       num_chunks_per_query&#13;
      </code>&#13;
      : This specifies the maximum number of chunks that can be retrieved in a query. This parameter helps limit the amount of data that can be processed in a single query, optimizing system performance&#13;
      &#13;
       and efficiency.&#13;
      &#13;
     </li>&#13;
    </ul>&#13;
    <p>&#13;
     Next, we’ll talk about how to&#13;
     <a id="_idIndexMarker564">&#13;
     </a>&#13;
     retrieve data from&#13;
     &#13;
      knowledge graphs.&#13;
     &#13;
    </p>&#13;
    <a id="_idTextAnchor139">&#13;
    </a>&#13;
    <h2 id="_idParaDest-140">&#13;
     The KnowledgeGraphIndex retrievers&#13;
    </h2>&#13;
    <p>&#13;
     As discussed in the previous chapter, this&#13;
     <a id="_idIndexMarker565">&#13;
     </a>&#13;
     type of Index constructs a&#13;
     <a id="_idIndexMarker566">&#13;
     </a>&#13;
     graph made up of&#13;
     <em class="italic">&#13;
      triplets&#13;
     </em>&#13;
     . Each&#13;
     <strong class="bold">&#13;
      triplet&#13;
     </strong>&#13;
     consists of a subject, a predicate, and an object. The&#13;
     <strong class="bold">&#13;
      subject&#13;
     </strong>&#13;
     is the entity or concept about which a statement is being made. The&#13;
     <strong class="bold">&#13;
      predicate&#13;
     </strong>&#13;
     is the relationship or verb that links the subject to the object, describing&#13;
     <a id="_idIndexMarker567">&#13;
     </a>&#13;
     how the two are related, and the object is the entity or concept that is linked to the subject by the predicate. At the core of this index, there are two retrievers,&#13;
     <code class="literal">&#13;
      KGTableRetriever&#13;
     </code>&#13;
     and&#13;
     <code class="literal">&#13;
      KnowledgeGraphRAGRetriever&#13;
     </code>&#13;
     , both of which extract relevant nodes from a knowledge graph based&#13;
     &#13;
      on queries.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     <code class="literal">&#13;
      KGTableRetriever&#13;
     </code>&#13;
     is the default retriever for&#13;
     <code class="literal">&#13;
      KnowledgeGraphIndex&#13;
     </code>&#13;
     and can be configured in three retrieval modes: using keywords only, using embeddings only, or a combination of both – in hybrid mode. All modes operate as described in&#13;
     &#13;
      <em class="italic">&#13;
       Figure 6&#13;
      </em>&#13;
     &#13;
     &#13;
      <em class="italic">&#13;
       .11&#13;
      </em>&#13;
     &#13;
     &#13;
      :&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     <div>&#13;
      <img src="img/B21861_06_11.jpg"/>&#13;
     </p>&#13;
    </div>&#13;
    <p class="IMG---Caption" lang="en-US">&#13;
     Figure 6.11 – The inner workings of KGTableRetriever&#13;
    </p>&#13;
    <p>&#13;
     Let’s look at how they work under&#13;
     &#13;
      the hood.&#13;
     &#13;
    </p>&#13;
    <h3>&#13;
     Keyword mode&#13;
    </h3>&#13;
    <p>&#13;
     The retriever can be built in this&#13;
     <a id="_idIndexMarker568">&#13;
     </a>&#13;
     mode using the&#13;
     &#13;
      following command:&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     When configured in keyword mode, the retriever uses keywords extracted from the query to find relevant nodes containing&#13;
     &#13;
      those keywords.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     Keywords are evaluated in case-sensitive mode. This means that on a hypothetical index, a query of the form&#13;
     <em class="italic">&#13;
      where is the Colosseum?&#13;
     </em>&#13;
     will return a correct result, while&#13;
     <em class="italic">&#13;
      where is the colosseum?&#13;
     </em>&#13;
     will return&#13;
     &#13;
      no nodes.&#13;
     &#13;
    </p>&#13;
    <h3>&#13;
     Embedding mode&#13;
    </h3>&#13;
    <p>&#13;
     We can set it to this mode using&#13;
     <a id="_idIndexMarker569">&#13;
     </a>&#13;
     the&#13;
     &#13;
      following code:&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     In this mode, the retriever turns the query into an embedding and the system finds nodes in the graph whose vector representation is similar to the embedding of the query, even if the same keywords are&#13;
     &#13;
      not used.&#13;
     &#13;
    </p>&#13;
    <h3>&#13;
     Hybrid mode&#13;
    </h3>&#13;
    <p>&#13;
     This mode can be configured using the&#13;
     &#13;
      following command:&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     In hybrid mode, the retriever uses&#13;
     <a id="_idIndexMarker570">&#13;
     </a>&#13;
     both the keywords extracted from the query and the embeddings to find a set of relevant Nodes. It combines the results from both the keyword-based and embedding-based retrieval steps and removes any duplicated results. This approach combines the precision of keyword-based search with the semantic understanding of&#13;
     &#13;
      the embeddings.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     There are several customizable parameters for this type of retriever. For example,&#13;
     <code class="literal">&#13;
      query_keyword_extract_template&#13;
     </code>&#13;
     ,&#13;
     <code class="literal">&#13;
      refine_template&#13;
     </code>&#13;
     , and&#13;
     <code class="literal">&#13;
      text_qa_template&#13;
     </code>&#13;
     can be used to change the default prompt for keyword extraction, the default prompt for query refinement, and the default prompt for text queries and answers, respectively. Here are some other&#13;
     &#13;
      useful parameters:&#13;
     &#13;
    </p>&#13;
    <ul>&#13;
     <li>&#13;
      <code class="literal">&#13;
       max_keywords_per_query&#13;
      </code>&#13;
      : This limits the number of keywords to avoid overloading the search process. The default value&#13;
      &#13;
       is&#13;
      &#13;
      &#13;
       <code class="literal">&#13;
        10&#13;
       </code>&#13;
      &#13;
      &#13;
       .&#13;
      &#13;
     </li>&#13;
     <li>&#13;
      <code class="literal">&#13;
       num_chunks_per_query&#13;
      </code>&#13;
      : This determines how many text fragments can be parsed in a single query. The default is&#13;
      <code class="literal">&#13;
       10&#13;
      </code>&#13;
      and any change must take into account the performance impact and limitations of the&#13;
      &#13;
       LLM used.&#13;
      &#13;
     </li>&#13;
     <li>&#13;
      <code class="literal">&#13;
       include_text&#13;
      </code>&#13;
      : The default value is&#13;
      <code class="literal">&#13;
       True&#13;
      </code>&#13;
      . This argument indicates whether the text of the source document&#13;
      <a id="_idIndexMarker571">&#13;
      </a>&#13;
      should be used in queries in each relevant triplet. This can enrich the query with additional context but inevitably increases the&#13;
      &#13;
       computational cost.&#13;
      &#13;
     </li>&#13;
     <li>&#13;
      <code class="literal">&#13;
       similarity_top_k&#13;
      </code>&#13;
      : When the retriever is configured in embedding or hybrid mode, this parameter specifies the number of similar embeddings to be considered in the retrieval process. The default value&#13;
      &#13;
       is&#13;
      &#13;
      &#13;
       <code class="literal">&#13;
        2&#13;
       </code>&#13;
      &#13;
      &#13;
       .&#13;
      &#13;
     </li>&#13;
     <li>&#13;
      <code class="literal">&#13;
       graph_store_query_depth&#13;
      </code>&#13;
      : This parameter controls how deep into the graph structure to search for relevant information. The default value&#13;
      &#13;
       is&#13;
      &#13;
      &#13;
       <code class="literal">&#13;
        2&#13;
       </code>&#13;
      &#13;
      &#13;
       .&#13;
      &#13;
     </li>&#13;
     <li>&#13;
      <code class="literal">&#13;
       use_global_node_triplets&#13;
      </code>&#13;
      : When set to&#13;
      <code class="literal">&#13;
       True&#13;
      </code>&#13;
      , the retriever will not limit itself to keywords extracted directly from the user query; instead, it will search for other keywords or entities in the text fragments that have already been identified as relevant to the initial keywords. This process helps bring an additional layer of knowledge to the query. By exploring the relationships and connections between different nodes in the graph, the retriever can access richer and more contextual information than would be possible by limiting itself to the original keywords. However, this approach is more costly in terms of computing resources and search time as it involves analyzing a greater number of nodes and relationships in the graph. For this reason, the option is disabled by default – that is, it’s set&#13;
      &#13;
       to&#13;
      &#13;
      &#13;
       <code class="literal">&#13;
        False&#13;
       </code>&#13;
      &#13;
      &#13;
       .&#13;
      &#13;
     </li>&#13;
     <li>&#13;
      <code class="literal">&#13;
       max_knowledge_sequence&#13;
      </code>&#13;
      : This parameter provides a balance between the quality and quantity of information presented. For example, if a query can theoretically generate 100 sequences of relevant knowledge, but&#13;
      <code class="literal">&#13;
       max_knowledge_sequence&#13;
      </code>&#13;
      is set to 30, only the most relevant 30 sequences will be presented as answers. This is also the default. Setting a limit ensures that the answer does not become too long or difficult to interpret, while still retaining&#13;
      <a id="_idIndexMarker572">&#13;
      </a>&#13;
      enough information to&#13;
      &#13;
       be useful&#13;
      &#13;
     </li>&#13;
    </ul>&#13;
    <p>&#13;
     Although they return&#13;
     <code class="literal">&#13;
      NodeWithScore&#13;
     </code>&#13;
     objects, the knowledge graph retrievers do not provide any score for the actual nodes. Instead, they simply return a default value of&#13;
     <code class="literal">&#13;
      1000&#13;
     </code>&#13;
     for each&#13;
     &#13;
      retrieved node.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     If the retrievers do not find any nodes in the index based on the configured mode and search parameters, they will first try to identify nodes based on the provided keywords only. If they do not find any relevant nodes, they will return a single placeholder node with the text&#13;
     <em class="italic">&#13;
      No relationships found&#13;
     </em>&#13;
     and a score&#13;
     &#13;
      of 1.&#13;
     &#13;
    </p>&#13;
    <h3>&#13;
     KnowledgeGraphRAGRetriever&#13;
    </h3>&#13;
    <p>&#13;
     This additional retriever is a bit more&#13;
     <a id="_idIndexMarker573">&#13;
     </a>&#13;
     special in that it operates by identifying key entities within a query and leveraging these to navigate the knowledge graph. It utilizes functions and templates for entity extraction (&#13;
     <code class="literal">&#13;
      extraction entity_extract_fn&#13;
     </code>&#13;
     and&#13;
     <code class="literal">&#13;
      entity_extract_template&#13;
     </code>&#13;
     ) and synonym expansion (&#13;
     <code class="literal">&#13;
      synonym_expand_fn&#13;
     </code>&#13;
     and&#13;
     <code class="literal">&#13;
      synonym_expand_template&#13;
     </code>&#13;
     ) to enrich the query with a broader context of related terms and concepts. The retriever traverses the graph to a specified depth –&#13;
     <code class="literal">&#13;
      graph_traversal_depth&#13;
     </code>&#13;
     – based on these entities and their synonyms, constructing a knowledge sequence relevant to&#13;
     &#13;
      the query.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     This retriever can operate in various modes and can be configured by setting&#13;
     <code class="literal">&#13;
      retriever_mode&#13;
     </code>&#13;
     , allowing for flexibility in its approach to finding&#13;
     &#13;
      relevant nodes.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     Just like&#13;
     <code class="literal">&#13;
      KGTableRetriever&#13;
     </code>&#13;
     , this retriever has three operating modes:&#13;
     <code class="literal">&#13;
      keyword&#13;
     </code>&#13;
     ,&#13;
     <code class="literal">&#13;
      embedding&#13;
     </code>&#13;
     ,&#13;
     &#13;
      and&#13;
     &#13;
     &#13;
      <code class="literal">&#13;
       keyword_embedding&#13;
      </code>&#13;
     &#13;
     &#13;
      .&#13;
     &#13;
    </p>&#13;
    <p class="callout-heading">&#13;
     A note regarding retrieval modes&#13;
    </p>&#13;
    <p class="callout">&#13;
     As of January 2024, in LlamaIndex v0.9.25, only the keyword&#13;
     <a id="_idIndexMarker574">&#13;
     </a>&#13;
     retrieval mode&#13;
     &#13;
      was implemented.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     In addition, the retriever features the&#13;
     <code class="literal">&#13;
      with_nl2graphquery&#13;
     </code>&#13;
     option, which, when enabled, combines&#13;
     <strong class="bold">&#13;
      Natural Language to Graph Query&#13;
     </strong>&#13;
     (&#13;
     <strong class="bold">&#13;
      NL2GraphQuery&#13;
     </strong>&#13;
     )  capabilities, enhancing its ability to interpret and&#13;
     <a id="_idIndexMarker575">&#13;
     </a>&#13;
     respond to complex queries. NL2GraphQuery is a process that converts natural language queries into graph-based query languages. This is achieved via a combination of entity extraction, synonym expansion, and graph&#13;
     <a id="_idIndexMarker576">&#13;
     </a>&#13;
     traversal techniques. This parameter is set to&#13;
     <code class="literal">&#13;
      False&#13;
     </code>&#13;
     &#13;
      by default.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     Here are some other parameters that we may wish&#13;
     &#13;
      to customize:&#13;
     &#13;
    </p>&#13;
    <ul>&#13;
     <li>&#13;
      <code class="literal">&#13;
       max_knowledge_sequence&#13;
      </code>&#13;
      : Sets a limit on the number of knowledge sequences included in the response, balancing detail&#13;
      &#13;
       with clarity&#13;
      &#13;
     </li>&#13;
     <li>&#13;
      <code class="literal">&#13;
       max_entities&#13;
      </code>&#13;
      : Specifies the maximum number of entities to extract from the query, defaulting&#13;
      &#13;
       to&#13;
      &#13;
      &#13;
       <code class="literal">&#13;
        5&#13;
       </code>&#13;
      &#13;
     </li>&#13;
     <li>&#13;
      <code class="literal">&#13;
       max_synonyms&#13;
      </code>&#13;
      : Determines the maximum number of synonyms to expand for each entity, with a default value&#13;
      &#13;
       of&#13;
      &#13;
      &#13;
       <code class="literal">&#13;
        5&#13;
       </code>&#13;
      &#13;
     </li>&#13;
     <li>&#13;
      <code class="literal">&#13;
       synonym_expand_policy&#13;
      </code>&#13;
      : Controls the policy for synonym expansion, either&#13;
      <em class="italic">&#13;
       union&#13;
      </em>&#13;
      or&#13;
      <em class="italic">&#13;
       intersection&#13;
      </em>&#13;
      , with&#13;
      <em class="italic">&#13;
       union&#13;
      </em>&#13;
      as&#13;
      &#13;
       the default&#13;
      &#13;
     </li>&#13;
     <li>&#13;
      <code class="literal">&#13;
       entity_extract_policy&#13;
      </code>&#13;
      : Sets the policy for entity extraction, also either&#13;
      <em class="italic">&#13;
       union&#13;
      </em>&#13;
      or&#13;
      <em class="italic">&#13;
       intersection&#13;
      </em>&#13;
      , defaulting&#13;
      &#13;
       to&#13;
      &#13;
      &#13;
       <em class="italic">&#13;
        union&#13;
       </em>&#13;
      &#13;
     </li>&#13;
     <li>&#13;
      <code class="literal">&#13;
       verbose&#13;
      </code>&#13;
      : As usual, this is used to enable or disable the printing of debug information, aiding in the understanding of the&#13;
      &#13;
       Retriever’s operation&#13;
      &#13;
     </li>&#13;
     <li>&#13;
      <code class="literal">&#13;
       graph_traversal_depth&#13;
      </code>&#13;
      : Determines the depth of the traversal within the knowledge graph. By default, this is set&#13;
      &#13;
       to&#13;
      &#13;
      &#13;
       <code class="literal">&#13;
        2&#13;
       </code>&#13;
      &#13;
     </li>&#13;
    </ul>&#13;
    <p class="callout-heading">&#13;
     A quick note&#13;
    </p>&#13;
    <p class="callout">&#13;
     There’s something important to highlight for all retrievers that use LLMs and accept parameters for customization prompts: All of these parameters are of the&#13;
     <code class="literal">&#13;
      BasePromptTemplate&#13;
     </code>&#13;
     type. We will talk more about the structure of this class and how to use it in&#13;
     <a>&#13;
      &#13;
       <em class="italic">&#13;
        Chapter 10&#13;
       </em>&#13;
      &#13;
     </a>&#13;
     ,&#13;
     <em class="italic">&#13;
      Prompt Engineering Guidelines and&#13;
     </em>&#13;
     &#13;
      <em class="italic">&#13;
       Best Practices&#13;
      </em>&#13;
     &#13;
     &#13;
      .&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     With that, we’ve covered the differences between each type of retriever. Now, let’s see what they all have&#13;
     &#13;
      in&#13;
     &#13;
     &#13;
      <a id="_idIndexMarker577">&#13;
      </a>&#13;
     &#13;
     &#13;
      common.&#13;
     &#13;
    </p>&#13;
    <a id="_idTextAnchor140">&#13;
    </a>&#13;
    <h2 id="_idParaDest-141">&#13;
     Common characteristics shared by all retrievers&#13;
    </h2>&#13;
    <p>&#13;
     All retrievers accept either&#13;
     <a id="_idIndexMarker578">&#13;
     </a>&#13;
     a query directly or a&#13;
     <code class="literal">&#13;
      QueryBundle&#13;
     </code>&#13;
     object as a parameter.&#13;
     <code class="literal">&#13;
      QueryBundle&#13;
     </code>&#13;
     is a universal mechanism that can be used for more advanced use cases, such as searching based on embeddings or searching for images and/or text in a&#13;
     &#13;
      multimodal scenario.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     In addition, all retrievers accept the&#13;
     <code class="literal">&#13;
      callback_manager&#13;
     </code>&#13;
     argument. We will discuss this mechanism in more detail in&#13;
     <a>&#13;
      &#13;
       <em class="italic">&#13;
        Chapter 10&#13;
       </em>&#13;
      &#13;
     </a>&#13;
     ,&#13;
     <em class="italic">&#13;
      Prompt Engineering Guidelines and&#13;
     </em>&#13;
     &#13;
      <em class="italic">&#13;
       Best Practices&#13;
      </em>&#13;
     &#13;
     &#13;
      .&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     These are the basic building blocks for the retrieval logic of our RAG applications. If we want a generic and easy-to-build solution, we can use them directly. However, for more complex cases, there are several advanced retrieval modules in LlamaIndex that either combine the functionality of the basic retrievers or add new features to the mix. We will discuss some of them later in&#13;
     &#13;
      this chapter.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     As we have seen, some retrievers use either embedding models or LLM queries to identify the most relevant nodes. However, at their core, all of the retriever types listed here are subclasses of&#13;
     <code class="literal">&#13;
      BaseRetriever&#13;
     </code>&#13;
     . This means that they all inherit the main&#13;
     <code class="literal">&#13;
      retrieve()&#13;
     </code>&#13;
     method, as well as&#13;
     <code class="literal">&#13;
      aretrieve()&#13;
     </code>&#13;
     , for&#13;
     &#13;
      asynchronous operation.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     We will discuss the asynchronous&#13;
     &#13;
      operation next.&#13;
     &#13;
    </p>&#13;
    <a id="_idTextAnchor141">&#13;
    </a>&#13;
    <h2 id="_idParaDest-142">&#13;
     Efficient use of retrieval mechanisms – asynchronous operation&#13;
    </h2>&#13;
    <p>&#13;
     For the sake of simplicity, all the code&#13;
     <a id="_idIndexMarker579">&#13;
     </a>&#13;
     examples we have discussed so&#13;
     <a id="_idIndexMarker580">&#13;
     </a>&#13;
     far have used&#13;
     <strong class="bold">&#13;
      synchronous methods&#13;
     </strong>&#13;
     . Although the synchronous – or&#13;
     <strong class="bold">&#13;
      serialized&#13;
     </strong>&#13;
     – mode of operation is linear, easy to understand, and predictable, in modern applications, performance and low latency are very important to provide a great&#13;
     &#13;
      user experience.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     The good news is that LlamaIndex already&#13;
     <a id="_idIndexMarker581">&#13;
     </a>&#13;
     offers – in most cases –&#13;
     <strong class="bold">&#13;
      asynchronous execution&#13;
     </strong>&#13;
     alternatives. Here’s a simple example of asynchronous execution for two Retrievers defined&#13;
     &#13;
      over&#13;
     &#13;
     &#13;
      <code class="literal">&#13;
       KeywordTableIndex&#13;
      </code>&#13;
     &#13;
     &#13;
      :&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     The preceding code executes&#13;
     <a id="_idIndexMarker582">&#13;
     </a>&#13;
     the two retrievals in parallel. Of&#13;
     <a id="_idIndexMarker583">&#13;
     </a>&#13;
     course, being a trivial example with a very small dataset, the performance benefits of&#13;
     <strong class="bold">&#13;
      asynchronous operation&#13;
     </strong>&#13;
     will not be significant in&#13;
     &#13;
      this case.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     However, in the context of a commercial application that frequently calls retrievers and operates numerous complex queries over many indexed nodes, the benefits will be substantial. Asynchronous operation improves performance, uses resources more efficiently, reduces latency, and generally provides a more natural user experience by reducing&#13;
     &#13;
      waiting times.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     Now, it’s time to talk&#13;
     <a id="_idIndexMarker584">&#13;
     </a>&#13;
     about the more advanced&#13;
     &#13;
      retrieval methods.&#13;
     &#13;
    </p>&#13;
    <a id="_idTextAnchor142">&#13;
    </a>&#13;
   </div>&#13;
  </div>&#13;
 </body>&#13;
</html>
<html>&#13;
 <head>&#13;
  <title>&#13;
   Building more advanced retrieval mechanisms&#13;
  </title>&#13;
 </head>&#13;
 <body>&#13;
  <p>&#13;
   <h1 id="_idParaDest-143">&#13;
    Building more advanced retrieval mechanisms&#13;
   </h1>&#13;
   <div>&#13;
    from llama_index.core.vector_stores.types import (&#13;
    FilterOperator, FilterCondition)&#13;
filters = MetadataFilters(&#13;
    filters=[&#13;
        MetadataFilter(&#13;
            key="department",&#13;
            value="Procurement"&#13;
        ),&#13;
        MetadataFilter(&#13;
            key="security_classification",&#13;
            value=&lt;user_clearance_level&gt;,&#13;
            operator=FilterOperator.LTE&#13;
        ),&#13;
    ],&#13;
    condition=FilterCondition.AND&#13;
)&#13;
    from llama_index.core.selectors.llm_selectors import LLMSingleSelector&#13;
options = [&#13;
    "option 1: this is good for summarization questions",&#13;
    "option 2: this is useful for precise definitions",&#13;
    "option 3: this is useful for comparing concepts",&#13;
]&#13;
selector = LLMSingleSelector.from_defaults()&#13;
    decision = selector.select(&#13;
    options,&#13;
    query="What's the definition of space?"&#13;
).selections[0]&#13;
print(decision.index+1)&#13;
print(decision.reason)&#13;
    from llama_index.core.selectors import PydanticMultiSelector&#13;
from llama_index.core.retrievers import RouterRetriever&#13;
from llama_index.core.tools import RetrieverTool&#13;
from llama_index.core import (&#13;
    VectorStoreIndex, SummaryIndex, SimpleDirectoryReader)&#13;
documents = SimpleDirectoryReader("files").load_data()&#13;
vector_index = VectorStoreIndex.from_documents([documents[0]])&#13;
summary_index = SummaryIndex.from_documents([documents[1]])&#13;
vector_retriever = vector_index.as_retriever()&#13;
summary_retriever = summary_index.as_retriever()&#13;
    vector_tool = RetrieverTool.from_defaults(&#13;
    retriever=vector_retriever,&#13;
    description="Use this for answering questions about Ancient Rome"&#13;
)&#13;
summary_tool = RetrieverTool.from_defaults(&#13;
    retriever=summary_retriever,&#13;
    description="Use this for answering questions about dogs"&#13;
)&#13;
    retriever = RouterRetriever(&#13;
    selector=PydanticMultiSelector.from_defaults(),&#13;
    retriever_tools=[&#13;
        vector_tool,&#13;
        summary_tool&#13;
    ]&#13;
)&#13;
response = retriever.retrieve(&#13;
    "What can you tell me about the Ancient Rome?"&#13;
)&#13;
for r in response:&#13;
    print(r.text)&#13;
    retriever.retrieve("What can you tell me about the Ancient Rome?")&#13;
    retriever.retrieve("Tell me all you know about dogs")&#13;
    retriever.retrieve("Tell me about dogs in Ancient Rome")&#13;
    from llama_index.core.indices.query.query_transform.base import DecomposeQueryTransform&#13;
decompose = DecomposeQueryTransform()&#13;
query_bundle = decompose.run(&#13;
    "Tell me about buildings in ancient Rome"&#13;
)&#13;
print(query_bundle.query_str)&#13;
    What were some famous buildings in ancient Rome?&#13;
    from llama_index.question_gen.openai import OpenAIQuestionGenerator&#13;
from llama_index.core.tools import RetrieverTool, ToolMetadata&#13;
from llama_index.core import (&#13;
    VectorStoreIndex, SummaryIndex, &#13;
    SimpleDirectoryReader, QueryBundle)&#13;
documents = SimpleDirectoryReader("files").load_data()&#13;
vector_index = VectorStoreIndex.from_documents(&#13;
    [documents[0]]&#13;
)&#13;
summary_index = SummaryIndex.from_documents([documents[1]])&#13;
    vector_tool_metadata = ToolMetadata(&#13;
    name="Vector Tool",&#13;
    description="Use this for answering questions about Ancient Rome"&#13;
)&#13;
summary_tool_metadata = ToolMetadata(&#13;
    name="Summary Tool",&#13;
    description="Use this for answering questions about dogs"&#13;
)&#13;
    vector_tool = RetrieverTool(&#13;
    retriever=vector_index.as_retriever(),&#13;
    metadata=vector_tool_metadata&#13;
)&#13;
summary_tool = RetrieverTool(&#13;
    retriever=summary_index.as_retriever(),&#13;
    metadata=summary_tool_metadata&#13;
)&#13;
    question_generator = OpenAIQuestionGenerator.from_defaults()&#13;
query_bundle = QueryBundle(&#13;
    query_str="Tell me about dogs and Ancient Rome")&#13;
sub_questions = question_generator.generate(&#13;
    tools=[vector_tool.metadata, summary_tool.metadata],&#13;
    query=query_bundle&#13;
)&#13;
    for sub_question in sub_questions:&#13;
    print(f"{sub_question.tool_name}: {sub_question.sub_question}")&#13;
    Summary Tool: What are the different breeds of dog?&#13;
Summary Tool: What was the role of dogs in ancient Rome?&#13;
Vector Tool: What were the most important events in Ancient Rome?&#13;
Vector Tool: What were the most famous buildings in ancient Rome?&#13;
    <p>&#13;
     Now we understand the basic components offered by LlamaIndex, we can build increasingly sophisticated solutions. On one hand, the retrievers we have discussed already provide efficient solutions for knowledge base querying and context enhancement in an RAG flow. On the other hand, we’ll see that there are many more advanced retrieval methods that either use specific techniques or ingeniously combine the retrievers&#13;
     &#13;
      already discussed.&#13;
     &#13;
    </p>&#13;
    <a id="_idTextAnchor143">&#13;
    </a>&#13;
    <h2 id="_idParaDest-144">&#13;
     The naive retrieval method&#13;
    </h2>&#13;
    <p>&#13;
     LlamaIndex provides fast query&#13;
     <a id="_idIndexMarker585">&#13;
     </a>&#13;
     methods by default. As we have seen, in just a few lines of code, we can ingest documents, create nodes and, for example, build a&#13;
     <code class="literal">&#13;
      VectorStoreIndex&#13;
     </code>&#13;
     retriever, which we can then just as easily query to return the most relevant parts using a retriever that uses similarity&#13;
     &#13;
      measurement techniques.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     The method is very simple and easy to implement. However, it is not an ideal method in all situations. More often than not, the&#13;
     <strong class="bold">&#13;
      naive method&#13;
     </strong>&#13;
     , as it is&#13;
     <a id="_idIndexMarker586">&#13;
     </a>&#13;
     usually called, produces&#13;
     <a id="_idIndexMarker587">&#13;
     </a>&#13;
     mediocre rather than&#13;
     <strong class="bold">&#13;
      state-of-the-art&#13;
     </strong>&#13;
     (&#13;
     &#13;
      <strong class="bold">&#13;
       SOTA&#13;
      </strong>&#13;
     &#13;
     &#13;
      ) solutions.&#13;
     &#13;
    </p>&#13;
    <p class="callout-heading">&#13;
     To use an analogy…&#13;
    </p>&#13;
    <p class="callout">&#13;
     It’s pretty much like using a hammer for all kinds of repairs in a house. The hammer is an essential and easy-to-use tool, but it is not always the best solution for every problem. Similarly, using a simplified method of questioning may be effective for basic situations but will not be as effective for more complex situations or specific needs that require a greater degree of finesse&#13;
     &#13;
      and adaptation.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     In these more complex cases, it is necessary to explore more advanced and tailored solutions, which may involve adapting the retrieval algorithms or combining them in&#13;
     &#13;
      different ways.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     Also, for large datasets, naive methods can be inefficient, either returning too many irrelevant results or missing important information. They can also underperform in terms of response time and&#13;
     &#13;
      resource consumption.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     In addition, in a real-world&#13;
     <a id="_idIndexMarker588">&#13;
     </a>&#13;
     situation, data can vary significantly in terms of quality, structure, and format. Simple methods are not always able to manage this diversity and extract&#13;
     &#13;
      valuable information.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     For example, if the specific information we are looking for is scattered in small chunks that are randomly distributed throughout the document, the results will be below expectations. In the next few sections, we’ll discuss some more advanced retrieval methods that can provide much better results in various&#13;
     &#13;
      specific situations.&#13;
     &#13;
    </p>&#13;
    <a id="_idTextAnchor144">&#13;
    </a>&#13;
    <h2 id="_idParaDest-145">&#13;
     Implementing metadata filters&#13;
    </h2>&#13;
    <p>&#13;
     A very simple but also effective&#13;
     <a id="_idIndexMarker589">&#13;
     </a>&#13;
     retrieval mechanism is filtering&#13;
     <a id="_idIndexMarker590">&#13;
     </a>&#13;
     the retrieved nodes by&#13;
     <strong class="bold">&#13;
      metadata&#13;
     </strong>&#13;
     . We’ll tackle a practical problem that’s usually encountered in an organization and for which the retrieval functions in LlamaIndex can provide&#13;
     &#13;
      a solution.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     We will see how to implement a retrieval system that filters the returned nodes according to the user’s department. Similar to the concept of polymorphism in object-oriented programming, it often happens that the same concept has different definitions, depending on the area&#13;
     &#13;
      of use.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     In our example, the user is looking for the definition of an incident in an organizational knowledge base. However, the term&#13;
     <em class="italic">&#13;
      incident&#13;
     </em>&#13;
     may have a different definition for those who deal with information security than for those who deal with IT service operations. Let’s have a look at how we can implement a form of polymorphism in a&#13;
     &#13;
      retrieval mechanism.&#13;
     &#13;
    </p>&#13;
    <ol>&#13;
     <li>&#13;
      First, we must take care of the necessary imports and define a mapping of users&#13;
      from llama_index.core.vector_stores.types import MetadataFilter, MetadataFilters&#13;
from llama_index.core import VectorStoreIndex&#13;
from llama_index.core.schema import TextNode&#13;
user_departments = {"Alice": "Security", "Bob": "IT"}&#13;
     &#13;
       to departments:&#13;
      &#13;
      </li>&#13;
     <li>&#13;
      Then, we must define two nodes that both store the definition of the concept of incident. The difference is in&#13;
      nodes = [&#13;
    TextNode(&#13;
        text=(&#13;
            "An incident is an accidental or malicious event that has the potential to cause unwanted effects on the security of our IT assets."),&#13;
        metadata={"department": "Security"},&#13;
    ),&#13;
    TextNode(&#13;
        text=("An incident is an unexpected interruption or&#13;
            degradation of an IT service."),&#13;
        metadata={"department": "IT"},&#13;
    )&#13;
]&#13;
Next, we must define the function that's responsible for filtering and retrieval:&#13;
def show_report(index, user, query):&#13;
    user_department = user_departments[user]&#13;
    filters = MetadataFilters(&#13;
        filters=[&#13;
            MetadataFilter(key="department", &#13;
                value=user_department)&#13;
        ]&#13;
    )&#13;
    retriever = index.as_retriever(filters=filters)&#13;
    response = retriever.retrieve(query)&#13;
    print(f"Response for {user}: {response[0].node.text}")&#13;
     <a id="_idIndexMarker591">&#13;
      </a>&#13;
      the metadata, which specifies the department where the&#13;
      &#13;
       definition applies:&#13;
      &#13;
      </li>&#13;
     <li>&#13;
      Now, if we run the same&#13;
      index = VectorStoreIndex(nodes)&#13;
query = "What is an incident?"&#13;
show_report(index, "Alice", query)&#13;
show_report(index, "Bob", query)&#13;
      Response for Alice: An incident is an accidental or malicious event that has the potential to cause unwanted effects on the security of our IT assets.&#13;
Response for Bob: An incident is an unexpected interruption or degradation of an IT service.&#13;
     <a id="_idIndexMarker592">&#13;
      </a>&#13;
      query in the context of each user, we will get different answers, depending on the department each user&#13;
      &#13;
       belongs to:&#13;
      &#13;
      <p class="list-inset">&#13;
       The output will look&#13;
       &#13;
        like this:&#13;
       &#13;
      </p>&#13;
      </li>&#13;
    </ol>&#13;
    <p>&#13;
     See how simple that was? The same mechanism can be used, for example, to control access to information and define&#13;
     &#13;
      security rules.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     For example, in a knowledge base system shared by several clients on a multi-tenancy model, we can restrict access by&#13;
     &#13;
      implementing&#13;
     &#13;
     &#13;
      <code class="literal">&#13;
       MetadataFilters&#13;
      </code>&#13;
     &#13;
     &#13;
      .&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     The code you saw earlier only does simple filtering: it restricts the search to nodes for which the value of the&#13;
     <code class="literal">&#13;
      department&#13;
     </code>&#13;
     key is equal to the user’s department. But there are also more complex filtering variants that use operators based on the&#13;
     <code class="literal">&#13;
      FilterOperator&#13;
     </code>&#13;
     class. Unfortunately, the default vector store in LlamaIndex only supports the&#13;
     <code class="literal">&#13;
      EQ&#13;
     </code>&#13;
     (equal) operator – that is, it can only apply filters where the value of a key is equal to a certain parameter. If we use a more sophisticated version of vector store (such as Pinecone or&#13;
     <a id="_idIndexMarker593">&#13;
     </a>&#13;
     ChromaDB), we can use the full range of operators available in&#13;
     <code class="literal">&#13;
      FilterOperator&#13;
     </code>&#13;
     , as listed in the&#13;
     &#13;
      following table:&#13;
     &#13;
    </p>&#13;
    <table class="No-Table-Style _idGenTablePara-1" id="table001-1">&#13;
     <colgroup>&#13;
      <col/>&#13;
      <col/>&#13;
      <col/>&#13;
     </colgroup>&#13;
     <thead>&#13;
      <tr class="No-Table-Style">&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         &#13;
          <strong class="bold">&#13;
           Symbolic Operator&#13;
          </strong>&#13;
         &#13;
        </p>&#13;
       </td>&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         &#13;
          <strong class="bold">&#13;
           Programming Equivalent&#13;
          </strong>&#13;
         &#13;
        </p>&#13;
       </td>&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         &#13;
          <strong class="bold">&#13;
           Description&#13;
          </strong>&#13;
         &#13;
        </p>&#13;
       </td>&#13;
      </tr>&#13;
     </thead>&#13;
     <tbody>&#13;
      <tr class="No-Table-Style">&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         &#13;
          EQ&#13;
         &#13;
        </p>&#13;
       </td>&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         ==&#13;
        </p>&#13;
       </td>&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         &#13;
          Equal (default)&#13;
         &#13;
        </p>&#13;
       </td>&#13;
      </tr>&#13;
      <tr class="No-Table-Style">&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         &#13;
          GT&#13;
         &#13;
        </p>&#13;
       </td>&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         &gt;&#13;
        </p>&#13;
       </td>&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         &#13;
          Greater than&#13;
         &#13;
        </p>&#13;
       </td>&#13;
      </tr>&#13;
      <tr class="No-Table-Style">&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         &#13;
          LT&#13;
         &#13;
        </p>&#13;
       </td>&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         &lt;&#13;
        </p>&#13;
       </td>&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         &#13;
          Less than&#13;
         &#13;
        </p>&#13;
       </td>&#13;
      </tr>&#13;
      <tr class="No-Table-Style">&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         &#13;
          NE&#13;
         &#13;
        </p>&#13;
       </td>&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         !=&#13;
        </p>&#13;
       </td>&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         Not&#13;
         &#13;
          equal to&#13;
         &#13;
        </p>&#13;
       </td>&#13;
      </tr>&#13;
      <tr class="No-Table-Style">&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         &#13;
          GTE&#13;
         &#13;
        </p>&#13;
       </td>&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         &gt;=&#13;
        </p>&#13;
       </td>&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         Greater than or&#13;
         &#13;
          equal to&#13;
         &#13;
        </p>&#13;
       </td>&#13;
      </tr>&#13;
      <tr class="No-Table-Style">&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         &#13;
          LTE&#13;
         &#13;
        </p>&#13;
       </td>&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         &lt;=&#13;
        </p>&#13;
       </td>&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         Less than or&#13;
         &#13;
          equal to&#13;
         &#13;
        </p>&#13;
       </td>&#13;
      </tr>&#13;
      <tr class="No-Table-Style">&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         &#13;
          IN&#13;
         &#13;
        </p>&#13;
       </td>&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         &#13;
          in&#13;
         &#13;
        </p>&#13;
       </td>&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         &#13;
          In array&#13;
         &#13;
        </p>&#13;
       </td>&#13;
      </tr>&#13;
      <tr class="No-Table-Style">&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         &#13;
          NIN&#13;
         &#13;
        </p>&#13;
       </td>&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         &#13;
          nin&#13;
         &#13;
        </p>&#13;
       </td>&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         Not&#13;
         &#13;
          in array&#13;
         &#13;
        </p>&#13;
       </td>&#13;
      </tr>&#13;
     </tbody>&#13;
    </table>&#13;
    <p class="IMG---Caption" lang="en-US">&#13;
     Table 6.1 – A complete list of operators available for FilterOperator&#13;
    </p>&#13;
    <p>&#13;
     Here is an example where we use filter operators and filter aggregation conditions to implement more&#13;
     &#13;
      complex scenarios:&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     In the previous example, we implemented a very simple access control mechanism based on clearance level and security classification. Only nodes that belong to a particular department and&#13;
     <a id="_idIndexMarker594">&#13;
     </a>&#13;
     have a classification level less than or equal to the user’s access level will be returned. We’ll talk about another&#13;
     &#13;
      method next.&#13;
     &#13;
    </p>&#13;
    <a id="_idTextAnchor145">&#13;
    </a>&#13;
    <h2 id="_idParaDest-146">&#13;
     Using selectors for more advanced decision logic&#13;
    </h2>&#13;
    <p>&#13;
     In an advanced user interaction&#13;
     <a id="_idIndexMarker595">&#13;
     </a>&#13;
     system, the user may employ a wide variety of queries. For example, they may ask a very specific question, looking for a precise definition. At other times, the user may be looking for more general information or may be asking the system to summarize or compare&#13;
     &#13;
      two documents.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     In these complex situations, which retriever should be used? It becomes clear that the best implementation is based on the combined strength of many retrieval systems. But this implicitly means that the RAG application must have an internal selection mechanism to choose the most appropriate retriever according to the query. This brings us to the topic of this section: the&#13;
     <a id="_idIndexMarker596">&#13;
     </a>&#13;
     use&#13;
     &#13;
      of&#13;
     &#13;
     &#13;
      <strong class="bold">&#13;
       selectors&#13;
      </strong>&#13;
     &#13;
     &#13;
      .&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     In LlamaIndex, they come in five different flavors:&#13;
     <code class="literal">&#13;
      LLMSingleSelector&#13;
     </code>&#13;
     ,&#13;
     <code class="literal">&#13;
      LLMMultiSelector&#13;
     </code>&#13;
     ,&#13;
     <code class="literal">&#13;
      EmbeddingSingleSelector&#13;
     </code>&#13;
     ,&#13;
     <code class="literal">&#13;
      PydanticSingleSelector&#13;
     </code>&#13;
     ,&#13;
     &#13;
      and&#13;
     &#13;
     &#13;
      <code class="literal">&#13;
       PydanticMultiSelector&#13;
      </code>&#13;
     &#13;
     &#13;
      .&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     The way they work is slightly different. As the name suggests, some rely on the decision capabilities of an LLM, others select a particular option from a list of options based on a similarity calculation, and others use Pydantic objects to return a selection. Some return a single option from a list; others may return multiple selections from a list of options. In the end, however, their result is more or less the same: they help us implement advanced conditional logic in the applications&#13;
     &#13;
      we develop.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     That is because they&#13;
     <a id="_idIndexMarker597">&#13;
     </a>&#13;
     can evaluate complex conditions and decide which logic branch the application should follow – just like an&#13;
     <em class="italic">&#13;
      IF</em>&#13;
     decision block, but able to handle more&#13;
     &#13;
      complex scenarios.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     The following diagram can help us better understand the role a selector plays in the logic of an RAG application.&#13;
     &#13;
      <em class="italic">&#13;
       Figure 6&#13;
      </em>&#13;
     &#13;
     <em class="italic">&#13;
      .12&#13;
     </em>&#13;
     , provides a visual representation of how&#13;
     &#13;
      <code class="literal">&#13;
       LLMSingleSelector&#13;
      </code>&#13;
     &#13;
     &#13;
      works:&#13;
     &#13;
    </p>&#13;
    <div>&#13;
     <div>&#13;
      <img src="img/B21861_06_12.jpg"/>&#13;
     </p>&#13;
    </div>&#13;
    <p class="IMG---Caption" lang="en-US">&#13;
     Figure 6.12 – Visualizing LLMSingleSelector&#13;
    </p>&#13;
    <p>&#13;
     Here is a very simple implementation of a selector that uses an LLM to return a single option from a list of&#13;
     &#13;
      predefined options:&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     In the first part of the code, we&#13;
     <a id="_idIndexMarker598">&#13;
     </a>&#13;
     defined the options as a list of strings to be sent to the LLM via the&#13;
     <code class="literal">&#13;
      .&#13;
     </code>&#13;
     &#13;
      <code class="literal">&#13;
       select()&#13;
      </code>&#13;
     &#13;
     &#13;
      method:&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     The&#13;
     <code class="literal">&#13;
      .select()&#13;
     </code>&#13;
     method takes the defined options and the user query as arguments. Under the hood, the selector uses a specially constructed prompt to ask the LLM to choose the best option from the list based on&#13;
     &#13;
      the query.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     As a response, the selector returns a&#13;
     <code class="literal">&#13;
      SingleSelection&#13;
     </code>&#13;
     object containing the number of the selected option and a justification for the selection made. As you can see, the selector is not something specific to retrievers. We haven’t even defined a retriever in&#13;
     &#13;
      this example.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     This is because I wanted to show that the mechanism is generic and can be used for absolutely any conditional logic we want to implement in the application. The returned option number could help us to choose from a list of parsers, indexes, retrievers, and so on. In this simple version, the selector simply chooses from a list of strings defining the available options. However, there is a more advanced form of selection that involves the use of the&#13;
     <code class="literal">&#13;
      ToolMetadata&#13;
     </code>&#13;
     class. But to understand this concept, we first need to clarify what a&#13;
     &#13;
      <strong class="bold">&#13;
       tool&#13;
      </strong>&#13;
     &#13;
     &#13;
      is.&#13;
     &#13;
    </p>&#13;
    <a id="_idTextAnchor146">&#13;
    </a>&#13;
    <h2 id="_idParaDest-147">&#13;
     Understanding tools&#13;
    </h2>&#13;
    <p>&#13;
     An essential element&#13;
     <a id="_idIndexMarker599">&#13;
     </a>&#13;
     in any&#13;
     <strong class="bold">&#13;
      agentic functionality&#13;
     </strong>&#13;
     , where the application decides which method to use depending on the context, is a generic container. It may contain different functionalities that can be called by&#13;
     <a id="_idIndexMarker600">&#13;
     </a>&#13;
     the application&#13;
     &#13;
      at runtime.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     There is a rich collection of tools already developed and available in LlamaHub:&#13;
     <a>&#13;
      https://llamahub.ai/?tab=tools&#13;
     </a>&#13;
     . They can perform various specific functions, from composing and sending emails to querying various APIs or interacting with the computer’s filesystem. We will talk much more about the use of tools in implementing&#13;
     <strong class="bold">&#13;
      agents&#13;
     </strong>&#13;
     in&#13;
     <a>&#13;
      &#13;
       <em class="italic">&#13;
        Chapter 8&#13;
       </em>&#13;
      &#13;
     </a>&#13;
     ,&#13;
     <em class="italic">&#13;
      Building Chatbots and Agents with LlamaIndex&#13;
     </em>&#13;
     , where we will build our&#13;
     &#13;
      PITS chatbot.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     For now, I want to show you how we can encapsulate a retriever in a tool container, and then use selectors to implement an adaptive retrieval mechanism. We will focus on the&#13;
     <code class="literal">&#13;
      RetrieverTool&#13;
     </code>&#13;
     class, which takes two important arguments: a retriever and a textual description of the retriever. Based on&#13;
     <a id="_idIndexMarker601">&#13;
     </a>&#13;
     the description, the selector decides, for example, whether to use one retriever or another for a particular query. We define a&#13;
     <code class="literal">&#13;
      RouterRetriever&#13;
     </code>&#13;
     object on top of each retriever we build. This&#13;
     <code class="literal">&#13;
      RouterRetriever&#13;
     </code>&#13;
     is a complex decision mechanism that uses the selector to decide which retriever to use depending on the situation. The most important arguments to give it are the selector and the options to choose from – in the form of&#13;
     <code class="literal">&#13;
      RetrieverTool&#13;
     </code>&#13;
     objects. Let’s see how we can implement this&#13;
     &#13;
      in code:&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     First, we took the two sample files from the&#13;
     <code class="literal">&#13;
      files&#13;
     </code>&#13;
     subfolder. The first file contains information about ancient Rome and the second is a generic text about dogs. Then, we created an index for&#13;
     <a id="_idIndexMarker602">&#13;
     </a>&#13;
     each file and from each index, we created a retriever. Now, we must define&#13;
     &#13;
      the tools:&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     As you can see, we have wrapped each retriever into&#13;
     <code class="literal">&#13;
      RetrieverTool&#13;
     </code>&#13;
     and added a clear description for the selector to use. Next, we must&#13;
     &#13;
      build&#13;
     &#13;
     &#13;
      <code class="literal">&#13;
       RouterRetriever&#13;
      </code>&#13;
     &#13;
     &#13;
      :&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     That’s all we need to do. From this point on, every time we query this dynamic retriever, the selector will determine which individual retriever to use to return the context. Here’s&#13;
     &#13;
      an example:&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     This will use&#13;
     <code class="literal">&#13;
      vector_tool&#13;
     </code>&#13;
     for retrieval. Now, take a look at the&#13;
     &#13;
      following code:&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     This will call&#13;
     <code class="literal">&#13;
      summary_tool&#13;
     </code>&#13;
     . Because we used&#13;
     <code class="literal">&#13;
      PydanticMultiSelector&#13;
     </code>&#13;
     , we can also handle situations where both retrievers should be used,&#13;
     &#13;
      like so:&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     Unlike&#13;
     <code class="literal">&#13;
      PydanticSingleSelector&#13;
     </code>&#13;
     ,&#13;
     <code class="literal">&#13;
      PydanticMultiSelector&#13;
     </code>&#13;
     can simultaneously select multiple options from the selector list, covering multiple use cases. Similarly, we can also define&#13;
     <a id="_idIndexMarker603">&#13;
     </a>&#13;
     more complex routers at the query engine level by using&#13;
     <code class="literal">&#13;
      RouterQueryEngine&#13;
     </code>&#13;
     . We will discuss this in more detail in&#13;
     <a>&#13;
      &#13;
       <em class="italic">&#13;
        Chapter 7&#13;
       </em>&#13;
      &#13;
     </a>&#13;
     &#13;
      .&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     First, we need to cover a few other advanced forms&#13;
     &#13;
      of retrievers.&#13;
     &#13;
    </p>&#13;
    <a id="_idTextAnchor147">&#13;
    </a>&#13;
    <h2 id="_idParaDest-148">&#13;
     Transforming and rewriting queries&#13;
    </h2>&#13;
    <p>&#13;
     In the previous section, we saw how&#13;
     <a id="_idIndexMarker604">&#13;
     </a>&#13;
     we can use selectors and the router concept to let the application decide which retriever&#13;
     &#13;
      to use.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     Another very powerful tool that our RAG application can use is the&#13;
     <code class="literal">&#13;
      QueryTransform&#13;
     </code>&#13;
     construct. This allows us to rewrite and modify a query before using it to interrogate the index, as shown in&#13;
     &#13;
      <em class="italic">&#13;
       Figure 6&#13;
      </em>&#13;
     &#13;
     &#13;
      <em class="italic">&#13;
       .13&#13;
      </em>&#13;
     &#13;
     &#13;
      :&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     <div>&#13;
      <img src="img/B21861_06_13.jpg"/>&#13;
     </p>&#13;
    </div>&#13;
    <p class="IMG---Caption" lang="en-US">&#13;
     Figure 6.13 – QueryTransform improving the retrieval process&#13;
    </p>&#13;
    <p>&#13;
     Let’s imagine a scenario where we&#13;
     <a id="_idIndexMarker605">&#13;
     </a>&#13;
     might need the functionality provided&#13;
     &#13;
      by&#13;
     &#13;
     &#13;
      <code class="literal">&#13;
       QueryTransform&#13;
      </code>&#13;
     &#13;
     &#13;
      .&#13;
     &#13;
    </p>&#13;
    <p class="callout-heading">&#13;
     Practical example&#13;
    </p>&#13;
    <p class="callout">&#13;
     <strong class="bold">&#13;
      A chatbot designed to provide technical support for complex software&#13;
     </strong>&#13;
     : Users often describe their problems in vague or non-technical terms.&#13;
     <code class="literal">&#13;
      QueryTransform&#13;
     </code>&#13;
     can interpret these descriptions, break them down into more specific sub-queries, or enrich them with technical terms that better match the documentation. For example, a query of the form&#13;
     <em class="italic">&#13;
      My computer keeps freezing&#13;
     </em>&#13;
     could be transformed into a more specific query, such as&#13;
     <em class="italic">&#13;
      Troubleshooting steps for operating&#13;
     </em>&#13;
     &#13;
      <em class="italic">&#13;
       system freezes&#13;
      </em>&#13;
     &#13;
     &#13;
      .&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     There are several variations of&#13;
     <code class="literal">&#13;
      QueryTransform&#13;
     </code>&#13;
     that we can use. Each has its specific role in augmenting the information retrieval process. Let’s look at&#13;
     &#13;
      each one:&#13;
     &#13;
    </p>&#13;
    <ul>&#13;
     <li>&#13;
      <code class="literal">&#13;
       IdentityQueryTransform&#13;
      </code>&#13;
      : This is a basic transform that does not modify the query. It returns the query as it was received, without any transformation. It’s useful for maintaining default or basic behavior where no specific transformations&#13;
      &#13;
       are required&#13;
      &#13;
     </li>&#13;
     <li>&#13;
      <code class="literal">&#13;
       HyDEQueryTransform&#13;
      </code>&#13;
      :&#13;
      <strong class="bold">&#13;
       Hypothetical Document Embeddings&#13;
      </strong>&#13;
      (&#13;
      <strong class="bold">&#13;
       HyDE&#13;
      </strong>&#13;
      ) transforms the query into a&#13;
      <a id="_idIndexMarker606">&#13;
      </a>&#13;
      hypothetical document generated by an LLM. The idea is to generate hypothetical query answers and use them as embedding strings. This can help improve the relevance of the results. This method filters out inaccurate details while&#13;
      <a id="_idIndexMarker607">&#13;
      </a>&#13;
      grounding the generated response in the actual content. You can read more about the benefits of using this technique here:&#13;
      <em class="italic">&#13;
       Gao, Luyu; Ma, Xueguang; Lin, Jimmy; Callan, Jamie (2022). “Precise Zero-Shot Dense Retrieval without Relevance Labels”. arXiv:2212.10496v1 [&#13;
      </em>&#13;
      &#13;
       <em class="italic">&#13;
        cs.IR].&#13;
       </em>&#13;
      &#13;
      &#13;
      &#13;
      <a>&#13;
       &#13;
        https://arxiv.org/abs/2212.10496&#13;
       &#13;
      </a>&#13;
     </li>&#13;
     <li>&#13;
      <code class="literal">&#13;
       DecomposeQueryTransform&#13;
      </code>&#13;
      : This type of transform decomposes a complex query into a simpler and more focused subquery. This can be useful to make queries easier for the index to process and increase the chances of finding relevant nodes, especially if the index structure is not optimized for complex or&#13;
      &#13;
       ambiguous queries&#13;
      &#13;
     </li>&#13;
     <li>&#13;
      <code class="literal">&#13;
       ImageOutputQueryTransform&#13;
      </code>&#13;
      : This method adds instructions for formatting results as images, such as generating HTML&#13;
      <em class="italic">&#13;
       &lt;img&gt;&#13;
      </em>&#13;
      tags. It is useful for cases where query results are expected to be displayed as images or when the output is just an intermediate step in more complex logic and has to be further processed in a&#13;
      &#13;
       particular format&#13;
      &#13;
     </li>&#13;
     <li>&#13;
      <code class="literal">&#13;
       StepDecomposeQueryTransform&#13;
      </code>&#13;
      : This is similar to&#13;
      <code class="literal">&#13;
       DecomposeQueryTransform&#13;
      </code>&#13;
      but it adds an extra layer by taking previous reasoning or context into account when decomposing the query. This can help to continually refine the query based on feedback or previous results, thus improving&#13;
      &#13;
       retrieval accuracy&#13;
      &#13;
     </li>&#13;
    </ul>&#13;
    <p>&#13;
     Each of these transformations improves a system’s ability to process and respond to queries in a more efficient way that is better tailored to the user’s specific needs or the nature of&#13;
     &#13;
      the data.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     Let’s have a look at a practical example to better understand how&#13;
     &#13;
      they work:&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     Once we run the code,&#13;
     <code class="literal">&#13;
      DecomposeQueryTransform&#13;
     </code>&#13;
     takes in our original – and otherwise very ambiguous – query. It then uses a specially designed prompt to generate a more precise query using the LLM. In our example, the output should look something&#13;
     &#13;
      like this:&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     You can immediately see&#13;
     <a id="_idIndexMarker608">&#13;
     </a>&#13;
     that the new query is much clearer and greatly increases the chances of the retriever generating a correct context from&#13;
     &#13;
      the index.&#13;
     &#13;
    </p>&#13;
    <a id="_idTextAnchor148">&#13;
    </a>&#13;
    <h2 id="_idParaDest-149">&#13;
     Creating more specific sub-queries&#13;
    </h2>&#13;
    <p>&#13;
     Another useful approach to&#13;
     <a id="_idIndexMarker609">&#13;
     </a>&#13;
     augmenting a query is to generate sub-queries. Sometimes, an ambiguous or very complex question becomes much clearer when it is split into several specific questions. LlamaIndex comes to our rescue this time too.&#13;
     <code class="literal">&#13;
      OpenAIQuestionGenerator&#13;
     </code>&#13;
     is a mechanism that’s designed exactly for this operation. Here is the code we used as an example earlier when we talked about selectors and routers. This time, we will adapt it a bit to demonstrate how&#13;
     &#13;
      <code class="literal">&#13;
       OpenAIQuestionGenerator&#13;
      </code>&#13;
     &#13;
     &#13;
      works:&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     So far, the code is identical to&#13;
     <a id="_idIndexMarker610">&#13;
     </a>&#13;
     the earlier example. We read the two files from the&#13;
     <code class="literal">&#13;
      files&#13;
     </code>&#13;
     subfolder and then create an index for&#13;
     &#13;
      each document:&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     For each index, we define a name and a description in a&#13;
     <code class="literal">&#13;
      ToolMetadata&#13;
     </code>&#13;
     structure. This information will be used by&#13;
     <code class="literal">&#13;
      OpenAIQuestionGenerator&#13;
     </code>&#13;
     to&#13;
     <em class="italic">&#13;
      understand&#13;
     </em>&#13;
     what role each retriever has and what type of questions it might answer. Next, we will define the&#13;
     &#13;
      two retrievers:&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     Now follows the generation of sub-queries. First, we initialize an&#13;
     <code class="literal">&#13;
      OpenAIQuestionGenerator&#13;
     </code>&#13;
     object with the default settings. Then, we build a&#13;
     <code class="literal">&#13;
      QueryBundle&#13;
     </code>&#13;
     object that will&#13;
     <a id="_idIndexMarker611">&#13;
     </a>&#13;
     contain the original query received from the user. This&#13;
     <code class="literal">&#13;
      QueryBundle&#13;
     </code>&#13;
     will be sent as an argument to the&#13;
     &#13;
      question generator:&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     As you can see, the subquery generator takes two arguments – a list of tools at its disposal, and the original query from which it can build more&#13;
     &#13;
      specific queries:&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     In the end, the generated questions might look something&#13;
     &#13;
      like this:&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     <code class="literal">&#13;
      OpenAIQuestionGenerator&#13;
     </code>&#13;
     took the initial query and, using the LLM, returned a list of more&#13;
     &#13;
      specific questions.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     The answer that’s returned in the&#13;
     <code class="literal">&#13;
      sub_questions&#13;
     </code>&#13;
     variable is a list of&#13;
     <code class="literal">&#13;
      SubQuestion&#13;
     </code>&#13;
     items - a simple class with two attributes:&#13;
     <code class="literal">&#13;
      tool_name&#13;
     </code>&#13;
     and&#13;
     <code class="literal">&#13;
      sub_question&#13;
     </code>&#13;
     . We can now iterate through all the items in the list and get the tools and questions we are&#13;
     &#13;
      looking for.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     In practice, using more specific queries, as in the preceding example, is likely to generate more context with the retriever and therefore likely to get a better-quality answer&#13;
     &#13;
      from&#13;
     &#13;
     &#13;
      <code class="literal">&#13;
       QueryEngine&#13;
      </code>&#13;
     &#13;
     &#13;
      .&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     As an alternative to&#13;
     <code class="literal">&#13;
      OpenAIQuestionGenerator&#13;
     </code>&#13;
     , it is good to know that there is also&#13;
     <code class="literal">&#13;
      LLMQuestionGenerator&#13;
     </code>&#13;
     , which, as its name suggests, allows us to use any LLM. Another difference&#13;
     <a id="_idIndexMarker612">&#13;
     </a>&#13;
     between the two is that&#13;
     <code class="literal">&#13;
      LLMQuestionGenerator&#13;
     </code>&#13;
     uses a special parser to structure the output, unlike&#13;
     <code class="literal">&#13;
      OpenAIQuestionGenerator&#13;
     </code>&#13;
     , which relies on the generation of&#13;
     &#13;
      Pydantic objects.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     The same collection of question generators also includes&#13;
     <code class="literal">&#13;
      GuidanceQuestionGenerator&#13;
     </code>&#13;
     . This mechanism uses an LLM to create helper questions to guide the query engine. It can be extremely useful when you’re dealing with complex queries that need to be broken down and processed in a&#13;
     &#13;
      particular order.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     Once these sub-queries have been generated, they can be used in a specially constructed query engine. We will discuss this step in more detail in&#13;
     <a>&#13;
      &#13;
       <em class="italic">&#13;
        Chapter 7&#13;
       </em>&#13;
      &#13;
     </a>&#13;
     ,&#13;
     <em class="italic">&#13;
      Querying Our Data, Part 2 – Postprocessing and Response Synthesis&#13;
     </em>&#13;
     , when we talk&#13;
     &#13;
      about&#13;
     &#13;
     &#13;
      <code class="literal">&#13;
       SubQuestionQueryEngine&#13;
      </code>&#13;
     &#13;
     &#13;
      .&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     Next, we’ll talk about two important concepts related to&#13;
     &#13;
      information retrieval.&#13;
     &#13;
    </p>&#13;
    <a id="_idTextAnchor149">&#13;
    </a>&#13;
   </div>&#13;
  </div>&#13;
 </body>&#13;
</html>
<html>&#13;
 <head>&#13;
  <title>&#13;
   Understanding the concepts of dense and sparse retrieval&#13;
  </title>&#13;
 </head>&#13;
 <body>&#13;
  <p>&#13;
   <h1 id="_idParaDest-150">&#13;
    Understanding the concepts of dense and sparse retrieval&#13;
   </h1>&#13;
   <div>&#13;
    pip install rank-bm25&#13;
pip install llama-index-retrievers-bm25&#13;
    from llama_index.retrievers.bm25 import BM25Retriever&#13;
from llama_index.core.node_parser import SentenceSplitter&#13;
from llama_index.core import SimpleDirectoryReader&#13;
reader = SimpleDirectoryReader('files')&#13;
documents = reader.load_data()&#13;
splitter = SentenceSplitter.from_defaults(&#13;
    chunk_size=60,&#13;
    chunk_overlap=0,&#13;
    include_metadata=False&#13;
)&#13;
nodes = splitter.get_nodes_from_documents(&#13;
    documents&#13;
)&#13;
    retriever = BM25Retriever.from_defaults(&#13;
    nodes=nodes,&#13;
    similarity_top_k=2&#13;
)&#13;
response = retriever.retrieve("Who built the Colosseum? ")&#13;
for node_with_score in response:&#13;
    print('Text:'+node_with_score.node.text)&#13;
    print('Score: '+str(node_with_score.score))&#13;
    <p>&#13;
     As we have seen, retrieval methods are a critical component of RAG systems. They enable the identification and ranking of relevant content for queries, which is the first step in generating useful answers from an LLM. During your journey into RAG application development, you’re&#13;
     <a id="_idIndexMarker613">&#13;
     </a>&#13;
     likely to encounter two&#13;
     <a id="_idIndexMarker614">&#13;
     </a>&#13;
     dominant retrieval paradigms –&#13;
     <strong class="bold">&#13;
      dense retrieval&#13;
     </strong>&#13;
     and&#13;
     <strong class="bold">&#13;
      sparse retrieval&#13;
     </strong>&#13;
     . Because it is important to understand these concepts, this section will focus on their characteristics, trade-offs, and the benefits of&#13;
     &#13;
      combining them.&#13;
     &#13;
    </p>&#13;
    <a id="_idTextAnchor150">&#13;
    </a>&#13;
    <h2 id="_idParaDest-151">&#13;
     Dense retrieval&#13;
    </h2>&#13;
    <p>&#13;
     The dense retrieval method relies on embedding vectors to represent text in a continuous, high-dimensional&#13;
     <a id="_idIndexMarker615">&#13;
     </a>&#13;
     space. Using embedding models, texts are&#13;
     <strong class="bold">&#13;
      encoded&#13;
     </strong>&#13;
     into fixed-length numerical vectors that are intended to capture semantic meaning. Queries are also encoded so that the similarity between them and the node vectors can be measured using geometric operations. In dense retrieval, nodes are embedded in vectors and stored in a specialized index such&#13;
     &#13;
      as&#13;
     &#13;
     &#13;
      <code class="literal">&#13;
       VectorStoreIndex&#13;
      </code>&#13;
     &#13;
     &#13;
      .&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     We call them&#13;
     <strong class="bold">&#13;
      dense&#13;
     </strong>&#13;
     because these vectors are typically densely populated with non-zero values, representing rich and nuanced semantic information in a compact form. During retrieval, incoming queries are dynamically embedded and used to retrieve the top-k nodes using similarity search algorithms, such as those discussed in&#13;
     <a>&#13;
      &#13;
       <em class="italic">&#13;
        Chapter 5&#13;
       </em>&#13;
      &#13;
     </a>&#13;
     &#13;
      .&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     This approach has several advantages, particularly in terms of semantic understanding, speed, and scalability. Nodes that convey similar meanings tend to cluster closer together. Also, the words themselves do not have to match perfectly. Synonyms and polysemous words don’t affect precision&#13;
     &#13;
      as much.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     Specialized indexing solutions, such as those provided by a Pinecone vector database (&#13;
     <a>&#13;
      https://www.pinecone.io/product/&#13;
     </a>&#13;
     ), also allow lightning-fast similarity searches over millions of vectors. Latencies range from milliseconds to less than a second and scaling is&#13;
     &#13;
      easily achieved.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     There are, however, several drawbacks associated with&#13;
     <a id="_idIndexMarker616">&#13;
     </a>&#13;
     &#13;
      dense search:&#13;
     &#13;
    </p>&#13;
    <ul>&#13;
     <li>&#13;
      <strong class="bold">&#13;
       Computational cost&#13;
      </strong>&#13;
      : Embedding and indexing large volumes of data can be computationally expensive&#13;
      &#13;
       and time-consuming.&#13;
      &#13;
     </li>&#13;
     <li>&#13;
      <strong class="bold">&#13;
       A trade-off between precision and recall&#13;
      </strong>&#13;
      : Dense retrieval systems can sometimes favor recall over precision or vice versa, depending on how the embedding model is tuned. Finding the right balance between retrieving all relevant documents and not retrieving too many irrelevant documents can&#13;
      &#13;
       be difficult.&#13;
      &#13;
     </li>&#13;
     <li>&#13;
      <strong class="bold">&#13;
       Difficulty in dealing with long documents&#13;
      </strong>&#13;
      : Dense models that generate fixed-length vectors can sometimes struggle with very long content, where important information can be diluted or lost in the&#13;
      &#13;
       embedding process.&#13;
      &#13;
     </li>&#13;
     <li>&#13;
      <strong class="bold">&#13;
       Logical reasoning gaps&#13;
      </strong>&#13;
      : While these methods are excellent at capturing semantic similarity, they typically lack logical reasoning capabilities. This means that they can identify documents that are semantically similar to the query but may struggle to understand&#13;
      <a id="_idIndexMarker617">&#13;
      </a>&#13;
      context or logical relationships that require reasoning beyond this pattern matching. As a result, they may retrieve documents that are&#13;
      <a id="_idIndexMarker618">&#13;
      </a>&#13;
      superficially related to the query but not truly relevant to the user’s intent, especially in cases where the query requires an understanding of complex relationships or&#13;
      &#13;
       nuanced reasoning.&#13;
      &#13;
     </li>&#13;
     <li>&#13;
      <strong class="bold">&#13;
       Dependence on model quality&#13;
      </strong>&#13;
      : The effectiveness of a dense retrieval system is highly dependent on the quality of the underlying embedding model. Poorly trained models can result in suboptimal&#13;
      &#13;
       retrieval performance.&#13;
      &#13;
     </li>&#13;
    </ul>&#13;
    <p>&#13;
     Next, we’ll talk about&#13;
     &#13;
      sparse retrieval.&#13;
     &#13;
    </p>&#13;
    <a id="_idTextAnchor151">&#13;
    </a>&#13;
    <h2 id="_idParaDest-152">&#13;
     Sparse retrieval&#13;
    </h2>&#13;
    <p>&#13;
     Sparse retrieval methods associate&#13;
     <a id="_idIndexMarker619">&#13;
     </a>&#13;
     documents with keywords. These methods are based on exact keyword matching or overlaps between the query and&#13;
     &#13;
      the documents.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     The general process involves indexing documents by analyzing them for important terms. These keywords are then recorded in inverted indexes, which are data structures used to quickly retrieve documents containing a&#13;
     &#13;
      given keyword.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     During the retrieval phase, queries are searched against these inverted indexes to find documents that share keywords with the query. Documents are ranked based on the number of common terms identified between the query and each indexed document. One of the most common techniques used in sparse&#13;
     <a id="_idIndexMarker620">&#13;
     </a>&#13;
     retrieval is the&#13;
     <strong class="bold">&#13;
      Term Frequency – Inverse Document Frequency&#13;
     </strong>&#13;
     (&#13;
     &#13;
      <strong class="bold">&#13;
       TF-IDF&#13;
      </strong>&#13;
     &#13;
     &#13;
      ) method.&#13;
     &#13;
    </p>&#13;
    <h3>&#13;
     TF-IDF in sparse retrieval&#13;
    </h3>&#13;
    <p>&#13;
     TF-IDF is a numerical statistic that reflects how important a word is to each document in a collection of documents. This method transforms text into a numerical representation that captures the significance of words in documents, taking into account both their frequency in individual documents and across the entire collection&#13;
     &#13;
      of documents.&#13;
     &#13;
    </p>&#13;
    <ul>&#13;
     <li>&#13;
      <strong class="bold">&#13;
       Term Frequency&#13;
      </strong>&#13;
      (&#13;
      <strong class="bold">&#13;
       TF&#13;
      </strong>&#13;
      ) measures&#13;
      <a id="_idIndexMarker621">&#13;
      </a>&#13;
      how often a term occurs in a&#13;
      <a id="_idIndexMarker622">&#13;
      </a>&#13;
      document, normalized by the total number of terms in the document. It’s calculated by dividing the number of times a particular term – that is, a word – appears in a document by the total number of words in that document. This indicates the importance of the term within the&#13;
      &#13;
       specific document.&#13;
      &#13;
     </li>&#13;
     <li>&#13;
      <strong class="bold">&#13;
       Inverse Document Frequency&#13;
      </strong>&#13;
      (&#13;
      <strong class="bold">&#13;
       IDF&#13;
      </strong>&#13;
      ) assesses the importance of the term across the collection. It is calculated by taking the logarithm of the ratio of the total number of documents to&#13;
      <a id="_idIndexMarker623">&#13;
      </a>&#13;
      the number of documents containing the term. This helps to downplay the importance of terms that occur very frequently in many documents. Common terms such as&#13;
      <em class="italic">&#13;
       the&#13;
      </em>&#13;
      or&#13;
      <em class="italic">&#13;
       is&#13;
      </em>&#13;
      appear in many documents and are less informative, so they have lower IDF scores. Unique terms have higher&#13;
      &#13;
       IDF scores.&#13;
      &#13;
     </li>&#13;
    </ul>&#13;
    <p>&#13;
     The&#13;
     <strong class="bold">&#13;
      TF-IDF score&#13;
     </strong>&#13;
     , which is obtained by&#13;
     <a id="_idIndexMarker624">&#13;
     </a>&#13;
     multiplying the TF by the IDF, represents the importance of each term in a document, adjusted for its commonness across the collection. In sparse retrieval, each document is represented as a vector in a high-dimensional space, where each dimension corresponds to a unique term and the value is the TF-IDF&#13;
     &#13;
      score:&#13;
     &#13;
     <a>&#13;
      &#13;
       https://en.wikipedia.org/wiki/Tf%E2%80%93idf&#13;
      &#13;
     </a>&#13;
     &#13;
      .&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     We call it&#13;
     <em class="italic">&#13;
      sparse&#13;
     </em>&#13;
     because, in this high-dimensional vector space, most dimensions (terms) will have a value of zero for any given document, indicating that most terms in the collection do not appear in that document. If we were to visualize these vectors, this would result in a&#13;
     <em class="italic">&#13;
      sparse&#13;
     </em>&#13;
     representation, with many zeros, as most documents contain only a small subset of the total vocabulary of&#13;
     &#13;
      the collection.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     During retrieval, a query is also converted into its TF-IDF vector representation. The relevance of each document to the query is calculated using measures such as cosine similarity, and the documents are ranked accordingly. The top-ranked documents with the highest similarity scores to the query are then returned&#13;
     &#13;
      as results.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     Sparse retrieval methods such as TF-IDF are particularly effective for tasks where exact term matching is important. However, they may not capture the semantic meaning of the text or the context in which terms are used, which can be addressed by more advanced retrieval techniques such as dense&#13;
     &#13;
      retrieval methods.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     As you’ve probably guessed, they have several advantages compared to&#13;
     &#13;
      dense retrieval:&#13;
     &#13;
    </p>&#13;
    <ul>&#13;
     <li>&#13;
      <strong class="bold">&#13;
       Efficient handling of large datasets&#13;
      </strong>&#13;
      : Sparse retrieval methods, such as TF-IDF, are generally more efficient at handling large datasets. The inverted index structure allows fast search and retrieval of documents based on keyword matching, making it suitable for large collections&#13;
      &#13;
       of text&#13;
      &#13;
     </li>&#13;
     <li>&#13;
      <strong class="bold">&#13;
       High precision&#13;
      </strong>&#13;
      : Sparse methods often&#13;
      <a id="_idIndexMarker625">&#13;
      </a>&#13;
      provide high accuracy in scenarios where the exact matching of terms is critical. They excel at retrieving documents that contain specific keywords present in the user’s query, which is beneficial in applications where keyword specificity&#13;
      &#13;
       is essential&#13;
      &#13;
     </li>&#13;
     <li>&#13;
      <strong class="bold">&#13;
       Simplicity and interpretability&#13;
      </strong>&#13;
      : Sparse retrieval methods are conceptually simpler and more interpretable than dense methods. The fact that they rely on explicit keyword frequencies makes it easier to understand why certain documents are retrieved in response to&#13;
      &#13;
       a query&#13;
      &#13;
     </li>&#13;
     <li>&#13;
      <strong class="bold">&#13;
       Less resource intensive&#13;
      </strong>&#13;
      : Unlike dense retrieval, sparse methods do not require complex neural network models to generate embeddings. This makes them less resource-intensive in terms of computing power and memory requirements. This means they’re easier to deploy&#13;
      &#13;
       and maintain&#13;
      &#13;
     </li>&#13;
     <li>&#13;
      <strong class="bold">&#13;
       Less dependence on model variability&#13;
      </strong>&#13;
      : Because sparse retrieval doesn’t depend on the nuances of machine learning models to the same extent as dense retrieval, it’s generally more robust to variations in model quality. Performance is more predictable and consistent across&#13;
      &#13;
       different datasets&#13;
      &#13;
     </li>&#13;
    </ul>&#13;
    <p>&#13;
     Sparse methods also have their limitations. Some of the most important are&#13;
     &#13;
      as follows:&#13;
     &#13;
    </p>&#13;
    <ul>&#13;
     <li>&#13;
      <strong class="bold">&#13;
       Lack of semantic understanding&#13;
      </strong>&#13;
      : Sparse methods may not capture the semantic relationships between words. They may miss documents that are contextually relevant but do not share exact keyword matches with&#13;
      &#13;
       the query.&#13;
      &#13;
     </li>&#13;
     <li>&#13;
      <strong class="bold">&#13;
       Vulnerability to synonymy and polysemy&#13;
      </strong>&#13;
      : These methods struggle with synonymy – different words with similar meanings – and polysemy – words with multiple meanings – leading to potential misses or&#13;
      &#13;
       irrelevant retrievals.&#13;
      &#13;
     </li>&#13;
     <li>&#13;
      <strong class="bold">&#13;
       Failure to capture context and nuance&#13;
      </strong>&#13;
      : Sparse retrieval does not effectively capture the broader context or nuances in language that can be critical to understanding&#13;
      <a id="_idIndexMarker626">&#13;
      </a>&#13;
      the true intent behind&#13;
      &#13;
       a query.&#13;
      &#13;
     </li>&#13;
    </ul>&#13;
    <a id="_idTextAnchor152">&#13;
    </a>&#13;
    <h2 id="_idParaDest-153">&#13;
     Implementing sparse retrieval in LlamaIndex&#13;
    </h2>&#13;
    <p>&#13;
     At a core level, constructs such as&#13;
     <code class="literal">&#13;
      KeywordTableIndex&#13;
     </code>&#13;
     can already be considered a basic form of sparse retrieval. After all, they share most of the principles and methods described above. However, there are&#13;
     <a id="_idIndexMarker627">&#13;
     </a>&#13;
     even more advanced&#13;
     <a id="_idIndexMarker628">&#13;
     </a>&#13;
     sparse retrieval capabilities available&#13;
     &#13;
      in LlamaIndex.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     A perfect example is&#13;
     <code class="literal">&#13;
      BM25Retriever&#13;
     </code>&#13;
     , which implements the&#13;
     <strong class="bold">&#13;
      Best Matching 25&#13;
     </strong>&#13;
     (&#13;
     <strong class="bold">&#13;
      BM25&#13;
     </strong>&#13;
     )&#13;
     &#13;
      retrieval algorithm.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     BM25, a refinement of the TF-IDF method, is a more sophisticated algorithm that’s used for sparse retrieval. Unlike TF-IDF, BM25 takes into account both term frequency and document length, providing a more nuanced approach to document relevance scoring. With this retriever, nodes are ranked based on their BM25 scores relative to the query. The top-k nodes with the highest scores are returned as query results, providing users with the most&#13;
     &#13;
      relevant results.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     Let’s look at an example of how we can&#13;
     &#13;
      use&#13;
     &#13;
     &#13;
      <code class="literal">&#13;
       BM25Retriever&#13;
      </code>&#13;
     &#13;
     &#13;
      .&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     To use this particular retriever, you’ll need to install the required Python package and the corresponding LlamaIndex integration package by running the&#13;
     &#13;
      following commands:&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     After installing the&#13;
     <code class="literal">&#13;
      rank-bm25&#13;
     </code>&#13;
     package, you can test it with this&#13;
     &#13;
      sample code:&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     We’re using the two initial&#13;
     <a id="_idIndexMarker629">&#13;
     </a>&#13;
     sample files containing data about ancient Rome and different breeds of dogs. In this example, I’ve used&#13;
     <code class="literal">&#13;
      SentenceSplitter&#13;
     </code>&#13;
     , configured with a relatively small chunk size. That is because the sample file is small in size and I&#13;
     <a id="_idIndexMarker630">&#13;
     </a>&#13;
     wanted to produce more granular nodes structured as sentences to better exemplify the workings of&#13;
     <code class="literal">&#13;
      BM25Retriever&#13;
     </code>&#13;
     . Next, let’s implement&#13;
     &#13;
      the retriever:&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     After chunking the two documents, we use the retriever to apply the BM25 algorithm and retrieve the two most relevant chunks relative to our query about&#13;
     &#13;
      the Colosseum.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     You can further experiment with&#13;
     <a id="_idIndexMarker631">&#13;
     </a>&#13;
     this sample and try to adjust the&#13;
     <code class="literal">&#13;
      similarity_top_k&#13;
     </code>&#13;
     parameter, the query, or the chunking strategy to better understand&#13;
     <a id="_idIndexMarker632">&#13;
     </a>&#13;
     how this&#13;
     &#13;
      retriever works.&#13;
     &#13;
    </p>&#13;
    <h3>&#13;
     When should we use sparse retrieval instead of dense retrieval?&#13;
    </h3>&#13;
    <p>&#13;
     Let’s consider a practical example&#13;
     <a id="_idIndexMarker633">&#13;
     </a>&#13;
     of when sparse retrieval might give better results than dense retrieval in an&#13;
     &#13;
      RAG application.&#13;
     &#13;
    </p>&#13;
    <p class="callout-heading">&#13;
     A practical use case for sparse retrieval&#13;
    </p>&#13;
    <p class="callout">&#13;
     Suppose we’ve built a system for retrieving legal documents. In this scenario, user queries would likely include precise legal terms, citations, or specific phrases found in legal texts. Let’s assume a user inputs a query such as, “&#13;
     <em class="italic">&#13;
      Article 45 of the GDPR regarding personal data transfers on the basis of an adequacy decision.&#13;
     </em>&#13;
     ” This query contains specific phrases, such as “Article 45” and “GDPR,” which are likely to be found in relevant legal documents exactly in&#13;
     &#13;
      this form.&#13;
     &#13;
    </p>&#13;
    <p class="callout">&#13;
     Sparse search is likely to provide very accurate results for such a query. It will accurately locate documents that contain the specific article from the GDPR, reducing noise and irrelevant retrievals. Given that legal documents often have a structured format, with different sections and articles, sparse retrieval methods can efficiently parse through this structured data and retrieve nodes based on direct references found in&#13;
     &#13;
      the query.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     Because dense retrieval methods tend to prioritize general meaning over exact term matching, they may produce less accurate results in such a specialized,&#13;
     &#13;
      keyword-specific query.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     Unless trained specifically on legal texts, an embedding model used for dense retrieval might struggle to accurately interpret and match the complex legal jargon and specific citation styles used in&#13;
     &#13;
      legal queries.&#13;
     &#13;
    </p>&#13;
    <h3>&#13;
     When would dense retrieval be a better choice?&#13;
    </h3>&#13;
    <p>&#13;
     Here’s another&#13;
     &#13;
      practical example.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     A typical use case where dense retrieval would most likely produce better results would be a customer support chatbot&#13;
     <a id="_idIndexMarker634">&#13;
     </a>&#13;
     designed to understand and respond to a wide range of customer queries. Let’s&#13;
     <a id="_idIndexMarker635">&#13;
     </a>&#13;
     say the chatbot is tasked with assisting users with various issues&#13;
     <a id="_idIndexMarker636">&#13;
     </a>&#13;
     related to technical products, such as hardware troubleshooting, software features, usage tips, and general inquiries about products&#13;
     &#13;
      and services.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     A user might ask a question such as “&#13;
     <em class="italic">&#13;
      My laptop battery is draining really quickly, even when I’m not using it much. What can I do about it?&#13;
     </em>&#13;
     ” Because dense search excels at understanding the semantic context of queries, in this case, it could understand the broader meaning behind phrases such as “battery drains really fast” and relate them to similar problems, even if the exact phrase isn’t in the&#13;
     &#13;
      knowledge base.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     Sparse methods, on the other hand, may not perform well if the query doesn’t contain specific keywords that are present in the support documents. In our example, the user might describe a problem using different terms to those used in the technical manuals&#13;
     &#13;
      or FAQs.&#13;
     &#13;
    </p>&#13;
    <h3>&#13;
     Can we combine the two methods in a single retriever?&#13;
    </h3>&#13;
    <p>&#13;
     The short answer is yes. You’ve probably already guessed that I’m building a case along these lines. By combining them, we’d get the best of both worlds in terms of benefits and features. A few pages ago, we talked about using selectors and routers to implement more complex query behavior in our&#13;
     &#13;
      RAG application.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     I’ll leave it up to you to adapt the methods I’ve demonstrated there and implement a hybrid system that uses both dense and sparse retrieval methods. If you feel the need for an additional example, you can have a look at this one, which uses the Pinecone vector database to implement hybrid&#13;
     &#13;
      search:&#13;
     &#13;
     <a>&#13;
      &#13;
       https://docs.llamaindex.ai/en/stable/examples/vector_stores/PineconeIndexDemo-Hybrid.html&#13;
      &#13;
     </a>&#13;
     &#13;
      .&#13;
     &#13;
    </p>&#13;
    <h3>&#13;
     Dealing with empty results from the retrieval process&#13;
    </h3>&#13;
    <p>&#13;
     Sometimes, our retrievers may come up empty-handed, without finding any indexed content matching the current query. This typically means that there are no relevant nodes in the index for that&#13;
     &#13;
      particular query.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     In such cases, the retriever may return an empty result set, indicating that no matching nodes were found. Depending on the type of index used, this situation can arise if the query keywords are very specific or rare, and none of the nodes in the index contain those exact keywords, or, in the case of embedding-based indexes, the similarity search that was performed during the search did not find any matching nodes with the current parameters used. To handle this scenario, we can consider&#13;
     &#13;
      various approaches:&#13;
     &#13;
    </p>&#13;
    <ul>&#13;
     <li>&#13;
      <strong class="bold">&#13;
       Fallback mechanisms&#13;
      </strong>&#13;
      : The search system can have fallback strategies in place, such as performing a more general search by adjusting the retriever’s parameters or suggesting alternative query terms to&#13;
      &#13;
       the user.&#13;
      &#13;
     </li>&#13;
     <li>&#13;
      <strong class="bold">&#13;
       Query expansion&#13;
      </strong>&#13;
      : The query can be automatically expanded to include synonyms, related terms, or broader concepts to increase the chances of finding&#13;
      &#13;
       relevant nodes.&#13;
      &#13;
     </li>&#13;
     <li>&#13;
      <strong class="bold">&#13;
       Relevance scoring&#13;
      </strong>&#13;
      : Even if no exact keyword matches are found, the search system can employ relevance&#13;
      <a id="_idIndexMarker637">&#13;
      </a>&#13;
      scoring algorithms to identify nodes that are semantically similar&#13;
      <a id="_idIndexMarker638">&#13;
      </a>&#13;
      to the query or contain&#13;
      &#13;
       partial matches.&#13;
      &#13;
     </li>&#13;
    </ul>&#13;
    <a id="_idTextAnchor153">&#13;
    </a>&#13;
    <h2 id="_idParaDest-154">&#13;
     Discovering other advanced retrieval methods&#13;
    </h2>&#13;
    <p>&#13;
     In addition to the basic concepts just discussed, several other advanced retrieval methods are worth familiarizing yourself with. There is a special section in the official documentation where these methods are&#13;
     &#13;
      explained:&#13;
     &#13;
     <a>&#13;
      &#13;
       https://docs.llamaindex.ai/en/stable/optimizing/advanced_retrieval/advanced_retrieval.html&#13;
      &#13;
     </a>&#13;
     &#13;
      .&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     There, you will learn more about special techniques, such as&#13;
     <em class="italic">&#13;
      Small-to-Big&#13;
     </em>&#13;
     <em class="italic">&#13;
      retrieval&#13;
     </em>&#13;
     ,&#13;
     <em class="italic">&#13;
      recursive retrieval&#13;
     </em>&#13;
     ,&#13;
     <em class="italic">&#13;
      retrieval from embedded tables&#13;
     </em>&#13;
     ,&#13;
     <em class="italic">&#13;
      multi-modal retrieval&#13;
     </em>&#13;
     ,&#13;
     <em class="italic">&#13;
      auto-merging retrieval&#13;
     </em>&#13;
     ,&#13;
     &#13;
      and others.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     A detailed explanation of each retrieval strategy would go far beyond what I intend to cover in this book, but that doesn’t mean they aren’t important. After all, there is no point in ingesting and indexing the original documents if we cannot effectively extract the context we need&#13;
     &#13;
      in RAG.&#13;
     &#13;
    </p>&#13;
    <p class="callout-heading">&#13;
     Practical advice&#13;
    </p>&#13;
    <p class="callout">&#13;
     Always read the latest version of the official documentation before starting a major project. Things move so fast, and new methods and techniques emerge so quickly, that it is a shame to waste time reinventing the wheel. As an anecdote, I can tell you from personal experience that I have spent hours&#13;
     <em class="italic">&#13;
      inventing&#13;
     </em>&#13;
     something very similar to the&#13;
     <em class="italic">&#13;
      small-to-big&#13;
     </em>&#13;
     method, only to discover a few days later that it was already a tested and&#13;
     &#13;
      documented technique.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     That’s enough information&#13;
     <a id="_idIndexMarker639">&#13;
     </a>&#13;
     for one chapter. We’ll skip the PITS coding practice now as we’ll let more&#13;
     <a id="_idIndexMarker640">&#13;
     </a>&#13;
     information accumulate in the next chapter before implementing additional features in our personal&#13;
     &#13;
      tutoring project.&#13;
     &#13;
    </p>&#13;
    <a id="_idTextAnchor154">&#13;
    </a>&#13;
   </p>&#13;
  </div>&#13;
 </body>&#13;
</html>
<html>&#13;
 <head>&#13;
  <title>&#13;
   Summary&#13;
  </title>&#13;
 </head>&#13;
 <body>&#13;
  <p>&#13;
   <h1 id="_idParaDest-155">&#13;
    Summary&#13;
   </h1>&#13;
   <div>&#13;
    <p>&#13;
     In this chapter, we explored various querying strategies and architectures within LlamaIndex with a deep focus on retrievers. Retrievers provide essential capabilities for extracting relevant information from indexes to generate useful responses in RAG systems. Throughout this chapter, we looked at basic retriever types such as&#13;
     <code class="literal">&#13;
      VectorIndexRetriever&#13;
     </code>&#13;
     and&#13;
     <code class="literal">&#13;
      SummaryIndexRetriever&#13;
     </code>&#13;
     . We also gained an understanding of advanced concepts such as asynchronous retrieval, metadata filters, tools, selectors, and query transformations. These allow us to build more sophisticated&#13;
     &#13;
      retrieval logic.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     Additionally, we covered fundamental paradigms such as dense retrieval and sparse retrieval and discussed their strengths and weaknesses. Implementations in LlamaIndex such as BM25Retriever were&#13;
     &#13;
      also introduced.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     Overall, this chapter provided an overview of retrieval capabilities in LlamaIndex, laying the foundation for building high-performance and contextually-aware&#13;
     &#13;
      RAG applications.&#13;
     &#13;
    </p>&#13;
    <p>&#13;
     We’re now equipped with the necessary knowledge to effectively retrieve information from indexes. In the next chapter, we’ll build on this knowledge by addressing the other important components of a query engine: post-processors and&#13;
     &#13;
      response synthesizers.&#13;
     &#13;
    </p>&#13;
   </p>&#13;
  </div>&#13;
 </body>&#13;
</html></body></html>