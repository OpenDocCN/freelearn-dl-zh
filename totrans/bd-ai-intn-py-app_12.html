<html><head></head><body>
		<div id="_idContainer094">
			<h1 class="chapter-number" id="_idParaDest-210"><a id="_idTextAnchor253"/>12</h1>
			<h1 id="_idParaDest-211"><a id="_idTextAnchor254"/>Correcting and Optimizing Your Generative AI Application</h1>
			<p>Until this point, you’ve read about how to build a <strong class="bold">generative AI</strong> (<strong class="bold">GenAI</strong>) application, its various components, and how they fit together. You've gained a solid understanding of what makes them work (and not work) well. You’re also aware of some of the challenges of GenAI applications and how to <span class="No-Break">identify them.</span></p>
			<p>In this chapter, you’ll begin unraveling the mystery of how to <em class="italic">improve</em> your GenAI application once you’ve identified its shortcomings. You will also learn about optimizing and fine-tuning your GenAI application, so it’s a reliable, effective, and stable machine working in your favor, instead of a rogue actor <span class="No-Break">bringing chaos.</span></p>
			<p>This chapter will discuss several well-known techniques to improve your GenAI application, so you can be confident in your finished product. Ideally, you will perform all of these techniques. The chapter will define each of these and explain how they can improve your application. Then, you will complete a robust example of each of these as an activity. By the end of this chapter, you will have many ideas on how to improve <span class="No-Break">your application.</span></p>
			<p>This chapter will cover the <span class="No-Break">following topics:</span></p>
			<ul>
				<li><span class="No-Break">Baselining</span></li>
				<li>Training and <span class="No-Break">evaluation datasets</span></li>
				<li><span class="No-Break">Few-shot prompting</span></li>
				<li>Retrieval <span class="No-Break">and reranking</span></li>
				<li>Late interaction strategies, including in-application feedback and user <span class="No-Break">feedback loops</span></li>
				<li><span class="No-Break">Query rewriting</span></li>
				<li>Testing and <span class="No-Break">red teaming</span></li>
				<li><span class="No-Break">Information post-processing</span></li>
			</ul>
			<h1 id="_idParaDest-212"><a id="_idTextAnchor255"/>Technical requirements</h1>
			<p>This chapter does not contain any coding. However, it builds upon all the previous chapters to describe various methodologies for improving and optimizing your GenAI application output. To recreate some of the examples, you’ll simply need to use your favorite <strong class="bold">large language model</strong> (<strong class="bold">LLM</strong>) provider and recreate the attempts yourself. This chapter <span class="No-Break">uses ChatGPT.</span></p>
			<h1 id="_idParaDest-213"><a id="_idTextAnchor256"/>Baselining</h1>
			<p><strong class="bold">Baselining</strong>, in the context of GenAI, refers to the process of defining a standard or a reference output for the AI model to compare future outputs. This standard serves as a crucial benchmark for evaluating the model’s performance, consistency, and improvements over time. By establishing a baseline, developers and stakeholders can objectively measure how the AI performs relative to a predefined set of expectations, ensuring that the model meets and maintains <span class="No-Break">desired standards.</span></p>
			<p>In GenAI, baselining is essential for several reasons. Firstly, it provides a clear metric for assessing the quality and performance of the AI model. Secondly, it helps in tracking the model’s progress and improvements over time. Finally, baselining is a tool to help ensure consistency in the model’s outputs, via detection of output variability. All of these are vital for maintaining reliability and trust in the <span class="No-Break">AI system.</span></p>
			<p>The aspects of the AI model that can be baselined are numerous and highly dependent on the specific application and its goals. Some common elements that might be baselined include <span class="No-Break">the following:</span></p>
			<ul>
				<li><strong class="bold">Accuracy</strong>: This involves measuring the correctness of the model’s outputs. For instance, in a language model, accuracy can be gauged by how well the generated text matches the expected text or how often it provides the <span class="No-Break">correct information.</span></li>
				<li><strong class="bold">Speed of response</strong>: This refers to the time it takes for the model to generate an output after receiving an input. Faster response times are generally preferred, especially in <span class="No-Break">real-time applications.</span></li>
				<li><strong class="bold">Effectiveness</strong>: This can be a measure of how well the AI meets its intended purpose. For example, in a recommendation system, effectiveness might be assessed by the relevance and personalization of the <span class="No-Break">recommendations provided.</span></li>
				<li><strong class="bold">User satisfaction</strong>: This subjective metric can be gauged through user feedback and surveys, reflecting how satisfied users are with the AI’s performance <span class="No-Break">and outputs.</span></li>
			</ul>
			<p>Establishing a baseline standard alongside your current performance also helps you—the engineer—determine whether you are improving results over time. This knowledge is crucial for ensuring that your application is not degrading in performance. In some industries, baseline performance indicators may be required to meet industry or regulatory standards and may be a reporting requirement for your application <span class="No-Break">or organization.</span></p>
			<p>Once you evaluate the initial performance of your application, you’ll want to document these results. Subsequently, ensure that you consistently compare the model’s outputs to the baseline during each training and update cycle. Comprehensive documentation provides a reference that can be used to compare future outputs and identify trends or issues in the <span class="No-Break">model’s performance.</span></p>
			<p>Regular evaluation of the model’s outputs against the baseline is also critical. During subsequent iterations of training and updates, these evaluations can help in detecting deviations from the expected (baseline) performance. If the model’s performance drops below the baseline, it can indicate a problem that needs to be addressed, such as data drift, changes in user behavior, or issues with the <span class="No-Break">training dataset.</span></p>
			<h2 id="_idParaDest-214"><a id="_idTextAnchor257"/>Training and evaluation datasets</h2>
			<p>To create your baseline, you will need to create an <strong class="bold">evaluation dataset</strong>. An evaluation dataset is a series of questions asked of your application to determine whether it meets the standards you have identified. Note that the evaluation dataset is not to be confused with the <strong class="bold">training dataset</strong>, which is the data that you used to <em class="italic">train</em> your model. The evaluation dataset should be a wholly different set of questions and answers. Effectively, the training dataset is akin to the notes and sources that you’d give to a student to learn, while the evaluation dataset is like the final exam. You don’t want to make that exam <span class="No-Break">too easy!</span></p>
			<h3>Training datasets</h3>
			<p>As its name suggests, a training dataset is a collection of data used to teach or <em class="italic">train</em> a machine learning model. It contains input-output pairs where the input data is fed to the model, and the model learns to produce the correct output. This process involves adjusting the model’s parameters so that it can generalize well to new, unseen data. The quality and diversity of the training dataset directly impact the performance and accuracy of the <span class="No-Break">trained model.</span></p>
			<p>High-quality training data ensures that the model can recognize patterns and make accurate predictions or generate appropriate responses. Therefore, your training dataset should be representative of the problem domain, covering a wide range of scenarios that the model would be expected to encounter in real-world applications. This helps in reducing biases and improving the <span class="No-Break">model’s generalizability.</span></p>
			<p>The types of data in the training dataset might include <span class="No-Break">the following:</span></p>
			<ul>
				<li><strong class="bold">Labeled data</strong>: This is the primary type of data used in supervised learning. Each data point consists of an input and a corresponding correct output, or label. For instance, in a text classification task, labeled data might include sentences paired with their <span class="No-Break">respective categories.</span></li>
				<li><strong class="bold">Unlabeled data</strong>: Used in unsupervised learning, this data does not come with predefined labels. The model tries to find patterns and structures in the data. For example, clustering algorithms use unlabeled data to group similar data <span class="No-Break">points together.</span></li>
				<li><strong class="bold">Mixed data</strong>: Semi-supervised learning uses a combination of labeled and unlabeled data. This approach leverages the large amounts of unlabeled data available while benefiting from the smaller labeled dataset to guide the <span class="No-Break">learning process.</span></li>
				<li><strong class="bold">Diverse data</strong>: Including diverse data ensures that the model can handle various inputs. This might include different languages, dialects, formats, and contexts. For certain types of applications, this might include training data that is both human-readable documentation as well as <span class="No-Break">code bases.</span></li>
			</ul>
			<p>Despite all that, you might wish to also include <strong class="bold">supplemental training data</strong>. Supplemental training data refers to additional data used to fine-tune or enhance the performance of an already trained model. There are many reasons to do this, but let’s talk about three that are <span class="No-Break">particularly compelling:</span></p>
			<ul>
				<li>Supplemental data can help adapt a general model to a specific domain. For example, a language model trained on general text might be fine-tuned with medical literature to perform better in <span class="No-Break">healthcare applications.</span></li>
				<li>Supplemental training data can be used to enhance the model’s ability in particular areas where it might be weak. For example, adding more data related to financial transactions can help a fraud detection model become <span class="No-Break">more accurate.</span></li>
				<li>As new information becomes available, supplemental training data can be used to update the model’s knowledge. This is especially relevant for applications requiring up-to-date information, such as news generation or where the industry is rapidly evolving (such <span class="No-Break">as technology).</span></li>
			</ul>
			<h3>Evaluation datasets</h3>
			<p>In addition to your training data and supplemental data, you’ll also need an evaluation dataset. Evaluation datasets are crucial because they provide a controlled and consistent way to measure the performance of your AI model. They serve as a benchmark for comparison, ensuring that the model’s outputs can be objectively assessed against predefined criteria. By using a standard dataset, you can reliably track improvements, identify weaknesses, and maintain the quality of the model over time. It helps in validating that the model is not only performing well during the development phase but also generalizing effectively to new, <span class="No-Break">unseen data.</span></p>
			<p>The content of an evaluation dataset depends on the specific application and its goals. Generally, it should include <span class="No-Break">the following:</span></p>
			<ul>
				<li><strong class="bold">Representative queries</strong>: A variety of questions or inputs that the AI is likely to encounter in real-world usage. These should cover different scenarios and edge cases to ensure a <span class="No-Break">comprehensive evaluation.</span></li>
				<li><strong class="bold">Expected outputs</strong>: Corresponding correct or ideal responses for each query, against which the AI’s responses will <span class="No-Break">be compared.</span></li>
				<li><strong class="bold">Diverse data</strong>: Data that reflects the diversity of inputs the model will face, including variations in language, format, and context. This helps in assessing the model’s robustness and ability to handle different types <span class="No-Break">of input.</span></li>
			</ul>
			<p>For example, the evaluation dataset for the MongoDB documentation chatbot includes questions and answers to the top 250 search terms, top 250 support questions by volume, and some of the most common questions asked about MongoDB. This can take the form of simple keywords or actual phrases in full-sentence format, <span class="No-Break">like so:</span></p>
			<pre class="source-code">
Mongodb install
Install mongodb ubuntu
Mongodb connection string
$in mongodb
How to create a collection in mongodb
What is an aggregation pipeline
Cannot deserialize a 'String' from BsonType 'ObjectId' in C#</pre>			<p>These terms and questions were retrieved from a combination of sources, which will vary depending on your infrastructure. For MongoDB, this infrastructure comes from the Google search console for <a href="http://mongodb.com"><span class="P---URL">mongodb.com</span></a> as well as the support chat, community forums, and <span class="No-Break">Stack Overflow.</span></p>
			<p>Determining the right amount of evaluation involves balancing thoroughness with practicality. You should have enough data to cover a wide range of scenarios and ensure the outputs of your GenAI application are consistently accurate and reliable. Typically, this involves hundreds or even thousands of data points, depending on the complexity of <span class="No-Break">the application.</span></p>
			<p>That said, while more data can provide a more comprehensive assessment, there is a point of diminishing returns where additional data does not significantly improve the evaluation but adds to the complexity and resource requirements. <strong class="bold">Over-evaluation</strong> can also lead to overfitting of the evaluation dataset rather than improving overall performance. Returning to the earlier student/exam analogy, you don’t want your evaluation exam to be an exact replica of the training materials because all you would be testing then is whether the student was able to memorize a question and response. You would not be testing how well the student has learned <span class="No-Break">the material.</span></p>
			<p>In summary, ensuring high-quality, accurate, and comprehensive training and evaluation datasets can reduce the likelihood of the model learning incorrect patterns. This requires significant effort upfront before deployment of the GenAI application but can dramatically improve your GenAI accuracy and depth of response as well as ensure its quality of responses to <span class="No-Break">your users.</span></p>
			<h2 id="_idParaDest-215"><a id="_idTextAnchor258"/>Few-shot prompting</h2>
			<p>In many cases, you will be asking your GenAI application to produce new content or summarize existing content, in which case what you need to do is provide the existing application with a properly engineered prompt. Most of the time, having the user simply request what they need is sufficient. But in cases where the outputs are complex, you will find that the quality and accuracy of the GenAI application’s response are improved by using a technique called <strong class="bold">few-shot prompting</strong>. Few-shot prompting is when you provide an example as part of the input to the LLM so that it can see exactly what type of syntax and response you need. You can also include a definition as part of the example in case you believe the input might be a term with which the LLM would not be familiar, or in case you’re using a <span class="No-Break">business-specific term.</span></p>
			<p>Let’s try out an example <span class="No-Break">using GPT-4.</span></p>
			<p><strong class="bold">Example 1</strong>: Let’s see how the LLM responds to a request that does not use <span class="No-Break">few-shot prompting.</span></p>
			<p>This is the <span class="No-Break">user input:</span></p>
			<pre class="source-code">
Please generate a linkedin post less than 500 words about the company OpenAI.</pre>			<p>Here is <span class="No-Break">the output:</span></p>
			<pre class="source-code">
🚀 Pioneering the Future with OpenAI 🚀
In the dynamic world of technology, OpenAI stands as a beacon of innovation and progress. Their mission to advance artificial general intelligence (AGI) is not just envisioning the future; they are actively shaping it.
OpenAI operates under the guidance of visionary leaders like CEO Sam Altman. Their cutting-edge research is pushing the boundaries of what's possible in AI, crafting a future where technology enhances human capabilities and opens new realms of possibility.
From healthcare to finance, and education to entertainment, OpenAI's innovations are leaving an indelible mark. Their models, such as GPT-4, are revolutionizing how we interact with technology. Businesses are leveraging these tools to enhance customer experiences, streamline operations, and achieve unprecedented levels of productivity.
OpenAI thrives on collaboration, partnering with organizations worldwide to accelerate innovation. Their open research culture demonstrates a belief in collective progress. By sharing insights, tools, and findings, OpenAI is democratizing access to AI, empowering developers, researchers, and businesses to push the boundaries of what's possible. Through initiatives like the OpenAI Scholars and Fellows programs, they are nurturing the next generation of AI talent. These programs provide mentorship, resources, and opportunities to individuals from diverse backgrounds, ensuring a wealth of perspectives and ideas in AI development.
Join the conversation and be part of the future OpenAI is creating.
#AI #OpenAI #Innovation #Technology #Future #Collaboration #Leadership</pre>			<p><strong class="bold">Example 2</strong>: Now, let’s try this example with <span class="No-Break">few-shot prompting.</span></p>
			<p>This is the <span class="No-Break">user input:</span></p>
			<pre class="source-code">
Please generate a linkedin post focusing on the OpenAI company. It should be less than 500 words in length. Also, please match the tone, syntax, word choices, and style of this passage:"There's a way to do it better. Find it." — Thomas Edison
"Lies. We are being lied to. We are told that technology takes our jobs, reduces our wages, increases inequality, threatens our health, ruins the environment, degrades our society, corrupts our children, impairs our humanity, threatens our future, and is ever on the verge of ruining everything.
We are told to be angry, bitter, and resentful about technology. We are told to be pessimistic. The myth of Prometheus – in various updated forms like Frankenstein, Oppenheimer, and Terminator – haunts our nightmares. We are told to denounce our birthright – our intelligence, our control over nature, our ability to build a better world. We are told to be miserable about the future." –Marc Andreessen</pre>			<p>Here is <span class="No-Break">the output:</span></p>
			<pre class="source-code">
We are told that artificial intelligence is a threat, that it steals our jobs, that it widens the chasm of inequality, that it's an invisible force eroding our humanity. We are told that AI is an uncontrollable beast, ready to plunge us into dystopia.
OpenAI is here to shatter these myths.
Founded on the principle of advancing digital intelligence for the collective good, OpenAI isn't just another tech company. It's a bold proclamation that the future is ours to shape. OpenAI stands as a beacon against the darkness of misinformation and fearmongering. It's a rallying cry for innovation, for the relentless pursuit of better.
Imagine a world where AI enhances every aspect of our lives—where it amplifies human potential rather than diminishes it. OpenAI's groundbreaking models, like GPT-4, are not instruments of destruction but tools of empowerment. From revolutionizing healthcare to transforming education, from pioneering new frontiers in entertainment to optimizing complex financial systems, OpenAI's innovations are the keystones of a new era.
OpenAI is driven by visionaries who refuse to bow to the pessimism that pervades our discourse. That we are a testament to what can be achieved when we refuse to accept the status quo. We are the architects of tomorrow, wielding AI not as a weapon, but as a bridge.</pre>			<p>You can see how, by providing the example text, you can enhance the output to make it match whatever syntax you prefer. The additional prompt information need not be terribly difficult to produce either. If you can provide an example output to your GenAI application, its results will be much nearer to what <span class="No-Break">you desire.</span></p>
			<h2 id="_idParaDest-216"><a id="_idTextAnchor259"/>Retrieval and reranking</h2>
			<p>Retrieval and reranking are key techniques used to enhance the performance and accuracy of LLMs. First, understand that by retrieving relevant context or documents, an LLM provides more accurate and contextually relevant responses. This is particularly useful when the model’s training data does not cover the specifics of the query or when up-to-date information <span class="No-Break">is required.</span></p>
			<p>In the context of LLMs, <strong class="bold">retrieval</strong> can involve searching through a vast collection of documents, knowledge bases, or other data sources to find pieces of information that are pertinent to a given query or task. Let’s have a look at the two different types <span class="No-Break">of retrieval:</span></p>
			<ul>
				<li><strong class="bold">Keyword-based retrieval</strong>: This uses keywords from the query to find matching documents. For instance, if you use the word <strong class="source-inline">cars</strong> in your query, it returns documents that contain the <span class="No-Break">word </span><span class="No-Break"><em class="italic">cars</em></span><span class="No-Break">.</span></li>
				<li><strong class="bold">Embedding-based retrieval</strong>: This uses vector embeddings to find matching documents. Both the query and documents are transformed into vectors in a high-dimensional space. Retrieval then involves finding vectors (that is, documents) that are close to the <span class="No-Break">query vector.</span></li>
			</ul>
			<p><strong class="bold">Reranking</strong> is the process of reordering the retrieved documents or pieces of information to prioritize the most relevant ones. After the initial retrieval, the documents are ranked based on their relevance to the query. Retrieved documents are initially ranked based on their similarity to the query using methods such as cosine similarity in embedding space. However, a more sophisticated model can rerank these initially retrieved documents by considering additional features <span class="No-Break">and context.</span></p>
			<p>Let’s look at the <span class="No-Break">following examples.</span></p>
			<p><strong class="bold">Example 1</strong>: Recommending restaurants with a <span class="No-Break">GenAI application.</span></p>
			<p>You have built a GenAI application that provides restaurant recommendations. A user requests restaurants currently open near them. When examining the potential restaurants to provide to the user, the application looks at the distance from the user’s current location or provided address and the current local time and <span class="No-Break">opening hours.</span></p>
			<p>It will then rank the results so that the closest restaurant is the first one shown to the user. This is a perfectly fine solution. But you may want to have smarter results that are dynamically reranked based on other criteria, such as user ratings for the restaurants. You may want to show a higher-rated restaurant that is three miles away first, rather than a one-star restaurant that is one mile away. As the user gives feedback on the results, you may want to rerank dynamically, expanding your pool of restaurants as you get more information about what the user would prefer (including, say, the type of cuisine <span class="No-Break">or ambiance).</span></p>
			<p>By reranking the results, the most relevant and useful information is prioritized, improving the overall quality of the LLM’s output. It helps in filtering out less relevant or redundant information, ensuring the response is precise <span class="No-Break">and useful.</span></p>
			<p>When combined, retrieval and reranking significantly enhance LLM outputs with <span class="No-Break">the following:</span></p>
			<ul>
				<li>The model can access and utilize relevant information that might not be present in its training data, providing more accurate and contextually <span class="No-Break">appropriate answers.</span></li>
				<li>By focusing on the most relevant information through reranking, the model’s responses become more precise, reducing errors and <span class="No-Break">irrelevant content.</span></li>
				<li>Retrieval can pull in the latest information from updated sources, making the model’s responses <span class="No-Break">more current.</span></li>
				<li>These techniques allow the model to handle specific, detailed queries efficiently without needing to retrain the entire <span class="No-Break">model frequently.</span></li>
			</ul>
			<p><strong class="bold">Example 2</strong>: Summarizing the latest research on <span class="No-Break">quantum computing.</span></p>
			<p>Here’s another practical example. Suppose you ask an LLM about the latest research on quantum computing. The steps of the output would be <span class="No-Break">as follows:</span></p>
			<ol>
				<li><strong class="bold">Retrieval</strong>: The model searches through a large database of scientific papers and articles to find relevant documents on <span class="No-Break">quantum computing.</span></li>
				<li><strong class="bold">Reranking</strong>: The initially retrieved documents are then reranked, with the most recent and pertinent studies placed at <span class="No-Break">the top.</span></li>
				<li><strong class="bold">Response generation</strong>: The LLM uses the top-ranked documents to generate a detailed and accurate response about the latest research trends in <span class="No-Break">quantum computing.</span></li>
			</ol>
			<p>By incorporating retrieval and reranking, the LLM can provide a well-informed, up-to-date, and contextually accurate answer, vastly improving the <span class="No-Break">user experience.</span></p>
			<h2 id="_idParaDest-217"><a id="_idTextAnchor260"/>Late interaction strategies</h2>
			<p>Now that you’re ready to take your application into production, there are still a few more things you can do to help improve the user experience and create a feedback loop in order to get a better signal as to the behavior of your GenAI application. This next set of recommendations focuses on <strong class="bold">late interaction strategies</strong>, sometimes referred to as <strong class="bold">contextualized late interaction over </strong><span class="No-Break"><strong class="bold">BERT</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">ColBERT</strong></span><span class="No-Break">).</span></p>
			<p>First, let’s define <strong class="bold">interaction</strong>. Interaction refers to the process of evaluating the relevance between a query and a document by comparing their representations. A late processing strategy is one where the interaction between the query and document representations occurs later in the process, typically after both have been independently encoded. Early interaction models are where query and document embeddings interact at earlier stages, typically before or during their encoding by <span class="No-Break">the model.</span></p>
			<p>Second, let’s dig a little bit into the internal workings. When a user interacts with a GenAI application, they input a query that is encoded into a dense vector representation. Potential responses, usually documents or passages, are also encoded into dense vector representations. The system performs similarity matching between the query and document embeddings, returning the documents with the highest similarity scores as the <span class="No-Break">best matches.</span></p>
			<p>To enhance relevance, you don’t return all matching results to the user. Instead, you aim to provide the most relevant results or a summarized version of the result set. Late interaction models such as ColBERT improve efficiency by focusing on the most promising query-document pairs rather than considering all possible pairs, yielding more precise results and a better user experience. This selective approach allows for more precise and relevant results, enhancing the <span class="No-Break">user experience.</span></p>
			<p>If you need to focus on improving search results, consider implementing ColBERT or similar techniques to enhance retrieval performance and provide more relevant results for <span class="No-Break">user queries.</span></p>
			<h2 id="_idParaDest-218"><a id="_idTextAnchor261"/>Query rewriting</h2>
			<p><strong class="bold">Query rewriting</strong>, or <strong class="bold">query reformulation</strong>, is a technique used to improve the quality of the answers provided by LLMs. This process involves modifying the original query to make it clearer, more specific, or more detailed, which can help the model generate better responses. LLMs do not explicitly rewrite queries in the background, so this effort is manual unless you have implemented a workflow that will evaluate and rewrite the user’s query before <span class="No-Break">it’s processed.</span></p>
			<p>Rewriting a query can make it clearer and more precise, reducing ambiguity and ensuring the model understands exactly what is being asked. Adding relevant context or details to the query can help the model provide more accurate and contextually appropriate answers and can help disambiguate terms that have multiple meanings, ensuring the response aligns with the intended meaning. In addition, reformulating the query to include additional relevant details can lead to more <span class="No-Break">comprehensive answers.</span></p>
			<p>How does query rewriting work? It’s important to understand user intent for your GenAI application. What is the <em class="italic">purpose</em> of your application, and what kinds of questions will your application attempt to answer? Understanding what sort of response users expect versus what your application might deliver is key. After that, you can do the following activities, which are not mutually exclusive, meaning that you can perform some, just one, or none <span class="No-Break">of these.</span></p>
			<p>For instance, based on the <strong class="bold">intent</strong>, the user query can be augmented with additional <strong class="bold">context</strong> and details. This activity substantially expands the user query (and increases the token count per query) but will typically yield much <span class="No-Break">better results.</span></p>
			<p>To take an easy example, imagine that your application generates images. The user requests <strong class="source-inline">a picture of a kitten</strong>, a quite simple query that could have <span class="No-Break">endless results.</span></p>
			<p>To help the user get better results, you can add three buttons in the UI so that the user can select a <strong class="bold">style</strong>—a realistic photograph style, a Renaissance painting style, or an anime cartoon style. When the user clicks the style button and then submits their inquiry, instead of relaying <strong class="source-inline">a picture of a kitten</strong>, the query is modified to <span class="No-Break">the following:</span></p>
			<pre class="source-code">
An image of a kitten, in anime style, large eyes, chikai, chibi-style, pixel-style, anime illustration, cute, in the style of Akira Toriyama.</pre>			<p>Here, for each button style, you can add the terms that augment the user query and then apply them <span class="No-Break">before submission.</span></p>
			<p>As another example, consider this <span class="No-Break">user query:</span></p>
			<pre class="source-code">
"What's the average revenue?"</pre>			<p>A meaningful rewrite could be <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
"What's the average revenue for [May 2024] for [sales sku 123]?"</pre>			<p>This rewritten query with additional context helps the system understand that the user is asking for a specific product and time period, leading to a more accurate and <span class="No-Break">useful response.</span></p>
			<p>Ultimately, when conducting query rewrites, you’ll want to <strong class="bold">simplify the language</strong>. Complex queries can be simplified or broken down into simpler parts, making it easier for the model to process and respond accurately. This method involves taking a large query and breaking it into constituent parts (which typically is achieved via a series of input fields/forms) and then unifying each data entry into a single submitted query. This guides your user into constructing a well-formed query without <span class="No-Break">specialized knowledge.</span></p>
			<p>As an example, imagine your user has only a single-entry field to input their query. In such a case, they may leave out relevant information or provide irrelevant information that could impact accuracy or increase the possibility of hallucination. Instead, if you were to provide the user with a series of fields, each with clear instructions, and then assemble the inputted information into a query that was fed into the GenAI application, you would get a better outcome than a free-form <span class="No-Break">text entry.</span></p>
			<p>For practical implementation, you could consider a workflow in which the system itself analyzes the query for intent and context, reviews the query’s complexity, and then rewrites the query to be clearer, more specific, or more detailed. The reformulated query can then be used to generate <span class="No-Break">the response.</span></p>
			<h1 id="_idParaDest-219"><a id="_idTextAnchor262"/>Testing and red teaming</h1>
			<p>Testing AI systems is critical to ensure their accuracy, reliability, and overall performance. Typically, in software engineering, automated testing is used as part of the software development process. GenAI applications are no different. You’ll want to routinely and regularly test the outputs to ensure there are no radical shifts in <span class="No-Break">output quality.</span></p>
			<h2 id="_idParaDest-220"><a id="_idTextAnchor263"/>Testing</h2>
			<p>Just like your typical software engineering features, you’ll want to include the phases of unit testing, integration testing, performance testing, and user acceptance into your test plan. However, the specifics of how this is done vary from one use case <span class="No-Break">to another.</span></p>
			<p>In the context of GenAI applications, <strong class="bold">unit testing</strong> still has the same basic tenets and involves testing individual components or modules of the application to ensure they function correctly. However, in the case of GenAI applications, your unit tests will need to also include steps such as <span class="No-Break">the following:</span></p>
			<ul>
				<li><strong class="bold">Input validation</strong>: Ensure that the application correctly handles and validates various input types, formats, and ranges. Test for edge cases, such as empty inputs, excessively large inputs, or <span class="No-Break">malformed data.</span></li>
				<li><strong class="bold">Pre-processing</strong>: Verify that any pre-processing steps, such as tokenization, normalization, or feature extraction, are <span class="No-Break">performed correctly.</span></li>
				<li><strong class="bold">Model loading</strong>: Test that the model is correctly loaded from its storage location, and verify that the correct version is <span class="No-Break">being used.</span></li>
				<li><strong class="bold">Model inference</strong>: Ensure that the model generates outputs without errors given valid inputs. Test the inference function with controlled inputs to verify expected behavior, such as deterministic responses for certain prompts <span class="No-Break">or scenarios.</span></li>
				<li><strong class="bold">Output format</strong>: Validate that the generated outputs meet the expected format and structure. This includes checking that outputs are complete, correctly formatted, and adhere to any length or <span class="No-Break">content constraints.</span></li>
				<li><strong class="bold">Post-processing</strong>: Test any post-processing steps that modify or enhance the model’s output, such as cleaning up text, converting formats, or applying additional <span class="No-Break">business logic.</span></li>
				<li><strong class="bold">Proper functioning</strong>: The outputs should work. If your GenAI application outputs code, you will need to test that the code itself compiles and behaves <span class="No-Break">as intended.</span></li>
			</ul>
			<p>These are just a few of the items that you should include for unit testing your <span class="No-Break">GenAI application.</span></p>
			<p><strong class="bold">Integration testing</strong> focuses on verifying that the components of your GenAI system work together as needed. This means you’ll be testing the interactions between components to check <span class="No-Break">the following:</span></p>
			<ul>
				<li>Whether your data ingestion pipeline pulls the <span class="No-Break">correct data</span></li>
				<li>How recommendations are presented to the user (formatting, for instance, if this is done by another library <span class="No-Break">or tool)</span></li>
				<li>API load testing, if you’re using another LLM such as OpenAI <span class="No-Break">or Anthropic</span></li>
			</ul>
			<p>You’ll want to evaluate processing time, efficiency, and scalability via <strong class="bold">performance testing</strong>. This might include activities such as <span class="No-Break">the following:</span></p>
			<ul>
				<li>Load testing your application for how it handles a large volume of <span class="No-Break">simultaneous queries.</span></li>
				<li>Assessing the inference time of self-hosted models on various <span class="No-Break">hardware configurations.</span></li>
				<li>Measuring how many token limits should be set for input and output to control costs and <span class="No-Break">processing time.</span></li>
				<li>Measuring the time taken for the model to generate outputs and ensuring it meets performance requirements. This can be especially important for applications with <span class="No-Break">real-time constraints.</span></li>
			</ul>
			<p>In addition to this routine testing, you have more to add to your test suite. In general, it is also recommended that GenAI applications go through <strong class="bold">additional testing</strong> for <span class="No-Break">the following:</span></p>
			<ul>
				<li><strong class="bold">Bias and fairness</strong>: If your model is making recommendations that affect lives and livelihoods, you’ll want to carefully consider training data biases for different <span class="No-Break">demographic groups.</span></li>
				<li><strong class="bold">Robustness</strong>: To ensure your GenAI application is resilient to variations and noise, you’ll want to test with adversarial examples and edge cases to evaluate its ability to handle <span class="No-Break">unexpected inputs.</span></li>
			</ul>
			<p>Once you’ve gotten through all of that, you’ll want to think about <strong class="bold">user acceptance testing</strong>, which is one of the most exciting parts of the process, as you will see in the <span class="No-Break">next section.</span></p>
			<h2 id="_idParaDest-221"><a id="_idTextAnchor264"/>Red teaming</h2>
			<p>If your GenAI application will accept natural language prompts and inputs from human beings, then the practice of <strong class="bold">red teaming</strong> cannot be recommended enough. Red teaming involves simulating real-world, challenging, or adversarial situations to identify vulnerabilities and weaknesses in your GenAI application. This approach is borrowed from cybersecurity practices and is particularly important for ensuring your GenAI application meets <span class="No-Break">user expectations.</span></p>
			<p>This involves having a large pool of <em class="italic">users</em> who will ask real-world questions, but they are not limited by <em class="italic">scripts</em> as to what they may ask. The reason for red teaming is that GenAI applications can, and often do, produce different outputs that vary widely, even with similar or the same input. Not only that but the quality of the generated output is often subjective and depends on human judgment. So, while traditional software applications produce predictable and consistent results, the same is not true of GenAI. Let’s take an example to see how <span class="No-Break">this works.</span></p>
			<p>For a chatbot application, you might have routine automated testing that would ask your GenAI application the top 200 most common user questions and then evaluate them for correctness. With a red team, you would have 50 users ask whatever questions they wanted, and then record both the questions asked and the responses. This might yield insights such as <span class="No-Break">the following:</span></p>
			<ul>
				<li>If a user asks a question in a similar way but not with the exact same wording, they receive incorrect or less <span class="No-Break">correct answers.</span></li>
				<li>Some users will ask malicious questions and the GenAI application will <span class="No-Break">respond poorly.</span></li>
				<li>Other users ask questions that are not part of the training data, and the GenAI application hallucinates answers (or gives no answer at all), thus identifying the need to expand your <span class="No-Break">training data.</span></li>
				<li>When users ask many questions in a row, the <span class="No-Break">application stalls.</span></li>
				<li>When a user asks specific question types, they are dissatisfied with the output because the application lacks high-quality training data or the formatting of the reply <span class="No-Break">is undesirable.</span></li>
				<li>When properly prompted, the GenAI application will share details of other users’ sessions, thus identifying a <span class="No-Break">security issue.</span></li>
			</ul>
			<p>To enable the red-teaming phase, it is recommended that you record every question asked by every user, as well as every response given, and then ask testers to rate the response with notes. While this level of detailed user testing is strenuous and uncommon in software development, it is incredibly valuable to see how your application performs in real-world scenarios, with real human beings, <span class="No-Break">before production.</span></p>
			<p>Due to the scale and scope of some AI systems, fully testing each component is impossible. Effective testing and red teaming rely on using judgment in terms of which parts of the system are most risky. It may be true that giving occasionally not-quite-accurate advice is a non-impactful event. However, the potential harm of a single hallucination could be quite high. You will want to consider the severity of harm, the likelihood of inaccuracy, and the ability to retract or rectify the inaccuracy as your standard measures of risk. Using those simple, albeit subjective, measures can assist you in determining to what extent you test each aspect of the system, and the size of your <span class="No-Break">red team.</span></p>
			<p>To give yourself a sense of what sorts of harms and incidents you will be testing for—which are too many to enumerate—you will find it helpful to review the AI Incident Database at <a href="https://incidentdatabase.ai/"><span class="P---URL">https://incidentdatabase.ai/</span></a>. Upon review of this tool, you may find your specific use case (or ones like it) and what incidents have already been reported, so that you can test and think through the repercussions <span class="No-Break">of inaccuracies.</span></p>
			<p>As an example, one incident that is detailed here involved an application that made staffing-level recommendations. However, the algorithm-based recommendations left facilities understaffed, leading to critical incidents of neglect, injury, and death. Those incidents then prompted lawsuits and even legislation against healthcare providers <span class="No-Break">using AI.</span></p>
			<h1 id="_idParaDest-222"><a id="_idTextAnchor265"/>Information post-processing</h1>
			<p>You might know that the main way in which GenAI differs from previous forms of AI or analytics is that it generates new content efficiently. But did you know that that content is often in <em class="italic">unstructured</em> forms, for example, written text or images? When you see outputs that are nicely formatted, in bulleted lists, multiple fonts, and so on, it is a form of <span class="No-Break"><strong class="bold">information post-processing</strong></span><span class="No-Break">.</span></p>
			<p>Information post-processing refers to the series of steps taken after an AI model generates an initial response, but before that response is sent to the user. This crucial step enhances the output of GenAI models, refining raw responses to make them more useful, accurate, and contextually appropriate. It can take many forms, so this chapter will only discuss some of the most useful ones along with information on how to <span class="No-Break">implement them:</span></p>
			<ul>
				<li><strong class="bold">Fact-checking</strong>: Verifying the accuracy of the information provided. This can involve checking facts against reliable sources <span class="No-Break">or databases.</span></li>
				<li><strong class="bold">Formatting</strong>: Structuring the information in a clear and readable format, such as bullet points, paragraphs, or tables. This may also include style changes such as bold, text color, or font to enhance readability <span class="No-Break">and emphasis.</span></li>
				<li><strong class="bold">Grammar, style, and tone checking</strong>: At times, the resulting text provided by GenAI applications is not up to par or consistent with the exact messaging, tone, and style that one would expect a human being to write. Post-processing tools and vendors can take generated text outputs and markedly improve them for readability, making them match <span class="No-Break">reader expectations.</span></li>
			</ul>
			<p>Information post-processing is a vital component in the lifecycle of GenAI outputs. It bridges the gap between raw model outputs and polished, user-ready responses, enhancing accuracy, readability, relevance, and overall user satisfaction. By implementing effective post-processing strategies, AI systems can deliver higher-quality and more <span class="No-Break">reliable results.</span></p>
			<p>There are entire services springing up around this valuable step in the GenAI process, so engineers do not have to build <span class="No-Break">it themselves.</span></p>
			<h1 id="_idParaDest-223"><a id="_idTextAnchor266"/>Other remedies</h1>
			<p>Some other technical remedies can be employed even more easily than the ones detailed in this chapter. Some of these may improve the accuracy and performance of your GenAI application, though the level of effort involved varies. As an example, during MongoDB’s testing of GPT, it was discovered that the accuracy rate for the same set of questions was improved by 7% between GPT-3.5 and GPT-4. Getting such a level of improvement in accuracy via prompting, retrieval augmentation, or late interaction strategies is certainly possible but would have <span class="No-Break">been difficult.</span></p>
			<p>So, it is worth investigating every avenue of potential improvement, including areas such as hardware upgrades, code optimization, concurrency management, database query optimization, and even just upgrading your software. All of these can improve the results of your GenAI application and should be <span class="No-Break">independently investigated:</span></p>
			<ul>
				<li><strong class="bold">Hardware and software upgrades</strong>: Upgrade computational resources, such as using more powerful GPUs, scaling horizontally with more servers, or updating to the latest version of the software, to outsize impacts on both accuracy <span class="No-Break">and performance.</span></li>
				<li><strong class="bold">Code optimization</strong>: Refactor and optimize code to improve efficiency, reduce computational load, and handle data <span class="No-Break">more effectively.</span></li>
				<li><strong class="bold">Network optimization</strong>: Reduce network latency by optimizing data transfer, caching responses, and minimizing API <span class="No-Break">call overheads.</span></li>
				<li><strong class="bold">Concurrency management</strong>: Implement concurrency and parallel processing techniques to handle multiple <span class="No-Break">requests efficiently.</span></li>
				<li><strong class="bold">Database optimization</strong>: Optimize database queries and interactions to reduce <span class="No-Break">I/O overhead.</span></li>
			</ul>
			<h1 id="_idParaDest-224"><a id="_idTextAnchor267"/>Summary</h1>
			<p>Implementing mechanisms to correct and optimize your GenAI application can have many forms and can be implemented before, during, and after answers are generated. For optimal performance, you’ll want to train your GenAI model with high-quality data, supplement existing models with your specific use case data, and have thorough evaluation datasets and record the model’s performance to establish a baseline <span class="No-Break">of accuracy.</span></p>
			<p>Once you have that baseline, however, you can immediately begin improving upon it with the techniques discussed in this chapter. Among these techniques is one- or few-shot prompting. It involves providing the GenAI model with a single example or prompt to guide its response, enabling the model to generate relevant and contextually appropriate outputs with minimal training data. You can also try retrieving and reranking relevant documents or data points based on the user’s query, and then reordering these results to prioritize the most relevant and useful information before generating a final response. Query rewriting is another technique that can improve clarity, specificity, or context, helping the AI model understand and respond more accurately to the <span class="No-Break">user’s requests.</span></p>
			<p>Formatting GenAI responses via structuring and presenting the AI-generated content in a clear, organized, and readable manner can enhance the overall user experience and ensure the information is easily digestible. Similarly, implementing late interaction strategies such as ColBERT can improve the relevance and accuracy of the retrieved information. By testing, red teaming, and recording your results, you can track your progress in improving the performance, security, and quality of responses <span class="No-Break">over time.</span></p>
			<p>GenAI technologies are changing (and will continue to change) the face of the software industry. With these optimization strategies in place, your GenAI application will be well equipped to adapt and excel in an <span class="No-Break">ever-evolving landscape.</span><a id="_idTextAnchor268"/></p>
		</div>
	

		<div id="_idContainer095">
			<h1 id="_idParaDest-225"><a id="_idTextAnchor269"/>Appendix: Further Reading</h1>
			<p>In addition to the links provided within the chapters, here are some resources to take your learning <span class="No-Break">journey forward.</span></p>
			<p><a href="B22495_01.xhtml#_idTextAnchor009"><span class="No-Break"><strong class="bold">Chapter 1</strong></span></a><strong class="bold">, Getting Started with </strong><span class="No-Break"><strong class="bold">Generative AI</strong></span></p>
			<ul>
				<li>Gryka, Maciej. “Invest in RAG” in “Building reliable systems out of unreliable agents.” <em class="italic">The Rainforest Blog</em>, April 3, <span class="No-Break">2024. </span><a href="https://www.rainforestqa.com/blog/building-reliable-systems-out-of-unreliable-agents#Invest_in_RAG"><span class="No-Break"><span>https://www.rainforestqa.com/blog/building-reliable-systems-out-of-unreliable-agents#Invest_in_RAG</span></span></a><span class="No-Break">.</span></li>
				<li>“The Black Box: Even AI’s creators don’t understand it.” July 2023. <em class="italic">Unexplainable</em>. Produced by Vox Creative. Podcast, Spotify, <span class="No-Break">36:15. </span><a href="https://open.spotify.com/episode/3npjXNCtUSGRUjVR4EYb4Y?si=-XpudYVzSEKfhD0-2NBjEQ"><span class="No-Break"><span>https://open.spotify.com/episode/3npjXNCtUSGRUjVR4EYb4Y?si=-XpudYVzSEKfhD0-2NBjEQ</span></span></a><span class="No-Break">.</span></li>
			</ul>
			<p><a href="B22495_02.xhtml#_idTextAnchor021"><span class="No-Break"><strong class="bold">Chapter 2</strong></span></a><strong class="bold">, Building Blocks of </strong><span class="No-Break"><strong class="bold">Intelligent Applications</strong></span></p>
			<ul>
				<li>Naveed et al. “A Comprehensive Overview of Large Language Models.” arXiv, July 12, <span class="No-Break">2023. </span><a href="https://arxiv.org/abs/2307.06435"><span class="No-Break"><span>https://arxiv.org/abs/2307.06435</span></span></a><span class="No-Break">.</span></li>
			</ul>
			<p><a href="B22495_03.xhtml#_idTextAnchor041"><span class="No-Break"><strong class="bold">Chapter 3</strong></span></a><strong class="bold">, Large </strong><span class="No-Break"><strong class="bold">Language Models</strong></span></p>
			<ul>
				<li>“Speech and Language Processing,” <span class="No-Break">n.d., </span><a href="https://web.stanford.edu/~jurafsky/slp3/"><span class="No-Break"><span>https://web.stanford.edu/~jurafsky/slp3/</span></span></a><span class="No-Break">.</span></li>
				<li>Hochreiter, Sepp, and Jürgen Schmidhuber. “Long Short-Term Memory.” <em class="italic">Neural Computation</em> 9, no. 8 (November 1, 1997): <span class="No-Break">1735–80. </span><a href="https://doi.org/10.1162/neco.1997.9.8.1735"><span class="No-Break"><span>https://doi.org/10.1162/neco.1997.9.8.1735</span></span></a><span class="No-Break">.</span></li>
				<li>Vaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. “Attention Is All You Need.” <em class="italic">arXiv (Cornell University)</em>, January 1, <span class="No-Break">2017. </span><a href="https://doi.org/10.48550/arxiv.1706.03762"><span class="No-Break"><span>https://doi.org/10.48550/arxiv.1706.03762</span></span></a><span class="No-Break">.</span></li>
				<li>“Prompt Engineering Guide – Nextra,” <span class="No-Break">n.d., </span><a href="https://www.promptingguide.ai/"><span class="No-Break"><span>https://www.promptingguide.ai/</span></span></a><span class="No-Break">.</span></li>
			</ul>
			<p><a href="B22495_04.xhtml#_idTextAnchor061"><span class="No-Break"><strong class="bold">Chapter 4</strong></span></a><strong class="bold">, </strong><span class="No-Break"><strong class="bold">Embedding Models</strong></span></p>
			<ul>
				<li>A. Aruna Gladys and V. Vetriselvi, “Survey on multimodal approaches to emotion recognition,” <em class="italic">Neurocomputing</em> 556 (November 1, 2023): <span class="No-Break">126693, </span><a href="https://doi.org/10.1016/j.neucom.2023.126693"><span class="No-Break"><span>https://doi.org/10.1016/j.neucom.2023.126693</span></span></a><span class="No-Break">.</span></li>
				<li>Sumit Kumar, “Positive and Negative Sampling Strategies for Representation Learning in Semantic Search,” Sumit’s Diary, March 22, <span class="No-Break">2023, </span><a href="https://blog.reachsumit.com/posts/2023/03/pairing-for-representation"><span class="No-Break"><span>https://blog.reachsumit.com/posts/2023/03/pairing-for-representation</span></span></a><span class="No-Break">.</span></li>
				<li>Tomas Mikolov et al., “Efficient Estimation of Word Representations in Vector Space,” arXiv.org, January 16, <span class="No-Break">2013, </span><a href="https://arxiv.org/abs/1301.3781"><span class="No-Break"><span>https://arxiv.org/abs/1301.3781</span></span></a><span class="No-Break">.</span></li>
				<li>OpenAI, “GPT-4”. GPT-4 Research, March 14, <span class="No-Break">2023. </span><a href="https://openai.com/index/gpt-4-research"><span class="No-Break"><span>https://openai.com/index/gpt-4-research</span></span></a><span class="No-Break">.</span></li>
				<li>Jeffrey Pennington, “GloVe: Global Vectors for Word Representation,” <span class="No-Break">n.d., </span><a href="https://nlp.stanford.edu/projects/glove"><span class="No-Break"><span>https://nlp.stanford.edu/projects/glove</span></span></a><span class="No-Break">.</span></li>
				<li>Jacob Devlin et al., “BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding,” arXiv.org, October 11, <span class="No-Break">2018, </span><a href="https://arxiv.org/abs/1810.04805"><span class="No-Break"><span>https://arxiv.org/abs/1810.04805</span></span></a><span class="No-Break">.</span></li>
				<li>“fastText,” <span class="No-Break">n.d., </span><a href="https://fasttext.cc/"><span class="No-Break"><span>https://fasttext.cc/</span></span></a><span class="No-Break">.</span></li>
				<li>Peters, M. E., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., and Zettlemoyer, L. “Deep contextualized word representations,” arXiv:1802.05365, March 22, <span class="No-Break">2018. </span><a href="https://arxiv.org/pdf/1802.05365"><span class="No-Break"><span>https://arxiv.org/pdf/1802.05365</span></span></a><span class="No-Break">.</span></li>
				<li> Karen Simonyan and Andrew Zisserman, “Very Deep Convolutional Networks for Large-Scale Image Recognition,” arXiv.org, September 4, <span class="No-Break">2014, </span><a href="https://arxiv.org/abs/1409.1556v6"><span class="No-Break"><span>https://arxiv.org/abs/1409.1556v6</span></span></a><span class="No-Break">.</span></li>
				<li>Kaiming He et al., “Deep Residual Learning for Image Recognition,” arXiv.org, December 10, <span class="No-Break">2015, </span><a href="https://arxiv.org/abs/1512.03385"><span class="No-Break"><span>https://arxiv.org/abs/1512.03385</span></span></a><span class="No-Break">.</span></li>
				<li>Aurora Cramer, Ho-Hsiang Wu, Justin Salamon, and Juan Pablo Bello, “OpenL3 — OpenL3 0.4.2 documentation,” <span class="No-Break">n.d., </span><a href="https://openl3.readthedocs.io/en/latest/#"><span class="No-Break"><span>https://openl3.readthedocs.io/en/latest/#</span></span></a><span class="No-Break">.</span></li>
				<li>“Google | vggish | Kaggle,” <span class="No-Break">n.d., </span><a href="https://www.kaggle.com/models/google/vggish"><span class="No-Break"><span>https://www.kaggle.com/models/google/vggish</span></span></a><span class="No-Break">.</span></li>
				<li>Tran, D., Bourdev, L., Fergus, R., Torresani, L., and Paluri, M., “Learning Spatiotemporal Features with 3D Convolutional Networks.” arXiv:1412.0767, October 7, <span class="No-Break">2015. </span><a href="https://arxiv.org/pdf/1412.0767"><span class="No-Break"><span>https://arxiv.org/pdf/1412.0767</span></span></a><span class="No-Break">.</span></li>
				<li>Grover, A., and Leskovec, J. “Node2Vec: Scalable Feature Learning for Networks.” <em class="italic">Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</em>, <span class="No-Break">2016. </span><a href="https://cs.stanford.edu/~jure/pubs/node2vec-kdd16.pdf"><span class="No-Break"><span>https://cs.stanford.edu/~jure/pubs/node2vec-kdd16.pdf</span></span></a><span class="No-Break">.</span></li>
				<li>Bryan Perozzi, Rami Al-Rfou, and Steven Skiena, “DeepWalk,” August 24, <span class="No-Break">2014, </span><a href="https://doi.org/10.1145/2623330.2623732"><span class="No-Break"><span>https://doi.org/10.1145/2623330.2623732</span></span></a><span class="No-Break">.</span></li>
				<li>Zhang, S., and Xu, Y. “Json2Vec: A Representation Learning Method for JSON Data.” arXiv:2002.05707, February 13, <span class="No-Break">2020. </span><a href="https://arxiv.org/pdf/2002.05707"><span class="No-Break"><span>https://arxiv.org/pdf/2002.05707</span></span></a><span class="No-Break">.</span></li>
				<li>Alec Radford et al., “Learning Transferable Visual Models From Natural Language Supervision,” arXiv.org, February 26, <span class="No-Break">2021, </span><a href="https://arxiv.org/abs/2103.00020"><span class="No-Break"><span>https://arxiv.org/abs/2103.00020</span></span></a><span class="No-Break">.</span></li>
			</ul>
			<p><a href="B22495_05.xhtml#_idTextAnchor115"><span class="No-Break"><strong class="bold">Chapter 5</strong></span></a><strong class="bold">, </strong><span class="No-Break"><strong class="bold">Vector Databases</strong></span></p>
			<ul>
				<li>Yu. A. Malkov and D. A. Yashunin, “Efficient and robust approximate nearest neighbor search using Hierarchical Navigable Small World graphs,” arXiv.org, March 30, <span class="No-Break">2016, </span><a href="http://arxiv.org/abs/1603.09320"><span class="No-Break"><span>http://arxiv.org/abs/1603.09320</span></span></a><span class="No-Break">.</span></li>
				<li>Yikun Han, Chunjiang Liu, and Pengfei Wang, “A Comprehensive Survey on Vector Database: Storage and Retrieval Technique, Challenge,” arXiv.org, October 18, <span class="No-Break">2023, </span><a href="http://arxiv.org/abs/2310.11703"><span class="No-Break"><span>http://arxiv.org/abs/2310.11703</span></span></a><span class="No-Break">.</span></li>
				<li>Zhi Jing et al., “When Large Language Models Meet Vector Databases: A Survey,” arXiv.org, January 30, <span class="No-Break">2024, </span><a href="http://arxiv.org/abs/2402.01763"><span class="No-Break"><span>http://arxiv.org/abs/2402.01763</span></span></a><span class="No-Break">.</span></li>
				<li>Doug Turnbull, “What Is a Judgment List?,” Doug Turnbull’s Blog, February 21, <span class="No-Break">2021, </span><a href="https://softwaredoug.com/blog/2021/02/21/what-is-a-judgment-list"><span class="No-Break"><span>https://softwaredoug.com/blog/2021/02/21/what-is-a-judgment-list</span></span></a><span class="No-Break">.</span></li>
				<li>“Building RAG-based LLM Applications for Production,” Anyscale, <span class="No-Break">n.d., </span><a href="https://www.anyscale.com/blog/a-comprehensive-guide-for-building-rag-based-llm-applications-part-1"><span class="No-Break"><span>https://www.anyscale.com/blog/a-comprehensive-guide-for-building-rag-based-llm-applications-part-1</span></span></a><span class="No-Break">.</span></li>
				<li>“How to Perform Hybrid Search - MongoDB Atlas,” <span class="No-Break">n.d., </span><a href="https://www.mongodb.com/docs/atlas/atlas-vector-search/tutorials/reciprocal-rank-fusion/"><span class="No-Break"><span>https://www.mongodb.com/docs/atlas/atlas-vector-search/tutorials/reciprocal-rank-fusion/</span></span></a><span class="No-Break">.</span></li>
				<li>“Review Deployment Options - MongoDB Atlas,” <span class="No-Break">n.d., </span><a href="https://www.mongodb.com/docs/atlas/atlas-vector-search/deployment-options/"><span class="No-Break"><span>https://www.mongodb.com/docs/atlas/atlas-vector-search/deployment-options/</span></span></a><span class="No-Break">.</span></li>
			</ul>
			<p><a href="B22495_06.xhtml#_idTextAnchor137"><span class="No-Break"><strong class="bold">Chapter 6</strong></span></a><strong class="bold">, AI/ML </strong><span class="No-Break"><strong class="bold">Application Design</strong></span></p>
			<ul>
				<li>“How to Index Fields for Vector Search - MongoDB Atlas,” <span class="No-Break">n.d., </span><a href="https://www.mongodb.com/docs/atlas/atlas-vector-search/vector-search-type/#considerations"><span class="No-Break"><span>https://www.mongodb.com/docs/atlas/atlas-vector-search/vector-search-type/#considerations</span></span></a><span class="No-Break">.</span></li>
				<li>Lauren Schaefer Daniel Coupal, “Bloated Documents | MongoDB,” May 31, <span class="No-Break">2022, </span><a href="https://www.mongodb.com/developer/products/mongodb/schema-design-anti-pattern-bloated-documents/"><span class="No-Break"><span>https://www.mongodb.com/developer/products/mongodb/schema-design-anti-pattern-bloated-documents/</span></span></a><span class="No-Break">.</span></li>
				<li>Daniel Coupal, “Building with Patterns: The Extended Reference Pattern,” MongoDB, March 19, <span class="No-Break">2019, </span><a href="https://www.mongodb.com/blog/post/building-with-patterns-the-extended-reference-pattern"><span class="No-Break"><span>https://www.mongodb.com/blog/post/building-with-patterns-the-extended-reference-pattern</span></span></a><span class="No-Break">.</span></li>
				<li>“Atlas Cluster Sizing and Tier Selection - MongoDB Atlas,” <span class="No-Break">n.d., </span><a href="https://www.mongodb.com/docs/atlas/sizing-tier-selection/"><span class="No-Break"><span>https://www.mongodb.com/docs/atlas/sizing-tier-selection/</span></span></a><span class="No-Break">.</span></li>
				<li>“Customize Cluster Storage - MongoDB Atlas,” <span class="No-Break">n.d., </span><a href="https://www.mongodb.com/docs/atlas/customize-storage/"><span class="No-Break"><span>https://www.mongodb.com/docs/atlas/customize-storage/</span></span></a><span class="No-Break">.</span></li>
				<li>“Amazon EBS volume types - Amazon EBS,” <span class="No-Break">n.d., </span><a href="https://docs.aws.amazon.com/ebs/latest/userguide/ebs-volume-types.html#gp3-ebs-volume-type"><span class="No-Break"><span>https://docs.aws.amazon.com/ebs/latest/userguide/ebs-volume-types.html#gp3-ebs-volume-type</span></span></a><span class="No-Break">.</span></li>
				<li>“Customize Cluster Storage - MongoDB Atlas,” <span class="No-Break">n.d., </span><a href="https://www.mongodb.com/docs/atlas/customize-storage/"><span class="No-Break"><span>https://www.mongodb.com/docs/atlas/customize-storage/</span></span></a><span class="No-Break">.</span></li>
			</ul>
			<p><a href="B22495_07.xhtml#_idTextAnchor162"><span class="No-Break"><strong class="bold">Chapter 7</strong></span></a><strong class="bold">, Useful Frameworks, Libraries, </strong><span class="No-Break"><strong class="bold">and APIs</strong></span></p>
			<ul>
				<li>“MongoDB Atlas,” LangChain, <span class="No-Break">n.d., </span><a href="https://python.langchain.com/v0.2/docs/integrations/vectorstores/mongodb_atlas/"><span class="No-Break"><span>https://python.langchain.com/v0.2/docs/integrations/vectorstores/mongodb_atlas/</span></span></a><span class="No-Break">.</span></li>
				<li>“How to Index Fields for Vector Search - MongoDB Atlas,” <span class="No-Break">n.d., </span><a href="https://www.mongodb.com/docs/atlas/atlas-vector-search/manage-indexes/"><span class="No-Break"><span>https://www.mongodb.com/docs/atlas/atlas-vector-search/manage-indexes/</span></span></a><span class="No-Break">.</span></li>
				<li>“Get Started with the LangChain Integration - MongoDB Atlas,” <span class="No-Break">n.d., </span><a href="https://www.mongodb.com/docs/atlas/atlas-vector-search/ai-integrations/langchain/"><span class="No-Break"><span>https://www.mongodb.com/docs/atlas/atlas-vector-search/ai-integrations/langchain/</span></span></a><span class="No-Break">.</span></li>
				<li>“MongoDB with Python - MongoDB Documentation,” <span class="No-Break">n.d., </span><a href="https://www.mongodb.com/docs/languages/python/#integrations"><span class="No-Break"><span>https://www.mongodb.com/docs/languages/python/#integrations</span></span></a><span class="No-Break">.</span></li>
				<li>“Transformers,” <span class="No-Break">n.d., </span><a href="https://huggingface.co/docs/transformers/en/index"><span class="No-Break"><span>https://huggingface.co/docs/transformers/en/index</span></span></a><span class="No-Break">.</span></li>
				<li>“OpenAI developer platform,” OpenAI Platform, <span class="No-Break">n.d., </span><a href="https://platform.openai.com/docs/overview"><span class="No-Break"><span>https://platform.openai.com/docs/overview</span></span></a><span class="No-Break">.</span></li>
			</ul>
			<p><a href="B22495_08.xhtml#_idTextAnchor180"><span class="No-Break"><strong class="bold">Chapter 8</strong></span></a><strong class="bold">, Implementing Vector Search in </strong><span class="No-Break"><strong class="bold">AI Applications</strong></span></p>
			<ul>
				<li>Yunfan Gao et al., “Retrieval-Augmented Generation for Large Language Models: A Survey,” arXiv.org, December 18, <span class="No-Break">2023, </span><a href="https://arxiv.org/abs/2312.10997"><span class="No-Break"><span>https://arxiv.org/abs/2312.10997</span></span></a><span class="No-Break">.</span></li>
				<li>Rupak Roy, “Harness LLM Output-parsers like CommaSeparatedListOutputParser, PydanticOutputParser and more for a Structured Ai | by Rupak (Bob) Roy - II | Medium | Medium,” <em class="italic">Medium</em>, August 14, <span class="No-Break">2024, </span><a href="https://bobrupakroy.medium.com/harness-llm-output-parsers-for-a-structured-ai-7b456d231834"><span class="No-Break"><span>https://bobrupakroy.medium.com/harness-llm-output-parsers-for-a-structured-ai-7b456d231834</span></span></a><span class="No-Break">.</span></li>
				<li>Mirjam Minor and Eduard Kaucher, “Retrieval Augmented Generation with LLMs for Explaining Business Process Models,” in <em class="italic">Lecture Notes in Computer Science</em>, 2024, <span class="No-Break">175–90, </span><a href="https://doi.org/10.1007/978-3-031-63646-2_12"><span class="No-Break"><span>https://doi.org/10.1007/978-3-031-63646-2_12</span></span></a><span class="No-Break">.</span></li>
			</ul>
			<p><a href="B22495_09.xhtml#_idTextAnchor193"><span class="No-Break"><strong class="bold">Chapter 9</strong></span></a><strong class="bold">, LLM </strong><span class="No-Break"><strong class="bold">Output Evaluation</strong></span></p>
			<ul>
				<li>“Papers with Code - Measuring Massive Multitask Language Understanding,” September 7, <span class="No-Break">2020, </span><a href="https://paperswithcode.com/paper/measuring-massive-multitask-language"><span class="No-Break"><span>https://paperswithcode.com/paper/measuring-massive-multitask-language</span></span></a><span class="No-Break">.</span></li>
				<li>“Papers with Code - HellaSwag: Can a Machine Really Finish Your Sentence?,” May 19, <span class="No-Break">2019, </span><a href="https://paperswithcode.com/paper/hellaswag-can-a-machine-really-finish-your"><span class="No-Break"><span>https://paperswithcode.com/paper/hellaswag-can-a-machine-really-finish-your</span></span></a><span class="No-Break">.</span></li>
				<li>“Papers with Code - Evaluating Large Language Models Trained on Code,” July 7, <span class="No-Break">2021, </span><a href="https://paperswithcode.com/paper/evaluating-large-language-models-trained-on"><span class="No-Break"><span>https://paperswithcode.com/paper/evaluating-large-language-models-trained-on</span></span></a><span class="No-Break">.</span></li>
				<li>“Introduction | Ragas,” <span class="No-Break">n.d., </span><a href="https://docs.ragas.io/en/stable/index.html"><span class="No-Break"><span>https://docs.ragas.io/en/stable/index.html</span></span></a><span class="No-Break">.</span></li>
			</ul>
			<p><a href="B22495_10.xhtml#_idTextAnchor214"><span class="No-Break"><strong class="bold">Chapter 10</strong></span></a><strong class="bold">, Refining the Semantic Data Model to </strong><span class="No-Break"><strong class="bold">Improve Accuracy</strong></span></p>
			<ul>
				<li>“SentenceTransformers Documentation — Sentence Transformers documentation,” <span class="No-Break">n.d., </span><a href="https://sbert.net/"><span class="No-Break"><span>https://sbert.net/</span></span></a><span class="No-Break">.</span></li>
				<li>“Train and Fine-Tune Sentence Transformers Models,” <span class="No-Break">n.d., </span><a href="https://huggingface.co/blog/how-to-train-sentence-transformers"><span class="No-Break"><span>https://huggingface.co/blog/how-to-train-sentence-transformers</span></span></a><span class="No-Break">.</span></li>
				<li>“Run Vector Search Queries - MongoDB Atlas,” <span class="No-Break">n.d., </span><a href="https://www.mongodb.com/docs/atlas/atlas-vector-search/vector-search-stage/#atlas-vector-search-pre-filter"><span class="No-Break"><span>https://www.mongodb.com/docs/atlas/atlas-vector-search/vector-search-stage/#atlas-vector-search-pre-filter</span></span></a><span class="No-Break">.</span></li>
				<li>“Knowledge Graph RAG Query Engine - LlamaIndex,” <span class="No-Break">n.d., </span><a href="https://docs.llamaindex.ai/en/stable/examples/query_engine/knowledge_graph_rag_query_engine/"><span class="No-Break"><span>https://docs.llamaindex.ai/en/stable/examples/query_engine/knowledge_graph_rag_query_engine/</span></span></a><span class="No-Break">.</span></li>
			</ul>
			<p><a href="B22495_11.xhtml#_idTextAnchor232"><span class="No-Break"><strong class="bold">Chapter 11</strong></span></a><strong class="bold">, Common Failures of </strong><span class="No-Break"><strong class="bold">Generative AI</strong></span></p>
			<ul>
				<li>Lance Eliot, “Doctors Relying On Generative AI To Summarize Medical Notes Might Unknowingly Be Taking Big Risks,” <em class="italic">Forbes</em>, July 2, <span class="No-Break">2024, </span><a href="https://www.forbes.com/sites/lanceeliot/2024/02/05/doctors-relying-on-generative-ai-to-summarize-medical-notes-might-unknowingly-be-taking-big-risks/"><span class="No-Break"><span>https://www.forbes.com/sites/lanceeliot/2024/02/05/doctors-relying-on-generative-ai-to-summarize-medical-notes-might-unknowingly-be-taking-big-risks/</span></span></a><span class="No-Break">.</span></li>
				<li>Markman, Ofer. “Time to Strategize: 85% of Data is Garbage or Siloed.” <em class="italic">Filo Focus</em>, February 11, <span class="No-Break">2024. </span><a href="https://www.filo.systems/blog/85-percent-of-data-is-not-actionable-time-to-restrategize"><span class="No-Break"><span>https://www.filo.systems/blog/85-percent-of-data-is-not-actionable-time-to-restrategize</span></span></a><span class="No-Break">.</span></li>
				<li>Neeman, Ella, Roee Aharoni, Or Honovich, et al. “DisentQA: Disentangling Parametric and Contextual Knowledge with Counterfactual Question Answering.” arXiv.org, November 10, <span class="No-Break">2022. </span><a href="https://arxiv.org/pdf/2211.05655"><span class="No-Break"><span>https://arxiv.org/pdf/2211.05655</span></span></a><span class="No-Break">.</span></li>
				<li>Sharma, Mrinank, Meg Tong, Tomasz Korbak, et al. “Towards Understanding Sycophancy in Language Models.” arXiv.org, October 20, <span class="No-Break">2023. </span><a href="https://arxiv.org/abs/2310.13548"><span class="No-Break"><span>https://arxiv.org/abs/2310.13548</span></span></a><span class="No-Break">.</span></li>
				<li>Sparkes, Matthew. “AI chatbots become more sycophantic as they get more advanced.” <em class="italic">New Scientist</em>, August 17, <span class="No-Break">2023. </span><a href="https://www.newscientist.com/article/2386915-ai-chatbots-become-more-sycophantic-as-they-get-more-advanced/"><span class="No-Break"><span>https://www.newscientist.com/article/2386915-ai-chatbots-become-more-sycophantic-as-they-get-more-advanced/</span></span></a><span class="No-Break">.</span></li>
				<li>Wei, Jerry, Da Huang, Yifeng Lu, et al. “Simple synthetic data reduces sycophancy in large language models.” arXiv.org, August 7, <span class="No-Break">2023. </span><a href="https://arxiv.org/abs/2308.03958"><span class="No-Break"><span>https://arxiv.org/abs/2308.03958</span></span></a><span class="No-Break">.</span></li>
			</ul>
			<p><a href="B22495_12.xhtml#_idTextAnchor253"><span class="No-Break"><strong class="bold">Chapter 12</strong></span></a><strong class="bold">, Correcting and Optimizing Your Generative </strong><span class="No-Break"><strong class="bold">AI Application</strong></span></p>
			<ul>
				<li>Chui, Michael, Roger Roberts, Tanya Rodchenko, et al. “What every CEO should know about generative AI.” McKinsey Digital, May 12, <span class="No-Break">2023. </span><a href="https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/what-every-ceo-should-know-about-generative-ai"><span class="No-Break"><span>https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/what-every-ceo-should-know-about-generative-ai</span></span></a><span class="No-Break">.</span></li>
				<li>Xiao, Han. “What is ColBERT and Late Interaction and Why They Matter in Search?,” Jina AI, February 20, <span class="No-Break">2024. </span><a href="https://jina.ai/news/what-is-colbert-and-late-interaction-and-why-they-matter-in-search/"><span class="No-Break"><span>https://jina.ai/news/what-is-colbert-and-late-interaction-and-why-they-matter-in-search/</span></span></a><span class="No-Break">.</span></li>
			</ul>
		</div>
	</body></html>