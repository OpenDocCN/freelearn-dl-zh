- en: '12'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Any product person who gets this far in the book has probably accepted that
    the generative AI space is far more complex than simply asking ChatGPT a question
    and expecting a good answer. What it can do is impressive, but it’s frustrating
    when it doesn’t do what is expected. The key here is whether it was *known* that
    it could have been more helpful. In many places, customers will need to learn
    or recognize if ChatGPT, in its air of confidence, was lying. That is why product
    people are the gatekeepers for quality.
  prefs: []
  type: TYPE_NORMAL
- en: 'This final chapter will take a different approach at a straight summary, focusing
    on what we did through other views of the world and a few ways of thinking about
    a generative AI journey:'
  prefs: []
  type: TYPE_NORMAL
- en: Applying learnings to the new frontier
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Double-checking what feels right
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Build processes that fit the solution
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wrapping up the journey
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applying learnings to the new frontier
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The book followed a traditional life cycle approach to applying user experience
    design methods, practices, heuristics, and guidance to the emerging field of generative
    AI. Even though the chapters align with an order for a development process, many
    of these tools and techniques can be used throughout the generative AI journey.
    User research is done up-front to unlock value for future features and is again
    deployed once solutions allow validation. We hope to instill *the care and feeding
    approach is an absolute* with generative solutions. One would think it is an absolute
    with many software products, but the industry needs to be more enamored with the
    approach. There are issues with companies picking up releases that change rapidly.
    Sometimes, it impacts training and is disruptive to services. Generative AI can
    support a continuous improvement process, just like Google search, which is updated
    without a decision by the user. Since generative AI follows the conversational
    AI boom in the early 2010s, there is already a broad understanding of why most
    AI-infused solutions failed. They were thrown over the wall to customers, and
    a care and feeding practice of constant improvement was not followed. Now, generative
    intelligence fills in some of the technical shortcomings of previous chatbot solutions
    and can apply most of that learning, such as the teachings in this book, to create
    more effective generative AI products and services.
  prefs: []
  type: TYPE_NORMAL
- en: In hindsight, most of the time was spent on interactive conversational AI products
    while ensuring the building blocks provided could work for all recommendation-type
    solutions. Whether prioritizing support tickets or sales leads, scoring a marketing
    lead, establishing a user reputation, suggesting the next best step, filtering
    content based on harmful or undesirable content, or classifying sentiment to encourage
    good agent behavior, this book should have the guidance needed to solve those
    problems. The backend services that AI might improve will only need some of our
    approaches, but now an arsenal of techniques are available to apply to any situation.
  prefs: []
  type: TYPE_NORMAL
- en: To be fair to the process, don’t apply every method to every project. Use some
    simple math from [*Chapter 4*](B21964_04.xhtml#_idTextAnchor085), *Scoring Stories*,
    to calculate that every tool and technique has its return on investment. Pick
    and choose the battles with development or the powers that be. Use resources wisely.
    Do what feels right.
  prefs: []
  type: TYPE_NORMAL
- en: Double-checking what feels right
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I attended an AI conference and listened to a talk on AI readiness. Given our
    discussion about when to deploy a solution and all the steps to make an AI solution
    successful, it would be helpful to see how others view what we have covered. Ann
    Maya presented the six tenets of AI readiness that Michael Bachman of **Boomi**
    ([https://boomi.com](https://boomi.com)) created in partnership with 250 C-level
    executives.
  prefs: []
  type: TYPE_NORMAL
- en: I bring up their tenets because they summarize much of our approach slightly
    differently and align nicely with putting in place a process (from [*Chapter 10*](B21964_10_split_000.xhtml#_idTextAnchor216),
    *Monitoring and Evaluation*) that can enable these tenets. It is always valuable
    to compare methods and practices to how others work. It might feel less innovative
    if what you do aligns with what others are doing. However, there is also value
    for our collective to be on the right journey in an emerging space. Even with
    alignment, there are places to learn about missing pieces to the puzzle that provide
    value. I show the results they shared in *Figure 12**.1*. It summarizes the six
    tenets of AI readiness.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B21964_12_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.1 – The six tenets of AI readiness.
  prefs: []
  type: TYPE_NORMAL
- en: Given our UX slant on AI readiness, these tenets don’t cover everything, but
    there is enough overlap that it was nice to find this resource right before I
    finished this book’s draft. Let me align each goal and their explanation with
    our efforts in this book. These are not in any specific order.
  prefs: []
  type: TYPE_NORMAL
- en: Set clear goals
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*From implementation to stewardship, knowing what you want and what you’re
    capable of doing with AI* *is essential.*'
  prefs: []
  type: TYPE_NORMAL
- en: We defined this by discussing use cases ([*Chapter 3*](B21964_03.xhtml#_idTextAnchor058),
    *Identifying Optimal Use Cases for ChatGPT*) in a way that made sense for customers’
    needs. Stay within reach. Focus on where AI can provide the most value and improve
    quality, then thoughtfully branch out. Companies will only do some of it, which
    is why there is a wealth of tools and support for implementation. The question
    is whether the best use cases are tackled to justify the cost.
  prefs: []
  type: TYPE_NORMAL
- en: Know your processes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Document, catalog, create, manage, and maintain workflows and* *business processes.*'
  prefs: []
  type: TYPE_NORMAL
- en: The Wove case study in [*Chapter 6*](B21964_06_split_000.xhtml#_idTextAnchor134)*,
    Gathering Data – Content is King*, touched on aligning goals and core expertise
    with what AI tools can do. A design process can reevaluate if steps in a current
    process are needed. Maintaining the workflow was the key to [*Chapter 7*](B21964_07.xhtml#_idTextAnchor150)*,
    Prompt Engineering*, and fine-tuning in the next chapter. Take the time to get
    these solutions right. They do not just magically work out of the box. Some current
    processes are ripe for re-imagineering. Occasionally, a team can ripe up a process
    and start from a clean slate. Mapping where to go might give a path forward. Sometimes,
    value comes from simple incremental improvements. You now know how to score these
    values, and using Agile, you can determine their costs. **Weighted Shortest Job
    First** is the decision-making process.
  prefs: []
  type: TYPE_NORMAL
- en: Consider the different models that can improve the processes. Examples like
    Hub and Spoke or Chaining came up a few times. As prices come down, it becomes
    practical and expected that multiple models can be used to solve a single problem.
    Different models, with different capabilities, intelligence, performance, and
    costs, can be adapted for unique use cases. It is not one size fits all. The generative
    AI process justifies some consideration, as covered in [*Chapter 11*](B21964_11.xhtml#_idTextAnchor236)*,
    Process*. As it is not uncommon for an enterprise solution to have dozens or hundreds
    of parts, expect a proliferation of models in the enterprise. This makes the entire
    care and feeding life cycle more critical.
  prefs: []
  type: TYPE_NORMAL
- en: Know the data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Understand the value of data, where the data lives, and how it’s generated,
    refined, secured,* *and governed.*'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 6*](B21964_06_split_000.xhtml#_idTextAnchor134), *Gathering Data
    – Content is King,* addressed managing data for bespoke ChatGPT solutions. Without
    enterprise data, there is no added value. It is essential to build a RAG process
    that keeps business data secure and presents it in the right light.'
  prefs: []
  type: TYPE_NORMAL
- en: The enterprise data is the entire reason for this book. It contains the collective
    wisdom for the company, the products and services, and the relationship with its
    customers. This is why it is so valuable. It also means being aware of inherent
    biases. It is not just about possible cultural biases; it could be just how the
    knowledge speaks about products or the terms it uses. Decide how to manage that
    data, deal with the governance of the data, and adapt it to allow AI to take full
    advantage of the corpus.
  prefs: []
  type: TYPE_NORMAL
- en: Align and be accountable
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Stakeholders should understand expectations and work together as good stewards
    of data* *and processes.*'
  prefs: []
  type: TYPE_NORMAL
- en: We often discussed being good stewards of the model and data. Handling bias,
    controlling for PII, and managing integrations are critical to success. As all
    UX partners are, being customer advocates sets the right expectations. Using the
    methods from the first few chapters, evaluating how it is going by following [*Chapter
    9*](B21964_09_split_000.xhtml#_idTextAnchor190), *Guidelines and Heuristics,*
    and measuring the results reviewed in [*Chapter 10*](B21964_10_split_000.xhtml#_idTextAnchor216),
    *Monitoring and Evaluation*, aligns stakeholders to common goals.
  prefs: []
  type: TYPE_NORMAL
- en: If ethical considerations come into play, be accountable for the outcome. The
    approaches discussed around checking results, using prompt engineering to talk
    in the best tone, and returning the most accurate answers are critical. Some mistakes
    by big players will start to make the news. In Hollywood, the saying goes, “*There
    is no such thing as bad publicity.*” Keep tight control over use cases that expose
    ethical, medical, societal, or community standards issues. Don’t be in the news
    for the wrong reasons.
  prefs: []
  type: TYPE_NORMAL
- en: Prioritize thoughtfully
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Establish and balance priorities critical to the business, corporate values,
    and* *societal impact.*'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 4*](B21964_04.xhtml#_idTextAnchor085), *Scoring Stories*, covered
    our scoring method for prioritizing the backlog using a customer-centric approach.
    As UX professionals, we focus on the value provided to customers, but as a proxy,
    we sometimes align with business, corporate, and societal goals. Let’s assume
    that the customer’s goals help achieve those priorities. It reminds me of a book
    commonly read in business school and one required by my professors. The key was
    the ability to answer three questions: *when to change*, *what to change to*,
    and *how to cause a change.* I hope you see the similarity in our approach to
    figuring out what to work on, how to work on it, and what the outcome should be.
    The book, *The Goal*, made for fine reading; it was compelling enough to read
    in one night.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Book: [The Goal: A Process of Ongoing Improvement](https://amzn.to/3WJqWHM)
    ([https://amzn.to/3WJqWHM](https://amzn.to/3WJqWHM))'
  prefs: []
  type: TYPE_NORMAL
- en: Not surprisingly, this novel’s protagonist adopts an iterative approach. However,
    it is based in a factory setting (the software industry wasn’t the powerhouse
    it is today when this book was written). I still encourage it for a thoughtful
    and enjoyable read.
  prefs: []
  type: TYPE_NORMAL
- en: Automate with intention
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Implementing AI without understanding processes or data can lead to inefficiencies
    and* *introduce risk.*'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 5*](B21964_05_split_000.xhtml#_idTextAnchor108), *Defining the Desired
    Experience*, covered this by figuring out thoughtful applications for our AI solutions.
    Make good decisions so the AI solutions provide the most value. Don’t over-AI.
    Pick your battles. Create value.'
  prefs: []
  type: TYPE_NORMAL
- en: There are many ways to approach AI solutions, ChatGPT integrations, and problem-solving
    with generative AI. However, all the best approaches do so thoughtfully, focusing
    on creating **Functional, Usable, Needed, and Effective** (**FUN-E**) experiences.
    Let’s do it with the right goals that follow a path to build a process that fits
    customer needs.
  prefs: []
  type: TYPE_NORMAL
- en: Building processes that fit the solution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We talk about bringing the solution to the customer, not forcing the customer
    to go to the solution. This takes many forms and many paths that follow this mantra:'
  prefs: []
  type: TYPE_NORMAL
- en: Talk in the customer’s language and refrained from forcing them to learn how
    we speak.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use prompt engineering and fine-tuning to align with the customer, and do not
    expect the customer to align with us.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Review how to deploy a solution, bringing AI where they need it. It might be
    on Slack, Teams, Discord, or a web channel. This could also be via several messaging
    apps, a web service, and a desktop or mobile app, all with slightly different
    capabilities.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To accommodate these solutions, processes must allow these engagements. Solutions
    need to span multiple channels, each with slightly different needs. The customer
    might have different expectations of those channels. Text, images, and links on
    a simple messaging platform might support more robust interactions for the same
    goals when deployed on a rich web experience. Also, only some steps will come
    from generative AI solutions. The best successes will come by breaking down use
    cases into the steps that are best solved with specific solutions. *Sometimes*,
    that will include an LLM. Process flows were discussed many times in the book,
    and we were able to take a peek into Wove’s process, which included generic and
    fine-tuned models. Consider the examples of models used in chains, such as the
    hub and spoke model to route to specific tasks and LLMs, branching to support
    different tasks, or looping through the same model with different prompts. These
    are just a few available variations. There is no one correct model. Each will
    require design effort, testing, validation, and a care and feeding process. Each
    is an application suite itself. This is unsurprising, as many enterprise solutions
    might comprise dozens or hundreds of systems and services.
  prefs: []
  type: TYPE_NORMAL
- en: As product owners, designers, and thought leaders, we should *bring the solution
    to the customer, not the customer to the solution*. This will help us wrap up
    our journey.
  prefs: []
  type: TYPE_NORMAL
- en: Wrapping up the journey
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There was a lot of ground to cover; will these skills, methods, practices, heuristics,
    and recommendations that will remain true three to five years from now? Sure,
    OpenAI will change its Playground, and a few links will stop working (the online
    references will be updated), but the concepts will live on for a while. The goal
    for OpenAI is to eliminate the considerable work needed with prompt engineering;
    when that happens, recycle the book and retire to the beach. However, for the
    foreseeable future, there is work to do.
  prefs: []
  type: TYPE_NORMAL
- en: And maybe you noticed we didn’t once discuss ChatGPT’s *enterprise* tools. Of
    course, they have new tools coming soon, and a few select companies would be early
    adopters. What OpenAI can provide is likely valuable and even necessary but not
    sufficient. Some of this is already part of any plan, like the public APIs, multi-factor
    authentication, batch APIs for offline workload, encryption, and single sign-on
    (SSO). The ecosystem still has plenty of maturities left for OpenAI, third parties,
    and enterprise companies to address.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The concepts in this book will outlive the models used in these examples. Apply
    this learning to the latest models available.
  prefs: []
  type: TYPE_NORMAL
- en: Since the goal is to have up-to-date knowledge and wisdom, the book’s online
    references will be monitored to ensure they continue working. Even during the
    writing process, references had to be retired. Our collective goal is to move
    our customers toward wisdom. It is insufficient to regurgitate or push only data
    or information to consumers of our generative AI solutions. Our knowledge and
    ability to use generative AI should allow us to impart *wisdom* in solutions.
    I don’t recall where I found the pyramid in *Figure 12**.2*.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B21964_12_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.2 – Wisdom is the goal
  prefs: []
  type: TYPE_NORMAL
- en: Let’s take an example anyone can appreciate. There is plenty of *data* on how
    tall mountains are across the world. However, it is intriguing for a climber to
    know that Mt. Everest is the tallest mountain in the world and has two climbing
    routes. *Knowledge* from previous climbers’ experience (and some basic physiology)
    tells us that summiting typically requires oxygen (bottled and carried by the
    incredible Sherpas). However, there is a more important reason why those who summit
    use Sherpas. If they listen to their sage advice (*wisdom*), they are in the best
    position to succeed. If they don’t accept the Sherpas’ collective wisdom, tragedy
    can strike. This slide is shared so it can be adapted to any use case.
  prefs: []
  type: TYPE_NORMAL
- en: 'GitHub: [Wisdom Pyramid slide](https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter12-WisdomPyramid.pptx)
    ([https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter12-WisdomPyramid.pptx](https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter12-WisdomPyramid.pptx))'
  prefs: []
  type: TYPE_NORMAL
- en: Figure out how to give customers the wisdom they need to be successful. Don’t
    just give them the same data in a new way. There is value to unlock by giving
    wise advice. Also, don’t be constrained by AI. Wisdom can be provided without
    AI.
  prefs: []
  type: TYPE_NORMAL
- en: 'Time to consider what is next for AI. Rapid changes are everywhere. With all
    the effort to research this book, it is fun to think about what is next for generative
    AI in enterprise solutions. What will the next few years bring prior to Skynet?
    Time to pontificate about the future:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open-source models and portable models that protect PII will become more plentiful.
    The downside is that with that protection comes the inability to learn how to
    improve them. Opt-in programs that allow data sharing for “improvement” purposes
    will be the norm. Always have this option: pay or credit customers for this privilege.
    Learning is fundamental.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prompt engineering will become easier as more effort is placed into the foundation
    models for broader intelligence. Writers and designers will have the limelight
    here, but its criticality will diminish over time.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As enterprise applications move deep into AI, second-tier services will blossom.
    Secondary use cases and less critical business needs can leverage these now-standard
    services to AI-enable more of the business life cycle. Yes, it will be just about
    everywhere.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Failures will still exist and continue to be news. Lawsuits beyond data scraping
    will be expected. However, just like errors from human agents, errors and subsequent
    lawsuits will be reduced as hallucinations are minimized.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Once we pass the hype cycle by the start of 2027, the need to explain that AI
    is behind the scenes will stop, as it will be the norm. The biggest jumps in AI
    improvements for this cycle have already happened. By 2025, we will enter a phase
    of incremental improvements until the next major cycle by 2031.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The AI revolution will be bigger than the web revolution. It will be used in
    every part of daily life and is as common as a smartphone, spanning every walk
    of life far beyond the web and the Internet. AI can benefit billions of less fortunate
    people. Crop yields, water management, more affordable healthcare, supply chain
    optimization, disaster predictions, and education are all critical and will align
    with governments that fund these areas.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Although it will eliminate some jobs, it will also generate more valuable opportunities
    for the next generation. This is not a stretch, given the speed of adoption. Every
    technological revolution, from the wheel to the internet, requires society to
    adapt. We are still smarter, in many ways, than AI.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In my lifetime, we will finally see home robots that can serve as general-purpose
    assistants (cook, clean, and fold laundry). The robot revolution, with vision
    analysis and LLMs, will come together in the next ten years. I suspect the same
    can be said for some hard day labor roles, as machine vision being used to pick
    fruit exists and will get better when robots are controlled.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I encourage engaging with me and the whole AI community. There is so much for
    UX people of all types to learn about what our data science and engineering friends
    are doing, and while learning from them, we can impart a wealth of value to their
    practices, hopefully with some of the wisdom imparted in this book. Connect, share,
    and engage.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '| ![](img/B21964_12_QR.png) | The links, book recommendations, and GitHub files
    in this chapter are posted on the reference page.Web Page: [Chapter 12 References](https://uxdforai.com/references#C12)
    ([https://uxdforai.com/references#C12](https://uxdforai.com/references#C12)) |'
  prefs: []
  type: TYPE_TB
