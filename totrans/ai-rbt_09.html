<html><head></head><body>
<div><h1 class="chapter-number" id="_idParaDest-147"><a id="_idTextAnchor294"/>9</h1>
<h1 id="_idParaDest-148"><a id="_idTextAnchor295"/>Giving the Robot an Artificial Personality</h1>
<p>When a person thinks of a robot with AI, what many consider AI is a robot that has emotions, feelings, a state of mind, and some sort of model<a id="_idIndexMarker681"/> or concept of how humans think or feel. We can call this form of AI an <strong class="bold">artificial personality</strong>. While giving a robot feelings is definitely way beyond the scope of this book (or current technology), what we can do is create a simulation of a personality for the robot using standard computer modeling techniques, such as Monte Carlo analysis, and finite state machines.</p>
<p>In this chapter, we will cover the following topics:</p>
<ul>
<li>What is an artificial personality?</li>
<li>A brief introduction to the (obsolete) Turing test, chatbots, and <strong class="bold">generative </strong><strong class="bold">AI</strong> (<strong class="bold">GenAI</strong>)</li>
<li>The art and science of simulation</li>
<li>An emotion state machine</li>
<li>Playing the emotion game</li>
<li>Creating a model of human behavior</li>
<li>Developing the robot emotion engine<a id="_idTextAnchor296"/><a id="_idTextAnchor297"/></li>
</ul>
<h1 id="_idParaDest-149"><a id="_idTextAnchor298"/>Technical requirements</h1>
<p>We will not be introducing any new programming libraries in this chapter. We will be building on the voice system we constructed previously. All you will need is imagination and some writing skills.</p>
<p>You’ll find the code for this chapter at <a href="https://github.com/PacktPublishing/Artificial-Intelligence-for-Robotics-2e">https://github.com/PacktPublishing/Artificial-Intelligence-for-Robotics-2e</a>.<a id="_idTextAnchor299"/><a id="_idTextAnchor300"/><a id="_idTextAnchor301"/></p>
<h1 id="_idParaDest-150"><a id="_idTextAnchor302"/>What is an artificial personality?</h1>
<p>Hollywood and the movie industry<a id="_idIndexMarker682"/> have turned out some very memorable robots. You can think of R2D2 and C3PO, the Laurel and Hardy of science fiction. What do you like most about these two? Could it be their personalities? Think about this a bit. Even though R2D2 is mostly a wastebasket shape with a dome head and no face, he has a definite personality. You’d describe him as <em class="italic">feisty</em> or <em class="italic">stubborn</em>. The <em class="italic">Robots and Androids</em> website (<a href="http://www.robots-and-androids.com/R2D2.html">http://www.robots-and-androids.com/R2D2.html</a>) described him in this way:</p>
<p class="uthor-quote">The droid is shown as being highly courageous, unwavering in loyalty, and a little bit stubborn. He never backs down from a mission, even when the odds appear to be stacked against him. His personality is often contrasted against that of [C3PO], who is fussy and timid.</p>
<p>This is pretty impressive for a robot who never says a word and communicates with beeps and whistles.</p>
<p>What were other movie robots that made an impression on you? Certainly, WALL-E, the lovable trash-compacting robot from the eponymous movie, is a favorite. WALL-E also had a small vocabulary, consisting of only his name, much like a Pokemon. WALL-E displayed a lot of emotion and even developed hobbies, collecting and repairing old trash. You may also remember M-O, the tiny, obsessive cleaning robot that gets frustrated with all of the dirt WALL-E brings in.</p>
<p>So, one thing that we might do as robotics creators and designers is to imbue our robot with some sort of personality. This has the advantage of letting humans relate to the robot better. It also gives the false impression that the robot is much smarter and is capable of more than it really is. This does give the advantage of the robot being more engaging and interesting.</p>
<p>We can also infer from the examples given to us by R2D2 and WALL-E that less can be more when it comes to communication – we need to not just have words but also body language and sound.</p>
<p>What we are going to do in this section<a id="_idIndexMarker683"/> is develop an artificial personality for our robots. While it is impossible for us to give a robot actual emotions or feelings, however you might define that, we can create a simulation of personality that will provide a convincing illusion. I think this is a meaningful exercise because the current state of the art in robotics demands some sort of personality and consistent demeanor from robotics that interact with huma<a id="_idTextAnchor303"/>ns.</p>
<p>The cartoon seen in <em class="italic">Figure 9</em><em class="italic">.1</em> expresses how people and robots might interact. The robot has had enough with picking up toys and wishes to show its feelings:</p>
<div><div><img alt="Figure 9.1 – A person and a robot interacting" src="img/B19846_09_1.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.1 – A person and a robot interacting</p>
<p>There is a lot of work going on in this area right now with digital personal assistance, such as Apple’s Siri and Amazon’s Alexa. Note that these robots, or AIs, have distinct names and voices, but I feel that they are very similar in personality and capability. There is some distinction when you ask Siri or Alexa a personal question, such as how old they are (Siri is considerably older than Alexa).</p>
<p>In this chapter, we are going to take tools from the science of simulation – specifically, <strong class="bold">state machines</strong> and <strong class="bold">Monte Carlo analysis</strong> – and use them to form a<a id="_idIndexMarker684"/> model of a personality<a id="_idIndexMarker685"/> for Albert, the robot. We already have a fairly powerful tool, in the Mycroft speech system we used to tell knock-knock jokes. We will be extending Mycroft with some new skills and capabilities, as well as developing cybernetic emotions, both for our robot and for the robot’s opinion of what we, the humans, are feeling.</p>
<p>I want to emphasize that we are simulating emotions, not creating an emotional robot. Our simulation bears the same resemblance to real emotions as a flight simulator bears to the space shuttle – both provide the same information, but the space shuttle flies around the Earth in 90 minutes, and the flight simulator never moves.</p>
<p>Let’s talk about what we are trying to accomplish<a id="_idIndexMarker686"/> in this section by first talking about the famous Turing test – can we create a robot that interacts in a way that's indistinguishable from a human be<a id="_idTextAnchor304"/><a id="_idTextAnchor305"/><a id="_idTextAnchor306"/>ing?</p>
<h1 id="_idParaDest-151"><a id="_idTextAnchor307"/>A brief introduction to the (obsolete) Turing test, chatbots, and generative AI</h1>
<p>Alan Turing proposed<a id="_idIndexMarker687"/> his famous<a id="_idIndexMarker688"/> test, which he called <em class="italic">The Imitation Game</em>, in a paper titled <em class="italic">Computing Machinery and Intelligence</em>, published in 1950 in the journal <em class="italic">Mind – A Quarterly Review of Psychology and Philosophy</em> (see <a href="https://www.abelard.org/turpap/turpap.php#the_imitation_game">https://www.abelard.org/turpap/turpap.php#the_imitation_game</a>). In the original text, Turing imagined a game<a id="_idIndexMarker689"/> where a player would have to guess the sex – male or female – of a hidden person by typing questions on a teletype. Then, he suggested that a truly intelligent machine would be one where you would not be able to distinguish if the hidden personality on the other end of the teletype was a human or a computer software program.</p>
<p class="callout-heading">Note</p>
<p class="callout">The movie <em class="italic">The Imitation Game</em> stars Benedict Cumberbatch as Alan Turing and features his role in breaking German code in WWII as part of the mathematicians of Bletchley Park. The title refers to Turing’s original name of the famous test that bears his name.</p>
<p>These days, you may talk to computer software many times a day and not realize that you are not speaking to a human. Robocalls and chatbots may call you on the telephone or engage you in a fake political conversation on Twitter. The Turing test has been won by the machines (<a href="https://www.nature.com/articles/d41586-023-02361-7">https://www.nature.com/articles/d41586-023-02361-7</a>), but have we developed intelligence in computers? Not at all – we have just become very clever at simulating conversation. Recently, robotics experts have suggested replacing the Turing test with a more demanding and difficult assessment of a computer’s cognitive skills and self-understanding: <a href="https://techxplore.com/news/2023-11-redefining-quest-artificial-intelligence-turing.html">https://techxplore.com/news/2023-11-redefining-quest-artificial-intelligence-turing.html</a>.</p>
<p>We are going to use another tool that Alan<a id="_idIndexMarker690"/> Turing mentioned in his paper – <strong class="bold">state machines</strong>. We will use state machines to define and model the emotions of our robot in the <em class="italic">An emotion state </em><em class="italic">machine</em> section.</p>
<p>Let’s now go back to the concept of a <strong class="bold">chatbot</strong>. A working definition may<a id="_idIndexMarker691"/> be a software program designed to engage a human in conversation or to interact with a person via voice or text. While most chatbots are up-front about being computer generated, there are a lot of chatbots that are not – including Twitter chatbots that seek to influence elections or public opinion. Many chatbots are gainfully employed answering tech support phone calls, making<a id="_idIndexMarker692"/> marketing calls, and entertaining users as the dialog of <strong class="bold">non-player characters</strong> (<strong class="bold">NPCs</strong>) in games.</p>
<p>According to the article <em class="italic">Ultimate Guide to Leveraging NLP and Machine Learning for Your Chatbot</em> by Stefan Kojouharov, published by <a href="http://chatbotslife.com">chatbotslife.com</a> in 2016, chatbots come in tw<a id="_idTextAnchor308"/>o flavors:</p>
<ul>
<li><strong class="bold">Retrieval-based</strong>: These chatbots rely on stored phrases<a id="_idIndexMarker693"/> and words, and use the software decision-making to select which reply is most appropriate. There may be some keyword recognition and noun-subject insertion involved, but the main action is to select the most appropriate phrase.</li>
<li><strong class="bold">Generative-based</strong>: These chatbots make up new sentences based on <strong class="bold">parts of speech</strong> (<strong class="bold">POS</strong>) and the robot’s divination<a id="_idIndexMarker694"/> of your intent. They<a id="_idIndexMarker695"/> can be thought of as machine translation engines that translate the input (your text or speech) into an output (the robot’s reply). As you might imagine, the generative-type chatbot is far more difficult to achieve, which is why we will be using a retrieval-based approach. Recent developments from projects such as ChatGPT<a id="_idIndexMarker696"/> have redefined what <a id="_idIndexMarker697"/>is possible<a id="_idIndexMarker698"/> for chatbots. The term <strong class="bold">Generative Pre-trained Transformer</strong> (<strong class="bold">GPT</strong>) refers to three characteristics of this <strong class="bold">neural </strong><strong class="bold">network</strong> (<strong class="bold">NN</strong>):<ul><li><strong class="bold">Generative</strong>: The model is capable of creating new text phrases, rather than just repeating or categorizing text</li><li><strong class="bold">Pre-trained</strong>: The model is pre-trained on enormous datasets – over a trillion examples – to understand language and the relationship between words</li><li><strong class="bold">Transformer</strong>: The NN architecture uses transformers to process an entire sentence at a time, learning both the word meanings and relationships in a sentence (positions of words in a sentence)</li></ul></li>
</ul>
<p>In the simplest form, the GenAI NN predicts what word is most likely to come next in a sentence, based on training on billions of examples.</p>
<p>We will use GenAI to develop some of our text<a id="_idIndexMarker699"/> outputs but apply these to a classical chatbot, thus having the best of both worlds – not having to generate text ourselves, and having a system where we have control over inputs and outputs and can trust the system to control a robot.</p>
<p>There are two other details we need to attend to. Chatbots<a id="_idIndexMarker700"/> can be designed to handle either short conversations or long conversations. The vast majority of chatbots – and that includes digital assistants such as Siri, Alexa, and Mycroft – are designed for very short conversations. <em class="italic">Siri, what is the weather?</em> <em class="italic">There is a 20% chance of rain.</em> <em class="italic">The high is 88 degrees.</em> That’s it – the whole conversation in three sentences and two interactions. If you ask another question, it starts a new conversation with little reference to the previous one.</p>
<p>A more difficult task is to have a longer conversation with several interactions and even a selection of topics. This requires the computer to keep track of context or what information has been discussed and might be referred to again.</p>
<p>We will be attempting to teach our robot<a id="_idIndexMarker701"/> to be able to have medium-length conversations <a id="_idIndexMarker702"/>at a 7-year-old level. I’ll define medium length to be between two and six interactions.</p>
<p>Now, before we proceed with our robot, let’s quickly discuss some statistical distributions because I’ve found the ability to use Monte Carlo analysis – and to create custom random number distributions – very<a id="_idTextAnchor309"/><a id="_idTextAnchor310"/> useful in robotics.</p>
<h1 id="_idParaDest-152"><a id="_idTextAnchor311"/>The art and science of simulation</h1>
<p>What is simulation? A <strong class="bold">simulator</strong> is a computer model of the physical<a id="_idIndexMarker703"/> world. You are probably familiar<a id="_idIndexMarker704"/> with flight simulators, which provide sensations and interactions of flight without leaving the ground. There are also a lot of other types of simulations and simulators. We could have a medical simulator that mimics diseases or responds to treatments. It could be a financial simulation that models profits on the stock market based on trends. There are structural simulations that model loads on bridges and buildings to see whether the m<a id="_idTextAnchor312"/>aterials are adequate.</p>
<p>The most common way of creating<a id="_idIndexMarker705"/> a simulation is by building a <strong class="bold">physics model</strong> of the item under test. For a flight simulator, this means plugging in formulas for the four forces on an airplane or a helicopter – lift, gravity, thrust, and drag. Each factor has parameters that affect its performance – for instance, the lift is a function of the speed through the air, the weight of the aircraft, the size of the wing, and the angle of attack, or the angle between the wing and the wind. Vary any of those, and the lift changes. If the amount of lift exceeds the force due to gravity (that is, the weight of the aircraft), then the aircraft flies. The simulation sets up a time-step interval, just like our control loop for the robot, and computes the forces on the aircraft for each time step. We can then apply controls and see how our model performs. Models just like this are used to predict performance in advance of building a prototype or test airplane.</p>
<p>Another type of <a id="_idIndexMarker706"/>simulation is called a <strong class="bold">Monte Carlo model</strong>. The Monte Carlo method uses <strong class="bold">probability theory</strong> to replace sophisticated physical<a id="_idIndexMarker707"/> models with a variation of random numbers that approximates the same result. If you wanted to create a computer model of flipping a coin, you wouldn’t spend a lot of time determining the physical properties of a nickel or modeling the number of flips in the air based on force. You would just pick a random number from 1 to 100 and say the result is heads if the number drawn is less than 50 and tails if it is greater than 50. That, in essence, is the Monte Carlo method. There are a lot of physical processes that can be approximated and studied using this technique, where outcomes can be described in terms of probabilities.</p>
<p>We can apply Monte Carlo<a id="_idIndexMarker708"/> analysis to model people going through security at an airport. If you had a copy<a id="_idIndexMarker709"/> of a typical schedule for the airlines and the average number of passengers per flight, you would know the daily traffic at the airport. The difficult bit would be modeling when people would arrive for their flight. Let’s imagine that we commissioned a study and determined roughly that 50% of people arrive 1 hour early, 25% arrive 2 hours early, and the rest are evenly distributed between 2.5 hours and 30 minutes, with 1 passenger out of every 200 missing their flight by being late. We can approximate the passenger arrival function with two standard distributions (bell curves) and two uniform distributions (boxes):</p>
<div><div><img alt="Figure 9.2 – A complex probability distribution function can be approximated by the union of simpler distributions" src="img/B19846_09_2.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.2 – A complex probability distribution function can be approximated by the union of simpler distributions</p>
<p>This information allows us to create sample<a id="_idIndexMarker710"/> sizes of passenger arrivals and thus obtain an estimate of the length of lines at security. We would add some distribution of values of how long it took to get through security, and we would have our model. We have a list of flights, and for each flight, we generate a distribution of passenger arrival times based on the study by assigning random numbers to each passenger and separating them out into groups based on arrival time.</p>
<p>Let’s assign random numbers from 1 to 100 to our 212 passengers arriving for the 08:00 flight from Dallas to Washington DC. Now, we assign an arrival time based on that number – if the number is from <em class="italic">1</em> to <em class="italic">25</em>, the passenger arrives 2 hours earlier than the flight (06:00). If the number is from <em class="italic">26</em> to <em class="italic">75</em> (the next 50%) then they arrive 1 hour early (07:00). The rest of the passengers, having numbers from <em class="italic">76</em> to <em class="italic">100</em>, are assigned random times between 2.5 hours early to 30 minutes early. And we pick 1 unlucky passenger out of our 212 to miss the flight completely by arriving late. Since there is some variability in people who intend to arrive exactly 2 hours<a id="_idIndexMarker711"/> ahead, but are delayed or advanced slightly, we can <strong class="bold">dither</strong> or add a small random distribution factor to each arrival time of plus or minus 10 minutes. We now have a statistically correct distribution of people arriving for a flight. Now, repeat this process for the other 1,849 flights leaving today from this airport. You can see from this model that we can still put a great deal of science into picking random numbers.</p>
<p>So, how do we make a <strong class="bold">probability distribution function</strong> (<strong class="bold">PDF</strong>) that looks like this (see <em class="italic">Figure 9</em><em class="italic">.2</em> top graph)? The answer<a id="_idIndexMarker712"/> is we combine several distributions. In the lower graph of <em class="italic">Figure 9</em><em class="italic">.2</em>, you see two standard distributions (the humps in green) and one uniform distribution (the lower green box) that combined make our overall correct function.</p>
<p>As you might have guessed from<a id="_idIndexMarker713"/> my example, the true secret of making this technique work is picking the correct distribution of random numbers. You may think, “Hey, random numbers<a id="_idIndexMarker714"/> are random numbers, right?” But<a id="_idIndexMarker715"/> this is not correct at all. You have heard of a <strong class="bold">standard distribution</strong> or the <strong class="bold">bell-shaped curve</strong>. Most of the values are in the center, with fewer and fewer as you go away from the center. Many natural processes follow this bell-shaped curve, including grades on a test, how tall people are, or how many grapes grow in a bunch. When you do Monte Carlo analysis, most often we use some form of normal or standard distribution.</p>
<p>Can you think of other types of random numbers? The second<a id="_idIndexMarker716"/> most common type of random number is a <strong class="bold">uniform distribution</strong>. Each number has the exact same probability of being selected, which makes for a flat distribution curve. Another name<a id="_idIndexMarker717"/> for this uniform distribution is <strong class="bold">white noise</strong>. Uniform distributions do occur in analysis, and if we want to add noise to an image, for example, we will use a uniform distribution. But in modeling emotions and people, normal or standard distributions are the rule.</p>
<p>You may find that in using Monte Carlo modeling, a standard distribution or uniform distribution just won’t work. Then, you can create a custom distribution, as I did in the airport example, where we used re-sampling to change a uniform distribution to a custom distribution fitting our passenger arrival model.</p>
<p><em class="italic">Figure 9</em><em class="italic">.3</em> shows the various shapes<a id="_idIndexMarker718"/> of distributions various kinds of random number generators produce, along with their commonly used names – the bell curve and the flat line. The lognormal graph looks to me like a ski slope – what do you think it looks like?</p>
<div><div><img alt="Figure 9.3 – Various types of random number generators and the distributions they produce" src="img/B19846_09_3.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.3 – Various types of random number generators and the distributions they produce</p>
<p>Our next task is to generate a personality<a id="_idIndexMarker719"/> simulation <a id="_idTextAnchor313"/>for our robot, and we will be using Monte Carlo modeling plus a state machine to create a model of our robot’s emotions. Let’s first discus<a id="_idTextAnchor314"/>s what an emotion state machine is.</p>
<h1 id="_idParaDest-153"><a id="_idTextAnchor315"/>An emotion state machine</h1>
<p>What is a state machine? We covered state machines<a id="_idIndexMarker720"/> in the systems engineering section of <a href="B19846_02.xhtml#_idTextAnchor032"><em class="italic">Chapter 2</em></a> – state machines are a technique for understanding or modeling automation or computer programs. A <strong class="bold">state</strong> is a set of conditions that exist<a id="_idIndexMarker721"/> at the present. I like to think of a state as being a set of functions that are constrained by limits. The machine (our robot) changes from state to state based on some <a id="_idTextAnchor316"/>event that causes the state to change.</p>
<p>Let’s work through a quick refresher example. Let’s take a slice of bread. When we get it, it is already baked and sliced, so its initial state is as a slice of bread. If we subject the bread to infrared radiation (that is, heat), then the surface becomes caramelized, and we call that toast. The state of the bread has changed, along with its taste and texture, from baked bread to toast. The event that caused that transition was the act of heating the bread in a toaster. This is pretty simple stuff, and I’m sure you have encountered state machines before.</p>
<p>Now, let’s think about our model of robot emotions. We can start by listing what emotions we want our robot to have:</p>
<ul>
<li>Happy</li>
<li>Welcoming</li>
<li>Friendly</li>
<li>Curious</li>
<li>Positive</li>
<li>Energetic</li>
</ul>
<p>Then, we can list the opposites of those emotions:</p>
<ul>
<li>Sad</li>
<li>Distant</li>
<li>Unfriendly</li>
<li>Frustrated</li>
<li>Tired</li>
</ul>
<p>These are the list of emotions<a id="_idIndexMarker722"/> I wanted to simulate in our robot. I looked at the different interactions the robot might have and how a human version of the robot would react:</p>
<div><div><img alt="Figure 9.4 – Robot emotional state machine model" src="img/B19846_09_4.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.4 – Robot emotional state machine model</p>
<p>In the preceding diagram, we model<a id="_idIndexMarker723"/> the overall emotive state of the robot by plotting<a id="_idIndexMarker724"/> the various emotional components or states on a polar plot, as follows:</p>
<ul>
<li>Each emotional element has a vector or direction. On the left side of the plot are happy, friendly, open feelings, and on the right side are sad, closed, distant feelings.</li>
<li>The distance from the center indicates the strength of the emotions.</li>
<li>The yellow circles are the robot’s current value on each axis.</li>
<li>The purple line is the vector sum of those emotions, which gives us the overall mood of the robot. The arcs show the minimum and maximum magnitude of emotion.</li>
</ul>
<p>We take the area made up of the four components and find the center of that area, and that is the overall state of the robot. In this example, the predominant emotion is <em class="italic">friendly</em>. Since the robot’s physical state determines whether it feels <em class="italic">tired</em> or not, that data is computed separately – this lets the robot feel tired but friendly, or refreshed but sad.</p>
<p>The robot starts in a state<a id="_idIndexMarker725"/> of <em class="italic">happy</em>, <em class="italic">distant</em>, <em class="italic">curious</em>, and <em class="italic">fresh</em>. That is to say, it feels happy, it is not in an interaction, so there is no one to be friendly to, and it will be curious about its surroundings. As the environment changes, the robot’s state will change. For example, we have about a 2-hour run time on Albert’s current battery. It starts off in a <em class="italic">fresh</em> state and will get more and more tired as it approaches the 2-hour mark. We are going to use a simple timer to create this state, but you could use the voltage sensor in the robot arm to provide information about how fresh the robot’s power supply is. Each emotion exists along an axis a<a id="_idTextAnchor317"/>nd all cross a central or neutral point.</p>
<p>We will drive the <em class="italic">happy-sad</em> axis based on how many conversation points the robot is earning. We’ll cover this in detail in the <em class="italic">Playing the emotion game</em> section. We will also be describing an empathy function for our robot that simulates the robot sharing feelings with you. The <em class="italic">distant-welcoming</em> aspect is controlled by how the human interacts with the robot. If you are acting friendly to the robot, then it will be welcoming. If you are new, the robot will start off cautiously in asking questions or interacting. If you are not answering questions, then the robot will become more distant. Likewise, the <em class="italic">friend-stranger</em> aspect is based on how much the robot knows about the person it is talking to. Finally, the <em class="italic">curious-frustrated</em> axis is based on how hard the robot has to work to get information or to accomplish a task. If it keeps failing at a task or is not getting rewards, it will become frustrated in its expressions and vocabulary.</p>
<p>How does a robot with no face express emotions? Remember we started talking about Hollywood robots, many of whom have distinct personalities without having faces or even heads. We will use body language with the robot arm and changes in vocabulary to express our simulation of emotions. And we will have the robot be open about how it is feeling and why.</p>
<p>Our goal for this part of the robot development is to provide a human interaction framework that invites people to talk to the robot and feel welcome or wanted. I’m modeling this interaction from watching my g<a id="_idTextAnchor318"/>randchildren. I wanted a robot that they would enjoy and find interesting. What we want<a id="_idIndexMarker726"/> to do is develop the ability for the robot to convey intent, or to provide a simulation that the robot has needs and desires. We are going to do this by creating a game that the robot will play with h<a id="_idTextAnchor319"/>umans – let’s call this t<a id="_idTextAnchor320"/>he emotion game.</p>
<h1 id="_idParaDest-154"><a id="_idTextAnchor321"/>Playing the emotion game</h1>
<p>So, what exactly is this game? What we want<a id="_idIndexMarker727"/> the robot to do is ask questions of another person and to use conversation to get personal information out of them so that the robot then can use that information in replies. In this game, the robot will be trying to score points by getting the human to interact socially. The robot will gain points by getting information from the person so that it can <em class="italic">get to know them better</em>. The trick for us is we need the robot to keep this information and remember it. We will be saving all this information and using it to modify the actual code<a id="_idIndexMarker728"/> the robot is running, thus implementing <strong class="bold">machine learning</strong> (<strong class="bold">ML</strong>) into the conversation. The robot will be using the same type of point-reward system we used in training the robot arm back in a previous chapter. Once the robot has scored by learning a fact, it will no longer get rewarded for that fact and will go on to get other facts. Once it has learned all the facts, it will end the conversation. In practice, I think most users will want fairly short conversations, so we are setting our goal to have between two and six interactions per conversation.</p>
<p>Let’s quickly summarize how the game will be played:</p>
<ol>
<li>The user will always initiate a conversation by saying the robot’s wake phrase, which right now is <em class="italic">Hey, Albert</em>.</li>
<li>The robot will respond using the Mycroft speech engine with a beep.</li>
<li>The user will initiate a conversation using a wake word, which is some version of <em class="italic">Hello, robot</em>.</li>
<li>The robot will then try to earn rewards by getting points, which it does by asking questions.</li>
<li>The emotion engine will respond to the human answers by modifying the robot’s emotions.</li>
<li>We will rank questions by importance – let’s say the robot gets 10 points for learning your name, 9 points for learning your age, and so on.</li>
<li>Once a fact is learned, no more points are earned, so the robot won’t repeat the questions.</li>
</ol>
<p>The facts we want the robot<a id="_idIndexMarker729"/> to know about each person are the following:</p>
<ul>
<li>Your name</li>
<li>Your age</li>
<li>How are you feeling today?</li>
<li>What is your favorite food?</li>
<li>What is your favorite book?</li>
<li>Do you go to school?</li>
<li>If so, what is your favorite subject?</li>
<li>When is your birthday?</li>
<li>What is your favorite song?</li>
<li>Do you like the color pink/singing/dancing/dinosaurs/race cars/building things/robots/airplanes/spaceships?</li>
<li>Do you brus<a id="_idTextAnchor322"/>h your teeth?</li>
<li>Do you like knock-knock jokes?</li>
</ul>
<p>As part of the learning game for the robot, we will adjust the robot’s emotions as it learns and interacts, by adjusting the levels of the eight emotions (or four emotion types) we provided to the robot. We will particularly pay attention to the place where the eight emotions balance – are they on the <em class="italic">happy</em>/<em class="italic">friendly</em>/<em class="italic">curious</em> side of the graph, or more on the <em class="italic">sad</em>/<em class="italic">frustrated</em>/<em class="italic">distant</em> side?</p>
<p>Since we are trying to get some personal information about people talking to the robot, they may want to find out more about the robot too. So, to respond, our robot will also have a backstory or a biography that it will use to answer questions about itself. We’ll give the robot a little narrative:</p>
<ul>
<li>His name is Albert.</li>
<li>His full name is Albert Robot the Second.</li>
<li>He is 8 months old.</li>
<li>He was made by Grandad.</li>
<li>He was born on January 28, 2023.</li>
<li>He likes the color green.</li>
<li>His favorite food is electricity.</li>
<li>His favorite author is Isaac Asimov.</li>
<li>He does not go to school but loves to learn.</li>
<li>His job, his hobby, and his passion is picking up toys.</li>
<li>If you ask him how he feels, he will tell you which emotional state is highest, plus how fresh or tired his battery is. We want him to occasionally interject how he is feeling into the conversation<a id="_idIndexMarker730"/> without being asked.</li>
</ul>
<p class="callout-heading">Note</p>
<p class="callout">I’ve been addressing this robot as <em class="italic">he</em> and <em class="italic">him</em> all through the book. This is just an anthropomorphic projection on my part and is implying features that a robot just does not have. The primary reason for Albert’s identity is his voice – I used a male voice for his synthesizer, mostly because I wanted it to stand out from all the female GPS and personal assistant computer voices around. Please feel free to create any voice you like – there are a lot of female voices available, and you can create whatever persona you like in your robot and give them any form of address. It is interesting that we tend to do this even with non-humanoid robots.</p>
<p class="callout">According to Colin Angle, CEO of iRobot, over 80% of Roomba owners have given their robot a name, including him (<a href="https://slate.com/technology/2014/03/roomba-vacuum-cleaners-have-names-irobot-ceo-on-peoples-ties-to-robots.html">https://slate.com/technology/2014/03/roomba-vacuum-cleaners-have-names-irobot-ceo-on-peoples-ties-to-robots.html</a>). You don’t see people naming their toaster ovens or stand mixers, no matter how attached they are to them. Albert the robot may very well be getting a sex-change operation, or get a sister, as my granddaughter gets a bit older.</p>
<p>We will also be using the emotional state to set the robot’s body language, which is primarily how he is carrying his robot<a id="_idIndexMarker731"/> arm. If he is happy, the arm will be extended with the hand pointed upward. If he is sad, the arm will be close to his body and his hand will point down. We will store all this information to give the robot a co<a id="_idTextAnchor323"/><a id="_idTextAnchor324"/><a id="_idTextAnchor325"/>nsistent set of answers to personal questions.</p>
<h1 id="_idParaDest-155"><a id="_idTextAnchor326"/>Creating a model of human behavior</h1>
<p>For the robot to support conducting<a id="_idIndexMarker732"/> a conversation, we must also have a model of how the human it is talking to is feeling. You may have had a friend or relation who went on talking about themselves and were oblivious to how you were feeling or reacting to their conversation. We don’t want that type of robot personality. Therefore, the robot has to have some internal representation of how it thinks you are feeling. We will not be using vision for this function, so the only way the robot knows how you are doing is by asking questions and evaluating the use of language.</p>
<p>We will give the robot a human model similar to our state machine but with just four emotions on two axes: <em class="italic">happy</em>/<em class="italic">sad</em> and <em class="italic">friendly</em>/<em class="italic">distant</em>. The robot will assume that everyone is somewhere in the middle when the conversation begins. The robot can use clues in language to understand how you might be feeling, so we will assign <em class="italic">colors</em> or shades of emotions to words to help drive the robot’s human model. This can be illustrated by the following diagram:</p>
<div><div><img alt="Figure 9.5 – A simplified emotional continuum" src="img/B19846_09_5.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.5 – A simplified emotional continuum</p>
<p>Different emotions from the person will drive different responses from the robot. We particularly want the robot to pay attention to clues that the human is becoming frustrated due t<a id="_idTextAnchor327"/>o the robot not understanding or responding in the way the person wants. This brings us to actually<a id="_idIndexMarker733"/> selecting and des<a id="_idTextAnchor328"/>igning an artificial personality for our robot.</p>
<h2 id="_idParaDest-156"><a id="_idTextAnchor329"/>Integrating an artificial personality into our robot</h2>
<p>We need to set some guidelines<a id="_idIndexMarker734"/> and parameters that will determine<a id="_idIndexMarker735"/> what kind of personality the robot<a id="_idIndexMarker736"/> has. We can start by listing some types of personalities that a robot might have and what kind of role they might be playing. This is particularly important because this robot will primarily be interacting with children. Let’s try a few out and see what fits:</p>
<ul>
<li><strong class="bold">Teacher/professor</strong>: The robot is attempting to convey information and to teach or cause the person to change behavior in some way. The robot presents itself as an authority and provides facts and information about itself, such as “I’m a robot. Do you know what a robot is?”</li>
<li><strong class="bold">Hyper-friendly</strong>: The robot is playful and excited<a id="_idIndexMarker737"/> about talking with <a id="_idIndexMarker738"/>humans, aggressively engages<a id="_idIndexMarker739"/> people in conversation, and asks lots of questions. The robot expresses a lot of enthusiasm and encouragement. “I love my job. Don’t you love your job? It’s so great! I just<a id="_idTextAnchor330"/> love talking to people! Do you want to hear a joke?”</li>
<li><strong class="bold">Chummy and friendly</strong>: The robot is trying to make friends and be helpful. “Hi! Nice to see you! What is your name?”</li>
<li><strong class="bold">Friendly but neutral</strong>: The robot is not quick to share information but does want to talk to you. “Hello, I am Albert. How are you today?”</li>
<li><strong class="bold">Feisty</strong>: The robot is supportive, friendly, and wants interaction. It keeps prompting for more information. It will repeat questions if necessary. “Hi! Nice to meet you. What is your name? How old are you?”</li>
<li><strong class="bold">Somber and staid</strong>: The robot is stuffy and authoritative. Think of having a conversation with a British butler. The robot uses formal English. (This is apparently the default non-personality of many digital assistants.) “Greetings. How may I help you? May I ask you your name?”</li>
<li><strong class="bold">Very neutral or robotic</strong>: The robot expresses no opinions and gives no information about itself. It expresses no emotions or interjections. “Hello. I am a robot. State a command.”</li>
<li><strong class="bold">Annoyed and grumpy</strong>: The robot is not very happy about having to pick up toys and does not mind saying so clearly and distinctly. This personality is aiming for comedy, not anger. “So, you are back again. I guess this means more toys to pick up.”</li>
</ul>
<p>We can see from this list the sort of gamut of personalities we can choose for simulation. I’m going to choose the <em class="italic">chummy and friendly</em> type of personality since that is what I feel will go over best<a id="_idIndexMarker740"/> with my grandchildren.<a id="_idTextAnchor331"/> You, of course, may<a id="_idIndexMarker741"/> choose any of these you please<a id="_idIndexMarker742"/> or add<a id="_idTextAnchor332"/> some more. Now, let’s see how we can proceed with this.</p>
<h2 id="_idParaDest-157"><a id="_idTextAnchor333"/>Constructing a personality</h2>
<p>In a quick review, what parts<a id="_idIndexMarker743"/> do we have so far for our robot<a id="_idIndexMarker744"/> with an artificial personality?</p>
<ul>
<li>We have simulation tools to model emotions.</li>
<li>We have a state machine with six types of emotions that we can mix together.</li>
<li>We have a backstory or biography of the robot’s personal information.</li>
<li>We have picked a personality to emulate.</li>
<li>We have the concept of a game engine where the robot is trying to score points for collecting<a id="_idIndexMarker745"/> information by engaging in small talk or <strong class="bold">phatic communication</strong>.</li>
<li>The robot will change emotions based on conversations. Emotions will be expressed either by asking the robot how he is feeling or by the body language of the robot’s arm.</li>
</ul>
<p>Now, we need some sort of framework to put all of these pieces together that can roughly carry on a conversation we can adjust and manipulate. For that, we are going to revis<a id="_idTextAnchor334"/>it an old, old<a id="_idIndexMarker746"/> friend. Let’s talk, once again, about <strong class="bold">ELIZA</strong>.</p>
<p>ELIZA is probably the original conversation engine software program. It was invented back in 1964 by Joseph Weizenbaum, professor at MIT, a Jewish German refugee from WWII, and considered one of the fathers of AI. ELIZA was named after Eliza Doolittle, the main character in George Bernard Shaw’s book <em class="italic">Pygmalion</em>. In Greek mythology, Pygmalion was a sculptor who fell in love with one of his statues. He prayed to Aphrodite, who granted his wish for the statue to come to life. This is very apt for what we are doing – bringing our robot to simulated life via this weird chain of events, titles, and Greek mythology.</p>
<p>ELIZA was a simulation of a Rogerian <a id="_idIndexMarker747"/>therapist. What is a Rogerian therapist? According to <em class="italic">Psychology Today</em> (<a href="https://www.psychologytoday.com/us/blog/what-doesnt-kill-us/201210/unconditional-positive-regard">https://www.psychologytoday.com/us/blog/what-doesnt-kill-us/201210/unconditional-positive-regard</a>), Carl Rogers (1902-1987) is the founder of <code>&gt;</code> prompt. By the way, I love cats – this is just an example. Please don’t tell my cat about this example:</p>
<pre class="source-code">
ELIZA: How do you do. Please tell me your problem.
&gt; I hate cats.
You say you hate cats?
&gt; Yes.
You seem to be quite positive.
&gt; I hate cats.
Can you elaborate on that?
&gt; I don't like cats because they smell bad.
Don't you really like cats because they smell bad?
&gt; No. Don't like cats.
Are you saying no just to be negative?
&gt; No.
You are being a bit negative.
&gt; I am
Is it because you are that you came to me?
&gt; No
Why not?
&gt; I am afraid of cats
How long have you been afraid of cats?
&gt; About a year
I'm not sure I understand you fully.
&gt; 1 year
Please go on.
&gt; I have been afraid of cats since the cat jumped on my head.
Your head ?
&gt; yes</pre> <p>So, you can see that ELIZA repeats back phrases to the user, reflecting what the user is talking about. When I said, “I am afraid of cats,” the program replied, “How long have you been afraid of cats?”</p>
<p>ELIZA goes through several steps<a id="_idIndexMarker752"/> in recognizing and responding<a id="_idIndexMarker753"/> to sentences. Most of the program is not hardcoded, and it works from a series of scripts that you can edit and replace to basically reprogram the personality of the program – which is why we are talking about ELIZA right now:</p>
<ol>
<li>The first step is to divide the sentence into words separated by spaces. The program also replaces all capital letters with lowercase.</li>
<li>The program replaces words with several versions with a standard word. For example, the program replaces <em class="italic">cant</em> with <em class="italic">can’t</em> in case<a id="_idIndexMarker754"/> you left out the apostrophe. This is called <strong class="bold">preprocessing</strong>.</li>
<li>The program looks for <strong class="bold">keywords</strong> that it knows about. A simple<a id="_idIndexMarker755"/> keyword is <em class="italic">sorry</em>. Any sentence with <em class="italic">sorry</em> gets a response such as <em class="italic">please don’t apologize</em>. Keywords are collected and prioritized by the order they appear in the script file.</li>
<li>The program looks for <em class="italic">decomposition</em> patterns for that keyword. This collects sentences into common groups. For example, one pattern is: <code>* i was *</code>, which can be read <code>any word phrase</code> – <code>I was - any </code><code>word phrase</code>.</li>
<li>ELIZA picks a <code>* I was *</code> pattern, one response is “Perhaps I already <a id="_idIndexMarker758"/>know you were (2).” The number <em class="italic">(2)</em> in parentheses tells the program to substitute the word phrase that comes after <code>I was</code> in the sentence. If you typed in, “Then I was left at a bus station,” the reply in this pattern could be, “Perhaps I already know you were left at a bus station.” You might also get a more pragmatic, “Oh, really.” It is important to know that ELIZA has no idea about the contents of phrases – it is just manipulating words to create sentences based on patterns.</li>
<li>ELIZA performs <strong class="bold">postprocessing</strong> substitutions of words. For example, it<a id="_idIndexMarker759"/> replaces the word <em class="italic">I</em> with <em class="italic">you</em>. If you type “I went to sleep,” the program replies with, “You say you went to s<a id="_idTextAnchor335"/>leep?”, which is the final reply rule after all the others are exhausted.</li>
</ol>
<p>The data that controls<a id="_idIndexMarker760"/> ELIZA’s personality is called a <strong class="bold">script</strong>. This gives the program all of the rules for forming replies. The script<a id="_idIndexMarker761"/> for the Rogerian therapist is called the <strong class="bold">DOCTOR</strong> script. It contains some greeting words, some final words when the program exits, a list of pre-substitution rules, a list of postprocessing substitution words, a list of synonyms, and a list of keywords with decomposition and reassembly rules.</p>
<p>Here is a sample rule for the <code>I </code><code>am</code> keywords:</p>
<pre class="source-code">
decomp: * i am *
reasmb: Is it because you are (2) that you came to me ?
reasmb: How long have you been (2) ?
reasmb: Do you believe it is normal to be (2) ?
reasmb: Do you enjoy being (2) ?</pre> <p>The program selects a random phrase out of the four provided. If I said, “I am afraid of cats,” then this rule would be triggered, and one of these four phrases would be generated. It might say, “Do you enjoy being afraid of cats?” or “How long have you been afraid of cats?”</p>
<p>Almost all of the dialog created by ELIZA comes from the script file, making ELIZA a form of rule-based expert system, and also gives an open framework for creating new applications of conversational engines.</p>
<p>As all computer programs do, ELIZA’s concepts for generating conversation were extended and amplified into a general<a id="_idIndexMarker762"/> purpose (that is, not just a therapist) software program called <strong class="bold">ALICE</strong>, which is a retronym for <strong class="bold">Artificial Linguist Internet Computer Entity</strong>. The simple script data file used by ELIZA became the <strong class="bold">Artificial Intelligence Markup Language</strong> (<strong class="bold">AIML</strong>). ALICE was extended to be far more useful <a id="_idIndexMarker763"/>than ELIZA ever was and to cover far more subjects and capabilities. However, ALICE retains the same concepts<a id="_idIndexMarker764"/> of pre- and post-substitution, keywords, and response patterns. There is a Mycroft plugin engine that allows Mycroft to use AIML files to design conversations (<a href="https://github.com/forslund/fallback-aiml">https://github.com/forslund/fallback-aiml</a>). This tool makes a great alternative construction kit for your robot personality.</p>
<p>Here, we’ve included an example of what AIML looks like (<a href="http://www.digitalanywhere.com/projects/dany/index.html">http://www.digitalanywhere.com/projects/dany/index.html</a>). You will see blocks with categories of statements, and then a pattern of what that category looks like. The next tag, <code>&lt;template&gt;</code>, describes the response<a id="_idIndexMarker765"/> that the robot will make when this category is triggered. For example, the first category is about playing musical instruments. If you say to the robot “I play guitar,” then the response will be, “Is guitar a game or a musical instrument?” We can create our simple sentence patterns this way:</p>
<pre class="source-code">
&lt;category&gt;
&lt;pattern&gt;I PLAY *&lt;/pattern&gt;
&lt;template&gt;Is &lt;set_it&gt;&lt;person/&gt;&lt;/set_it&gt; a game or a musical instrument?&lt;/template&gt;
&lt;/category&gt;
&lt;category&gt;
&lt;pattern&gt;I PLAY THE *&lt;/pattern&gt;
&lt;template&gt;I wish I played an instrument. My pa<a id="_idTextAnchor336"/>rents could not afford the lessons.
&lt;think&gt;&lt;set_it&gt;&lt;set_does&gt;&lt;settopic&gt;play the
&lt;person/&gt;&lt;/settopic&gt;&lt;/set_does&gt;&lt;/set_it&gt;&lt;/think&gt;&lt;/template&gt;
&lt;/category&gt;
&lt;category&gt;
&lt;pattern&gt;I PRIDE MYSELF *&lt;/pattern&gt;
&lt;template&gt;It seems you have good self esteem.&lt;/template&gt;
&lt;/category&gt;
&lt;category&gt;
&lt;pattern&gt;I QUIT MY JOB *&lt;/pattern&gt;
&lt;template&gt;Where did you work and why did you quit?&lt;/template&gt;
&lt;/category&gt;
&lt;category&gt;
&lt;pattern&gt;I READ *&lt;/pattern&gt;
&lt;template&gt;I don't think I've read that. Can you give me a reference?
&lt;think&gt;&lt;set_it&gt;&lt;set_does&gt;&lt;settopic&gt;read
&lt;person/&gt;&lt;/settopic&gt;&lt;/set_does&gt;&lt;/set_it&gt;&lt;/think&gt;&lt;/template&gt;
&lt;/category&gt;
&lt;category&gt;
&lt;pattern&gt;I READ * BOOKS&lt;/pattern&gt;
&lt;template&gt;Name some books in that genre.
&lt;think&gt;&lt;set_it&gt;&lt;set_does&gt;&lt;settopic&gt;read &lt;person/&gt; books&lt;/settopic&gt;&lt;/set_does&gt;&lt;/set_it&gt;&lt;/think&gt;
&lt;think&gt;&lt;set_pers<a id="_idTextAnchor337"/>onality&gt;critical&lt;/set_personality&gt;&lt;/think&gt;&lt;/template&gt;
&lt;/category&gt;</pre> <p>ALICE is <strong class="bold">open source software</strong> (<strong class="bold">OSS</strong>) released under the <a id="_idIndexMarker766"/>GNU <a id="_idIndexMarker767"/>public<a id="_idIndexMarker768"/> lic<a id="_idTextAnchor338"/>ense.</p>
<p>Now, let’s look at how we can add some context to our robot’s conversations.</p>
<h2 id="_idParaDest-158"><a id="_idTextAnchor339"/>Adding context</h2>
<p>One of the most important shortcomings<a id="_idIndexMarker769"/> of ELIZA is a total lack of memory. ELIZA only<a id="_idIndexMarker770"/> remembers the previous statement. You can’t talk about your father and then say, “He was a good man.” ELIZA will have no idea whom you are talking about. ELIZA has no concept of context beyond the previous sentence.</p>
<p>What is <strong class="bold">context</strong>? In the course of a conversation, we often<a id="_idIndexMarker771"/> shorten nouns into pronouns. We might say, “I like my dog,” and in the next sentence say, “She is well behaved.” Who does <em class="italic">she</em> refer to? We know it is the dog, but how does the c<a id="_idTextAnchor340"/>omputer know? We are going to add some ability to reason from context to our program.</p>
<p>We are going to create a storage<a id="_idIndexMarker772"/> object we will call the <strong class="bold">context memory</strong>. In that object, we will be able to keep up with several parts of our conversation, including the person we are talking to currently, the last subject we talked about, if we had asked any questions we still don’t have the answer to, and the answers to any previous questions, in case we need them again. The computer will assume that a pronoun other than <em class="italic">I</em> will refer to the last subject, whatever that was. If I was talking about a dog, and then said, “She is so cute,” then the robot would assume I meant the dog.</p>
<p>Previously, we discussed playing a game to get information from a person. The robot will be collecting and remembering this information, even after it is turned off, so that the next time that person is talking to the robot, it remembers the information it learned the last time – just as you do with a new friend. If you want to continue to expand this AI chatbot concept, you can use this information to create additional conversations. For example, if the human says they like baseball, the robot could ask what their favorite team is and then look up on the internet when the next baseball game is scheduled.</p>
<p>That is the end of our list of parts we are going to use to build our robot personality. We can now dive in and use our personality construction kit. I’m going to use the bones of the ELIZA Python open source program from Wade Brainerd to build Albert the robot’s personality.</p>
<p>In the interest of time and space, I’m only<a id="_idIndexMarker773"/> going to put the parts here that I added<a id="_idIndexMarker774"/> to the <a id="_idTextAnchor341"/>base program. The entire code will be in the GitHub repository. You can get the original program at<a id="_idTextAnchor342"/> <a href="https://github.com/wadetb/eliza">https://github.com/wadetb/eliza</a> if you want to follow along beyond what’s in this book.</p>
<h2 id="_idParaDest-159"><a id="_idTextAnchor343"/>Under construction</h2>
<p>Let’s review all the parts<a id="_idIndexMarker775"/> we have to put together to make our robot personality:</p>
<ul>
<li>Simulation</li>
<li>Monte Carlo (stochastic, or random-based) modeling</li>
<li>Our robot emotion state machine</li>
<li>Perception of human emotion state machine</li>
<li>Our robot biography (list of internal facts about the robot)</li>
<li>A conversation engine framework <a id="_idTextAnchor344"/>called ELIZA</li>
<li>Context or the ability to remember and return facts and “fill in the blanks”</li>
</ul>
<p>In this and the next few sections, I will be presenting the code that I added to Albert to facilitate his artificial personality. A lot of it will be contained in script files that provide rules and patterns for Albert’s speech. There will also be code functions for his emotion engine, human emotion model, and game engine. Let’s get started:</p>
<ol>
<li>I needed to add some new functions<a id="_idIndexMarker776"/> to the script language used by ELIZA. First, I added the context of our robot, who takes the place of ELIZA, the therapist. First, we have the opening words when we initiate the interactive conversation mode of Albert by saying “Hey, Albert” (or whatever you decided to call it), the wake word for Mycroft, and then just “Hello.”</li>
<li>The robot responds<a id="_idIndexMarker777"/> with the <code>initial</code> phrase, as noted by the tag before the colon. We also have our closing phrase here. You can actually put as many phrases as you like, and the computer will randomly choose one. These rules go into the file I named <code>AlbertPersonality.txt</code>, which started as a copy of the original <code>doctor.txt</code> script file that came with ELIZA:<pre class="source-code">
initial: Hello. My name is Albert the Robot.
initial: Hello. I am Albert the Robot, but you can call me Albert.
initial: Hello. Nice to meet you. Call me Albert.
final: Goodbye. Thank you for talking to me.
final: Goodbye. It was nice to talk to you.
final: Goodbye. I need to get back to my tasks.
quit: bye
quit: goodbye</pre></li> <li>I added some word substitutes in case the user calls the robot by name rather than <em class="italic">you</em>. This just substitutes <em class="italic">you</em> for anything you might call the robot. I also set synonyms for various versions of <a id="_idTextAnchor345"/>the robot’s name, so you can call it <em class="italic">robot</em> or <em class="italic">bot</em>, as well as <em class="italic">Albert</em>, <em class="italic">Bert</em>, or even <em class="italic">Bertie</em>.<p class="list-inset">A rule with <code>pre:</code> in front of it is substituted before any other processing takes place. From the first rule, if the word <em class="italic">robot</em> appears in a sentence, as in “Robot, how old are you?”, the program removes <em class="italic">robot</em> and substitutes <em class="italic">you</em> to make the parsing consistent. We also change all uppercase letters to lowercase, so there are no capital letters in the rules. The <code>synon:</code> rule (synonym) replaces any of the listed words with the first word given:</p><pre class="source-code">
pre: robot you
pre: albert you
…
synon: you robot albert bert bertie bot
synon: belief feel think believe wish</pre></li> <li>The next thing we needed was to create questions that we wanted the robot to ask in order to gain information. The program will automatically <em class="italic">harvest</em> this data in any of the keywords we define to appear in a sentence. Here is the definition for rules about asking questions:<pre class="source-code">
questions:
reasmb: What is your name? &lt;assert name&gt;
reasmb: What can I call you? &lt;assert name&gt;
reasmb: How old are you? &lt;assert old&gt;
reasmb: How are you feeling today &lt;assert feeling&gt;</pre></li> <li>We create a new flag for questions<a id="_idIndexMarker778"/> to add to our script file. Each line represents one question, but we can ask it in different ways or forms. The program will select one version at random and decide which question to ask based on the relative priority we will set on the questions. The <code>assert</code> keyword with the <code>&lt;&gt;</code> symbols around it is another new flag I added to cue the context memory that we have created a context of asking some question, and the next statement is probably an answer:<pre class="source-code">
datum: name
decomp * my name is * decomp I am *
decomp call me *
decomp &lt;name&gt; * # we are in the name context reasmb: Hello (1). Nice to meet you
reasmb: Hi (1).
reasmb: Your name is (1), right?
reasmb: Thank you for telling me your name, (1) store: &lt;name&gt; (1)<a id="_idTextAnchor346"/>
decomp * my name is *
reasmb: Hello (2). Nice to meet you.[welcome][happy] store:&lt;name&gt; (2)</pre></li> <li>I created a new data structure I called <code>datum</code>, the singular of <em class="italic">data</em>. This represents some information we want the robot to ask about. We give the datum a title – <code>name</code> in this case, as we want the robot to ask the name of who it is talking to. The <code>decomp</code> (for decomposition) tags are the patterns of sentences where the user might say their name. <code>*</code> represents any phrase. So, if the human says “Hello. My name is Fred Rodgers,” then the robot will call them Fred Rodgers from then on. If the human says, “Call me Ishmael” for some unknown reason, then the robot will use that. We must reassemble the response phrase with the <code>reasmb</code> rules. <code>(1)</code> refers to the first <code>*</code> phrase that appears. If the user says, “I am John,” then when we use the reassemble rules, <code>(1)</code> will be replaced by <code>John</code>. The robot will pick one of the phrases provided at random, such as: “Your name is John, right?”<p class="list-inset">I added another new tag to allow<a id="_idIndexMarker779"/> the robot to use the context memory area to perform two functions. We can declare a context subject when we ask a question, which we will do in a later section. For example, when we ask the user, “What is your name?”, then we want the robot to know that the next answer will be in the context of that question. It’s perfectly reasonable for the robot to say “Who are you?” and the user to immediately answer “Julia” with no other words in that sentence. How is the program to know what to do with <em class="italic">Julia</em>? The answer is the context flag, noted by being bracketed by <code>&lt;&gt;</code>. We read the <code>decomp &lt;name&gt; *</code> decomposition rule as if you are in the context of asking for a name, and you get a reply with no keywords, so take whatever you get as the answer.</p><p class="list-inset">Emotion tags are noted by a bracket, such as <code>[happy]</code> or <code>[sad]</code>. This will move either the robot’s emotions or the robot’s perception of human emotions, depending on whether it is a statement received from a human or a sentence uttered by the robot. There can be<a id="_idIndexMarker780"/> more than one emotion tag associated with a statement.</p><p class="list-inset">Here are the rules for listening for the answer to the <code>age</code> question:</p><pre class="source-code">
datum: age
decomp &lt;age&gt; * I am * years old decomp &lt;age&gt; * I am % # integer
reasmb: You are (2) years old?
reasmb: (2) years old!
decomp &lt;age&gt; *
reasmb: You are (1) years old?
reasmb: (1) years old!
store: &lt;age&gt; (1)</pre><p class="list-inset">On the final line, <code>store:</code> is the command to tell the computer that this i<a id="_idTextAnchor347"/>s the answer to the question and to store that away in the dictionary with the title provided.</p></li> <li>Next, let’s use an example of an interaction with some emotions tied to it so that we can see how we will use the emotion engine to control what the robot says. This set of rules is enacted when the user says “How are you?” to the robot:<pre class="source-code">
key: feeling
decomp: how are you feeling decomp: how are you
decomp: hows it hanging
decomp: how are you today
reasmb: &lt;happy&gt; I'm doing well. How are you? &lt;assert feeling&gt;
reasmb: &lt;sad&gt; I am feeling sad. How are you? &lt;assert feeling&gt;
reasmb: &lt;curious&gt; I am curious about my surroundings
reasmb: &lt;friend&gt; I am feeling friendly today
reasmb: &lt;welcome&gt; I am in a welcoming mood today, my friend
reasmb: &lt;frust&gt; I am a bit frustrated, to tell you the truth
reasmb: &lt;frust&gt; I am feeling a bit frustrated
reasmb: &lt;strange&gt; I am having relationship problems
reasmb: &lt;distant&gt; None of my friends have come to visit
reasmb: &lt;tired&gt;  My batteries are low.  Maybe I need a rest.</pre></li> <li>We will be putting the robot’s emotions<a id="_idIndexMarker781"/> into the context memory so that the script processing program can have access to it. We treat an emotion – for dialog purposes – as part of the context that we are speaking about, which I think is a reasonable approach to working with emotions. Each emotion has a tag or name in the context memory dictionary. If the predominant emotion in the robot is happy, then the robot sets the <code>happy</code> context in the context memory. Then, the rule base will use the context tag to determine which phrase to use to reply to “How are you feeling?” We can also ask a follow-up question. Look at the rule for <code>&lt;happy&gt;</code>. The robot replies, “I’m doing well. How are you?” and then sets the <code>feeling</code> context to let the engine know that we asked a question about feeling. Finally, the last line relates to the <code>tired</code> emotion. If the robot is feeling tired, then we jump to a separate section for the robot to talk about being tired. We make it a separate routine because we need to call it from several places, which illustrates the utility of this rule-based approach to speech. I don’t want to imagine how many C or C++ source lines of code it would take to create all of these rules for each line of dialog. We continue to modify the scripts using these guidelines until we have completed all our questions<a id="_idIndexMarker782"/> and have patterns for all of the answers.</li>
</ol>
<p>Now, we are going to switch back to Python code<a id="_idTextAnchor348"/><a id="_idTextAnchor349"/><a id="_idTextAnchor350"/> for the rest of this example. Our next section describes how we are going to simulate emotions.</p>
<h1 id="_idParaDest-160"><a id="_idTextAnchor351"/>Developing the robot emotion engine</h1>
<p>Now we are going to put together<a id="_idIndexMarker783"/> the robot’s emotion model. This is the heart of the artificial personality as it computes, updates, and remembers the emotional state of the robot. The robot starts in a generally neutral state and performs updates based on the combination of eight emotional traits: <em class="italic">happy</em>/<em class="italic">sad</em>, <em class="italic">welcoming</em>/<em class="italic">distant</em>, <em class="italic">friendly</em>/ <em class="italic">stranger</em>, <em class="italic">curious</em>/<em class="italic">frustrated</em>, and <em class="italic">fresh</em>/<em class="italic">tired</em>. As events happen in the experience of the robot, it gets cues that cause its emotional state to change. For example, if the user said “That is stupid” to something the robot said, then the robot would add to the <code>sad</code> axis of its emotion.</p>
<p>We compute the overall emotional state using polar coordinates, just like you saw in the diagram we drew earlier in this chapter (<em class="italic">Figure 9</em><em class="italic">.4</em>). The current emotional state is determined by computing the center of mass of the other emotions. If the emotions are more or less balanced, the center of mass of the emotions, as plotted on our polar chart, would be near the center. If the robot is mostly happy and friendly, then the mass moves more over to that side of the graph. We pick the single emotional state that is closest to the center of the mass. This is intended to be the basis of creating a complex emotional character for the robot. The attribute of <em class="italic">fresh</em>/<em class="italic">tired</em> is unique, in that the value for that emotion is based on the elapsed runtime of the robot.</p>
<p>The primary expressions of emotion for the robot will be the position of the robot arm – happier robots carry their arms higher and more forward – and the choice of vocabulary in conversation.</p>
<p>The following block of code creates data entries for the emotion engine in the format required by our conversation engine. We are creating a Python interface to the rule-based format so that we can connect it to the rest of the robot:</p>
<pre class="source-code">
class RobotEmotionEngine():
  def __in _(self):
    self.emostate = [90,0]
    self.emoText = "neutral 50"
    self.emotions = {"happy" : 50, "sad": 50,"welcome" : 50, "distant":50,"friend" : 50,"strange" :50, "curious" : 50,"frustrated":50, "fresh" : 50, "tired",50}
    self.bio = {"name":"Albert Albert", "lastname": "Albert", "age": "6 months","maker": "granddad", "color":"green","food","electricity","author":"Isaac Asimov, of course","school": "I do not go to school but I love to learn","hobby":"picking up toys", "job":"picking up toys"}
    # list of happy emotions and sad emotions self.emotBalance={"happy": "sad", "welcome":"distant","friend": "strange", "curious": "frustrated","fresh": "tired"} self.emotionAxis{"happy":112, "welcome": 22,"friend":67,"curious":157,
    "sad":292,"distant":202,"strange":247,"frustrated",337}
    self.update()
  def change(self,emot, val):
    self.emotions[emot]=val
    balance = 100 - val
    otherEmotion = self.emotBalance[emot] 
    self.emotions[otherEmotion]=balance</pre> <p>Next up is the <code>update</code> function; this function<a id="_idIndexMarker784"/> checks to see if we’ve had a change in our emotional state, and if so, we change our current emotion:</p>
<pre class="source-code">
    def update(self):
        rmin = 100
        rmax = 0
        thetamin =360
        thetamax=0
        for emote in self.emotions:
            theta = self.emotionAxis[emote]
            thetamax = min(theta,thetamax)
            thetamin = max(theta,thetamin)
            r = self.emotions[emote]
            rmin = max(rmin, r)
            rmax = max(rmax,r)
        stateR = (rmax-rmin)/ 2
        stateTheta = (thetamax-thetamin) / 2
        for emo in self.emotionAxis:
            thisAngle = self.emotionAxis[emo]
            if stateTheta &gt; thisAngle
            myEmotion = emo
            break
        
        self.emostate = [stateTheta, stateR]
        if stateR &lt; 55 and stateR &gt; 45: 
            myEmotion = "neutral"
        self.emoText = myEmotion + " "+ str(stateR)
        print "Current Emotional State"  = myEmotion, stateR, stateTheta
        return</pre> <p>The robot also needs a model of the human<a id="_idIndexMarker785"/> it is talking to so that it can make different responses based on how the human is interacting. In the next section, we are going to create a smaller version of the emotion<a id="_idIndexMarker786"/> model we used earlier.</p>
<h2 id="_idParaDest-161"><a id="_idTextAnchor352"/>Creating a human emotion model</h2>
<p>We model four emotions for our human<a id="_idIndexMarker787"/> interactions for the robot<a id="_idIndexMarker788"/> to use in formulating responses: <em class="italic">happy</em>/<em class="italic">sad</em> and <em class="italic">welcoming</em>/<em class="italic">distant</em>. We can put emotion tags into our patterns in the script file with <code>[happy]</code>, <code>[sad]</code>, <code>[welcome]</code>, or <code>[distant]</code> to mark the emotions of responses. For example, if we are not getting answers to our questions, we can mark that response with <code>[distant]</code> to note that our subject is not being cooperative:</p>
<div><div><img alt="Figure 9.6 – Simplified human emotional model showing the axes between happy and sad emotions: robot point of view" src="img/B19846_09_6.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.6 – Simplified human emotional model showing the axes between happy and sad emotions: robot point of view</p>
<p>Our human emotion model makes use of a Python dictionary data structure to hold our model. Let’s take a closer look at this:</p>
<ol>
<li>We have two axes: the <em class="italic">happy</em>/<em class="italic">sad</em> axis and the <em class="italic">welcoming</em>/<em class="italic">distant</em> axis. We move the <em class="italic">happy</em>/<em class="italic">s</em><em class="italic">ad</em> index up or down based on responses. If we think a response expresses happy thoughts (“Do you like school?” “Yes”), the program moves up the emotion index in the <em class="italic">happy</em> direction. We use the intersection of these to set the current emotional index. If the human is near the center, we note this<a id="_idIndexMarker789"/> as neutral, our starting<a id="_idIndexMarker790"/> point:<pre class="source-code">
class HumanEmotionEngine():
  def _init_ (self):
    self.emostate = [90,<a id="_idTextAnchor353"/>0]
    self.emoText = "neutral 50"
    self.emotions = {"happy" : 50, "sad": 50,"welcome" : 50, "distant":50}
    # list of happy emotions and sad emotions
    self.emotBalance={"happy": "sad", "welcome":"distant"}
    self.emotionAxis = {'distant': 315, 'welcome': 135, 'sad': 225,'happy': 45}
    self.update()</pre></li> <li>Let’s look at the <code>change</code> function. If <code>happy</code> goes up, <code>sad</code> goes down, so we balance this automatically when emotions change:<pre class="source-code">
def change(self,emot, val):
    self.emotions[emot]=val balance = 100 – val
    otherEmotion = self.emotBalance[emot] 
    self.emotions[otherEmotion]=balance</pre></li> <li>The <code>update</code> function gets the current emotional balance of the human model:<pre class="source-code">
def update(self):
    stateR = self.emotion["happy"]
    stateS = self.emotion["welcome"]
    self.emostate = [stateR, stateS]</pre></li> <li>If the emotional state<a id="_idIndexMarker791"/> is near the<a id="_idIndexMarker792"/> middle, we call that <code>neutral</code>:<pre class="source-code">
if stateR &lt; 55 and stateR &gt; 45 and stateS &lt; 55 and stateS &gt; 45: 
 myEmotion = "neutral"
happySad = stateR-50 welcomDist = stateS-50
if abs(happySad) &gt; abs(welcomDist):
 myEmotion = "sad"
if happySad &gt; 0:
 myEmotion = "happy"
else:
myEmotion = "distant" if welcomDist&gt; 0:
myEmotion = "welcome"
self.emoText = myEmotion + " "+ str(stateR)
print "Current Human Emotional State" = myEmotion, stateR, stateTheta
retu<a id="_idTextAnchor354"/><a id="_idTextAnchor355"/>rn</pre></li> </ol>
<p>This next section discusses where we are going to store the information we are collecting from humans.</p>
<h2 id="_idParaDest-162"><a id="_idTextAnchor356"/>Creating human information storage</h2>
<p>This data structure stores<a id="_idIndexMarker793"/> the information<a id="_idIndexMarker794"/> we have collected about the human user and lets the robot know what questions have yet to be answered. We use a Python dictionary to hold the data. Let’s make a f<a id="_idTextAnchor357"/>reeform version of a database-like table. I add values to the dictionary as we go to make extension easier. I put a list of miscellaneous questions called <code>stuff</code> to throw some spice into the robot’s information gathering so that the questions don’t seem too monotonous. The robot will ask if you like the color pink, singing, dancing, robots, airplanes, and so on.</p>
<p>We put the list in priority order by copying the dictionary and replacing the data fields with relative point values from 20 to 0. <code>name</code> is first with 20 points, <code>age</code> is second with 18, and so on. As each question is answered, we set this point value to zero. For example, if we get an answer for “What is your favorite food?” as “apple,” we set <code>self.info["food"] = apple</code>, and set <code>self.points["food"] = 0</code>. I also added some extra questions for things that my grandchildren like, with the points set very low so that the conversation is more varied. I ask about princesses, airplanes, dinosaurs, singing, and building things:</p>
<pre class="source-code">
class HumanInformation():
  def __init__(self):
    self.info = {"name":"none"}
    self.info["age"]=0
    self.info["school"]="none"
    self.info["feeling"]="none"
    self.info["food"]="none"
    self.info["book"]="none"
    self.info["subject"]="none"
    self.info["song"]="none"
    self.info["teeth"]="none"
    self.info["jokes"]="none"
    # stuff is random information that we use to get more information and have the human answer questions
    # these are aimed at 3-7 year olds
    self.info["stuff"]="none"
    self.stuff = ["the color pink", "singing", "dancing", "dinosaurs", "race cars", "building things",
    "robots", "airplanes", "space ships", "unicorns", "princesses"] self.points = self.info
    # setup points scoring scheme
    points = 20
    for item in self.points:
      self.points[item]=points
      points -= 2</pre> <p>Now, in the next<a id="_idIndexMarker795"/> section, we’ll create<a id="_idIndexMarker796"/> a memory for our robo<a id="_idTextAnchor358"/><a id="_idTextAnchor359"/>t so that the robot can remember what it has already learned. We need a place to put the answers we receive.</p>
<h2 id="_idParaDest-163"><a id="_idTextAnchor360"/>Context memory</h2>
<p>This block of code constructs<a id="_idIndexMarker797"/> the robot’s context memory. You can think of this as<a id="_idIndexMarker798"/> a pool of information that the robot can remember. We set up the robot’s emotion and the model of human emotion to both be neutral. I created some data structure so that we can refer to multiple human users by pointing <code>self.currentHuman</code> to the <code>HumanInformation</code> data object we created previously.</p>
<p>This is where we have the robot remember what emotional state it is in, along with what the software perceives as the human’s emotional state so that the robot doesn’t suddenly forget the decisions it has already made. In the following code snippet, we define <code>self.emotion</code>, which is the robot’s internal state, and <code>humanEmotion</code> for the person we are interacting with. Then, we <a id="_idTextAnchor361"/>use these structures to create a file we write to disk so the robot’s personality persists if you turn it off. We use the <code>inContext</code> function to retrieve data from the context pool. If no data is available, we return an integer of <code>0</code>:</p>
<pre class="source-code">
class ContextMemory():
    def __init__(self):
        self.currentContext = "None"
        self.currentHuman = None # pointer to the data file for the human we are currentl talking to
        self.humanFile = []
        self.emotion = "happy"
        self.humanEmotion = "happy"
        self.contextDict={}
        self.contextDict['currentHuman'] = self.currentHuman
        self.contextDict['robotEmotion'] = self.emotion
        self.contextDict['humanEmotion'] = self.humanEmotion
        
    def inContext(self, datum):
        if datum in self.contextDict:
            return self.contextDict[datum]
        else:
            return 0
            
    def setHuman(self,human):
        self.currentHuman = human
        self.humanFile.append(human)  # add this person to the database of people we know
        
    def addHuman(self,human):
        self.humanFile.append(human)</pre> <p>In these sections, we created<a id="_idIndexMarker799"/> a place for the robot to store information <a id="_idIndexMarker800"/>about how it currently feels, what emotional state the robot is in, and what it has learned about the human it is talking to. We also have a structure to add new humans to our database for when we meet someone new.</p>
<h1 id="_idParaDest-164"><a id="_idTextAnchor362"/>Summary</h1>
<p>This was a very busy chapter. We created an emotional engine for our robot and created a conversational interface so that it can interact with people. We introduced simulation concepts, as we were creating a simulation of emotion for our robot. We can’t create real, biologically motivated emotions, so we simulated emotions via playing a game. In this game, we tried to get humans to provide information about themselves, which is what we humans call <em class="italic">small talk</em>. We assigned point values for emotions and created an emotional state machine both for the robot’s internal <em class="italic">feelings</em> and a representation of how the robot perceives your emotions via interactions.</p>
<p>In our final chapter, we will talk about your robotics educational <a id="_idTextAnchor363"/>journey, give some guidance on careers in robotics, and talk about the future, which is always a perilous topic.</p>
<h1 id="_idParaDest-165"><a id="_idTextAnchor364"/>Questions</h1>
<ol>
<li>What is your favorite movie robot? How would you describe its personality?</li>
<li>What techniques did the movie-makers use to express that robot’s personality (body language, sounds, and so on)?</li>
<li>What are the two types of chatbots? List some of the strengths and weaknesses of each.</li>
<li>In the diagram of modeling custom distributions (the airport example), the bottom image shows two standard distributions and two uniform distributions. Why don’t the curves go all the way to the top of the graph?</li>
<li>Design your own robot emotions. Pick six contrasting emotions that can express the entire range of your robot’s personality. Why did you pick those?</li>
</ol>
<h1 id="_idParaDest-166"><a id="_idTextAnchor365"/>Further reading</h1>
<ul>
<li><em class="italic">Affective Computing</em> by Rosalind Picard: <a href="https://direct.mit.edu/books/book/4296/Affective-Computing">https://direct.mit.edu/books/book/4296/Affective-Computing</a>. This book is a foundational text in the field of affective computing, which is directly relevant to simulating emotions in AI.</li>
<li><em class="italic">Emotion Modelling for Social Robots</em> by Ana Paiva, Iolanda Leite, and Tiago Ribeiro: <a href="https://people.ict.usc.edu/~gratch/CSCI534/Readings/ACII-Handbook-Robots.pdf">https://people.ict.usc.edu/~gratch/CSCI534/Readings/ACII-Handbook-Robots.pdf</a>. This book includes research papers and studies focused on implementing emotional responses in robots.</li>
<li><em class="italic">Designing Sociable Robots</em> by Cynthia Breazeal: <a href="https://direct.mit.edu/books/book/2309/Designing-Sociable-Robots">https://direct.mit.edu/books/book/2309/Designing-Sociable-Robots</a>. A key resource for understanding the integration of emotional and social dynamics in robots.</li>
</ul>
</div>
</body></html>