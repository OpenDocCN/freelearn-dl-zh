["```py\n from langchain.prompts.chat import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate\n```", "```py\n def augment_query_generated(user_query):\n     system_message_prompt = SystemMessagePromptTemplate.from_template(\n           \"You are a helpful expert environmental research assistant. Provide an example answer to the given question, that might be found in a document like an annual environmental report.\" )\n     human_message_prompt = HumanMessagePromptTemplate.from_template(\"{query}\")\n    chat_prompt = ChatPromptTemplate.from_messages([\n        system_message_prompt, human_message_prompt])\n    response = chat_prompt.format_prompt(\n        query=user_query).to_messages()\n    result = llm(response)\n    content = result.content\n    return content\n```", "```py\n original_query = \"What are Google's environmental initiatives?\" hypothetical_answer = augment_query_generated(\n    original_query)\njoint_query = f\"{original_query} {hypothetical_answer}\"\nprint(joint_query)\n```", "```py\n What are Google's environmental initiatives? In 2022, Google continued to advance its environmental initiatives, focusing on sustainability and reducing its carbon footprint. Key initiatives included:\n1\\. **Carbon Neutrality and Renewable Energy**: Google has maintained its carbon-neutral status since 2007 and aims to operate on 24/7 carbon-free energy by 2030\\. In 2022, Google procured over 7 gigawatts of renewable energy, making significant strides towards this goal. 2\\. **Data Center Efficiency**: Google's data centers are among the most energy-efficient in the world. In 2022, the company achieved an average power usage effectiveness (PUE) of 1.10, significantly lower than the industry average. This was accomplished through advanced cooling technologies and AI-driven energy management systems. 3\\. **Sustainable Products and Services**…[TRUNCATED]\n```", "```py\n result_alt = rag_chain_with_source.invoke(joint_query)\nretrieved_docs_alt = result_alt['context']\nprint(f\"Original Question: {joint_query}\\n\")\nprint(f\"Relevance Score:\n    {result_alt['answer']['relevance_score']}\\n\")\nprint(f\"Final Answer:\\n{\n    result_alt['answer']['final_answer']}\\n\\n\")\nprint(\"Retrieved Documents:\")\nfor i, doc in enumerate(retrieved_docs_alt, start=1):\n     print(f\"Document {i}: Document ID:\n        {doc.metadata['id']} source:\n        {doc.metadata['search_source']}\")\n     print(f\"Content:\\n{doc.page_content}\\n\")\n```", "```py\n from IPython.display import Markdown, display\nmarkdown_text_alt = result_alt['answer']['final_answer']\ndisplay(Markdown(markdown_text_alt))\n```", "```py\n Google has implemented a comprehensive set of environmental initiatives aimed at sustainability and reducing its carbon footprint. Here are the key initiatives: <st c=\"12705\">1\\.</st> <st c=\"12708\">Carbon Neutrality and Renewable Energy</st>: Google has been carbon-neutral since 2007 and aims to operate on 24/7 carbon-free energy by 2030\\. In 2022, Google procured over 7 gigawatts of renewable energy. <st c=\"12910\">2\\.</st> <st c=\"12913\">Data Center Efficiency</st>: Google's data centers are among the most energy-efficient globally, achieving an average power usage effectiveness (PUE) of 1.10 in 2022\\. This was achieved through advanced cooling technologies and AI-driven energy management systems. <st c=\"13173\">…[TRUNCATED FOR BREVITY]</st>\n<st c=\"13197\">3\\.</st> <st c=\"13201\">Supplier Engagement</st>: Google works with its suppliers to build an energy-efficient, low-carbon, circular supply chain, focusing on improving environmental performance and integrating sustainability principles. <st c=\"13411\">4\\.</st> <st c=\"13414\">Technological Innovations</st>: Google is investing in breakthrough technologies, such as next-generation geothermal power and battery-based backup power systems, to optimize the carbon footprint of its operations. These initiatives reflect Google's commitment to sustainability and its role in addressing global environmental challenges. The company continues to innovate and collaborate to create a more sustainable future. ---- END OF OUTPUT ----\n```", "```py\n from langchain.load import dumps, loads\n```", "```py\n prompt_decompose = PromptTemplate.from_template(\n     \"\"\"You are an AI language model assistant. Your task is to generate five different versions of\n     the\n     given user query to retrieve relevant documents from a\n     vector search. By generating multiple perspectives on\n     the user question, your goal is to help the user\n     overcome some of the limitations of the distance-based\n     similarity search. Provide these alternative\n     questions\n     separated by newlines. Original question: {question}\"\"\"\n)\n```", "```py\n decompose_queries_chain = (\n     prompt_decompose\n     | llm\n     | str_output_parser\n     | (lambda x: x.split(\"\\n\"))\n)\n```", "```py\n decomposed_queries = decompose_queries_chain.invoke(\n    {\"question\": user_query})\nprint(\"Five different versions of the user query:\")\nprint(f\"Original: {user_query}\")\nfor i, question in enumerate(decomposed_queries, start=1):\n     print(f\"{question.strip()}\")\n```", "```py\n Five different versions of the user query:\nOriginal: What are Google's environmental initiatives? What steps is Google taking to address environmental concerns? How is Google contributing to environmental sustainability? Can you list the environmental programs and projects Google is involved in? What actions has Google implemented to reduce its environmental impact? What are the key environmental strategies and goals of Google?\n```", "```py\n def format_retrieved_docs(documents: list[list]):\n    flattened_docs = [dumps(doc) for sublist in documents\n        for doc in sublist]\n    print(f\"FLATTENED DOCS: {len(flattened_docs)}\")\n    deduped_docs = list(set(flattened_docs))\n    print(f\"DEDUPED DOCS: {len(deduped_docs)}\")\n    return [loads(doc) for doc in deduped_docs]\n```", "```py\n FLATTENED DOCS: 100\nDEDUPED DOCS: 67\n```", "```py\n retrieval_chain = (\n     decompose_queries_chain\n     | ensemble_retriever.map()\n     | format_retrieved_docs\n)\n```", "```py\n docs = retrieval_chain.invoke({\"question\":user_query})\n```", "```py\n rag_chain_with_source = RunnableParallel(\n    {\"context\": retrieval_chain,\n     \"question\": RunnablePassthrough()}\n).assign(answer=rag_chain_from_docs)\n```", "```py\n Google has implemented a wide range of environmental initiatives aimed at improving sustainability and reducing its environmental impact. Here are some key initiatives based on the provided context. Here is the beginning of the current results, truncated to just the first couple of bullets: <st c=\"24426\">1\\.</st> <st c=\"24429\">Campus and Habitat Restoration</st>:\nGoogle has created and restored more than 40 acres of habitat on its campuses and surrounding urban landscapes, primarily in the Bay Area. This includes planting roughly 4,000 native trees and restoring ecosystems like oak woodlands, willow groves, and wetland habitats. <st c=\"24733\">2\\.</st> <st c=\"24736\">Carbon-Free Energy</st>:\nGoogle is working towards achieving net-zero emissions and 24/7 carbon-free energy (CFE) by 2030\\. This involves clean energy procurement, technology innovation, and policy advocacy. They have also launched a policy roadmap for 24/7 CFE and are advocating for strong public policies to decarbonize electricity grids worldwide. <st c=\"25083\">3\\.</st> <st c=\"25086\">Water Stewardship</st>…[TRUNCATED FOR BREVITY]\n```", "```py\n %pip install \"unstructured[pdf]\"\n%pip install pillow\n%pip install pydantic\n%pip install lxml\n%pip install matplotlib\n%pip install tiktoken\n!sudo apt-get -y install poppler-utils\n!sudo apt-get -y install tesseract-ocr\n```", "```py\n from langchain.retrievers.multi_vector import MultiVectorRetriever\nfrom langchain_community.document_loaders import UnstructuredPDFLoader\nfrom langchain_core.runnables import RunnableLambda\nfrom langchain.storage import InMemoryStore\nfrom langchain_core.messages import HumanMessage\nimport base64\nimport uuid\nfrom IPython.display import HTML, display\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n```", "```py\n     llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n    ```", "```py\n     short_pdf_path = \"google-2023-environmental-report-short.pdf\"\n    ```", "```py\n     embedding_function = OpenAIEmbeddings()\n    ```", "```py\n pdfloader = UnstructuredPDFLoader(\n     short_pdf_path,\n     mode=\"elements\",\n     strategy=\"hi_res\",\n     extract_image_block_types=[\"Image\",\"Table\"],\n     extract_image_block_to_payload=True,\n     # converts images to base64 format\n)\npdf_data = pdfloader.load()\n```", "```py\n texts = [doc for doc in pdf_data if doc.metadata\n    [\"category\"] == NarrativeText\"]\nimages = [doc for doc in pdf_data if doc.metadata[\n    \"category\"] == \"Image\"]\nprint(f\"TOTAL DOCS USED BEFORE REDUCTION: texts:\n    {len(texts)} images: {len(images)}\")\ncategories = set(doc.metadata[\n    \"category\"] for doc in pdf_data)\nprint(f\"CATEGORIES REPRESENTED: {categories}\")\n```", "```py\n TOTAL DOCS USED BEFORE REDUCTION: texts: 78 images: 17\nCATEGORIES REPRESENTED: {'ListItem', 'Title', 'Footer', 'Image', 'Table', 'NarrativeText', 'FigureCaption', 'Header', 'UncategorizedText'}\n```", "```py\n if len(images) > 3:\n     images = images[:3]\nprint(f\"total documents after reduction: texts:\n    {len(texts)} images: {len(images)}\")\n```", "```py\n total documents after reduction: texts: 78 images: 3\n```", "```py\n def apply_prompt(img_base64):\n    # Prompt\n    prompt = \"\"\"You are an assistant tasked with summarizing images for retrieval. \\\n     These summaries will be embedded and used to retrieve the raw image. \\\n     Give a concise summary of the image that is well optimized for retrieval.\"\"\"\n     return [HumanMessage(content=[\n           {\"type\": \"text\", \"text\": prompt},\n           {\"type\": \"image_url\",\"image_url\": {\"url\":\n                 f\"data:image/jpeg;base64,{img_base64}\"},},\n     ])]\n```", "```py\n text_summaries = [doc.page_content for doc in texts]\n# Store base64 encoded images, image summaries\nimg_base64_list = []\nimage_summaries = []\nfor img_doc in images:\n     base64_image = img_doc.metadata[\"image_base64\"]\n     img_base64_list.append(base64_image)\n     message = llm.invoke(apply_prompt(base64_image))\n     image_summaries.append(message.content)\n```", "```py\n vectorstore = Chroma(\n     collection_name=\"mm_rag_google_environmental\",\n     embedding_function=embedding_function\n)\n```", "```py\n store = InMemoryStore()\nid_key = \"doc_id\"\nretriever_multi_vector = MultiVectorRetriever(\n     vectorstore=vectorstore,\n     docstore=store,\n     id_key=id_key,\n)\n```", "```py\n def add_documents(retriever, doc_summaries, doc_contents):\n     doc_ids = [str(uuid.uuid4()) for _ in doc_contents]\n     summary_docs = [\n           Document(page_content=s, metadata={id_key:\n               doc_ids[i]})\n           for i, s in enumerate(doc_summaries)\n     ]\n     content_docs = [\n           Document(page_content=doc.page_content,\n           metadata={id_key: doc_ids[i]})\n           for i, doc in enumerate(doc_contents)\n     ]\n     retriever.vectorstore.add_documents(summary_docs)\n     retriever.docstore.mset(list(zip(doc_ids,\n         doc_contents)))\n```", "```py\n if text_summaries:\n    add_documents(\n         retriever_multi_vector, text_summaries, texts)\nif image_summaries:\n     add_documents(\n        retriever_multi_vector, image_summaries, images)\n```", "```py\n def split_image_text_types(docs):\n    b64_images = []\n    texts = []\n    for doc in docs:\n        if isinstance(doc, Document):\n            if doc.metadata.get(\"category\") == \"Image\":\n                base64_image = doc.metadata[\"image_base64\"]\n                b64_images.append(base64_image)\n            else:\n                     texts.append(doc.page_content)\n        else:\n                if isinstance(doc, str):\n                    texts.append(doc)\n     return {\"images\": b64_images, \"texts\": texts}\n```", "```py\n def img_prompt_func(data_dict):\n    formatted_texts = \"\\n\".join(\n        data_dict[\"context\"][\"texts\"])\n    messages = []\n    if data_dict[\"context\"][\"images\"]:\n        for image in data_dict[\"context\"][\"images\"]:\n            image_message = {\"type\": \"image_url\",\n                \"image_url\": {\"url\": f\"data:image/jpeg;\n                     base64,{image}\"}}\n                messages.append(image_message)\n     text_message = {\n           \"type\": \"text\",\n           \"text\": (\n                 f\"\"\"You are are a helpful assistant tasked with describing what is in an image. The user will ask for a picture of something. Provide text that supports what was asked for. Use this information to provide an in-depth description of the aesthetics of the image. Be clear and concise and don't offer any additional commentary. User-provided question: {data_dict['question']}\nText and / or images: {formatted_texts}\"\"\"\n           ),\n     }\n     messages.append(text_message)\n     return [HumanMessage(content=messages)]\n```", "```py\n chain_multimodal_rag = ({\"context\": retriever_multi_vector\n    | RunnableLambda(split_image_text_types),\n    \"question\": RunnablePassthrough()}\n    | RunnableLambda(img_prompt_func)\n    | llm\n    | str_output_parser\n)\n```", "```py\n user_query = \"Picture of multiple wind turbines in the ocean.\" chain_multimodal_rag.invoke(user_query)\n```", "```py\n 'The image shows a vast array of wind turbines situated in the ocean, extending towards the horizon. The turbines are evenly spaced and stand tall above the water, with their large blades capturing the wind to generate clean energy. The ocean is calm and blue, providing a serene backdrop to the white turbines. The sky above is clear with a few scattered clouds, adding to the tranquil and expansive feel of the scene. The overall aesthetic is one of modernity and sustainability, highlighting the use of renewable energy sources in a natural setting.'\n```", "```py\n def plt_img_base64(img_base64):\n    image_html = f'<img src=\"data:image/jpeg;base64,\n        {img_base64}\" />'\n    display(HTML(image_html))\nplt_img_base64(img_base64_list[1])\n```", "```py\n image_summaries[1]\n```", "```py\n 'Offshore wind farm with multiple wind turbines in the ocean, text \"What\\'s inside\" on the left side.'\n```"]