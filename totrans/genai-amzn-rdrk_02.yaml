- en: '2'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '2'
- en: Accessing and Utilizing Models in Amazon Bedrock
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 访问和利用 Amazon Bedrock 中的模型
- en: This chapter provides a practical guide to accessing Amazon Bedrock and uncovering
    its generative AI capabilities. We will start with an overview of the different
    interfaces for invoking Bedrock models, including the console playground, **command-line
    interface** (**CLI**), and **software development kit** (**SDK**). Then, we will
    unveil some of the core Bedrock APIs, along with the code snippets that you can
    run in your environment. Finally, we’ll demonstrate how to leverage Bedrock within
    the LangChain Python framework to build customized pipelines that chain multiple
    models and provide insight into PartyRock, a powerful playground for Amazon Bedrock.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章提供了一本实用的指南，用于访问 Amazon Bedrock 并揭示其生成式 AI 功能。我们将从介绍调用 Bedrock 模型的不同接口开始，包括控制台游乐场、**命令行界面**（**CLI**）和**软件开发工具包**（**SDK**）。然后，我们将揭示一些核心的
    Bedrock API，以及您可以在您的环境中运行的代码片段。最后，我们将展示如何在 LangChain Python 框架中利用 Bedrock 来构建定制化的管道，这些管道将连接多个模型，并深入了解
    PartyRock，这是 Amazon Bedrock 的一个强大游乐场。
- en: By the end of this chapter, you will be able to run and execute applications
    by leveraging SOTA FMs available from Amazon Bedrock as you gain a deeper understanding
    of each of the FMs available and how to utilize them for your needs. You will
    also be able to accelerate your creative thinking regarding building new generative
    AI applications as we dive into building cool apps with PartyRock and learn how
    to integrate Amazon Bedrock into different use cases.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章结束时，您将能够通过利用 Amazon Bedrock 提供的 SOTA FM 来运行和执行应用程序，随着您对每个可用的 FM 的深入了解以及如何利用它们来满足您的需求，您还将能够加速您在构建新的生成式
    AI 应用程序方面的创造性思维。随着我们深入构建 PartyRock 中的酷炫应用程序，并学习如何将 Amazon Bedrock 集成到不同的用例中，您将能够做到这一点。
- en: 'The following key topics will be covered in this chapter:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下关键主题：
- en: Accessing Amazon Bedrock
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 访问 Amazon Bedrock
- en: Using Amazon Bedrock APIs
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Amazon Bedrock API
- en: Amazon Bedrock integration points
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Amazon Bedrock 集成点
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: For this chapter, you’ll need to have access to an **Amazon Web Services** (**AWS**)
    account. If you don’t have one already, you can go to [https://aws.amazon.com/getting-started/](https://aws.amazon.com/getting-started/)
    and create one.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本章，您需要访问一个 **Amazon Web Services**（**AWS**）账户。如果您还没有，您可以去 [https://aws.amazon.com/getting-started/](https://aws.amazon.com/getting-started/)
    创建一个。
- en: Once you’ve done this, you’ll need to install and configure the AWS CLI ([https://aws.amazon.com/cli/](https://aws.amazon.com/cli/))
    as you’ll need this to access Amazon Bedrock FMs from your local machine. Since
    the majority of the code blocks that we will execute are based on Python, setting
    up an AWS Python SDK (Boto3) ([https://docs.aws.amazon.com/bedrock/latest/APIReference/welcome.html](https://docs.aws.amazon.com/bedrock/latest/APIReference/welcome.html))
    would be beneficial. You can set up Python by installing it on your local machine,
    or using AWS Cloud9, or utilizing AWS Lambda, or leveraging Amazon SageMaker.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 完成此操作后，您需要安装和配置 AWS CLI ([https://aws.amazon.com/cli/](https://aws.amazon.com/cli/))，因为您需要它从您的本地机器访问
    Amazon Bedrock FM。由于我们将执行的多数代码块都是基于 Python 的，因此设置 AWS Python SDK（Boto3）([https://docs.aws.amazon.com/bedrock/latest/APIReference/welcome.html](https://docs.aws.amazon.com/bedrock/latest/APIReference/welcome.html))
    将是有益的。您可以通过在本地机器上安装 Python、使用 AWS Cloud9、利用 AWS Lambda 或利用 Amazon SageMaker 来设置
    Python。
- en: Note
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: There will be a charge associated with invocating and customizing the FMs of
    Amazon Bedrock. Please refer to [https://aws.amazon.com/bedrock/pricing/](https://aws.amazon.com/bedrock/pricing/)
    to learn more.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 调用和定制 Amazon Bedrock 的 FM 将产生相关费用。请参阅 [https://aws.amazon.com/bedrock/pricing/](https://aws.amazon.com/bedrock/pricing/)
    了解更多信息。
- en: Accessing Amazon Bedrock
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 访问 Amazon Bedrock
- en: When building a generative AI application, you’re faced with a dizzying array
    of choices. Which FM should you use? How will you ensure security and privacy?
    Do you have the infrastructure to support large-scale deployment? Enter Amazon
    Bedrock.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 当构建生成式 AI 应用程序时，您将面临令人眼花缭乱的选项。您应该使用哪个 FM？您将如何确保安全和隐私？您是否有支持大规模部署的基础设施？这就是 Amazon
    Bedrock 的作用。
- en: As you know by now, Amazon Bedrock provides access to a selection of SOTA FMs
    from leading AI companies in the space, including AI21 Labs, Anthropic, Cohere,
    Meta, Stability AI, Amazon, and Mistral. With a single API, you can tap into cutting-edge
    generative AI across modalities such as text, embeddings, and images. You have
    the flexibility to mix and match models to find the perfect fit for your needs.
    Bedrock handles provisioning, scalability, and governance behind the scenes. Hence,
    you can choose the best model suited to your needs and simply invoke the Bedrock
    serverless API to plug those models into your application.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所知，Amazon Bedrock 提供了访问来自该领域领先 AI 公司的 SOTA FM 的选择，包括 AI21 Labs、Anthropic、Cohere、Meta、Stability
    AI、Amazon 和 Mistral。通过单个 API，您可以访问跨文本、嵌入和图像等模态的尖端生成式 AI。您可以根据需要混合匹配模型以找到最佳匹配。Bedrock
    在幕后处理供应、可扩展性和治理。因此，您可以选择最适合您需求的最佳模型，并简单地调用 Bedrock 无服务器 API 将这些模型插入到您的应用程序中。
- en: So, let’s jump onto the AWS console and see Amazon Bedrock in action.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们跳转到 AWS 控制台，看看 Amazon Bedrock 的实际应用。
- en: 'When you open Amazon Bedrock in the AWS console by navigating to https://console.aws.amazon.com/
    and choosing Bedrock from the search bar, you can explore different FMs, as well
    as a few learning tools, as depicted in *Figure 2**.1*:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 当您通过访问 https://console.aws.amazon.com/ 并在搜索栏中选择 Bedrock 来在 AWS 控制台中打开 Amazon
    Bedrock 时，您可以探索不同的 FM，以及一些学习工具，如图 *图 2.1* 所示：
- en: '![Figure 2.1 – Amazon Bedrock – Overview](img/B22045_02_01.jpg)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.1 – Amazon Bedrock – 概览](img/B22045_02_01.jpg)'
- en: Figure 2.1 – Amazon Bedrock – Overview
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.1 – Amazon Bedrock – 概览
- en: Amazon Bedrock provides users with the flexibility to experiment with various
    models through its playground interface. Users can access the Bedrock playground
    from the AWS console by navigating to the Amazon Bedrock landing page and clicking
    **Examples** to open the playground environment.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Bedrock 通过其沙盒界面为用户提供实验各种模型的灵活性。用户可以通过访问 Amazon Bedrock 登录页面并点击 **示例**
    来打开沙盒环境，从 AWS 控制台中访问 Bedrock 沙盒。
- en: Note
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: At the time of writing this book, users will have to initially enable access
    to the models by navigating to the **Model access** link in the left panel within
    the Bedrock console (as shown in *Figure 2**.2*). Once you’ve landed on the **Model
    access** page view, you can click on **Manage model access**, select the list
    of base models you want to leverage for your use cases, and click **Save changes**.
    Instantly, the users will be given access to those models. Users can also review
    the EULA agreement next to the respective base models to view their terms of service.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写此书时，用户将需要首先通过导航到 Bedrock 控制台左侧面板中的 **模型访问** 链接来启用对模型的访问（如图 *图 2.2* 所示）。一旦您到达
    **模型访问** 页面视图，您可以通过点击 **管理模型访问**，选择您想要用于用例的基本模型列表，然后点击 **保存更改**。用户将立即获得对这些模型的访问权限。用户还可以查看相邻基本模型的
    EULA 协议，以查看其服务条款。
- en: 'Within the playground, you can explore the different examples of generative
    AI models available in Bedrock. This allows you to test out and interact with
    the models without needing to configure resources or write any code. Overall,
    the playground provides a convenient way for users to try out the capabilities
    of Bedrock’s generative models. *Figure 2**.2* depicts some of the capabilities
    available within the Amazon Bedrock console:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在沙盒中，您可以探索 Bedrock 中可用的不同生成式 AI 模型示例。这允许您在不配置资源或编写任何代码的情况下测试和交互这些模型。总的来说，沙盒为用户提供了一种方便的方式来尝试
    Bedrock 生成模型的特性。*图 2.2* 描述了 Amazon Bedrock 控制台中的一些可用功能：
- en: '![Figure 2.2 – Amazon Bedrock’s capabilities](img/B22045_02_02.jpg)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.2 – Amazon Bedrock 的功能](img/B22045_02_02.jpg)'
- en: Figure 2.2 – Amazon Bedrock’s capabilities
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.2 – Amazon Bedrock 的功能
- en: Within the playground, you are given the option to start exploring examples
    based on **Text**, **Chat**, and **Image**. This enables hands-on experimentation
    with the latest generative AI models in a convenient sandbox environment. The
    breadth of options, from conversational chatbots to text and image generation,
    gives you the flexibility to test diverse AI functions firsthand. By providing
    accessible entry points, emerging generative AI becomes more tangible and approachable
    for users to understand. Now, let’s learn about each of these in greater detail.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在游乐场内，您可以选择基于**文本**、**聊天**和**图像**的示例进行探索。这使您能够在方便的沙盒环境中亲手实验最新的生成式 AI 模型。从对话聊天机器人到文本和图像生成，选项的广泛性让您能够亲身体验各种
    AI 功能。通过提供易于访问的入口点，新兴的生成式 AI 对用户来说变得更加具体和易于理解。现在，让我们更详细地了解每个部分。
- en: Chat playground
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Chat 游乐场
- en: Amazon Bedrock gives you access to chat models, which you can experiment with
    in the **Chat playground**.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Bedrock 为您提供了访问聊天模型的方式，您可以在**Chat 游乐场**中进行实验。
- en: The **Chat playground** is an experimental interface that allows you to test
    the conversational AI models available through Amazon Bedrock. You can enter sample
    prompts and view the responses that are generated by a selected model. Usage metrics
    are also displayed to evaluate the model’s performance. A compare mode is available
    to contrast the outputs of up to three different models side by side.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**Chat 游乐场**是一个实验性界面，允许您测试通过 Amazon Bedrock 可用的对话式 AI 模型。您可以输入示例提示并查看由所选模型生成的响应。还会显示使用指标以评估模型的表现。还有一个比较模式，可以并排对比最多三个不同模型的输出。'
- en: 'As shown in the following figures, users can select which model they want to
    use (*Figure 2**.3*):'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 如以下图所示，用户可以选择他们想要使用的模型（*图 2.3*）：
- en: '![Figure 2.3 – Selecting a model](img/B22045_02_03.jpg)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.3 – 选择模型](img/B22045_02_03.jpg)'
- en: Figure 2.3 – Selecting a model
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.3 – 选择模型
- en: 'Thereafter, users can enter a query in the chat box (*Figure 2**.4*):'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 此后，用户可以在聊天框中输入查询（*图 2.4*）：
- en: '![Figure 2.4 – Querying the chat model in the Chat playground](img/B22045_02_04.jpg)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.4 – 在 Chat 游乐场中查询聊天模型](img/B22045_02_04.jpg)'
- en: Figure 2.4 – Querying the chat model in the Chat playground
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.4 – 在 Chat 游乐场中查询聊天模型
- en: Running a query fetches information from the chosen model. This allows you to
    evaluate factors such as accuracy, response length, latency, and suitability for
    your use case. Selecting the optimal model depends on weighing these factors against
    individual needs.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 运行查询会从所选模型中获取信息。这允许您评估准确性、响应长度、延迟以及适用性等因素。选择最佳模型取决于权衡这些因素与个人需求。
- en: While invoking the FMs, you will see the option to modify the **inference parameters**
    so that you can influence the model’s response in a certain way. While some inference
    parameters are common among LLMs, image models have a separate set of parameters
    that can be tuned by users.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在调用 FM 时，您将看到修改**推理参数**的选项，这样您就可以以某种方式影响模型的响应。虽然一些推理参数在 LLM 中是通用的，但图像模型有一组用户可以调整的独立参数。
- en: Let’s look at some of these common parameters.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这些常见参数中的一些。
- en: LLM inference parameters
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: LLM 推理参数
- en: '*Temperature*, *Top P*, *Top K*, *Response length*, *Stop sequences*, and *Max
    tokens* are the inference parameters that we will learn about in detail in this
    section. *Figure 2**.5* shows them on the Amazon Bedrock **Chat playground** screen;
    they can be found in the **Configurations** window:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '*温度*、*Top P*、*Top K*、*响应长度*、*停止序列*和*最大标记数*是我们将在本节中详细了解的推理参数。*图 2.5* 显示了它们在
    Amazon Bedrock **Chat 游乐场**屏幕上；它们可以在**配置**窗口中找到：'
- en: '![Figure 2.5 – Common LLM inference parameters](img/B22045_02_05.jpg)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.5 – 常见 LLM 推理参数](img/B22045_02_05.jpg)'
- en: Figure 2.5 – Common LLM inference parameters
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.5 – 常见 LLM 推理参数
- en: 'Let’s take a closer look:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更仔细地看看：
- en: '**Temperature**: This parameter controls the degree of randomness in the output.
    A lower temperature results in more deterministic output, favoring the most likely
    option. On the other hand, a higher temperature promotes randomness, leading to
    a wider range of diverse and creative outputs. For example, in QA tasks, a lower
    temperature ensures more factual and concise responses, whereas if your use case
    revolves around generating creative and diverse output, such as in creative writing
    or advertisement generation, it might be worthwhile to increase the temperature
    value.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**温度**：此参数控制输出中的随机程度。较低的温度会导致更确定性的输出，倾向于最可能的选项。另一方面，较高的温度会促进随机性，导致更广泛和多样化的创意输出。例如，在问答任务中，较低的温度确保了更事实性和简洁的回答，而如果你的用例涉及生成创意和多样化的输出，如创意写作或广告生成，那么增加温度值可能是有益的。'
- en: '**Top K** **and** **Top P**: Sampling techniques such as **Top K** and **Top
    P** can be employed to enhance the coherence and sense of the output. **Top K**
    limits the number of options to a specified number, ensuring a balance between
    randomness and coherence. **Top P**, on the other hand, restricts the predictions
    with combined probabilities below a specified threshold, preventing highly improbable
    options from being selected. These techniques help strike a balance between generating
    coherent text and maintaining a certain level of randomness, making the text generation
    process more natural and engaging for the reader.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Top K** 和 **Top P**：可以使用如 **Top K** 和 **Top P** 这样的采样技术来增强输出的连贯性和意义感。**Top
    K** 限制选项数量为指定数量，确保在随机性和连贯性之间保持平衡。另一方面，**Top P** 限制了预测概率低于指定阈值的预测，防止选择高度不可能的选项。这些技术有助于在生成连贯文本和保持一定程度的随机性之间取得平衡，使文本生成过程对读者来说更加自然和吸引人。'
- en: Using these together balances novelty and fluency. For example, you could set
    **Top K** to 70 and **Top P** to 0.8\. This allows some uncommon but still relevant
    words via the **Top P** setting, while **Top K** retains focus on more common
    words. The result is text that is fairly fluent with occasional novel words mixed
    in. You can experiment with different values for **Top K** and **Top P** to achieve
    the novelty versus fluency balance you want for a particular generative AI application.
    Start with a **Top K** value around 50 to 100 and a **Top P** value around 0.7
    to 0.9 as reasonable initial settings. The optimal values depend on factors such
    as model size, dataset, and use case.
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用这些参数可以平衡新颖性和流畅性。例如，可以将 **Top K** 设置为 70，**Top P** 设置为 0.8。这允许通过 **Top P**
    设置使用一些不常见但仍然相关的单词，而 **Top K** 则保持对更常见单词的关注。结果是文本相当流畅，偶尔会混入一些新颖的单词。您可以通过对 **Top
    K** 和 **Top P** 使用不同的值来实验，以实现特定生成 AI 应用所需的创新性与流畅性之间的平衡。可以从大约 50 到 100 的 **Top
    K** 值和大约 0.7 到 0.9 的 **Top P** 值作为合理的初始设置开始。最佳值取决于模型大小、数据集和用例等因素。
- en: '`bedrock`, the model will stop generating output as soon as it encounters the
    word *bedrock* in the generated text.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bedrock`，模型将在生成的文本中遇到单词 *bedrock* 时立即停止生成输出。'
- en: '`Write a sentence in` `100 words`.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`用 100 个单词写一句话`。'
- en: Image model inference parameters
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 图像模型推理参数
- en: 'When performing image generation with FMs, several key parameters affect the
    inference process. For instance, in the case of Stable Diffusion models, the model
    takes in a text prompt and random noise vector to produce an image. Several configuration
    settings for the model can influence the final generated image, as depicted in
    *Figure 2**.6*:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用 FM 进行图像生成时，几个关键参数会影响推理过程。例如，在稳定扩散模型的情况下，模型接收一个文本提示和一个随机噪声向量来生成图像。模型的几个配置设置可以影响最终生成的图像，如图
    *图 2.6* 所示。6*：
- en: '![Figure 2.6 – Image model inference parameters](img/B22045_02_06.jpg)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.6 – 图像模型推理参数](img/B22045_02_06.jpg)'
- en: Figure 2.6 – Image model inference parameters
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.6 – 图像模型推理参数
- en: 'Let’s take a closer look at these parameters:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更仔细地看看这些参数：
- en: '**Prompt strength**: This controls the degree of randomness. Lowering the **Prompt
    strength** value generates a more random image while increasing it generates a
    more accurate representation of the prompt.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提示强度**：这控制了随机程度。降低 **提示强度** 值会生成更随机的图像，而增加它则会生成更准确提示的表示。'
- en: '**Generation step**: Similar to **Prompt strength**, increasing the **Generation
    step** value generates a more intricate and detailed image while decreasing it
    generates a simpler image.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生成步骤**：与 **提示强度** 类似，增加 **生成步骤** 值会生成更复杂和详细的图像，而减少它则会生成更简单的图像。'
- en: '**Seed**: The **Seed** parameter controls the initial state of the random number
    generator, which affects the overall randomness of the generated image. It is
    important to note that the precise values of these parameters can vary depending
    on the specific use case and the desired trade-off between image fidelity and
    randomness.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**种子**：**种子**参数控制随机数生成器的初始状态，这会影响生成图像的整体随机性。需要注意的是，这些参数的精确值可能因具体用例和图像保真度与随机性之间的期望权衡而异。'
- en: 'For a more detailed description of these parameters, take a look at the Stable
    Diffusion documentation: [https://platform.stability.ai/docs/api-reference#tag/Image-to-Image](https://platform.stability.ai/docs/api-reference#tag/Image-to-Image).'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 要详细了解这些参数，请查看 Stable Diffusion 文档：[https://platform.stability.ai/docs/api-reference#tag/Image-to-Image](https://platform.stability.ai/docs/api-reference#tag/Image-to-Image)。
- en: If you’re using Amazon Titan Image Generator, there are various parameters you
    can use. You can find a full list at [https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-titan-image.html](https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-titan-image.html).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在使用 Amazon Titan Image Generator，你可以使用各种参数。你可以找到完整的列表在 [https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-titan-image.html](https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-titan-image.html)。
- en: Text playground
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 文本游乐场
- en: The **Text playground** serves a similar function for evaluating generative
    text models from Amazon Bedrock. You may enter text prompts that the selected
    model will then expand upon or continue as a longer passage of generated text
    reflecting that prompt. The expanded text from the model is shown in the playground’s
    interface.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '**文本游乐场**为评估 Amazon Bedrock 中的生成文本模型提供了类似的功能。你可以输入文本提示，所选模型将在此基础上扩展或继续作为更长的生成文本段落，反映该提示。模型扩展的文本显示在游乐场的界面上。'
- en: However, the **Text playground** doesn’t manage conversational context. Essentially,
    it generates a sequence of most likely tokens from the end of the text placed
    in the **Text playground** window. The behavior demonstrated in the **Text playground**
    is a fundamental building block of the chat behavior, and when chained together
    over multiple turns, it can create a chat experience.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，**文本游乐场**不管理对话上下文。本质上，它从放置在**文本游乐场**窗口中的文本末尾生成一系列最可能的标记。在**文本游乐场**中展示的行为是聊天行为的基本构建块，当在多个回合中串联起来时，它可以创建聊天体验。
- en: 'Hence, similar to the **Chat playground**, users can also navigate to the text
    playground, select another model (for instance, Anthropic Claude 3 Sonnet, as
    shown in *Figure 2**.7*), update the inference configuration, and prompt the model
    to generate a response for their use case:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，类似于**Chat 游乐场**，用户也可以导航到文本游乐场，选择另一个模型（例如，如*图 2.7*所示，Anthropic Claude 3 Sonnet），更新推理配置，并提示模型为他们的用例生成响应：
- en: '![Figure 2.7 – Adding a prompt in the text playground](img/B22045_02_07.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.7 – 在文本游乐场中添加提示](img/B22045_02_07.jpg)'
- en: Figure 2.7 – Adding a prompt in the text playground
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.7 – 在文本游乐场中添加提示
- en: Image playground
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图像游乐场
- en: 'In **Image playground**, you can try out two different image models: Amazon
    Titan Image Generator and Stability AI’s Stable Diffusion. If these sound new
    to you, please refer to their eponymous sub-sections in [*Chapter 1*](B22045_01.xhtml#_idTextAnchor014).
    These models generate images through text or images and also perform in-painting,
    image editing, and more. Let''s see an example:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在**图像游乐场**中，你可以尝试两种不同的图像模型：Amazon Titan Image Generator 和 Stability AI 的 Stable
    Diffusion。如果你对这些听起来很陌生，请参阅[*第 1 章*](B22045_01.xhtml#_idTextAnchor014)中同名的子章节。这些模型通过文本或图像生成图像，并执行修复、图像编辑等操作。让我们看看一个例子：
- en: '![Figure 2.8 – Adding a prompt in the image playground](img/B22045_02_08.jpg)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.8 – 在图像游乐场中添加提示](img/B22045_02_08.jpg)'
- en: Figure 2.8 – Adding a prompt in the image playground
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.8 – 在图像游乐场中添加提示
- en: As shown in *Figure 2**.8*, when we provide `High quality, intricate detailed,
    hyper-realistic cat photography, volumetric lighting, full character, 4k, in spacesuit`
    as a prompt, the model generates an image conditioned on the text that was provided.
    Within the configuration, you also have the option to provide a **Negative prompt**
    value, which tells the model what it shouldn’t generate. In addition, you can
    provide a **Reference image** value, which the model will use as a reference to
    generate the image. In [*Chapter 9*](B22045_09.xhtml#_idTextAnchor171), we will
    explore how image generation and editing work with Amazon Bedrock.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如**图 2**.8 所示，当我们提供“**高质量、复杂细致、超现实主义猫摄影、体积光照、全角色、4k、宇航服**”作为提示时，模型会根据提供的文本生成图像。在配置中，您还可以选择提供**否定提示**值，告诉模型它不应该生成的内容。此外，您还可以提供**参考图像**值，模型将使用该图像作为生成图像的参考。在[*第
    9 章*](B22045_09.xhtml#_idTextAnchor171)中，我们将探讨如何使用 Amazon Bedrock 进行图像生成和编辑。
- en: API-based approach
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于API的方法
- en: One of the major benefits of using a unified API for inference is that it allows
    you to easily experiment with different models from various providers using the
    same interface. Even as new model versions are released, you can swap them in
    with minimal code changes required on your end.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 使用统一的推理 API 的一大好处是，它允许您通过相同的界面轻松地尝试来自不同提供商的不同模型。即使新模型版本发布，您也可以通过最小的代码更改在您的端进行替换。
- en: The single API abstraction acts as an insulation layer, shielding your application
    code from underlying model implementation details. This frees you from vendor
    lock-in and grants flexibility to adopt cutting-edge models as they become available.
    With a consistent API shielding this complexity, you can focus on product innovation
    rather than engineering logistics.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 单一 API 抽象层充当绝缘层，保护您的应用程序代码免受底层模型实现细节的影响。这使您摆脱了供应商锁定，并赋予您采用最新模型的灵活性。有了这种一致的 API
    来屏蔽这种复杂性，您可以专注于产品创新，而不是工程物流。
- en: Amazon Bedrock provides a set of APIs that can be directly accessed and utilized
    via the *AWS CLI* or *AWS SDK*.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Bedrock 提供了一组可以直接访问和利用的 API，通过 *AWS CLI* 或 *AWS SDK*。
- en: AWS CLI
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AWS CLI
- en: 'The `list-foundation-models` API:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '`list-foundation-models` API：'
- en: '[PRE0]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Similarly, to invoke a model (for example, the Mistral 7B Instruct model),
    you can call the `invoke-model` API of `bedrock-runtime`. At the time of writing,
    users have to request model access from the console. Once granted in the system,
    the following code can be used to invoke the respective model:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，要调用模型（例如，Mistral 7B Instruct 模型），您可以调用 `bedrock-runtime` 的 `invoke-model`
    API。在撰写本文时，用户必须从控制台请求模型访问权限。一旦在系统中获得授权，就可以使用以下代码调用相应的模型：
- en: '[PRE1]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'In the `body` parameter of the `invoke-model` API call, you can see it is written
    in a particular format (`"{\"prompt\":\"<s>[INST]text [/INST]\"`). Different models
    may require a different structure of prompt while invoking the model. If you search
    for Amazon Bedrock in the AWS console, you can view the actual API request that’s
    sent to the model. Follow these steps to view the API requests:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `invoke-model` API 调用的 `body` 参数中，我们可以看到它是以特定格式编写的（`"{\"prompt\":\"<s>[INST]text
    [/INST]\"}`）。在调用模型时，不同的模型可能需要不同的提示结构。如果您在 AWS 控制台中搜索 Amazon Bedrock，可以查看发送给模型的实际
    API 请求。按照以下步骤查看 API 请求：
- en: Open Amazon Bedrock in the AWS console by navigating to [https://console.aws.amazon.com/](https://console.aws.amazon.com/)
    and choosing **Bedrock** from the search bar.
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过导航到 [https://console.aws.amazon.com/](https://console.aws.amazon.com/) 并在搜索栏中选择**Bedrock**，在
    AWS 控制台中打开 Amazon Bedrock。
- en: Select **Providers** under **Getting started**.
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**入门**下选择**提供商**。
- en: Choose any provider and model of your choice.
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择您选择的任何提供商和模型。
- en: Scroll down to the **Model** section and expand **API request**.
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 滚动到**模型**部分并展开**API 请求**。
- en: 'In *Figure 2**.9*, you can see the API request in JSON from the *Mistral 7B
    Instruct* model. In the `body` parameter of the API request, we can see the format
    of the prompt needed by the model, along with the inference parameters:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在**图 2**.9 中，您可以看到来自 *Mistral 7B Instruct* 模型的 API 请求的 JSON 格式。在 API 请求的 `body`
    参数中，我们可以看到模型需要的提示格式，以及推理参数：
- en: '![Figure 2.9 – Mistral 7B Instruct API request](img/B22045_02_09.jpg)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.9 – Mistral 7B Instruct API 请求](img/B22045_02_09.jpg)'
- en: Figure 2.9 – Mistral 7B Instruct API request
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.9 – Mistral 7B Instruct API 请求
- en: This enables transparency regarding how the user’s input gets formatted and
    passed to the underlying AI system. Overall, the playground allows users to not
    only test prompts but also inspect the API requests that are made to generate
    the AI responses.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得用户输入的格式化和传递到底层AI系统的过程具有透明度。总的来说，沙盒允许用户不仅测试提示，还可以检查生成AI响应所发出的API请求。
- en: AWS SDK
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AWS SDK
- en: AWS provides SDKs for various programming languages, such as JavaScript, Python,
    Java, and more. These SDKs provide wrapper libraries that make it easy to integrate
    Bedrock API calls into your code. It is often beneficial to use an SDK tailored
    to your programming language of choice. Consulting the SDK documentation for your
    chosen language can provide helpful code samples, usage guidelines, and other
    resources to ensure the integration process goes smoothly ([https://docs.aws.amazon.com/bedrock/latest/APIReference/welcome.html](https://docs.aws.amazon.com/bedrock/latest/APIReference/welcome.html)).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: AWS为JavaScript、Python、Java等多种编程语言提供了SDK。这些SDK提供了包装库，使得将Bedrock API调用集成到您的代码中变得容易。使用针对您选择的编程语言量身定制的SDK通常是有益的。查阅您选择语言的SDK文档可以提供有用的代码示例、使用指南和其他资源，以确保集成过程顺利进行（[https://docs.aws.amazon.com/bedrock/latest/APIReference/welcome.html](https://docs.aws.amazon.com/bedrock/latest/APIReference/welcome.html)）。
- en: You can call these Bedrock APIs through AWS SDKs from your local machines or
    use AWS services such as AWS Lambda, Amazon SageMaker Studio notebooks, AWS Cloud9,
    and others. Using the AWS SDK for Python (Boto3), you can call Bedrock APIs to
    build ML workflows. Let’s look at some of the APIs provided by Amazon Bedrock
    and examples of their usage in the **AWS SDK** for Python (Boto3).
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过AWS SDK从本地机器调用这些Bedrock API，或者使用AWS服务，如AWS Lambda、Amazon SageMaker Studio笔记本、AWS
    Cloud9等。使用Python的AWS SDK（Boto3），您可以调用Bedrock API来构建ML工作流程。让我们看看Amazon Bedrock提供的API及其在Python的AWS
    SDK（Boto3）中的使用示例。
- en: Thus far, we have explored the array of FMs that are offered through Amazon
    Bedrock, experimenting with various prompts and tuning inference configurations
    to produce preferred outputs. We’ve tapped into models directly via the Amazon
    Bedrock playground and examined leveraging the AWS CLI and various SDKs to invoke
    FMs programmatically.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经探索了通过Amazon Bedrock提供的FM系列，通过实验各种提示和调整推理配置来产生期望的输出。我们直接通过Amazon Bedrock沙盒使用模型，并检查了利用AWS
    CLI和各种SDK来程序化调用FM。
- en: Having established this foundation of working knowledge, we’ll pivot to investigating
    Amazon Bedrock’s APIs more deeply. The next section will help us leverage these
    APIs in custom generative AI applications that harness the power of FMs while
    providing developers with more control and customization. We will map out an end-to-end
    workflow – from initializing a client to generating outputs – that will empower
    you to build robust, reliable generative apps powered by industrial-grade FMs.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在建立这个工作知识的基础之后，我们将深入调查Amazon Bedrock的API。下一节将帮助我们利用这些API在自定义生成AI应用中发挥FM的力量，同时为开发者提供更多控制和定制。我们将规划一个端到端的工作流程——从初始化客户端到生成输出——这将使您能够构建由工业级FM驱动的强大、可靠的生成应用。
- en: Using Amazon Bedrock APIs
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Amazon Bedrock API
- en: 'Like other AWS services, Amazon Bedrock provides several APIs. These APIs can
    be placed under the Control Plane API for managing, training, and deploying FMs
    and the Runtime Plane API for making invocations or inference requests to the
    FMs. Some of the common Control Plane Bedrock APIs include **ListFoundationModels**,
    **GetFoundationModels**, and **CreateModelCustomizationJob**. On the other hand,
    the Runtime Plane API has two APIs: **InvokeModel** and **InvokeModelWithResponseStream**.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他AWS服务一样，Amazon Bedrock提供了几个API。这些API可以放置在控制平面API下，用于管理、训练和部署FM，以及在运行平面API下进行调用或推理请求。一些常见的控制平面Bedrock
    API包括**ListFoundationModels**、**GetFoundationModels**和**CreateModelCustomizationJob**。另一方面，运行平面API有两个API：**InvokeModel**和**InvokeModelWithResponseStream**。
- en: In addition, there are separate APIs associated with Agents for Amazon Bedrock,
    something we’ll cover in more detail in [*Chapter 10*](B22045_10.xhtml#_idTextAnchor192).
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还有与Amazon Bedrock的代理相关的单独API，我们将在[*第10章*](B22045_10.xhtml#_idTextAnchor192)中更详细地介绍。
- en: You can find the complete list of API calls supported by Amazon Bedrock, including
    all the data types and actions you can perform, at [https://docs.aws.amazon.com/bedrock/latest/APIReference/](https://docs.aws.amazon.com/bedrock/latest/APIReference/).
    Let’s look at some of the commonly used Bedrock API calls.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在 [https://docs.aws.amazon.com/bedrock/latest/APIReference/](https://docs.aws.amazon.com/bedrock/latest/APIReference/)
    找到 Amazon Bedrock 支持的所有 API 调用完整列表，包括您可以执行的所有数据类型和操作。让我们看看一些常用的 Bedrock API 调用。
- en: ListFoundationModels
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ListFoundationModels
- en: To utilize the generative capabilities of Bedrock, the first step is to discover
    which FMs are available via the service. The **ListFoundationModels** API retrieves
    metadata about the base models, including the unique model ID required to generate
    content using that model.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 要利用 Bedrock 的生成能力，第一步是发现哪些 FM 通过该服务可用。**ListFoundationModels** API 获取有关基础模型的元数据，包括使用该模型生成内容所需的唯一模型
    ID。
- en: 'The following Python code sample demonstrates how to call the ListFoundationModels
    API to enumerate the available base models:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 以下 Python 代码示例演示了如何调用 ListFoundationModels API 来列出可用的基础模型：
- en: '[PRE2]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Let’s consider some of the currently available base models and their respective
    model IDs provided via Amazon Bedrock. You use a model ID as a means to indicate
    the base model when users intend to leverage any of the existing models using
    InvokeModel ([https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_InvokeModel.html](https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_InvokeModel.html))
    or InvokeModelWithResponseStream ([https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_InvokeModelWithResponseStream.html](https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_InvokeModelWithResponseStream.html)).
    With this information, the desired model can be selected and its ID can be used
    to call other Bedrock operations, such as InvokeModel, to generate content tailored
    to your application’s needs.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑一些目前通过 Amazon Bedrock 提供的基础模型及其相应的模型 ID。您使用模型 ID 作为一种方式来指示基础模型，当用户打算使用
    InvokeModel ([https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_InvokeModel.html](https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_InvokeModel.html))
    或 InvokeModelWithResponseStream ([https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_InvokeModelWithResponseStream.html](https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_InvokeModelWithResponseStream.html))
    调用利用任何现有模型时。有了这些信息，就可以选择所需的模型并使用其 ID 调用其他 Bedrock 操作，例如 InvokeModel，以生成满足您应用程序需求的内容。
- en: GetFoundationModel
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GetFoundationModel
- en: 'Utilizing Amazon Bedrock, developers can access SOTA generative AI models through
    the **GetFoundationModel** API call. This operation retrieves comprehensive information
    on a specified base model. For example, to return details on Meta’s Llama 3 70B
    Instruct model in Python, you can run the following code:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 通过 Amazon Bedrock，开发者可以通过 **GetFoundationModel** API 调用来访问最先进的生成式 AI 模型。此操作检索有关指定基础模型的详细信息。例如，要返回
    Meta 的 Llama 3 70B Instruct 模型的详细信息，您可以在 Python 中运行以下代码：
- en: '[PRE3]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: InvokeModel
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: InvokeModel
- en: The **InvokeModel** API simplifies the deployment of ML models. With just a
    few API calls, you can deploy your trained models onto the AWS infrastructure
    securely. This eliminates the need for managing complex deployment processes,
    allowing you to focus on the core of your AI application.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '**InvokeModel** API 简化了机器学习模型的部署。只需几步 API 调用，您就可以安全地将训练好的模型部署到 AWS 基础设施上。这消除了管理复杂部署流程的需求，让您能够专注于
    AI 应用程序的核心。'
- en: You can invoke specified Bedrock models to perform inference using inputs provided
    in the request body. The InvokeModel API allows you to run inference for various
    model types, including text, embedding, and image models. This allows users to
    leverage pretrained models available via Amazon Bedrock to generate predictions
    and insights by passing data into the model and receiving the desired output.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用请求体中提供的输入调用指定的 Bedrock 模型进行推理。InvokeModel API 允许您为各种模型类型运行推理，包括文本、嵌入和图像模型。这使用户能够通过将数据传递到模型并接收所需输出，利用通过
    Amazon Bedrock 提供的预训练模型生成预测和洞察。
- en: Here’s an example of an API request for sending text to Meta’s Llama 3 70 B
    model. Inference parameters depend on the model that you are going to use.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个将文本发送到 Meta 的 Llama 3 70 B 模型的 API 请求示例。推理参数取决于您将要使用的模型。
- en: '[PRE4]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: As shown in the preceding code block, the `InvokeModel` operation allows you
    to perform inference on models. The `modelId` field specifies the desired model
    to utilize. The process of obtaining `modelId` varies based on the model type.
    By leveraging the `InvokeModel` operation and specifying the appropriate `modelId`
    value, users can harness the power of a plethora of generative AI models to draw
    relevant insights.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 如前述代码块所示，`InvokeModel` 操作允许您对模型进行推理。`modelId` 字段指定了要使用的模型。获取 `modelId` 的过程取决于模型类型。通过利用
    `InvokeModel` 操作并指定适当的 `modelId` 值，用户可以利用大量生成式 AI 模型的力量来获取相关的见解。
- en: 'If you are using Anthropic Claude models, you can use the Messages API to create
    conversational interfaces to manage the chat between the user and the model. Here’s
    an example of an API request that could be sent to the Anthropic Claude Sonnet
    3 model:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您正在使用 Anthropic Claude 模型，您可以使用 Messages API 创建会话式界面来管理用户与模型之间的聊天。以下是一个可以向
    Anthropic Claude Sonnet 3 模型发送的 API 请求示例：
- en: '[PRE5]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The API manages the back-and-forth flow of dialogue by accepting a series of
    messages with alternating *user* and *assistant* roles as input. To learn more
    about the Messages API, you can look at the documentation: [https://docs.anthropic.com/claude/reference/messages_post](https://docs.anthropic.com/claude/reference/messages_post).'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: API 通过接受一系列交替包含 *用户* 和 *助手* 角色的消息来管理对话的来回流动。要了解更多关于 Messages API 的信息，您可以查看文档：[https://docs.anthropic.com/claude/reference/messages_post](https://docs.anthropic.com/claude/reference/messages_post)。
- en: 'Amazon Bedrock also allows you to precisely configure the throughput your models
    need to deliver responsive performance for your applications. With **Provisioned
    Throughput**, you can choose the compute capacity your models require to meet
    your workload demands and latency requirements. Hence, in the case of Amazon and
    third-party base models, and with customized models, users can purchase Provisioned
    Throughput before running inferences. This capability ensures that you get the
    guaranteed throughput your models require for optimal cost and performance. More
    details on Provisioned Throughput can be found here: [https://docs.aws.amazon.com/bedrock/latest/userguide/prov-throughput.html](https://docs.aws.amazon.com/bedrock/latest/userguide/prov-throughput.html).'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Bedrock 还允许您精确配置模型所需的吞吐量，以提供对应用程序的响应性能。使用 **Provisioned Throughput**，您可以选择模型所需的计算能力以满足您的工作负载需求和延迟要求。因此，对于
    Amazon 和第三方基础模型，以及定制模型，用户在运行推理之前可以购买 Provisioned Throughput。此功能确保您获得模型所需的保证吞吐量，以实现最佳成本和性能。有关
    Provisioned Throughput 的更多详细信息，请参阅此处：[https://docs.aws.amazon.com/bedrock/latest/userguide/prov-throughput.html](https://docs.aws.amazon.com/bedrock/latest/userguide/prov-throughput.html)。
- en: InvokeModelWithResponseStream
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: InvokeModelWithResponseStream
- en: This streaming inference method that’s available via Amazon Bedrock allows FMs
    to produce long, coherent content on demand. Rather than waiting for generation
    to complete, applications can stream results. This allows you to send responses
    from the model in faster chunks rather than having to wait for a complete response.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 通过 Amazon Bedrock 可用的此流式推理方法允许 FM 生成按需的长篇连贯内容。而不是等待生成完成，应用程序可以流式传输结果。这允许您以更快的块发送来自模型的响应，而不是等待完整的响应。
- en: To run inference with streaming, you can simply invoke the `InvokeModelWithResponseStream`
    operation provided by Amazon Bedrock. This runs inference on the model with the
    given input and returns the generated content progressively in a stream.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 使用流式处理进行推理时，您可以直接调用 Amazon Bedrock 提供的 `InvokeModelWithResponseStream` 操作。这将使用给定的输入在模型上运行推理，并以流的形式逐步返回生成的内容。
- en: Let’s look at how the Claude V2 model can generate a 500-word blog on quantum
    computing.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看 Claude V2 模型如何生成一篇关于量子计算的 500 字博客。
- en: Note
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The following code snippet works when run in a Jupyter Notebook environment.
    Jupyter Notebook provides additional functionality and initialization that allows
    this code to operate correctly. Attempting to run this snippet directly in a terminal
    without the Jupyter environment may result in errors. For the best results, run
    this code in Jupyter Notebook rather than directly in a terminal.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段在 Jupyter Notebook 环境中运行时有效。Jupyter Notebook 提供了额外的功能初始化，使得此代码能够正确运行。如果在没有
    Jupyter 环境的终端中直接运行此片段，可能会导致错误。为了获得最佳结果，请在 Jupyter Notebook 中而不是在终端中直接运行此代码。
- en: '[PRE6]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This will print out the generated blog text continuously as it is produced by
    the model. This stream-based approach allows the output to be displayed live while
    Claude V2 is *writing* the blog content. Hence, streaming inference unlocks new
    real-time and interactive use cases for large generative models.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 这将连续打印出由模型产生的生成的博客文本。这种基于流的处理方法允许在 Claude V2 **编写**博客内容时实时显示输出。因此，流式推理为大型生成式模型解锁了新的实时和交互式用例。
- en: In this section, we explored Amazon Bedrock’s key APIs, all of which allow us
    to build generative AI applications. We reviewed how to list the FMs that are
    available through Amazon Bedrock and detailed how to invoke these models to produce
    customized outputs. Next, we will uncover how Amazon Bedrock integrates with LangChain
    to choreograph and address intricate use cases. By leveraging Bedrock’s API and
    LangChain’s orchestration, developers can assemble sophisticated generative solutions.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们探讨了 Amazon Bedrock 的关键 API，所有这些 API 都允许我们构建生成式 AI 应用程序。我们回顾了如何列出通过 Amazon
    Bedrock 可用的 FM，并详细说明了如何调用这些模型以生成定制输出。接下来，我们将揭示 Amazon Bedrock 如何与 LangChain 集成以编排和解决复杂用例。通过利用
    Bedrock 的 API 和 LangChain 的编排，开发者可以构建复杂的生成式解决方案。
- en: Converse API
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Converse API
- en: The Amazon Bedrock **Converse API** offers a standardized method to interact
    with LLMs available via Amazon Bedrock. It facilitates turn-based communication
    between users and generative AI models and ensures consistent tool definitions
    for models that support functions (referred to as **function calling**).
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Bedrock 的 `Converse API` 提供了一种标准化的方法来与通过 Amazon Bedrock 可用的 LLM 进行交互。它促进了用户和生成式
    AI 模型之间的回合制通信，并确保支持函数（称为 **函数调用**）的模型具有一致的工具定义。
- en: The significance of the `Converse` API lies in its ability to streamline integration.
    Previously, using the `InvokeModel` API required adapting to varying JSON request
    and response structures from different model providers. With the `Converse` API,
    a uniform format for requests and responses is implemented across all LLMs on
    Amazon Bedrock, simplifying development and ensuring consistent interaction protocols.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '`Converse` API 的重要性在于其能够简化集成过程。之前，使用 `InvokeModel` API 需要适应来自不同模型提供者的各种 JSON
    请求和响应结构。通过 `Converse` API，实现了对所有 Amazon Bedrock 上的 LLM 的请求和响应格式的统一，简化了开发并确保了一致的交互协议。'
- en: Let us walk through an example of using `Converse` API for text generation scenario
    by leveraging Anthropic Claude 3 Sonnet model. Please ensure you have the required
    permission for you require permission for `bedrock:InvokeModel` operation in order
    to call `Converse` API.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个使用 `Converse` API 进行文本生成场景的示例来了解其用法，该示例利用了 Anthropic Claude 3 Sonnet
    模型。请确保您有调用 `Converse` API 所需的权限，因为您需要 `bedrock:InvokeModel` 操作的权限。
- en: '[PRE7]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Please note that switching the model ID to another text generation FM available
    on Amazon Bedrock allows it to run using the `Converse` API. The code example
    above, along with other `Converse` API examples, has been added to the GitHub
    repository for readers to experiment with in their own accounts.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，将模型 ID 切换到 Amazon Bedrock 上可用的其他文本生成 FM，允许它使用 `Converse` API 运行。上面的代码示例以及其他
    `Converse` API 示例已添加到 GitHub 仓库中，供读者在自己的账户中进行实验。
- en: The `Converse` API can also process documents and images. For instance, you
    can send an image or document in a message and use `Converse` API to have the
    model describe its contents. For more details on supported models and model features
    with `Converse` API, visit [https://docs.aws.amazon.com/bedrock/latest/userguide/conversation-inference.html#conversation-inference-call](https://docs.aws.amazon.com/bedrock/latest/userguide/conversation-inference.html#conversation-inference-call)
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '`Converse` API 还可以处理文档和图像。例如，您可以在消息中发送图像或文档，并使用 `Converse` API 让模型描述其内容。有关
    `Converse` API 支持的模型和模型功能的更多详细信息，请访问 [https://docs.aws.amazon.com/bedrock/latest/userguide/conversation-inference.html#conversation-inference-call](https://docs.aws.amazon.com/bedrock/latest/userguide/conversation-inference.html#conversation-inference-call)'
- en: Similarly, the **ConverseStream API** makes it easy to send messages to specific
    Amazon Bedrock models and receive responses in a continuous stream. It provides
    a unified interface that works across all foundational models supported by Amazon
    Bedrock for messaging.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，**ConverseStream API** 使得向特定的 Amazon Bedrock 模型发送消息并接收连续流中的响应变得容易。它提供了一个统一的界面，该界面适用于
    Amazon Bedrock 支持的所有基础模型进行消息传递。
- en: To use the `ConverseStream` API, you can invoke it with the `Converse` API.
    Note that you need the `bedrock:InvokeModelWithResponseStream` operation permission
    to use `ConverseStream.`
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用`ConverseStream` API，您可以使用`Converse` API来调用它。请注意，您需要`bedrock:InvokeModelWithResponseStream`操作权限才能使用`ConverseStream`。
- en: '[PRE8]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: When you run the code sample above, it streams the response output. For more
    information on `ConverseStream,` you can refer to the documentation at [https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_ConverseStream.html](https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_ConverseStream.html).
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 当您运行上述代码示例时，它将流式传输响应输出。有关`ConverseStream`的更多信息，请参阅[https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_ConverseStream.html](https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_ConverseStream.html)的文档。
- en: Amazon Bedrock integration points
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Amazon Bedrock集成点
- en: 'When building end-to-end generative AI applications, architects must follow
    best practices for security, performance, cost optimization, and latency reduction,
    as outlined in the AWS Well-Architected Framework pillars. They aid developers
    in weighing different choices and optimizations when creating end-to-end systems
    on AWS. More information on the AWS Well-Architected Framework can be found here:
    [https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html](https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html).'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 当构建端到端生成式AI应用时，架构师必须遵循AWS Well-Architected Framework支柱中概述的安全、性能、成本优化和延迟降低的最佳实践。这些实践帮助开发者权衡在AWS上创建端到端系统时的不同选择和优化。有关AWS
    Well-Architected Framework的更多信息，请参阅[https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html](https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html)。
- en: Many customers looking to build conversational interfaces such as chatbots,
    virtual assistants, or summarization systems integrate Amazon Bedrock’s serverless
    API with other services. Useful integration points include orchestration frameworks
    such as LangChain and AWS Step Functions for invoking Amazon Bedrock models via
    AWS Lambda.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 许多希望构建聊天机器人、虚拟助手或摘要系统等对话界面的客户将Amazon Bedrock的无服务器API与其他服务集成。有用的集成点包括LangChain和AWS
    Step Functions等编排框架，这些框架可以通过AWS Lambda调用Amazon Bedrock模型。
- en: As customers adopt LLMOps approaches to optimize building, scaling, and deploying
    LLMs for enterprise applications, these integration tools and frameworks are becoming
    more widely adopted. The serverless API, orchestration layer, and Lambda functions
    create a robust and scalable pipeline for delivering performant and cost-effective
    generative AI services.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 随着客户采用LLMOps方法来优化企业应用中LLMs的构建、扩展和部署，这些集成工具和框架越来越被广泛采用。无服务器API、编排层和Lambda函数创建了一个强大且可扩展的管道，用于提供性能优异且成本效益高的生成式AI服务。
- en: Amazon Bedrock with LangChain
  id: totrans-139
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Amazon Bedrock与LangChain集成
- en: Now, let’s take our understanding of Amazon Bedrock and generative AI applications
    to the next level by introducing LangChain integration with Amazon Bedrock!
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们通过介绍LangChain与Amazon Bedrock的集成，将我们对Amazon Bedrock和生成式AI应用的理解提升到新的水平！
- en: LangChain is a revolutionary framework that empowers developers to build advanced
    language models and generate human-like text. By chaining together various components,
    you can create sophisticated use cases that were previously unimaginable. For
    example, if you work in the financial services industry, you can create an application
    that can provide insights, a simplified summary, and a Q&A of complex financial
    documents, and by using the LangChain framework, you can abstract the API complexities.
    By bringing Bedrock and LangChain together, developers gain the best of both worlds.
    Need an AI assistant, search engine, or content generator? Spin up a capable model
    with Bedrock, then use LangChain’s templates and pipelines to craft the perfect
    prompt and handle the output. This modular approach allows for immense flexibility,
    adapting as your needs change. By creating a custom prompt template via LangChain,
    you can pass in different input variables on every run. This allows you to generate
    content that’s tailored to your specific use case, whether it’s responding to
    customer feedback or crafting personalized marketing messages.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain是一个革命性的框架，它赋予开发者构建高级语言模型和生成类似人类文本的能力。通过连接各种组件，您可以创建以前难以想象的高级用例。例如，如果您在金融服务行业工作，您可以创建一个应用程序，该应用程序可以提供见解、简化摘要和复杂金融文件的问答，通过使用LangChain框架，您可以抽象API的复杂性。通过将Bedrock和LangChain结合在一起，开发者可以同时获得两者的最佳之处。需要AI助手、搜索引擎或内容生成器？使用Bedrock启动一个强大的模型，然后使用LangChain的模板和管道来制作完美的提示并处理输出。这种模块化方法允许极大的灵活性，根据您的需求变化而适应。通过通过LangChain创建自定义提示模板，您可以在每次运行时传递不同的输入变量。这允许您生成针对特定用例的内容，无论是响应客户反馈还是制作个性化的营销信息。
- en: And it’s easy to get started! LangChain’s Bedrock API component provides a simple
    way to invoke Bedrock APIs from within a LangChain pipeline. Just a few lines
    of code can kick off a request, feeding your input to a beefy model and returning
    the goods. From there, your app has a robust, scalable AI backend ready to go.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 开始使用非常简单！LangChain的Bedrock API组件提供了一个简单的方法，在LangChain管道内调用Bedrock API。只需几行代码就可以启动一个请求，将您的输入传递给强大的模型，并返回结果。从那时起，您的应用程序就拥有了一个强大、可扩展的AI后端，随时可用。
- en: The following piece of code showcases the ease with which you can leverage Amazon
    Bedrock with LangChain.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段展示了您如何轻松利用LangChain与Amazon Bedrock。
- en: Note
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Before running the following code, make sure you have the latest version of
    the LangChain package installed. If not, run the package installation cell provided
    next to install LangChain in your environment. Alternatively, you can download
    the package from [https://pypi.org/project/langchain/](https://pypi.org/project/langchain/)
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行以下代码之前，请确保您已安装LangChain包的最新版本。如果没有，请运行旁边提供的包安装单元格，以在您的环境中安装LangChain。或者，您可以从[https://pypi.org/project/langchain/](https://pypi.org/project/langchain/)下载该包。
- en: '[PRE9]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: As shown in the preceding code snippet, users can invoke a particular model
    using a simple prompt by easily leveraging the LLM for the LangChain Bedrock class
    and passing the respective FM’s arguments for inference.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 如前述代码片段所示，用户可以通过利用LangChain Bedrock类的LLM轻松调用特定模型，并传递相应的FM推理参数来使用简单的提示。
- en: Creating a LangChain custom prompt template
  id: totrans-148
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建LangChain自定义提示模板
- en: 'By creating a template for a prompt, you can pass different input variables
    to it on every run. This is useful when you have to generate content with different
    input variables that you may be fetching from a database:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 通过为提示创建模板，您可以在每次运行时向其传递不同的输入变量。这在您需要生成具有不同输入变量的内容时很有用，这些输入变量可能来自数据库：
- en: '[PRE10]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Now, we can invoke Bedrock using the prompt template to see a curated response:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以使用提示模板调用Bedrock，以查看精心挑选的响应：
- en: '[PRE11]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This integration exemplifies how LangChain’s framework facilitates the creation
    of complex language-based tasks. In this instance, the Bedrock API acts as a bridge
    between the LangChain components and the underlying language model.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 这种集成展示了LangChain框架如何促进复杂基于语言的任务的创建。在这个例子中，Bedrock API充当LangChain组件和底层语言模型之间的桥梁。
- en: Hence, by integrating LangChain and Amazon Bedrock, developers can leverage
    the advanced functionalities of LangChain, such as prompt templates, pipelines,
    and orchestration capabilities with other AI services, to create dynamic and adaptive
    applications.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，通过集成LangChain和Amazon Bedrock，开发者可以利用LangChain的高级功能，如提示模板、管道和与其他AI服务的编排能力，来创建动态和自适应的应用程序。
- en: PartyRock
  id: totrans-155
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PartyRock
- en: Now that we’ve discussed how to access and explore Amazon Bedrock for your applications
    using different techniques, let’s look at another interesting feature. Amazon
    also has a mechanism to quickly build and deploy a fun and intuitive application
    for experimentalists and hobbyists through **PartyRock**, a powerful playground
    for Amazon Bedrock. Within PartyRock, you can create multiple applications and
    experiment with Amazon Bedrock. For example, you can create an optimized party
    plan and budgeting tool for your 5-year-old.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经讨论了如何使用不同的技术访问和探索Amazon Bedrock以用于您的应用程序，让我们看看另一个有趣的功能。Amazon还通过**PartyRock**（Amazon
    Bedrock的强大游乐场）为实验者和爱好者提供了一个快速构建和部署有趣且直观的应用程序的机制。在PartyRock中，您可以创建多个应用程序并实验Amazon
    Bedrock。例如，您可以为您的5岁孩子创建一个优化的派对计划和预算工具。
- en: In *Figure 2**.10*, we have created a sample application that can list different
    Grammy award winners based on the year(s) that users can input in the app. Users
    can simply click on the link provided next and enter a particular year (or years
    in each line) in the left pane. On entering a particular year or a few years,
    the system will generate the Grammy award winners in the right pane. You can check
    out the app at [https://partyrock.aws/u/shikharkwtra/jAJQre8A0/Grammy-Celebrity-Namer](https://partyrock.aws/u/shikharkwtra/jAJQre8A0/Grammy-Celebrity-Namer).
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在**图2.10**中，我们创建了一个示例应用程序，可以根据用户在应用程序中输入的年份列出不同的格莱美获奖者。用户只需简单地点击提供的链接，并在左侧面板中输入特定的年份（或每行中的年份）。输入特定的年份或几个年份后，系统将在右侧面板中生成格莱美获奖者。您可以在[https://partyrock.aws/u/shikharkwtra/jAJQre8A0/Grammy-Celebrity-Namer](https://partyrock.aws/u/shikharkwtra/jAJQre8A0/Grammy-Celebrity-Namer)查看该应用程序。
- en: '![Figure 2.10 – PartyRock example – Grammy Celebrity Namer](img/B22045_02_10.jpg)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![图2.10 – PartyRock示例 – 格莱美名人命名器](img/B22045_02_10.jpg)'
- en: Figure 2.10 – PartyRock example – Grammy Celebrity Namer
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.10 – PartyRock示例 – 格莱美名人命名器
- en: PartyRock provides builders with access to FMs from Amazon Bedrock to learn
    the fundamentals of prompt engineering and generative AI. Users are encouraged
    to build some cool apps with PartyRock and go a step further to understand Amazon
    Bedrock. Simply navigate to [https://partyrock.aws/](https://partyrock.aws/),
    click on **Build your own app**, and get started with your journey to becoming
    a generative AI application developer on PartyRock!
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: PartyRock为构建者提供了访问来自Amazon Bedrock的FMs的权限，以学习提示工程和生成式AI的基础知识。鼓励用户使用PartyRock构建一些酷炫的应用程序，并进一步了解Amazon
    Bedrock。只需简单地导航到[https://partyrock.aws/](https://partyrock.aws/)，点击**Build your
    own app**，就可以开始你的生成式AI应用开发者之旅在PartyRock上！
- en: Summary
  id: totrans-161
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Before moving on to the next chapter, let’s quickly recap what we covered in
    this chapter. First, we looked at how to access Amazon Bedrock through the AWS
    console. Utilizing the Bedrock console, we queried the **Text**, **Chat**, and
    **Image playground** APIs and experimented with various inference parameters to
    analyze their impact on model outputs. In addition to interacting with the models
    through the Bedrock console, we investigated accessing the FMs via the AWS CLI
    and AWS SDK.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在进入下一章之前，让我们快速回顾一下本章所涵盖的内容。首先，我们探讨了如何通过AWS控制台访问Amazon Bedrock。利用Bedrock控制台，我们查询了**文本**、**聊天**和**图像游乐场**API，并实验了各种推理参数以分析它们对模型输出的影响。除了通过Bedrock控制台与模型交互之外，我们还研究了通过AWS
    CLI和AWS SDK访问FMs的方法。
- en: By leveraging the CLI and SDK, we were able to uncover some of the underlying
    Bedrock APIs that can be used to list available FMs, retrieve detailed information
    about them, and invoke them. We concluded this chapter by looking at some integration
    points of Amazon Bedrock, including the popular LangChain framework, and provided
    a brief overview of PartyRock, a powerful playground in Amazon Bedrock for testing
    prompts and building fun applications.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 通过利用CLI和SDK，我们能够揭示一些底层的Bedrock API，这些API可以用来列出可用的FMs，检索它们的详细信息，并调用它们。我们通过查看Amazon
    Bedrock的一些集成点来结束这一章，包括流行的LangChain框架，并对PartyRock进行了简要概述，它是在Amazon Bedrock中测试提示和构建有趣应用程序的强大游乐场。
- en: Now that we have a good conceptual understanding of Amazon Bedrock and the ability
    to access various Bedrock models, in the next chapter, we will explore some effective
    prompt engineering techniques we can implement when we use Amazon Bedrock.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对Amazon Bedrock有了良好的概念理解，并且能够访问各种Bedrock模型，在下一章中，我们将探讨一些在使用Amazon Bedrock时可以实施的有效提示工程技巧。
