["```py\nclass LargeModel(Model):\n    def _make_net(self, x, num_actions):\n        x = self.nonlin(self.conv(x, name='conv1', num_outputs=32, \n                                  kernel_size=8, stride=4, std=1.0))\n        x = self.nonlin(self.conv(x, name='conv2', num_outputs=64, \n                                  kernel_size=4, stride=2, std=1.0))\n        x = self.nonlin(self.conv(x, name='conv3', num_outputs=64, \n                                  kernel_size=3, stride=1, std=1.0))\n        x = self.flattenallbut0(x)\n        x = self.nonlin(self.dense(x, 512, 'fc'))\n\n        return self.dense(x, num_actions, 'out', std=0.1)\n```", "```py\n    idx = seeds[0]\n    theta = noise.get(idx, self.num_params).copy() * self.scale_by\n\n    for mutation in seeds[1:]:\n        idx, power = mutation\n        theta = self.compute_mutation(noise, theta, idx, power)\n    return theta\n```", "```py\n    def compute_mutation(self, noise, parent_theta, idx, mutation_power):\n        return parent_theta + mutation_power * noise.get(idx, \n                                                        self.num_params)\n```", "```py\n    def mutate(self, parent, rs, noise, mutation_power):\n        parent_theta, parent_seeds = parent\n        idx = noise.sample_index(rs, self.num_params)\n        seeds = parent_seeds + ((idx, mutation_power), )\n        theta = self.compute_mutation(noise, parent_theta, idx, \n                                      mutation_power)\n        return theta, seeds\n```", "```py\n    def step(self, action, indices=None, name=None):\n        if indices is None:\n            indices = np.arange(self.batch_size)\n        with tf.variable_scope(name, default_name='AtariStep'):\n            rew, done = gym_tensorflow_module.environment_step(\n                               self.instances, indices, action)\n            return rew, done\n```", "```py\n    def observation(self, indices=None, name=None):\n        if indices is None:\n            indices = np.arange(self.batch_size)\n        with tf.variable_scope(name, default_name='AtariObservation'):\n            with tf.device('/cpu:0'):\n                obs = gym_tensorflow_module.environment_observation(\n                                   self.instances, indices, T=tf.uint8)\n\n            obs = tf.gather(tf.constant(self.color_pallete), \n                                                tf.cast(obs,tf.int32))\n            obs = tf.reduce_max(obs, axis=1)\n            obs = tf.image.resize_bilinear(obs, self.warp_size, \n                                                   align_corners=True)\n            obs.set_shape((None,) + self.warp_size + (1,))\n            return obs\n```", "```py\n    def reset(self, indices=None, max_frames=None, name=None):\n        if indices is None:\n            indices = np.arange(self.batch_size)\n        with tf.variable_scope(name, default_name='AtariReset'):\n            noops = tf.random_uniform(tf.shape(indices), minval=1, \n                                       maxval=31, dtype=tf.int32)\n            if max_frames is None:\n                max_frames = tf.ones_like(indices, dtype=tf.int32) * \\\n                                         (100000 * self.frameskip)\n            import collections\n            if not isinstance(max_frames, collections.Sequence):\n                max_frames = tf.ones_like(indices, dtype=tf.int32) * \\\n                                          max_frames\n            return gym_tensorflow_module.environment_reset(self.instances, \n                             indices, noops=noops, max_frames=max_frames)\n```", "```py\n    self.model = model_constructor()\n    …\n    with tf.variable_scope(None, default_name='model'):\n        with tf.device(‘/cpu:0'):\n            self.env = self.make_env_f(self.batch_size)\n```", "```py\n        self.placeholder_indices = tf.placeholder(tf.int32, \n                                                    shape=(None, ))\n        self.placeholder_max_frames = tf.placeholder(\n                                          tf.int32, shape=(None, ))\n        self.reset_op = self.env.reset(\n                            indices=self.placeholder_indices, \n                            max_frames=self.placeholder_max_frames)\n```", "```py\n        with tf.device(device):\n            self.obs_op = self.env.observation(\n                            indices=self.placeholder_indices)\n            obs = tf.expand_dims(self.obs_op, axis=1)\n            self.action_op = self.model.make_net(obs, \n                            self.env.action_space, \n                            indices=self.placeholder_indices, \n                            batch_size=self.batch_size, \n                            ref_batch=ref_batch)\n```", "```py\n        if self.env.discrete_action:\n            self.action_op = tf.argmax(\n                        self.action_op[:tf.shape(\n                        self.placeholder_indices)[0]], \n                        axis=-1, output_type=tf.int32)\n```", "```py\n        with tf.device(device):\n            self.rew_op, self.done_op = \\\n                       self.env.step(self.action_op, \n                       indices=self.placeholder_indices)\n```", "```py\nrunning = np.zeros((self.batch_size,), dtype=np.bool)\ncumrews = np.zeros((self.batch_size, ), dtype=np.float32)\ncumlen = np.zeros((self.batch_size, ), dtype=np.int32)\n```", "```py\n    while True:\n        # nothing loaded, block\n        if not any(running):\n            idx = self.queue.get()\n            if idx is None:\n               break\n            running[idx] = True\n        while not self.queue.empty():\n           idx = self.queue.get()\n           if idx is None:\n                 break\n           running[idx] = True\n```", "```py\nindices = np.nonzero(running)[0]\nrews, is_done, _ = self.sess.run(\n          [self.rew_op, self.done_op, self.incr_counter], \n          {self.placeholder_indices: indices})\ncumrews[running] += rews\ncumlen[running] += 1\n```", "```py\nif any(is_done):\n    for idx in indices[is_done]:\n        self.sample_callback[idx](self, idx, \n              (self.model.seeds[idx],cumrews[idx], \n                                         cumlen[idx]))\n    cumrews[indices[is_done]] = 0.\n    cumlen[indices[is_done]] = 0.\n    running[indices[is_done]] = False\n```", "```py\n    theta, extras, max_frames=task\n    self.model.load(self.sess, task_id, theta, extras)\n    if max_frames is None:\n        max_frames = self.env.env_default_timestep_cutoff\n```", "```py\n    self.sess.run(self.reset_op, {self.placeholder_indices:[task_id], \n                  self.placeholder_max_frames:[max_frames]})\n    self.sample_callback[task_id] = callback\n    self.queue.put(task_id)\n```", "```py\n    self.workers = [RLEvalutionWorker(make_env_f, *args, \n         ref_batch=ref_batch, \n         **dict(kwargs, device=gpus[i])) for i in range(len(gpus))]\n    self.model = self.workers[0].model\n    self.steps_counter = sum([w.steps_counter for w in self.workers])\n    self.async_hub = AsyncTaskHub()\n    self.hub = WorkerHub(self.workers, self.async_hub.input_queue, \n                            self.async_hub)\n```", "```py\n    tasks = []\n    for t in it:\n        tasks.append(self.eval_async(*t, max_frames=max_frames, \n                                    error_callback=error_callback))\n        if time.time() - tstart > logging_interval:\n            cur_timesteps = self.sess.run(self.steps_counter)\n            tlogger.info('Num timesteps:', cur_timesteps, \n             'per second:', \n             (cur_timesteps-last_timesteps)//(time.time()-tstart),\n             'num episodes finished: {}/{}'.format(\n             sum([1 if t.ready() else 0 for t in tasks]), \n             len(tasks)))\n            tstart = time.time()\n            last_timesteps = cur_timesteps\n```", "```py\n    while not all([t.ready() for t in tasks]):\n        if time.time() - tstart > logging_interval:\n            cur_timesteps = self.sess.run(self.steps_counter)\n            tlogger.info('Num timesteps:', cur_timesteps, 'per second:', (cur_timesteps-last_timesteps)//(time.time()-tstart), 'num episodes:', sum([1 if t.ready() else 0 for t in tasks]))\n            tstart = time.time()\n            last_timesteps = cur_timesteps\n        time.sleep(0.1)\n```", "```py\n    tlogger.info(\n       'Done evaluating {} episodes in {:.2f} seconds'.format(\n                          len(tasks), time.time()-tstart_all))\n    return [t.get() for t in tasks]\n```", "```py\n{\n    \"game\": \"frostbite\",\n    \"model\": \"LargeModel\",\n    \"num_validation_episodes\": 30,\n    \"num_test_episodes\": 200,\n    \"population_size\": 1000,\n    \"episode_cutoff_mode\": 5000,\n    \"timesteps\": 1.5e9,\n    \"validation_threshold\": 10,\n    \"mutation_power\": 0.002,\n    \"selection_threshold\": 20\n}\n```", "```py\n    Model = neuroevolution.models.__dict__[config['model']]\n    all_tstart = time.time()\n    def make_env(b):\n        return gym_tensorflow.make(game=config[\"game\"], \n                                   batch_size=b)\n    worker = ConcurrentWorkers(make_env, Model, batch_size=64)\n```", "```py\n    noise = SharedNoiseTable()\n    rs = np.random.RandomState()\n\n    def make_offspring():\n        if len(cached_parents) == 0:\n            return worker.model.randomize(rs, noise)\n        else:\n            assert len(cached_parents) == config['selection_threshold']\n            parent = cached_parents[\n                    rs.randint(len(cached_parents))]\n            theta, seeds = worker.model.mutate( parent, rs, noise, \n                   mutation_power=state.sample(\n                   state.mutation_power))\n            return theta, seeds\n```", "```py\n    tasks = [make_offspring() for _ in range(\n                              config['population_size'])]\n    for seeds, episode_reward, episode_length in \\\n        worker.monitor_eval(tasks, max_frames=state.tslimit * 4):\n        results.append(Offspring(seeds, \n                       [episode_reward], [episode_length]))\n\n    state.num_frames += sess.run(worker.steps_counter) - \\\n                                frames_computed_so_far\n```", "```py\n    state.population = sorted(results, \n                  key=lambda x:x.fitness, reverse=True)\n    …\n    validation_population = state.\\\n                   population[:config['validation_threshold']]\n    if state.elite is not None:\n        validation_population = [state.elite] + \\\n                                    validation_population[:-1]\n\n    validation_tasks = [\n        (worker.model.compute_weights_from_seeds(noise, \n        validation_population[x].seeds, cache=cached_parents), \n        validation_population[x].seeds) for x in range(\n                             config['validation_threshold'])]\n    _,population_validation, population_validation_len =\\ \n        zip(*worker.monitor_eval_repeated(validation_tasks, \n        max_frames=state.tslimit * 4, \n        num_episodes=config['num_validation_episodes']))\n```", "```py\n    population_elite_idx = np.argmax(population_validation)\n    state.elite = validation_population[population_elite_idx]\n    elite_theta = worker.model.compute_weights_from_seeds(\n              noise, state.elite.seeds, cache=cached_parents)\n    _,population_elite_evals,population_elite_evals_timesteps=\\\n                  worker.monitor_eval_repeated(\n                  [(elite_theta, state.elite.seeds)], \n                  max_frames=None, \n                  num_episodes=config[‘num_test_episodes’])[0]\n```", "```py\n    if config['selection_threshold'] > 0:\n        tlogger.info(\"Caching parents\")\n        new_parents = []\n        if state.elite in \\\n            state.population[:config['selection_threshold']]:\n            new_parents.extend([\n                 (worker.model.compute_weights_from_seeds(\n                  noise, o.seeds, cache=cached_parents), o.seeds) for o in state.population[:config['selection_threshold']]])\n        else:\n            new_parents.append(\n                (worker.model.compute_weights_from_seeds(\n                 noise, state.elite.seeds, cache=cached_parents), \n                 state.elite.seeds))\n            new_parents.extend([\n                (worker.model.compute_weights_from_seeds(\n                 noise, o.seeds, cache=cached_parents), o.seeds) for o in state.population[:config[‘selection_threshold']-1]])\n```", "```py\n$ conda create -n deep_ne python=3.5\n$ conda activate deep_ne\n$ conda install -c anaconda tensorflow-gpu\n$ pip install gym\n$ pip install Pillow\n```", "```py\n$ git clone https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Python.git\n$ cd Hands-on-Neuroevolution-with-Python/Chapter10\n```", "```py\n$ cd cd gym_tensorflow/atari/\n$ git clone https://github.com/yaricom/atari-py.git\n$ cd ./atari-py && make\n```", "```py\n$ cd ../..gym_tensorflow && make\n```", "```py\n$ python ga.py -c configurations/ga_atari_config.json -o out\n```", "```py\n...\n| PopulationEpRewMax                    | 3.47e+03  |\n| PopulationEpRewMean                   | 839       |\n| PopulationEpCount                     | 1e+03     |\n| PopulationTimesteps                   | 9.29e+05  |\n| NumSelectedIndividuals                | 20        |\n| TruncatedPopulationRewMean            | 3.24e+03  |\n| TruncatedPopulationValidationRewMean  | 2.36e+03  |\n| TruncatedPopulationEliteValidationRew | 3.1e+03   |\n| TruncatedPopulationEliteIndex         | 0         |\n...\n| TruncatedPopulationEliteTestRewMean   | 3.06e+03  |\n...\n Current elite: (47236580, (101514609, 0.002), (147577692, 0.002), (67106649, 0.002), (202520553, 0.002), (230555280, 0.002), (38614601, 0.002), (133511446, 0.002), (27624159, 0.002), (233455358, 0.002), (73372122, 0.002), (32459655, 0.002), (181449271, 0.002), (205743718, 0.002), (114244841, 0.002), (129962094, 0.002), (24016384, 0.002), (77767788, 0.002), (90094370, 0.002), (14090622, 0.002), (171607709, 0.002), (147408008, 0.002), (150151615, 0.002), (224734414, 0.002), (138721819, 0.002), (154735910, 0.002), (172264633, 0.002)) \n```", "```py\n$ python display.py\n```", "```py\n$ pip install click\n$ conda install matplotlib\n$ pip install colour\n$ conda install pandas\n```", "```py\n$ git clone https://github.com/uber-research/deep-neuroevolution.git\n$ cd visual_inspector\n```", "```py\n$ python -m main_mujoco 90 99 sample_data/mujoco/final_xy_bc/\n```"]