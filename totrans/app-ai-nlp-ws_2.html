<html><head></head><body>
		<div>
			<div id="_idContainer061" class="Content">
			</div>
		</div>
		<div id="_idContainer062" class="Content">
			<h1 id="_idParaDest-53"><a id="_idTextAnchor053"/>2. Analyzing Documents and Text with Natural Language Processing</h1>
		</div>
		<div id="_idContainer130" class="Content">
			<p class="callout-heading">Overview</p>
			<p class="callout">This chapter describes the use of Amazon Comprehend to summarize text documents and create Lambda functions to analyze the texts. You will learn how to develop services by applying the serverless computing paradigm, and use Amazon Comprehend to examine texts to determine their primary language. You will extract information such as entities (people or places), key phrases (noun phrases that are indicative of the content), emotional sentiments, and topics from a set of documents.</p>
			<p class="callout">By the end of this chapter, you will able to set up a Lambda function to process and analyze imported text using Comprehend and extract structured information from scanned paper documents using Amazon Textract.</p>
			<h1 id="_idParaDest-54"><a id="_idTextAnchor054"/>Introduction</h1>
			<p>Since 2005, when Amazon formally launched its <strong class="bold">Elastic Compute Cloud</strong> (<strong class="bold">EC2</strong>) web service, cloud computing has grown from a developer service to mission-critical infrastructure. The spectrum of applications is broad—most highly scalable consumer platforms such as Netflix are based on AWS, and so are many pharmaceuticals and genomics, as well as organizations such as the BBC and The Weather Channel, BMW, and Canon. As of January 2020, there are about 143 distinct AWS services spanning 25 categories, from compute and storage to quantum technologies, robotics, and machine learning. In this book, we will cover a few of them, as shown in the following diagram:</p>
			<div>
				<div id="_idContainer063" class="IMG---Figure">
					<img src="image/B16061_02_01.jpg" alt="Figure 2.1: Amazon AI services covered&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.1: Amazon AI services covered</p>
			<div>
				<div id="_idContainer064" class="IMG---Figure">
					<img src="image/B16061_02_Inline_image1.jpg" alt="a"/>
				</div>
			</div>
			<p><strong class="bold">S3</strong> is the versatile object store that we use to store the inputs to our AI services as well as the outputs from those services. You have been working with S3 since <em class="italic">Chapter 1</em>, <em class="italic">An Introduction to AWS</em>.</p>
			<div>
				<div id="_idContainer065" class="IMG---Figure">
					<img src="image/B16061_02_Inline_image2.jpg" alt="b"/>
				</div>
			</div>
			<p><strong class="bold">Lambda</strong> is the glue service that makes serverless computing possible. You will use Lambda later in this chapter to analyze text using Comprehend.</p>
			<div>
				<div id="_idContainer066" class="IMG---Figure">
					<img src="image/B16061_02_Inline_image3.jpg" alt="c"/>
				</div>
			</div>
			<p><strong class="bold">API Gateway</strong> is a delivery service that can enable you to create microservices that can be accessed by various clients, such as web, mobile, and server applications, via internet protocols such as HTTP, WebSocket, and REST. API Gateway gives you the ability to expose your microservices in a secure and scalable way. In the age of microservices and the "API-first" approach, the greatest challenge is the creation, publishing, monitoring, and maintenance of API endpoints. Almost all AWS services are APIs and use the API Gateway infrastructure.</p>
			<p>Amazon's machine learning services, the main focus of our book, are a set of 16 services as of January 2020. They are also called AI services, and currently, the terms are interchangeable. Let's take a quick look at the ones we are interested in.</p>
			<div>
				<div id="_idContainer067" class="IMG---Figure">
					<img src="image/B16061_02_Inline_image4.jpg" alt="d"/>
				</div>
			</div>
			<p><strong class="bold">Comprehend</strong>, the topic of this chapter, is a very versatile text analytics service. It performs a variety of tasks—keyphrase extraction, sentiment analysis (positive, negative, neutral, or mixed), syntax analysis, entity recognition, medical <strong class="bold">Named Entity Recognition</strong> (<strong class="bold">NER</strong>), language detection, and topic modeling. You will see this in action later in this chapter.</p>
			<div>
				<div id="_idContainer068" class="IMG---Figure">
					<img src="image/B16061_02_Inline_image5.jpg" alt="e"/>
				</div>
			</div>
			<p><strong class="bold">Lex</strong> is a platform for building conversational AI, bots, or intelligent assistants. Conversational AI capabilities such as <strong class="bold">automatic speech recognition</strong> (<strong class="bold">ASR</strong>) and <strong class="bold">natural language understanding</strong> (<strong class="bold">NLU</strong>) are built into the Lex framework. Lex provides a very intuitive object model consisting of bots, utterances, slots, and sessions, as well as integration with Amazon Lambda, thus enabling you to develop interesting, intelligent bots in a serverless environment. We will see more of Lex in <em class="italic">Chapter 4</em>, <em class="italic">Conversational Artificial Intelligence</em>.</p>
			<div>
				<div id="_idContainer069" class="IMG---Figure">
					<img src="image/B16061_02_Inline_image6.jpg" alt="f"/>
				</div>
			</div>
			<p><strong class="bold">Personalize</strong> is a very useful service that allows you to personalize your bots. For example, incorporating personalized recommendations/content delivery, personalized searching based on previous interactions, or even personalized notifications and marketing based on user behavior! While we will not be using Amazon Personalize in this book, we wanted to bring your attention to services closely related to the ones covered in this book. That way, you can add extremely rich features as you expand the power of your bots and NLP services.</p>
			<div>
				<div id="_idContainer070" class="IMG---Figure">
					<img src="image/B16061_02_Inline_image7.jpg" alt="g"/>
				</div>
			</div>
			<p><strong class="bold">Polly</strong> is a text-to-speech service using <strong class="bold">neural text-to-speech</strong> (<strong class="bold">NTTS</strong>) technologies. It is very flexible and powerful, offering two styles: a newscaster reading style and a normal conversational style. The voice need not be monotone—Amazon Polly supports <strong class="bold">Speech Synthesis Markup Language</strong> (<strong class="bold">SSML</strong>), which enables you to adjust the speaking style, volume, speech rate, pitch, phrasing, emphasis, intonation, and other characteristics.</p>
			<div>
				<div id="_idContainer071" class="IMG---Figure">
					<img src="image/B16061_02_Inline_image8.jpg" alt="h"/>
				</div>
			</div>
			<p><strong class="bold">Textract</strong>, as the name implies, extracts text from documents. It is an <strong class="bold">optical character recognition</strong> (<strong class="bold">OCR</strong>) solution that is suitable for process automation. It can extract key-value pairs or tables from documents such as tax forms, legal documents, medical forms, bank forms, patent registration, and so forth.</p>
			<div>
				<div id="_idContainer072" class="IMG---Figure">
					<img src="image/B16061_02_Inline_image9.jpg" alt="i"/>
				</div>
			</div>
			<p><strong class="bold">Transcribe</strong> is a speech-to-text <strong class="bold">Automatic Speech Recognition</strong> (<strong class="bold">ASR</strong>) service and is very versatile; for example, it can recognize multiple speakers and you can filter out words. It is very useful in medical transcription, for time-stamped subtitle generation, and for transcribing customer interactions. </p>
			<div>
				<div id="_idContainer073" class="IMG---Figure">
					<img src="image/B16061_02_Inline_image10.jpg" alt="j"/>
				</div>
			</div>
			<p><strong class="bold">Translate</strong> is another very useful service that's able to translate more than 50 languages in a scalable, real-time fashion. </p>
			<div>
				<div id="_idContainer074" class="IMG---Figure">
					<img src="image/B16061_02_Inline_image11.jpg" alt="k"/>
				</div>
			</div>
			<p><strong class="bold">Rekognition</strong>, of course, is a visual analysis and image detection service capable of a variety of tasks, such as facial recognition, video analysis, object detection, and recognizing text in images. <em class="italic">Chapter 6</em>, <em class="italic">Computer Vision and Image Processing</em> is dedicated to Amazon Rekognition.</p>
			<div>
				<div id="_idContainer075" class="IMG---Figure">
					<img src="image/B16061_02_Inline_image12.jpg" alt="l"/>
				</div>
			</div>
			<p>Unlike the AI services we have looked at so far in this chapter, <strong class="bold">Amazon Connect</strong> is a very feature-rich contact center application. It consists of an omnichannel cloud contact center with high-quality audio, web/mobile secure chat, and a web-based contact control panel. The Contact Lens for Amazon Connect is a set of Contact center analytics services that adds capabilities such as full-text search and sentiment analysis, with forthcoming features such as theme detection and custom vocabulary. The integration with Amazon Lex for chatbots is an interesting capability where we can leverage the flexibility of Lex to create intelligent and useful bots.</p>
			<div>
				<div id="_idContainer076" class="IMG---Figure">
					<img src="image/B16061_02_Inline_image13.jpg" alt="m"/>
				</div>
			</div>
			<p><strong class="bold">Amazon Alexa</strong>, of course, is a platform for a conversational interface as well as a set of hardware devices such as smart speakers that leverage the Alexa service to become smart assistants. </p>
			<p>The reason for including customer engagement platforms such as Connect and Alexa is to show the wider possibilities of the work we are doing in this book. While we will not be directly showing how to develop bots for an Amazon Connect or Amazon Alexa-based bot <strong class="bold">voice user interface</strong> (<strong class="bold">VUI</strong>), we want to open your mind to the possibility of an omnichannel customer experience across different integration points—web, mobile, smart speakers, and so forth.</p>
			<p>As you can see, the services cover a wide variety of layers, from the storage and infrastructure layer to the AI services layer, and finally extending to the UX.</p>
			<h1 id="_idParaDest-55"><a id="_idTextAnchor055"/>Serverless Computing</h1>
			<p>Serverless computing is a relatively new architecture that takes a different spin on the cloud application architecture. Let's start with a traditional on-premise server-based architecture.</p>
			<p>Usually, a traditional application architecture starts with a set of computer hardware, a host operating system, virtualization, containers, and an application stack consisting of libraries and frameworks tied together by networking and storage. On top of all this, we write business logic. In essence, to maintain a business capability, we have to maintain the server hardware, operating system patches, updates, library updates, and so forth. We also have to worry about scalability, fault tolerance, and security at the least. </p>
			<p>With cloud computing, the application architecture is free of computer hardware as well as having elasticity. We still have to maintain the OS, libraries, patches, and so on. This where serverless computing comes in—in the words of Amazon, serverless computing "shifts more of your operational responsibilities to AWS."</p>
			<p>Serverless computing improves upon cloud computing, eliminating infrastructure management, starting from provisioning to scaling up and down, depending on the load, as well as the patching and maintenance of the whole runtime stack. As Amazon depicts it, serverless computing definitely "reduces cost and increases agility and innovation" as well as enabling automated high availability, if designed properly. </p>
			<p>An O'Reilly report defines serverless computing as "an architectural approach to software solutions that relies on small independent functions running on transient servers in an elastic runtime environment." So, there are servers—serverless is not the right term, but in some sense, the servers are transparent, managed by Amazon during the execution of a Lambda function, which is usually in milliseconds.</p>
			<h2 id="_idParaDest-56"><a id="_idTextAnchor056"/>Amazon Lambda and Function as a Service</h2>
			<p>Essentially, serverless computing is enabled by functions, more precisely, <strong class="bold">Function as a Service</strong> (<strong class="bold">FaaS</strong>). Amazon Lambda is the prime example of an enabling platform for serverless computing.</p>
			<p>You write the business logic as a set of Lambda functions that are event-driven, stateless, fault-tolerant, and autoscaling. A Lambda function has an upstream side and a downstream side—it responds to upstream events; the runtime processor executes the embedded code and the results are sent to downstream destinations. The upstream events could be generated by something put into a queue or something that is dropped into an S3 bucket or a <strong class="bold">Simple Notification Service</strong> (<strong class="bold">SNS</strong>) message. And the downstream can be S3 buckets, queues, DynamoDB, and so forth. The runtime supports multiple languages, such as Python, Go, Java, Ruby, Node.js, and .NET.</p>
			<p>A Lambda function is much more granular than a microservice—you can think of it as a nano service. It is charged on a 100 ms basis and will time out after 15 minutes. The payload size is 6 MB. That gives you an estimate of the size of a Lambda function. Also, as you have noticed, there are no charges when a Lambda function is idling – that means we can scale down to zero. And you can implement data parallelism easily—trigger a Lambda function for each row of data. As one Lambda function can trigger another Lambda function, you can even do task parallelism. Of course, all of this requires careful architecture, but it's worth the effort.</p>
			<p>Amazon's serverless platform covers compute, storage, networking, orchestration, API proxy, analytics, and developer tooling. We will look at some of these components—Lambda for compute, S3 for storage, API Gateway for networking.</p>
			<h2 id="_idParaDest-57"><a id="_idTextAnchor057"/>Serverless Computing as an Approach</h2>
			<p>Industry analysts and technologists consider serverless computing as an approach and a set of principles. Amazon Lambda is not serverless computing but an enabler of the approach. The serverless computing architecture does reduce what you have to build—some of the traditional code that we write now manifests as a function chaining pipeline, the configuration of events, triggers, and attributes of Lambda functions. The essential business logic does need to be written, and that will reside inside the Lambda functions. As a result, there is a very well-defined separation between the platform and the business code, and that is the value of serverless computing.</p>
			<h1 id="_idParaDest-58"><a id="_idTextAnchor058"/>Amazon Comprehend</h1>
			<p>Amazon Comprehend is a text analytics service. It has a broad spectrum of capabilities. Amazon Comprehend can extract key phrases and entities. It can do language detection and topic modeling. It can also perform sentiment analysis as well as syntax analysis. Amazon Comprehend is multilingual. Some of the applications of Amazon Comprehend include:</p>
			<ul>
				<li>Understanding the main themes and topics of various unstructured text items such as support tickets, social media posts, customer feedback, customer complaints, and business documents such as contracts and medical records.</li>
				<li>Knowledge management by categorizing business documents such as internal procedures, white papers, notes and descriptions, media posts, and emails.</li>
				<li>Brand monitoring—effectively responding to social media posts, reviews, and other user-generated content from various channels. Respond faster by prioritizing the content as well as routing the content to the appropriate person or process. To prioritize and respond faster, businesses need to analyze the content for language, topics, and the entities mentioned in the media – all of which are capabilities of Amazon Comprehend.</li>
				<li>One important capability of Comprehend is the fact that underneath the hood, it improves models by monitoring errors and training AI models with new and improved data. </li>
				<li>Also, you can fine-tune models with your domain-specific data, thus increasing the accuracy to fit your application while leveraging the general capability of the AI models.</li>
				<li>One interesting application of Comprehend is to extract information from business documents such as contract numbers, terms of contracts, various codes, and even the dosage of medication</li>
			</ul>
			<p>An interesting end-to-end use case is to use Amazon Comprehend to analyze a collection of text documents and organize the articles by topic, identify the most frequently mentioned features, and group articles by subject matter, to enable personalized recommendations for website visitors.</p>
			<div>
				<div id="_idContainer077" class="IMG---Figure">
					<img src="image/B16061_02_02.jpg" alt="Figure 2.2: Amazon Comprehend search flow&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.2: Amazon Comprehend search flow</p>
			<p><strong class="bold">Amazon Comprehend Medical</strong> is a feature-rich service for analyzing patient health records, doctor's notes, and reports from clinical trials as well as links to medical ontologies. It can even figure out medication dosages, test results, and treatment information that can be used for analysis by healthcare professionals:</p>
			<div>
				<div id="_idContainer078" class="IMG---Figure">
					<img src="image/B16061_02_03.jpg" alt="Figure 2.3: Amazon Comprehend Medical flow&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.3: Amazon Comprehend Medical flow</p>
			<p>The Amazon Comprehend service continually learns from new data from Amazon product descriptions and consumer reviews, and thus, it perpetually improves its ability to understand a variety of topics from government, health, media, education, advertising, and so on.</p>
			<p>In <em class="italic">Chapter 1</em>, <em class="italic">An Introduction to AWS</em>, you learned how to use Amazon Comprehend to extract insights by using <strong class="bold">Natural Language Processing</strong> <strong class="bold">(NLP)</strong> from the contents of documents. In this chapter, we will dig deeper and you will learn how to use the Amazon Comprehend API to produce insights by recognizing the language, entities, key phrases, sentiments, and topics in a document. This will allow you to understand deep learning-based NLP to build more complex applications, which we will cover further.</p>
			<p>In the second part of this chapter, you will learn about AWS Lambda, and how to integrate this service with Amazon Comprehend. You will also integrate a database to provide the foundation to build scalable NLP processing applications.</p>
			<h1 id="_idParaDest-59"><a id="_idTextAnchor059"/>What Is an NLP Service?</h1>
			<p>Amazon Comprehend is an NLP service. The overall goal of an NLP service is to make machines understand our spoken and written language. Virtual assistants, such as Alexa or Siri, use NLP to produce insights from input data. The input data is structured by a language, which has a unique grammar, syntax, and vocabulary. Thus, processing text data requires identifying the language first and applying subsequent rules to identify the document's information. NLP's general task is to capture this information as a numeral representation. This general task is split into specific tasks, such as identifying languages, entities, key phrases, emotional sentiments, and topics.</p>
			<div>
				<div id="_idContainer079" class="IMG---Figure">
					<img src="image/B16061_02_04.jpg" alt="Figure 2.4: Amazon Comprehend data flow &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.4: Amazon Comprehend data flow </p>
			<p>As we discussed earlier, Amazon Comprehend uses pre-trained models to perform document analysis tasks. This is very good because it enables a business to develop capabilities without going through an exhaustive AI model training effort. And Amazon keeps up with the latest developments in ML and AI, constantly retraining the models—so the models get better without any work from users. Also, there are capabilities for fine-tuning the models by training them with your domain-specific content.</p>
			<h1 id="_idParaDest-60"><a id="_idTextAnchor060"/>Using Amazon Comprehend to Inspect Text and Determine the Primary Language</h1>
			<p>Amazon Comprehend is used for searching and examining texts and then gathering insights from a variety of topics (health, media, telecom, education, government, and so on) and languages in the text data format. Thus, the first step to analyze text data and utilize more complex features (such as topic, entity, and sentiment analysis) is to determine the dominant language. Determining the dominant language ensures the accuracy of more in-depth analysis. To examine the text in order to determine the primary language, there are two operations (<strong class="source-inline">DetectDominantLanguage</strong> and <strong class="source-inline">BatchDetectDominantLanguage</strong>).</p>
			<p>Both operations expect the text in the UTF-8 format with a length of at least 20 characters and a maximum of 5,000 bytes. If you are sending a list, it should not contain more than 25 items.</p>
			<p>The response includes what language was identified using a two-letter code. The following table shows the language codes for different languages:</p>
			<p class="callout-heading">Note</p>
			<p class="callout">Check out <a href="https://docs.aws.amazon.com/comprehend/latest/dg/how-languages.html">https://docs.aws.amazon.com/comprehend/latest/dg/how-languages.html</a> for an updated list of the supported languages.</p>
			<div>
				<div id="_idContainer080" class="IMG---Figure">
					<img src="image/B16061_02_05.jpg" alt="Figure 2.5: Amazon Comprehend's supported languages&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.5: Amazon Comprehend's supported languages</p>
			<p>There are three ways to invoke dominant language detection. The result is the code for the dominant language in the content and a confidence score determined by the Comprehend algorithms:</p>
			<ul>
				<li><strong class="source-inline">DetectDominantLanguage</strong> will return the dominant language in a single document.</li>
				<li><strong class="source-inline">BatchDetectDominantLanguage</strong> works on a set of documents and will return a list of the dominant language in each of the documents.</li>
				<li>While both of the preceding APIs work in synchronous mode, that is, you send the content to the API and it will return the results, <strong class="source-inline">StartDominantLanguageDetectionJob</strong> works on a collection of jobs asynchronously. This API is well suited to large jobs that take more time.</li>
			</ul>
			<div>
				<div id="_idContainer081" class="IMG---Figure">
					<img src="image/B16061_02_06.jpg" alt="Figure 2.6: Dominant language score confidence output&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.6: Dominant language score confidence output</p>
			<h2 id="_idParaDest-61"><a id="_idTextAnchor061"/>Exercise 2.01: Detecting the Dominant Language in a Text Document Using the Command-Line Interface</h2>
			<p>In this exercise, you will learn how to detect the dominant language in a text using Comprehend's <strong class="source-inline">DetectDominantLanguage</strong> function. The following steps describe how to detect the dominant language:</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The source code for the Jupyter notebook is available via GitHub in the repository at <a href="https://packt.live/2O4cw0V">https://packt.live/2O4cw0V</a>.</p>
			<p class="callout">The files for this chapter are located in the <strong class="source-inline">Chapter02</strong> folder in the GitHub repository <a href="https://packt.live/31TIzbU">https://packt.live/31TIzbU</a>. As we mentioned in <em class="italic">Chapter 1</em>, <em class="italic">An Introduction to AWS</em>, you should have downloaded the GitHub files into a local subdirectory. </p>
			<p class="callout">As an example, we have downloaded the files in the <strong class="source-inline">Documents/aws-book/The-Applied-AI-and-Natural-Language-Processing-with-AWS</strong> directory.</p>
			<ol>
				<li>Open a new Jupyter Notebook.<p class="callout-heading">Note</p><p class="callout">For configuration instructions, refer the section titled <em class="italic">Pre checkup</em> on GitHub: <a href="https://packt.live/2O4cw0V">https://packt.live/2O4cw0V</a>.</p></li>
				<li>Before we begin, the <strong class="source-inline">boto3</strong> library must be installed. On a fresh Jupyter Notebook cell, type in the following command to install it:<p class="source-code">!pip install boto3  </p></li>
				<li>Now, let's go ahead and import Boto3. Boto3 is nothing but the AWS SDK for Python. (<a href="https://boto3.amazonaws.com/v1/documentation/api/latest/index.html">https://boto3.amazonaws.com/v1/documentation/api/latest/index.html</a>):<p class="source-code">import boto3</p></li>
				<li>Then, import the JSON module to serialize the JSON (<a href="https://docs.python.org/3.6/library/json.html">https://docs.python.org/3.6/library/json.html</a>):<p class="source-code">import json</p></li>
				<li>Instantiate a new Comprehend client:<p class="source-code">comprehend = boto3.client(service_name='comprehend')</p></li>
				<li>Next, we assign English and Spanish strings to be analyzed by Comprehend:<p class="source-code">english_string = 'Machine Learning is fascinating.'</p><p class="source-code">spanish_string = 'El aprendizaje automático es fascinante.'</p></li>
				<li>Next, we print a string to indicate the respective variable that our script is about to execute: <p class="source-code">print('Calling DetectDominantLanguage')</p><p class="source-code">print('english_string result:')</p></li>
				<li>Lastly, call Comprehend's <strong class="source-inline">detect_dominant_language</strong> method with the <strong class="source-inline">english_string</strong> and <strong class="source-inline">spanish_string</strong> variables (<a href="https://docs.aws.amazon.com/comprehend/latest/dg/API_DetectDominantLanguage.html">https://docs.aws.amazon.com/comprehend/latest/dg/API_DetectDominantLanguage.html</a>).<p><strong class="source-inline">json.dumps()</strong> writes the JSON data to a Python string in the terminal:</p><p class="source-code">print('\n English string result:')</p><p class="source-code">print(json.dumps(comprehend.detect_dominant_language\</p><p class="source-code">                (Text = english_string), sort_keys=True, \</p><p class="source-code">                indent=4))</p><p class="source-code">print('\n spanish_string result:')</p><p class="source-code">print(json.dumps(comprehend.detect_dominant_language\</p><p class="source-code">                (Text = spanish_string), sort_keys=True, \</p><p class="source-code">                indent=4))</p><p class="source-code">print('End of DetectDominantLanguage\n')</p><p class="callout-heading">Note </p><p class="callout">The code snippet shown above uses a backslash ( <strong class="source-inline">\</strong> ) to split the logic across multiple lines. When the code is executed, Python will ignore the backslash, and treat the code on the next line as a direct continuation of the current line.</p></li>
				<li>Save the notebook.</li>
				<li>Press <em class="italic">Shift</em> + <em class="italic">Enter</em> to run the two notebook cells. Executing the cells will produce the following output (see the following screenshot):<div id="_idContainer082" class="IMG---Figure"><img src="image/B16061_02_07.jpg" alt="Figure 2.7: Detecting the dominant language output – English and Spanish&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 2.7: Detecting the dominant language output – English and Spanish</p>
			<p>As expected, the <strong class="source-inline">english_text</strong> string is identified as English (with the <strong class="source-inline">en</strong> language code) with a ~0.99 confidence score.</p>
			<p>Also as expected, the <strong class="source-inline">spanish_text</strong> string is identified as Spanish (with the <strong class="source-inline">es</strong> language code) with a ~0.99 confidence score.</p>
			<h2 id="_idParaDest-62"><a id="_idTextAnchor062"/>Exercise 2.02: Detecting the Dominant Language in Multiple Documents by Using the CLI</h2>
			<p>In this exercise, you will learn how to use Comprehend's <strong class="source-inline">DetectDominantLanguage</strong> operation for multiple documents. The following steps describe how to detect the dominant language:</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The <em class="italic">Pre checkup instructions</em> and the source code for this exercise are available via GitHub in the repository at <a href="https://packt.live/2Z8Vbu4">https://packt.live/2Z8Vbu4</a>.</p>
			<ol>
				<li value="1">Open a new Jupyter Notebook. </li>
				<li>On a fresh empty cell, import the AWS SDK for Python (boto3:<a href="https://boto3.amazonaws.com/v1/documentation/api/latest/index.html">https://boto3.amazonaws.com/v1/documentation/api/latest/index.html</a>): <p class="source-code">import boto3</p></li>
				<li>Then, import the JSON module to serialize the JSON (<a href="https://docs.python.org/3.6/library/json.html">https://docs.python.org/3.6/library/json.html</a>):<p class="source-code">import json</p></li>
				<li>Instantiate a new Comprehend client:<p class="source-code">comprehend = boto3.client(service_name='comprehend')</p></li>
				<li>Next, assign a list of English and Spanish strings to be analyzed by Comprehend:<p class="source-code"><strong class="bold">english_string_list</strong> = \</p><p class="source-code">['Machine Learning is fascinating.', \</p><p class="source-code"> 'Studying Artificial Intelligence is my passion.']</p><p class="source-code"><strong class="bold">spanish_string_list</strong> = \</p><p class="source-code">['El aprendizaje automático es fascinante.', \</p><p class="source-code"> 'Estudiar Inteligencia Artificial es mi pasión.']</p></li>
				<li>Lastly, we call Comprehend's <strong class="source-inline">batch_detect_dominant_language</strong> method with the <strong class="source-inline">english_string_list</strong> and <strong class="source-inline">spanish_string_list</strong> variables (<a href="https://docs.aws.amazon.com/comprehend/latest/dg/API_DetectDominantLanguage.html">https://docs.aws.amazon.com/comprehend/latest/dg/API_DetectDominantLanguage.html</a>). Then, <strong class="source-inline">json.dumps()</strong> writes the JSON data to a Python string to the terminal:<p class="source-code">print('Calling BatchDetectDominantLanguage')</p><p class="source-code">print('english_string_list results:')</p><p class="source-code">print(json.dumps(comprehend.batch_detect_dominant_language\</p><p class="source-code">                (TextList=english_string_list), \</p><p class="source-code">                sort_keys=True, indent=4))</p><p class="source-code">print('\nspanish_string_list results:')</p><p class="source-code">print(json.dumps(comprehend.batch_detect_dominant_language\</p><p class="source-code">                (TextList=spanish_string_list), \</p><p class="source-code">                sort_keys=True, indent=4))</p><p class="source-code">print('End of BatchDetectDominantLanguage\n')</p></li>
				<li>Save the notebook.</li>
				<li>Press <em class="italic">Shift</em> + <em class="italic">Enter</em> to run the two notebook cells. Executing the cells will produce the following output (see the following partial screenshot—the output is too long to fit; you can see the full output in the notebook):<div id="_idContainer083" class="IMG---Figure"><img src="image/B16061_02_08.jpg" alt="Figure 2.8: Detecting the dominant language (multiple documents) output—English &#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 2.8: Detecting the dominant language (multiple documents) output—English </p>
			<p>The important concepts to remember are that Comprehend has the ability to detect different languages and can take text input as a single string or in a batch format as a list of strings.</p>
			<p>In this topic, we reviewed how Comprehend's <strong class="source-inline">DetectDominantLanguage</strong> method is structured, and how to pass in both strings and a list of strings. Next, we will extract entities, phrases, and sentiments from a set of documents.</p>
			<h1 id="_idParaDest-63"><a id="_idTextAnchor063"/>Extracting Information from a Set of Documents</h1>
			<p>At a business level, knowing if and why a customer is angry or happy when they contact a virtual assistant is extremely important, to retain the customer. At an NLP level, this requires more information to be extracted and a more complex algorithm. The additional information to extract and quantify is <strong class="source-inline">entities</strong>, <strong class="source-inline">key phrases</strong>, <strong class="source-inline">emotional sentiment</strong>, and <strong class="source-inline">topics</strong>.</p>
			<h2 id="_idParaDest-64"><a id="_idTextAnchor064"/>Detecting Named Entities—AWS SDK for Python (boto3)</h2>
			<p>An entity is a broader concept—it is something that has an identity of its own. An entity can be a person or a place, a company name or an organization; it can also be a number (say quantity, price, number of days) or a date, a title, a policy number, or a medical code. For example, in the text "Martin lives at 27 Broadway St.", <strong class="bold">Martin</strong> might be detected as a <strong class="bold">PERSON</strong>, while <strong class="bold">27 Broadway St</strong> might be detected as a <strong class="bold">LOCATION</strong>.</p>
			<p>Entities also have a score to indicate the confidence level that the entity type was detected correctly. The following table shows a complete list of entity types and descriptions:</p>
			<div>
				<div id="_idContainer084" class="IMG---Figure">
					<img src="image/B16061_02_09.jpg" alt="Figure 2.9: AWS Comprehend entity types and descriptions&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.9: AWS Comprehend entity types and descriptions</p>
			<p>There are three ways to invoke the detection of entities:</p>
			<ul>
				<li><strong class="source-inline">DetectEntities</strong> will return the entities in a single document.</li>
				<li><strong class="source-inline">BatchDetectEntities</strong> works on a set of documents and will return a list of the entities in each of the documents.</li>
				<li>While both the preceding APIs work in synchronous mode, that is, you send the content to the API and it will return the results, <strong class="source-inline">StartEntitiesDetectionJob</strong> works on a collection of jobs asynchronously. This API is well suited to large jobs that take more time.</li>
			</ul>
			<h2 id="_idParaDest-65"><a id="_idTextAnchor065"/>DetectEntities – Input and Output</h2>
			<p><strong class="source-inline">DetectEntities</strong> takes a <strong class="source-inline">LanguageCode</strong> and a string of text as an input and then provides the following information about each entity within the input text: <strong class="source-inline">BeginOffset</strong>, <strong class="source-inline">EndOffset</strong>, <strong class="source-inline">Score</strong>, <strong class="source-inline">Text</strong>, and <strong class="source-inline">Type</strong>. The following table shows a complete list of AWS Comprehend <strong class="source-inline">DetectEntities</strong>, types, and descriptions:</p>
			<div>
				<div id="_idContainer085" class="IMG---Figure">
					<img src="image/B16061_02_10.jpg" alt="Figure 2.10: AWS Comprehend entity types and descriptions&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.10: AWS Comprehend entity types and descriptions</p>
			<h2 id="_idParaDest-66"><a id="_idTextAnchor066"/>Exercise 2.03: Determining the Named Entities in a Document (the DetectEntities method)</h2>
			<p>In this exercise, we will determine the named entities in a document. For this, we will use Amazon Comprehend's <strong class="source-inline">DetectEntities</strong> operation. The following are the steps for detecting named entities:</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The <em class="italic">Pre checkup instructions</em> and the source code for this exercise are available via GitHub in the repository at <a href="https://packt.live/2ADssUI">https://packt.live/2ADssUI</a>.</p>
			<ol>
				<li value="1">Open a new Jupyter Notebook.</li>
				<li>Import the AWS SDK for Python (boto3: <a href="https://boto3.amazonaws.com/v1/documentation/api/latest/index.html">https://boto3.amazonaws.com/v1/documentation/api/latest/index.html</a>) by using the following command:<p class="source-code">import boto3</p></li>
				<li>Now, import the <strong class="source-inline">JSON</strong> module to serialize <strong class="source-inline">JSON</strong> from <a href="https://docs.python.org/3.6/library/json.html">https://docs.python.org/3.6/library/json.html</a> by using the following command: <p class="source-code">import json</p></li>
				<li>Now, instantiate a new Comprehend client:<p class="source-code">comprehend = boto3.client(service_name='comprehend')</p></li>
				<li>Now, after instantiating a new Comprehend client, provide the <strong class="source-inline">English</strong> text to analyze: <p class="source-code">english_string = "I study Machine Learning in "\</p><p class="source-code">                 "Seattle on Thursday."</p><p class="source-code">print('Calling DetectEntities')</p></li>
				<li>Now, <strong class="source-inline">json.dumps()</strong> writes JSON data to a Python string: <p class="source-code">print(json.dumps(comprehend.detect_entities\</p><p class="source-code">                (Text = english_string, LanguageCode='en'), \</p><p class="source-code">                sort_keys=True, indent=4))</p><p class="source-code">print('End of DetectEntities\n')</p></li>
				<li>Press <em class="italic">Shift</em> + <em class="italic">Enter</em> to run the two notebook cells. The output of the preceding code is shown in the following screenshot:<div id="_idContainer086" class="IMG---Figure"><img src="image/B16061_02_11.jpg" alt="Figure 2.11: AWS Comprehend DetectEntities output&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 2.11: AWS Comprehend DetectEntities output</p>
			<p>The confidence scores were both ~0.99, as the inputs were simple examples. As expected, <strong class="source-inline">Seattle</strong> was detected as a <strong class="source-inline">LOCATION</strong>, and <strong class="source-inline">Thursday</strong> was detected as a <strong class="source-inline">DATE</strong>:</p>
			<div>
				<div id="_idContainer087" class="IMG---Figure">
					<img src="image/B16061_02_12.jpg" alt="Figure 2.12: AWS Comprehend BeginOffset and EndOffset review&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.12: AWS Comprehend BeginOffset and EndOffset review</p>
			<h2 id="_idParaDest-67"><a id="_idTextAnchor067"/>Exercise 2.04: Detecting Entities in a Set of Documents (Text Files)</h2>
			<p>In this exercise, we will determine the named entities in multiple documents. For this, we will use Amazon Comprehend's <strong class="source-inline">DetectEntities</strong> operation. The following are the steps for detecting the named entities from a set of documents:</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The <em class="italic">Pre checkup instructions</em> and the source code for this exercise are available via GitHub in the repository at <a href="https://packt.live/31UCuMs">https://packt.live/31UCuMs</a>.</p>
			<ol>
				<li value="1">Open a new Jupyter Notebook.</li>
				<li>Import the AWS SDK for Python (boto3: <a href="https://boto3.amazonaws.com/v1/documentation/api/latest/index.html">https://boto3.amazonaws.com/v1/documentation/api/latest/index.html</a>) by using the following command:<p class="source-code">import boto3</p></li>
				<li>Now, import the <strong class="source-inline">JSON</strong> module to serialize <strong class="source-inline">JSON</strong> from <a href="https://docs.python.org/3.6/library/json.html">https://docs.python.org/3.6/library/json.html</a> by using the following command:<p class="source-code">import json</p></li>
				<li>We also need to do some file operations to iterate through the documents. Import the <strong class="source-inline">glob</strong> module to find text files ending <strong class="source-inline">.txt</strong> from <a href="https://docs.python.org/3.6/library/glob.html">https://docs.python.org/3.6/library/glob.html</a> by using the following command:<p class="source-code">import glob</p></li>
				<li>We also need the <strong class="source-inline">os</strong> library. Import the <strong class="source-inline">os</strong> module from <a href="https://docs.python.org/3.6/library/os.html">https://docs.python.org/3.6/library/os.html</a> by using the following command:<p class="source-code">import os</p></li>
				<li>Now, instantiate a new Comprehend client:<p class="source-code">comprehend = boto3.client(service_name='comprehend')</p><p>Let's get a list of all the documents (assumes in Jupyter notebook you navigated to <strong class="source-inline">Chapter02/Exercise02.04/</strong> directory and the opened the notebook <strong class="source-inline">Exercise2.04.ipynb</strong>):</p><p class="source-code">data_dir = '<strong class="bold">../reviews__pos/*.txt</strong>' </p><p class="source-code"># Works for Linux, OSX. Change to \\ for windows</p><p class="source-code">file_list = glob.glob(data_dir)</p><p class="callout-heading">Note</p><p class="callout">The <strong class="source-inline">#</strong> symbol in the code snippet above denotes a code comment. Comments are added into code to help explain specific bits of logic. In this exercise, we are assuming the<strong class="source-inline">.txt</strong> files are stored in the <strong class="source-inline">review_pos</strong> directory. Depending on where you have downloaded and stored the <strong class="source-inline">.txt</strong> files on your system, the highlighted path must be modified in the code. </p></li>
				<li>Now, we can iterate through the documents and detect the entities in the documents. We will be calling <strong class="source-inline">detect_entities</strong> on each of the documents. As before, we will also use <strong class="source-inline">json.dumps()</strong> to write the JSON data to a Python string:<p class="source-code">for file in file_list:</p><p class="source-code">  with open(file, 'r', encoding="utf-8") as f:</p><p class="source-code">    file_as_str = f.read()</p><p class="source-code">    # python string formatting to print the text file name</p><p class="source-code">    print('Calling detect_entities_from_documents.py on file: %s' \</p><p class="source-code">          % file[-15:])</p><p class="source-code">    # json.dumps() writes JSON data to a Python string</p><p class="source-code">    print(json.dumps(comprehend.detect_entities\</p><p class="source-code">                    (Text = file_as_str, LanguageCode='en'), \</p><p class="source-code">                    sort_keys=True, indent=4))</p><p class="source-code">    print('End of detect_entities\n')</p></li>
				<li>Press <em class="italic">Shift</em> + <em class="italic">Enter</em> to run the two notebook cells. The output of the preceding code is shown in the following screenshot. It is a long output—we are showing the output for one file. You will see the entities listed for all the files in the <strong class="source-inline">/reviews__pos/*.txt</strong> subdirectory:<div id="_idContainer088" class="IMG---Figure"><img src="image/B16061_02_13.jpg" alt="Figure 2.13: DetectEntities output&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 2.13: DetectEntities output</p>
			<p>In this exercise, we extended entity detection to a set of documents, calling Amazon Comprehend's <strong class="source-inline">DetectEntities</strong> recursively.</p>
			<h2 id="_idParaDest-68"><a id="_idTextAnchor068"/>Detecting Key Phrases</h2>
			<p>A key phrase for AWS is analogous to a noun phrase, which represents an actual thing. In English, when we put together different words that represent one concrete idea, we call it a noun phrase. </p>
			<p>For example, <strong class="bold">A fast machine</strong> is a noun phrase because it consists of <strong class="bold">A</strong>, the article; <strong class="bold">fast</strong>, an adjective; and <strong class="bold">machine</strong>, which is a noun. AWS looks for appropriate word combinations and gives scores that indicate the confidence that a string is a noun phrase.</p>
			<h2 id="_idParaDest-69"><a id="_idTextAnchor069"/>Exercise 2.05: Detecting Key Phrases</h2>
			<p>In this exercise, we will detect key phrases. To do so, we will use Amazon Comprehend's <strong class="source-inline">DetectKeyPhrase</strong> operation. The following are the steps for detecting key phrases:</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The <em class="italic">Pre checkup instructions</em> and the source code for this exercise are available via GitHub in the repository at <a href="https://packt.live/2Z75cI4">https://packt.live/2Z75cI4</a>.</p>
			<ol>
				<li value="1">Import the AWS SDK for Python (boto3: <a href="http://boto3.readthedocs.io/en/latest/">http://boto3.readthedocs.io/en/latest/</a>) by using the following command:<p class="source-code">import boto3</p></li>
				<li>Now, import the JSON module to serialize the JSON from <a href="https://docs.python.org/3.6/library/json.html ">https://docs.python.org/3.6/library/json.html </a>by using the following command:<p class="source-code">import json</p></li>
				<li>Now, instantiate a new Comprehend client by using the following code:<p class="source-code">comprehend = boto3.client(service_name='comprehend')</p></li>
				<li>Now, provide the <strong class="source-inline">English</strong> text to analyze using the following code:<p class="source-code">english_string = 'robert redfords a river runs through '\</p><p class="source-code">                 'is not a film i watch often. it is a '\</p><p class="source-code">                 'masterpiece, one of the better films of '\</p><p class="source-code">                 'recent years. The acting and direction is '\</p><p class="source-code">                 'top-notch never sappy , always touching.'</p><p class="source-code">print('Calling DetectKeyPhrases')</p><p class="source-code"># json.dumps() writes JSON data to a Python string</p><p class="source-code">print(json.dumps(comprehend.detect_key_phrases\</p><p class="source-code">     (Text = english_string, LanguageCode='en'), \</p><p class="source-code">     sort_keys=True, indent=4))</p><p class="source-code">print('End of DetectKeyPhrases\n')</p></li>
				<li>Run the code by executing the cells with <em class="italic">Shift</em> + <em class="italic">Enter</em>. You will see the following output:<div id="_idContainer089" class="IMG---Figure"><img src="image/B16061_02_14.jpg" alt="Figure 2.14: AWS Comprehend DetectKeyPhrase output&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 2.14: AWS Comprehend DetectKeyPhrase output</p>
			<h2 id="_idParaDest-70"><a id="_idTextAnchor070"/>Detecting Sentiments</h2>
			<p>Amazon Comprehend has the capability to detect sentiments, usually used for social media posts, blog posts, reviews, emails, and other user-generated content. Amazon Comprehend can determine the four shades of sentiment polarity: positive, negative, neutral, and mixed. Mixed sentiment is interesting as it can differentiate between different aspects; for example, a user might like your website but not be thrilled about the price of a product.</p>
			<h2 id="_idParaDest-71"><a id="_idTextAnchor071"/>Exercise 2.06: Conducting Sentiment Analysis</h2>
			<p>In this exercise, we will carry out sentiment analysis. To do so, we will use Amazon Comprehend's <strong class="source-inline">DetectSentiment</strong> operation. The following are the steps for detecting sentiment:</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The <em class="italic">Pre checkup instructions</em> and the source code for this exercise are available via GitHub in the repository at <a href="https://packt.live/3ebVNU1">https://packt.live/3ebVNU1</a>.</p>
			<ol>
				<li value="1">Open a new Jupyter Notebook.</li>
				<li>Import the <strong class="source-inline">AWS SDK</strong> for Python (boto3) from <a href="http://boto3.readthedocs.io/en/latest/">http://boto3.readthedocs.io/en/latest/</a> by using the following command:<p class="source-code">import boto3</p></li>
				<li>Now, import the <strong class="source-inline">JSON</strong> module to serialize JSON from <a href="https://docs.python.org/3.6/library/json.html">https://docs.python.org/3.6/library/json.html</a> by using the following command:<p class="source-code">import json</p></li>
				<li>Now, instantiate a new Comprehend client, using the following code:<p class="source-code">comprehend = boto3.client(service_name='comprehend')</p></li>
				<li>Then, provide a text string to analyze, using the following code:<p class="source-code">english_string = 'Today is my birthday, I am so happy.'</p><p class="source-code">print('Calling DetectSentiment')</p><p class="source-code"># json.dumps() #writes JSON data to a Python string</p><p class="source-code">print('english_string results:')</p><p class="source-code">print(json.dumps(comprehend.detect_sentiment\</p><p class="source-code">     (Text = english_string, LanguageCode='en'), \</p><p class="source-code">     sort_keys=True, indent=4))</p><p class="source-code">print('End of DetectSentiment\n')</p></li>
				<li>Run the code by executing the cells with <em class="italic">Shift</em> + <em class="italic">Enter</em>. The output is as follows:<div id="_idContainer090" class="IMG---Figure"><img src="image/B16061_02_15.jpg" alt="Figure 2.15: AWS Comprehend—DetectSentiment output&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 2.15: AWS Comprehend—DetectSentiment output</p>
			<p>In this exercise, we saw how easy it is to perform sentiment analysis using AWS Comprehend. <strong class="source-inline">DetectSentiment</strong> correctly predicted the sentiment of the statement <em class="italic">Today is my birthday, I am so happy</em> as positive.</p>
			<h1 id="_idParaDest-72"><a id="_idTextAnchor072"/>Setting Up a Lambda Function and Analyzing Imported Text Using Comprehend</h1>
			<p>We have used Amazon Comprehend to do various NLP tasks, such as detecting entities and key phrases and carrying out sentiment analysis.</p>
			<h2 id="_idParaDest-73"><a id="_idTextAnchor073"/>Integrating Comprehend and AWS Lambda for responsive NLP</h2>
			<p>In this topic, we will be integrating AWS Lambda functions with Comprehend, which provides a more powerful, scalable infrastructure. You can use AWS Lambda to run your code in response to events, such as changes to data in an Amazon S3 bucket.</p>
			<p>Executing code in response to events provides a real-world solution for developing scalable software architecture. Overall, this increases our data pipeline and provides the ability to handle more complex big data volumes and NLP operations.</p>
			<h2 id="_idParaDest-74"><a id="_idTextAnchor074"/>What Is AWS Lambda?</h2>
			<p>AWS Lambda is a compute service that runs code without provisioning or managing servers. AWS Lambda executes code only when needed, and scales automatically. AWS Lambda runs your code on a high-availability compute infrastructure, which performs the administration of the compute service. More specifically, AWS Lambda performs the following: server and operating system maintenance, capacity provisioning and automatic scaling, code monitoring, and logging.</p>
			<p>Overall, the goal of AWS Lambda is to make short, simple, modular code segments that you can tie together into a larger processing infrastructure.</p>
			<h2 id="_idParaDest-75"><a id="_idTextAnchor075"/>What Does AWS Lambda Do?</h2>
			<p>Lambda allows users to run small segments of code (Java, Node, or Python) to complete a specific task. These specific tasks can be storing and then executing changes to your AWS setup, or responding to events in S3 (we will explore the latter later in this topic). Before Lambda, you would typically need a separate EC2 server to run your entire code; however, Lambda allows small segments of code to run without the need for EC2.</p>
			<h2 id="_idParaDest-76"><a id="_idTextAnchor076"/>Lambda Function Anatomy</h2>
			<p>AWS Lambda provides two options for implementing Python code. First, you can upload a complete Python code file. Second, you can use the Lambda function editor entirely inline, which means that you can enter and modify the code directly, without having to upload any files to AWS. The code that you enter will be executed when the Lambda function is invoked. The second option will allow for easier testing, so we will use it. </p>
			<p>Let's examine the structure of a Lambda function:</p>
			<ul>
				<li>When you create a function (for example, <strong class="source-inline">s3_trigger</strong>), AWS creates a folder named the same, with a Python file named <strong class="source-inline">Lambda_function.py</strong> within the folder. This file contains a stub for the <strong class="source-inline">Lambda_handler</strong> function, which is the entry point of our Lambda function. The entry point takes two parameters as arguments: The <strong class="source-inline">event</strong> argument and the <strong class="source-inline">context</strong> argument.</li>
				<li>The <strong class="source-inline">event</strong> argument provides the value of the payload, which is sent to the function from the <strong class="source-inline">calling</strong> process. It typically takes the form of a Python <strong class="source-inline">dict</strong> type, although it could also be one of <strong class="source-inline">list</strong>, <strong class="source-inline">str</strong>, <strong class="source-inline">int</strong>, <strong class="source-inline">float</strong>, or <strong class="source-inline">NoneType</strong>.</li>
				<li>The <strong class="source-inline">context</strong> argument is of the type <strong class="source-inline">LambdaContext</strong> and contains runtime information. You will be using this parameter for an exercise in a later section. The return value of the function can be any type that is JSON-serializable. This value gets returned to the calling application, after serializing.</li>
			</ul>
			<p>We will incorporate Lambda, S3, and Amazon Comprehend, to automatically perform document analysis when a text document is uploaded to S3. The architecture of a Lambda function is as follows:</p>
			<div>
				<div id="_idContainer091" class="IMG---Figure">
					<img src="image/B16061_02_16.jpg" alt="Figure 2.16: Architecture diagram&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.16: Architecture diagram</p>
			<h2 id="_idParaDest-77"><a id="_idTextAnchor077"/>Exercise 2.07: Setting Up a Lambda Function for S3</h2>
			<p>In this exercise, we will integrate the following AWS services: S3, Lambda, and Amazon Comprehend. To perform this exercise, the architecture should be recollected. Upload a file (<strong class="source-inline">test_s3trigger_configured.txt</strong>) to S3 and view the results of Comprehend's analysis. The following are the steps for setting up a Lambda function:</p>
			<p><strong class="bold">Creating the S3 bucket</strong></p>
			<ol>
				<li value="1">You should have an AWS account and have completed the exercises and activities in <em class="italic">Chapter 1</em>, <em class="italic">An Introduction to AWS</em>.</li>
				<li>First, navigate to the Amazon S3 service, <a href="https://console.aws.amazon.com/s3/">https://console.aws.amazon.com/s3/</a>, and click <strong class="source-inline">Create bucket</strong>:<div id="_idContainer092" class="IMG---Figure"><img src="image/B16061_02_17.jpg" alt="Figure 2.17: S3 Bucket creation for the Lambda trigger&#13;&#10;"/></div><p class="figure-caption">Figure 2.17: S3 Bucket creation for the Lambda trigger</p><p>For <strong class="source-inline">Bucket name</strong>, type <strong class="source-inline">aws-ml-s3-trigger</strong>, and then click <strong class="source-inline">Create</strong>:</p><p class="callout-heading">Note</p><p class="callout">Bucket names in AWS have to be unique, otherwise you will get an error "<strong class="source-inline">Bucket name already exists</strong>". One easy way to get a unique name is to append the bucket name with today's date plus the time, for instance, YYYYMMDDHHMM. While writing this chapter, I created the bucket <strong class="source-inline">aws-ml-s3-trigger-202001181023 </strong>.</p><div id="_idContainer093" class="IMG---Figure"><img src="image/B16061_02_18.jpg" alt="Figure 2.18: Creating an S3 bucket&#13;&#10;"/></div><p class="figure-caption">Figure 2.18: Creating an S3 bucket</p></li>
				<li>Your bucket will be created, and you will be redirected to the bucket list in the <strong class="source-inline">S3 buckets</strong> screen as shown:<div id="_idContainer094" class="IMG---Figure"><img src="image/B16061_02_19.jpg" alt="Figure 2.19: S3 Bucket list screen&#13;&#10;"/></div><p class="figure-caption">Figure 2.19: S3 Bucket list screen</p></li>
				<li>Next, navigate to Amazon Lambda, under <strong class="source-inline">Services</strong>, and click <strong class="source-inline">Lambda</strong> under <strong class="source-inline">Compute</strong>:<div id="_idContainer095" class="IMG---Figure"><img src="image/B16061_02_20.jpg" alt="Figure 2.20: Services | Compute | Lambda&#13;&#10;"/></div><p class="figure-caption">Figure 2.20: Services | Compute | Lambda</p></li>
				<li>You will see the Lambda console, as shown here:<div id="_idContainer096" class="IMG---Figure"><img src="image/B16061_02_21.jpg" alt="Figure 2.21: Lambda console&#13;&#10;"/></div><p class="figure-caption">Figure 2.21: Lambda console</p></li>
				<li>In the Lambda console, click <strong class="source-inline">Create function</strong>:<div id="_idContainer097" class="IMG---Figure"><img src="image/B16061_02_22.jpg" alt="Figure 2.22: AWS Lambda Create function button&#13;&#10;"/></div><p class="figure-caption">Figure 2.22: AWS Lambda Create function button</p></li>
				<li>Choose <strong class="source-inline">Author from scratch</strong> from the options. For <strong class="source-inline">Name</strong>, type <strong class="source-inline">s3_trigger</strong>:<div id="_idContainer098" class="IMG---Figure"><img src="image/B16061_02_23.jpg" alt="Figure 2.23: AWS Lambda—Creating a function with the Author from scratch option&#13;&#10;"/></div><p class="figure-caption">Figure 2.23: AWS Lambda—Creating a function with the Author from scratch option</p></li>
				<li>For the runtime options, choose <strong class="source-inline">Python 3.6</strong> from the list:<div id="_idContainer099" class="IMG---Figure"><img src="image/B16061_02_24.jpg" alt="Figure 2.24: AWS Lambda—Python 3.6 selection&#13;&#10;"/></div><p class="figure-caption">Figure 2.24: AWS Lambda—Python 3.6 selection</p></li>
				<li>Click <strong class="source-inline">Choose or create an execution role</strong> and choose <strong class="source-inline">Create new role from AWS policy template(s)</strong> and enter the name <strong class="source-inline">s3TriggerRole</strong> in the <strong class="source-inline">Role name</strong> field:<div id="_idContainer100" class="IMG---Figure"><img src="image/B16061_02_25.jpg" alt="Figure 2.25: AWS Lambda Create Role template&#13;&#10;"/></div><p class="figure-caption">Figure 2.25: AWS Lambda Create Role template</p></li>
				<li>Click the dropdown in <strong class="source-inline">Policy templates</strong> and select <strong class="source-inline">Amazon S3 object read-only permissions</strong>. You will see AWS Lambda Policy template dropdown box, as shown here:<div id="_idContainer101" class="IMG---Figure"><img src="image/B16061_02_26.jpg" alt="Figure 2.26: AWS Lambda Policy templates dropdown box&#13;&#10;"/></div><p class="figure-caption">Figure 2.26: AWS Lambda Policy templates dropdown box</p></li>
				<li>Then, click the <strong class="source-inline">Create function</strong> button to create the Lambda function in AWS. The final AWS Lambda Create function screen looks as follows:<div id="_idContainer102" class="IMG---Figure"><img src="image/B16061_02_27.jpg" alt="Figure 2.27: AWS Lambda—Create a function screen&#13;&#10;"/></div><p class="figure-caption">Figure 2.27: AWS Lambda—Create a function screen</p></li>
				<li>You will see the Lambda function designer. There is lot of information displayed. Let's focus on the essentials for this exercise:<div id="_idContainer103" class="IMG---Figure"><img src="image/B16061_02_28.jpg" alt="Figure 2.28: AWS Lambda—function designer&#13;&#10;"/></div><p class="figure-caption">Figure 2.28: AWS Lambda—function designer</p></li>
				<li>Click <strong class="source-inline">Add trigger</strong>, and from the drop-down menu, select <strong class="source-inline">S3</strong>:<div id="_idContainer104" class="IMG---Figure"><img src="image/B16061_02_29.jpg" alt="Figure 2.29: Trigger configuration drop-down menu&#13;&#10;"/></div><p class="figure-caption">Figure 2.29: Trigger configuration drop-down menu</p></li>
				<li>Take a quick look at the options and select <strong class="source-inline">Add</strong>:<p>The bucket name should be the S3 trigger bucket you created (in my case, it was <strong class="source-inline">aws-ml-s3-trigger-202001181023</strong>); in the <strong class="source-inline">Event type</strong> section, <strong class="source-inline">All object create events</strong> must be selected in the dropdown and <strong class="source-inline">Enable Trigger</strong> should be checked, as shown here:</p><p class="callout-heading">Note</p><p class="callout">You might get the error "<strong class="source-inline">An error occurred when creating the trigger: Configurations overlap. Configurations on the same bucket cannot share a common event type</strong>." This would happen if you created a function and deleted it. The easiest way is to delete the event via <strong class="source-inline">Services | Storage/S3 | Click the bucket | Properties | Events</strong> and deleting the Lambda event. Make sure you click the <strong class="source-inline">Save</strong> button after deleting the event.</p><div id="_idContainer105" class="IMG---Figure"><img src="image/B16061_02_30.jpg" alt="Figure 2.30: Amazon S3 Trigger configuration&#13;&#10;"/></div><p class="figure-caption">Figure 2.30: Amazon S3 Trigger configuration</p><p>You will see S3 on the Lambda <strong class="source-inline">Designer</strong> screen:</p><div id="_idContainer106" class="IMG---Figure"><img src="image/B16061_02_31.jpg" alt="Figure 2.31: Lambda function designer with S3&#13;&#10;"/></div><p class="figure-caption">Figure 2.31: Lambda function designer with S3</p></li>
				<li>Again, choose <strong class="source-inline">Add trigger</strong> and choose <strong class="source-inline">CloudWatch/Events/EventBridge</strong>:<div id="_idContainer107" class="IMG---Figure"><img src="image/B16061_02_32.jpg" alt="Figure 2.32: Adding the trigger configuration&#13;&#10;"/></div><p class="figure-caption">Figure 2.32: Adding the trigger configuration</p></li>
				<li>Then click the box next to <strong class="source-inline">Rule</strong>:<div id="_idContainer108" class="IMG---Figure"><img src="image/B16061_02_33.jpg" alt="Figure 2.33: Add trigger – creating a new rule&#13;&#10;"/></div><p class="figure-caption">Figure 2.33: Add trigger – creating a new rule</p></li>
				<li>Select <strong class="source-inline">Create a new rule</strong>. The following screen will be displayed. Type <strong class="source-inline">s3_trigger_CWRule</strong> for the rule name.<div id="_idContainer109" class="IMG---Figure"><img src="image/B16061_02_34.jpg" alt="Figure 2.34: Add Trigger—New Rule Configuration&#13;&#10;"/></div><p class="figure-caption">Figure 2.34: Add Trigger—New Rule Configuration</p></li>
				<li>Choose <strong class="source-inline">Event pattern</strong> in <strong class="source-inline">Rule type</strong>. Then select <strong class="source-inline">Simple Storage Service (S3)</strong> from the dropdown and <strong class="source-inline">All events</strong> and click <strong class="source-inline">Add</strong>:<div id="_idContainer110" class="IMG---Figure"><img src="image/B16061_02_35.jpg" alt="Figure 2.35: Adding an S3 rule type&#13;&#10;"/></div><p class="figure-caption">Figure 2.35: Adding an S3 rule type</p></li>
				<li>Let's explore the interface a bit more so that you can get comfortable navigating through different pages. Click <strong class="source-inline">Functions</strong> in the top-left corner:<div id="_idContainer111" class="IMG---Figure"><img src="image/B16061_02_36.jpg" alt="Figure 2.36: Top navigation bar to navigate back to functions&#13;&#10;"/></div><p class="figure-caption">Figure 2.36: Top navigation bar to navigate back to functions</p></li>
				<li>Click <strong class="source-inline">s3_trigger</strong> to go back to the function you are working on:<div id="_idContainer112" class="IMG---Figure"><img src="image/B16061_02_37.jpg" alt="Figure 2.37: Selecting the lambda function to work on&#13;&#10;"/></div><p class="figure-caption">Figure 2.37: Selecting the lambda function to work on</p></li>
				<li>Next, scroll down the screen to the <strong class="source-inline">Function code</strong> section. The default code will be the same as, or similar to, the following:<div id="_idContainer113" class="IMG---Figure"><img src="image/B16061_02_38.jpg" alt="Figure 2.38: AWS Lambda—the default lambda_function screen&#13;&#10;"/></div><p class="figure-caption">Figure 2.38: AWS Lambda—the default lambda_function screen</p><p>Here, we can enter and edit our code entirely within the <strong class="source-inline">lambda_function</strong> screen (as long as <strong class="source-inline">Code entry type</strong> is set to <strong class="source-inline">Edit code inline</strong>, which is the default value in the drop-down menu).</p><p class="callout-heading">Note</p><p class="callout">For this step, you may either follow along and type in the code or obtain it from the source code folder at <a href="https://packt.live/2O6WsLW">https://packt.live/2O6WsLW</a>.</p></li>
				<li>First, we import the <strong class="bold">AWS SDK</strong> for Python (boto3: <a href="http://boto3.readthedocs.io/en/latest/">http://boto3.readthedocs.io/en/latest/</a>):<p class="source-code">import boto3</p></li>
				<li>Then, import the JSON module to serialize the JSON (<a href="https://docs.python.org/3.6/library/json.html">https://docs.python.org/3.6/library/json.html</a>):<p class="source-code">import json</p></li>
				<li>Next, create a function that takes two parameters—<strong class="source-inline">event</strong> and <strong class="source-inline">context</strong>:<p class="source-code">def Lambda_handler(event, context):</p></li>
				<li>Next, create the <strong class="source-inline">s3</strong> client object:<p class="source-code">s3 = boto3.client("s3")</p></li>
				<li>Add an <strong class="source-inline">if</strong> event to check whether an event occurs.</li>
				<li>Next, replace <strong class="source-inline">&lt;input Bucket name&gt;</strong> with the bucket you created (<strong class="source-inline">aws-ml-s3-trigger-202001181023</strong>, in are example):<p class="source-code">bucket = "&lt;input Bucket name&gt;"</p></li>
				<li>Next, access the first index of the <strong class="source-inline">Records</strong> event to obtain the text file object:<p class="source-code">text_file_obj = event["Records"][0]</p></li>
				<li>Next, assign the <strong class="source-inline">filename</strong> text to a variable and print the filename:<p class="source-code">filename = str(text_file_obj['s3']['object']['key'])</p><p class="source-code">print("filename: ", filename)</p></li>
				<li>Next, create the file object by getting the bucket and key:<p class="source-code">file_obj = s3.get_object(Bucket = Bucket, Key = filename)</p></li>
				<li>Assign the text to the <strong class="source-inline">body_str_obj</strong> variable:<p class="source-code">body_str_obj = str(file_obj['Body'].read())</p></li>
				<li>Create the <strong class="source-inline">comprehend</strong> variable:<p class="source-code">comprehend = boto3.client(service_name="comprehend")</p></li>
				<li>The next three lines of code call the respective Comprehend functions to detect the sentiment, entities, and key phrases from the text document. Then, the output is printed to the console:<p class="source-code">sentiment_response = comprehend.detect_sentiment\</p><p class="source-code">                     (Text = body_str_obj, \</p><p class="source-code">                     LanguageCode = "en")</p><p class="source-code">print(«sentiment_response: \n», sentiment_response)</p><p class="source-code">entity_response = comprehend.detect_entities\</p><p class="source-code">                  (Text = body_str_obj, LanguageCode = "en")</p><p class="source-code">print("\n\nentity_response: \n", entity_response)</p><p class="source-code">key_phases_response = comprehend.detect_key_phrases\</p><p class="source-code">                      (Text = body_str_obj, \</p><p class="source-code">                      LanguageCode = "en") </p><p class="source-code">print("\n\nkey_phases_response: \n", key_phases_response)</p></li>
				<li>The final statement returns the <strong class="source-inline">'Hello from Lambda'</strong> string, like so:<p class="source-code">return {</p><p class="source-code">      'statusCode' :200,</p><p class="source-code">      'body' : json.dumps('Hello from Lambda')</p><p class="source-code">    }</p></li>
				<li>Now, click the <strong class="source-inline">Save</strong> button:<div id="_idContainer114" class="IMG---Figure"><img src="image/B16061_02_39.jpg" alt="Figure 2.39: AWS Lambda – save screen&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 2.39: AWS Lambda – save screen</p>
			<p>From this exercise, the <strong class="source-inline">s3_trigger</strong> function has access to S3, but not Amazon Comprehend. We need to attach a policy to the <strong class="source-inline">s3_trigger</strong> function to allow it to access Amazon Comprehend to execute the text analysis functions (<strong class="source-inline">detect_sentiment</strong>, <strong class="source-inline">detect_entities</strong>, and <strong class="source-inline">detect_key_phrases</strong>).</p>
			<h2 id="_idParaDest-78"><a id="_idTextAnchor078"/>Exercise 2.08: Assigning Policies to S3_trigger to Access Comprehend</h2>
			<p>In this exercise, we will attach the policies to the <strong class="source-inline">S3_trigger</strong> function to allow it to access Comprehend. The steps for completion for assigning the policies are as follows:</p>
			<ol>
				<li value="1">In the Amazon Management Console, click <strong class="source-inline">Services</strong> at the top left:<div id="_idContainer115" class="IMG---Figure"><img src="image/B16061_02_40.jpg" alt="Figure 2.40: AWS Services from the AWS Management Console&#13;&#10;"/></div><p class="figure-caption">Figure 2.40: AWS Services from the AWS Management Console</p></li>
				<li>Navigate to the <strong class="source-inline">Identity and Access Management</strong> dashboard in the <strong class="source-inline">Security, Identity, &amp; Compliance</strong> section. You can also type <strong class="source-inline">IAM</strong> and select it from the dropdown:<div id="_idContainer116" class="IMG---Figure"><img src="image/B16061_02_41.jpg" alt="Figure 2.41: IAM dashboard&#13;&#10;"/></div><p class="figure-caption">Figure 2.41: IAM dashboard</p></li>
				<li>Now, once you get to the IAM dashboard, click <strong class="source-inline">Roles</strong>:<div id="_idContainer117" class="IMG---Figure"><img src="image/B16061_02_42.jpg" alt="Figure 2.42: Left-hand side of the IAM dashboard&#13;&#10;"/></div><p class="figure-caption">Figure 2.42: Left-hand side of the IAM dashboard</p></li>
				<li>Now, the screen will be populated with the role list. Click <strong class="source-inline">s3TriggerRole</strong> in the role list:<div id="_idContainer118" class="IMG---Figure"><img src="image/B16061_02_43.jpg" alt="Figure 2.43: Role list—selecting s3TriggerRole&#13;&#10;"/></div><p class="figure-caption">Figure 2.43: Role list—selecting s3TriggerRole</p></li>
				<li>The <strong class="source-inline">s3TriggerRole</strong> option will be enabled. Then, click <strong class="source-inline">Attach policies</strong>:<div id="_idContainer119" class="IMG---Figure"><img src="image/B16061_02_44.jpg" alt="Figure 2.44: Permissions tab for s3TriggerRole&#13;&#10;"/></div><p class="figure-caption">Figure 2.44: Permissions tab for s3TriggerRole</p></li>
				<li>Type <strong class="source-inline">Comprehend</strong> to filter the policies. Then, click the checkbox next to <strong class="source-inline">ComprehendFullAccess</strong>:<div id="_idContainer120" class="IMG---Figure"><img src="image/B16061_02_45.jpg" alt="Figure 2.45: ComprehendFullAccess policy selection&#13;&#10;"/></div><p class="figure-caption">Figure 2.45: ComprehendFullAccess policy selection</p></li>
				<li>Once you have selected the checkbox, click <strong class="source-inline">Attach policy</strong> (located in the lower right-hand corner of the screen):<div id="_idContainer121" class="IMG---Figure"><img src="image/B16061_02_46.jpg" alt="Figure 2.46: Attaching the selected policies&#13;&#10;"/></div><p class="figure-caption">Figure 2.46: Attaching the selected policies</p></li>
				<li>You will be redirected to the <strong class="source-inline">s3TriggerRole</strong> screen, and you will receive the following message:<div id="_idContainer122" class="IMG---Figure"><img src="image/B16061_02_47.jpg" alt="Figure 2.47: Successfully attached policies message&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 2.47: Successfully attached policies message</p>
			<p>With that, we have successfully attached the policies to the <strong class="source-inline">S3_trigger</strong> function thus allowing it to access Comprehend.</p>
			<h2 id="_idParaDest-79"><a id="_idTextAnchor079"/>Activity 2.01: Integrating Lambda with Amazon Comprehend to Perform Text An<a id="_idTextAnchor080"/>alysis</h2>
			<p>In this activity, we will integrate the Lambda functions with Comprehend to perform text analysis (<strong class="source-inline">detect_sentiment</strong>, <strong class="source-inline">detect_entities</strong>, and <strong class="source-inline">detect_key_phrases</strong>) when a document is uploaded to S3.</p>
			<p>Suppose that you are creating a chatbot. You have identified a business topic and the corresponding text documents, with content that will allow the chatbot to make your business successful. Your next step is to integrate the Lambda functions with Comprehend, for sentiment, key phrases, and entities. To ensure that this happens correctly, you will need to have <strong class="source-inline">test_s3trigger_configured.txt</strong>. </p>
			<p class="callout-heading">Note</p>
			<p class="callout">The <strong class="source-inline">test_s3trigger_configured.txt</strong> file can be found on GitHub at link <a href="https://packt.live/3gAxqku">https://packt.live/3gAxqku</a>.</p>
			<p>Before you execute <strong class="source-inline">s3_trigger</strong>, consider the output, based on the following aspects of the text: sentiment (positive, negative, or neutral), entities (quantity, person, place, and so on), and key phrases:</p>
			<ol>
				<li value="1">First, navigate to the <strong class="source-inline">S3_trigger</strong> Lambda function.</li>
				<li>Add <strong class="source-inline">test_s3trigger_configured.txt</strong> to the S3 bucket, to verify the Lambda <strong class="source-inline">S3_trigger</strong> function.</li>
				<li>Now, upload the file into the bucket and monitor the file.</li>
				<li>Next, click <strong class="source-inline">View logs</strong> in <strong class="source-inline">CloudWatch</strong> by using the log stream. </li>
				<li>Now, expand the output in a text format.<p>The following will be the output:</p><p><strong class="source-inline">Sentiment_response</strong> -&gt; Classified as 60.0% likely to be positive</p><p><strong class="source-inline">Sentiment_response</strong>:</p><p class="source-code">{'Sentiment': 'POSITIVE',</p><p class="source-code">'SentimentScore':{'Positive': 0.6005121469497681,</p><p class="source-code">                  'Negative': 0.029164031147956848, </p><p class="source-code">                  'Neutral': 0.3588017225265503, </p><p class="source-code">                  'Mixed': 0.01152205839753151}, </p><p><strong class="source-inline">entity_response</strong> -&gt; Classified as 70.5% likely to be a quantity</p><p><strong class="source-inline">entity_response</strong>:</p><p class="source-code">{Entities':[{'Score':0.7053232192993164, </p><p class="source-code">             'Type': 'QUANTITY','Text': '3 trigger', </p><p class="source-code">             'BeginOffset': 35, 'EndOffset': 44}], </p><p><strong class="source-inline">key_phases_response</strong> -&gt; Classified as 89.9% likely "a test file" and 98.5% likely "the s3 trigger" are the key phrases:</p><p><strong class="source-inline">key_phases_response</strong>:</p><p class="source-code">{'KeyPhrases': [{'Score': 0.8986637592315674, </p><p class="source-code">                 'Text': 'a test file', </p><p class="source-code">                 'BeginOffset': 8, 'EndOffset': 19}, </p><p class="source-code">                {'Score': 0.9852105975151062, </p><p class="source-code">                 'Text': 'the s3 trigger', 'BeginOffset': 30, </p><p class="source-code">                 'EndOffset': 44}],</p><p class="callout-heading">Note</p><p class="callout">The solution for this activity can be found on page 279.</p></li>
			</ol>
			<h1 id="_idParaDest-80"><a id="_idTextAnchor081"/>Amazon Textract</h1>
			<p>Another interesting NLP Amazon service is Textract. Essentially, Textract can extract information from documents, usually business documents such as tax forms, legal documents, medical forms, bank forms, patent registrations, and so forth. It is an <strong class="bold">optical character recognition (OCR</strong>) solution for scanning structured documents, suitable for <strong class="bold">robotic process automation</strong> (<strong class="bold">RPA</strong>). Textract is a relatively new service—previewed in November 2018 and generally available in May 2019.</p>
			<p>The advantage of Textract is that it understands documents and can extract tables and/or key-value pairs suitable for downstream processing. A lot of business processes, such as health insurance processing, tax preparation, loan application processing, monitoring and evaluation of existing loans, compliance evaluation, and engineering evaluations take in these documents, usually processing them manually to extract information and then start digital processes. Using Amazon Textract, the manual intake of various documents can be automated, resulting in a faster turnaround when approving loans, accelerated processing of health claims, or approving an engineering design quickly, thus achieving good business value.</p>
			<h2 id="_idParaDest-81"><a id="_idTextAnchor082"/>Exercise 2.09: Extracting Tax Information Using Amazon Textract</h2>
			<p>In this exercise, you will take a page of a sample tax return document from documentcloud.org (<a href="https://www.documentcloud.org/documents/3462212-Sample-2016-Tax-Return.html">https://www.documentcloud.org/documents/3462212-Sample-2016-Tax-Return.html</a>) and see how much information Textract can extract:</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The sample document (page 1 of US Tax form 1040) is available at <a href="https://packt.live/2O5e1Mn">https://packt.live/2O5e1Mn</a>.</p>
			<ol>
				<li value="1">For this exercise, we will use the Textract interface directly. This is very useful to try out and to see how a document is amenable to OCR.</li>
				<li>First, go to the Textract dashboard by selecting <strong class="source-inline">Services | Machine Learning | Amazon Textract</strong>. There are lots of interesting details on that page. Take the time to read through the materials:<div id="_idContainer123" class="IMG---Figure"><img src="image/B16061_02_48.jpg" alt="Figure 2.48: Amazon Textract dashboard&#13;&#10;"/></div><p class="figure-caption">Figure 2.48: Amazon Textract dashboard</p></li>
				<li>Click <strong class="source-inline">Try Amazon Textract</strong>. A very simple utilitarian page appears:<div id="_idContainer124" class="IMG---Figure"><img src="image/B16061_02_49.jpg" alt="Figure 2.49: Amazon Textract Analyze document&#13;&#10;"/></div><p class="figure-caption">Figure 2.49: Amazon Textract Analyze document</p></li>
				<li>Click <strong class="source-inline">Upload document</strong> and upload the <strong class="source-inline">Sample-2016-Tax-Return.jpeg</strong> file. The service thinks for a minute and shows very informative tabs and the information it has extracted:<div id="_idContainer125" class="IMG---Figure"><img src="image/B16061_02_50.jpg" alt="Figure 2.50: Amazon Textract Analyze document screen with the sample tax form&#13;&#10;"/></div><p class="figure-caption">Figure 2.50: Amazon Textract Analyze document screen with the sample tax form</p><p>The raw text is interesting, but we are looking for more value for our automation pipeline.</p></li>
				<li>Click the <strong class="source-inline">Forms</strong> tab and you will see a very interesting page—it can get the value as well as the key. For example, line 7 is extracted as <strong class="source-inline">7 Wages, salaries, tips, etc. Attach Form(s) W-2 7</strong> and a value of <strong class="source-inline">93,500</strong>. Now, a downstream loan processing application can get the value as well as the context and act on it.<p>You can click other fields on the image on the left-hand side and see the extracted entry on the right-hand side. </p><p>You can download the results as JSON, CSV, table, and text formats. As expected, <strong class="source-inline">keyvalues.csv</strong> has the line 7 we saw earlier as the key and <strong class="source-inline">93,500</strong> as the value:</p><div id="_idContainer126" class="IMG---Figure"><img src="image/B16061_02_51.jpg" alt="Figure 2.51: Amazon Textract Analyze document screen with the sample tax document form&#13;&#10;"/></div><p class="figure-caption">Figure 2.51: Amazon Textract Analyze document screen with the sample tax document form</p></li>
				<li>You can see the extracted fields in a table format (with the keys as the caption and the value in the grey box under the captions) as shown below:<div id="_idContainer127" class="IMG---Figure"><img src="image/B16061_02_52.jpg" alt="Figure 2.52: Amazon Textract Analyze document screen with the sample tax document Forms tab showing the key value&#13;&#10;"/></div><p class="figure-caption">Figure 2.52: Amazon Textract Analyze document screen with the sample tax document Forms tab showing the key value</p></li>
				<li>The <strong class="source-inline">Tables</strong> tab is also interesting. Textract was able to extract two tables—the top and the bottom portion—but was not able to extract the middle one:<div id="_idContainer128" class="IMG---Figure"><img src="image/B16061_02_53.jpg" alt="Figure 2.53: Amazon Textract Analyze document screen &#13;&#10;with the sample tax form showing Tables (form)&#13;&#10;"/></div><p class="figure-caption">Figure 2.53: Amazon Textract Analyze document screen with the sample tax form showing Tables (form)</p></li>
				<li>You can see the extracted fields in a table format by clicking the <strong class="source-inline">Tables</strong> tab:<div id="_idContainer129" class="IMG---Figure"><img src="image/B16061_02_54.jpg" alt="Figure 2.54: Amazon Textract Analyze document screen &#13;&#10;with the sample tax form showing Tables (extracted)&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 2.54: Amazon Textract Analyze document screen with the sample tax form showing Tables (extracted)</p>
			<p>Now that you have a feel for what Textract can do, another useful exercise would be to develop a loan processing pipeline using Lambda. When page 1 of US Tax 1040 is dropped into an S3 bucket as a JPEG file, trigger a Lambda that takes the file and invokes Textract and stores the key-value file as a CSV in another bucket. If you feel adventurous, you can develop another Lambda downstream of Textract that gets triggered when the output file is created, and it can either alert a loan officer via SMS or a queue or even a mobile app alert.</p>
			<h1 id="_idParaDest-82"><a id="_idTextAnchor083"/>Summary</h1>
			<p>In this chapter, we started with high-level concepts around Amazon AI services and serverless computing. On a conceptual level, you learned about serverless computing as well as the various AI services available on the AWS platform.</p>
			<p>Overall, the culmination of these independent functions provides the foundation for building complex machine learning-based NLP applications (for example, Siri, Alexa, and so on). Knowing how and why the individual functions operate will allow you to build your own AWS-based NLP applications.</p>
			<p>Then, we dived into the details of Amazon Comprehend—how Comprehend's <strong class="source-inline">DetectDominantLanguage</strong> method is structured, and how to pass in both strings and a list of strings. You learned how to extract entities, sentiments, key phrases, and topics, which provide the data for complex NLP. This allows Amazon Comprehend to become more efficient by automating text analysis upon a text document that's been uploaded to S3.</p>
			<p>You also learned how to use Amazon Textract to extract structured information (tables and key-value pairs) out of scanned documents as a prelude to process automation.</p>
			<p>In the next chapter, we will explore topic modeling and perform theme extraction.</p>
		</div>
	</body></html>