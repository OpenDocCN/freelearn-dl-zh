<html><head></head><body>
		<div><div></div>
		</div>
		<div><h1 id="_idParaDest-53"><a id="_idTextAnchor053"/>2. Analyzing Documents and Text with Natural Language Processing</h1>
		</div>
		<div><p class="callout-heading">Overview</p>
			<p class="callout">This chapter describes the use of Amazon Comprehend to summarize text documents and create Lambda functions to analyze the texts. You will learn how to develop services by applying the serverless computing paradigm, and use Amazon Comprehend to examine texts to determine their primary language. You will extract information such as entities (people or places), key phrases (noun phrases that are indicative of the content), emotional sentiments, and topics from a set of documents.</p>
			<p class="callout">By the end of this chapter, you will able to set up a Lambda function to process and analyze imported text using Comprehend and extract structured information from scanned paper documents using Amazon Textract.</p>
			<h1 id="_idParaDest-54"><a id="_idTextAnchor054"/>Introduction</h1>
			<p>Since 2005, when Amazon formally launched its <strong class="bold">Elastic Compute Cloud</strong> (<strong class="bold">EC2</strong>) web service, cloud computing has grown from a developer service to mission-critical infrastructure. The spectrum of applications is broad—most highly scalable consumer platforms such as Netflix are based on AWS, and so are many pharmaceuticals and genomics, as well as organizations such as the BBC and The Weather Channel, BMW, and Canon. As of January 2020, there are about 143 distinct AWS services spanning 25 categories, from compute and storage to quantum technologies, robotics, and machine learning. In this book, we will cover a few of them, as shown in the following diagram:</p>
			<div><div><img src="img/B16061_02_01.jpg" alt="Figure 2.1: Amazon AI services covered&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.1: Amazon AI services covered</p>
			<div><div><img src="img/B16061_02_Inline_image1.jpg" alt="a"/>
				</div>
			</div>
			<p><strong class="bold">S3</strong> is the versatile object store that we use to store the inputs to our AI services as well as the outputs from those services. You have been working with S3 since <em class="italic">Chapter 1</em>, <em class="italic">An Introduction to AWS</em>.</p>
			<div><div><img src="img/B16061_02_Inline_image2.jpg" alt="b"/>
				</div>
			</div>
			<p><strong class="bold">Lambda</strong> is the glue service that makes serverless computing possible. You will use Lambda later in this chapter to analyze text using Comprehend.</p>
			<div><div><img src="img/B16061_02_Inline_image3.jpg" alt="c"/>
				</div>
			</div>
			<p><strong class="bold">API Gateway</strong> is a delivery service that can enable you to create microservices that can be accessed by various clients, such as web, mobile, and server applications, via internet protocols such as HTTP, WebSocket, and REST. API Gateway gives you the ability to expose your microservices in a secure and scalable way. In the age of microservices and the "API-first" approach, the greatest challenge is the creation, publishing, monitoring, and maintenance of API endpoints. Almost all AWS services are APIs and use the API Gateway infrastructure.</p>
			<p>Amazon's machine learning services, the main focus of our book, are a set of 16 services as of January 2020. They are also called AI services, and currently, the terms are interchangeable. Let's take a quick look at the ones we are interested in.</p>
			<div><div><img src="img/B16061_02_Inline_image4.jpg" alt="d"/>
				</div>
			</div>
			<p><strong class="bold">Comprehend</strong>, the topic of this chapter, is a very versatile text analytics service. It performs a variety of tasks—keyphrase extraction, sentiment analysis (positive, negative, neutral, or mixed), syntax analysis, entity recognition, medical <strong class="bold">Named Entity Recognition</strong> (<strong class="bold">NER</strong>), language detection, and topic modeling. You will see this in action later in this chapter.</p>
			<div><div><img src="img/B16061_02_Inline_image5.jpg" alt="e"/>
				</div>
			</div>
			<p><strong class="bold">Lex</strong> is a platform for building conversational AI, bots, or intelligent assistants. Conversational AI capabilities such as <strong class="bold">automatic speech recognition</strong> (<strong class="bold">ASR</strong>) and <strong class="bold">natural language understanding</strong> (<strong class="bold">NLU</strong>) are built into the Lex framework. Lex provides a very intuitive object model consisting of bots, utterances, slots, and sessions, as well as integration with Amazon Lambda, thus enabling you to develop interesting, intelligent bots in a serverless environment. We will see more of Lex in <em class="italic">Chapter 4</em>, <em class="italic">Conversational Artificial Intelligence</em>.</p>
			<div><div><img src="img/B16061_02_Inline_image6.jpg" alt="f"/>
				</div>
			</div>
			<p><strong class="bold">Personalize</strong> is a very useful service that allows you to personalize your bots. For example, incorporating personalized recommendations/content delivery, personalized searching based on previous interactions, or even personalized notifications and marketing based on user behavior! While we will not be using Amazon Personalize in this book, we wanted to bring your attention to services closely related to the ones covered in this book. That way, you can add extremely rich features as you expand the power of your bots and NLP services.</p>
			<div><div><img src="img/B16061_02_Inline_image7.jpg" alt="g"/>
				</div>
			</div>
			<p><strong class="bold">Polly</strong> is a text-to-speech service using <strong class="bold">neural text-to-speech</strong> (<strong class="bold">NTTS</strong>) technologies. It is very flexible and powerful, offering two styles: a newscaster reading style and a normal conversational style. The voice need not be monotone—Amazon Polly supports <strong class="bold">Speech Synthesis Markup Language</strong> (<strong class="bold">SSML</strong>), which enables you to adjust the speaking style, volume, speech rate, pitch, phrasing, emphasis, intonation, and other characteristics.</p>
			<div><div><img src="img/B16061_02_Inline_image8.jpg" alt="h"/>
				</div>
			</div>
			<p><strong class="bold">Textract</strong>, as the name implies, extracts text from documents. It is an <strong class="bold">optical character recognition</strong> (<strong class="bold">OCR</strong>) solution that is suitable for process automation. It can extract key-value pairs or tables from documents such as tax forms, legal documents, medical forms, bank forms, patent registration, and so forth.</p>
			<div><div><img src="img/B16061_02_Inline_image9.jpg" alt="i"/>
				</div>
			</div>
			<p><strong class="bold">Transcribe</strong> is a speech-to-text <strong class="bold">Automatic Speech Recognition</strong> (<strong class="bold">ASR</strong>) service and is very versatile; for example, it can recognize multiple speakers and you can filter out words. It is very useful in medical transcription, for time-stamped subtitle generation, and for transcribing customer interactions. </p>
			<div><div><img src="img/B16061_02_Inline_image10.jpg" alt="j"/>
				</div>
			</div>
			<p><strong class="bold">Translate</strong> is another very useful service that's able to translate more than 50 languages in a scalable, real-time fashion. </p>
			<div><div><img src="img/B16061_02_Inline_image11.jpg" alt="k"/>
				</div>
			</div>
			<p><strong class="bold">Rekognition</strong>, of course, is a visual analysis and image detection service capable of a variety of tasks, such as facial recognition, video analysis, object detection, and recognizing text in images. <em class="italic">Chapter 6</em>, <em class="italic">Computer Vision and Image Processing</em> is dedicated to Amazon Rekognition.</p>
			<div><div><img src="img/B16061_02_Inline_image12.jpg" alt="l"/>
				</div>
			</div>
			<p>Unlike the AI services we have looked at so far in this chapter, <strong class="bold">Amazon Connect</strong> is a very feature-rich contact center application. It consists of an omnichannel cloud contact center with high-quality audio, web/mobile secure chat, and a web-based contact control panel. The Contact Lens for Amazon Connect is a set of Contact center analytics services that adds capabilities such as full-text search and sentiment analysis, with forthcoming features such as theme detection and custom vocabulary. The integration with Amazon Lex for chatbots is an interesting capability where we can leverage the flexibility of Lex to create intelligent and useful bots.</p>
			<div><div><img src="img/B16061_02_Inline_image13.jpg" alt="m"/>
				</div>
			</div>
			<p><strong class="bold">Amazon Alexa</strong>, of course, is a platform for a conversational interface as well as a set of hardware devices such as smart speakers that leverage the Alexa service to become smart assistants. </p>
			<p>The reason for including customer engagement platforms such as Connect and Alexa is to show the wider possibilities of the work we are doing in this book. While we will not be directly showing how to develop bots for an Amazon Connect or Amazon Alexa-based bot <strong class="bold">voice user interface</strong> (<strong class="bold">VUI</strong>), we want to open your mind to the possibility of an omnichannel customer experience across different integration points—web, mobile, smart speakers, and so forth.</p>
			<p>As you can see, the services cover a wide variety of layers, from the storage and infrastructure layer to the AI services layer, and finally extending to the UX.</p>
			<h1 id="_idParaDest-55"><a id="_idTextAnchor055"/>Serverless Computing</h1>
			<p>Serverless computing is a relatively new architecture that takes a different spin on the cloud application architecture. Let's start with a traditional on-premise server-based architecture.</p>
			<p>Usually, a traditional application architecture starts with a set of computer hardware, a host operating system, virtualization, containers, and an application stack consisting of libraries and frameworks tied together by networking and storage. On top of all this, we write business logic. In essence, to maintain a business capability, we have to maintain the server hardware, operating system patches, updates, library updates, and so forth. We also have to worry about scalability, fault tolerance, and security at the least. </p>
			<p>With cloud computing, the application architecture is free of computer hardware as well as having elasticity. We still have to maintain the OS, libraries, patches, and so on. This where serverless computing comes in—in the words of Amazon, serverless computing "shifts more of your operational responsibilities to AWS."</p>
			<p>Serverless computing improves upon cloud computing, eliminating infrastructure management, starting from provisioning to scaling up and down, depending on the load, as well as the patching and maintenance of the whole runtime stack. As Amazon depicts it, serverless computing definitely "reduces cost and increases agility and innovation" as well as enabling automated high availability, if designed properly. </p>
			<p>An O'Reilly report defines serverless computing as "an architectural approach to software solutions that relies on small independent functions running on transient servers in an elastic runtime environment." So, there are servers—serverless is not the right term, but in some sense, the servers are transparent, managed by Amazon during the execution of a Lambda function, which is usually in milliseconds.</p>
			<h2 id="_idParaDest-56"><a id="_idTextAnchor056"/>Amazon Lambda and Function as a Service</h2>
			<p>Essentially, serverless computing is enabled by functions, more precisely, <strong class="bold">Function as a Service</strong> (<strong class="bold">FaaS</strong>). Amazon Lambda is the prime example of an enabling platform for serverless computing.</p>
			<p>You write the business logic as a set of Lambda functions that are event-driven, stateless, fault-tolerant, and autoscaling. A Lambda function has an upstream side and a downstream side—it responds to upstream events; the runtime processor executes the embedded code and the results are sent to downstream destinations. The upstream events could be generated by something put into a queue or something that is dropped into an S3 bucket or a <strong class="bold">Simple Notification Service</strong> (<strong class="bold">SNS</strong>) message. And the downstream can be S3 buckets, queues, DynamoDB, and so forth. The runtime supports multiple languages, such as Python, Go, Java, Ruby, Node.js, and .NET.</p>
			<p>A Lambda function is much more granular than a microservice—you can think of it as a nano service. It is charged on a 100 ms basis and will time out after 15 minutes. The payload size is 6 MB. That gives you an estimate of the size of a Lambda function. Also, as you have noticed, there are no charges when a Lambda function is idling – that means we can scale down to zero. And you can implement data parallelism easily—trigger a Lambda function for each row of data. As one Lambda function can trigger another Lambda function, you can even do task parallelism. Of course, all of this requires careful architecture, but it's worth the effort.</p>
			<p>Amazon's serverless platform covers compute, storage, networking, orchestration, API proxy, analytics, and developer tooling. We will look at some of these components—Lambda for compute, S3 for storage, API Gateway for networking.</p>
			<h2 id="_idParaDest-57"><a id="_idTextAnchor057"/>Serverless Computing as an Approach</h2>
			<p>Industry analysts and technologists consider serverless computing as an approach and a set of principles. Amazon Lambda is not serverless computing but an enabler of the approach. The serverless computing architecture does reduce what you have to build—some of the traditional code that we write now manifests as a function chaining pipeline, the configuration of events, triggers, and attributes of Lambda functions. The essential business logic does need to be written, and that will reside inside the Lambda functions. As a result, there is a very well-defined separation between the platform and the business code, and that is the value of serverless computing.</p>
			<h1 id="_idParaDest-58"><a id="_idTextAnchor058"/>Amazon Comprehend</h1>
			<p>Amazon Comprehend is a text analytics service. It has a broad spectrum of capabilities. Amazon Comprehend can extract key phrases and entities. It can do language detection and topic modeling. It can also perform sentiment analysis as well as syntax analysis. Amazon Comprehend is multilingual. Some of the applications of Amazon Comprehend include:</p>
			<ul>
				<li>Understanding the main themes and topics of various unstructured text items such as support tickets, social media posts, customer feedback, customer complaints, and business documents such as contracts and medical records.</li>
				<li>Knowledge management by categorizing business documents such as internal procedures, white papers, notes and descriptions, media posts, and emails.</li>
				<li>Brand monitoring—effectively responding to social media posts, reviews, and other user-generated content from various channels. Respond faster by prioritizing the content as well as routing the content to the appropriate person or process. To prioritize and respond faster, businesses need to analyze the content for language, topics, and the entities mentioned in the media – all of which are capabilities of Amazon Comprehend.</li>
				<li>One important capability of Comprehend is the fact that underneath the hood, it improves models by monitoring errors and training AI models with new and improved data. </li>
				<li>Also, you can fine-tune models with your domain-specific data, thus increasing the accuracy to fit your application while leveraging the general capability of the AI models.</li>
				<li>One interesting application of Comprehend is to extract information from business documents such as contract numbers, terms of contracts, various codes, and even the dosage of medication</li>
			</ul>
			<p>An interesting end-to-end use case is to use Amazon Comprehend to analyze a collection of text documents and organize the articles by topic, identify the most frequently mentioned features, and group articles by subject matter, to enable personalized recommendations for website visitors.</p>
			<div><div><img src="img/B16061_02_02.jpg" alt="Figure 2.2: Amazon Comprehend search flow&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.2: Amazon Comprehend search flow</p>
			<p><strong class="bold">Amazon Comprehend Medical</strong> is a feature-rich service for analyzing patient health records, doctor's notes, and reports from clinical trials as well as links to medical ontologies. It can even figure out medication dosages, test results, and treatment information that can be used for analysis by healthcare professionals:</p>
			<div><div><img src="img/B16061_02_03.jpg" alt="Figure 2.3: Amazon Comprehend Medical flow&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.3: Amazon Comprehend Medical flow</p>
			<p>The Amazon Comprehend service continually learns from new data from Amazon product descriptions and consumer reviews, and thus, it perpetually improves its ability to understand a variety of topics from government, health, media, education, advertising, and so on.</p>
			<p>In <em class="italic">Chapter 1</em>, <em class="italic">An Introduction to AWS</em>, you learned how to use Amazon Comprehend to extract insights by using <strong class="bold">Natural Language Processing</strong> <strong class="bold">(NLP)</strong> from the contents of documents. In this chapter, we will dig deeper and you will learn how to use the Amazon Comprehend API to produce insights by recognizing the language, entities, key phrases, sentiments, and topics in a document. This will allow you to understand deep learning-based NLP to build more complex applications, which we will cover further.</p>
			<p>In the second part of this chapter, you will learn about AWS Lambda, and how to integrate this service with Amazon Comprehend. You will also integrate a database to provide the foundation to build scalable NLP processing applications.</p>
			<h1 id="_idParaDest-59"><a id="_idTextAnchor059"/>What Is an NLP Service?</h1>
			<p>Amazon Comprehend is an NLP service. The overall goal of an NLP service is to make machines understand our spoken and written language. Virtual assistants, such as Alexa or Siri, use NLP to produce insights from input data. The input data is structured by a language, which has a unique grammar, syntax, and vocabulary. Thus, processing text data requires identifying the language first and applying subsequent rules to identify the document's information. NLP's general task is to capture this information as a numeral representation. This general task is split into specific tasks, such as identifying languages, entities, key phrases, emotional sentiments, and topics.</p>
			<div><div><img src="img/B16061_02_04.jpg" alt="Figure 2.4: Amazon Comprehend data flow &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.4: Amazon Comprehend data flow </p>
			<p>As we discussed earlier, Amazon Comprehend uses pre-trained models to perform document analysis tasks. This is very good because it enables a business to develop capabilities without going through an exhaustive AI model training effort. And Amazon keeps up with the latest developments in ML and AI, constantly retraining the models—so the models get better without any work from users. Also, there are capabilities for fine-tuning the models by training them with your domain-specific content.</p>
			<h1 id="_idParaDest-60"><a id="_idTextAnchor060"/>Using Amazon Comprehend to Inspect Text and Determine the Primary Language</h1>
			<p>Amazon Comprehend is used for searching and examining texts and then gathering insights from a variety of topics (health, media, telecom, education, government, and so on) and languages in the text data format. Thus, the first step to analyze text data and utilize more complex features (such as topic, entity, and sentiment analysis) is to determine the dominant language. Determining the dominant language ensures the accuracy of more in-depth analysis. To examine the text in order to determine the primary language, there are two operations (<code>DetectDominantLanguage</code> and <code>BatchDetectDominantLanguage</code>).</p>
			<p>Both operations expect the text in the UTF-8 format with a length of at least 20 characters and a maximum of 5,000 bytes. If you are sending a list, it should not contain more than 25 items.</p>
			<p>The response includes what language was identified using a two-letter code. The following table shows the language codes for different languages:</p>
			<p class="callout-heading">Note</p>
			<p class="callout">Check out <a href="https://docs.aws.amazon.com/comprehend/latest/dg/how-languages.html">https://docs.aws.amazon.com/comprehend/latest/dg/how-languages.html</a> for an updated list of the supported languages.</p>
			<div><div><img src="img/B16061_02_05.jpg" alt="Figure 2.5: Amazon Comprehend's supported languages&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.5: Amazon Comprehend's supported languages</p>
			<p>There are three ways to invoke dominant language detection. The result is the code for the dominant language in the content and a confidence score determined by the Comprehend algorithms:</p>
			<ul>
				<li><code>DetectDominantLanguage</code> will return the dominant language in a single document.</li>
				<li><code>BatchDetectDominantLanguage</code> works on a set of documents and will return a list of the dominant language in each of the documents.</li>
				<li>While both of the preceding APIs work in synchronous mode, that is, you send the content to the API and it will return the results, <code>StartDominantLanguageDetectionJob</code> works on a collection of jobs asynchronously. This API is well suited to large jobs that take more time.</li>
			</ul>
			<div><div><img src="img/B16061_02_06.jpg" alt="Figure 2.6: Dominant language score confidence output&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.6: Dominant language score confidence output</p>
			<h2 id="_idParaDest-61"><a id="_idTextAnchor061"/>Exercise 2.01: Detecting the Dominant Language in a Text Document Using the Command-Line Interface</h2>
			<p>In this exercise, you will learn how to detect the dominant language in a text using Comprehend's <code>DetectDominantLanguage</code> function. The following steps describe how to detect the dominant language:</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The source code for the Jupyter notebook is available via GitHub in the repository at <a href="https://packt.live/2O4cw0V">https://packt.live/2O4cw0V</a>.</p>
			<p class="callout">The files for this chapter are located in the <code>Chapter02</code> folder in the GitHub repository <a href="https://packt.live/31TIzbU">https://packt.live/31TIzbU</a>. As we mentioned in <em class="italic">Chapter 1</em>, <em class="italic">An Introduction to AWS</em>, you should have downloaded the GitHub files into a local subdirectory. </p>
			<p class="callout">As an example, we have downloaded the files in the <code>Documents/aws-book/The-Applied-AI-and-Natural-Language-Processing-with-AWS</code> directory.</p>
			<ol>
				<li>Open a new Jupyter Notebook.<p class="callout-heading">Note</p><p class="callout">For configuration instructions, refer the section titled <em class="italic">Pre checkup</em> on GitHub: <a href="https://packt.live/2O4cw0V">https://packt.live/2O4cw0V</a>.</p></li>
				<li>Before we begin, the <code>boto3</code> library must be installed. On a fresh Jupyter Notebook cell, type in the following command to install it:<pre>!pip install boto3  </pre></li>
				<li>Now, let's go ahead and import Boto3. Boto3 is nothing but the AWS SDK for Python. (<a href="https://boto3.amazonaws.com/v1/documentation/api/latest/index.html">https://boto3.amazonaws.com/v1/documentation/api/latest/index.html</a>):<pre>import boto3</pre></li>
				<li>Then, import the JSON module to serialize the JSON (<a href="https://docs.python.org/3.6/library/json.html">https://docs.python.org/3.6/library/json.html</a>):<pre>import json</pre></li>
				<li>Instantiate a new Comprehend client:<pre>comprehend = boto3.client(service_name='comprehend')</pre></li>
				<li>Next, we assign English and Spanish strings to be analyzed by Comprehend:<pre>english_string = 'Machine Learning is fascinating.'
spanish_string = 'El aprendizaje automático es fascinante.'</pre></li>
				<li>Next, we print a string to indicate the respective variable that our script is about to execute: <pre>print('Calling DetectDominantLanguage')
print('english_string result:')</pre></li>
				<li>Lastly, call Comprehend's <code>detect_dominant_language</code> method with the <code>english_string</code> and <code>spanish_string</code> variables (<a href="https://docs.aws.amazon.com/comprehend/latest/dg/API_DetectDominantLanguage.html">https://docs.aws.amazon.com/comprehend/latest/dg/API_DetectDominantLanguage.html</a>).<p><code>json.dumps()</code> writes the JSON data to a Python string in the terminal:</p><pre>print('\n English string result:')
print(json.dumps(comprehend.detect_dominant_language\
                (Text = english_string), sort_keys=True, \
                indent=4))
print('\n spanish_string result:')
print(json.dumps(comprehend.detect_dominant_language\
                (Text = spanish_string), sort_keys=True, \
                indent=4))
print('End of DetectDominantLanguage\n')
\</strong> ) to split the logic across multiple lines. When the code is executed, Python will ignore the backslash, and treat the code on the next line as a direct continuation of the current line.</pre></li>
				<li>Save the notebook.</li>
				<li>Press <em class="italic">Shift</em> + <em class="italic">Enter</em> to run the two notebook cells. Executing the cells will produce the following output (see the following screenshot):<div><img src="img/B16061_02_07.jpg" alt="Figure 2.7: Detecting the dominant language output – English and Spanish&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 2.7: Detecting the dominant language output – English and Spanish</p>
			<p>As expected, the <code>english_text</code> string is identified as English (with the <code>en</code> language code) with a ~0.99 confidence score.</p>
			<p>Also as expected, the <code>spanish_text</code> string is identified as Spanish (with the <code>es</code> language code) with a ~0.99 confidence score.</p>
			<h2 id="_idParaDest-62"><a id="_idTextAnchor062"/>Exercise 2.02: Detecting the Dominant Language in Multiple Documents by Using the CLI</h2>
			<p>In this exercise, you will learn how to use Comprehend's <code>DetectDominantLanguage</code> operation for multiple documents. The following steps describe how to detect the dominant language:</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The <em class="italic">Pre checkup instructions</em> and the source code for this exercise are available via GitHub in the repository at <a href="https://packt.live/2Z8Vbu4">https://packt.live/2Z8Vbu4</a>.</p>
			<ol>
				<li value="1">Open a new Jupyter Notebook. </li>
				<li>On a fresh empty cell, import the AWS SDK for Python (boto3:<a href="https://boto3.amazonaws.com/v1/documentation/api/latest/index.html">https://boto3.amazonaws.com/v1/documentation/api/latest/index.html</a>): <pre>import boto3</pre></li>
				<li>Then, import the JSON module to serialize the JSON (<a href="https://docs.python.org/3.6/library/json.html">https://docs.python.org/3.6/library/json.html</a>):<pre>import json</pre></li>
				<li>Instantiate a new Comprehend client:<pre>comprehend = boto3.client(service_name='comprehend')</pre></li>
				<li>Next, assign a list of English and Spanish strings to be analyzed by Comprehend:<pre><strong class="bold">english_string_list</strong> = \
['Machine Learning is fascinating.', \
 'Studying Artificial Intelligence is my passion.']
<strong class="bold">spanish_string_list</strong> = \
['El aprendizaje automático es fascinante.', \
 'Estudiar Inteligencia Artificial es mi pasión.']</pre></li>
				<li>Lastly, we call Comprehend's <code>batch_detect_dominant_language</code> method with the <code>english_string_list</code> and <code>spanish_string_list</code> variables (<a href="https://docs.aws.amazon.com/comprehend/latest/dg/API_DetectDominantLanguage.html">https://docs.aws.amazon.com/comprehend/latest/dg/API_DetectDominantLanguage.html</a>). Then, <code>json.dumps()</code> writes the JSON data to a Python string to the terminal:<pre>print('Calling BatchDetectDominantLanguage')
print('english_string_list results:')
print(json.dumps(comprehend.batch_detect_dominant_language\
                (TextList=english_string_list), \
                sort_keys=True, indent=4))
print('\nspanish_string_list results:')
print(json.dumps(comprehend.batch_detect_dominant_language\
                (TextList=spanish_string_list), \
                sort_keys=True, indent=4))
print('End of BatchDetectDominantLanguage\n')</pre></li>
				<li>Save the notebook.</li>
				<li>Press <em class="italic">Shift</em> + <em class="italic">Enter</em> to run the two notebook cells. Executing the cells will produce the following output (see the following partial screenshot—the output is too long to fit; you can see the full output in the notebook):<div><img src="img/B16061_02_08.jpg" alt="Figure 2.8: Detecting the dominant language (multiple documents) output—English &#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 2.8: Detecting the dominant language (multiple documents) output—English </p>
			<p>The important concepts to remember are that Comprehend has the ability to detect different languages and can take text input as a single string or in a batch format as a list of strings.</p>
			<p>In this topic, we reviewed how Comprehend's <code>DetectDominantLanguage</code> method is structured, and how to pass in both strings and a list of strings. Next, we will extract entities, phrases, and sentiments from a set of documents.</p>
			<h1 id="_idParaDest-63"><a id="_idTextAnchor063"/>Extracting Information from a Set of Documents</h1>
			<p>At a business level, knowing if and why a customer is angry or happy when they contact a virtual assistant is extremely important, to retain the customer. At an NLP level, this requires more information to be extracted and a more complex algorithm. The additional information to extract and quantify is <code>entities</code>, <code>key phrases</code>, <code>emotional sentiment</code>, and <code>topics</code>.</p>
			<h2 id="_idParaDest-64"><a id="_idTextAnchor064"/>Detecting Named Entities—AWS SDK for Python (boto3)</h2>
			<p>An entity is a broader concept—it is something that has an identity of its own. An entity can be a person or a place, a company name or an organization; it can also be a number (say quantity, price, number of days) or a date, a title, a policy number, or a medical code. For example, in the text "Martin lives at 27 Broadway St.", <strong class="bold">Martin</strong> might be detected as a <strong class="bold">PERSON</strong>, while <strong class="bold">27 Broadway St</strong> might be detected as a <strong class="bold">LOCATION</strong>.</p>
			<p>Entities also have a score to indicate the confidence level that the entity type was detected correctly. The following table shows a complete list of entity types and descriptions:</p>
			<div><div><img src="img/B16061_02_09.jpg" alt="Figure 2.9: AWS Comprehend entity types and descriptions&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.9: AWS Comprehend entity types and descriptions</p>
			<p>There are three ways to invoke the detection of entities:</p>
			<ul>
				<li><code>DetectEntities</code> will return the entities in a single document.</li>
				<li><code>BatchDetectEntities</code> works on a set of documents and will return a list of the entities in each of the documents.</li>
				<li>While both the preceding APIs work in synchronous mode, that is, you send the content to the API and it will return the results, <code>StartEntitiesDetectionJob</code> works on a collection of jobs asynchronously. This API is well suited to large jobs that take more time.</li>
			</ul>
			<h2 id="_idParaDest-65"><a id="_idTextAnchor065"/>DetectEntities – Input and Output</h2>
			<p><code>DetectEntities</code> takes a <code>LanguageCode</code> and a string of text as an input and then provides the following information about each entity within the input text: <code>BeginOffset</code>, <code>EndOffset</code>, <code>Score</code>, <code>Text</code>, and <code>Type</code>. The following table shows a complete list of AWS Comprehend <code>DetectEntities</code>, types, and descriptions:</p>
			<div><div><img src="img/B16061_02_10.jpg" alt="Figure 2.10: AWS Comprehend entity types and descriptions&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.10: AWS Comprehend entity types and descriptions</p>
			<h2 id="_idParaDest-66"><a id="_idTextAnchor066"/>Exercise 2.03: Determining the Named Entities in a Document (the DetectEntities method)</h2>
			<p>In this exercise, we will determine the named entities in a document. For this, we will use Amazon Comprehend's <code>DetectEntities</code> operation. The following are the steps for detecting named entities:</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The <em class="italic">Pre checkup instructions</em> and the source code for this exercise are available via GitHub in the repository at <a href="https://packt.live/2ADssUI">https://packt.live/2ADssUI</a>.</p>
			<ol>
				<li value="1">Open a new Jupyter Notebook.</li>
				<li>Import the AWS SDK for Python (boto3: <a href="https://boto3.amazonaws.com/v1/documentation/api/latest/index.html">https://boto3.amazonaws.com/v1/documentation/api/latest/index.html</a>) by using the following command:<pre>import boto3</pre></li>
				<li>Now, import the <code>JSON</code> module to serialize <code>JSON</code> from <a href="https://docs.python.org/3.6/library/json.html">https://docs.python.org/3.6/library/json.html</a> by using the following command: <pre>import json</pre></li>
				<li>Now, instantiate a new Comprehend client:<pre>comprehend = boto3.client(service_name='comprehend')</pre></li>
				<li>Now, after instantiating a new Comprehend client, provide the <code>English</code> text to analyze: <pre>english_string = "I study Machine Learning in "\
                 "Seattle on Thursday."
print('Calling DetectEntities')</pre></li>
				<li>Now, <code>json.dumps()</code> writes JSON data to a Python string: <pre>print(json.dumps(comprehend.detect_entities\
                (Text = english_string, LanguageCode='en'), \
                sort_keys=True, indent=4))
print('End of DetectEntities\n')</pre></li>
				<li>Press <em class="italic">Shift</em> + <em class="italic">Enter</em> to run the two notebook cells. The output of the preceding code is shown in the following screenshot:<div><img src="img/B16061_02_11.jpg" alt="Figure 2.11: AWS Comprehend DetectEntities output&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 2.11: AWS Comprehend DetectEntities output</p>
			<p>The confidence scores were both ~0.99, as the inputs were simple examples. As expected, <code>Seattle</code> was detected as a <code>LOCATION</code>, and <code>Thursday</code> was detected as a <code>DATE</code>:</p>
			<div><div><img src="img/B16061_02_12.jpg" alt="Figure 2.12: AWS Comprehend BeginOffset and EndOffset review&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.12: AWS Comprehend BeginOffset and EndOffset review</p>
			<h2 id="_idParaDest-67"><a id="_idTextAnchor067"/>Exercise 2.04: Detecting Entities in a Set of Documents (Text Files)</h2>
			<p>In this exercise, we will determine the named entities in multiple documents. For this, we will use Amazon Comprehend's <code>DetectEntities</code> operation. The following are the steps for detecting the named entities from a set of documents:</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The <em class="italic">Pre checkup instructions</em> and the source code for this exercise are available via GitHub in the repository at <a href="https://packt.live/31UCuMs">https://packt.live/31UCuMs</a>.</p>
			<ol>
				<li value="1">Open a new Jupyter Notebook.</li>
				<li>Import the AWS SDK for Python (boto3: <a href="https://boto3.amazonaws.com/v1/documentation/api/latest/index.html">https://boto3.amazonaws.com/v1/documentation/api/latest/index.html</a>) by using the following command:<pre>import boto3</pre></li>
				<li>Now, import the <code>JSON</code> module to serialize <code>JSON</code> from <a href="https://docs.python.org/3.6/library/json.html">https://docs.python.org/3.6/library/json.html</a> by using the following command:<pre>import json</pre></li>
				<li>We also need to do some file operations to iterate through the documents. Import the <code>glob</code> module to find text files ending <code>.txt</code> from <a href="https://docs.python.org/3.6/library/glob.html">https://docs.python.org/3.6/library/glob.html</a> by using the following command:<pre>import glob</pre></li>
				<li>We also need the <code>os</code> library. Import the <code>os</code> module from <a href="https://docs.python.org/3.6/library/os.html">https://docs.python.org/3.6/library/os.html</a> by using the following command:<pre>import os</pre></li>
				<li>Now, instantiate a new Comprehend client:<pre>comprehend = boto3.client(service_name='comprehend')</pre><p>Let's get a list of all the documents (assumes in Jupyter notebook you navigated to <code>Chapter02/Exercise02.04/</code> directory and the opened the notebook <code>Exercise2.04.ipynb</code>):</p><pre>data_dir = '<code>review_pos</code> directory. Depending on where you have downloaded and stored the <code>.txt</code> files on your system, the highlighted path must be modified in the code. </pre></li>
				<li>Now, we can iterate through the documents and detect the entities in the documents. We will be calling <code>detect_entities</code> on each of the documents. As before, we will also use <code>json.dumps()</code> to write the JSON data to a Python string:<pre>for file in file_list:
  with open(file, 'r', encoding="utf-8") as f:
    file_as_str = f.read()
    # python string formatting to print the text file name
    print('Calling detect_entities_from_documents.py on file: %s' \
          % file[-15:])
    # json.dumps() writes JSON data to a Python string
    print(json.dumps(comprehend.detect_entities\
                    (Text = file_as_str, LanguageCode='en'), \
                    sort_keys=True, indent=4))
    print('End of detect_entities\n')</pre></li>
				<li>Press <em class="italic">Shift</em> + <em class="italic">Enter</em> to run the two notebook cells. The output of the preceding code is shown in the following screenshot. It is a long output—we are showing the output for one file. You will see the entities listed for all the files in the <code>/reviews__pos/*.txt</code> subdirectory:<div><img src="img/B16061_02_13.jpg" alt="Figure 2.13: DetectEntities output&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 2.13: DetectEntities output</p>
			<p>In this exercise, we extended entity detection to a set of documents, calling Amazon Comprehend's <code>DetectEntities</code> recursively.</p>
			<h2 id="_idParaDest-68"><a id="_idTextAnchor068"/>Detecting Key Phrases</h2>
			<p>A key phrase for AWS is analogous to a noun phrase, which represents an actual thing. In English, when we put together different words that represent one concrete idea, we call it a noun phrase. </p>
			<p>For example, <strong class="bold">A fast machine</strong> is a noun phrase because it consists of <strong class="bold">A</strong>, the article; <strong class="bold">fast</strong>, an adjective; and <strong class="bold">machine</strong>, which is a noun. AWS looks for appropriate word combinations and gives scores that indicate the confidence that a string is a noun phrase.</p>
			<h2 id="_idParaDest-69"><a id="_idTextAnchor069"/>Exercise 2.05: Detecting Key Phrases</h2>
			<p>In this exercise, we will detect key phrases. To do so, we will use Amazon Comprehend's <code>DetectKeyPhrase</code> operation. The following are the steps for detecting key phrases:</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The <em class="italic">Pre checkup instructions</em> and the source code for this exercise are available via GitHub in the repository at <a href="https://packt.live/2Z75cI4">https://packt.live/2Z75cI4</a>.</p>
			<ol>
				<li value="1">Import the AWS SDK for Python (boto3: <a href="http://boto3.readthedocs.io/en/latest/">http://boto3.readthedocs.io/en/latest/</a>) by using the following command:<pre>import boto3</pre></li>
				<li>Now, import the JSON module to serialize the JSON from <a href="https://docs.python.org/3.6/library/json.html ">https://docs.python.org/3.6/library/json.html </a>by using the following command:<pre>import json</pre></li>
				<li>Now, instantiate a new Comprehend client by using the following code:<pre>comprehend = boto3.client(service_name='comprehend')</pre></li>
				<li>Now, provide the <code>English</code> text to analyze using the following code:<pre>english_string = 'robert redfords a river runs through '\
                 'is not a film i watch often. it is a '\
                 'masterpiece, one of the better films of '\
                 'recent years. The acting and direction is '\
                 'top-notch never sappy , always touching.'
print('Calling DetectKeyPhrases')
# json.dumps() writes JSON data to a Python string
print(json.dumps(comprehend.detect_key_phrases\
     (Text = english_string, LanguageCode='en'), \
     sort_keys=True, indent=4))
print('End of DetectKeyPhrases\n')</pre></li>
				<li>Run the code by executing the cells with <em class="italic">Shift</em> + <em class="italic">Enter</em>. You will see the following output:<div><img src="img/B16061_02_14.jpg" alt="Figure 2.14: AWS Comprehend DetectKeyPhrase output&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 2.14: AWS Comprehend DetectKeyPhrase output</p>
			<h2 id="_idParaDest-70"><a id="_idTextAnchor070"/>Detecting Sentiments</h2>
			<p>Amazon Comprehend has the capability to detect sentiments, usually used for social media posts, blog posts, reviews, emails, and other user-generated content. Amazon Comprehend can determine the four shades of sentiment polarity: positive, negative, neutral, and mixed. Mixed sentiment is interesting as it can differentiate between different aspects; for example, a user might like your website but not be thrilled about the price of a product.</p>
			<h2 id="_idParaDest-71"><a id="_idTextAnchor071"/>Exercise 2.06: Conducting Sentiment Analysis</h2>
			<p>In this exercise, we will carry out sentiment analysis. To do so, we will use Amazon Comprehend's <code>DetectSentiment</code> operation. The following are the steps for detecting sentiment:</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The <em class="italic">Pre checkup instructions</em> and the source code for this exercise are available via GitHub in the repository at <a href="https://packt.live/3ebVNU1">https://packt.live/3ebVNU1</a>.</p>
			<ol>
				<li value="1">Open a new Jupyter Notebook.</li>
				<li>Import the <code>AWS SDK</code> for Python (boto3) from <a href="http://boto3.readthedocs.io/en/latest/">http://boto3.readthedocs.io/en/latest/</a> by using the following command:<pre>import boto3</pre></li>
				<li>Now, import the <code>JSON</code> module to serialize JSON from <a href="https://docs.python.org/3.6/library/json.html">https://docs.python.org/3.6/library/json.html</a> by using the following command:<pre>import json</pre></li>
				<li>Now, instantiate a new Comprehend client, using the following code:<pre>comprehend = boto3.client(service_name='comprehend')</pre></li>
				<li>Then, provide a text string to analyze, using the following code:<pre>english_string = 'Today is my birthday, I am so happy.'
print('Calling DetectSentiment')
# json.dumps() #writes JSON data to a Python string
print('english_string results:')
print(json.dumps(comprehend.detect_sentiment\
     (Text = english_string, LanguageCode='en'), \
     sort_keys=True, indent=4))
print('End of DetectSentiment\n')</pre></li>
				<li>Run the code by executing the cells with <em class="italic">Shift</em> + <em class="italic">Enter</em>. The output is as follows:<div><img src="img/B16061_02_15.jpg" alt="Figure 2.15: AWS Comprehend—DetectSentiment output&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 2.15: AWS Comprehend—DetectSentiment output</p>
			<p>In this exercise, we saw how easy it is to perform sentiment analysis using AWS Comprehend. <code>DetectSentiment</code> correctly predicted the sentiment of the statement <em class="italic">Today is my birthday, I am so happy</em> as positive.</p>
			<h1 id="_idParaDest-72"><a id="_idTextAnchor072"/>Setting Up a Lambda Function and Analyzing Imported Text Using Comprehend</h1>
			<p>We have used Amazon Comprehend to do various NLP tasks, such as detecting entities and key phrases and carrying out sentiment analysis.</p>
			<h2 id="_idParaDest-73"><a id="_idTextAnchor073"/>Integrating Comprehend and AWS Lambda for responsive NLP</h2>
			<p>In this topic, we will be integrating AWS Lambda functions with Comprehend, which provides a more powerful, scalable infrastructure. You can use AWS Lambda to run your code in response to events, such as changes to data in an Amazon S3 bucket.</p>
			<p>Executing code in response to events provides a real-world solution for developing scalable software architecture. Overall, this increases our data pipeline and provides the ability to handle more complex big data volumes and NLP operations.</p>
			<h2 id="_idParaDest-74"><a id="_idTextAnchor074"/>What Is AWS Lambda?</h2>
			<p>AWS Lambda is a compute service that runs code without provisioning or managing servers. AWS Lambda executes code only when needed, and scales automatically. AWS Lambda runs your code on a high-availability compute infrastructure, which performs the administration of the compute service. More specifically, AWS Lambda performs the following: server and operating system maintenance, capacity provisioning and automatic scaling, code monitoring, and logging.</p>
			<p>Overall, the goal of AWS Lambda is to make short, simple, modular code segments that you can tie together into a larger processing infrastructure.</p>
			<h2 id="_idParaDest-75"><a id="_idTextAnchor075"/>What Does AWS Lambda Do?</h2>
			<p>Lambda allows users to run small segments of code (Java, Node, or Python) to complete a specific task. These specific tasks can be storing and then executing changes to your AWS setup, or responding to events in S3 (we will explore the latter later in this topic). Before Lambda, you would typically need a separate EC2 server to run your entire code; however, Lambda allows small segments of code to run without the need for EC2.</p>
			<h2 id="_idParaDest-76"><a id="_idTextAnchor076"/>Lambda Function Anatomy</h2>
			<p>AWS Lambda provides two options for implementing Python code. First, you can upload a complete Python code file. Second, you can use the Lambda function editor entirely inline, which means that you can enter and modify the code directly, without having to upload any files to AWS. The code that you enter will be executed when the Lambda function is invoked. The second option will allow for easier testing, so we will use it. </p>
			<p>Let's examine the structure of a Lambda function:</p>
			<ul>
				<li>When you create a function (for example, <code>s3_trigger</code>), AWS creates a folder named the same, with a Python file named <code>Lambda_function.py</code> within the folder. This file contains a stub for the <code>Lambda_handler</code> function, which is the entry point of our Lambda function. The entry point takes two parameters as arguments: The <code>event</code> argument and the <code>context</code> argument.</li>
				<li>The <code>event</code> argument provides the value of the payload, which is sent to the function from the <code>calling</code> process. It typically takes the form of a Python <code>dict</code> type, although it could also be one of <code>list</code>, <code>str</code>, <code>int</code>, <code>float</code>, or <code>NoneType</code>.</li>
				<li>The <code>context</code> argument is of the type <code>LambdaContext</code> and contains runtime information. You will be using this parameter for an exercise in a later section. The return value of the function can be any type that is JSON-serializable. This value gets returned to the calling application, after serializing.</li>
			</ul>
			<p>We will incorporate Lambda, S3, and Amazon Comprehend, to automatically perform document analysis when a text document is uploaded to S3. The architecture of a Lambda function is as follows:</p>
			<div><div><img src="img/B16061_02_16.jpg" alt="Figure 2.16: Architecture diagram&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.16: Architecture diagram</p>
			<h2 id="_idParaDest-77"><a id="_idTextAnchor077"/>Exercise 2.07: Setting Up a Lambda Function for S3</h2>
			<p>In this exercise, we will integrate the following AWS services: S3, Lambda, and Amazon Comprehend. To perform this exercise, the architecture should be recollected. Upload a file (<code>test_s3trigger_configured.txt</code>) to S3 and view the results of Comprehend's analysis. The following are the steps for setting up a Lambda function:</p>
			<p><strong class="bold">Creating the S3 bucket</strong></p>
			<ol>
				<li value="1">You should have an AWS account and have completed the exercises and activities in <em class="italic">Chapter 1</em>, <em class="italic">An Introduction to AWS</em>.</li>
				<li>First, navigate to the Amazon S3 service, <a href="https://console.aws.amazon.com/s3/">https://console.aws.amazon.com/s3/</a>, and click <code>Create bucket</code>:<div><img src="img/B16061_02_17.jpg" alt="Figure 2.17: S3 Bucket creation for the Lambda trigger&#13;&#10;"/></div><p class="figure-caption">Figure 2.17: S3 Bucket creation for the Lambda trigger</p><p>For <code>Bucket name</code>, type <code>aws-ml-s3-trigger</code>, and then click <code>Create</code>:</p><p class="callout-heading">Note</p><p class="callout">Bucket names in AWS have to be unique, otherwise you will get an error "<code>Bucket name already exists</code>". One easy way to get a unique name is to append the bucket name with today's date plus the time, for instance, YYYYMMDDHHMM. While writing this chapter, I created the bucket <code>aws-ml-s3-trigger-202001181023 </code>.</p><div><img src="img/B16061_02_18.jpg" alt="Figure 2.18: Creating an S3 bucket&#13;&#10;"/></div><p class="figure-caption">Figure 2.18: Creating an S3 bucket</p></li>
				<li>Your bucket will be created, and you will be redirected to the bucket list in the <code>S3 buckets</code> screen as shown:<div><img src="img/B16061_02_19.jpg" alt="Figure 2.19: S3 Bucket list screen&#13;&#10;"/></div><p class="figure-caption">Figure 2.19: S3 Bucket list screen</p></li>
				<li>Next, navigate to Amazon Lambda, under <code>Services</code>, and click <code>Lambda</code> under <code>Compute</code>:<div><img src="img/B16061_02_20.jpg" alt="Figure 2.20: Services | Compute | Lambda&#13;&#10;"/></div><p class="figure-caption">Figure 2.20: Services | Compute | Lambda</p></li>
				<li>You will see the Lambda console, as shown here:<div><img src="img/B16061_02_21.jpg" alt="Figure 2.21: Lambda console&#13;&#10;"/></div><p class="figure-caption">Figure 2.21: Lambda console</p></li>
				<li>In the Lambda console, click <code>Create function</code>:<div><img src="img/B16061_02_22.jpg" alt="Figure 2.22: AWS Lambda Create function button&#13;&#10;"/></div><p class="figure-caption">Figure 2.22: AWS Lambda Create function button</p></li>
				<li>Choose <code>Author from scratch</code> from the options. For <code>Name</code>, type <code>s3_trigger</code>:<div><img src="img/B16061_02_23.jpg" alt="Figure 2.23: AWS Lambda—Creating a function with the Author from scratch option&#13;&#10;"/></div><p class="figure-caption">Figure 2.23: AWS Lambda—Creating a function with the Author from scratch option</p></li>
				<li>For the runtime options, choose <code>Python 3.6</code> from the list:<div><img src="img/B16061_02_24.jpg" alt="Figure 2.24: AWS Lambda—Python 3.6 selection&#13;&#10;"/></div><p class="figure-caption">Figure 2.24: AWS Lambda—Python 3.6 selection</p></li>
				<li>Click <code>Choose or create an execution role</code> and choose <code>Create new role from AWS policy template(s)</code> and enter the name <code>s3TriggerRole</code> in the <code>Role name</code> field:<div><img src="img/B16061_02_25.jpg" alt="Figure 2.25: AWS Lambda Create Role template&#13;&#10;"/></div><p class="figure-caption">Figure 2.25: AWS Lambda Create Role template</p></li>
				<li>Click the dropdown in <code>Policy templates</code> and select <code>Amazon S3 object read-only permissions</code>. You will see AWS Lambda Policy template dropdown box, as shown here:<div><img src="img/B16061_02_26.jpg" alt="Figure 2.26: AWS Lambda Policy templates dropdown box&#13;&#10;"/></div><p class="figure-caption">Figure 2.26: AWS Lambda Policy templates dropdown box</p></li>
				<li>Then, click the <code>Create function</code> button to create the Lambda function in AWS. The final AWS Lambda Create function screen looks as follows:<div><img src="img/B16061_02_27.jpg" alt="Figure 2.27: AWS Lambda—Create a function screen&#13;&#10;"/></div><p class="figure-caption">Figure 2.27: AWS Lambda—Create a function screen</p></li>
				<li>You will see the Lambda function designer. There is lot of information displayed. Let's focus on the essentials for this exercise:<div><img src="img/B16061_02_28.jpg" alt="Figure 2.28: AWS Lambda—function designer&#13;&#10;"/></div><p class="figure-caption">Figure 2.28: AWS Lambda—function designer</p></li>
				<li>Click <code>Add trigger</code>, and from the drop-down menu, select <code>S3</code>:<div><img src="img/B16061_02_29.jpg" alt="Figure 2.29: Trigger configuration drop-down menu&#13;&#10;"/></div><p class="figure-caption">Figure 2.29: Trigger configuration drop-down menu</p></li>
				<li>Take a quick look at the options and select <code>Add</code>:<p>The bucket name should be the S3 trigger bucket you created (in my case, it was <code>aws-ml-s3-trigger-202001181023</code>); in the <code>Event type</code> section, <code>All object create events</code> must be selected in the dropdown and <code>Enable Trigger</code> should be checked, as shown here:</p><p class="callout-heading">Note</p><p class="callout">You might get the error "<code>An error occurred when creating the trigger: Configurations overlap. Configurations on the same bucket cannot share a common event type</code>." This would happen if you created a function and deleted it. The easiest way is to delete the event via <code>Services | Storage/S3 | Click the bucket | Properties | Events</code> and deleting the Lambda event. Make sure you click the <code>Save</code> button after deleting the event.</p><div><img src="img/B16061_02_30.jpg" alt="Figure 2.30: Amazon S3 Trigger configuration&#13;&#10;"/></div><p class="figure-caption">Figure 2.30: Amazon S3 Trigger configuration</p><p>You will see S3 on the Lambda <code>Designer</code> screen:</p><div><img src="img/B16061_02_31.jpg" alt="Figure 2.31: Lambda function designer with S3&#13;&#10;"/></div><p class="figure-caption">Figure 2.31: Lambda function designer with S3</p></li>
				<li>Again, choose <code>Add trigger</code> and choose <code>CloudWatch/Events/EventBridge</code>:<div><img src="img/B16061_02_32.jpg" alt="Figure 2.32: Adding the trigger configuration&#13;&#10;"/></div><p class="figure-caption">Figure 2.32: Adding the trigger configuration</p></li>
				<li>Then click the box next to <code>Rule</code>:<div><img src="img/B16061_02_33.jpg" alt="Figure 2.33: Add trigger – creating a new rule&#13;&#10;"/></div><p class="figure-caption">Figure 2.33: Add trigger – creating a new rule</p></li>
				<li>Select <code>Create a new rule</code>. The following screen will be displayed. Type <code>s3_trigger_CWRule</code> for the rule name.<div><img src="img/B16061_02_34.jpg" alt="Figure 2.34: Add Trigger—New Rule Configuration&#13;&#10;"/></div><p class="figure-caption">Figure 2.34: Add Trigger—New Rule Configuration</p></li>
				<li>Choose <code>Event pattern</code> in <code>Rule type</code>. Then select <code>Simple Storage Service (S3)</code> from the dropdown and <code>All events</code> and click <code>Add</code>:<div><img src="img/B16061_02_35.jpg" alt="Figure 2.35: Adding an S3 rule type&#13;&#10;"/></div><p class="figure-caption">Figure 2.35: Adding an S3 rule type</p></li>
				<li>Let's explore the interface a bit more so that you can get comfortable navigating through different pages. Click <code>Functions</code> in the top-left corner:<div><img src="img/B16061_02_36.jpg" alt="Figure 2.36: Top navigation bar to navigate back to functions&#13;&#10;"/></div><p class="figure-caption">Figure 2.36: Top navigation bar to navigate back to functions</p></li>
				<li>Click <code>s3_trigger</code> to go back to the function you are working on:<div><img src="img/B16061_02_37.jpg" alt="Figure 2.37: Selecting the lambda function to work on&#13;&#10;"/></div><p class="figure-caption">Figure 2.37: Selecting the lambda function to work on</p></li>
				<li>Next, scroll down the screen to the <code>Function code</code> section. The default code will be the same as, or similar to, the following:<div><img src="img/B16061_02_38.jpg" alt="Figure 2.38: AWS Lambda—the default lambda_function screen&#13;&#10;"/></div><p class="figure-caption">Figure 2.38: AWS Lambda—the default lambda_function screen</p><p>Here, we can enter and edit our code entirely within the <code>lambda_function</code> screen (as long as <code>Code entry type</code> is set to <code>Edit code inline</code>, which is the default value in the drop-down menu).</p><p class="callout-heading">Note</p><p class="callout">For this step, you may either follow along and type in the code or obtain it from the source code folder at <a href="https://packt.live/2O6WsLW">https://packt.live/2O6WsLW</a>.</p></li>
				<li>First, we import the <strong class="bold">AWS SDK</strong> for Python (boto3: <a href="http://boto3.readthedocs.io/en/latest/">http://boto3.readthedocs.io/en/latest/</a>):<pre>import boto3</pre></li>
				<li>Then, import the JSON module to serialize the JSON (<a href="https://docs.python.org/3.6/library/json.html">https://docs.python.org/3.6/library/json.html</a>):<pre>import json</pre></li>
				<li>Next, create a function that takes two parameters—<code>event</code> and <code>context</code>:<pre>def Lambda_handler(event, context):</pre></li>
				<li>Next, create the <code>s3</code> client object:<pre>s3 = boto3.client("s3")</pre></li>
				<li>Add an <code>if</code> event to check whether an event occurs.</li>
				<li>Next, replace <code>&lt;input Bucket name&gt;</code> with the bucket you created (<code>aws-ml-s3-trigger-202001181023</code>, in are example):<pre>bucket = "&lt;input Bucket name&gt;"</pre></li>
				<li>Next, access the first index of the <code>Records</code> event to obtain the text file object:<pre>text_file_obj = event["Records"][0]</pre></li>
				<li>Next, assign the <code>filename</code> text to a variable and print the filename:<pre>filename = str(text_file_obj['s3']['object']['key'])
print("filename: ", filename)</pre></li>
				<li>Next, create the file object by getting the bucket and key:<pre>file_obj = s3.get_object(Bucket = Bucket, Key = filename)</pre></li>
				<li>Assign the text to the <code>body_str_obj</code> variable:<pre>body_str_obj = str(file_obj['Body'].read())</pre></li>
				<li>Create the <code>comprehend</code> variable:<pre>comprehend = boto3.client(service_name="comprehend")</pre></li>
				<li>The next three lines of code call the respective Comprehend functions to detect the sentiment, entities, and key phrases from the text document. Then, the output is printed to the console:<pre>sentiment_response = comprehend.detect_sentiment\
                     (Text = body_str_obj, \
                     LanguageCode = "en")
print(«sentiment_response: \n», sentiment_response)
entity_response = comprehend.detect_entities\
                  (Text = body_str_obj, LanguageCode = "en")
print("\n\nentity_response: \n", entity_response)
key_phases_response = comprehend.detect_key_phrases\
                      (Text = body_str_obj, \
                      LanguageCode = "en") 
print("\n\nkey_phases_response: \n", key_phases_response)</pre></li>
				<li>The final statement returns the <code>'Hello from Lambda'</code> string, like so:<pre>return {
      'statusCode' :200,
      'body' : json.dumps('Hello from Lambda')
    }</pre></li>
				<li>Now, click the <code>Save</code> button:<div><img src="img/B16061_02_39.jpg" alt="Figure 2.39: AWS Lambda – save screen&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 2.39: AWS Lambda – save screen</p>
			<p>From this exercise, the <code>s3_trigger</code> function has access to S3, but not Amazon Comprehend. We need to attach a policy to the <code>s3_trigger</code> function to allow it to access Amazon Comprehend to execute the text analysis functions (<code>detect_sentiment</code>, <code>detect_entities</code>, and <code>detect_key_phrases</code>).</p>
			<h2 id="_idParaDest-78"><a id="_idTextAnchor078"/>Exercise 2.08: Assigning Policies to S3_trigger to Access Comprehend</h2>
			<p>In this exercise, we will attach the policies to the <code>S3_trigger</code> function to allow it to access Comprehend. The steps for completion for assigning the policies are as follows:</p>
			<ol>
				<li value="1">In the Amazon Management Console, click <code>Services</code> at the top left:<div><img src="img/B16061_02_40.jpg" alt="Figure 2.40: AWS Services from the AWS Management Console&#13;&#10;"/></div><p class="figure-caption">Figure 2.40: AWS Services from the AWS Management Console</p></li>
				<li>Navigate to the <code>Identity and Access Management</code> dashboard in the <code>Security, Identity, &amp; Compliance</code> section. You can also type <code>IAM</code> and select it from the dropdown:<div><img src="img/B16061_02_41.jpg" alt="Figure 2.41: IAM dashboard&#13;&#10;"/></div><p class="figure-caption">Figure 2.41: IAM dashboard</p></li>
				<li>Now, once you get to the IAM dashboard, click <code>Roles</code>:<div><img src="img/B16061_02_42.jpg" alt="Figure 2.42: Left-hand side of the IAM dashboard&#13;&#10;"/></div><p class="figure-caption">Figure 2.42: Left-hand side of the IAM dashboard</p></li>
				<li>Now, the screen will be populated with the role list. Click <code>s3TriggerRole</code> in the role list:<div><img src="img/B16061_02_43.jpg" alt="Figure 2.43: Role list—selecting s3TriggerRole&#13;&#10;"/></div><p class="figure-caption">Figure 2.43: Role list—selecting s3TriggerRole</p></li>
				<li>The <code>s3TriggerRole</code> option will be enabled. Then, click <code>Attach policies</code>:<div><img src="img/B16061_02_44.jpg" alt="Figure 2.44: Permissions tab for s3TriggerRole&#13;&#10;"/></div><p class="figure-caption">Figure 2.44: Permissions tab for s3TriggerRole</p></li>
				<li>Type <code>Comprehend</code> to filter the policies. Then, click the checkbox next to <code>ComprehendFullAccess</code>:<div><img src="img/B16061_02_45.jpg" alt="Figure 2.45: ComprehendFullAccess policy selection&#13;&#10;"/></div><p class="figure-caption">Figure 2.45: ComprehendFullAccess policy selection</p></li>
				<li>Once you have selected the checkbox, click <code>Attach policy</code> (located in the lower right-hand corner of the screen):<div><img src="img/B16061_02_46.jpg" alt="Figure 2.46: Attaching the selected policies&#13;&#10;"/></div><p class="figure-caption">Figure 2.46: Attaching the selected policies</p></li>
				<li>You will be redirected to the <code>s3TriggerRole</code> screen, and you will receive the following message:<div><img src="img/B16061_02_47.jpg" alt="Figure 2.47: Successfully attached policies message&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 2.47: Successfully attached policies message</p>
			<p>With that, we have successfully attached the policies to the <code>S3_trigger</code> function thus allowing it to access Comprehend.</p>
			<h2 id="_idParaDest-79"><a id="_idTextAnchor079"/>Activity 2.01: Integrating Lambda with Amazon Comprehend to Perform Text An<a id="_idTextAnchor080"/>alysis</h2>
			<p>In this activity, we will integrate the Lambda functions with Comprehend to perform text analysis (<code>detect_sentiment</code>, <code>detect_entities</code>, and <code>detect_key_phrases</code>) when a document is uploaded to S3.</p>
			<p>Suppose that you are creating a chatbot. You have identified a business topic and the corresponding text documents, with content that will allow the chatbot to make your business successful. Your next step is to integrate the Lambda functions with Comprehend, for sentiment, key phrases, and entities. To ensure that this happens correctly, you will need to have <code>test_s3trigger_configured.txt</code>. </p>
			<p class="callout-heading">Note</p>
			<p class="callout">The <code>test_s3trigger_configured.txt</code> file can be found on GitHub at link <a href="https://packt.live/3gAxqku">https://packt.live/3gAxqku</a>.</p>
			<p>Before you execute <code>s3_trigger</code>, consider the output, based on the following aspects of the text: sentiment (positive, negative, or neutral), entities (quantity, person, place, and so on), and key phrases:</p>
			<ol>
				<li value="1">First, navigate to the <code>S3_trigger</code> Lambda function.</li>
				<li>Add <code>test_s3trigger_configured.txt</code> to the S3 bucket, to verify the Lambda <code>S3_trigger</code> function.</li>
				<li>Now, upload the file into the bucket and monitor the file.</li>
				<li>Next, click <code>View logs</code> in <code>CloudWatch</code> by using the log stream. </li>
				<li>Now, expand the output in a text format.<p>The following will be the output:</p><p><code>Sentiment_response</code> -&gt; Classified as 60.0% likely to be positive</p><p><code>Sentiment_response</code>:</p><pre>{'Sentiment': 'POSITIVE',
'SentimentScore':{'Positive': 0.6005121469497681,
                  'Negative': 0.029164031147956848, 
                  'Neutral': 0.3588017225265503, 
                  'Mixed': 0.01152205839753151}, </pre><p><code>entity_response</code> -&gt; Classified as 70.5% likely to be a quantity</p><p><code>entity_response</code>:</p><pre>{Entities':[{'Score':0.7053232192993164, 
             'Type': 'QUANTITY','Text': '3 trigger', 
             'BeginOffset': 35, 'EndOffset': 44}], </pre><p><code>key_phases_response</code> -&gt; Classified as 89.9% likely "a test file" and 98.5% likely "the s3 trigger" are the key phrases:</p><p><code>key_phases_response</code>:</p><pre>{'KeyPhrases': [{'Score': 0.8986637592315674, 
                 'Text': 'a test file', 
                 'BeginOffset': 8, 'EndOffset': 19}, 
                {'Score': 0.9852105975151062, 
                 'Text': 'the s3 trigger', 'BeginOffset': 30, 
                 'EndOffset': 44}],</pre><p class="callout-heading">Note</p><p class="callout">The solution for this activity can be found on page 279.</p></li>
			</ol>
			<h1 id="_idParaDest-80"><a id="_idTextAnchor081"/>Amazon Textract</h1>
			<p>Another interesting NLP Amazon service is Textract. Essentially, Textract can extract information from documents, usually business documents such as tax forms, legal documents, medical forms, bank forms, patent registrations, and so forth. It is an <strong class="bold">optical character recognition (OCR</strong>) solution for scanning structured documents, suitable for <strong class="bold">robotic process automation</strong> (<strong class="bold">RPA</strong>). Textract is a relatively new service—previewed in November 2018 and generally available in May 2019.</p>
			<p>The advantage of Textract is that it understands documents and can extract tables and/or key-value pairs suitable for downstream processing. A lot of business processes, such as health insurance processing, tax preparation, loan application processing, monitoring and evaluation of existing loans, compliance evaluation, and engineering evaluations take in these documents, usually processing them manually to extract information and then start digital processes. Using Amazon Textract, the manual intake of various documents can be automated, resulting in a faster turnaround when approving loans, accelerated processing of health claims, or approving an engineering design quickly, thus achieving good business value.</p>
			<h2 id="_idParaDest-81"><a id="_idTextAnchor082"/>Exercise 2.09: Extracting Tax Information Using Amazon Textract</h2>
			<p>In this exercise, you will take a page of a sample tax return document from documentcloud.org (<a href="https://www.documentcloud.org/documents/3462212-Sample-2016-Tax-Return.html">https://www.documentcloud.org/documents/3462212-Sample-2016-Tax-Return.html</a>) and see how much information Textract can extract:</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The sample document (page 1 of US Tax form 1040) is available at <a href="https://packt.live/2O5e1Mn">https://packt.live/2O5e1Mn</a>.</p>
			<ol>
				<li value="1">For this exercise, we will use the Textract interface directly. This is very useful to try out and to see how a document is amenable to OCR.</li>
				<li>First, go to the Textract dashboard by selecting <code>Services | Machine Learning | Amazon Textract</code>. There are lots of interesting details on that page. Take the time to read through the materials:<div><img src="img/B16061_02_48.jpg" alt="Figure 2.48: Amazon Textract dashboard&#13;&#10;"/></div><p class="figure-caption">Figure 2.48: Amazon Textract dashboard</p></li>
				<li>Click <code>Try Amazon Textract</code>. A very simple utilitarian page appears:<div><img src="img/B16061_02_49.jpg" alt="Figure 2.49: Amazon Textract Analyze document&#13;&#10;"/></div><p class="figure-caption">Figure 2.49: Amazon Textract Analyze document</p></li>
				<li>Click <code>Upload document</code> and upload the <code>Sample-2016-Tax-Return.jpeg</code> file. The service thinks for a minute and shows very informative tabs and the information it has extracted:<div><img src="img/B16061_02_50.jpg" alt="Figure 2.50: Amazon Textract Analyze document screen with the sample tax form&#13;&#10;"/></div><p class="figure-caption">Figure 2.50: Amazon Textract Analyze document screen with the sample tax form</p><p>The raw text is interesting, but we are looking for more value for our automation pipeline.</p></li>
				<li>Click the <code>Forms</code> tab and you will see a very interesting page—it can get the value as well as the key. For example, line 7 is extracted as <code>7 Wages, salaries, tips, etc. Attach Form(s) W-2 7</code> and a value of <code>93,500</code>. Now, a downstream loan processing application can get the value as well as the context and act on it.<p>You can click other fields on the image on the left-hand side and see the extracted entry on the right-hand side. </p><p>You can download the results as JSON, CSV, table, and text formats. As expected, <code>keyvalues.csv</code> has the line 7 we saw earlier as the key and <code>93,500</code> as the value:</p><div><img src="img/B16061_02_51.jpg" alt="Figure 2.51: Amazon Textract Analyze document screen with the sample tax document form&#13;&#10;"/></div><p class="figure-caption">Figure 2.51: Amazon Textract Analyze document screen with the sample tax document form</p></li>
				<li>You can see the extracted fields in a table format (with the keys as the caption and the value in the grey box under the captions) as shown below:<div><img src="img/B16061_02_52.jpg" alt="Figure 2.52: Amazon Textract Analyze document screen with the sample tax document Forms tab showing the key value&#13;&#10;"/></div><p class="figure-caption">Figure 2.52: Amazon Textract Analyze document screen with the sample tax document Forms tab showing the key value</p></li>
				<li>The <code>Tables</code> tab is also interesting. Textract was able to extract two tables—the top and the bottom portion—but was not able to extract the middle one:<div><img src="img/B16061_02_53.jpg" alt="Figure 2.53: Amazon Textract Analyze document screen &#13;&#10;with the sample tax form showing Tables (form)&#13;&#10;"/></div><p class="figure-caption">Figure 2.53: Amazon Textract Analyze document screen with the sample tax form showing Tables (form)</p></li>
				<li>You can see the extracted fields in a table format by clicking the <code>Tables</code> tab:<div><img src="img/B16061_02_54.jpg" alt="Figure 2.54: Amazon Textract Analyze document screen &#13;&#10;with the sample tax form showing Tables (extracted)&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 2.54: Amazon Textract Analyze document screen with the sample tax form showing Tables (extracted)</p>
			<p>Now that you have a feel for what Textract can do, another useful exercise would be to develop a loan processing pipeline using Lambda. When page 1 of US Tax 1040 is dropped into an S3 bucket as a JPEG file, trigger a Lambda that takes the file and invokes Textract and stores the key-value file as a CSV in another bucket. If you feel adventurous, you can develop another Lambda downstream of Textract that gets triggered when the output file is created, and it can either alert a loan officer via SMS or a queue or even a mobile app alert.</p>
			<h1 id="_idParaDest-82"><a id="_idTextAnchor083"/>Summary</h1>
			<p>In this chapter, we started with high-level concepts around Amazon AI services and serverless computing. On a conceptual level, you learned about serverless computing as well as the various AI services available on the AWS platform.</p>
			<p>Overall, the culmination of these independent functions provides the foundation for building complex machine learning-based NLP applications (for example, Siri, Alexa, and so on). Knowing how and why the individual functions operate will allow you to build your own AWS-based NLP applications.</p>
			<p>Then, we dived into the details of Amazon Comprehend—how Comprehend's <code>DetectDominantLanguage</code> method is structured, and how to pass in both strings and a list of strings. You learned how to extract entities, sentiments, key phrases, and topics, which provide the data for complex NLP. This allows Amazon Comprehend to become more efficient by automating text analysis upon a text document that's been uploaded to S3.</p>
			<p>You also learned how to use Amazon Textract to extract structured information (tables and key-value pairs) out of scanned documents as a prelude to process automation.</p>
			<p>In the next chapter, we will explore topic modeling and perform theme extraction.</p>
		</div>
	</body></html>