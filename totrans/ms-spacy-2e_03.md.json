["```py\n    import spacy\n    spacy.explain(\"NNS\")\n    >>> 'noun, plural'\n    ```", "```py\n    nlp = spacy.load(\"en_core_web_sm\")\n    doc = nlp(\"I saw flowers.\")\n    ```", "```py\n    for token in doc:\n        print(token.text, \"tag:\", token.tag_)\n    >>> I tag: PRP\n    saw tag: VBD\n    flowers tag: NNS\n    . tag: .\n    ```", "```py\n    for token in doc:\n        print(token.text, \"tag:\", token.tag_, \"explanation:\",\n              spacy.explain(token.tag_))\n    >>> I tag: PRP explanation: pronoun, personal\n    saw tag: VBD explanation: verb, past tense\n    flowers tag: NNS explanation: noun, plural\n    . tag: . explanation: punctuation mark, sentence closer\n    ```", "```py\nimport spacy\nnlp = spacy.load(\"en_core_web_sm\")\nsent1 = \"I flew to Rome\"\nsent2 = \"I'm flying to Rome\"\nsent3 = \"I will fly to Rome\"\ndoc1 = nlp(sent1)\ndoc2 = nlp(sent2)\ndoc3 = nlp(sent3)\nfor doc in [doc1, doc2, doc3]:\n    print([(w.text, w.lemma_) for w in doc if \n           w.tag_== 'VBG' or w.tag_== 'VB'])\n>>> []\n    [('flying', 'fly')]\n    [('fly', 'fly')]\n```", "```py\ndoc = nlp(\"blue flower\")\nfor token in doc:\n    print(token.text, \"\\tdep:\",token.dep_)\n>>> blue dep: amod\n    flower dep: ROOT\n```", "```py\ndoc = nlp(\"This is my book\")\nfor token in doc:\n    print(token.text, \"\\tpos:\", token.pos_, \"\\tdep:\", token.dep_)\n>>> This   pos: PRON    dep: nsubj\n    is     pos: AUX     dep: ROOT\n    my     pos: PRON    dep: poss\n    book   pos: NOUN    dep: attr\n```", "```py\ndoc = nlp(\"This is my book\")\nfor token in doc:\n    print(token.text, \"\\tpos:\", token.pos_, \"\\tdep:\", token.dep_, \"\\thead:\", token.head)\n>>> This   pos: PRON   dep: nsubj   head: is\n    is     pos: AUX    dep: ROOT    head: is\n    my     pos: PRON   dep: poss    head: book\n    book   pos: NOUN   dep: attr    head: is\n```", "```py\ndoc = nlp(\"We are trying to understand the difference.\")\nfor token in doc:\n    print(token.text, token.pos_, \"\\tdep:\", token.dep_, \"\\thead:\", token.head)\n>>>  We         PRON  dep: nsubj      head: trying\n     are        AUX   dep: aux        head: trying\n     trying     VERB  dep: ROOT       head: trying\n     to         PART  dep: aux        head: understand\n     understand VERB  dep: xcomp      head: trying\n     the        DET   dep: det        head: difference\n     difference NOUN  dep: dobj       head: understand\n     .          PUNCT dep: punct      head: trying\n```", "```py\ndoc = nlp(\"The Brazilian president visited Beijing.\")\nprint(doc.ents)\nprint(type(doc.ents[0]))\n>>> (Brazilian, Beijing)\n<class 'spacy.tokens.span.Span'>\n```", "```py\ndoc = nlp(\"He worked for NASA.\")\ntoken = doc[3]\nprint(token.ent_type_, spacy.explain(token.ent_type_))\n>>> ORG Companies, agencies, institutions, etc.\n```", "```py\n    doc = nlp(\"She lived in New Hampshire.\")\n    print(doc.ents)\n    ```", "```py\n    print([(token.text, token.i) for token in doc])\n    >>> [('She', 0), ('lived', 1), ('in', 2), ('New', 3), ('Hampshire', 4), ('.', 5)]\n    ```", "```py\n    with doc.retokenize() as retokenizer:\n        retokenizer.merge(\n            doc[3:5], attrs={\"LEMMA\": \"new hampshire\"})\n    ```", "```py\n    print([(token.text, token.i) for token in doc])\n    >>> [('She', 0), ('lived', 1), ('in', 2), ('New Hampshire', 3), ('.', 4)]\n    ```", "```py\ndoc = nlp(\"She lived in NewHampshire\")\nprint([(token.text, token.lemma_, token.i) for token in doc])\n>>> [('She', 'she', 0),\n('lived', 'live', 1),\n('in', 'in', 2),\n('NewHampshire', 'NewHampshire', 3)]\n```", "```py\nwith doc.retokenize() as retokenizer:\n    heads = [(doc[3], 1), doc[2]]\n    attrs = {\"TAG\":[\"NNP\", \"NNP\"], \"DEP\": [\"compound\", \"pobj\"]}\n    retokenizer.split(doc[3], [\"New\", \"Hampshire\"], heads=heads, attrs=attrs)\nprint([(token.text, token.lemma_, token.i) for token in doc])\n>>> [('She', 'she', 0),\n('lived', 'live', 1),\n('in', 'in', 2),\n('New', 'New', 3),\n('Hampshire', '', 4)]\n```"]