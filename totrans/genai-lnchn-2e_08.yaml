- en: '7'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '7'
- en: Software Development and Data Analysis Agents
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 软件开发与数据分析代理
- en: This chapter explores how natural language—our everyday English or whatever
    language you prefer to interact in with an LLM—has emerged as a powerful interface
    for programming, a paradigm shift that, when taken to its extreme, is called *vibe
    coding*. Instead of learning acquiring new programming languages or frameworks,
    developers can now articulate their intent in natural language, leaving it to
    advanced LLMs and frameworks such as LangChain to translate these ideas into robust,
    production-ready code. Moreover, while traditional programming languages remain
    essential for production systems, LLMs are creating new workflows that complement
    existing practices and potentially increase accessibility This evolution represents
    a significant shift from earlier attempts at code generation and automation.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章探讨了自然语言——无论是我们日常使用的英语还是你与LLM交互时偏好的任何语言——如何成为编程的强大界面，这是一种范式转变，当其被推向极致时，被称为*振动编码*。开发者现在可以用自然语言表达他们的意图，而将这些想法转化为健壮、可投入生产的代码的任务留给高级LLMs和框架，如LangChain。此外，尽管传统的编程语言对于生产系统仍然是必不可少的，但LLMs正在创造新的工作流程，这些工作流程补充了现有实践，并可能提高可访问性。这种演变代表了从早期代码生成和自动化尝试的重大转变。
- en: We’ll specifically discuss LLMs’ place in software development and the state
    of the art of performance, models, and applications. We’ll see how to use LLM
    chains and agents to help in code generation and data analysis, training ML models,
    and extracting predictions. We’ll cover writing code with LLMs, giving examples
    with different models be it on Google’s generative AI services, Hugging Face,
    or Anthropic. After this, we’ll move on to more advanced approaches with agents
    and RAG for documentation or a code repository.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将具体讨论大型语言模型（LLMs）在软件开发中的位置以及性能、模型和应用的最新状态。我们将了解如何使用LLM链和代理来帮助代码生成、数据分析、训练机器学习模型以及提取预测。我们将涵盖使用LLMs编写代码，并通过Google的生成式AI服务、Hugging
    Face或Anthropic等不同模型给出示例。在此之后，我们将转向使用代理和RAG进行文档编写或代码仓库的更高级方法。
- en: 'We’ll also be applying LLM agents to data science: we’ll first train a model
    on a dataset, then we’ll analyze and visualize a dataset. Whether you’re a developer,
    a data scientist, or a technical decision-maker, this chapter will equip you with
    a clear understanding of how LLMs are reshaping software development and data
    analysis while maintaining the essential role of conventional programming languages.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将应用LLM代理于数据科学：我们首先在数据集上训练一个模型，然后分析和可视化数据集。无论你是开发者、数据科学家还是技术决策者，本章将帮助你清晰地理解LLMs如何重塑软件开发和数据分析，同时保持传统编程语言的基本作用。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: LLMs in software development
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLMs在软件开发中的应用
- en: Writing code with LLMs
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用LLMs编写代码
- en: Applying LLM agents for data science
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用LLM代理进行数据科学
- en: LLMs in software development
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLMs在软件开发中的应用
- en: The relationship between natural language and programming is undergoing a significant
    transformation. Traditional programming languages remain essential in software
    development—C++ and Rust for performance-critical applications, Java and C# for
    enterprise systems, and Python for rapid development, data analysis, and ML workflows.
    However, natural language, particularly English, now serves as a powerful interface
    to streamline software development and data science tasks, complementing rather
    than replacing these specialized programming tools.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 自然语言与编程之间的关系正在经历重大的转变。在软件开发中，传统的编程语言仍然是必不可少的——C++和Rust用于性能关键的应用，Java和C#用于企业系统，Python用于快速开发、数据分析以及机器学习工作流程。然而，自然语言，尤其是英语，现在成为了一种强大的界面，用于简化软件开发和数据科学任务，它补充而不是取代这些专门的编程工具。
- en: Advanced AI assistants let you build software by simply staying “in the vibe”
    of what you want, without ever writing or even picturing a line of code. This
    style of development, known as vibe coding, was popularized by Andrej Karpathy
    in early 2025\. Instead of framing tasks in programming terms or wrestling with
    syntax, you describe desired behaviors, user flows or outcomes in plain conversation.
    The model then orchestrates data structures, logic and integration behind the
    scenes. With vibe coding you don’t debug—you re-vibe. This means, you iterate
    by restating or refining requirements in natural language, and let the assistant
    reshape the system. The result is a pure, intuitive design-first workflow that
    completely abstracts away all coding details.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 高级AI助手让你只需保持“在感觉”中，就能简单地构建软件，而无需编写或甚至想象一行代码。这种开发风格被称为vibe coding，在2025年初由Andrej
    Karpathy普及。你不必用编程术语来界定任务或与语法搏斗，而是用普通的对话描述所需的行为、用户流程或结果。然后模型在幕后协调数据结构、逻辑和集成。在vibe
    coding中，你不是调试，而是重新调整感觉。这意味着，你通过用自然语言重申或细化需求来迭代，让助手重塑系统。结果是纯粹直观的设计优先工作流程，完全抽象出所有编码细节。
- en: Tools such as Cursor, Windsurf (formerly Codeium), OpenHands, and Amazon Q Developer
    have emerged to support this development approach, each offering different capabilities
    for AI-assisted coding. In practice, these interfaces are democratizing software
    creation while freeing experienced engineers from repetitive tasks. However, balancing
    speed with code quality and security remains critical, especially for production
    systems.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 出现了诸如Cursor、Windsurf（原名Codeium）、OpenHands和Amazon Q Developer等工具，以支持这种开发方法，每个工具都为AI辅助编码提供了不同的功能。在实践中，这些界面正在使软件开发民主化，同时让经验丰富的工程师从重复性任务中解放出来。然而，在速度、代码质量和安全性之间保持平衡仍然至关重要，尤其是在生产系统中。
- en: The software development landscape has long sought to make programming more
    accessible through various abstraction layers. Early efforts included fourth-generation
    languages that aimed to simplify syntax, allowing developers to express logic
    with fewer lines of code. This evolution continued with modern low-code platforms,
    which introduced visual programming with pre-built components to democratize application
    development beyond traditional coding experts. The latest and perhaps most transformative
    evolution features natural language programming through LLMs, which interpret
    human intentions expressed in plain language and translate them into functional
    code.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 软件开发领域长期以来一直在通过各种抽象层使编程更加易于访问。早期的努力包括旨在简化语法的第四代语言，允许开发者用更少的代码行表达逻辑。这种演变继续与现代低代码平台的发展，它们引入了带有预构建组件的可视编程，以使应用开发超越传统的编码专家。最新的、也许是最具变革性的演变是自然语言编程，通过LLM将人类用普通语言表达的意思解释成功能性代码。
- en: What makes this current evolution particularly distinctive is its fundamental
    departure from previous approaches. Rather than creating new artificial languages
    for humans to learn, we’re adapting intelligent tools to understand natural human
    communication, significantly lowering the barrier to entry. Unlike traditional
    low-code platforms that often result in proprietary implementations, natural language
    programming generates standard code without vendor lock-in, preserving developer
    freedom and compatibility with existing ecosystems. Perhaps most importantly,
    this approach offers unprecedented flexibility across the spectrum, from simple
    tasks to complex applications, serving both novices seeking quick solutions and
    experienced developers looking to accelerate their workflow.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 当前这一演变之所以特别显著，是因为它从根本上不同于以往的方法。我们不是为人类创造新的学习的人工语言，而是将智能工具适应于理解自然的人类交流，显著降低了入门门槛。与传统低代码平台往往导致专有实现不同，自然语言编程生成标准代码，没有供应商锁定，保护了开发者的自由，并与现有生态系统兼容。也许最重要的是，这种方法在整个范围内提供了前所未有的灵活性，从简单任务到复杂应用，既服务于寻求快速解决方案的新手，也服务于希望加速工作流程的资深开发者。
- en: The future of development
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 开发的未来
- en: Analysts at International Data Corporation (IDC) project that, by 2028, natural
    language will be used to create 70% of new digital solutions (IDC FutureScape,
    *Worldwide Developer and DevOps 2025 Predictions*). However, this doesn’t mean
    traditional programming will disappear; rather, it’s evolving into a two-tier
    system where natural language serves as a high-level interface while traditional
    programming languages handle precise implementation details.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 国际数据公司（IDC）的分析师预测，到2028年，自然语言将用于创建70%的新数字解决方案（IDC FutureScape，*全球开发者与DevOps
    2025预测*）。但这并不意味着传统编程会消失；相反，它正在演变成一个双层系统，其中自然语言作为高级接口，而传统编程语言处理精确的实现细节。
- en: However, this evolution does not spell the end for traditional programming languages.
    While natural language can streamline the design phase and accelerate prototyping,
    the precision and determinism of languages like Python remain essential for building
    reliable, production-ready systems. In other words, rather than replacing code
    entirely, English (or Mandarin, or whichever natural language best suits our cognitive
    process) is augmenting it—acting as a high-level layer that bridges human intent
    with executable logic.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这种演变并不意味着传统编程语言的终结。虽然自然语言可以简化设计阶段并加速原型设计，但像Python这样的语言的精确性和确定性对于构建可靠、可生产的系统仍然是必不可少的。换句话说，英语（或普通话，或任何最适合我们认知过程的自然语言）并不是完全取代代码，而是在作为高级层，将人类意图与可执行逻辑连接起来。
- en: For software developers, data scientists, and technical decision-makers, this
    shift means embracing a hybrid workflow where natural language directives, powered
    by LLMs and frameworks such as LangChain, coexist with conventional code. This
    integrated approach paves the way for faster innovation, personalized software
    solutions, and, ultimately, a more accessible development process.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 对于软件开发人员、数据科学家和技术决策者来说，这种转变意味着接受一个混合工作流程，其中由LLM和LangChain等框架驱动的自然语言指令与传统的代码共存。这种集成方法为更快地创新、个性化的软件解决方案以及最终更易于开发的过程铺平了道路。
- en: Implementation considerations
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实施考虑因素
- en: For production environments, the current evolution manifests in several ways
    that are transforming how development teams operate. Natural language interfaces
    enable faster prototyping and reduce time spent on boilerplate code, while traditional
    programming remains essential for the optimization and implementation of complex
    features. However, recent independent research shows significant limitations in
    current AI coding capabilities.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 对于生产环境，当前的演变以多种方式体现，正在改变开发团队的工作方式。自然语言界面使原型设计更快，减少了编写样板代码的时间，而传统编程对于复杂功能的优化和实现仍然是必不可少的。然而，最近的一项独立研究显示，当前AI编码能力存在重大局限性。
- en: The 2025 OpenAI *SWE-Lancer* benchmark study found that even the top-performing
    model completed only 26.2% of individual engineering tasks drawn from real-world
    freelance projects. The research identified specific challenges including surface-level
    problem-solving, limited context understanding across multiple files, inadequate
    testing, and poor edge case handling.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 2025年OpenAI *SWE-Lancer*基准研究显示，即使是表现最好的模型也只完成了从现实世界自由职业项目中抽取的个别工程任务的26.2%。研究确定了具体挑战，包括表面问题解决、跨多个文件有限的上下文理解、测试不足和边缘情况处理不当。
- en: Despite these limitations, many organizations report productivity gains when
    using AI coding assistants in targeted ways. The most effective approach appears
    to be collaboration—using AI to accelerate routine tasks while applying human
    expertise to areas where AI still struggles, such as architectural decisions,
    comprehensive testing, and understanding business requirements in context. As
    the technology matures, the successful integration of natural language and traditional
    programming will likely depend on clearly defining where each excels rather than
    assuming AI can autonomously handle complex software engineering challenges.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管存在这些限制，许多组织报告称，在使用AI编码助手时，如果目标明确，则可以提升生产力。最有效的方法似乎是协作——利用AI加速日常任务，同时将人类专业知识应用于AI仍存在挑战的领域，例如架构决策、全面测试和情境理解业务需求。随着技术的成熟，自然语言与传统编程的成功整合可能取决于明确界定各自的优势，而不是假设AI可以自主处理复杂的软件工程挑战。
- en: 'Code maintenance has evolved through AI-assisted approaches where developers
    use natural language to understand and modify codebases. While GitHub reports
    Copilot users completed specific coding tasks 55% faster in controlled experiments,
    independent field studies show more modest productivity gains ranging from 4–22%,
    depending on context and measurement approach. Similarly, Salesforce reports their
    internal CodeGenie tool contributes to productivity improvements, including automating
    aspects of code review and security scanning. Beyond raw speed improvements, research
    consistently shows AI coding assistants reduce developer cognitive load and improve
    satisfaction, particularly for repetitive tasks. However, studies also highlight
    important limitations: generated code often requires significant human verification
    and rework, with some independent research reporting higher bug rates in AI-assisted
    code. The evidence suggests these tools are valuable assistants that streamline
    development workflows while still requiring human expertise for quality and security
    assurance.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 代码维护已经通过人工智能辅助方法得到发展，开发者使用自然语言来理解和修改代码库。虽然GitHub报告称，在控制实验中，Copilot用户完成特定编码任务的速度提高了55%，但独立的现场研究表明，生产力的提升更为适度，范围在4-22%之间，这取决于具体情境和测量方法。同样，Salesforce报告称，他们内部的CodeGenie工具有助于提高生产力，包括自动化代码审查和安全扫描的某些方面。除了速度的提升之外，研究一致表明，人工智能编码助手可以减轻开发者的认知负担并提高满意度，尤其是在重复性任务中。然而，研究也突出了重要的局限性：生成的代码通常需要大量的人工验证和修改，一些独立研究报道了人工智能辅助代码中更高的错误率。证据表明，这些工具是有价值的助手，可以简化开发工作流程，同时仍然需要人类专业知识来确保质量和安全性。
- en: The field of code debugging has been enhanced as natural language queries help
    developers identify and resolve issues faster by explaining error messages, suggesting
    potential fixes, and providing context for unexpected behavior. AXA’s deployment
    of “AXA Secure GPT,” trained on internal policies and code repositories, has significantly
    reduced routine task turnaround times, allowing development teams to focus on
    more strategic work (AXA, *AXA offers secure Generative AI to employees*).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 代码调试领域得到了增强，因为自然语言查询通过解释错误信息、建议潜在修复并提供意外行为的背景信息，帮助开发者更快地识别和解决问题。AXA部署的“AXA Secure
    GPT”，该模型在内部政策和代码库上进行了训练，显著减少了常规任务的周转时间，使开发团队能够专注于更具战略性的工作（AXA，*AXA向员工提供安全的生成式人工智能*）。
- en: When it comes to understanding complex systems, developers can use LLMs to generate
    explanations and visualizations of intricate architectures, legacy codebases,
    or third-party dependencies, accelerating onboarding and system comprehension.
    For example, Salesforce’s system landscape diagrams show how their LLM-integrated
    platforms connect across various services, though recent earnings reports indicate
    these AI initiatives have yet to significantly impact their financial results.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到理解复杂系统时，开发者可以使用大型语言模型（LLMs）生成复杂架构、遗留代码库或第三方依赖关系的解释和可视化，从而加速入职和系统理解。例如，Salesforce的系统景观图显示了他们的LLM集成平台如何连接到各种服务，尽管最近的收益报告表明，这些人工智能项目尚未对其财务结果产生重大影响。
- en: System architecture itself is evolving as applications increasingly need to
    be designed with natural language interfaces in mind, both for development and
    potential user interaction. BMW reported implementing a platform that uses generative
    AI to produce real-time insights via chat interfaces, reducing the time from data
    ingestion to actionable recommendations from days to minutes. However, this architectural
    transformation reflects a broader industry pattern where consulting firms have
    become major financial beneficiaries of the generative AI boom. Recent industry
    analysis shows that consulting giants such as Accenture are generating more revenue
    from generative AI services ($3.6 billion in annualized bookings) than most generative
    AI startups combined, raising important questions about value delivery and implementation
    effectiveness that organizations must consider when planning their AI architecture
    strategies.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 系统架构本身正在演变，因为应用程序越来越多地需要考虑使用自然语言界面进行设计，无论是为了开发还是潜在的用户交互。宝马报告称，他们实施了一个平台，该平台使用生成式人工智能通过聊天界面产生实时洞察，将数据摄入到可操作建议的时间从几天缩短到几分钟。然而，这种架构转型反映了更广泛的行业趋势，即咨询公司已成为生成式人工智能繁荣的主要财务受益者。最近的行业分析显示，像埃森哲这样的咨询巨头从生成式人工智能服务中获得的收入（年度预订额为36亿美元）比大多数生成式人工智能初创公司总和还要多，这引发了关于价值交付和实施有效性的重要问题，组织在规划其人工智能架构策略时必须考虑这些问题。
- en: For software developers, data scientists, and decision-makers, this integration
    means faster iteration, lower costs, and a smoother transition from idea to deployment.
    While LLMs help generate boilerplate code and automate routine tasks, human oversight
    remains critical for system architecture, security, and performance. As the case
    studies demonstrate, companies integrating natural language interfaces into development
    and operational pipelines are already realizing tangible business value while
    maintaining necessary human guidance.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 对于软件开发人员、数据科学家和决策者来说，这种集成意味着更快的迭代、更低的成本，以及从想法到部署的更平滑过渡。虽然LLM有助于生成样板代码和自动化常规任务，但人类监督对于系统架构、安全和性能仍然至关重要。正如案例研究所示，将自然语言界面集成到开发和运营管道中的公司已经在实现可衡量的商业价值的同时，保持了必要的人类指导。
- en: Evolution of code LLMs
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 代码LLM的演变
- en: The development of code-specialized LLMs has followed a rapid trajectory since
    their inception, progressing through three distinct phases that have transformed
    software development practices. The first *Foundation phase* (2021 to early 2022)
    introduced the first viable code generation models that proved the concept was
    feasible. This was followed by the *Expansion phase* (late 2022 to early 2023),
    which brought significant improvements in reasoning capabilities and contextual
    understanding. Most recently, the *Diversification phase* (mid-2023 to 2024) has
    seen the emergence of both advanced commercial offerings and increasingly capable
    open-source alternatives.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 代码专用LLM的发展自其诞生以来就遵循了快速发展的轨迹，经历了三个不同的阶段，这些阶段已经改变了软件开发实践。第一个 *基础阶段*（2021年至2022年初）引入了第一个可行的代码生成模型，证明了该概念是可行的。这随后是
    *扩展阶段*（2022年末至2023年初），在这一阶段，推理能力和上下文理解能力得到了显著提升。最近，*多样化阶段*（2023年中至2024年）见证了先进商业产品和越来越强大的开源替代品的出现。
- en: This evolution has been characterized by parallel development tracks in both
    proprietary and open-source ecosystems. Initially, commercial models dominated
    the landscape, but open-source alternatives have gained substantial momentum more
    recently. Throughout this progression, several key milestones have marked transformative
    shifts in capabilities, opening new possibilities for AI-assisted development
    across different programming languages and tasks. The historical context of this
    evolution provides important insights for understanding implementation approaches
    with LangChain.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这种演变的特点是在专有和开源生态系统中都存在并行的发展轨迹。最初，商业模型主导了市场，但开源替代品最近已经获得了巨大的动力。在整个这一过程中，几个关键里程碑标志着能力上的转型性变化，为不同编程语言和任务上的AI辅助开发开辟了新的可能性。这一演变的历史背景为理解使用LangChain的实施方法提供了重要的见解。
- en: '![Figure 7.1: Evolution of code LLMs (2021–2024)](img/B32363_07_01.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![图7.1：代码LLM的演变（2021–2024）](img/B32363_07_01.png)'
- en: 'Figure 7.1: Evolution of code LLMs (2021–2024)'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.1：代码LLM的演变（2021–2024）
- en: '*Figure 7.1* illustrates the progression of code-specialized language models
    across commercial (upper track) and open-source (lower track) ecosystems. Key
    milestones are highlighted, showing the transition from early proof-of-concept
    models to increasingly specialized solutions. The timeline spans from early commercial
    models such as Codex to recent advancements such as Google’s Gemini 2.5 Pro (March
    2025) and specialized code models such as Mistral AI’s Codestral series.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '*图7.1* 展示了代码专用语言模型在商业（上轨）和开源（下轨）生态系统中的发展进程。关键里程碑被突出显示，展示了从早期概念验证模型到越来越专业化的解决方案的转变。时间线从早期的商业模型如Codex到最近的进步如谷歌的Gemini
    2.5 Pro（2025年3月）以及如Mistral AI的Codestral系列这样的专用代码模型。'
- en: 'In recent years, we’ve witnessed an explosion of LLMs fine-tuned specifically
    tailored for coding—commonly known as code LLMs. These models are rapidly evolving,
    each with its own set of strengths and limitations, and are reshaping the software
    development landscape. They offer the promise of accelerating development workflows
    across a broad spectrum of software engineering tasks:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，我们见证了针对编码专门定制的LLM（大型语言模型）的爆炸式增长，通常被称为代码LLM。这些模型正在迅速发展，每个模型都有其独特的优势和局限性，并正在重塑软件开发格局。它们为加速软件开发任务范围内的开发工作流程提供了希望：
- en: '**Code generation:** Transforming natural language requirements into code snippets
    or full functions. For instance, developers can generate boilerplate code or entire
    modules based on project specifications.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**代码生成**：将自然语言需求转换为代码片段或完整函数。例如，开发者可以根据项目规范生成样板代码或整个模块。'
- en: '**Test generation:** Creating unit tests from descriptions of expected behavior
    to improve code reliability.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**测试生成**：从预期行为的描述中创建单元测试，以提高代码可靠性。'
- en: '**Code documentation**: Automatically generating docstrings, comments, and
    technical documentation from existing code or specifications. This significantly
    reduces the documentation burden that often gets deprioritized in fast-paced development
    environments.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**代码文档**：从现有代码或规范中自动生成docstrings、注释和技术文档，这显著减少了在快速开发环境中经常被优先级降低的文档负担。'
- en: '**Code editing and refactoring:** Automatically suggesting improvements, fixing
    bugs, and restructuring code for maintainability.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**代码编辑和重构**：自动建议改进、修复错误和重构代码以提高可维护性。'
- en: '**Code translation:** Converting code between different programming languages
    or frameworks.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**代码翻译**：在不同编程语言或框架之间转换代码。'
- en: '**Debugging and automated program repair**: Identifying bugs within large codebases
    and generating patches to resolve issues. For example, tools such as SWE-agent,
    AutoCodeRover, and RepoUnderstander iteratively refine code by navigating repositories,
    analyzing abstract syntax trees, and applying targeted changes.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**调试和自动化程序修复**：识别大型代码库中的错误并生成补丁以解决问题。例如，SWE-agent、AutoCodeRover和RepoUnderstander等工具通过导航存储库、分析抽象语法树和应用有针对性的更改来迭代优化代码。'
- en: 'The landscape of code-specialized LLMs has grown increasingly diverse and complex.
    This evolution raises critical questions for developers implementing these models
    in production environments: Which model is most suitable for specific programming
    tasks? How do different models compare in terms of code quality, accuracy, and
    reasoning capabilities? What are the trade-offs between open-source and commercial
    options? This is where benchmarks become essential tools for evaluation and selection.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 代码专用LLM的领域正变得越来越多样化和复杂。这种演变对在生产环境中实施这些模型的开发者提出了关键问题：哪种模型最适合特定的编程任务？不同模型在代码质量、准确性和推理能力方面如何比较？开源和商业选项之间的权衡是什么？这正是基准测试成为评估和选择关键工具的地方。
- en: Benchmarks for code LLMs
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 代码LLM的基准测试
- en: Objective benchmarks provide standardized methods to compare model performance
    across a variety of coding tasks, languages, and complexity levels. They help
    quantify capabilities that would otherwise remain subjective impressions, allowing
    for data-driven implementation decisions.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 目标基准测试提供了标准化的方法，用于比较各种编码任务、语言和复杂程度下的模型性能。它们有助于量化那些否则可能保持主观印象的能力，从而允许基于数据的实施决策。
- en: 'For LangChain developers specifically, understanding benchmark results offers
    several advantages:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 对于LangChain开发者来说，理解基准测试结果具有以下优势：
- en: '**Informed model selection:** Choosing the optimal model for specific use cases
    based on quantifiable performance metrics rather than marketing claims or incomplete
    testing'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**信息化的模型选择**：根据可量化的性能指标选择特定用例的最佳模型，而不是基于营销声明或不完整的测试'
- en: '**Appropriate tooling**: Designing LangChain pipelines that incorporate the
    right balance of model capabilities and augmentation techniques based on known
    model strengths and limitations'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**适当的工具**：设计LangChain管道，根据已知的模型优势和局限性，平衡模型能力和增强技术'
- en: '**Cost-benefit analysis:** Evaluating whether premium commercial models justify
    their expense compared to free or self-hosted alternatives for particular applications'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**成本效益分析**：评估高级商业模型是否比免费或自托管替代方案在特定应用中的费用合理'
- en: '**Performance expectations:** Setting realistic expectations about what different
    models can achieve when integrated into larger systems'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**性能预期**：设定关于不同模型集成到更大系统时可以实现的真实预期。'
- en: 'Code-generating LLMs demonstrate varying capabilities across established benchmarks,
    with performance characteristics directly impacting their effectiveness in LangChain
    implementations. Recent evaluations of leading models, including OpenAI’s GPT-4o
    (2024), Anthropic’s Claude 3.5 Sonnet (2025), and open-source models such as Llama
    3, show significant advancements in standard benchmarks. For instance, OpenAI’s
    o1 achieves 92.4% pass@1 on HumanEval (*A Survey On Large Language Models For
    Code Generation*, 2025), while Claude 3 Opus reaches 84.9% on the same benchmark
    (*The Claude 3 Model Family: Opus, Sonnet, Haiku*, 2024). However, performance
    metrics reveal important distinctions between controlled benchmark environments
    and the complex requirements of production LangChain applications.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 代码生成型大型语言模型（LLM）在既定基准测试中展现出不同的能力，其性能特征直接影响其在LangChain实现中的有效性。最近对领先模型进行的评估，包括OpenAI的GPT-4o（2024年）、Anthropic的Claude
    3.5 Sonnet（2025年）以及如Llama 3等开源模型，在标准基准测试中显示出显著的进步。例如，OpenAI的o1在HumanEval（*关于代码生成的大型语言模型的调查*,
    2025年）上实现了92.4%的pass@1，而Claude 3 Opus在同一基准测试上达到84.9% (*Claude 3模型家族：Opus, Sonnet,
    Haiku*, 2024年)。然而，性能指标揭示了受控基准环境与生产LangChain应用复杂需求之间的重要区别。
- en: 'Standard benchmarks provide useful but limited insights into model capabilities
    for LangChain implementations:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 标准基准为LangChain实现中模型能力的洞察提供了有用的但有限的见解：
- en: '**HumanEval**: This benchmark evaluates functional correctness through 164
    Python programming problems. HumanEval primarily tests isolated function-level
    generation rather than the complex, multi-component systems typical in LangChain
    applications.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**HumanEval**：此基准通过164个Python编程问题评估功能正确性。HumanEval主要测试的是隔离的函数级生成，而不是LangChain应用中典型的复杂、多组件系统。'
- en: '**MBPP** (**Mostly Basic Programming Problems**): This contains approximately
    974 entry-level Python tasks. These problems lack the dependencies and contextual
    complexity found in production environments.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**MBPP**（**大多数基本编程问题**）：包含大约974个入门级Python任务。这些问题缺乏生产环境中存在的依赖关系和上下文复杂性。'
- en: '**ClassEval**: This newer benchmark tests class-level code generation, addressing
    some limitations of function-level testing. Recent research by Liu et al. (*Evaluating
    Large Language Models in Class-Level Code Generation*, 2024) shows performance
    degradation of 15–30% compared to function-level tasks, highlighting challenges
    in maintaining contextual dependencies across methods—a critical consideration
    for LangChain components that manage state.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ClassEval**：这个较新的基准测试类级别代码生成，解决了函数级测试的一些局限性。Liu等人（*在类级别代码生成中评估大型语言模型*, 2024年）的最新研究显示，与函数级任务相比，性能降低了15-30%，突显了在方法之间维护上下文依赖关系方面的挑战——这对于管理状态的LangChain组件来说是一个关键考虑因素。'
- en: '**SWE-bench**: More representative of real-world development, this benchmark
    evaluates models on bug-fixing tasks from actual GitHub repositories. Even top-performing
    models achieve only 40–65% success rates, as found by Jimenez et al. (*SWE-bench:
    Can Language Models Resolve Real-World GitHub Issues?*, 2023), demonstrating the
    significant gap between synthetic benchmarks and authentic coding challenges.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**SWE-bench**：更贴近现实世界开发，此基准评估模型在来自实际GitHub仓库的bug修复任务上的表现。即使是表现最顶尖的模型，成功率也只有40-65%，正如Jimenez等人（*SWE-bench：语言模型能否解决现实世界的GitHub问题？*,
    2023年）所发现的那样，这表明了合成基准与真实编码挑战之间的巨大差距。'
- en: LLM-based software engineering approaches
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于LLM的软件工程方法
- en: When implementing code-generating LLMs within LangChain frameworks, several
    key challenges emerge.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在LangChain框架内实现代码生成型LLM时，会出现几个关键挑战。
- en: Repository-level problems that require understanding multiple files, dependencies,
    and context present significant challenges. Research using the ClassEval benchmark
    (Xueying Du and colleagues, *Evaluating Large Language Models in Class-Level Code
    Generation*, 2024) demonstrated that LLMs find class-level code generation “significantly
    more challenging than generating standalone functions,” with performance consistently
    lower when managing dependencies between methods compared to function-level benchmarks
    such as HumanEval.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 需要理解多个文件、依赖关系和上下文级别的仓库问题提出了重大挑战。使用ClassEval基准（Xueying Du及其同事，*在类级别代码生成中评估大型语言模型*,
    2024年）的研究表明，LLM发现类级别代码生成“比生成独立函数具有显著挑战性”，在管理方法之间的依赖关系时，性能始终低于如HumanEval之类的函数级基准。
- en: 'LLMs can be leveraged to understand repository-level code context despite the
    inherent challenges. The following implementation demonstrates a practical approach
    to analyzing multi-file Python codebases with LangChain, loading repository files
    as context for the model to consider when implementing new features. This pattern
    helps address the context limitations by directly providing a repository structure
    to the LLM:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管存在固有的挑战，LLMs可以用来理解存储库级别的代码上下文。以下实现演示了使用LangChain分析多文件Python代码库的实用方法，将存储库文件作为上下文加载到模型中，以便在实现新功能时考虑。这种模式通过直接向LLM提供存储库结构来帮助解决上下文限制问题：
- en: '[PRE0]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This implementation uses GPT-4o to generate code while considering the context
    of entire repositories by pulling in relevant Python files to understand dependencies.
    This approach addresses context limitations but requires careful document chunking
    and retrieval strategies for large codebases.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 此实现使用GPT-4o生成代码，同时通过拉入相关的Python文件来考虑整个存储库的上下文，以理解依赖关系。这种方法解决了上下文限制问题，但需要为大型代码库进行仔细的文档分块和检索策略。
- en: 'Generated code often appears superficially correct but contains subtle bugs
    or security vulnerabilities that evade initial detection. The Uplevel Data Labs
    study (*Can GenAI Actually Improve Developer Productivity?*) analyzing nearly
    800 developers found a “significantly higher bug rate” in code produced by developers
    with access to AI coding assistants compared to those without. This is further
    supported by BlueOptima’s comprehensive analysis in 2024 of over 218,000 developers
    (*Debunking GitHub’s Claims: A Data-Driven Critique of Their Copilot Study*),
    which revealed that 88% of professionals needed to substantially rework AI-generated
    code before it was production-ready, often due to “aberrant coding patterns” that
    weren’t immediately apparent.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '生成的代码表面上看起来是正确的，但往往包含微妙的错误或安全漏洞，这些漏洞在初始检测中可能被忽略。Uplevel Data Labs的研究（*Can GenAI
    Actually Improve Developer Productivity?*）分析了近800名开发者，发现与没有访问AI编码辅助工具的开发者相比，能够访问AI编码辅助工具的开发者产生的代码中“显著更高的错误率”。这一点进一步得到了BlueOptima在2024年对超过218,000名开发者进行的全面分析（*Debunking
    GitHub’s Claims: A Data-Driven Critique of Their Copilot Study*）的支持，该分析揭示了88%的专业人士在代码投入生产前需要对其进行大量重写，通常是由于“异常编码模式”而这些模式并不立即明显。'
- en: 'Security researchers have identified a persistent risk where AI models inadvertently
    introduce security flaws by replicating insecure patterns from their training
    data, with these vulnerabilities frequently escaping detection during initial
    syntax and compilation checks (*Evaluating Large Language Models through Role-Guide
    and Self-Reflection: A Comparative Study*, 2024, and *HalluLens: LLM Hallucination
    Benchmark*, 2024). These findings emphasize the critical importance of thorough
    human review and testing of AI-generated code before production deployment.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '安全研究人员已经确定了一个持续存在的风险，即AI模型无意中通过复制其训练数据中的不安全模式引入安全漏洞，这些漏洞在初始语法和编译检查中经常被忽略（*Evaluating
    Large Language Models through Role-Guide and Self-Reflection: A Comparative Study*,
    2024，以及*HalluLens: LLM Hallucination Benchmark*, 2024）。这些发现强调了在投入生产部署之前对AI生成的代码进行彻底的人类审查和测试的至关重要性。'
- en: 'The following example demonstrates how to create a specialized validation chain
    that systematically analyzes generated code for common issues, serving as a first
    line of defense against subtle bugs and vulnerabilities:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例演示了如何创建一个专门的验证链，该链系统性地分析生成的代码以查找常见问题，作为对抗微妙错误和漏洞的第一道防线：
- en: '[PRE1]python'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE1]python'
- en: '{generated_code}'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '`{generated_code}`'
- en: Provide a detailed analysis with specific issues and recommended fixes. """
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 提供详细的分析，包括具体问题和推荐的修复方案。
- en: validation_prompt = PromptTemplate( input_variables=["generated_code"], template=validation_template
    )
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '`validation_prompt = PromptTemplate(input_variables=["generated_code"], template=validation_template)`'
- en: validation_chain = validation_prompt | llm
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '`validation_chain = validation_prompt | llm`'
- en: '[PRE2]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: from typing import List
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 从`typing`导入`List`
- en: from langchain_core.output_parsers import PydanticOutputParser
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 从`langchain_core.output_parsers`导入`PydanticOutputParser`
- en: from langchain_core.prompts import PromptTemplate
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 从`langchain_core.prompts`导入`PromptTemplate`
- en: from langchain_openai import ChatOpenAI
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 从`langchain_openai`导入`ChatOpenAI`
- en: from pydantic import BaseModel, Field
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 从`pydantic`导入`BaseModel`, `Field`
- en: Define the Pydantic model for structured output
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义Pydantic模型以进行结构化输出
- en: 'class SecurityAnalysis(BaseModel):'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '`class SecurityAnalysis(BaseModel):`'
- en: '"""Security analysis results for generated code."""'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '```安全分析生成的代码结果。```'
- en: 'vulnerabilities: List[str] = Field(description="List of identified security
    vulnerabilities")'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`vulnerabilities: List[str] = Field(description="已识别的安全漏洞列表")`'
- en: 'mitigation_suggestions: List[str] = Field(description="Suggested fixes for
    each vulnerability")'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 'mitigation_suggestions: List[str] = Field(description="针对每个漏洞的建议修复")'
- en: 'risk_level: str = Field(description="Overall risk assessment: Low, Medium,
    High, Critical")'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'risk_level: str = Field(description="总体风险评估：低，中，高，危急")'
- en: Initialize the output parser with the Pydantic model
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Pydantic 模型初始化输出解析器
- en: parser = PydanticOutputParser(pydantic_object=SecurityAnalysis)
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: parser = PydanticOutputParser(pydantic_object=SecurityAnalysis)
- en: Create the prompt template with format instructions from the parser
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用解析器的格式说明创建提示模板
- en: security_prompt = PromptTemplate.from_template(
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: security_prompt = PromptTemplate.from_template(
- en: 'template="""Analyze the following code for security vulnerabilities: {code}'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: template="""分析以下代码的安全漏洞：{code}
- en: 'Consider:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑：
- en: SQL injection vulnerabilities
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: SQL 注入漏洞
- en: Cross-site scripting (XSS) risks
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 跨站脚本 (XSS) 风险
- en: Insecure direct object references
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 不安全直接对象引用
- en: Authentication and authorization weaknesses
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 身份验证和授权弱点
- en: Sensitive data exposure
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 敏感数据泄露
- en: Missing input validation
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 缺少输入验证
- en: Command injection opportunities
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 命令注入机会
- en: Insecure dependency usage
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 不安全依赖使用
- en: '{format_instructions}""",'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '{format_instructions}"""'
- en: '[PRE3]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: input_variables=["code"],
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: input_variables=["code"],
- en: 'partial_variables={"format_instructions": parser.get_format_instructions()}'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'partial_variables={"format_instructions": parser.get_format_instructions()}'
- en: )
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: Initialize the language model
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 初始化语言模型
- en: llm = ChatOpenAI(model="gpt-4", temperature=0)
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: llm = ChatOpenAI(model="gpt-4", temperature=0)
- en: Compose the chain using LCEL
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 LCEL 组合链
- en: security_chain = security_prompt | llm | parser
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: security_chain = security_prompt | llm | parser
- en: '[PRE4]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: from langchain_google_genai import ChatGoogleGenerativeAI
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: from langchain_google_genai import ChatGoogleGenerativeAI
- en: question = """
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: question = """
- en: 'Given an integer n, return a string array answer (1-indexed) where:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个整数 n，返回一个字符串数组 answer（1 索引）：
- en: answer[i] == "FizzBuzz" if i is divisible by 3 and 5.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: answer[i] == "FizzBuzz" 如果 i 能被 3 和 5 整除。
- en: answer[i] == "Fizz" if i is divisible by 3.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: answer[i] == "Fizz" 如果 i 能被 3 整除。
- en: answer[i] == "Buzz" if i is divisible by 5.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: answer[i] == "Buzz" 如果 i 能被 5 整除。
- en: answer[i] == i (as a string) if none of the above conditions are true.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: answer[i] == i (作为字符串) 如果没有上述任何条件。
- en: '"""'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '"""'
- en: llm = ChatGoogleGenerativeAI(model="gemini-1.5-pro")
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: llm = ChatGoogleGenerativeAI(model="gemini-1.5-pro")
- en: print(llm.invoke(question).content)
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: print(llm.invoke(question).content)
- en: '[PRE5]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: from langchain.llms import HuggingFacePipeline
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: from langchain.llms import HuggingFacePipeline
- en: from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline
- en: Choose a more up-to-date model
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择一个更新的模型
- en: checkpoint = "google/codegemma-2b"
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: checkpoint = "google/codegemma-2b"
- en: Load the model and tokenizer
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加载模型和分词器
- en: model = AutoModelForCausalLM.from_pretrained(checkpoint)
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: model = AutoModelForCausalLM.from_pretrained(checkpoint)
- en: tokenizer = AutoTokenizer.from_pretrained(checkpoint)
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: tokenizer = AutoTokenizer.from_pretrained(checkpoint)
- en: Create a text generation pipeline
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建文本生成管道
- en: pipe = pipeline(
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: pipe = pipeline(
- en: task="text-generation",
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: task="text-generation",
- en: model=model,
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: model=model,
- en: tokenizer=tokenizer,
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: tokenizer=tokenizer,
- en: max_new_tokens=500
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: max_new_tokens=500
- en: )
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: Integrate the pipeline with LangChain
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将管道与 LangChain 集成
- en: llm = HuggingFacePipeline(pipeline=pipe)
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: llm = HuggingFacePipeline(pipeline=pipe)
- en: Define the input text
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义输入文本
- en: text = """
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: text = """
- en: 'def calculate_primes(n):'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 'def calculate_primes(n):'
- en: \"\"\"Create a list of consecutive integers from 2 up to N.
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: \"\"\"创建从 2 到 N 的连续整数列表。
- en: 'For example:'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 例如：
- en: '>>> calculate_primes(20)'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '>>> calculate_primes(20)'
- en: 'Output: [2, 3, 5, 7, 11, 13, 17, 19]'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出：[2, 3, 5, 7, 11, 13, 17, 19]
- en: \"\"\"
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: \"\"\"
- en: '[PRE8]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '"""'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '"""'
- en: Use the LangChain LLM to generate text
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 LangChain LLM 生成文本
- en: output = llm(text)
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: output = llm(text)
- en: print(output)
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: print(output)
- en: '[PRE9]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'def calculate_primes(n):'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 'def calculate_primes(n):'
- en: '"""Create a list of consecutive integers from 2 up to N.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '"""创建从 2 到 N 的连续整数列表。'
- en: 'For example:'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 例如：
- en: '>>> calculate_primes(20)'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '>>> calculate_primes(20)'
- en: 'Output: [2, 3, 5, 7, 11, 13, 17, 19]'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出：[2, 3, 5, 7, 11, 13, 17, 19]
- en: '"""'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"""'
- en: primes = []
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: primes = []
- en: 'for i in range(2, n + 1):'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 'for i in range(2, n + 1):'
- en: 'if is_prime(i):'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 'if is_prime(i):'
- en: primes.append(i)
  id: totrans-157
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: primes.append(i)
- en: return primes
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 返回素数
- en: '[PRE10]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'def is_prime(n):'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 'def is_prime(n):'
- en: '"""Return True if n is prime."""'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '"""返回 True 如果 n 是素数。'
- en: 'if n < 2:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 'if n < 2:'
- en: return False
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 返回 False
- en: 'for i in range(2, int(n ** 0.5) + 1):'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 'for i in range(2, int(n ** 0.5) + 1):'
- en: 'if n % i == 0:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 'if n % i == 0:'
- en: return False
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: return False
- en: return True
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: return True
- en: 'def main():'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 'def main():'
- en: '"""Get user input and print the list of primes."""'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '"""获取用户输入并打印素数列表。'
- en: 'n = int(input("Enter a number: "))'
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: n = int(input("输入一个数字："))
- en: primes = calculate_primes(n)
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: primes = calculate_primes(n)
- en: print(primes)
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: print(primes)
- en: 'if __name__ == "__main__":'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 'if __name__ == "__main__":'
- en: main()
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: main()
- en: <|file_separator|>
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: <|file_separator|>
- en: '[PRE11]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: from langchain.llms import HuggingFaceHub
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: from langchain.llms import HuggingFaceHub
- en: Choose a lightweight model good for code generation
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择一个适合代码生成的轻量级模型
- en: repo_id = "bigcode/starcoder"
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: repo_id = "bigcode/starcoder"
- en: Initialize the HuggingFaceHub LLM
  id: totrans-180
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 初始化HuggingFaceHub LLM
- en: llm = HuggingFaceHub(
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: llm = HuggingFaceHub(
- en: repo_id=repo_id,
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: repo_id=repo_id,
- en: '[PRE12]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: task="text-generation",
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: task="text-generation",
- en: model_kwargs={
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: model_kwargs={
- en: '"temperature": 0.5,'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '"temperature": 0.5,'
- en: '"max_length": 1000'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '"max_length": 1000'
- en: '}'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '}'
- en: )
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: Use the LangChain LLM to generate text
  id: totrans-190
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用LangChain LLM生成文本
- en: output = llm.invoke(text)
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: output = llm.invoke(text)
- en: print(output)
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: print(output)
- en: '[PRE13]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: from langchain_anthropic import ChatAnthropic
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: from langchain_anthropic import ChatAnthropic
- en: from langchain_core.prompts.prompt import PromptTemplate
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: from langchain_core.prompts.prompt import PromptTemplate
- en: 'template = """Question: {question}'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: template = """问题：{question}
- en: Let's think step by step.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们一步一步地思考。
- en: 'Answer:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 答案：
- en: '"""'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '"""'
- en: prompt = PromptTemplate(template=template, input_variables=["question"])
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: prompt = PromptTemplate(template=template, input_variables=["question"])
- en: llm = ChatAnthropic(model='claude-3-opus-20240229')
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: llm = ChatAnthropic(model='claude-3-opus-20240229')
- en: llm_chain = prompt | llm
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: llm_chain = prompt | llm
- en: print(llm_chain.invoke(text))
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: print(llm_chain.invoke(text))
- en: '[PRE14]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'To calculate the prime numbers up to a given number N, we can follow the Sieve
    of Eratosthenes algorithm. Here''s a step-by-step approach to solve the problem:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 要计算给定数字N的素数，我们可以遵循埃拉托斯特尼筛法。以下是解决问题的逐步方法：
- en: '[PRE15]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Step-by-step explanation:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 逐步解释：
- en: We create a list called `numbers` that contains consecutive integers from 2
    to N using the `range()` function.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`range()`函数创建一个名为`numbers`的列表，其中包含从2到N的连续整数。
- en: We initialize an empty list called `primes` to store the prime numbers that
    we will calculate.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 我们初始化一个名为`primes`的空列表，用于存储我们将要计算的素数。
- en: We start a loop that continues as long as there are numbers in the `numbers`
    list.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 我们开始一个循环，只要`numbers`列表中还有数字，循环就会继续。
- en: Inside the loop, we take the first number from the `numbers` list and consider
    it as a prime number. We append this prime number to the `primes` list.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 在循环内部，我们从`numbers`列表中取出第一个数字，将其视为一个素数。我们将这个素数添加到`primes`列表中。
- en: We remove all the multiples of the prime number from the `numbers` list using
    a list comprehension. The list comprehension creates a new list containing only
    the numbers that are not divisible by the current prime number.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用列表推导从`numbers`列表中删除所有素数的倍数。列表推导创建了一个新列表，其中只包含不能被当前素数整除的数字。
- en: '[PRE16]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: We repeat steps 4 and 5 until the `numbers` list becomes empty. This ensures
    that we have considered all the numbers up to N and identified the prime numbers
    among them.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 我们重复步骤4和5，直到`numbers`列表变为空。这确保了我们考虑了所有从1到N的数字，并从中识别出素数。
- en: Finally, we return the `primes` list, which contains all the prime numbers up
    to N.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们返回包含所有从1到N的素数的`primes`列表。
- en: '[PRE17]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Output:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE19]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[PRE20]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: from langchain_openai import ChatOpenAI
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: from langchain_openai import ChatOpenAI
- en: from langchain.agents import load_tools, initialize_agent, AgentType
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: from langchain.agents import load_tools, initialize_agent, AgentType
- en: from langchain_experimental.tools import PythonREPLTool
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: from langchain_experimental.tools import PythonREPLTool
- en: 'tools = [PythonREPLTool()]   # Gives agent ability to run Python code'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 'tools = [PythonREPLTool()]   # 使代理能够运行Python代码'
- en: llm = ChatOpenAI()
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: llm = ChatOpenAI()
- en: Set up the agent with necessary tools and model
  id: totrans-226
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用必要的工具和模型设置代理
- en: agent = initialize_agent(
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: agent = initialize_agent(
- en: tools,
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 工具
- en: 'llm,  # Language model to power the agent'
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'llm,  # 语言模型以驱动代理'
- en: agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
- en: 'verbose=True # Shows agent''s thinking process'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'verbose=True # 显示代理的思考过程'
- en: ')  # Agent makes decisions without examples'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: ')  # 代理无需示例即可做出决策'
- en: result = agent("What are the prime numbers until 20?")
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: result = agent("What are the prime numbers until 20?")
- en: print(result)
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: print(result)
- en: '[PRE21]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Entering new AgentExecutor chain...
  id: totrans-236
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 进入新的AgentExecutor链...
- en: I can write a Python script to find the prime numbers up to 20.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 我可以编写一个Python脚本来查找20以内的素数。
- en: 'Action: Python_REPL'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 行动：Python_REPL
- en: 'Action Input: def is_prime(n):'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: '行动输入：def is_prime(n):'
- en: 'if n <= 1:'
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'if n <= 1:'
- en: return False
  id: totrans-241
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: return False
- en: 'for i in range(2, int(n**0.5) + 1):'
  id: totrans-242
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'for i in range(2, int(n**0.5) + 1):'
- en: 'if n % i == 0:'
  id: totrans-243
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'if n % i == 0:'
- en: return False
  id: totrans-244
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: return False
- en: return True
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: return True
- en: primes = [num for num in range(2, 21) if is_prime(num)]
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: primes = [num for num in range(2, 21) if is_prime(num)]
- en: print(primes)
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: print(primes)
- en: 'Observation: [2, 3, 5, 7, 11, 13, 17, 19]'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 观察：[2, 3, 5, 7, 11, 13, 17, 19]
- en: I now know the final answer
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 我现在知道了最终答案
- en: 'Final Answer: [2, 3, 5, 7, 11, 13, 17, 19]'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 最终答案：[2, 3, 5, 7, 11, 13, 17, 19]
- en: Finished chain.
  id: totrans-251
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 完成链。
- en: '{''input'': ''What are the prime numbers until 20?'', ''output'': ''[2, 3,
    5, 7, 11, 13, 17, 19]''}'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: '{''input'': ''What are the prime numbers until 20?'', ''output'': ''[2, 3,
    5, 7, 11, 13, 17, 19]''}'
- en: '[PRE22]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: from langchain_community.document_loaders import DocusaurusLoader
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: from langchain_community.document_loaders import DocusaurusLoader
- en: import nest_asyncio
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: import nest_asyncio
- en: nest_asyncio.apply()
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: nest_asyncio.apply()
- en: '[PRE23]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Load all pages from LangChain docs
  id: totrans-258
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从LangChain文档中加载所有页面
- en: loader = DocusaurusLoader("https://python.langchain.com")
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: loader = DocusaurusLoader("https://python.langchain.com")
- en: documents[0]
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: documents[0]
- en: nest_asyncio.apply() enables async operations in Jupyter notebooks. The loader
    gets all pages.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: nest_asyncio.apply() 启用 Jupyter 笔记本中的异步操作。加载器获取所有页面。
- en: '[PRE24]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: from langchain.embeddings import CacheBackedEmbeddings
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 从 langchain.embeddings 导入 CacheBackedEmbeddings
- en: from langchain_openai import OpenAIEmbeddings
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 从 langchain_openai 导入 OpenAIEmbeddings
- en: from langchain.storage import LocalFileStore
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 从 langchain.storage 导入 LocalFileStore
- en: Cache embeddings locally to avoid redundant API calls
  id: totrans-266
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本地缓存嵌入以避免重复的 API 调用
- en: store = LocalFileStore("./cache/")
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: store = LocalFileStore("./cache/")
- en: underlying_embeddings = OpenAIEmbeddings(model="text-embedding-3-large")
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: underlying_embeddings = OpenAIEmbeddings(model="text-embedding-3-large")
- en: embeddings = CacheBackedEmbeddings.from_bytes_store(
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: embeddings = CacheBackedEmbeddings.from_bytes_store(
- en: underlying_embeddings, store, namespace=underlying_embeddings.model
  id: totrans-270
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: underlying_embeddings, store, namespace=underlying_embeddings.model
- en: )
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: '[PRE25]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: from langchain_text_splitters import RecursiveCharacterTextSplitter
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 从 langchain_text_splitters 导入 RecursiveCharacterTextSplitter
- en: text_splitter = RecursiveCharacterTextSplitter(
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: text_splitter = RecursiveCharacterTextSplitter(
- en: chunk_size=1000,
  id: totrans-275
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: chunk_size=1000,
- en: chunk_overlap=20,
  id: totrans-276
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: chunk_overlap=20,
- en: length_function=len,
  id: totrans-277
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: length_function=len,
- en: is_separator_regex=False,
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: is_separator_regex=False,
- en: )
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: splits = text_splitter.split_documents(documents)
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: splits = text_splitter.split_documents(documents)
- en: '[PRE26]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: from langchain_chroma import Chroma
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 从 langchain_chroma 导入 Chroma
- en: Store document embeddings for efficient retrieval
  id: totrans-283
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 存储文档嵌入以实现高效检索
- en: vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings)
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings)
- en: '[PRE27]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: from langchain_google_vertexai import VertexAI
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 从 langchain_google_vertexai 导入 VertexAI
- en: llm = VertexAI(model_name="gemini-pro")
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: llm = VertexAI(model_name="gemini-pro")
- en: '[PRE28]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: from langchain import hub
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 从 langchain 导入 hub
- en: retriever = vectorstore.as_retriever()
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: retriever = vectorstore.as_retriever()
- en: Use community-created RAG prompt template
  id: totrans-291
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用社区创建的 RAG 提示模板
- en: prompt = hub.pull("rlm/rag-prompt")
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: prompt = hub.pull("rlm/rag-prompt")
- en: '[PRE29]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: from langchain_core.runnables import RunnablePassthrough
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 从 langchain_core.runnables 导入 RunnablePassthrough
- en: 'def format_docs(docs):'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 'def format_docs(docs):'
- en: return "\n\n".join(doc.page_content for doc in docs)
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: return "\n\n".join(doc.page_content for doc in docs)
- en: Chain combines context retrieval, prompting, and response generation
  id: totrans-297
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 链结合上下文检索、提示和响应生成
- en: rag_chain = (
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: rag_chain = (
- en: '{"context": retriever | format_docs, "question": RunnablePassthrough()}'
  id: totrans-299
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '{"context": retriever | format_docs, "question": RunnablePassthrough()}'
- en: '| prompt'
  id: totrans-300
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '| prompt'
- en: '| llm'
  id: totrans-301
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '| llm'
- en: '| StrOutputParser()'
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '| StrOutputParser()'
- en: )
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: '[PRE30]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: response = rag_chain.invoke("What is Task Decomposition?")
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: response = rag_chain.invoke("什么是任务分解？")
- en: '[PRE31]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: import os
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 导入 os
- en: from git import Repo
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 从 git 导入 Repo
- en: from langchain_community.document_loaders.generic import GenericLoader
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 从 langchain_community.document_loaders.generic 导入 GenericLoader
- en: from langchain_community.document_loaders.parsers import LanguageParser
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 从 langchain_community.document_loaders.parsers 导入 LanguageParser
- en: from langchain_text_splitters import Language, RecursiveCharacterTextSplitter
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 从 langchain_text_splitters 导入 Language, RecursiveCharacterTextSplitter
- en: Clone the book repository from GitHub
  id: totrans-312
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从 GitHub 克隆书籍仓库
- en: 'repo_path = os.path.expanduser("~/Downloads/generative_ai_with_langchain")  #
    this directory should not exist yet!'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 'repo_path = os.path.expanduser("~/Downloads/generative_ai_with_langchain")  #
    此目录尚不存在！'
- en: repo = Repo.clone_from("https://github.com/benman1/generative_ai_with_langchain",
    to_path=repo_path)
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: repo = Repo.clone_from("https://github.com/benman1/generative_ai_with_langchain",
    to_path=repo_path)
- en: '[PRE32]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: loader = GenericLoader.from_filesystem(
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: loader = GenericLoader.from_filesystem(
- en: repo_path,
  id: totrans-317
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: repo_path,
- en: glob="**/*",
  id: totrans-318
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: glob="**/*",
- en: suffixes=[".py"],
  id: totrans-319
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: suffixes=[".py"],
- en: parser=LanguageParser(language=Language.PYTHON, parser_threshold=500),
  id: totrans-320
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: parser=LanguageParser(language=Language.PYTHON, parser_threshold=500),
- en: )
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: documents = loader.load()
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: documents = loader.load()
- en: python_splitter = RecursiveCharacterTextSplitter.from_language(
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: python_splitter = RecursiveCharacterTextSplitter.from_language(
- en: language=Language.PYTHON, chunk_size=50, chunk_overlap=0
  id: totrans-324
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: language=Language.PYTHON, chunk_size=50, chunk_overlap=0
- en: )
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: Split the Document into chunks for embedding and vector storage
  id: totrans-326
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将文档分割成块以进行嵌入和向量存储
- en: texts = python_splitter.split_documents(documents)
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: texts = python_splitter.split_documents(documents)
- en: '[PRE33]'
  id: totrans-328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Create vector store and retriever
  id: totrans-329
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建向量存储和检索器
- en: db = Chroma.from_documents(texts, OpenAIEmbeddings())
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: db = Chroma.from_documents(texts, OpenAIEmbeddings())
- en: retriever = db.as_retriever(
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: retriever = db.as_retriever(
- en: 'search_type="mmr",  # Maximal Marginal Relevance for diverse results'
  id: totrans-332
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'search_type="mmr",  # 最大边际相关度用于多样化结果'
- en: 'search_kwargs={"k": 8}  # Return 8 most relevant chunks'
  id: totrans-333
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'search_kwargs={"k": 8}  # 返回 8 个最相关的片段'
- en: )
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: Set up Q&A chain
  id: totrans-335
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置 Q&A 链
- en: prompt = ChatPromptTemplate.from_messages([
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: prompt = ChatPromptTemplate.from_messages([
- en: ("system", "Answer based on context:\n\n{context}"),
  id: totrans-337
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ("system", "基于上下文回答：\n\n{context}"),
- en: ("placeholder", "{chat_history}"),
  id: totrans-338
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ("placeholder", "{chat_history}"),
- en: ("user", "{input}"),
  id: totrans-339
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ("user", "{input}"),
- en: '])'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: '])'
- en: Create chain components
  id: totrans-341
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建链组件
- en: document_chain = create_stuff_documents_chain(ChatOpenAI(), prompt)
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: document_chain = create_stuff_documents_chain(ChatOpenAI(), prompt)
- en: qa = create_retrieval_chain(retriever, document_chain)
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: qa = create_retrieval_chain(retriever, document_chain)
- en: '[PRE34]'
  id: totrans-344
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: question = "What examples are in the code related to software development?"
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: question = "What examples are in the code related to software development?"
- en: 'result = qa.invoke({"input": question})'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 'result = qa.invoke({"input": question})'
- en: print(result["answer"])
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: print(result["answer"])
- en: 'Here are some examples of the code related to software development in the given
    context:'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 在给定上下文中，以下是一些与软件开发相关的代码示例：
- en: '[PRE35]'
  id: totrans-349
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '1\. Task planner and executor for software development: This indicates that
    the code includes functionality for planning and executing tasks related to software
    development.'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 1. 软件开发的任务规划器和执行器：这表明代码包括与软件开发相关的任务规划和执行功能。
- en: '2\. debug your code: This suggests that there is a recommendation to debug
    the code if an error occurs during software development.'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 2. 调试你的代码：这表明如果在软件开发过程中发生错误，建议调试代码。
- en: These examples provide insights into the software development process described
    in the context.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 这些示例提供了对上下文中描述的软件开发过程的见解。
- en: '[PRE36]'
  id: totrans-353
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: from langchain_experimental.agents.agent_toolkits.python.base import create_python_agent
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: from langchain_experimental.agents.agent_toolkits.python.base import create_python_agent
- en: from langchain_experimental.tools.python.tool import PythonREPLTool
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: from langchain_experimental.tools.python.tool import PythonREPLTool
- en: from langchain_anthropic import ChatAnthropic
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: from langchain_anthropic import ChatAnthropic
- en: from langchain.agents.agent_types import AgentType
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: from langchain.agents.agent_types import AgentType
- en: agent_executor = create_python_agent(
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: agent_executor = create_python_agent(
- en: llm=ChatAnthropic(model='claude-3-opus-20240229'),
  id: totrans-359
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: llm=ChatAnthropic(model='claude-3-opus-20240229'),
- en: tool=PythonREPLTool(),
  id: totrans-360
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: tool=PythonREPLTool(),
- en: '[PRE37]'
  id: totrans-361
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: verbose=True,
  id: totrans-362
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: verbose=True,
- en: agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
  id: totrans-363
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
- en: )
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: '[PRE38]'
  id: totrans-365
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: result = agent_executor.run(
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: result = agent_executor.run(
- en: '"""Understand, write a single neuron neural network in PyTorch.'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: '"""理解，用 PyTorch 编写一个单一神经元神经网络。'
- en: Take synthetic data for y=2x. Train for 1000 epochs and print every 100 epochs.
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 y=2x 的合成数据。训练 1000 个 epoch，每 100 个 epoch 打印一次。
- en: Return prediction for x = 5"""
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 返回 x = 5 的预测"""
- en: )
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: print(result)
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: print(result)
- en: '[PRE39]'
  id: totrans-372
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Entering new AgentExecutor chain...
  id: totrans-373
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 进入新的 AgentExecutor 链...
- en: 'Here is a single neuron neural network in PyTorch that trains on synthetic
    data for y=2x, prints the loss every 100 epochs, and returns the prediction for
    x=5:'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个在 PyTorch 中训练的单一神经元神经网络，用于合成数据 y=2x，每 100 个 epoch 打印一次损失，并返回 x=5 的预测结果：
- en: 'Action: Python_REPL'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 行动：Python_REPL
- en: 'Action Input:'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 行动输入：
- en: import torch
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: import torch
- en: import torch.nn as nn
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: import torch.nn as nn
- en: Create synthetic data
  id: totrans-379
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建合成数据
- en: X = torch.tensor([[1.0], [2.0], [3.0], [4.0]])
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: X = torch.tensor([[1.0], [2.0], [3.0], [4.0]])
- en: y = torch.tensor([[2.0], [4.0], [6.0], [8.0]])
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: y = torch.tensor([[2.0], [4.0], [6.0], [8.0]])
- en: Define the model
  id: totrans-382
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义模型
- en: '[...] # Code for creating the model omitted for brevity'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: '[...] # 省略了创建模型的代码以节省篇幅'
- en: 'Observation:'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 观察：
- en: 'Epoch [100/1000], Loss: 0.0529'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: Epoch [100/1000], 损失：0.0529
- en: '[...] # Training progress for epochs 200-900 omitted for brevity'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: '[...] # 省略了 200-900 个 epoch 的训练进度以节省篇幅'
- en: '[PRE40]'
  id: totrans-387
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Epoch [1000/1000], Loss: 0.0004'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: Epoch [1000/1000], 损失：0.0004
- en: 'Prediction for x=5: 9.9659'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 x=5 的预测：9.9659
- en: 'To summarize:'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 总结：
- en: '- I created a single neuron neural network model in PyTorch using nn.Linear(1,
    1)'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: '- 我使用 nn.Linear(1, 1) 在 PyTorch 中创建了一个单一神经元神经网络模型'
- en: '- I generated synthetic data where y=2x for training'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: '- 我生成了 y=2x 的合成数据进行训练'
- en: '- I defined the MSE loss function and SGD optimizer'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: '- 我定义了 MSE 损失函数和 SGD 优化器'
- en: '- I trained the model for 1000 epochs, printing the loss every 100 epochs'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: '- 我训练了模型 1000 个 epoch，每 100 个 epoch 打印一次损失'
- en: '- After training, I made a prediction for x=5'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: '- 训练后，我为 x=5 进行了预测'
- en: The final prediction for x=5 is 9.9659, which is very close to the expected
    value of 10 (since y=2x).
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 x=5 的最终预测为 9.9659，非常接近预期的 10（因为 y=2x）。
- en: So in conclusion, I was able to train a simple single neuron PyTorch model to
    fit the synthetic y=2x data well and make an accurate prediction for a new input
    x=5.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，总的来说，我能够训练一个简单的单一神经元 PyTorch 模型，使其很好地拟合合成数据 y=2x，并对新的输入 x=5 进行准确的预测。
- en: 'Final Answer: The trained single neuron PyTorch model predicts a value of 9.9659
    for x=5.'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 最终答案：训练好的单一神经元 PyTorch 模型预测 x=5 的值为 9.9659。
- en: Finished chain.
  id: totrans-399
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 链接完成。
- en: The final output confirms that our agent successfully built and trained a model
    that learned the y=2x relationship. The prediction for x=5 is approximately 9.97,
    which is very close to the expected value of 10.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 最终输出确认我们的代理成功构建并训练了一个学习 y=2x 关系的模型。对于 x=5 的预测值约为 9.97，非常接近预期的 10。
- en: '[PRE41]'
  id: totrans-401
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: from sklearn.datasets import load_iris
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: from sklearn.datasets import load_iris
- en: df = load_iris(as_frame=True)["data"]
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: df = load_iris(as_frame=True)["data"]
- en: df.to_csv("iris.csv", index=False)
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: df.to_csv("iris.csv", index=False)
- en: '[PRE42]'
  id: totrans-405
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: from langchain_experimental.agents.agent_toolkits.pandas.base import
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: from langchain_experimental.agents.agent_toolkits.pandas.base import
- en: create_pandas_dataframe_agent
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: create_pandas_dataframe_agent
- en: from langchain import PromptTemplate
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: from langchain import PromptTemplate
- en: PROMPT = (
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: PROMPT = (
- en: '"If you do not know the answer, say you don''t know.\n"'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: '"如果你不知道答案，就说你不知道。\n"'
- en: '"Think step by step.\n"'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: '"一步一步思考。\n"'
- en: '"\n"'
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: '"\n"'
- en: '"Below is the query.\n"'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: '"以下是对查询的描述。\n"'
- en: '[PRE43]'
  id: totrans-414
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '"Query: {query}\n"'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: '"查询：{query}\n"'
- en: )
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: prompt = PromptTemplate(template=PROMPT, input_variables=["query"])
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: prompt = PromptTemplate(template=PROMPT, input_variables=["query"])
- en: llm = OpenAI()
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: llm = OpenAI()
- en: agent = create_pandas_dataframe_agent(
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: agent = create_pandas_dataframe_agent(
- en: llm, df, verbose=True, allow_dangerous_code=True
  id: totrans-420
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: llm, df, verbose=True, allow_dangerous_code=True
- en: )
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: '[PRE44]'
  id: totrans-422
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: agent.run(prompt.format(query="What's this dataset about?"))
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: agent.run(prompt.format(query="What's this dataset about?"))
- en: '[PRE45]'
  id: totrans-424
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Output:'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: Entering new AgentExecutor chain...
  id: totrans-426
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 进入新的AgentExecutor链...
- en: 'Thought: I need to understand the structure and contents of the dataset.'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 思考：我需要理解数据集的结构和内容。
- en: 'Action: python_repl_ast'
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 操作：python_repl_ast
- en: 'Action Input: print(df.head())'
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 操作输入：print(df.head())
- en: sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 花瓣长度 (cm)  花瓣宽度 (cm)  花萼长度 (cm)  花萼宽度 (cm)
- en: 0                5.1               3.5                1.4               0.2
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 0                5.1               3.5                1.4               0.2
- en: 1                4.9               3.0                1.4               0.2
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 1                4.9               3.0                1.4               0.2
- en: 2                4.7               3.2                1.3               0.2
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 2                4.7               3.2                1.3               0.2
- en: '[PRE46]'
  id: totrans-434
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 3                4.6               3.1                1.5               0.2
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 3                4.6               3.1                1.5               0.2
- en: 4                5.0               3.6                1.4               0.2
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 4                5.0               3.6                1.4               0.2
- en: This dataset contains four features (sepal length, sepal width, petal length,
    and petal width) and 150 entries.
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集包含四个特征（花瓣长度、花瓣宽度、花萼长度和花萼宽度）和150个条目。
- en: 'Final Answer: Based on the observation, this dataset is likely about measurements
    of flower characteristics.'
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: 最终答案：根据观察，这个数据集很可能是关于花卉特征的测量。
- en: Finished chain.
  id: totrans-439
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 链接完成。
- en: '''Based on the observation, this dataset is likely about measurements of flower
    characteristics.'''
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: '''根据观察，这个数据集很可能是关于花卉特征的测量。'''
- en: '[PRE47]'
  id: totrans-441
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: agent.run(prompt.format(query="Which row has the biggest difference between
    petal length and petal width?"))
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: agent.run(prompt.format(query="Which row has the biggest difference between
    petal length and petal width?"))
- en: '[PRE48]'
  id: totrans-443
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: Entering new AgentExecutor chain...
  id: totrans-444
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 进入新的AgentExecutor链...
- en: 'Thought: First, we need to find the difference between petal length and petal
    width for each row. Then, we need to find the row with the maximum difference.'
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: 思考：首先，我们需要找到每行花瓣长度和花瓣宽度之间的差异。然后，我们需要找到差异最大的行。
- en: 'Action: python_repl_ast'
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 操作：python_repl_ast
- en: 'Action Input: df[''petal_diff''] = df[''petal length (cm)''] - df[''petal width
    (cm)'']'
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: 操作输入：df['petal_diff'] = df['petal length (cm)'] - df['petal width (cm)']
- en: df['petal_diff'].max()
  id: totrans-448
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: df['petal_diff'].max()
- en: 'Observation: 4.7'
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 观察：4.7
- en: 'Action: python_repl_ast'
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: 操作：python_repl_ast
- en: 'Action Input: df[''petal_diff''].idxmax()'
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: 操作输入：df['petal_diff'].idxmax()
- en: 'Observation: 122'
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: 观察：122
- en: '[PRE49]'
  id: totrans-453
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Final Answer: Row 122 has the biggest difference between petal length and petal
    width.'
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: 最终答案：第122行花瓣长度和花瓣宽度之间的差异最大。
- en: Finished chain.
  id: totrans-455
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 链接完成。
- en: '''Row 122 has the biggest difference between petal length and petal width.'''
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: '''第122行花瓣长度和花瓣宽度之间的差异最大。'''
- en: '[PRE50]'
  id: totrans-457
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: agent.run(prompt.format(query="Show the distributions for each column visually!"))
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: agent.run(prompt.format(query="Show the distributions for each column visually!"))
- en: '```'
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: '```'
- en: For this visualization query, the agent generates code to create appropriate
    plots for each measurement column. The agent decides to use histograms to show
    the distribution of each feature in the dataset, providing visual insights that
    complement the numerical analyses from previous queries. This demonstrates how
    our agent can generate code for creating informative data visualizations that
    help understand the dataset’s characteristics.
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个可视化查询，代理生成了创建每个测量列适当图表的代码。代理决定使用直方图来展示数据集中每个特征的分布，提供与之前查询的数值分析相补充的视觉洞察。这展示了我们的代理如何生成代码以创建有助于理解数据集特征的信息性数据可视化。
- en: These three examples showcase the versatility of our data analysis agent in
    handling different types of analytical tasks. By progressively increasing the
    complexity of our queries—from basic exploration to statistical analysis and visualization—we
    can see how the agent uses its tools effectively to provide meaningful insights
    about the data.
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 这三个示例展示了我们的数据分析代理在处理不同类型分析任务中的多功能性。通过逐步增加查询的复杂性——从基本探索到统计分析与可视化——我们可以看到代理如何有效地使用其工具来提供关于数据的实质性见解。
- en: 'When designing your own data analysis agents, consider providing them with
    a variety of analysis tools that cover the full spectrum of data science workflows:
    exploration, preprocessing, analysis, visualization, and interpretation.'
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 当设计自己的数据分析代理时，考虑为他们提供覆盖数据科学工作流程全谱系的分析工具：探索、预处理、分析、可视化和解释。
- en: '![](img/B32363_07_02.png)'
  id: totrans-463
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B32363_07_02.png)'
- en: 'Figure 7.2: Our LLM agent visualizing the well-known Iris dataset'
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.2：我们的LLM代理可视化著名的Iris数据集
- en: In the repository, you can see a UI that wraps a data science agent.
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: 在存储库中，你可以看到一个包裹数据科学代理的用户界面。
- en: 'Data science agents represent a powerful application of LangChain’s capabilities.
    These agents can:'
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学代理代表了LangChain能力的强大应用。这些代理可以：
- en: Generate and execute Python code for data analysis and machine learning
  id: totrans-467
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成和执行用于数据分析和机器学习的Python代码
- en: Build and train models based on simple natural language instructions
  id: totrans-468
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于简单的自然语言指令构建和训练模型
- en: Answer complex questions about datasets through analysis and visualization
  id: totrans-469
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过分析和可视化回答关于数据集的复杂问题
- en: Automate repetitive data science tasks
  id: totrans-470
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动化重复的数据科学任务
- en: While these agents aren’t yet ready to replace human data scientists, they can
    significantly accelerate workflows by handling routine tasks and providing quick
    insights from data.
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这些代理尚未准备好取代人类数据科学家，但它们可以通过处理常规任务和提供数据快速洞察来显著加速工作流程。
- en: Let’s conclude the chapter!
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们结束本章！
- en: Summary
  id: totrans-473
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter has examined how LLMs are reshaping software development and data
    analysis practices through natural language interfaces. We traced the evolution
    from early code generation models to today’s sophisticated systems, analyzing
    benchmarks that reveal both capabilities and limitations. Independent research
    suggests that while 55% productivity gains in controlled settings don’t fully
    translate to production environments, meaningful improvements of 4-22% are still
    being realized, particularly when human expertise guides LLM implementation.
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: 本章探讨了通过自然语言界面，大型语言模型（LLMs）如何重塑软件开发和数据分析实践。我们追溯了从早期的代码生成模型到今天复杂系统的演变，分析了揭示能力和局限性的基准测试。独立研究显示，尽管在受控环境中55%的生产力提升并不能完全转化为生产环境，但仍有4-22%的实质性改进正在实现，尤其是在人类专业知识引导LLM实施的情况下。
- en: Our practical demonstrations illustrated diverse approaches to LLM integration
    through LangChain. We used multiple models to generate code solutions, built RAG
    systems to augment LLMs with documentation and repository knowledge, and created
    agents capable of training neural networks and analyzing datasets with minimal
    human intervention. Throughout these implementations, we looked at critical security
    considerations, providing validation frameworks and risk mitigation strategies
    essential for production deployments.
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的实际演示展示了通过LangChain集成LLMs的多种方法。我们使用了多个模型来生成代码解决方案，构建了RAG系统以增强LLMs的文档和存储库知识，并创建了需要最小人工干预就能训练神经网络和分析数据集的代理。在这些实现过程中，我们考虑了关键的安全因素，提供了对生产部署至关重要的验证框架和风险缓解策略。
- en: Having explored the capabilities and integration strategies for LLMs in software
    and data workflows, we now turn our attention to ensuring these solutions work
    reliably in production. In [*Chapter 8*](E_Chapter_8.xhtml#_idTextAnchor390),
    we’ll delve into evaluation and testing methodologies that help validate AI-generated
    code and safeguard system performance, setting the stage for building truly production-ready
    applications.
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: 在探索了软件和数据工作流程中LLMs的能力和集成策略后，我们现在转向确保这些解决方案在生产中可靠工作。在[*第8章*](E_Chapter_8.xhtml#_idTextAnchor390)中，我们将深入研究评估和测试方法，这些方法有助于验证AI生成的代码并保护系统性能，为构建真正生产就绪的应用程序奠定基础。
- en: Questions
  id: totrans-477
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: What is vibe coding, and how does it change the traditional approach to writing
    and maintaining code?
  id: totrans-478
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是vibe编码，它如何改变编写和维护代码的传统方法？
- en: What key differences exist between traditional low-code platforms and LLM-based
    development approaches?
  id: totrans-479
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 传统低代码平台与基于LLM的开发方法之间存在哪些关键差异？
- en: How do independent research findings on productivity gains from AI coding assistants
    differ from vendor claims, and what factors might explain this discrepancy?
  id: totrans-480
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何区分独立研究关于人工智能编码助手生产力提升的发现与供应商的声明，以及哪些因素可能解释这种差异？
- en: What specific benchmark metrics show that LLMs struggle more with class-level
    code generation compared to function-level tasks, and why is this distinction
    important for practical implementations?
  id: totrans-481
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪些具体的基准指标表明，与函数级任务相比，大型语言模型（LLMs）在类级代码生成方面遇到更多困难，为什么这种区别对实际应用很重要？
- en: Describe the validation framework presented in the chapter for LLM-generated
    code. What are the six key areas of assessment, and why is each important for
    production systems?
  id: totrans-482
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 描述章节中提出的用于LLM生成代码的验证框架。评估的六个关键领域是什么，为什么每个领域对生产系统都很重要？
- en: Using the repository RAG example from the chapter, explain how you would modify
    the implementation to better handle large codebases with thousands of files.
  id: totrans-483
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以章节中的RAG示例库为例，解释你将如何修改实现以更好地处理包含数千个文件的庞大代码库。
- en: What patterns emerged in the dataset analysis examples that demonstrate how
    LLMs perform in structured data analysis tasks versus unstructured text processing?
  id: totrans-484
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在数据集分析示例中，哪些模式出现，展示了LLMs在结构化数据分析任务与无结构化文本处理中的表现？
- en: How does the agentic approach to data science, as demonstrated in the neural
    network training example, differ from traditional programming workflows? What
    advantages and limitations did this approach reveal?
  id: totrans-485
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如神经网络训练示例中所示，数据科学的代理方法与传统编程工作流程有何不同？这种方法揭示了哪些优势和局限性？
- en: How do LLM integrations in LangChain enable more effective software development
    and data analysis?
  id: totrans-486
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: LangChain中的LLM集成如何使软件开发和数据分析更加有效？
- en: What critical factors should organizations consider when implementing LLM-based
    development or analysis tools?
  id: totrans-487
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 组织在实施基于LLM的开发或分析工具时应考虑哪些关键因素？
