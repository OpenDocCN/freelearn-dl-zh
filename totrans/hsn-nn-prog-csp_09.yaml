- en: Face and Motion Detection
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 面部与动作检测
- en: 'Now it is time for us to get into a really neat application. We''ll start off
    by using the open source package [http://www.aforgenet.com/](http://www.aforgenet.com/)
    to build a face and motion detection application. To do this, you''ll need to
    have a camera installed in your system to see live streaming video. From there,
    we will use that camera to detect faces as well as motion. In this chapter, we
    are going to show two separate examples: one for facial detection, the other for
    motion detection. We''ll show you exactly what goes on, and just how fast you
    can add these capabilities into your application.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是我们深入一个真正有趣的应用的时候了。我们将从使用开源包[http://www.aforgenet.com/](http://www.aforgenet.com/)来构建一个面部和动作检测应用开始。为此，你需要在你的系统中安装一个摄像头来查看实时视频流。从那里，我们将使用这个摄像头来检测面部和动作。在本章中，我们将展示两个独立的示例：一个用于面部检测，另一个用于动作检测。我们将向你展示具体发生了什么，以及你如何快速将这些功能添加到你的应用中。
- en: 'In this chapter, we will cover such topics as:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Facial detection
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 面部检测
- en: Motion detection
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 动作检测
- en: How to use the local video-integrated camera
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用本地视频集成摄像头
- en: Image filtering/algorithms
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像滤波/算法
- en: Let's start out with facial detection. In our example, I'm going to use my friendly
    little French bulldog to pose for us. Before I do that, please re-read the chapter
    title. No matter how many times you read it, you'll probably miss the key point
    here. Notice it says face *DETECTION* and not face *RECOGNITION*. This is so very
    important I wanted to stop and re-stress it. We are not trying to identify Joe,
    Bob, or Sally. We are trying to verify that, out of everything we see via our
    camera, we can *detect* that there is a face there. We are not concerned with
    whose face it is, just the fact that it is a face! It is so important that we
    understand this before moving on, otherwise your expectations will be so incorrectly
    biased that you are going to make yourself confused and upset, and we don't want
    that!
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从面部检测开始。在我们的示例中，我将使用我友好的小法国斗牛犬来为我们摆姿势。在我这样做之前，请重新阅读章节标题。无论你读多少次，你可能会错过这里的关键点。注意它说的是面部*检测*而不是面部*识别*。这一点非常重要，我想停下来再次强调。我们不是试图识别Joe、Bob或Sally。我们试图验证，通过我们的摄像头看到的所有事物中，我们能否*检测*到有面孔存在。我们并不关心这是谁的面孔，只是它是一个面孔！这一点非常重要，在我们继续之前，我们必须理解这一点，否则你的期望可能会被错误地偏向，这会让你感到困惑和沮丧，而我们不想看到这种情况发生！
- en: Facial detection, as I will stress again later, is the first part of facial
    recognition, a much more complicated beast. If you can't identify, out of all
    the things that are on the screen, one or more faces, then you'll never be able
    to recognize whose face it is!
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 面部检测，就像我稍后会再次强调的那样，是面部识别的第一步，这是一个更为复杂的任务。如果你不能从屏幕上所有的事物中识别出一张或更多面孔，那么你永远无法识别出这是谁的面孔！
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: As a prerequisite, you will need Microsoft Visual Studio(any version) installed
    on your system. You will also need to access the open source accord framework
    at [https://github.com/accord-net/framework](https://github.com/accord-net/framework).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 作为先决条件，你需要在你的系统上安装Microsoft Visual Studio（任何版本）。你还需要访问开源的accord框架，网址为[https://github.com/accord-net/framework](https://github.com/accord-net/framework)。
- en: Check out the following video to see Code in Action: [http://bit.ly/2xH0thh](http://bit.ly/2xH0thh).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下视频以了解代码的实际应用：[http://bit.ly/2xH0thh](http://bit.ly/2xH0thh)。
- en: Facial detection
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 面部检测
- en: 'Now, let''s take a quick look at our application. You should have the sample
    solution loaded into Microsoft Visual Studio:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们快速看一下我们的应用。你应该已经将示例解决方案加载到Microsoft Visual Studio中：
- en: '![](img/e561a83d-af1a-49e3-9a0a-c869351ace7b.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/e561a83d-af1a-49e3-9a0a-c869351ace7b.png)'
- en: And here's a look at our sample application running. Say Hi to Frenchie everyone!
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是我们的示例应用运行时的样子。大家好，向Frenchie问好！
- en: '![](img/76dc37eb-27d2-48d3-9f37-61ecc39691ff.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/76dc37eb-27d2-48d3-9f37-61ecc39691ff.png)'
- en: 'As you can see, we have a very simple screen that is dedicated to our video
    capture device. In this case, the laptop camera is our video capture device. Frenchie
    is kindly posing in front of the camera for us, and as soon as we enable facial
    tracking, look what happens:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，我们有一个非常简单的屏幕，专门用于我们的视频捕获设备。在这种情况下，笔记本电脑的摄像头是我们的视频捕获设备。Frenchie友好地站在摄像头前为我们摆姿势，一旦我们启用面部跟踪，看看会发生什么：
- en: '![](img/5aedfcf2-47bb-416d-bdbf-5d99efa1227a.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/5aedfcf2-47bb-416d-bdbf-5d99efa1227a.png)'
- en: 'The facial features of Frenchie are now being tracked. What you see surrounding
    Frenchie are the tracking containers (white boxes), and our angle detector (red
    line) displayed. As we move Frenchie around, the tracking container and angle
    detector will track him. That''s all well and good, but what happens if we enable
    facial tracking on a real human face? As you can see in the following screenshot,
    the tracking containers and angles are tracking the face of our guest poser, just
    like it did for Frenchie:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: Frenchie的面部特征现在正在被跟踪。你看到围绕Frenchie的是跟踪容器（白色方框），以及我们的角度检测器（红色线条）显示。当我们移动Frenchie时，跟踪容器和角度检测器将跟踪他。那很好，但如果我们在真实的人类脸上启用面部跟踪会怎样呢？正如你在下面的截图中所见，跟踪容器和角度正在跟踪我们客座摆姿势者的面部，就像对Frenchie做的那样。
- en: '![](img/7ae5fc01-5b16-431b-a337-3dae7b8f0bb1.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/7ae5fc01-5b16-431b-a337-3dae7b8f0bb1.png)'
- en: 'As our poser moves his head from side to side, the camera tracks this, and
    you can see the angle detectors adjusting to what it recognizes as the angle of
    the face. In this case you will notice that the color space is in black and white
    and not color. This is a histogram back projection and is an option that you can
    change:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们的摆姿势者从一侧移动头部时，相机跟踪这个动作，你可以看到角度检测器正在调整以识别为面部角度。在这种情况下，你会注意到色彩空间是黑白而不是彩色。这是一个直方图反向投影，这是一个你可以更改的选项：
- en: '![](img/d3d38715-814f-4d2c-a11f-55b668a4e872.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/d3d38715-814f-4d2c-a11f-55b668a4e872.png)'
- en: 'Even as we move farther away from the camera where other objects come into
    view, the facial detector can keep track of our face among the noise. This is
    exactly how the facial recognition systems you see in movies work, albeit more
    simplistic, and within minutes you can be up and running with your own facial
    recognition application too!:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 即使当我们远离相机，其他物体进入视野时，面部检测器也能在噪声中跟踪我们的面部。这正是电影中你看到的面部识别系统的工作方式，尽管更为简单，而且几分钟内你就可以启动自己的面部识别应用！
- en: '![](img/a360a506-8548-4e24-b9c5-fee01dd29139.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/a360a506-8548-4e24-b9c5-fee01dd29139.png)'
- en: Now that we've seen the outside, let's look under the hood at what is going
    on.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经看到了外部情况，那么让我们来看看引擎盖下正在发生的事情。
- en: 'We need to ask ourselves exactly what the problem is that we are trying to
    solve here. Well, we are trying to detect (notice I did not say recognize) facial
    images. While easy for a human, a computer needs very detailed instruction sets
    to accomplish this feat. Luckily for us there is a very famous algorithm called
    the Viola-Jones algorithm that will do the heavy lifting for us. Why did we pick
    this algorithm?:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要确切地问问自己，我们在这里试图解决什么问题。嗯，我们正在尝试检测（注意我没有说识别）面部图像。虽然对人类来说很容易，但计算机需要非常详细的指令集来完成这项任务。幸运的是，有一个非常著名的算法叫做Viola-Jones算法，它将为我们完成繁重的工作。我们为什么选择这个算法呢？
- en: Very high detection rates and very low false positives.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非常高的检测率和极低的误报率。
- en: Very good at real-time processing.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非常擅长实时处理。
- en: Very good at detecting faces from non-faces. Detecting faces is the first step
    in facial recognition.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非常擅长从非面部检测面部。检测面部是面部识别的第一步。
- en: This algorithm requires that the camera has a full-frontal upright view of the
    face. To be detected, the face will need to be pointing straight towards the camera,
    not tilted, not looking up or down. Remember, for the moment, we are just interested
    in facial detection.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 此算法要求相机有一个正面的正面视角。为了被检测到，面部需要直接朝向相机，不能倾斜，不能向上或向下看。记住，目前我们只对面部检测感兴趣。
- en: 'To delve into the technical side of things, our algorithm will require four
    stages to accomplish its job. They are:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 要深入了解技术方面，我们的算法需要四个阶段来完成其任务。它们是：
- en: Haar feature selection
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Haar特征选择
- en: Creating an integral image
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建积分图像
- en: Adaboost training
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Adaboost训练
- en: Cascading classifiers
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 级联分类器
- en: We must start by stating that all human faces share some similar properties,
    such as the eye being darker than the upper cheeks, the nose bridge being brighter
    than the eyes, your forehead may be lighter than the rest of your face, and so
    on. Our algorithm matches these up by using what is known as **Haar Features**.
    We can come up with matchable facial features by looking at the location and size
    of the eyes, mouth, and bridge of the nose, and so forth. However, here's our
    problem.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须首先声明，所有人类面部都有一些相似的特征，例如眼睛比上脸颊暗，鼻梁比眼睛亮，你的额头可能比你的脸的其他部分亮，等等。我们的算法通过使用所谓的**Haar特征**来匹配这些特征。我们可以通过观察眼睛、嘴巴和鼻梁的位置和大小来得出可匹配的面部特征。然而，这里是我们的问题。
- en: In a 24x24 pixel window, there are a total of 162,336 possible features. Obviously,
    to try and evaluate them all would be prohibitively expensive, if it would work
    at all. So, we are going to work with a technique known as **adaptive boosting**,
    or more commonly, **AdaBoost**. It's another one for your buzzword list, you've
    heard it everywhere and perhaps even read about it. Our learning algorithm will
    use AdaBoost to select the best features and train classifiers to use them. Let's
    stop and talk about it for a moment.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个24x24像素的窗口中，总共有162,336个可能的特征。显然，尝试评估所有这些特征将是非常昂贵的，如果它甚至能工作的话。因此，我们将使用一种称为**自适应提升**的技术，或者更常见地，**AdaBoost**。这是你词汇表中的一个新词，你无处不在都能听到它，也许甚至读过它。我们的学习算法将使用AdaBoost来选择最佳特征并训练分类器来使用它们。让我们停下来谈谈它。
- en: AdaBoost can be used with many types of learning algorithm and is considered
    the best out-of-the-box algorithm for many tasks. You usually won't notice how
    good and fast it is until you switch to another algorithm and time it. I have
    done this countless times, and I can tell you the difference is very noticeable.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: AdaBoost可以与许多类型的学习算法一起使用，被认为是许多任务的最好现成算法。你通常不会注意到它有多好、有多快，直到你切换到另一个算法并对其进行计时。我已经这样做过无数次，我可以告诉你差别非常明显。
- en: Boosting takes the output from other weak-learning algorithms and combines them
    with a weighted sum that is the final output of the boosted classifier. The adaptive
    part of AdaBoost comes from the fact that subsequent learners are tweaked in favor
    of those instances that have been misclassified by previous classifiers. We must
    be careful with our data preparation though, as AdaBoost is sensitive to noisy
    data and outliers (remember how we stressed those in [Chapter 1](a48527d5-838a-4f47-a4fd-505597aeed58.xhtml),
    *A Quick Refresher*). The algorithm tends to overfit the data more than other
    algorithms, which is why in our earlier chapters we stressed data preparation
    for missing data and outliers. In the end, if *weak* learning algorithms are better
    than random guessing, AdaBoost can be a valuable addition to our process.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: Boosting从其他弱学习算法的输出中提取信息，并将它们与加权求和结合起来，这是提升分类器的最终输出。AdaBoost的自适应部分来自于后续的学习者被调整以有利于那些被先前分类器错误分类的实例。然而，我们必须小心我们的数据准备，因为AdaBoost对噪声数据和异常值很敏感（记得我们在[第1章](a48527d5-838a-4f47-a4fd-505597aeed58.xhtml)，*快速复习*中强调了这些）。该算法比其他算法更容易过拟合数据，这就是为什么在我们早期的章节中我们强调了缺失数据和异常值的数据准备。最后，如果*弱*学习算法比随机猜测更好，AdaBoost可以成为我们流程中的一个宝贵补充。
- en: With that brief description behind us, let's look under the covers at what's
    happening. For this example, we will again use the Accord framework and we will
    work with the Vision Face Tracking sample. You can download the latest version
    of this framework from its GitHub location: [https://github.com/accord-net/framework](https://github.com/accord-net/framework).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在有了这个简短的描述之后，让我们来看看底层发生了什么。在这个例子中，我们再次使用Accord框架，我们将与Vision Face Tracking示例一起工作。你可以从其GitHub位置下载这个框架的最新版本：[https://github.com/accord-net/framework](https://github.com/accord-net/framework)。
- en: We start by creating a `FaceHaarCascade` object. This object holds a collection
    of Haar-like features' weak classification stages, or stages. There will be many
    stages provided, each containing a set of classifier trees that will be used in
    the decision-making process. We are now technically working with a decision tree.
    The beauty of the Accord framework is that `FaceHaarCascade` automatically creates
    all these stages and trees for us without exposing us to the details.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先创建一个`FaceHaarCascade`对象。这个对象包含了一组Haar-like特征的弱分类阶段，或者说是阶段。将提供许多阶段，每个阶段包含一组将在决策过程中使用的分类树。我们现在实际上是在处理一个决策树。Accord框架的美丽之处在于`FaceHaarCascade`会自动为我们创建所有这些阶段和树，而不会暴露给我们细节。
- en: 'Let''s take a look at what a particular stage might look like:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一个特定阶段可能的样子：
- en: '[PRE0]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: As you can see, we are building a decision tree underneath the hood by providing
    the nodes for each stage with the numeric values for each feature.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，我们通过为每个阶段的节点提供每个特征的数值，在底层构建了一个决策树。
- en: 'Once created, we can use our cascade object to create our `HaarObjectDetector`,
    which is what we will use for detection. It takes:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦创建，我们可以使用我们的级联对象来创建我们的`HaarObjectDetector`，这是我们用于检测的工具。它需要：
- en: Our facial cascade objects
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们的面部级联对象
- en: The minimum window size to use when searching for objects
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 搜索对象时使用的最小窗口大小
- en: Our search mode—in our case, we are searching for only a single object
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们搜索的模式——在我们的例子中，我们只搜索单个对象
- en: The re-scaling factor to use when re-scaling our search window during the search
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在搜索过程中重新调整搜索窗口大小时使用的缩放因子
- en: '[PRE1]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Once created, we are ready to tackle the topic of our video collection source.
    In our examples, we will simply use the local camera to capture all images. However,
    the Accord.Net framework makes it easy to use other sources for image capture,
    such as `.avi` files, animated `.jpg` files, and so forth.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦创建，我们就准备好处理视频源的话题。在我们的示例中，我们将简单地使用本地相机来捕获所有图像。然而，Accord.Net 框架使得使用其他图像捕获源变得容易，例如
    `.avi` 文件，动画 `.jpg` 文件等等。
- en: 'We connect to the camera, select the resolution, and are ready to go:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们连接到相机，选择分辨率，然后准备出发：
- en: '[PRE2]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'With the application now running and our video source selected, our application
    will look like the following. Once again, enter Frenchie the bulldog! Please excuse
    the mess, Frenchie is not the tidiest of pets!:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序现在正在运行，并且已选择视频源，我们的应用程序将如下所示。再次，请输入法尼奇这只斗牛犬！请原谅这儿的混乱，法尼奇不是最整洁的宠物！：
- en: '![](img/4d9d9b29-f1e7-4ab7-b41b-c8fde389d082.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/4d9d9b29-f1e7-4ab7-b41b-c8fde389d082.png)'
- en: For this demonstration, you will notice that Frenchie is facing the camera,
    and in the background, we have 2 x 55" monitors, as well as many other items my
    wife likes to refer to as *junk* (we'll be proper and call it *noise*)! This is
    done to show how the face detection algorithm can distinguish Frenchie's face
    amongst everything else! If our detector cannot handle this, it is going to get
    lost in the noise and will be of little use to us.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个演示中，您会注意到法尼奇正对着相机，背景中有2个55英寸的显示器，以及许多其他我妻子喜欢称之为*垃圾*（我们将正式称之为*噪声*）的东西！这是为了展示面部检测算法如何从其他所有东西中区分出法尼奇的脸！如果我们的检测器无法处理这种情况，它将迷失在噪声中，对我们几乎没有用处。
- en: 'With our video source now coming in, we need to be notified when a new frame
    is received so that we can process it, apply our markers, and so on. We do this
    by attaching to the `NewFrameReceived` event handler of the video source player,
    as follows. .NET developers should be very familiar with this:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了视频源，我们需要在接收到新帧时得到通知，以便我们可以处理它，应用我们的标记等。我们通过将视频源播放器的 `NewFrameReceived`
    事件处理程序附加到它来完成此操作。.NET 开发者应该非常熟悉这一点：
- en: '[PRE3]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Let's look at what happens each time we are notified that a new video frame
    is available.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看每次我们被通知有新的视频帧可用时会发生什么。
- en: 'The first thing that we need to do is `downsample` the image to make it easier
    to work with:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要做的第一件事是将图像`下采样`，使其更容易处理：
- en: '[PRE4]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'With the image in a more manageable size, we will process the frame. If we
    have not found a facial region, we will stay in tracking mode waiting for a frame
    that has a detectable face. If we have found a facial region, we will reset our
    tracker, locate the face, reduce its size in order to flush away any background
    noise, initialize the tracker, and apply the marker window to the image. All of
    this is accomplished with the following code:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 当图像大小更易于处理时，我们将处理该帧。如果没有找到面部区域，我们将保持在跟踪模式中等待一个可检测到面部的帧。如果找到了面部区域，我们将重置跟踪器，定位面部，减小其大小以清除任何背景噪声，初始化跟踪器，并将标记窗口应用于图像。所有这些操作都通过以下代码完成：
- en: '[PRE5]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'If a face was detected, our image frame now looks like the following:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 如果检测到面部，我们的图像帧现在看起来如下：
- en: '![](img/1536495b-9168-4a57-a784-517d0591fe1b.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/1536495b-9168-4a57-a784-517d0591fe1b.png)'
- en: 'If Frenchie tilts his head to the side, our image frame now looks like the
    following:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 如果法尼奇将头倾斜到一边，我们的图像帧现在看起来如下：
- en: '![](img/ee9335bd-0879-4341-bbd9-24a00d11b2ae.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/ee9335bd-0879-4341-bbd9-24a00d11b2ae.png)'
- en: Motion detection
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运动检测
- en: 'We will now make our focus a bit more wide-scale and detect any motion at all,
    not just faces. Again, we''ll use Accord.Net for this and use the `Motion detection`
    sample. As with facial recognition, you will see just how simple it is to add
    this capability to your applications and instantly become a hero at work! Let''s
    make sure you have the correct project loaded into Microsoft Visual Studio:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将关注范围扩大一些，检测任何运动，而不仅仅是面部运动。再次，我们将使用 Accord.Net 并使用 `运动检测` 示例。就像面部识别一样，您将看到如何简单地将此功能添加到您的应用程序中，并立即成为工作中的英雄！让我们确保您已将正确的项目加载到
    Microsoft Visual Studio 中：
- en: '![](img/cb0ee117-d5bf-4cbd-bd7c-30e9feb5217c.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/cb0ee117-d5bf-4cbd-bd7c-30e9feb5217c.png)'
- en: 'With motion detection, anything that moves on the screen we will highlighted
    in red, so using the following screenshot you can see that the fingers are moving
    but everything else remains motionless:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 使用运动检测，屏幕上移动的任何东西都会用红色突出显示，所以使用以下屏幕截图，你可以看到手指在移动，但其他一切保持静止：
- en: '![](img/4b6f2db8-633c-40dd-a4ee-4ce16da9cfe4.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/4b6f2db8-633c-40dd-a4ee-4ce16da9cfe4.png)'
- en: 'In the following screenshot, you can see more movement, denoted by the red
    blocks along this anonymous hand:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的屏幕截图中，你可以看到更多的运动，由沿着这个匿名手的红色方块表示：
- en: '![](img/3a9bc94e-95ee-49c2-83b7-9d93747dcc8a.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/3a9bc94e-95ee-49c2-83b7-9d93747dcc8a.png)'
- en: 'In the following screenshot, you can see that the entire hand is moving:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的屏幕截图中，你可以看到整个手在移动：
- en: '![](img/be569970-5761-4a5a-852f-39054b3bad17.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/be569970-5761-4a5a-852f-39054b3bad17.png)'
- en: 'If we do not wish to process the entire screen area for motion, we can define
    *motion regions*, where motion detection will occur only in those regions. In
    the following screenshot, you can see that I defined a motion region. You will
    notice in upcoming screenshots that this is the only area that motion will be
    processed from:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们不希望处理整个屏幕区域中的运动，我们可以定义**运动区域**，运动检测将仅在这些区域内发生。在下面的屏幕截图中，你可以看到我定义了一个运动区域。你将在接下来的屏幕截图中注意到，这是唯一一个将处理运动的区域：
- en: '![](img/b1e77ea7-22a7-4caa-82eb-233dc2796570.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/b1e77ea7-22a7-4caa-82eb-233dc2796570.png)'
- en: 'Now, if we create some motion for the camera, you will see that only motion
    from our defined region is being processed, as follows:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果我们为相机创建一些运动，你会看到只有我们定义区域内的运动被处理，如下所示：
- en: '![](img/aa867f0c-b7af-419d-91f4-096416eb4758.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/aa867f0c-b7af-419d-91f4-096416eb4758.png)'
- en: 'You can also see that, with a motion region defined and Peter the meditating
    Gnome in front of the region, we are still able to detect motion behind him, but
    his face is not part of the recognition. You could of course, combine both processes
    to have the best of both worlds, as follows:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以看到，在定义了运动区域，并且彼得这个冥想的哥布林站在区域前面时，我们仍然能够检测到他后面的运动，但他的脸不是识别的一部分。当然，你可以将这两个过程结合起来，以获得最好的效果，如下所示：
- en: '![](img/0e7bf3a5-7ad7-4340-a31a-aed2597fed13.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/0e7bf3a5-7ad7-4340-a31a-aed2597fed13.png)'
- en: 'Another option that we can use is Grid Motion Highlighting. This highlights
    the motion detected region in red squares based upon a defined grid. Basically,
    the motion area is now a red box, as you can see:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个我们可以使用的选项是**网格运动高亮**。它根据定义的网格以红色方块的形式突出显示检测到的运动区域。基本上，运动区域现在是一个红色框，正如你所见：
- en: '![](img/9622811a-aaa7-4bad-a7d3-b9d3b7064755.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/9622811a-aaa7-4bad-a7d3-b9d3b7064755.png)'
- en: Code
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 代码
- en: 'The following snippet shows a simple example of all you need to do to add video
    recognition to your application. As you can see, it couldn’t be any easier:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '以下代码片段展示了添加视频识别到你的应用所需做的所有事情。正如你所见，这 couldn’t be any easier:'
- en: '[PRE6]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We now open our video source:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在打开我们的视频源：
- en: '[PRE7]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'When we receive a new video frame, that''s when all the magic happens. The
    following are all the code it takes to make processing a new video frame a success:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们接收到一个新的视频帧时，所有的魔法就会发生。以下是将处理新的视频帧成功所需的全部代码：
- en: '[PRE8]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The key here is detecting the amount of motion that is happening in the frame,
    which is done with the following code. For this example, we are using a motion
    alarm level of 0.2, but you can use whatever you like. Once this threshold has
    been passed, you can do whatever logic you like such as send an email alert, text,
    start a video capture operation, and so forth:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 关键在于检测帧中发生的运动量，这是通过以下代码完成的。对于这个例子，我们使用运动警报级别为 0.2，但你可以使用任何你喜欢的。一旦这个阈值被超过，你可以执行任何你喜欢的逻辑，比如发送电子邮件警报，短信，启动视频捕获操作等等：
- en: '[PRE9]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Summary
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we learned about image and motion detection (not recognition!).
    We used Accord.Net as an example of what open-source tools provide us with when
    we want to add power to our applications.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了图像和运动检测（不是识别！）我们以 Accord.Net 作为开源工具为我们提供添加应用功能的一个例子。
- en: In the next chapter, we remain with the image theme, but work on training Convolutional
    Neural Networks with the open-source package ConvNetSharp.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们继续探讨图像主题，但使用开源包 ConvNetSharp 训练卷积神经网络。
