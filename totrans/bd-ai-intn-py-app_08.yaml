- en: '8'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '8'
- en: Implementing Vector Search in AI Applications
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在AI应用中实现向量搜索
- en: Vector search is revolutionizing the way people interact with data in AI applications.
    MongoDB Atlas Vector Search allows developers to implement sophisticated search
    capabilities that understand the nuances of discovery and retrieval. It works
    by converting text, video, image, or audio files into numerical vector representations,
    which can then be stored and searched efficiently. MongoDB Atlas can perform similarity
    searches alongside your operational data, making it an essential tool for enhancing
    user experience in applications ranging from e-commerce to content discovery.
    With MongoDB Atlas, setting up vector search is streamlined, enabling developers
    to focus on creating dynamic, responsive, and intelligent applications.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 向量搜索正在改变人们与AI应用中数据交互的方式。MongoDB Atlas向量搜索允许开发者实现理解发现和检索细微差别的复杂搜索功能。它通过将文本、视频、图像或音频文件转换为数值向量表示，然后可以高效地存储和搜索。MongoDB
    Atlas可以在您的运营数据旁边执行相似度搜索，使其成为增强从电子商务到内容发现等应用程序用户体验的必备工具。使用MongoDB Atlas，设置向量搜索流程简化，使开发者能够专注于创建动态、响应和智能的应用程序。
- en: In this chapter, you will learn how to use the Vector Search feature of MongoDB
    Atlas to build intelligent applications. You will learn how to build **retrieval-augmented
    generation** (**RAG**) architecture systems and delve deeper into the understanding
    and development of various patterns of complex RAG architectures with MongoDB
    Atlas, unraveling the synergies that underpin their joint value and potential.
    Through real-world use cases and practical demonstrations, you will learn how
    this dynamic duo can seamlessly transform businesses across industries, driving
    efficiency, accuracy, and operational excellence.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将学习如何使用MongoDB Atlas的向量搜索功能构建智能应用程序。您将学习如何构建**检索增强生成**（**RAG**）架构系统，并深入了解使用MongoDB
    Atlas理解和开发各种复杂RAG架构模式，揭示其联合价值和潜力的协同效应。通过实际用例和实践演示，您将了解这对动态组合如何无缝地改变各行业的业务，推动效率、准确性和运营卓越。
- en: 'This chapter covers the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖了以下主题：
- en: Leverage vector search and full-text search with MongoDB Atlas, which will later
    help you build a robust retriever for RAG
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用MongoDB Atlas的向量搜索和全文搜索，这将有助于您构建一个强大的RAG检索器
- en: Understand the various components involved in the development of a RAG system
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解在RAG系统开发中涉及的各个组件
- en: Learn about the process and steps involved in the development of simple RAG
    and advanced RAG systems.
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解简单RAG和高级RAG系统开发的过程和步骤。
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'This chapter assumes that you have at least beginner-level expertise in Python
    coding. To follow along with the demos, you’ll need to set up your development
    environment by completing the following steps:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本章假设您至少具备Python编码的入门级专业知识。为了跟随演示，您需要通过完成以下步骤来设置您的开发环境：
- en: Install either `python@3.9` or `python@3.11` on the operating system of your
    choice.
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在您选择的操作系统上安装`python@3.9`或`python@3.11`。
- en: 'Set up a Python virtual environment and activate it:'
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置并激活Python虚拟环境：
- en: '[PRE0]'
  id: totrans-12
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'You will be using the following packages to develop the demo described in this
    chapter:'
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您将使用以下包来开发本章中描述的演示：
- en: '`pandas`: Helps with data preprocessing and handling'
  id: totrans-14
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pandas`: 帮助进行数据预处理和处理'
- en: '`numpy`: Handles numerical data'
  id: totrans-15
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`numpy`: 处理数值数据'
- en: '`openai`: For the embedding model and invoking the LLM'
  id: totrans-16
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`openai`: 用于嵌入模型和调用LLM'
- en: '`pymongo`: For the MongoDB Atlas vector store and full-text search'
  id: totrans-17
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pymongo`: 用于MongoDB Atlas向量存储和全文搜索'
- en: '`s3fs`: Allows loading data directly from an S3 bucket'
  id: totrans-18
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`s3fs`: 允许直接从S3存储桶加载数据'
- en: '`langchain_mongodb`: Enables vector search in MongoDB Atlas using a LangChain
    wrapper'
  id: totrans-19
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`langchain_mongodb`: 使您能够使用LangChain包装器在MongoDB Atlas中实现向量搜索'
- en: '`langchain`: Used to build a RAG application'
  id: totrans-20
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`langchain`: 用于构建RAG应用'
- en: '`langchain-openai`: Enables you to interact with OpenAI chat models'
  id: totrans-21
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`langchain-openai`: 使您能够与OpenAI聊天模型交互'
- en: '`boto3`: Enables you to interact with AWS s3 buckets'
  id: totrans-22
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`boto3`: 使您能够与AWS s3存储桶交互'
- en: '`python-dotenv:` Enables you to load environment variables from a `.``env`
    file'
  id: totrans-23
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`python-dotenv:` 使您能够从`.env`文件中加载环境变量'
- en: 'To install the mentioned packages in your Python virtual environment, run the
    following command:'
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要在您的Python虚拟环境中安装所提到的包，请运行以下命令：
- en: '[PRE1]'
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: You will also need to know how to set up and run JupyterLab or Jupyter Notebook.
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您还需要了解如何设置和运行JupyterLab或Jupyter Notebook。
- en: Information retrieval with MongoDB Atlas Vector Search
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用MongoDB Atlas Vector Search进行信息检索
- en: Information retrieval is a critical component of RAG systems. It enhances the
    accuracy and relevance of the generated text by sourcing information from extensive
    knowledge bases. This process allows the RAG system to produce responses that
    are not only precise but also deeply rooted in factual content, making it a powerful
    tool for various **natural language processing** (**NLP**) tasks. By effectively
    combining retrieval with generation, RAG addresses challenges related to bias
    and misinformation, contributing to the advancement of AI-related applications
    and tasks.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 信息检索是RAG系统的关键组成部分。它通过从广泛的知识库中获取信息，提高了生成文本的准确性和相关性。这个过程使得RAG系统能够生成既精确又基于事实内容的响应，使其成为各种**自然语言处理**（**NLP**）任务的有力工具。通过有效地结合检索与生成，RAG解决了与偏见和错误信息相关的挑战，为AI相关应用和任务的进步做出了贡献。
- en: In the context of information retrieval, it’s essential to distinguish between
    *relevance* and *similarity*. While **similarity** focuses on word matching, **relevance**
    is about the interconnectedness of ideas. While a vector database query can help
    identify semantically related content, more advanced tools are needed to accurately
    retrieve relevant information.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在信息检索的背景下，区分*相关性*和*相似性*是至关重要的。虽然**相似性**关注于词匹配，但**相关性**是关于思想的相互联系。虽然向量数据库查询可以帮助识别语义相关的内容，但需要更高级的工具来准确检索相关信息。
- en: In *Chapter 5*, *Vector Databases*, you learned about MongoDB Atlas Vector Search
    and how it enhances the retrieval of relevant information by allowing the creation
    and indexing of vector embeddings, which can be generated using machine learning
    models, such as embedding models. This facilitates semantic search capabilities,
    enabling the identification of content that is contextually similar rather than
    just being keyword based. Full-text search complements this by providing robust
    text search capabilities that can handle typos, synonyms, and other variations
    in text, ensuring that searches return the most pertinent results. Together, these
    tools provide a comprehensive search solution that can discern and retrieve information
    based on both the similarity of terms and the relevance of the content.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第5章*，*向量数据库*中，你学习了MongoDB Atlas Vector Search以及它是如何通过允许创建和索引向量嵌入（可以使用机器学习模型，如嵌入模型生成）来增强相关信息的检索。这促进了语义搜索功能，能够识别出在上下文中相似的内容，而不仅仅是基于关键词。全文搜索通过提供强大的文本搜索能力来补充这一点，可以处理拼写错误、同义词和其他文本变化，确保搜索返回最相关的结果。这些工具共同提供了一种全面的搜索解决方案，可以根据术语的相似性和内容的关联性来识别和检索信息。
- en: Vector search tutorial in Python
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Python中的向量搜索教程
- en: 'With the help of an example, let’s see how to load a small dataset in MongoDB
    to perform a vector search along with full-text search to perform information
    retrieval. For this demonstration, you will load a sample movie dataset from an
    S3 bucket:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 通过一个示例，让我们看看如何将小型数据集加载到MongoDB中，以执行向量搜索和全文搜索以进行信息检索。为此演示，你将从一个S3存储桶中加载一个示例电影数据集：
- en: Write a simple Python function to accept search terms or phrases and pass it
    through the embeddings API again to get a query vector.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写一个简单的Python函数，接受搜索词或短语，并将其通过嵌入API再次传递以获取查询向量。
- en: Take the resultant query vector embeddings and perform a vector search query
    using the [`$vectorsearch`](https://www.mongodb.com/docs/atlas/atlas-vector-search/vector-search-stage/)
    operator in the MongoDB aggregation pipeline.
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将生成的查询向量嵌入取出来，并使用MongoDB聚合管道中的`$vectorsearch`（[向量搜索](https://www.mongodb.com/docs/atlas/atlas-vector-search/vector-search-stage/)）运算符执行向量搜索查询。
- en: Pre-filter the documents using meta information to narrow the search across
    your dataset, thereby speeding up the performance of the vector search results
    while retaining accuracy.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用元信息对文档进行预过滤，以缩小数据集上的搜索范围，从而加快向量搜索结果的处理速度，同时保持准确性。
- en: Further, post-filter the retrieved documents that are semantically similar (based
    on relevancy score), if you want to demonstrate a higher degree of control over
    the semantic search behavior.
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此外，如果您想展示对语义搜索行为的更高程度的控制，可以对语义上相似的检索到的文档进行后过滤（基于相关性分数）。
- en: 'Initialize the OpenAI API key and MongoDB connection string:'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化OpenAI API密钥和MongoDB连接字符串：
- en: '[PRE2]'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now, load the dataset from the S3 bucket. Run the following lines of code in
    Jupyter Notebook to read data from an AWS S3 bucket directly to a `pandas` DataFrame:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，从S3存储桶中加载数据集。在Jupyter Notebook中运行以下代码行以直接从AWS S3存储桶读取数据到`pandas` DataFrame：
- en: '[PRE3]'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: On executing the preceding snippet of code, you should see the following result
    in your Jupyter Notebook cell.
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 执行前面的代码片段后，你应该在你的Jupyter Notebook单元格中看到以下结果。
- en: '![](img/B22495_08_01.jpg)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![img/B22495_08_01.jpg](img/B22495_08_01.jpg)'
- en: 'Figure 8.1: Sample movies data view'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.1：样本电影数据视图
- en: Initialize and run an embedding job to embed the `sample_movies` dataset. In
    the following code example, you create a `final` field, which is a field derived
    from the `text` and `overview` fields that are already available in the dataset.
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化并运行一个嵌入作业以嵌入`sample_movies`数据集。在下面的代码示例中，你创建了一个`final`字段，这是一个从数据集中已存在的`text`和`overview`字段派生出来的字段。
- en: 'Next, run this `final` field against the embedding API from OpenAI, as shown
    here:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，运行此`final`字段与OpenAI的嵌入API，如图所示：
- en: '[PRE4]'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: You should see that the `sample_movies` dataset is enriched with the OpenAI
    embeddings in the `embedding` field, as shown in *Figure 8**.2*.
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该看到`sample_movies`数据集在`embedding`字段中丰富了OpenAI嵌入，如图*图8**.2*所示。
- en: '![](img/B22495_08_02.jpg)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![img/B22495_08_02.jpg](img/B22495_08_02.jpg)'
- en: 'Figure 8.2: Sample movies dataset view with OpenAI embeddings'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.2：使用OpenAI嵌入的样本电影数据集视图
- en: Next, initialize MongoDB Atlas and insert data into a MongoDB collection.
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，初始化MongoDB Atlas并将数据插入MongoDB集合中。
- en: 'Now that you have created the vector embeddings for your `sample_movies` dataset,
    you can initialize the MongoDB client and insert the documents into your collection
    of choice by running the following lines of code:'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在你已经为`sample_movies`数据集创建了向量嵌入，你可以初始化MongoDB客户端并将文档插入你选择的集合中，通过运行以下代码行：
- en: '[PRE5]'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: You have ingested the test data to build a vector search capability. Now, let’s
    proceed to build a vector search index in the following steps.
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你已经将测试数据导入以构建向量搜索功能。现在，让我们按照以下步骤构建向量搜索索引。
- en: 'Let’s first create vector index definitions. You can create a vector search
    index in the MongoDB Atlas Vector Search UI by following the steps explained in
    *Chapter 5*, *Vector Databases*. The vector index required for this demo tutorial
    is provided here:'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们首先创建向量索引定义。你可以在MongoDB Atlas向量搜索UI中通过遵循*第5章*，*向量数据库*中解释的步骤创建一个向量搜索索引。本演示教程所需的向量索引在此提供：
- en: '[PRE6]'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Once the vector index definitions are added under the Vector Search index JSON
    editor in the MongoDB Atlas UI, the process for creating a vector search index
    is triggered and the vector search index is created at the specified `path` field
    mentioned in the vector index definition. Now, you are ready to perform vector
    search queries on the `sample_movies.embed_movies` collection in MongoDB Atlas
    where all the data is stored, and create vector indexes.
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一旦在MongoDB Atlas UI中的向量搜索索引JSON编辑器下添加了向量索引定义，创建向量搜索索引的过程就会被触发，并在向量索引定义中指定的`path`字段处创建向量搜索索引。现在，你准备好在MongoDB
    Atlas中执行向量搜索查询，在存储所有数据的`sample_movies.embed_movies`集合上创建向量索引。
- en: Let’s equip the vector search or the retriever API to use in your RAG framework.
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 让我们为向量搜索或检索API配备你的RAG框架。
- en: You can query a MongoDB vector index using `$vectorSearch`. MongoDB Atlas brings
    the flexibility of using vector search alongside search filters. Additionally,
    you can apply range, string, and numeric filters using the aggregation pipeline.
    This allows the end user to control the behavior of the semantic search response
    from the search engine.
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以使用`$vectorSearch`查询MongoDB向量索引。MongoDB Atlas带来了使用向量搜索的同时使用搜索过滤器的灵活性。此外，你还可以使用聚合管道应用范围、字符串和数字过滤器。这允许最终用户控制来自搜索引擎的语义搜索响应的行为。
- en: The following code example demonstrates how you can perform vector search along
    with pre-filtering on the `year` field to get movies released post `1990`. To
    have better control over the relevance of returned results, you can perform post-filtering
    on the response using the MongoDB Query API.
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下面的代码示例演示了如何执行向量搜索，并在`year`字段上进行预过滤以获取1990年后发布的电影。为了更好地控制返回结果的关联性，你可以使用MongoDB查询API对响应进行后过滤。
- en: 'The following code demonstrates how you can perform these steps:'
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下面的代码演示了如何执行这些步骤：
- en: Represent a raw text query as a vector embedding. There are multiple embedding
    models currently available with OpenAI, such as `text-embedding-3-small`, `text-embedding-3-large`
    with variable dimensions, and the `text-embedding-ada-002` model.
  id: totrans-61
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将原始文本查询表示为向量嵌入。目前 OpenAI 提供了多种嵌入模型，例如 `text-embedding-3-small`、`text-embedding-3-large`（具有可变维度）和
    `text-embedding-ada-002` 模型。
- en: Build and perform a vector search query to MongoDB Atlas.
  id: totrans-62
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建并向 MongoDB Atlas 执行向量搜索查询。
- en: Perform pre-filtering before performing a vector search on the `year` field.
  id: totrans-63
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在对 `year` 字段执行向量搜索之前进行预过滤。
- en: Perform post-filtering using the `score` field to better control the relevancy
    and accuracy of the returned results.
  id: totrans-64
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `score` 字段进行后过滤，以更好地控制返回结果的关联性和准确性。
- en: 'Run the following code to initialize a function that can help you achieve vector
    search, pre-filter, and post-filter:'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 运行以下代码以初始化一个可以帮助您实现向量搜索、预过滤和后过滤的函数：
- en: '[PRE7]'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'You should get the following result:'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您应该得到以下结果：
- en: '![](img/B22495_08_03.jpg)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22495_08_03.jpg)'
- en: 'Figure 8.3: Sample result from running the vector search query with pre-filters'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.3：使用预过滤运行向量搜索查询的示例结果
- en: 'This is a sample query with `year` as a pre-filter and a `score`-based post-filter
    to retain only the relevant results:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个示例查询，使用 `year` 作为预过滤和一个基于 `score` 的后过滤来仅保留相关结果：
- en: '[PRE8]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'You should get the following result:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该得到以下结果：
- en: '![](img/B22495_08_04.jpg)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22495_08_04.jpg)'
- en: 'Figure 8.4: Sample result from running the vector search query with a pre-filter
    and post-filter'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.4：使用预过滤和后过滤运行向量搜索查询的示例结果
- en: With this Python method, you were able to filter on the `score` field and the
    `year` field to generate results as well as results for vector similarity. Using
    a heuristic, you were able to control the accuracy of the results to retain only
    the most relevant documents and were also able to apply a range filter query (on
    the `year` field).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 使用此 Python 方法，您能够对 `score` 字段和 `year` 字段进行过滤以生成结果，以及向量相似度的结果。通过使用启发式方法，您能够控制结果的准确性，仅保留最相关的文档，并且还能够应用范围过滤查询（在
    `year` 字段上）。
- en: Vector Search tutorial with LangChain
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LangChain 向量搜索教程
- en: 'Utilizing **LangChain** with MongoDB Atlas Vector Search for building a semantic
    similarity retriever offers several advantages. The following example demonstrates
    how to carry out a vector similarity search using LangChain wrapper classes:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 利用 **LangChain** 和 MongoDB Atlas 向量搜索构建语义相似度检索器提供了几个优点。以下示例演示了如何使用 LangChain
    包装类执行向量相似度搜索：
- en: '[PRE9]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Here’s the result:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这是结果：
- en: '![](img/B22495_08_05.jpg)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22495_08_05.jpg)'
- en: 'Figure 8.5: Sample result vector search query using the LangChain module for
    MongoDB'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.5：使用 MongoDB 的 LangChain 模块执行的示例向量搜索查询结果
- en: This demonstrates a more sophisticated yet simple approach that is particularly
    beneficial for developers creating RAG applications. The LangChain framework offers
    a suite of APIs and wrapper classes that can be used to integrate with various
    serverless LLM providers, such as OpenAI, and talk to MongoDB Atlas Vector Search
    to build RAG frameworks with very few lines of code. It is also easy to maintain
    and scale.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这展示了更复杂但简单的方法，特别有利于开发 RAG 应用程序的程序员。LangChain 框架提供了一套 API 和包装类，可用于与各种无服务器 LLM
    提供商集成，例如 OpenAI，并与 MongoDB Atlas 向量搜索通信，以用很少的代码构建 RAG 框架。它也易于维护和扩展。
- en: In this section, you were able to build and perform vector similarity search
    using MongoDB Atlas. You developed reusable wrapper classes and functions that
    will be useful in developing a more sophisticated application, such as a chatbot.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，您已经能够使用 MongoDB Atlas 构建并执行向量相似度搜索。您开发了可重用的包装类和函数，这些将在开发更复杂的应用程序，如聊天机器人时非常有用。
- en: Now, let’s delve deep into understanding what RAG architectures are and how
    to develop one using the resources that you’ve created so far.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们深入探讨理解 RAG 架构是什么以及如何使用您迄今为止创建的资源来开发它。
- en: Building RAG architecture systems
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建 RAG 架构系统
- en: In the dynamic landscape of modern business, the relentless pursuit of efficiency
    and accuracy urges organizations to adopt cutting-edge technologies. Among these,
    automation stands as a cornerstone, particularly in processing and automating
    workflows. However, traditional methods suffer when they’re subjected to large
    volumes of data with intricate tasks, and human-led processes often fall short
    due to error-prone manual interventions.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在现代商业的动态景观中，对效率和准确性的不懈追求促使组织采用尖端技术。在这些技术中，自动化是基石，尤其是在处理和自动化工作流程方面。然而，当面对大量复杂任务的数据时，传统方法会受到影响，而以人为中心的过程往往由于易出错的手动干预而不足。
- en: This section explores the transformative landscape of automation, discussing
    the pivotal role RAG plays in revolutionizing business operations. MongoDB, known
    for its prowess in data management and flexible schemas, offers a compelling synergy
    with RAG through its vector search and full-text search capabilities. Delving
    into the architectural details of RAG, this section dissects its constituent building
    blocks, offering practical insights into constructing automated document-processing
    workflows that harness the full potential of LLMs and MongoDB Vector Search.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 本节探讨了自动化转型的变革性景观，讨论了RAG在革命性改变业务运营中的关键作用。MongoDB以其在数据管理和灵活模式方面的优势而闻名，通过其向量搜索和全文搜索功能，与RAG形成了引人注目的协同效应。深入探讨RAG的架构细节，本节剖析了其构成的基本模块，提供了构建利用LLMs和MongoDB向量搜索全部潜力的自动化文档处理工作流的实用见解。
- en: '![](img/B22495_08_06.jpg)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B22495_08_06.jpg)'
- en: 'Figure 8.6: Building blocks of RAG architecture'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.6：RAG架构的构建块
- en: 'Let’s go over the key components of the RAG architecture in detail:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们详细探讨RAG架构的关键组件：
- en: '**Document loading**: Initially, documents are loaded from data storage. This
    involves text extraction, parsing, formatting, and cleaning to prepare the data
    for document splitting.'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**文档加载**：最初，文档从数据存储中加载。这包括文本提取、解析、格式化和清理，以准备数据以便文档分割。'
- en: '**Document splitting**: The next step is to break down the documents into smaller,
    manageable segments or chunks. Strategies for splitting can vary, from fixed-size
    chunking to content-aware chunking that considers the content structure.'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**文档分割**：下一步是将文档分解成更小、更易于管理的段或片段。分割策略可能有所不同，从固定大小的块分割到考虑内容结构的感知内容分割。'
- en: '**Text embedding**: These document chunks are then transformed into vector
    representations (embeddings) using techniques such as **OpenAIEmbeddings**, **Sentence
    e-BERT**, and **Instructor Embeddings**. This step is crucial for understanding
    the semantic content of the chunks.'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**文本嵌入**：这些文档片段随后使用**OpenAIEmbeddings**、**Sentence e-BERT**和**Instructor Embeddings**等技术转换为向量表示（嵌入）。这一步对于理解片段的语义内容至关重要。'
- en: '**Vector store**: The generated vectors, each associated with unique document
    chunks, are stored in a vector store alongside the document chunks and other metadata
    extracted from the MongoDB Atlas collection. Atlas Vector Search indexes and Apache
    Lucene search can be built through the **MongoDB Atlas UI** for easy and fast
    retrieval.'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**向量存储**：生成的向量，每个都与独特的文档片段相关联，存储在向量存储中，与文档片段和其他从MongoDB Atlas集合中提取的元数据一起。可以通过**MongoDB
    Atlas UI**构建Atlas向量搜索索引和Apache Lucene搜索，以便快速检索。'
- en: '**Query processing**: When a user submits a query, it is also converted into
    a vector representation using the same embedding technique as mentioned in *Step
    3*.'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**查询处理**：当用户提交查询时，它也使用与第3步中提到的相同嵌入技术转换为向量表示。'
- en: '**Document retrieval**: The retriever component locates and fetches document
    chunks that are semantically like the query. This retrieval process employs vector
    similarity search techniques and MongoDB Atlas using the **Hierarchical Navigable
    Small Worlds** (**HNSW)** algorithm to perform a fast nearest neighbor search
    to retrieve relevant documents without compromising the accuracy of the retrieved
    search results.'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**文档检索**：检索组件定位并获取与查询语义相似的文档片段。此检索过程采用向量相似性搜索技术和MongoDB Atlas，使用**分层可导航小世界**（**HNSW**）算法进行快速最近邻搜索，以检索相关文档，同时不牺牲检索搜索结果的准确性。'
- en: '**Document chunk post-filtering**: The relevant document chunks are retrieved
    from the MongoDB collection with the help of the **Unified Query API** and can
    be post-filtered easily to transform the output document chunks into the required
    format.'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**文档块后过滤**：使用**统一查询API**从MongoDB集合中检索相关文档块，并且可以轻松后过滤以将输出文档块转换为所需的格式。'
- en: '**LLM prompt creation**: The retrieved document chunks and the query are combined
    to create a context and prompt for the LLM.'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**LLM提示创建**：将检索到的文档块和查询组合以创建LLM的上下文和提示。'
- en: '**Answer generation**: Finally, the LLM generates a response based on the prompt,
    completing the RAG process.'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**答案生成**：最后，LLM根据提示生成响应，完成RAG过程。'
- en: 'In the context of RAG systems, there are two primary types: **simple** (**or
    naive**) **RAG** and **advanced** **RAG**. In practical scenarios, this classification
    helps address different types of personas and questions the applications are handling,
    and it’s common to encounter both simple and complex RAG queries within the same
    workflow and from the same persona. As a developer, it is important to reason
    out the functionalities that the application is expected to serve before deciding
    on the building blocks involved in the RAG architecture.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在RAG系统的背景下，有两种主要类型：**简单**（**或天真**）**RAG**和**高级****RAG**。在实际场景中，这种分类有助于解决不同类型的人物和应用程序处理的问题，并且通常在同一个工作流程和同一个人物中会遇到简单和复杂的RAG查询。作为开发者，在决定RAG架构中涉及的构建块之前，重要的是要推理出应用程序预期要提供的功能。
- en: 'When building your RAG architecture system, consider the following points to
    help with programming and planning:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建您的RAG架构系统时，考虑以下要点以帮助编程和规划：
- en: '**Workflow specificity**: Define the specific workflow you intend to automate
    with RAG; it may be related to **question answering** (**QA**), data augmentation,
    summarization, reasoning, or assertion. Maybe your customers frequently ask a
    specific set of three or four types of queries.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**工作流程的特定性**：定义您打算使用RAG自动化的特定工作流程；它可能与**问答**（**QA**）、数据增强、摘要、推理或断言相关。也许您的客户经常询问一组特定的三到四种类型的查询。'
- en: '**User experience**: Collaborate with your target user group to understand
    the types of queries they are likely to ask to identify the user group journey,
    which might be a simple single-state response or a multi-state chat flow.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**用户体验**：与您的目标用户群体合作，了解他们可能提出的问题类型，以确定用户群体旅程，这可能是一个简单的单状态响应或一个多状态聊天流程。'
- en: '**Data sources**: First, identify the nature of your data source—whether it’s
    unstructured or structured. Next, map the locations of these data sources. Once
    you’ve done that, classify the data based on whether it serves operational or
    analytical purposes. Finally, observe the data patterns to determine whether answers
    are readily available in one location or if you’ll need to gather information
    from multiple sources.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据源**：首先，确定数据源的性质——它是不结构化还是结构化的。接下来，映射这些数据源的位置。一旦完成，根据数据是否用于操作或分析目的对数据进行分类。最后，观察数据模式以确定答案是否在某个位置即可获得，或者您需要从多个来源收集信息。'
- en: These pointers will help you determine whether you need to go for a simple RAG
    system or an advanced RAG system and also help you to determine the essential
    building blocks to consider while constructing your RAG architecture.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 这些要点将帮助您确定是否需要采用简单RAG系统或高级RAG系统，并帮助您确定构建RAG架构时需要考虑的基本构建块。
- en: Now, let’s delve deeper into the building blocks of this architecture with some
    code examples to better explain the nuances. However, before you develop RAG-powered
    applications, let’s look at the fundamentals of how to process source documents
    to maximize the accuracy of the rated responses from the RAG application. The
    following strategies will come in handy while processing documents before storing
    them in a MongoDB Atlas collection.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们通过一些代码示例深入探讨这个架构的构建块，以更好地解释细微差别。然而，在开发RAG应用程序之前，让我们看看如何处理源文档以最大限度地提高RAG应用程序的评分响应准确性的基本原理。以下策略在将文档存储到MongoDB
    Atlas集合之前处理文档时将非常有用。
- en: Chunking or document-splitting strategies
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 块化或文档拆分策略
- en: '**Chunking** or **document splitting** is a critical step in handling extensive
    texts within RAG systems. When dealing with large documents, the token limits
    imposed by language models (such as **gpt-3.5-turbo**) necessitate breaking them
    into manageable chunks. However, a naive fixed-chunk-size approach can lead to
    fragmented sentences across chunks, affecting subsequent tasks such as QA.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '**块划分**或**文档分割**是处理RAG系统中的大量文本的关键步骤。在处理大型文档时，语言模型（如**gpt-3.5-turbo**）施加的标记限制需要将它们划分为可管理的块。然而，简单的固定块大小方法可能导致块之间的句子碎片化，影响后续任务，如问答。'
- en: To address this, consider semantics when dividing documents. Most segmentation
    algorithms use chunk size and overlap principles. **Chunk size** (measured by
    characters, words, or tokens) determines segment length, while **overlaps** ensure
    continuity by sharing context between adjacent chunks. This approach preserves
    semantic context and enhances RAG system performance.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，在划分文档时考虑语义。大多数分割算法使用块大小和重叠原则。**块大小**（以字符、单词或标记衡量）决定了段长度，而**重叠**通过在相邻块之间共享上下文来确保连续性。这种方法保留了语义上下文并提高了RAG系统性能。
- en: 'Now, let’s delve into the intricacies of document-splitting techniques, particularly
    focusing on content-aware chunking. While fixed-size chunking with overlap is
    straightforward and computationally efficient, more sophisticated methods enhance
    the quality of text segmentation. The following are the various document-splitting
    techniques:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们深入了解文档分割技术的复杂性，特别是关注内容感知的块划分。虽然固定大小块划分与重叠简单且计算效率高，但更复杂的方法提高了文本分割的质量。以下是一些文档分割技术：
- en: '**Recursive chunking**: This technique includes the following approaches:'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**递归划分**：这项技术包括以下方法：'
- en: '**Hierarchical approach**: Recursive chunking breaks down input text into smaller
    chunks iteratively. It operates hierarchically, using different separators or
    criteria at each level.'
  id: totrans-112
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**层次方法**：递归划分通过迭代地将输入文本分解成更小的块。它采用层次结构，在每一级使用不同的分隔符或标准。'
- en: '**Customizable structure**: By adjusting the criteria, you can achieve the
    desired chunk size or structure. Recursive chunking adapts well to varying document
    lengths.'
  id: totrans-113
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可定制结构**：通过调整标准，您可以实现所需的块大小或结构。递归划分很好地适应了不同长度的文档。'
- en: '**Sentence splitting**: Sentence splitting involves various strategies, such
    as the ones listed here:'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**句子分割**：句子分割涉及各种策略，如以下所列：'
- en: '**Naive splitting**: This method relies on basic punctuation marks (such as
    periods and new lines) to divide text into sentences. While simple, it might not
    handle complex sentence structures well.'
  id: totrans-115
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**朴素分割**：这种方法依赖于基本的标点符号（如句号和新行）来将文本划分为句子。虽然简单，但它可能无法很好地处理复杂的句子结构。'
- en: '**spaCy**: Another robust NLP library, spaCy, offers accurate sentence segmentation.
    It uses statistical models and linguistic rules.'
  id: totrans-116
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**spaCy**：另一个强大的NLP库spaCy提供了准确的句子分割。它使用统计模型和语言规则。'
- en: '**Natural Language Toolkit (NLTK)**: NLTK, a powerful Python library for NLP,
    provides efficient sentence tokenization. It considers context and punctuation
    patterns.'
  id: totrans-117
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自然语言工具包（NLTK）**：NLTK是一个强大的Python NLP库，提供了高效的句子分词。它考虑上下文和标点符号模式。'
- en: '**Advanced tools**: Some tools employ smaller models to predict sentence boundaries,
    ensuring precise divisions.'
  id: totrans-118
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高级工具**：一些工具使用较小的模型来预测句子边界，确保精确的划分。'
- en: '**Specialized techniques**: Specialized techniques include the following:'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**专用技术**：专用技术包括以下内容：'
- en: '**Structured content**: For documents with specific formats (e.g., Markdown,
    LaTeX), specialized techniques come into play.'
  id: totrans-120
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**结构化内容**：对于具有特定格式（例如Markdown、LaTeX）的文档，专用技术就派上用场。'
- en: '**Intelligent division**: These methods analyze the content’s structure and
    hierarchy. They create semantically coherent chunks by understanding headings,
    lists, and other formatting cues.'
  id: totrans-121
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**智能划分**：这些方法分析内容的结构和层次。通过理解标题、列表和其他格式提示，它们创建语义上连贯的块。'
- en: In summary, while fixed-size chunking serves as a baseline, content-aware techniques
    consider semantics, context, and formatting intricacies. Choosing the right method
    depends on your data’s unique characteristics and the requirements of your RAG
    system. While choosing the retriever for storing and retrieving these chunks,
    you may want to consider solutions such as document hierarchies and knowledge
    graphs. MongoDB Atlas has a flexible schema and a simple unified query API to
    query data from it.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，虽然固定大小的分块可以作为基线，但内容感知技术考虑语义、上下文和格式复杂性。选择正确的方法取决于你数据的独特特性和你RAG系统的需求。在选择用于存储和检索这些块的数据检索器时，你可能想要考虑诸如文档层次结构和知识图谱等解决方案。MongoDB
    Atlas具有灵活的模式和简单的统一查询API，可以从中查询数据。
- en: Now let’s use the recursive document-splitting strategy to build a simple RAG
    application.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们使用递归文档拆分策略来构建一个简单的RAG应用。
- en: Simple RAG
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 简单RAG
- en: A simple RAG architecture implements a naive approach where the model retrieves
    a predetermined number of documents from the knowledge base based on their similarity
    to the user’s query. These retrieved documents are then combined with the query
    and input into the language model for generation, as shown in *Figure 8**.7*.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 一个简单的RAG架构实现了一种天真方法，其中模型根据与用户查询的相似性从知识库中检索预定的文档数量。然后，这些检索到的文档与查询结合，并输入到语言模型中进行生成，如图*8.7*所示。
- en: '![](img/B22495_08_07.jpg)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22495_08_07.jpg)'
- en: 'Figure 8.7: Naive RAG'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.7：天真RAG
- en: To build a simple RAG application, you will use the dataset you loaded to the
    MongoDB Atlas collection in the *Information retrieval with MongoDB Vector Search*
    section of this chapter. With this application, you’ll be able perform queries
    on the available movies and create a recommender system.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 要构建一个简单的RAG应用，你将使用本章“使用MongoDB向量搜索进行信息检索”部分中加载到MongoDB Atlas集合的数据集。通过这个应用，你将能够对可用的电影进行查询并创建一个推荐系统。
- en: LLM
  id: totrans-129
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: LLM
- en: This example will use the OpenAI APIs and `gpt-3.5-turbo`, but there are other
    variations of LLM models made available from OpenAI, such as `gpt-4o` and `gpt-4o-mini`.
    The same prompting technique can be used with other LLMs, such as `claude-v2`
    or `mistral8x-7B`, to achieve similar results.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 此示例将使用OpenAI API和`gpt-3.5-turbo`，但OpenAI还提供了其他LLM模型的变体，例如`gpt-4o`和`gpt-4o-mini`。相同的提示技术也可以用于其他LLM，如`claude-v2`或`mistral8x-7B`，以实现类似的结果。
- en: 'The following is the sample code to invoke the OpenAI LLM using LangChain:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是通过LangChain调用OpenAI LLM的示例代码：
- en: '[PRE10]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Here is the result:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是结果：
- en: '[PRE11]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Now that you have the APIs to call MongoDB Atlas Vector Search for retrieval
    and an API for invoking an LLM, you can combine these two tools to create a RAG
    system.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你有了调用MongoDB Atlas向量搜索进行检索的API以及调用LLM的API，你可以结合这两个工具来创建一个RAG系统。
- en: Prompt
  id: totrans-136
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: A prompt to an LLM is a user-provided instruction or input that guides the model’s
    response. It can be a question, a statement, or a command, and is designed to
    drive the LLM to respond with a specific output. The effectiveness of a prompt
    can greatly influence the quality of the results generated by a RAG-based system,
    making prompt engineering a crucial aspect for interacting with these models.
    Good prompts are clear, specific, and structured to communicate the user’s intent
    to the LLM, enabling it to generate the most accurate and helpful responses possible.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 对LLM的提示是用户提供的指令或输入，它指导模型的响应。它可以是一个问题、一个声明或一个命令，旨在驱动LLM以特定的输出进行响应。提示的有效性可以极大地影响基于RAG的系统生成结果的质量，使得提示工程与这些模型交互的一个关键方面。好的提示是清晰、具体和结构化的，以便将用户的意图传达给LLM，使其能够生成最准确和最有帮助的响应。
- en: 'The following is an example of a prompt to perform QA on a private knowledge
    base:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个在私有知识库上执行QA的提示示例：
- en: '[PRE12]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: To demonstrate the benefits of RAG over a foundational LLM, let's first ask
    the LLM a question without vector search context and then with it included. This
    will demonstrate how you can improve the accuracy of the results and reduce hallucinations
    while utilizing a foundational LLM, such as `gpt-3.5-turbo`, that was not trained
    on a private knowledge base.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示RAG相对于基础LLM的优势，让我们首先在没有向量搜索上下文的情况下询问LLM一个问题，然后包含它。这将展示你如何通过利用未在私有知识库上训练的基础LLM，如`gpt-3.5-turbo`，来提高结果的准确性并减少幻觉。
- en: 'Here is the query response without vector search:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是未使用向量搜索的查询响应：
- en: '[PRE13]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'This is the result:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 这是结果：
- en: '[PRE14]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Although the LLM’s response shows it struggles with factual accuracy, there
    is still promise in using it alongside human oversight for enterprise applications.
    Together, these systems can work effectively to power applications for businesses.
    To help overcome this issue, you need to add context to the prompt through vector
    search results.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然LLM的响应显示它在事实准确性方面存在困难，但与人类监督一起在企业应用中使用它仍然有希望。这些系统可以协同有效地为商业应用提供动力。为了帮助克服这个问题，你需要通过向量搜索结果向提示中添加上下文。
- en: 'Let''s see how you can use the `invoke_llm` function with the `query_vector_search`
    method to provide the relevant context alongside the user query to generate a
    response with a factually correct answer:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何使用`invoke_llm`函数和`query_vector_search`方法，将相关上下文与用户查询一起提供，以生成具有事实正确答案的响应：
- en: '[PRE15]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Here is the result:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是结果：
- en: '[PRE16]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Similarly, you can use the `get_recommendation_prompt` method to generate some
    movie recommendations using a simple RAG framework:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，你可以使用`get_recommendation_prompt`方法，通过简单的RAG框架生成一些电影推荐：
- en: '[PRE17]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Here is the result:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是结果：
- en: '![](img/B22495_08_08.jpg)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B22495_08_08.jpg)'
- en: 'Figure 8.8: Sample output from the simple RAG application'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.8：简单RAG应用的示例输出
- en: The simple RAG system you just built can handle straightforward queries that
    need answers to the point. Some examples are a customer service chatbot responding
    to a basic question such as “`Where is the customer support center in Bangalore?`”
    or helping you find all the restaurants where your favorite delicacy is served
    in Koramangala. The chatbot can retrieve the contextual piece of information in
    its retrieval step and generate an answer to this question with the help of the
    LLM.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 你刚刚构建的简单RAG系统可以处理需要直接答案的简单查询。一些例子包括客户服务聊天机器人回答诸如“`班加罗尔的客户服务中心在哪里？`”这样的基本问题，或者帮助你找到在Koramangala提供你最喜欢的美食的所有餐厅。聊天机器人在检索步骤中可以检索到相关的信息片段，并在LLM的帮助下生成对这个问题的答案。
- en: Advanced RAG
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 高级RAG
- en: An advanced RAG framework incorporates more complex retrieval techniques, better
    integration of retrieved information, and often, the ability to iteratively refine
    both the retrieval and generation processes. In this section, you will learn how
    to build an intelligent recommendation engine on fashion data that can identify
    the interest of the user and then generate relevant fashion product or accessory
    recommendations only when there is intent to purchase a product in the user’s
    utterance. You will be building an intelligent conversation chatbot that leverages
    the power of LangChain, MongoDB Atlas Vector Search, and OpenAI in this section.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 高级RAG框架集成了更复杂的检索技术，更好地整合检索到的信息，并且通常能够迭代地改进检索和生成过程。在本节中，你将学习如何构建一个智能推荐引擎，该引擎可以在时尚数据上识别用户的兴趣，并在用户的话语中有购买产品的意图时，仅生成相关的时尚产品或配件推荐。在本节中，你将构建一个利用LangChain、MongoDB
    Atlas Vector Search和OpenAI的力量的智能对话聊天机器人。
- en: 'The advanced RAG system in the current example will demonstrate the following
    features:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 当前示例中的高级RAG系统将展示以下功能：
- en: Utilize an LLM to generate multiple searchable fashion queries given a user’s
    chat utterance
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用LLM根据用户的聊天语句生成多个可搜索的时尚查询
- en: Classify the user’s chat utterance as to whether there is an intent to purchase
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将用户的聊天语句分类为是否有购买意图
- en: Develop a fusion stage that will also fetch vector similarity search results
    from multiple search queries to fuse them as a single recommendation set that
    is reranked with the help of an LLM
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发一个融合阶段，它还将从多个搜索查询中检索向量相似度搜索结果，并将它们融合为一个单一的推荐集，该推荐集通过LLM的帮助进行重新排序。
- en: 'The flow of steps when a user queries the RAG system is depicted in *Figure
    8**.9*:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 用户查询RAG系统时的步骤流程在*图8**.9*中展示：
- en: '![](img/B22495_08_09.jpg)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B22495_08_09.jpg)'
- en: 'Figure 8.9: Sample advanced RAG, flowchart for query processing and recommendation'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.9：查询处理和推荐的示例高级RAG流程图
- en: Let’s walk through the code to load the sample dataset and build the advanced
    RAG system with all the features that were listed at the beginning of this section.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐步分析代码，以加载示例数据集并构建具有本节开头列出的所有功能的先进RAG系统。
- en: Loading the dataset
  id: totrans-166
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 加载数据集
- en: 'For this example, you will utilize fashion data from a popular e-commerce company.
    The following code shows you how to load a dataset from an S3 bucket to a `pandas`
    DataFrame and then insert these documents into a MongoDB Atlas collection, `search.catalog_final_myn`:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 对于此示例，您将利用来自一家知名电子商务公司的时尚数据。以下代码展示了如何将数据集从S3存储桶加载到`pandas` DataFrame中，然后将这些文档插入到MongoDB
    Atlas集合`search.catalog_final_myn`中：
- en: '[PRE18]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Here is the result:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是结果：
- en: '![](img/B22495_08_10.jpg)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22495_08_10.jpg)'
- en: 'Figure 8.10: Sample view of the fashion dataset with OpenAI embeddings'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.10：使用OpenAI嵌入的时尚数据集的示例视图
- en: Creating a vector search index
  id: totrans-172
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建向量搜索索引
- en: 'As you can see in *Figure 8**.10*, the vector embeddings are already provided
    as part of the dataset. Therefore, the next step is to create a vector search
    index. You can create the vector search index by following the steps detailed
    in *Chapter 5*, *Vector Databases*, using the following index mapping:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 如您在*图8**.10*中看到的那样，向量嵌入已经作为数据集的一部分提供。因此，下一步是创建向量搜索索引。您可以通过遵循*第5章*，*向量数据库*中详细说明的步骤，使用以下索引映射来创建向量搜索索引：
- en: '[PRE19]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Fashion recommendations using advanced RAG
  id: totrans-175
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用高级RAG的时尚推荐
- en: 'You have successfully loaded the new fashion dataset into the MongoDB Atlas
    collection and also created a vector search index with all the building blocks
    in place. You can now use the following code to set up an advanced RAG system
    and build a recommender system with the features mentioned earlier:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 您已成功将新的时尚数据集加载到MongoDB Atlas集合中，并创建了包含所有构建块的向量搜索索引。现在，您可以使用以下代码设置高级RAG系统并构建具有之前提到的功能的推荐系统：
- en: '[PRE20]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The preceding code carries out the following tasks:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码执行以下任务：
- en: Importing the necessary modules and functions from various libraries. These
    include `JsonOutputParser` for parsing JSON output, `PromptTemplate` for creating
    prompts, `BaseModel` and `Field` for defining data models, and `MongoDBAtlasVectorSearch`
    for interacting with a MongoDB Atlas vector store. It also imports `MongoClient`
    for connecting to MongoDB, `load_dotenv` for loading environment variables, and
    `lru_cache` for caching function results.
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从各种库中导入必要的模块和函数。这包括用于解析JSON输出的`JsonOutputParser`，用于创建提示的`PromptTemplate`，用于定义数据模型的`BaseModel`和`Field`，以及用于与MongoDB
    Atlas向量存储交互的`MongoDBAtlasVectorSearch`。它还导入了`MongoClient`以连接到MongoDB，`load_dotenv`以加载环境变量，以及`lru_cache`以缓存函数结果。
- en: It defines three functions, each decorated with `lru_cache` to cache their results
    for efficiency. `get_openai_emb_transformers` returns an instance of `OpenAIEmbeddings`,
    which provides access to OpenAI transformer models for NLP. `get_vector_store`
    retrieves the vector store for MongoDB Atlas. `get_conversation_chain_conv` retrieves
    a conversation chain model for chat conversations.
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它定义了三个函数，每个函数都使用`lru_cache`装饰以缓存其结果以提高效率。`get_openai_emb_transformers`返回一个`OpenAIEmbeddings`实例，该实例提供对OpenAI
    NLP转换器模型的访问。`get_vector_store`检索MongoDB Atlas的向量存储。`get_conversation_chain_conv`检索用于聊天对话的对话链模型。
- en: It defines three classes using Pydantic’s `BaseModel` and `Field`. These classes
    represent the status of product recommendations (`ProductRecoStatus`), a product
    (`Product`), and a set of recommendations for products and a message to the user
    (`Recommendations`).
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用Pydantic的`BaseModel`和`Field`定义了三个类。这些类代表产品推荐的状态（`ProductRecoStatus`），一个产品（`Product`），以及一组产品推荐和用户消息（`Recommendations`）。
- en: Creating instances of `JsonOutputParser` and `PromptTemplate` for parsing JSON
    output and creating prompts, respectively. These instances are used to create
    conversation chains in the next section.
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建用于解析JSON输出和创建提示的`JsonOutputParser`和`PromptTemplate`实例。这些实例用于在下一节中创建对话链。
- en: It defines two functions for retrieving the recommendation status for a product
    and retrieving product recommendations based on a given query and chat history.
    `get_product_reco_status` uses a conversation chain to determine the recommendation
    status for a product based on a given query and chat history. `get_product_recommendations`
    retrieves product recommendations based on a given query and chat history, a filter
    query, and a list of recommendation queries. It uses a vector store retriever
    to get relevant documents for each recommendation query, and then uses a conversation
    chain to generate the final recommendations.
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它定义了两个函数，用于检索产品的推荐状态和基于给定的查询和聊天历史检索产品推荐。`get_product_reco_status`使用会话链根据给定的查询和聊天历史确定产品的推荐状态。`get_product_recommendations`根据给定的查询和聊天历史、过滤查询和推荐查询列表检索产品推荐。它使用向量存储检索器获取每个推荐查询的相关文档，然后使用会话链生成最终的推荐。
- en: 'Let’s now use these methods to create a product recommendations example. Enter
    the following code and then examine its output:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们现在使用这些方法来创建一个产品推荐示例。输入以下代码，然后检查其输出：
- en: '[PRE21]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'This is the status output:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 这是状态输出：
- en: '[PRE22]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: You can see from the preceding example output that the LLM is able to classify
    the product intent purchase as positive and recommend suitable queries by performing
    vector similarity search on the MongoDB Atlas collection.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从前面的示例输出中看到，LLM能够通过在MongoDB Atlas集合上执行向量相似性搜索来将产品意图购买分类为正面，并推荐合适的查询。
- en: 'This is the product recommendations output:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 这是产品推荐输出：
- en: '![](img/B22495_08_11.jpg)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B22495_08_11.jpg)'
- en: 'Figure 8.11: Sample output from the advanced RAG chatbot with recommendations
    for the user''s search intent'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.11：高级RAG聊天机器人根据用户的搜索意图提供的推荐示例输出
- en: 'Conversely, you can test the same methods to find a suitable place for a date
    instead of ideas for gifts or what to wear. In this case, the model will classify
    the query as having negative product purchase intent and not provide any search
    term suggestions:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，你可以测试相同的方法来找到一个适合约会的地点，而不是寻找礼物或着装的建议。在这种情况下，模型将查询分类为具有负面产品购买意图，并且不会提供任何搜索词建议：
- en: '[PRE23]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Here is the status output:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 这是状态输出：
- en: '[PRE24]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Here is the output from the LLM:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 这是LLM的输出：
- en: '![](img/B22495_08_12.jpg)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B22495_08_12.jpg)'
- en: 'Figure 8.12: Sample output from the advanced RAG system when there is no purchase
    intent in the query'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.12：在查询中没有购买意图时高级RAG系统的示例输出
- en: Advanced RAG introduces the concept of modularity when building RAG architecture
    systems. The above example focuses on developing a user flow-based approach for
    the sample advanced RAG system. It also explores how to leverage LLMs for conditional
    decision making, recommendation generation, and re-ranking the recommendations
    retrieved from the retriever system. The goal is to enhance the user experience
    during interactions with the application.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 高级RAG在构建RAG架构系统时引入了模块化的概念。上述示例侧重于为示例高级RAG系统开发基于用户流程的方法。它还探讨了如何利用大型语言模型进行条件决策、推荐生成以及重新排序检索系统检索到的推荐。目标是增强与应用程序交互时的用户体验。
- en: Summary
  id: totrans-200
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you explored the pivotal role of vector search in enhancing
    AI-powered systems. The key takeaway is that vector search plays a vital role
    in AI applications, addressing the challenge of efficient search as unstructured
    and multimodal datasets expand. It benefits image recognition, NLP, and recommendation
    systems.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你探讨了向量搜索在增强人工智能系统中的关键作用。关键要点是向量搜索在人工智能应用中发挥着至关重要的作用，解决了随着非结构化和多模态数据集的扩展而带来的高效搜索挑战。它对图像识别、自然语言处理和推荐系统都有益。
- en: MongoDB Atlas is used to demonstrate vector search implementation using its
    flexible schema and vector indexing capabilities. You were able to build a RAG
    framework for solving QA use cases that combines retrieval and generation models,
    with a simple RAG system utilizing pre-trained language models and embedding models
    from OpenAI. You also learned how to build an advanced RAG system that employs
    iterative refinement and sophisticated retrieval algorithms with the help of LLMs
    for building a recommendation system for the fashion industry. With these insights,
    you can now build efficient AI applications for any domain or industry.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 使用MongoDB Atlas演示了利用其灵活的架构和向量索引功能实现向量搜索的实现。您能够构建一个用于解决问答用例的RAG框架，该框架结合了检索和生成模型，使用了一个简单的RAG系统，该系统利用了来自OpenAI的预训练语言模型和嵌入模型。您还学习了如何构建一个高级RAG系统，该系统利用迭代优化和复杂的检索算法，在LLM的帮助下为时尚行业构建推荐系统。有了这些见解，您现在可以为任何领域或行业构建高效的AI应用。
- en: In the next chapter, you will delve into the critical aspects of evaluating
    LLM outputs in such RAG applications and explore various evaluation methods, metrics,
    and user feedback. You will also learn about the implementation of guardrails
    to ensure responsible AI deployment and how to better control the behavior of
    LLM-generated responses.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，您将深入了解在RAG应用中评估LLM输出的关键方面，并探讨各种评估方法、指标和用户反馈。您还将了解如何实施安全措施以确保负责任的AI部署，以及如何更好地控制LLM生成的响应的行为。
- en: Part 3
  id: totrans-204
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第三部分
- en: 'Optimizing AI Applications: Scaling, Fine-Tuning, Troubleshooting, Monitoring,
    and Analytics'
  id: totrans-205
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优化AI应用：扩展、微调、故障排除、监控和分析
- en: This set of chapters shares techniques and practices for evaluating your AI
    application as well as strategies and expert insights for improving your application,
    avoiding pitfalls, and ensuring that your application continues to function optimally
    despite rapid technological changes.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 这套章节分享了评估您的AI应用的技巧和实践，以及改进应用、避免陷阱和确保应用在快速技术变革中持续最优运行的策略和专家见解。
- en: 'This part of the book includes the following chapters:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 本书本部分包括以下章节：
- en: '[*Chapter 9*](B22495_09.xhtml#_idTextAnchor193), *LLM Output Evaluation*'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第9章*](B22495_09.xhtml#_idTextAnchor193), *LLM输出评估*'
- en: '[*Chapter 10*](B22495_10.xhtml#_idTextAnchor214), *Refining the Semantic Data
    Model to Improve Accuracy*'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第10章*](B22495_10.xhtml#_idTextAnchor214), *精炼语义数据模型以提高准确性*'
- en: '[*Chapter 11*](B22495_11.xhtml#_idTextAnchor232), *Common Failures of Generative
    AI*'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第11章*](B22495_11.xhtml#_idTextAnchor232), *生成式AI的常见故障*'
- en: '[*Chapter 12*](B22495_12.xhtml#_idTextAnchor253), *Correcting and Optimizing
    Your Generative AI Application*'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第12章*](B22495_12.xhtml#_idTextAnchor253), *优化您的生成式AI应用*'
