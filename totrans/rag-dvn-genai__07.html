<html><head></head><body>
  <div id="_idContainer087" class="Basic-Text-Frame">
    <h1 class="chapterNumber"><span class="koboSpan" id="kobo.1.1">7</span></h1>
    <h1 id="_idParaDest-183" class="chapterTitle"><span class="koboSpan" id="kobo.2.1">Building Scalable Knowledge-Graph-Based RAG with Wikipedia API and LlamaIndex</span></h1>
    <p class="normal"><span class="koboSpan" id="kobo.3.1">Scaled datasets can rapidly become challenging to manage. </span><span class="koboSpan" id="kobo.3.2">In real-life projects, data management generates more headaches than AI! </span><span class="koboSpan" id="kobo.3.3">Project managers, consultants, and developers constantly struggle to obtain the necessary data to get any project running, let alone a RAG-driven generative AI application. </span><span class="koboSpan" id="kobo.3.4">Data is often unstructured before it becomes organized in one way or another through painful decision-making processes. </span><span class="koboSpan" id="kobo.3.5">Wikipedia is a good example of how scaling data leads to mostly reliable but sometimes incorrect information. </span><span class="koboSpan" id="kobo.3.6">Real-life projects often evolve the way Wikipedia does. </span><span class="koboSpan" id="kobo.3.7">Data keeps piling up in a company, challenging database administrators, project managers, and users.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.4.1">One of the main problems is seeing how large amounts of data fit together, and </span><strong class="keyWord"><span class="koboSpan" id="kobo.5.1">knowledge graphs</span></strong><span class="koboSpan" id="kobo.6.1"> provide an </span><a id="_idIndexMarker445"/><span class="koboSpan" id="kobo.7.1">effective way of visualizing the relationships between different types of data. </span><span class="koboSpan" id="kobo.7.2">This chapter begins by defining the architecture of a knowledge base ecosystem designed for RAG-driven generative AI. </span><span class="koboSpan" id="kobo.7.3">The ecosystem contains three pipelines: data collection, populating a vector store, and running a knowledge graph index-based RAG program. </span><span class="koboSpan" id="kobo.7.4">We will then build </span><em class="italic"><span class="koboSpan" id="kobo.8.1">Pipeline 1: Collecting and preparing the documents</span></em><span class="koboSpan" id="kobo.9.1">, in which we will build an automated Wikipedia retrieval program with the Wikipedia API. </span><span class="koboSpan" id="kobo.9.2">We will simply choose a topic based on a Wikipedia page and then let the program retrieve the metadata we need to collect and prepare the data. </span><span class="koboSpan" id="kobo.9.3">The system will be flexible and allow you to choose any topic you wish. </span><span class="koboSpan" id="kobo.9.4">The use case to first run the program is a marketing knowledge base for students who want to upskill for a new job, for example. </span><span class="koboSpan" id="kobo.9.5">The next step is to build </span><em class="italic"><span class="koboSpan" id="kobo.10.1">Pipeline 2: Creating and populating the Deep Lake vector store</span></em><span class="koboSpan" id="kobo.11.1">. </span><span class="koboSpan" id="kobo.11.2">We will load the data in a vector store leveraging Deep Lake’s in-built automated chunking and OpenAI embedding functionality. </span><span class="koboSpan" id="kobo.11.3">We will peek into the dataset to explore how this marvel of technology does the job.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.12.1">Finally, we will build </span><em class="italic"><span class="koboSpan" id="kobo.13.1">Pipeline 3: Knowledge graph index-based RAG</span></em><span class="koboSpan" id="kobo.14.1">, where LlamaIndex will automatically build a knowledge graph index. </span><span class="koboSpan" id="kobo.14.2">It will be exciting to see how the index function churns through our data and produces a graph showing semantic relationships contained in our data. </span><span class="koboSpan" id="kobo.14.3">We will then query the graph with LlamaIndex’s in-built OpenAI functionality to automatically manage user inputs and produce a response. </span><span class="koboSpan" id="kobo.14.4">We will also see how re-ranking can be done and implement metrics to calculate and display the system’s performance.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.15.1">This chapter covers the following topics:</span></p>
    <ul>
      <li class="bulletList"><span class="koboSpan" id="kobo.16.1">Defining knowledge graphs</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.17.1">Implementing the Wikipedia API to prepare summaries and content</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.18.1">Citing Wikipedia sources in an ethical approach</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.19.1">Populating a Deep Lake vector store with Wikipedia data</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.20.1">Building a knowledge graph index with LlamaIndex</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.21.1">Displaying the LlamaIndex knowledge graph</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.22.1">Interacting with the knowledge graph</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.23.1">Generating retrieval responses with the knowledge graph</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.24.1">Re-ranking the order retrieval responses to choose a better output</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.25.1">Evaluating and measuring the outputs with metrics</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.26.1">Let’s begin by defining the architecture of RAG for knowledge-based semantic search.</span></p>
    <h1 id="_idParaDest-184" class="heading-1"><span class="koboSpan" id="kobo.27.1">The architecture of RAG for knowledge-graph-based semantic search</span></h1>
    <p class="normal"><span class="koboSpan" id="kobo.28.1">As established, we will build a</span><a id="_idIndexMarker446"/><span class="koboSpan" id="kobo.29.1"> graph-based RAG program in this chapter. </span><span class="koboSpan" id="kobo.29.2">The graph will enable us to visually map out the relationships between the documents of a RAG dataset. </span><span class="koboSpan" id="kobo.29.3">It can be created automatically with LlamaIndex, as we will do in the </span><em class="italic"><span class="koboSpan" id="kobo.30.1">Pipeline 3: Knowledge graph index-based RAG</span></em><span class="koboSpan" id="kobo.31.1"> section of this chapter. </span><span class="koboSpan" id="kobo.31.2">The program in this chapter will be designed for any Wikipedia topic, as illustrated in the following figure:</span></p>
    <figure class="mediaobject"><span class="koboSpan" id="kobo.32.1"><img src="../Images/B31169_07_01.png" alt="A diagram of a graph  Description automatically generated"/></span></figure>
    <p class="packt_figref"><span class="koboSpan" id="kobo.33.1">Figure 7.1: From a Wikipedia topic to interacting with a graph-based vector store index</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.34.1">We will first implement a marketing agency for which a knowledge graph can visually map out the complex relationships between different marketing concepts. </span><span class="koboSpan" id="kobo.34.2">Then, you can go back and explore</span><a id="_idIndexMarker447"/><span class="koboSpan" id="kobo.35.1"> any topic you wish once you understand the process. </span><span class="koboSpan" id="kobo.35.2">In simpler words, we will implement the three pipelines seamlessly to:</span></p>
    <ul>
      <li class="bulletList"><span class="koboSpan" id="kobo.36.1">Select a Wikipedia topic related to </span><em class="italic"><span class="koboSpan" id="kobo.37.1">marketing</span></em><span class="koboSpan" id="kobo.38.1">. </span><span class="koboSpan" id="kobo.38.2">Then, you can run the process with the topic of your choice to explore the ecosystem.</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.39.1">Generate a corpus of Wikipedia pages with the Wikipedia API.</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.40.1">Retrieve and store the citations for each page.</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.41.1">Retrieve and store the URLs for each page.</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.42.1">Retrieve and upsert the content of the URLs in a Deep Lake vector store.</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.43.1">Build a knowledge base index with LlamaIndex.</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.44.1">Define a user input prompt.</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.45.1">Query the knowledge base index.</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.46.1">Let LlamaIndex’s in-built LLM functionality, based on OpenAI’s embedding models, produce a response based on the embedded data in the knowledge graph.</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.47.1">Evaluate the LLM’s response with a sentence transformer.</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.48.1">Evaluate the LLM’s response with a human feedback score.</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.49.1">Provide time metrics for the key functions, which you can extend to other functions if necessary.</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.50.1">Run metric calculations and display the results.</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.51.1">To attain our goal, we will implement three pipelines leveraging the components we have already built in the previous</span><a id="_idIndexMarker448"/><span class="koboSpan" id="kobo.52.1"> chapters, as illustrated in the following figure:</span></p>
    <figure class="mediaobject"><span class="koboSpan" id="kobo.53.1"><img src="../Images/B31169_07_02.png" alt="A diagram of a graph  Description automatically generated"/></span></figure>
    <p class="packt_figref"><span class="koboSpan" id="kobo.54.1">Figure 7.2: Knowledge graph ecosystem for index-based RAG</span></p>
    <ul>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.55.1">Pipeline 1: Collecting and preparing the documents</span></strong><span class="koboSpan" id="kobo.56.1"> will involve building a Wikipedia program using the Wikipedia API to retrieve links from a Wikipedia page and the metadata for all the pages (summary, URL, and citation data). </span><span class="koboSpan" id="kobo.56.2">Then, we will load and parse the URLs to prepare the data for upserting.</span></li>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.57.1">Pipeline 2: Creating and populating the Deep Lake vector store</span></strong><span class="koboSpan" id="kobo.58.1"> will embed and upsert parsed content of the Wikipedia pages prepared by </span><em class="italic"><span class="koboSpan" id="kobo.59.1">Pipeline 1</span></em><span class="koboSpan" id="kobo.60.1"> to a Deep Lake vector store.</span></li>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.61.1">Pipeline 3: Knowledge graph index-based RAG</span></strong><span class="koboSpan" id="kobo.62.1"> will build the knowledge graph index using embeddings with LlamaIndex and display it. </span><span class="koboSpan" id="kobo.62.2">Then, we will build the functionality to query the knowledge base index and let LlamaIndex’s in-built LLM generate the response based on the updated dataset.</span></li>
    </ul>
    <div class="note">
      <p class="normal"><span class="koboSpan" id="kobo.63.1">In this chapter’s scenario, we are directly implementing an augmented retrieval system leveraging OpenAI’s embedding models more than we are augmenting inputs. </span><span class="koboSpan" id="kobo.63.2">This implementation shows the many ways we can improve real-time data retrieval with LLMs. </span><span class="koboSpan" id="kobo.63.3">There are no conventional rules. </span><span class="koboSpan" id="kobo.63.4">What works, works!</span></p>
    </div>
    <p class="normal"><span class="koboSpan" id="kobo.64.1">The ecosystem of the</span><a id="_idIndexMarker449"/><span class="koboSpan" id="kobo.65.1"> three pipelines will be controlled by a scenario that will enable an administrator to either query the vector base or add new Wikipedia pages, as we will implement in this chapter. </span><span class="koboSpan" id="kobo.65.2">As such, the architecture of the ecosystem allows for indefinite scaling since it processes and populates the vector dataset one set of Wikipedia pages at a time. </span><span class="koboSpan" id="kobo.65.3">The system only uses a CPU and an optimized amount of memory. </span><span class="koboSpan" id="kobo.65.4">There are limits to this approach since the LlamaIndex knowledge graph index is loaded with the entire dataset. </span><span class="koboSpan" id="kobo.65.5">We can only load portions of the dataset as the vector store grows. </span><span class="koboSpan" id="kobo.65.6">Or, we can create one Deep Lake vector store per topic and run queries on multiple datasets. </span><span class="koboSpan" id="kobo.65.7">These are decisions to make in real-life projects that require careful decision-making and planning depending on the specific requirements of each project.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.66.1">We will now dive into the code, beginning a tree-to-graph sandbox.</span></p>
    <h2 id="_idParaDest-185" class="heading-2"><span class="koboSpan" id="kobo.67.1">Building graphs from trees</span></h2>
    <p class="normal"><span class="koboSpan" id="kobo.68.1">A graph is a collection </span><a id="_idIndexMarker450"/><span class="koboSpan" id="kobo.69.1">of nodes (or vertices) connected by edges (or arcs). </span><span class="koboSpan" id="kobo.69.2">Nodes represent entities, and edges represent relationships or connections between these entities. </span><span class="koboSpan" id="kobo.69.3">For instance, in our chapter’s use case, nodes could represent various marketing strategies, and the edges could show how these strategies are interconnected. </span><span class="koboSpan" id="kobo.69.4">This helps new customers understand how different marketing tactics work together to achieve overall business goals, facilitating clearer communication and more effective strategy planning. </span><span class="koboSpan" id="kobo.69.5">You can play around with the tree-to-graph sandbox before building the pipelines in this chapter.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.70.1">You may open </span><code class="inlineCode"><span class="koboSpan" id="kobo.71.1">Tree-2-Graph.ipynb</span></code><span class="koboSpan" id="kobo.72.1"> on GitHub. </span><span class="koboSpan" id="kobo.72.2">The provided program is designed to visually represent relationships in a tree structure using NetworkX and Matplotlib in Python. </span><span class="koboSpan" id="kobo.72.3">It specifically creates a directed graph from given pairs, checks and marks friendships, and then </span><a id="_idIndexMarker451"/><span class="koboSpan" id="kobo.73.1">displays this tree with customized visual attributes.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.74.1">The program first defines the main functions:</span></p>
    <ul>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.75.1">build_tree_from_pairs(pairs)</span></code><span class="koboSpan" id="kobo.76.1">: Constructs a directed graph (tree) from a list of node pairs, potentially identifying a root node</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.77.1">check_relationships(pairs, friends)</span></code><span class="koboSpan" id="kobo.78.1">: Checks and prints the friendship status for each pair</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.79.1">draw_tree(G, layout_choice, root, friends)</span></code><span class="koboSpan" id="kobo.80.1">: Visualizes the tree using </span><code class="inlineCode"><span class="koboSpan" id="kobo.81.1">matplotlib</span></code><span class="koboSpan" id="kobo.82.1">, applying different styles to edges based on friendship status and different layout options for node positioning</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.83.1">Then, the program executes the process from tree to graph:</span></p>
    <ul>
      <li class="bulletList"><span class="koboSpan" id="kobo.84.1">Node pairs and friendship data are defined.</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.85.1">The tree is built from the pairs.</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.86.1">Relationships are checked against the friendship data.</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.87.1">The tree is drawn using a selected layout, with edges styled differently to denote friendship.</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.88.1">For example, the program first defines a set of node pairs with their pairs of friends:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.89.1"># Pairs</span></span><span class="koboSpan" id="kobo.90.1">
pairs = [(</span><span class="hljs-string"><span class="koboSpan" id="kobo.91.1">'</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.92.1">a'</span></span><span class="koboSpan" id="kobo.93.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.94.1">'b'</span></span><span class="koboSpan" id="kobo.95.1">), (</span><span class="hljs-string"><span class="koboSpan" id="kobo.96.1">'b'</span></span><span class="koboSpan" id="kobo.97.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.98.1">'e'</span></span><span class="koboSpan" id="kobo.99.1">), (</span><span class="hljs-string"><span class="koboSpan" id="kobo.100.1">'e'</span></span><span class="koboSpan" id="kobo.101.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.102.1">'m'</span></span><span class="koboSpan" id="kobo.103.1">), (</span><span class="hljs-string"><span class="koboSpan" id="kobo.104.1">'m'</span></span><span class="koboSpan" id="kobo.105.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.106.1">'p'</span></span><span class="koboSpan" id="kobo.107.1">), (</span><span class="hljs-string"><span class="koboSpan" id="kobo.108.1">'a'</span></span><span class="koboSpan" id="kobo.109.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.110.1">'z'</span></span><span class="koboSpan" id="kobo.111.1">), (</span><span class="hljs-string"><span class="koboSpan" id="kobo.112.1">'</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.113.1">b'</span></span><span class="koboSpan" id="kobo.114.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.115.1">'q'</span></span><span class="koboSpan" id="kobo.116.1">)]
friends = {(</span><span class="hljs-string"><span class="koboSpan" id="kobo.117.1">'a'</span></span><span class="koboSpan" id="kobo.118.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.119.1">'b'</span></span><span class="koboSpan" id="kobo.120.1">), (</span><span class="hljs-string"><span class="koboSpan" id="kobo.121.1">'b'</span></span><span class="koboSpan" id="kobo.122.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.123.1">'e'</span></span><span class="koboSpan" id="kobo.124.1">), (</span><span class="hljs-string"><span class="koboSpan" id="kobo.125.1">'e'</span></span><span class="koboSpan" id="kobo.126.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.127.1">'m'</span></span><span class="koboSpan" id="kobo.128.1">), (</span><span class="hljs-string"><span class="koboSpan" id="kobo.129.1">'m'</span></span><span class="koboSpan" id="kobo.130.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.131.1">'p'</span></span><span class="koboSpan" id="kobo.132.1">)}
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.133.1">Notice that </span><code class="inlineCode"><span class="koboSpan" id="kobo.134.1">('a', 'z')</span></code><span class="koboSpan" id="kobo.135.1"> are not friends because they are not on the </span><code class="inlineCode"><span class="koboSpan" id="kobo.136.1">friends</span></code><span class="koboSpan" id="kobo.137.1"> list. </span><span class="koboSpan" id="kobo.137.2">Neither are </span><code class="inlineCode"><span class="koboSpan" id="kobo.138.1">('b', 'q')</span></code><span class="koboSpan" id="kobo.139.1">. </span><span class="koboSpan" id="kobo.139.2">You can imagine any type of relationship between the pairs, such as the same customer age, similar job, same country, or any other concept you wish to represent. </span><span class="koboSpan" id="kobo.139.3">For instance, the </span><code class="inlineCode"><span class="koboSpan" id="kobo.140.1">friends</span></code><span class="koboSpan" id="kobo.141.1"> list could contain relationships between friends on social media, friends living in the same country, or anything else you can imagine or need!</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.142.1">The program then builds the tree and checks the relationships:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.143.1"># Build the tree</span></span><span class="koboSpan" id="kobo.144.1">
tree, root = build_tree_from_pairs(pairs)
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.145.1"># Check relationships</span></span><span class="koboSpan" id="kobo.146.1">
check_relationships(pairs, friends)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.147.1">The output shows which pairs are friends and which ones are not:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.148.1">Pair ('a', 'b'): friend
Pair ('b', 'e'): friend
Pair ('e', 'm'): friend
Pair ('m', 'p'): friend
Pair ('a', 'z'): not friend
Pair ('b', 'q'): not friend
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.149.1">The output can be used to provide useful information for similarity searches. </span><span class="koboSpan" id="kobo.149.2">The program now draws the graph with the </span><code class="inlineCode"><span class="koboSpan" id="kobo.150.1">'spring'</span></code><span class="koboSpan" id="kobo.151.1"> layout:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.152.1"># Draw the tree</span></span><span class="koboSpan" id="kobo.153.1">
layout_choice = </span><span class="hljs-string"><span class="koboSpan" id="kobo.154.1">'spring'</span></span>  <span class="hljs-comment"><span class="koboSpan" id="kobo.155.1"># Define your layout choice here</span></span><span class="koboSpan" id="kobo.156.1">
draw_tree(tree, layout_choice=layout_choice, root=root, friends=friends)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.157.1">The </span><code class="inlineCode"><span class="koboSpan" id="kobo.158.1">'spring'</span></code><span class="koboSpan" id="kobo.159.1"> layout </span><a id="_idIndexMarker452"/><span class="koboSpan" id="kobo.160.1">attracts nodes attracted by edges, simulating the effect of springs. </span><span class="koboSpan" id="kobo.160.2">It also ensures that all nodes repel each other to avoid overlapping. </span><span class="koboSpan" id="kobo.160.3">You can dig into the </span><code class="inlineCode"><span class="koboSpan" id="kobo.161.1">draw_tree</span></code><span class="koboSpan" id="kobo.162.1"> function to explore and select other layouts listed there. </span><span class="koboSpan" id="kobo.162.2">You can also modify the colors and line styles.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.163.1">In this case, the pairs of friends are represented with solid lines, and the pairs that are not friends are represented with dashes, as shown in the following graph:</span></p>
    <figure class="mediaobject"><span class="koboSpan" id="kobo.164.1"><img src="../Images/B31169_07_03.png" alt="A diagram of a tree  Description automatically generated"/></span></figure>
    <p class="packt_figref"><span class="koboSpan" id="kobo.165.1">Figure 7.3: Example of a spring layout</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.166.1">You can play with this </span><a id="_idIndexMarker453"/><span class="koboSpan" id="kobo.167.1">sandbox graph with different pairs of nodes. </span><span class="koboSpan" id="kobo.167.2">If you imagine doing this with hundreds of nodes, you will begin to appreciate the automated functionality we will build in this chapter with LlamaIndex’s knowledge graph index!</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.168.1">Let’s go from the architecture to the code, starting by collecting and preparing the documents.</span></p>
    <h1 id="_idParaDest-186" class="heading-1"><span class="koboSpan" id="kobo.169.1">Pipeline 1: Collecting and preparing the documents</span></h1>
    <p class="normal"><span class="koboSpan" id="kobo.170.1">The code in this section retrieves the metadata we need from Wikipedia, retrieves the documents, cleans them, and </span><a id="_idIndexMarker454"/><span class="koboSpan" id="kobo.171.1">aggregates them to be ready for insertion into the Deep Lake vector</span><a id="_idIndexMarker455"/><span class="koboSpan" id="kobo.172.1"> store. </span><span class="koboSpan" id="kobo.172.2">This process is illustrated in the following figure:</span></p>
    <figure class="mediaobject"><span class="koboSpan" id="kobo.173.1"><img src="../Images/B31169_07_04.png" alt="A diagram of a document  Description automatically generated"/></span></figure>
    <p class="packt_figref"><span class="koboSpan" id="kobo.174.1">Figure 7.4: Pipeline 1 flow chart</span></p>
    <p class="normal"><em class="italic"><span class="koboSpan" id="kobo.175.1">Pipeline 1</span></em><span class="koboSpan" id="kobo.176.1"> includes two notebooks:</span></p>
    <ul>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.177.1">Wikipedia_API.ipynb</span></code><span class="koboSpan" id="kobo.178.1">, in which we will implement the Wikipedia API to retrieve the URLs of the pages related to the root page of the topic we selected, including the citations for each page. </span><span class="koboSpan" id="kobo.178.2">As mentioned, the topic is “marketing” in our case.</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.179.1">Knowledge_Graph_Deep_Lake_LlamaIndex_OpenAI_RAG.ipynb</span></code><span class="koboSpan" id="kobo.180.1">, in which we will implement all three pipelines. </span><span class="koboSpan" id="kobo.180.2">In Pipeline 1, it will fetch the URLs provided by the </span><code class="inlineCode"><span class="koboSpan" id="kobo.181.1">Wikipedia_API</span></code><span class="koboSpan" id="kobo.182.1"> notebook, clean them, and load and aggregate them for upserting.</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.183.1">We will begin by implementing the Wikipedia API.</span></p>
    <h2 id="_idParaDest-187" class="heading-2"><span class="koboSpan" id="kobo.184.1">Retrieving Wikipedia data and metadata</span></h2>
    <p class="normal"><span class="koboSpan" id="kobo.185.1">Let’s begin by building a</span><a id="_idIndexMarker456"/><span class="koboSpan" id="kobo.186.1"> program to interact with the Wikipedia API to retrieve information about a specific topic, tokenize the retrieved text, and manage citations from Wikipedia </span><a id="_idIndexMarker457"/><span class="koboSpan" id="kobo.187.1">articles. </span><span class="koboSpan" id="kobo.187.2">You may open </span><code class="inlineCode"><span class="koboSpan" id="kobo.188.1">Wikipedia_API.ipynb</span></code><span class="koboSpan" id="kobo.189.1"> in the GitHub repository and follow along.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.190.1">The program begins by installing the </span><code class="inlineCode"><span class="koboSpan" id="kobo.191.1">wikipediaapi</span></code><span class="koboSpan" id="kobo.192.1"> library we need:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.193.1">try</span></span><span class="koboSpan" id="kobo.194.1">:
  </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.195.1">import</span></span><span class="koboSpan" id="kobo.196.1"> wikipediaapi
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.197.1">except</span></span><span class="koboSpan" id="kobo.198.1">:
  !pip install Wikipedia-API==</span><span class="hljs-number"><span class="koboSpan" id="kobo.199.1">0.6.0</span></span>
  <span class="hljs-keyword"><span class="koboSpan" id="kobo.200.1">import</span></span><span class="koboSpan" id="kobo.201.1"> wikipediaapi
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.202.1">The next step is to define the tokenization function that will be called to count the number of tokens of a summary, as shown in the following excerpt:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.203.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.204.1">nb_tokens</span></span><span class="koboSpan" id="kobo.205.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.206.1">text</span></span><span class="koboSpan" id="kobo.207.1">):
    </span><span class="hljs-comment"><span class="koboSpan" id="kobo.208.1"># More sophisticated tokenization which includes punctuation</span></span><span class="koboSpan" id="kobo.209.1">
    tokens = word_tokenize(text)
    </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.210.1">return</span></span> <span class="hljs-built_in"><span class="koboSpan" id="kobo.211.1">len</span></span><span class="koboSpan" id="kobo.212.1">(tokens)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.213.1">This function takes a string of text as input and returns the number of tokens in the text, using the NLTK library for sophisticated tokenization, including punctuation. </span><span class="koboSpan" id="kobo.213.2">Next, to start retrieving data, we need to set up an instance of the Wikipedia API with a specified language and user agent:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.214.1"># Create an instance of the Wikipedia API with a detailed user agent</span></span><span class="koboSpan" id="kobo.215.1">
wiki = wikipediaapi.Wikipedia(
    language=</span><span class="hljs-string"><span class="koboSpan" id="kobo.216.1">'en'</span></span><span class="koboSpan" id="kobo.217.1">,
    user_agent=</span><span class="hljs-string"><span class="koboSpan" id="kobo.218.1">'Knowledge/1.0 ([USER AGENT EMAIL)'</span></span><span class="koboSpan" id="kobo.219.1">
)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.220.1">In this case, English was defined with </span><code class="inlineCode"><span class="koboSpan" id="kobo.221.1">'en'</span></code><span class="koboSpan" id="kobo.222.1">, and you must enter the user agent information, such as an email address, for example. </span><span class="koboSpan" id="kobo.222.2">We can now define the main topic and filename associated with the Wikipedia page of interest:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.223.1">topic=</span><span class="hljs-string"><span class="koboSpan" id="kobo.224.1">"Marketing"</span></span>     <span class="hljs-comment"><span class="koboSpan" id="kobo.225.1"># topic</span></span><span class="koboSpan" id="kobo.226.1">
filename=</span><span class="hljs-string"><span class="koboSpan" id="kobo.227.1">"Marketing"</span></span>  <span class="hljs-comment"><span class="koboSpan" id="kobo.228.1"># filename for saving the outputs</span></span><span class="koboSpan" id="kobo.229.1">
maxl=</span><span class="hljs-number"><span class="koboSpan" id="kobo.230.1">100</span></span>
</code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.231.1">The three parameters defined are:</span></p>
    <ul>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.232.1">topic</span></code><span class="koboSpan" id="kobo.233.1">: The topic of the retrieval process</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.234.1">filename</span></code><span class="koboSpan" id="kobo.235.1">: The name of the topic that will customize the files we produce, which can be different from the topic</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.236.1">maxl</span></code><span class="koboSpan" id="kobo.237.1">: The maximum</span><a id="_idIndexMarker458"/><span class="koboSpan" id="kobo.238.1"> number of URL links of the pages we will retrieve</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.239.1">We now need to </span><a id="_idIndexMarker459"/><span class="koboSpan" id="kobo.240.1">retrieve the summary of the specified Wikipedia page, check if the page exists, and print its summary:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.241.1">import</span></span><span class="koboSpan" id="kobo.242.1"> textwrap </span><span class="hljs-comment"><span class="koboSpan" id="kobo.243.1"># to wrap the text and display it in paragraphs</span></span><span class="koboSpan" id="kobo.244.1">
page=wiki.page(topic)
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.245.1">if</span></span><span class="koboSpan" id="kobo.246.1"> page.exists()==</span><span class="hljs-literal"><span class="koboSpan" id="kobo.247.1">True</span></span><span class="koboSpan" id="kobo.248.1">:
  </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.249.1">print</span></span><span class="koboSpan" id="kobo.250.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.251.1">"Page - Exists: %s"</span></span><span class="koboSpan" id="kobo.252.1"> % page.exists())
  summary=page.summary
  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.253.1"># number of tokens)</span></span><span class="koboSpan" id="kobo.254.1">
  nbt=nb_tokens(summary)
  </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.255.1">print</span></span><span class="koboSpan" id="kobo.256.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.257.1">"Number of tokens: "</span></span><span class="koboSpan" id="kobo.258.1">,nbt)
  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.259.1"># Use textwrap to wrap the summary text to a specified width, e.g., 70 characters</span></span><span class="koboSpan" id="kobo.260.1">
  wrapped_text = textwrap.fill(summary, width=</span><span class="hljs-number"><span class="koboSpan" id="kobo.261.1">60</span></span><span class="koboSpan" id="kobo.262.1">)
  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.263.1"># Print the wrapped summary text</span></span>
  <span class="hljs-built_in"><span class="koboSpan" id="kobo.264.1">print</span></span><span class="koboSpan" id="kobo.265.1">(wrapped_text)
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.266.1">else</span></span><span class="koboSpan" id="kobo.267.1">:
  </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.268.1">print</span></span><span class="koboSpan" id="kobo.269.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.270.1">"Page does not exist"</span></span><span class="koboSpan" id="kobo.271.1">)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.272.1">The output provides the control information requested:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.273.1">Page - Exists: True
Number of tokens:  229
Marketing is the act of satisfying and retaining customers.
</span><span class="koboSpan" id="kobo.273.2">It is one of the primary components of business management
and commerce. </span><span class="koboSpan" id="kobo.273.3">Marketing is typically conducted by the seller, typically a retailer or manufacturer…
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.274.1">The information provided shows if we are on the right track or not before running a full search on the main page of the topic:</span></p>
    <ul>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.275.1">Page - Exists: True</span></code><span class="koboSpan" id="kobo.276.1"> confirms that the page exists. </span><span class="koboSpan" id="kobo.276.2">If not, the </span><code class="inlineCode"><span class="koboSpan" id="kobo.277.1">print("Page does not exist")</span></code><span class="koboSpan" id="kobo.278.1"> message will be displayed.</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.279.1">Number of tokens: 229</span></code><span class="koboSpan" id="kobo.280.1"> provides us with insights into the size of the content we are retrieving for project management assessments.</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.281.1">The output of </span><code class="inlineCode"><span class="koboSpan" id="kobo.282.1">summary=page.summary</span></code><span class="koboSpan" id="kobo.283.1"> displays a summary of the page.</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.284.1">In this case, the page exists, fits </span><a id="_idIndexMarker460"/><span class="koboSpan" id="kobo.285.1">our topic, and the summary makes sense. </span><span class="koboSpan" id="kobo.285.2">Before we continue, we </span><a id="_idIndexMarker461"/><span class="koboSpan" id="kobo.286.1">check if we are working on the right page to be sure:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-built_in"><span class="koboSpan" id="kobo.287.1">print</span></span><span class="koboSpan" id="kobo.288.1">(page.fullurl)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.289.1">The output is correct:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.290.1">https://en.wikipedia.org/wiki/Marketing
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.291.1">We are now ready to retrieve the URLs, links, and summaries on the target page:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.292.1"># prompt: read the program up to this cell. </span><span class="koboSpan" id="kobo.292.2">Then retrieve all the links for this page: print the link and a summary of each link.</span></span>
<span class="hljs-comment"><span class="koboSpan" id="kobo.293.1"># Get all the links on the page</span></span><span class="koboSpan" id="kobo.294.1">
links = page.links
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.295.1"># Print the link and a summary of each link</span></span><span class="koboSpan" id="kobo.296.1">
urls = []
counter=</span><span class="hljs-number"><span class="koboSpan" id="kobo.297.1">0</span></span>
<span class="hljs-keyword"><span class="koboSpan" id="kobo.298.1">for</span></span><span class="koboSpan" id="kobo.299.1"> link </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.300.1">in</span></span><span class="koboSpan" id="kobo.301.1"> links:
  </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.302.1">try</span></span><span class="koboSpan" id="kobo.303.1">:
    counter+=</span><span class="hljs-number"><span class="koboSpan" id="kobo.304.1">1</span></span>
    <span class="hljs-built_in"><span class="koboSpan" id="kobo.305.1">print</span></span><span class="koboSpan" id="kobo.306.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.307.1">f"Link </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.308.1">{counter}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.309.1">: </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.310.1">{link}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.311.1">"</span></span><span class="koboSpan" id="kobo.312.1">)
    summary = wiki.page(link).summary
    </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.313.1">print</span></span><span class="koboSpan" id="kobo.314.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.315.1">f"Link: </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.316.1">{link}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.317.1">"</span></span><span class="koboSpan" id="kobo.318.1">)
    </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.319.1">print</span></span><span class="koboSpan" id="kobo.320.1">(wiki.page(link).fullurl)
    urls.append(wiki.page(link).fullurl)
    </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.321.1">print</span></span><span class="koboSpan" id="kobo.322.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.323.1">f"Summary: </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.324.1">{summary}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.325.1">"</span></span><span class="koboSpan" id="kobo.326.1">)
    </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.327.1">if</span></span><span class="koboSpan" id="kobo.328.1"> counter&gt;=maxl:
      </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.329.1">break</span></span>
  <span class="hljs-keyword"><span class="koboSpan" id="kobo.330.1">except</span></span><span class="koboSpan" id="kobo.331.1"> page.exists()==</span><span class="hljs-literal"><span class="koboSpan" id="kobo.332.1">False</span></span><span class="koboSpan" id="kobo.333.1">:
    </span><span class="hljs-comment"><span class="koboSpan" id="kobo.334.1"># Ignore pages that don't exist</span></span>
    <span class="hljs-keyword"><span class="koboSpan" id="kobo.335.1">pass</span></span>
<span class="hljs-built_in"><span class="koboSpan" id="kobo.336.1">print</span></span><span class="koboSpan" id="kobo.337.1">(counter)
</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.338.1">print</span></span><span class="koboSpan" id="kobo.339.1">(urls)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.340.1">The function is limited to </span><code class="inlineCode"><span class="koboSpan" id="kobo.341.1">maxl</span></code><span class="koboSpan" id="kobo.342.1">, defined at the beginning of the program. </span><span class="koboSpan" id="kobo.342.2">The function will retrieve URL links up to </span><code class="inlineCode"><span class="koboSpan" id="kobo.343.1">maxl</span></code><span class="koboSpan" id="kobo.344.1"> links, or less if the page contains fewer links than the maximum requested. </span><span class="koboSpan" id="kobo.344.2">We then check the output before moving on to the next step and generating files:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.345.1">Link 1: 24-hour news cycle
Link: 24-hour news cycle
https://en.wikipedia.org/wiki/24-hour_news_cycle
Summary: The 24-hour news cycle (or 24/7 news cycle) is 24-hour investigation and reporting of news, concomitant with fast-paced lifestyles…
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.346.1">We observe that we have</span><a id="_idIndexMarker462"/><span class="koboSpan" id="kobo.347.1"> the information we need, and the summaries are acceptable:</span></p>
    <ul>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.348.1">Link 1</span></code><span class="koboSpan" id="kobo.349.1">: The link counter</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.350.1">Link</span></code><span class="koboSpan" id="kobo.351.1">: The actual link to the page retrieved from the main topic page</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.352.1">Summary</span></code><span class="koboSpan" id="kobo.353.1">: A summary of the link to the page</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.354.1">The next step is to </span><a id="_idIndexMarker463"/><span class="koboSpan" id="kobo.355.1">apply the function we just built to generate the text file containing citations for the links retrieved from a Wikipedia page and their URLs:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.356.1">from</span></span><span class="koboSpan" id="kobo.357.1"> datetime </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.358.1">import</span></span><span class="koboSpan" id="kobo.359.1"> datetime
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.360.1"># Get all the links on the page</span></span><span class="koboSpan" id="kobo.361.1">
links = page.links
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.362.1"># Prepare a file to store the outputs</span></span><span class="koboSpan" id="kobo.363.1">
fname = filename+</span><span class="hljs-string"><span class="koboSpan" id="kobo.364.1">"_citations.txt"</span></span>
<span class="hljs-keyword"><span class="koboSpan" id="kobo.365.1">with</span></span> <span class="hljs-built_in"><span class="koboSpan" id="kobo.366.1">open</span></span><span class="koboSpan" id="kobo.367.1">(fname, </span><span class="hljs-string"><span class="koboSpan" id="kobo.368.1">"w"</span></span><span class="koboSpan" id="kobo.369.1">) </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.370.1">as</span></span><span class="koboSpan" id="kobo.371.1"> file:
    </span><span class="hljs-comment"><span class="koboSpan" id="kobo.372.1"># Write the citation header</span></span><span class="koboSpan" id="kobo.373.1">
    file.write(</span><span class="hljs-string"><span class="koboSpan" id="kobo.374.1">f"Citation. </span><span class="koboSpan" id="kobo.374.2">In Wikipedia, The Free Encyclopedia. </span><span class="koboSpan" id="kobo.374.3">Pages retrieved from the following Wikipedia contributors on </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.375.1">{datetime.now()}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.376.1">\n"</span></span><span class="koboSpan" id="kobo.377.1">)
    file.write(</span><span class="hljs-string"><span class="koboSpan" id="kobo.378.1">"Root page: "</span></span><span class="koboSpan" id="kobo.379.1"> + page.fullurl + </span><span class="hljs-string"><span class="koboSpan" id="kobo.380.1">"\n"</span></span><span class="koboSpan" id="kobo.381.1">)
    counter = </span><span class="hljs-number"><span class="koboSpan" id="kobo.382.1">0</span></span><span class="koboSpan" id="kobo.383.1">
    urls = []…
</span></code></pre>
    <p class="normal"><code class="inlineCode"><span class="koboSpan" id="kobo.384.1">urls = []</span></code><span class="koboSpan" id="kobo.385.1"> will be appended to have the full list of URLs we need for the final step. </span><span class="koboSpan" id="kobo.385.2">The output is a file containing the name of the topic, </span><code class="inlineCode"><span class="koboSpan" id="kobo.386.1">datetime</span></code><span class="koboSpan" id="kobo.387.1">, and the citations beginning with the citation text:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.388.1">Citation. </span><span class="koboSpan" id="kobo.388.2">In Wikipedia, The Free Encyclopedia. </span><span class="koboSpan" id="kobo.388.3">Pages retrieved from the following Wikipedia contributors on {datetime.now()}\n")
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.389.1">The output, in this case, is a file named </span><code class="inlineCode"><span class="koboSpan" id="kobo.390.1">Marketing_citations.txt</span></code><span class="koboSpan" id="kobo.391.1">. </span><span class="koboSpan" id="kobo.391.2">The file was downloaded and uploaded to the </span><code class="inlineCode"><span class="koboSpan" id="kobo.392.1">/citations</span></code><span class="koboSpan" id="kobo.393.1"> directory of this chapter’s directory in the GitHub repository.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.394.1">With that, the citations page has been generated, displayed in this notebook, and also saved in the GitHub repository to respect Wikipedia’s citation terms. </span><span class="koboSpan" id="kobo.394.2">The final step is to generate the file</span><a id="_idIndexMarker464"/><span class="koboSpan" id="kobo.395.1"> containing the list of URLs we will use to fetch the content of the pages we</span><a id="_idIndexMarker465"/><span class="koboSpan" id="kobo.396.1"> need. </span><span class="koboSpan" id="kobo.396.2">We first display the URLs:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.397.1">urls
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.398.1">The output confirms we have the URLs required:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.399.1">['https://en.wikipedia.org/wiki/Marketing',
 'https://en.wikipedia.org/wiki/24-hour_news_cycle',
 'https://en.wikipedia.org/wiki/Account-based_marketing',
…
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.400.1">The URLs are written in a file with the topic as a prefix:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.401.1"># Write URLs to a file</span></span><span class="koboSpan" id="kobo.402.1">
ufname = filename+</span><span class="hljs-string"><span class="koboSpan" id="kobo.403.1">"_urls.txt"</span></span>
<span class="hljs-keyword"><span class="koboSpan" id="kobo.404.1">with</span></span> <span class="hljs-built_in"><span class="koboSpan" id="kobo.405.1">open</span></span><span class="koboSpan" id="kobo.406.1">(ufname, </span><span class="hljs-string"><span class="koboSpan" id="kobo.407.1">'w'</span></span><span class="koboSpan" id="kobo.408.1">) </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.409.1">as</span></span><span class="koboSpan" id="kobo.410.1"> file:
    </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.411.1">for</span></span><span class="koboSpan" id="kobo.412.1"> url </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.413.1">in</span></span><span class="koboSpan" id="kobo.414.1"> urls:
        file.write(url + </span><span class="hljs-string"><span class="koboSpan" id="kobo.415.1">'\n'</span></span><span class="koboSpan" id="kobo.416.1">)
</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.417.1">print</span></span><span class="koboSpan" id="kobo.418.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.419.1">"URLs have been written to urls.txt"</span></span><span class="koboSpan" id="kobo.420.1">)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.421.1">In this case, the output is a file named </span><code class="inlineCode"><span class="koboSpan" id="kobo.422.1">Marketing_urls.txt</span></code><span class="koboSpan" id="kobo.423.1"> that contains the URLs of the pages we need to fetch. </span><span class="koboSpan" id="kobo.423.2">The file was downloaded and uploaded to the </span><code class="inlineCode"><span class="koboSpan" id="kobo.424.1">/citations</span></code><span class="koboSpan" id="kobo.425.1"> directory of the chapter’s directory in the GitHub repository.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.426.1">We are now ready to prepare the data for upsertion.</span></p>
    <h2 id="_idParaDest-188" class="heading-2"><span class="koboSpan" id="kobo.427.1">Preparing the data for upsertion</span></h2>
    <p class="normal"><span class="koboSpan" id="kobo.428.1">The URLs provided by the Wikipedia API in the </span><code class="inlineCode"><span class="koboSpan" id="kobo.429.1">Wikipedia_API.ipynb</span></code><span class="koboSpan" id="kobo.430.1"> notebook will be processed in the </span><code class="inlineCode"><span class="koboSpan" id="kobo.431.1">Knowledge_Graph_ Deep_Lake_LlamaIndex_OpenAI_RAG.ipynb</span></code><span class="koboSpan" id="kobo.432.1"> notebook you can find in the</span><a id="_idIndexMarker466"/><span class="koboSpan" id="kobo.433.1"> GitHub directory of the chapter. </span><span class="koboSpan" id="kobo.433.2">The </span><em class="italic"><span class="koboSpan" id="kobo.434.1">Installing the environment</span></em><span class="koboSpan" id="kobo.435.1"> section of this notebook is almost the same section as its equivalent section in </span><em class="chapterRef"><span class="koboSpan" id="kobo.436.1">Chapter 2</span></em><span class="koboSpan" id="kobo.437.1">, </span><em class="italic"><span class="koboSpan" id="kobo.438.1">RAG Embedding Vector Stores with Deep Lake and OpenAI</span></em><span class="koboSpan" id="kobo.439.1">, and </span><em class="chapterRef"><span class="koboSpan" id="kobo.440.1">Chapter 3</span></em><span class="koboSpan" id="kobo.441.1">, </span><em class="italic"><span class="koboSpan" id="kobo.442.1">Building Index-Based RAG with LlamaIndex, Deep Lake, and OpenAI</span></em><span class="koboSpan" id="kobo.443.1">. </span><span class="koboSpan" id="kobo.443.2">In this chapter, however, the list of URLs was generated by the </span><code class="inlineCode"><span class="koboSpan" id="kobo.444.1">Wikipedia_API.ipynb</span></code><span class="koboSpan" id="kobo.445.1"> notebook, and we will retrieve it.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.446.1">First, go to the </span><em class="italic"><span class="koboSpan" id="kobo.447.1">Scenario</span></em><span class="koboSpan" id="kobo.448.1"> section of the notebook to define the strategy of the workflow:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.449.1">#File name for file management</span></span><span class="koboSpan" id="kobo.450.1">
graph_name=</span><span class="hljs-string"><span class="koboSpan" id="kobo.451.1">"Marketing"</span></span>
<span class="hljs-comment"><span class="koboSpan" id="kobo.452.1"># Path for vector store and dataset</span></span><span class="koboSpan" id="kobo.453.1">
db=</span><span class="hljs-string"><span class="koboSpan" id="kobo.454.1">"hub://denis76/marketing01"</span></span><span class="koboSpan" id="kobo.455.1">
vector_store_path = db
dataset_path = db
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.456.1">#if True upserts data; if False, passes upserting and goes to connection</span></span><span class="koboSpan" id="kobo.457.1">
pop_vs=</span><span class="hljs-literal"><span class="koboSpan" id="kobo.458.1">True</span></span>
<span class="hljs-comment"><span class="koboSpan" id="kobo.459.1"># if pop_vs==True, overwrite=True will overwrite dataset, False will append it:</span></span><span class="koboSpan" id="kobo.460.1">
ow=</span><span class="hljs-literal"><span class="koboSpan" id="kobo.461.1">True</span></span>
</code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.462.1">The parameters will determine the behavior of the three pipelines in the notebook:</span></p>
    <ul>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.463.1">graph_name="Marketing"</span></code><span class="koboSpan" id="kobo.464.1">: The prefix (topic) of the files we will read and write.</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.465.1">db="hub://denis76/marketing01"</span></code><span class="koboSpan" id="kobo.466.1">: The name of the Deep Lake vector store. </span><span class="koboSpan" id="kobo.466.2">You can choose the name of the dataset you wish.</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.467.1">vector_store_path = db</span></code><span class="koboSpan" id="kobo.468.1">: The path to the vector store.</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.469.1">dataset_path = db</span></code><span class="koboSpan" id="kobo.470.1">: The path to the dataset of the vector store.</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.471.1">pop_vs=True</span></code><span class="koboSpan" id="kobo.472.1">: Activates data insertion if </span><code class="inlineCode"><span class="koboSpan" id="kobo.473.1">True</span></code><span class="koboSpan" id="kobo.474.1"> and deactivates it if </span><code class="inlineCode"><span class="koboSpan" id="kobo.475.1">False</span></code><span class="koboSpan" id="kobo.476.1">.</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.477.1">ow=True</span></code><span class="koboSpan" id="kobo.478.1">: Overwrites</span><a id="_idIndexMarker467"/><span class="koboSpan" id="kobo.479.1"> the existing dataset if </span><code class="inlineCode"><span class="koboSpan" id="kobo.480.1">True</span></code><span class="koboSpan" id="kobo.481.1"> and appends it if </span><code class="inlineCode"><span class="koboSpan" id="kobo.482.1">False</span></code><span class="koboSpan" id="kobo.483.1">.</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.484.1">Then, we can launch the </span><em class="italic"><span class="koboSpan" id="kobo.485.1">Pipeline 1: Collecting and preparing the documents</span></em><span class="koboSpan" id="kobo.486.1"> section of the notebook. </span><span class="koboSpan" id="kobo.486.2">The program will download the URL list generated in the previous section of this chapter:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.487.1"># Define your variables</span></span>
<span class="hljs-keyword"><span class="koboSpan" id="kobo.488.1">if</span></span><span class="koboSpan" id="kobo.489.1"> pop_vs==</span><span class="hljs-literal"><span class="koboSpan" id="kobo.490.1">True</span></span><span class="koboSpan" id="kobo.491.1">:
  directory = </span><span class="hljs-string"><span class="koboSpan" id="kobo.492.1">"</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.493.1">Chapter07/citations"</span></span><span class="koboSpan" id="kobo.494.1">
  file_name = graph_name+</span><span class="hljs-string"><span class="koboSpan" id="kobo.495.1">"_urls.txt"</span></span><span class="koboSpan" id="kobo.496.1">
  download(directory,file_name)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.497.1">It will then read the file and store the URLs in a list named </span><code class="inlineCode"><span class="koboSpan" id="kobo.498.1">urls</span></code><span class="koboSpan" id="kobo.499.1">. </span><span class="koboSpan" id="kobo.499.2">The rest of the code in the </span><em class="italic"><span class="koboSpan" id="kobo.500.1">Pipeline 1: Collecting and preparing the documents</span></em><span class="koboSpan" id="kobo.501.1"> section of this notebook follows the same process as the </span><code class="inlineCode"><span class="koboSpan" id="kobo.502.1">Deep_Lake_LlamaIndex_OpenAI_RAG.ipynb</span></code><span class="koboSpan" id="kobo.503.1"> notebook from </span><em class="italic"><span class="koboSpan" id="kobo.504.1">Chapter 3</span></em><span class="koboSpan" id="kobo.505.1">. </span><span class="koboSpan" id="kobo.505.2">In </span><em class="italic"><span class="koboSpan" id="kobo.506.1">Chapter 3</span></em><span class="koboSpan" id="kobo.507.1">, the URLs of the web pages were entered manually in a list.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.508.1">The code will fetch the content in the list of URLs. </span><span class="koboSpan" id="kobo.508.2">The program then cleans and prepares the data to populate</span><a id="_idIndexMarker468"/><span class="koboSpan" id="kobo.509.1"> the Deep Lake vector store.</span></p>
    <h1 id="_idParaDest-189" class="heading-1"><span class="koboSpan" id="kobo.510.1">Pipeline 2: Creating and populating the Deep Lake vector store</span></h1>
    <p class="normal"><span class="koboSpan" id="kobo.511.1">The pipeline in this section of </span><code class="inlineCode"><span class="koboSpan" id="kobo.512.1">Deep_Lake_LlamaIndex_OpenAI_RAG.ipynb</span></code><span class="koboSpan" id="kobo.513.1"> was built with the code of </span><em class="italic"><span class="koboSpan" id="kobo.514.1">Pipeline 2</span></em><span class="koboSpan" id="kobo.515.1"> from </span><em class="italic"><span class="koboSpan" id="kobo.516.1">Chapter 3</span></em><span class="koboSpan" id="kobo.517.1">. </span><span class="koboSpan" id="kobo.517.2">We can see that by creating pipelines as components, we can rapidly repurpose and adapt them to other applications. </span><span class="koboSpan" id="kobo.517.3">Also, Activeloop Deep Lake </span><a id="_idIndexMarker469"/><span class="koboSpan" id="kobo.518.1">possesses in-built default chunking, embedding, and </span><a id="_idIndexMarker470"/><span class="koboSpan" id="kobo.519.1">upserting functions, making it seamless to integrate various types of unstructured data, as in the case of the Wikipedia documents we are upserting.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.520.1">The output of the </span><code class="inlineCode"><span class="koboSpan" id="kobo.521.1">display_record(record_number)</span></code><span class="koboSpan" id="kobo.522.1"> function shows how seamless the process is. </span><span class="koboSpan" id="kobo.522.2">The output displays the ID and metadata such as the file information, the data collected, the text, and the embedded vector:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.523.1">ID:
['a61734be-fe23-421e-9a8b-db6593c48e08']
Metadata:
file_path: /content/data/24-hour_news_cycle.txt
file_name: 24-hour_news_cycle.txt
file_type: text/plain
file_size: 2763
creation_date: 2024-07-05
last_modified_date: 2024-07-05
…
Text:
['24hour investigation and reporting of news concomitant with fastpaced lifestyles This article is about the fastpaced cycle of news media in technologically advanced societies.
</span><span class="koboSpan" id="kobo.523.2">Embedding:
[-0.00040736704249866307, 0.009565318934619427, 0.015906672924757004, -0.009085721336305141, …]
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.524.1">And with that, we have successfully repurposed the </span><em class="italic"><span class="koboSpan" id="kobo.525.1">Pipeline 2</span></em><span class="koboSpan" id="kobo.526.1"> component of </span><em class="italic"><span class="koboSpan" id="kobo.527.1">Chapter 3</span></em><span class="koboSpan" id="kobo.528.1"> and can now move on and build the graph knowledge index.</span></p>
    <h1 id="_idParaDest-190" class="heading-1"><span class="koboSpan" id="kobo.529.1">Pipeline 3: Knowledge graph index-based RAG</span></h1>
    <p class="normal"><span class="koboSpan" id="kobo.530.1">It’s time to create a knowledge</span><a id="_idIndexMarker471"/><span class="koboSpan" id="kobo.531.1"> graph index-based RAG pipeline and interact with it. </span><span class="koboSpan" id="kobo.531.2">As illustrated in the following figure, we have a lot of work to do:</span></p>
    <figure class="mediaobject"><span class="koboSpan" id="kobo.532.1"><img src="../Images/B31169_07_05.png" alt="A diagram of a graph  Description automatically generated"/></span></figure>
    <p class="packt_figref"><span class="koboSpan" id="kobo.533.1">Figure 7.5: Building knowledge graph-index RAG from scratch</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.534.1">In this section, we will:</span></p>
    <ul>
      <li class="bulletList"><span class="koboSpan" id="kobo.535.1">Generate the knowledge graph index</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.536.1">Display the graph</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.537.1">Define the user prompt</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.538.1">Define the hyperparameters of LlamaIndex’s in-built LLM model</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.539.1">Install the similarity score packages</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.540.1">Define the similarity score functions</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.541.1">Run a sample similarity comparison between the similarity functions</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.542.1">Re-rank the output vectors of an LLM response</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.543.1">Run evaluation samples and apply metrics and human feedback scores</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.544.1">Run metric calculations and display them</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.545.1">Let’s go through these steps and begin by generating the knowledge graph index.</span></p>
    <h2 id="_idParaDest-191" class="heading-2"><span class="koboSpan" id="kobo.546.1">Generating the knowledge graph index</span></h2>
    <p class="normal"><span class="koboSpan" id="kobo.547.1">We will create a knowledge graph index from a set of documents using the </span><code class="inlineCode"><span class="koboSpan" id="kobo.548.1">KnowledgeGraphIndex</span></code><span class="koboSpan" id="kobo.549.1"> class from the </span><code class="inlineCode"><span class="koboSpan" id="kobo.550.1">llama_index.core</span></code><span class="koboSpan" id="kobo.551.1"> module. </span><span class="koboSpan" id="kobo.551.2">We will also time the index creation process to evaluate performance.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.552.1">The function begins </span><a id="_idIndexMarker472"/><span class="koboSpan" id="kobo.553.1">by recording the start time with </span><code class="inlineCode"><span class="koboSpan" id="kobo.554.1">time.time()</span></code><span class="koboSpan" id="kobo.555.1">. </span><span class="koboSpan" id="kobo.555.2">In this case, measuring the time is important because it takes quite some time to create the index:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.556.1">from</span></span><span class="koboSpan" id="kobo.557.1"> llama_index.core </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.558.1">import</span></span><span class="koboSpan" id="kobo.559.1"> KnowledgeGraphIndex
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.560.1">import</span></span><span class="koboSpan" id="kobo.561.1"> time
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.562.1"># Start the timer</span></span><span class="koboSpan" id="kobo.563.1">
start_time = time.time()
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.564.1">We now create a </span><code class="inlineCode"><span class="koboSpan" id="kobo.565.1">KnowledgeGraphIndex</span></code><span class="koboSpan" id="kobo.566.1"> with embeddings using the </span><code class="inlineCode"><span class="koboSpan" id="kobo.567.1">from_documents</span></code><span class="koboSpan" id="kobo.568.1"> method. </span><span class="koboSpan" id="kobo.568.2">The function uses the following parameters:</span></p>
    <ul>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.569.1">documents</span></code><span class="koboSpan" id="kobo.570.1"> is the set of documents to index</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.571.1">max_triplets_per_chunk</span></code><span class="koboSpan" id="kobo.572.1"> is set to 2, limiting the number of triplets per chunk to optimize memory usage and processing time</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.573.1">include_embeddings</span></code><span class="koboSpan" id="kobo.574.1"> is set to </span><code class="inlineCode"><span class="koboSpan" id="kobo.575.1">True</span></code><span class="koboSpan" id="kobo.576.1">, indicating that embeddings should be included</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.577.1">The graph index is thus created in a few lines of code:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.578.1">#graph index with embeddings</span></span><span class="koboSpan" id="kobo.579.1">
graph_index = KnowledgeGraphIndex.from_documents(
    documents,
    max_triplets_per_chunk=</span><span class="hljs-number"><span class="koboSpan" id="kobo.580.1">2</span></span><span class="koboSpan" id="kobo.581.1">,
    include_embeddings=</span><span class="hljs-literal"><span class="koboSpan" id="kobo.582.1">True</span></span><span class="koboSpan" id="kobo.583.1">,
)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.584.1">The timer is stopped and the creation time is measured:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.585.1"># Stop the timer</span></span><span class="koboSpan" id="kobo.586.1">
end_time = time.time()
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.587.1"># Calculate and print the execution time</span></span><span class="koboSpan" id="kobo.588.1">
elapsed_time = end_time - start_time
</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.589.1">print</span></span><span class="koboSpan" id="kobo.590.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.591.1">f"Index creation time: </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.592.1">{elapsed_time:</span></span><span class="hljs-number"><span class="koboSpan" id="kobo.593.1">.4</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.594.1">f}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.595.1"> seconds"</span></span><span class="koboSpan" id="kobo.596.1">)
</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.597.1">print</span></span><span class="koboSpan" id="kobo.598.1">(</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.599.1">type</span></span><span class="koboSpan" id="kobo.600.1">(graph_index))
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.601.1">The output displays the time:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.602.1">Index creation time: 371.9844 seconds
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.603.1">The graph type is displayed:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-built_in"><span class="koboSpan" id="kobo.604.1">print</span></span><span class="koboSpan" id="kobo.605.1">(</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.606.1">type</span></span><span class="koboSpan" id="kobo.607.1">(graph_index))
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.608.1">The output confirms the</span><a id="_idIndexMarker473"/><span class="koboSpan" id="kobo.609.1"> knowledge graph index class:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.610.1">&lt;class 'llama_index.core.indices.knowledge_graph.base.KnowledgeGraphIndex'&gt;
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.611.1">We will now set up a query engine for our knowledge graph index and configure it to manage similarity, response</span><a id="_idIndexMarker474"/><span class="koboSpan" id="kobo.612.1"> temperature, and output length parameters:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.613.1">#similarity_top_k</span></span><span class="koboSpan" id="kobo.614.1">
k=</span><span class="hljs-number"><span class="koboSpan" id="kobo.615.1">3</span></span>
<span class="hljs-comment"><span class="koboSpan" id="kobo.616.1">#temperature</span></span><span class="koboSpan" id="kobo.617.1">
temp=</span><span class="hljs-number"><span class="koboSpan" id="kobo.618.1">0.1</span></span>
<span class="hljs-comment"><span class="koboSpan" id="kobo.619.1">#num_output</span></span><span class="koboSpan" id="kobo.620.1">
mt=</span><span class="hljs-number"><span class="koboSpan" id="kobo.621.1">1024</span></span><span class="koboSpan" id="kobo.622.1">
graph_query_engine = graph_index.as_query_engine(similarity_top_k=k, temperature=temp, num_output=mt)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.623.1">The parameters will determine the behavior of the query engine:</span></p>
    <ul>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.624.1">k=3</span></code><span class="koboSpan" id="kobo.625.1"> sets the number of top similar results to take into account.</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.626.1">temp=0.1</span></code><span class="koboSpan" id="kobo.627.1"> sets the temperature parameter, controlling the randomness of the query engine’s response generation. </span><span class="koboSpan" id="kobo.627.2">The lower it is, the more precise it is; the higher it is, the more creative it is.</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.628.1">mt=1024</span></code><span class="koboSpan" id="kobo.629.1"> sets the maximum number of tokens for the output, defining the length of the generated responses.</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.630.1">The query engine is then created with the parameters we defined:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.631.1">graph_query_engine = graph_index.as_query_engine(similarity_top_k=k, temperature=temp, num_output=mt)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.632.1">The graph index and query engine are ready. </span><span class="koboSpan" id="kobo.632.2">Let’s display the graph.</span></p>
    <h2 id="_idParaDest-192" class="heading-2"><span class="koboSpan" id="kobo.633.1">Displaying the graph</span></h2>
    <p class="normal"><span class="koboSpan" id="kobo.634.1">We will create a</span><a id="_idIndexMarker475"/><span class="koboSpan" id="kobo.635.1"> graph instance, </span><code class="inlineCode"><span class="koboSpan" id="kobo.636.1">g</span></code><span class="koboSpan" id="kobo.637.1">, with </span><code class="inlineCode"><span class="koboSpan" id="kobo.638.1">pyvis.network</span></code><span class="koboSpan" id="kobo.639.1">, a Python library used for creating interactive network visualizations. </span><span class="koboSpan" id="kobo.639.2">The displayed parameters are similar to the ones we defined in the </span><em class="italic"><span class="koboSpan" id="kobo.640.1">Building graphs from trees</span></em><span class="koboSpan" id="kobo.641.1"> section of this chapter:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.642.1">## create graph</span></span>
<span class="hljs-keyword"><span class="koboSpan" id="kobo.643.1">from</span></span><span class="koboSpan" id="kobo.644.1"> pyvis.network </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.645.1">import</span></span><span class="koboSpan" id="kobo.646.1"> Network
g = graph_index.get_networkx_graph()
net = Network(notebook=</span><span class="hljs-literal"><span class="koboSpan" id="kobo.647.1">True</span></span><span class="koboSpan" id="kobo.648.1">, cdn_resources=</span><span class="hljs-string"><span class="koboSpan" id="kobo.649.1">"in_line"</span></span><span class="koboSpan" id="kobo.650.1">, directed=</span><span class="hljs-literal"><span class="koboSpan" id="kobo.651.1">True</span></span><span class="koboSpan" id="kobo.652.1">)
net.from_nx(g)
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.653.1"># Set node and edge properties: colors and sizes</span></span>
<span class="hljs-keyword"><span class="koboSpan" id="kobo.654.1">for</span></span><span class="koboSpan" id="kobo.655.1"> node </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.656.1">in</span></span><span class="koboSpan" id="kobo.657.1"> net.nodes:
    node[</span><span class="hljs-string"><span class="koboSpan" id="kobo.658.1">'color'</span></span><span class="koboSpan" id="kobo.659.1">] = </span><span class="hljs-string"><span class="koboSpan" id="kobo.660.1">'lightgray'</span></span><span class="koboSpan" id="kobo.661.1">
    node[</span><span class="hljs-string"><span class="koboSpan" id="kobo.662.1">'size'</span></span><span class="koboSpan" id="kobo.663.1">] = </span><span class="hljs-number"><span class="koboSpan" id="kobo.664.1">10</span></span>
<span class="hljs-keyword"><span class="koboSpan" id="kobo.665.1">for</span></span><span class="koboSpan" id="kobo.666.1"> edge </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.667.1">in</span></span><span class="koboSpan" id="kobo.668.1"> net.edges:
    edge[</span><span class="hljs-string"><span class="koboSpan" id="kobo.669.1">'color'</span></span><span class="koboSpan" id="kobo.670.1">] = </span><span class="hljs-string"><span class="koboSpan" id="kobo.671.1">'black'</span></span><span class="koboSpan" id="kobo.672.1">
    edge[</span><span class="hljs-string"><span class="koboSpan" id="kobo.673.1">'width'</span></span><span class="koboSpan" id="kobo.674.1">] = </span><span class="hljs-number"><span class="koboSpan" id="kobo.675.1">1</span></span>
</code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.676.1">A directed graph has been created, and now we will save it in an HTML file to display it for further use:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.677.1">fgraph=</span><span class="hljs-string"><span class="koboSpan" id="kobo.678.1">"Knowledge_graph_"</span></span><span class="koboSpan" id="kobo.679.1">+ graph_name + </span><span class="hljs-string"><span class="koboSpan" id="kobo.680.1">".html"</span></span><span class="koboSpan" id="kobo.681.1">
net.write_html(fgraph)
</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.682.1">print</span></span><span class="koboSpan" id="kobo.683.1">(fgraph)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.684.1">The </span><code class="inlineCode"><span class="koboSpan" id="kobo.685.1">graph_name</span></code><span class="koboSpan" id="kobo.686.1"> was defined at the beginning of the notebook, in the </span><em class="italic"><span class="koboSpan" id="kobo.687.1">Scenario</span></em><span class="koboSpan" id="kobo.688.1"> section. </span><span class="koboSpan" id="kobo.688.2">We will now display the graph in the notebook as an HTML file:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.689.1">from</span></span><span class="koboSpan" id="kobo.690.1"> IPython.display </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.691.1">import</span></span><span class="koboSpan" id="kobo.692.1"> HTML
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.693.1"># Load the HTML content from a file and display it</span></span>
<span class="hljs-keyword"><span class="koboSpan" id="kobo.694.1">with</span></span> <span class="hljs-built_in"><span class="koboSpan" id="kobo.695.1">open</span></span><span class="koboSpan" id="kobo.696.1">(fgraph, </span><span class="hljs-string"><span class="koboSpan" id="kobo.697.1">'r'</span></span><span class="koboSpan" id="kobo.698.1">) </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.699.1">as</span></span><span class="koboSpan" id="kobo.700.1"> file:
    html_content = file.read()
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.701.1"># Display the HTML in the notebook</span></span><span class="koboSpan" id="kobo.702.1">
display(HTML(html_content))
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.703.1">You can now download the file to display it in your browser to interact with it. </span><span class="koboSpan" id="kobo.703.2">You can also visualize it in the notebook, as shown in the following figure:</span></p>
    <figure class="mediaobject"><span class="koboSpan" id="kobo.704.1"><img src="../Images/B31169_07_06.png" alt="A diagram of marketing strategy  Description automatically generated"/></span></figure>
    <p class="packt_figref"><span class="koboSpan" id="kobo.705.1">Figure 7.6: The knowledge graph</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.706.1">We are all set to</span><a id="_idIndexMarker476"/><span class="koboSpan" id="kobo.707.1"> interact with the knowledge graph index.</span></p>
    <h2 id="_idParaDest-193" class="heading-2"><span class="koboSpan" id="kobo.708.1">Interacting with the knowledge graph index</span></h2>
    <p class="normal"><span class="koboSpan" id="kobo.709.1">Let’s now define the</span><a id="_idIndexMarker477"/><span class="koboSpan" id="kobo.710.1"> functionality we need to execute the query, as we have done in </span><em class="italic"><span class="koboSpan" id="kobo.711.1">Chapter 3</span></em><span class="koboSpan" id="kobo.712.1"> in the </span><em class="italic"><span class="koboSpan" id="kobo.713.1">Pipeline 3: Index-based RAG</span></em><span class="koboSpan" id="kobo.714.1"> section:</span></p>
    <ul>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.715.1">execute_query</span></code><span class="koboSpan" id="kobo.716.1"> is the function we created that will execute the query: </span><code class="inlineCode"><span class="koboSpan" id="kobo.717.1">response = graph_query_engine.query(user_input)</span></code><span class="koboSpan" id="kobo.718.1">. </span><span class="koboSpan" id="kobo.718.2">It also measures the time it takes.</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.719.1">user_query="What is the primary goal of marketing for the consumer market?"</span></code><span class="koboSpan" id="kobo.720.1">, which we will use to make the query.</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.721.1">response = execute_query(user_query)</span></code><span class="koboSpan" id="kobo.722.1">, which is encapsulated in the request code and displays the response.</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.723.1">The output provides the best vectors that we created with the Wikipedia data with the time measurement:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.724.1">Query execution time: 2.4789 seconds
The primary goal of marketing for the consumer market is to effectively target consumers, understand their behavior, preferences, and needs, and ultimately influence their purchasing decisions.
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.725.1">We will now install similarity </span><a id="_idIndexMarker478"/><span class="koboSpan" id="kobo.726.1">score packages and define the similarity calculation functions we need.</span></p>
    <h2 id="_idParaDest-194" class="heading-2"><span class="koboSpan" id="kobo.727.1">Installing the similarity score packages and defining the functions</span></h2>
    <p class="normal"><span class="koboSpan" id="kobo.728.1">We will first retrieve </span><a id="_idIndexMarker479"/><span class="koboSpan" id="kobo.729.1">the Hugging Face </span><a id="_idIndexMarker480"/><span class="koboSpan" id="kobo.730.1">token from the </span><strong class="screenText"><span class="koboSpan" id="kobo.731.1">Secrets</span></strong><span class="koboSpan" id="kobo.732.1"> tab on Google Colab, where it was stored in the settings of the notebook:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.733.1">from</span></span><span class="koboSpan" id="kobo.734.1"> google.colab </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.735.1">import</span></span><span class="koboSpan" id="kobo.736.1"> userdata
userdata.get(</span><span class="hljs-string"><span class="koboSpan" id="kobo.737.1">'HF_TOKEN'</span></span><span class="koboSpan" id="kobo.738.1">)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.739.1">In August 2024, the token is optional for Hugging Face’s </span><code class="inlineCode"><span class="koboSpan" id="kobo.740.1">sentence-transformers</span></code><span class="koboSpan" id="kobo.741.1">. </span><span class="koboSpan" id="kobo.741.2">You can ignore the message and comment the code. </span><span class="koboSpan" id="kobo.741.3">Next, we install </span><code class="inlineCode"><span class="koboSpan" id="kobo.742.1">sentence-transformers</span></code><span class="koboSpan" id="kobo.743.1">:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.744.1">!pip install sentence-transformers==</span><span class="hljs-number"><span class="koboSpan" id="kobo.745.1">3.0.1</span></span>
</code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.746.1">We then create a cosine similarity function with embeddings:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.747.1">from</span></span><span class="koboSpan" id="kobo.748.1"> sklearn.metrics.pairwise </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.749.1">import</span></span><span class="koboSpan" id="kobo.750.1"> cosine_similarity
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.751.1">from</span></span><span class="koboSpan" id="kobo.752.1"> sentence_transformers </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.753.1">import</span></span><span class="koboSpan" id="kobo.754.1"> SentenceTransformer
model = SentenceTransformer(</span><span class="hljs-string"><span class="koboSpan" id="kobo.755.1">'all-MiniLM-L6-v2'</span></span><span class="koboSpan" id="kobo.756.1">)
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.757.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.758.1">calculate_cosine_similarity_with_embeddings</span></span><span class="koboSpan" id="kobo.759.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.760.1">text1, text2</span></span><span class="koboSpan" id="kobo.761.1">):
    embeddings1 = model.encode(text1)
    embeddings2 = model.encode(text2)
    similarity = cosine_similarity([embeddings1], [embeddings2])
    </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.762.1">return</span></span><span class="koboSpan" id="kobo.763.1"> similarity[</span><span class="hljs-number"><span class="koboSpan" id="kobo.764.1">0</span></span><span class="koboSpan" id="kobo.765.1">][</span><span class="hljs-number"><span class="koboSpan" id="kobo.766.1">0</span></span><span class="koboSpan" id="kobo.767.1">]
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.768.1">We import the libraries we need:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.769.1">import</span></span><span class="koboSpan" id="kobo.770.1"> time
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.771.1">import</span></span><span class="koboSpan" id="kobo.772.1"> textwrap
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.773.1">import</span></span><span class="koboSpan" id="kobo.774.1"> sys
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.775.1">import</span></span><span class="koboSpan" id="kobo.776.1"> io
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.777.1">We have a similarity function and can use it for re-ranking.</span></p>
    <h2 id="_idParaDest-195" class="heading-2"><span class="koboSpan" id="kobo.778.1">Re-ranking</span></h2>
    <p class="normal"><span class="koboSpan" id="kobo.779.1">In this section, the </span><a id="_idIndexMarker481"/><span class="koboSpan" id="kobo.780.1">program re-ranks the response of a query by reordering the top results to select other, possibly better, ones:</span></p>
    <ul>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.781.1">user_query=" Which experts are often associated with marketing theory?"</span></code><span class="koboSpan" id="kobo.782.1"> represents the query we are making.</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.783.1">start_time = time.time()</span></code><span class="koboSpan" id="kobo.784.1"> records the start time for the query execution.</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.785.1">response = execute_query(user_query)</span></code><span class="koboSpan" id="kobo.786.1"> executes the query.</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.787.1">end_time = time.time()</span></code><span class="koboSpan" id="kobo.788.1"> stops the timer, and the query execution time is displayed.</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.789.1">for idx, node_with_score in enumerate(response.source_nodes)</span></code><span class="koboSpan" id="kobo.790.1"> iterates through the response to retrieve all the nodes in the response.</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.791.1">similarity_score3=calculate_cosine_similarity_with_embeddings(text1, text2)</span></code><span class="koboSpan" id="kobo.792.1"> calculates the similarity score between the user query and the text in the nodes retrieved from the response. </span><span class="koboSpan" id="kobo.792.2">All the comparisons are displayed.</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.793.1">best_score=similarity_score3</span></code><span class="koboSpan" id="kobo.794.1"> stores the best similarity score found.</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.795.1">print(textwrap.fill(str(best_text), 100))</span></code><span class="koboSpan" id="kobo.796.1"> displays the best re-ranked result.</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.797.1">The initial response for the </span><code class="inlineCode"><span class="koboSpan" id="kobo.798.1">user_query</span></code> <code class="inlineCode"><span class="koboSpan" id="kobo.799.1">"Which experts are often associated with marketing theory?"</span></code><span class="koboSpan" id="kobo.800.1"> was:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.801.1">Psychologists, cultural anthropologists, and market researchers are often associated with marketing
theory.
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.802.1">The response is acceptable. </span><span class="koboSpan" id="kobo.802.2">However, the re-ranked response goes deeper and mentions the names of marketing experts (highlighted in bold font):</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.803.1">Best Rank: 2
Best Score: 0.5217772722244263
[…In 1380 the German textile manufacturer </span><span class="code-highlight"><strong class="hljs-con-slc"><span class="koboSpan" id="kobo.804.1">Johann Fugger</span></strong><strong class="hljs-con-slc"><span class="koboSpan" id="kobo.805.1">Daniel Defoe</span></strong></span><span class="koboSpan" id="kobo.806.1">  travelled from Augsburg to Graben in order to gather information on the international textile industry… During this period   a
London merchant published information on trade and economic resources of England and Scotland…]
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.807.1">The re-ranked response is longer and contains raw document content instead of the summary provided by LlamaIndex’s LLM query engine. </span><span class="koboSpan" id="kobo.807.2">The original query engine response is better from an LLM perspective. </span><span class="koboSpan" id="kobo.807.3">However, it isn’t easy to estimate what an end-user will prefer. </span><span class="koboSpan" id="kobo.807.4">Some users like short answers, and some like long documents. </span><span class="koboSpan" id="kobo.807.5">We can imagine many other ways of re-ranking documents, such as modifying the prompt, adding documents, and deleting documents. </span><span class="koboSpan" id="kobo.807.6">We can even decide to fine-tune an LLM, as we will do in </span><em class="chapterRef"><span class="koboSpan" id="kobo.808.1">Chapter 9</span></em><span class="koboSpan" id="kobo.809.1">, </span><em class="italic"><span class="koboSpan" id="kobo.810.1">Empowering AI Models: Fine-Tuning RAG Data and Human Feedback</span></em><span class="koboSpan" id="kobo.811.1">. </span><span class="koboSpan" id="kobo.811.2">We can also introduce human feedback scores as we did in </span><em class="chapterRef"><span class="koboSpan" id="kobo.812.1">Chapter 5</span></em><span class="koboSpan" id="kobo.813.1">, </span><em class="italic"><span class="koboSpan" id="kobo.814.1">Boosting RAG Performance with Expert Human Feedback</span></em><span class="koboSpan" id="kobo.815.1">, because, in many cases, mathematical metrics will not </span><a id="_idIndexMarker482"/><span class="koboSpan" id="kobo.816.1">capture the accuracy of a response (writing fiction, long answers versus short input, and other complex responses). </span><span class="koboSpan" id="kobo.816.2">But we need to try anyway!</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.817.1">Let’s perform some of the possible metrics for the examples we are going to run.</span></p>
    <h2 id="_idParaDest-196" class="heading-2"><span class="koboSpan" id="kobo.818.1">Example metrics</span></h2>
    <p class="normal"><span class="koboSpan" id="kobo.819.1">To evaluate the knowledge</span><a id="_idIndexMarker483"/><span class="koboSpan" id="kobo.820.1"> graph index’s query engine, we will run ten examples and keep track of the scores. </span><code class="inlineCode"><span class="koboSpan" id="kobo.821.1">rscores</span></code><span class="koboSpan" id="kobo.822.1"> keeps track of human feedback scores while </span><code class="inlineCode"><span class="koboSpan" id="kobo.823.1">scores=[]</span></code><span class="koboSpan" id="kobo.824.1"> keeps track of similarity function scores:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.825.1"># create an empty array score human feedback scores:</span></span><span class="koboSpan" id="kobo.826.1">
rscores =[]
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.827.1"># create an empty score for similarity function scores</span></span><span class="koboSpan" id="kobo.828.1">
scores=[]
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.829.1">The number of examples can be increased as much as necessary depending on the needs of a project. </span><span class="koboSpan" id="kobo.829.2">Each of the ten examples has the same structure:</span></p>
    <ul>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.830.1">user_query</span></code><span class="koboSpan" id="kobo.831.1">, which is the input text for the query engine</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.832.1">elapsed_time</span></code><span class="koboSpan" id="kobo.833.1">, which is the result of the time measurement of the system’s response</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.834.1">response = execute_query(user_query)</span></code><span class="koboSpan" id="kobo.835.1"> executes the query</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.836.1">The user query and output are the same as in the example used for the re-ranking function:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.837.1">Query execution time: 1.9648 seconds
Psychologists, cultural anthropologists, and other experts in behavioral sciences are often
associated with marketing theory.
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.838.1">However, this time, we will run a similarity function and also ask a human for a score:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.839.1">text1=</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.840.1">str</span></span><span class="koboSpan" id="kobo.841.1">(response)
text2=user_query
similarity_score3=calculate_cosine_similarity_with_embeddings(text1, text2)
</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.842.1">print</span></span><span class="koboSpan" id="kobo.843.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.844.1">f"Cosine Similarity Score with sentence transformer: </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.845.1">{similarity_score3:</span></span><span class="hljs-number"><span class="koboSpan" id="kobo.846.1">.3</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.847.1">f}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.848.1">"</span></span><span class="koboSpan" id="kobo.849.1">)
scores.append(similarity_score3)
human_feedback=</span><span class="hljs-number"><span class="koboSpan" id="kobo.850.1">0.75</span></span><span class="koboSpan" id="kobo.851.1">
rscores.append(human_feedback)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.852.1">In this function:</span></p>
    <ul>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.853.1">text1</span></code><span class="koboSpan" id="kobo.854.1"> is the query</span><a id="_idIndexMarker484"/><span class="koboSpan" id="kobo.855.1"> engine’s response.</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.856.1">text2</span></code><span class="koboSpan" id="kobo.857.1"> is the user query.</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.858.1">similarity_score3</span></code><span class="koboSpan" id="kobo.859.1"> is the cosine similarity score.</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.860.1">scores.append(similarity_score3)</span></code><span class="koboSpan" id="kobo.861.1"> appends the similarity score to scores.</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.862.1">human_feedback</span></code><span class="koboSpan" id="kobo.863.1"> is the human similarity evaluation. </span><span class="koboSpan" id="kobo.863.2">We could replace this score with a document as we did in </span><em class="chapterRef"><span class="koboSpan" id="kobo.864.1">Chapter 5</span></em><span class="koboSpan" id="kobo.865.1">, </span><em class="italic"><span class="koboSpan" id="kobo.866.1">Boosting RAG Performance with Expert Human Feedback</span></em><span class="koboSpan" id="kobo.867.1">, or we could replace the human score with a human text response, which will become the ground truth. </span><span class="koboSpan" id="kobo.867.2">In both cases, the similarity score is recalculated with human feedback content.</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.868.1">rscores.append(human_feedback)</span></code><span class="koboSpan" id="kobo.869.1"> appends the human score to </span><code class="inlineCode"><span class="koboSpan" id="kobo.870.1">rscores</span></code><span class="koboSpan" id="kobo.871.1">.</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.872.1">Let’s review a few of the ten examples’ outputs and add a comment at the end of each one.</span></p>
    <div class="note">
      <p class="normal"><span class="koboSpan" id="kobo.873.1">LLMs are stochastic algorithms. </span><span class="koboSpan" id="kobo.873.2">As such, the responses and scores may vary from one run to another.</span></p>
    </div>
    <ul>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.874.1">Example 1</span></strong><span class="koboSpan" id="kobo.875.1">:</span><ul>
          <li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.876.1">User query</span></strong><span class="koboSpan" id="kobo.877.1">: </span><code class="inlineCode"><span class="koboSpan" id="kobo.878.1">Which experts are often associated with marketing theory?</span></code></li>
          <li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.879.1">Response</span></strong><span class="koboSpan" id="kobo.880.1">: Psychologists, cultural anthropologists, and other experts in behavioral sciences are often associated with marketing theory.</span></li>
          <li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.881.1">Cosine similarity score</span></strong><span class="koboSpan" id="kobo.882.1">: </span><code class="inlineCode"><span class="koboSpan" id="kobo.883.1">0.809</span></code></li>
          <li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.884.1">Human feedback</span></strong><span class="koboSpan" id="kobo.885.1">: </span><code class="inlineCode"><span class="koboSpan" id="kobo.886.1">0.75</span></code></li>
          <li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.887.1">Comment</span></strong><span class="koboSpan" id="kobo.888.1">: The response is acceptable, but it could be more specific and mention the names of experts. </span><span class="koboSpan" id="kobo.888.2">However, the prompt is ambiguous and only mentions experts in general.</span></li>
        </ul>
      </li>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.889.1">Example 3</span></strong><span class="koboSpan" id="kobo.890.1">:</span><ul>
          <li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.891.1">User query</span></strong><span class="koboSpan" id="kobo.892.1">: </span><code class="inlineCode"><span class="koboSpan" id="kobo.893.1">What is the difference between B2B and B2C?</span></code></li>
          <li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.894.1">Response</span></strong><span class="koboSpan" id="kobo.895.1">: B2B businesses sell products and services to other companies, while B2C businesses sell directly to customers.</span></li>
          <li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.896.1">Cosine Similarity score</span></strong><span class="koboSpan" id="kobo.897.1">: </span><code class="inlineCode"><span class="koboSpan" id="kobo.898.1">0.760</span></code></li>
          <li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.899.1">Human feedback</span></strong><span class="koboSpan" id="kobo.900.1">: </span><code class="inlineCode"><span class="koboSpan" id="kobo.901.1">0.8</span></code></li>
          <li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.902.1">Comment</span></strong><span class="koboSpan" id="kobo.903.1">: The response is precise, but in some cases, users like examples.</span></li>
        </ul>
      </li>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.904.1">Example 7</span></strong><span class="koboSpan" id="kobo.905.1">:</span><ul>
          <li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.906.1">User query</span></strong><span class="koboSpan" id="kobo.907.1">: </span><code class="inlineCode"><span class="koboSpan" id="kobo.908.1">What commodity programs does the Agricultural Marketing Service (AMS) maintain?</span></code></li>
          <li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.909.1">Response</span></strong><span class="koboSpan" id="kobo.910.1">: The </span><strong class="keyWord"><span class="koboSpan" id="kobo.911.1">Agricultural Marketing Service</span></strong><span class="koboSpan" id="kobo.912.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.913.1">AMS</span></strong><span class="koboSpan" id="kobo.914.1">) maintains programs</span><a id="_idIndexMarker485"/><span class="koboSpan" id="kobo.915.1"> in five commodity</span><a id="_idIndexMarker486"/><span class="koboSpan" id="kobo.916.1"> areas: cotton and tobacco, dairy, fruit and vegetable, livestock and seed, and poultry.</span></li>
          <li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.917.1">Cosine Similarity score</span></strong><span class="koboSpan" id="kobo.918.1">: </span><code class="inlineCode"><span class="koboSpan" id="kobo.919.1">0.904</span></code></li>
          <li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.920.1">Human feedback</span></strong><span class="koboSpan" id="kobo.921.1">: </span><code class="inlineCode"><span class="koboSpan" id="kobo.922.1">0.9</span></code></li>
          <li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.923.1">Comment</span></strong><span class="koboSpan" id="kobo.924.1">: This response is accurate and interesting because the information is contained in a page linked to the main page. </span><span class="koboSpan" id="kobo.924.2">Thus, this is information from a linked page to the main page. </span><span class="koboSpan" id="kobo.924.3">We could ask Wikipedia to search the links of all the linked pages to the main page and go down several levels. </span><span class="koboSpan" id="kobo.924.4">However, the main information we are looking for may be diluted in less relevant data. </span><span class="koboSpan" id="kobo.924.5">The decision on the scope of the depth of the data depends on the needs of each project. </span></li>
        </ul>
      </li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.925.1">We will now perform metric calculations on the cosine similarity scores and the human feedback scores.</span></p>
    <h3 id="_idParaDest-197" class="heading-3"><span class="koboSpan" id="kobo.926.1">Metric calculation and display</span></h3>
    <p class="normal"><span class="koboSpan" id="kobo.927.1">The cosine similarity scores of </span><a id="_idIndexMarker487"/><span class="koboSpan" id="kobo.928.1">the examples are </span><a id="_idIndexMarker488"/><span class="koboSpan" id="kobo.929.1">stored in </span><code class="inlineCode"><span class="koboSpan" id="kobo.930.1">scores</span></code><span class="koboSpan" id="kobo.931.1">:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-built_in"><span class="koboSpan" id="kobo.932.1">print</span></span><span class="koboSpan" id="kobo.933.1">(</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.934.1">len</span></span><span class="koboSpan" id="kobo.935.1">(scores), scores)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.936.1">The ten scores are displayed:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.937.1">10 [0.808918, 0.720165, 0.7599532, 0.8513956, 0.5457667, 0.6963912, 0.9036964, 0.44829217, 0.59976315, 0.47448665]
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.938.1">We could expand the evaluations to as many other examples, depending on the needs of each project. </span><span class="koboSpan" id="kobo.938.2">The human feedback scores for the same examples are stored in </span><code class="inlineCode"><span class="koboSpan" id="kobo.939.1">rscores</span></code><span class="koboSpan" id="kobo.940.1">:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-built_in"><span class="koboSpan" id="kobo.941.1">print</span></span><span class="koboSpan" id="kobo.942.1">(</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.943.1">len</span></span><span class="koboSpan" id="kobo.944.1">(rscores), rscores)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.945.1">The ten human feedback scores are displayed:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.946.1">10 [0.75, 0.5, 0.8, 0.9, 0.65, 0.8, 0.9, 0.2, 0.2, 0.9]
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.947.1">We apply metrics to evaluate the responses:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.948.1">mean_score = np.mean(scores)
median_score = np.median(scores)
std_deviation = np.std(scores)
variance = np.var(scores)
min_score = np.</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.949.1">min</span></span><span class="koboSpan" id="kobo.950.1">(scores)
max_score = np.</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.951.1">max</span></span><span class="koboSpan" id="kobo.952.1">(scores)
range_score = max_score - min_score
percentile_25 = np.percentile(scores, </span><span class="hljs-number"><span class="koboSpan" id="kobo.953.1">25</span></span><span class="koboSpan" id="kobo.954.1">)
percentile_75 = np.percentile(scores, </span><span class="hljs-number"><span class="koboSpan" id="kobo.955.1">75</span></span><span class="koboSpan" id="kobo.956.1">)
iqr = percentile_75 - percentile_25
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.957.1">Each metric can provide several insights. </span><span class="koboSpan" id="kobo.957.2">Let’s go through each of them and the outputs obtained:</span></p>
    <ul>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.958.1">Central tendency (mean, median)</span></strong><span class="koboSpan" id="kobo.959.1"> gives us an idea of what a typical score looks like.</span></li>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.960.1">Variability (standard deviation, variance, range, IQR)</span></strong><span class="koboSpan" id="kobo.961.1"> tells us how spread out the scores are, indicating the consistency or diversity of the data.</span></li>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.962.1">Extremes (minimum, maximum)</span></strong><span class="koboSpan" id="kobo.963.1"> show the bounds of our dataset.</span></li>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.964.1">Distribution (percentiles)</span></strong><span class="koboSpan" id="kobo.965.1"> provides insights into how scores are distributed across the range of values.</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.966.1">Let’s go through these</span><a id="_idIndexMarker489"/><span class="koboSpan" id="kobo.967.1"> metrics calculated from the cosine </span><a id="_idIndexMarker490"/><span class="koboSpan" id="kobo.968.1">similarity scores and the human feedback scores and display their outputs:</span></p>
    <ol>
      <li class="numberedList" value="1"><strong class="keyWord"><span class="koboSpan" id="kobo.969.1">Mean (average)</span></strong><span class="koboSpan" id="kobo.970.1">:</span><ul>
          <li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.971.1">Definition</span></strong><span class="koboSpan" id="kobo.972.1">: The mean is the sum of all the scores divided by the number of scores.</span></li>
          <li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.973.1">Purpose</span></strong><span class="koboSpan" id="kobo.974.1">: It gives us the central value of the data, providing an idea of the typical score.</span></li>
          <li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.975.1">Calculation</span></strong><span class="koboSpan" id="kobo.976.1">:</span></li>
        </ul>
      </li>
    </ol>
    <p class="center"><a id="_idIndexMarker491"/><span class="koboSpan" id="kobo.977.1"><img src="../Images/B31169_07_001.png" alt=""/></span></p>
    <ul>
      <li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.978.1">Output</span></strong><span class="koboSpan" id="kobo.979.1">: </span><code class="inlineCode"><span class="koboSpan" id="kobo.980.1">Mean: 0.68</span></code></li>
    </ul>
    <ol>
      <li class="numberedList" value="2"><strong class="keyWord"><span class="koboSpan" id="kobo.981.1">Median</span></strong><span class="koboSpan" id="kobo.982.1">:</span><ul>
          <li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.983.1">Definition</span></strong><span class="koboSpan" id="kobo.984.1">: The median is the middle value when the scores are ordered from smallest to largest.</span></li>
          <li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.985.1">Purpose</span></strong><span class="koboSpan" id="kobo.986.1">: It provides the central point of the dataset and is less affected by extreme values (outliers) compared to the mean.</span></li>
          <li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.987.1">Output</span></strong><span class="koboSpan" id="kobo.988.1">: </span><code class="inlineCode"><span class="koboSpan" id="kobo.989.1">Median: 0.71</span></code></li>
        </ul>
      </li>
      <li class="numberedList"><strong class="keyWord"><span class="koboSpan" id="kobo.990.1">Standard deviation</span></strong><span class="koboSpan" id="kobo.991.1">:</span><ul>
          <li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.992.1">Definition</span></strong><span class="koboSpan" id="kobo.993.1">: The standard deviation measures the average amount by which each score differs from the mean.</span></li>
          <li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.994.1">Purpose</span></strong><span class="koboSpan" id="kobo.995.1">: It gives an idea of how spread out the scores are around the mean. </span><span class="koboSpan" id="kobo.995.2">A higher value indicates more variability.</span></li>
          <li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.996.1">Calculation</span></strong><span class="koboSpan" id="kobo.997.1">:</span></li>
        </ul>
      </li>
    </ol>
    <p class="center"><a id="_idIndexMarker492"/><span class="koboSpan" id="kobo.998.1"><img src="../Images/B31169_07_002.png" alt=""/></span></p>
    <ul>
      <li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.999.1">Output</span></strong><span class="koboSpan" id="kobo.1000.1">: </span><code class="inlineCode"><span class="koboSpan" id="kobo.1001.1">Standard Deviation: 0.15</span></code></li>
    </ul>
    <ol>
      <li class="numberedList" value="4"><strong class="keyWord"><span class="koboSpan" id="kobo.1002.1">Variance</span></strong><span class="koboSpan" id="kobo.1003.1">:</span><ul>
          <li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.1004.1">Definition</span></strong><span class="koboSpan" id="kobo.1005.1">: The variance is the square of the standard deviation.</span></li>
          <li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.1006.1">Purpose</span></strong><span class="koboSpan" id="kobo.1007.1">: It also measures</span><a id="_idIndexMarker493"/><span class="koboSpan" id="kobo.1008.1"> the spread of the scores, showing how much they </span><a id="_idIndexMarker494"/><span class="koboSpan" id="kobo.1009.1">vary from the mean.</span></li>
          <li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.1010.1">Output</span></strong><span class="koboSpan" id="kobo.1011.1">: </span><code class="inlineCode"><span class="koboSpan" id="kobo.1012.1">Variance: 0.02</span></code></li>
        </ul>
      </li>
      <li class="numberedList"><strong class="keyWord"><span class="koboSpan" id="kobo.1013.1">Minimum</span></strong><span class="koboSpan" id="kobo.1014.1">:</span><ul>
          <li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.1015.1">Definition</span></strong><span class="koboSpan" id="kobo.1016.1">: The minimum is the smallest score in the dataset.</span></li>
          <li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.1017.1">Purpose</span></strong><span class="koboSpan" id="kobo.1018.1">: It tells us the lowest value.</span></li>
          <li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.1019.1">Output</span></strong><span class="koboSpan" id="kobo.1020.1">: </span><code class="inlineCode"><span class="koboSpan" id="kobo.1021.1">Minimum: 0.45</span></code></li>
        </ul>
      </li>
      <li class="numberedList"><span class="koboSpan" id="kobo.1022.1">Maximum:</span><ul>
          <li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.1023.1">Definition</span></strong><span class="koboSpan" id="kobo.1024.1">: The maximum is the largest score in the dataset.</span></li>
          <li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.1025.1">Purpose</span></strong><span class="koboSpan" id="kobo.1026.1">: It tells us the highest value.</span></li>
          <li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.1027.1">Output</span></strong><span class="koboSpan" id="kobo.1028.1">: </span><code class="inlineCode"><span class="koboSpan" id="kobo.1029.1">Maximum: 0.90</span></code></li>
        </ul>
      </li>
      <li class="numberedList"><strong class="keyWord"><span class="koboSpan" id="kobo.1030.1">Range</span></strong><span class="koboSpan" id="kobo.1031.1">:</span><ul>
          <li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.1032.1">Definition</span></strong><span class="koboSpan" id="kobo.1033.1">: The range is the difference between the maximum and minimum scores.</span></li>
          <li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.1034.1">Purpose</span></strong><span class="koboSpan" id="kobo.1035.1">: It shows the span of the dataset from the lowest to the highest value.</span></li>
          <li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.1036.1">Calculation</span></strong><span class="koboSpan" id="kobo.1037.1">:</span></li>
        </ul>
        <p class="normal"><em class="italic"><span class="koboSpan" id="kobo.1038.1">Range</span></em><span class="koboSpan" id="kobo.1039.1"> = </span><em class="italic"><span class="koboSpan" id="kobo.1040.1">Maximum</span></em><span class="koboSpan" id="kobo.1041.1"> - </span><em class="italic"><span class="koboSpan" id="kobo.1042.1">Minimum</span></em></p>
        <ul>
          <li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.1043.1">Output</span></strong><span class="koboSpan" id="kobo.1044.1">: </span><code class="inlineCode"><span class="koboSpan" id="kobo.1045.1">Range: 0.46</span></code></li>
        </ul>
      </li>
      <li class="numberedList"><strong class="keyWord"><span class="koboSpan" id="kobo.1046.1">25</span></strong><sup class="superscript-bold" style="font-weight: bold;"><span class="koboSpan" id="kobo.1047.1">th</span></sup><strong class="keyWord"><span class="koboSpan" id="kobo.1048.1"> Percentile (Q1)</span></strong><span class="koboSpan" id="kobo.1049.1">:</span><ul>
          <li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.1050.1">Definition</span></strong><span class="koboSpan" id="kobo.1051.1">: The 25</span><sup class="superscript"><span class="koboSpan" id="kobo.1052.1">th</span></sup><span class="koboSpan" id="kobo.1053.1"> percentile is the value below which 25% of the scores fall.</span></li>
          <li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.1054.1">Purpose</span></strong><span class="koboSpan" id="kobo.1055.1">: It provides a point below which a quarter of the data lies.</span></li>
          <li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.1056.1">Output</span></strong><span class="koboSpan" id="kobo.1057.1">: </span><code class="inlineCode"><span class="koboSpan" id="kobo.1058.1">25th Percentile (Q1): 0.56</span></code></li>
        </ul>
      </li>
      <li class="numberedList"><strong class="keyWord"><span class="koboSpan" id="kobo.1059.1">75</span></strong><sup class="superscript-bold" style="font-weight: bold;"><span class="koboSpan" id="kobo.1060.1">th</span></sup><strong class="keyWord"><span class="koboSpan" id="kobo.1061.1"> Percentile (Q3)</span></strong><span class="koboSpan" id="kobo.1062.1">:</span><ul>
          <li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.1063.1">Definition</span></strong><span class="koboSpan" id="kobo.1064.1">: The 75</span><sup class="superscript"><span class="koboSpan" id="kobo.1065.1">th</span></sup><span class="koboSpan" id="kobo.1066.1"> percentile is the value below which 75% of the scores fall.</span></li>
          <li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.1067.1">Purpose</span></strong><span class="koboSpan" id="kobo.1068.1">: It gives a point below which three-quarters of the data lies.</span></li>
          <li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.1069.1">Output</span></strong><span class="koboSpan" id="kobo.1070.1">: </span><code class="inlineCode"><span class="koboSpan" id="kobo.1071.1">75th Percentile (Q3): 0.80</span></code></li>
        </ul>
      </li>
      <li class="numberedList"><strong class="keyWord"><span class="koboSpan" id="kobo.1072.1">Interquartile Range (IQR)</span></strong><span class="koboSpan" id="kobo.1073.1">:</span><ul>
          <li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.1074.1">Definition</span></strong><span class="koboSpan" id="kobo.1075.1">: The IQR is the range between the 25</span><sup class="superscript"><span class="koboSpan" id="kobo.1076.1">th</span></sup><span class="koboSpan" id="kobo.1077.1"> percentile (Q1) and the 75</span><sup class="superscript"><span class="koboSpan" id="kobo.1078.1">th</span></sup><span class="koboSpan" id="kobo.1079.1"> percentile (Q3).</span></li>
          <li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.1080.1">Purpose</span></strong><span class="koboSpan" id="kobo.1081.1">: It measures the middle 50% of the data, providing a sense of the data’s spread without being affected by extreme values.</span></li>
          <li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.1082.1">Calculation</span></strong><span class="koboSpan" id="kobo.1083.1">:</span></li>
        </ul>
        <p class="normal"><em class="italic"><span class="koboSpan" id="kobo.1084.1">IQR</span></em><span class="koboSpan" id="kobo.1085.1"> = </span><em class="italic"><span class="koboSpan" id="kobo.1086.1">Q3</span></em><span class="koboSpan" id="kobo.1087.1"> – </span><em class="italic"><span class="koboSpan" id="kobo.1088.1">Q1</span></em></p>
        <ul>
          <li class="bulletList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.1089.1">Output</span></strong><span class="koboSpan" id="kobo.1090.1">: </span><code class="inlineCode"><span class="koboSpan" id="kobo.1091.1">Interquartile Range (IQR): 0.24</span></code></li>
        </ul>
      </li>
    </ol>
    <p class="normal"><span class="koboSpan" id="kobo.1092.1">We have built a</span><a id="_idIndexMarker495"/><span class="koboSpan" id="kobo.1093.1"> knowledge-graph-based RAG system, interacted</span><a id="_idIndexMarker496"/><span class="koboSpan" id="kobo.1094.1"> with it, and evaluated it with some examples and metrics. </span><span class="koboSpan" id="kobo.1094.2">Let’s sum up our journey.</span></p>
    <h1 id="_idParaDest-198" class="heading-1"><span class="koboSpan" id="kobo.1095.1">Summary</span></h1>
    <p class="normal"><span class="koboSpan" id="kobo.1096.1">In this chapter, we explored the creation of a scalable knowledge-graph-based RAG system using the Wikipedia API and LlamaIndex. </span><span class="koboSpan" id="kobo.1096.2">The techniques and tools developed are applicable across various domains, including data management, marketing, and any field requiring organized and accessible data retrieval.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.1097.1">Our journey began with data collection in </span><em class="italic"><span class="koboSpan" id="kobo.1098.1">Pipeline 1</span></em><span class="koboSpan" id="kobo.1099.1">. </span><span class="koboSpan" id="kobo.1099.2">This pipeline focused on automating the retrieval of Wikipedia content. </span><span class="koboSpan" id="kobo.1099.3">Using the Wikipedia API, we built a program to collect metadata and URLs from Wikipedia pages based on a chosen topic, such as marketing. </span><span class="koboSpan" id="kobo.1099.4">In </span><em class="italic"><span class="koboSpan" id="kobo.1100.1">Pipeline 2</span></em><span class="koboSpan" id="kobo.1101.1">, we created and populated the Deep Lake vector store. </span><span class="koboSpan" id="kobo.1101.2">The retrieved data from </span><em class="italic"><span class="koboSpan" id="kobo.1102.1">Pipeline 1</span></em><span class="koboSpan" id="kobo.1103.1"> was embedded and upserted into the Deep Lake vector store. </span><span class="koboSpan" id="kobo.1103.2">This pipeline highlighted the ease of integrating vast amounts of data into a structured vector store, ready for further processing and querying. </span><span class="koboSpan" id="kobo.1103.3">Finally, in </span><em class="italic"><span class="koboSpan" id="kobo.1104.1">Pipeline 3</span></em><span class="koboSpan" id="kobo.1105.1">, we introduced knowledge graph index-based RAG. </span><span class="koboSpan" id="kobo.1105.2">Using LlamaIndex, we automatically built a knowledge graph index from the embedded data. </span><span class="koboSpan" id="kobo.1105.3">This index visually mapped out the relationships between different pieces of information, providing a semantic overview of the data. </span><span class="koboSpan" id="kobo.1105.4">The knowledge graph was then queried using LlamaIndex’s built-in language model to generate optimal responses. </span><span class="koboSpan" id="kobo.1105.5">We also implemented metrics to evaluate the system’s performance, ensuring accurate and efficient data retrieval.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.1106.1">By the end of this chapter, we had constructed a comprehensive, automated RAG-driven knowledge graph system capable of collecting, embedding, and querying vast amounts of Wikipedia data with minimal human intervention. </span><span class="koboSpan" id="kobo.1106.2">This journey showed the power and potential of combining multiple AI tools and models to create an efficient pipeline for data management and retrieval. </span><span class="koboSpan" id="kobo.1106.3">You are now all set to implement knowledge graph-based RAG systems in real-life projects. </span><span class="koboSpan" id="kobo.1106.4">In the next chapter, we will learn how to implement dynamic RAG for short-term usage.</span></p>
    <h1 id="_idParaDest-199" class="heading-1"><span class="koboSpan" id="kobo.1107.1">Questions</span></h1>
    <p class="normal"><span class="koboSpan" id="kobo.1108.1">Answer the following questions with yes or no:</span></p>
    <ol>
      <li class="numberedList" value="1"><span class="koboSpan" id="kobo.1109.1">Does the chapter focus on building a scalable knowledge-graph-based RAG system using the Wikipedia API and LlamaIndex?</span></li>
      <li class="numberedList"><span class="koboSpan" id="kobo.1110.1">Is the primary use case discussed in the chapter related to healthcare data management?</span></li>
      <li class="numberedList"><span class="koboSpan" id="kobo.1111.1">Does </span><em class="italic"><span class="koboSpan" id="kobo.1112.1">Pipeline 1</span></em><span class="koboSpan" id="kobo.1113.1"> involve collecting and preparing documents from Wikipedia using an API?</span></li>
      <li class="numberedList"><span class="koboSpan" id="kobo.1114.1">Is Deep Lake used for creating a relational database in </span><em class="italic"><span class="koboSpan" id="kobo.1115.1">Pipeline 2</span></em><span class="koboSpan" id="kobo.1116.1">?</span></li>
      <li class="numberedList"><span class="koboSpan" id="kobo.1117.1">Does </span><em class="italic"><span class="koboSpan" id="kobo.1118.1">Pipeline 3</span></em><span class="koboSpan" id="kobo.1119.1"> utilize LlamaIndex to build a knowledge graph index?</span></li>
      <li class="numberedList"><span class="koboSpan" id="kobo.1120.1">Is the system designed to only handle a single specific topic, such as marketing, without flexibility?</span></li>
      <li class="numberedList"><span class="koboSpan" id="kobo.1121.1">Does the chapter describe how to retrieve URLs and metadata from Wikipedia pages?</span></li>
      <li class="numberedList"><span class="koboSpan" id="kobo.1122.1">Is a GPU required to run the pipelines described in the chapter?</span></li>
      <li class="numberedList"><span class="koboSpan" id="kobo.1123.1">Does the knowledge graph index visually map out relationships between pieces of data?</span></li>
      <li class="numberedList"><span class="koboSpan" id="kobo.1124.1">Is human intervention required at every step to query the knowledge graph index?</span></li>
    </ol>
    <h1 id="_idParaDest-200" class="heading-1"><span class="koboSpan" id="kobo.1125.1">References</span></h1>
    <ul>
      <li class="bulletList"><span class="koboSpan" id="kobo.1126.1">Wikipedia API GitHub repository: </span><a href="https://github.com/martin-majlis/Wikipedia-API"><span class="url"><span class="koboSpan" id="kobo.1127.1">https://github.com/martin-majlis/Wikipedia-API</span></span></a></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.1128.1">PyVis Network: </span><em class="italic"><span class="koboSpan" id="kobo.1129.1">Interactive Network Visualization in Python</span></em><span class="koboSpan" id="kobo.1130.1">.</span></li>
    </ul>
    <h1 id="_idParaDest-201" class="heading-1"><span class="koboSpan" id="kobo.1131.1">Further reading</span></h1>
    <ul>
      <li class="bulletList"><span class="koboSpan" id="kobo.1132.1">Hogan, A., Blomqvist, E., Cochez, M., et al. </span><em class="italic"><span class="koboSpan" id="kobo.1133.1">Knowledge Graphs</span></em><span class="koboSpan" id="kobo.1134.1">. </span><code class="inlineCode"><span class="koboSpan" id="kobo.1135.1">arXiv:2003.02320</span></code></li>
    </ul>
    <h1 id="_idParaDest-202" class="heading-1"><span class="koboSpan" id="kobo.1136.1">Join our community on Discord</span></h1>
    <p class="normal"><span class="koboSpan" id="kobo.1137.1">Join our community’s Discord space for discussions with the author and other readers:</span></p>
    <p class="normal"><a href="https://www.packt.link/rag"><span class="url"><span class="koboSpan" id="kobo.1138.1">https://www.packt.link/rag</span></span></a></p>
    <p class="normal"><span class="koboSpan" id="kobo.1139.1"><img src="../Images/QR_Code50409000288080484.png" alt=""/></span></p>
  </div>
</body></html>