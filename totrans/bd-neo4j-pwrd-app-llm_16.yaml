- en: '13'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Epilogue
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We have looked at quite a few topics and explored how to build intelligent
    applications. Now, we will revisit what we learned in the earlier chapters and
    look at the next steps in our journey. We will review how Neo4j is best suited
    to build knowledge graphs and how it integrates with the GenAI ecosystem to build
    intelligent search and recommendation applications with ease. We will cover the
    following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: The combined power of GenAI and Neo4j
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Beyond the book: exploring advanced techniques and resources for continued
    learning'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Closing remarks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The combined power of GenAI and Neo4j
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In *Chapters 1–3*, we looked at how GenAI and the evolution of LLMs came into
    the picture and how they jumpstarted technology, enabling natural interactions
    and ease of use. We also looked at how these same capabilities, because of the
    way they work, can provide information that is believable but might actually be
    false, as well as information that might not exist, which is referred to as hallucinations.
    We looked at how RAG can help with reducing these hallucinations.
  prefs: []
  type: TYPE_NORMAL
- en: We looked into knowledge graphs and how we can model them effectively to participate
    in RAG flows, called GraphRAG approaches. GraphRAG can be more effective and accurate
    than traditional RAG by integrating evolving knowledge graphs, which can ground
    LLMs with ease of use.
  prefs: []
  type: TYPE_NORMAL
- en: GraphRAG for search applications
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In *Chapters 4–6*, we embarked on a hands-on journey to build a powerful and
    intelligent search experience using a movie knowledge graph. Starting with structured
    data, we modeled and constructed the graph using Python and enriched it with vector
    embeddings generated through the Haystack framework. These embeddings, stored
    directly in the graph, helped us achieve a similarity search for our GraphRAG
    pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: Using vector search with the power of knowledge graphs, we created a hybrid
    retrieval system capable of answering not just simple keyword queries but also
    complex questions that might require multi-hop traversal to retrieve results.
    Through the integration of LLMs and GraphRAG, we moved on to intelligent search,
    which is capable of both document retrieval and context-aware understanding.
  prefs: []
  type: TYPE_NORMAL
- en: These chapters demonstrated the real-world potential of combining structured
    knowledge from graphs with the expressive power of LLMs.
  prefs: []
  type: TYPE_NORMAL
- en: GraphRAG for recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In *Chapters 7–10*, we looked at building a recommendations application by leveraging
    GraphRAG. We leveraged Langchain4J and Spring AI to understand how we can build
    GraphRAG applications using Java and the Spring framework. We followed numerous
    steps to build an intelligent recommendation application. The first one was building
    a knowledge graph by loading H&M customer transaction data. The next important
    step was to augment the graph by adding seasonal relationships, which helped consume
    the data in a more granular fashion. We then used these seasonal relationships
    as part of the GraphRAG flow to generate a summary of customer purchases for a
    given season, along with embeddings to enrich the graph with more context. These
    embeddings and graph data science algorithms captured relationships between similar
    customers, with the help of the KNN algorithm. Upon creating similarity relationships,
    community detection algorithms were utilized to group the customers into communities
    to provide better recommendations. We also looked at why this pipeline gives us
    better recommendations than relying on a simple vector search itself.
  prefs: []
  type: TYPE_NORMAL
- en: When we built this application, we used GraphRAG not to generate text for end
    user consumption but to enrich the knowledge graph, to provide better recommendations.
    This showed how LLMs can play a part not just as chatbots but also in enriching
    the data to understand it better and in a new light.
  prefs: []
  type: TYPE_NORMAL
- en: Choosing your cloud platform
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Chapters 11–12* focused on various available cloud services. We drew a detailed
    comparison to help you select a cloud for your GenAI applications. In the last
    chapter, we demonstrated how to deploy your application to the Google Cloud.'
  prefs: []
  type: TYPE_NORMAL
- en: Next up, we will talk about how we can go beyond what we have discussed in this
    book.
  prefs: []
  type: TYPE_NORMAL
- en: 'Beyond the book: exploring resources for continued learning'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'While we have discussed, with simple examples, the importance of graph data
    modeling and looked at two specific graph data model examples, it would be prudent
    to understand how Neo4j helps in building better graphs and how its architecture
    can assist with building knowledge graphs in a scalable manner. Neo4j provides
    the following resources to learn more about Neo4j, knowledge graphs, and GraphRAG
    implementations:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Neo4j Graph Academy**: You can find Neo4j Graph Academy at https://graphacademy.neo4j.com/.
    This contains a wealth of resources to understand Neo4j concepts and build knowledge
    graphs. For example, the course at https://graphacademy.neo4j.com/courses/genai-workshop-graphrag/
    provides an easy-to-follow workshop to understand GraphRAG principles.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Neo4j GraphRAG Python package**: Neo4j provides a simple-to-use GraphRAG
    Python package. You can read more about it at [https://neo4j.com/docs/neo4j-graphrag-python/current/index.html](https://neo4j.com/docs/neo4j-graphrag-python/current/index.html).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Neo4J GenAI ecosystem**: You can read more about the GenAI ecosystem integrations
    at [https://neo4j.com/labs/genai-ecosystem/](https://neo4j.com/labs/genai-ecosystem/).
    This link contains documentation about the integration with Haystack, LangChain,
    Spring AI, and other frameworks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s head over to the closing remarks.
  prefs: []
  type: TYPE_NORMAL
- en: Closing remarks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have looked at various aspects of emerging LLM frameworks and how we can
    build better solutions using these frameworks. While this technology is exciting
    and opening new doors for how we look at and solve problems, it is still in its
    nascent stages. It requires a lot of processing power and may not have the **service-level
    agreement (SLA)** response times we might be looking for. While we might get excited
    about solving all the problems using this approach, it’s important to evaluate
    whether trying to solve a given problem really needs to leverage these technologies
    or whether we can solve them more reasonably and effectively. For example, many
    people are excited about LLM capabilities and trying to generate data models (be
    it graphs, SQL, or other) by describing a problem. This can be a double-edged
    sword. If we are not familiar with the data we are working with, we may not be
    able to validate the model generated. If we are very familiar with the data, we
    might have better context and nuances of the data that LLMs might be missing.
    So, we might not benefit as much when we try to solve the problems in this manner.
    So, keep in mind that this might be a surgical knife to solve the problems effectively,
    not an axe, so use it effectively.
  prefs: []
  type: TYPE_NORMAL
- en: While this book concludes here, your journey does not have to. Armed with the
    foundational knowledge, tools, and working examples, you are now ready to experiment,
    expand, and elevate your own GenAI solutions. Whether you are building smart assistants,
    contextual search engines, or personalized recommender systems, the future of
    intelligent applications is now in your hands.
  prefs: []
  type: TYPE_NORMAL
- en: Keep building. Keep exploring. And most importantly, keep connecting ideas,
    data, and people through the power of knowledge graphs and generative AI.
  prefs: []
  type: TYPE_NORMAL
- en: Stay tuned
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To keep up with the latest developments in the fields of Generative AI and LLMs,
    subscribe to our weekly newsletter, AI_Distilled, at [https://packt.link/Q5UyU](https://packt.link/Q5UyU).
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/qrcodeAINL1.png)'
  prefs: []
  type: TYPE_IMG
- en: Have questions about the book or want to contribute to discussions on Generative
    AI and LLMs?
  prefs: []
  type: TYPE_NORMAL
- en: Join our Discord server at [https://packt.link/4Bbd9](https://packt.link/4Bbd9)
    and our Reddit channel at [https://packt.link/wcYOQ](https://packt.link/wcYOQ)
    to connect, share, and collaborate with like-minded enthusiasts.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/qrcodeDiscord.png) ![](img/qrcodeReddit.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/Packt_Logo_New1.png)'
  prefs: []
  type: TYPE_IMG
- en: '[packtpub.com](http://packtpub.com)'
  prefs: []
  type: TYPE_NORMAL
- en: Subscribe to our online digital library for full access to over 7,000 books
    and videos, as well as industry leading tools to help you plan your personal development
    and advance your career. For more information, please visit our website.
  prefs: []
  type: TYPE_NORMAL
- en: Why subscribe?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Spend less time learning and more time coding with practical eBooks and Videos
    from over 4,000 industry professionals
  prefs: []
  type: TYPE_NORMAL
- en: Improve your learning with Skill Plans built especially for you
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Get a free eBook or video every month
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fully searchable for easy access to vital information
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Copy and paste, print, and bookmark content
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Did you know that Packt offers eBook versions of every book published, with
    PDF and ePub files available? You can upgrade to the eBook version at [packtpub.com](http://packtpub.com)
    and as a print book customer, you are entitled to a discount on the eBook copy.
    Get in touch with us at [customercare@packtpub.com](https://customercare@packtpub.com)
    for more details.
  prefs: []
  type: TYPE_NORMAL
- en: At [www.packtpub.com](http://www.packtpub.com), you can also read a collection
    of free technical articles, sign up for a range of free newsletters, and receive
    exclusive discounts and offers on Packt books and eBooks.
  prefs: []
  type: TYPE_NORMAL
- en: Other Books You May Enjoy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you enjoyed this book, you may be interested in these other books by Packt:'
  prefs: []
  type: TYPE_NORMAL
- en: '[![A picture containing website'
  prefs: []
  type: TYPE_NORMAL
- en: Description automatically generated](img/9781835884447.png)](https://packt.link/1835884458)
  prefs: []
  type: TYPE_NORMAL
- en: '**Generative AI with Python and PyTorch**'
  prefs: []
  type: TYPE_NORMAL
- en: Joseph Babcock, Raghav Bali
  prefs: []
  type: TYPE_NORMAL
- en: 'ISBN: 978-1-83588-444-7'
  prefs: []
  type: TYPE_NORMAL
- en: Grasp the core concepts and capabilities of LLMs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Craft effective prompts using chain-of-thought, ReAct, and prompt query language
    to guide LLMs toward your desired outputs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understand how attention and transformers have changed NLP
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Optimize your diffusion models by combining them with VAEs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Build text generation pipelines based on LSTMs and LLMs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Leverage the power of open-source LLMs, such as Llama and Mistral, for diverse
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: applications
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[![A picture containing website'
  prefs: []
  type: TYPE_NORMAL
- en: Description automatically generated](img/9781836200079.png)](https://packt.link/1836200072)
  prefs: []
  type: TYPE_NORMAL
- en: '**LLM Engineer’s Handbook**'
  prefs: []
  type: TYPE_NORMAL
- en: Paul Iusztin, Maxime Labonne
  prefs: []
  type: TYPE_NORMAL
- en: 'ISBN: 9781836200079'
  prefs: []
  type: TYPE_NORMAL
- en: Implement robust data pipelines and manage LLM training cycles
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create your own LLM and refine it with the help of hands-on examples
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Get started with LLMOps by diving into core MLOps principles such as orchestrators
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: and prompt monitoring
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Perform supervised fine-tuning and LLM evaluation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploy end-to-end LLM solutions using AWS and other tools
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Design scalable and modular LLM systems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learn about RAG applications by building a feature and inference pipeline
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Packt is searching for authors like you
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you’re interested in becoming an author for Packt, please visit [authors.packtpub.com](http://authors.packtpub.com)
    and apply today. We have worked with thousands of developers and tech professionals,
    just like you, to help them share their insight with the global tech community.
    You can make a general application, apply for a specific hot topic that we are
    recruiting an author for, or submit your own idea.
  prefs: []
  type: TYPE_NORMAL
- en: Share your thoughts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now you’ve finished *Building Neo4j-Powered Applications with LLMs*, we’d love
    to hear your thoughts! If you purchased the book from Amazon, please [click here
    to go straight to the Amazon review page](https://packt.link/r/1836206232) for
    this book and share your feedback or leave a review on the site that you purchased
    it from.
  prefs: []
  type: TYPE_NORMAL
- en: Your review is important to us and the tech community and will help us make
    sure we’re delivering excellent quality content.
  prefs: []
  type: TYPE_NORMAL
