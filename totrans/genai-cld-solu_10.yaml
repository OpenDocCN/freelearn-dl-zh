- en: '10'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '10'
- en: The Future of Generative AI – Trends and Emerging Use Cases
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成式AI的未来 – 趋势和新兴用例
- en: We have reached the final chapter of this book on building generative AI solutions
    in the cloud. In this chapter, we would like you to get a sense of the future
    and where things are going by delving into the transformative possibilities and
    emerging trends that will shape the landscape of generative AI technologies such
    as ChatGPT. This chapter is not just a summary of what we’ve learned but a forward-looking
    exploration into the evolving world of cloud-based AI solutions.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经到达了这本书关于在云中构建生成式AI解决方案的最后一章。在这一章中，我们希望您通过深入了解将塑造生成式AI技术（如ChatGPT）格局的变革性可能性和新兴趋势，来获得对未来的感知以及事物的发展方向。这一章不仅是对我们所学内容的总结，而且是对基于云的AI解决方案不断演变世界的前瞻性探索。
- en: We will start by talking about the evolution of multimodal interactions. Here,
    we explore how integrating various communication methods through text, images,
    audio, and video is revolutionizing user interaction with AI. This is vital for
    those seeking to innovate in AI user interfaces.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先谈论多模态交互的演变。在这里，我们探讨通过文本、图像、音频和视频整合各种通信方式如何革命性地改变用户与AI的交互。这对于那些寻求在AI用户界面创新的人来说至关重要。
- en: This chapter starts with *Emerging trends and industry-specific generative AI
    apps*, drawing inspiration from industry leaders. This segment reveals the versatile
    applications of generative AI across different sectors.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章从*新兴趋势和行业特定的生成式AI应用*开始，从行业领导者那里汲取灵感。这一部分揭示了生成式AI在不同领域的多功能应用。
- en: Next, in the *Integrating generative AI with intelligent edge devices* section,
    we’ll discuss the fusion of ChatGPT and generative AI with smart technologies.
    This part is crucial for integrating AI into hardware and intelligent systems,
    particularly with the **Internet of** **Things** (**IoT**).
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，在*将生成式AI与智能边缘设备集成*部分，我们将讨论ChatGPT和生成式AI与智能技术的融合。这部分对于将AI集成到硬件和智能系统中至关重要，尤其是与**物联网**（**IoT**）的结合。
- en: Finally, *From quantum computing to AGI – charting ChatGPT’s future trajectory*
    offers a speculative glimpse into how emerging technologies could dramatically
    evolve ChatGPT’s capabilities, inching closer to **artificial general** **intelligence**
    (**AGI**).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，*从量子计算到通用人工智能 – 绘制ChatGPT的未来轨迹*提供了一个推测性的视角，展示了新兴技术如何极大地演变ChatGPT的能力，逐步接近**通用人工智能**（**AGI**）。
- en: By the end of this chapter, you will be equipped with a comprehensive understanding
    of the current trends and potential future directions of generative AI, along
    with the knowledge and inspiration to innovate and implement cutting-edge AI solutions
    in the cloud. This chapter provides a vision of the future of AI, empowering you
    to lead in the AI revolution.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，您将具备对生成式AI当前趋势和潜在未来方向的全面理解，以及创新和实施云中尖端AI解决方案的知识和灵感。本章为AI的未来提供了一个愿景，使您能够在AI革命中引领潮流。
- en: 'In this chapter, we’re going to cover the following main topics:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要主题：
- en: The era of multimodal interactions
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多模态交互的时代
- en: Industry-specific generative AI apps
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 行业特定的生成式AI应用
- en: The rise of SLMs
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SLMs的兴起
- en: Emerging trends and 2024-25 predictions
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 新兴趋势和2024-25预测
- en: Integrating ChatGPT with intelligent edge devices
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将ChatGPT与智能边缘设备集成
- en: From quantum computing to AGI – charting ChatGPT’s future trajectory
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从量子计算到通用人工智能 – 绘制ChatGPT的未来轨迹
- en: '![Figure 10.1 – Comic depiction of the future of generative AI](img/B21443_10_1.jpg)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![图10.1 – 生成式AI未来的漫画描绘](img/B21443_10_1.jpg)'
- en: Figure 10.1 – Comic depiction of the future of generative AI
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.1 – 生成式AI未来的漫画描绘
- en: The era of multimodal interactions
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多模态交互的时代
- en: Multimodal interaction in **large language models** (**LLMs**) refers to the
    ability of these models to understand “input prompts” and generate content as
    “output completions” in multiple modalities, typically combining text with other
    forms of data, such as images, audio, or even video. It’s the capacity to process
    and generate information using different sensory channels.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在**大型语言模型**（**LLMs**）中的多模态交互指的是这些模型理解“输入提示”并在多种模态中生成“输出完成”内容的能力，通常结合文本与其他形式的数据，如图像、音频甚至视频。这是使用不同的感官通道处理和生成信息的能力。
- en: We already know that LLMs such as GPT-4 perform well with text input and outputs.
    Renowned LLMs such as GPT-4 have already demonstrated exceptional proficiency
    with textual inputs and outputs. The recent surge in advanced image generation
    models, including DALL-E 3 and Midjourney, further illustrates this progress.
    The next significant leap in generative AI applications is anticipated to incorporate
    groundbreaking capabilities, extending to text-to-video and image-to-video conversions,
    thus broadening the horizons of AI’s creative and functional potential.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经知道，像GPT-4这样的LLM在处理文本输入和输出方面表现良好。著名的LLM如GPT-4已经展示了在文本输入和输出方面的卓越能力。最近高级图像生成模型（包括DALL-E
    3和Midjourney）的激增进一步说明了这一进展。预计下一代生成式AI应用的重大飞跃将结合突破性的能力，扩展到文本到视频和图像到视频的转换，从而拓宽AI在创意和功能潜力方面的视野。
- en: 'Let’s consider the benefits and use cases of multimodal LLMs:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑多模态LLM的益处和用例：
- en: '**Cost-effective production**: Producing videos traditionally can be expensive
    and time-consuming. LMMs with text-to-video technology can offer a more cost-effective
    alternative, particularly for small businesses or individuals.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**成本效益的生产**：传统上制作视频可能既昂贵又耗时。具有文本到视频技术的LLM可以提供更经济实惠的替代方案，尤其是对小企业或个人来说。'
- en: '**Enhanced understanding and interaction**: By incorporating multiple modalities,
    these models better understand and interpret the context and nuances of real-world
    scenarios. This leads to more accurate and contextually relevant responses, particularly
    in complex interactions.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**增强理解和交互**：通过整合多种模态，这些模型能更好地理解和解释现实世界场景的上下文和细微差别。这导致更准确和上下文相关的响应，尤其是在复杂交互中。'
- en: '**Richer content generation/creative storytelling**: Multimodal LLMs can create
    more comprehensive and detailed content. For instance, they can generate descriptive
    narratives for images or videos, or even create visual content from textual descriptions.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**更丰富的内容生成/创意叙事**：多模态大型语言模型可以创建更全面和详细的内容。例如，它们可以为图像或视频生成描述性叙述，甚至可以从文本描述中创建视觉内容。'
- en: '**Improved accessibility**: They can be instrumental in making technology more
    accessible. For example, converting text into speech or vice versa can help individuals
    with visual or auditory impairments.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提高可访问性**：它们在使技术更易于访问方面可以发挥重要作用。例如，将文本转换为语音或反之亦然可以帮助视觉或听觉障碍人士。'
- en: '**Better data analysis**: Multimodal LLMs can analyze data from various sources
    simultaneously, offering more nuanced insights. This is particularly useful in
    fields such as market research, media analysis, and scientific research, where
    data comes in various formats.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**更好的数据分析**：多模态LLM可以同时分析来自各种来源的数据，提供更深入的见解。这在市场研究、媒体分析和科学研究等领域尤其有用，因为这些领域的数据格式多种多样。'
- en: '**Advanced learning and training tools**: In educational contexts, these models
    can provide a more interactive and engaging learning experience by incorporating
    various media types, making learning more dynamic and effective.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高级学习和训练工具**：在教育环境中，这些模型通过整合各种媒体类型，可以提供更加互动和吸引人的学习体验，使学习更加动态和有效。'
- en: '**Innovative applications in creative industries**: In creative fields such
    as art, music, and film, multimodal LLMs can assist in the creative process by
    offering new ways to generate and modify content.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**创意产业中的创新应用**：在艺术、音乐和电影等创意领域，多模态大型语言模型可以通过提供新的内容生成和修改方式来协助创意过程。'
- en: '**Enhanced customer experience**: In customer service, they can interact in
    a more human-like manner, understanding queries better and providing more relevant
    information, sometimes even using visual aids.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**增强客户体验**：在客户服务中，它们可以以更人性化的方式互动，更好地理解查询并提供更相关的信息，有时甚至使用视觉辅助工具。'
- en: '**Language and cultural adaptation**: This technology can include features
    such as subtitles or dubbing in different languages, making content accessible
    to a wider, multilingual audience.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**语言和文化适应性**：这项技术可以包括诸如不同语言的字幕或配音等功能，使内容对更广泛的、多语言受众可访问。'
- en: '**Personalization**: They can tailor experiences and content to individual
    users by understanding and integrating cues from various data types, leading to
    more personalized interactions.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**个性化**：它们可以通过理解和整合来自各种数据类型的线索来定制用户体验和内容，从而实现更个性化的交互。'
- en: '**Support for content creators**: For bloggers, educators, or marketers, this
    technology provides a simple way to diversify content formats, enhancing their
    digital presence and engagement.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**支持内容创作者**：对于博客作者、教育工作者或营销人员，这项技术提供了一种简单的方法来多样化内容格式，增强他们的数字存在感和参与度。'
- en: GPT-4 Turbo Vision and beyond – a closer look at this LMM
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GPT-4 Turbo Vision及以后 – 对此LMM的深入了解
- en: '**GPT-4 Turbo with Vision** (**GPT-4V**), released by OpenAI in late 2023,
    is a new version of the LLM that supports 128,000 tokens of context (~300 pages
    of text as input prompts), is cheaper, has updated knowledge and image capabilities,
    provides text-to-speech offerings, and has a copyright shield. It can also understand
    images as inputs and generate captions and descriptions, all while providing intricate
    analyses of them.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**GPT-4 Turbo with Vision**（**GPT-4V**），由OpenAI于2023年底发布，是LLM的新版本，支持128,000个上下文标记（约300页文本作为输入提示），更便宜，更新了知识和图像能力，提供文本到语音服务，并具有版权保护。它还可以理解图像作为输入，并生成标题和描述，同时对其提供复杂的分析。'
- en: 'GPT-4V is an improvement over GPT-V4 in terms of its broader general knowledge
    and advanced reasoning capabilities. The following figure from the research paper
    *The Dawn of the LMMs: Preliminary Explorations with GPT-4V(ision)* demonstrates
    the remarkable reasoning capabilities of GPT-4V with different prompting techniques
    (*The Dawn of LMMs: Preliminary Explorations with* *GPT-4*, [https://export.arxiv.org/pdf/2309.17421](https://export.arxiv.org/pdf/2309.17421)):'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4V在更广泛的一般知识和高级推理能力方面优于GPT-V4。以下来自研究论文《LMMs的黎明：GPT-4V(视觉)的初步探索》的图表展示了GPT-4V在不同提示技术下的卓越推理能力（*LMMs的黎明：GPT-4的初步探索*，[https://export.arxiv.org/pdf/2309.17421](https://export.arxiv.org/pdf/2309.17421)）：
- en: '![Figure 10.2 – Demonstration of GPT-4V following text instructions](img/B21443_10_2.jpg)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![图10.2 – GPT-4V遵循文本指令的演示](img/B21443_10_2.jpg)'
- en: Figure 10.2 – Demonstration of GPT-4V following text instructions
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.2 – GPT-4V遵循文本指令的演示
- en: '![Figure 10.3 – Demonstration of GPT-4V with visual referring prompting](img/B21443_10_3.jpg)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![图10.3 – GPT-4V使用视觉参考提示的演示](img/B21443_10_3.jpg)'
- en: Figure 10.3 – Demonstration of GPT-4V with visual referring prompting
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.3 – GPT-4V使用视觉参考提示的演示
- en: 'It also possesses multilingual multimodal understanding so that it can understand
    text in different languages in images and answer your questions in English or
    a language of your choice, as shown here:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 它还具备多语言多模态理解能力，因此它可以理解图像中的不同语言的文本，并用英语或你选择的任何语言回答你的问题，如下所示：
- en: '![Figure 10.4 – GPT-4V’s capabilities regarding multilingual scene text recognition](img/B21443_10_4.jpg)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![图10.4 – GPT-4V在多语言场景文本识别方面的能力](img/B21443_10_4.jpg)'
- en: Figure 10.4 – GPT-4V’s capabilities regarding multilingual scene text recognition
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.4 – GPT-4V在多语言场景文本识别方面的能力
- en: '![Figure 10.5 – GPT-4V’s capabilities regarding multimodal multicultural understanding](img/B21443_10_5.jpg)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![图10.5 – GPT-4V在多模态跨文化理解方面的能力](img/B21443_10_5.jpg)'
- en: Figure 10.5 – GPT-4V’s capabilities regarding multimodal multicultural understanding
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.5 – GPT-4V在多模态跨文化理解方面的能力
- en: Video prompts for video understanding
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 视频理解的视频提示
- en: A novel feature not present in earlier GPT models is the capability to comprehend
    videos. With video prompting, you can prompt the LLM with not only text but also
    video. GPT-4V can analyze brief video clips and produce comprehensive descriptions.
    Though GPT-4V doesn’t directly process video inputs, the Azure Open AI Chat playground,
    enhanced with GPT-4V and Azure Vision services, allows for interactive questioning
    of video content. This system operates by identifying key frames from the video
    that are relevant to your query. It then examines these frames in detail to generate
    a response. This integration bridges the gap between video content and AI-driven
    insights. For example, you can upload a short video of a boy playing football
    on Azure Open AI Chat playground and simultaneously state, “Give me a summary
    of the video and what sport is being played in the video.”
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在早期GPT模型中不存在的创新功能是理解视频的能力。通过视频提示，你可以用文本和视频来提示LLM。GPT-4V可以分析简短的视频片段并生成全面的描述。尽管GPT-4V不直接处理视频输入，但增强GPT-4V和Azure
    Vision服务的Azure Open AI Chat playground允许对视频内容进行交互式提问。该系统通过识别与你的查询相关的关键帧来运行。然后它详细检查这些帧以生成响应。这种集成弥合了视频内容和AI驱动的洞察力之间的差距。例如，你可以在Azure
    Open AI Chat playground上传一个男孩踢足球的短视频，并同时声明，“给我视频的总结以及视频中正在进行的运动类型。”
- en: The frames are examined by GPT-4V seamlessly due to its varying capabilities,
    such as temporal ordering, temporal anticipation, and temporal localization and
    reasoning. Let’s dig into these concepts in a bit more detail.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 由于其不同的能力，如时间顺序、时间预测、时间定位和推理，GPT-4V可以无缝地检查这些帧。让我们更详细地探讨这些概念。
- en: '**Temporal ordering** means being able to put things in the right order based
    on time. For GPT-4V, this skill is really important. It’s like if you mixed up
    a bunch of photos from an event, say making sushi, and then asked the AI to put
    them back in the right order. GPT-4V can look at these shuffled pictures and figure
    out the correct sequence, showing how the sushi was made step by step. There are
    two types of temporal ordering: long-term and short-term. Long-term is like the
    sushi example, where the AI organizes a series of events over a longer period.
    Short-term is more about quick actions, such as opening or closing a door. GPT-4V
    can understand these actions and put them in the right order too. These tests
    are a way to check if GPT-4V understands how things happen over time, both for
    long processes and quick actions. It’s like testing if the AI can make sense of
    a story or an event just by looking at pictures, even if they’re all mixed up
    at first:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**时间顺序**意味着能够根据时间将事物排列在正确的顺序。对于GPT-4V来说，这项技能非常重要。就像如果你把一个事件的许多照片混在一起，比如制作寿司，然后要求AI将它们按正确的顺序放回，GPT-4V可以查看这些打乱的图片并找出正确的顺序，展示寿司是如何一步步制作的。有两种类型的时间顺序：长期和短期。长期就像寿司的例子，AI在较长时间内组织一系列事件。短期更多的是关于快速动作，比如开门或关门。GPT-4V也能理解这些动作并将它们按正确的顺序排列。这些测试是检查GPT-4V是否理解事物随时间发生的方式，无论是长期过程还是快速动作的一种方法。这就像测试AI是否可以通过查看图片来理解故事或事件，即使它们最初都是混乱的：'
- en: '![Figure 10.6 – Long-term temporal ordering: “GPT-4V” is shown a series of
    mixed-up images that show the process of making sushi. Despite the images being
    out of order, GPT-4V successfully recognizes the event and arranges the images
    in the proper chronological sequence (2309.17421 (arxiv.org))](img/B21443_10_6.jpg)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![图10.6 – 长期时间顺序：“GPT-4V”被展示了一系列混乱的图片，展示了制作寿司的过程。尽管图片顺序混乱，GPT-4V仍然成功地识别了事件并将图片按正确的时序排列（2309.17421
    (arxiv.org))](img/B21443_10_6.jpg)'
- en: 'Figure 10.6 – Long-term temporal ordering: “GPT-4V” is shown a series of mixed-up
    images that show the process of making sushi. Despite the images being out of
    order, GPT-4V successfully recognizes the event and arranges the images in the
    proper chronological sequence (2309.17421 (arxiv.org))'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.6 – 长期时间顺序：“GPT-4V”被展示了一系列混乱的图片，展示了制作寿司的过程。尽管图片顺序混乱，GPT-4V仍然成功地识别了事件并将图片按正确的时序排列（2309.17421
    (arxiv.org)）
- en: '![Figure 10.7 – Short-term temporal ordering: when presented with a specific
    action, such as opening or closing a door, GPT-4V proves its ability to understand
    the content of the images and accurately arrange them in the right sequence that
    matches the given action](img/B21443_10_7.jpg)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![图10.7 – 短期时间顺序：当展示一个特定的动作，例如开门或关门时，GPT-4V证明了其理解图片内容并准确地将它们按给定动作的正确顺序排列的能力](img/B21443_10_7.jpg)'
- en: 'Figure 10.7 – Short-term temporal ordering: when presented with a specific
    action, such as opening or closing a door, GPT-4V proves its ability to understand
    the content of the images and accurately arrange them in the right sequence that
    matches the given action'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.7 – 短期时间顺序：当展示一个特定的动作，例如开门或关门时，GPT-4V证明了其理解图片内容并准确地将它们按给定动作的正确顺序排列的能力
- en: '**Temporal anticipation** is where GPT-4V predicts future events from the beginning
    frames of an action. It does this for both short-term and long-term events. For
    example, with a soccer penalty kick, GPT-4V can guess the next moves of the kicker
    and goalkeeper by understanding the game’s rules. Similarly, in sushi making,
    it predicts the next steps in the process by recognizing the current stage and
    the overall procedure. This ability lets GPT-4V understand and predict actions
    that happen over different lengths of time:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**时间预测**是指GPT-4V从动作的开始帧预测未来事件。它对短期和长期事件都这样做。例如，在足球点球中，GPT-4V可以通过理解比赛规则来猜测踢球者和守门员接下来的动作。同样，在制作寿司中，它通过识别当前阶段和整体程序来预测过程中的下一步。这种能力让GPT-4V能够理解和预测不同时间长度内发生的行为：'
- en: '![Figure 10.8 – Long-term temporal anticipation: GPT-4V can predict the next
    moves based on the initial frames](img/B21443_10_8.jpg)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![图10.8 – 长期时间预测：GPT-4V可以根据初始帧预测下一步动作](img/B21443_10_8.jpg)'
- en: 'Figure 10.8 – Long-term temporal anticipation: GPT-4V can predict the next
    moves based on the initial frames'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.8 – 长期时间预测：GPT-4V可以根据初始帧预测下一步动作
- en: '**Temporal localization and reasoning** refer to GPT-4V’s skill in pinpointing
    specific moments in time and making logical connections. An example is its ability
    to identify the exact moment a soccer player hits the ball. Moreover, GPT-4V can
    understand cause and effect relationships, such as figuring out whether a goalkeeper
    will successfully stop the ball. This involves not just seeing where the goalkeeper
    and ball are, but also understanding how they interact and predicting what will
    happen next. This shows a high level of complex reasoning in the model:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**时间定位和推理**指的是GPT-4V在特定时间点定位和建立逻辑联系的能力。一个例子是它能够识别足球运动员击球的精确时刻。此外，GPT-4V可以理解因果关系，例如判断守门员是否能成功阻止球。这不仅仅是要看到守门员和球的位置，还要理解它们之间的互动并预测接下来会发生什么。这显示了模型在复杂推理方面的高水平：'
- en: '![Figure 10.9 – Temporal localization and reasoning: GPT-4V exhibits its skill
    in temporal localization by precisely pinpointing the moment the player hits the
    ball. Additionally, it showcases its understanding of cause and effect by assessing
    if the ball was stopped and analyzing the interaction between the goalkeeper and
    the ball](img/B21443_10_9.jpg)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![图10.9 – 时间定位和推理：GPT-4V通过精确地指出球员击球的那一刻来展示其在时间定位方面的技能。此外，它通过评估球是否被阻止并分析守门员与球之间的互动来展示其对因果关系的理解](img/B21443_10_9.jpg)'
- en: 'Figure 10.9 – Temporal localization and reasoning: GPT-4V exhibits its skill
    in temporal localization by precisely pinpointing the moment the player hits the
    ball. Additionally, it showcases its understanding of cause and effect by assessing
    if the ball was stopped and analyzing the interaction between the goalkeeper and
    the ball'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.9 – 时间定位和推理：GPT-4V通过精确地指出球员击球的那一刻来展示其在时间定位方面的技能。此外，它通过评估球是否被阻止并分析守门员与球之间的互动来展示其对因果关系的理解
- en: GPT-4V limitations (as of Jan 2024)
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4V的限制（截至2024年1月）
- en: 'Although GPT-4V is very intelligent compared to its predecessors, we must be
    aware of its limitations when leveraging it in applications. These limitations
    are mentioned on the OpenAI website ([https://platform.openai.com/docs/guides/vision](https://platform.openai.com/docs/guides/vision)):'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '虽然与前辈相比，GPT-4V非常智能，但在将其应用于应用时，我们必须意识到其局限性。这些局限性在OpenAI网站上有所提及（[https://platform.openai.com/docs/guides/vision](https://platform.openai.com/docs/guides/vision)）:'
- en: '**Medical diagnostics**: It’s not equipped to interpret specialized medical
    imagery such as CT scans and is not a source for medical guidance'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**医学诊断**: 它无法解释如CT扫描等专业的医学图像，也不是医学指导的来源'
- en: '**Non-Latin scripts**: Performance may falter with image texts in non-Latin
    scripts such as Japanese or Korean'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**非拉丁文字**: 在非拉丁文字（如日语或韩语）的图像文本中，性能可能会下降'
- en: '**Text size**: Amplifying text size can enhance readability, but important
    parts of the image should not be excluded'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文本大小**: 放大文本大小可以增强可读性，但不应排除图像的重要部分'
- en: '**Orientation**: Misinterpretation is possible with rotated or upside-down
    text and images'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**方向性**: 旋转或颠倒的文字和图像可能导致误解'
- en: '**Complex visuals**: The model might struggle with graphs or texts where there
    are variations in color or line styles (solid, dashed, dotted, and so on)'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**复杂视觉**: 模型可能会在颜色或线条样式（实线、虚线、点线等）有变化的图表或文本中遇到困难'
- en: '**Spatial analysis**: The model has limitations in tasks that require precise
    spatial understanding, such as identifying chessboard positions'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**空间分析**: 该模型在需要精确空间理解的任务中存在局限性，例如识别棋盘位置'
- en: '**Accuracy**: In certain contexts, it might generate incorrect image descriptions
    or captions'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**准确性**: 在某些情况下，它可能会生成不正确的图像描述或标题'
- en: '**Unusual image formats**: Challenges arise with panoramic and fisheye photographs'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**不寻常的图像格式**: 全景和鱼眼照片会带来挑战'
- en: '**Metadata and image resizing**: Original filenames and metadata are not processed,
    and images undergo resizing which alters their original dimensions'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**元数据和图像缩放**: 原始文件名和元数据不会被处理，图像经过缩放，这会改变其原始尺寸'
- en: '**Object counting**: The model may only provide approximate counts of items
    in an image'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对象计数**: 模型可能只能提供一个图像中项目的近似计数'
- en: '**CAPTCHAs**: Due to safety measures, CAPTCHA submissions are blocked'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**CAPTCHAs**：由于安全措施，CAPTCHA提交被阻止'
- en: Moving past GPT-4V’s limitations, we expect future models, such as GPT-5, to
    offer better features for interaction and smarter reasoning, leading to more creative
    and useful applications. Anticipated improvements include a deeper understanding
    of language and context, advanced multimodal capabilities for interacting with
    various types of content, and enhanced reasoning for complex problem-solving.
    Furthermore, GPT-5 is likely to offer more precise customization options, demonstrate
    a significant reduction in biases for more ethical responses, and possess an expanded
    knowledge base that remains current with the latest information, ensuring more
    accurate and relevant outputs across a wide array of applications.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 超越GPT-4V的限制，我们预计未来的模型，如GPT-5，将提供更好的交互和智能推理功能，从而带来更多创造性和有用的应用。预期的改进包括对语言和上下文的更深入理解、与各种类型内容交互的先进多模态能力以及复杂问题解决的增强推理能力。此外，GPT-5可能提供更多精确的定制选项，显著减少偏见以实现更道德的响应，并拥有一个与最新信息保持同步的扩展知识库，确保在各种应用中提供更准确和相关的输出。
- en: Video generation models – a far-fetched dream?
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 视频生成模型——一个遥远的梦想？
- en: 'The first wave of generative AI marked remarkable advancements in text-to-text
    and text-to-image models, bringing photorealistic images to the forefront. Models
    such as DALL-E have continually enhanced their capabilities, producing increasingly
    lifelike images. The next leap forward, anticipated in the near future, lies in
    video generation models that include text-to-video, image-to-video, and audio-to-video,
    a progression hinted at in 2023\. The text-to-video conversion process faces significant
    challenges, including the following:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI的第一波浪潮标志着文本到文本和文本到图像模型取得了显著进步，将逼真的图像推到了前沿。例如，DALL-E等模型不断增强了其功能，产生了越来越逼真的图像。预计在不久的将来，下一个飞跃将在于视频生成模型，包括文本到视频、图像到视频和音频到视频，这在2023年有所暗示。文本到视频转换过程面临重大挑战，包括以下方面：
- en: Computational demands for ensuring spatial and temporal frame consistency. Hence,
    training such models becomes unaffordable for most researchers.
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保空间和时间帧一致性的计算需求。因此，对于大多数研究人员来说，训练此类模型变得不可负担。
- en: A lack of quality in multi-modal datasets for training the models.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练模型的多模态数据集质量不足。
- en: The complexity of effectively describing videos for the models to learn. This
    often requires a series of detailed prompts or narratives.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于模型学习来说，有效描述视频的复杂性。这通常需要一系列详细的提示或叙述。
- en: Although there have been some limitations with these models, we have seen some
    continual progress in video generation techniques such as GANs, Variational Auto
    Encoders, Transformers, and Stable Diffusion. Some popular video generation models
    have been released by organizations such as Runway ML, Stable Video Diffusion
    by Stability AI, Moonshot by Salesforce, and Google’s VideoPoet.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这些模型存在一些局限性，但我们已经看到在视频生成技术方面，如GANs、变分自编码器、Transformers和Stable Diffusion等技术上取得了一些持续进步。Runway
    ML、Stability AI的Stable Video Diffusion、Salesforce的Moonshot以及Google的VideoPoet等组织已经发布了一些流行的视频生成模型。
- en: SORA, from OpenAI, is the most recent one with complex scene generation and
    advanced language comprehension capabilities. We provided more details on this
    model in [*Chapter 1*](B21443_01.xhtml#_idTextAnchor015).
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 来自OpenAI的SORA是最新的一个，具有复杂场景生成和高级语言理解能力。我们已在[*第一章*](B21443_01.xhtml#_idTextAnchor015)中提供了更多关于此模型的信息。
- en: Video generation models possess profound capabilities, with the potential to
    influence society, especially as they evolve and mature. This influence becomes
    particularly critical during election seasons, where the information landscape
    can shape public opinion and democratic outcomes significantly. However, this
    power also carries the risk of severe consequences if not implemented responsibly.
    Consequently, it’s imperative to establish robust ethical guidelines and safeguards,
    especially during sensitive periods such as elections, to ensure that these technologies
    are used in a manner that is beneficial and does not undermine the integrity of
    democratic processes.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 视频生成模型具有深远的能力，有可能影响社会，尤其是在它们发展和成熟的过程中。这种影响在选举季节尤其关键，因为信息景观可以显著塑造公众舆论和民主结果。然而，如果不负责任地实施，这种力量也带来了严重后果的风险。因此，在选举等敏感时期建立稳健的伦理准则和安全措施至关重要，以确保这些技术以有益的方式使用，不损害民主过程的完整性。
- en: Can AI smell?
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AI能闻气味吗？
- en: 'We have learned that AI can hear, see, and speak. But can AI smell too? Recent
    research in the field of AI has shown significant progress in AI’s ability to
    “smell.” Various studies have explored how AI can analyze and interpret odors,
    a task that’s traditionally been challenging due to the complexity and subjective
    nature of olfaction:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经了解到AI可以听、看和说话。但AI也能闻气味吗？最近在AI领域的科研进展表明，AI的“闻”气味能力取得了显著进步。各种研究探讨了AI如何分析和解释气味，这是一个由于嗅觉的复杂性和主观性质而传统上具有挑战性的任务：
- en: '**AI model outperforms humans in describing odors**: A study demonstrated that
    an AI model was more accurate than human panelists in predicting the smell of
    different molecules. The model was particularly effective at identifying pairs
    of structurally dissimilar molecules that had similar smells, as well as characterizing
    a variety of odor properties, such as odor strength, for a large number of potential
    scent molecules. [https://techxplore.com/news/2023-08-closer-digitizing-odors-human-panelists.html](https://techxplore.com/news/2023-08-closer-digitizing-odors-human-panelists.html).'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AI模型在描述气味方面优于人类**：一项研究表明，AI模型在预测不同分子的气味方面比人类评审团更准确。该模型在识别具有相似气味的结构上不相似的分子对方面特别有效，以及为大量潜在香料分子表征各种气味特性，如气味强度。[https://techxplore.com/news/2023-08-closer-digitizing-odors-human-panelists.html](https://techxplore.com/news/2023-08-closer-digitizing-odors-human-panelists.html).'
- en: '**AI in detecting illnesses through breath analysis**: Laboratories have been
    using machines such as **gas-chromatography mass-spectrometers** (**GC-MSs**)
    to detect substances in the air, including volatile organic compounds present
    in human breath. These compounds can indicate various illnesses, including cancers.
    AI, particularly deep learning networks, is being adapted to analyze these compounds
    more efficiently, significantly speeding up the process of identifying specific
    patterns in breath samples that indicate certain diseases. [https://www.smithsonianmag.com/innovation/artificial-intelligence-may-be-able-to-smell-illnesses-in-human-breath-180969286/](https://www.smithsonianmag.com/innovation/artificial-intelligence-may-be-able-to-smell-illnesses-in-human-breath-180969286/)'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**通过呼吸分析检测疾病中的AI**：实验室一直在使用如**气相色谱质谱联用仪**（GC-MSs）等机器来检测空气中的物质，包括存在于人类呼吸中的挥发性有机化合物。这些化合物可以指示各种疾病，包括癌症。AI，尤其是深度学习网络，正在被用于更有效地分析这些化合物，显著加快了识别呼吸样本中指示特定疾病的特定模式的过程。[https://www.smithsonianmag.com/innovation/artificial-intelligence-may-be-able-to-smell-illnesses-in-human-breath-180969286/](https://www.smithsonianmag.com/innovation/artificial-intelligence-may-be-able-to-smell-illnesses-in-human-breath-180969286/)'
- en: '**Artificial networks learning to smell like the brain**: Research at MIT has
    involved building an artificial smell network inspired by the fruit fly’s olfactory
    system. This network, comprising an input layer, a compression layer, and an expansion
    layer, mirrors the structure of the fruit fly’s olfactory system. The network
    was able to organize itself and process odor information in a manner strikingly
    similar to the fruit fly brain, demonstrating AI’s potential to mimic biological
    olfactory systems. [https://news.mit.edu/2021/artificial-networks-learn-smell-like-the-brain-1018](https://news.mit.edu/2021/artificial-networks-learn-smell-like-the-brain-1018).'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**人工神经网络学习像大脑一样闻气味**：麻省理工学院的研究涉及构建一个受果蝇嗅觉系统启发的模拟嗅觉网络。这个网络由输入层、压缩层和扩展层组成，与果蝇嗅觉系统的结构相呼应。该网络能够自行组织并处理气味信息，其方式与果蝇大脑惊人地相似，展示了AI模仿生物嗅觉系统的潜力。[https://news.mit.edu/2021/artificial-networks-learn-smell-like-the-brain-1018](https://news.mit.edu/2021/artificial-networks-learn-smell-like-the-brain-1018).'
- en: '**AI “nose” predicts smells from molecular structures**: AI technology has
    been developed to predict the smell of chemicals based on their molecular structures.
    This advancement is significant as it opens up the possibility of designing new
    synthetic scents and provides insights into how the human brain interprets smell.
    [https://phys.org/news/2023-09-ai-nose-molecular.html](https://phys.org/news/2023-09-ai-nose-molecular.html).'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AI “鼻子”预测分子结构中的气味**：AI技术已被开发出来，可以根据化学物质的分子结构预测其气味。这一进步意义重大，因为它开辟了设计新型合成香料和深入了解人类大脑如何解释气味的可能性。[https://phys.org/news/2023-09-ai-nose-molecular.html](https://phys.org/news/2023-09-ai-nose-molecular.html).'
- en: '**Training AI to understand and map odors**: Researchers have trained a neural
    network with thousands of compounds and corresponding smell labels from perfumery
    databases. The AI was able to create a “principal odor map” that visually shows
    the relationships between different smells. When tested, the AI’s predictions
    of how a new molecule would smell were found to be more accurate than those of
    human panelists. [https://www.popsci.com/science/teach-ai-how-to-smell/](https://www.popsci.com/science/teach-ai-how-to-smell/).'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练AI理解和绘制气味**：研究人员使用来自香水数据库的数千种化合物及其相应的气味标签训练了一个神经网络。该AI能够创建一个“主要气味图”，直观地展示不同气味之间的关系。测试结果显示，AI对新分子气味的预测比人类评审团更为准确。[https://www.popsci.com/science/teach-ai-how-to-smell/](https://www.popsci.com/science/teach-ai-how-to-smell/)'
- en: This section primarily focused on multimodal capabilities and how they will
    enhance our communication with AI as these capabilities mature. In the next section,
    we will discuss how these multimodal capabilities can foster creativity and innovation
    within industry-specific, generative AI applications.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 本节主要关注多模态能力及其如何随着这些能力的成熟而增强我们与AI的沟通。在下一节中，我们将讨论这些多模态能力如何能够在行业特定的生成式AI应用中促进创造力和创新。
- en: Industry-specific generative AI apps
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 行业特定的生成式AI应用
- en: 'We can anticipate a sustained surge in sector-specific generative AI applications,
    heralding a wave of remarkable advancements and innovations across industries:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以预见行业特定的生成式AI应用将持续激增，预示着跨行业将出现一系列显著的发展和革新：
- en: '**AI in art, music, and cinema**: Generative AI is revolutionizing the realms
    of music, art, movies, and literature by fostering innovative creation, personalized
    experiences, and broader accessibility. In music, the maturity of audio generation
    models is transforming composition, production, and performance, offering tailored
    listening experiences and enabling new forms of interactive and virtual performances.
    In art, AI is a collaborator in generating unique visual works through image generation
    models. In literature, AI aids in writing, editing, and exploring new narrative
    forms, while also making literary works more accessible through advanced translation
    and localization. This integration of AI into creative domains is not just reshaping
    existing paradigms but is also unlocking unprecedented avenues for creative expression
    and cultural exchange.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**艺术、音乐和电影领域的AI**：生成式AI通过促进创新创作、个性化体验和更广泛的可访问性，正在音乐、艺术、电影和文学领域引发革命。在音乐领域，音频生成模型的成熟正在改变创作、制作和表演，提供定制的听觉体验，并使新的互动和虚拟表演形式成为可能。在艺术领域，AI通过图像生成模型成为生成独特视觉作品的合作伙伴。在文学领域，AI在写作、编辑和探索新的叙事形式方面提供帮助，同时通过高级翻译和本地化使文学作品更加易于获取。这种AI在创意领域的整合不仅正在重塑现有范式，而且正在开启前所未有的创意表达和文化交流的新途径。'
- en: '**AI in finance**: Generative AI is set to revolutionize the finance sector
    by enabling highly personalized services, automating trading and investment strategies,
    enhancing risk management, and improving fraud detection. Its advanced analytics
    will streamline regulatory compliance and revolutionize customer service through
    intelligent chatbots. An example is BloombergGPT, a 50 billion parameter LLM built
    ground-up just for finance.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**金融领域的AI**：生成式AI通过提供高度个性化的服务、自动化交易和投资策略、增强风险管理以及提高欺诈检测，有望彻底改变金融行业。其高级分析将简化合规监管并通过智能聊天机器人革新客户服务。例如，BloombergGPT是一个从头开始构建的50亿参数的大型语言模型（LLM），专为金融行业设计。'
- en: '**AI in education**: Generative AI, particularly through the rise of multimodal
    LLMs, is substantially enhancing the education landscape by creating highly customized
    and interactive learning experiences. These advanced AI models are adept at generating
    dynamic educational content, providing personalized tutoring, and adapting to
    individual learning styles and needs. For instance, platforms such as Khan Academy
    are at the forefront of this transformative wave, as evidenced by their Khanmigo
    App, which leverages generative AI to offer tailored educational experiences.
    This integration of multimodal LLMs and their advanced reasoning capabilities
    in education is not only automating administrative tasks and optimizing curriculum
    development but is also pioneering a more engaging, inclusive, and student-focused
    approach to learning, promising a future where education is deeply personalized,
    interactive, and accessible to all.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**人工智能在教育中的应用**：生成式人工智能，尤其是多模态大型语言模型（LLMs）的兴起，通过创造高度定制和互动的学习体验，极大地改善了教育格局。这些先进的AI模型擅长生成动态的教育内容，提供个性化的辅导，并适应个人的学习风格和需求。例如，可汗学院是这一变革浪潮的先锋，其Khanmigo应用程序就是利用生成式人工智能提供定制化的教育体验。这种多模态LLMs及其在教育中的高级推理能力的集成不仅自动化了行政任务和优化课程开发，而且开创了一种更吸引人、更具包容性和以学生为中心的学习方法，预示着一个教育将深刻个性化、互动并面向所有人的未来。'
- en: '**AI in scientific research and innovation**: Generative AI will continue to
    revolutionize scientific research and innovation by accelerating drug discovery,
    enhancing genomic analysis, and improving the precision of experiments across
    various disciplines. Its powerful data analysis and pattern recognition capabilities
    are unlocking new insights in complex fields such as astrophysics and climate
    science, while predictive modeling aids in designing sustainable systems. By automating
    routine tasks and fostering interdisciplinary collaboration, Gen AI is significantly
    enhancing efficiency and creativity in scientific endeavors, heralding a new era
    of accelerated discovery and advanced innovation.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**人工智能在科学研究与创新中**：生成式人工智能将继续通过加速药物发现、增强基因组分析和提高各学科实验的精确度，革命性地改变科学研究与创新。其强大的数据分析能力和模式识别能力正在解锁复杂领域如天体物理学和气候科学的新见解，而预测建模有助于设计可持续系统。通过自动化常规任务和促进跨学科合作，通用人工智能显著提高了科学事业中的效率和创造力，预示着一个加速发现和高级创新的新时代。'
- en: '**AI in communication/translation**: Advancements in audio generation will
    facilitate real-time, accurate translation and enable seamless communication across
    different languages and cultures. This will also give rise to AI avatars that
    will be able to understand and talk to you in different languages and will be
    an integral part of consumer applications.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**人工智能在通信/翻译中的应用**：音频生成的进步将促进实时、准确的翻译，并使不同语言和文化之间的无缝沟通成为可能。这将还会催生能够用不同语言理解和与你交谈的AI头像，并将成为消费者应用的重要组成部分。'
- en: '**AI in gaming**: Generative AI will be able to create more dynamic, immersive
    environments and enhance **non-player character** (**NPC**) behavior, leading
    to more engaging and unpredictable gameplay. It personalizes experiences by adapting
    to individual player actions and preferences and introduces advanced technologies
    such as voice and facial recognition for more intuitive interactions. Additionally,
    AI will continue to streamline game development, enforcing fair play through cheating
    detection, and making gaming more accessible and globally connected through assistive
    features and real-time translation. These advancements will not only elevate the
    player experience but also transform how games are designed and developed, signaling
    a new era in the gaming world where each interaction is more interactive, inclusive,
    and personalized.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**人工智能在游戏中的应用**：生成式人工智能将能够创建更动态、沉浸式的环境，并增强**非玩家角色**（NPC）的行为，从而带来更吸引人和不可预测的游戏体验。它通过适应个别玩家的行动和偏好来个性化体验，并引入语音和面部识别等先进技术以实现更直观的交互。此外，人工智能将继续简化游戏开发，通过作弊检测来确保公平竞争，并通过辅助功能和实时翻译使游戏更具可访问性和全球连接性。这些进步不仅将提升玩家的体验，还将改变游戏的设计和开发方式，标志着游戏世界进入一个新纪元，其中每一次交互都更加互动、包容和个性化。'
- en: '**AI in healthcare and medical research**: Generative AI will continue to revolutionize
    healthcare by personalizing medicine, enhancing diagnostic accuracy, and accelerating
    drug discovery, leading to more effective and targeted treatments. It leverages
    predictive analytics for proactive healthcare management and assists in precise,
    robot-assisted surgeries. AI-powered medical copilots, virtual health assistants,
    and wearable devices provide continuous patient monitoring and support, while
    also democratizing access to healthcare services. Furthermore, AI enhances medical
    training by simulating realistic clinical scenarios, preparing professionals for
    various situations. These advancements signify a transformative shift in healthcare
    toward a future where treatments are not only more personalized and precise but
    also more accessible and preventive, fundamentally improving patient outcomes
    and healthcare efficiency.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**医疗和医学研究中的AI**：生成式AI将继续通过个性化医疗、提高诊断准确性和加速药物发现来革新医疗保健，从而带来更有效和有针对性的治疗方案。它利用预测分析进行主动医疗保健管理，并协助进行精确的、机器人辅助的手术。AI驱动的医疗共飞行员、虚拟健康助手和可穿戴设备提供持续的患者监测和支持，同时使医疗保健服务更加民主化。此外，AI通过模拟真实的临床场景，为专业人士准备各种情况，从而增强医学培训。这些进步标志着医疗保健向一个未来的转变，在这个未来中，治疗方案不仅更加个性化和精确，而且更加易于获取和预防，从根本上改善患者结果和医疗保健效率。'
- en: BioGPT
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: BioGPT
- en: BioGPT, a tailored language model, is meticulously pre-trained on biomedical
    literature, equipping it with a profound comprehension of medical and biological
    concepts and terminology. Its purpose is to support a variety of biomedical NLP
    tasks, including answering medical queries and summarizing research articles,
    by offering precise, contextually relevant insights. The field is poised for further
    innovation, with specialized LLMs such as BioGPT simplifying the intricacies of
    medical research.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: BioGPT，一个定制的语言模型，在生物医学文献上进行了精心预训练，使其具备对医学和生物概念及术语的深刻理解。其目的是通过提供精确、上下文相关的见解，支持各种生物医学NLP任务，包括回答医学查询和总结研究文章。该领域正处于进一步创新的边缘，专门的LLM如BioGPT简化了医学研究的复杂性。
- en: '**AI in consumer applications**: Generative AI will continue to revolutionize
    consumer applications by offering highly personalized and intuitive experiences
    across various domains. It will power personalized shopping recommendations, smart
    home automation, and customized entertainment content, enhancing user engagement
    and convenience. AI-driven chatbots improve customer service, while interactive
    gaming and personalized health and fitness apps cater to individual preferences
    and lifestyles. Moreover, AI facilitates seamless language translation and enables
    businesses to analyze consumer data for targeted marketing and product development.
    This transformative technology will continue to reimagine consumer interactions,
    making them more engaging, efficient, and tailored to individual needs.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**消费者应用中的AI**：生成式AI将继续通过在各个领域提供高度个性化和直观的体验来革新消费者应用。它将为个性化购物推荐、智能家居自动化和定制娱乐内容提供动力，增强用户参与度和便利性。AI驱动的聊天机器人改善客户服务，而互动游戏和个性化的健康与健身应用满足个人偏好和生活方式。此外，AI促进无缝语言翻译，并使企业能够分析消费者数据以进行针对性的营销和产品开发。这种变革性技术将继续重新构想消费者互动，使它们更加引人入胜、高效，并针对个人需求。'
- en: 'In this section, we delved into a select few of the countless industries on
    the brink of transformation due to the emergence of generative AI. Although this
    only scratches the surface of potential applications, the influence of generative
    AI is unmistakably substantial and holds the promise of ushering in an era of
    significant evolution and innovation across various sectors. Nonetheless, it’s
    crucial to acknowledge and address the apprehensions surrounding job displacement
    attributed to AI advancements. The writers’ strike of 2023 serves as a notable
    example, highlighting the growing concern among professionals about AI potentially
    encroaching on their roles. (*TV’s war with a robot is already here*: [https://tinyurl.com/yvdw5h3y](https://tinyurl.com/yvdw5h3y)).
    It’s imperative for society to engage in thoughtful discourse on these ethical
    dilemmas and to establish robust frameworks that strike a harmonious balance between
    fostering innovation and mitigating the impact on employment.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们深入探讨了由于生成式 AI 的出现而即将发生变革的无数行业中的少数几个。尽管这仅仅触及了潜在应用的表面，但生成式 AI 的影响无疑是巨大的，并预示着在各个领域带来重大变革和创新的时代的到来。尽管如此，承认并解决因
    AI 进步而导致的就业岗位流失的担忧至关重要。2023 年的作家罢工是一个值得注意的例子，突显了专业人士对 AI 可能侵犯其角色的日益增长的担忧。（*电视与机器人的战争已经到来*：[https://tinyurl.com/yvdw5h3y](https://tinyurl.com/yvdw5h3y)）。社会必须就这些伦理困境进行深思熟虑的讨论，并建立强大的框架，在促进创新和减轻对就业的影响之间取得和谐平衡。
- en: The rise of small language models (SLMs)
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 小型语言模型（SLMs）的兴起
- en: Following the popularity of LLMs, we have seen a rise in SLMs. Researchers began
    exploring SLMs as a response to the challenges posed by their larger counterparts.
    While large models offer impressive performance, they also bring substantial demands
    in terms of computational resources, energy consumption, and data requirements.
    These factors limit accessibility and practicality, especially for individuals
    and organizations with constrained resources.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 随着大型语言模型（LLMs）的流行，我们看到了 SLMs 的兴起。研究人员开始探索 SLMs 作为对更大模型带来的挑战的回应。虽然大型模型提供了令人印象深刻的性能，但它们也带来了对计算资源、能源消耗和数据需求的大量需求。这些因素限制了可访问性和实用性，尤其是对于资源有限的个人和组织。
- en: The architecture of SLMs is fundamentally similar to that of LLMs, with both
    based on the transformer architecture (for example, Llama). The differences mainly
    lie in the scale and some specific optimizations tailored to their respective
    use cases. Language models in the range of millions and the order of 10 billion
    parameters or less are considered to be SLMs. They are streamlined versions of
    language models that are designed to deliver a balance between performance and
    efficiency. Unlike their larger counterparts, SLMs require significantly less
    computational power and data to train and run, making them more accessible, lower
    cost to build, and environmentally friendly.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: SLMs 的架构在本质上与 LLMs 相似，两者都基于 Transformer 架构（例如，Llama）。差异主要在于规模和一些针对各自用例的特定优化。参数数量在数百万到数十亿或更少的语言模型被认为是
    SLMs。它们是专为在性能和效率之间提供平衡而设计的语言模型的精简版。与更大的模型相比，SLMs 需要显著更少的计算能力和数据来训练和运行，这使得它们更易于访问、建设成本更低，并且对环境友好。
- en: Examples of SLMs include Tiny Llama (1.1 B parameters), Llama 2 (7 B parameters),
    Orca-2 (7B, 13B parameters) and Phi-2 (2.7B parameters), Mistral (7B parameters),
    and Falcon-7B, and each offers a unique trade-off between size, speed, and performance.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: SLMs 的例子包括 Tiny Llama（1.1 B 参数）、Llama 2（7 B 参数）、Orca-2（7B，13B 参数）和 Phi-2（2.7B
    参数）、Mistral（7B 参数）、Falcon-7B，每个都提供了大小、速度和性能之间的独特权衡。
- en: Phi-2, an open source model developed by Microsoft, trained in textbook quality
    data, sets a new standard in performance efficiency, outshining models tenfold
    its size across a range of popular benchmarks. This model showcases greater proficiency
    in areas such as commonsense reasoning, language understanding, mathematical problem-solving,
    and coding!
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: Phi-2 是微软开发的开源模型，在教科书质量的数据上进行训练，在性能效率方面设定了新的标准，在一系列流行的基准测试中超越了其十倍大小的模型。该模型在常识推理、语言理解、数学问题解决和编码等领域表现出更高的熟练度！
- en: 'Let’s look at the benefits of SLMs:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看 SLMs 的好处：
- en: '**Efficiency**: SLMs, with their fewer parameters, offer notable computational
    advantages over larger models such as GPT-3\. They provide quicker inference speeds,
    demand less memory and storage, and use smaller datasets for training compared
    to larger models.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**效率**：SLMs（稀疏语言模型）由于其参数较少，在计算效率上比GPT-3等大型模型具有显著优势。它们提供更快的推理速度，需要更少的内存和存储空间，并且与大型模型相比，使用更小的数据集进行训练。'
- en: '**Fine-tunable**: SLMs can be easily tailored to specific domains and specialized
    uses.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可微调**：SLMs可以轻松地调整到特定领域和专业用途。'
- en: '**Easy access**: Since they are often open source, they democratize access
    to advanced NLP capabilities, allowing a broader range of users and developers
    to incorporate sophisticated language understanding into their applications.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**易于访问**：由于它们通常是开源的，因此它们使高级NLP能力民主化，允许更广泛的用户和开发者将复杂的语言理解集成到他们的应用程序中。'
- en: '**Deployment on the edge**: Additionally, the reduced resource requirements
    of SLMs make them ideal for deployment in edge computing scenarios – offline mode
    and on devices with limited processing capabilities.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**在边缘部署**：此外，SLMs的资源需求减少使它们非常适合在边缘计算场景中部署——离线模式和在处理能力有限的设备上。'
- en: Moreover, their lower energy consumption contributes to a more sustainable AI
    ecosystem, addressing some of the environmental concerns associated with larger
    models.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，它们较低的能耗有助于构建更可持续的AI生态系统，解决与大型模型相关的一些环境问题。
- en: While SLMs are gaining traction, some are not yet fully developed for production
    use. However, we expect continued enhancements in their efficiency and readiness
    for deployment. Furthermore, SLMs are set to become a core component in edge devices
    such as smartphones and other cutting-edge gadgets. This trend presents an exciting
    segue into the next section, where we’ll delve into the opportunities this technology
    brings to edge devices.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然SLMs正在获得关注，但其中一些尚未完全开发用于生产使用。然而，我们预计它们在效率和部署准备方面的持续改进。此外，SLMs预计将成为智能手机和其他尖端设备等边缘设备的核心组件。这一趋势为下一节提供了一个令人兴奋的过渡，我们将深入探讨这项技术为边缘设备带来的机遇。
- en: Integrating generative AI with intelligent edge devices
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将生成式AI与智能边缘设备集成
- en: 'As we progress into 2024, the fusion of generative AI with intelligent edge
    devices is poised to revolutionize the technology landscape. Examples of edge
    devices include smartphones, tablets, autonomous vehicles, medical devices, wearable
    devices, and IoT devices such as smart thermostats, cameras, and more. SLMs are
    becoming a pivotal component of edge computing, offering a new dimension of smart,
    localized processing. This is because we face challenges with LLMs when they’re
    integrated on edge devices. LLMs need to be optimized before deploying edge devices
    for several reasons:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们进入2024年，生成式AI与智能边缘设备的融合有望彻底改变技术格局。边缘设备的例子包括智能手机、平板电脑、自动驾驶汽车、医疗设备、可穿戴设备和智能恒温器、摄像头等物联网设备。SLMs正成为边缘计算的关键组成部分，为智能、本地化处理提供了新的维度。这是因为当LLMs（大型语言模型）集成到边缘设备时，我们面临着挑战。LLMs在部署边缘设备之前需要优化，原因有以下几点：
- en: '**Limited resources**: Edge devices typically have constrained computational
    resources, including CPU, GPU, memory, and storage. Large models require substantial
    resources for both storage (>500 GB) and computation.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**资源有限**：边缘设备通常具有有限的计算资源，包括CPU、GPU、内存和存储。大型模型在存储（>500 GB）和计算方面都需要大量的资源。'
- en: '**Energy efficiency**: Running large models can consume significant power,
    which is critical for battery-operated devices. Optimizations aim to reduce the
    energy consumption of these models.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**能源效率**：运行大型模型可能会消耗大量电力，这对于电池供电的设备至关重要。优化目标是为了减少这些模型的能源消耗。'
- en: '**Latency**: For real-time applications, it’s crucial to have low latency.
    Large models can lead to slower inference times, so optimizing the model can help
    meet the latency requirements of the application.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**延迟**：对于实时应用，低延迟至关重要。大型模型可能导致较慢的推理时间，因此优化模型可以帮助满足应用的延迟要求。'
- en: '**Bandwidth**: Deploying large models or updating them over the network can
    consume significant bandwidth, which might be limited or costly in some edge environments.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**带宽**：在网络中部署大型模型或更新它们可能会消耗大量带宽，这在某些边缘环境中可能是有限的或昂贵的。'
- en: '**Cost**: Computational resources on edge devices are not only limited but
    also potentially more expensive. Optimizing models can reduce the overall cost
    of deployment and operation.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**成本**：边缘设备上的计算资源不仅有限，而且可能更加昂贵。优化模型可以降低部署和运营的整体成本。'
- en: There are different techniques to achieve this kind of efficiency in LLMs. One
    method, known as “knowledge distillation” or “domain reduction,” trains a smaller
    model to emulate a larger one using less data. Another method, “quantization,”
    shrinks the model size and boosts performance by decreasing the precision of its
    weights and activations, while still maintaining accuracy.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在LLMs中实现这种效率有不同的技术。一种方法被称为“知识蒸馏”或“领域缩减”，通过使用更少的数据训练一个较小的模型来模仿一个较大的模型。另一种方法，“量化”，通过降低其权重和激活的精度来缩小模型大小并提高性能，同时仍保持准确性。
- en: A device named Rabbit R1, which was announced at CES this year, a 2.88-inch
    touchscreen is an early example of the integration of generative AI on edge devices.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 一款名为Rabbit R1的设备，今年在CES上发布，2.88英寸的触摸屏是边缘设备上集成生成式AI的早期例子。
- en: More important emerging trends and 2024–2025 predictions
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更重要的新兴趋势和2024-2025年的预测
- en: 'The following trends and predictions are derived from our comprehensive research
    and experience, as well as insights shared by leading industry experts:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 以下趋势和预测来源于我们全面的研究和经验，以及行业领先专家分享的见解：
- en: '**LLMs optimized for structured data**: LLMs excel in comprehending and generating
    natural language text, benefiting from extensive training on diverse textual sources,
    such as books and web pages. Yet, their proficiency in interpreting structured,
    tabular data remains less developed. Nevertheless, this domain is witnessing burgeoning
    research, with promising advancements anticipated in 2024 and beyond. A notable
    initiative in this trajectory is Table-GPT by Microsoft, which signifies a concerted
    effort to enhance LLMs’ capabilities in processing tabular data by specifically
    fine-tuning them on such datasets ([https://arxiv.org/abs/2310.09263](https://arxiv.org/abs/2310.09263)).'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**针对结构化数据的LLMs优化**：LLMs在理解和生成自然语言文本方面表现出色，得益于对书籍和网页等多样化文本来源的广泛训练。然而，它们在解释结构化、表格数据方面的能力仍不够发达。尽管如此，这一领域正在见证研究蓬勃发展，预计2024年及以后将出现令人期待的发展。微软的Table-GPT是一个值得注意的举措，它标志着共同努力通过在特定数据集上微调来增强LLMs处理表格数据的能力（[https://arxiv.org/abs/2310.09263](https://arxiv.org/abs/2310.09263)）。'
- en: '**Maturity of LLMOps**: In 2023, the focus was predominantly on developing
    and transitioning **Proof of Concepts** (**PoCs**) into production environments.
    As we progress, the emphasis will shift toward refining and streamlining **large
    language model operations** (**LLMOps**) by leveraging automation and enhancing
    efficiency. This next phase is poised to attract increased investment from organizations,
    signaling a commitment to optimize and scale the operational aspects of these
    advanced AI systems.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LLMOps的成熟**：2023年，重点主要在于开发和将**概念验证**（**PoCs**）过渡到生产环境。随着我们继续前进，重点将转向通过利用自动化和提升效率来精炼和简化**大型语言模型操作**（**LLMOps**）。这一下一阶段预计将吸引来自组织的更多投资，这标志着对这些先进AI系统操作方面进行优化和扩展的承诺。'
- en: '**Building products with Agentive AI**: In [*Chapter 6*](B21443_06.xhtml#_idTextAnchor117),
    we delved into frameworks for autonomous agents, such as Autogen, and explored
    groundbreaking research and applications in this arena. These innovative developments
    showcase AI systems autonomously interacting and executing tasks. As we move from
    2024 and the years that follow, we anticipate a surge in products that integrate
    agentive actions, marking a significant evolution in how AI enhances user productivity.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**构建具有Agentive AI的产品**：在[*第6章*](B21443_06.xhtml#_idTextAnchor117)中，我们探讨了自主代理的框架，如Autogen，并探索了这一领域的开创性研究和应用。这些创新进展展示了AI系统自主交互和执行任务的能力。随着我们进入2024年和以后的年份，我们预计将出现大量集成agentive动作的产品，标志着AI增强用户生产力的重大演变。'
- en: '**Increasing context window**: We can expect ongoing progress in the realm
    of context window capabilities. Google recently unveiled the Gemini 1.5 model,
    which boasts an impressive context window of 1 million tokens.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**增加上下文窗口**：我们预计在上下文窗口能力领域将持续取得进展。谷歌最近推出了Gemini 1.5模型，它拥有令人印象深刻的100万个token的上下文窗口。'
- en: '**More AI-generated influencers**: The popularity of virtual AI avatars is
    growing, as seen with figures such as Lil Miquela on Instagram, who has millions
    of followers and partnerships with big brands such as Chanel, Prada, and Calvin
    Klein, despite being a digital creation. We will continue to see more AI influencers
    gain popularity in the future.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**更多AI生成的影响者**：随着像Instagram上的Lil Miquela这样的虚拟AI形象越来越受欢迎，我们可以看到这一趋势，尽管她是一个数字创作，但她拥有数百万的追随者，并与香奈儿、普拉达和卡尔文·克莱恩等大品牌建立了合作关系。我们预计未来将看到更多AI影响者获得人气。'
- en: '**Real-time AI**: Real-time AI matters a lot for user experience. As compute
    prices start to go down, we will see evolving LLM architectures that produce faster
    responses. An example we saw in 2023 was Krea AI’s real-time image transfer.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实时AI**：实时AI对用户体验至关重要。随着计算价格的下降，我们将看到不断发展的LLM架构，它们能够产生更快的响应。2023年我们看到的一个例子是Krea
    AI的实时图像传输。'
- en: '**The rise of open source models**: We anticipate a growing trend in the adoption
    of open source models. However, industry leaders maintain that closed source models
    will likely maintain their edge in performance. This perspective is rooted in
    the challenges associated with managing open source models, particularly the potential
    for increased maintenance demands and security or privacy vulnerabilities that
    may arise from untimely community-driven updates.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**开源模型的兴起**：我们预计开源模型的采用趋势将不断增长。然而，行业领导者认为，封闭源代码模型可能会在性能上保持优势。这种观点源于管理开源模型所面临的挑战，特别是由于社区驱动的更新不及时而可能出现的维护需求增加、安全或隐私漏洞等问题。'
- en: '**Better embedding models**: We will continue to witness advancements in embedding
    models that incorporate multimodality with higher dimensions, meaning they will
    also be capable of embedding images to enhance image search functionalities. The
    increasing number of dimensions signifies data representation in a richer format,
    capturing more intricate nuances within the data and yielding improved retrieval
    performance.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**更好的嵌入模型**：我们将继续见证嵌入模型的进步，这些模型结合了多模态和更高维度，这意味着它们也将能够嵌入图像以增强图像搜索功能。维度的增加意味着以更丰富的格式表示数据，捕捉数据中的更多细微差别，从而提高检索性能。'
- en: '**Rising deepfake threats**: The proliferation of deepfake technology poses
    a substantial threat to the integrity of upcoming elections as it enables the
    creation of convincingly altered media. It’s crucial for individuals to critically
    assess and verify information sources, especially during such pivotal times, to
    ensure that what they perceive as true is not a product of sophisticated manipulation.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**日益增长的深度伪造威胁**：深度伪造技术的普及对即将到来的选举的完整性构成了重大威胁，因为它使得创建令人信服的媒体变得可能。在如此关键的时刻，个人对信息来源进行批判性评估和验证至关重要，以确保他们所认为的真相不是复杂操纵的产物。'
- en: '**Compute continues to be precious**: Nvidia’s expansion in 2023 was remarkable,
    primarily fueled by the soaring demand for its chips among major cloud computing
    giants such as Microsoft, Amazon, and Google. Looking ahead, it’s anticipated
    that these conglomerates will shift toward manufacturing their chips internally.
    This strategic pivot aims to diminish dependency on third-party suppliers and
    enhance their capability to meet the burgeoning demand for AI applications among
    their clientele. We have already started seeing this trend.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**计算依然宝贵**：2023年英伟达的扩张引人注目，主要得益于其对微软、亚马逊和谷歌等主要云计算巨头芯片需求的激增。展望未来，预计这些企业集团将转向内部制造芯片。这一战略转变旨在减少对第三方供应商的依赖，并增强它们满足客户对AI应用日益增长需求的能力。我们已经开始看到这一趋势。'
- en: '**Regulations**: As highlighted in [*Chapter 9*](B21443_09.xhtml#_idTextAnchor184),
    the passage of executive orders in the US, EU, India, and other nations marks
    a significant turn toward stricter regulation in the AI sector. We can expect
    more defined and stringent regulatory frameworks to emerge, shaping the future
    of AI development and deployment.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**法规**：如[第9章](B21443_09.xhtml#_idTextAnchor184)所述，美国、欧盟、印度和其他国家行政命令的通过标志着向更严格AI行业监管的重大转变。我们可以期待出现更多明确和严格的监管框架，塑造AI开发和部署的未来。'
- en: '**Digital Copilots**: Microsoft has been at the forefront of the copilot revolution.
    Copilots are digital assistants, a conversational interface that has become an
    integral part of every product in the Microsoft Stack. A prime example is GitHub
    Copilot, which has not only enhanced developers’ coding efficiency but also reshaped
    the coding paradigm by providing code autocompletion, troubleshooting, and generation
    capabilities, thereby amplifying developer productivity exponentially. The horizon
    looks even more promising as these digital assistants are poised to become fundamental
    components of an expanding array of SaaS offerings across various industries.
    This evolution will be characterized by the integration of multimodal capabilities
    and the emergence of autonomous agents capable of executing tasks, interfacing
    with both internal databases and external applications, and harnessing internet
    data to deliver unparalleled efficiency and innovation.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数字副驾驶**：微软一直处于副驾驶革命的尖端。副驾驶是数字助手，一种对话界面，已成为微软产品堆栈中每个产品的核心部分。一个典型的例子是GitHub
    Copilot，它不仅提高了开发者的编码效率，还通过提供代码自动补全、故障排除和生成功能，重塑了编码范式，从而极大地提高了开发者的生产力。随着这些数字助手有望成为各行各业SaaS产品中扩展数组的基本组成部分，前景看起来更加光明。这一演变将由多模态功能的集成和出现能够执行任务、与内部数据库和外部应用程序交互以及利用互联网数据提供无与伦比的效率和创新的自主代理的特点所定义。'
- en: '**Advancements in brain-machine interfaces (BMIs)**: BMIs such as Neuralink
    will get a boost. They utilize AI to decode and interpret complex neural signals,
    enabling the translation of brain activity into actionable commands for computers
    or prosthetic devices. This technology promises enhanced mobility and communication
    for individuals with physical disabilities, offering a seamless integration between
    human intention and machine action.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**脑机接口（BMI）的进步**：Neuralink等BMI将得到推动。它们利用人工智能解码和解释复杂的神经信号，使大脑活动能够转化为对计算机或假肢设备的可执行命令。这项技术承诺为身体残疾的个人提供增强的移动性和沟通能力，实现人类意图与机器动作的无缝集成。'
- en: '**Robotic AI/robotic process automation (RPA)**: We will continue to witness
    advancements in robotic systems through the integration of LLMs that further enhance
    their reasoning capabilities. Tesla unveiled its humanoid robot, Optimus, in 2022\.
    Since then, remarkable improvements have been observed in the robot. It is now
    capable of picking up objects and folding shirts. Similarly, Amazon is experimenting
    with robots in its warehouses to move items, a development that is quite impressive.
    This demonstrates the physical ingenuity of modern robots and their potential
    to assist humans in repetitive, tedious, and mundane tasks. While robotics and
    AI have been deeply intertwined, we’ll see compelling advancements through the
    continued integration of RPA technology and generative AI:'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**机器人人工智能/机器人流程自动化（RPA）**：我们将继续见证通过集成LLMs（大型语言模型）来进一步增强其推理能力的机器人系统的进步。特斯拉在2022年揭幕了其人形机器人Optimus。从那时起，机器人在各方面都取得了显著的进步。现在它能够拿起物体和折叠衬衫。同样，亚马逊正在其仓库中测试机器人以移动物品，这是一个相当令人印象深刻的发展。这展示了现代机器人的物理独创性和它们在帮助人类完成重复、繁琐和日常任务方面的潜力。虽然机器人和人工智能已经紧密相连，但我们将通过持续集成RPA技术和生成式人工智能看到令人信服的进步：'
- en: '![Figure 10.10 – Image of Tesla’s Humanoid Robot Optimus. Source: Tesla](img/B21443_10_10.jpg)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![图10.10 – 特斯拉人形机器人Optimus的图片。来源：特斯拉](img/B21443_10_10.jpg)'
- en: 'Figure 10.10 – Image of Tesla’s Humanoid Robot Optimus. Source: Tesla'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.10 – 特斯拉人形机器人Optimus的图片。来源：特斯拉
- en: From quantum computing to AGI – charting ChatGPT’s future trajectory
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从量子计算到通用人工智能（AGI）——绘制ChatGPT的未来轨迹
- en: AGI has emerged as a prevalent buzzword in the wake of significant advancements
    in generative AI. The growing curiosity and anticipation surrounding the timeline
    to achieve AGI underscores its importance. To truly understand AGI, it’s important
    to get to the heart of what it is, recognize why it matters so much, and consider
    how cutting-edge technologies such as quantum computing could speed up our progress
    toward achieving AGI.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 随着生成人工智能的重大进步，AGI已成为一个普遍的流行词汇。围绕实现AGI的时间表的日益增长的兴趣和期待凸显了其重要性。要真正理解AGI，重要的是要深入了解其本质，认识到为什么它如此重要，并考虑如何利用量子计算等尖端技术加快我们实现AGI的进程。
- en: What is AGI?
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是AGI？
- en: Although there is no single definition of what AGI is, we synthesized information
    from credible sources to form a definition. AGI is generally understood as a form
    of AI that can understand, learn, and apply knowledge in a way that is not specifically
    tied to certain tasks, environments, or domains. It is characterized by its versatility
    and flexibility, similar to the cognitive capabilities of a human being. OpenAI,
    as a leading AI research organization, has been at the forefront of developing
    advanced AI systems. Although OpenAI has not provided a singular, definitive definition
    of AGI, they describe it as highly autonomous systems that outperform humans at
    most economically valuable work. This description implies a level of general intelligence
    that allows these systems to perform a wide range of tasks, adapt to new environments,
    and continually improve themselves through self-feedback and learning.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管对AGI的定义没有统一的说法，但我们综合了可信来源的信息，形成了一个定义。AGI通常被理解为一种人工智能，它能够以不特定于某些任务、环境或领域的方式理解、学习和应用知识。它以其多功能性和灵活性为特征，类似于人类的认知能力。OpenAI作为领先的AI研究机构，一直处于开发先进AI系统的前沿。尽管OpenAI没有提供一个单一、明确的AGI定义，但他们将其描述为高度自主的系统，在大多数具有经济价值的工作中超越人类。这种描述暗示了一种通用智能水平，使这些系统能够执行广泛的任务，适应新环境，并通过自我反馈和学习不断自我改进。
- en: Quantum computing and AI
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 量子计算与AI
- en: AGI could potentially be significantly enhanced by quantum computing, a technology
    that operates on the principles of quantum mechanics. Quantum computers, with
    their ability to perform complex calculations at unprecedented speeds, offer a
    promising solution to the immense computational demands of AGI. They could drastically
    reduce the time needed for data processing and pattern recognition, key components
    of machine learning and AI. Additionally, quantum computing could enable AGI systems
    to analyze vast datasets more efficiently, optimize algorithms to a degree unimaginable,
    and solve optimization and simulation problems that are intractable for classical
    computers. This synergy might not only accelerate the development of AGI but also
    expand its capabilities, leading to more sophisticated and adaptable AI systems.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: AGI（通用人工智能）有可能通过量子计算得到显著提升，量子计算是一种基于量子力学原理的技术。量子计算机凭借其以前所未有的速度执行复杂计算的能力，为满足AGI巨大的计算需求提供了一个有希望的解决方案。它们可以大幅减少数据处理和模式识别所需的时间，这两者是机器学习和人工智能的关键组成部分。此外，量子计算可以使AGI系统更有效地分析大量数据集，优化算法到难以想象的程度，并解决经典计算机难以处理的优化和模拟问题。这种协同作用不仅可能加速AGI的发展，也可能扩展其能力，导致更复杂和适应性更强的AI系统。
- en: The impact of AGI on society
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AGI对社会的影响
- en: AGI could have a profound impact on society because it embodies the potential
    to perform a wide range of cognitive tasks at human or superhuman levels, promising
    breakthroughs in virtually every domain – from medicine to economics to science
    – by solving complex problems, driving innovation, and reshaping our understanding
    of intelligence itself. Unlike narrow AI, which excels in specific tasks, AGI’s
    comprehensive and adaptable nature could lead to unprecedented advancements in
    technology and productivity, and our ability to address the most challenging and
    intricate issues facing humanity. However, alongside its vast potential, AGI also
    poses profound ethical, societal, and existential questions, necessitating careful
    consideration and governance to ensure its benefits are harnessed responsibly
    and equitably. OpenAI’s mission statement emphasizes its commitment to ensuring
    that AGI, when it’s developed, benefits all humanity. They focus on creating safe
    and beneficial AI systems, acknowledging the profound impact that AGI could have
    on society.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: AGI可能对社会产生深远的影响，因为它体现了在人类或超人类水平上执行广泛认知任务的能力，几乎在每一个领域——从医学到经济学到科学——都承诺通过解决复杂问题、推动创新和重塑我们对智能本身的理解实现突破。与擅长特定任务的窄AI不同，AGI的全面性和适应性可能导致技术和社会生产力的前所未有的进步，以及我们解决人类面临的最具挑战性和复杂问题的能力。然而，随着其巨大的潜力，AGI也提出了深刻的伦理、社会和存在主义问题，需要仔细考虑和治理，以确保其利益得到负责任和公平地利用。OpenAI的使命宣言强调了其确保AGI（一旦开发）造福全人类的承诺。他们专注于创建安全且有益的AI系统，承认AGI可能对社会产生深远的影响。
- en: Conclusion
  id: totrans-148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: In this chapter, we explored our predictions for the future of generative AI.
    We comprehensively covered what we think will happen next, starting with advancements
    in multimodal LLMs, industry-specific specialized models, and AI regulations,
    and discussed the emergence of more efficient, SLMs that promise to significantly
    enhance intelligent edge devices. We will see a rise in open source models, which
    will democratize AI innovation, enabling widespread access to cutting-edge technology
    and fostering a global community of collaborators to accelerate progress and creativity.
    We also discussed predictions from leading industry figures and charted the path
    toward AGI and quantum computing.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了我们对生成式人工智能未来的预测。我们全面覆盖了我们认为接下来会发生的事情，从多模态LLM的进步、行业特定的专业模型和人工智能法规开始，并讨论了更高效、SLMs的出现，这些SLMs承诺将显著提高智能边缘设备的能力。我们将看到开源模型数量的增加，这将使人工智能创新民主化，使人们能够广泛地访问尖端技术，并培养一个全球合作者社区，以加速进步和创造力。我们还讨论了行业领军人物的预测，并绘制了通往通用人工智能和量子计算的道路。
- en: As we turn the final page of our journey together, this book reaches its conclusion,
    culminating in a chapter that has navigated the pivotal advancements and anticipated
    directions in the realm of generative AI. Our exploration embarked from the shores
    of an introductory overview, where generative AI’s harmony with cloud technologies
    was unveiled. We ventured deeper, dissecting strategies to refine the relevance
    of GPT outputs through prompt engineering, fine-tuning, and innovative **retrieval-augmented
    generation** (**RAG**). Our voyage also charted the territories of building generative
    AI applications with sturdy frameworks such as Semantic Kernel, Langchain, and
    Autogen, delving into the complexities of scaling and securing applications, and
    championing the crucial ethos of responsible AI development.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们一起翻到旅程的最后一页时，这本书达到了它的结论，在生成人工智能领域的关键进步和预期方向上达到了高潮。我们的探索从介绍性概述的岸边开始，在那里揭示了生成人工智能与云计算的和谐。我们进一步深入，剖析了通过提示工程、微调和创新的**检索增强生成**（**RAG**）来细化GPT输出的相关性的策略。我们的航行还绘制了使用语义内核、Langchain和Autogen等坚固框架构建生成人工智能应用的领域，深入探讨了扩展和保障应用复杂性的问题，并倡导了负责任的人工智能开发的重要伦理。
- en: This book has been more than a guide; it has been a shared expedition, offering
    you the compass and tools to navigate the vast ocean of AI possibilities. As we
    bid farewell, remember that the end of this book is not the conclusion but a new
    beginning. Armed with knowledge, may you embark on your own adventures, crafting
    sophisticated, end-to-end AI applications. The prospects of AI are indeed thrilling;
    as AI technology advances, it promises to augment human productivity, thereby
    liberating time for more meaningful endeavors. Thank you for joining us on this
    remarkable journey. Together, we stand on the brink of a bright future with potential,
    ready to explore, innovate, and transform the world with generative AI. Farewell,
    and may your path be ever illuminated by the light of curiosity and the joy of
    discovery.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 这本书不仅仅是一本指南；它更是一次共同探险，为你提供了导航人工智能可能性广阔海洋的指南针和工具。当我们告别之际，请记住，这本书的结束不是终点，而是一个新的开始。带着知识，愿你踏上自己的冒险之旅，打造复杂且端到端的人工智能应用。人工智能的前景确实令人兴奋；随着人工智能技术的进步，它承诺将提高人类的生产力，从而为更有意义的事业释放时间。感谢您与我们一同踏上这段非凡之旅。我们共同站在一个充满潜力的光明未来的边缘，准备利用生成式人工智能探索、创新和改变世界。再见，愿你的道路永远被好奇心和发现的喜悦之光照亮。
- en: References
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'To learn more about the topics that were covered in this chapter, take a look
    at the following resources:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于本章所涵盖的主题的信息，请查看以下资源：
- en: 'Phi-2, the surprising power of small language models: [https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/?msclkid=12a004f4700c6f8608db16e471a46efa](https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/?msclkid=12a004f4700c6f8608db16e471a46efa)'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Phi-2，小型语言模型的惊人力量：[https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/?msclkid=12a004f4700c6f8608db16e471a46efa](https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/?msclkid=12a004f4700c6f8608db16e471a46efa)
- en: 'Text-to-Video: The Task, Challenges and the Current State: [https://huggingface.co/blog/text-to-video](https://huggingface.co/blog/text-to-video)'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文本到视频：任务、挑战和当前状态：[https://huggingface.co/blog/text-to-video](https://huggingface.co/blog/text-to-video)
- en: 'The Dawn of LMMs:Preliminary Explorations with GPT-4V(ision): [https://export.arxiv.org/pdf/2309.17421](https://export.arxiv.org/pdf/2309.17421GPT-4)'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LMM 的新纪元：使用 GPT-4V(ision) 的初步探索 [https://export.arxiv.org/pdf/2309.17421](https://export.arxiv.org/pdf/2309.17421GPT-4)
- en: 'Video Retrieval: GPT-4 Turbo with Vision Integrates with Azure to Redefine
    Video Understanding (microsoft.com): https://techcommunity.microsoft.com/t5/ai-azure-ai-services-blog/video-retrieval-gpt-4-turbo-with-vision-integrates-with-azure-to/ba-p/3982753'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 视频检索：GPT-4 Turbo with Vision 集成 Azure 重新定义视频理解 (microsoft.com)：[https://techcommunity.microsoft.com/t5/ai-azure-ai-services-blog/video-retrieval-gpt-4-turbo-with-vision-integrates-with-azure-to/ba-p/3982753](https://techcommunity.microsoft.com/t5/ai-azure-ai-services-blog/video-retrieval-gpt-4-turbo-with-vision-integrates-with-azure-to/ba-p/3982753)
- en: '[https://techcommunity.microsoft.com/t5/ai-azure-ai-services-blog/video-retrieval-gpt-4-turbo-with-vision-integrates-with-azure-to/ba-p/3982753](https://techcommunity.microsoft.com/t5/ai-azure-ai-services-blog/video-retrieval-gpt-4-turbo-with-vision-integrates-with-azure-to/ba-p/3982753)'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://techcommunity.microsoft.com/t5/ai-azure-ai-services-blog/video-retrieval-gpt-4-turbo-with-vision-integrates-with-azure-to/ba-p/3982753](https://techcommunity.microsoft.com/t5/ai-azure-ai-services-blog/video-retrieval-gpt-4-turbo-with-vision-integrates-with-azure-to/ba-p/3982753)'
- en: 'Moonshot Video Generation Model: [https://arxiv.org/abs/2401.01827](https://arxiv.org/abs/2401.01827)'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 月球视频生成模型：[https://arxiv.org/abs/2401.01827](https://arxiv.org/abs/2401.01827)
- en: SLM [https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/?msclkid=12a004f4700c6f8608db16e471a46efa](https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/?msclkid=12a004f4700c6f8608db16e471a46efa)
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SLM [https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/?msclkid=12a004f4700c6f8608db16e471a46efa](https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/?msclkid=12a004f4700c6f8608db16e471a46efa)
- en: 'Orca 2: Teaching Small Language Models How to Reason [https://www.microsoft.com/en-us/research/blog/orca-2-teaching-small-language-models-how-to-reason/](https://www.microsoft.com/en-us/research/blog/orca-2-teaching-small-language-models-how-to-reason/)'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Orca 2：教授小型语言模型如何推理 [https://www.microsoft.com/en-us/research/blog/orca-2-teaching-small-language-models-how-to-reason/](https://www.microsoft.com/en-us/research/blog/orca-2-teaching-small-language-models-how-to-reason/)
- en: 'TinyLlama: An Open-Source Small Language Model [https://arxiv.org/pdf/2401.02385.pdf](https://arxiv.org/pdf/2401.02385.pdf)'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TinyLlama：开源小型语言模型 [https://arxiv.org/pdf/2401.02385.pdf](https://arxiv.org/pdf/2401.02385.pdf)
- en: Rabbit R1 Technology https://www.rabbit.tech/research
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rabbit R1 技术 https://www.rabbit.tech/research
- en: How To Run Large AI Models On An Edge Device [https://www.forbes.com/sites/karlfreund/2023/07/10/how-to-run-large-ai-models-on-an-edge-device/?sh=634476263d67](https://www.forbes.com/sites/karlfreund/2023/07/10/how-to-run-large-ai-models-on-an-edge-device/?sh=634476263d67)
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何在边缘设备上运行大型 AI 模型 [https://www.forbes.com/sites/karlfreund/2023/07/10/how-to-run-large-ai-models-on-an-edge-device/?sh=634476263d67](https://www.forbes.com/sites/karlfreund/2023/07/10/how-to-run-large-ai-models-on-an-edge-device/?sh=634476263d67)
- en: 'Table-GPT: Table-tuned GPT for Diverse Table Tasks [https://arxiv.org/abs/2310.09263](https://arxiv.org/abs/2310.09263)'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Table-GPT：针对多样化表格任务的表格调整 GPT [https://arxiv.org/abs/2310.09263](https://arxiv.org/abs/2310.09263)
