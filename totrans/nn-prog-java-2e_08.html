<html><head></head><body><div><div><div><div><div><h1 class="title"><a id="ch08" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Chapter 8. Text Recognition</h1></div></div></div><p class="calibre11">We all know that humans can read and recognize images faster than any supercomputer. However, we have seen so far that neural networks show amazing capabilities of learning through data in both a supervised and an unsupervised way. In this chapter, we present an additional case of pattern recognition involving an example of optical character recognition. Neural networks can be trained to strictly recognize digits written in an image file. The topics of this chapter are:</p><div><ul class="itemizedlist"><li class="listitem">Pattern recognition</li><li class="listitem">Defined classes</li><li class="listitem">Undefined classes</li><li class="listitem">Neural networks in pattern recognition</li><li class="listitem">MLP</li><li class="listitem">The OCR problem</li><li class="listitem">Preprocessing and classes definition</li><li class="listitem">Implementation in Java</li><li class="listitem">Digit recognition</li></ul></div><div><div><div><div><h1 class="title2"><a id="ch08lvl1sec51" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Pattern recognition</h1></div></div></div><p class="calibre11">Patterns are<a id="id480" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> a bunch of data and elements that look similar to each other, in such a way that they can occur systematically and repeat from time to time. This is a task that can be solved mainly by unsupervised learning by clustering; however, when there is labelled data or there are defined classes of data, this task can be solved by supervised methods. We, as humans, perform this task more often than we can imagine. When we see objects and recognise them as belonging to a certain class, we are indeed recognising a pattern. Also, when we analyse charts, discrete events, and time series, we might find evidence of some sequence of events that repeat systematically under certain conditions. In summary, patterns can be learned by data observations.</p><p class="calibre11">Examples <a id="id481" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>of pattern recognition tasks include, but are not limited to:</p><div><ul class="itemizedlist"><li class="listitem">Shape recognition</li><li class="listitem">Object classification</li><li class="listitem">Behavior clustering</li><li class="listitem">Voice recognition</li><li class="listitem">OCR</li><li class="listitem">Chemical reaction taxonomy</li></ul></div><div><div><div><div><h2 class="title5"><a id="ch08lvl2sec99" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Defined classes</h2></div></div></div><p class="calibre11">In a list<a id="id482" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> of classes that has been predefined for a specific <a id="id483" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>domain, each class is considered to be a pattern; therefore every data record or occurrence is assigned one of these predefined classes.</p><div><div><h3 class="title6"><a id="tip32" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Tip</h3><p class="calibre17">The predefinition of classes can usually be performed by an expert or based on previous knowledge of the application domain. Also, it is desirable to apply defined classes when we want the data to be classified strictly into one of the predefined classes.</p></div></div><p class="calibre11">One illustrated example of pattern recognition using defined classes is animal recognition by image, shown in the figure below. The pattern recogniser, however, should be trained to catch all the characteristics that formally define the classes. In the example, eight figures of animals are shown, belonging to two classes: mammals and birds. Since this is a supervised mode of learning, the neural network should be provided with a sufficient number of images to allow it to properly classify new images.</p><div><img src="img/B04971_08_01.jpg" alt="Defined classes" class="calibre199"/></div><p class="calibre11">Of course, sometimes<a id="id484" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> the classification may fail, mainly due to <a id="id485" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>similar hidden patterns in the images that neural networks may catch and also due to small nuances present in the shapes. For example, the dolphin has flippers but it is still a mammal. Sometimes, in order to obtain a more accurate classification, it is necessary to apply preprocessing and ensure that the neural network will receive the appropriate data that will allow for classification.</p></div><div><div><div><div><h2 class="title5"><a id="ch08lvl2sec100" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Undefined classes</h2></div></div></div><p class="calibre11">When data is <a id="id486" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>unlabelled and there is no predefined set of<a id="id487" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> classes, it is an unsupervised learning scenario. Shape recognition is a good example, since the shapes may be flexible and have an infinite number of edges, vertices, or bindings.</p><div><img src="img/B04971_08_02.jpg" alt="Undefined classes" class="calibre200"/></div><p class="calibre11">In the image<a id="id488" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> above, we can see some sorts of shapes and we <a id="id489" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>want to arrange them, so that similar ones can be grouped into the same cluster. Based on the shape information that is present in the images, it is likely that the pattern recognizer will classify the rectangle, the square and the, triangle into the same group. However, if the information were presented to the pattern recognizer, not as an image, but as a graph with edges and vertices coordinates, the classification might change a little.</p><p class="calibre11">In summary, the pattern recognition task may use both supervised and unsupervised modes of learning, basically depending of the objective of recognition.</p></div></div></div></div>



  
<div><div><div><div><div><h1 class="title2"><a id="ch08lvl1sec52" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Neural networks in pattern recognition</h1></div></div></div><p class="calibre11">For pattern<a id="id490" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> recognition, the neural network<a id="id491" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> architectures that can be applied are MLPs (supervised) and the Kohonen Network (unsupervised). In the first case, the problem should be set up as a classification problem, that is, the data should be transformed into the <em class="calibre16">X-Y</em> dataset, where for every data record in <em class="calibre16">X</em> there should be a corresponding class in <em class="calibre16">Y</em>. As stated in <a class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2" href="ch03.xhtml" title="Chapter 3. Perceptrons and Supervised Learning">Chapter 3</a>, <em class="calibre16">Perceptrons and Supervised Learning</em> and <a class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2" href="ch06.xhtml" title="Chapter 6. Classifying Disease Diagnosis">Chapter 6</a>, <em class="calibre16">Classifying Disease Diagnosis</em> the output of the neural network for classification problems should have all of the possible classes, and this may require preprocessing of the output records.</p><p class="calibre11">For the other case, unsupervised learning, there is no need to apply labels to the output, but the input data should be properly structured. To remind you, the schema of both neural networks are shown in the next figure:</p><div><img src="img/B04971_08_03.jpg" alt="Neural networks in pattern recognition" class="calibre201"/></div><div><div><div><div><h2 class="title5"><a id="ch08lvl2sec101" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Data pre-processing</h2></div></div></div><p class="calibre11">As previously <a id="id492" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>seen in <a class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2" href="ch06.xhtml" title="Chapter 6. Classifying Disease Diagnosis">Chapter 6</a>, <em class="calibre16">Classifying Disease Diagnosis</em> and <a class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2" href="ch07.xhtml" title="Chapter 7. Clustering Customer Profiles">Chapter 7</a>, <em class="calibre16">Clustering Customer Profiles</em> we have to deal with all possible types of data, i.e., numerical (continuous and discrete) and categorical (ordinal or unscaled).</p><p class="calibre11">However, here we have the possibility of performing pattern recognition on multimedia content, such as images and videos. So, can multimedia could be handled? The answer to this question lies in the way these contents are stored in files. Images, for example, are written with a representation of small colored points called pixels. Each color can be coded in an RGB notation where the intensity of red, green, and blue define every color the human eye is able to see. Therefore an image of dimension 100x100 would have 10,000 pixels, each one having three values for red, green and blue, yielding a total of 30,000 points. That is the challenge for image processing in neural networks.</p><p class="calibre11">Some methods, which we'll review in the next chapter, may reduce this huge number of dimensions. Afterwards an image can be treated as big matrix of numerical continuous values.</p><p class="calibre11">For simplicity, we are applying only gray-scale images with small dimensions in this chapter.</p></div><div><div><div><div><h2 class="title5"><a id="ch08lvl2sec102" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Text recognition (optical character recognition)</h2></div></div></div><p class="calibre11">Many documents<a id="id493" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> are now being scanned and stored<a id="id494" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> as images, making it necessary to convert these documents back into text, for a computer to apply edition and text processing. However, this feature involves a number of challenges:</p><div><ul class="itemizedlist"><li class="listitem">Variety of text font</li><li class="listitem">Text size</li><li class="listitem">Image noise</li><li class="listitem">Manuscripts</li></ul></div><p class="calibre11">In spite of that, humans can easily interpret and read even texts produced in a bad quality image. This<a id="id495" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> can be explained by the fact that humans are <a id="id496" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>already familiar with text characters and the words in their language. Somehow the algorithm must become acquainted with these elements (characters, digits, signalization, and so on), in order to successfully recognize texts in images.</p></div><div><div><div><div><h2 class="title5"><a id="ch08lvl2sec103" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Digit recognition</h2></div></div></div><p class="calibre11">Although<a id="id497" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> there are a variety of tools available on the <a id="id498" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>market for OCR, it still remains a big challenge for an algorithm to properly recognize texts in images. So, we will be restricting our application to in a smaller domain, so that we'll face simpler problems. Therefore, in this chapter, we are going to implement a neural network to recognize digits from 0 to 9 represented on images. Also, the images will have standardized and small dimensions, for the sake of simplicity.</p></div><div><div><div><div><h2 class="title5"><a id="ch08lvl2sec104" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Digit representation</h2></div></div></div><p class="calibre11">We<a id="id499" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> applied the standard dimension of 10x10 (100 pixels) in<a id="id500" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> gray scaled images, resulting in 100 values of gray scale for each image:</p><div><img src="img/B04971_08_04.jpg" alt="Digit representation" class="calibre202"/></div><p class="calibre11">In the preceding image we have a sketch representing the digit 3 at the left and a corresponding matrix with gray values for the same digit, in gray scale.</p><p class="calibre11">We apply<a id="id501" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> this preprocessing in order to represent all ten<a id="id502" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> digits in this application.</p></div><div><div><div><div><h2 class="title5"><a id="ch08lvl2sec105" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Implementation in Java</h2></div></div></div><p class="calibre11">To recognize<a id="id503" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> optical characters, data to train and to<a id="id504" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> test neural network was produced by us. In this example, digits from 0 (super black) to 255 (super white) were considered. According to pixel disposal, two versions of each digit data were created: one to train and another to test. Classification techniques presented in <a class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2" href="ch03.xhtml" title="Chapter 3. Perceptrons and Supervised Learning">Chapter 3</a>, <em class="calibre16">Perceptrons and Supervised Learning</em> and <a class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2" href="ch06.xhtml" title="Chapter 6. Classifying Disease Diagnosis">Chapter 6</a>, <em class="calibre16">Classifying Disease Diagnosis</em> will be used here.</p></div><div><div><div><div><h2 class="title5"><a id="ch08lvl2sec106" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Generating data</h2></div></div></div><p class="calibre11">Numbers<a id="id505" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> from zero to nine were drawn in the Microsoft Paint ®. The images have been converted into matrices, from which some examples are shown in the following image. All pixel values between zero and nine are grayscale:</p><div><img src="img/B04971_08_05.jpg" alt="Generating data" class="calibre203"/></div><p class="calibre11">For each digit we generated five variations, where one is the perfect digit, and the others contain noise, either by the drawing, or by the image quality.</p><p class="calibre11">Each matrix row was merged into vectors (D<sub class="calibre144">train</sub> and D<sub class="calibre144">test</sub>) to form a pattern that will be used to train and test the neural network. Therefore, the input layer of the neural network will be composed of 101 neurons.</p><p class="calibre11">The output dataset was represented by ten patterns. Each one has a more expressive value (one) and the rest of the values are zero. Therefore, the output layer of the neural network will have ten neurons.</p></div><div><div><div><div><h2 class="title5"><a id="ch08lvl2sec107" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Neural architecture</h2></div></div></div><p class="calibre11">So, in this<a id="id506" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> application our neural network will have 100 inputs (for images that have a 10x10 pixel size) and ten outputs, the number of hidden neurons remaining unrestricted. We created a class called <code class="literal">DigitExample</code> in the package examples.chapter08 to handle this application. The neural network architecture <a id="id507" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>was chosen with these parameters:</p><div><ul class="itemizedlist"><li class="listitem"><strong class="calibre12">Neural network type</strong>: MLP</li><li class="listitem"><strong class="calibre12">Training algorithm</strong>: Backpropagation</li><li class="listitem"><strong class="calibre12">Number of hidden layers</strong>: 1</li><li class="listitem"><strong class="calibre12">Number of neurons in the hidden layer</strong>: 18</li><li class="listitem"><strong class="calibre12">Number of epochs</strong>: 1000</li><li class="listitem"><strong class="calibre12">Minimum overall error</strong>: 0.001</li></ul></div><div><img src="img/B04971_08_06.jpg" alt="Neural architecture" class="calibre204"/></div></div><div><div><div><div><h2 class="title5"><a id="ch08lvl2sec108" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Experiments</h2></div></div></div><p class="calibre11">Now, as has<a id="id508" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> been done in other cases previously presented, let's find the best neural network topology training several nets. The strategy to do that is summarized in the following table:</p><div><table border="1" class="calibre20"><colgroup class="calibre21"><col class="calibre22"/><col class="calibre22"/><col class="calibre22"/></colgroup><thead class="calibre23"><tr class="calibre24"><th valign="bottom" class="calibre25">
<p class="calibre26">Experiment</p>
</th><th valign="bottom" class="calibre25">
<p class="calibre26">Learning rate</p>
</th><th valign="bottom" class="calibre25">
<p class="calibre26">Activation Functions</p>
</th></tr></thead><tbody class="calibre27"><tr class="calibre31"><td rowspan="2" class="calibre29">
<p class="calibre26">#1</p>
</td><td rowspan="2" class="calibre29">
<p class="calibre26">0.3</p>
</td><td class="calibre29">
<p class="calibre26">Hidden Layer: SIGLOG</p>
</td></tr><tr class="calibre34"><td class="calibre29">
<p class="calibre26">Output Layer: LINEAR</p>
</td></tr><tr class="calibre31"><td rowspan="2" class="calibre29">
<p class="calibre26">#2</p>
</td><td rowspan="2" class="calibre29">
<p class="calibre26">0.5</p>
</td><td class="calibre29">
<p class="calibre26">Hidden Layer: SIGLOG</p>
</td></tr><tr class="calibre34"><td class="calibre29">
<p class="calibre26">Output Layer: LINEAR</p>
</td></tr><tr class="calibre31"><td rowspan="2" class="calibre29">
<p class="calibre26">#3</p>
</td><td rowspan="2" class="calibre29">
<p class="calibre26">0.8</p>
</td><td class="calibre29">
<p class="calibre26">Hidden Layer: SIGLOG</p>
</td></tr><tr class="calibre34"><td class="calibre29">
<p class="calibre26">Output Layer: LINEAR</p>
</td></tr><tr class="calibre31"><td rowspan="2" class="calibre29">
<p class="calibre26">#4</p>
</td><td rowspan="2" class="calibre29">
<p class="calibre26">0.3</p>
</td><td class="calibre29">
<p class="calibre26">Hidden Layer: HYPERTAN</p>
</td></tr><tr class="calibre34"><td class="calibre29">
<p class="calibre26">Output Layer: LINEAR</p>
</td></tr><tr class="calibre31"><td rowspan="2" class="calibre29">
<p class="calibre26">#5</p>
</td><td rowspan="2" class="calibre29">
<p class="calibre26">0.5</p>
</td><td class="calibre29">
<p class="calibre26">Hidden Layer: SIGLOG</p>
</td></tr><tr class="calibre34"><td class="calibre29">
<p class="calibre26">Output Layer: LINEAR</p>
</td></tr><tr class="calibre31"><td rowspan="2" class="calibre29">
<p class="calibre26">#6</p>
</td><td rowspan="2" class="calibre29">
<p class="calibre26">0.8</p>
</td><td class="calibre29">
<p class="calibre26">Hidden Layer: SIGLOG</p>
</td></tr><tr class="calibre34"><td class="calibre29">
<p class="calibre26">Output Layer: LINEAR</p>
</td></tr><tr class="calibre31"><td rowspan="2" class="calibre29">
<p class="calibre26">#7</p>
</td><td rowspan="2" class="calibre29">
<p class="calibre26">0.3</p>
</td><td class="calibre29">
<p class="calibre26">Hidden Layer: HYPERTAN</p>
</td></tr><tr class="calibre34"><td class="calibre29">
<p class="calibre26">Output Layer: SIGLOG</p>
</td></tr><tr class="calibre31"><td rowspan="2" class="calibre29">
<p class="calibre26">#8</p>
</td><td rowspan="2" class="calibre29">
<p class="calibre26">0.5</p>
</td><td class="calibre29">
<p class="calibre26">Hidden Layer: HYPERTAN</p>
</td></tr><tr class="calibre34"><td class="calibre29">
<p class="calibre26">Output Layer: SIGLOG</p>
</td></tr><tr class="calibre31"><td rowspan="2" class="calibre29">
<p class="calibre26">#9</p>
</td><td rowspan="2" class="calibre29">
<p class="calibre26">0.8</p>
</td><td class="calibre29">
<p class="calibre26">Hidden Layer: HYPERTAN</p>
</td></tr><tr class="calibre37"><td class="calibre29">
<p class="calibre26">Output Layer: SIGLOG</p>
</td></tr></tbody></table></div><p class="calibre11">The<a id="id509" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> following <code class="literal">DigitExample</code> class code defines how to create a neural network to read from digit data:</p><div><pre class="programlisting">// enter neural net parameter via keyboard (omitted)

// load dataset from external file (omitted)

// data normalization (omitted)

// create ANN and define parameters to TRAIN: 
Backpropagation backprop = new Backpropagation(nn, neuralDataSetToTrain, LearningAlgorithm.LearningMode.BATCH);
backprop.setLearningRate( typedLearningRate );
backprop.setMaxEpochs( typedEpochs );
backprop.setGeneralErrorMeasurement(Backpropagation.ErrorMeasurement.SimpleError);
backprop.setOverallErrorMeasurement(Backpropagation.ErrorMeasurement.MSE);
backprop.setMinOverallError(0.001);
backprop.setMomentumRate(0.7);
backprop.setTestingDataSet(neuralDataSetToTest);
backprop.printTraining = true;
backprop.showPlotError = true;

// train ANN:
try {
    backprop.forward();
    //neuralDataSetToTrain.printNeuralOutput();

    backprop.train();
    System.out.println("End of training");
    if (backprop.getMinOverallError() &gt;= backprop.getOverallGeneralError()) {
        System.out.println("Training successful!");
    } else {
        System.out.println("Training was unsuccessful");
    }
    System.out.println("Overall Error:" + String.valueOf(backprop.getOverallGeneralError()));
    System.out.println("Min Overall Error:" + String.valueOf(backprop.getMinOverallError()));
    System.out.println("Epochs of training:" + String.valueOf(backprop.getEpoch()));

} catch (NeuralException ne) {
    ne.printStackTrace();
} 

// test ANN (omitted)</pre></div></div><div><div><div><div><h2 class="title5"><a id="ch08lvl2sec109" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Results</h2></div></div></div><p class="calibre11">After running<a id="id510" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> each experiment using the <code class="literal">DigitExample</code> class, excluding training and testing overall errors and the quantity of right number classifications using the test data (table above), it is possible observe that experiments #2 and #4 have the lowest MSE values. The differences between these two experiments are learning rate and activation function used in the output layer.</p><div><table border="1" class="calibre20"><colgroup class="calibre21"><col class="calibre22"/><col class="calibre22"/><col class="calibre22"/><col class="calibre22"/></colgroup><thead class="calibre23"><tr class="calibre24"><th valign="bottom" class="calibre25">
<p class="calibre26">Experiment</p>
</th><th valign="bottom" class="calibre25">
<p class="calibre26">Training overall error</p>
</th><th valign="bottom" class="calibre25">
<p class="calibre26">Testing overall error</p>
</th><th valign="bottom" class="calibre25">
<p class="calibre26"># Right number classifications</p>
</th></tr></thead><tbody class="calibre27"><tr class="calibre31"><td class="calibre29">
<p class="calibre26">#1</p>
</td><td class="calibre29">
<p class="calibre26">9.99918E-4</p>
</td><td class="calibre29">
<p class="calibre26">0.01221</p>
</td><td class="calibre29">
<p class="calibre26">2 by 10</p>
</td></tr><tr class="calibre34"><td class="calibre29">
<p class="calibre26">
<strong class="calibre12">#2</strong>
</p>
</td><td class="calibre29">
<p class="calibre26">
<strong class="calibre12">9.99384E-4</strong>
</p>
</td><td class="calibre29">
<p class="calibre26">
<strong class="calibre12">0.00140</strong>
</p>
</td><td class="calibre29">
<p class="calibre26">
<strong class="calibre12">5 by 10</strong>
</p>
</td></tr><tr class="calibre31"><td class="calibre29">
<p class="calibre26">#3</p>
</td><td class="calibre29">
<p class="calibre26">9.85974E-4</p>
</td><td class="calibre29">
<p class="calibre26">0.00621</p>
</td><td class="calibre29">
<p class="calibre26">4 by 10</p>
</td></tr><tr class="calibre34"><td class="calibre29">
<p class="calibre26">#4</p>
</td><td class="calibre29">
<p class="calibre26">9.83387E-4</p>
</td><td class="calibre29">
<p class="calibre26">0.02491</p>
</td><td class="calibre29">
<p class="calibre26">3 by 10</p>
</td></tr><tr class="calibre31"><td class="calibre29">
<p class="calibre26">#5</p>
</td><td class="calibre29">
<p class="calibre26">9.99349E-4</p>
</td><td class="calibre29">
<p class="calibre26">0.00382</p>
</td><td class="calibre29">
<p class="calibre26">3 by 10</p>
</td></tr><tr class="calibre34"><td class="calibre29">
<p class="calibre26">#6</p>
</td><td class="calibre29">
<p class="calibre26">273.70</p>
</td><td class="calibre29">
<p class="calibre26">319.74</p>
</td><td class="calibre29">
<p class="calibre26">2 by 10</p>
</td></tr><tr class="calibre31"><td class="calibre29">
<p class="calibre26">#7</p>
</td><td class="calibre29">
<p class="calibre26">1.32070</p>
</td><td class="calibre29">
<p class="calibre26">6.35136</p>
</td><td class="calibre29">
<p class="calibre26">5 by 10</p>
</td></tr><tr class="calibre34"><td class="calibre29">
<p class="calibre26">
<strong class="calibre12">#8</strong>
</p>
</td><td class="calibre29">
<p class="calibre26">
<strong class="calibre12">1.24012</strong>
</p>
</td><td class="calibre29">
<p class="calibre26">
<strong class="calibre12">4.87290</strong>
</p>
</td><td class="calibre29">
<p class="calibre26">
<strong class="calibre12">7 by 10</strong>
</p>
</td></tr><tr class="calibre28"><td class="calibre29">
<p class="calibre26">#9</p>
</td><td class="calibre29">
<p class="calibre26">1.51045</p>
</td><td class="calibre29">
<p class="calibre26">4.35602</p>
</td><td class="calibre29">
<p class="calibre26">3 by 10</p>
</td></tr></tbody></table></div><p class="calibre11">The figure above shows the MSE evolution (train and test) by each epoch graphically by experiment #2. It is<a id="id511" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> interesting to notice the curve stabilizes near the 30th epoch:</p><div><img src="img/B04971_08_07.jpg" alt="Results" class="calibre190"/></div><p class="calibre11">The same graphic analysis was performed for experiment #8. It is possible to check the MSE curve stabilizes near the 200th epoch.</p><div><img src="img/B04971_08_08.jpg" alt="Results" class="calibre190"/></div><p class="calibre11">As already explained, only MSE values might not be considered to attest neural net quality. Accordingly, the test dataset has verified the neural network generalization capacity. The <a id="id512" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>next table shows the comparison between real output with noise and the neural net estimated output of experiment #2 and #8. It is possible to conclude that the neural network weights by experiment #8 can recognize seven digits patterns better than #2's:</p><div><table border="1" class="calibre20"><colgroup class="calibre21"><col class="calibre22"/><col class="calibre22"/></colgroup><thead class="calibre23"><tr class="calibre24"><th colspan="2" valign="bottom" class="calibre80">
<p class="calibre26">
<strong class="calibre12">Output comparison</strong>
</p>
</th></tr></thead><tbody class="calibre27"><tr class="calibre31"><td class="calibre29">
<p class="calibre26">
<strong class="calibre12">Real output (test dataset)</strong>
</p>
</td><td class="calibre29">
<p class="calibre26">
<strong class="calibre12">Digit</strong>
</p>
</td></tr><tr class="calibre34"><td class="calibre29">
<p class="calibre26">0.0    0.0        0.0        0.0        0.0        0.0        0.0        0.0        0.0        1.0</p>
<p class="calibre26">0.0    0.0        0.0        0.0        0.0        0.0        0.0        0.0        1.0        0.0</p>
<p class="calibre26">0.0    0.0        0.0        0.0        0.0        0.0        0.0        1.0        0.0        0.0</p>
<p class="calibre26">0.0    0.0        0.0        0.0        0.0        0.0        1.0        0.0        0.0        0.0</p>
<p class="calibre26">0.0    0.0        0.0        0.0        0.0        1.0        0.0        0.0        0.0        0.0</p>
<p class="calibre26">0.0    0.0        0.0        0.0        1.0        0.0        0.0        0.0        0.0        0.0</p>
<p class="calibre26">0.0    0.0        0.0        1.0        0.0        0.0        0.0        0.0        0.0        0.0</p>
<p class="calibre26">0.0    0.0        1.0        0.0        0.0        0.0        0.0        0.0        0.0        0.0</p>
<p class="calibre26">0.0    1.0        0.0        0.0        0.0        0.0        0.0        0.0        0.0        0.0</p>
<p class="calibre26">1.0    0.0        0.0        0.0        0.0        0.0        0.0        0.0        0.0        0.0</p>
</td><td class="calibre29">
<p class="calibre26">0</p>
<p class="calibre26">1</p>
<p class="calibre26">2</p>
<p class="calibre26">3</p>
<p class="calibre26">4</p>
<p class="calibre26">5</p>
<p class="calibre26">6</p>
<p class="calibre26">7</p>
<p class="calibre26">8</p>
<p class="calibre26">9</p>
</td></tr><tr class="calibre31"><td class="calibre29">
<p class="calibre26">
<strong class="calibre12">Estimated output (test dataset) – Experiment #2</strong>
</p>
</td><td class="calibre29">
<p class="calibre26">
<strong class="calibre12">Digit</strong>
</p>
</td></tr><tr class="calibre34"><td class="calibre29">
<p class="calibre26">0.20   0.26  0.09  -0.09  0.39   0.24  0.35   0.30  0.24   1.02</p>
<p class="calibre26">0.42  -0.23  0.39   0.06  0.11    0.16    0.43   0.25  0.17  -0.26</p>
<p class="calibre26">0.51   0.84  -0.17  0.02  0.16    0.27    -0.15  0.14  -0.34 -0.12</p>
<p class="calibre26">-0.20  -0.05  -0.58  0.20  -0.16     0.27     0.83    -0.56  0.42   0.35</p>
<p class="calibre26">0.24   0.05  0.72  -0.05  -0.25    -0.38    -0.33  0.66  0.05  -0.63</p>
<p class="calibre26">0.08   0.41  -0.21  0.41  0.59     -0.12     -0.54  0.27  0.38  0.00</p>
<p class="calibre26">-0.76  -0.35  -0.09  1.25  -0.78     0.55     -0.22  0.61  0.51  0.27</p>
<p class="calibre26">-0.15   0.11  0.54  -0.53  0.55     0.17     0.09  -0.72  0.03  0.12</p>
<p class="calibre26">0.03   0.41  0.49  -0.44  -0.01    0.05    -0.05 -0.03  -0.32 -0.30</p>
<p class="calibre26">0.63  -0.47  -0.15  0.17  0.38    -0.24     0.58   0.07  -0.16 0.54</p>
</td><td class="calibre29">
<p class="calibre26">0    (OK)</p>
<p class="calibre26">1    (ERR)</p>
<p class="calibre26">2    (ERR)</p>
<p class="calibre26">3    (OK)</p>
<p class="calibre26">4    (ERR)</p>
<p class="calibre26">5    (OK)</p>
<p class="calibre26">6    (OK)</p>
<p class="calibre26">7    (ERR)</p>
<p class="calibre26">8    (ERR)</p>
<p class="calibre26">9    (OK)</p>
</td></tr><tr class="calibre31"><td class="calibre29">
<p class="calibre26">
<strong class="calibre12">Estimated output (test dataset) – Experiment #8</strong>
</p>
</td><td class="calibre29">
<p class="calibre26">
<strong class="calibre12">Digit</strong>
</p>
</td></tr><tr class="calibre37"><td class="calibre29">
<p class="calibre26">0.10    0.10    0.12    0.10    0.12    0.13    0.13    0.26    0.17    0.39</p>
<p class="calibre26">0.13    0.10    0.11    0.10    0.11    0.10    0.29    0.23    0.32    0.10</p>
<p class="calibre26">0.26    0.38    0.10    0.10    0.12    0.10    0.10    0.17    0.10    0.10</p>
<p class="calibre26">0.10    0.10    0.10    0.10    0.10    0.17    0.39    0.10    0.38    0.10</p>
<p class="calibre26">0.15    0.10    0.24    0.10    0.10    0.10    0.10    0.39    0.37    0.10</p>
<p class="calibre26">0.20    0.12    0.10    0.10    0.37    0.10    0.10    0.10    0.17    0.12</p>
<p class="calibre26">0.10    0.10    0.10    0.39    0.10    0.16    0.11    0.30    0.14    0.10</p>
<p class="calibre26">0.10    0.11    0.39    0.10    0.10    0.15    0.10    0.10    0.17    0.10</p>
<p class="calibre26">0.10    0.25    0.34    0.10    0.10    0.10    0.10    0.10    0.10    0.10</p>
<p class="calibre26">0.39    0.10    0.10    0.10    0.28    0.10    0.27    0.11    0.10    0.21</p>
</td><td class="calibre29">
<p class="calibre26">0    (OK)</p>
<p class="calibre26">1    (OK)</p>
<p class="calibre26">2    (OK)</p>
<p class="calibre26">3    (ERR)</p>
<p class="calibre26">4    (OK)</p>
<p class="calibre26">5    (ERR)</p>
<p class="calibre26">6    (OK)</p>
<p class="calibre26">7    (OK)</p>
<p class="calibre26">8    (ERR)</p>
<p class="calibre26">9    (OK)</p>
</td></tr></tbody></table></div><div><div><h3 class="title6"><a id="tip33" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Tip</h3><p class="calibre17">The<a id="id513" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> experiments showed in this chapter have taken in consideration 10x10 pixel information images. We recommend that you try to use 20x20 pixel datasets to build a neural net able to classify digit images of this size.</p><p class="calibre17">You should also change the training parameters of the neural net to achieve better classifications.</p></div></div></div></div></div>



  
<div><div><div><div><div><h1 class="title2"><a id="ch08lvl1sec53" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Summary</h1></div></div></div><p class="calibre11">In this chapter we've seen the power of neural networks in recognizing digits from 0 to 9 in images. Although the coding of the digits was very small in 10x10 images, it was important to understand the concept in practice. Neural networks are capable of learning from data, and provided that real-world representations can be transformed into data, it is reasonable to take into account that character recognition can be a very good example of the application in pattern recognition. The application here can be extended to any type of characters, under the condition that the neural network should all be presented with the predefined characters.</p></div></div>



  </body></html>