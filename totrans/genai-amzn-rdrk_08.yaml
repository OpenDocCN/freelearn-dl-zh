- en: '8'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Extracting Entities and Generating Code with Amazon Bedrock
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter uncovers the realm of entity extraction, a crucial technique in
    NLP. We will explore the intricacies of entity extraction applications, providing
    a comprehensive understanding of implementing entity extraction using Amazon Bedrock.
    Through real-world use cases, you will gain insights into the practical applications
    of entity extraction across various domains.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, the chapter will guide you through the exciting world of generative
    AI for code generation. We will investigate the underlying principles and methodologies
    that enable AI systems to generate code snippets, functions, and even entire applications.
    You will learn how to leverage Amazon Bedrock to streamline your development workflows
    and enhance productivity.
  prefs: []
  type: TYPE_NORMAL
- en: By mastering these techniques, you will be equipped with the knowledge and skills
    to tackle complex NLP tasks and harness the power of generative AI in your coding
    endeavors.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in detail:'
  prefs: []
  type: TYPE_NORMAL
- en: Entity extraction – a comprehensive exploration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Industrial use cases of entity extraction – unleashing the power of unstructured
    data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Entity extraction with Amazon Bedrock
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Code generation with LLMs – unleashing the power of AI-driven development
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter requires you to have access to an AWS account. If you don’t have
    one already, you can go to [https://aws.amazon.com/getting-started/](https://aws.amazon.com/getting-started/)
    and create an AWS account.
  prefs: []
  type: TYPE_NORMAL
- en: 'Secondly, you will need to install and configure the AWS CLI from [https://aws.amazon.com/cli/](https://aws.amazon.com/cli/)
    after you create an account, which will be needed to access Amazon Bedrock FMs
    from your local machine. Since the majority of the code cells we will be executing
    are based on Python, setting up an AWS Python SDK (Boto3) at [https://docs.aws.amazon.com/bedrock/latest/APIReference/welcome.html](https://docs.aws.amazon.com/bedrock/latest/APIReference/welcome.html)
    would be beneficial at this point. You can carry out the Python setup in the following
    manner: install it on your local machine, use AWS Cloud9 or AWS Lambda, or leverage
    Amazon SageMaker.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: There will be a charge associated with the invocation and customization of Amazon
    Bedrock FMs. Please refer to [https://aws.amazon.com/bedrock/pricing/](https://aws.amazon.com/bedrock/pricing/)
    to learn more.
  prefs: []
  type: TYPE_NORMAL
- en: Entity extraction – a comprehensive exploration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the era of big data and information overload, the ability to extract meaningful
    insights from unstructured text data has become increasingly valuable. **Entity
    extraction**, a subfield of NLP, plays a pivotal role in this endeavor by identifying
    and classifying named entities within text, such as people, organizations, locations,
    and more. This process not only facilitates information retrieval and knowledge
    management but also enables a wide range of applications, including **question-answering**,
    sentiment analysis, and **decision support** **systems** (**DSSs**).
  prefs: []
  type: TYPE_NORMAL
- en: The journey of entity extraction began with simple pattern-matching and rule-based
    systems, which relied heavily on manually crafted rules and lexicons. These methods,
    while useful, lacked scalability and robustness when dealing with diverse and
    complex datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Hence, traditionally, entity extraction has been a challenging task, requiring
    extensive manual effort and domain-specific knowledge. However, the advent of
    generative AI, particularly LLMs, has revolutionized this field, offering more
    accurate, scalable, and efficient solutions. In this chapter, we will explore
    the various techniques employed by LLMs on Amazon Bedrock for entity extraction,
    diving into their underlying architectures, strengths, and limitations.
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning approaches
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The advent of machine learning introduced statistical models that leveraged
    feature engineering. These models, including **hidden Markov models** (**HMMs**)
    and **conditional random fields** (**CRFs**), represented a significant step forward.
    They utilized hand-crafted features and probabilistic frameworks to improve extraction
    accuracy. However, their performance was still limited by the quality and comprehensiveness
    of the features engineered by experts.
  prefs: []
  type: TYPE_NORMAL
- en: Neural networks marked a paradigm shift in entity extraction by automating feature
    learning and capturing intricate patterns within the data. Early applications
    of neural networks, such as **recurrent NNs** (**RNNs**) and **long short-term
    memory networks** (**LSTMs**), demonstrated the potential of deep learning in
    handling sequential data and extracting entities with greater accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: While models such as BERT and its successors represent a significant leap in
    NLP, our focus will remain on models and techniques that align with the practical
    applications and tools used in Bedrock. We will explore some deep learning approaches
    and models that have proven effective in various scenarios and are relevant to
    our framework.
  prefs: []
  type: TYPE_NORMAL
- en: Transformer-based models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Transformer architectures, introduced by the seminal paper *Attention is All
    You Need* (*Vaswani et al.*, *2017*: [https://arxiv.org/abs/1706.03762](https://arxiv.org/abs/1706.03762)),
    have become the backbone of many SOTA LLMs for entity extraction. These models
    employ self-attention mechanisms to capture long-range dependencies within the
    input text, enabling them to better understand the context and relationships between
    entities.'
  prefs: []
  type: TYPE_NORMAL
- en: BERT, developed by Google AI, is a prominent example of a transformer-based
    model that has achieved exceptional results in various NLP tasks, including entity
    extraction. It is a bidirectional model, meaning it can process text in both directions
    simultaneously, allowing it to capture contextual information more effectively
    than its predecessors.
  prefs: []
  type: TYPE_NORMAL
- en: Sequence labeling and CRFs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Entity extraction can be framed as a sequence labeling problem, where each token
    in the input text is assigned a label indicating its entity type (for example,
    person, organization, location) or a non-entity label. LLMs can be trained to
    perform this task by leveraging techniques such as CRFs or the more recent **bidirectional
    LSTM with CRF** (**BiLSTM-CRF**) architecture.
  prefs: []
  type: TYPE_NORMAL
- en: '**CRFs** are probabilistic graphical models that can effectively capture the
    dependencies between labels in a sequence, making them well suited for entity
    extraction tasks. They model the conditional probability of label sequences given
    the input text, allowing for the incorporation of rich features and contextual
    information.'
  prefs: []
  type: TYPE_NORMAL
- en: '**BiLSTM-CRF models** combine the strengths of BiLSTMs for capturing long-range
    dependencies and CRFs for sequence labeling. This hybrid approach has shown impressive
    performance in entity extraction, particularly in scenarios where entities may
    span multiple tokens or have complex structures.'
  prefs: []
  type: TYPE_NORMAL
- en: Rule-based systems
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While deep learning approaches have gained significant traction in recent years,
    rule-based systems remain valuable tools in the entity extraction domain. These
    systems rely on manually crafted rules and patterns to identify and classify entities
    within text, leveraging domain-specific knowledge and expert insights. These rules
    can be augmented to the prompt template when invoking Amazon Bedrock in order
    to generate a desirable response from the FMs. For example, in a medical application,
    the rule-based component might identify drug names, dosages, and patient information
    using predefined patterns.
  prefs: []
  type: TYPE_NORMAL
- en: Regular expressions and pattern matching
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Regular expressions** and **pattern-matching** techniques are fundamental
    building blocks of rule-based entity extraction systems. These methods allow for
    the definition of patterns that can match and extract specific entity types, such
    as phone numbers, email addresses, or specific named entities (for example, company
    names and product names).'
  prefs: []
  type: TYPE_NORMAL
- en: 'While regular expressions can be effective for well-defined and structured
    entity types, they may struggle with more complex or ambiguous entities that require
    contextual understanding. Nevertheless, they remain valuable tools, particularly
    in combination with other techniques or as a preprocessing step for more advanced
    methods. Here are some examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Ruleset**: Define rules using regular expressions and pattern matching to
    identify specific entities such as drug names, dosages, and patient information'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`\d+mg` (for example, `500mg`)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Patient information can be identified through patterns such as `Patient: [A-Za-z]+`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gazetteer lists and dictionaries
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Gazetteer lists** and **dictionaries** are curated collections of known entities,
    often organized by entity type or domain. These resources can be used to match
    and extract entities within text by performing lookups against predefined lists.'
  prefs: []
  type: TYPE_NORMAL
- en: For example, a gazetteer of geographic locations can be employed to identify
    and extract mentions of cities, countries, or other places in a given text. Similarly,
    dictionaries of person names or organization names can ease the extraction of
    these entity types.
  prefs: []
  type: TYPE_NORMAL
- en: While gazetteer lists and dictionaries can be highly accurate for the entities
    they cover, they may struggle with ambiguity, variations, or newly emerging entities
    not present in the predefined lists. Additionally, maintaining and updating these
    resources can be a labor-intensive process, especially in rapidly evolving domains.
  prefs: []
  type: TYPE_NORMAL
- en: Hybrid approaches
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In practice, many entity extraction systems employ a combination of deep learning
    and rule-based techniques, leveraging the strengths of both approaches to achieve
    optimal performance. These hybrid approaches aim to strike a balance between the
    flexibility and generalization capabilities of deep learning models and the precision
    and interpretability of rule-based systems.
  prefs: []
  type: TYPE_NORMAL
- en: Ensemble methods
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Ensemble methods** involve combining the outputs of multiple entity extraction
    models, potentially using different architectures or techniques, to improve overall
    performance. This approach can leverage the strengths of individual models while
    mitigating their weaknesses, resulting in more robust and accurate entity extraction.'
  prefs: []
  type: TYPE_NORMAL
- en: For example, an ensemble system might combine the predictions of a transformer-based
    model such as BERT with those of a rule-based system or a gazetteer lookup. The
    outputs of these models can be combined using various strategies, such as majority
    voting, weighted averaging, or more sophisticated ensemble learning techniques.
  prefs: []
  type: TYPE_NORMAL
- en: Hybrid architectures
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Hybrid architectures** integrate deep learning and rule-based components
    within a single model, allowing for the seamless integration of both approaches.
    These architectures often involve a deep learning component for learning representations
    and capturing contextual information, combined with rule-based components for
    incorporating domain-specific knowledge or handling well-defined entity types.'
  prefs: []
  type: TYPE_NORMAL
- en: 'One example of a hybrid architecture is the use of LLMs for entity representation
    learning, followed by a rule-based component for entity classification or extraction.
    The LLM component can learn rich representations of the input text, capturing
    contextual information and long-range dependencies, while the rule-based component
    can leverage expert knowledge and precise patterns for entity identification and
    classification. For instance, consider an application designed to extract financial
    information from corporate earnings reports. Here’s a detailed example of how
    a hybrid architecture can be implemented:'
  prefs: []
  type: TYPE_NORMAL
- en: '`revenue`, `net income`, and `operating expenses`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`revenue`, `net income`, or `expenses`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Extracting dates and fiscal periods using regular expressions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recognizing company-specific terminology and abbreviations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The rule-based system analyzes the LLM-generated representations, applying these
    rules to accurately extract specific financial entities.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s now look at how the representations are integrated and optimized:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Pipeline**: The system processes the earnings report through the LLM, which
    outputs rich text representations. These representations are then fed into the
    rule-based component.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Output**: The final output includes precisely extracted financial entities,
    such as revenue figures, net income amounts, and fiscal periods, all verified
    and categorized according to the predefined rules.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By employing such a hybrid approach on Amazon Bedrock, the application leverages
    the comprehensive text understanding provided by LLMs and the precision and reliability
    of rule-based extraction methods. This approach ensures that entity extraction
    is more accurate and contextually aware, making it useful for complex domains
    such as financial analysis.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to gain a deeper understanding of hybrid LLM frameworks, readers are
    encouraged to read these papers: *Hybrid LLM-Rule-based Approaches to Business
    Insights Generation from Structured Data* (https://arxiv.org/pdf/2404.15604) and
    *An innovative hybrid approach for extracting named entities from unstructured
    text* *data* (https://www.researchgate.net/publication/332676137_An_innovative_hybrid_approach_for_extracting_named_entities_from_unstructured_text_data).'
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we covered different approaches (deep learning, rule-based,
    and hybrid approaches) associated with entity extraction. Now that we have a basic
    understanding of these approaches, let us dive into some industrial use cases
    of entity extraction.
  prefs: []
  type: TYPE_NORMAL
- en: Industrial use cases of entity extraction – unleashing the power of unstructured
    data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Entity extraction has numerous applications across various domains, ranging
    from information retrieval and knowledge management to DSSs and **business intelligence**
    (**BI**). In this section, we will explore some practical use cases and applications
    of entity extraction with GenAI:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Google was founded by Larry Page and Sergey Brin while they were Ph.D. students
    at` `Stanford University.`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'With entity extraction, the following information can be extracted:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Google (Organization)`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Larry` `Page (Person)`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Sergey` `Brin (Person)`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Stanford` `University (Organization`)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`founded by` (`Google` -> `Larry Page and Sergey Brin`) and `studied at` (`Larry
    Page and Sergey Brin` -> `Stanford University`), are established as edges connecting
    the nodes. This structured representation allows for efficient querying and reasoning
    over the information.*   `Google (Organization)`*   `Larry` `Page (Person)`*   `Sergey`
    `Brin (Person)`*   `Stanford` `University (Organization)`*   `Google -> Founded
    by ->` `Larry Page`*   `Google -> Founded by ->` `Sergey Brin`*   `Larry Page
    -> Studied at ->` `Stanford University`*   `Sergey Brin -> Studied at ->` `Stanford
    University`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'LLMs on Amazon Bedrock can be employed for accurate and scalable entity extraction,
    facilitating the creation of comprehensive knowledge graphs from diverse data
    sources, such as news articles, scientific publications, or social media posts.
    These knowledge graphs can power various applications, including question answering
    systems, recommendation engines, and decision support tools. Here are some examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Biomedical and scientific literature analysis**: Entity extraction is particularly
    valuable in the biomedical and scientific domains, where vast amounts of unstructured
    text data are generated through research publications, clinical notes, and other
    sources. Identifying and classifying entities such as genes, proteins, diseases,
    and chemical compounds can enable researchers and healthcare professionals to
    quickly navigate and extract insights from this wealth of information.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LLMs in Amazon Bedrock can be fine-tuned on domain-specific datasets to achieve
    high accuracy in extracting biomedical and scientific entities. These models can
    assist in literature review processes, drug discovery pipelines, and the development
    of knowledge bases for precision medicine and personalized healthcare.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**BI and competitive analysis**: In the business world, entity extraction can
    be leveraged for competitive analysis, market research, and BI applications. By
    extracting entities such as company names, product names, and industry-specific
    terms from news articles, social media posts, and other online sources, businesses
    can gain valuable insights into their competitors, market trends, and customer
    sentiment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Amazon Bedrock APIs can be coupled with **BI platforms** (**BIPs**) and analytics
    tools, enabling real-time entity extraction and analysis of vast amounts of unstructured
    data. This can empower data-driven decision-making, strategic planning, and the
    identification of new business opportunities.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Social media monitoring and sentiment analysis**: Social media platforms
    generate a constant stream of user-generated content, containing valuable information
    about public opinion, trends, and sentiment toward various entities, such as brands,
    products, or public figures. Entity extraction plays a crucial role in social
    media monitoring and sentiment analysis by identifying the relevant entities within
    this unstructured data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LLMs in Amazon Bedrock can be employed to accurately extract entities from social
    media posts, enabling sentiment analysis and opinion mining around these entities.
    This can provide businesses with valuable insights into customer feedback, brand
    perception, and potential issues or opportunities, allowing them to respond proactively
    and shape their marketing and communication strategies accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we covered industrial applications applicable in the context
    of entity extraction. Keep in mind that the number of these use cases can increase
    exponentially as we uncover more diverse scenarios across different industries.
    Now, let us learn how to leverage Amazon Bedrock for entity extraction use cases.
  prefs: []
  type: TYPE_NORMAL
- en: Entity extraction with Amazon Bedrock
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At its core, entity extraction with GenAI involves providing a prompt that instructs
    the model to identify and classify relevant entities within a given text input.
    The key is constructing prompts that are clear, consistent, and provide enough
    examples for the model to understand the desired behavior.
  prefs: []
  type: TYPE_NORMAL
- en: The Amazon Bedrock service, with the ability to invoke LLMs in a serverless
    manner, provides a scalable and cost-effective solution for entity extraction.
    This service allows developers to leverage pre-trained models or fine-tune them
    on custom datasets, enabling tailored entity extraction for specific domains or
    use cases.
  prefs: []
  type: TYPE_NORMAL
- en: Structuring prompts for entity extraction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When designing prompts for entity extraction tasks, it’s essential to provide
    clear instructions and examples to the model. A well-structured prompt typically
    includes the following components:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Identify and classify the following entities in the` `given text`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Person`, `Organization`, `Location`, and so on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Example inputs and outputs**: Include one or more examples of input text
    with the corresponding entities annotated. This helps the model understand the
    desired output format and learn from real-world instances.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following is an example prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '`''''''`'
  prefs: []
  type: TYPE_NORMAL
- en: '`: Identify and classify the following entities in the` `given text:`'
  prefs: []
  type: TYPE_NORMAL
- en: '`Entity Types: Person,` `Organization, Location`'
  prefs: []
  type: TYPE_NORMAL
- en: '`: "Michael Jordan, the legendary basketball player for the Chicago Bulls,
    announced his retirement from the NBA after an` `illustrious career."`'
  prefs: []
  type: TYPE_NORMAL
- en: '`The output looks` `like this:`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '`Let''s look at` `another example:`'
  prefs: []
  type: TYPE_NORMAL
- en: '`: "Apple Inc., the tech giant based in Cupertino, California, unveiled its
    latest iPhone model at a` `press event."`'
  prefs: []
  type: TYPE_NORMAL
- en: '`The output looks` `like this:`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '`''''''`'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s explore these use cases through a code example and generate an output
    by invoking an Anthropic Claude 3 Sonnet FM on Amazon Bedrock.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Please ensure that you have the required libraries, such as `boto3`, installed
    to run the code. If not, please install the library using the `pip install boto3`
    command in your editor.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, ensure that you have enabled access to the models available on
    Amazon Bedrock. For further documentation on model access on Bedrock, please visit
    https://docs.aws.amazon.com/bedrock/latest/userguide/model-access.html.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s a sample output from the FM:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.1 – Sample output](img/B22045_08_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.1 – Sample output
  prefs: []
  type: TYPE_NORMAL
- en: While this basic structure works for simple cases, more advanced prompting techniques
    are needed for robust, production-level entity extraction.
  prefs: []
  type: TYPE_NORMAL
- en: Incorporating context and domain knowledge
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Entity extraction scenarios often benefit from contextual information and domain-specific
    knowledge. By providing relevant background or domain-specific details within
    the prompt, you can enhance the model’s understanding and improve its ability
    to accurately identify entities.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s an example prompt with context:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3] [PRE4]'
  prefs: []
  type: TYPE_NORMAL
- en: '[Athlete: Serena Williams], [Athlete: Venus Williams], [Tournament: Grand Slam],
    [Tournament: Australian Open], [Sport: tennis]'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]` [PRE6]`'
  prefs: []
  type: TYPE_NORMAL
- en: 'In *Figure 8**.2*, the code sample for the preceding use case is depicted.
    It’s important to note that the code does not explicitly mention the installed
    libraries. It is assumed that users have already pre-installed the required Python
    packages and libraries, as detailed in the previous code sample:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.2 – Prompting Amazon Bedrock FM for entity extraction with contextual
    information](img/B22045_08_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.2 – Prompting Amazon Bedrock FM for entity extraction with contextual
    information
  prefs: []
  type: TYPE_NORMAL
- en: 'It might produce favorable output for certain FMs based on the input instructions.
    However, in other scenarios, it has the potential to generate hallucinated or
    irrelevant additional information, as demonstrated in *Figure 8**.3*. Therefore,
    employing few-shot prompting can be advantageous for entity extraction in such
    cases:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.3 – AI21 Labs J2 Jumbo Instruct FM output](img/B22045_08_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.3 – AI21 Labs J2 Jumbo Instruct FM output
  prefs: []
  type: TYPE_NORMAL
- en: Leveraging few-shot learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As you are aware, few-shot learning involves providing the model with a small
    number of labeled examples during training or inference. This approach can be
    particularly effective for entity extraction tasks, as it allows the model to
    learn from a limited set of high-quality examples and generalize to new, unseen
    data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s an example prompt with few-shot learning:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7] [PRE8]'
  prefs: []
  type: TYPE_NORMAL
- en: '[Company: Microsoft], [Product: Windows 11], [Location: Redmond], [Location:
    Washington]'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '[Company: Alphabet Inc.], [Company: Google], [Location: Iowa], [Location: Nevada]'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '[Company: Samsung Electronics], [Product: Galaxy S22], [Location: South Korea]'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]` [PRE12]`'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s craft a code sample for the preceding use case and invoke the Amazon
    Titan model on Amazon Bedrock:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Executing the preceding code generates the following output, as shown in *Figure
    8**.4*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure 8.4 – Generated output from Amazon Titan FM](img/B22045_08_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.4 – Generated output from Amazon Titan FM
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, in this example, the prompt offers a set of labeled instances to
    assist the model in understanding the entity extraction task within the technology
    domain. Through the utilization of few-shot learning, the model can proficiently
    generalize to unfamiliar input text, all while upholding a high level of accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: Iterative refinement and evaluation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Prompt engineering constitutes an iterative process that frequently necessitates
    refinement and evaluation. As you explore various prompts and techniques, it’s
    vital to assess the model’s performance through automatic model evaluation or
    human evaluation methods, as elaborated upon in [*Chapter 11*](B22045_11.xhtml#_idTextAnchor207).
    Through careful analysis of the model’s outputs and identifying areas for enhancement,
    you can iteratively refine your prompts, thereby augmenting the overall accuracy
    of your entity extraction system.
  prefs: []
  type: TYPE_NORMAL
- en: 'Take a look at the following example of model analysis and refinement:'
  prefs: []
  type: TYPE_NORMAL
- en: '`''''''`'
  prefs: []
  type: TYPE_NORMAL
- en: '`:`'
  prefs: []
  type: TYPE_NORMAL
- en: '`: Identify and classify entities in the` `given text.`'
  prefs: []
  type: TYPE_NORMAL
- en: '`Entity Types: Person,` `Organization, Location`'
  prefs: []
  type: TYPE_NORMAL
- en: '`: "Elon Musk, the CEO of Tesla Inc., announced plans to build a new Gigafactory
    in` `Austin, Texas."`'
  prefs: []
  type: TYPE_NORMAL
- en: '`The output looks` `like this:`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '`: The model correctly identified the person and organization entities but
    missed the` `location "Texas."`'
  prefs: []
  type: TYPE_NORMAL
- en: '`:`'
  prefs: []
  type: TYPE_NORMAL
- en: '`: Identify and classify entities in the given text, including nested or` `multi-word
    entities.`'
  prefs: []
  type: TYPE_NORMAL
- en: '`Entity Types: Person,` `Organization, Location`'
  prefs: []
  type: TYPE_NORMAL
- en: '`: "Elon Musk, the CEO of Tesla Inc., announced plans to build a new Gigafactory
    in` `Austin, Texas."`'
  prefs: []
  type: TYPE_NORMAL
- en: '`The output looks` `like this:`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '`''''''`'
  prefs: []
  type: TYPE_NORMAL
- en: By refining the prompt to include instructions for handling nested or multi-word
    entities, the model’s performance improved, correctly identifying the location
    as Austin, Texas.
  prefs: []
  type: TYPE_NORMAL
- en: We encourage users to run the provided code on Amazon Bedrock to extract pertinent
    entities using the Claude 3 model and the `Messages` API. As mentioned earlier,
    please ensure that access to these models on Amazon Bedrock is enabled. For further
    documentation on accessing models on Bedrock, please visit [https://docs.aws.amazon.com/bedrock/latest/userguide/model-access.html](https://docs.aws.amazon.com/bedrock/latest/userguide/model-access.html).
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'Make sure you have the `boto3` library installed, as explained in the previous
    chapters. If not, please install the latest version using the following command:
    `pip` `install boto3`.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Printing `response_body` as shown in the preceding snippet might yield the
    following output, as expected:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Hence, by leveraging effective prompt engineering techniques with Amazon Bedrock,
    such as providing clear instructions, relevant examples, and handling ambiguity,
    GenAI models can be guided to perform high-quality entity extraction across several
    use cases and different domains. As with any AI application, it requires careful
    design, testing, and refinement to build a truly production-ready system.
  prefs: []
  type: TYPE_NORMAL
- en: As LLMs continue to grow in size and complexity, their capabilities in entity
    extraction are expected to further improve, enabling more accurate and robust
    solutions.
  prefs: []
  type: TYPE_NORMAL
- en: Ongoing research also focuses on integrating external knowledge sources such
    as knowledge graphs or ontologies into LLMs for entity extraction. By embedding
    structured knowledge into the model’s architecture or training regimen, these
    methods have the potential to enrich the model’s comprehension of entities and
    their interconnections, thereby potentially enhancing both performance and interpretability.
  prefs: []
  type: TYPE_NORMAL
- en: 'Check the following AWS blog showcasing the integration of **intelligent document
    processing** (**IDP**) in the context of entity extraction automation using AWS
    AI/ML services such as Amazon Textract with Amazon Bedrock and LangChain: [https://aws.amazon.com/blogs/machine-learning/intelligent-document-processing-with-amazon-textract-amazon-bedrock-and-langchain/](https://aws.amazon.com/blogs/machine-learning/intelligent-document-processing-with-amazon-textract-amazon-bedrock-and-langchain/).'
  prefs: []
  type: TYPE_NORMAL
- en: This solution proves particularly beneficial for handling handwritten or scanned
    documents, encompassing the extraction of pertinent data from various file formats
    such as PDF, PNG, TIFF, and JPEG, regardless of the document layout. The Amazon
    Textract service facilitates the automatic extraction of text, handwriting, and
    data from such scanned documents.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consequently, this solution capitalizes on the strengths of each component:
    Amazon Textract for precise data extraction, Amazon Bedrock for streamlined data
    processing pipelines, and LangChain for seamlessly integrating LLMs into the workflow.
    Overall, the blog post offers a pragmatic solution for automating document processing
    tasks, underscoring the advantages of leveraging AWS services and open source
    frameworks such as LangChain to develop intelligent applications. Therefore, it
    holds substantial potential for diverse document processing scenarios, providing
    dynamic adaptability to evolving data patterns.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Additional examples of entity extraction with Bedrock have been added here:
    [https://github.com/aws-samples/amazon-bedrock-workshop/blob/main/01_Text_generation/04_entity_extraction.ipynb](https://github.com/aws-samples/amazon-bedrock-workshop/blob/main/01_Text_generation/04_entity_extraction.ipynb).
    Users are encouraged to run and execute the code cells to gain a much better understanding
    of entity extraction using Amazon Bedrock for GenAI use cases.'
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have grasped the concepts of entity extraction in more detail,
    we will dive into more code generation scenarios in the universe of Amazon Bedrock.
  prefs: []
  type: TYPE_NORMAL
- en: Code generation with LLMs – unleashing the power of AI-driven development
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As the field of AI continues to evolve, one of the most exciting and promising
    areas is the use of LLMs for code generation, especially in the case of developer
    productivity gains. Customers can leverage state-of-the-art LLMs available on
    Amazon Bedrock to generate high-quality code, revolutionizing the way developers
    approach software development.
  prefs: []
  type: TYPE_NORMAL
- en: The code generation process
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The code generation process with Amazon Bedrock is straightforward and user-friendly.
    Developers can interact with the platform through a web-based interface or via
    an API, as discussed in the previous chapters. The process typically involves
    the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Problem description**: The developer provides a natural language description
    of the desired functionality or task that they want the code to perform.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Context and constraints**: The developer can optionally provide additional
    context, such as programming language preferences, coding styles, or specific
    libraries or frameworks to be used.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**LLM code generation**: Amazon Bedrock’s LLMs analyze the problem description
    and any provided context and generate the corresponding code.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Code refinement**: The generated code can be iteratively refined through
    additional prompts or feedback from the developer, allowing for a collaborative
    and interactive process.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Code integration**: The final generated code can be seamlessly integrated
    into the developer’s project or code base.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Benefits of code generation with Amazon Bedrock
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Leveraging LLMs for code generation offers numerous benefits to developers,
    including the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Increased productivity**: With Amazon Bedrock, developers can quickly generate
    code for various tasks and functionalities, reducing the time and effort required
    for manual coding'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Improved code quality**: The code generated by Amazon Bedrock’s LLMs can
    provide high-quality outputs, adhering to best practices and coding standards
    based on the iterative refinement of the prompts'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reduced errors**: LLMs can help reduce the likelihood of common coding errors,
    such as syntax errors or logical flaws, by generating correct and coherent code
    with prompt engineering'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Exploration and prototyping**: Bedrock enables developers to rapidly explore
    and prototype different ideas and approaches, facilitating more efficient and
    creative problem-solving'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Accessibility**: By leveraging natural language descriptions and FMs for
    code generation purposes (Llama, Claude, Titan, Mistral, and so on), Amazon Bedrock
    makes code generation more accessible to developers with varying levels of expertise
    or backgrounds'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Limitations and considerations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'While LLM-based code generation offers numerous advantages, it is important
    to be aware of their limitations and considerations:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Specialized domain knowledge**: LLMs may not always generate code that requires
    highly specialized domain knowledge or complex algorithms. Human expertise and
    review may still be necessary in certain cases.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Security and compliance**: Generated code should be thoroughly reviewed and
    tested to ensure it adheres to security best practices and any relevant compliance
    requirements.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Integration and maintenance**: Generated code may need to be adapted and
    maintained over time as requirements or dependencies change.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Ethical considerations**: As with any AI system, it is crucial to ensure
    LLMs are used responsibly and ethically, considering potential biases or unintended
    consequences.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use cases and examples
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Amazon Bedrock’s code generation capabilities can be applied to a wide range
    of use cases across various domains and programming languages. Some examples include
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Web development**: Developers can generate code using Bedrock for web applications,
    APIs, or user interfaces using languages such as JavaScript, Python, or Ruby.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data processing and analysis**: Developers can leverage Bedrock to write
    code for data manipulation, analysis, and visualization tasks using languages
    such as Python or R.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Mobile app development**: Bedrock can be utilized to generate code for mobile
    applications using languages such as Swift, Kotlin, or React Native.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Embedded systems and Internet of Things (IoT) devices**: Developers can create
    code for embedded systems, microcontrollers, or IoT devices using languages such
    as C, C++, or Rust with the assistance of Bedrock models.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scientific computing**: Bedrock can aid in writing code for scientific simulations,
    numerical calculations, or data processing tasks using languages such as MATLAB,
    Julia, or Fortran through its code generation features.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, let’s look at a few examples of code generation, debugging, or code transformation
    use cases with Amazon Bedrock.
  prefs: []
  type: TYPE_NORMAL
- en: Prompt engineering examples with Amazon Bedrock
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here is a sample prompt given to a Claude 3 Sonnet model within Amazon Bedrock
    to adopt the role of a Python developer and perform a code generation task:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]python block. After writing the code, carefully check for errors. If
    errors exist, list them within <error> tags and provide a new corrected version.
    If no errors, write "CHECKED: NO ERRORS" within <[PRE20]'
  prefs: []
  type: TYPE_NORMAL
- en: Import the respective libraries
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: import boto3
  prefs: []
  type: TYPE_NORMAL
- en: import botocore
  prefs: []
  type: TYPE_NORMAL
- en: import os
  prefs: []
  type: TYPE_NORMAL
- en: import json
  prefs: []
  type: TYPE_NORMAL
- en: import sys
  prefs: []
  type: TYPE_NORMAL
- en: '#Create client side Amazon Bedrock connection with Boto3 library'
  prefs: []
  type: TYPE_NORMAL
- en: region = os.environ.get("AWS_REGION")
  prefs: []
  type: TYPE_NORMAL
- en: bedrock_runtime = boto3.client(service_name='bedrock-runtime',region_name=region)
  prefs: []
  type: TYPE_NORMAL
- en: 'Adding prompt example here:'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'prompt_data = """Human: You are an expert Python developer tasked with coding
    a web scraper for an experienced developer. The scraper should extract data from
    multiple web pages and store the results in a SQLite database. Write clean, high-quality
    Python code for this task, including necessary imports. Do not write anything
    before the [PRE21]'
  prefs: []
  type: TYPE_NORMAL
- en: 'We won’t dive into the entirety of the output generated, but provided in *Figure
    8**.5* is a code snippet generated as a result of invoking a Claude 3 Sonnet model
    via Amazon Bedrock API with the preceding prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.5 – Output code snippet generated by invoking Claude 3 Sonnet model
    via Amazon Bedrock](img/B22045_08_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.5 – Output code snippet generated by invoking Claude 3 Sonnet model
    via Amazon Bedrock
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 8**.6* shows yet another example of a code debugging use case, leveraging
    a Llama 2 Chat 13B model available on Amazon Bedrock within the chat playground:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.6 – Code debugging using Llama 2 Chat 13B model on Amazon Bedrock](img/B22045_08_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.6 – Code debugging using Llama 2 Chat 13B model on Amazon Bedrock
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s take a look at a code translation scenario. Here’s an example prompt
    for a code translation use case with a Mixtral 8X7B instruct model on Amazon Bedrock,
    followed by a generated output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]python'
  prefs: []
  type: TYPE_NORMAL
- en: 'class BankAccount:'
  prefs: []
  type: TYPE_NORMAL
- en: 'def __init__(self, initial_balance=0):'
  prefs: []
  type: TYPE_NORMAL
- en: self.balance = initial_balance
  prefs: []
  type: TYPE_NORMAL
- en: 'def deposit(self, amount):'
  prefs: []
  type: TYPE_NORMAL
- en: self.balance += amount
  prefs: []
  type: TYPE_NORMAL
- en: 'def withdraw(self, amount):'
  prefs: []
  type: TYPE_NORMAL
- en: 'if self.balance >= amount:'
  prefs: []
  type: TYPE_NORMAL
- en: self.balance -= amount
  prefs: []
  type: TYPE_NORMAL
- en: 'else:'
  prefs: []
  type: TYPE_NORMAL
- en: print("Insufficient funds")
  prefs: []
  type: TYPE_NORMAL
- en: 'def check_balance(self):'
  prefs: []
  type: TYPE_NORMAL
- en: return self.balance
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The translated JavaScript code output looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]javascript'
  prefs: []
  type: TYPE_NORMAL
- en: // Define the BankAccount class
  prefs: []
  type: TYPE_NORMAL
- en: class BankAccount {
  prefs: []
  type: TYPE_NORMAL
- en: // Initialize the balance property with an initial_balance of 0
  prefs: []
  type: TYPE_NORMAL
- en: constructor(initial_balance = 0) {
  prefs: []
  type: TYPE_NORMAL
- en: this.balance = initial_balance;
  prefs: []
  type: TYPE_NORMAL
- en: '}'
  prefs: []
  type: TYPE_NORMAL
- en: // Deposit method to add amount to the balance
  prefs: []
  type: TYPE_NORMAL
- en: deposit(amount) {
  prefs: []
  type: TYPE_NORMAL
- en: this.balance += amount;
  prefs: []
  type: TYPE_NORMAL
- en: '}'
  prefs: []
  type: TYPE_NORMAL
- en: // Withdraw method to subtract amount from the balance if there are sufficient
    funds
  prefs: []
  type: TYPE_NORMAL
- en: withdraw(amount) {
  prefs: []
  type: TYPE_NORMAL
- en: if (this.balance >= amount) {
  prefs: []
  type: TYPE_NORMAL
- en: this.balance -= amount;
  prefs: []
  type: TYPE_NORMAL
- en: '} else {'
  prefs: []
  type: TYPE_NORMAL
- en: console.log("Insufficient funds");
  prefs: []
  type: TYPE_NORMAL
- en: '}'
  prefs: []
  type: TYPE_NORMAL
- en: '}'
  prefs: []
  type: TYPE_NORMAL
- en: // Check_balance method to return the current balance
  prefs: []
  type: TYPE_NORMAL
- en: check_balance() {
  prefs: []
  type: TYPE_NORMAL
- en: return this.balance;
  prefs: []
  type: TYPE_NORMAL
- en: '}'
  prefs: []
  type: TYPE_NORMAL
- en: '}'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: In this example, the prompt provides context about the code’s purpose and the
    original Python code and instructs Code Llama to translate it to JavaScript. The
    model is asked to maintain clear variable naming and proper indentation and add
    comments to explain non-trivial logic or language-specific constructs.
  prefs: []
  type: TYPE_NORMAL
- en: 'The generated output shows the translated JavaScript code, with the class structure
    and methods translated correctly while preserving the original functionality.
    After translating the code, the model has carefully reviewed its work and indicated
    `CHECKED: NO ERRORS` within `<error>` tags, signifying that the translation is
    correct and error-free.'
  prefs: []
  type: TYPE_NORMAL
- en: This example demonstrates how a prompt can be crafted to guide Code Llama (or
    similar AI code models) to perform code translation tasks while ensuring the translated
    code is verified and correct. Note that it is always a best practice to perform
    a human evaluation of the generated output to verify the accuracy of these models
    and rectify any issues.
  prefs: []
  type: TYPE_NORMAL
- en: Users are encouraged to try these examples within the Amazon Bedrock playground
    or leveraging Amazon Bedrock APIs with several other models such as Amazon Titan,
    Cohere Command, Meta Llama, and alternate variations of Anthropic Claude or Mistral
    models to test the generated output and refine it further.
  prefs: []
  type: TYPE_NORMAL
- en: 'Users are further invited to explore this code sample where Amazon Bedrock
    LLMs are being invoked with zero-shot prompting to generate SQL and Python programs:
    [https://github.com/aws-samples/amazon-bedrock-workshop/blob/main/01_Text_generation/01_code_generation_w_bedrock.ipynb](https://github.com/aws-samples/amazon-bedrock-workshop/blob/main/01_Text_generation/01_code_generation_w_bedrock.ipynb).'
  prefs: []
  type: TYPE_NORMAL
- en: Entity extraction with GenAI represents a significant step forward in our ability
    to extract valuable insights from unstructured text data. By leveraging the power
    of LLMs and combining them with rule-based techniques, hybrid approaches offer
    accurate, scalable, and domain-adaptable solutions for a wide range of applications.
    As we continue to push the boundaries of these areas, we can expect to unlock
    new opportunities for knowledge discovery, decision support, and data-driven innovation
    across various industries and domains.
  prefs: []
  type: TYPE_NORMAL
- en: The field of LLM-based code generation is also rapidly evolving, and Amazon
    Bedrock is at the forefront of this exciting development. As LLMs become more
    advanced and the available training data continues to grow, the capabilities and
    applications of code generation will expand further. Amazon Bedrock represents
    a significant step forward in the realm of code generation, empowering developers
    to leverage the power of LLMs to increase productivity, improve code quality,
    and explore new ideas more efficiently. As this technology continues to mature,
    it has the potential to revolutionize the way software is developed and open up
    new possibilities for innovation across various industries and domains.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter commenced with an in-depth exploration of entity extraction, uncovering
    its fundamentals, techniques, and best practices. It then transitioned to showcasing
    potential industrial applications of entity extraction, highlighting real-world
    use cases that demonstrate the power of unlocking valuable insights from unstructured
    data across various sectors.
  prefs: []
  type: TYPE_NORMAL
- en: Recognizing the pivotal role of prompt engineering, the chapter further provided
    a comprehensive guide to crafting effective prompts, equipping readers with strategies
    and guidelines to optimize entity extraction performance. Shifting gears, the
    discussion then centered on the transformative potential of code generation with
    LLMs on Amazon Bedrock. We gained insights into the capabilities and limitations
    of LLMs in driving AI-based development, as well as methodologies for leveraging
    these cutting-edge models.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the chapter culminated with a compelling exploration of practical use
    cases for code generation, demonstrating how this technology can accelerate innovation
    and boost productivity across various domains. Through real-world examples and
    case studies, readers witnessed firsthand the profound impact of code generation
    on streamlining development processes and unleashing new possibilities. In the
    following chapter, we are going to explore image generation use cases with Amazon
    Bedrock, along with its potential applications. Stay tuned!
  prefs: []
  type: TYPE_NORMAL
