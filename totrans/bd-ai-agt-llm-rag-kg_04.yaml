- en: '4'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '4'
- en: Building a Web Scraping Agent with an LLM
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用LLM构建网络爬虫代理
- en: The French philosopher Denis Diderot said, “*If they find a parrot who could
    answer to everything, I would claim it to be an intelligent being without hesitation*.”
    Diderot was referring to a parrot, but an LLM could be defined as a sophisticated
    parrot. There is a difference between *answering* a question and *understanding*
    a question. Therefore, today, we do not define LLMs as intelligent beings. They
    can though answer almost any question amazingly well. Despite such answering abilities,
    LLMs cannot perform an action. Therefore, attempts have been made to solve this
    main limitation with the use of agents.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 法国哲学家丹尼斯·狄德罗曾说，“*如果他们找到一只能够回答所有问题的鹦鹉，我会毫不犹豫地宣称它是一个智能生物*。”狄德罗指的是鹦鹉，但一个大型语言模型（LLM）可以被定义为一种复杂的鹦鹉。回答问题和理解问题之间存在着区别。因此，今天，我们并不将LLM定义为智能生物。尽管如此，LLM可以非常出色地回答几乎任何问题。尽管具有这样的回答能力，LLM却无法执行动作。因此，人们尝试通过使用代理来解决这一主要限制。
- en: An AI agent is an extension of an LLM, taking it from a language model toward
    a system that possesses capabilities such as autonomy, reactivity, pro-activeness,
    and social ability. This research has focused, on the one hand, on specific applications
    (such as mastering games such as chess or Go), and on the other, on more general
    abilities, such as memorization, long-term planning, generalization, and efficient
    interaction with the user. These are considered the first steps in the direction
    of **artificial general intelligence** (**AGI**). According to author and philosopher
    Nick Bostrom, “*Machine intelligence is the last invention that humanity will
    ever need to* *make*” ([https://x.com/TEDTalks/status/1191035758704037891](https://x.com/TEDTalks/status/1191035758704037891)).
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能代理是LLM的扩展，使其从语言模型向具有自主性、反应性、主动性和社交能力等能力的系统转变。这项研究一方面关注特定应用（如掌握国际象棋或围棋等游戏），另一方面关注更一般的能力，如记忆、长期规划、泛化和与用户的有效互动。这些都被认为是通向**人工通用智能**（**AGI**）方向的第一步。根据作者和哲学家尼克·博斯特罗姆的说法，“*机器智能是人类将永远需要的最后一种发明*”
    ([https://x.com/TEDTalks/status/1191035758704037891](https://x.com/TEDTalks/status/1191035758704037891))).
- en: AGI, in fact, is a type of intelligence that reaches or exceeds human intelligence
    in a range of cognitive tasks (reasoning, planning, and learning – thus, representing
    knowledge). Creating AGI is the goal of several major companies (such as OpenAI
    and Meta AI). AGI could be an assistant to (and, according to some, replace) humans
    in complex tasks such as research. While many companies view this positively,
    some influential researchers, such as Geoffrey Hinton, are concerned about such
    a development. Prof. Geoffrey Hinton said there is “*a 10% chance of the technology
    triggering a catastrophic outcome for humanity*.” In this chapter and the following,
    we will focus on models and approaches that focus on increasing a model’s capabilities.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 通用人工智能（AGI）实际上是一种在一系列认知任务（推理、规划和学习——因此，代表知识）中达到或超过人类智能的智能类型。创建AGI是几家主要公司（如OpenAI和Meta
    AI）的目标。AGI可能成为人类在复杂任务（如研究）中的助手（根据某些观点，甚至可以取代人类）。尽管许多公司对此持积极态度，但一些有影响力的研究人员，如杰弗里·辛顿，对此发展表示担忧。杰弗里·辛顿教授说，“*有10%的可能性这项技术会引发对人类造成灾难性后果的结果*。”在本章和接下来的章节中，我们将重点关注那些专注于提高模型能力的模型和方法。
- en: The first step we will look at is how to free an LLM from its “box.” For example,
    we will see how to enable a model to be able to retrieve information from the
    internet.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要探讨的第一步是如何让LLM摆脱其“盒子”。例如，我们将看到如何使模型能够从互联网上检索信息。
- en: 'In this chapter, we’ll be covering the following topics:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Understanding the brain, perception, and action paradigm
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解大脑、感知和动作范式
- en: Classifying AI agents
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对人工智能代理进行分类
- en: Understanding the abilities of single-agent and multiple-agent systems
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解单代理和多代理系统的能力
- en: Exploring the principal libraries
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索主要库
- en: The general ability of a single agent
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单个代理的一般能力
- en: Creating an agent to search the web
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个用于搜索网络的代理
- en: Technical requirements
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'Most of this code can be run on a CPU, but it is preferable to run it on a
    GPU. The code is written in PyTorch and uses standard libraries for the most part
    (PyTorch, Hugging Face Transformers, LangChain, pandas, and Matplotlib). The code
    can be found on GitHub: [https://github.com/PacktPublishing/Modern-AI-Agents/tree/main/chr4](https://github.com/PacktPublishing/Modern-AI-Agents/tree/main/chr4).'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数这段代码可以在CPU上运行，但最好在GPU上运行。代码是用PyTorch编写的，大部分使用标准库（PyTorch、Hugging Face Transformers、LangChain、pandas和Matplotlib）。代码可以在GitHub上找到：[https://github.com/PacktPublishing/Modern-AI-Agents/tree/main/chr4](https://github.com/PacktPublishing/Modern-AI-Agents/tree/main/chr4)。
- en: Understanding the brain, perception, and action paradigm
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解大脑、感知和动作范式
- en: An **agent** can be defined as an entity that has the capacity to act. In philosophy,
    an agent is a being that also possesses desires, beliefs, and intentions. Traditionally,
    there is an overlap between an “agent” and a conscious entity. A conscious entity
    should also possess its own internal state that enables it to understand the world
    according to its internal representation.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**代理**可以被定义为具有行动能力的实体。在哲学上，代理是一种也拥有欲望、信念和意图的存在。传统上，“代理”和有意识实体之间存在重叠。有意识实体还应拥有自己的内部状态，使其能够根据其内部表征来理解世界。'
- en: An **AI agent** is defined by its ability to perform an action, but it does
    not possess desires and intentions (unfortunately, as we discussed in the previous
    chapter, a model inherits the biases of its training set and thus we can vaguely
    speak of beliefs). An LLM possesses an internal state, but it is merely a learned
    representation from the data it was trained with. So no, an AI agent is *not*
    a conscious entity. Although the term *agent* (and others such as *representation*
    and *internal state*) has a different meaning in philosophy, calling an LLM conscious
    is an anthropomorphizing fallacy.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**AI代理**的定义在于其执行动作的能力，但它不具备欲望和意图（不幸的是，正如我们在上一章讨论的那样，模型继承了其训练集的偏见，因此我们可以模糊地谈论信念）。LLM拥有内部状态，但这仅仅是它从训练数据中学习到的表征。所以，不，AI代理不是有意识的实体。尽管术语“代理”（以及其他如“表征”和“内部状态”）在哲学上有不同的含义，称LLM为有意识的是一种拟人化的谬误。'
- en: At the same time, through language modeling, an LLM learns a useful representation
    of a text and how to put the elements present in context. An LLM can, then, through
    in-context learning, relate the instruction of a prompt to what it has learned,
    and thus solve a task. During instruction tuning, the model learns to perform
    tasks, all of which are skills that enable the model to perform an action. We
    can define a task as a set of actions that have a definite goal, while an action
    is an individual accomplishable act.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，通过语言建模，LLM学习到文本的有用表征以及如何将现有元素置于上下文中。然后，LLM可以通过上下文学习将提示的指令与它所学习的内容联系起来，从而解决问题。在指令调整期间，模型学习执行任务，所有这些任务都是使模型能够执行动作的技能。我们可以将任务定义为具有明确目标的动作集合，而动作则是一个可完成的单个行为。
- en: 'An AI agent can therefore be defined as an artificial entity that perceives
    its surrounding environment via a set of sensors, makes a decision, and implements
    it. This definition is quite broad and has been used to define various systems.
    In this book, we will focus on LLM-based agents. As a further definition, we will
    use a framework consisting of three parts:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，一个AI代理可以被定义为一种通过一组传感器感知其周围环境、做出决策并实施该决策的人工实体。这个定义相当宽泛，并被用来定义各种系统。在这本书中，我们将专注于基于LLM的代理。作为一个进一步的定义，我们将使用一个由三个部分组成的框架：
- en: '**Brain**: The main component of the system that integrates information, stores
    it, and makes decisions'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**大脑**：系统的主要组件，它整合信息、存储信息并做出决策'
- en: '**Perception**: The component that extends the model’s capabilities in the
    perceptual domain, allowing the system to obtain information from different modalities
    (textual, auditory, and visual modalities)'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**感知**：扩展模型在感知领域能力的组件，允许系统从不同的模态（文本、听觉和视觉模态）获取信息'
- en: '**Action**: The component that enables the model to act and use tools to modify
    its surroundings (or respond to changes in the environment)'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**动作**：使模型能够行动并使用工具来修改其环境（或对环境中的变化做出反应）的组件'
- en: 'We can see how these components are interconnected with each other in the following
    figure:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在以下图中看到这些组件是如何相互关联的：
- en: '![Figure 4.1 – Conceptual framework of an LLM-based agent with three components:
    brain, perception, and action (https://arxiv.org/pdf/2309.07864)](img/B21257_04_01.jpg)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![图4.1 – 基于LLM的代理的概念框架，包含三个组件：大脑、感知和行动 (https://arxiv.org/pdf/2309.07864)](img/B21257_04_01.jpg)'
- en: 'Figure 4.1 – Conceptual framework of an LLM-based agent with three components:
    brain, perception, and action ([https://arxiv.org/pdf/2309.07864](https://arxiv.org/pdf/2309.07864))'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.1 – 基于LLM的代理的概念框架，包含三个组件：大脑、感知和行动 ([https://arxiv.org/pdf/2309.07864](https://arxiv.org/pdf/2309.07864))
- en: An LLM can thus be considered the brain of an agent system, where the LLM has
    access to tools that enable it to perform an action or enable perception. This
    system allows the expansion of an LLM’s space of perception and action, and thus
    its own capabilities (a multimodal extension allows it to integrate information
    of different types, access to the internet allows it to access real-time information,
    and an e-commerce tool allows it to conduct transactions). Indeed, as we saw in
    the previous chapter, an LLM can exhibit reasoning capabilities, which can be
    enhanced with techniques such as **chain-of-thought** (**CoT**) or other prompting
    approaches. In addition, the model, through in-context learning, can generalize
    its abilities to new tasks. CoT prompting can integrate feedback from the environment,
    thus creating reactive systems.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，LLM可以被视为代理系统的“大脑”，其中LLM可以访问使其能够执行动作或感知的工具。这个系统允许扩展LLM的感知和行动空间，从而增强其自身的能力（多模态扩展允许它整合不同类型的信息，互联网的接入允许它获取实时信息，电子商务工具允许它进行交易）。实际上，正如我们在上一章中看到的，LLM可以表现出推理能力，这些能力可以通过如**思维链**（**CoT**）或其他提示方法来增强。此外，通过上下文学习，该模型可以将其能力推广到新的任务中。CoT提示可以整合来自环境的反馈，从而创建反应性系统。
- en: 'We look for four fundamental properties in an agent:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在代理中寻找四个基本属性：
- en: '**Autonomy**: An agent should be able to operate without human intervention.
    In addition, an agent should not need explicit instructions to complete a task
    but should execute it without a step-by-step description. LLMs have shown some
    creativity and ability to solve tasks without needing to explain all the steps.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自主性**：代理应能够在没有人类干预的情况下运行。此外，代理不应需要明确的指令来完成一项任务，而应能够在不进行逐步描述的情况下执行它。LLM已经显示出一些创造力和解决任务的能力，而无需解释所有步骤。'
- en: '**Reactivity**: An agent should respond quickly to changes in the environment,
    perceive an external state change, and respond appropriately. This already happens
    at the textual level for an LLM (for example, in a dialogue where the topic can
    change). Extending an LLM multimodally allows different types of information and
    stimuli to be integrated.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**反应性**：代理应能快速对环境中的变化做出反应，感知外部状态的变化，并做出适当的反应。对于LLM来说，这已经在文本层面上发生了（例如，在对话中，话题可能会改变）。扩展LLM的多模态功能允许整合不同类型的信息和刺激。'
- en: '**Pro-activeness**: The agent’s reaction should not be a mere response but
    directed toward a goal. In other words, an agent should be capable of reasoning
    and conducting plans in response to a change in an environment (these capacities
    can be stimulated in an LLM with reasoning-directed prompting techniques such
    as CoT).'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**主动性**：代理的反应不应仅仅是响应，而应指向一个目标。换句话说，代理应能够根据环境中的变化进行推理和制定计划（这些能力可以通过如CoT等推理导向的提示技术来激发）。'
- en: '**Social ability**: An agent should be able to interact with humans or other
    agents. This is one of the strengths of LLMs that exhibit dialogic and understanding
    skills. In fact, environments can be created with different LLM-based agents with
    different goals and tasks. Environments with multiple agents promote behavior
    as teamwork (where agents coordinate).'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**社交能力**：代理应能够与人类或其他代理进行交互。这是表现出对话和理解技能的LLM的优势之一。实际上，可以创建具有不同目标和任务的基于不同LLM的代理的环境。具有多个代理的环境可以促进团队合作行为（其中代理进行协调）。'
- en: '![Figure 4.2 – Screenshot of a simulated environment featuring multiple agents](img/B21257_04_02.jpg)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![图4.2 – 具有多个代理的模拟环境的截图](img/B21257_04_02.jpg)'
- en: Figure 4.2 – Screenshot of a simulated environment featuring multiple agents
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.2 – 具有多个代理的模拟环境的截图
- en: In *Figure 4**.2*, we can see that agents are interacting not only with the
    environment but also with each other. By collaborating, the agents can solve complex
    tasks. This shows the sophisticated abilities that can be obtained with LLM-based
    agents.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图4.2*中，我们可以看到代理不仅与环境互动，还彼此互动。通过协作，代理可以解决复杂任务。这展示了基于LLM的代理可以获得的复杂能力。
- en: 'One example of collaborative behavior includes 25 agents in a *The Sims*-like
    environment created for the paper *Generative Agents: Interactive Simulacra of
    Human Behavior*, by J. S. Park et al. ([https://arxiv.org/pdf/2304.03442](https://arxiv.org/pdf/2304.03442)).
    Users can observe and intervene as agents plan their days, share news, form relationships,
    and coordinate group activities.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 协作行为的例子之一包括25个代理在一个为论文《生成代理：人类行为交互模拟》创建的类似《模拟人生》的环境中，该论文由J. S. Park等人撰写([https://arxiv.org/pdf/2304.03442](https://arxiv.org/pdf/2304.03442))。用户可以观察并干预代理规划他们的日子、分享新闻、建立关系以及协调团队活动。
- en: In the following sections, we analyze the various components of an AI agent
    (LLM-based), starting with what is called the brain
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将分析AI代理（基于LLM）的各个组成部分，从所谓的“大脑”开始。
- en: The brain
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 大脑
- en: 'The brain is the core of the system and is responsible for several functions:
    saving information, finding knowledge, reasoning, and decision-making. Since the
    core of this system is an LLM, all interactions are based on natural language.
    This is an advantage because these interactions and operations can be understood
    by humans and therefore monitored (especially in case something goes wrong). Because
    an agent can interact with other entities and changes in the surrounding environment,
    it must be capable of multi-turn interactive conversations (conversations with
    multiple entities at the same time, different topics, complex structure, and understanding
    based on previous history). If the agent has poor conversational skills, humans
    will become frustrated when interacting with it, so it’s important that the model
    can communicate clearly. The model must be able to understand instructions, comprehend
    incoming information, integrate this information, and respond appropriately to
    the task.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 大脑是系统的核心，负责几个功能：保存信息、寻找知识、推理和决策。由于这个系统的核心是一个LLM，所有交互都是基于自然语言的。这是一个优势，因为这些交互和操作可以被人类理解，因此可以监控（尤其是在出现问题时）。由于代理可以与其他实体互动，并且周围环境发生变化，它必须能够进行多轮交互对话（同时与多个实体进行对话，涉及不同主题、复杂结构和基于先前历史的理解）。如果代理的对话技巧不佳，当与人类互动时，人们会感到沮丧，因此模型能够清晰沟通非常重要。模型必须能够理解指令、理解传入的信息、整合这些信息，并适当地对任务做出响应。
- en: Today’s LLMs are able to conduct this type of conversation with high quality.
    Conversational skills have increased exponentially in recent years due to alignment.
    Instruction tuning has enabled LLMs to respond to instructions and perform tasks.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 今天的LLM能够以高质量进行这种类型的对话。由于对齐，对话技巧在近年来呈指数增长。指令调整使得LLM能够响应指令并执行任务。
- en: 'Another important component is model knowledge, which is categorized into the
    following:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个重要组成部分是模型知识，它被分为以下几类：
- en: '**Linguistic knowledge**: Knowledge of the semantics and syntax of a language.
    This enables the LLM to interact formally with a human, and today there are LLMs
    in different languages as needed.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**语言知识**：对一种语言的语义和语法的了解。这使得LLM能够以正式的方式与人类互动，并且如今有不同语言的LLM以满足需求。'
- en: '**Common-sense knowledge**: A set of rules and facts that are known to most
    individuals. For instance, anyone can witness the effects of gravity or understand
    that humans cannot fly. This kind of information is not specifically mentioned
    in a prompt or context but is necessary for the model to perform a task or answer
    a question efficiently (and avoid misunderstandings).'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**常识知识**：大多数个体都知道的一套规则和事实。例如，任何人都可以见证重力的效果或理解人类不能飞行。这类信息在提示或上下文中没有具体提及，但对于模型高效地完成任务或回答问题（以及避免误解）是必要的。'
- en: '**Domain knowledge**: Knowledge specific to a professional domain (e.g., science
    or medicine) or technical domain (e.g., mathematics or programming). This is the
    necessary knowledge or skill to be possessed to succeed in a certain domain. There
    are now specialized LLMs in various domains (medicine, finance, and so on), or
    by starting from a generalist model, you can get a specialized model (fine-tuning).'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Also, it is important to remember that knowledge of the model is frozen at the
    time of pre-training. An LLM cannot acquire information (continual learning) or
    remember past interactions with the user. As we will see in the next chapters,
    there are methods to overcome this limitation.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: 'Possessing information is not enough for a brain; our agent must be capable
    of both **reasoning** and **planning**. Techniques with CoT and self-consistency
    (which we saw in the previous chapter) can help the model reason better about
    solving a task. In general, reasoning step by step helps the model have both the
    task-solving and planning steps needed. Planning is a critical component for an
    agent because, to solve a task, the model must select the most appropriate steps
    to achieve the goal. In general, this is a two-stage process:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: '**Plan formulation**: The model decomposes the task into subtasks. Depending
    on the approaches, the LLM decomposes the task into different steps and then executes
    them all sequentially. Other studies suggest that an adaptive strategy is better,
    in which one step at a time is executed (this can be followed by evaluation).'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Plan reflection**: After formulation, it is recommended to analyze and conduct
    a feedback analysis of the plan. Once a plan is described, the LLM can evaluate
    it, or a second model may be present to evaluate the work of the first model.'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Suppose we have several LLMs. Our choice might be affected by space or memory
    limitations. Also, we might have speed problems in inference (user experience
    will be impacted if the model takes too long to respond). We can then benchmark
    by evaluating speed (tokens per second) and relative performance (performance
    per second per billion parameters).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.3 – Two graphs benchmarking different LLMs for generation speed:
    A) shows the number of tokens generated per second, and B) shows the number of
    tokens per second divided per billion parameters](img/B21257_04_03.jpg)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.3 – Two graphs benchmarking different LLMs for generation speed: A)
    shows the number of tokens generated per second, and B) shows the number of tokens
    per second divided per billion parameters'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: '**A)** in *Figure 4**.3* shows the number of tokens generated per second in
    response to the instruction “*Describe briefly what an AI agent is*.” **B)** shows
    the number of tokens per second divided per billion parameters (a higher number
    means greater model efficiency).'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: In addition, it is always good to evaluate the quality of the response. An easy
    way is to have a model such as GPT-4 (or any model that is larger than the initial
    models used) evaluate the responses.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，始终评估响应质量是个好主意。一种简单的方法是让一个模型如GPT-4（或任何比初始模型更大的模型）评估响应。
- en: '![Figure 4.4 – Evaluation of models’ answers](img/B21257_04_04.jpg)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![图4.4 – 模型答案评估](img/B21257_04_04.jpg)'
- en: Figure 4.4 – Evaluation of models’ answers
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.4 – 模型答案评估
- en: As shown in *Figure 4**.4*, GPT-4 evaluates the answer generated by the different
    models. Each column represents the assigned score (overall quality, completeness,
    and truthfulness) by GPT-4.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图4**.4所示，GPT-4评估了不同模型生成的答案。每一列代表GPT-4分配的分数（整体质量、完整性和真实性）。
- en: 'In summary, here are some recommendations for choosing which LLM to use as
    the brain of an AI agent system:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，以下是一些关于选择哪个LLM作为AI代理系统大脑的建议：
- en: The first choice is whether to use a closed source model (such as GPT-4 or Claude)
    via an API or open source (such as Mistral or Meta’s Llama). In the first case,
    it is important to evaluate the costs of a proprietary model (cost per inference,
    per incorporation into an application). In the second case, the number of parameters
    should be chosen by balancing computational cost and performance.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先的选择是是否通过API使用闭源模型（例如GPT-4或Claude）或开源模型（例如Mistral或Meta的Llama）。在前一种情况下，重要的是评估专有模型的成本（每次推理成本、集成到应用程序中的成本）。在后一种情况下，应通过平衡计算成本和性能来选择参数数量。
- en: Consider the infrastructure cost of a model. An LLM and other system components
    must be hosted in an infrastructure. For example, our LLM may be available on
    Azure, and the greater the number of parameters, the greater the cost.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 考虑模型的基础设施成本。一个LLM和其他系统组件必须托管在基础设施中。例如，我们的LLM可能托管在Azure上，参数数量越多，成本就越高。
- en: Almost all models have good knowledge of both linguistics and common sense.
    On the other hand, for some specific domains, you may need a model that possesses
    a knowledge domain. There are already models that have been adapted and are open
    source (for example, FinGPT for finance), or if you own the data, you can decide
    to conduct fine-tuning yourself. Alternatively, retrieval approaches can be exploited,
    which we will see in later chapters.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 几乎所有模型都对语言学和常识都有很好的了解。另一方面，对于某些特定领域，你可能需要一个具有知识领域的模型。已经有了一些被调整并开源的模型（例如，用于金融的FinGPT），或者如果你拥有数据，你可以决定自行进行微调。或者，可以采用检索方法，我们将在后面的章节中看到。
- en: In the next section, we will discuss how to connect this brain to the outside
    world.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将讨论如何将这个大脑连接到外部世界。
- en: The perception
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 感知
- en: While LLMs may be the brain, they can only comprehend textual input and thus
    lack visual perception (for example, although ChatGPT-4o can now have not only
    text but also images as input and can describe what it is in the image, that functionality
    is not technically part of the LLM itself). As humans, we rely extremely heavily
    on our visual perception. Vision allows us to acquire an enormous amount of information
    about the external world and the relationships between objects in the environment.
    Similarly, there are other modalities that allow us to acquire real-time information
    about the environment that we wish our agent could perceive. For example, an agent
    connected to home appliances could close windows if a sensor detects rain or lower
    blinds if the camera detects strong sunshine.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然LLM可能是大脑，但它们只能理解文本输入，因此缺乏视觉感知（例如，尽管ChatGPT-4o现在不仅可以接受文本输入，还可以接受图像输入并描述图像中的内容，但这种功能并非LLM本身的技术组成部分）。作为人类，我们极其依赖我们的视觉感知。视觉使我们能够获取关于外部世界以及环境中物体之间关系的巨大信息量。同样，还有其他模态使我们能够获取我们希望代理能够感知的环境实时信息。例如，连接到家用电器的代理如果传感器检测到雨，可以关闭窗户；如果摄像头检测到强烈的阳光，可以降低百叶窗。
- en: As sentient beings, we integrate the information we receive from sensory organs
    and process a response to external stimuli. For an agent to respond to a change
    in the environment, it must be able to perceive changes.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 作为有感知的生物，我们整合从感官器官接收到的信息，对外部刺激做出反应。为了使代理能够对环境的变化做出反应，它必须能够感知变化。
- en: In order to help the LLM understand **visual input**, the simplest solution
    is to use another model to conduct image captioning. These captions can then be
    inserted into the prompt as additional context for task instruction. The advantage
    of this approach is that it is easily interpreted, and pre-trained templates can
    be used for captioning. During the captioning process, however, there is a loss
    of information, and the result does not represent the complexity of the visual
    information. Instead of using captions, PaLM-E ([https://arxiv.org/pdf/2303.03378)](https://arxiv.org/pdf/2303.03378))
    and other works use **embodied** **language models**.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助语言模型理解**视觉输入**，最简单的解决方案是使用另一个模型进行图像字幕。然后，这些字幕可以作为任务指令的额外上下文插入到提示中。这种方法的优势在于它易于解释，并且可以使用预训练模板进行字幕。然而，在字幕过程中，信息会有所损失，结果并不代表视觉信息的复杂性。而不是使用字幕，PaLM-E
    ([https://arxiv.org/pdf/2303.03378)](https://arxiv.org/pdf/2303.03378)) 和其他工作使用**具身****语言模型**。
- en: PaLM-E is a single general-purpose multimodal language model for embodied reasoning
    tasks. The model integrates directly into the embedding images and text, allowing
    the solving of vision and language tasks.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: PaLM-E是一个用于具身推理任务的单一通用多模态语言模型。该模型直接集成到嵌入图像和文本中，允许解决视觉和语言任务。
- en: Sensory modality inputs (such as images) are directly incorporated into the
    input for the language model. The idea is that images are embedded into the same
    latent embedding as language tokens. The subsequent embedded vectors are then
    passed to the transformer blocks as if they were textual inputs. The model is
    then fine-tuned and learns how to relate the information present in the various
    modalities.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 感官模态输入（如图像）直接纳入语言模型的输入。其理念是图像被嵌入到与语言标记相同的潜在嵌入中。随后嵌入的向量随后被传递到变换器块，就像它们是文本输入一样。然后，模型被微调并学习如何关联各种模态中存在的信息。
- en: Alternatively, as we saw with BLIP-2 in the previous chapter, we can achieve
    multimodality by combining two models that have already been trained and keeping
    them frozen. Instead, we train the **Querying Transformer** (**Q-Former**) module
    to put in communication the visual encoder and the LLM. This approach has the
    advantage that we only have to conduct training for a module with much fewer parameters.
    Also, LLMs do not have visual-language alignment, which can lead to catastrophic
    forgetting.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，正如我们在上一章中通过BLIP-2所看到的，我们可以通过结合两个已经训练好的模型并保持它们冻结来实现多模态。相反，我们训练**查询变换器**（**Q-Former**）模块，以使视觉编码器和语言模型进行通信。这种方法的优势在于我们只需要对一个参数数量少得多的模块进行训练。此外，语言模型没有视觉-语言对齐，这可能导致灾难性的遗忘。
- en: '**Video input** can be considered visual input in which we have an added temporal
    dimension. A video consists of a stream of continuous image frames (there is,
    however, a relationship between frames and this information must be preserved).
    To prevent the one-moment model from seeing the future and understanding the temporal
    order, models such as Flamingo ([https://arxiv.org/pdf/2204.14198](https://arxiv.org/pdf/2204.14198))
    use a masked mechanism.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '**视频输入**可以被视为具有额外时间维度的视觉输入。视频由一系列连续的图像帧组成（然而，帧之间存在关系，这些信息必须被保留）。为了防止一瞬间的模型看到未来并理解时间顺序，模型如Flamingo
    ([https://arxiv.org/pdf/2204.14198](https://arxiv.org/pdf/2204.14198)) 使用了掩码机制。'
- en: '**Auditory input** also conveys important information. For example, in human
    speech, there is information beyond the content of the message (as intonation,
    pauses, and so on) or some sounds associated with particular dangers or physical
    events. Several models excel in specific tasks associated with auditory signals.
    Models such as Whisper can be used for speech-to-text, after which the transcript
    can be used for an LLM. In addition, an audio spectrogram is a rich source of
    information and can be represented as an image (frequency spectrum changes over
    time). Many models are basic vision transformers that have been adapted to spectrograms.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '**听觉输入**也传递着重要的信息。例如，在人类语言中，信息不仅限于消息的内容（如语调、停顿等），还有一些与特定危险或物理事件相关的声音。一些模型在处理与听觉信号相关的特定任务上表现出色。例如，Whisper模型可以用于语音转文本，之后可以将转录内容用于语言模型。此外，音频频谱图是信息丰富的来源，可以表示为图像（随时间变化的频率谱）。许多模型是基本的视觉变换器，已经被调整为处理频谱图。'
- en: In fact, an LLM can invoke other models for other auditory tasks (text-to-audio,
    speech translation and recognition, speech separation, sound extraction, and so
    on). As discussed in [*Chapter 3*](B21257_03.xhtml#_idTextAnchor042), multimodality
    is when an LLM can take as input other modes besides text (such as images, video,
    audio, and so on). AudioGPT ([https://arxiv.org/pdf/2304.12995](https://arxiv.org/pdf/2304.1299))
    is an example of this approach where we have an LLM interacting with audio foundation
    models (each of them specialized in a different task).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，LLM可以调用其他模型来执行其他听觉任务（如文本到音频、语音翻译和识别、语音分离、声音提取等）。如[第3章](B21257_03.xhtml#_idTextAnchor042)所述，多模态是指LLM可以接受除了文本之外的其他模态作为输入（如图像、视频、音频等）。AudioGPT
    ([https://arxiv.org/pdf/2304.12995](https://arxiv.org/pdf/2304.12995)) 是这种方法的例子，其中我们有一个LLM与音频基础模型（每个模型都专注于不同的任务）进行交互。
- en: '![Figure 4.5 – High-level overview of AudioGPT (https://arxiv.org/pdf/2304.12995)](img/B21257_04_05.jpg)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![图4.5 – AudioGPT的高级概述 (https://arxiv.org/pdf/2304.12995)](img/B21257_04_05.jpg)'
- en: Figure 4.5 – High-level overview of AudioGPT ([https://arxiv.org/pdf/2304.12995](https://arxiv.org/pdf/2304.12995))
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.5 – AudioGPT的高级概述 ([https://arxiv.org/pdf/2304.12995](https://arxiv.org/pdf/2304.12995))
- en: There are, of course, other types of sensor inputs in the real world. Modalities
    such as smell or touch are more complex to conjugate and require sensors. In various
    industries, though, there are sensors (temperature, humidity, and so on) that
    receive input from machines. An LLM could integrate this information directly
    or through an intermediate model. Additionally, a model can receive information
    from other sources, such as LiDAR, GPS, and even the internet.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，现实世界中还有其他类型的传感器输入。例如，嗅觉或触觉等模态更复杂，需要传感器。然而，在各个行业中，存在接收来自机器输入的传感器（如温度、湿度等）。一个大型语言模型（LLM）可以直接或通过中间模型整合这些信息。此外，模型还可以从其他来源接收信息，例如激光雷达（LiDAR）、全球定位系统（GPS）以及互联网。
- en: Action
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 行动
- en: 'In living things, we have the perception of a signal and its interpretation,
    which is then followed by a response. For example, an animal can visually perceive
    the figure of a predator (feel its movements and smell), and its brain will integrate
    this information and decide the best course of action (hide or run). For our agent,
    we can expect something similar, in which perceived signals are integrated and
    the LLM plans tasks that are then executed by dedicated action modules. The simplest
    example of output is text: LLMs have an inherent generation capability and can
    then generate a text in response to an instruction. The capabilities of an LLM
    can be extended through **tools**. In fact, we humans can solve complex tasks
    by using tools that extend the inherent capabilities of our bodies (or enable
    tasks to be performed faster or more efficiently).'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在生物体中，我们具有对信号的感知及其解释，然后是相应的反应。例如，动物可以视觉上感知捕食者的形象（感受其动作和气味），其大脑将整合这些信息并决定最佳行动方案（隐藏或逃跑）。对于我们的智能体，我们可以期待类似的情况，其中感知到的信号被整合，LLM计划任务，然后由专门的行动模块执行。输出的最简单例子是文本：LLM具有固有的生成能力，可以响应指令生成文本。LLM的能力可以通过**工具**来扩展。实际上，我们人类可以通过使用工具来解决复杂任务，这些工具可以扩展我们身体的固有能力（或使任务执行更快或更有效率）。
- en: The model obviously needs to understand what tools are available and how to
    use them. By itself, an LLM can generalize to a certain limit (zero-shot capabilities),
    but there are techniques to improve its ability to use these tools (few-shot models,
    for example). Some approaches, as we will see later, will be like providing an
    instruction manual to the model. Learning how to use these tools can also be conducted
    as feedback so that the LLM can then conduct adjustments.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，模型需要理解可用的工具以及如何使用它们。LLM本身可以泛化到一定限度（零样本能力），但有一些技术可以提高其使用这些工具的能力（例如，少样本模型）。我们将在后面看到的一些方法将类似于为模型提供使用手册。学习如何使用这些工具也可以作为反馈进行，这样LLM就可以进行相应的调整。
- en: A more complex aspect of defining actions is a sub-branch called **embodied
    action**. So far, the interactions have been within a virtual environment. In
    embodiment, we have an extension of the system to the outside world. According
    to the **embodiment hypothesis**, humans develop their intelligence through their
    continuous interaction and feedback with the environment and not simply by reading
    textbooks about it. Therefore, if we want to achieve AGI, a model should be able
    to interact with the environment. AGI could enable applications that we could
    previously only imagine because it could monitor the external environment in real
    time and act with a sophisticated and complex goal (for example, acting to counter
    global warming, monitoring nuclear fusion, or probes being sent to explore space
    autonomously). An LLM could then be embedded in a robot and, thus, provided with
    a body, being able to explore the environment and learn from it.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 定义动作的一个更复杂方面是称为**具身动作**的子分支。到目前为止，交互一直是在虚拟环境中进行的。在具身中，我们将系统扩展到外部世界。根据**具身假设**，人类通过与环境持续互动和反馈来发展他们的智慧，而不仅仅是通过阅读关于它的教科书。因此，如果我们想要实现通用人工智能（AGI），模型应该能够与环境交互。AGI
    可以使我们实现以前只能想象的应用，因为它可以实时监控外部环境并采取复杂和复杂的目标行动（例如，采取行动对抗全球变暖、监控核聚变，或发送探测器自主探索太空）。然后，一个
    LLM 可以嵌入到机器人中，从而获得一个身体，能够探索环境并从中学习。
- en: In the next section, we will dig more into how agents learn and how we can better
    classify them. This will help us to better define and plan an AI agent when we
    need it.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将更深入地探讨代理的学习方式以及如何更好地对它们进行分类。这将帮助我们更好地定义和规划在需要时的人工智能代理。
- en: Classifying AI agents
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人工智能代理分类
- en: In this section, we will discuss how best to classify agents and go into more
    detail about how such a complex system learns. The first classification is between
    agents that move only in a virtual environment and embodied agents.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论如何最好地分类代理，并更详细地讨论这样一个复杂系统是如何学习的。第一种分类是在仅存在于虚拟环境中的代理和具身代理之间。
- en: '**Digital agents** are confined to a virtual environment. Again, we have varying
    degrees of interaction with the virtual universe. The simplest agents have interaction
    with a single user. For example, an agent can be programmed in a virtual environment
    as a Jupyter notebook, and although it can search the internet, it has rather
    small, and therefore primarily passive, interactions. There are two subsequent
    levels of extension:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '**数字代理**被限制在虚拟环境中。再次强调，我们与虚拟宇宙的交互程度各不相同。最简单的代理与单个用户进行交互。例如，代理可以在虚拟环境中编程为 Jupyter
    笔记本，尽管它可以搜索互联网，但它的交互相对较小，因此主要是被动的。有两个后续的扩展级别：'
- en: '**Action agents** perform actions in a simulated or virtual world. Gaming agents
    interact with other agents or users. These agents usually have a goal (such as
    winning a game) and must interact with other players to succeed in achieving their
    goal. A reinforcement learning algorithm is usually used to train the system by
    providing a reward to the model when it achieves certain goals.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**动作代理**在模拟或虚拟世界中执行动作。游戏代理与其他代理或用户进行交互。这些代理通常有一个目标（例如赢得游戏）并且必须与其他玩家互动以成功实现其目标。通常使用强化学习算法通过向模型提供奖励来训练系统，当它实现某些目标时。'
- en: An **interactive agent** is an extension of the action agent. The model communicates
    with the world and can modify it (these are not necessarily physical actions).
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**交互式代理**是动作代理的扩展。该模型与世界进行通信并可以修改它（这些不一定是物理动作）。'
- en: 'Once we have decided the limits of our system’s interaction, it is important
    to decide how it should approach a task. Therefore, the question is: how does
    the model decide how to plan actions?'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们决定了我们系统交互的限制，重要的是决定它应该如何处理任务。因此，问题是：模型是如何决定如何规划动作的？
- en: 'This is one of the fundamental skills of the system: how to decompose a task
    into actions and what to prioritize. We will discuss the possible systems at a
    high level, especially for task planning.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 这是系统的一项基本技能：如何将任务分解为动作以及优先考虑什么。我们将从高层次讨论可能的系统，特别是针对任务规划。
- en: '![Figure 4.6 – Taxonomy for existing LLM-agent planning works (https://arxiv.org/pdf/2402.02716)](img/B21257_04_06.jpg)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.6 – 现有 LLM-agent 规划工作的分类 (https://arxiv.org/pdf/2402.02716)](img/B21257_04_06.jpg)'
- en: Figure 4.6 – Taxonomy for existing LLM-agent planning works ([https://arxiv.org/pdf/2402.02716](https://arxiv.org/pdf/2402.02716))
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.6 – 现有 LLM-agent 规划工作的分类 ([https://arxiv.org/pdf/2402.02716](https://arxiv.org/pdf/2402.02716))
- en: 'In the real world, tasks are generally complex, and it is virtually impossible
    to solve them in a single step. For this reason, agents must divide the task into
    a series of subtasks that are more manageable (subtasks can also consist of a
    series of steps to be solved). In this process, it first has to decide how to
    divide a task into various subtasks and then how to solve them. There are usually
    two approaches to solving this challenge:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实世界中，任务通常是复杂的，几乎不可能一步解决它们。因此，代理必须将任务分解成一系列更易于管理的子任务（子任务也可以由一系列要解决的步骤组成）。在这个过程中，它首先必须决定如何将任务分解成各种子任务，然后如何解决它们。通常有两种解决这一挑战的方法：
- en: '**Decomposition-first methods** (*Figure 4**.7a*): The LLM divides the task
    into a series of subgoals and solves them sequentially by creating a plan for
    each goal after it has solved the previous goal. This system is inspired by zero-shot
    CoT, and the LLM is asked to conduct the process in two steps with two explicit
    prompts: “Let’s first devise a plan” and “Let’s carry out the plan.” This approach
    has the advantage of giving the model an overview of the task, reducing hallucinations
    and forgetting. On the other hand, since everything is planned at the beginning,
    the model cannot correct errors that may occur at some steps.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分解优先方法** (*图4.7a*): LLM将任务分解成一系列子目标，并在解决前一个目标后为每个目标创建一个计划来顺序解决它们。这个系统受到零样本CoT的启发，LLM被要求通过两个明确的提示进行两个步骤的过程：“让我们首先制定一个计划”和“让我们执行这个计划”。这种方法的优势是给模型提供了一个任务概述，减少了幻觉和遗忘。另一方面，由于一切都在一开始就计划好了，模型无法纠正可能发生在某些步骤中的错误。'
- en: '**Interleaved decomposition methods** (*Figure 4**.7b*): Task decomposition
    and planning are interleaved. In other words, we generate a subtask and solve
    it with a plan until we have solved the whole task. Alternating reasoning and
    planning allows the model to improve its planning capabilities because it addresses
    the entire process in steps. This approach dynamically adjusts the task solution.
    It has the disadvantage that if the problem is too complex, it creates expensive
    and long reasoning-planning chains without getting a result.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**交错分解方法** (*图4.7b*): 任务分解和规划是交错进行的。换句话说，我们生成一个子任务，并使用一个计划来解决它，直到我们解决了整个任务。交替推理和规划允许模型通过逐步处理整个过程来提高其规划能力。这种方法可以动态调整任务解决方案。它的缺点是，如果问题过于复杂，它可能会在没有得到结果的情况下创建昂贵且漫长的推理-规划链。'
- en: '![Figure 4.7 – Types of task decomposition methods (https://arxiv.org/pdf/2402.02716)](img/B21257_04_07.jpg)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![图4.7 – 任务分解方法的类型 (https://arxiv.org/pdf/2402.02716)](img/B21257_04_07.jpg)'
- en: Figure 4.7 – Types of task decomposition methods ([https://arxiv.org/pdf/2402.02716](https://arxiv.org/pdf/2402.02716))
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.7 – 任务分解方法的类型 ([https://arxiv.org/pdf/2402.02716](https://arxiv.org/pdf/2402.02716))
- en: There are variations and alternatives to these two approaches. For example,
    inspired by a self-consistency prompt (where we sample different reasoning paths
    for a single question), in the **multi-plan selection approach**, several different
    plans are generated for each task. This is because even if the model can reason,
    it might generate a plan that is incorrect or not feasible. The model generates
    several candidate plans for a single task, and then we can exploit different algorithms
    to choose the best plan of action. In the simplest version, we choose the majority
    voting strategy, but there are alternatives in which we exploit tree search algorithms
    or reinforcement learning. This approach often succeeds in solving complex cases,
    and the use of heuristic algorithms decreases the cost of solving them in extended
    hypothesis spaces. On the other hand, generating different paths has a higher
    computational cost (with the risk of higher time cost as well), and since it uses
    stochastic processes, it may not be consistent.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这两种方法，存在变体和替代方案。例如，受自洽提示（其中我们对单个问题采样不同的推理路径）的启发，在**多计划选择方法**中，为每个任务生成几个不同的计划。这是因为即使模型可以进行推理，它也可能生成一个不正确或不可行的计划。模型为单个任务生成几个候选计划，然后我们可以利用不同的算法来选择最佳行动计划。在最简单的版本中，我们选择多数投票策略，但也有一些利用树搜索算法或强化学习的替代方案。这种方法通常在解决复杂案例时成功，并且使用启发式算法降低了在扩展假设空间中解决问题的成本。另一方面，生成不同的路径具有更高的计算成本（以及更高的时间成本风险），并且由于它使用随机过程，可能不一致。
- en: Another approach is **external planner-aided planning**, in which external planners
    are integrated. For example, symbolic planners can be added to identify the optimal
    path of resolution. Today, there are also neural planners (much lighter neural
    networks) to help LLMs find the optimal plan. In other words, the LLM conducts
    reasoning that can be seen as a slow, meditative process, while the planner provides
    a quick, instinctive response. This slow and fast thinking can also be alternated,
    with a fast plan developed first, and then an LLM used to solve any mistakes.
    This approach is resource-efficient and seems promising for tasks that require
    code generation. The system is complex to develop and implement, however.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方法是**外部规划辅助规划**，其中集成了外部规划器。例如，可以添加符号规划器来识别解决方案的最佳路径。今天，也有神经规划器（更轻的神经网络）来帮助LLM找到最佳计划。换句话说，LLM进行的是可以被视为缓慢、沉思的过程的推理，而规划器提供的是快速、本能的反应。这种慢速和快速思考也可以交替进行，首先制定一个快速计划，然后使用LLM来解决任何错误。这种方法资源效率高，对于需要代码生成的任务似乎很有希望。然而，系统的开发和实施是复杂的。
- en: To avoid hallucinations and other errors, another possible approach is **reflection
    and refinement**. This can be seen as an interleaved decomposition extension,
    in which the LLM conducts an iterative process of generation, feedback, and refinement.
    After each generation step, the model also generates feedback on the plan and
    then uses this feedback to conduct refinement. In more sophisticated versions,
    there is an additional model that evaluates the plan (evaluator) and proposes
    feedback. It is also possible to incorporate environmental changes into the feedback,
    making the system particularly versatile. Despite the potential, there is no guarantee
    that the refinement process will lead the model to solve the goal. The LLM can
    get stuck in a continuous chain, especially when the process is complex.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免幻觉和其他错误，另一种可能的方法是**反思和精炼**。这可以被视为一种交错分解扩展，其中LLM进行生成、反馈和精炼的迭代过程。在每次生成步骤之后，模型还会对计划生成反馈，然后使用这些反馈来进行精炼。在更复杂的版本中，还有一个额外的模型来评估计划（评估器）并提出反馈。还可以将环境变化纳入反馈中，使系统特别灵活。尽管有潜力，但无法保证精炼过程将使模型解决目标。LLM可能会陷入连续的链条中，尤其是在过程复杂时。
- en: '**Memory-augmented planning** is an approach that seeks to overcome the current
    context-length limitation of the model. Memory-augmented planning for an agent
    refers to the use of an external memory system to enhance the agent’s decision-making
    and planning capabilities. This approach allows the agent to store, recall, and
    utilize past experiences, observations, or computations to improve performance
    in complex tasks. Imagine a robot vacuum cleaner tasked with cleaning a house.
    Without memory, it randomly navigates the house and might repeatedly clean the
    same areas or miss some spots. With memory augmentation, the robot keeps a map
    (memory) of where it has already cleaned and where obstacles (such as furniture)
    are located. This allows the system to plan the next move, without revisiting
    cleaned areas, to efficiently cover the house.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '**记忆增强规划**是一种试图克服模型当前上下文长度限制的方法。对于智能体的记忆增强规划是指使用外部记忆系统来增强智能体的决策和规划能力。这种方法允许智能体存储、回忆和利用过去的经验、观察或计算，以改善复杂任务中的性能。想象一下，一个被分配清洁房子的机器人吸尘器。没有记忆，它会随机在房子里移动，可能会反复清洁相同区域或错过一些地方。有了记忆增强，机器人会保存一个地图（记忆），记录它已经清洁的地方和障碍物（如家具）的位置。这使得系统可以规划下一步行动，不重复清洁区域，从而高效地覆盖整个房子。'
- en: In fact, a task can be divided into several subtasks, and these into further
    subtasks. Together with planning and intermediate results, more information can
    be generated than fits in the context.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，一个任务可以被分解成几个子任务，这些子任务又可以进一步分解。与规划和中间结果一起，可以生成比上下文所能容纳更多的信息。
- en: '**Retrieval-augmented generation** (**RAG**) is a technique that allows the
    retrieval of information for later use in generation (we will discuss this in
    detail in the next two chapters) and can be used to store an agent’s past experience.
    In RAG, there is an external memory in the form of a database, and at each user
    query, we can search for the context needed to answer a question or perform an
    action (this context becomes part of the model input). In other words, the model
    can find previous task planning, other solutions to the task, or additional information
    that can serve the task solution. Alternatively, it is possible to use these previous
    experiences for fine-tuning the model. Fine-tuning on previous tasks helps generalization
    to subsequent tasks. On the one hand, the use of RAG is less costly but requires
    that retrieval be accurate, and that the found past experiences be relevant to
    the task. Fine-tuning is more expensive but allows the model to store experiences
    (a kind of internalization). There are even more sophisticated RAG versions in
    which structures are built to mimic human short-term and long-term memories (the
    former to store temporary changes in the environment and the latter to consolidate
    important information).'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: As we will see in the next section, we can have either a single agent or multiple
    agents interacting within a single system. This flexibility allows us to be able
    to deal with complex tasks by choosing the appropriate architecture (one or more
    agents). In *Chapters 9 and 10*, we will return to this topic and look at multi-agent
    systems in practice.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the abilities of single-agent and multiple-agent systems
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is important to discuss what an agent’s capabilities are, and how they can
    be used to accomplish tasks. Conceptually, the scenario in which our agent can
    act must be defined. **Task-oriented deployment** is the simplest scenario in
    which an agent assists a human in some tasks. These types of agents need to be
    able to solve task bases or break them down into manageable subtasks. The purpose
    of this agent is to understand a user’s instructions, then understand the task,
    decompose it into steps, plan, and execute that plan until the goal is achieved.
    A single agent can perform these tasks in web or real-life scenarios.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: '*In a web scenario*, an agent must be capable of performing actions on the
    web (and thus be connected to the internet). An LLM has the potential to automate
    various tasks such as online shopping, sending emails, and filling out forms.
    An agent devoted to these tasks must have the ability to adapt to changes in various
    websites. LLM agents are favored in this area, as sites often have large text
    content. With too much information, agents can still have problems (performance
    drop). In fact, if relevant information is scattered amid too much irrelevant
    context, the model may hallucinate, fail to resolve the task, or fail to plan.
    To improve the model’s capabilities, one of the tools can often read HTML.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在网络场景中，一个智能体必须能够执行网络上的操作（因此需要连接到互联网）。大型语言模型（LLM）有潜力自动化各种任务，例如在线购物、发送电子邮件和填写表格。专注于这些任务的智能体必须能够适应各种网站的变化。LLM智能体在这个领域受到青睐，因为网站通常包含大量的文本内容。即使信息量很大，智能体仍然可能遇到问题（性能下降）。事实上，如果相关信息散布在过多的无关背景中，模型可能会产生幻觉，无法完成任务，或者无法进行规划。为了提高模型的能力，一个常用的工具可以读取HTML。
- en: '*In a live scenario*, an agent must be capable of being able to perform actions
    and have common-sense reasoning (for example, an agent making purchases on the
    internet). For an LLM that has only been trained with massive amounts of text,
    these tasks can be especially complex. For example, although it may be trained
    on texts about the fact that there is day/night alternation, it is difficult for
    a model to understand how to orient itself when lighting changes without further
    instruction. Also, an agent must have common sense when planning actions (these
    actions must be feasible and not contradict common sense). Therefore, the agent
    will need spatial information in order to understand its environment in a future
    deployment of embodied robots.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际场景中，一个智能体必须能够执行操作并具备常识推理能力（例如，在互联网上购物的智能体）。对于一个仅用大量文本训练过的LLM来说，这些任务可能特别复杂。例如，尽管它可能训练过关于日夜交替的文本，但没有进一步的指令，模型很难理解如何在光线变化时定位自己。此外，智能体在规划行动时必须具备常识（这些行动必须是可行的，并且不违背常识）。因此，智能体在未来的实体机器人部署中需要空间信息来理解其环境。
- en: '**Innovation-oriented deployment** is a more complex scenario (and represents
    future developments in the coming years, not a current use), where the agent does
    not simply have to perform tasks. These agents must demonstrate some exploratory
    capability in science (for example, lab assistants, application planning, or software
    design). Complex and innovative projects are difficult to define solely as textual
    information; they are multidimensional. An agent will need to have a clear understanding
    of an entire knowledge domain and be able to extrapolate from it. These kinds
    of agents can then be used to develop code and software or to create new materials,
    conduct experiments, and much more. Although it is an active field of research,
    and LLMs show some of these required skills, this potential has not yet been reached.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '**以创新为导向的部署**是一个更复杂的场景（并且代表了未来几年来的发展趋势，而不是当前的应用），智能体不仅必须执行任务。这些智能体必须在科学领域展现出一些探索能力（例如，实验室助手、应用规划或软件设计）。复杂和创新的项目很难仅通过文本信息来定义；它们是多维的。智能体需要清楚地理解整个知识领域，并能够从中进行外推。这类智能体可以用来开发代码和软件，或创造新材料，进行实验等等。尽管这是一个活跃的研究领域，LLM也显示出一些这些所需技能，但这种潜力尚未实现。'
- en: '**Life cycle-oriented deployment** can be defined as the ultimate goal for
    many in the community. It refers to an agent that is capable of exploring on its
    own, developing new skills, and operating even in an unfamiliar world. Today,
    interesting studies are being conducted on Minecraft on “test beds” for many projects
    oriented in this direction. In fact, Minecraft represents a virtual world in which
    a model must perform both short-term and long-term tasks (in these settings, it
    is important to have a memory, which we will discuss more in the next chapter).'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '**以生命周期为导向的部署**可以定义为社区中许多人的最终目标。它指的是一个能够自主探索、开发新技能并在不熟悉的世界中运行的智能体。今天，许多以这个方向为导向的项目正在“测试床”上对Minecraft进行有趣的研究。事实上，Minecraft代表了一个虚拟世界，在这个世界中，模型必须执行短期和长期的任务（在这些设置中，拥有记忆很重要，我们将在下一章中进一步讨论）。'
- en: '![Figure 4.8 – Practical applications of the single LLM-based agent in increasingly
    complex scenarios (https://arxiv.org/pdf/2309.07864)](img/B21257_04_08.jpg)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
- en: Figure 4.8 – Practical applications of the single LLM-based agent in increasingly
    complex scenarios ([https://arxiv.org/pdf/2309.07864](https://arxiv.org/pdf/2309.07864))
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: Human beings, though, learn not only from books but also from other human beings.
    In addition, most of our work is done collaboratively. Also, because of resource
    issues, the division of labor is much more convenient. Therefore, several researchers
    propose that the same approach should be followed with AI. In **multi-agent systems**
    (**MASs**), different agents collaborate and communicate with each other. Several
    LLM agents collaborate and communicate in natural language (which means that their
    actions are also interpretable by a human observer). In this case, one can also
    have several LLMs that are specialized in a particular task, rather than having
    to use one model that specializes in everything. In fact, some approaches focus
    on creating agents that are complementary and can collaborate and share information.
    In these settings, models can also make collective decisions and are capable of
    solving tasks that a single agent cannot solve. For example, to improve the resolution
    of a process, agents can provide different responses and conduct a majority vote.
    There may be agents who provide feedback or monitor the actions of other agents.
    These interactions can be orderly (follow rules or have a sequential order) or
    messy (each agent can voice its opinion).
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: 'Agents need not cooperate. In accordance with game theory, exploiting competition
    among agents can be beneficial to task resolution. This process has been used
    to train models to win games. In fact, AlphaGo ([https://www.nature.com/articles/nature24270](https://www.nature.com/articles/nature24270))
    was trained to beat itself at Go, so it was able to amass many more game hours.
    LLMs can be put into what are called *adversarial settings*, in which they receive
    feedback from another agent and use it to improve themselves. There are several
    approaches in which you might have agents discuss or reflect on another agent’s
    performance:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.9 – Interaction scenarios for multiple LLM-based agents (https://arxiv.org/pdf/2309.07864)](img/B21257_04_09.jpg)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
- en: Figure 4.9 – Interaction scenarios for multiple LLM-based agents ([https://arxiv.org/pdf/2309.07864](https://arxiv.org/pdf/2309.07864))
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: Agents can also interact with humans (human-agent interaction). This assumes
    control over agents’ behavior so that their goals are aligned with those of humans.
    At the same time, interaction with humans is a source of important information
    that should be exploited to provide feedback to agents (performance, safety, and
    potential bias). In addition, interaction with humans can be a way to allow agents
    to evolve.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: 'We can have two types of interaction between agents and humans:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: '**Unequal interaction**, also called the **instructor-executor paradigm**,
    is an approach in which humans provide instructions via natural language and agents
    execute. This dialogue can be a single prompt (instruction and execution) or interactive
    (conversational). In this approach, the agent executes, while the human provides
    instructions and feedback. In the simplest format, feedback can be quantitative
    (binary or rating) or qualitative (natural language, advice, suggestions, or criticism),
    which the model can use to improve current and future responses. A sub-branch
    of this approach, called **continual learning**, studies a way for the model to
    learn with each interaction.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**不平等交互**，也称为**指导者-执行者范式**，是一种人类通过自然语言提供指令而智能体执行的方法。这种对话可以是单一提示（指令和执行）或交互式（对话）。在这种方法中，智能体执行，而人类提供指令和反馈。在最简单的格式中，反馈可以是定量的（二元或评分）或定性的（自然语言、建议、建议或批评），模型可以使用这些反馈来改进当前和未来的响应。这种方法的一个子分支，称为**持续学习**，研究模型如何通过每次交互进行学习。'
- en: '**Equal interaction** is a paradigm in which there is an equal partnership
    between the agent and the human. Given the conversational capabilities of current
    LLMs, an agent can have a collaborative role for humans. One of the limitations
    of this approach is the lack of chatbot emotion, which is perceived as problematic
    by users. For this reason, several researchers have focused on making chatbots
    more empathetic. In addition, these agents need to better understand beliefs and
    goals in interacting with humans before gaining equal status in interactions.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**平等交互**是一种智能体与人类之间存在平等伙伴关系的范式。鉴于当前LLM的对话能力，智能体可以为人类提供协作角色。这种方法的局限性之一是缺乏聊天机器人的情感，这被用户视为问题。因此，一些研究人员专注于使聊天机器人更具同理心。此外，这些智能体在与人类互动之前需要更好地理解信念和目标，才能在互动中获得平等的地位。'
- en: '![Figure 4.10 – Two paradigms of human-agent interaction (https://arxiv.org/pdf/2309.07864)](img/B21257_04_10.jpg)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![图4.10 – 人类-智能体交互的两种范式 (https://arxiv.org/pdf/2309.07864)](img/B21257_04_10.jpg)'
- en: Figure 4.10 – Two paradigms of human-agent interaction ([https://arxiv.org/pdf/2309.07864](https://arxiv.org/pdf/2309.07864))
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.10 – 人类-智能体交互的两种范式([https://arxiv.org/pdf/2309.07864](https://arxiv.org/pdf/2309.07864))
- en: In the next section, we will discuss the principal libraries to create agents.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将讨论创建智能体的主要库。
- en: Exploring the principal libraries
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索主要库
- en: After discussing the various components and frameworks on a conceptual and theoretical
    level, in this section, we will discuss some of the major libraries that allow
    these concepts to be put into practice. These libraries make it possible to connect
    an LLM to the various additional modules. LLMs remain central but are thus connected
    to perception modules and execution tools. In the next chapters, we will elaborate
    on some aspects and see different practical examples.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在概念和理论层面上讨论了各种组件和框架之后，在本节中，我们将讨论一些主要的库，这些库使得这些概念得以付诸实践。这些库使得将LLM连接到各种附加模块成为可能。LLM仍然是核心，但因此连接到感知模块和执行工具。在接下来的章节中，我们将详细阐述一些方面，并展示不同的实际例子。
- en: 'In general, the structure of an LLM-based application has several components:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，基于LLM的应用结构包含几个组件：
- en: '**The interface**: this connects the user to the system.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**界面**：这连接用户到系统。'
- en: '**The brain**: an LLM that can also be connected to additional memory. An LLM
    has its own parametric memory (obtained during training), but we can add external
    memory (such as a vector database or knowledge graph).'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**大脑**：一个可以连接额外记忆的LLM。LLM拥有自己的参数化记忆（在训练期间获得），但我们还可以添加外部记忆（例如向量数据库或知识图谱）。'
- en: '**Perception modules**: these allow the ingestion and transformation of user
    data.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**感知模块**：这些模块允许摄取和转换用户数据。'
- en: '**Tools**: modules that extend the abilities of the LLM. These can be built
    in the library or created by the developer.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**工具**：扩展LLM能力的模块。这些模块可以在库中构建或由开发者创建。'
- en: '**Prompts**: the user’s dialogue with the application in natural language.
    The prompt contains both instructions provided by the user (frontend prompt) and
    information that is not seen by the user (backend prompt). The backend information
    is additional instructions that condition the behavior of the LLM. For example,
    we can force the LLM to respond only using the information in context or present
    in the vector database. Some backend prompts are developed to prevent the model
    from responding with harmful content.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提示词**：用户与应用程序在自然语言中的对话。提示词包含用户提供的指令（前端提示词）以及用户看不到的信息（后端提示词）。后端信息是条件化LLM行为的额外指令。例如，我们可以强制LLM只使用上下文中的信息或向量数据库中的信息进行响应。一些后端提示词是为了防止模型以有害内容进行响应而开发的。'
- en: 'There are several different libraries that enable us to be able to build such
    a system, and here we will introduce the following:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 有几个不同的库使我们能够构建这样的系统，以下我们将介绍以下内容：
- en: LangChain
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LangChain
- en: Haystack
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Haystack
- en: LlamaIndex
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LlamaIndex
- en: Semantic Kernel
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Semantic Kernel
- en: AutoGen
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AutoGen
- en: Let’s look at each of them.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐一看看它们。
- en: LangChain
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LangChain
- en: '**LangChain** is a framework for developing applications with LLMs at their
    core. The focus of this framework is the development and deployment of these applications
    into production. The LangChain ecosystem consists of three core components:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '**LangChain**是一个以LLM为核心开发应用程序的框架。这个框架的重点是这些应用程序的开发和部署到生产环境。LangChain生态系统由三个核心组件组成：'
- en: '**LangChain**: Different modules allow the incorporation of LLMs with added
    memory, prompts, and other tools'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LangChain**：不同的模块允许将具有附加内存、提示词和其他工具的LLM集成'
- en: '**LangSmith**: This component is used to inspect, monitor, and evaluate your
    application'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LangSmith**：这个组件用于检查、监控和评估你的应用程序'
- en: '**LangServe**: This allows you to turn your system into an API'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LangServe**：这允许你将你的系统转变为API'
- en: LangChain can be used in both Python and JavaScript (and some modules are also
    available in Rust). To date, it is one of the most widely used libraries in the
    community, and in fact, there are several components that have been developed
    by the open source community.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain可以在Python和JavaScript中使用（并且一些模块也适用于Rust）。到目前为止，它是社区中最广泛使用的库之一，实际上，已经有一些组件是由开源社区开发的。
- en: LangChain is compatible with either models that are closed source (such as OpenAI
    or Anthropic) or models that are available on Hugging Face. LangChain is development-oriented
    (one of the advantages of LangChain is that it allows both parallel execution
    and asynchronous support) and one of the best libraries for building an application
    that needs to go into production. LangChain provides convenient wrappers for LLMs
    and allows them to be connected to additional tools. One of the most interesting
    aspects is that it allows you to build so-called chains (LLMs and add-ons) that
    can then be tracked and deployed in production. LangChain also provides several
    functions to transform different data (CSV, PDF, text, images, and so on). In
    addition, the library provides a number of prompt templates to better use the
    various LLMs.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain与闭源模型（如OpenAI或Anthropic）或Hugging Face上可用的模型兼容。LangChain以开发为导向（LangChain的一个优点是它允许并行执行和异步支持），是构建需要投入生产的应用程序的最佳库之一。LangChain为LLM提供了方便的包装器，并允许它们连接到额外的工具。最有趣的一点是，它允许你构建所谓的链（LLM和附加组件），然后可以在生产环境中跟踪和部署。LangChain还提供了一些函数来转换不同的数据（CSV、PDF、文本、图像等）。此外，该库提供了一系列提示词模板，以更好地使用各种LLM。
- en: LangChain creates modular abstractions, thus allowing models to be connected
    to tools efficiently. By building with chains, you can create efficient (but still
    versatile and customized) pipelines that can then be easily deployed. In addition,
    through LangSmith, you can monitor the system to avoid problems.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain通过创建模块化抽象，从而使得模型能够高效地连接到工具。通过构建链，你可以创建高效（但仍然灵活和定制）的管道，然后可以轻松部署。此外，通过LangSmith，你可以监控系统以避免问题。
- en: 'LangChain has several advantages:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain有几个优点：
- en: '**Comprehensive library**: It presents a broad library of features with ready-made
    templates for many applications. In addition, the design is modular, so you can
    easily swap components.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**综合库**：它提供了一个广泛的特性库，为许多应用程序提供了现成的模板。此外，设计是模块化的，因此你可以轻松地交换组件。'
- en: '**Extensive integrations**: LangChain offers the ability to connect to a large
    number of external libraries in an easy way: LLM providers, vector databases,
    cloud service, and so on.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**广泛的集成**：LangChain提供了一种简单的方式连接到大量的外部库：LLM提供商、向量数据库、云服务等。'
- en: '**Precise and clear workflows**: LangChain makes it possible to clearly define
    inputs and outputs and also allows intermediate products in the chain to be monitored
    and extensive prompt engineering to be conducted.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**精确且清晰的流程**：LangChain使得可以清楚地定义输入和输出，并允许监控链中的中间产品以及进行广泛的提示工程。'
- en: '**Active developing community**: There is a large user base, with different
    solutions that have been developed by the community, and there are many tutorials
    written on various sites and forums.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**活跃的开发社区**：有一个庞大的用户基础，社区已经开发出不同的解决方案，并在各种网站和论坛上编写了许多教程。'
- en: '**Flexible framework focused on an end-to-end cycle**: LangChain provides elements
    for the entire cycle of an application (integration, development, deployment,
    and observability).'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**专注于端到端周期的灵活框架**：LangChain提供了应用程序整个周期的元素（集成、开发、部署和可观察性）。'
- en: 'At the same time, it also has a couple of disadvantages:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，它也有一些缺点：
- en: '**Steeper learning curve**: Users may require more time to adapt to the library
    syntax and achieve the full capability of the library. Abstraction capability
    comes at a cost; all functions are defined as a class. For example, a simple prompt
    must be abstracted into a **prompt template**.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**更陡峭的学习曲线**：用户可能需要更多时间来适应库的语法并实现库的全部功能。抽象能力是有代价的；所有功能都定义为类。例如，一个简单的提示必须抽象成一个**提示模板**。'
- en: '**Documentation**: Many users have complained that the documentation is out
    of date or not easily understood, generalized but not specialized. Versatility
    is also a disadvantage because, for several specific applications, there are systems
    that have more functionality (for example, for RAG applications).'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文档**：许多用户抱怨文档过时或难以理解，过于通用但缺乏专业性。通用性也是一个缺点，因为对于几个特定的应用，有更多的系统具有更多功能（例如，对于RAG应用）。'
- en: LangChain is the most widely used library, especially for building complex agents.
    However, it also has the steepest learning curve. For this reason, many project
    users often prefer a simpler library.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain是最广泛使用的库，特别是用于构建复杂代理。然而，它也有最陡峭的学习曲线。因此，许多项目用户通常更喜欢一个更简单的库。
- en: Haystack
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**干草堆**'
- en: '**Haystack** is an open source framework for building production-ready LLM
    applications. Like LangChain, it is compatible with the major LLM sources and
    deployment platforms. Haystack also allows you to connect tools to LLMs and has
    a whole set of tools designed to put the system into production (including evaluation,
    monitoring, and data ingestion). It is designed to be able to easily create LLMs
    with associated external storage, chatbots, and agents, but also multimodal systems.
    One of the advantages of Haystack is that it has several pre-built features that
    can then be inserted into one’s own pipeline with ease.'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '**干草堆**是一个用于构建生产就绪型LLM应用程序的开源框架。与LangChain类似，它兼容主要的LLM来源和部署平台。干草堆还允许您将工具连接到LLM，并有一整套工具旨在将系统投入生产（包括评估、监控和数据摄取）。它旨在能够轻松创建具有相关外部存储、聊天机器人和代理的LLM，以及多模态系统。干草堆的一个优点是它具有几个预构建的功能，可以轻松地插入到自己的管道中。'
- en: 'Haystack is built on the idea that everything can be composable with ease,
    the main elements being the following:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 干草堆建立在一切都可以轻松组合的理念之上，主要元素如下：
- en: '**Components**: These are building blocks dedicated to document retrieval,
    text generation, or creating embeddings. These components can be viewed as nodes,
    and the library presents many that have already been built and are ready to use.
    The user still has the option of creating their own nodes.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**组件**：这些是专门用于文档检索、文本生成或创建嵌入的构建块。这些组件可以被视为节点，库提供了许多已经构建并准备好使用的节点。用户仍然可以选择创建自己的节点。'
- en: '**Pipelines**: These are a convenient abstraction for understanding how data
    flows in the application. A pipeline consists of several components that are connected.
    Haystack facilitates the system because it allows for versatile pipeline control
    (you can join pipelines, create loops, and so on). In Haystack, you can see them
    as graphs where the components are nodes that can be interconnected in sophisticated
    ways.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**管道**：这些是理解应用程序中数据流的一个方便的抽象。一个管道由几个连接的组件组成。Haystack 通过允许灵活的管道控制（你可以连接管道、创建循环等）来简化系统。在
    Haystack 中，你可以将它们视为组件作为节点可以以复杂方式相互连接的图。'
- en: 'Haystack has several advantages:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: Haystack 有几个优点：
- en: '**Specialized components**: Haystack provides a number of excellent components
    for data processing, embedding, ranking, and writing. In addition, the library
    specializes in searching and **question and answer** (**Q&A**) systems. For this
    user case, it provides components that are optimized.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**专用组件**：Haystack 提供了用于数据处理、嵌入、排名和编写的许多优秀组件。此外，该库专注于搜索和**问答**（**Q&A**）系统。对于这个用例，它提供了优化的组件。'
- en: '**Extensive documentation and community**: Haystack is adopted by a large community
    and there are now many community-developed components. It also presents quality
    documentation and there are many tutorials.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**广泛的文档和社区**：Haystack 被一个大型社区采用，现在有许多社区开发的组件。它还提供了高质量的文档，有许多教程。'
- en: '**Gentler learning** **curve**: Haystack is considered an easy-to-learn framework.
    It is versatile, and it is easy to adapt it to different cases.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**更平缓的学习曲线**：Haystack 被认为是一个易于学习的框架。它很灵活，很容易适应不同的情况。'
- en: 'However, it also has several disadvantages:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，它也有一些缺点：
- en: '**Smaller user base**: The community is active but smaller than other frameworks
    such as LangChain or LlamaIndex.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**较小的用户基础**：社区很活跃，但比 LangChain 或 LlamaIndex 等其他框架要小。'
- en: '**Less integration**: There are fewer dedicated integrations than other frameworks.
    Despite this, the system is flexible and many custom tools exist.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**较少的集成**：与其他框架相比，集成的数量较少。尽管如此，该系统是灵活的，存在许多自定义工具。'
- en: '**Narrower scope**: Haystack is more focused on retrieval and document-understanding
    tasks, so it has fewer tools and parsers for other NLP applications. This is a
    limitation when you have to develop applications that include dialogues, chatbots,
    or other tools.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**更窄的范围**：Haystack 更专注于检索和文档理解任务，因此它为其他 NLP 应用程序提供的工具和解析器较少。当你需要开发包含对话、聊天机器人或其他工具的应用程序时，这是一个限制。'
- en: '**Scalability**: Many users complain of problems when they have to scale the
    system or have to handle large datasets.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可扩展性**：许多用户在需要扩展系统或处理大量数据集时都会遇到问题。'
- en: Haystack is an easy library and can be a great choice for RAG-based applications,
    but less so for more sophisticated applications that involve agents.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: Haystack 是一个易于使用的库，对于基于 RAG 的应用程序来说是一个很好的选择，但对于涉及代理的更复杂的应用程序来说则不那么理想。
- en: LlamaIndex
  id: totrans-167
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LlamaIndex
- en: '**LlamaIndex** is another framework focused on building a system around an
    LLM. LlamaIndex began as a data framework that focuses on building RAG. For this
    reason, the system has several data connectors to both integrate external sources
    and ingest different types of data. One of the interesting points of LlamaIndex
    is that it allows knowledge graphs to be easily integrated as well. It can also
    be integrated with different types of models, but it also has integration for
    other frameworks (Docker, OpenAI, LangChain, Flask, and so on).'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '**LlamaIndex** 是另一个专注于围绕 LLM 构建系统的框架。LlamaIndex 最初是一个数据框架，专注于构建 RAG。因此，该系统具有多个数据连接器，既可以集成外部来源，也可以摄取不同类型的数据。LlamaIndex
    的一个有趣之处在于它允许知识图轻松集成。它还可以与不同类型的模型集成，但它也提供了与其他框架（Docker、OpenAI、LangChain、Flask 等）的集成。'
- en: LlamaIndex can be used to nimbly build chatbots and connect them with external
    storage. It also allows you to build autonomous agents that can search the internet
    or conduct actions. There are several tools and features already constituted and
    others that have been developed by the community around it.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: LlamaIndex 可以用来敏捷地构建聊天机器人并将它们与外部存储连接起来。它还允许你构建能够搜索互联网或执行操作的自主代理。已经构成了一些工具和功能，还有其他由其社区开发的功能。
- en: 'LlamaIndex also has several advantages:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: LlamaIndex 也具有几个优点：
- en: '**Handling different data sources**: LlamaIndex can handle over 160 data sources,
    making it efficient for many types of data commonly found in the enterprise. It
    is ideal for when you have complex and diverse datasets. It also supports multimodal
    integration.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**处理不同的数据源**：LlamaIndex可以处理超过160种数据源，使其在处理企业中常见的多种类型数据时效率很高。当拥有复杂且多样化的数据集时，它尤为理想。它还支持多模态集成。'
- en: '**Indexing and efficient retrieval**: This is the strength of LlamaIndex; it
    was designed with accurate and fast retrieval of information in mind. The library
    offers several tools and features for RAG and other retrieval paradigms.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**索引和高效检索**：这是LlamaIndex的优势；它旨在准确快速地检索信息。该库为RAG和其他检索范式提供了多种工具和功能。'
- en: '**Customization**: Especially for retrieval, LlamaIndex offers a high possibility
    of customization.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**定制**：特别是在检索方面，LlamaIndex提供了高度的可定制性。'
- en: 'There are also some disadvantages:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 也有一些缺点：
- en: '**Complexity**: LlamaIndex has a steep learning curve compared to other frameworks.
    In order to use it best, it assumes that you have a clear idea of information
    retrieval.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**复杂性**：与其它框架相比，LlamaIndex的学习曲线较为陡峭。为了最佳使用，它假设你有一个清晰的信息检索概念。'
- en: '**Limited functionality**: LlamaIndex has a focus on retrieval tasks but has
    limited functionality regarding other NLP tasks. This results in a lack of versatility.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**功能有限**：LlamaIndex专注于检索任务，但在其他NLP任务方面的功能有限。这导致缺乏多功能性。'
- en: LlamaIndex is the first choice for RAG-based applications and a good solution
    for agents.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: LlamaIndex是RAG应用的首选，也是智能代理的良好解决方案。
- en: Semantic Kernel
  id: totrans-178
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 语义内核
- en: '**Semantic Kernel** is an open source framework developed by Microsoft to build
    agents. This library can also connect with OpenAI, Hugging Face, and other frameworks.
    Semantic Kernel was originally written in C#, but today there is also a version
    in Python. The idea behind this library is to provide the ability to create functions
    that are the result of combining various functions (also known as **function composition**).
    In other words, Semantic Kernel is structured on the idea that various components
    can be tied together to build versatile pipelines.'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '**语义内核**是由微软开发的开源框架，用于构建智能代理。此库还可以与OpenAI、Hugging Face和其他框架连接。Semantic Kernel最初是用C#编写的，但今天也有Python版本。这个库背后的理念是提供创建组合各种函数（也称为**函数组合**）的能力。换句话说，语义内核建立在各种组件可以组合在一起构建多功能管道的理念之上。'
- en: In Semantic Kernel, the core is an LLM, but we can add code that we have developed
    as plugins so that the LLM can then execute it. In addition, it allows an LLM
    to have memory that can be either in the form of files or vector databases. An
    interesting element is that one can create native functions that are dedicated
    to performing a task. It also implements a planner that takes your task as input
    and returns a set of actions, functions, or plugins to succeed in solving the
    task.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在语义内核中，核心是一个LLM，但我们可以添加我们开发的代码作为插件，以便LLM可以执行它。此外，它允许LLM拥有可以以文件或向量数据库形式存在的内存。一个有趣的因素是，可以创建专门执行任务的本地函数。它还实现了一个规划器，该规划器将你的任务作为输入，并返回一组动作、函数或插件以成功解决任务。
- en: Semantic Kernel is versatile, supports several libraries, and has lightweight
    support for C# and .NET frameworks. It is inspired by the Copilot framework, which
    is stable and a good choice for enterprises.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 语义内核功能多样，支持多个库，并对C#和.NET框架提供轻量级支持。它受到Copilot框架的启发，该框架稳定且是企业的好选择。
- en: AutoGen
  id: totrans-182
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自动生成
- en: '`UserProxyAgent` (which collects information from users and passes the information
    to other agents), `AssistantAgent` (which receives data from another `AssistantAgent`
    instance and `UserProxyAgent`, processes it, and completes a task), and `GroupChatManager`
    (which controls and directs communication between agents). AutoGen supports several
    complex conversation patterns that allow complex workflows to take place without
    human intervention. Systems involving several agents communicating with each other
    in complex ways can be configured.'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '`UserProxyAgent`（从用户收集信息并将其传递给其他代理），`AssistantAgent`（从另一个`AssistantAgent`实例和`UserProxyAgent`接收数据，处理它并完成任务），以及`GroupChatManager`（控制和指导代理之间的通信）。AutoGen支持多种复杂的对话模式，允许在没有人为干预的情况下进行复杂的流程。涉及多个代理以复杂方式相互通信的系统可以配置。'
- en: 'This library has the following advantages:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 此库有以下优点：
- en: '**Simplicity**: Abstraction makes it possible to intuit how agents converse
    and arrive at accomplishing a task. In addition, this makes it easier to explain
    the system to non-technical staff and other stakeholders.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**简单性**：抽象使得可以直观地了解代理如何进行对话并完成任务。此外，这也使得向非技术人员和其他利益相关者解释系统变得更加容易。'
- en: '**Customization**: The process is intuitive and allows easy customization with
    little code.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**定制性**：过程直观，并且可以通过少量代码轻松定制。'
- en: 'There are a couple of drawbacks, however:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，也有一些缺点：
- en: '**Harder to debug**: Agents are interdependent, making debugging difficult'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**更难调试**：代理相互依赖，这使得调试变得困难'
- en: '**Less support**: It is less adopted by the community, so there are fewer users
    to turn to for help when you need it'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**支持较少**：它不太被社区采用，因此当你需要帮助时，可供求助的用户较少'
- en: AutoGen is an interesting and promising library, but at this stage, it can be
    hard to start a project with.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: AutoGen是一个有趣且具有潜力的库，但在这个阶段，用它开始一个项目可能会有点困难。
- en: Choosing an LLM agent framework
  id: totrans-191
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 选择一个LLM代理框架
- en: In general, the different frameworks offer similar components and are inspired
    by the same philosophy (extending the capabilities of an LLM). In addition, almost
    all libraries today are mature and have purpose-built components. For those functions
    that are not natively present within the library, there are many resources today
    that have been built by the community. The main component is the LLM, and the
    capabilities of the LLM are those that most condition the result of the application.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，不同的框架提供类似的功能，并受到相同哲学的启发（扩展LLM的能力）。此外，今天几乎所有的库都相当成熟，并且有专门构建的组件。对于库中未原生存在的功能，今天有许多由社区构建的资源。主要组件是LLM，LLM的能力是那些最影响应用程序结果的因素。
- en: The first factor that may affect the choice is the programming language of the
    library. Often, these libraries must be integrated into existing systems that
    cannot be modified. Almost all libraries are written in Python but also have modules
    that can be written in other languages and facilitate their integration. In some
    cases, although support is not native, it has been developed by the open source
    community. For example, LangChain has support for Rust and there are unofficial
    implementations in other languages (C#, R, and so on). The tasks that the system
    has to accomplish are another determining factor. The increased complexity of
    the system requires that the framework be both robust and flexible at the same
    time. Some systems are designed with a greater focus on information retrieval
    (LlamaIndex) and thus are better choices if our system is to focus on chat and
    retrieval. In other contexts, we are more interested in system scalability and
    performance, so we might be interested in all the monitoring and evaluation ecosystems
    that LangChain and Haystack provide.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 影响选择的第一因素可能是库的编程语言。通常，这些库必须集成到无法修改的现有系统中。几乎所有的库都是用Python编写的，但也包含可以用其他语言编写的模块，这有助于它们的集成。在某些情况下，尽管支持不是原生的，但已经被开源社区开发出来。例如，LangChain支持Rust，在其他语言（如C#、R等）中也有非官方的实现。系统必须完成的任务也是另一个决定因素。系统的复杂性增加要求框架同时具备鲁棒性和灵活性。一些系统设计时更注重信息检索（LlamaIndex），因此如果我们的系统要专注于聊天和检索，它们是更好的选择。在其他情况下，我们更关注系统的可扩展性和性能，因此我们可能会对LangChain和Haystack提供的所有监控和评估生态系统感兴趣。
- en: In addition, it is desirable that there be an active community of developers
    and that the library itself be actively maintained. When one adopts a framework,
    it is important that there are resources and a community to ask to avoid getting
    stuck or not finding a solution to a bug. A community-adopted library will have
    a large supply of tutorials and examples to help you learn the system.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，希望有一个活跃的开发者社区，并且库本身也要积极维护。当采用一个框架时，重要的是要有资源和社区可以求助，以避免陷入困境或找不到解决方案。一个社区采用的库将拥有大量的教程和示例，帮助你学习系统。
- en: Another factor is the level of customization. Although all libraries offer predefined
    features, these features do not cover all user cases, and in-house solutions will
    need to be developed. An ideal library should have this versatility and the ability
    to modify and integrate components. It may happen that we want to change our LLM
    or one of the components because we need a different performance. Similarly, the
    default parameters may not be optimal for our application, and it is better to
    have a library where it is not complex to adapt the parameters.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个因素是定制化程度。尽管所有库都提供预定义的功能，但这些功能并不涵盖所有用户场景，并且需要开发内部解决方案。理想的库应该具有这种多功能性和修改和集成组件的能力。可能发生的情况是我们想改变我们的LLM或其中一个组件，因为我们需要不同的性能。同样，默认参数可能不适合我们的应用程序，并且最好有一个库，其中调整参数并不复杂。
- en: The best library is determined mainly by the use case. Each of them has strengths
    and weaknesses. For example, if the application is focused on retrieval, LlamaIndex
    may be the winning choice, or Haystack if the core of the application is Q&A.
    LangChain is a more natural choice for a broad scope, but if the system is to
    be integrated into .NET, you might choose Semantic Kernel. The chosen framework
    should be evaluated taking into consideration additional constraints and what
    the main focus of the application is.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 最佳库主要取决于用例。每个库都有其优势和劣势。例如，如果应用程序侧重于检索，LlamaIndex可能是最佳选择，或者如果应用程序的核心是问答，则Haystack可能是更好的选择。LangChain对于广泛的范围是一个更自然的选择，但如果系统要集成到.NET中，您可能会选择Semantic
    Kernel。选择的框架应该考虑额外的约束以及应用程序的主要关注点。
- en: We have now seen the most important libraries for AI agents. In the next section,
    we will start to test them in action.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经看到了AI代理最重要的库。在下一节中，我们将开始测试它们在实际中的应用。
- en: Creating an agent to search the web
  id: totrans-198
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建一个搜索网络的代理
- en: 'We typically associate internet searches with search engines like Google. The
    search for a query is conducted using an algorithm, but it is not an AI algorithm.
    PageRank is, in fact, a graph search algorithm that does not involve learning.
    A search algorithm presupposes two main steps:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通常将互联网搜索与像Google这样的搜索引擎联系起来。查询的搜索是通过算法进行的，但这不是人工智能算法。PageRank实际上是一个不涉及学习的图搜索算法。搜索算法预设了两个主要步骤：
- en: '**Matching**: Finding documents that are relevant to a given user query'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**匹配**：找到与特定用户查询相关的文档'
- en: '**Ranking**: Ordering these documents from most relevant to least relevant'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**排名**：将这些文档按相关性从高到低排序'
- en: These two steps do not necessarily require AI. However, searching with the use
    of AI can bring a better service and solve some of the problems that plague search
    algorithms. A user today expects an AI algorithm to be able to distinguish the
    entity and terminology and to contextualize and localize it. For example, a user
    searching for “the best pizzeria” expects the search engine to return the best
    restaurants nearby. The search process of the future will also integrate other
    elements, such as a conversation about the results, complex responses (summarization
    and action), and multimodality.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个步骤不一定需要人工智能。然而，使用人工智能进行搜索可以提供更好的服务并解决一些困扰搜索算法的问题。现在的用户期望人工智能算法能够区分实体和术语，并将其置于上下文中进行定位。例如，搜索“最好的比萨饼店”的用户期望搜索引擎返回附近的最佳餐厅。未来的搜索过程也将整合其他元素，例如关于结果的对话、复杂的响应（摘要和行动），以及多模态。
- en: There is another aspect. In today’s systems, search results should in many cases
    be user-related. Searches can be ambiguous and some results will be more relevant
    by considering the user’s history. In addition, a user may want a search conditional
    on other parameters and want to express it in natural language (for example, the
    difference between “best pizzeria in Paris” and expressing “best pizzeria AND
    Paris”). Once the results are found, the user may have other questions that require
    reasoning (“Which of these pizzerias is suitable for a dinner with children?”).
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个方面是，在今天的系统中，搜索结果在许多情况下应该是与用户相关的。搜索可能是模糊的，并且考虑到用户的历史记录，某些结果可能更为相关。此外，用户可能希望基于其他参数进行搜索，并希望用自然语言表达（例如，“巴黎最好的比萨饼店”与表达“最好的比萨饼店
    AND 巴黎”之间的区别）。一旦找到结果，用户可能会有其他需要推理的问题（“这些比萨饼店中哪一家适合带小孩的晚餐？”）。
- en: An AI-enhanced search can meet these needs because it has an LLM at its core.
    An LLM can understand the difference between the various keywords in the query,
    as well as understand which domain the user is looking for (for example, “Transformer”
    can be an AI model or a toy). In addition, by accessing the history of previous
    interactions, the LLM is aware of the user’s preferences (so you do not have to
    state your preferences each time). This allows for a more relevant ranking of
    the results since they are in order not only for the query but also for a user’s
    preferences. The model can also conduct reasoning and give more importance to
    results that are more implicitly relevant (for example, when searching for a family
    restaurant, a multimodal model will give more preference to a restaurant with
    a picture of a playground even if it is not explicitly stated in the description
    that it is for families). The user can also ask questions about the results and
    the model using agents can perform operations.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 增强型搜索可以满足这些需求，因为它在其核心处有一个 LLM。LLM 可以理解查询中各种关键词之间的区别，以及理解用户正在寻找哪个领域（例如，“Transformer”可以是一个
    AI 模型或玩具）。此外，通过访问先前交互的历史记录，LLM 了解用户的偏好（因此你不必每次都声明你的偏好）。这使得结果的相关性排名更加相关，因为它们不仅按查询排序，还按用户的偏好排序。模型还可以进行推理，并给予更隐含相关的结果更高的权重（例如，当搜索家庭餐厅时，即使描述中未明确指出是为家庭设计的，多模态模型也会更倾向于有游乐场图片的餐厅）。用户还可以通过代理向结果和模型提出问题。
- en: The traditional search returns links in order of importance for a query. Today,
    however, information can be extracted from sites and analyzed by an LLM. For a
    given query, the model can now either extract the most relevant passage in the
    site (**extractive question-answering**) or propose a summary of the first results
    that directly answer the query (**abstractive question-answering**). In this way,
    the user does not even have to click the links but has the answer directly. This
    system can then be integrated with other tools, such as external memory (such
    as RAG and knowledge graphs, which we will see in the next three chapters).
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 传统搜索按查询的重要性顺序返回链接。然而，今天，信息可以从网站中提取并由 LLM 分析。对于给定的查询，模型现在可以提取网站中最相关的段落（**提取式问答**）或提出直接回答查询的第一结果的摘要（**抽象式问答**）。这样，用户甚至不需要点击链接，就能直接获得答案。然后，这个系统可以与其他工具集成，例如外部存储（如
    RAG 和知识图谱，我们将在下一章中看到）。
- en: In addition, an LLM has generative capabilities, so these can be used in combination
    with the query (“search for sources on the French Revolution” or “search for code
    in Python for convolution and translate it into R”). One of the problems with
    this type of generative search is the risk of hallucination, so the system must
    preserve the sources it has used so that backtracking can be conducted.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，LLM 具有生成能力，因此这些可以与查询结合使用（例如，“搜索法国大革命的资料”或“搜索用于卷积的 Python 代码并将其翻译成 R”）。这种类型生成搜索的一个问题是幻觉风险，因此系统必须保留它所使用的来源，以便可以进行回溯。
- en: In the simplest form of searching with an LLM plus agents, we have an LLM connected
    with an interface that allows it to receive a query and a tool that allows it
    to search the internet. In this basic case, the LLM must analyze the query, plan
    to use the tool to search the internet, analyze the results found, and answer
    the query. In more sophisticated forms, the LLM may have more tools at its disposal.
    For instance, it can execute code, a calculator, and external memory to save data
    or call up models that perform NLP tasks (entity identification in text, extracting
    passages, and so on).
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用 LLM 和代理的最简单搜索形式中，我们有一个连接到界面的 LLM，它允许接收查询，以及一个允许它搜索互联网的工具。在这个基本案例中，LLM 必须分析查询，计划使用工具搜索互联网，分析找到的结果，并回答查询。在更复杂的形式中，LLM
    可能拥有更多可用的工具。例如，它可以执行代码、计算器和外部存储来保存数据或调用执行 NLP 任务（如文本中的实体识别、提取段落等）的模型。
- en: '![Figure 4.11 – Representation of an LLM agent’s system for internet research](img/B21257_04_11.jpg)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.11 – LLM 代理互联网研究系统的表示](img/B21257_04_11.jpg)'
- en: Figure 4.11 – Representation of an LLM agent’s system for internet research
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.11 – LLM 代理互联网研究系统的表示
- en: 'Let’s break down *Figure 4**.11*:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分解 *图 4.11*：
- en: The user formulates a query.
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用户提出查询。
- en: The model analyzes the query and plans actions to solve the task.
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型分析查询并计划执行操作。
- en: The appropriate tool (in this case, internet search) is selected.
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择合适的工具（在这种情况下，互联网搜索）。
- en: Documents are identified during the internet search. The information is sent
    back to the model, which analyzes it and decides whether further action is required
    or whether the task is accomplished.
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 文档在互联网搜索过程中被识别。信息被发送回模型，模型分析信息并决定是否需要进一步行动或任务是否已完成。
- en: The model generates the answer, which is sent back to the user.
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型生成答案，并将其发送回用户。
- en: LangChain allows the LLM to be able to connect to the web through the use of
    tools. In general, the most widely used approach is known as **Reasoning and Acting**
    (**ReAct**) prompting. During the first stage (reasoning), the model considers
    the best strategy to be able to arrive at the answer, and in the second stage
    (acting), it executes the plan. In this approach, the model also tracks the reasoning
    steps and can guide it to the solution. This approach also allows flexibility
    because it enables the model to mold the prompt to its needs.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain允许LLM通过使用工具连接到网络。通常，最广泛使用的方法被称为**推理与行动**（**ReAct**）提示。在第一阶段（推理）中，模型考虑最佳策略以到达答案，在第二阶段（行动）中执行计划。在此方法中，模型还跟踪推理步骤并可以引导它到达解决方案。这种方法也允许灵活性，因为它使模型能够根据其需求调整提示。
- en: By itself, LangChain offers a number of tools that are designed to extend the
    model and find the information it needs. For example, it offers several tools
    for searching the internet. The DuckDuckGo tool allows people to use the DuckDuckGo
    search engine. This search engine is free and does not track user data (it also
    filters out pages that are full of advertising or have articles written only to
    rank highly in the Google search engine).
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 就其本身而言，LangChain提供了一些旨在扩展模型并找到所需信息的工具。例如，它提供了几个用于搜索互联网的工具。DuckDuckGo工具允许人们使用DuckDuckGo搜索引擎。这个搜索引擎是免费的，不跟踪用户数据（它还过滤掉充满广告或仅为了在谷歌搜索引擎中排名靠前的页面）。
- en: 'In order to use it, we need to install a specific Python library and then import
    the tool into LangChain:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用它，我们需要安装一个特定的Python库，然后将工具导入到LangChain中：
- en: '[PRE0]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Note
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: You can directly use the tool, and it will provide you with the search results.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以直接使用该工具，它将为您提供搜索结果。
- en: 'One of the strengths of LangChain is the ability to build a list of tools that
    can then be used by the LLM. To do this, we have to give a name, explain what
    the function to be performed is, and provide a description. This way, the LLM
    is informed about what tool it can use when it has to do an internet search:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain的一个优势是能够构建一个工具列表，然后由LLM使用。为此，我们必须给出一个名称，解释要执行的功能，并提供描述。这样，LLM就会知道在它需要进行网络搜索时可以使用哪些工具：
- en: '[PRE1]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'It is possible to use Google Serper, a low-cost API (albeit with some limitations)
    that enables you to use the Google search engine (you have to register at [https://serper.dev/](https://serper.dev/)
    to get an API key); however, there is a fee for the service. In fact, the Google
    API is much more expensive and the LLM cannot access directly the search engine
    (Serper allows us to use the Google search engine through their API, and they
    provide some free credits):'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用Google Serper，这是一个低成本API（尽管有一些限制），允许您使用谷歌搜索引擎（您必须注册[https://serper.dev/](https://serper.dev/)以获取API密钥）；然而，这项服务需要付费。实际上，谷歌API的费用更高，LLM无法直接访问搜索引擎（Serper允许我们通过他们的API使用谷歌搜索引擎，并且他们提供一些免费信用额）：
- en: '[PRE2]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Additionally, we can add Wikipedia as a reliable source of information:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还可以将维基百科添加为可靠的信息来源：
- en: '[PRE3]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Once we have the various tools, we can then initialize an agent and conduct
    a query:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了各种工具，我们就可以初始化一个代理并执行查询：
- en: '[PRE4]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The model will choose which results will be interesting to our query. The model
    can access different information but has nowhere to save it. Using an LLM for
    internet research can be useful for different fields (from medicine to finance).
    For example, models have been used to access genetic sequences and conduct comparisons,
    or to search for information about drugs, chemical structures, and more. Similarly,
    a model can search for the latest financial and economic news. Another tool can
    be the **OpenStreetMap** (**OSM**) search.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 模型将选择哪些结果对我们查询感兴趣。模型可以访问不同的信息，但没有地方可以保存它们。使用大型语言模型进行网络研究可以适用于不同领域（从医学到金融）。例如，模型已被用于访问基因序列并进行比较，或搜索有关药物、化学结构等信息。同样，模型可以搜索最新的财经新闻。另一个工具可以是**OpenStreetMap**（**OSM**）搜索。
- en: In the next chapter, we will discuss how the model can save and access this
    memory. For example, we may want our model to be able to access conversation history
    or extend its knowledge. This can be useful in both business applications, but
    also in fields such as finance and healthcare.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将讨论模型如何保存和访问这些记忆。例如，我们可能希望我们的模型能够访问对话历史或扩展其知识。这在商业应用中非常有用，在金融和医疗保健等领域也是如此。
- en: Summary
  id: totrans-232
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we introduced how an LLM can be the brain of a sophisticated
    and complex system. We can use the conversational and reasoning abilities of the
    LLM to solve a task. As we said, this brain can be extended by providing perceptual
    systems (senses) and tools (hands). In fact, we can allow the model to search
    the internet by connecting with APIs, but also to ingest information from other
    modalities (audio, images, or video). Similarly, the model uses this received
    information to solve user tasks. If we can imagine agents performing and automating
    routine tasks for users today, it is not difficult to imagine a world in which
    agents interact with humans and other agents in increasingly sophisticated and
    complex ways.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了如何使一个大型语言模型（LLM）成为复杂系统的“大脑”。我们可以利用LLM的对话和推理能力来解决任务。正如我们所说，这个大脑可以通过提供感知系统（感官）和工具（双手）来扩展。实际上，我们可以通过连接API来允许模型搜索互联网，也可以从其他模态（音频、图像或视频）中摄取信息。同样，模型使用这些接收到的信息来解决用户任务。如果我们能够想象到今天代理执行和自动化为用户执行常规任务，那么想象一个代理以越来越复杂和高级的方式与人类和其他代理互动的世界并不困难。
- en: In the next chapter, we will see how a model can have a memory, as well as how
    to store information and be able to find it again to be more efficient.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将看到模型如何拥有记忆，以及如何存储信息并能够再次找到它以提高效率。
- en: Further reading
  id: totrans-235
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'Silver, *Mastering the game of Go without human knowledge*, 2017: [https://www.nature.com/articles/nature24270](https://www.nature.com/articles/nature24270)'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Silver，*《无需人类知识精通围棋》，2017年*：[https://www.nature.com/articles/nature24270](https://www.nature.com/articles/nature24270)
- en: 'LangChain: [https://python.langchain.com/v0.2/docs/introduction/](https://python.langchain.com/v0.2/docs/introduction/)'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'LangChain: [https://python.langchain.com/v0.2/docs/introduction/](https://python.langchain.com/v0.2/docs/introduction/)'
- en: 'Haystack: [https://haystack.deepset.ai/overview/intro](https://haystack.deepset.ai/overview/intro)'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Haystack: [https://haystack.deepset.ai/overview/intro](https://haystack.deepset.ai/overview/intro)'
- en: 'Semantic Kernel: [https://learn.microsoft.com/en-us/semantic-kernel/overview/](https://learn.microsoft.com/en-us/semantic-kernel/overview/)'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Semantic Kernel: [https://learn.microsoft.com/en-us/semantic-kernel/overview/](https://learn.microsoft.com/en-us/semantic-kernel/overview/)'
- en: 'AutoGen: [https://microsoft.github.io/autogen/](https://microsoft.github.io/autogen/)'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'AutoGen: [https://microsoft.github.io/autogen/](https://microsoft.github.io/autogen/)'
- en: 'LlamaIndex: [https://www.llamaindex.ai/](https://www.llamaindex.ai/)'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'LlamaIndex: [https://www.llamaindex.ai/](https://www.llamaindex.ai/)'
- en: 'LangChain tools: [https://python.langchain.com/v0.2/docs/integrations/tools/](https://python.langchain.com/v0.2/docs/integrations/tools/)'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'LangChain 工具: [https://python.langchain.com/v0.2/docs/integrations/tools/](https://python.langchain.com/v0.2/docs/integrations/tools/)'
- en: 'DuckDuckGo: [https://duckduckgo.com/](https://duckduckgo.com/)'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'DuckDuckGo: [https://duckduckgo.com/](https://duckduckgo.com/)'
- en: 'Guardian, *‘Godfather of AI’ shortens odds of the technology wiping out humanity
    over next 30 years*, 2024: [https://www.theguardian.com/technology/2024/dec/27/godfather-of-ai-raises-odds-of-the-technology-wiping-out-humanity-over-next-30-years](https://www.theguardian.com/technology/2024/dec/27/godfather-of-ai-raises-odds-of-the-technology-wiping-out-humanity-over-next-30-years)'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 守护者报，*“AI教父缩短了未来30年内技术灭绝人类的可能性”，2024年*：[https://www.theguardian.com/technology/2024/dec/27/godfather-of-ai-raises-odds-of-the-technology-wiping-out-humanity-over-next-30-years](https://www.theguardian.com/technology/2024/dec/27/godfather-of-ai-raises-odds-of-the-technology-wiping-out-humanity-over-next-30-years)
