<html><head></head><body>
		<div><h1 id="_idParaDest-16" class="chapter-number"><a id="_idTextAnchor015"/>1</h1>
			<h1 id="_idParaDest-17"><a id="_idTextAnchor016"/>Surveying Deepfakes</h1>
			<p>Understanding deepfakes begins with understanding where they came from and what they can do. In this chapter, we’ll begin to explore deepfakes and their operation. We will go through the basics of what makes a deepfake work, talking about the differences between a <strong class="bold">generative auto-encoder</strong> and a <strong class="bold">generative adversarial network</strong> (<strong class="bold">GAN</strong>). We will examine their usTo PD: es in media, education, and advertising. We’ll investigate their limitations and consider how to plan and design your deepfakes to avoid the common pitfalls. Finally, we’ll examine existing deepfake software and discuss what each kind can do.</p>
			<p>We’ll cover this in the following sections:</p>
			<ul>
				<li>Introducing deepfakes</li>
				<li>Exploring the uses of deepfakes</li>
				<li>Discovering how deepfakes work</li>
				<li>Assessing the limitations of generative AI</li>
				<li>Looking at existing deepfake software</li>
			</ul>
			<h1 id="_idParaDest-18"><a id="_idTextAnchor017"/>Introducing deepfakes</h1>
			<p>The name <strong class="bold">deepfake</strong> comes from a<a id="_idIndexMarker000"/> portmanteau of “deep”, referring to <strong class="bold">deep learning</strong>, and “fake,” referring to the fact that the images generated are not genuine. The term first came into use on the popular website Reddit, where the original author released several deepfakes of adult actresses with other women’s faces artificially applied to them.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The ethics of deepfakes are controversial, and we will cover this in more depth in <a href="B17535_02.xhtml#_idTextAnchor035"><em class="italic">Chapter 2</em></a><em class="italic">,</em> <em class="italic">Examining Deepfake Ethics </em><em class="italic">and Dangers.</em></p>
			<p>This unethical beginning is still what the technology is most known for, but it’s not all that it can be used for. Since that time, deepfakes have moved into movies, memes, and more. Tom Cruise signed up for Instagram only after “Deep Tom Cruise” beat him to it. Steve Buscemi has remarked to Stephen Colbert that he “never looked better” when his face was placed on top of Jennifer Lawrence’s and a younger version of Bill Nighy was deepfaked onto his own older self for a news clip from the “past” in the movie <em class="italic">Detective Pikachu</em>.</p>
			<p>In this book, we will be taking a fairly narrow view of what deepfaking is, so let’s define it now. A deepfake is <a id="_idIndexMarker001"/>the use of a <strong class="bold">neural network</strong> trained on two faces to replace one face with another. There<a id="_idIndexMarker002"/> are other technologies to swap faces that aren’t deepfakes, and there are generative AIs that do other things besides swapping faces but to include all of those in the term just muddies the water and confuses the issue.</p>
			<h1 id="_idParaDest-19"><a id="_idTextAnchor018"/>Exploring the uses of deepfakes</h1>
			<p>The original use of<a id="_idIndexMarker003"/> Deepfakes might be the one that required the least amount of imagination. Putting one person’s face on another’s person has many different uses in various fields. Please don’t consider the ideas here as the full extent of the capabilities of deepfakes – someone is bound to imagine something new!</p>
			<h2 id="_idParaDest-20"><a id="_idTextAnchor019"/>Entertainment</h2>
			<p>Entertainment is the<a id="_idIndexMarker004"/> first area that comes to mind for most people when they consider the usage of deepfakes. There are two main areas of entertainment in which I see<a id="_idIndexMarker005"/> deepfakes playing a significant role: <em class="italic">narrative</em> and <em class="italic">parody</em>.</p>
			<h3>Narrative</h3>
			<p>The utility of deepfakes in movies<a id="_idIndexMarker006"/> is obvious. Imagine an actor’s face being superimposed onto their stunt double or an actor who becomes unavailable being replaced by another performer without any changes to the faces in the final movie.</p>
			<p>While deepfakes may not seem good enough, deepfakes are already being used in Hollywood and other media today – from <em class="italic">Detective Pikachu</em>, which used deepfakes to de-age Bill Nighy, to <em class="italic">For All Mankind</em>, which used it to put actors face to face with Ronald Reagan. Agencies and VFX shops are all examining how to use deepfakes in their work.</p>
			<p>These techniques are not unique to deepfakes. CGI (in this book, referring to 3D graphics) face replacements have been used in many movies. However, using CGI face replacement is expensive and complicated, requiring filming to be done in particular ways with lots of extra data captured to be used by the artists to get the CGI face to look good in the final scene. This is an art more than a science and requires extensive skills and knowledge to accomplish. Deepfakes solve many of these problems making new forms of face replacements possible.</p>
			<p>Making a deepfake requires<a id="_idIndexMarker007"/> no special filming techniques (although some <a id="_idIndexMarker008"/>awareness will make the process smoother). Deepfakes also require very little attention or skill compared to CGI face replacements. This makes it ideal for lower-cost face replacements, but it can also be higher-quality since the AI accounts for details that even the most dedicated artist can’t recreate.</p>
			<h2 id="_idParaDest-21"><a id="_idTextAnchor020"/>Parody</h2>
			<p>Parody is an extremely <a id="_idIndexMarker009"/>popular form of social criticism and forms the basis for entire To PD: movies, TV shows, and other forms of media. Parody is normally done by professional impersonators. In some cases, those impersonators look (or can be made to look) similar to the person they’re impersonating. Other times, there is a reliance on their performance to make the impersonation clear.</p>
			<p>Deepfakes provide an opportunity to change the art of parody wherein the impersonator can be made to look like the individual being parodied via a deepfake instead of by chance of birth. By removing the attention from basic appearance, deepfakes allow the focus to be placed directly on the performance itself.</p>
			<p>Deepfakes also enable a whole new form of parody in which normal situations can become parodic simply due to the changed face. This particular form becomes humorous due to the distinct oddity of very different faces, instead of an expected swap.</p>
			<div><div><img src="img/B17535_01_001.jpg" alt="Figure 1.1 – Steve Buscemi as Jennifer Lawrence by birbfakes"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.1 – Steve Buscemi as Jennifer Lawrence by birbfakes</p>
			<p class="callout-heading">Note</p>
			<p class="callout">This image is included with the kind permission of its original creator, birbfakes. You can view the original video here: <a href="https://youtu.be/r1jng79a5xc">https://youtu.be/r1jng79a5xc</a>.</p>
			<h3>Video games</h3>
			<p>Video games present an<a id="_idIndexMarker010"/> interesting opportunity when it comes to deepfakes. The idea here is that a computer-generated character could be deepfaked into a<a id="_idIndexMarker011"/> photorealistic avatar. This could be done for any character in the game, even the player’s character. For example, it would be possible to make a game in which, when the player’s character looked into a mirror, they would see their own face looking back at them. Another possibility would be to replace a non-player character with a deepfake of the original actor, allowing for a far more realistic appearance without making a complete 3D clone of the actor.</p>
			<h2 id="_idParaDest-22"><a id="_idTextAnchor021"/>Education</h2>
			<p>Education could also<a id="_idIndexMarker012"/> benefit from deepfakes. Imagine if your history class had a video of Abraham Lincoln himself reading the Gettysburg address. Or a corporate training video in which the entire video is hosted by the public mascot (who may not even be a real person) without having to resort to costumes or CGI. It could even be used to allow multiple videos or scenes filmed at significantly different times to appear to <a id="_idIndexMarker013"/>be more cohesive by appearing to show the actor at the same time.</p>
			<p>Many people are very visual learners and seeing a person “come alive” can really bring the experience home. Bringing the pre-video past to life using deepfakes enables a whole new learning experience. One example of this is the Dalí Museum, which created a series of videos of Salvador Dalí talking to guests. This was done by training a deepfake model on an actor to put Dalí’s face on the videos. Once the model was trained and set up, they were able to convert many videos, saving a lot of time and effort compared to a CGI solution.</p>
			<h2 id="_idParaDest-23"><a id="_idTextAnchor022"/>Advertisements</h2>
			<p>Advertising agencies are always looking for the newest way to grab attention and deepfakes could be a whole new way to catch viewers’ attention. Imagine if you walked past a clothing store, you<a id="_idIndexMarker014"/> stopped to look at an item of clothing in the window, and suddenly the screen beside the item showed a video of an actor wearing the item but with your face, allowing you to see how the item would look on you. Alternatively, a mascot figure could be brought to life in a commercial. Deepfakes offer a whole new tool for creative use, which can grab attention and provide whole new experiences in advertising.</p>
			<p>Now that we’ve got some idea of a few potential uses for deepfakes, let’s take a quick look under the hood and see how they work.</p>
			<h1 id="_idParaDest-24"><a id="_idTextAnchor023"/>Discovering how deepfakes work</h1>
			<p>Deepfakes are<a id="_idIndexMarker015"/> a unique variation of a generative auto-encoder being used to generate the face swap. This requires a special structure, which we will explain in this section.</p>
			<h2 id="_idParaDest-25"><a id="_idTextAnchor024"/>Generative auto-encoders</h2>
			<p>The particular type of neural network that regular deepfakes use is called a <strong class="bold">generative auto-encoder</strong>. Unlike<a id="_idIndexMarker016"/> a <strong class="bold">Generative Adversarial Network</strong> (<strong class="bold">GAN</strong>), an auto-encoder does not use a<a id="_idIndexMarker017"/> discriminator or any “adversarial” techniques.</p>
			<p>All auto-encoders work by training a collection of neural network models to solve a problem. In the case of generative auto-encoders, the AI is used to generate a new image with new details that weren’t in the original image. However, with a normal auto-encoder, the problem is usually <a id="_idIndexMarker018"/>something such as <strong class="bold">classification</strong> (deciding what an image is), <strong class="bold">object identification</strong> (finding something inside an image), or <strong class="bold">segmentation</strong> (identifying different parts of an image). To do this, there are two types of models used in the autoencoder – the <strong class="bold">encoder</strong> and <strong class="bold">decoder</strong>. Let’s see how this works.</p>
			<h3>The deepfake training cycle</h3>
			<p>The training cycle is a cyclical <a id="_idIndexMarker019"/>process in which the model is continuously trained on images until stopped. The process can be broken down into four steps:</p>
			<ul>
				<li><strong class="bold">Encode</strong> faces into smaller intermediate representations.</li>
				<li><strong class="bold">Decode</strong> the intermediate representations back into faces.</li>
				<li>Calculate the <strong class="bold">loss</strong> of (meaning, the difference between) the original face and the output of the model.</li>
				<li>Modify (<strong class="bold">backpropagate</strong>) the models toward the correct answer.</li>
			</ul>
			<div><div><img src="img/B17535_01_002.jpg" alt="Figure 1.2 – Diagram of the training cycle"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.2 – Diagram of the training cycle</p>
			<p>In more detail, the <a id="_idIndexMarker020"/>process unfolds as follows:</p>
			<ul>
				<li>The <strong class="bold">encoder’s</strong> job is to <strong class="bold">encode</strong> two different faces into an array, which we call the intermediate representation. The intermediate representation is much smaller than the original image size, with enough space to describe the lighting, pose, and expression of the faces. This process is similar to compression, where unnecessary data is thrown out to fit the data into a smaller space.</li>
				<li>The <strong class="bold">decoder</strong> is actually a matched pair of models, which turn the intermediate representation back into faces. There is one decoder for each of the input faces, which is trained only on images of that one person’s face. This process tries to create a new face that matches the original face that was given to the encoder and encoded into the intermediate representation.</li>
			</ul>
			<div><div><img src="img/B17535_01_003.jpg" alt="Figure 1.3 – Encoder and decoder"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.3 – Encoder and decoder</p>
			<ul>
				<li><strong class="bold">Loss</strong> is a score that is given to the auto-encoder based on how well it recreates the original faces. This is calculated by comparing the original image to the output from the encoder-decoder process. This comparison can be done in many ways, from a strict difference between them or something significantly more complicated that includes human perception as part of the calculation. No matter how it’s done, the result is the same: a number from 0 to 1, with 0 being the score for <a id="_idIndexMarker021"/>the model returning the exact same image and 1 being the exact opposite or the image. Most of the numbers will fall between 0 to 1. However, a perfect reconstruction (or its opposite) is impossible.</li>
			</ul>
			<p class="callout-heading">Note</p>
			<p class="callout">The loss is where an auto-encoder differs from a GAN. In a GAN, the comparison loss is either replaced or supplemented with an additional network (usually an auto-encoder itself), which then produces a loss score of its own. The theory behind this structure is that the loss model (called a discriminator) can learn to get better at detecting the output of the generating model (called a generator) while the generator can learn to get better at fooling the discriminator.</p>
			<ul>
				<li>Finally, there is <strong class="bold">b</strong><strong class="bold">ackpropagation</strong>, a process in which the models are adjusted by following the path back through both the decoder and encoder that generated the face and nudging those paths toward the correct answer.</li>
			</ul>
			<div><div><img src="img/B17535_01_004.jpg" alt="Figure 1.4 – Loss and backpropagation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.4 – Loss and backpropagation</p>
			<p>Once complete, the whole process starts back over at the encoder again. This continues to repeat until the neural network has finished training. The decision of when to end training can happen in<a id="_idIndexMarker022"/> several ways. It can happen when a certain number of repetitions have occurred (called <strong class="bold">iterations</strong>), when all the<a id="_idIndexMarker023"/> data has been gone through (called an <strong class="bold">epoch</strong>), or when the results meet a <a id="_idIndexMarker024"/>certain loss score.</p>
			<h3>Why not GANs?</h3>
			<p>GANs are one of the current darlings of generative networks. They are extremely popular and used extensively, being used particularly for super-resolution (intelligent upscaling), music generation, and <a id="_idIndexMarker025"/>even sometimes deepfakes. However, there are some reasons that they’re not used in all deepfake solutions.</p>
			<p>GANs are popular due to their “imaginative” nature. They learn through the interaction of their generator and discriminator to fill in gaps in the data. Because they can fill in missing pieces, they are great at reconstruction tasks or at tasks where new data is required.</p>
			<p>The ability of a GAN to create new data where it is missing is great for numerous tasks, but it has a critical flaw when used for deepfakes. In deepfakes, the goal is to replace one face with another face. An imaginative GAN would likely learn to fill the gaps in the data from one face with the data from the other. This leads to a problem that we call “identity bleed” where the two faces aren’t swapped properly; instead, they’re blended into a face that doesn’t look like either person, but a mix of the two.</p>
			<p>This flaw in a GAN-created<a id="_idIndexMarker026"/> deepfake can be corrected or prevented but requires much more careful data collection and processing. In general, it’s easier to get a full swap instead of a blending by using a generative auto-encoder instead of a GAN.</p>
			<h3>The auto-encoder structure</h3>
			<p>Another name for an <a id="_idIndexMarker027"/>auto-encoder is an “hourglass” model. The reason for this is that each layer of an encoder is smaller than the layer before it while each layer of a decoder is larger than the one before. Because of this, the auto-encoder figure starts out large at the beginning, shrinks toward the middle, and then widens back out again as it reaches the end:</p>
			<div><div><img src="img/B17535_01_005.jpg" alt="Figure 1.5 – Hourglass structure of an autoencoder"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.5 – Hourglass structure of an autoencoder</p>
			<p>While these methods are flexible and have many potential uses, there are limitations. Let’s examine those limitations now.</p>
			<h1 id="_idParaDest-26"><a id="_idTextAnchor025"/>Assessing the limitations of generative AI</h1>
			<p>Generative AIs like those <a id="_idIndexMarker028"/>used in deepfakes are not a panacea and actually have some significant limitations. However, by knowing about these limitations, they can generally be worked around or sidestepped with careful design.</p>
			<h2 id="_idParaDest-27"><a id="_idTextAnchor026"/>Resolution</h2>
			<p>Deepfakes are limited in the<a id="_idIndexMarker029"/> resolution that they can swap. This is a hardware and time limitation: greater hardware and more time can provide higher resolution swaps. However, this is not a 1:1 linear growth. Doubling the resolution (from, say, 64x64 to 128x128) actually quadruples the amount of required <strong class="bold">VRAM</strong> – that is, the memory that a GPU has direct access to – and the time necessary to train is expanded a roughly equivalent amount. Because of this, resolution is often a balancing act, where you’ll want to make the deepfake the lowest resolution you can without sacrificing the results.</p>
			<h2 id="_idParaDest-28"><a id="_idTextAnchor027"/>Training required for each face pair</h2>
			<p>To provide the best results, traditional <a id="_idIndexMarker030"/>deepfakes require that you train on every face pair that you wish to swap. This means that if you wanted to swap your own face with two of your friends, you’d have to train two separate models. This is because each model has one encoder and two decoders, which are trained only to swap the faces they were given.</p>
			<p>There is a workaround to some multi-face swaps. In order to swap additional faces, you could write your own version with more than two decoders allowing you to swap additional faces. This is an imperfect solution, however, as each decoder takes up a significant amount of VRAM, requiring you to balance the number of faces carefully.</p>
			<p>It may be better to simply train multiple pairs. By splitting the task up on multiple computers, you could train multiple models simultaneously, allowing you to create many face pairs at once.</p>
			<p>Another option is to use a different type of AI face replacement. <strong class="bold">First Order Model</strong> (which is covered in the <em class="italic">Looking at existing deepfake software</em> section of this chapter) uses a different technique: instead of a paired approach, it uses AI to animate an image to match the <a id="_idIndexMarker031"/>actions of a replacement. This solution removes the need to retrain on each face pair, but comes at the cost of greatly reduced quality of the swap.</p>
			<h2 id="_idParaDest-29"><a id="_idTextAnchor028"/>Training data</h2>
			<p>Generative AIs requires<a id="_idIndexMarker032"/> a significant amount of training data to accomplish their tasks. Sometimes, finding sufficient data or data of a high-enough quality is not possible. For example, how would someone create a deepfake of William Shakespeare when there are no videos or photographs of him? This is a tricky problem but can be worked around in several ways. While it is unfortunately impossible to create a proper deepfake of England’s greatest playwright, it would be possible to use an actor who looks like his portraits and then deepfake that actor as Shakespeare.</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">We will cover more on how to deal with poor or insufficient data in <a href="B17535_03.xhtml#_idTextAnchor054"><em class="italic">Chapter 3</em></a>, <em class="italic">Mastering Data.</em></p>
			<p>Finding sufficient data (or clever workarounds) is the most difficult challenge that any data scientist faces. Occasionally, there simply is no way to get sufficient data. This is when you might need to re-examine the video to see whether there is another way to shoot it to avoid the lack of data, or you might try using other sources of similar data to patch the gaps. Sometimes, just knowing the limitations in advance can prevent a problem – other times, a workaround in the last minutes may be enough to save a project from failure.</p>
			<p>While everyone should know the data limitations, knowing the limitations of the process is only for experts. If you are only looking to use deepfakes, you’ll probably use existing software. Let’s explore those next.</p>
			<h1 id="_idParaDest-30"><a id="_idTextAnchor029"/>Looking at existing deepfake software</h1>
			<p>There have been many <a id="_idIndexMarker033"/>programs that have risen to fill the niche of deepfaking; however, few of them are still under development or supported. The rapid development of GPU hardware and AI software has led to unique challenges in software development, and many deepfake programs are no longer usable. However, there are still several deepfake software programs and, in this section, we’ll go over the major options.</p>
			<p class="callout-heading">Important Note</p>
			<p class="callout">The authors have made every effort to be unbiased in this section, but are among the developers of Faceswap. Faceswap will be covered in more detail in <a href="B17535_04.xhtml#_idTextAnchor071"><em class="italic">Chapter 4</em></a>, <em class="italic">The Deepfake Workflow</em>, with a walkthrough of the workflow of a deepfake through the Faceswap software.</p>
			<h2 id="_idParaDest-31"><a id="_idTextAnchor030"/>Faceswap</h2>
			<p>Faceswap is a <strong class="bold">Free and Open Source</strong> (<strong class="bold">FOSS</strong>) software <a id="_idIndexMarker034"/>program for creating deepfakes. It’s released under the GPL3 and can be <a id="_idIndexMarker035"/>used by anyone anywhere. It’s written in Python and runs AI on the TensorFlow backend. It supports <a id="_idIndexMarker036"/>NVIDIA, AMD, and Apple GPUs for accelerating the machine learning models, or can be run on a CPU at a reduced speed. There are installers for Windows and Linux that can help by installing all the needed libraries and tools<a id="_idIndexMarker037"/> inside of a self-contained environment.</p>
			<p>It’s available at <a href="https://Faceswap.dev/">https://Faceswap.dev/</a>.</p>
			<h2 id="_idParaDest-32"><a id="_idTextAnchor031"/>DeepFaceLab</h2>
			<p>Originally a fork of Faceswap, DeepFaceLab is now developed mostly by Ivan Perov. DeepFaceLab is another FOSS software<a id="_idIndexMarker038"/> program for deepfakes. It is <a id="_idIndexMarker039"/>known for more experimental models and features. There is no GUI, but there are Jupyter Notebooks that can be run in any of the Jupyter environments. There is also a DirectML version, which provides another option for people using Windows. There are fully contained builds that are packaged together into a single compressed <a id="_idIndexMarker040"/>file, which <a id="_idIndexMarker041"/>provides a <a id="_idIndexMarker042"/>fully working package for many operating systems.</p>
			<p>It’s available at <a href="https://github.com/iperov/DeepFaceLab">https://github.com/iperov/DeepFaceLab</a>.</p>
			<h2 id="_idParaDest-33"><a id="_idTextAnchor032"/>First Order Model</h2>
			<p><strong class="bold">First Order Model</strong> works in a fundamentally different way from Faceswap and DeepFaceLab. Instead of swapping a face onto a new video, First Order Model “puppets” the face, making it match the<a id="_idIndexMarker043"/> movements of a video<a id="_idIndexMarker044"/> but leaving the face the same. Furthermore, it doesn’t require training on each face pair, making it easy to use to make quick deepfakes where you can “animate” a person even with just a single photo of them.</p>
			<p>It is important to note that while the First Order Model software is available freely, it is licensed only for non-commercial use: if you want to use it in a commercial context, you’ll need to contact the author for<a id="_idIndexMarker045"/> a license. It’s available at <a href="https://github.com/AliaksandrSiarohin/first-order-model">https://github.com/AliaksandrSiarohin/first-order-model</a>.</p>
			<h2 id="_idParaDest-34"><a id="_idTextAnchor033"/>Reface</h2>
			<p><strong class="bold">Reface</strong> is yet another method of <a id="_idIndexMarker046"/>creating deepfakes. Reface is closed <a id="_idIndexMarker047"/>source and proprietary, so we can’t analyze exactly how it works, but it uses a zero-shot learning method like First Order Model to swap faces without requiring training on a pair of swaps. Reface offers apps for Apple iOS and Android and does the swap in the cloud, making it easier to get a quick result, but means that you might not be <a id="_idIndexMarker048"/>able to swap the exact clip you want, and licensing may be an issue.</p>
			<p>It’s available at <a href="https://reface.ai/">https://reface.ai/</a>.</p>
			<h1 id="_idParaDest-35"><a id="_idTextAnchor034"/>Summary</h1>
			<p>The technology of deepfakes is not itself anything new or unique. These techniques existed in various forms long before they were applied to face-swapping, but deepfakes have caught public attention in a way that other AI techniques have never really been able to. There is something very visceral about seeing a face where it doesn’t belong, seeing an actor in a role you know that they didn’t play, or seeing your own face doing something you’ve never done.</p>
			<p>While the techniques that make up deepfakes have all existed previously on their own, together, they provide completely new possibilities. There are numerous use cases that deepfakes can be applied to, from stunt-double replacement to advertising. The technology is here, and its use will only grow as more and more industries find ways to use it.</p>
			<p>There are still limits to the capabilities of generative AI. Knowing what a deepfake cannot do is as important as knowing what it can do. Especially regarding data, knowing how to work around those limitations is key to a quality result.</p>
			<p>We’ve given an overview of deepfakes, covering what they are, what they can be used for, how they work, their limitations, and the existing software you can use to make them. In the next chapter, we’ll cover the potential dangers of deepfakes and talk about the ethical questions that the technology brings with it.</p>
		</div>
		<div><div></div>
		</div>
	<div><p>EBSCOhost - printed on 11/27/2023 6:20 AM via . All use subject to <a target="_blank" href="https://www.ebsco.com/terms-of-use">https://www.ebsco.com/terms-of-use</a></p></div>
</body></html>