- en: '8'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Hyperparameter Tuning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you’ll learn about the hyperparameters in LLMs and strategies
    for optimizing them efficiently. We’ll explore both manual and automated tuning
    approaches, including grid search, random search, and more advanced methods, such
    as Bayesian optimization and population-based training. You’ll also gain insights
    into handling multi-objective optimization scenarios common in LLM development.
  prefs: []
  type: TYPE_NORMAL
- en: By the end, you’ll be equipped with practical tools and techniques to fine-tune
    your LLMs for optimal performance across various tasks and domains.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’ll be covering the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding hyperparameters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Manual versus automated tuning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Grid and random search
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bayesian optimization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Population-based methods
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multi-objective hyperparameter optimization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hyperparameter tuning at scale – challenges and solutions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding hyperparameters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Hyperparameters are settings that are set before the machine learning training
    process begins and are not learned from the data. They control various aspects
    of the learning algorithm itself, such as the model’s complexity, learning rate,
    and the overall training process. Data scientists manually choose and tune these
    hyperparameters to optimize the model’s performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Hyperparameters in LLMs can be broadly categorized into three groups: architectural,
    optimization, and regularization hyperparameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Architectural hyperparameters**: These define the design and structure of
    the model, determining how it processes and represents data. They are critical
    because they directly influence the model’s capacity to learn complex patterns
    and relationships in the data. The right architecture balances computational efficiency
    with performance, enabling the model to generalize well to unseen data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Parameters within this category include the following:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Number of layers
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden size
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Number of attention heads
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Feed-forward dimension
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Vocabulary size
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Optimization hyperparameters**: These govern how the model learns during
    training by adjusting the parameters to minimize the loss function. They are important
    because they control the rate and manner of updates, affecting convergence speed,
    stability, and the model’s ability to reach an optimal solution. Proper tuning
    ensures efficient training without divergence or underfitting.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Parameters within this category include the following (we covered these in
    [*Chapter 7*](B31249_07.xhtml#_idTextAnchor108)):'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Learning rate
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Batch size
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Number of training steps
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Warmup steps
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Learning rate schedule
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Regularization hyperparameters**: These introduce mechanisms to prevent the
    model from overfitting to the training data, ensuring it generalizes to new data.
    They are crucial because models with high capacity can easily memorize the training
    data, leading to poor performance on unseen data. Regularization techniques enforce
    constraints that encourage simplicity and robustness.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Parameters within this category include the following (see [*Chapter 9*](B31249_09.xhtml#_idTextAnchor141)
    for more):'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Dropout rate
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Weight decay
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Label smoothing
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let’s implement a function to create an LLM with configurable hyperparameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'In this code, we define a function, `create_llm`, that allows us to easily
    create LLMs with different architectural hyperparameters. The function takes the
    following parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '`num_layers`: The number of transformer layers in the model. More layers can
    capture more complex patterns, but they increase computational requirements.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`hidden_size`: The dimension of the hidden states throughout the model. This
    affects the model’s capacity to capture information.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_heads`: The number of attention heads in each layer. Multiple heads allow
    the model to focus on different aspects of the input simultaneously.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ff_dim`: The dimension of the feed-forward layer in each transformer block.
    This is typically set to four times the `hidden_size`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`vocab_size`: The size of the model’s vocabulary. This determines the size
    of the embedding layer and the output layer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We use these parameters to create a `GPT2Config` object, which is then used
    to initialize a `GPT2LMHeadModel`. This approach allows us to easily experiment
    with different model architectures.
  prefs: []
  type: TYPE_NORMAL
- en: Manual versus automated tuning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Manual tuning** involves adjusting hyperparameters based on intuition, experience,
    and gradual experimentation. Manual tuning allows you to leverage domain knowledge
    to explore tailored configurations systematically, but it is time-intensive, prone
    to suboptimal results, and inefficient in exploring large hyperparameter spaces.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Automated tuning**, on the other hand, uses algorithms to systematically
    explore the hyperparameter space. Automated tuning efficiently explores large
    hyperparameter spaces using algorithms to optimize performance, saving time and
    effort compared to manual tuning, but it can be computationally expensive and
    may require expertise to configure properly.'
  prefs: []
  type: TYPE_NORMAL
- en: Manual tuning is useful when domain knowledge or intuition can guide a small,
    targeted search space, especially in resource-constrained settings or for simpler
    models. Automated tuning is better for large, complex hyperparameter spaces where
    systematic exploration and optimization are required, as it can find better configurations
    more efficiently despite higher computational costs.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s implement both approaches.
  prefs: []
  type: TYPE_NORMAL
- en: Manual tuning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'First, we’ll implement manual tuning:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Start with the imports:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load a sample dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Set up the manual tuning hyperparameters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Conduct training with `manual_hyperparameters`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Evaluate the model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In this manual tuning example, we define a list of hyperparameter configurations
    to try. We then iterate through these configurations, creating a model for each,
    training it, and evaluating its performance. This approach allows us to systematically
    explore different model sizes and architectures.
  prefs: []
  type: TYPE_NORMAL
- en: 'The manual tuning process can be guided by domain knowledge and intuition.
    For example, we might start with a small model (6 layers, 512 hidden size) and
    gradually increase the size to see how it affects performance. We choose these
    specific configurations based on common practices in transformer-based models:'
  prefs: []
  type: TYPE_NORMAL
- en: The smallest configuration (6 layers, 512 hidden size) represents a compact
    model suitable for faster training and deployment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The medium configuration (12 layers, 768 hidden size) is similar to the base
    GPT-2 model, known to perform well on many tasks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The largest configuration (24 layers, 1,024 hidden size) represents a more powerful
    model that might capture more complex patterns but requires more computational
    resources
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automated tuning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, let’s implement a simple automated tuning approach using random search
    (we will show a more advanced random search in the next section):'
  prefs: []
  type: TYPE_NORMAL
- en: 'Add the `import` statement and set up the random parameters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Conduct training:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Evaluate and print out the results:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This random search implementation randomly selects hyperparameters from predefined
    options for each trial (no manual intervention during trials). Predefined options
    refer to the specified ranges, sets, or distributions from which random values
    for hyperparameters are sampled during the search process. For example, discrete
    hyperparameters such as the number of layers might be chosen from a set `[6, 12,
    24]`, while continuous hyperparameters such as learning rate could be sampled
    from a uniform or log-uniform distribution, such as `10^(-5)` to `10^(-3)`. These
    options define the boundaries and possible values for each hyperparameter, guiding
    the random sampling process.
  prefs: []
  type: TYPE_NORMAL
- en: We choose to search over a discrete set of values for each hyperparameter to
    limit the search space and ensure that we’re exploring configurations that are
    known to work well for transformer models. The number of trials (10 in this case)
    is a balance between exploration and computational resources. More trials increase
    the chance of finding a good configuration but also increase the computational
    cost.
  prefs: []
  type: TYPE_NORMAL
- en: In the subsequent sections, we will introduce other automated turning techniques
    such as grid search and more advanced random search, Bayesian optimization, the
    population-based method, and multi-objective hyperparameter optimization.
  prefs: []
  type: TYPE_NORMAL
- en: Grid and random search
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Grid search** and **random search** are two common methods for hyperparameter
    tuning. We covered random search in the previous section. In this section, we
    implement grid search and a more advanced version of random search.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Add the import and set up the grid search parameters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Train the model with the defined hyperparameters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Evaluate and print out the results:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Grid search exhaustively explores all combinations of hyperparameters. This
    approach is thorough but can be computationally expensive, especially for LLMs
    with many hyperparameters. In this implementation, we’re exploring `3^4` = `81`
    different configurations, which could take a significant amount of time and resources.
  prefs: []
  type: TYPE_NORMAL
- en: The hyperparameter ranges are chosen to cover a reasonable space of model sizes,
    from relatively small (6 layers, 512 hidden size) to quite large (24 layers, 1,024
    hidden size). This allows us to explore the trade-off between model size and performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s implement a more sophisticated random search that also includes
    optimization hyperparameters:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Add the `import` statement and set up the `advanced_random_search` hyperparameters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Conduct the training:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Evaluate and print out the results:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This advanced random search includes both architectural and optimization hyperparameters.
    We use `random.uniform` for `0.001`, `0.0015`, or `0.002`) such as learning rate
    and weight decay, and `random.choice` or `random.randint` for `32`, `64`, and
    `128` for batch size or selecting from a fixed set of options).
  prefs: []
  type: TYPE_NORMAL
- en: 'The ranges for each hyperparameter are chosen based on common practices in
    LLM training (see also [*Chapter 7*](B31249_07.xhtml#_idTextAnchor108)):'
  prefs: []
  type: TYPE_NORMAL
- en: '`1e-5` and `1e-3`, as learning rates for LLMs are typically in this range'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`8`, `16`, and `32`, which are common batch sizes that balance between computational
    efficiency and stability'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`2` to `5` epochs, as LLMs often converge within a few epochs on large datasets'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`100` and `1,000` steps, which can help stabilize early training'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`0` and `0.2`, as small amounts of weight decay can help prevent overfitting'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Advanced random search is better than grid search because it explores the hyperparameter
    space more efficiently by sampling randomly instead of exhaustively evaluating
    every possible combination. This flexibility allows it to focus on key hyperparameters
    that significantly impact performance, preventing redundant evaluations of less
    impactful ones. It can handle continuous parameters directly by sampling from
    distributions, unlike grid search, which requires discretization and exponentially
    grows in computational cost as the parameter space increases. By limiting the
    number of trials to a predefined budget, advanced random search can discover effective
    configurations faster and with less computational expense, making it more practical
    for large and complex models.
  prefs: []
  type: TYPE_NORMAL
- en: Bayesian optimization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Bayesian optimization** is a more sophisticated approach to hyperparameter
    tuning that can be particularly effective for LLMs. It uses a probabilistic model
    to predict the performance of different hyperparameter configurations and intelligently
    selects the next configuration to try.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s implement Bayesian optimization using the `optuna` library. **Optuna**
    is an open source hyperparameter optimization framework for automating the process
    of finding optimal parameters for algorithms and models. It employs advanced Bayesian
    optimization techniques, primarily the **Tree-structured Parzen Estimator** (**TPE**)
    algorithm, to efficiently search complex parameter spaces:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import optuna and set up the hyperparameters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Conduct training:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Run the optimization:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In this implementation, we define an `objective` function that Optuna will optimize.
    The function creates and trains a model with the hyperparameters suggested by
    Optuna and then returns the evaluation loss.
  prefs: []
  type: TYPE_NORMAL
- en: 'We use Optuna’s suggestion methods to define the search space:'
  prefs: []
  type: TYPE_NORMAL
- en: '`suggest_int` for integer hyperparameters such as `num_layers` and `num_epochs`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`suggest_categorical` for hyperparameters with discrete options such as `hidden_size`
    and `num_heads`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`suggest_loguniform` for the learning rate, as we want to search this space
    logarithmically'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`suggest_uniform` for weight decay, as we want to search this space uniformly'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The ranges for each hyperparameter are similar to those in our random search
    implementation based on common practices in LLM training.
  prefs: []
  type: TYPE_NORMAL
- en: Bayesian optimization can be more efficient than grid or random search, especially
    for expensive-to-evaluate functions such as training LLMs. It uses the results
    of previous trials to inform the selection of future trials, potentially finding
    good configurations more quickly.
  prefs: []
  type: TYPE_NORMAL
- en: Population-based methods
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Population-based training** (**PBT**) is a powerful technique that combines
    parallel search with adaptive hyperparameter tuning during the training process.
    PBT is particularly effective for problems where training can be paused and resumed
    efficiently. This is because PBT periodically evaluates and updates hyperparameters
    and model weights across a population, requiring seamless pause-and-resume capabilities.
    This adaptability ensures optimal use of computational resources and makes PBT
    ideal for tasks such as neural architecture search, reinforcement learning, and
    hyperparameter tuning, where iterative optimization is computationally intensive.'
  prefs: []
  type: TYPE_NORMAL
- en: Here, we’ll implement a simplified version of PBT to illustrate its core concepts
    and functionality.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll start by creating a `SimplePBT` class that encapsulates the core functionality
    of the PBT algorithm. Let’s break down the implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, initialize the class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The `SimplePBT` class is initialized with two main parameters:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`population_size`: The number of different hyperparameter configurations to
    maintain (the default is `4`)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_generations`: The number of iterations the PBT algorithm will run (the
    default is `5`)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The `population` list will store dictionaries representing each individual in
    the population, containing hyperparameters and their corresponding performance
    scores.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Initialize the population: The `initialize_population` method creates the initial
    set of hyperparameter configurations:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'For each individual in the population, do the following:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`num_layers`, `hidden_size`), are randomly selected from predefined options.
    These hyperparameters are categorical because they represent distinct, individual
    choices rather than values along a continuum.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`learning_rate`, `weight_decay`) are sampled from specified ranges.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Each configuration is added to the `population` list with an initial score of
    `None`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Train and evaluate: The `train_and_evaluate` method is responsible for creating
    an LLM with the given hyperparameters, setting up training arguments, initializing
    a trainer with the model and arguments, training the model, evaluating the model,
    and returning the evaluation loss:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This method assumes the existence of `create_llm`, `TrainingArguments`, and
    `Trainer` classes, which would typically be provided by a deep learning framework
    such as Hugging Face Transformers.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Exploit and explore: The `exploit_and_explore` method implements the core PBT
    algorithm:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'It sorts the population based on their scores (a lower score indicates less
    loss). The bottom-performing half of the population is replaced with mutated versions
    of the top-performing half. This approach balances `mutate` method introduces
    variations in the hyperparameters:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: It randomly selects one hyperparameter to mutate. For categorical parameters,
    it chooses a new value from predefined options. For continuous parameters like
    learning rate, it perturbs the current value within a certain range. For weight
    decay, it adds a small random value while keeping it within [`0, 0.2`].
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This mutation strategy allows both small and large changes in the hyperparameters,
    promoting diverse exploration of the hyperparameter space.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Run the PBT process:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The `run` method orchestrates the entire PBT process:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: It initializes the population.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: For each generation, it trains and evaluates each individual in the population
    and it performs exploitation and exploration to update the population.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: After all generations, it prints the best hyperparameters and the score found.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Use the `SimplePBT` class: To use the `SimplePBT` class, you can simply create
    an instance and run it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This will start the PBT process with the default population size of `4` and
    `5` generations. You can adjust these parameters when creating the `SimplePBT`
    instance to suit your specific needs.
  prefs: []
  type: TYPE_NORMAL
- en: Multi-objective hyperparameter optimization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In LLM development, we often need to balance multiple objectives, such as model
    performance, inference speed, and model size. Let’s implement multi-objective
    optimization using Optuna:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Add the `import` statement and set up the hyperparameters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Conduct the training:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Carry out the evaluation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Run the multi-objective optimization:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In this multi-objective optimization, we’re trying to minimize three objectives
    simultaneously:'
  prefs: []
  type: TYPE_NORMAL
- en: Evaluation loss (model performance)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Model size (in MB)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Inference time (simulated based on model architecture)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We use Optuna’s multi-objective optimization capability by specifying multiple
    directions in `create_study`. The optimization process will try to find the **Pareto
    front** (the set of solutions where improving any one objective necessitates degrading
    at least one other objective) of these objectives’ configurations, where improving
    one objective would necessarily worsen another.
  prefs: []
  type: TYPE_NORMAL
- en: The `objective` function now returns three values corresponding to our three
    objectives. For model size, we calculate the total number of parameters and convert
    it to MB. For inference time, we use a simple heuristic based on the model’s architecture
    in a real scenario, you would want to measure this.
  prefs: []
  type: TYPE_NORMAL
- en: This approach allows us to explore trade-offs between model performance, size,
    and speed. It’s particularly useful for LLM development, where we often need to
    balance these factors for different deployment scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: Hyperparameter tuning at scale – challenges and solutions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When tuning hyperparameters for LLMs, we face several challenges:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Computational cost**: Training LLMs is expensive, limiting the number of
    trials we can run'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Long training times**: Each trial can take days or weeks, making the entire
    process very time-consuming'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Large search space**: LLMs have many hyperparameters, creating a vast search
    space'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sensitivity to initialization**: LLM performance can vary significantly with
    different random seeds'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To address these challenges, we can employ several strategies:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Use smaller proxy tasks**: Instead of tuning on the full task, use a smaller
    dataset or fewer training steps to get a quick estimate of performance'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Leverage pre-trained models**: Start from pre-trained weights and focus on
    tuning fine-tuning hyperparameters'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Use multi-fidelity optimization**: Start with low-fidelity evaluations (e.g.,
    few training steps) and gradually increase fidelity for promising configurations'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Distributed hyperparameter tuning**: Use multiple machines to explore different
    hyperparameters in parallel'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let’s implement a simple multi-fidelity optimization approach:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Add the `import` statement and set up the hyperparameters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use a multi-fidelity strategy to train, starting with a small number of steps:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Conduct evaluation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Prune the unpromising trials:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Run the multi-fidelity optimization:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'There are a few aspects of this multi-fidelity approach that we should look
    at:'
  prefs: []
  type: TYPE_NORMAL
- en: We start by training each model configuration for only `100` steps, which gives
    a quick initial estimate of performance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We then increase the number of training steps to `500` and then `2,000` for
    promising configurations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We use Optuna’s pruning mechanism to early-stop unpromising trials, saving computational
    resources
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`MedianPruner` stops a trial if its performance is worse than the median of
    previous trials at the same step. This allows us to focus our computational resources
    on the most promising hyperparameter configurations.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This approach helps to address the challenges of hyperparameter tuning at scale:'
  prefs: []
  type: TYPE_NORMAL
- en: It reduces the computational cost by quickly eliminating poor configurations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It shortens the overall tuning time by using shorter training runs for initial
    evaluation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It allows us to explore a larger search space by running more trials in the
    same amount of time
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: However, there are still limitations to this approach. The performance after
    a small number of steps may not always correlate well with the final performance,
    especially for LLMs that often require long training times to converge.
  prefs: []
  type: TYPE_NORMAL
- en: 'To further improve hyperparameter tuning at scale, consider the following advanced
    techniques:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Distributed hyperparameter tuning**: This setup allows multiple machines
    to contribute to the same hyperparameter search, greatly speeding up the process:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**Leveraging pre-trained models**: This approach starts from pre-trained models
    and focuses on tuning the fine-tuning hyperparameters and model size, which can
    be more efficient than training from scratch:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**Bayesian optimization with Gaussian processes**: For problems where we can
    only afford a small number of trials, Gaussian process-based Bayesian optimization
    can be more sample-efficient than tree-based methods such as TPE (which is Optuna’s
    default):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This approach can be particularly useful for LLM tuning where each trial is
    very expensive.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Asynchronous Successive Halving Algorithm** (**ASHA**): ASHA is a bandit-based
    algorithm that can be more efficient than simple pruning methods:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: ASHA is particularly well-suited for large-scale hyperparameter optimization
    as it can handle asynchronous parallel optimization efficiently.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Hyperparameter tuning for LLMs presents unique challenges due to the scale and
    complexity of these models. By leveraging techniques such as multi-fidelity optimization,
    distributed tuning, and advanced algorithms such as Bayesian optimization and
    ASHA, we can make this process more efficient and effective. However, it’s important
    to remember that there’s often no one-size-fits-all solution, and the best approach
    may depend on your specific use case, available resources, and the characteristics
    of your LLM task.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we’ll focus on LLM regularization.
  prefs: []
  type: TYPE_NORMAL
