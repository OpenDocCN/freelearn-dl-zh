- en: '6'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Teaching a Robot to Listen
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Teaching a robot to listen to spoken instructions is a whole discipline in itself.
    It is not sufficient for the robot to just recognize individual words or some
    canned phrase. We want the robot to respond to normal spoken commands with a normal
    variety of phrasing. We might say, “Pick up the toys,” or “Please pick up all
    the toys,” or “Clean this mess up,” any of which would be a valid command to instruct
    the robot to begin searching the room for toys to pick up and put away. We will
    be using a variety of techniques and processes for this chapter. We are going
    to be building on an open source verbal assistant called **Mycroft**, an AI-based
    speech recognition and **natural language processing** (**NLP**) engine that can
    be programmed and extended by us. We will be adding some additional capability
    to Mycroft – we will use a technique I call the “fill in the blank” method of
    command processing to extract the intent of the user’s voice instructions, so
    that the robot does what you want it to do, even if that is not exactly what you
    said. We will complete this chapter by teaching the robot to both tell and respond
    to a specific form of human communication – knock-knock jokes.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in the chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Exploring robot speech recognition with NLP – both **speech to text** (**STT**)
    and **text to** **speech** (**TTS**)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Programming our robot
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This chapter uses the following tools:'
  prefs: []
  type: TYPE_NORMAL
- en: Mycroft Open Source Voice Assistant ([http://mycroft.ai](http://mycroft.ai))
    – I had to build it from source from the GitHub repository ([https://github.com/MycroftAI](https://github.com/MycroftAI)),
    so expect to do the same to keep it compatible with the **Robot Operating System**
    (**ROS**) we run the robot with.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Python 3.2.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You will need a GitHub account at [https://github.com/](https://github.com/).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I used a miniature USB speaker and microphone for this project, which worked
    very well with the Jetson. They can be found at [https://www.amazon.com/gp/product/B08R95XJW8](https://www.amazon.com/gp/product/B08R95XJW8)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The code used in this chapter can be found in the GitHub repository for this
    book at [https://github.com/PacktPublishing/Artificial-Intelligence-for-Robotics-2e](https://github.com/PacktPublishing/Artificial-Intelligence-for-Robotics-2e).
  prefs: []
  type: TYPE_NORMAL
- en: Exploring robot speech recognition with NLP
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This is going to be a rather involved chapter, but all of the concepts are fairly
    easy to understand. We will end up with a very strong framework to build voice
    recognition and commands upon. Not only will you get a voice-based command system
    for a robot, but also a full-featured digital assistant that tells jokes. Let’s
    first quickly introduce NLP.
  prefs: []
  type: TYPE_NORMAL
- en: Briefly introducing the NLP concept
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: NLP is not just converting sound waves to written words (speech to text, or
    STT), but also understanding what those words mean. We don’t want to just have
    some rigid, pre-programmed spoken commands, but some ability for the robot to
    respond to human speech.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will be using two different forms of STT processing:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Spectrum analysis**: This type helps to detect when you say the robot’s name.
    This technique recognizes words or phrases by sampling which frequencies and amplitudes
    make up the word. This process has the advantage of not taking a lot of computer
    resources and it is good at recognizing just one word or phrase – our “wake word”
    that will cause the computer to switch to the second type of voice recognition.
    This is the reason other voice-operated assistants require you to use a specific
    word (e.g., Siri, or Alexa) to enable them to start listening.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Phoneme recognition**: This technique converts STT by recognizing the parts
    of sounds – phonemes – that make up words. This technique, which seeks to interpret
    all sounds as words, is much more difficult, so we use the wake word to trigger
    the change. We’ll cover this in more detail later in this chapter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Next, let’s explore our primary goals for implementing speech recognition.
  prefs: []
  type: TYPE_NORMAL
- en: Setting our goals
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We set several goals for our robot in [*Chapter 2*](B19846_02.xhtml#_idTextAnchor032),
    which included being able to give voice commands to the robot since we may be
    using the robot without a base station. I also wanted the robot to be able to
    interact with my grandchildren, and specifically to be able to tell and respond
    to knock-knock jokes, a favorite activity of my grandson, William. For our robot,
    we do not want to use canned or memorized speech commands but rather have it be
    able to do some NLP to create a form of robot understanding of the spoken word.
    For example, if we want to have a command for picking up a toy, we humans could
    phrase that several ways: *grab a toy*, *grasp a toy*, *pick up that toy car*,
    or even *get that*. We want the robot to understand or at least respond to all
    of those utterances with the same action, to drive to the nearest toy and pick
    it up with the robot arm. STT systems are fairly commonplace today, but we would
    like to have some natural variations in the robot’s speech patterns to help create
    the illusion that the robot is smarter than it really is. We can break this process
    down into several steps, which we will be handling independently:'
  prefs: []
  type: TYPE_NORMAL
- en: Receive audio (sound) inputs. We need the robot to be able to hear or have the
    ability to convert sound into a digital form.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Those sounds need to be converted into text that the robot can process.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use processing on those text words to understand the intent of the speaker.
    We need to not just recognize individual words but combine those words into sentences
    and from those sentences, infer the intent of the speaker to understand what the
    robot is to do.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use that intent as a command to perform some task.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Provide verbal responses in the form of spoken words (text to speech, or TTS)
    back to the operator to confirm the robot heard and understood the command.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create a custom verbal interface that both tells and responds to knock-knock
    jokes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will start in the next section by introducing the process of STT, which is
    how the robot will receive voice input from you.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the STT process
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the rest of this chapter, we will be implementing an AI-based voice recognition
    and response system in the robot and creating our own custom voice interface.
    We will be using Mycroft, an open source voice-activated digital assistant that
    is adept at understanding speech and is easily extended for new functions and
    custom interfaces.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will discuss each of the steps involved in voice interaction in detail.
    There are two forms of STT involved in this process that greatly simplify matters
    for the robot: **wake word recognition** and **STT recognition**. Let’s explore
    wake word recognition first.'
  prefs: []
  type: TYPE_NORMAL
- en: Listening for the wake word
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the first approach, the robot is listening continuously for only one sound
    – the wake word. This is a specific sound that just means one thing – get ready
    to process the next sound into a command. Why is this necessary? Since the robot
    has only a very small processor – the Jetson Nano – it really does not have the
    sort of onboard compute power to run a robust STT engine. But it can run a simple
    sound recognizer that can listen for the wake word. You are familiar with this
    from other voice command systems, such as Alexa or Siri, that also either use
    a special wake word or a button to have the interface pay attention (see [https://www.howtogeek.com/427686/how-alexa-listens-for-wake-words/](https://www.howtogeek.com/427686/how-alexa-listens-for-wake-words/)).
  prefs: []
  type: TYPE_NORMAL
- en: Once the wake word is received, the Jetson Nano switches into record mode and
    records the next thing we say. It then transfers that information to an online
    system, the Google Cloud Speech to Text system (the same thing that runs the Google
    Assistant).
  prefs: []
  type: TYPE_NORMAL
- en: 'How does the robot recognize the wake word? The speech system we will be using,
    the open source system Mycroft, uses one of two methods:'
  prefs: []
  type: TYPE_NORMAL
- en: The first is a **phoneme recognition system** called Sphynx. What is a phoneme?
    You can understand that words are made up of individual sounds, which we roughly
    assign to letters of the alphabet. An example would be the *p* sound in the word
    *pet* or *pick* – this is an example of a phoneme. The word “Albert” has several
    phonemes – the *A* sound, (ah), the *L* sound, the *B*, the *ER* together, and
    finally, the *T*. The letters we associate with the sounds – for example, the
    *ch* in *cherry*, and the *er* in *Albert*, are called **graphemes**, as they
    graphically represent these sounds. We could say that the STT problem is one of
    mapping these phonemes to graphemes, but we know that this is too easy – English
    has all sorts of borrowed words and phrases where the pronunciation and the spelling
    are far apart.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The frontend of the Mycroft speech recognition process uses phonemes to recognize
    the wake word. You will find that it is quite sensitive. I had no problem getting
    the speech processor to receive the wake word from eight feet away. When we get
    to the setup, we will change the default Mycroft wake word from “Hey, Mycroft,”
    to “Hey, Albert.”
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Mycroft can also use a trained **neural network** that has been taught to recognize
    entire words all at once by their **spectral power graph**. What is a spectral
    graph? The sound of your voice is not one frequency of sound energy – it is a
    complex congregation of different frequencies produced by our mouths and vocal
    cords. If we spoke in pure frequencies, we would sound like a flute – pure tones
    at mostly one frequency. We can use a process called a **fast Fourier transform**
    to convert a selection of speech into a graph that shows the amount of energy
    (volume) at each frequency. This is called a spectral plot or spectral graph.
    The low frequencies are on the left, and higher frequencies are on the right.
    Most human speech’s energy is concentrated in the frequencies between 300 Hz and
    4,000 Hz. Each word has a unique distribution of sound energy amounts in these
    frequencies, and can be recognized by a neural network in this manner:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: "![Figure 6.1 – Analog audio waveform (top) and the spectral graph for the phrase\
    \ “Hey, Albert” (bottom)\uFEFF](img/B19846_06_1.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 6.1 – Analog audio waveform (top) and the spectral graph for the phrase
    “Hey, Albert” (bottom)
  prefs: []
  type: TYPE_NORMAL
- en: This preceding diagram shows both the audio waveform (top graph) in the time
    domain and the spectral plot in the frequency domain for the phrase “Hey, Albert.”
  prefs: []
  type: TYPE_NORMAL
- en: Both the phoneme method and the neural network method use spectral plots to
    recognize sounds as words, but the phoneme process divides words into individual
    sounds, and the neural network listens and recognizes the entire word all at once.
    Why does this make a big difference? The phoneme system can be developed to recognize
    any word in English without reprogramming or retraining, while the neural network
    has to be trained on each word individually, and hopefully by a lot of different
    speakers with a lot of different accents. We’ll be using the neural network method
    for Albert.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'You can remember from [*Chapter 4*](B19846_04.xhtml#_idTextAnchor126) that
    we needed labeled data to train a neural network. You recall we had pictures in
    categories and trained on each category. Training **artificial neural networks**
    (**ANNs**) for sound is the same: we need sounds and the associated words. Can
    you think of a place to get samples of lots of different voices where you also
    have the exact written script to match? Have you ever listened to a book on tape?'
  prefs: []
  type: TYPE_NORMAL
- en: Converting STT
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Our next step after receiving the wake word is to record the next sounds that
    the robot hears. The Mycroft system then transfers that audio data over the internet
    to the Google online STT engine ([https://cloud.google.com/speech-to-text/](https://cloud.google.com/speech-to-text/)).
    This is a quick way to resolve the problem of our little Jetson Nano not having
    enough processing power or storage to have a robust speech recognition capability.
  prefs: []
  type: TYPE_NORMAL
- en: What goes on in Google Cloud? The STT engine breaks the speech down into phonemes
    (sounds) and uses a neural network to assign the most probable graphemes (letters)
    to those sounds. The output would be spelled out more phonetically than we want
    to receive. For example, as per the *Carnegie Mellon University Pronouncing Dictionary*,
    the sentence “Pick up the toys, please?” comes out as `P IH K . AH P . DH AH .
    T OY Z . P L IY Z`. Why is this the case? What happened? These are the phonemes
    that make up that sentence. The periods indicate spaces between words. Now the
    system has to convert this into the words we are expecting. The STT system uses
    word rules and dictionaries to come up with the most likely conversion into regular
    words. This includes both expert systems (word rules) and trained neural networks
    that predict output words based on phonemes.
  prefs: []
  type: TYPE_NORMAL
- en: We can call this step the **language model**. Our STT outputs the sentence “How
    many ounces in a gallon?” and sends it back to the robot, all in less than two
    seconds.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have the command in text, an English sentence, how does the robot
    recognize what your intent is?
  prefs: []
  type: TYPE_NORMAL
- en: Clarifying the intent
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The NLP we are doing has one aim, or goal. We are giving commands to our robot
    using a voice interface. Commands in English normally follow a sentence pattern,
    something like “You – do this.” Often the “you” subject of the sentence is implied
    or understood and left out. We are left with statements such as “Clean this room,”
    or “Pick up those toys.” The intent of these commands is to have the robot initiate
    a program that results in the robot picking up toys and putting them away. The
    robot and its processor have to divine or derive the intent of the user from the
    words that are spoken. What we want is for any reasonable sentence to have as
    its meaning: “You, robot, start your pick-up-toys process.”'
  prefs: []
  type: TYPE_NORMAL
- en: 'Think of how many ways we can say that command to the robot. Here are some
    examples:'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s clean up this room
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Put away the toys
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pick up the toys
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pick up all the toys
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Clean up this room
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Put those away
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Put this away
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Time to clean up
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What do these phrases have in common? They all imply the subject who is doing
    the action is the robot. There are no words such as “You,” “robot,” or “Albert”
    to indicate to whom the command is intended for. The word “toys” appears a lot,
    as does “pick,” “clean,” and “put away.” It is possible that we can just pay attention
    to those keywords to understand this command. If we get rid of all of the common
    conjunction and pronoun words, what does the list look like?
  prefs: []
  type: TYPE_NORMAL
- en: Clean room
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Put toys
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pick toys
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pick toys
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Clean room
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Put away
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Put away
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Time clean
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An important concept for this chapter is to understand that we are not trying
    to understand all speech, but only that subset of speech that are commands that
    the robot can execute. A general solution to this voice recognition problem would
    be to have some ability to predict from the command given to the robot, the likelihood
    that the intent of the user points to one command more than any of the others.
    You can see that in the case of the word “clean,” none of our other commands (“drive
    around,” “move arm,” or “stop”) relate to “clean” at all. Thus, a sentence with
    “clean” in it is likely associated with the *pick up toys* command. This process
    of deciding intent will be used later in this chapter to send commands to the
    robot using Mycroft.
  prefs: []
  type: TYPE_NORMAL
- en: Now we are going to jump right into programming the Albert robot to listen and
    understand commands using Mycroft.
  prefs: []
  type: TYPE_NORMAL
- en: Programming our robot
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As discussed earlier in this chapter, Mycroft is a version of a digital assistant
    similar to Siri from Apple or Alexa from Amazon in that it can listen to voice
    commands in a mostly normal fashion and interface those commands to a computer.
    We are using it because it has an interface that runs on a Jetson Nano 3\. In
    this section, we will be setting up our hardware and our software (i.e., Mycroft).
  prefs: []
  type: TYPE_NORMAL
- en: Setting up the hardware
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will be installing Mycroft on Nvidia Jetson Nano (or whatever microprocessor
    you’re using). One of the few things that the Jetson Nano did not come with is
    **audio capability**. It has no speakers or microphones. I found that a quick
    and effective way to add that capability was to use an existing hardware kit that
    provided both a very high-quality speaker and an excellent set of stereo microphones
    in a robot-friendly form factor. Note that this works with pretty much any Linux
    **single-board** **computer** (**SBC**).
  prefs: []
  type: TYPE_NORMAL
- en: The kit is a miniature USB audio board that plugs into the Jetson Nano. It has
    both speakers and a microphone.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: I used a USB audio board (the brand is not important as any of them will do)
    for the Jetson Nano, which has been working very well for me and fits in the very
    small space we have on the robot. Installation could not be simpler. Plug in the
    audio board. You will need to go to **Settings** in the upper-right corner of
    your screen to select the USB audio version. There will be several other options
    listed.
  prefs: []
  type: TYPE_NORMAL
- en: Turn on your Jetson Nano 3 with the new speaker and microphone. I ran a quick
    test with YouTube to make sure the audio worked, and you can test it directly
    in the **Settings** user interface. Now we can dive into the software.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up the Mycroft software
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are several ways to install Mycroft, as we have to put Mycroft on top
    of the other software we have already:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Since Mycroft must get along with the ROS, and all of the AI libraries we installed,
    such as TensorFlow, Theano, and Keras, it is best that we use the `git clone`
    method to download the source code and build Mycroft on the Jetson Nano:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Mycroft will create a virtual environment it needs to run. It also isolates
    the Mycroft package from the rest of the packages on the Jetson Nano.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Please do not install Mycroft as the root user (or superuser). This will cause
    permissions problems with the configuration files.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to get the Mycroft system to work in this manner, I also had to do
    one more step. The Mycroft system kept failing when I first tried to get it to
    run. It would quit or get stuck when I tried to start the debugger. In order to
    correct this problem, I had to recompile the entire system using the following
    steps:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You can start in debug mode:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Next, you can ask Mycroft a more advanced skill, such as looking up information
    on the internet. Ask, “Hey, Mycroft, how many ounces in a gallon?” Mycroft will
    use the internet to look up the answer and reply.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, you can change the wake word on the Mycroft website to something more
    appropriate – we did not name this robot Mycroft. We have been calling this robot
    Albert, but you can choose to call the robot anything you want. You may find that
    a very short name such as Bob is too quick to be a good wake word, so pick a name
    with at least two syllables. To do this, navigate to the Mycroft web page ([http://home.mycroft.ai](http://home.mycroft.ai))
    and log in to your account, which we created back in *Step 4*. Click on your name
    in the upper right corner and select **Settings** from the menu. You can select
    several settings on this page, such as the type of voice you want, the units of
    measurement, and time and date formats. Select **Advanced Settings**, which will
    take you to the page where we can change the wake word.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We change the first field, the **Wake word** field, to **Custom**. We change
    the next line to put in our custom wake word – “Hey, Albert.”
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We also need to look up the phonemes for this wake word. Go to *The CMU Pronouncing
    Dictionary* from Carnegie Mellon University ([http://www.speech.cs.cmu.edu/cgi-bin/cmudict](http://www.speech.cs.cmu.edu/cgi-bin/cmudict)).
    Put in our phrase and you will get out the phoneme phrase. Copy and paste this
    phrase and go back to the Mycroft page to paste the phoneme phrase into the **Phonemes**
    field. You are done – don’t change any of the other settings.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Hit **Save** at the top of the page before you navigate away.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You can test your new wake word back on the Jetson Nano. Start Mycroft up again
    in debug mode and wait for it to come up. Say your new wake phrase and enjoy the
    response. I have a standard test set of phrases to show Mycroft’s skill at being
    the voice of our robot. Try the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Hey, Albert. What time is it?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hey, Albert. What is the weather for tomorrow? Hey, Albert. How many ounces
    in a gallon?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hey, Albert. Who is the king of England?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You should get the appropriate answers to these questions.
  prefs: []
  type: TYPE_NORMAL
- en: Mycroft has many other skills that we can take advantage of, such as setting
    a timer, setting an alarm, listening to music on Pandora, or playing the news.
    What we will be doing next is adding to these skills by creating our own that
    are specific to our room-cleaning robot.
  prefs: []
  type: TYPE_NORMAL
- en: Adding skills
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first skill we will create is a command to pick up toys. We are going to
    connect this command to the ROS to control the robot. Later on, we will add a
    skill to tell knock-knock jokes.
  prefs: []
  type: TYPE_NORMAL
- en: Designing our dialogs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Our first step is to design our dialog on how we will talk to the robot. Start
    by making a list of what ways you might tell the robot to pick up the toys in
    the playroom. Here is my list, which I generated using ChatGPT (version 3.5):'
  prefs: []
  type: TYPE_NORMAL
- en: Hey robot, could you please start picking up all the toys?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It’s time to tidy up. Can you gather all the toys for me?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Need your help, robot. Could you please pick up all the toys and put them in
    the toy bin?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s clean up together. Begin by collecting all the toys, please.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I need a clean room. Can you please start by picking up the toys scattered around?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dear robot, would you be so kind as to tidy up the room by gathering all the
    toys?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s make this room spotless. Begin with collecting all the toys, please.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It’s clean-up time.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can you pick up all the toys?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pick up all the toys.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You could collect all the toys and place them in the toy box.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It’s time to showcase your cleaning skills. Start by picking up all the toys,
    please.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Could you please make the room tidy by picking up all the toys?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You will note that there are several keywords that are specific to the command
    to clean up the room. We have the word “clean,” of course. We have the phrase
    “pick up,” and “away.” We also have the words “toys” or “toy”, and finally, “mess.”
    These keywords will cue the natural language processor and allow some variation
    in the exact words used.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we write down what we want the robot to say back. We don’t want the same
    canned response each time; it would be good to have some natural variation in
    the robot’s responses. Here is my list of responses, created again by ChatGPT3,
    with a variety of robot attitudes represented:'
  prefs: []
  type: TYPE_NORMAL
- en: Command received – picking up toys.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Of course, I will start cleaning the room right away.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understood, I will tidy up the room and ensure everything is in its proper place.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cleaning mode activated! I will make sure to leave your room spotless and organized.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As you wish, I will take care of cleaning the room for you.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: No problem, I will use my cleaning capabilities to efficiently tidy up the room
    and remove any clutter.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Consider it done! I will sweep, dust, and mop the room to make it pristine for
    you.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cleaning in progress! I will diligently clean up the room and ensure it’s tidy
    and presentable.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I’m on it! I will use my cleaning tools and techniques to make your room look
    spick and span.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Acknowledged, I will clean up the room and ensure it’s organized and ready for
    your use.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cleaning task accepted! I will work diligently to make your room clean and inviting,
    just the way you like it.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can use as many of these as you want. The Mycroft system will grab a random
    phrase from this list. This gives us some room for creativity and gives the illusion
    that the robot is more intelligent than it really is. This type of response system
    enables us to quickly develop our dialogs.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we’ll look at how we can connect voice commands to the
    ROS interface.
  prefs: []
  type: TYPE_NORMAL
- en: Creating skills
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section, we’ll build the framework in Mycroft that allows it to associate
    our spoken phrases with the commands to be sent to the robot. This will involve
    adding each skill that we want the robot to possess.
  prefs: []
  type: TYPE_NORMAL
- en: Cleaning up the toys
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'First, let’s add the most basic skill for Albert – cleaning the room by picking
    up toys. To do this, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Use the `mycroft-msk create` command, which helps us put together our skills
    in the proper format:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Then it will ask for a class name and a repository name, for both of which I
    used `Cleanroomrobot`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Enter a one-line description for your skill: `Pick up all of the toys in` `the
    room`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Enter a long description, such as `Command the robot to detect toys, move to
    grab a toy, pick it up, and put it into` `the toybox`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Enter some example phrases to trigger your skill:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`Hey robot, could you please start picking up all` `the toys?`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`It''s time to tidy up. Can you gather all the toys` `for me?`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Can you pick up all` `the toys?`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Enter the following parameters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`<your` `name here>`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Productivity`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`IoT`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Entering tags makes it easier to search for your skill (although this is optional):
    `robot`, `cleanup`, `pick up`, and `toys`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We will end up with a directory structure in `/opt/Mycroft/skills/cleanroomrobot-skill`
    like the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We are going to import the libraries we need from Mycroft (`IntentBuilder`,
    `MycroftSkill`, `getLogger`, and `intent_handler`). We also import `rclpy`, the
    ROS Python interface, and the ROS standard message `String`, which we use to send
    commands to the robot by publishing on the `syscommand` topic:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: '`MycroftSkill` is a function that is called when one of its phrases is recognized
    by the Mycroft Intent Engine. As such, it has no body or main function, just a
    function definition for the `create_skill` function that instantiates a `MycroftSkill`
    object. The `init` function does most of the work of setting up the various dialogs,
    intent handlers, and vocabulary for the skill. This arrangement works very well
    in our limited environment of giving the robot commands or telling jokes.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The next line is the logger for Mycroft so that we can save our responses.
    Anything we put out to stdout, such as print statements, will end up in the log,
    or on the screen if you are in debug mode:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'class Cleanroomrobot(MycroftSkill):'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'def __init__(self):'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: MycroftSkill.__init__(self)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'def setRobotInterface(self,interfce):'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: self.interface = interfce
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'def initialize(self):'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: pass  # just return for now
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We set up the publisher for our `syscommand` topic in the ROS. This is how
    we send commands to the robot control program via the ROS publish/subscribe system.
    We will be publishing commands only, and the only message format we need is `String`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Our Mycroft skill is created as a child object of the `MycroftSkill` object.
    We rename our skill object class to `CleanRoomSkill`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: According to the template, Mycroft requires both an `init` method and an `initialize`
    method. These commands set up the intent in the Intent Builder part of Mycroft
    and register our handler when any of our phrases are spoken.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Next, we refer to the dialogs we built back in the *Creating skills* section
    with `require("CleanRoomKeyword")`, so be careful that all the spelling is correct:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This next section creates our handler for when the system has recognized one
    of our phrases, and we want to perform the action for this command. This is where
    we kick off the publish command to the robot’s control program via the ROS using
    the `pubMessage` function we defined earlier:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We also need a `stop` function, where we can command the robot to stop cleaning,
    if necessary, to prevent any sort of *Mickey Mouse – Sorcerer’s* *Apprentice*
    accident:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: In the movie *Fantasia*, Mickey Mouse acts out the part of the Sorcerer’s Apprentice
    from a fairy tale. In the story, the Apprentice learns to animate a broom, which
    he teaches to fetch water from a well. The problem is the Apprentice never learned
    how to stop the enchantment, and soon the room is flooded.
  prefs: []
  type: TYPE_NORMAL
- en: 'We now need a block of code to create the skill in the program where we can
    associate the ROS interface to the robot into the skill. We will add a `create_skill`
    function to allow Mycroft to create the skill and to have a function pointer to
    enable the skill:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we have the ROS interface. All we need to do is send a command to the
    robot to publish mode commands on our `RobotCmd` topic:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We define our ROS interface and create a control node called `mycroftROS` to
    serve as our interface. Then we create a subscriber and publisher to the `RobotCmd`
    topic so we can send and receive commands from the ROS 2 interface.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The rest of the program is just housekeeping. We need to start up our ROS node,
    start the Mycroft logger, and instantiate the ROS interface object and the `cleanSkill`
    objects for ROS and Mycroft, respectively. Then we point the `cleanSkill` object
    to the ROS interface so they can communicate. Finally, we start the ROS 2 interface
    with the `.spin` function. When the program is stopped, we fall out of `.spin`
    and shut down our program:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In order for our skill to work, we need to copy our directory to `/opt/mycroft/skills`.
    From there, we can test it in debug mode. Remember that you have to source the
    ROS 2 directory (`source /opt/ros/foxy/local_setup.sh` and `source ~/ros2_ws/install/local_setup.sh`)
    or the program won’t be able to find all of the inclusion files or ROS nodes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Our next skill comes at the request of my grandson, William, who just adores
    knock-knock jokes. William is seven, so he is just the right age for this. Let’s
    look at how we can implement this.
  prefs: []
  type: TYPE_NORMAL
- en: Telling jokes
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In this section, we will handle the case where the robot is telling the knock-knock
    joke. As you probably know, knock-knock jokes are pun-based jokes that always
    take the same form:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Person 1: Knock, knock'
  prefs: []
  type: TYPE_NORMAL
- en: 'Person 2: Who’s there?'
  prefs: []
  type: TYPE_NORMAL
- en: 'Person 1: Wooden'
  prefs: []
  type: TYPE_NORMAL
- en: 'Person 2: Wooden Who?'
  prefs: []
  type: TYPE_NORMAL
- en: 'Person 1: Wooden you like to know!'
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see, the dialog is very simple. Several parts of it are standard,
    such as the first two lines – “Knock, knock” and “Who’s there?” We can create
    a generic knock-knock joke in the following form:'
  prefs: []
  type: TYPE_NORMAL
- en: Knock, knock.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Who’s there?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`<``word 1>`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`<word` `1>` who?'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`<``punchline phrase>`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In defining our joke, you can see we just have two variable elements – the word
    in *Step 3*, and the punchline phrase in *Step 5*. Our word is repeated in *Step
    4*.
  prefs: []
  type: TYPE_NORMAL
- en: 'We begin by creating a joke database of one-line jokes, which we will put in
    a text file. Since we just have two elements, we can separate them with a slash
    (`/)`. Here is an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: I’m providing you with a database of about 10 jokes in the files section of
    the repository for this chapter. Please feel free to add all of your favorites,
    or send them to me and I’ll add them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s look at the steps involved in telling the joke:'
  prefs: []
  type: TYPE_NORMAL
- en: We will start, as with any skill, with the wake word, “Hey, Albert.”
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then we need a phrase to indicate we want to hear a joke, so we will use variations
    of “Tell me a knock-knock joke,” such as “I want to hear a knock-knock joke.”
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This will trigger our skill program to look up a joke. We will create several
    intents, or response capabilities, to respond to the user (or child) talking to
    the robot. We will start with the “Who’s there?” dialog intent. That will let
    the robot know to proceed to the next part of the joke, which is to say our word.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then we disable the “Who’s there?” dialog and enable a dialog for listening
    for `<word>` and the phrase “who.”
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then we can deliver the final part of the joke by reciting the punchline phrase,
    and we are done.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'How can we implement this? You can follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We start by creating our vocabulary files, of which we will need three. These
    are the things that the user will be saying to the robot. We have our first “tell
    me a knock, knock joke” phrase – so let’s create a file called `knockknock.voc`
    (you can use any text editor to create the file) and put the following in it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Please note that the Mycroft STT system interprets the phrase “knock, knock”
    as `knock-knock` with a hyphen, so it is important to put that into our script.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Now our second vocabulary is just “Who’s there,” so we can create this as a
    second `.voc` file, `whosthere.voc`, which contains the line `Whos there`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Our final line is a bit trickier. We really only care about the keyword “who”
    to trigger the punchline, so we can look only for that. Make a file called `who.voc`
    and put the one word `who` in it. Remember these all go in the `dialog/en-us`
    folder in our `skill` directory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now for our responses. We have one canned response, which is to reply to “tell
    me a knock-knock joke” with the phrase “knock, knock.” We don’t need any sophisticated
    dialog system, we just have the robot say the “knock, knock” phrase. To do this,
    we first import the libraries we need to call in this program, which are the `MycroftSkill`
    class and the `intent_file_handler` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We define our skill as a child object of the `MycroftSkill` object – this is
    a standard object-oriented design. We are inheriting all of the functions and
    data of the `MycroftSkill` parent object and adding our own functionality to it.
    We create an initialize function and then call the `init` parent function to execute
    the code of the parent class as well. We are augmenting the functionality of the
    `init` parent function. Without this call, we would be replacing the `init` function
    with our own, and might have to duplicate a considerable amount of work:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The next step is to create our `knockknock.intent` file and place that file
    in the `voc` directory (which was `dialog/voc-en`):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here, we get two parts from the joke database:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The name to say after “who’s there”
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The punchline that ends the joke
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We use the `get_response` function from `MycroftSkill` to have the robot make
    a statement and then wait for a reply, which will get turned into a text string
    and stored in the `response` variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now we are at the part where the robot says the name in response. For example,
    the user asks “who’s there?” and the robot replies “Harold.” What we are expecting
    next is for the user to say “Harold (or whatever name) who?” We will check our
    response, and see whether the word “who” is included. If it is not, we can prompt
    the user to follow along with the joke. We will only do this one time to keep
    from getting stuck in a loop. If they are not playing along, the robot will just
    continue:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We have moved through the joke, so now we get to say the punchline, such as
    “Harold you like a hug?” (How would you like a hug?). The task is complete and
    we exit the routine; both the comedy routine and the program routine:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We need a function to read the joke database we defined earlier. As described
    earlier, the database has one knock-knock joke per line, with a forward slash
    (`/`) between the name and the punchline. We read all of the jokes, put them in
    a list, and then choose one at random using the (wait for it) `random.choice`
    function. We return the name and the punchline separately. We should only call
    this routine once per instance of the joke:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We finish the program by defining our instance of the `Knockknock` class and
    returning that object to the calling program, Mycroft:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Next, we’ll discuss the other end of the knock-knock joke concept, which is
    to receive a joke – where the child wants to tell the robot a joke. If you know
    any seven-year-olds, then you know that this is a requirement also – the child
    will want to tell the robot a joke as well.
  prefs: []
  type: TYPE_NORMAL
- en: Receiving jokes
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The receiving dialog is pretty simple as well. The user will say “knock, knock”,
    which is the cue to the robot to go into the *receive knock-knock joke* mode.
    The robot then has only one response – “who’s there.” We could also add “who is
    there?” if we want to keep to the common sci-fi concept that robots do not use
    contractions.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'Data, the android from *Star Trek: The Next Generation*, stated many times
    he was not able to use contractions, although the writers slipped up from time
    to time.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to create our schema for our new Mycroft skill, we will be using the
    `pip3 install msk`. MSK provides a dialog-driven approach to building skills that
    will make a framework, including all of the subdirectories for dialog files and
    vocabulary. This saves a lot of time, so let’s try it out:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the command for creating the *receive knock-knock* *joke*
    code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We start with our imports, which are `MycroftSkill` and `intent_file_handler`.
    We will also need the `time` library to do some pauses:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here is our class definition for our `ReceiveKnock` class, which is a child
    class of the `MycroftSkill` object we imported. We start the `init` function by
    passing an `init` command back up to the parent class (`MycroftSkill`) and have
    it do its initialization. Then we add our custom functionality on top of that:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The next section is our intent handler for receiving a knock-knock joke. We
    use the `@decorator` to extend the intent handler, in this case, reading the parameters
    of the intent from a file called `knock.receive.intent`. The intent handler just
    has our two key words, the immortal phrase: `knock, knock`. We are fortunate that
    all jokes start exactly the same way, so we only have these two words.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'After the `handle_knock_receive` function has been activated by the Intent
    Engine seeing the phrase “knock, knock,” we then get control passed to our handler.
    What is our next step? We reply with the single answer “Who is there?” You will
    remember we said robots do not use contractions. We use a different function to
    do this. We don’t want to use another intent handler, but fortunately, Mycroft
    provides a free-form interface called `get_response`. You need to look up the
    documentation for this versatile function, but it makes our joke routine a lot
    simpler. The `get_response` function both lets us speak our reply and then receive
    whatever the user says next and store it as a string in the `response` variable:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now that we have our response, we can just repeat it back with the robot’s voice,
    with the additional word “who?” So, if the child says, “Howard,” the robot responds
    “Howard who?”
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We use `get_response` again to have the robot speak and then record whatever
    the child or adult says next. We don’t need it, but we want to have the robot’s
    speech system listen to whatever is said next. We toss away the response, but
    insert our own comment to the joke from our dialog `veryfunny.dialog`, which is
    a file in the `dialog` directory. I created this file to hold responses to our
    jokes from the robot. I tried to make some responses that the grandchildren would
    find funny – I guess I can add “robot joke writer” to my resume, as I seem to
    have done this a lot in my career. After this, I added a sleep timer to allow
    everything to settle down before returning control. We include the standard `stop`
    function required of all `MycroftSkills`, and make our `create_skill` function
    make a `ReceiveCall` object and return it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You can get as creative as you want with the responses, but here are my suggestions:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: That was very funny!
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Ha ha ha.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Very good joke.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: I like that one. Thank you!
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Ho HO! Ho.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: That was cute!
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: I do not have a sound for a groan thththththpppppp!
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here is our directory structure and files for our receive knock-knock jokes
    skill:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Remember the local version of the skill goes in the `/opt/mycroft/skills/receive-knock-skill`
    directory. Now test to your heart’s content – how many knock-knock jokes can you
    tell the robot?
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This chapter introduced NLP for robotics and concentrated on developing a natural
    language interface for the robot that accomplished three tasks: starting the *pick
    up toys* process, telling knock-knock jokes, and listening to knock-knock jokes.'
  prefs: []
  type: TYPE_NORMAL
- en: The concepts introduced included recognizing words by phonemes, turning phonemes
    into graphemes and graphemes into words, parsing intent from sentences, and executing
    computer programs with a voice interface. We introduced the open source AI engine,
    Mycroft, which is an AI-based voice assistant program that runs on the Jetson
    Nano. We also wrote a joke database to entertain small children with some very
    simple dialog.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we’ll be learning about **robot navigation** using landmarks,
    neural networks, obstacle avoidance, and machine learning.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Do some internet research on why the AI engine was named Mycroft. How many different
    stories did you find, and which one did you like?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the discussion of intent, how would you design a neural network to predict
    command intent from natural language sentences?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Rewrite “Receive knock-knock jokes” to remember the jokes told to the robot
    by adding them to the joke database used by the “tell knock knock jokes” program.
    Is this machine learning?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Modify the “tell jokes” program to play sounds from a wave file, such as a music
    clip, as well as doing TTS.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The sentence structures used in this chapter are all based on English grammar.
    Other languages, such as French and Japanese, have different structures. How does
    that change the parsing of sentences? Would the program we wrote be able to understand
    Yoda?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Do you think that Mycroft’s Intent Engine is actually understanding intent,
    or just pulling out keywords?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Describe the voice commands necessary to instruct the robot to drive to an object
    and pick it up without the robot being able to recognize the object. How many
    commands do you need?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: From *Question 7*, work to minimize the number of commands. How many can you
    eliminate or combine?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Also from *Question 7*, how many unique keywords are involved? How many non-unique
    keywords?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Python Natural Language Processing* by Jalaj Thanaki, Packt Publishing'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Artificial Intelligence with Python* by Prateek Joshi, Packt Publishing'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mycroft tutorial for developing skills is located at [https://mycroft.gitbook.io/mycroft-docs/developing_a_skill/introduction-developing-skills](https://mycroft.gitbook.io/mycroft-docs/developing_a_skill/introduction-developing-skills)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Additional documentation for using Mycroft is located at [https://media.readthedocs.org/pdf/mycroft-core/stable/mycroft-core.pdf](https://media.readthedocs.org/pdf/mycroft-core/stable/mycroft-core.pdf)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Part 3: Advanced Concepts – Navigation, Manipulation, Emotions, and More'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the last part of the book, we tackle more advanced topics including AI-based
    navigation and obstacle avoidance. We learn about decision trees and classification
    algorithms for unsupervised learning and then start an exciting chapter on creating
    a simulation of a robot personality. While we can’t give a robot real emotions,
    we can create a simulation of emotion using state machines and Monte Carlo techniques.
    Finally, we end the book with a discussion of AI philosophy and a look at the
    future from the author’s perspective, and provide advice for people wanting to
    pursue robotics and autonomy as a career.
  prefs: []
  type: TYPE_NORMAL
- en: 'This part has the following chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 7*](B19846_07.xhtml#_idTextAnchor221), *Teaching the Robot to Navigate
    and Avoid Stairs*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 8*](B19846_08.xhtml#_idTextAnchor235), *Putting Things Away*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 9*](B19846_09.xhtml#_idTextAnchor294), *Giving the Robot an Artificial
    Personality*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 10*](B19846_10.xhtml#_idTextAnchor366), *Conclusions and Reflections*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
