<html><head></head><body>
		<div id="_idContainer019">
			<h1 id="_idParaDest-28" class="chapter-number"><a id="_idTextAnchor037"/>2</h1>
			<h1 id="_idParaDest-29"><a id="_idTextAnchor038"/>Setting Up the Environment for Stable Diffusion</h1>
			<p>Welcome to <a href="B21263_02.xhtml#_idTextAnchor037"><span class="No-Break"><em class="italic">Chapter 2</em></span></a>. In this chapter, we will be focusing on setting up the environment to run Stable Diffusion. We will cover all the necessary steps and aspects to ensure a seamless experience while working with Stable Diffusion models. Our primary goal is to help you understand the importance of each component and how they contribute to the <span class="No-Break">overall process.</span></p>
			<p>The contents of this chapter are <span class="No-Break">as follows:</span></p>
			<ul>
				<li>Introduction to the hardware requirements to run <span class="No-Break">Stable Diffusion</span></li>
				<li>Detailed steps to install the required software dependencies: CUDA from NVIDIA, Python, a Python virtual environment (optional but recommended), <span class="No-Break">and PyTorch</span></li>
				<li>Alternative options for users without a GPU, such as Google Colab and Apple MacBook with silicon CPU (<span class="No-Break">M series)</span></li>
				<li>Troubleshooting common issues during the <span class="No-Break">setup process</span></li>
				<li>Tips and best practices for maintaining a <span class="No-Break">stable environment</span></li>
			</ul>
			<p>We will begin by providing an overview of Stable Diffusion, its significance, and its applications in various fields. This will help you gain a better understanding of the core concept and <span class="No-Break">its importance.</span></p>
			<p>Next, we will dive into the step-by-step installation process for each dependency, including CUDA, Python, and PyTorch. We will also discuss the benefits of using a Python virtual environment and guide you through setting <span class="No-Break">one up.</span></p>
			<p>For those who do not have access to a machine with a GPU, we will explore alternative options such as Google Colab. We will provide a comprehensive guide to using these services and discuss the trade-offs associated <span class="No-Break">with them.</span></p>
			<p>Finally, we will address common issues that may arise during the setup process and provide troubleshooting tips. Additionally, we will share best practices for maintaining a stable environment to ensure a smooth experience while working with Stable <span class="No-Break">Diffusion models.</span></p>
			<p>By the end of this chapter, you will have a solid foundation for setting up and maintaining an environment tailored for Stable Diffusion, allowing you to focus on building and experimenting with your <span class="No-Break">models efficiently.</span></p>
			<h1 id="_idParaDest-30"><a id="_idTextAnchor039"/>Hardware requirements to run Stable Diffusion</h1>
			<p>This section will discuss the hardware requirements of running a Stable Diffusion model. This book will cover <strong class="bold"><a id="_idIndexMarker034"/></strong><strong class="bold">Stable Diffusion v1.5</strong> and the <strong class="bold">Stable Diffusion XL</strong> (<strong class="bold">SDXL</strong>) version. These two are also the most used models at the time of writing <span class="No-Break">this book.</span></p>
			<p>Stable Diffusion v1.5, released in October 2022, is<a id="_idIndexMarker035"/> considered a general-purpose model, and can be <a id="_idIndexMarker036"/>used interchangeably with v1.4. On the other hand, SDXL, which was released in July 2023, is known for its ability to handle higher resolutions more effectively compared to Stable Diffusion v1.5. It can generate images with larger dimensions without compromising <span class="No-Break">on quality.</span></p>
			<p>Essentially, Stable Diffusion is a set of models that includes <span class="No-Break">the following:</span></p>
			<ul>
				<li><strong class="bold">Tokenizer</strong>: This <a id="_idIndexMarker037"/>tokenizes a text prompt into a <a id="_idIndexMarker038"/>sequence <span class="No-Break">of tokens.</span></li>
				<li><strong class="bold">Text Encoder</strong>: The Stable <a id="_idIndexMarker039"/>Diffusion text encoder<a id="_idIndexMarker040"/> is a special Transformer language model – specifically, the text encoder of a CLIP model. In SDXL, a larger-size OpenCLIP [6] text encoder is also used to encode the tokens into <span class="No-Break">text embeddings.</span></li>
				<li><strong class="bold">Variational Autoencoder</strong> (<strong class="bold">VAE</strong>): This <a id="_idIndexMarker041"/>encodes images into a latent space and decodes <a id="_idIndexMarker042"/>them back <span class="No-Break">into images.</span></li>
				<li><strong class="bold">UNet</strong>: This <a id="_idIndexMarker043"/>is where the denoising process happens. The UNet<a id="_idIndexMarker044"/> structure is employed to comprehend the steps involved in the noising/denoising cycle. It accepts certain elements such as noise, time step data, and a conditioning signal (for instance, a representation of a text description), and forecasts noise residuals that can be utilized in the <span class="No-Break">denoising process.</span></li>
			</ul>
			<p>The components of Stable Diffusion provide neural network weight data, except for the tokenizer. While the CPU can handle the training and inference in theory, a physical machine with a GPU or parallel computing device can provide the best experience to learn and run Stable <span class="No-Break">Diffusi<a id="_idTextAnchor040"/>on models.</span></p>
			<h2 id="_idParaDest-31"><a id="_idTextAnchor041"/>GPU</h2>
			<p>In theory, Stable <a id="_idIndexMarker045"/>Diffusion models can run on both GPU and CPU. In reality, PyTorch-based models work best on an NVIDIA GPU <span class="No-Break">with CUDA.</span></p>
			<p>Stable Diffusion requires a GPU with at least 4 GB VRAM. From my own experience, a GPU with 4 GB VRAM can only enable you to generate 512x512 images but it may take a long time to generate them. A GPU with at least 8 GB VRAM grants a relatively pleasant learning and usage experience. The larger the VRAM size, <span class="No-Break">the better.</span></p>
			<p>The code of this book is tested on NVIDIA RTX 3070Ti with 8 GB VRAM and RTX 3090 with <a id="_idTextAnchor042"/>24 <span class="No-Break">GB VRAM.</span></p>
			<h2 id="_idParaDest-32"><a id="_idTextAnchor043"/>System memory</h2>
			<p>There will <a id="_idIndexMarker046"/>be a lot of data transferred between GPU and CPU, and some Stable Diffusion models will easily take up to 6 GB RAM. Please prepare at least 16 GB of system RAM; 32 GB RAM will be good – the more, the better, especially for <span class="No-Break">mult<a id="_idTextAnchor044"/>iple models.</span></p>
			<h2 id="_idParaDest-33"><a id="_idTextAnchor045"/>Storage</h2>
			<p>Do prepare <a id="_idIndexMarker047"/>a large drive. By default, the Hugging Face package will download model data to a cache folder located in the system drive. If you only have 256 GB or 512 GB storage, you will find it quickly running out. Preparing a 1 TB NVME SSD is recommended, although 2 TB or more will be<a id="_idTextAnchor046"/> <span class="No-Break">even better.</span></p>
			<h1 id="_idParaDest-34"><a id="_idTextAnchor047"/>Software requirements</h1>
			<p>Now <a id="_idIndexMarker048"/>we have the hardware prepared, Stable Diffusion requires additional software to support its execution and provide better control using Python. This section will provide you with the steps to prepare the <span class="No-Break">softwar<a id="_idTextAnchor048"/>e environment.</span></p>
			<h2 id="_idParaDest-35"><a id="_idTextAnchor049"/>CUDA installation</h2>
			<p>If you are using <a id="_idIndexMarker049"/>Microsoft Windows, please install Microsoft <strong class="bold">Visual Studio</strong> (<strong class="bold">VS</strong>) [5] first. VS will install all other dependent packages and binary files for <a id="_idIndexMarker050"/>CUDA. You can <a id="_idIndexMarker051"/>simply choose the latest Community version of VS <span class="No-Break">for free.</span></p>
			<p>Now, go to the NVIDIA CUDA download page [1] to get the CUDA installation file. The following screenshot shows an example of selecting CUDA for <span class="No-Break">Windows 11:</span></p>
			<div>
				<div id="_idContainer014" class="IMG---Figure">
					<img src="image/B21263_02_01.jpg" alt="Figure 2.1: Selecting the CUDA installation download file for Windows"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.1: Selecting the CUDA installation download file for Windows</p>
			<p>Download the <a id="_idIndexMarker052"/>CUDA installation file, then double-click this file to install CUDA like any other <span class="No-Break">Windows application.</span></p>
			<p>If you are <a id="_idIndexMarker053"/>using a Linux operating system, installing CUDA for Linux is slightly different. You can execute the Bash script provided by NVIDIA to automate the installation. Here are the <span class="No-Break">detailed steps:</span></p>
			<ol>
				<li>It is better to uninstall all NVIDIA drivers first to ensure minimum errors, so if you have NVIDIA’s driver already installed, use the following command to <span class="No-Break">uninstall it:</span><pre class="source-code">
sudo apt-get purge nvidia*</pre><pre class="source-code">
sudo apt-get autoremove</pre><p class="list-inset">Then, reboot <span class="No-Break">your system:</span></p><pre class="source-code">
sudo reboot</pre></li>
				<li>Install GCC. <strong class="bold">GNU Compiler Collection</strong> (<strong class="bold">GCC</strong>) is a set of compilers for various programming <a id="_idIndexMarker054"/>languages such as C, C++, Objective-C, Fortran, Ada, and others. It is an open source project developed by the <a id="_idIndexMarker055"/>GNU Project and is widely used for compiling and building software on Unix-like operating systems, including Linux. Without GCC being installed, we will get errors during the CUDA installation. Install it with the <span class="No-Break">following command:</span><pre class="source-code">
sudo apt install gcc</pre></li>
				<li>Select the right CUDA version for your system on the CUDA download page [2]. The following screenshot shows an example of selecting CUDA for <span class="No-Break">Ubuntu 22.04:</span></li>
			</ol>
			<div>
				<div id="_idContainer015" class="IMG---Figure">
					<img src="image/B21263_02_02.jpg" alt="Figure 2.2: Selecting the CUDA installation download file for Linux"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.2: Selecting the CUDA installation download file for Linux</p>
			<p class="list-inset">After your selection, the page will show you the command scripts that handle the entire installation process. Here is <span class="No-Break">one example:</span></p>
			<pre class="source-code">
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-ubuntu2204.pin
sudo mv cuda-ubuntu2204.pin /etc/apt/preferences.d/cuda-repository-pin-600
wget https://developer.download.nvidia.com/compute/cuda/12.1.1/local_installers/cuda-repo-ubuntu2204-12-1-local_12.1.1-530.30.02-1_amd64.deb
sudo dpkg <strong class="bold">-i</strong> cuda-repo-ubuntu2204-12-1-local_12.1.1-530.30.02-1_amd64.deb
sudo cp /var/cuda-repo-ubuntu2204-12-1-local/cuda-*-keyring.gpg /usr/share/keyrings/
sudo apt-get update
sudo apt-get <strong class="bold">-y</strong> install cuda</pre>
			<p class="callout-heading">Note</p>
			<p class="callout">The script may have been updated by the time you read this book. To avoid errors and potential installation failures, I would suggest opening the page and using the script that refle<a id="_idTextAnchor050"/>cts <span class="No-Break">your selection.</span></p>
			<h2 id="_idParaDest-36"><a id="_idTextAnchor051"/>Installing Python for Windows, Linux, and macOS</h2>
			<p>We will first install Python <span class="No-Break">for Windows.</span></p>
			<h3>Installing Python for Windows</h3>
			<p>You <a id="_idIndexMarker056"/>can visit <a href="https://www.python.org/">https://www.python.org/</a> and download<a id="_idIndexMarker057"/> Python 3.9 or Python 3.10 to <span class="No-Break">install it.</span></p>
			<p>After years <a id="_idIndexMarker058"/>of manually downloading and clicking through the installation process, I found that using a package manager is quite useful to automate the installation. With a package manager, you write a script once, save it, and then the next time you need to install the software, all you have to do is run the same script in a terminal window. One of the best package managers for Windows is <a id="_idIndexMarker059"/><span class="No-Break">Chocolatey (</span><a href="https://chocolatey.org/"><span class="No-Break">https://chocolatey.org/</span></a><span class="No-Break">).</span></p>
			<p>Once you have Chocolatey installed, use the following command to install <span class="No-Break">Python 3.10.6:</span></p>
			<pre class="console">
choco install python --version=3.10.6</pre>
			<p>Create a <a id="_idIndexMarker060"/>Python <span class="No-Break">virtual environment:</span></p>
			<pre class="console">
pip install --upgrade --user pip
pip install virtualenv
python -m virtualenv venv_win_p310
venv_win_p310\Scripts\activate
python -m ensurepip
python -m pip install --upgrade pip</pre>
			<p>We <a id="_idIndexMarker061"/>will move on to the steps to install Python <span class="No-Break">for Linux.</span></p>
			<h3>Installing Python for Linux</h3>
			<p>Let’s <a id="_idIndexMarker062"/>now install <a id="_idIndexMarker063"/>Python for Linux (Ubuntu). Follow <span class="No-Break">these steps:</span></p>
			<ol>
				<li>Install the <span class="No-Break">required packages:</span><pre class="source-code">
sudo apt-get install software-properties-common</pre><pre class="source-code">
sudo add-apt-repository ppa:deadsnakes/ppa</pre><pre class="source-code">
sudo apt-get update</pre><pre class="source-code">
sudo apt-get install python3.10</pre><pre class="source-code">
sudo apt-get install python3.10-dev</pre><pre class="source-code">
sudo apt-get install python3.10-distutils</pre></li>
				<li><span class="No-Break">Install </span><span class="No-Break"><strong class="source-inline">pip</strong></span><span class="No-Break">:</span><pre class="source-code">
curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py</pre><pre class="source-code">
python3.10 get-pip.py</pre></li>
				<li>Create<a id="_idIndexMarker064"/> a Python<a id="_idIndexMarker065"/> <span class="No-Break">virtual environment:</span><pre class="source-code">
python3.10 -m pip install --user virtualenv</pre><pre class="source-code">
python3.10 -m virtualenv venv_ubuntu_p310</pre><pre class="source-code">
. venv_ubuntu_p310/bin/activate</pre></li>
			</ol>
			<h3>Installing Python for macOS</h3>
			<p>If you <a id="_idIndexMarker066"/>are using <a id="_idIndexMarker067"/>a Mac with the silicon chip inside (with Apple Mx CPU), there is a high chance you have Python installed already. You can test whether you have Python installed on your Mac with the <span class="No-Break">following command:</span></p>
			<pre class="source-code">
python3 <strong class="bold">--version</strong></pre>
			<p>If your machine doesn’t have a Python interpreter yet, you can install it with one simple command using Homebrew [7] <span class="No-Break">like this:</span></p>
			<pre class="console">
brew install python</pre>
			<p>Keep in mind that Python versions are regularly updated, usually on an annual basis. You can change the version number to install a specific Python version. For example, you can c<a id="_idTextAnchor052"/>hange <strong class="source-inline">python3.10</strong> <span class="No-Break">to </span><span class="No-Break"><strong class="source-inline">python3.11</strong></span><span class="No-Break">.</span></p>
			<h2 id="_idParaDest-37"><a id="_idTextAnchor053"/>Installing PyTorch</h2>
			<p>The Hugging <a id="_idIndexMarker068"/>Face Diffusers package relies on the PyTorch package, so we <a id="_idIndexMarker069"/>will need to have the PyTorch package installed. Go to the<a id="_idIndexMarker070"/> PyTorch <strong class="bold">Get Started</strong> page (<a href="https://pytorch.org/get-started/locally/">https://pytorch.org/get-started/locally/</a>) and select the appropriate PyTorch version for your system. The following is a screenshot of PyTorch <span class="No-Break">for Windows:</span></p>
			<div>
				<div id="_idContainer016" class="IMG---Figure">
					<img src="image/B21263_02_03.jpg" alt="Figure 2.3: Installing PyTorch"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.3: Installing PyTorch</p>
			<p>Next, use the dynamically generated command to <span class="No-Break">install PyTorch:</span></p>
			<pre class="console">
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117</pre>
			<p>In addition to CUDA 11.7, there is also CUDA 11.8. The choice of version will depend on the CUDA version installed on <span class="No-Break">your machine.</span></p>
			<p>You can <a id="_idIndexMarker071"/>use the following command to find out your <span class="No-Break">CUDA version:</span></p>
			<pre class="console">
nvcc --version</pre>
			<p>You can <a id="_idIndexMarker072"/>also use <span class="No-Break">this command:</span></p>
			<pre class="console">
nvidia-smi</pre>
			<p>Your machine’s CUDA version may be higher than the listed versions of 11.7 or 11.8, such as 12.1. Often, a specific version is required by a certain model or package. For Stable Diffusion, just install the <span class="No-Break">newest version.</span></p>
			<p>If you are using a Mac, select the <strong class="bold">Mac</strong> option to install PyTorch <span class="No-Break">for macOS.</span></p>
			<p>If you are using a Python virtual environment, make sure to install PyTorch within the activated virtual environment. Otherwise, you may encounter issues where PyTorch is not installed correctly if you accidentally install it outside the virtual environment and then run your Python c<a id="_idTextAnchor054"/>ode within the <span class="No-Break">virtual environment.</span></p>
			<h1 id="_idParaDest-38"><a id="_idTextAnchor055"/>Running a Stable Diffusion pipeline</h1>
			<p>Now that you have installed all the dependencies, it is time to run a Stable Diffusion pipeline to <a id="_idIndexMarker073"/>test whether the environment is correctly set up. You can use any Python editing tool, such as VS Code or Jupyter Notebook, to edit and execute Python code. Follow <span class="No-Break">these steps:</span></p>
			<ol>
				<li>Install the packages for Hugging <span class="No-Break">Face Diffusers:</span><pre class="source-code">
pip install diffusers</pre><pre class="source-code">
pip install transformers scipy ftfy accelerate</pre></li>
				<li>Start a Stable <span class="No-Break">Diffusion pipeline:</span><pre class="source-code">
import torch</pre><pre class="source-code">
from diffusers import StableDiffusionPipeline</pre><pre class="source-code">
pipe = StableDiffusionPipeline.from_pretrained(</pre><pre class="source-code">
    "runwayml/stable-diffusion-v1-5",</pre><pre class="source-code">
    torch_dtype=torch.float16)</pre><pre class="source-code">
pipe.to("cuda") # mps for mac</pre><p class="list-inset">If you are using a Mac, change <strong class="source-inline">cuda</strong> to <strong class="source-inline">mps</strong>. Even though macOS is supported and can generate images using the Diffusers package, its performance is relatively slow. As a comparison, an NVIDIA RTX 3090 can achieve about 20 iterations per second to generate one 512x512 image using Stable Diffusion V1.5, whereas an M3 Max CPU can only reach around 5 iterations per second with the <span class="No-Break">default settings.</span></p></li>
				<li>Generate <span class="No-Break">an image:</span><pre class="source-code">
prompt = "a photo of an astronaut riding a horse on mars,blazing fast, wind and sand moving back"</pre><pre class="source-code">
image = pipe(</pre><pre class="source-code">
    prompt, num_inference_steps=30</pre><pre class="source-code">
).images[0]</pre><pre class="source-code">
image</pre></li>
			</ol>
			<p>If you see <a id="_idIndexMarker074"/>an image of an astronaut riding a horse, you have all the environments set u<a id="_idTextAnchor056"/>p correctly in your <span class="No-Break">physical machine.</span></p>
			<h1 id="_idParaDest-39"><a id="_idTextAnchor057"/>Using Google Colaboratory</h1>
			<p><strong class="bold">Google Colaboratory</strong> (or <strong class="bold">Google Colab</strong>) is an online computing service provided by Google. In <a id="_idIndexMarker075"/>essence, Google Colab is an online Jupyter notebook with <span class="No-Break">GPU/CUDA capability.</span></p>
			<p>Its free <a id="_idIndexMarker076"/>notebook can provide CUDA computing with 15 GB VRAM equivalent to an NVIDIA RTX 3050 or RTX 3060. The performance is decent if you don’t have a discrete GPU <span class="No-Break">at hand.</span></p>
			<p>Let’s look at the advantages and disadvantages of using <span class="No-Break">Google Colab:</span></p>
			<ul>
				<li><span class="No-Break"><strong class="bold">Advantages</strong></span><span class="No-Break">:</span><ul><li>No <a id="_idIndexMarker077"/>need to manually install CUDA <span class="No-Break">and Python</span></li><li>Everything is online; you can save a link and reopen <span class="No-Break">it anywhere</span></li><li>The installation of <strong class="source-inline">pip</strong> and downloading of resources <span class="No-Break">are fast</span></li></ul></li>
				<li><span class="No-Break"><strong class="bold">Disadvantages</strong></span><span class="No-Break">:</span><ul><li>There <a id="_idIndexMarker078"/>is a disk limitation for <span class="No-Break">each notebook</span></li><li>You don't have full control of the backend server; terminal access requires a Colab <span class="No-Break">Pro subscription</span></li><li>The performance is not guaranteed so you may experience slow GPU inference during peak time and could be disconnected for <span class="No-Break">long-time computing</span></li><li>The Colab <a id="_idIndexMarker079"/>notebook compute environment will be reset every time you restart the notebook; in other words, you will need to reinstall all the packages and download the mod<a id="_idTextAnchor058"/>el files every time you start <span class="No-Break">the notebook</span></li></ul></li>
			</ul>
			<h1 id="_idParaDest-40"><a id="_idTextAnchor059"/>Using Google Colab to run a Stable Diffusion pipeline</h1>
			<p>Here <a id="_idIndexMarker080"/>are the detailed steps to start using <span class="No-Break">Google Colab:</span></p>
			<ol>
				<li>Create <a id="_idIndexMarker081"/>a new instance <span class="No-Break">from </span><a href="https://colab.research.google.com/"><span class="No-Break">https://colab.research.google.com/</span></a><span class="No-Break">.</span></li>
				<li>Click <strong class="bold">Runtime</strong> | <strong class="bold">Change runtime type</strong> and select <strong class="bold">T4 GPU</strong>, as shown in <span class="No-Break"><em class="italic">Figure 2</em></span><span class="No-Break"><em class="italic">.4</em></span><span class="No-Break">:</span></li>
			</ol>
			<div>
				<div id="_idContainer017" class="IMG---Figure">
					<img src="image/B21263_02_04.jpg" alt="Figure 2.4: Selecting GPU in the Google Colab notebook"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.4: Selecting GPU in the Google Colab notebook</p>
			<ol>
				<li value="3">Create a new cell and use the following command to check whether the GPU and CUDA <span class="No-Break">are working:</span><pre class="source-code">
!nvidia-smi</pre></li>
				<li>Install the packages for Hugging <span class="No-Break">Face Diffusers:</span><pre class="source-code">
!pip install diffusers</pre><pre class="source-code">
!pip install transformers scipy ftfy accelerate ipywidgets</pre></li>
				<li>Start <a id="_idIndexMarker082"/>a Stable <span class="No-Break">Diffusion pipeline:</span><pre class="source-code">
import torch</pre><pre class="source-code">
from diffusers import StableDiffusionPipeline</pre><pre class="source-code">
pipe = StableDiffusionPipeline.from_pretrained(</pre><pre class="source-code">
    "runwayml/stable-diffusion-v1-5",</pre><pre class="source-code">
     torch_dtype=torch.float16)</pre><pre class="source-code">
pipe.to("cuda")</pre></li>
				<li>Generate <a id="_idIndexMarker083"/><span class="No-Break">an image:</span><pre class="source-code">
prompt = "a photo of an astronaut riding a horse on mars,blazing fast, wind and sand moving back"</pre><pre class="source-code">
image = pipe(</pre><pre class="source-code">
    prompt, num_inference_steps=30</pre><pre class="source-code">
).images[0]</pre><pre class="source-code">
image</pre></li>
			</ol>
			<p>In a few seconds, you should be able to see the result as shown in <span class="No-Break"><em class="italic">Figure 2</em></span><span class="No-Break"><em class="italic">.5</em></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer018" class="IMG---Figure">
					<img src="image/B21263_02_05.jpg" alt="Figure 2.5: Running a Stable Diffusion pipeline in Google Colab"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.5: Running a Stable Diffusion pipeline in Google Colab</p>
			<p>If <a id="_idIndexMarker084"/>you see an <a id="_idIndexMarker085"/>image generated as in <span class="No-Break"><em class="italic">Figure 2</em></span><em class="italic">.5</em>, you have successfully set up the Diffusers package to r<a id="_idTextAnchor060"/>un the Stable Diffusion model in <span class="No-Break">Google Colab.</span></p>
			<h1 id="_idParaDest-41"><a id="_idTextAnchor061"/>Summary</h1>
			<p>Some say that the most challenging part of starting to train a machine learning model is not the math or its internal logic. Often, the biggest hurdle is setting up a proper working environment to run the model. It's not uncommon to see engineers and professors spend an entire weekend trying to install CUDA on their lab machines. This can be due to missing dependencies, skipped steps, or <span class="No-Break">version incompatibilities.</span></p>
			<p>I dedicated an entire chapter to covering the installation process, hoping that these detailed steps would help you avoid common pitfalls. By following these steps, you’ll be able to delve into the Stable Diffusion model and start image generation with <span class="No-Break">minimum obstacles.</span></p>
			<p>Furthermore, the software and packages you installed will also work for Transformer-based large <span class="No-Break">language models.</span></p>
			<p>In the next chapter, we will st<a id="_idTextAnchor062"/>art using Stable Diffusion to <span class="No-Break">generate images.</span></p>
			<h1 id="_idParaDest-42"><a id="_idTextAnchor063"/>References</h1>
			<ol>
				<li><em class="italic">CUDA Installation Guide for Microsoft </em><span class="No-Break"><em class="italic">Windows</em></span><span class="No-Break">: </span><a href="https://docs.nvidia.com/cuda/cuda-installation-guide-microsoft-windows/index.html"><span class="No-Break">https://docs.nvidia.com/cuda/cuda-installation-guide-microsoft-windows/index.html</span></a></li>
				<li><em class="italic">NVIDIA CUDA </em><span class="No-Break"><em class="italic">Downloads</em></span><span class="No-Break">: </span><a href="https://developer.nvidia.com/cuda-downloads"><span class="No-Break">https://developer.nvidia.com/cuda-downloads</span></a></li>
				<li><em class="italic">Google </em><span class="No-Break"><em class="italic">Colab</em></span><span class="No-Break">: </span><a href="https://colab.research.google.com/"><span class="No-Break">https://colab.research.google.com/</span></a></li>
				<li><em class="italic">Hugging Face Diffusers </em><span class="No-Break"><em class="italic">Installation</em></span><span class="No-Break">: </span><a href="https://huggingface.co/docs/diffusers/installation"><span class="No-Break">https://huggingface.co/docs/diffusers/installation</span></a></li>
				<li><em class="italic">Visual Studio Community </em><span class="No-Break"><em class="italic">Download</em></span><span class="No-Break">: </span><a href="https://visualstudio.microsoft.com/vs/community/"><span class="No-Break">https://visualstudio.microsoft.com/vs/community/</span></a></li>
				<li><em class="italic">OpenCLIP GitHub </em><span class="No-Break"><em class="italic">repository</em></span><span class="No-Break">: </span><a href="https://github.com/mlfoundations/open_clip"><span class="No-Break">https://github.com/mlfoundations/open_clip</span></a></li>
				<li><span class="No-Break"><em class="italic">Homebrew</em></span><span class="No-Break">: </span><a href="https://brew.sh/"><span class="No-Break">https://brew.sh/</span></a></li>
			</ol>
		</div>
	</body></html>