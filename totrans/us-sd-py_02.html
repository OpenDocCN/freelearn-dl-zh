<html><head></head><body>
		<div><h1 id="_idParaDest-28" class="chapter-number"><a id="_idTextAnchor037"/>2</h1>
			<h1 id="_idParaDest-29"><a id="_idTextAnchor038"/>Setting Up the Environment for Stable Diffusion</h1>
			<p>Welcome to <a href="B21263_02.xhtml#_idTextAnchor037"><em class="italic">Chapter 2</em></a>. In this chapter, we will be focusing on setting up the environment to run Stable Diffusion. We will cover all the necessary steps and aspects to ensure a seamless experience while working with Stable Diffusion models. Our primary goal is to help you understand the importance of each component and how they contribute to the overall process.</p>
			<p>The contents of this chapter are as follows:</p>
			<ul>
				<li>Introduction to the hardware requirements to run Stable Diffusion</li>
				<li>Detailed steps to install the required software dependencies: CUDA from NVIDIA, Python, a Python virtual environment (optional but recommended), and PyTorch</li>
				<li>Alternative options for users without a GPU, such as Google Colab and Apple MacBook with silicon CPU (M series)</li>
				<li>Troubleshooting common issues during the setup process</li>
				<li>Tips and best practices for maintaining a stable environment</li>
			</ul>
			<p>We will begin by providing an overview of Stable Diffusion, its significance, and its applications in various fields. This will help you gain a better understanding of the core concept and its importance.</p>
			<p>Next, we will dive into the step-by-step installation process for each dependency, including CUDA, Python, and PyTorch. We will also discuss the benefits of using a Python virtual environment and guide you through setting one up.</p>
			<p>For those who do not have access to a machine with a GPU, we will explore alternative options such as Google Colab. We will provide a comprehensive guide to using these services and discuss the trade-offs associated with them.</p>
			<p>Finally, we will address common issues that may arise during the setup process and provide troubleshooting tips. Additionally, we will share best practices for maintaining a stable environment to ensure a smooth experience while working with Stable Diffusion models.</p>
			<p>By the end of this chapter, you will have a solid foundation for setting up and maintaining an environment tailored for Stable Diffusion, allowing you to focus on building and experimenting with your models efficiently.</p>
			<h1 id="_idParaDest-30"><a id="_idTextAnchor039"/>Hardware requirements to run Stable Diffusion</h1>
			<p>This section will discuss the hardware requirements of running a Stable Diffusion model. This book will cover <strong class="bold"><a id="_idIndexMarker034"/></strong><strong class="bold">Stable Diffusion v1.5</strong> and the <strong class="bold">Stable Diffusion XL</strong> (<strong class="bold">SDXL</strong>) version. These two are also the most used models at the time of writing this book.</p>
			<p>Stable Diffusion v1.5, released in October 2022, is<a id="_idIndexMarker035"/> considered a general-purpose model, and can be <a id="_idIndexMarker036"/>used interchangeably with v1.4. On the other hand, SDXL, which was released in July 2023, is known for its ability to handle higher resolutions more effectively compared to Stable Diffusion v1.5. It can generate images with larger dimensions without compromising on quality.</p>
			<p>Essentially, Stable Diffusion is a set of models that includes the following:</p>
			<ul>
				<li><strong class="bold">Tokenizer</strong>: This <a id="_idIndexMarker037"/>tokenizes a text prompt into a <a id="_idIndexMarker038"/>sequence of tokens.</li>
				<li><strong class="bold">Text Encoder</strong>: The Stable <a id="_idIndexMarker039"/>Diffusion text encoder<a id="_idIndexMarker040"/> is a special Transformer language model – specifically, the text encoder of a CLIP model. In SDXL, a larger-size OpenCLIP [6] text encoder is also used to encode the tokens into text embeddings.</li>
				<li><strong class="bold">Variational Autoencoder</strong> (<strong class="bold">VAE</strong>): This <a id="_idIndexMarker041"/>encodes images into a latent space and decodes <a id="_idIndexMarker042"/>them back into images.</li>
				<li><strong class="bold">UNet</strong>: This <a id="_idIndexMarker043"/>is where the denoising process happens. The UNet<a id="_idIndexMarker044"/> structure is employed to comprehend the steps involved in the noising/denoising cycle. It accepts certain elements such as noise, time step data, and a conditioning signal (for instance, a representation of a text description), and forecasts noise residuals that can be utilized in the denoising process.</li>
			</ul>
			<p>The components of Stable Diffusion provide neural network weight data, except for the tokenizer. While the CPU can handle the training and inference in theory, a physical machine with a GPU or parallel computing device can provide the best experience to learn and run Stable Diffusi<a id="_idTextAnchor040"/>on models.</p>
			<h2 id="_idParaDest-31"><a id="_idTextAnchor041"/>GPU</h2>
			<p>In theory, Stable <a id="_idIndexMarker045"/>Diffusion models can run on both GPU and CPU. In reality, PyTorch-based models work best on an NVIDIA GPU with CUDA.</p>
			<p>Stable Diffusion requires a GPU with at least 4 GB VRAM. From my own experience, a GPU with 4 GB VRAM can only enable you to generate 512x512 images but it may take a long time to generate them. A GPU with at least 8 GB VRAM grants a relatively pleasant learning and usage experience. The larger the VRAM size, the better.</p>
			<p>The code of this book is tested on NVIDIA RTX 3070Ti with 8 GB VRAM and RTX 3090 with <a id="_idTextAnchor042"/>24 GB VRAM.</p>
			<h2 id="_idParaDest-32"><a id="_idTextAnchor043"/>System memory</h2>
			<p>There will <a id="_idIndexMarker046"/>be a lot of data transferred between GPU and CPU, and some Stable Diffusion models will easily take up to 6 GB RAM. Please prepare at least 16 GB of system RAM; 32 GB RAM will be good – the more, the better, especially for mult<a id="_idTextAnchor044"/>iple models.</p>
			<h2 id="_idParaDest-33"><a id="_idTextAnchor045"/>Storage</h2>
			<p>Do prepare <a id="_idIndexMarker047"/>a large drive. By default, the Hugging Face package will download model data to a cache folder located in the system drive. If you only have 256 GB or 512 GB storage, you will find it quickly running out. Preparing a 1 TB NVME SSD is recommended, although 2 TB or more will be<a id="_idTextAnchor046"/> even better.</p>
			<h1 id="_idParaDest-34"><a id="_idTextAnchor047"/>Software requirements</h1>
			<p>Now <a id="_idIndexMarker048"/>we have the hardware prepared, Stable Diffusion requires additional software to support its execution and provide better control using Python. This section will provide you with the steps to prepare the softwar<a id="_idTextAnchor048"/>e environment.</p>
			<h2 id="_idParaDest-35"><a id="_idTextAnchor049"/>CUDA installation</h2>
			<p>If you are using <a id="_idIndexMarker049"/>Microsoft Windows, please install Microsoft <strong class="bold">Visual Studio</strong> (<strong class="bold">VS</strong>) [5] first. VS will install all other dependent packages and binary files for <a id="_idIndexMarker050"/>CUDA. You can <a id="_idIndexMarker051"/>simply choose the latest Community version of VS for free.</p>
			<p>Now, go to the NVIDIA CUDA download page [1] to get the CUDA installation file. The following screenshot shows an example of selecting CUDA for Windows 11:</p>
			<div><div><img src="img/B21263_02_01.jpg" alt="Figure 2.1: Selecting the CUDA installation download file for Windows"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.1: Selecting the CUDA installation download file for Windows</p>
			<p>Download the <a id="_idIndexMarker052"/>CUDA installation file, then double-click this file to install CUDA like any other Windows application.</p>
			<p>If you are <a id="_idIndexMarker053"/>using a Linux operating system, installing CUDA for Linux is slightly different. You can execute the Bash script provided by NVIDIA to automate the installation. Here are the detailed steps:</p>
			<ol>
				<li>It is better to uninstall all NVIDIA drivers first to ensure minimum errors, so if you have NVIDIA’s driver already installed, use the following command to uninstall it:<pre class="source-code">
sudo apt-get purge nvidia*</pre><pre class="source-code">
sudo apt-get autoremove</pre><p class="list-inset">Then, reboot your system:</p><pre class="source-code">
sudo reboot</pre></li>
				<li>Install GCC. <strong class="bold">GNU Compiler Collection</strong> (<strong class="bold">GCC</strong>) is a set of compilers for various programming <a id="_idIndexMarker054"/>languages such as C, C++, Objective-C, Fortran, Ada, and others. It is an open source project developed by the <a id="_idIndexMarker055"/>GNU Project and is widely used for compiling and building software on Unix-like operating systems, including Linux. Without GCC being installed, we will get errors during the CUDA installation. Install it with the following command:<pre class="source-code">
sudo apt install gcc</pre></li>
				<li>Select the right CUDA version for your system on the CUDA download page [2]. The following screenshot shows an example of selecting CUDA for Ubuntu 22.04:</li>
			</ol>
			<div><div><img src="img/B21263_02_02.jpg" alt="Figure 2.2: Selecting the CUDA installation download file for Linux"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.2: Selecting the CUDA installation download file for Linux</p>
			<p class="list-inset">After your selection, the page will show you the command scripts that handle the entire installation process. Here is one example:</p>
			<pre class="source-code">
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-ubuntu2204.pin
sudo mv cuda-ubuntu2204.pin /etc/apt/preferences.d/cuda-repository-pin-600
wget https://developer.download.nvidia.com/compute/cuda/12.1.1/local_installers/cuda-repo-ubuntu2204-12-1-local_12.1.1-530.30.02-1_amd64.deb
sudo dpkg <strong class="bold">-i</strong> cuda-repo-ubuntu2204-12-1-local_12.1.1-530.30.02-1_amd64.deb
sudo cp /var/cuda-repo-ubuntu2204-12-1-local/cuda-*-keyring.gpg /usr/share/keyrings/
sudo apt-get update
sudo apt-get <strong class="bold">-y</strong> install cuda</pre>
			<p class="callout-heading">Note</p>
			<p class="callout">The script may have been updated by the time you read this book. To avoid errors and potential installation failures, I would suggest opening the page and using the script that refle<a id="_idTextAnchor050"/>cts your selection.</p>
			<h2 id="_idParaDest-36"><a id="_idTextAnchor051"/>Installing Python for Windows, Linux, and macOS</h2>
			<p>We will first install Python for Windows.</p>
			<h3>Installing Python for Windows</h3>
			<p>You <a id="_idIndexMarker056"/>can visit <a href="https://www.python.org/">https://www.python.org/</a> and download<a id="_idIndexMarker057"/> Python 3.9 or Python 3.10 to install it.</p>
			<p>After years <a id="_idIndexMarker058"/>of manually downloading and clicking through the installation process, I found that using a package manager is quite useful to automate the installation. With a package manager, you write a script once, save it, and then the next time you need to install the software, all you have to do is run the same script in a terminal window. One of the best package managers for Windows is <a id="_idIndexMarker059"/>Chocolatey (<a href="https://chocolatey.org/">https://chocolatey.org/</a>).</p>
			<p>Once you have Chocolatey installed, use the following command to install Python 3.10.6:</p>
			<pre class="console">
choco install python --version=3.10.6</pre>
			<p>Create a <a id="_idIndexMarker060"/>Python virtual environment:</p>
			<pre class="console">
pip install --upgrade --user pip
pip install virtualenv
python -m virtualenv venv_win_p310
venv_win_p310\Scripts\activate
python -m ensurepip
python -m pip install --upgrade pip</pre>
			<p>We <a id="_idIndexMarker061"/>will move on to the steps to install Python for Linux.</p>
			<h3>Installing Python for Linux</h3>
			<p>Let’s <a id="_idIndexMarker062"/>now install <a id="_idIndexMarker063"/>Python for Linux (Ubuntu). Follow these steps:</p>
			<ol>
				<li>Install the required packages:<pre class="source-code">
sudo apt-get install software-properties-common</pre><pre class="source-code">
sudo add-apt-repository ppa:deadsnakes/ppa</pre><pre class="source-code">
sudo apt-get update</pre><pre class="source-code">
sudo apt-get install python3.10</pre><pre class="source-code">
sudo apt-get install python3.10-dev</pre><pre class="source-code">
sudo apt-get install python3.10-distutils</pre></li>
				<li>Install <code>pip</code>:<pre class="source-code">
curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py</pre><pre class="source-code">
python3.10 get-pip.py</pre></li>
				<li>Create<a id="_idIndexMarker064"/> a Python<a id="_idIndexMarker065"/> virtual environment:<pre class="source-code">
python3.10 -m pip install --user virtualenv</pre><pre class="source-code">
python3.10 -m virtualenv venv_ubuntu_p310</pre><pre class="source-code">
. venv_ubuntu_p310/bin/activate</pre></li>
			</ol>
			<h3>Installing Python for macOS</h3>
			<p>If you <a id="_idIndexMarker066"/>are using <a id="_idIndexMarker067"/>a Mac with the silicon chip inside (with Apple Mx CPU), there is a high chance you have Python installed already. You can test whether you have Python installed on your Mac with the following command:</p>
			<pre class="source-code">
python3 <strong class="bold">--version</strong></pre>
			<p>If your machine doesn’t have a Python interpreter yet, you can install it with one simple command using Homebrew [7] like this:</p>
			<pre class="console">
brew install python</pre>
			<p>Keep in mind that Python versions are regularly updated, usually on an annual basis. You can change the version number to install a specific Python version. For example, you can c<a id="_idTextAnchor052"/>hange <code>python3.10</code> to <code>python3.11</code>.</p>
			<h2 id="_idParaDest-37"><a id="_idTextAnchor053"/>Installing PyTorch</h2>
			<p>The Hugging <a id="_idIndexMarker068"/>Face Diffusers package relies on the PyTorch package, so we <a id="_idIndexMarker069"/>will need to have the PyTorch package installed. Go to the<a id="_idIndexMarker070"/> PyTorch <strong class="bold">Get Started</strong> page (<a href="https://pytorch.org/get-started/locally/">https://pytorch.org/get-started/locally/</a>) and select the appropriate PyTorch version for your system. The following is a screenshot of PyTorch for Windows:</p>
			<div><div><img src="img/B21263_02_03.jpg" alt="Figure 2.3: Installing PyTorch"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.3: Installing PyTorch</p>
			<p>Next, use the dynamically generated command to install PyTorch:</p>
			<pre class="console">
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117</pre>
			<p>In addition to CUDA 11.7, there is also CUDA 11.8. The choice of version will depend on the CUDA version installed on your machine.</p>
			<p>You can <a id="_idIndexMarker071"/>use the following command to find out your CUDA version:</p>
			<pre class="console">
nvcc --version</pre>
			<p>You can <a id="_idIndexMarker072"/>also use this command:</p>
			<pre class="console">
nvidia-smi</pre>
			<p>Your machine’s CUDA version may be higher than the listed versions of 11.7 or 11.8, such as 12.1. Often, a specific version is required by a certain model or package. For Stable Diffusion, just install the newest version.</p>
			<p>If you are using a Mac, select the <strong class="bold">Mac</strong> option to install PyTorch for macOS.</p>
			<p>If you are using a Python virtual environment, make sure to install PyTorch within the activated virtual environment. Otherwise, you may encounter issues where PyTorch is not installed correctly if you accidentally install it outside the virtual environment and then run your Python c<a id="_idTextAnchor054"/>ode within the virtual environment.</p>
			<h1 id="_idParaDest-38"><a id="_idTextAnchor055"/>Running a Stable Diffusion pipeline</h1>
			<p>Now that you have installed all the dependencies, it is time to run a Stable Diffusion pipeline to <a id="_idIndexMarker073"/>test whether the environment is correctly set up. You can use any Python editing tool, such as VS Code or Jupyter Notebook, to edit and execute Python code. Follow these steps:</p>
			<ol>
				<li>Install the packages for Hugging Face Diffusers:<pre class="source-code">
pip install diffusers</pre><pre class="source-code">
pip install transformers scipy ftfy accelerate</pre></li>
				<li>Start a Stable Diffusion pipeline:<pre class="source-code">
import torch</pre><pre class="source-code">
from diffusers import StableDiffusionPipeline</pre><pre class="source-code">
pipe = StableDiffusionPipeline.from_pretrained(</pre><pre class="source-code">
    "runwayml/stable-diffusion-v1-5",</pre><pre class="source-code">
    torch_dtype=torch.float16)</pre><pre class="source-code">
pipe.to("cuda") # mps for mac</pre><p class="list-inset">If you are using a Mac, change <code>cuda</code> to <code>mps</code>. Even though macOS is supported and can generate images using the Diffusers package, its performance is relatively slow. As a comparison, an NVIDIA RTX 3090 can achieve about 20 iterations per second to generate one 512x512 image using Stable Diffusion V1.5, whereas an M3 Max CPU can only reach around 5 iterations per second with the default settings.</p></li>
				<li>Generate an image:<pre class="source-code">
prompt = "a photo of an astronaut riding a horse on mars,blazing fast, wind and sand moving back"</pre><pre class="source-code">
image = pipe(</pre><pre class="source-code">
    prompt, num_inference_steps=30</pre><pre class="source-code">
).images[0]</pre><pre class="source-code">
image</pre></li>
			</ol>
			<p>If you see <a id="_idIndexMarker074"/>an image of an astronaut riding a horse, you have all the environments set u<a id="_idTextAnchor056"/>p correctly in your physical machine.</p>
			<h1 id="_idParaDest-39"><a id="_idTextAnchor057"/>Using Google Colaboratory</h1>
			<p><strong class="bold">Google Colaboratory</strong> (or <strong class="bold">Google Colab</strong>) is an online computing service provided by Google. In <a id="_idIndexMarker075"/>essence, Google Colab is an online Jupyter notebook with GPU/CUDA capability.</p>
			<p>Its free <a id="_idIndexMarker076"/>notebook can provide CUDA computing with 15 GB VRAM equivalent to an NVIDIA RTX 3050 or RTX 3060. The performance is decent if you don’t have a discrete GPU at hand.</p>
			<p>Let’s look at the advantages and disadvantages of using Google Colab:</p>
			<ul>
				<li><code>pip</code> and downloading of resources are fast</li></ul></li>
				<li><strong class="bold">Disadvantages</strong>:<ul><li>There <a id="_idIndexMarker078"/>is a disk limitation for each notebook</li><li>You don't have full control of the backend server; terminal access requires a Colab Pro subscription</li><li>The performance is not guaranteed so you may experience slow GPU inference during peak time and could be disconnected for long-time computing</li><li>The Colab <a id="_idIndexMarker079"/>notebook compute environment will be reset every time you restart the notebook; in other words, you will need to reinstall all the packages and download the mod<a id="_idTextAnchor058"/>el files every time you start the notebook</li></ul></li>
			</ul>
			<h1 id="_idParaDest-40"><a id="_idTextAnchor059"/>Using Google Colab to run a Stable Diffusion pipeline</h1>
			<p>Here <a id="_idIndexMarker080"/>are the detailed steps to start using Google Colab:</p>
			<ol>
				<li>Create <a id="_idIndexMarker081"/>a new instance from <a href="https://colab.research.google.com/">https://colab.research.google.com/</a>.</li>
				<li>Click <strong class="bold">Runtime</strong> | <strong class="bold">Change runtime type</strong> and select <strong class="bold">T4 GPU</strong>, as shown in <em class="italic">Figure 2</em><em class="italic">.4</em>:</li>
			</ol>
			<div><div><img src="img/B21263_02_04.jpg" alt="Figure 2.4: Selecting GPU in the Google Colab notebook"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.4: Selecting GPU in the Google Colab notebook</p>
			<ol>
				<li value="3">Create a new cell and use the following command to check whether the GPU and CUDA are working:<pre class="source-code">
!nvidia-smi</pre></li>
				<li>Install the packages for Hugging Face Diffusers:<pre class="source-code">
!pip install diffusers</pre><pre class="source-code">
!pip install transformers scipy ftfy accelerate ipywidgets</pre></li>
				<li>Start <a id="_idIndexMarker082"/>a Stable Diffusion pipeline:<pre class="source-code">
import torch</pre><pre class="source-code">
from diffusers import StableDiffusionPipeline</pre><pre class="source-code">
pipe = StableDiffusionPipeline.from_pretrained(</pre><pre class="source-code">
    "runwayml/stable-diffusion-v1-5",</pre><pre class="source-code">
     torch_dtype=torch.float16)</pre><pre class="source-code">
pipe.to("cuda")</pre></li>
				<li>Generate <a id="_idIndexMarker083"/>an image:<pre class="source-code">
prompt = "a photo of an astronaut riding a horse on mars,blazing fast, wind and sand moving back"</pre><pre class="source-code">
image = pipe(</pre><pre class="source-code">
    prompt, num_inference_steps=30</pre><pre class="source-code">
).images[0]</pre><pre class="source-code">
image</pre></li>
			</ol>
			<p>In a few seconds, you should be able to see the result as shown in <em class="italic">Figure 2</em><em class="italic">.5</em>:</p>
			<div><div><img src="img/B21263_02_05.jpg" alt="Figure 2.5: Running a Stable Diffusion pipeline in Google Colab"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.5: Running a Stable Diffusion pipeline in Google Colab</p>
			<p>If <a id="_idIndexMarker084"/>you see an <a id="_idIndexMarker085"/>image generated as in <em class="italic">Figure 2</em><em class="italic">.5</em>, you have successfully set up the Diffusers package to r<a id="_idTextAnchor060"/>un the Stable Diffusion model in Google Colab.</p>
			<h1 id="_idParaDest-41"><a id="_idTextAnchor061"/>Summary</h1>
			<p>Some say that the most challenging part of starting to train a machine learning model is not the math or its internal logic. Often, the biggest hurdle is setting up a proper working environment to run the model. It's not uncommon to see engineers and professors spend an entire weekend trying to install CUDA on their lab machines. This can be due to missing dependencies, skipped steps, or version incompatibilities.</p>
			<p>I dedicated an entire chapter to covering the installation process, hoping that these detailed steps would help you avoid common pitfalls. By following these steps, you’ll be able to delve into the Stable Diffusion model and start image generation with minimum obstacles.</p>
			<p>Furthermore, the software and packages you installed will also work for Transformer-based large language models.</p>
			<p>In the next chapter, we will st<a id="_idTextAnchor062"/>art using Stable Diffusion to generate images.</p>
			<h1 id="_idParaDest-42"><a id="_idTextAnchor063"/>References</h1>
			<ol>
				<li><em class="italic">CUDA Installation Guide for Microsoft </em><em class="italic">Windows</em>: <a href="https://docs.nvidia.com/cuda/cuda-installation-guide-microsoft-windows/index.html">https://docs.nvidia.com/cuda/cuda-installation-guide-microsoft-windows/index.html</a></li>
				<li><em class="italic">NVIDIA CUDA </em><em class="italic">Downloads</em>: <a href="https://developer.nvidia.com/cuda-downloads">https://developer.nvidia.com/cuda-downloads</a></li>
				<li><em class="italic">Google </em><em class="italic">Colab</em>: <a href="https://colab.research.google.com/">https://colab.research.google.com/</a></li>
				<li><em class="italic">Hugging Face Diffusers </em><em class="italic">Installation</em>: <a href="https://huggingface.co/docs/diffusers/installation">https://huggingface.co/docs/diffusers/installation</a></li>
				<li><em class="italic">Visual Studio Community </em><em class="italic">Download</em>: <a href="https://visualstudio.microsoft.com/vs/community/">https://visualstudio.microsoft.com/vs/community/</a></li>
				<li><em class="italic">OpenCLIP GitHub </em><em class="italic">repository</em>: <a href="https://github.com/mlfoundations/open_clip">https://github.com/mlfoundations/open_clip</a></li>
				<li><em class="italic">Homebrew</em>: <a href="https://brew.sh/">https://brew.sh/</a></li>
			</ol>
		</div>
	</body></html>