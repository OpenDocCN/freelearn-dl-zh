- en: Hypercube-Based NEAT for Visual Discrimination
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于超立方的NEAT用于视觉辨别
- en: In this chapter, you will learn about the main concepts behind a hypercube-based
    NEAT algorithm and about the main challenges it was designed to solve. We take
    a look at the problems that arise when attempting to use direct genome encoding
    with large-scale **artificial neural networks** (**ANN**) and how they can be
    solved with the introduction of an indirect genome encoding scheme. You will learn
    how a **Compositional Pattern Producing** **Network** (**CPPN**) can be used to
    store genome encoding information with an extra-high compression rate and how
    CPPNs are employed by the HyperNEAT algorithm. Finally, you will work with practical
    examples that demonstrate the power of the HyperNEAT algorithm.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将了解基于超立方体的NEAT算法背后的主要概念以及它旨在解决的主要挑战。我们将探讨在尝试使用直接基因组编码与大规模**人工神经网络**（**ANN**）时出现的问题，以及如何通过引入间接基因组编码方案来解决这些问题。你将学习如何使用**组合模式生成**网络（**CPPN**）以极高的压缩率存储基因组编码信息，以及HyperNEAT算法如何使用CPPNs。最后，你将通过实际示例了解HyperNEAT算法的强大功能。
- en: 'In this chapter, we discuss the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论以下主题：
- en: The problem with the direct encoding of large-scale natural networks using NEAT,
    and how HyperNEAT can help by introducing the indirect encoding method
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用NEAT直接编码大规模自然网络的问题，以及HyperNEAT如何通过引入间接编码方法来帮助解决这个问题
- en: The evolution of CPPNs with NEAT to explore geometric regularities within the
    hypercube, which allows us to efficiently encode connectivity patterns within
    the target ANN
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用NEAT进化CPPN以探索超立方体中的几何规律，这使我们能够高效地编码目标ANN中的连接模式
- en: How to use the HyperNEAT method to detect and recognize objects in a visual
    field
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用HyperNEAT方法在视觉场中检测和识别对象
- en: The definition of the objective function for a visual discrimination experiment
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 视觉辨别实验的目标函数定义
- en: A discussion of the visual discrimination experiment results
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 讨论视觉辨别实验结果
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'The following technical requirements should be met in order to execute the
    experiments described in this chapter:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 为了执行本章中描述的实验，以下技术要求应得到满足：
- en: Windows 8/10, macOS 10.13 or newer, modern Linux
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Windows 8/10，macOS 10.13或更高版本，现代Linux
- en: Anaconda Distribution version 2019.03 or newer
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Anaconda Distribution版本2019.03或更高版本
- en: The code for this chapter can be found at [https:/​/​github.​com/​PacktPublishing/​Hands-
    on-​Neuroevolution-​with-​Python/​tree/​master/​Chapter7](https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Python/tree/master/Chapter7)
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码可以在[https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Python/tree/master/Chapter7](https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Python/tree/master/Chapter7)找到
- en: Indirect encoding of ANNs with CPPNs
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用CPPNs间接编码ANN
- en: In the previous chapters, you learned about the direct encoding of ANNs using
    the nature-inspired conception of a genotype that is mapped to the phenotype in
    a `1:1` ratio to represent the ANN topology. This mapping allows us to use advanced
    NEAT algorithm features such as an innovation number, which allows us to track
    when a particular mutation was introduced during the evolution. Each gene in the
    genome has a specific value of the innovation number, allowing fast and accurate
    crossover of parent genomes to produce offspring. While this feature introduces
    immense benefits and also reduces the computational costs needed to match the
    parent genomes during the recombination, the direct encoding used to encode the
    ANN topology of the phenotype has a significant drawback as it limits the size
    of the encoded ANN. The bigger the encoded ANN, the bigger the genome that is
    evaluated during the evolution, and this involves tremendous computational costs.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在前几章中，你学习了使用自然启发式的基因型概念直接编码人工神经网络（ANN），该基因型以`1:1`的比例映射到表型以表示ANN拓扑结构。这种映射使我们能够使用先进的NEAT算法特性，如创新编号，它允许我们在进化过程中跟踪特定突变何时被引入。基因组中的每个基因都有一个特定的创新编号值，这使得快速准确地交叉父代基因组以产生后代成为可能。虽然这一特性带来了巨大的好处并减少了在重组过程中匹配父代基因组所需的计算成本，但用于编码表型ANN拓扑结构的直接编码方法有一个显著的缺点，即它限制了编码ANN的大小。编码的ANN越大，在进化过程中评估的基因组就越大，这涉及到巨大的计算成本。
- en: There are many tasks, primarily related to pattern recognition in images or
    other high-dimensional data sources, that require employing ANNs that have advanced
    topologies with many layers and nodes within them. Such topological configurations
    cannot be effectively processed by the classic NEAT algorithm due to the inefficiencies
    of direct encoding discussed previously.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多任务，主要与图像或其他高维数据源中的模式识别相关，需要使用具有许多层和节点的高级拓扑结构的ANN。由于之前讨论的直接编码的低效性，这种拓扑配置不能被经典的NEAT算法有效地处理。
- en: The new method of encoding the phenotype ANN was proposed to address this drawback
    while still having all the benefits provided by the NEAT algorithm. We'll discuss
    it in the next section.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这一缺点，同时保留NEAT算法提供的所有优点，提出了编码表型ANN的新方法。我们将在下一节中讨论它。
- en: CPPN encoding
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CPPN编码
- en: 'The proposed encoding scheme employs a method of representing the connectivity
    patterns within the phenotype ANN by querying another specialized neural network
    about the weights of the connections between the nodes. This specialized neural
    network is called a **CPPN**. Its main task is to represent the connectivity patterns
    of the phenotype ANN as a function of its geometry. The resulting connectivity
    pattern is represented as a four-dimensional hypercube. Each point of the hypercube
    encodes the connection between two related nodes within the phenotype ANN and
    is described by four numbers: the coordinates of the source node and the coordinates
    of the target node. The connective CPPN takes as input each point of the hypercube
    and calculates the weights of the connections between every node in the phenotype
    ANN. Also, a connection between two nodes is not expressed if the magnitude of
    the connection weight returned by the CPPN is less than a minimal threshold (![](img/ade9b185-b4ae-44a0-b628-082618ce0fea.png)).
    Thus, we can define the connective CPPN as a four-dimensional function returning
    the connection weight, as given by the following formula:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 提出的编码方案采用了一种通过查询另一个专门神经网络来表示表型ANN中连接模式的方法，该专门神经网络关于节点之间连接的权重。这个专门神经网络被称为**CPPN**。其主要任务是将其几何作为函数来表示表型ANN的连接模式。生成的连接模式表示为一个四维超立方体。超立方体的每个点编码了表型ANN中两个相关节点之间的连接，并由四个数字描述：源节点的坐标和目标节点的坐标。连接性CPPN将超立方体的每个点作为输入，并计算表型ANN中每个节点之间的连接权重。此外，如果CPPN返回的连接权重的大小小于一个最小阈值（![图片](img/ade9b185-b4ae-44a0-b628-082618ce0fea.png)），则两个节点之间的连接不会表示。因此，我们可以将连接性CPPN定义为返回连接权重的四维函数，如下公式所示：
- en: '![](img/5dd4ef9f-20b1-401a-95e5-35807388b252.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/5dd4ef9f-20b1-401a-95e5-35807388b252.png)'
- en: The source node of the phenotype ANN is at ![](img/c248e489-d2cf-4726-93e6-1ba5a39b6518.png), and
    the target node is at ![](img/830c9acc-1001-4637-a7d8-e01d615adf9a.png).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 表型ANN的源节点位于![图片](img/c248e489-d2cf-4726-93e6-1ba5a39b6518.png)，目标节点位于![图片](img/830c9acc-1001-4637-a7d8-e01d615adf9a.png)。
- en: 'Another essential feature of CPPNs is that unlike conventional ANNs, which
    employ only one type of activation function for each node (usually from the sigmoid
    family of functions), CPPNs can use multiple geometric functions as node activators.
    Due to this, CPPNs can express a rich set of geometric motifs in the produced
    connectivity patterns:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: CPPN的另一个基本特征是，与仅使用一种激活函数（通常来自Sigmoid函数族）的常规ANN不同，CPPN可以使用多个几何函数作为节点激活器。因此，CPPNs可以在生成的连接模式中表达丰富的几何模式：
- en: Symmetry (Gaussian function)
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对称性（高斯函数）
- en: Imperfect symmetry (Gaussian combined with an asymmetric coordinate frame)
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不完美的对称性（高斯函数与不对称坐标框架相结合）
- en: Repetition (sine function)
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重复（正弦函数）
- en: Repetition with variations (sine combined with a coordinate frame that doesn't
    repeat)
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 变化中的重复（正弦函数与不重复的坐标框架相结合）
- en: Considering the features of the CPPN that we've discussed, we can assume that
    the connectivity pattern produced by it can represent any network topology for
    the phenotype ANN. Also, the connectivity pattern can be used to encode large-scale
    topologies by discovering the regularities in the training data and reusing the
    same set of genes within the CPPN to encode repetitions in the phenotype ANN.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到我们讨论的CPPN的特征，我们可以假设它产生的连接模式可以表示表型ANN的任何网络拓扑。此外，连接模式可以通过在训练数据中发现规律并重复使用CPPN中的同一组基因来编码表型ANN中的重复来编码大规模拓扑。
- en: Hypercube-based NeuroEvolution of Augmenting Topologies
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于超立方体的增强拓扑结构神经进化
- en: The methodology described in the previous section was invented by Kenneth O.
    Stanley and was called **Hypercube-based** **NeuroEvolution of Augmenting Topologies**
    (**HyperNEAT**). As its name suggests, it is an extension of the NEAT algorithm
    that we have already used in this book. The main difference between these two
    methods is that the HyperNEAT method uses an indirect encoding scheme based on
    the CPPN. During the evolution, the HyperNEAT method employs a NEAT algorithm
    to evolve a population of genomes that encode a topology of the connective CPPN.
    After that, each created CPPN can be used to establish the connectivity patterns
    within a specific phenotype ANN. Finally, the phenotype ANN can be evaluated against
    the problem space.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 上一个章节中描述的方法是由Kenneth O. Stanley发明的，被称为**基于超立方体的** **增强拓扑神经进化**（**HyperNEAT**）。正如其名称所暗示的，它是NEAT算法的扩展，我们已经在本书中使用过。这两种方法之间的主要区别是HyperNEAT方法使用基于CPPN的间接编码方案。在进化过程中，HyperNEAT方法使用NEAT算法进化一个基因组种群，这些基因组编码了连接CPPN的拓扑结构。之后，每个创建的CPPN都可以用来在特定表型ANN中建立连接模式。最后，表型ANN可以针对问题空间进行评估。
- en: So far, we have discussed how connectivity patterns can be evolved using NEAT
    with a CPPN and can be applied to the nodes of the phenotype ANN. However, we
    have not mentioned how the geometric layout of the nodes is determined in the
    first place. The responsibility of defining the nodes and their positions (layout)
    is assigned to the human architect. The architect analyzes the problem space and
    utilizes the most appropriate layout.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经讨论了如何使用带有CPPN的NEAT进化连接模式，并将其应用于表型ANN的节点。然而，我们还没有提到节点几何布局最初是如何确定的。定义节点及其位置（布局）的责任分配给了人类建筑师。建筑师分析问题空间，并利用最合适的布局。
- en: 'By convention, the initial layout of the nodes of the phenotype ANN has a name:
    substrate. There are several types of substrate configuration (layout), and they
    have proven their efficiency for particular tasks:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 按照惯例，表型ANN节点的初始布局有一个名称：基质。存在几种基质配置（布局）类型，并且它们已经证明在特定任务中的效率：
- en: '**Two-dimensional grid**: A regular grid of network nodes in a two-dimensional
    Cartesian space centered at (0,0).'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**二维网格**：以(0,0)为中心的两维笛卡尔空间中的网络节点规则网格。'
- en: '**Three-dimensional grid**: A regular grid of network nodes in a three-dimensional
    Cartesian space centered at (0,0,0).'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**三维网格**：以(0,0,0)为中心的三维笛卡尔空间中的网络节点规则网格。'
- en: '**State-space sandwich**: Two two-dimensional planar grids with corresponding source
    and target nodes in which one layer can only send connections in the direction
    of the other one.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**状态空间三明治**：两个二维平面网格，其中包含相应的源节点和目标节点，其中一个层只能向另一个层的方向发送连接。'
- en: '**Circular**: A regular radial structure suited to define regularities in radial
    geometry based on polar coordinates.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**圆形**：一种适合基于极坐标定义径向几何规律性的规则径向结构。'
- en: By arranging the ANN nodes in an appropriate layout on the substrate, it is
    possible to exploit regularities in the geometry of the problem space. That significantly
    increases the efficiency of the encoding by using the connective CPPN to draw
    connectivity patterns between the substrate nodes. Let's now look at the basics
    of a visual discrimination experiment.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在基质上适当地排列ANN节点，可以利用问题空间几何中的规律性。这通过使用连接CPPN在基质节点之间绘制连接模式，显著提高了编码的效率。现在让我们看看视觉辨别实验的基础。
- en: For more details about the HyperNEAT method, please refer to [Chapter 1](f59c6396-55e5-4495-95c0-7af9a42c2f20.xhtml),
    *Overview of Neuroevolution Methods.*
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 关于HyperNEAT方法的更多细节，请参阅[第1章](f59c6396-55e5-4495-95c0-7af9a42c2f20.xhtml)，*神经进化方法概述*。
- en: Visual discrimination experiment basics
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 视觉辨别实验基础
- en: As we have already mentioned, the main advantage of the indirect encoding employed
    by the HyperNEAT algorithm is the ability to encode the topology of the large-scale
    ANN. In this section, we will describe an experiment that can be used to test
    the capacity of the HyperNEAT method to train a large-scale ANN. Visual pattern
    recognition tasks typically require large ANNs as detectors due to the high dimensionality
    of the input data (the image height multiplied by the image width). In this chapter,
    we consider a variation of this family of computer science problems called visual
    discrimination tasks.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们已经提到的，HyperNEAT算法使用的间接编码的主要优势是能够编码大规模人工神经网络（ANN）的拓扑结构。在本节中，我们将描述一个可以用来测试HyperNEAT方法训练大规模ANN能力的实验。由于输入数据（图像高度乘以图像宽度）的高维性，视觉模式识别任务通常需要大型的ANN作为检测器。在本章中，我们考虑这一系列计算机科学问题中的一个变体，称为视觉识别任务。
- en: 'The task of visual discrimination is to distinguish a large object from a small
    object in a two-dimensional visual space, regardless of their positions in the
    visual space and their positions relative to each other. The visual discrimination
    task is performed by a specialized discriminator ANN, which is built on a substrate
    configured as a state-space sandwich with two sheets:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 视觉识别任务的目的是在二维视觉空间中区分大物体和小物体，无论它们在视觉空间中的位置以及它们相对于彼此的位置。视觉识别任务由一个专门的判别器ANN执行，该ANN建立在配置为状态空间三明治的两层底座上：
- en: 'The visual field is a two-dimensional array of sensors that can be in two states:
    on or off (black and white).'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 视觉场是一个二维传感器数组，可以处于两种状态：开启或关闭（黑白）。
- en: The target field is a two-dimensional array of outputs with activation values
    in the `[0,1]` range.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 目标域是一个二维输出数组，其激活值在`[0,1]`范围内。
- en: 'The scheme of the visual discrimination task is shown here:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 视觉识别任务的方案如下所示：
- en: '![](img/c50c3901-45c5-40e5-a73d-774997ad8083.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/c50c3901-45c5-40e5-a73d-774997ad8083.png)'
- en: The visual discrimination task
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 视觉识别任务
- en: You can see in the diagram that the objects to be detected are represented as
    two squares separated by an empty space. The larger object is precisely three
    times bigger than the other one. The algorithm we are trying to build needs to
    detect the center of the larger object. The detection is based on measuring the
    activation values of the ANN nodes in the target field. The position of the node
    with the highest activation value marks the center of the detected object. Our
    goal is to discover the right connectivity patterns between visual and target
    fields that align the output node with the highest activation and the center of
    the big object in the visual field. Also, the discovered connectivity pattern
    should be invariant to the relative positions of both objects.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在图中看到，要检测的对象被表示为两个由空隙分隔的正方形。较大的对象恰好比另一个大两倍。我们试图构建的算法需要检测较大对象的中心。检测基于测量目标场中ANN节点的激活值。激活值最高的节点的位置标志着检测到的对象的中心。我们的目标是发现视觉场和目标场之间正确的连接模式，使激活值最高的输出节点与视觉场中较大对象的中心对齐。此外，发现的连接模式应不受两个对象相对位置的影响。
- en: The algorithm for the task of visual discrimination needs to evaluate a large
    number of inputs - the values representing the cells in the visual field. Also,
    the successful algorithm needs to discover the strategy that can process inputs
    from multiple cells simultaneously. Such a strategy should be based on the general
    principle that allows the detection of the relative sizes of the objects in the
    visual field. The visual field in our experiment is represented as a two-dimensional
    grid. Thus, the general geometric principle to be discovered is the concept of locality.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 用于视觉识别任务的算法需要评估大量输入——代表视觉场中细胞值的数值。此外，成功的算法还需要发现能够同时处理多个细胞输入的策略。这种策略应基于一个普遍原则，即允许检测视觉场中物体的大小相对值。在我们的实验中，视觉场被表示为一个二维网格。因此，要发现的普遍几何原则是局部性概念。
- en: We can exploit the locality principle in the substrate configuration of the
    discriminator ANN that we have chosen by discovering a particular pattern in the
    scheme of the links that connect the nodes of the visual and the target fields.
    In this connection scheme, separate nodes of the visual field are connected to
    the multiple adjacent output nodes around a specific location in the target field.
    As a result, the more activations the output node collects, the more signals are
    supplied into it through connections with individual input nodes.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过在视觉场和目标场节点连接方案中发现的特定模式来利用我们选择的辨别器ANN衬底配置中的局部性原理。在这个连接方案中，视觉场的单独节点连接到目标场特定位置周围的多个相邻输出节点。因此，输出节点收集的激活越多，通过连接向它提供的信号就越多。
- en: To effectively exploit the locality principle mentioned previously, the representation
    of connections should take into account the geometry of the discriminator ANN
    substrate and the fact that the correct connectivity pattern repeats across it.
    The best candidate for such a representation is a CPPN, which can discover the
    local connectivity pattern once and repeat it across the substrate grid at any
    resolution.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 为了有效地利用之前提到的局部性原理，连接的表示应考虑辨别器ANN衬底的几何形状以及正确的连接模式在整个衬底上重复的事实。这种表示的最佳候选者是CPPN，它一旦发现局部连接模式，就可以在任何分辨率上重复它在衬底网格上的模式。
- en: Objective function definition
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 目标函数定义
- en: The main task of the visual discriminator is to correctly determine the position
    of a larger object regardless of the relative positions of both objects. Thus,
    we can define the objective function to guide the neuroevolution process. The
    objective function should be based on the Euclidean distance between the exact
    position of the larger object in the visual field and its predicted position in
    the target field.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 视觉辨别器的主要任务是正确确定较大物体的位置，无论两个物体的相对位置如何。因此，我们可以定义目标函数来指导神经进化过程。目标函数应基于视觉场中较大物体确切位置与其在目标场中预测位置之间的欧几里得距离。
- en: 'The loss function can be directly represented as the Euclidean distance between
    the actual and predicted positions as follows:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 损失函数可以直接表示为实际位置和预测位置之间的欧几里得距离，如下所示：
- en: '![](img/699dc1b0-b237-4196-8156-039e0ab72b66.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/699dc1b0-b237-4196-8156-039e0ab72b66.png)'
- en: '![](img/510315d6-bb2f-4e07-bad5-0f1feeb1da7d.png) is a loss function, ![](img/91dfcca9-9a9a-4677-b363-98a6577866fc.png) is
    the ground truth coordinates of the big object, and ![](img/f77190a1-381b-4b78-843f-2a578f739538.png) is
    predicted by the discriminator ANN coordinates.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/510315d6-bb2f-4e07-bad5-0f1feeb1da7d.png) 是损失函数，![图片](img/91dfcca9-9a9a-4677-b363-98a6577866fc.png)
    是大物体的真实坐标，![图片](img/f77190a1-381b-4b78-843f-2a578f739538.png) 是由辨别器ANN预测的坐标。'
- en: 'With the loss function as defined previously, we can write the objective function
    as follows:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 使用之前定义的损失函数，我们可以将目标函数写为以下形式：
- en: '![](img/0ecb5686-c207-44ca-bce5-3c9103ebe605.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/0ecb5686-c207-44ca-bce5-3c9103ebe605.png)'
- en: '![](img/a5fa600f-b85b-497a-a646-2f398d51b634.png) is the maximal possible distance
    between the two points within the target field space. The objective function formula
    guarantees that the calculated fitness score (![](img/96b5cab2-09d7-45ab-8cad-e9443b8e07c6.png)
    ) always falls within the `[0,1] `range. Now that we know the basics of the visual
    discrimination experiment, let''s start with setting it up.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/a5fa600f-b85b-497a-a646-2f398d51b634.png) 是目标场空间内两点之间的最大可能距离。目标函数公式保证了计算出的适应度分数（![图片](img/96b5cab2-09d7-45ab-8cad-e9443b8e07c6.png)）始终落在
    `[0,1]` 范围内。现在我们了解了视觉辨别实验的基本知识，让我们开始设置它。'
- en: Visual discrimination experiment setup
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 视觉辨别实验设置
- en: In our experiment, during the training of the discriminator ANN, we use the
    resolution of the visual and target fields fixed at 11 x 11\. Thus, the connective
    CPPN must learn the correct connectivity pattern between the 121 inputs of the
    visual field and the 121 outputs of the target fields, which results in a total
    of 14,641 potential connection weights.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的实验中，在辨别器ANN的训练过程中，我们使用视觉场和目标场的分辨率固定在 11 x 11。因此，连接的CPPN必须学习视觉场121个输入和目标场121个输出之间的正确连接模式，这导致总共14,641个潜在的连接权重。
- en: 'The following diagram shows the scheme of the substrate for the discriminator
    ANN:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 下图显示了辨别器ANN衬底的方案：
- en: '![](img/d14d3979-7aaf-4756-803f-23d01cde0226.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/d14d3979-7aaf-4756-803f-23d01cde0226.png)'
- en: The state-space sandwich substrate of the discriminator ANN
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 辨别器ANN的状态空间夹层衬底
- en: The discriminator ANN shown in the diagram has two layers with nodes forming
    one two-dimensional planar grid per layer. The connective CPPN draws the connectivity
    patterns by connecting nodes from one layer to another.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图中所示的判别器ANN具有两层，每层由形成二维平面网格的节点组成。连接性CPPN通过连接来自一个层的节点到另一个层的节点来绘制连接模式。
- en: At each generation of the evolution, each individual in the population (the
    genome encoding the CPPN) is evaluated for its ability to create connectivity
    patterns of the discriminator ANN. The discriminator ANN is then tested to see
    whether it can find the center of the large object within the visual field. There
    are a total of 75 evaluation trials for a particular ANN, in which two objects
    are placed at different locations in each trial. At each trial, we put a small
    object in one of the 25 positions uniformly distributed in the visual field. The
    center of a large object is five steps from the small object to the right, down,
    or diagonally. If a large object doesn't fit into the visual field completely,
    then it wraps around to the other side. Thus, considering the logic of the placement
    of objects relative to each other and the grid, we should be able to evaluate
    all possible configurations in 75 trials.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在进化的每一代中，种群中的每个个体（编码CPPN的基因组）都会对其创建判别器ANN连接模式的能力进行评估。然后测试判别器ANN是否能够在视觉场内找到大物体的中心。对于特定的ANN，总共有75次评估试验，其中每个试验中放置两个物体在不同的位置。在每个试验中，我们在视觉场中均匀分布的25个位置之一放置一个小物体。大物体的中心在小物体的右侧、下方或对角线方向五步之遥。如果大物体不能完全放入视觉场中，则它将绕到另一侧。因此，考虑到物体相对于彼此和网格的放置逻辑，我们应该能够在75次试验中评估所有可能的配置。
- en: Our experiment setup has two major parts, which we will discuss in the following
    sections.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的实验设置有两个主要部分，我们将在接下来的几节中讨论。
- en: Visual discriminator test environment
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 视觉判别器测试环境
- en: First we need to define the test environment and provide access to the dataset,
    which contains all the possible visual field configurations as described in the
    previous section. The dataset used in this experiment is created during the test
    environment initialization. We will discuss dataset creation later in this section.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要定义测试环境并提供对数据集的访问，该数据集包含上一节中描述的所有可能的视觉场配置。本实验中使用的数据集是在测试环境初始化期间创建的。我们将在本节的后面讨论数据集的创建。
- en: 'The test environment has two major components:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 测试环境有两个主要组件：
- en: The data structure to maintain the visual field definition
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 维护视觉场定义的数据结构
- en: The test environment manager, which stores the dataset and provides a means
    to evaluate discriminator ANNs against it
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试环境管理器，它存储数据集，并提供一种方法来评估判别器ANN相对于它的性能
- en: Next, we provide a detailed description of these components.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将详细描述这些组件。
- en: Visual field definition
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 视觉场定义
- en: 'We store the configuration of the visual field for each of the 75 trials discussed
    previously in the `VisualField` Python class. It has the following constructor:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在`VisualField` Python类中存储了之前讨论的75次试验中每个试验的视觉场配置。它具有以下构造函数：
- en: '[PRE0]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The constructor of `VisualField` accepts as parameters the tuple with coordinates
    (*x*, *y*) of the large and small object, as well as the size of the visual field.
    We consider the square visual field, so the size of the visual field along each
    axis is equal. The visual field is internally represented as a two-dimensional
    binary array where ones represent positions occupied by objects, and zeros are
    empty spaces. It is stored in the `self.data` field, which is a NumPy array with
    the shape (2, 2).
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '`VisualField`的构造函数接受一个包含大物体和小物体坐标（*x*，*y*）的元组，以及视觉场的大小。我们考虑的是正方形视觉场，因此视觉场沿每个轴的大小相等。视觉场在内部表示为一个二维二进制数组，其中1表示被物体占据的位置，而0是空空间。它存储在`self.data`字段中，这是一个形状为（2，2）的NumPy数组。'
- en: 'The small object has a size 1 x 1, and the large object is three times bigger.
    The following snippet from the constructor''s source code creates the representation
    of the big object in the data array:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 小物体的大小为1 x 1，大物体是它的三倍大。以下是从构造函数源代码中创建大物体表示的片段：
- en: '[PRE1]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The constructor of the `VisualField` class receives the coordinates of the center
    of the big object as a tuple, (`x`, `y`). The preceding code draws the big object
    starting from the top-left corner (`x-1`, `y-1`) and ending at the bottom-right
    corner (`x+1`, `y+1`).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '`VisualField`类的构造函数接收大物体中心的坐标作为元组（`x`，`y`）。前面的代码从左上角（`x-1`，`y-1`）开始绘制大物体，并结束于右下角（`x+1`，`y+1`）。'
- en: 'The `_set_point(self, x, y)` function referred to in the preceding code sets
    the `1.0` value at the specific position in the `self.data` field:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 前面代码中提到的`_set_point(self, x, y)`函数在`self.data`字段中的特定位置设置`1.0`值：
- en: '[PRE2]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The `_set_point(self, x, y)` function performs coordinate wrapping when the
    coordinate value exceeds the allowed number of dimensions per axis. For example,
    for the *x* axis, the source code for the coordinate value wrapping is as follows:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '`_set_point(self, x, y)`函数在坐标值超过每轴允许的维度数时执行坐标包裹。例如，对于*x*轴，坐标值包裹的源代码如下：'
- en: '[PRE3]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The source code for coordinate wrapping along the *y* axis is similar.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 沿着*y*轴的坐标包裹源代码类似。
- en: After wrapping the coordinates specified as parameters of the function (if needed),
    we set the corresponding positions in the `self.data` field to have a value of
    `1.0`.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在需要的情况下，在函数参数指定的坐标包裹后，我们将`self.data`字段中相应的位置设置为`1.0`值。
- en: NumPy indexes as `[row, column]`. Thus, we need to use *y* in the first position
    and *x* in the second position of the index.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy索引为`[行, 列]`。因此，我们需要在索引的第一个位置使用*y*，在第二个位置使用*x*。
- en: Visual discriminator environment
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可视判别环境
- en: 'The visual discriminator environment holds the generated dataset with the visual
    field definitions. Also, it provides methods to create the dataset and to evaluate
    the discriminator ANN against the dataset. The `VDEnvironment` Python class holds
    the definitions of all mentioned methods, as well as related data structures.
    Next, we''ll look at all the significant parts of the `VDEnvironment` class definition:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 可视判别环境持有带有视觉场定义的生成数据集。它还提供了创建数据集和评估判别器ANN相对于数据集的方法。`VDEnvironment` Python类包含了所有提到的方法定义，以及相关的数据结构。接下来，我们将查看`VDEnvironment`类定义的所有重要部分：
- en: 'The class constructor is defined as follows:'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 类构造函数定义如下：
- en: '[PRE4]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The first parameter of the `VDEnvironment` constructor is an array with the
    definitions of all the possible small object positions defined as a sequence of
    coordinate values for each axis. The second parameter defines the offset of the
    coordinates of the center of the big object from the small object coordinates.
    We use `5` as the value of this parameter in our experiment. Finally, the third
    parameter is the visual field size along with both dimensions.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '`VDEnvironment`构造函数的第一个参数是一个数组，包含所有可能的小物体位置的定义，作为每个轴上坐标值的序列。第二个参数定义了大物体中心坐标相对于小物体坐标的偏移量。在我们的实验中，我们使用`5`作为此参数的值。最后，第三个参数是视觉场的大小，包括两个维度。'
- en: 'After all the received parameters are saved into object fields, we calculate
    the maximum possible distance between two points in the visual field as follows:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有接收到的参数都保存到对象字段后，我们计算视觉场中两点之间的最大可能距离如下：
- en: '[PRE5]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The Euclidean distance between the top-left and the bottom-right corner of the
    visual field is then stored in the `self.max_dist` field. This value will be used
    later to normalize the distances between points in the visual field by keeping
    them in the `[0, 1]` range.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 可视场左上角和右下角之间的欧几里得距离随后存储在`self.max_dist`字段中。此值将用于后续通过保持它们在`[0, 1]`范围内来归一化视觉场中点之间的距离。
- en: 'The `_create_data_set()` function creates all possible datasets given the specified
    environment parameters. The source code of this function is as follows:'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`_create_data_set()`函数根据指定的环境参数创建所有可能的数据集。此函数的源代码如下：'
- en: '[PRE6]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The function iterates over the small object positions along two axes and tries
    to create the big object at coordinates that are to the right, below, or on a
    diagonal from the small object coordinates.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 函数遍历两个轴上的小物体位置，并尝试在相对于小物体坐标的右侧、下方或对角线位置创建大物体。
- en: 'The `_create_visual_field` function creates the appropriate visual field configuration
    using the coordinates of the small object (`sx`, `sy`) and an offset of the big
    object''s center (`x_off`, `y_off`). The following source code shows how this
    is implemented:'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`_create_visual_field` 函数使用小物体的坐标（`sx`，`sy`）和大物体中心偏移量（`x_off`，`y_off`）创建适当的视觉场配置。以下源代码显示了如何实现这一点：'
- en: '[PRE7]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'If the coordinates of the big object calculated by the preceding function are
    outside the visual field space, we apply the wrapping as follows:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 如果前面函数计算的大物体坐标超出了视觉场空间，我们按以下方式应用包装：
- en: '[PRE8]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The preceding snippet shows the wrapping along the *x* axis. The wrapping along
    the *y* axis is similar. Finally, the `VisualField` object is created and returned
    to be appended to the dataset.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码片段显示了沿 *x* 轴的包装。沿 *y* 轴的包装类似。最后，创建并返回 `VisualField` 对象以附加到数据集中。
- en: 'However, the most exciting part of the `VDEnvironment` definition is related
    to the evaluation of the discriminator ANN, which is defined in the `evaluate_net(self,
    net)` function as follows:'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然而，`VDEnvironment` 定义中最激动人心的部分与判别器 ANN 的评估有关，该评估在 `evaluate_net(self, net)`
    函数中定义如下：
- en: '[PRE9]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The preceding function receives the discriminator ANN as a parameter, and returns
    the evaluated fitness score and the mean distance between the detected coordinates
    of the big object and the ground truth values calculated for all evaluated visual
    fields. The average distance is calculated as follows:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的函数接收判别器人工神经网络（ANN）作为参数，并返回评估的适应度分数以及所有评估视觉场中检测到的目标坐标与计算的所有真实值之间的平均距离。平均距离的计算如下：
- en: '[PRE10]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The preceding source code iterates over all `VisualField` objects in the dataset,
    and uses the discriminator ANN to determine the coordinates of the big object.
    After that, we calculate the distance (detection error) between the ground truth
    and the predicted position of the big object. Finally, we find the mean of the
    detection errors and normalize it as follows:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的源代码遍历数据集中的所有 `VisualField` 对象，并使用判别器 ANN 确定大物体的坐标。之后，我们计算真实值与预测位置之间的距离（检测误差）。最后，我们找到检测误差的平均值，并按以下方式归一化：
- en: '[PRE11]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The maximum possible error value is `1.0`, according to the preceding code.
    The value of the fitness score is a complement to the `1.0` of the error value
    since it increases as the error decreases:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 根据前面的代码，最大可能的误差值是 `1.0`。适应度分数的值是误差值的 `1.0` 的补充，因为随着误差的减小而增加：
- en: '[PRE12]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The `evaluate_net` function returns the calculated fitness score along with
    the unnormalized detection error.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '`evaluate_net` 函数返回计算出的适应度分数以及未归一化的检测误差。'
- en: 'The `evaluate_net_vf(self, net, vf)` function provides a means to evaluate
    the discriminator ANN against a specific `VisualField` object. It is defined as
    follows:'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`evaluate_net_vf(self, net, vf)` 函数提供了一种评估判别器 ANN 对特定 `VisualField` 对象的方法。它定义如下：'
- en: '[PRE13]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The preceding function receives the discriminator ANN as the first parameter
    and the `VisualField` object as the second parameter. After that, it obtains the
    flattened input array from the `VisualField` object and uses it as input to the
    discriminator ANN:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的函数接收判别器 ANN 作为第一个参数，`VisualField` 对象作为第二个参数。之后，它从 `VisualField` 对象中获取展平的输入数组，并将其用作判别器
    ANN 的输入：
- en: '[PRE14]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: After we set the inputs of the discriminator ANN, it must be activated to propagate
    input values through all network nodes. Our discriminator ANN has only two layers,
    as determined by the space-sandwich substrate configuration. Thus we need to activate
    it twice—once per each layer. After propagation of the activation signal through
    both layers of the discriminator ANN, we can determine the position of the big
    object in the target field as an index of the maximal value in the output array.
    Using the `_big_object_coordinates(self, outputs)` function, we can extract the
    Cartesian coordinates (*x*, *y*) of the big object within the target field.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们设置判别器 ANN 的输入之后，它必须被激活以将输入值传播到所有网络节点。我们的判别器 ANN 只有两层，这是由空间三明治底座配置确定的。因此，我们需要激活它两次——每层一次。在判别器
    ANN 的两层中传播激活信号之后，我们可以确定目标场中大物体的位置，作为输出数组中最大值的索引。使用 `_big_object_coordinates(self,
    outputs)` 函数，我们可以提取目标场中大物体的笛卡尔坐标（*x*，*y*）。
- en: Finally, the `evaluate_net_vf` function returns the raw output array along with
    the extracted Cartesian coordinates (*x*, *y*) of the big object in the target
    field space.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，`evaluate_net_vf` 函数返回原始输出数组以及目标字段空间中大物体的提取的笛卡尔坐标 (*x*, *y*)。
- en: 'The `_big_object_coordinates(self, outputs)` function extracts the Cartesian
    coordinates of the big object within the target field space from the raw outputs
    obtained from the discriminator ANN. The function''s source code is as follows:'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`_big_object_coordinates(self, outputs)` 函数从从判别器 ANN 获得的原始输出中提取目标字段空间中大物体的笛卡尔坐标。该函数的源代码如下：'
- en: '[PRE15]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'At first, the function enumerates through the output array and finds the index
    of the maximal value:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，该函数遍历输出数组并找到最大值的索引：
- en: '[PRE16]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'After that, it uses the index it finds to estimate the Cartesian coordinates,
    taking into account the size of the target field:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，它使用找到的索引来估计笛卡尔坐标，考虑到目标字段的大小：
- en: '[PRE17]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Finally, the function returns the tuple (*x*, *y*) with the Cartesian coordinates
    of the big object within the target field.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，该函数返回包含目标字段内大物体笛卡尔坐标的元组 (*x*, *y*)。
- en: For complete implementation details, please look at `vd_environment.py` at [https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Python/blob/master/Chapter7/vd_environment.py](https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Python/blob/master/Chapter7/vd_environment.py).
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 对于完整的实现细节，请查看 [https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Python/blob/master/Chapter7/vd_environment.py](https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Python/blob/master/Chapter7/vd_environment.py)
    中的 `vd_environment.py`。
- en: Experiment runner
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实验运行。
- en: As we described earlier, the solution for the visual discrimination task can
    be found using the HyperNEAT method. Thus, we need to use a library that provides
    an implementation of the HyperNEAT algorithm. The MultiNEAT Python library is
    the right candidate for this experiment. As such, we are implementing our experiment
    using this library.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前所描述的，视觉判别任务的解决方案可以使用 HyperNEAT 方法找到。因此，我们需要使用一个提供 HyperNEAT 算法实现的库。MultiNEAT
    Python 库是本实验的正确选择。因此，我们使用这个库来实现我们的实验。
- en: Next, we discuss the most critical components of the experiment runner implementation.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们讨论实验运行实现中最关键的部分。
- en: For complete implementation details, please refer to `vd_experiment_multineat.py`
    at [https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Python/blob/master/Chapter7/vd_experiment_multineat.py](https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Python/blob/master/Chapter7/vd_experiment_multineat.py).
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 对于完整的实现细节，请参阅 [https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Python/blob/master/Chapter7/vd_experiment_multineat.py](https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Python/blob/master/Chapter7/vd_experiment_multineat.py)
    中的 `vd_experiment_multineat.py`。
- en: The experiment runner function
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实验运行函数。
- en: The `run_experiment` function allows us to run the experiment using the provided
    hyperparameters and the initialized visual discriminator test environment. The
    function implementation has the following parts.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '`run_experiment` 函数允许我们使用提供的超参数和初始化的视觉判别器测试环境来运行实验。函数实现包含以下部分。'
- en: Initializing the first CPPN genome population
  id: totrans-130
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 初始化第一个 CPPN 基因组种群。
- en: 'In the following code, at first, we initialize the random number generator
    seed with the current system time. After that, we create the appropriate substrate
    configuration for the discriminator ANN that is able to operate over the dimensionality
    of the experiment''s visual field. Next, we create the CPPN genome using the created
    substrate configuration:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下代码中，首先，我们使用当前系统时间初始化随机数生成器种子。之后，我们为能够操作实验视觉字段维度的判别器 ANN 创建适当的基质配置。接下来，我们使用创建的基质配置创建
    CPPN 基因组：
- en: '[PRE18]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The CPPN genome created in the preceding code has the appropriate number of
    input and output nodes provided by the substrate. Initially, it uses the unsigned
    sigmoid as the node activation function. Later, during the evolution, the activation
    function type at each node of the CPPN will be changed, following the HyperNEAT
    algorithm routines. Finally, the initial population is created using the initialized
    CPPN genome and the HyperNEAT hyperparameters.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中创建的 CPPN 基因组具有由基质提供的适当数量的输入和输出节点。最初，它使用无符号的 Sigmoid 作为节点激活函数。后来，在进化过程中，CPPN
    中每个节点的激活函数类型将根据 HyperNEAT 算法流程进行更改。最后，使用初始化的 CPPN 基因组和 HyperNEAT 超参数创建初始种群。
- en: Running the neuroevolution over the specified number of generations
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在指定的代数内运行神经进化。
- en: 'At the beginning of this part, we create the intermediate variables to hold
    the execution results and create the statistics collector (`Statistics`). After
    that, we execute the evolution loop for the number of generations specified in
    the `n_generations` parameter:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在本部分的开始，我们创建中间变量以保存执行结果，并创建统计收集器（`Statistics`）。之后，我们根据`n_generations`参数指定的代数执行进化循环：
- en: '[PRE19]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Within the evolution loop, we obtain the list of genomes belonging to the population
    at the current generation and evaluate all genomes from the list against the test
    environment as follows:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在进化循环中，我们获取当前代种群所属的基因组列表，并将列表中的所有基因组与测试环境进行评估，如下所示：
- en: '[PRE20]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: We save the values returned by the `eval_genomes(genomes, substrate, vd_environment,
    generation)` function for the current generation into the statistics collector.
    Also, we use the fitness score returned by `eval_genomes` to estimate whether
    a successful solution has been found or not. If the fitness score exceeds the
    `FITNESS_THRESHOLD` value, we consider that a successful solution has been found.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将当前代`eval_genomes(genomes, substrate, vd_environment, generation)`函数返回的值保存到统计收集器中。我们还使用`eval_genomes`返回的适应度分数来估计是否找到了成功的解决方案。如果适应度分数超过`FITNESS_THRESHOLD`值，我们认为找到了成功的解决方案。
- en: 'If a successful solution was found or the current fitness score is the maximum
    fitness score ever achieved, we save the CPPN genome and the current fitness score:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 如果找到成功的解决方案或当前适应度分数是迄今为止达到的最大适应度分数，我们将保存CPPN基因组和当前适应度分数：
- en: '[PRE21]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Also, if a successful solution is found, we break the evolution loop and move
    to the reporting steps, which we will discuss later:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，如果找到成功的解决方案，我们将退出进化循环，并进入后续的报表步骤，我们将在后面讨论：
- en: '[PRE22]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'If a successful solution was not found, we print the statistics for the current
    generation and advance to the next generation with the following code:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有找到成功的解决方案，我们将打印当前代的统计数据，并使用以下代码进入下一代：
- en: '[PRE23]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: After the main evolution loop, the results of the experiment are reported, which
    uses the statistics collected in the loop.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在主要进化循环之后，报告实验结果，这使用了循环中收集的统计数据。
- en: Saving the results of the experiment
  id: totrans-147
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 保存实验结果
- en: 'The experiment results reported and saved in textual and graphical representations
    (SVG files). We start by printing general performance statistics as follows:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 实验结果以文本和图形表示（SVG文件）的形式报告和保存。我们首先打印以下一般性能统计数据：
- en: '[PRE24]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The first three lines of the preceding code print the best ever fitness score
    obtained among all the generations of evolution to the console. After that, we
    print the experiment's elapsed time and the random seed value used.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 前述代码的前三行将所有进化代数中获得的最佳适应度分数打印到控制台。之后，我们打印实验的已用时间和使用的随机种子值。
- en: 'If we requested to save or show visualizations, the corresponding functions
    are invoked:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们请求保存或显示可视化，将调用相应的函数：
- en: '[PRE25]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The preceding code draws the network graph of the CPPN and prints the statistics
    of the graph.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 前述代码绘制了CPPN的网络图，并打印了图的统计数据。
- en: 'Next, we move to the visualization of the output of the discriminator ANN:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们转向判别器ANN输出的可视化：
- en: '[PRE26]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: In the preceding code, we create the discriminator ANN using the best CPPN genome
    found during the evolution. After that, we draw the activation outputs obtained
    by running the evaluation of the discriminator ANN against the test environment.
    We use the visual field that is randomly selected from the dataset of the experiment.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在前述代码中，我们使用在进化过程中找到的最佳CPPN基因组创建判别器ANN。之后，我们绘制通过在测试环境中评估判别器ANN获得的激活输出。我们使用从实验数据集中随机选择的视野。
- en: 'Finally, we render the general statistics collected during the experiment:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们渲染实验期间收集的一般统计数据：
- en: '[PRE27]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: The statistics plot includes the best fitness scores and the average error distances
    drawn over the generations of evolution.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 统计图包括在进化代数中绘制的最佳适应度分数和平均误差距离。
- en: For implementation details of the visualization functions mentioned in this
    section, please refer to `visualize.py` at [https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Python/blob/master/Chapter7/visualize.py](https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Python/blob/master/Chapter7/visualize.py).
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 关于本节中提到的可视化函数的实现细节，请参阅[https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Python/blob/master/Chapter7/visualize.py](https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Python/blob/master/Chapter7/visualize.py)中的`visualize.py`。
- en: The substrate builder function
  id: totrans-161
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 底层构建函数
- en: 'The HyperNEAT method is built around the notion of the substrate that defines
    the structure of the discriminator ANN. Therefore, it is crucial to create an
    appropriate substrate configuration to be used during the experiment execution.
    The substrate creation routines are defined in the following two functions:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: HyperNEAT 方法建立在底层概念的基础上，该底层定义了判别器 ANN 的结构。因此，在实验执行期间创建一个合适的底层配置至关重要。底层创建例程定义在以下两个函数中：
- en: 'The substrate builder function `create_substrate` creates the substrate object
    as follows:'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 底层构建函数 `create_substrate` 如下创建底层对象：
- en: '[PRE28]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The preceding function first creates the two grid-based Cartesian sheets that
    represent inputs (the visual field) and outputs (the target field) of the substrate
    configuration. Remember that for this experiment we selected a state-space sandwich
    substrate configuration. After that, the substrate instance was initialized using
    the created field configurations:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的函数首先创建了两个基于网格的笛卡尔纸张，分别代表底层配置的输入（视觉场）和输出（目标场）。记住，对于这个实验，我们选择了状态空间三明治底层配置。之后，使用创建的字段配置初始化了底层实例：
- en: '[PRE29]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Please note that the substrate doesn't use any hidden nodes; we provide an empty
    list instead of hidden nodes.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，底层不使用任何隐藏节点；我们提供空列表代替隐藏节点。
- en: Next, we configure the substrate to only allow connections from input to output
    nodes and to use a signed sigmoid activation function at the output nodes. Finally,
    we set the maximum values for the bias and the connection weights.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们配置底层以仅允许从输入节点到输出节点的连接，并在输出节点使用有符号的 sigmoid 激活函数。最后，我们设置偏差和连接权重的最大值。
- en: 'The `create_sheet_space` function invoked by the substrate builder function
    is defined as follows:'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由底层构建函数调用的 `create_sheet_space` 函数定义如下：
- en: '[PRE30]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The `create_sheet_space` function receives the start and end coordinates of
    the grid within one dimension along with the number of grid dimensions. Also,
    the *z* coordinate of the sheet is provided. Using the specified parameters, the
    preceding code creates the uniform linear space with coordinates starting in the `[start,
    stop]` range with a step of `dim`:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '`create_sheet_space` 函数接收一个维度内网格的起始和结束坐标以及网格维度的数量。同时，提供纸张的 *z* 坐标。使用指定的参数，前面的代码创建了一个以
    `[start, stop]` 范围开始，步长为 `dim` 的均匀线性空间：'
- en: '[PRE31]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'After that, we use this linear space to populate the two-dimensional array
    with the coordinates of the grid nodes as follows:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，我们使用这个线性空间如下填充二维数组，其中包含网格节点的坐标：
- en: '[PRE32]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The `create_sheet_space` function returns the grid configuration in the form
    of a two-dimensional array.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '`create_sheet_space` 函数以二维数组的形式返回网格配置。'
- en: Fitness evaluation
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 健身评估
- en: 'The genome''s fitness evaluation is a significant part of any neuroevolution
    algorithm, including the HyperNEAT method. As you''ve seen, the main experiment
    loop invokes the `eval_genomes` function to evaluate the fitness of all genomes
    within a population for each generation. Here, we consider the implementation
    details of the fitness evaluation routines, which consists of two main functions:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 基因组的适应性评估是任何神经进化算法，包括 HyperNEAT 方法的一个重要部分。正如你所看到的，主要实验循环调用 `eval_genomes` 函数来评估每一代种群中所有基因组的适应性。在这里，我们考虑了适应性评估例程的实现细节，它由两个主要函数组成：
- en: 'The `eval_genomes` function evaluates all genomes in the population:'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eval_genomes` 函数评估种群中的所有基因组：'
- en: '[PRE33]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The `eval_genomes` function takes a list of genomes, the discriminator ANN
    substrate configuration, the initialized test environment, and the ID of the current
    generation as parameters. The first lines of the function create intermediate
    variables, which are used to store the evaluation results:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '`eval_genomes` 函数接受一个基因组列表、判别器 ANN 底层配置、初始化的测试环境和当前代的 ID 作为参数。函数的前几行创建了一些中间变量，用于存储评估结果：'
- en: '[PRE34]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'After that, we iterate over all the genomes in the population and collect appropriate
    statistics:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，我们遍历种群中的所有基因组并收集适当的统计数据：
- en: '[PRE35]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Finally, the `eval_genomes` function returns the collected statistics as a tuple, `(best_genome,
    max_fitness, distances)`.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，`eval_genomes` 函数以元组的形式返回收集到的统计数据，`(best_genome, max_fitness, distances)`。
- en: 'The `eval_individual` function allows us to evaluate the fitness of the individual
    genome as follows:'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eval_individual` 函数允许我们如下评估单个基因组的适应性：'
- en: '[PRE36]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: In the beginning, the preceding source code creates the discriminator ANN phenotype
    using the CPPN genome provided as a parameter. After that, the discriminator ANN
    phenotype evaluated against the test environment.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始时，前面的源代码使用提供的 CPPN 基因创建判别器 ANN 表型。之后，判别器 ANN 表型在测试环境中进行评估。
- en: The `eval_individual` function returns the fitness score and error distance
    obtained from the test environment during the phenotype evaluation. Now that we
    have completed the setup, let us start with the visual discrimination experiment.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '`eval_individual` 函数返回在表型评估期间从测试环境中获得的适应度分数和误差距离。现在我们已经完成了设置，让我们开始进行视觉辨别实验。'
- en: Visual discrimination experiment
  id: totrans-189
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 视觉辨别实验
- en: Having done all of the necessary setup steps, we are ready to start the experiment.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 完成所有必要的设置步骤后，我们准备开始实验。
- en: 'In the visual discrimination experiment, we use the following configuration
    of the visual field:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在视觉辨别实验中，我们使用以下配置的视野：
- en: '| **Parameter** | **Value** |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| **参数** | **值** |'
- en: '| Size of the visual field | 11 x 11 |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| 视野大小 | 11 x 11 |'
- en: '| Positions of the small objects in the visual field along each axis | [1,
    3, 5, 7, 9] |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| 视野中每个轴上小物体的位置 | [1, 3, 5, 7, 9] |'
- en: '| Size of the small object | 1 x 1 |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| 小物体的大小 | 1 x 1 |'
- en: '| Size of the big object | 3 x 3 |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| 大物体的大小 | 3 x 3 |'
- en: '| Offset of the center of the big object from the small object | 5 |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| 大物体中心相对于小物体的偏移量 | 5 |'
- en: Next, we need to select the appropriate values of the HyperNEAT hyperparameters,
    allowing us to find a successful solution to the visual discrimination problem.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要选择合适的 HyperNEAT 超参数值，以便找到视觉辨别问题的成功解决方案。
- en: Note that the hyperparameter that we describe next determines how to evolve
    the connective CPPN using the neuroevolution process. The discriminator ANN is
    created by applying the connective CPPN to the substrate.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们接下来描述的超参数决定了如何使用神经进化过程进化连接的 CPPN。判别器 ANN 通过将连接的 CPPN 应用到基质中创建。
- en: Hyperparameter selection
  id: totrans-200
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 超参数选择
- en: 'The MultiNEAT library uses the `Parameters` Python class to hold all the required
    hyperparameters. To set the appropriate values of the hyperparameters, we define
    the `create_hyperparameters` function in the experiment runner Python script.
    Here, we describe the essential hyperparameters that have a significant impact
    on the HyperNEAT algorithm performance in this experiment:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: MultiNEAT 库使用 `Parameters` Python 类来保存所有必需的超参数。为了设置超参数的适当值，我们在实验运行器 Python 脚本中定义了
    `create_hyperparameters` 函数。在这里，我们描述了在这次实验中对 HyperNEAT 算法性能有重大影响的必要超参数：
- en: 'The `create_hyperparameters` function begins by creating a `Parameters` object to
    hold the HyperNEAT parameters:'
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`create_hyperparameters` 函数首先创建一个 `Parameters` 对象来保存 HyperNEAT 参数：'
- en: '[PRE37]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'We decided to start with a medium-sized population of genomes to keep the computations
    fast. At the same time, we want to maintain a sufficient number of organisms in
    the population for evolutionary diversity. The population size is defined as follows:'
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们决定从一个中等大小的基因组群体开始，以保持计算快速。同时，我们希望在群体中保持足够多的生物体以维持进化多样性。群体大小如下定义：
- en: '[PRE38]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'We are interested in producing compact CPPN genomes that have as few nodes
    as possible to increase the effectiveness of indirect encoding. Thus, we set a
    tiny probability of adding a new node during evolution, and also keep the probability
    of creating a new connection quite low:'
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们对产生尽可能少的节点的紧凑型 CPPN 基因组感兴趣，以增加间接编码的有效性。因此，我们在进化过程中设置了极小的添加新节点的概率，并且保持创建新连接的概率相当低：
- en: '[PRE39]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The HyperNEAT method produces CPPN genomes with different types of activation
    functions in the hidden and output nodes. Thus, we define the probability of mutation
    that changes the type of the node activation. Also, in this experiment, we are
    interested in using only four types of activation function: signed Gaussian, signed
    sigmoid, signed sine, and linear. We set the likelihood of choosing any activation
    type among the four we just mentioned to `1.0`, which effectively makes the probability
    of choosing each type equal. We define this in the hyperparameters as follows:'
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: HyperNEAT 方法在隐藏节点和输出节点中产生具有不同激活函数的 CPPN 基因组。因此，我们定义了改变节点激活类型变异的概率。此外，在这个实验中，我们只对使用四种类型的激活函数感兴趣：符号高斯、符号
    S 型、符号正弦和线性。我们将选择这四种激活类型中任何一种的概率设置为 `1.0`，这实际上使得选择每种类型的概率相等。我们如下定义了超参数：
- en: '[PRE40]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Finally, we define the number of species within the population to be kept in
    the `[5,10]` range and set the value of the species stagnation parameter to `100`
    generations. This configuration maintains moderate species diversity, but keeps
    species for long enough to allow them to evolve and produce useful CPPN genome
    configurations:'
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们定义种群中要保留的物种数量在`[5,10]`范围内，并将物种停滞参数的值设置为`100`代。此配置保持了适度的物种多样性，但足以让物种长时间存在，以便它们可以进化并产生有用的CPPN基因组配置：
- en: '[PRE41]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: The selection of hyperparameters presented here demonstrates the high efficiency
    of producing successful CPPN genomes during the evolution.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 这里展示的超参数选择展示了在进化过程中产生成功的CPPN基因组的效率之高。
- en: Working environment setup
  id: totrans-213
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作环境设置
- en: 'In this experiment, we use the MultiNEAT Python library, which provides the
    implementation of the HyperNEAT algorithm. Thus, we need to create an appropriate
    Python environment, which includes the MultiNEAT Python library and all the necessary
    dependencies. This can be done using Anaconda by executing the following commands
    in the command line:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个实验中，我们使用MultiNEAT Python库，它提供了HyperNEAT算法的实现。因此，我们需要创建一个合适的Python环境，这包括MultiNEAT
    Python库和所有必要的依赖项。这可以通过在命令行中执行以下命令使用Anaconda来完成：
- en: '[PRE42]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: These commands create and activate a `vd_multineat` virtual environment with
    Python 3.5\. After that, they install the latest version of the MultiNEAT Python
    library, along with the dependencies that are used by our code for the result
    visualization.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 这些命令创建并激活了一个`vd_multineat`虚拟环境，使用Python 3.5。之后，它们安装了MultiNEAT Python库的最新版本，以及我们代码用于结果可视化的依赖项。
- en: Running the visual discrimination experiment
  id: totrans-217
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行视觉判别实验
- en: 'To start the experiment, you need to enter the local directory that contains
    the `vd_experiment_multineat.py` script, and execute the following command:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始实验，你需要进入包含`vd_experiment_multineat.py`脚本的本地目录，并执行以下命令：
- en: '[PRE43]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Do not forget to activate the appropriate virtual environment with the following
    command:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 不要忘记使用以下命令激活适当的虚拟环境：
- en: '**`$ conda activate vd_multineat`**'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '**`$ conda activate vd_multineat`**'
- en: 'After a particular number of generations, the successful solution will be found,
    and you will see lines similar to the following in the console output:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 在经过特定代数之后，成功解决方案将被找到，你将在控制台输出中看到类似以下内容的行：
- en: '[PRE44]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: The console output says that the solution was found at generation `17`. The
    ID of the successful CPPN genome is `2565`, and this genome has 10 nodes and 16
    connections among them. Also, you can see the results of the evaluation of the
    discriminator ANN produced by the best CPPN genome against the randomly selected
    visual field.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 控制台输出表明解决方案在第`17`代找到。成功CPPN基因组的ID是`2565`，这个基因组有10个节点和它们之间的16个连接。你还可以看到由最佳CPPN基因组产生的判别器ANN对随机选择的视觉场的评估结果。
- en: In this case, the detected Cartesian coordinates of the big object in the target
    field and the actual coordinates in the visual field are the same (5, 1), which
    means that the solution found is capable of visual discrimination with exact precision.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，检测到的目标场中大型物体的笛卡尔坐标和视觉场中的实际坐标相同（5，1），这意味着找到的解决方案能够以精确的精度进行视觉判别。
- en: 'Next, it is interesting to take a look at the visualization of the activation
    outputs of the discriminator ANN obtained during test evaluation:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，查看在测试评估期间获得的判别器ANN的激活输出的可视化是非常有趣的：
- en: '![](img/c11a26be-bf38-494e-84a5-16ccf7802e91.png)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/c11a26be-bf38-494e-84a5-16ccf7802e91.png)'
- en: The target field activations of the discriminator ANN
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 判别器ANN的目标场激活
- en: The right part of the preceding plot renders the activation values of the target
    field (the output layer) of the discriminator ANN, which we obtained during evaluation
    against a random visual field. Also, in the left part of the plot, you can see
    the actual visual field configuration. As you can see, the maximum target field
    activation value (the darkest cell) is precisely at the same position as the center
    of the big object in the visual field, having the coordinates (`5`, `1`).
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 前一个图的右侧显示了在评估随机视觉场时获得的判别器ANN的目标字段（输出层）的激活值。同样，在图的左侧，你可以看到实际的视觉场配置。正如你所看到的，最大目标字段激活值（最暗的单元格）正好位于视觉场中大型物体的中心位置，坐标为（`5`，`1`）。
- en: 'As you can see from the preceding graph, the scale of ANN activation values
    is extremely low: the minimum activation is `~1e-13`, and the maximum is only
    `~9e-13`. A human-designed ANN would probably be normalized so that the output
    is on `[0,1]`, having a minimum close to zero and a maximum near one. However,
    we only require the activation to have a maximum in the right place, and the network
    is free to choose an output activation scheme that most folks would view as unusual.'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的图中可以看出，ANN激活值的尺度极低：最小激活值为`~1e-13`，最大值仅为`~9e-13`。一个由人类设计的ANN可能会进行归一化处理，使得输出在`[0,1]`范围内，最小值接近零，最大值接近一。然而，我们只要求激活值在正确的位置达到最大值，网络可以自由选择大多数人认为不寻常的输出激活方案。
- en: 'Another plot allows you to study how the evolution process performed over the
    generations of evolution and how good the produced connective CPPNs were in creating
    successful discriminator ANNs:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个图允许你研究进化过程中每一代的表现以及产生的连接CPPN在创建成功的判别ANN中的表现如何：
- en: '![](img/81b24e28-f535-46a1-ac00-c0303ae401a0.png)'
  id: totrans-232
  prefs: []
  type: TYPE_IMG
  zh: '![](img/81b24e28-f535-46a1-ac00-c0303ae401a0.png)'
- en: The best fitness scores and average error distances of discriminator ANNs
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 判别ANN的最佳适应度分数和平均误差距离
- en: The preceding plot renders the change in the fitness scores (the ascending line)
    and the average error distances (the descending line) for each generation of the
    evolution. You can see that the fitness scores almost reached the maximum value
    in the third generation of the evolution and needed seven more generations to
    elaborate over the CPPN genome configurations to finally find the winner. Also,
    you can see that the average error distance between the detected and the ground
    truth position of the big object gradually decreases during the evolution process.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的图显示了每一代进化过程中适应度分数（上升线）和平均误差距离（下降线）的变化。你可以看到，适应度分数在进化的第三代几乎达到了最大值，并且需要再经过七代来详细阐述CPPN基因配置，最终找到胜者。此外，你还可以看到，在进化过程中，检测到的物体位置与真实位置之间的平均误差距离逐渐减小。
- en: 'However, the most exciting part of this experiment is shown in the following
    diagram of the CPPN phenotype graph:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这个实验最激动人心的部分体现在以下CPPN表型图的图中：
- en: '![](img/e49c120b-23b9-443f-80ea-a456227ddb41.png)'
  id: totrans-236
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e49c120b-23b9-443f-80ea-a456227ddb41.png)'
- en: The CPPN phenotype graph of the best genome
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 最佳基因的CPPN表型图
- en: The plot demonstrates the network topology of the CPPN phenotype that was used
    to draw connections over the discriminator ANN producing the successful visual
    discriminator. In the CPPN phenotype plot, input nodes are marked with squares,
    output nodes are filled circles, and the bias node is a diamond.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 该图展示了用于在判别ANN上绘制连接的最佳CPPN表型网络拓扑。在CPPN表型图中，输入节点用方块标记，输出节点用实心圆圈标记，偏置节点用菱形标记。
- en: 'The two output nodes of the CPPN have the following meaning:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: CPPN的两个输出节点有以下含义：
- en: The first node (8) provides the weight of the connection.
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一个节点（8）提供连接的权重。
- en: The second node (9) determines whether the connection is expressed or not.
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二个节点（9）确定连接是否表达。
- en: 'The CPPN input nodes are defined as follows:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: CPPN输入节点定义如下：
- en: The first two nodes (0 and 1) set the point coordinates (*x*, *y*) in the input
    layer of the substrate.
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 前两个节点（0和1）在基底的输入层中设置点坐标（*x*，*y*）。
- en: The next two nodes (2 and 3) set the point coordinates (*x*, *y*) in the hidden
    layer of the substrate (not used in our experiment).
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接下来的两个节点（2和3）在基底的隐藏层中设置点坐标（*x*，*y*）（在我们的实验中未使用）。
- en: The next two nodes (4 and 5) set the point coordinates (*x*, y) in the output
    layer of the substrate.
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接下来的两个节点（4和5）在基底的输出层中设置点坐标（*x*，*y*）。
- en: The last node (6) sets the Euclidean distance from the point in the input layer
    from the origin of the coordinates.
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后一个节点（6）设置输入层中点与坐标原点的欧几里得距离。
- en: Also, you can see that the CPPN phenotype doesn't include any hidden nodes.
    For the visual discrimination task, the neuroevolutionary process was able to
    find the appropriate activation function types for the output nodes of the CPPN.
    This finding allows the connective CPPN to draw the correct connectivity patterns
    within the substrate of the discriminator ANN.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，你还可以看到CPPN表型中不包含任何隐藏节点。对于视觉判别任务，神经进化过程能够找到适合CPPN输出节点的适当激活函数类型。这一发现使得连接CPPN能够在判别ANN的基底中绘制正确的连接模式。
- en: By counting the number of nodes and connections between them as presented in
    the preceding plot, you can feel the power of the indirect encoding method introduced
    by the HyperNEAT algorithm. With only 16 connections between 10 nodes, the CPPN
    phenotype was able to expose the connectivity pattern of the substrate, which
    for the visual field at 11 x 11 resolution can have up to 14,641 connections between
    the nodes in the visual field and the target field. So, we achieved an information
    compression ratio of about 0.11%, which is pretty impressive.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 通过计算前述图中节点和它们之间的连接数量，您可以感受到HyperNEAT算法引入的间接编码方法的威力。仅用10个节点之间的16个连接，CPPN表型就能揭示底物的连接模式，对于11
    x 11分辨率的视觉场，节点之间和目标场之间的连接数最多可达14,641个。因此，我们实现了大约0.11%的信息压缩率，这相当令人印象深刻。
- en: Such a high compression rate is possible because of the discovery of the geometric
    regularities within the connectivity motifs of the substrate by the connective
    CPPN. Using the regularities of the discovered patterns, the CPPN can store only
    a few patterns (local connectivity motifs) for the whole connectivity space of
    the substrate. After that, the CPPN can apply these local patterns multiple times
    at different substrate positions to draw the full connectivity scheme between
    the substrate layers, in our case, to draw connections between the input layer
    (visual field) and the output layer (target field).
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 这样高的压缩率是由于连接CPPN在底物连接基元中发现了几何规律。利用发现的模式规律，CPPN只需存储整个底物连接空间中的少量模式（局部连接基元），然后可以在不同的底物位置多次应用这些局部模式，以绘制底物层之间的完整连接方案。在我们的案例中，是为了绘制输入层（视觉场）和输出层（目标场）之间的连接。
- en: Exercises
  id: totrans-250
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 练习
- en: Try to decrease the value of the `params.PopulationSize` hyperparameter and
    see what happens. How did this affect the algorithm's performance?
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 尝试降低`params.PopulationSize`超参数的值，看看会发生什么。这对算法的性能有何影响？
- en: Try to set zero probabilities for the values of the following hyperparameters: `params.ActivationFunction_SignedGauss_Prob`,
    `params.ActivationFunction_SignedSigmoid_Prob`, and `params.ActivationFunction_SignedSine_Prob`.
    Was a successful solution found with these changes? How did this affect the configuration
    of the substrate connections?
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 尝试将以下超参数的值设置为0概率：`params.ActivationFunction_SignedGauss_Prob`、`params.ActivationFunction_SignedSigmoid_Prob`和`params.ActivationFunction_SignedSine_Prob`。这些更改是否找到了成功的解决方案？这对底物连接的配置有何影响？
- en: Print out the winning genome, try to come up with a visualization, then see
    how your intuition from looking at the genome matches with the visualized CPPN.
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印出获胜的基因组，尝试创建一个可视化，然后看看您从基因组中获得的直观感受与可视化的CPPN是否匹配。
- en: Summary
  id: totrans-254
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we learned about the method of indirect encoding of the ANN
    topology using CPPNs. You learned about the HyperNEAT extension of the NEAT algorithm,
    which uses a connective CPPN to draw connectivity patterns within the substrate
    of the phenotype of the discriminator ANN. Also, we demonstrated how the indirect
    encoding scheme allows the HyperNEAT algorithm to work with large-scale ANN topologies,
    which is common in pattern recognition and visual discrimination tasks.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了使用CPPN间接编码ANN拓扑结构的方法。您了解了NEAT算法的HyperNEAT扩展，该扩展使用连接CPPN在判别器ANN的表型底物中绘制连接模式。我们还展示了间接编码方案如何使HyperNEAT算法能够处理大规模ANN拓扑结构，这在模式识别和视觉辨别任务中很常见。
- en: With the theoretical background we provided, you have had the chance to improve
    your coding skills by implementing the solution for a visual discrimination task
    using Python and the MultiNEAT library. Also, you learned about a new visualization
    method that renders the activation values of the nodes in the output layer of
    the discriminator ANN and how this visualization can be used to verify the solution.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们提供的理论背景下，您有机会通过使用Python和MultiNEAT库实现视觉辨别任务的解决方案来提高您的编码技能。此外，您还了解了一种新的可视化方法，该方法可以渲染判别器ANN输出层中节点的激活值，以及如何使用这种可视化来验证解决方案。
- en: In the next chapter, we will discuss how the HyperNEAT method can be further
    improved by introducing an automatic way to generate the appropriate substrate
    configuration. We will consider the **Evolvable Substrate HyperNEAT** (**ES-HyperNEAT**)
    extension of the NEAT algorithm and see how it can be applied to solve practical
    tasks that require the modular topologies of the solver ANN.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将讨论如何通过引入一种自动生成适当基板配置的方法来进一步改进HyperNEAT方法。我们将考虑NEAT算法的**可进化基板HyperNEAT**（**ES-HyperNEAT**）扩展，并看看它如何应用于解决需要求解器ANN模块化拓扑结构的实际任务。
