- en: <st c="0">4</st>
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="2">Components of a RAG System</st>
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="28">When you’re developing</st> <st c="52">with</st> **<st c="57">retrieval-augmented
    generation</st>** <st c="87">(</st>**<st c="89">RAG</st>**<st c="92">), it is
    essential to understand the intricacies of each component, how they can be integrated,
    and the technologies that empower</st> <st c="223">these systems.</st>
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: <st c="237">In this chapter, we will cover the</st> <st c="273">following topics:</st>
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: <st c="290">Key</st> <st c="295">component overview</st>
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="313">Indexing</st>
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="322">Retrieval</st> <st c="333">and generation</st>
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="347">Prompting</st>
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="357">Defining</st> <st c="367">your LLM</st>
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="375">User</st> <st c="381">interface (UI)</st>
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="395">Evaluation</st>
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="406">These topics should provide you with a comprehensive understanding
    of the key components representing a</st> <st c="511">RAG application.</st>
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: <st c="527">Technical requirements</st>
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="550">The code for this chapter is placed in the following GitHub</st>
    <st c="611">repository:</st> [<st c="623">https://github.com/PacktPublishing/Unlocking-Data-with-Generative-AI-and-RAG/tree/main/Chapter_04</st>](https://github.com/PacktPublishing/Unlocking-Data-with-Generative-AI-and-RAG/tree/main/Chapter_04)
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: <st c="720">Key component overview</st>
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="743">This chapter delves</st> <st c="763">into the intricate components
    that make up a RAG system.</st> <st c="821">Let’s start with an overview of the</st>
    <st c="857">entire system.</st>
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: <st c="871">In</st> [*<st c="875">Chapter 1</st>*](B22475_01.xhtml#_idTextAnchor015)<st
    c="884">, we introduced the three main stages of the RAG system from a technical
    standpoint (see</st> *<st c="973">Figure 4</st>**<st c="981">.1</st>*<st c="983">):</st>
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: '**<st c="986">Indexing</st>**'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**<st c="995">Retrieval</st>**'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**<st c="1005">Generation</st>**'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 4.1 – The three stages of a RAG system](img/B22475_04_01.jpg)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
- en: <st c="1095">Figure 4.1 – The three stages of a RAG system</st>
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: <st c="1140">We will continue to build off this concept, but we will also introduce
    the practical aspects of development that are required for building an application.</st>
    <st c="1296">These include prompting, defining</st> <st c="1330">your</st> **<st
    c="1335">large language model</st>** <st c="1355">(</st>**<st c="1357">LLM</st>**<st
    c="1360">), the UI, and an evaluation component.</st> <st c="1401">Later</st>
    <st c="1406">chapters will cover each of those areas even further.</st> <st c="1461">All
    of this will be done with code so that you can tie the conceptual framework we’ll
    discuss directly with the implementation.</st> <st c="1589">Let’s start</st> <st
    c="1601">with indexing.</st>
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: <st c="1615">Indexing</st>
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="1624">The first stage in</st> <st c="1643">the RAG system we will examine
    more closely is indexing.</st> <st c="1701">Note</st> <st c="1705">that we are
    skipping the setup, where we install and import packages, as well as set up OpenAI
    and related accounts.</st> <st c="1823">That is a typical step in every generative
    artificial intelligence (AI) project, not just RAG systems.</st> <st c="1926">We
    provided a thorough setup guide in</st> [*<st c="1964">Chapter 2</st>*](B22475_02.xhtml#_idTextAnchor035)<st
    c="1973">, so jump back there if you want to review the libraries we’ve added
    to support these</st> <st c="2059">next steps.</st>
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: <st c="2070">Indexing occurs as the first main stage of RAG.</st> <st c="2119">As</st>
    *<st c="2122">Figure 4</st>**<st c="2130">.2</st>* <st c="2132">indicates, it
    is the step after the</st> <st c="2169">user query:</st>
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 4.2 – The \uFEFFIndexing stage of RAG highlighted](img/B22475_04_02.jpg)"
  id: totrans-26
  prefs: []
  type: TYPE_IMG
- en: <st c="2254">Figure 4.2 – The Indexing stage of RAG highlighted</st>
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: <st c="2304">In our code from</st> [*<st c="2322">Chapter 2</st>*](B22475_02.xhtml#_idTextAnchor035)<st
    c="2331">,</st> *<st c="2333">Indexing</st>* <st c="2341">is the</st> <st c="2348">first
    section of code you see.</st> <st c="2380">This is the step where the data you
    are introducing to the RAG system is processed.</st> <st c="2464">As you can see
    in the code, the</st> *<st c="2496">data</st>* <st c="2500">in this scenario is
    the web document that is being loaded by</st> `<st c="2562">WebBaseLoader</st>`<st
    c="2575">. This is</st> <st c="2584">the beginning of that document (</st>*<st
    c="2617">Figure 4</st>**<st c="2626">.3</st>*<st c="2628">):</st>
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.3 – The web page that we process](img/B22475_04_03.jpg)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
- en: <st c="5490">Figure 4.3 – The web page that we process</st>
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: <st c="5531">In</st> [*<st c="5535">Chapter 2</st>*](B22475_02.xhtml#_idTextAnchor035)<st
    c="5544">, you may have noticed that the code in the latter stages,</st> *<st
    c="5603">Retrieval</st>* <st c="5612">and</st> *<st c="5617">Generation</st>*<st
    c="5627">, is used after the user query is passed to the chain.</st> <st c="5682">This
    is done in</st> *<st c="5698">real time</st>*<st c="5707">, meaning that it happens
    at the time that the user interacts with it.</st> <st c="5778">Indexing, on the
    other hand, typically happens well before the user interacts with the RAG application.</st>
    <st c="5882">This aspect of indexing makes it a very different step from the other
    two stages, with the flexibility of being run at a different time than when the
    application is used.</st> <st c="6053">This is</st> <st c="6061">called</st> **<st
    c="6068">pre-processing offline</st>**<st c="6090">, meaning that this step is
    done before the user has even opened the application.</st> <st c="6172">There
    are instances where indexing can be done in real time as well, but that is much
    less common.</st> <st c="6271">For now, we will focus on the much more common
    step of</st> <st c="6326">pre-processing offline.</st>
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: <st c="6349">The</st> <st c="6353">following</st> <st c="6363">code</st> <st
    c="6368">is our</st> **<st c="6376">document extraction</st>**<st c="6395">:</st>
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: <st c="6602">In this extract, we are ingesting a web page.</st> <st c="6649">But
    imagine if this was pulling data in from a PDF or Word document, or other forms
    of unstructured data.</st> <st c="6755">As discussed in</st> [*<st c="6771">Chapter
    3</st>*](B22475_03.xhtml#_idTextAnchor056)<st c="6780">, unstructured data is
    a very popular data format in RAG applications.</st> <st c="6851">Historically,
    unstructured data has been very difficult for companies to access relative to
    structured data (from SQL databases and similar applications).</st> <st c="7006">But
    RAG has changed all of this, and companies are finally realizing how to significantly
    tap into this data.</st> <st c="7116">We will review how to access other types
    of data</st> <st c="7164">using</st> **<st c="7171">document loaders</st>** <st
    c="7187">in</st> [*<st c="7191">Chapter 11</st>*](B22475_11.xhtml#_idTextAnchor229)
    <st c="7201">and how to do it</st> <st c="7219">with LangChain.</st>
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: <st c="7234">Regardless of what type of data you are pulling in, it all goes
    through a similar process, as shown in</st> *<st c="7338">Figure 4</st>**<st c="7346">.4</st>*<st
    c="7348">:</st>
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.4 – Creating a retriever in the Indexing stage of the RAG process](img/B22475_04_04.jpg)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
- en: <st c="7404">Figure 4.4 – Creating a retriever in the Indexing stage of the
    RAG process</st>
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: '<st c="7478">The document loader from the code fills the</st> **<st c="7523">Documents</st>**
    <st c="7532">component of this so that they can be retrieved later using the user
    query.</st> <st c="7609">But in most RAG applications, you must turn that data
    into a more searchable format: vectors.</st> <st c="7703">We will talk more about
    vectors in a moment, but first, to get your data into vector format, you must</st>
    <st c="7805">apply</st> **<st c="7811">splitting</st>**<st c="7820">. In our code,
    that is</st> <st c="7843">this section:</st>'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: <st c="7953">Splitting breaks your content into digestible chunks that can be
    vectorized.</st> <st c="8031">Different vectorization algorithms have different
    requirements for the maximum size of the content</st> <st c="8129">you can</st>
    <st c="8138">pass.</st> <st c="8144">In this case, we are using the</st> `<st
    c="8175">OpenAIEmbeddings()</st>` <st c="8193">vectorizer, which currently has
    a max input of</st> `<st c="8241">8191</st>` <st c="8245">tokens.</st>
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: <st c="8253">Note</st>
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: <st c="8258">In the OpenAI API, the text is tokenized using a byte-level</st>
    **<st c="8319">byte pair encoding</st>** <st c="8337">(</st>**<st c="8339">BPE</st>**<st
    c="8342">) vocabulary.</st> <st c="8357">This means the raw text is split</st>
    <st c="8389">into subword tokens rather than individual characters.</st> <st c="8445">The
    number of tokens that are consumed for a given input text depends on the specific
    content as common words and subwords are represented by single tokens while less
    common words may be split into multiple tokens.</st> <st c="8660">On average,
    one token is approximately four characters for English text.</st> <st c="8733">However,
    this is just a rough estimate and can vary significantly based on the specific
    text.</st> <st c="8827">For example, short words such as</st> *<st c="8860">a</st>*
    <st c="8861">or</st> *<st c="8865">the</st>* <st c="8868">would be a single token,
    while a long, uncommon word might be split into</st> <st c="8942">several tokens.</st>
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: <st c="8957">These digestible chunks need to be smaller than that</st> `<st
    c="9011">8191</st>` <st c="9015">token limit, and other embedding services have
    their token limits.</st> <st c="9083">If you’re using a splitter that defines
    a chunk size and a chunk overlap, keep the chunk overlap in mind for that token
    limit as well.</st> <st c="9218">You have to add that overlap to the overall chunk
    size to be able to determine how large that chunk is.</st> <st c="9322">Here is
    an example o</st><st c="9342">f using a</st> `<st c="9409">1000</st>` <st c="9413">and
    the chunk overlap</st> <st c="9436">is</st> `<st c="9439">200</st>`<st c="9442">:</st>
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: <st c="9573">Expanding the chunk overlap is a common approach to ensuring that
    no context is lost between chunks.</st> <st c="9675">For example, if a chunk happens
    to cut an address in half in a legal document, it is unlikely you will find that
    address if you search for it.</st> <st c="9818">But with chunk overlap, you can
    account for issues like that.</st> <st c="9880">We will review various splitter
    options, including the</st> <st c="9935">recursive</st> <st c="9944">character</st>
    `<st c="9955">TextSplitter</st>` <st c="9967">in LangChain in</st> [*<st c="9984">Chapter
    11</st>*](B22475_11.xhtml#_idTextAnchor229)<st c="9994">.</st>
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: <st c="9995">The last part of the</st> *<st c="10017">Indexing</st>* <st c="10025">stage
    is defining the vector store and adding the embeddings, built from your data splits
    to that vector store.</st> <st c="10138">You see it here in</st> <st c="10157">this
    code:</st>
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: <st c="10291">In this case, we use</st> `<st c="10712">OpenAIEmbeddings</st>`
    <st c="10728">API is just one of many vectorizing algorithms that can be used
    here as well.</st> <st c="10807">We will dive into this topic in more detail in</st>
    *<st c="10854">Chapters 7</st>* <st c="10864">and</st> *<st c="10869">8</st>*
    <st c="10870">when we discuss vectors, vector stores, and</st> <st c="10915">vector
    searches.</st>
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: <st c="10931">Going back to our diagram of the</st> *<st c="10965">Indexing</st>*
    <st c="10973">process,</st> *<st c="10983">Figure 4</st>**<st c="10991">.5</st>*
    <st c="10993">is an even more accurate representation of what it</st> <st c="11045">looks
    like:</st>
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.5 – Vectors during the Indexing stage of the RAG process](img/B22475_04_05.jpg)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
- en: <st c="11246">Figure 4.5 – Vectors during the Indexing stage of the RAG process</st>
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: <st c="11311">You might be wondering why we aren’t calling the step where we
    define the</st> *<st c="11386">retriever</st>* <st c="11395">a part of the</st>
    *<st c="11410">Retrieval</st>* <st c="11419">step.</st> <st c="11426">This is
    because we are establishing this as the mechanism that we retrieve from, but we
    do not apply the retrieval until later during the retrieval step as a result of
    the user submitting their user query.</st> <st c="11632">The</st> *<st c="11636">Indexing</st>*
    <st c="11644">step focuses on building the infrastructure that the other two steps
    work from, and we are indeed indexing the data so</st> <st c="11763">that it can
    be retrieved later.</st> <st c="11796">At the end of this part of the</st> <st
    c="11826">code, you have a retriever ready and waiting to receive a user query
    when the process starts.</st> <st c="11921">Let’s talk about the parts of the
    code that will use this retriever – the retrieval and</st> <st c="12009">generation
    steps!</st>
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: <st c="12026">Retrieval and generation</st>
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="12051">In our RAG application code, we have combined the</st> *<st c="12102">Retrieval</st>*
    <st c="12111">and</st> *<st c="12116">Generation</st>* <st c="12126">stages.</st>
    <st c="12135">From a diagram standpoint, this looks like what’s shown in</st>
    *<st c="12194">Figure 4</st>**<st c="12202">.6</st>*<st c="12204">:</st>
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.6 – Vectors during the Indexing stage of the RAG process](img/B22475_04_06.jpg)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
- en: <st c="12278">Figure 4.6 – Vectors during the Indexing stage of the RAG process</st>
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: <st c="12343">While retrieval and generation are two separate stages serving
    two important functions of the RAG application, they are combined in our code.</st>
    <st c="12486">When we invoke</st> `<st c="12501">rag_chain</st>` <st c="12510">as
    the last step, it is stepping through both of these stages, making them difficult
    to separate when talking about the code.</st> <st c="12637">But conceptually,
    we will separate them here, and then show how they pull them together to process
    the user query and provide an intelligent generative AI response.</st> <st c="12802">Let’s
    start with the</st> <st c="12823">retrieval step.</st>
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: <st c="12838">Retrieval focused steps</st>
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="12862">In the</st> <st c="12869">complete</st> <st c="12879">code (which
    can be found in</st> [*<st c="12907">Chapter 2</st>*](B22475_02.xhtml#_idTextAnchor035)<st
    c="12916">), there are only two areas in this code where actual retrieval takes
    place or is processed.</st> <st c="13010">This is</st> <st c="13018">the first:</st>
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: <st c="13122">The second can be found as the first step within the</st> <st
    c="13176">RAG chain:</st>
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: <st c="13258">When the code is initiated, it runs in</st> <st c="13298">this
    order:</st>
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: <st c="13367">The chain is invoked with the user query and runs through the
    steps we defined in the</st> <st c="13454">chain here:</st>
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: <st c="13588">With this chain, the user query is passed to the first link, which
    passes that user query into the retriever we defined earlier, where it performs
    a similarity search to match the user query against the other data in the vector
    store.</st> <st c="13824">At this point, we have a retrieved list of content strings
    that is contextually similar to the</st> <st c="13919">user query.</st>
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: <st c="13930">However, as shown in</st> [*<st c="13952">Chapter 2</st>*](B22475_02.xhtml#_idTextAnchor035)<st
    c="13961">, there is a bit of a glitch in our retrieval steps due to the formatting
    of the tools we are using.</st> <st c="14062">The</st> `<st c="14066">{question}</st>`
    <st c="14076">and</st> `<st c="14081">{context}</st>` <st c="14090">placeholders
    both expect strings, but the retrieval mechanism we use to fill in the context
    is a long list of separate content strings.</st> <st c="14227">We need a mechanism
    to turn that list of content pieces</st> <st c="14282">into</st> <st c="14287">the
    string format that the prompt in the next chain link</st> <st c="14345">is expecting.</st>
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: <st c="14358">So, if you look closely at the code for the retriever, you may
    notice that the retriever is actually in a mini-chain (</st>`<st c="14477">retriever
    | format_docs</st>`<st c="14501">), indicated by the pipe (</st>`<st c="14528">|</st>`<st
    c="14530">) symbol, so the output of the retriever is passed right into the</st>
    `<st c="14596">format_docs</st>` <st c="14607">function</st> <st c="14617">shown
    here:</st>
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: <st c="14704">Let’s consider this a post-processing step in the</st> *<st c="14755">Retrieval</st>*
    <st c="14764">stage.</st> <st c="14772">The data has been retrieved, but it is
    not in the right format, so we are not done.</st> <st c="14856">The</st> `<st
    c="14860">format_docs</st>` <st c="14871">function completes the task and returns
    our content in the</st> <st c="14931">proper format.</st>
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: <st c="14945">However, this only provides us with</st> `<st c="14982">{context}</st>`<st
    c="14991">, one of the input variable placeholders.</st> <st c="15033">The other
    placeholder we need to hydrate our prompt is the</st> `<st c="15092">{question}</st>`
    <st c="15102">placeholder.</st> <st c="15116">However, we do not have the same
    formatting problem with the</st> *<st c="15177">question</st>* <st c="15185">that
    we had with the</st> *<st c="15207">context</st>* <st c="15214">since the</st>
    *<st c="15225">question</st>* <st c="15233">is already a string.</st> <st c="15255">So,
    we can use a convenient object called</st> `<st c="15297">RunnablePassThrough</st>`
    <st c="15316">that, as its name suggests, passes the input (the</st> *<st c="15367">question</st>*<st
    c="15375">)</st> <st c="15378">through as-is.</st>
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: <st c="15392">If you take the entire first chain link in its entirety, this
    is essentially performing the retrieval step, formatting its output, and pulling
    it all together in the proper format to pass on to the</st> <st c="15591">next
    step:</st>
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: <st c="15673">But wait a minute.</st> <st c="15693">If you’re doing a vector
    search, you need to convert the user query into a vector, right?</st> <st c="15783">Did
    we not say that we are taking the mathematical representation of the user query
    and measuring the distance to other vectors, finding which ones are closer?</st>
    <st c="15943">So, where does that happen?</st> <st c="15971">The retriever was
    created from a method of the</st> <st c="16018">vector store:</st>
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: <st c="16070">The vector store that this was generated from is a Chroma vector
    database that was declared</st> <st c="16163">using</st> <st c="16168">the</st>
    `<st c="16173">OpenAIEmbeddings()</st>` <st c="16191">object as its</st> <st c="16206">embedding
    function:</st>
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: <st c="16310">That</st> `<st c="16316">.as_retriever()</st>` <st c="16331">method
    has all of the functionality built in to take that user query, convert it into
    an embedding that matches the embedding format of the other embeddings, and then
    run the</st> <st c="16507">retrieval process.</st>
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: <st c="16525">Note</st>
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: <st c="16530">Because this is using the</st> `<st c="16557">OpenAIEmbeddings()</st>`
    <st c="16575">object, it sends your embeddings to the OpenAI API and you will
    incur charges from this.</st> <st c="16665">In this case, it is just one embedding;
    with OpenAI, this currently costs $0.10 per 1M tokens.</st> <st c="16760">So,
    for the</st> `<st c="16772">What are the Advantages of using RAG?</st>` <st c="16809">input,
    which is ten tokens according to OpenAI, this is going to cost a whopping $0.000001\.</st>
    <st c="16902">That may not seem like a lot, but we want to be completely transparent
    when there is any</st> <st c="16991">cost involved!</st>
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: <st c="17005">That concludes our</st> *<st c="17025">Retrieval</st>* <st c="17034">stage,
    with an output that is properly formatted for the next step – the prompt!</st>
    <st c="17116">Next, we’ll discuss the</st> *<st c="17140">Generation</st>* <st
    c="17150">stage, where we utilize the LLM to take the</st> <st c="17194">final</st>
    <st c="17200">step of generating</st> <st c="17220">a response.</st>
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: <st c="17231">Generation stage</st>
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="17248">The</st> *<st c="17253">Generation</st>* <st c="17263">stage is</st>
    <st c="17272">the final stage and is where you will use</st> <st c="17314">the
    LLM to generate the response to the user query based on the content you retrieved
    in the</st> *<st c="17408">Retrieval</st>* <st c="17417">stage.</st> <st c="17425">But
    before we can do this, we have to do a little bit of preparation work.</st> <st
    c="17500">Let’s walk</st> <st c="17511">through this.</st>
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: <st c="17524">Overall, the</st> *<st c="17538">Generation</st>* <st c="17548">stage
    is represented by two parts of the code, starting with</st> <st c="17610">the
    prompt:</st>
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: <st c="17664">Then, we have</st> <st c="17679">the LLM:</st>
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: <st c="17740">With the prompt and LLM defined, these components are used in
    the</st> <st c="17807">RAG chain:</st>
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: <st c="17832">Note that the</st> `<st c="17847">question</st>` <st c="17855">section
    was bolded in both the</st> *<st c="17887">Retrieval</st>* <st c="17896">and the</st>
    *<st c="17905">Generation</st>* <st c="17915">stages.</st> <st c="17924">We already
    noted how it is used in the</st> *<st c="17963">Retrieval</st>* <st c="17972">stage
    as the basis for what the similarity search is run against.</st> <st c="18039">Now,
    we will show how it is used again when integrating it into a prompt that is fed
    to the LLM</st> <st c="18135">for generation.</st>
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: <st c="18150">Prompting</st>
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**<st c="18160">Prompts</st>** <st c="18168">are a</st> <st c="18174">fundamental
    part of any generative AI application, not</st> <st c="18229">just RAG.</st> <st
    c="18240">When you start talking about prompts, particularly with RAG, you know
    LLMs are going to be involved soon after.</st> <st c="18352">But first, you must
    create and prepare a proper prompt for our LLM.</st> <st c="18420">In theory,
    you could write your prompt, but I wanted to take this chance to teach you this
    very common development pattern and get you used to using it when you need it.</st>
    <st c="18590">In this example, we’ll pull the prompt</st> <st c="18629">from the</st>
    **<st c="18638">LangChain Hub</st>**<st c="18651">.</st>'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: <st c="18652">LangChain describes its Hub as a place to “</st>*<st c="18696">discover,
    share, and version control prompts.</st>*<st c="18742">” Other users of the hub
    have shared their polished prompts here, making it easier for you to build off
    common knowledge.</st> <st c="18865">It is a good way to start with prompts, pulling
    down pre-designed prompts and seeing how they are written.</st> <st c="18972">But
    you will eventually want to move on to writing your own, more</st> <st c="19038">customized
    prompts.</st>
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: <st c="19057">Let’s talk about what the purpose of this prompt is in terms of
    the retrieval process.</st> <st c="19145">The “prompt” is the next link in the
    chain after the Retrieval stage we just discussed.</st> <st c="19233">You can
    see it here</st> <st c="19253">in</st> `<st c="19256">rag_chain</st>`<st c="19265">:</st>
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: <st c="19390">Staying true to the LangChain pattern, the inputs of the prompt
    are the outputs of the previous step.</st> <st c="19493">You can see these inputs
    at any time by printing them out</st> <st c="19551">like this:</st>
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: <st c="19627">This results in the</st> <st c="19648">following output:</st>
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: <st c="19689">This matches what we defined in the</st> <st c="19726">previous
    step:</st>
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: <st c="19816">Printing out the entire prompt object, using</st> `<st c="19862">print(prompt)</st>`<st
    c="19875">, shows that there is much more than just the text prompt and</st> <st
    c="19937">input variables:</st>
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: <st c="20341">Let’s unravel this a bit further, starting with the input variables.</st>
    <st c="20411">These are the variables we just discussed, that this particular
    prompt takes as input.</st> <st c="20498">These can vary depending on the prompt.</st>
    <st c="20538">There is a</st> `<st c="20549">messages []</st>` <st c="20560">list,
    but in this case, there is only one message in the list.</st> <st c="20624">This
    message is an instance of</st> `<st c="20655">HumanMessagePromptTemplate</st>`<st
    c="20681">, which represents a specific type of message template.</st> <st c="20737">It</st>
    <st c="20739">is</st> <st c="20743">initialized with a</st> `<st c="20762">PromptTemplate</st>`
    <st c="20776">object.</st> <st c="20785">The</st> `<st c="20789">PromptTemplate</st>`
    <st c="20803">object is created with the specified</st> `<st c="20841">input_variables</st>`
    <st c="20856">and a template string.</st> <st c="20880">Again,</st> `<st c="20887">input_variables</st>`
    <st c="20902">are</st> `<st c="20907">context</st>` <st c="20914">and</st> `<st
    c="20919">question</st>`<st c="20927">, and you can see where they are placed
    in the</st> `<st c="20974">template</st>` <st c="20982">string:</st>
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: <st c="21235">The</st> `<st c="21240">{question}</st>` <st c="21250">and</st>
    `<st c="21255">{context}</st>` <st c="21264">placeholders will be replaced with
    the actual values of the</st> `<st c="21325">question</st>` <st c="21333">and</st>
    `<st c="21338">context</st>` <st c="21345">variables when the prompt is used in
    the chain.</st> <st c="21394">The output of this chain link is the string template
    that was filled in with</st> `<st c="21471">{question}</st>` <st c="21481">and</st>
    `<st c="21486">{context}</st>` <st c="21495">from the previous</st> <st c="21514">retrieval
    step.</st>
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: <st c="21529">The last part is simply</st> `<st c="21554">Answer:</st>` <st
    c="21561">with nothing after that.</st> <st c="21587">This prompts the LLM for
    an answer and is a prevalent pattern that works well for LLM interactions to elicit</st>
    <st c="21696">an answer.</st>
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: <st c="21706">In short, a prompt is an object that is plugged into your LangChain
    chain with inputs to fill a prompt template, generating the prompt that you will
    pass to an LLM for inference.</st> <st c="21886">This is essentially a</st> <st
    c="21907">preparation stage for the</st> *<st c="21934">Generation</st>* <st c="21944">stage
    of the</st> <st c="21958">RAG</st> <st c="21961">system.</st>
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: <st c="21969">In the next step, we will pull in the LLM, the brains behind the</st>
    <st c="22035">whole operation!</st>
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: <st c="22051">Defining your LLM</st>
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="22069">With the prompt</st> <st c="22086">template selected, we can select
    an LLM, a central component for any RAG application.</st> <st c="22172">The following
    code shows the LLM model as the next chain link</st> <st c="22234">in</st> `<st
    c="22237">rag_chain</st>`<st c="22246">:</st>
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: <st c="22371">As discussed previously, the output of the previous step, which
    was the</st> `<st c="22444">prompt</st>` <st c="22450">object, is going to be
    the input of the next step, the LLM.</st> <st c="22511">In this case, the prompt
    will</st> *<st c="22541">pipe</st>* <st c="22545">right into the LLM with the
    prompt we generated in the</st> <st c="22601">previous step.</st>
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: <st c="22615">Above</st> `<st c="22622">rag_chain</st>`<st c="22631">, we define
    the LLM we want</st> <st c="22659">to use:</st>
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: <st c="22719">This is creating an instance of the</st> `<st c="22756">ChatOpenAI</st>`
    <st c="22766">class from the</st> `<st c="22782">langchain_openai</st>` <st c="22799">module,
    which serves as an interface to OpenAI’s language models, specifically the GPT-4o
    model.</st> <st c="22896">LLMs are typically fed a prompt using the invoke method,
    and you could call this directly in the code here by adding</st> <st c="23013">the
    following:</st>
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: <st c="23148">Doing it this way, you are asking the LLM directly for</st> <st
    c="23204">the answer.</st>
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: <st c="23215">If you run the preceding code, it will give you the response from
    GPT-4o, which will know about RAG.</st> <st c="23317">But for comparison, what
    if we changed it to GPT3.5?</st> <st c="23370">Here is the response I received
    when using</st> <st c="23413">ChatGPT 3.5:</st>
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: <st c="23930">Uh-oh!</st> <st c="23938">ChatGPT 3.5 doesn’t know about RAG!</st>
    <st c="23974">At least not in the context we are talking about.</st> <st c="24024">This
    highlights the value of using RAG to add your data.</st> <st c="24081">The most
    recent cutoff date for ChatGPT 3.5 was January 2022\.</st> <st c="24143">The generative
    AI-focused concept of RAG must not have been popular enough for it to instantly
    know what I was referring to with the</st> <st c="24276">RAG acronym.</st>
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: <st c="24288">Using RAG, we can</st> <st c="24307">augment its knowledge and
    utilize the LLM’s other skills of summarizing and finding data to have a more
    successful result overall.</st> <st c="24438">But try changing this to the question</st>
    `<st c="24476">answering in less than 100 words, what are the Advantages of using
    Retrieval Augmented Generation (RAG)?</st>` <st c="24580">and see what results
    you can get.</st> <st c="24615">Try it with a newer model that likely has more
    information about RAG applications in its training data.</st> <st c="24719">You
    will likely get a better response because the data that the LLM was trained on
    has a more recent</st> <st c="24820">cutoff date!</st>
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: '<st c="24832">But instead of calling the LLM directly, we pass it the prompt
    we have structured using the</st> *<st c="24925">Retrieval</st>* <st c="24934">stage
    and can get a much more informed answer.</st> <st c="24982">You could end the
    chain here and the output of your chain would be what’s returned from the LLM.</st>
    <st c="25079">In most cases, this is not just the text you might see when you
    type something into ChatGPT – it is in JSON format and has a lot of other data
    included with it.</st> <st c="25240">So, if you want a nicely formatted string
    output reflecting the LLM’s response, you have one more chain link to pipe the
    LLM response into: the</st> `<st c="25384">StrOutputParser()</st>` <st c="25401">object.</st>
    <st c="25410">The</st> `<st c="25414">StrOutputParser()</st>` <st c="25431">object
    is a utility class in LangChain that parses the key output of the language model
    into a string format.</st> <st c="25542">Not only does it strip away all the information
    you did not want to deal with right now, but it ensures that the generated response
    is returned as</st> <st c="25689">a string.</st>'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: <st c="25698">And of course, the last line of code is the line that kicks</st>
    <st c="25759">everything off:</st>
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: <st c="25832">After the</st> *<st c="25843">Retrieval</st>* <st c="25852">stage,
    this user query is used a second time as one of the input variables for the prompt
    that is passed to the LLM.</st> <st c="25970">Here,</st> `<st c="25976">What are
    the advantages of using RAG?</st>` <st c="26013">is the string that’s passed into</st>
    <st c="26047">the chain.</st>
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: <st c="26057">As we discussed</st> <st c="26073">in</st> [*<st c="26077">Chapter
    2</st>*](B22475_02.xhtml#_idTextAnchor035)<st c="26086">, in the future, this
    prompt will include a query that comes from a UI.</st> <st c="26158">Let’s discuss
    the UI as another important component of the</st> <st c="26217">RAG system.</st>
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: <st c="26228">UI</st>
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="26231">At some point, to make</st> <st c="26255">this application more
    professional and usable, you must add a way for regular users who do not have
    your code to enter their queries directly and see the results.</st> <st c="26418">The
    UI serves as the primary point of interaction between the user and the system
    and therefore is a critical component when building a RAG application.</st> <st
    c="26571">Advanced interfaces might</st> <st c="26596">include</st> **<st c="26605">natural
    language understanding</st>** <st c="26635">(</st>**<st c="26637">NLU</st>**<st
    c="26640">) capabilities to interpret the user’s intent more accurately, a form
    of</st> **<st c="26714">natural language processing</st>** <st c="26741">(</st>**<st
    c="26743">NLP</st>**<st c="26746">) that focuses on the understanding part of
    natural language.</st> <st c="26809">This component is crucial for ensuring that
    users can easily and effectively communicate their needs to</st> <st c="26913">the
    system.</st>
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: <st c="26924">This begins with replacing this last line with</st> <st c="26972">a
    UI:</st>
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: <st c="27035">This line would be replaced with an entry field for the user to
    submit a text question, rather than a set string that we pass it in, as</st> <st
    c="27172">shown here.</st>
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: <st c="27183">This also includes displaying the resulting response from the
    LLM in a more user-friendly interface, such as in a nicely designed screen.</st>
    <st c="27322">In</st> [*<st c="27325">Chapter 6</st>*](B22475_06.xhtml#_idTextAnchor114)<st
    c="27334">, we will show this in code, but for now, let’s have a higher-level
    talk about adding an interface to your</st> <st c="27441">RAG application.</st>
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: <st c="27457">When an application is loaded for a user, they will have some
    way to interact with it.</st> <st c="27545">This is typically facilitated through
    an interface that can range from simple text input fields on a web page to more
    complex voice recognition systems.</st> <st c="27698">The key is to accurately
    capture the intent of the user’s query in a format that can be processed by the
    system.</st> <st c="27811">One obvious advantage of adding a UI is that it allows
    your users to test the results of other queries.</st> <st c="27915">A</st> <st
    c="27917">user could enter any query they want and see what the</st> <st c="27971">result
    is.</st>
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: <st c="27981">Pre-processing</st>
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="27996">As we discussed, even though</st> <st c="28026">the user just
    enters a question such as</st> `<st c="28066">What is Task Decomposition?</st>`
    <st c="28093">in the UI, after that question is submitted, there is pre-processing
    that often occurs to make that query more LLM-friendly.</st> <st c="28219">This
    is primarily done in the prompt, which also gets help from many of the other functions.</st>
    <st c="28312">But all of this happens behind the scenes and not in the view of
    the user.</st> <st c="28387">All they will see in this scenario is the final output
    displayed in a</st> <st c="28457">user-friendly way.</st>
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: <st c="28475">Post-processing</st>
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="28491">Even after the LLM</st> <st c="28510">has returned the response,
    this response is often post-processed before it is shown to</st> <st c="28598">the
    user.</st>
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: <st c="28607">Here’s what an actual LLM output</st> <st c="28641">looks like:</st>
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: <st c="28931">As a last step in the chain, we pass that through</st> `<st c="28982">StrOutput
    Parser()</st>` <st c="29000">to parse out just</st> <st c="29019">the string:</st>
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: <st c="29504">That is certainly better than the previous step’s output, but
    this is still displaying in your notebook.</st> <st c="29610">In a more professional
    application, you will want to display this on a screen in a way that is friendly
    for the user.</st> <st c="29728">You may want to display other information, such
    as the source document we showed in the</st> [*<st c="29816">Chapter 3</st>*](B22475_03.xhtml#_idTextAnchor056)
    <st c="29825">code.</st> <st c="29832">This will depend on the intentions of your</st>
    <st c="29874">application and will vary significantly across</st> <st c="29922">RAG
    systems.</st>
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: <st c="29934">Output interface</st>
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="29951">For a full UI, this string</st> <st c="29978">will be passed to
    the interface that displays the message that’s returned to the chain.</st> <st
    c="30067">This interface can be very simple, like what you can see with ChatGPT
    in</st> *<st c="30140">Figure 4</st>**<st c="30148">.7</st>*<st c="30150">:</st>
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.7 – The ChatGPT 4 interface](img/B22475_04_07.jpg)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
- en: <st c="30654">Figure 4.7 – The ChatGPT 4 interface</st>
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: <st c="30690">You could also build something more robust that is more suitable
    for your particular target user group.</st> <st c="30795">If it is meant to be
    more conversational, the interface should also be designed to facilitate further
    interaction.</st> <st c="30910">You could give users options to refine their queries,
    ask follow-up questions, or request</st> <st c="31000">additional information.</st>
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: '<st c="31023">Another common feature in the UI is the collection of feedback
    on the usefulness and accuracy of the response.</st> <st c="31135">This can be
    used to continuously improve the system’s performance.</st> <st c="31202">By analyzing
    user interactions and feedback, the system can learn to better understand user
    intent, refine the vector search process, and enhance the relevance and quality
    of</st> <st c="31377">the generated responses.</st> <st c="31402">This leads us
    to our last key</st> <st c="31432">component: evaluation.</st>'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: <st c="31454">Evaluation</st>
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="31465">The evaluation component is</st> <st c="31494">essential for assessing
    and</st> <st c="31522">improving the RAG system’s performance.</st> <st c="31562">While
    there are many common practices for evaluation, the most effective evaluation
    system will focus on what is most important for your users and provide an evaluation
    for improving those features and capabilities.</st> <st c="31778">Often, this
    involves analyzing the system’s outputs using various metrics, such as accuracy,
    relevance, response time, and user satisfaction.</st> <st c="31920">This feedback
    is used to identify areas of improvement, and guide adjustments in the system’s
    design, data handling, and LLM integration.</st> <st c="32058">Continuous evaluation
    is crucial for maintaining high-quality responses and ensuring that the system
    meets users’</st> <st c="32172">needs effectively.</st>
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: <st c="32190">As mentioned previously, you can also collect user feedback in
    various ways, including qualitative data (entry forms with open-ended questions)
    or quantitative (true/false, ratings, or other numerical representations) on the
    usefulness and accuracy of the response.</st> <st c="32457">A thumbs up/down is
    often used to get a quick feedback response from the user and gauge the general
    effectiveness of the application among</st> <st c="32596">many users.</st>
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: <st c="32607">We will go more in-depth about how to incorporate evaluation into
    your code in</st> [*<st c="32687">Chapter 10</st>*](B22475_10.xhtml#_idTextAnchor218)<st
    c="32697">.</st>
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: <st c="32698">Summary</st>
  id: totrans-155
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="32706">This chapter hasn’t provided an exhaustive list of components
    for a RAG system.</st> <st c="32787">However, these are components that tend to
    be in every successful RAG system.</st> <st c="32865">Keep in mind that RAG systems
    are constantly evolving and new types of components are appearing every day.</st>
    <st c="32972">The key aspect of your RAG system should be to add the components
    that will deliver what your users need.</st> <st c="33078">This can be very specific
    to your project but is often an intuitive outgrowth of what your</st> <st c="33169">company
    does.</st>
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: <st c="33182">This chapter provided a comprehensive overview of the essential
    components that make up a successful RAG system.</st> <st c="33296">It delved
    into the three main stages:</st> *<st c="33334">Indexing</st>*<st c="33342">,</st>
    *<st c="33344">Retrieval</st>*<st c="33353">, and</st> *<st c="33359">Generation</st>*<st
    c="33369">, and explained how these stages work together to deliver enhanced responses
    to</st> <st c="33449">user queries.</st>
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: <st c="33462">In addition to the core stages, this chapter highlighted the importance
    of the UI and evaluation components.</st> <st c="33572">The UI serves as the primary
    point of interaction between the user and the RAG system, allowing users to input
    their queries and view the generated responses.</st> <st c="33731">Evaluation
    is crucial for assessing and improving the RAG system’s performance.</st> <st
    c="33811">This involves analyzing the system’s outputs using various metrics and
    collecting user feedback.</st> <st c="33908">Continuous evaluation helps identify
    areas for improvement and guides adjustments in the system’s design, data handling,
    and</st> <st c="34033">LLM integration.</st>
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: <st c="34049">While the components that were discussed in this chapter are not
    exhaustive, they form the foundation of most successful</st> <st c="34171">RAG
    systems.</st>
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: '<st c="34183">However, there is a very important aspect of every RAG system
    that we didn’t cover in this chapter: security.</st> <st c="34294">We will dedicate
    the entire next chapter to covering key aspects of security, particularly as it
    relates</st> <st c="34399">to RAG.</st>'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: <st c="34406">References</st>
  id: totrans-161
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="34417">LangChain’s prompt hub</st> <st c="34441">information:</st> [<st
    c="34454">https://docs.smith.langchain.com/old/category/prompt-hub</st>](https://docs.smith.langchain.com/old/category/prompt-hub)<st
    c="34510">.</st>
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '[LangChain的提示中心](https://docs.smith.langchain.com/old/category/prompt-hub)
    <st c="34441">信息：</st> [<st c="34454">https://docs.smith.langchain.com/old/category/prompt-hub</st>](https://docs.smith.langchain.com/old/category/prompt-hub)<st
    c="34510">.</st>'
