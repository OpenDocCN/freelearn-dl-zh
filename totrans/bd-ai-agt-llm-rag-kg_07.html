<html><head></head><body>
<div><h1 class="chapter-number" id="_idParaDest-114"><a id="_idTextAnchor113"/>7</h1>
<h1 id="_idParaDest-115"><a id="_idTextAnchor114"/>Creating and Connecting a Knowledge Graph to an AI Agent</h1>
<p>In the previous two chapters, we discussed the RAG framework in detail. We started with naïve RAG and then saw how we could add different components, replace others, or modify the entire pipeline for our needs. The whole system is extremely flexible, but some concepts remain the same. First, we start with a corpus (or multiple corpora of texts) and conduct embedding of these texts to obtain a database of vectors. Once the user query arrives, we conduct a similarity search on this database of vectors. Regardless of the scope or type of texts, our pipeline is based on the concept of vectorizing these texts in some way and then providing the information contained in the discovered texts to the LLM.</p>
<p>Texts are often full of redundant information, and in the previous chapter, we saw that LLMs are sensitive to the amount of noise in the input. Most people have seen the benefit of creating schematic notes or mind maps. These schematics are concise because of the principle that underlining everything in a book is like underlining nothing. The principle of these diagrams is to extract the key information to remember that will enable us to answer questions in the future. Schematics should present the fundamental information and the relationships that connect them. These schemas can be represented as a graph and, more precisely, as a knowledge graph. The advantage of these graphs is that they are compact, represent knowledge as entities and relationships, and we can conduct analyses and use graph search algorithms on them. Over the years, these <strong class="bold">knowledge graphs</strong> (<strong class="bold">KGs</strong>) have been built by major companies or institutions and are now available for use. Many of these KGs have been used for information extraction, where information is extracted with a series of queries to answer questions. This extracted information is a series of entities and relationships, rich in knowledge but less understandable to us humans. The natural step is to use this information for the context of an LLM and then generate a natural language response. This paradigm is called <strong class="bold">GraphRAG,</strong> and we will discuss it in detail in this chapter.</p>
<p>In any case, nothing prohibits us from using an LLM for all the steps in KG. In fact, LLMs have a number of innate capabilities that make them useful even for tasks for which they are not trained. This is precisely why we will see that we can use LLMs to extract relationships and entities and build our KGs. LLMs, though, also possess reasoning capabilities, and in this chapter, we will discuss how we can use these models to reason both about the information contained in graphs and about the structure of the graphs themselves. Finally, we will discuss what perspectives and questions remain open, and the advantages and disadvantages of the proposed approaches.</p>
<p>In this chapter, we’ll be covering the following topics:</p>
<ul>
<li>Introduction to knowledge graphs</li>
<li>Creating a knowledge graph with your LLM</li>
<li>Retrieving information with a knowledge graph and an LLM</li>
<li>Understanding graph reasoning</li>
<li>Ongoing challenges in knowledge graphs and GraphRAG</li>
</ul>
<h1 id="_idParaDest-116"><a id="_idTextAnchor115"/>Technical requirements</h1>
<p>Most of this code can be run on a CPU, but it is preferable to be run on a GPU. The code is written in PyTorch and uses standard libraries for the most part (PyTorch, Hugging Face Transformers, LangChain, ChromaDB, <code>sentence-transformer</code>, <code>faiss-cpu</code>, and so on).</p>
<p>In this chapter, we also use Neo4j as the database for the graph. Although we will do all operations with Python, Neo4j must be installed and you must be registered to use it. The code can be found on GitHub: <a href="https://github.com/PacktPublishing/Modern-AI-Agents/tree/main/chr7">https://github.com/PacktPublishing/Modern-AI-Agents/tree/main/chr7</a>.</p>
<h1 id="_idParaDest-117"><a id="_idTextAnchor116"/>Introduction to knowledge graphs</h1>
<p>Knowledge representation is <a id="_idIndexMarker748"/>one of the open problems of AI and has very ancient roots (Leibniz believed that the whole knowledge could be represented and used to conduct calculations). The interest in knowledge representation is based on the fact that it represents the first step in conducting computer reasoning. Once this knowledge is organized in an orderly manner, it can be used to design inference algorithms and solve reasoning problems. Early studies focused on using deduction to solve problems about organized entities (e.g., through the use of ontologies). This has worked well for many toy problems, but it is laborious, often requires a whole set of hardcoded rules, and risks succumbing to combinatorial explosion. Because search in these<a id="_idIndexMarker749"/> spaces could be extremely computationally expensive, an attempt was made to define two concepts:</p>
<ul>
<li><strong class="bold">Limited rationality</strong>: Finding a solution but<a id="_idIndexMarker750"/> also considering the cost of it</li>
<li><strong class="bold">Heuristic search</strong>: Limiting the<a id="_idIndexMarker751"/> search in space, thus finding a semi-optimal solution (a local but not global optima)</li>
</ul>
<p>These principles have inspired a whole series of algorithms that have since allowed information searches to be conducted more efficiently and tractably. Interest in these algorithms grew strongly in the late 1990s with the advent of the World Wide Web and the need to conduct internet searches quickly and accurately. Regarding data, the World Wide Web is also based on three technological principles:</p>
<ul>
<li><strong class="bold">Distributed data</strong>: Data is distributed <a id="_idIndexMarker752"/>across the world and <a id="_idIndexMarker753"/>accessible from all parts of the world</li>
<li><strong class="bold">Connected data</strong>: Data is<a id="_idIndexMarker754"/> interconnected <a id="_idIndexMarker755"/>and not isolated; the data’s meaning is a function of its connection with other data</li>
<li><strong class="bold">Semantic metadata</strong>: In<a id="_idIndexMarker756"/> addition to the data itself, we have information about its relationships, and this metadata allows <a id="_idIndexMarker757"/>us to search efficiently</li>
</ul>
<p>For this reason, we began to search for a technology that could respect the nature of this new data. It came naturally to turn to representations of a graphical nature. In fact, by definition, graphs model relationships between different entities. This approach began to be used in web searches in 2012 when Google began adding knowledge cards for each concept searched. These knowledge cards can be seen as graphs of name entities in which the connections are the graph links. These cards then allow for more relevant search and user facilitation. Subsequently, the term <em class="italic">knowledge graph</em> came to mean any graph that connects entities through a series<a id="_idIndexMarker758"/> of meaningful relationships. These relationships generally represent semantic relationships between entities.</p>
<div><div><img alt="Figure 7.1 – Knowledge card in Google" src="img/B21257_07_01.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.1 – Knowledge card in Google</p>
<h2 id="_idParaDest-118"><a id="_idTextAnchor117"/>A formal definition of graphs and knowledge graphs</h2>
<p>Since KGs are a subtype of graphs, we will start with a brief introduction of graphs. Graphs are data structures composed of <a id="_idIndexMarker759"/>nodes (or vertices) that are connected by relationships (or edges) to represent a model of a domain. A graph can then represent knowledge in a compact manner while trying to reduce noise. There are different types of graphs:</p>
<ul>
<li><strong class="bold">Undirected</strong>: Edges have<a id="_idIndexMarker760"/> no <a id="_idIndexMarker761"/>direction</li>
<li><strong class="bold">Directed</strong>: Edges have a <a id="_idIndexMarker762"/>defined direction (there is a defined beginning <a id="_idIndexMarker763"/>and end)</li>
<li><strong class="bold">Weighted</strong>: Edges carry<a id="_idIndexMarker764"/> weights, representing <a id="_idIndexMarker765"/>the strength or cost of the relationship</li>
<li><strong class="bold">Labeled</strong>: Nodes are <a id="_idIndexMarker766"/>associated <a id="_idIndexMarker767"/>with features and labels</li>
<li><strong class="bold">Multigraph</strong>: Multiple <a id="_idIndexMarker768"/>edges (relationships) exist<a id="_idIndexMarker769"/> between the same pair of nodes</li>
</ul>
<p>The following figure shows a visual representation of these graphs:</p>
<div><div><img alt="Figure 7.2 – Different types of graph architecture" src="img/B21257_07_02.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.2 – Different types of graph architecture</p>
<p>A KG is thus a subgraph with three main properties:</p>
<ul>
<li><strong class="bold">Nodes represent real-world entities</strong>: These entities can represent people, places, or domain-specific <a id="_idIndexMarker770"/>entities (genes, proteins, diseases, financial products, and so on)</li>
<li><strong class="bold">Relationships define semantic connections between nodes</strong>: For example, two people may be linked by a relationship that represents friendship, or a specific gene is associated with a particular disease</li>
<li><strong class="bold">Nodes and edges may have associated properties</strong>: For example, all people will have as a property that they are human beings (a label) but they can also have quantitative properties (date of birth, a specific identifier, and so on)</li>
</ul>
<p>So, a little more formally, we can say that we have a knowledge base (a database of facts) represented in the form of factual triplets. A factual triples has the form of <code>(head, relation, tail)</code> or <code>(subject, predicate, object)</code>, or more succinctly, <code>(e1,r1,e2)</code>, such as <code>(Napoleon, BornIn, Ajaccio)</code>. The KG is a representation of this knowledge base that allows us to conduct interpretation. Given the structure of these triplets, a KG is a directed graph where the nodes are these entities and the edges are factual relationships.</p>
<div><div><img alt="Figure 7.3 – Example of a knowledge base and knowledge graph (https://arxiv.org/pdf/2002.00388)" src="img/B21257_07_03.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.3 – Example of a knowledge base and knowledge graph (<a href="https://arxiv.org/pdf/2002.00388">https://arxiv.org/pdf/2002.00388</a>)</p>
<p>A KG is defined as a <a id="_idIndexMarker771"/>graph consisting of a set of entities, <em class="italic">E</em>, relations, <em class="italic">R</em>, and facts, <em class="italic">F</em>, where each fact <em class="italic">f</em> is a triplet:</p>
<p><math display="block"><mrow><mrow><mrow><mi mathvariant="script">G</mi><mo>=</mo><mfenced close="}" open="{"><mrow><mi mathvariant="script">E</mi><mo>,</mo><mi mathvariant="script">R</mi><mo>,</mo><mi mathvariant="script">F</mi></mrow></mfenced><mo>;</mo><mi>f</mi><mo>=</mo><mo>(</mo><mi>h</mi><mo>,</mo><mi>r</mi><mo>,</mo><mi>t</mi><mo>)</mo></mrow></mrow></mrow></math></p>
<p>As you can see, a KG is an alternative representation of knowledge. The same kind of data can be represented in either a table or a graph. We can directly create triplets from a table and then directly represent them in a KG. We do not need table headers, and it is easier to conduct the update of such a structure. Graphs are considered universal data representations because they can be applied to any type of data. In fact, not only can we map tabular data to a KG, but we can also get data from other formats (JSON, XML, CSV, and so on). Graphs also allow us to nimbly represent recursive structures (such as trees and documents) or cyclical structures (such as social networks). Also, if we do not have the information for all properties, the table representation will be full of missing values; in a KG, we do not have this problem.</p>
<p>Graphs <em class="italic">per se</em> represent network structures. This is very useful for many business cases (e.g., in finance and medicine) where a lot of data is already structured as networks. Another advantage is that it is much easier to conduct a merge of graphs than of tables. Merging tables is usually a complicated task (where you have to choose which columns to merge, avoid creating duplicates, and other potential problems). If the data is in triplets, it is extremely easy to merge two KG databases. For example, look how simple it is to transform this table into a graph; they are equivalent:</p>
<div><div><img alt="Figure 7.4 – Table and graph are equivalent" src="img/B21257_07_04.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.4 – Table and graph are equivalent</p>
<p>A KG should not be seen <a id="_idIndexMarker772"/>as a static entity. In fact, knowledge evolves; this causes new entities or relationships to be added. One of the most widely used tasks in <strong class="bold">knowledge graph reasoning</strong> (<strong class="bold">KGR</strong>) is to predict new relationships. For example, if A is the <a id="_idIndexMarker773"/>husband of B and father of C, this implies that B is the mother of C, which could be derived with logical ruling: <em class="italic">(A, husband of, B) ^ (A, father of C) -&gt; (B, mother of, C)</em>. In this pre-existing datum, we have inferred a missing relationship.</p>
<p>Another very important task is how to conduct the update of a KG once we have obtained new triplets (this may require complex preprocessing). This is very important because once we have integrated some new knowledge, we can conduct further analysis and further reasoning. Also, being a graph, we can use graph analysis algorithms (such as centrality measures, connectivity, clustering, and so on) for our business cases. Leveraging these algorithms makes it much easier to conduct searches or complex queries in a KG than in relational databases.</p>
<div><div><img alt="Figure 7.5 – A KG is a dynamic entity" src="img/B21257_07_05.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.5 – A KG is a dynamic entity</p>
<p>In addition, KGs are much more flexible and adaptable than people think. KGs can be adapted for different tasks. For example, there are extensions of KGs such as <strong class="bold">hierarchical KGs</strong> where we <a id="_idIndexMarker774"/>have multiple levels. In hierarchical KGs, entities from one level can be connected to the next level (this, for example, is very useful when we have ontologies). Entities<a id="_idIndexMarker775"/> can also be <strong class="bold">multimodal</strong>, so a node can represent an image to which other entities (textual or other images, or other types of modalities) are connected. Another type of KG is a <strong class="bold">temporal KG</strong>, in which<a id="_idIndexMarker776"/> we incorporate a temporal dimension. This type of KG can be very useful for predictive analysis. We can see these KGs in the following figure:</p>
<div><div><img alt="Figure 7.6 – Different types of knowledge graphs" src="img/B21257_07_06.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.6 – Different types of knowledge graphs</p>
<h2 id="_idParaDest-119"><a id="_idTextAnchor118"/>Taxonomies and ontologies</h2>
<p>The main difference between a graph and a KG is that the former is a given structure representing relationships between entities, while the latter makes semantic relationships explicit by allowing reasoning and inference to humans and machines. So, the advantage of a KG is that we can use algorithms for both graphs and specific reasoning algorithms (we will see later, in the <em class="italic">Understanding graph reasoning</em> section, some approaches in detail). These capabilities are enhanced by incorporating metadata. Indeed, we can <a id="_idIndexMarker777"/>construct <code>dog</code> and <code>cat</code> entities might be grouped under <code>mammals</code>). In addition, multiple taxonomies can be integrated if necessary (thus having multiple trees to allow for more refined searching). These taxonomies help in searching or when we need to filter and work with very large KGs. <code>maximum_speed</code> property of <code>100</code> km, so Bob will not be able to get there in less than an hour because his job has a <code>distance_from_home</code> property of <code>120</code> km). Rules allow us to be able to improve search and solve tasks that were too complex before (for example, we can assign different properties to relations: if <code>married_to</code> is transitive, we can automatically infer information about a person without the relation being specified). Thanks to ontologies, we can<a id="_idIndexMarker779"/> conduct certain types of reasoning effectively and quickly, such as deductive reasoning, class inference, transitive reasoning, and so on.</p>
<p>Ontologies are generally grouped into two groups:</p>
<ul>
<li><strong class="bold">Domain-independent ontologies</strong>: Ontologies that provide fundamental concepts that are not tied to a <a id="_idIndexMarker780"/>particular domain. They <a id="_idIndexMarker781"/>provide a high-level view that helps with data integration, especially when there are several domains. Commonly, these are a small number, they represent the first level, and they are the first ones built.</li>
<li><strong class="bold">Domain ontologies</strong>: These are<a id="_idIndexMarker782"/> focused on a domain and are used to provide the fundamental terminology. They <a id="_idIndexMarker783"/>are most useful for specialized domains such as medicine and finance. They are usually found at levels below the domain-independent one and are a subclass of it.</li>
</ul>
<p>In this section, we have seen how KGs are flexible systems that can store data and be able to easily find knowledge. This flexibility makes them powerful tools for subsequent analysis, but at the same time, does not make them easy to build. In the next section, we will see how we can build a KG from a collection of texts.</p>
<h1 id="_idParaDest-120"><a id="_idTextAnchor119"/>Creating a knowledge graph with your LLM</h1>
<p>The construction of a KG is generally a multistep<a id="_idIndexMarker784"/> process consisting of the <a id="_idIndexMarker785"/>following:</p>
<ol>
<li><strong class="bold">Knowledge creation</strong>: The first step, in which we define the purpose of this KG, is to gather the sources from which to extract knowledge. In this step, we have to decide how we build our KG but also where we maintain it. Once built, the KG has to be stored, and we have to have an efficient structure to query it.</li>
<li><strong class="bold">Knowledge assessment</strong>: In this step, we assess the quality of the KG obtained.</li>
<li><strong class="bold">Knowledge cleaning</strong>: There are several steps and procedures to make sure there are no errors and then correct them. This step can be conducted at the same time as knowledge assessment, and some pipelines conduct them together.</li>
<li><strong class="bold">Knowledge enrichment</strong>: This involves a series of steps to identify whether there are gaps in knowledge. We can also integrate additional sources (extract information from other datasets, integrate databases, or merge multiple KGs).</li>
<li><strong class="bold">Knowledge deployment</strong>: In this final <a id="_idIndexMarker786"/>step, the KG is deployed <a id="_idIndexMarker787"/>either as a standalone application (e.g., as a graph database) or used within another application.</li>
</ol>
<p>We can see the process in the following figure:</p>
<div><div><img alt="Figure 7.7 – KG construction pipeline" src="img/B21257_07_07.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.7 – KG construction pipeline</p>
<h2 id="_idParaDest-121"><a id="_idTextAnchor120"/>Knowledge creation</h2>
<p>In general, when building a KG from scratch, the definition of ontologies is the first step. There are several guides on how to <a id="_idIndexMarker788"/>build them (both libraries and tools to visualize them). Efforts are made to build ontologies that are clear, verifiable, and reusable. Defining ontologies should be done with a purpose in mind, discussing what the purpose of a KG is with various stakeholders, and then defining ontologies accordingly. The most relevant ones should be chosen (the first level of the KG), following which the hierarchy and properties should be defined. There are two approaches: top-down (define core ontologies first and then more specialized ones) or bottom-up (define specialized ontologies and then group them into superclasses). Especially for specialized domains, we could start from ontologies that have already been built (there are several <a id="_idIndexMarker789"/>defined for finance, medicine, and academic research) and this ensures better interoperability.</p>
<p>The next step is to extract knowledge from our sources. In this step, we have to extract triplets (or a set of facts) from a text corpus or another source (a database, or structured and unstructured data). Two tasks can be defined:</p>
<ul>
<li><strong class="bold">Named entity recognition</strong> (<strong class="bold">NER</strong>): NER is the task of <a id="_idIndexMarker790"/>extracting entities from text and classifying them</li>
<li><strong class="bold">Relation extraction</strong> (<strong class="bold">RE</strong>): RE is the <a id="_idIndexMarker791"/>task of identifying connections between various entities in a context</li>
</ul>
<p>NER is one of the most common tasks in <strong class="bold">natural language processing</strong> (<strong class="bold">NLP</strong>) and is used not only for KG creation but also as a <a id="_idIndexMarker792"/>key step when we want to move from unstructured text to structured data. It generally requires a pipeline consisting of several steps (text preprocessing, entity identification and classification, contextual analysis, and data post-processing). During NER, we try to identify entities by first conducting a preprocessing step to avoid errors in the pipeline (e.g., proper tokenization). Once entities are identified, they are usually classified (e.g., by adding a label such as people, organizations, or places). In addition, surrounding text is attempted to be used to disambiguate them (e.g., trying to recognize whether <em class="italic">Apple</em> in the text represents the fruit or the company). A preprocessing step is then conducted to resolve ambiguities or merge multi-token entities.</p>
<div><div><img alt="Figure 7.8 – Example of NER (https://arxiv.org/pdf/2401.10825)" src="img/B21257_07_08.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.8 – Example of NER (<a href="https://arxiv.org/pdf/2401.10825">https://arxiv.org/pdf/2401.10825</a>)</p>
<p>RE is the task in which we understand the relationships between the various extracted entities. More formally, we use a model to identify and categorize the connections between entities in a text (e.g., in the sentence <em class="italic">Bob works at Apple</em>, we extract the relationship <em class="italic">works at</em>). It can be considered a separate task or, in some cases, conducted together with NER (e.g., with a single model). Also, RE is a key step for KG creation and, at the same time, useful for several other NLP tasks (such as question answering, information retrieval, and so on).</p>
<p>There are several methods to be<a id="_idIndexMarker793"/> able to conduct NER and RE. The earliest and most laborious methods were knowledge-based or rule-based. For example, one of the simplest approaches to identifying company names in financial documents was to use indicators such as capital letters (identify <code>Mr.</code> and <code>Ms.</code> elements to extract people, and so on). Rule-based worked very well for standardized documents (such as clinical notes or official documents) but demonstrated little scalability. These methods require establishing laborious upstream rules and specific knowledge, risking missing many entities in different datasets.</p>
<p>Statistical methods based on the hidden Markov model, conditional random fields, or maximum entropy (methods that rely on predicting the entity based on likelihood learned from training data) have allowed for greater scalability. These methods, though, require large, quality datasets that have defined labels. Other supervised learning algorithms have been used to predict entities and then extract them. These algorithms have worked well with high computational costs and especially the need for labels. Obtaining labels is expensive and these datasets quickly become outdated (new companies, new products, and so on are created).</p>
<p>Recently, given the advances in unsupervised learning (models such as the transformer), it has been decided to use LLMs also for NER and RE and for constructing KGs (in some studies, these are called <strong class="bold">LLM-augmented KGs</strong>). The ability to <a id="_idIndexMarker794"/>process large corpora of text, the knowledge acquired during pre-training, and their versatility make LLMs useful for the construction of KGs (and other related tasks that we will see later).</p>
<p>Due to their ability to leverage contextual information and linguistic abilities, state-of-the-art methods generally <a id="_idIndexMarker795"/>employ transformer-based models for NER tasks. Previous methods had problems with texts that had complex structures (a token that belongs to several entities, or entities that are not contiguous in the text) while transformers are superior in solving these cases. BERT-based models were previously used, which were then later fine-tuned for different tasks. Today, however, we exploit the capabilities of an LLM that does not need to be fine-tuned but can learn a task without training through in-context learning. An LLM can then directly extract entities from text without the need for labels and provide them in the desired format (for example, we might want the LLM to provide a list of triplets or the triplet plus a given label). To avoid disambiguation problems, we can ask the LLM to provide additional information when conducting the extraction. For example, in music, <em class="italic">Apple</em> can refer to Apple Music, the British psychedelic rock band Apple, or the singer Fiona Apple. LLMs can help us disambiguate which of these entities it refers to based on the context of the period. At the same time, the flexibility of LLMs allows us to tie entities to various ontologies during extraction.</p>
<p>Similarly, an LLM can help with the RE task. There are several ways to do this. One of the simplest is to conduct sentence-level RE, in which you provide the model with a sentence and it must extract the relationship between the two entities. The extension of this approach is to extract all the relationships between entities at the level of an entire document. Since this is not an easy task, more sophisticated approaches with more than one LLM can be used to make sure that we can understand relationships at the local and global levels of the document (for example, in a document, a local relationship between two entities is in the same sentence, but we can also have global relationships where an entity mentioned at the beginning of the document is related to an entity that is present at the end of the document).</p>
<div><div><img alt="Figure 7.9 – General framework of LLM-based KG construction (This information was taken from an article published in 2023; https://arxiv.org/pdf/2306.08302)" src="img/B21257_07_09.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.9 – General framework of LLM-based KG construction (This information was taken from an article published in 2023; <a href="https://arxiv.org/pdf/2306.08302">https://arxiv.org/pdf/2306.08302</a>)</p>
<p>As mentioned, the two tasks need not be conducted separately (NER and RE), but an LLM provides the flexibility to conduct them in a single step. In this case, it is of great importance to define the<a id="_idIndexMarker796"/> right prompt in which we instruct the model in extracting entities and relationships and in which format we want the output. We can then proceed iteratively, extracting entities and relationships for a large body of text. Alternatively, we can use a set of prompts for different tasks (one for entity extraction, one for relation extraction, and so on) and scan the corpus and these prompts automatically with the LLM. In some approaches, to maintain more flexibility, one LLM is used for extraction and then a smaller LLM is used for correction.</p>
<p>Another interesting perspective is that an LLM is enough to create a KG. In fact, LLMs are trained with a huge amount of text (the latest LLMs are trained with trillions of tokens that include scraping the internet and thousands of books). Several studies today show that even small LLMs (around 7 billion parameters) have considerable knowledge, especially about facts (the definition of knowledge in an LLM is also complicated because this is not associated with a single parameter but widespread). Therefore, some authors have proposed distilling knowledge directly from the LLM. In this case, by exploiting prompts constructed for the<a id="_idIndexMarker797"/> task, we conduct what is called a <strong class="bold">knowledge search</strong> of the LLM to extract triplets. In this way, by extracting facts directly from the LLM, we can then directly <a id="_idIndexMarker798"/>construct our KG. KGs constructed in this way are competitive in quality, diversity, and novelty with those constructed with large text datasets.</p>
<div><div><img alt="Figure 7.10 – General framework of distilling KGs from LLMs (https://arxiv.org/pdf/2306.08302)" src="img/B21257_07_10.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.10 – General framework of distilling KGs from LLMs (<a href="https://arxiv.org/pdf/2306.08302">https://arxiv.org/pdf/2306.08302</a>)</p>
<h2 id="_idParaDest-122"><a id="_idTextAnchor121"/>Creating a knowledge graph with an LLM</h2>
<p>In this tutorial, I will use Neo4j and LangChain to create a KG with an LLM. LangChain allows us to use LLMs efficiently to <a id="_idIndexMarker799"/>extract information from a text corpus, while<a id="_idIndexMarker800"/> Neo4j is a program for analyzing and visualizing graphs. The complete code is in the book’s GitHub repository (<a href="https://github.com/PacktPublishing/Modern-AI-Agents/tree/main/chr7">https://github.com/PacktPublishing/Modern-AI-Agents/tree/main/chr7</a>); here, we will describe the general process and the most important code snippets. We can have two methods:</p>
<ul>
<li><strong class="bold">Custom method</strong>: LLMs have innate abilities to be able to accomplish tasks; we can take advantage of these generalist abilities</li>
<li><strong class="bold">LangChain graph transformers</strong>: Today, there are libraries that make the job easier and allow just a few lines of code to achieve the same result</li>
</ul>
<p>The custom method is simply to define a prompt that allows the model to understand the task and execute it efficiently. In this case, our prompt is structured with the following elements:</p>
<ul>
<li>A clear definition of the task with a set of bullet points. The task description can contain both what the model must do and what it must not do.</li>
<li>Additional context that allows the model to better understand how to perform the task. Since these <a id="_idIndexMarker801"/>models are trained for dialogic tasks, providing<a id="_idIndexMarker802"/> them with information about what role they should play helps the performance.</li>
<li>Some examples to explain how to perform the task.</li>
</ul>
<p>This approach builds on what we learned in <a href="B21257_03.xhtml#_idTextAnchor042"><em class="italic">Chapter 3</em></a>. The model we are using is instruction-tuned (trained to perform tasks) so providing clear instructions helps the model understand the task and perform it. The addition of some examples leverages in-context learning. Using a crafted prompt allows us to be flexible and be able to adapt the prompt to our needs:</p>
<pre class="source-code">
#Custom method
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import SystemMessage
from langchain_core.output_parsers import StrOutputParser
prompt = ChatPromptTemplate.from_messages([
    SystemMessage(content="""
    You are a helpful assistant in creates knowledge graphs by Generating Cypher Queries.\n
    Task:
     *  Identify Entities, Relationships and Property Keys from Context.\n
     *  Generate Cypher Query to Create Knowledge Graph from the Entities Relationships and Property Keys discovered.\n
     *  Extract ALL Entities and RelationShips as Possible.\n
     *  Always extract a person Profession as an Entity.\n
     *  Be creative.
     *  Understand hidden relationships from the network.
     Note: Read the Context twice and carefully before generating Cypher Query.\n
     Note: Do not return anything other than the Cypher Query.\n
     Note: Do not include any explanations or apologies in your responses.\n
     Note: Do not hallucinate.\n
     Entities include Person, Place, Product, WorkPlaces, Companies, City, Country, Animals, Tags like peoples Profession and more \n
     Few Shot Prompts:
      Example Context:
       Mary was born in 1995. She is Friends with Jane and John. Jane is 2 years older than Mary.
       Mary has a dog named Max,and is 3 years old. She is also married to John. Mary is from USA and a Software Engineer.
      Answer:
        MERGE (Mary:Person {name: "Mary", birth_year: 1995})
        MERGE (Jane:Person {name: "Jane", age:1993})
        MERGE (John:Person {name: "John"})
        MERGE (Mary)-[:FRIENDS_WITH]-&gt;(Jane)
        MERGE (Mary)-[:FRIENDS_WITH]-&gt;(John)
        MERGE (Jane)-[:FRIENDS_WITH]-&gt;(Mary)
        MERGE (John)-[:FRIENDS_WITH]-&gt;(Mary)
        MERGE (Mary)-[:HAS_DOG]-&gt;(Max:Dog {name: "Max", age: 3})
        MERGE (Mary)-[:MARRIED_TO]-&gt;(John)
        MERGE (Mary)-[:HAS_PROFESSION]-&gt;(SoftwareEngineer:Profession {name: "Software Engineer"})
        MERGE (Mary)-[:FROM]-&gt;(USA:Country {name: "USA"})
    """),
    ("human", "Context:{text}"),
])</pre> <p>Executing the <a id="_idIndexMarker803"/>preceding should <a id="_idIndexMarker804"/>yield the following result:</p>
<div><div><img alt="Figure 7.11 – Screenshot of the results" src="img/B21257_07_11.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.11 – Screenshot of the results</p>
<p>The results show how a crafted prompt succeeds in generating triplets (which we can then use to construct <a id="_idIndexMarker805"/>our KG). This highlights the great flexibility of LLMs.</p>
<p>We do not always want a <a id="_idIndexMarker806"/>custom approach but might want to use a more established pipeline. LangChain provides the ability to do this with just a few lines of code:</p>
<pre class="source-code">
from langchain_core.documents import Document
from langchain_experimental.graph_transformers import LLMGraphTransformer
llm_transformer = LLMGraphTransformer(llm=llm)
documents = [Document(page_content=content)]
graph_documents = llm_transformer.convert_to_graph_documents(documents)</pre> <p>LangChain gives us the same <a id="_idIndexMarker807"/>result in an already structured format that simplifies our work.</p>
<p>The graph can then be<a id="_idIndexMarker808"/> visualized in Neo4j and we can work on the graph, conduct searches, select nodes, and so on.</p>
<div><div><img alt="Figure 7.12 – Screenshot of the graph from Neo4j" src="img/B21257_07_12.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.12 – Screenshot of the graph from Neo4j</p>
<p>Once the graph is generated, we can use it for our queries. Obviously, we can conduct these queries in Neo4j, but it is <a id="_idIndexMarker809"/>also possible to do it in Python. For <a id="_idIndexMarker810"/>example, LangChain allows us to conduct queries of our KG:</p>
<pre class="source-code">
from langchain.chains import GraphCypherQAChain
graphchain = GraphCypherQAChain.from_llm(
    llm, graph=graph, verbose=True, return_intermediate_steps=True
)
results = graphchain.invoke({"query":"People who have kids"})
print(results["result"])</pre> <p>Once executed the code, you should obtain these results:</p>
<div><div><img alt="Figure 7.13 – Querying the KG" src="img/B21257_07_13.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.13 – Querying the KG</p>
<p>As we can see, LangChain in this case <a id="_idIndexMarker811"/>generates a corresponding query in Cypher and then conducts the graph query. In this way, we are using an LLM to generate a query in Cypher, while we can write directly in natural language.</p>
<h2 id="_idParaDest-123"><a id="_idTextAnchor122"/>Knowledge assessment</h2>
<p>Once the KG has been <a id="_idIndexMarker812"/>created, it is necessary to check for errors and the overall quality of the KG. The quality of a KG is assessed by a set of dimensions (there are metrics associated with each of these dimensions) that are used to monitor the KG in terms of accessibility, representation, context, and intrinsic quality. Some of the metrics are as follows:</p>
<ul>
<li><strong class="bold">Accuracy</strong>: This metric assesses accuracy in syntactic and semantic terms.</li>
<li><strong class="bold">Completeness</strong>: This metric measures how much knowledge a KG contains with respect to a certain domain or task. It usually measures whether a KG contains all the necessary entities and relationships for a domain (sometimes a comparison with a golden standard KG is used).</li>
<li><strong class="bold">Conciseness</strong>: KGs allow knowledge to<a id="_idIndexMarker813"/> be expressed efficiently, but they risk scaling quickly. Blank nodes (specific types of nodes that represent anonymous or unnamed entities, used when a node is needed in the graph but is not precisely indicated) can often be generated during the creation process. If care is not taken, one risks filling the KG with blank nodes.</li>
<li><strong class="bold">Timeliness</strong>: Knowledge should also be updated regularly because it can change and become outdated. Therefore, it is important to decide the frequency of updates.</li>
<li><strong class="bold">Accessibility, ease of manipulation, and operation</strong>: KGs are used for searches or other tasks; metrics exist today that measure the usefulness of KGs. In fact, for a KG to be useful, it must be easily accessible, be able to be manipulated, and be able to conduct research and updates.</li>
<li><strong class="bold">Ease of understanding</strong>: Since the KG is meant to be used to represent knowledge for humans, some authors have proposed measuring the degree to which the KG is interpretable for humans. Indeed, today, there is a greater emphasis on transparency and interpretation of models in AI.</li>
<li><strong class="bold">Security, privacy, and traceability</strong>: Metrics also exist today to control who accesses the KG and whether it is secure from outside access. Similarly, knowledge also needs to be tracked, as we need to be sure which sources it comes from. Traceability also allows us to be in privacy compliance. For example, our KG may contain sensitive data about users or come from erroneous or problematic documents. Traceability allows us to correct these errors, delete data from users who require their data to be deleted, and so on.</li>
</ul>
<h2 id="_idParaDest-124"><a id="_idTextAnchor123"/>Knowledge cleaning</h2>
<p>Having assessed the quality of our KG, we can see that there are errors. In general, error detection and correction are<a id="_idIndexMarker814"/> together called <strong class="bold">knowledge cleaning</strong>. Different types of errors can occur in a KG:</p>
<ul>
<li>We may have entities or relationships that have syntactic errors</li>
<li>Some errors may be ontology-related (assigning to ontologies that do not exist, connecting them to the wrong ontologies, wrong properties of ontologies, and so on)</li>
<li>Some may be semantic and may be more difficult to identify</li>
<li>There are also knowledge errors<a id="_idIndexMarker815"/> that may result from errors in the sources for creating the knowledge (symptom <em class="italic">x</em> is not a symptom of disease <em class="italic">y</em>, person <em class="italic">x</em> is not the CEO of company <em class="italic">y</em>, and so on)</li>
</ul>
<p>There are several methods to detect these errors. The simplest methods are statistical and seek to identify outliers in a KG by exploiting probabilistic and statistical modeling. There are also more sophisticated variations that exploit simple machine-learning models. These models are not particularly accurate. Since we can use logical reasoning and ontologies with KGs, there are knowledge-based reasoning methods to identify outliers (e.g., an instance of a person cannot also be an instance of a place, so by exploiting similar rules, we can identify outliers). Finally, there are methods based on AI, and one can also use an LLM to check for errors. An LLM possesses both knowledge and reasoning skills so it can be used to verify that facts are correct. For example, if for some error, we have the triplet <code>(Vienna, CapitalOf, Hungary)</code>, an LLM can identify the error). Then, there are similar methods for conducting KG correction. However, several frameworks have already been built and established to conduct detection and correction.</p>
<h2 id="_idParaDest-125"><a id="_idTextAnchor124"/>Knowledge enrichment</h2>
<p><strong class="bold">Knowledge enrichment</strong> (or KG completion) is generally the next step. KGs are notoriously incomplete, so several rounds of KG completion and correction can occur. The completeness of a KG is sometimes <a id="_idIndexMarker816"/>complicated to define and is contextual to the domain and application tasks. The first step in completing a KG is usually to identify additional sources of information (e.g., for a medical KG, it could be an additional biomedical database or an additional corpus of scientific articles). Often, in the first step of building the KG, we use only one data type (unstructured text) and then extend the extraction in a second step to other data types (CSV, XML, JSON, images, PDF, and so on). Each of these data types presents different challenges, so we should modify our pipeline. The more sources we use, the more crucial KG cleaning and alignment tasks become. For example, the more heterogeneous the sources, the greater the importance of entity resolution (identifying duplicate<a id="_idIndexMarker817"/> entities at the KG level).</p>
<p>An interesting alternative is to infer knowledge using an LLM (or other transformer models). For example, three possible approaches have been explored:</p>
<ul>
<li> <code>(h,r,t)</code> is given to a model as a transformer model to predict the<a id="_idIndexMarker818"/> probability that it exists (<code>0</code> represents that the triplet is invalid, while <code>1</code> is a valid triplet). A variation of this approach is to take the final hidden state from the model and train a linear classifier to predict in a binary fashion whether the triplet is valid or not.</li>
<li><code>(h,r,?)</code>, we can try to complete the gap.</li>
<li><code>(h,r)</code> and <code>(t)</code>. In this way, we get two representations from the model (the final hidden state of the model is used). After that, we use a scoring function to predict whether this triplet is valid. This approach is definitely more accurate but risks a combinatorial explosion. As you can see, in this approach, we are trying to calculate the similarity between two textual representations (the representation of <code>(h,r)</code> and <code>(t)</code>).</li>
</ul>
<p>These approaches are, in fact, very similar to those we have seen in previous chapters when trying to calculate the similarity between two sentences.</p>
<div><div><img alt="Figure 7.14 – LLMs as encoders for KG completion (https://arxiv.org/pdf/2306.08302)" src="img/B21257_07_14.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.14 – LLMs as encoders for KG completion (<a href="https://arxiv.org/pdf/2306.08302">https://arxiv.org/pdf/2306.08302</a>)</p>
<p>Alternatively, one can use few-shot examples or other prompting techniques and ask an LLM to complete them directly. In addition, this approach allows you to be able to provide additional items in the <a id="_idIndexMarker821"/>prompt. In previous approaches, we provided only the triplet <code>(h,r,t)</code>; with prompt engineering, we can also provide other contextual elements (relationship descriptions, entity descriptions, etc.) or add instructions to better complete the task.</p>
<div><div><img alt="Figure 7.15 – Prompt-based KG completion (https://arxiv.org/pdf/2306.08302)" src="img/B21257_07_15.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.15 – Prompt-based KG completion (<a href="https://arxiv.org/pdf/2306.08302">https://arxiv.org/pdf/2306.08302</a>)</p>
<h2 id="_idParaDest-126"><a id="_idTextAnchor125"/>Knowledge hosting and deployment</h2>
<p>The last step is the hosting and deployment of the KG. The KG is a set of nodes and relationships, so we can use a graph-specific paradigm to be able to store the data. Of course, hosting a KG is not without <a id="_idIndexMarker822"/>challenges:</p>
<ul>
<li><strong class="bold">Size</strong>: The larger the KG, the more complex its management becomes</li>
<li><strong class="bold">Data model</strong>: We have to choose the system that allows us to optimally access the information for our tasks, as different systems have different advantages and disadvantages</li>
<li><strong class="bold">Heterogeneity</strong>: The graph may contain multiple modes, thus making storage more complex</li>
<li><strong class="bold">Speed</strong>: The more it grows, the more complex knowledge updates become</li>
<li><strong class="bold">User needs</strong>: Users may have heterogeneous needs that may be conflicting, requiring us to have to implement rules and constraints</li>
<li><strong class="bold">Deployment</strong>: The system must be accessible to users and allow easy inference</li>
</ul>
<p>There are different alternatives for the storage of a KG:</p>
<ul>
<li>KGs can be hosted in classic <strong class="bold">relational databases</strong> (e.g., <strong class="bold">Structured Query Language</strong> (<strong class="bold">SQL</strong>) where entities and <a id="_idIndexMarker823"/>relationships are stored in<a id="_idIndexMarker824"/> tables). From these tables, one can then reconstruct the graph’s relational structure using projections. Using a relational database <a id="_idIndexMarker825"/>to store a large KG can result in large tables that are impractical or a multitude of tables with a complex hierarchy.</li>
<li>An alternative is the <strong class="bold">document model</strong> where <a id="_idIndexMarker826"/>data is stored as tuples (key-value pairs) and then organized into collections. This structure can be convenient for searching; it is a schematic system that allows the speed of writing, but updating knowledge in nested collections can be a nightmare.</li>
<li><strong class="bold">Graph databases</strong> are databases<a id="_idIndexMarker827"/> that are optimized for <a id="_idIndexMarker828"/>storing and searching graphs and data transformation. The graph data model then has nodes and edges with various metadata that are attached. The query language is also adapted to this structure (and is vaguely reminiscent of SQL). Graph databases also have the advantage of allowing heterogeneity and supporting speed. Neo4j is one of the most widely used and uses an adapted query language (Cypher).</li>
<li><strong class="bold">Triplet stores</strong> are where <a id="_idIndexMarker829"/>the database is made up directly of triplets. Databases exist today that save information in triplets and allow queries to be conducted in the database. Typically, these databases also have native support for ontologies and for conducting logical reasoning.</li>
</ul>
<p>Hosting comes with its own set of challenges, and the choice of data model should be conducted with subsequent applications in mind. For example, if our KG needs to retrieve data from our relational database, using this system has advantages for integration. On the other hand, though, in this case, we will sacrifice performance for heterogeneity and speed. A graph database handles performance and the structural nature of the graph better, but it may integrate poorly with other components of the system. Whatever system we use for storage, we can either build hybrid systems depending on the applications or create a KG as a layer on top of the database.</p>
<p>Deployment is the last step in the pipeline. That doesn’t mean it’s the end of the story, though. A KG can become outdated easily, so we need to have pipelines in mind for knowledge updates or to be able to handle new applications. Similarly, the entry of new knowledge means that we must have pipelines for knowledge assessment (monitoring the quality of the KG, ensuring that no errors are entered or that there are no conflicts). Some knowledge may be outdated or need to be deleted for legal or privacy issues; therefore, we should have pipelines for cleaning the KG. Other pipelines should instead focus on controlling access and <a id="_idIndexMarker830"/>security of our system.</p>
<p>In this section, we have seen all the steps necessary to create and deploy a KG. Now that we have our KG, we can use it; in the next section, we will discuss how to find information and use it as a context for our LLM.</p>
<h1 id="_idParaDest-127"><a id="_idTextAnchor126"/>Retrieving information with a knowledge graph and an LLM</h1>
<p>In the previous two chapters, we discussed the capabilities of RAG and its role in reducing hallucinations generated by<a id="_idIndexMarker831"/> LLMs. Although RAG has been<a id="_idIndexMarker832"/> widely used in both research and industrial applications, there are still limitations:</p>
<ul>
<li><strong class="bold">Neglecting relationships</strong>: The text in the databases is interconnected and not isolated. For example, a document is divided into chunks; since these chunks belong to a single document, there is a semantic connection between them. RAG fails to capture structured relational knowledge when this cannot be captured by semantic similarity. Some authors point out that, in science, there are important relationships between an article and previous works, and these relationships are usually highlighted with a citation network. Using RAG, we can find articles that are similar to the query but we cannot find this citation network, losing this relational information.</li>
<li><strong class="bold">Redundant information</strong>: The context that comes to the LLM is a series of concatenated chunks. Today with LLMs, we can add more and more context (the context length of models is getting longer and longer) but they struggle with the presence of redundant information. The more chunks we add to the context, the greater the amount of redundant or non-essential information to answer the query. The presence of this redundant information reduces the performance of the model.</li>
<li><strong class="bold">Lacking global information</strong>: RAG finds a set of documents but fails to find global information because the set of documents is not representative of global information. This is a problem, especially for summarization tasks.</li>
</ul>
<p><strong class="bold">Graph retrieval-augmented generation</strong> (<strong class="bold">GraphRAG</strong>) has<a id="_idIndexMarker833"/> emerged as a new paradigm to try to solve these challenges. In traditional RAG, we find text chunks by conducting a similarity analysis on the <a id="_idIndexMarker834"/>embedded vectors. In GraphRAG, we conduct the search on the knowledge graph, and<a id="_idIndexMarker835"/> the found triplets are provided to the context. So, the main difference is that upon arrival of a query from a user, we conduct the search in the KG and use the information contained in the graph to answer the query.</p>
<div><div><img alt="Figure 7.16 – Comparison between direct LLM, RAG, and GraphRAG (https://arxiv.org/pdf/2408.08921)" src="img/B21257_07_16.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.16 – Comparison between direct LLM, RAG, and GraphRAG (<a href="https://arxiv.org/pdf/2408.08921">https://arxiv.org/pdf/2408.08921</a>)</p>
<p>Formally, we can define GraphRAG as a framework that exploits a KG to provide context to an LLM and produce a better response. The system, therefore, is very similar to classical RAG; to avoid confusion, in this <a id="_idIndexMarker836"/>context, we will call it <em class="italic">vector RAG</em>. In GraphRAG, the KG is the knowledge<a id="_idIndexMarker837"/> base, and from this, we find information on entities and relationships. GraphRAG consists of three main steps:</p>
<ol>
<li><strong class="bold">Graph-based indexing</strong> (<strong class="bold">G-indexing</strong>): In this initial <a id="_idIndexMarker838"/>phase, the goal is to build a graph database and index it correctly.</li>
<li><code>q</code>, in natural language, we want to extract a subgraph that we can use to correctly answer the query.</li>
<li><strong class="bold">Graph-enhanced generation</strong> (<strong class="bold">G-generation</strong>): The last <a id="_idIndexMarker840"/>step concerns using the found knowledge for generation. This step is conducted with an LLM that receives the context and generates the answer.</li>
</ol>
<div><div><img alt="Figure 7.17 – Overview of the GraphRAG framework for a question-answering task (https://arxiv.org/pdf/2408.08921)" src="img/B21257_07_17.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.17 – Overview of the GraphRAG framework for a question-answering task (<a href="https://arxiv.org/pdf/2408.08921">https://arxiv.org/pdf/2408.08921</a>)</p>
<p>In the following subsections, we will talk about each step in detail.</p>
<h2 id="_idParaDest-128"><a id="_idTextAnchor127"/>Graph-based indexing</h2>
<p>In the first step, we need to choose what our graph data will be. Generally, two types of KGs are used: open KGs or self-constructed KGs. In the first case, we <a id="_idIndexMarker841"/>can use a KG that is already available and adapt it to our GraphRAG. Today, many KGs have already been built and are available (for example, Wikidata is a knowledge base that collects data from various Wikipedia-related projects). Several KGs are specialized in a particular domain; these KGs have a greater understanding of a particular domain (some of these KGs are open and usable). Alternatively, it is possible to build your own KG.</p>
<p>When building it or before using it in GraphRAG, you should pay attention to indexing. Proper indexing allows us to have a faster and more efficient GraphRAG. Although we can imagine the KG visually as a graph, it is still stored in a database. Indexing allows us access to the information we want to find. Thus, there are several types of indexing. For example, we can have text descriptions associated with nodes, triplets, or ontologies that are then used during the search. Another way is to transform graph data into vectors and conduct the search on these vector spaces (embedding). We can also use indexing that better respects the<a id="_idIndexMarker842"/> graph nature of the data or hybrid versions.</p>
<div><div><img alt="Figure 7.18 – Overview of graph-based indexing (https://arxiv.org/pdf/2408.08921)" src="img/B21257_07_18.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.18 – Overview of graph-based indexing (<a href="https://arxiv.org/pdf/2408.08921">https://arxiv.org/pdf/2408.08921</a>)</p>
<h2 id="_idParaDest-129"><a id="_idTextAnchor128"/>Graph-guided retrieval</h2>
<p>In GraphRAG, retrieval is crucial for the quality of response generation (similar to vector RAG). The search for a KG has two challenges that need to be solved:</p>
<ul>
<li><strong class="bold">Explosive candidate subgraphs</strong>: As the graph grows, the number of subgraphs in the KG increases <a id="_idIndexMarker843"/>exponentially. This means we need efficient algorithms to explore the KG and find the relevant subgraphs. Some of these algorithms use heuristic methods to be more efficient.</li>
<li><strong class="bold">Insufficient similarity measurement</strong>: Our query is in text form, but we want to conduct our similarity search on a graph. This means that our algorithm must be able to understand both textual and structural information and be able to succeed in comparing the similarity between data from different sources.</li>
</ul>
<p>We can have different types of retrievers. The simplest are <code>Obama</code> entity, in KG, we take neighboring entities, <code>k-hop=1</code>, or even neighbors of neighbors, <code>k-hop=2</code>, and so on). Non-parametric retrievers are the simplest and also the fastest systems, but they suffer from inaccurate retrieval (they can be improved by learning). There are machine and deep learning models that are natively trained on graphs. GNN-based retrievers are one example. <strong class="bold">Graph neural networks</strong> (<strong class="bold">GNNs</strong>) are neural <a id="_idIndexMarker845"/>networks that natively handle graphs and can be used for many tasks on graphs (node classification, edge prediction, and so on) so they search the graph for subgraphs similar to the query.</p>
<p>Alternatively, we can use an LLM-based retriever where we have a transformer-based model that conducts the search. The model then processes and interprets the query to conduct the search. Several of these LLMs are models that have been trained on the text, and then fine-tuning is conducted to search the graphs. One advantage is that an LLM can be used as an agent and use different tools or functions to search the graph. Both LLM-based retrievers and GNN-based retrievers significantly improve retrieval accuracy but at a high computational cost. There are also alternatives today that use different methods (conduct with both a GNN and LLM, or use heuristic methods together with an LLM) or the process can be multistage (e.g., conduct an initial search with an LLM and then refine the results).</p>
<p>As was done for the vector RAG, we can add additional components to conduct enhancement. For example, in the previous chapter, we saw that we can rewrite a query or decompose queries that are too complex. Query modification helps to better capture the meaning of the query (because sometimes the query does not capture the implicit meaning intended by the user). Retrieval can also be a flexible process. In the previous chapter, we saw that in naïve RAG, retrieval was conducted only once, but then variations in advanced and modular RAG were established where retrieval can be multistage or iterative. Even more sophisticated variations make the process adaptive depending on the query, so for simpler queries, only one retrieval is conducted, and for more complex queries, multiple iterations may be conducted. Similarly, the<a id="_idIndexMarker846"/> results obtained after retrieval can also be modified. For example, even with GraphRAG, we can conduct a compression of the retrieved knowledge. In fact, we may also find redundant information if we conduct multiple retrieval stages and thus it is convenient to filter out irrelevant information.</p>
<p>Today, there are also reranking approaches to reorder the retrieved results with GraphRAG. One example is to reorder the various subgraphs found and perhaps choose the top <em class="italic">k</em> subgraphs.</p>
<div><div><img alt="Figure 7.19 – General architectures of graph-based retrieval (https://arxiv.org/pdf/2408.08921)" src="img/B21257_07_19.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.19 – General architectures of graph-based retrieval (<a href="https://arxiv.org/pdf/2408.08921">https://arxiv.org/pdf/2408.08921</a>)</p>
<p>Another difference with vector RAG is how we control search granularity. In vector RAG, granularity is controlled by deciding the size of the chunks. In the case of GraphRAG, we do not conduct chunking or find chunks. We can, however, control granularity during retrieval by choosing what we find:</p>
<ul>
<li><strong class="bold">Nodes</strong>: In GraphRAG, we can <a id="_idIndexMarker847"/>retrieve individual entities. Nodes can have properties associated with them and then only add entities and their properties to the context. This can be useful for target queries.</li>
<li><strong class="bold">Triplets</strong>: By <a id="_idIndexMarker848"/>expanding the search granularity, we choose to retrieve triplets (so not only nodes, but also their relationships). This is useful when we are interested not only in the entity itself but also in their relationships.</li>
<li><strong class="bold">Paths</strong>: In this case, we<a id="_idIndexMarker849"/> still <a id="_idIndexMarker850"/>expand the retrieval. A path is a chain of nodes and relationships, so starting from entity <em class="italic">X</em> and arriving at entity <em class="italic">Y</em>, the path is all the chain of entities and relationships that connect them. Obviously, there are multiple paths between different entities, and these grow exponentially as the size of the graph increases. So, we generally define rules, use GNNs, or choose the shortest path.</li>
<li><strong class="bold">Subgraphs</strong>: A subgraph<a id="_idIndexMarker851"/> can be defined as a subset of nodes and relationships internal to the KG. Extracting a subgraph allows us to answer complex queries because it allows us to analyze complex patterns and dependencies between entities. There are several ways to extract a subgraph: we can use specific patterns or conduct a merge of different paths.</li>
<li> <strong class="bold">Hybrid granularities</strong>: We <a id="_idIndexMarker852"/>can use different granularities at the same time or choose an adaptive system.</li>
</ul>
<p>In the case of GraphRAG, balancing granularity and efficiency is important. We do not want to saturate the context with elements to prevent later LLM struggles with irrelevant information. It also depends on the complexity of the query: for simple queries, even low granularity is enough, whereas complex queries benefit from higher granularity. An adaptive approach can make the system more efficient while maintaining nuances when needed.</p>
<div><div><img alt="Figure 7.20 – Different levels of retrieval granularity" src="img/B21257_07_20.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.20 – Different levels of retrieval granularity</p>
<p>Once the knowledge is found and cleaned up, we can provide it to the LLM to generate a response to the query. This knowledge enters the prompt provided to the LLM and the model generates a response. Alternatively, this found knowledge can be used for certain types of models that are used for some specific tasks (e.g., a GNN to answer multiple-choice questions). The main problem is that the graph has a non-Euclidean nature and integration with textual information is not <a id="_idIndexMarker853"/>optimal. For this, graph translators that convert the found graph information into more digestible information for an LLM can be used. This conversion increases the LLM’s ability to understand the information. So, once we find the information in graph form (nodes, relationships, path, or subgraph), we put it in the context of the LLM. There are some alternatives:</p>
<ul>
<li><strong class="bold">Graph formats</strong>: We can directly add the set of relationships and nodes in the prompt, or we can use a form of graph structure representation such as adjacency or edge tables. The<a id="_idIndexMarker854"/> latter compactly conveys a better relational structure. Another idea is a node sequence, which is generated according to a predeterminate rule. This is a compact representation that contains the order of the nodes in the graph.</li>
<li><strong class="bold">Natural language</strong>: There are specific graph languages that can be used to transform information into <a id="_idIndexMarker855"/>natural language, a representation that is more congenial to LLM. In this process, we convert the found subgraph into a descriptive form. Templates can be used to transform the graph where it is filled with nodes and relationships. In some templates, you can define which are the nearest neighbors of a node and which are the most distant (1-hop and 2-hop in the graph), or you can use an LLM to transform this subgraph into a natural language description.</li>
<li><strong class="bold">Syntax tree</strong>: The graph is flattened and represented as a syntax tree. These trees have the advantage of <a id="_idIndexMarker856"/>a hierarchical structure and maintain the topological order of the graph. This approach maintains the properties of the graph but makes the information more digestible for the LLM.</li>
<li><strong class="bold">Code-like forms</strong>: Retrieved graphs <a id="_idIndexMarker857"/>can be converted into a standard format such as <strong class="bold">Graph Markup Language</strong> (<strong class="bold">GraphML</strong>). These languages are specifically designed for graphs but are <a id="_idIndexMarker858"/>a structural and textual hybrid.</li>
</ul>
<p>Conversion still presents difficulties because it must ensure that the result is concise and complete but, at the same time, understandable by the LLM. Optimally, this representation should also include the structural information of the graph. Whether<a id="_idIndexMarker859"/> the retrieved subgraph is converted or not, the result is entered into the LLM prompt and a response is generated.</p>
<div><div><img alt="Figure 7.21 – Subgraph transformation to enhance generation (https://arxiv.org/pdf/2408.08921)" src="img/B21257_07_21.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.21 – Subgraph transformation to enhance generation (<a href="https://arxiv.org/pdf/2408.08921">https://arxiv.org/pdf/2408.08921</a>)</p>
<h2 id="_idParaDest-130"><a id="_idTextAnchor129"/>GraphRAG applications</h2>
<p>GraphRAG has several applications. The first is question answering (so the same application as RAG) where we extract the subgraphs and the LLM uses them for subsequent reasoning and answering. A <a id="_idIndexMarker860"/>sub-branch of question answering is commonsense reasoning question answering where it often takes the format of multiple choice questions. For this subtask, we often do not use an LLM but a GNN or other machine learning (ML) model instead. However, KGs (and therefore also GraphRAG) have an extensive application for information retrieval, for example, if we want to investigate the relationships between some entities of interest. A KG can be used by itself to extract relationships between entities, but the addition of generation with an LLM allows us to explore these relationships and contextual nuances better. This is an attractive factor for academic and literature research. In fact, in academia, an article is authored by multiple authors who are part of different institutions. An article builds on previous research, and so for each article, there is a network of citations. These structural elements are easily modeled for a graph. An interesting application recently published shows how Ghafarollahi et al. used multiple KG agents to analyze published literature and propose <a id="_idIndexMarker861"/>new research hypotheses. In short, they extracted paths or subgraphs from a KG (constructed from 1,000 articles), then an agent analyzed the ontologies, and then a new research hypothesis was generated from this. In this interesting application, a number of agents collaborate to create new potential searches for new materials.</p>
<div><div><img alt="Figure 7.22 – Overview of the multi-agent graph-reasoning system for scientific discovery assistance (https://arxiv.org/pdf/2409.05556v1)" src="img/B21257_07_22.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.22 – Overview of the multi-agent graph-reasoning system for scientific discovery assistance (<a href="https://arxiv.org/pdf/2409.05556v1">https://arxiv.org/pdf/2409.05556v1</a>)</p>
<p>One of the reasons for interest in GraphRAG is that KGs used to be used for fact verification (after all, a KG is a collection of facts) so providing facts to an LLM should reduce LLM hallucinations. This <a id="_idIndexMarker862"/>aspect makes it particularly attractive for biomedical applications. In fact, hallucinations are a serious problem for medical decision-making applications. In medicine, if the vector RAG can reduce hallucinations, it does not allow for a holistic view, especially when an overview is needed to answer a question. Therefore, Wu et al. suggest using a GraphRAG-based approach called <strong class="bold">MedGraphRAG</strong>. In this work, they use several medical sources to create their system and take advantage of the hierarchical <a id="_idIndexMarker863"/>nature of KGs. They construct three levels for their KG. At the first level, there are user-provided documents (medical reports from a hospital). Entities at this level are then connected to a more foundational level of commonly accepted information. The second level is constructed from medical textbooks and scientific articles. Finally, at the third level, there are well-defined medical terms and knowledge relationships that have been obtained from standardized and reliable sources. Leveraging retrieval from this KG obtains state-of-the-art results on major medical question-answering benchmark datasets. The advantage is that this system also<a id="_idIndexMarker864"/> outperforms models that are fine-tuned on medical knowledge, thus with large computational savings.</p>
<div><div><img alt="Figure 7.23 – MedGraphRAG framework (https://arxiv.org/pdf/2408.04187)" src="img/B21257_07_23.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.23 – MedGraphRAG framework (<a href="https://arxiv.org/pdf/2408.04187">https://arxiv.org/pdf/2408.04187</a>)</p>
<p>A further interest in GraphRAG comes from the use of KGs to propose recommendations to users. In e-commerce platforms, recommendation systems are used to predict the future purchasing intentions of users and suggest other products of interest. Thus, it was proposed that the system matches a new user to subgraphs derived from past users with similar behavior, and leverages these to predict likely future purchases and suggest appropriate products. In addition, this approach can also be useful for the legal and financial fields. In the legal field, there are extensive citations between cases and judicial opinions, and judges use past cases and opinions to make new decisions. Given a legal case, GraphRAG could suggest previous legal cases and help in decision-making. In finance, GraphRAG might suggest previous financial transactions or customer cases.</p>
<p>Finally, up to this point, we have suggested that GraphRAG and vector RAG are antagonistic. Actually, both systems have advantages and disadvantages so it would be more useful to use them in synergy. Sarmah et al., proposed <strong class="bold">HybridRAG</strong>, where both GraphRAG and vector RAG are used in one system. Their <a id="_idIndexMarker865"/>system shows advantages in financial responses. In the future, there may be systems that exploit both one and the other approach with the addition of a router that can choose whether to search for the KG <a id="_idIndexMarker866"/>or the vector database. Alternatively, there could be more complex systems for knowledge fusion in context (especially if KG search and chunks provide some redundant information).</p>
<p>In this section, we discussed how an LLM can be connected to a KG, and how it can be used to find information that enriches the context of the LLM. In the next section, we will discuss other tasks for which the synergy of LLMs and KGs is useful.</p>
<h1 id="_idParaDest-131"><a id="_idTextAnchor130"/>Understanding graph reasoning</h1>
<p>This section is devoted to a discussion of <a id="_idIndexMarker867"/>how to solve graph data tasks. In this section, we will discuss some of the approaches used to solve tasks on knowledge graphs: KG embeddings, GNNs, and LLMs. KG embeddings and GNNs would require at least one chapter each; hence, these topics are outside the scope of the book, but we believe that an introduction to them would be beneficial to a practitioner. In fact, both embedding and GNNs can be used synergistically with LLMs and agents.</p>
<p>There are many tasks in which a model is required to understand the structure to solve, and these are collectively called <strong class="bold">graph structure understanding tasks</strong>. Many of these tasks are solved using algorithms or models <a id="_idIndexMarker868"/>designed specifically to learn these tasks. Today, a new paradigm is being developed in which we try to use LLMs to solve these tasks; we will discuss this in depth at the end of this section. Examples of tasks might be degree calculation (how many neighbors a node has), path search (defining a path between two nodes, calculating which is the minimum path, and so on), Hamilton path (identifying a path that visits each node only once), topological sorting (identifying whether nodes can be visited in topological order), and many others. Some of these tasks are simple (degree calculation and path search) but others are much more complex (topological sorting and Hamilton path).</p>
<div><div><img alt="Figure 7.24 – Graph structure understanding tasks (https://arxiv.org/pdf/2404.14809)" src="img/B21257_07_24.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.24 – Graph structure understanding tasks (<a href="https://arxiv.org/pdf/2404.14809">https://arxiv.org/pdf/2404.14809</a>)</p>
<p>Graph learning tasks, on the other hand, require the model to include not only the structure of the graph but also the attributes of the graph (features of nodes, edges, and the graph), thus understanding<a id="_idIndexMarker869"/> the semantic information of graphs. Examples of some of the tasks are node classification (classify the node according to its attributes and according to the attributes of its neighbors), graph classification (you have to understand the whole graph to classify it), edge classification, and node feature explanation (explain a feature of the node). <strong class="bold">Knowledge graph question answering</strong> (<strong class="bold">KGQA</strong>) is a task that falls into<a id="_idIndexMarker870"/> this group, as we need to understand both the structure and meaning of entities and relationships to answer questions. A similar task is conducting KG queries to generate text (this can also be seen as a subtask). KG embeddings capture multi-relational semantics and latent patterns in the graph, making them particularly useful for relational reasoning and symbolic link prediction tasks (KG link prediction, for example). GNNs, on the other hand, capture<a id="_idIndexMarker871"/> graph structure and node/edge features; these make them perform well for tasks that require inductive reasoning, use of features, or local/global representation of graph structure (node or graph classification/regression).</p>
<div><div><img alt="Figure 7.25 – Graph learning tasks (https://arxiv.org/pdf/2404.14809)" src="img/B21257_07_25.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.25 – Graph learning tasks (<a href="https://arxiv.org/pdf/2404.14809">https://arxiv.org/pdf/2404.14809</a>)</p>
<h2 id="_idParaDest-132"><a id="_idTextAnchor131"/>Knowledge graph embeddings</h2>
<p>KGs are effective in representing knowledge, but <a id="_idIndexMarker872"/>they are complex to manipulate at scale. This complicates their use when we are interested in particular tasks such as<a id="_idIndexMarker873"/> link prediction and entity classification. Therefore, <strong class="bold">knowledge graph embedding</strong> (<strong class="bold">KGE</strong>) was proposed to be able to simplify these tasks. We have already discussed the concept of embedding in the first chapter. An embedding is a projection of data into a low-dimensional and continuous vector space, which is especially useful when our data has a sparse representation (such as text and graphs). For a KG, an embedding is the projection of the graph (nodes, edges, and their feature vectors) in this reduced space. A KGE model then tries to learn a projection that preserves both structure and information, so that it can then be used for downstream tasks.</p>
<p>Learning this representation is not an easy task, and several types of algorithms have been proposed. For example, some KGEs try to preserve relational patterns between entities. TransE is an approach that embeds KGs in Euclidean space where the relationships between entities are vectors. TransE is based on the idea that two entities connected in the triplet should be as close as possible in space. Furthermore, from a triplet <code>(h, r, t)</code>, it tries to learn a space where <em class="italic">h + r ≈ t</em>, thus allowing us to do various mathematical operations. RotatE, another approach, also tries to preserve other relational patterns (symmetry, antisymmetry, inversion, and composition) using a complex vector space. This is quite useful when we want to answer questions that require this notion of symmetry (<em class="italic">marriage</em> is symmetric) or composition (<em class="italic">my nephew is my brother’s son</em>). Other methods, however, try to preserve structural patterns. In fact, larger KGs contain complex and compound <a id="_idIndexMarker874"/>structures that are lost during the embedding process. For example, hierarchical, chain structure, and ring structure are lost during classical embeddings. These structures are important when we want to conduct reasoning or extract<a id="_idIndexMarker875"/> subgraphs for some tasks. ATTH (another KG embedding method) uses hyperbolic space to preserve hierarchical structures and logical patterns at the same time. Other methods, however, try to model the uncertainties of entities and relationships, making tasks such as link prediction easier.</p>
<div><div><img alt="Figure 7.26 – Illustration of three typical structures in KGs (https://arxiv.org/pdf/2211.03536)" src="img/B21257_07_26.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.26 – Illustration of three typical structures in KGs (<a href="https://arxiv.org/pdf/2211.03536">https://arxiv.org/pdf/2211.03536</a>)</p>
<p>KGEs have been used extensively for several tasks such as link prediction. In this case, exploiting the small space is used to try to identify the most likely missing links. Similarly, continuous space allows models to be used to conduct triple classification. A further application is to use learned embeddings to recommender systems.</p>
<h2 id="_idParaDest-133"><a id="_idTextAnchor132"/>Graph neural networks</h2>
<p>There are several challenges in using graphs natively with ML algorithms. First, classical ML models take data that is in a rectangular <a id="_idIndexMarker876"/>or grid-like form, making it non-intuitive how to apply it to graphs. In addition, for a graph, there are several pieces of information that we want to use to solve tasks: nodes, edges, global context, and connectivity. The last one is particularly difficult to represent, and we usually use <a id="_idIndexMarker877"/>an adjacency matrix. This representation is sparse, grows largely with the number of nodes in the graph, and thus is space inefficient. Also, since there is no order in the graph, we can get several adjacency matrices that convey the same information but may not be recognized by a model.</p>
<p>A GNN is a deep learning model that natively takes a graph and also exploits its structure during its learning process. There are different types of GNNs (in the <em class="italic">Further reading</em> section, there are some reviews so you can go into more detail on this topic) but here we will focus on the main <a id="_idIndexMarker878"/>framework: message passing. Most GNNs can be seen as graph convolution networks in which we aggregate for each node the information coming from its neighbors. One of the advantages of a GNN is that at<a id="_idIndexMarker879"/> the same time as it is being trained for a task, it learns an embedding for each node. At each step, this node embedding is updated with information from its neighbors.</p>
<p>The message-passing framework is in a sense very similar to a neural network, as we saw earlier. In this case, there are two main steps: gather the embeddings of the various neighboring nodes and then follow by an aggregation function (which can be different depending on various architectures) and a nonlinearity. Then, at each step, we conduct an update of the embedding of each node, learning a new representation of the graph. A classical GNN can be composed of a series of GNN blocks and then a final layer that exploits the learned representation to accomplish a task. This can be written in a formula like this:</p>
<p><mml:math display="block"><mml:msubsup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>∙</mml:mo><mml:mrow><mml:munder><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>w</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="script">N</mml:mi><mml:mo>(</mml:mo><mml:mi>v</mml:mi><mml:mo>)</mml:mo><mml:mo>⋃</mml:mo><mml:mo>{</mml:mo><mml:mi>v</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:munder><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mrow><mml:msubsup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:math></p>
<p>Here, at layer <em class="italic">l+1</em>, we learn a representation, <em class="italic">h</em>, based on the previous embedding. <em class="italic">W</em> is a layer-specific weight matrix, <em class="italic">v</em> is a node, <em class="italic">w</em> is the set of neighbors, and <em class="italic">c</em> is the normalization coefficient.</p>
<div><div><img alt="Figure 7.27 – GNNs" src="img/B21257_07_27.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.27 – GNNs</p>
<p>In this case, we are assuming that each neighbor’s contribution is the same. This may not be the case, so inspired by the attention mechanism of RNNs and transformers, <strong class="bold">graph attention networks</strong> (<strong class="bold">GATs</strong>) have been <a id="_idIndexMarker880"/>proposed. In this type of GNN, the model learns different levels of importance for each neighbor. Several models of GNN layers exist today, but basically, the principle<a id="_idIndexMarker881"/> does not change much.</p>
<p>GNNs have been successfully used for several graph tasks but still have some limitations such as difficult scalability, problems with batching, and so on. They have also been applied to KGs, but they increase complexity.</p>
<h2 id="_idParaDest-134"><a id="_idTextAnchor133"/>LLMs reasoning on knowledge graphs</h2>
<p>LLMs have the advantage that they are not trained for a specific task but acquire a broad spectrum of skills during training. In addition, LLMs have reasoning skills that can be improved with specific approaches. Therefore, several researchers have suggested conducting graph reasoning with LLMs. The <a id="_idIndexMarker882"/>main method of approaching an LLM is to use a prompt as input. There are three approaches:</p>
<ul>
<li><strong class="bold">Manual prompt</strong>: The simplest<a id="_idIndexMarker883"/> approach is to <a id="_idIndexMarker884"/>provide a prompt to <a id="_idIndexMarker885"/>an LLM in which they are asked to solve a task on a graph. In the prompt, the graph is entered and additional information can be added (e.g., if we want the LLM to <a id="_idIndexMarker886"/>conduct a <strong class="bold">depth-first search</strong> (<strong class="bold">DFS</strong>) algorithm to solve the task, we provide a succinct explanation of how this algorithm works). A limitation to these prompts is that it is not possible to insert wide graphs within a prompt (limitation due to the context length of the LLM).</li>
<li><strong class="bold">Self-prompting</strong>: The<a id="_idIndexMarker887"/> LLM conducts a continuous update of the prompt to make it easier for the LLM to solve tasks. In other words, given an original prompt, the LLM conducts prompt<a id="_idIndexMarker888"/> updates to better define tasks and how to resolve them. Then, based on the output of the LLM, a new prompt is generated and fed back to the LLM. This process can be conducted multiple times to refine the output.</li>
<li><strong class="bold">API call prompts</strong>: This type <a id="_idIndexMarker889"/>of prompt is<a id="_idIndexMarker890"/> inspired by agents, in which the LLM is provided with a set of APIs that it can invoke to conduct reasoning about graphs or other external tools.</li>
</ul>
<div><div><img alt="Figure 7.28 – Prompting methods for the LLM applied to graph tasks (https://arxiv.org/pdf/2404.14809)" src="img/B21257_07_28.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.28 – Prompting methods for the LLM applied to graph tasks (<a href="https://arxiv.org/pdf/2404.14809">https://arxiv.org/pdf/2404.14809</a>)</p>
<p>The alternative to finding complex prompting strategies is the <strong class="bold">supervised fine-tuning</strong> (<strong class="bold">SFT</strong>) method. In this case, a dataset<a id="_idIndexMarker891"/> with graph tasks and their solutions is used to train the model to improve its reasoning skills.</p>
<p>Another interesting aspect of LLMs is that they can also be used in combination with other models. This allows their qualities to be exploited with models that are specialized and better suited for certain tasks. For example, we can combine LLMs with GNNs, in which case LLMs can function as enhancers of GNNs. The GNN handles graph structure much better than the LLM, but the latter <a id="_idIndexMarker892"/>handles textual attributes much better. We can then capitalize on the strengths <a id="_idIndexMarker893"/>of the two models to have a much stronger synergistic model. LLMs possess greater semantic and syntactic capacity than other models, and this allows them to create powerful textual embeddings. An LLM can then generate numerical embeddings that are then used by the GNN as node features. For example, we have a citation network between scientific articles (our graph where each node is an article) and we want to classify articles into various topics. We can take the abstract for each article and use an LLM to create an embedding of the abstract. These number vectors will be the node features for the articles. At this point, we can train our GNN with better results than without features. Alternatively, if the node features are textual, we can use an LLM to generate labels. For example, for our article network, we have the article titles associated with each node, and we use the LLM in a zero-shot setting to generate a set of labels. This is useful because manual annotation is expensive, so we can get labels much more quickly. When we have obtained the labels, we can train a GNN on the graph. Alternatively, we can also think of conducting fine-tuning of the LLM and GNN at the same time for tasks.</p>
<div><div><img alt="Figure 7.29 – LLM and GNN synergy" src="img/B21257_07_29.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.29 – LLM and GNN synergy</p>
<p>Another interesting approach is graph-formed reasoning. Several of the prompting techniques that have been used for reasoning<a id="_idIndexMarker894"/> do not take into account that human thinking is not linear, so according to<a id="_idIndexMarker895"/> some, this method of reasoning can be approximated using graphs. There are two types of approaches that take advantage of this idea:</p>
<ul>
<li><code>Distance = 60 km</code>, <code>Time = 1.5 hours</code>, <code>Use speed = distance ÷ time</code>, and <code>Speed = 40 km/h</code>, with edges showing how each thought leads to the next. This graph structure enables the model to reason step by step, explore alternatives, or verify calculations.</li>
<li><strong class="bold">Verify on the graph</strong>: In this approach, we use a graph to verify the correctness and consistency of the reasoning. For example, if different paths should lead to a logical conclusion, they should be the same or similar. So, if there is a contradiction, it means<a id="_idIndexMarker897"/> the reasoning is wrong. Generally, one generates several reasonings<a id="_idIndexMarker898"/> for a question, structures them as a graph, and analyzes them to improve the final answer. This approach requires a verifier who analyzes this graph, usually another LLM.</li>
</ul>
<div><div><img alt="Figure 7.30 – Think on graphs and verify on graphs (https://arxiv.org/pdf/2404.14809)" src="img/B21257_07_30.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.30 – Think on graphs and verify on graphs (<a href="https://arxiv.org/pdf/2404.14809">https://arxiv.org/pdf/2404.14809</a>)</p>
<p>In this section, we discussed the intricate relationship between graphs and LLMs and how they can enable us to solve some tasks that were previously conducted with graph ML algorithms. In the next section, we will discuss exciting perspectives in the field of some questions that remain open.</p>
<h1 id="_idParaDest-135"><a id="_idTextAnchor134"/>Ongoing challenges in knowledge graphs and GraphRAG</h1>
<p>KGs are a powerful medium for storing and organizing information, but there are still limitations and open questions. Especially for<a id="_idIndexMarker899"/> large KGs, scalability is important; a <a id="_idIndexMarker900"/>balance must be struck between expressiveness and computational efficiency. Plus building a KG requires a lot of computational effort (using an LLM to extract triplets from a large corpus of text can be expensive and require adequate infrastructure). In addition, once the KG is built, it must be evaluated and cleaned, which also requires some effort (manual or computational). Moreover, growth in the KG also means growth in the infrastructural cost to enable access or use. Querying large KGs requires having optimized algorithms to avoid the risk of <a id="_idIndexMarker901"/>increasingly large latency times. Industrial KGs can contain billions of entities and <a id="_idIndexMarker902"/>relationships, representing an intricate and complex scale. Many of the algorithms are designed for small-scale KGs (up to thousands of entities) so retrieval in large-scale KGs still remains challenging.</p>
<p>In addition, KGs are notoriously incomplete, which means that one must have pipelines in order to complete the KG. This means having both pipelines to add additional sources and pipelines to conduct the update of data sources. Most databases are static, so creating dynamic systems is challenging. This is critical to make the best use of KGs for domains such as finance, where we want to account for rapid market changes. On a side note, KGs can be multimodal, but integrating these modes is not easy at all. While adding modalities significantly improves the reasoning process, the understanding of the nuances of stored knowledge, and the richness of the KG, it significantly increases management complexity (more storage required, more sophisticated pipelines, more complex knowledge harmonization, and so on).</p>
<p>GraphRAG is a relatively new technology and still not fully optimized. For one thing, information retrieval could be improved, especially the transition between the user’s text query and retrieval on the KG. The more the KG grows, the more there is a risk of finding redundant information that harms the generation process. After retrieval, we could then end up with a long context that is provided to the LLM for generation. To reduce noise and reduce computation, we can compress the context, but this carries the risk of information loss. At present, lossless compression is an active field of research, while current methods allow, at most, a trade-off between compression and information preservation. There is also currently a lack of benchmark standards to evaluate new GraphRAG approaches; this does not allow for an easy comparison of either current or future methods. GraphRAG allows for considering inter-entity relationships and structural knowledge information, reducing redundant text information, and being able to find global information again. At the same time, though, the nuances of the text are lost, and GraphRAG underperforms in abstractive question-answering tasks or when there is no explicit entity mentioned in the question. So, the union of vector and GraphRAG (or HybridRAG) is an exciting prospect for the future. It remains interesting to understand how these two technologies will be integrated in an optimal way.</p>
<p>An important note is that LLMs are not specifically trained for graph tasks. As we mentioned in <a href="B21257_03.xhtml#_idTextAnchor042"><em class="italic">Chapter 3</em></a>, LLMs are trained to predict the next word in a sequence. By optimizing this simple goal, they acquire most of their skills. Obviously, it is difficult to assimilate a spatial understanding simply from text. This means that LLMs generally struggle with structural data. This is highlighted with tabular data, where LLMs have problems with understanding tables and relationships. The first problem is that LLMs struggle with numerical representation <a id="_idIndexMarker903"/>since the tokenization step makes it difficult for an LLM to understand the whole<a id="_idIndexMarker904"/> number (lack of consistent decimal representation, and problems with numerical operation). This then impacts the execution of graph tasks where this numerical understanding is necessary. Specific studies on graph understanding show that LLMs have a basic understanding of graph structure. LLMs understand these graphs in linear form and better understand the labels associated with the nodes more than the topological structure of the graph. According to these studies, LLMs have a basic understanding, which is strongly impacted by prompt design, prompt techniques, semantic information provided, and the presence of examples. Next-generation, multi-parameter LLMs succeed in solving simple tasks on small graphs, but their performance decays rapidly as both graph and task complexity increase. There are two reasons for this lack of understanding of structural data. The first is that in the large text corpora used for training LLMs, there is not much graph-derived data. So, LLMs can only learn basic spatial relationships because these are described in the texts. Therefore, SFT on graph datasets allows for results that are better than much larger models.</p>
<div><div><img alt="Figure 7.31 – SFT on graph data allows better performance for small LLMs than larger LLMs (https://arxiv.org/pdf/2403.04483)" src="img/B21257_07_31.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.31 – SFT on graph data allows better performance for small LLMs than larger LLMs (<a href="https://arxiv.org/pdf/2403.04483">https://arxiv.org/pdf/2403.04483</a>)</p>
<p>The second reason, on the other hand, stems from why humans understand spatial structures well. Humans learn <a id="_idIndexMarker905"/>spatial relationships from their experiences in the outside world. The brain creates<a id="_idIndexMarker906"/> mental maps that allow us to orient ourselves in space. These maps also enable us to better understand abstract spatial concepts such as graphs. LLMs do not have a mental map nor can they have the experience of the outside world, thus making them disadvantaged in understanding abstract spatial concepts.</p>
<h1 id="_idParaDest-136"><a id="_idTextAnchor135"/>Summary</h1>
<p>In <em class="italic">Chapters 5</em> and <em class="italic">6</em>, the main question was how to find information and how to use this information to generate an answer to users’ questions. Finding information dynamically allows us to reduce the hallucinations of our model and keep its knowledge up to date.</p>
<p>In this chapter, we started with a text corpus and created a system to find the most relevant information for generating an answer (naïve RAG). Next, we created a more sophisticated system to try to extract only the relevant information and avoid redundant information or noise. For some researchers, by its nature, text contains relevant information intermixed with background noise. What matters are the entities present and their relationships. From this reductionist approach comes the idea of representing essential knowledge in a knowledge graph. The graph allows us to use algorithms to search for information or explore possible connections. For a long time, graph reasoning and LLMs have run on parallel tracks, but recently, their stories have begun to intertwine. We have seen how this interaction between LLM and KG can be conducted in various ways. For example, an LLM can be used to extract relationships and entities for our graph construction, or an LLM can be used to conduct reasoning about the KG. Similarly, we can use the KG to find knowledge and enrich the context of the LLM, thus enabling it to effectively answer a user question.</p>
<p>Right now, there is a sort of a Manichean definition: either the vector RAG or the GraphRAG. Both have merits and demerits, and the research points toward a unification of these two worlds (HybridRAG). In the future, we will find more sophisticated ways of uniting KGs and vectors. Also, the understanding of the graph structure on one side of an LLM is still immature. With the growth of training datasets, the new generation LLMs are exposed to more examples of graphs. However, understanding spatial relationships in an abstract concept such as a graph also means understanding them in problems with greater real-world relevance. Therefore, this is an active field of research, especially for robots that must interact in space and use AI.</p>
<p>Moving into space is one of the next frontiers of AI. Interaction in space presents peculiar challenges, such as balancing exploration and exploitation. In the next chapter, we will discuss this concept more abstractly. We will focus on reinforcement learning and agent behavior in the relationship to space. Whether chess, a video game, or a real-world environment, an agent must learn how to interact with space to achieve a goal. In the next chapter, we will look at how to enable an agent to explore the world without losing sight of the aim.</p>
<h1 id="_idParaDest-137"><a id="_idTextAnchor136"/>Further reading</h1>
<ul>
<li>Ghafarollahi, <em class="italic">SciAgents: Automating Scientific Discovery through Multi-agent Intelligent Graph Reasoning</em>, 2024, <a href="https://arxiv.org/pdf/2409.05556v1">https://arxiv.org/pdf/2409.05556v1</a></li>
<li>Raieli, <em class="italic">A Brave New World for Scientific Discovery: Are AI Research Ideas Better?</em>, 2024, <a href="https://levelup.gitconnected.com/a-brave-new-world-for-scientific-discovery-are-ai-research-ideas-better-5692c5aa8182">https://levelup.gitconnected.com/a-brave-new-world-for-scientific-discovery-are-ai-research-ideas-better-5692c5aa8182</a></li>
<li>Raieli, <em class="italic">How the LLM Got Lost in the Network and Discovered Graph Reasoning</em>, 2024, <a href="https://towardsdatascience.com/how-the-llm-got-lost-in-the-network-and-discovered-graph-reasoning-e2736bd04efa">https://towardsdatascience.com/how-the-llm-got-lost-in-the-network-and-discovered-graph-reasoning-e2736bd04efa</a></li>
<li>Wu, <em class="italic">Medical Graph RAG: Towards Safe Medical Large Language Model via Graph Retrieval-Augmented Generation</em>, 2024, <a href="https://arxiv.org/abs/2408.04187">https://arxiv.org/abs/2408.04187</a></li>
<li>Raieli, <em class="italic">The Convergence of Graph and Vector RAGs: A New Era in Information Retrieval</em>, 2024, <a href="https://medium.com/gitconnected/the-convergence-of-graph-and-vector-rags-a-new-era-in-information-retrieval-b5773a723615">https://medium.com/gitconnected/the-convergence-of-graph-and-vector-rags-a-new-era-in-information-retrieval-b5773a723615</a></li>
<li>Sarmah, <em class="italic">HybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction</em>, 2024, <a href="https://arxiv.org/pdf/2408.04948">https://arxiv.org/pdf/2408.04948</a></li>
<li>Liang, <em class="italic">Survey of Graph Neural Networks and Applications</em>, 2022, <a href="https://onlinelibrary.wiley.com/doi/10.1155/2022/9261537">https://onlinelibrary.wiley.com/doi/10.1155/2022/9261537</a></li>
<li>Arora, <em class="italic">A Survey on Graph Neural Networks for Knowledge Graph Completion</em>, 2020, <a href="https://arxiv.org/pdf/2007.12374">https://arxiv.org/pdf/2007.12374</a></li>
<li>Huang, <em class="italic">Can LLMs Effectively Leverage Graph Structural Information through Prompts, and Why?</em>, 2023, <a href="https://arxiv.org/abs/2309.16595">https://arxiv.org/abs/2309.16595</a></li>
<li>Liu, <em class="italic">Evaluating Large Language Models on Graphs: Performance Insights and Comparative Analysis</em>, 2023, <a href="https://arxiv.org/abs/2308.11224">https://arxiv.org/abs/2308.11224</a></li>
</ul>
</div>
</body></html>