- en: ES-HyperNEAT and the Retina Problem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you will learn about the ES-HyperNEAT extension of the HyperNEAT
    method, which we discussed in the previous chapter. As you learned in the previous
    chapter, the HyperNEAT method allows the encoding of larger-scale **artificial
    neural network** (**ANN**) topologies, which is essential for working in areas
    where the input data has a large number of dimensions, such as computer vision.
    However, despite all its power, the HyperNEAT method has a significant drawback—the
    configuration of the ANN substrate should be designed beforehand by a human architect.
    The ES-HyperNEAT method was invented to address this issue by introducing the
    concept of evolvable-substrate, which allows us to produce the appropriate configuration
    of the substrate automatically during evolution.
  prefs: []
  type: TYPE_NORMAL
- en: After familiarizing yourself with the basics of the ES-HyperNEAT method, you
    will have a chance to apply this knowledge to solve the modular retina problem.
    During this task, we will show you how to choose an appropriate initial substrate
    configuration that helps the evolutionary process to discover the modular structures.
    Also, we will discuss the source code of the modular retina problem solver along
    with the test environment, which can be used to evaluate the fitness of each detector
    ANN.
  prefs: []
  type: TYPE_NORMAL
- en: Through this chapter, you will gain hands-on experience with applying the ES-HyperNEAT
    method using the MultiNEAT Python library.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Manual versus evolution-based configuration of the topography of neural nodes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Quadtree information extraction and ES-HyperNEAT basics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The modular left and right retina experiment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Discussion of the experiment results
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following technical requirements should be met to execute the experiments
    described in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Windows 8/10, macOS 10.13 or newer, or modern Linux
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Anaconda Distribution version 2019.03 or newer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The code for this chapter can be found at [https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Python/tree/master/Chapter8](https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Python/tree/master/Chapter8)
  prefs: []
  type: TYPE_NORMAL
- en: Manual versus evolution-based configuration of the topography of neural nodes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The HyperNEAT method, which we discussed in [Chapter 7](21fb699f-605d-4156-aa5c-5ba501dc09cf.xhtml),
    *Hypercube-Based NEAT for Visual Discrimination*, allows us to use neuroevolution
    methods for a broad class of problems that require the use of large-scale ANN
    structures to find a solution. This class of problem spreads across multiple practical
    domains, including visual pattern recognition. The main distinguishing feature
    of all these problems is the high dimensionality of the input/output data.
  prefs: []
  type: TYPE_NORMAL
- en: In the previous chapter, you learned how to define the configuration of the
    substrate of the discriminator ANN to solve a visual discrimination task. You
    also learned that it is crucial to use an appropriate substrate configuration
    that is aligned with the geometric features of the search space of the target
    problem. With the HyperNEAT method, you, as an architect, need to define the substrate
    configuration beforehand, using only your understanding of the spatial geometry
    of the problem. However, it is not always possible to learn about all the geometric
    regularities hidden behind a specific problem space.
  prefs: []
  type: TYPE_NORMAL
- en: If you design the substrate manually, you create an unintentional constraint
    on the pattern of weights drawn over it by the connective**Compositional Pattern
    Producing Networks** (**CPPNs**). By placing nodes at specific locations in the
    substrate, you interfere with the ability of the CPPN to discover the geometric
    regularities of the natural world. The CPPN should produce a connectivity pattern
    that is perfectly aligned with the structure of the substrate that you provided,
    and connections are only possible between the nodes of this structure. This limitation
    leads to unnecessary approximation errors, which taints the results when you use
    an evolved CPPN to create the topology of the solution-solver ANN (the phenotype).
  prefs: []
  type: TYPE_NORMAL
- en: 'However, why are the limitations that are introduced with manual substrate
    configuration inflicted in the first place? Would it be better if the CPPN could
    elaborate on the connectivity patterns between the nodes of the substrate that
    are automatically positioned in the right locations in the substrate? It seems
    that evolving connectivity patterns in the substrate provides valuable implicit
    hints that help us to estimate the nodes'' positions for the next epoch of the
    evolution. The method of substrate configuration evolution during the CPPN training
    got a name: **Evolvable-Substrate**.'
  prefs: []
  type: TYPE_NORMAL
- en: The implicit data allowing us to estimate the position of the next node is the
    amount of the information encoded by the connectivity pattern in the specific
    substrate area. The areas with a uniform distribution of connection weights encode
    a small amount of information, thereby requiring only a few substrate nodes in
    those areas. At the same time, substrate areas with large gradients of connection
    weights are informationally intensive and can benefit from additional nodes placed
    within those areas. When you place an additional node in such areas of the substrate,
    you allow the CPPN to represent the much more granular encoding of the natural
    world. Thus, the placement of the nodes and the connectivity pattern can be mandated
    by the distribution of the connection weights while the CPPN produces the connection
    weights during the evolution.
  prefs: []
  type: TYPE_NORMAL
- en: HyperNEAT represents each connection between two nodes of the substrate as a
    point in the four-dimensional hypercube. The evolvable-substrate HyperNEAT algorithm
    extends HyperNEAT by automatically placing fewer hyperpoints in the areas of the
    hypercube with lower variation in the connection weights. Thus, ES-HyperNEAT uses
    information density as the primary guiding principle when determining the topology
    of the substrate during the evolution.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we discuss the particulars of the ES-HyperNEAT algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Quadtree information extraction and ES-HyperNEAT basics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For the effective calculation of the information density within the connectivity
    patterns of the substrate, we need to use an appropriate data structure. We need
    to employ a data structure that allows an effective search through the two-dimensional
    substrate space at different levels of granularity. In computer science, there
    is a data structure that perfectly fits these requirements. This structure is
    the **quadtree**.
  prefs: []
  type: TYPE_NORMAL
- en: The quadtree is a data structure that allows us to organize an effective search
    through two-dimensional space by splitting any area of interest into four subareas.
    Each of these subareas consequently becomes a leaf of a tree, with the root node
    representing the initial region.
  prefs: []
  type: TYPE_NORMAL
- en: ES-HyperNEAT employs the quadtree data structure to iteratively look for the
    new connections and nodes in the substrate, starting from the input and the output
    nodes predefined by the data scientist. Using a quadtree to search for new connections
    and nodes is much more computationally effective than searching in the four-dimensional
    space of the hypercube.
  prefs: []
  type: TYPE_NORMAL
- en: 'The scheme of information extraction using the quadtree structure is shown
    in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e7cca6a3-0382-4424-b28f-3b759c53f33e.png)'
  prefs: []
  type: TYPE_IMG
- en: The scheme of information extraction
  prefs: []
  type: TYPE_NORMAL
- en: 'The information extraction method depicted in the diagram has two major parts:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The **division and initialization** stage is presented in the top part of the
    diagram. At this stage, the quadtree is created by recursively dividing the initial
    substrate area, which spans from (*-1*, *-1*) to (*1, 1*). The division stops
    when the desired depth of the quadtree is reached. Now we have several subspaces
    that are fitted into the substrate, determining the initial substrate resolution
    (*r*). Next, for every node of the quadtree with a center at (![](img/7b9cf86d-a9b4-429d-bc7e-faa039aa599c.png),![](img/058e9c7f-9dc4-42db-9c59-311c42c52554.png)),
    we query the CPPN to find a connection weight (*w*) between this node and a specific
    input or output neuron at coordinates (*a, b*). When we have calculated the connection
    weights for the* k* leaf nodes in the subtree of the quadtree, *p*, we are ready
    to calculate the information variance of the node, *p*, in the quadtree as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/4c372061-3f19-40ba-90fe-8c7d3773a415.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/806e14e4-960c-4327-bd4c-d6c048112dd3.png) is the mean connection weight
    among *k* leaf nodes and ![](img/7567b3d8-2e17-4436-9d1b-8bc18199c6ee.png) is
    a connection weight to each leaf node.'
  prefs: []
  type: TYPE_NORMAL
- en: We can use this estimated variance value as a heuristic indicator of the information
    density in the specific subarea of the substrate. The higher this value, the higher
    the information density. The variance can be used to manage the information density
    in the specific subarea of the substrate by introducing the **division threshold** constant.
    If the variance is greater than the division threshold, then the division stage
    is repeated until the desired information density is reached.
  prefs: []
  type: TYPE_NORMAL
- en: At this stage, we create an indicative structure that allows the CPPN to decide
    where to make connections within the given substrate. The next stage of the processing
    places all necessary connections using the created quadtree structure.
  prefs: []
  type: TYPE_NORMAL
- en: The** pruning and extraction** stage is represented in the bottom part of the
    diagram. In this stage, we use the populated quadtree structure from the previous
    stage to find the regions with high variance and make sure that more connections
    are expressed among the nodes of these regions. We traverse the quadtree depth-first
    and stop the traversal at the node that has a variance value that's smaller than
    the given** variance threshold **(![](img/00f974a1-7ad2-4378-a76b-079f334dc42b.png))
    or when the current node has no children (that is, has zero variance). For every
    quadtree node found by the depth-first search, we express the connection between
    the center of the node (*x*, *y*) and each parent node that is already determined.
    The parent node can either be determined by an architect (input/output nodes)
    or be found in the previous runs of the information extraction method, that is,
    from hidden nodes already created by the ES-HyperNEAT method. When this stage
    completes, the substrate configuration will have more nodes in the informationally
    intensive substrate regions and fewer nodes in the regions encoding a small amount
    of information.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the following section, we will discuss how to use the ES-HyperNEAT algorithm
    we've just described to find a solution for the modular retina problem.
  prefs: []
  type: TYPE_NORMAL
- en: For more details about the ES-HyperNEAT algorithm, refer to [Chapter 1](f59c6396-55e5-4495-95c0-7af9a42c2f20.xhtml),
    *Overview of Neuroevolution Methods*.
  prefs: []
  type: TYPE_NORMAL
- en: Modular retina problem basics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The hierarchical modular structures are an essential part of the complex biological
    organisms and play an indispensable role in their evolution. The modularity enhances
    the evolvability, allowing the recombination of various modules during the evolution
    process. The evolved hierarchy of modular components bootstraps the evolution
    process, allowing operations over a collection of complex structures rather than
    basic genes. After that, the neuroevolutionary process does not need to spend
    time to evolve similar functionality from scratch again. Instead, the ready-to-use
    modular components can be used as building blocks to produce very complex neural
    networks.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will implement a solution to the retina problem using the
    ES-HyperNEAT algorithm. The retina problem is about the simultaneous identification
    of valid 2x2 patterns on the left and the right side of an artificial retina that
    has a resolution of 4x2\. Thus, the detector ANN must decide if the patterns presented
    on the left and the right side of the retina are valid for the corresponding side
    of the retina (left or right).
  prefs: []
  type: TYPE_NORMAL
- en: In the retina problem, the left and the right problem components are perfectly
    separated into different functional units. At the same time, some components can
    be present on each side of the retina, while others are unique to a specific part
    of the retina. Thus, to produce a successful detector ANN, the neuroevolution
    process needs to discover the modular structures separately for the left and the
    right detection zones.
  prefs: []
  type: TYPE_NORMAL
- en: 'The retina problem scheme is shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6015ae45-08dd-4dcd-afcf-3af1767e3ab2.png)'
  prefs: []
  type: TYPE_IMG
- en: The retina problem scheme
  prefs: []
  type: TYPE_NORMAL
- en: As you can see in the preceding diagram, the artificial retina is represented
    as a 2D grid with a resolution of 4x2 pixels. The values of the two-dimensional
    array representing the patterns drawn on the retina constitute the inputs of the
    detector ANN. The filled pixels in the array have a value of `1.0` and the empty
    pixels have a value of `0.0`. With the given resolution, it is possible to draw
    16 different 2x2 patterns for the left and the right parts of the retina. Thus,
    we have eight valid patterns for the left side and eight valid patterns for the
    right side of the retina. Some of the patterns mentioned are valid for both sides
    of the retina.
  prefs: []
  type: TYPE_NORMAL
- en: 'The scheme of decision-making by the detector ANN in the retina problem domain
    is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4a0213e3-11fc-47ec-a951-e49296ae65fc.png)'
  prefs: []
  type: TYPE_IMG
- en: The scheme of decision making by the detector ANN
  prefs: []
  type: TYPE_NORMAL
- en: The detector ANN has eight inputs to accept input data patterns from both sides
    of the retina and two output nodes. Each of the output nodes produces a value
    that can be used to classify the pattern's validity at each side of the retina.
    The first output node is assigned to the left and the second node to the right
    side of the retina correspondingly. The activation value of the output node that
    is greater than or equal to `0.5` classifies the pattern for the related side
    of the retina as valid. If the activation value is less than `0.5`, the pattern
    is considered not valid. To even further simplify the detection, we apply rounding
    to the values of the output nodes according to the rounding scheme shown in the
    diagram. Thus, each output node of the detector ANN serves as a binary classifier
    for the related part of the retina that produces a value of `0.0` or `1.0` to
    mark the input pattern as invalid or valid correspondingly.
  prefs: []
  type: TYPE_NORMAL
- en: Objective function definition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The task of the detector ANN is to correctly classify the inputs from the left
    and right sides of the retina as valid or not by producing a vector of the binary
    outputs with values of `0.0` or `1.0`. The output vector has a length of 2, which
    is equal to number of the output nodes.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can define the detection error as the Euclidean distance between the vector
    with ground truth values and the vector with ANN output values, as given by the
    following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/264a3ace-8838-4bf8-a668-371867d9bc28.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/9132f8c9-c333-422f-a337-a3652a762eae.png) is the squared detection
    error for one trial, ![](img/75051026-cfcc-4719-9751-778e01da36aa.png) is the
    vector with detector ANN outputs, and ![](img/a1fbc606-d1ef-4b6e-9a30-29a33ff88b84.png)
    is the vector with the ground truth values.'
  prefs: []
  type: TYPE_NORMAL
- en: 'At each generation of the evolution, we evaluate each detector ANN (phenotype)
    against all 256 possible combinations of 4x4 retina patterns, which are produced
    by combining 16 different 2x2 patterns for each side of the retina. Thus, to get
    a final detection error value for the particular detector ANN, we calculate the
    sum of 256 error values obtained for each configuration of the retina patterns,
    as indicated by the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4c0370c0-7e99-48b6-a17e-607e740979a1.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/653fbe3d-5f27-475f-b9c4-f46b68d9ce66.png) is the sum of all errors
    obtained during 256 trials and ![](img/debe4e93-4cab-486d-bc3e-8161c06bf4af.png) is
    the squared detection error for a particular trial.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The fitness function can be defined as the inverse of the sum of the errors
    obtained from all 256 trials against all possible retina patterns, as shown in
    the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/da755433-17e7-417d-8e5d-0cb93ed122fe.png)'
  prefs: []
  type: TYPE_IMG
- en: We add `1.0` to the sum of errors (![](img/bd661974-d4b9-45c8-b734-3585e3f849ef.png))
    in the denominator to avoid dividing by 0 in cases when all trials produce no
    error. Thus, according to the fitness function formula, the maximum value of the
    fitness score in our experiment is `1000.0`, which we will use as a fitness threshold
    value later.
  prefs: []
  type: TYPE_NORMAL
- en: Modular retina experiment setup
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we discuss the details of an experiment aimed at creating a
    successful solver of the modular retina problem. In our experiment, we use this
    problem as a benchmark to test the ability of the ES-HyperNEAT method to discover
    modular topologies in the phenotype ANN.
  prefs: []
  type: TYPE_NORMAL
- en: The initial substrate configuration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As described earlier in the chapter, the retina has dimensions of 4x2, with
    two 2x2 areas, one on the left side and one on the right side. The particulars
    of the retina geometry must be represented in the geometry of the initial substrate
    configuration. In our experiment, we use a three-dimensional substrate, as shown
    in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8a75c354-2a52-42a3-ba74-c43d033e7e8f.png)'
  prefs: []
  type: TYPE_IMG
- en: The initial substrate configuration
  prefs: []
  type: TYPE_NORMAL
- en: As you can see in the diagram, the input nodes are placed within the XZ plane,
    which is orthogonal to the XY plane. They are presented in two groups, with four
    nodes to describe the left and right sides of the retina. The two output and bias
    nodes are located within the XY plane, which divides the Z-plane in half with
    the input nodes. The evolution of the substrate creates new hidden nodes in the
    same XY plane where the output nodes are located. The evolved connective CPPN
    draws the connectivity patterns between all nodes within the substrate. Our ultimate
    goal is to evolve the CPPN and the substrate configuration, which produces an
    appropriate modular graph of the detector ANN. This graph should include two modules,
    each representing an appropriate configuration for the binary classifier, which
    we discussed earlier. Let's now look at the test environment for the modular retina
    problem.
  prefs: []
  type: TYPE_NORMAL
- en: Test environment for the modular retina problem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First, we need to create a test environment that can be used to evaluate the
    results of the neuroevolution process that aims to create a successful detector
    ANN. The test environment should create a dataset that consists of all possible
    patterns of pixels on the retina. Also, it should provide functions to evaluate
    the detector ANN against each pattern in the dataset. Thus, the test environment
    can be divided into two main parts:'
  prefs: []
  type: TYPE_NORMAL
- en: The data structure to hold visual patterns for the left-hand, the right-hand,
    or both sides of the retina
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The test environment storing the dataset and providing functions for detector
    ANN evaluation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the following sections, we provide a detailed description of each part.
  prefs: []
  type: TYPE_NORMAL
- en: The visual object definition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Each of the allowed configurations of pixels in the specific part of the retina
    space can be represented as a separate visual object. The Python class encapsulating
    the related functionality is named `VisualObject` and is defined in the `retina_experiment.py`
    file. It has the following constructor:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The constructor receives the configuration of a particular visual object as
    a string, along with a valid location for this object in the retina space. After
    that, it assigns received parameters to the internal fields and creates a two-dimensional
    data array holding the states of the pixels in the visual object.
  prefs: []
  type: TYPE_NORMAL
- en: 'The pixels'' states are obtained by parsing the visual object configuration
    string as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The visual object configuration string has four characters, excluding the line
    break, which define the state of the corresponding pixel in the visual object.
    If the symbol at a specific position in the configuration line is `o`, then the
    pixel at the corresponding position of the visual object is set to the ON state,
    and the value `1.0` is saved to the data array at this position.
  prefs: []
  type: TYPE_NORMAL
- en: The retina environment definition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The retina environment creates and stores the dataset consisting of all possible
    visual objects and provides functions for evaluating the fitness of the detector
    ANN. It has the following main implementation parts.
  prefs: []
  type: TYPE_NORMAL
- en: The function to create a dataset with all the possible visual objects
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this function, we create the visual objects for the dataset as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code creates visual objects for the left side of the retina.
    The visual objects for the right side can be created in a similar way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The created objects appended to the list of the visual objects are defined as
    a dataset for evaluating the fitness of the detector ANN produced by the neuroevolution
    process from the substrate.
  prefs: []
  type: TYPE_NORMAL
- en: The function to evaluate the detector ANN against two specific visual objects
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This function evaluates the performance of the detector ANN against two given
    visual objects—one for each side of the retina space. For the complete source
    code, please refer to the `def _evaluate(self, net, left, right, depth, debug=False)` function
    defined at [https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Python/blob/master/Chapter8/retina_environment.py](https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Python/blob/master/Chapter8/retina_environment.py).
  prefs: []
  type: TYPE_NORMAL
- en: 'The source code of the function has the following essential parts:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we prepare the inputs for the detector ANN in the order that they are
    defined in for the substrate configuration:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The `inputs` array starts with the left-side data and continues with the right-side
    data. After that, the bias value is appended to the end of the `inputs` array
    and the array data is supplied as input to the detector ANN.
  prefs: []
  type: TYPE_NORMAL
- en: 'After a specific number of activations of the detector ANN, the outputs are
    obtained and rounded:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we need to calculate squared detection error, which is the Euclidean
    distance between the outputs vector and the vector with the ground-truth values.
    Thus, we first create the vector with ground-truth values as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The corresponding ground-truth value is set to `1.0` if the visual object is
    valid for a given side of the retina, or both sides. Otherwise, it is set to `0.0`
    to indicate an incorrect visual object position.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, the squared detection error is calculated as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The function returns the detection error and the outputs from the detector ANN.
    In the next section, we will discuss the retina experiment runner implementation.
  prefs: []
  type: TYPE_NORMAL
- en: For complete implementation details, refer to the `retina_environment.py` file
    at [https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Python/blob/master/Chapter8/retina_environment.py](https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Python/blob/master/Chapter8/retina_environment.py).
  prefs: []
  type: TYPE_NORMAL
- en: Experiment runner
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To solve the modular retina problem, we need to use a Python library that provides
    an implementation of the ES-HyperNEAT algorithm. If you've read the previous chapter,
    you are already familiar with the MultiNEAT Python library, which also has an
    implementation of the ES-HyperNEAT algorithm. Thus, we can use this library to
    create a retina experiment runner implementation.
  prefs: []
  type: TYPE_NORMAL
- en: Let's discuss the essential components of the implementation.
  prefs: []
  type: TYPE_NORMAL
- en: For full implementation details, refer to the `retina_experiment.py` file at
    [https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Python/blob/master/Chapter8/retina_experiment.py](https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Python/blob/master/Chapter8/retina_experiment.py).
  prefs: []
  type: TYPE_NORMAL
- en: The experiment runner function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `run_experiment` function runs the experiment using the provided hyperparameters
    and an initialized test environment to evaluate the discovered detector ANNs against
    the possible retina configurations. The function implementation has the following
    significant parts:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First is the initialization of the population of the initial CPPN genomes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: At first, the preceding code sets the random seed value to the one that we found
    to be useful for generating successful solutions by sequentially running many
    experiment trials. After that, we create the substrate configuration that is suitable
    for the retina experiment, taking into account the geometry of the retina space.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we create the initial CPPN genome using the substrate configuration we
    already have. The CPPN genome needs to have a number of input and output nodes
    that is compatible with the substrate configuration. Also, we seed the initial
    CPPN genome with two hidden nodes with a Gaussian activation function to boost
    the neuroevolution process in the right direction. The Gaussian hidden nodes start
    the neuroevolution search with a bias toward producing particular detector ANN
    topologies. With these hidden nodes, we introduce to the connectivity patterns
    of the substrate the principle of symmetry, which is precisely what we are expecting
    to achieve in the topology of the successful detector ANN. For the retina problem,
    we need to discover a symmetrical detector ANN configuration incorporating the
    two symmetrical classifier modules.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we prepare the intermediary variables to hold the experiment execution
    results, along with the statistics collector. After that, we run the evolution
    loop for a set number of generations:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Inside the evolution loop, we get the list of genomes belonging to the current
    population and evaluate it against the test environment as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The `eval_genomes` function returns a tuple that has the following components:
    the best-fit genome, the highest fitness score among all evaluated genomes, and
    the list of detection errors for each evaluated genome. We save the appropriate
    parameters into a statistics collector and evaluate the obtained fitness score
    against the search termination criterion, which is defined as a `FITNESS_THRESHOLD`
    constant with a value of `1000.0`. The evolutionary search terminates successfully
    if the best fitness score in population is greater than or equal to the `FITNESS_THRESHOLD`
    value.'
  prefs: []
  type: TYPE_NORMAL
- en: 'If the successful solution was found, or the current best fitness score of
    the population is higher than the maximum fitness score ever achieved, we save
    the best CPPN genome and current fitness score as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'After that, if the value of the `solution_found` variable was set to `True`,
    we terminate the evolution loop:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'If the evolution failed to produce a successful solution, we print the statistics
    for the current generation and move to the next epoch:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The rest of the experiment runner code reports the results of the experiment
    in different formats.
  prefs: []
  type: TYPE_NORMAL
- en: 'We report the experiment results in textual and visual formats using the statistics
    collected in the evolution loop. Furthermore, visualizations are also saved into
    the local filesystem in the SVG vector format:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The first three lines of the code print general statistics about experiment
    execution, such as the highest fitness score achieved, the time elapsed for experiment
    execution, and the random generator seed value.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next part of the code is about visualizing the experiment results, which
    is the most informative part, and you should pay great attention to it. We start
    with visualizing the CPPN network that we create from the best genome found during
    the evolution:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'After that, we visualize the detector ANN topology that is created using the
    best CPPN genome and the retina substrate:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Also, we print the results of the evaluation of the detector ANN created by
    the preceding code against a full dataset and two randomly selected visual objects:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we render the statistics data collected during the experiment as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: All visualization plots mentioned here can be found after execution of the experiment
    in the `trial_out_dir` directory of the local filesystem. Now, let's discuss how
    the substrate builder function is implemented.
  prefs: []
  type: TYPE_NORMAL
- en: The substrate builder function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The ES-HyperNEAT method runs the neuroevolution process, which includes the
    evolution of the CPPN genomes along with the evolution of the substrate configuration.
    However, even though the substrate is evolving during evolution, it is incredibly
    beneficial to start with an appropriate initial substrate configuration. This
    configuration should correspond to the geometry of the problem space.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the retina experiment, the appropriate substrate configuration is created
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we create the configuration of the input layer of the substrate. As
    you may remember from the *The initial substrate configuration* section, the eight
    nodes of the input layer are placed within the XZ plane, which is orthogonal to
    the XY plane. Furthermore, to reflect the geometry of the retina space, the left
    object''s nodes need to be placed on the left side, and the right object''s nodes
    on the right side of the plane correspondingly. The bias node should be located
    at the center of the input nodes plane. Thus, the input layer is created as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: The two output nodes are located within the XY plane, which is orthogonal to
    the inputs plane. This substrate configuration allows natural substrate evolution
    by placing the discovered hidden nodes within the XY plane.
  prefs: []
  type: TYPE_NORMAL
- en: 'The output layer is created as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we define the general substrate configuration parameters as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: We allow the substrate to have connections from input-to-hidden, hidden-to-hidden,
    and hidden-to-output nodes. We specify that hidden nodes should use the signed
    sigmoid activation function, while output nodes should use the unsigned sigmoid
    activation function. We choose the unsigned sigmoid activation for the output
    nodes in order to have detector ANN output values in the range `[0,1]`.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we discuss the implementation of the functions to evaluate
    the fitness of the solutions.
  prefs: []
  type: TYPE_NORMAL
- en: Fitness evaluation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The neuroevolution process requires a means to evaluate the fitness of the genome
    population at each generation of evolution. The fitness evaluation in our experiment
    consists of two parts, which we discuss here.
  prefs: []
  type: TYPE_NORMAL
- en: The eval_genomes function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This function evaluates the fitness of the overall population. It has the following
    definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: The `eval_genomes` function takes the list of CPPN genomes from the current
    population, the substrate configuration, the initialized test environment, and
    the ES-HyperNEAT hyperparameters as parameters.
  prefs: []
  type: TYPE_NORMAL
- en: 'At the beginning of the code, we create an intermediary object to collect the
    evaluation results of each specific genome:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'After that, we start the loop that iterates over all genomes and evaluates
    each genome against a given test environment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Finally, the function returns the evaluation results as a tuple that includes
    the best genome, the highest fitness score, and the list of all detection errors
    for each evaluated genome.
  prefs: []
  type: TYPE_NORMAL
- en: The eval_individual function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This function evaluates the fitness of each individual genome and has the following
    definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: It takes the CPPN genome to be evaluated, the substrate configuration, the test
    environment, and the ES-HyperNEAT hyperparameters as parameters. Using the provided
    parameters, we create the neural network configuration of the detector ANN and
    evaluate it against the given test environment. The function then returns the
    evaluation result.
  prefs: []
  type: TYPE_NORMAL
- en: Modular retina experiment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now we are ready to start experimenting against the test environment that simulates
    the modular retina problem space. In the next subsections, you will learn how
    to select appropriate hyperparameters and how to set up the environment and run
    the experiment. After that, we discuss the experiment results.
  prefs: []
  type: TYPE_NORMAL
- en: Hyperparameter selection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The hyperparameters are defined as a `Parameters` Python class, and the MultiNEAT
    library refers to it for the necessary configuration options. In the source code
    of the experiment runner script, we define a specialized function called `create_hyperparameters`,
    which encapsulates the logic of the hyperparameter initialization. Hereafter,
    we describe the most critical hyperparameters and the reasons for choosing these
    specific values:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We decided to use a medium size for the CPPN genome population. This is done
    to intensify the evolution by providing a large space of options for the solution
    search from the beginning. The size of the population is defined as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we define the number of species to be kept during evolution in the range`[5,15]`and
    set the species stagnation to `100` generations. This configuration allows us
    to have healthy diversity among species and keep them alive for long enough to
    produce the solution we are looking for:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'We are interested in producing an extra-compact configuration of CPPN genomes.
    Thus, we have very small values of probabilities that control how often new nodes
    and connections will be introduced into the genome:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'The ES-HyperNEAT method is an extension of the HyperNEAT method. Thus, during
    the evolution, it changes the types of activation functions in the hidden and
    output nodes. In this experiment, to produce appropriate substrate configurations,
    we are interested in the following activation types, selected with equal probability:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we define the ES-HyperNEAT specific hyperparameters, which control
    how the substrate evolves. The following hyperparameters control the dynamics
    of the creation of nodes and connections within the substrate during evolution:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: '`params.DivisionThreshold` controls how many new nodes and connections are
    introduced into the substrate at each generation of evolution. `params.VarianceThreshold` determines
    how many nodes and connections are allowed to remain in the substrate after the
    pruning and extraction phase. See the *Quadtree information extraction and ES-HyperNEAT
    basics* section for more details about these thresholds.'
  prefs: []
  type: TYPE_NORMAL
- en: Working environment setup
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this experiment, we use the MultiNEAT Python library, which provides the
    implementation of the ES-HyperNEAT algorithm. Thus, we need to create an appropriate
    Python environment, which includes the MultiNEAT Python library and all necessary
    dependencies. This can be done using Anaconda by executing the following commands
    on the command line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: These commands create and activate the `rt_multineat` virtual environment with
    Python 3.5\. After that, they install the MultiNEAT Python library with the latest
    version, along with dependencies that are used by our code for result visualization.
  prefs: []
  type: TYPE_NORMAL
- en: Running the modular retina experiment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'At this stage, we already have the experiment runner script fully defined in
    the `retina_experiment.py` Python script. You can start the experiment by cloning
    the corresponding Git repository and running the script with the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Do not forget to activate the appropriate virtual environment with the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '**`conda activate rt_multineat`**'
  prefs: []
  type: TYPE_NORMAL
- en: 'The preceding command starts one trial of the experiment for 1,000 generations
    of evolution. After a particular number of generations, the successful solution
    should be found, and you will see the following output in the console:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: As you can see in the output, the successful solution was found in generation
    `949`. It was produced by a CPPN genome with 21 nodes and 22 connections among
    them. At the same time, the substrate that determines the topology of the detector
    ANN has 15 nodes and 28 connections between them. The successful solution was
    produced using random seed value `1569777981`. Using other random seed values
    may fail to produce successful solutions, or it will require many more generations
    of evolution.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, it is interesting to look at the plot of the average fitness and error
    during the evolution:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/cbf8d9e1-8200-4f88-816c-a7fa49166931.png)'
  prefs: []
  type: TYPE_IMG
- en: The average fitness and error per generation
  prefs: []
  type: TYPE_NORMAL
- en: You can see in the preceding plot that, during most of the evolution generations,
    the fitness score was very small (about 20), but suddenly, the successful CPPN
    genome was found, which produced an immediate evolutionary leap just in one generation.
  prefs: []
  type: TYPE_NORMAL
- en: 'The configuration of the successful CPPN genome is shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3f032f44-2073-4c2d-b375-9b60f090b918.png)'
  prefs: []
  type: TYPE_IMG
- en: The CPPN phenotype graph of the successful genome
  prefs: []
  type: TYPE_NORMAL
- en: 'The diagram is extremely interesting because, as you can see, the configuration
    of the successful CPPN genome does not use all the available inputs (the gray
    squares) to produce outputs. Moreover, even more confounding is that it uses only
    the *x* coordinate of the input (node #0) and the *y* coordinate of the hidden
    (node #3) substrate nodes when deciding about exposing a connection between these
    substrate nodes. At the same time, both the *x* and *y* coordinates of the substrate
    output nodes are involved in the decision-making process (nodes #4 and #5).'
  prefs: []
  type: TYPE_NORMAL
- en: When you look at the initial substrate configuration, which we presented earlier,
    you will see that the peculiarities we've mentioned are fully substantiated by
    the substrate topology. We placed the input nodes within the XZ plane. Thus, the
    *y* coordinate is not critical for them at all. At the same time, the hidden nodes
    located within the XY plane, with the *y* coordinate determining the distance
    from the inputs plane. Finally, the output nodes are also located within the XY
    plane. Their *x* coordinate determines the side of the retina to which each output
    node relates. Thus, for the output nodes, it is natural that both the *x* and
    *y* coordinates are included.
  prefs: []
  type: TYPE_NORMAL
- en: In the CPPN phenotype plot, the input nodes are marked with squares, the output
    nodes are filled circles, the bias node is a diamond, and the hidden nodes are
    empty circles.
  prefs: []
  type: TYPE_NORMAL
- en: 'Two output nodes in the CPPN diagram has the following meaning:'
  prefs: []
  type: TYPE_NORMAL
- en: The first node (8) provides the weight of the connection.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The second node (9) determines whether the connection is expressed or not.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The CPPN''s input nodes are defined as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The first two nodes (0 and 1) set the point coordinates (*x*, *z*) in the input
    layer of the substrate.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The next two nodes (2 and 3) set the point coordinates (*x*, *y*) in the hidden
    layer of the substrate.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The next two nodes (4 and 5) set the point coordinates (*x*, *y*) in the output
    layer of the substrate.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The last node (6) sets the Euclidean distance of the point in the input layer
    from the origin of the coordinates.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'However, you can see the most exciting part of the experiment results in the
    following diagram. It represents the configuration of the successful detector
    ANN:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ed3cd3e3-ba05-4ea1-9434-257132dfc46b.png)'
  prefs: []
  type: TYPE_IMG
- en: The configuration of the detector ANN
  prefs: []
  type: TYPE_NORMAL
- en: As in the previous plot, we mark the input nodes with squares, the output nodes
    with filled circles, the bias node as a diamond, and the hidden nodes as empty
    circles.
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see, we have two clearly separated modular structures on the left
    and right sides of the graph. Each module is connected to the corresponding inputs
    from the left (nodes #0, #1, #2, and #3) and the right (nodes #4, #5, #6, and
    #7) sides of the retina. Both modules have the same number of hidden nodes, which
    are connected to the corresponding output nodes: node #9 for the left side and
    node #10 for the right side of the retina. Also, you can see that connectivity
    patterns in the left and right modules are similar. The hidden node, #11, on the
    left has similar connection patterns to node #14 on the right, and the same can
    be said for nodes #12 and #13.'
  prefs: []
  type: TYPE_NORMAL
- en: It is just amazing how the stochastic evolutionary process was able to discover
    such a simple and elegant solution. With the results of this experiment, we fully
    confirmed our hypothesis that the retina problem can be solved by the creation
    of modular detector ANN topologies.
  prefs: []
  type: TYPE_NORMAL
- en: More details about modular retina problem can be found in the original paper
    at [http://eplex.cs.ucf.edu/papers/risi_alife12.pdf](http://eplex.cs.ucf.edu/papers/risi_alife12.pdf).
  prefs: []
  type: TYPE_NORMAL
- en: Exercises
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Try to run an experiment with different values of the random seed generator
    that can be changed in line 101 of the `retina_experiment.py` script. See if you
    can find successful solutions with other values.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Try to increase the initial population size to 1,000 by adjusting the value
    of the `params.PopulationSize` hyperparameter. How did this affect the performance
    of the algorithm?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Try to change the number of activation function types used during the evolution
    by setting the probability of its selection to 0\. It's especially interesting
    to see what happens when you exclude the `ActivationFunction_SignedGauss_Prob`
    and `ActivationFunction_SignedStep_Prob` activation types from selection.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned about the neuroevolution method that allows the
    substrate configuration to evolve during the process of finding the solution to
    the problem. This approach frees the human designer from the burden of creating
    a suitable substrate configuration to the smallest details, allowing us to define
    only the primary outlines. The algorithm will automatically learn the remaining
    details of the substrate configuration during the evolution.
  prefs: []
  type: TYPE_NORMAL
- en: Also, you learned about the modular ANN structures that can be used to solve
    various problems, including the modular retina problem. Modular ANN topologies
    are a very powerful concept that allows the reuse of the successful phenotype
    ANN module multiple times to build a complex hierarchical topology. Furthermore,
    you have had the chance to hone your skills with the Python programming language
    by implementing the corresponding solution using the MultiNEAT Python library.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will discuss the fascinating concept of coevolution
    and how it can be used to simultaneously coevolve the solver and the objective
    function that is used for optimization. We will discuss the method of solution
    and fitness evolution, and you will learn how to apply it to the modified maze-solving
    experiment.
  prefs: []
  type: TYPE_NORMAL
