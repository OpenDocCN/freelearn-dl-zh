<html><head></head><body>
		<div id="_idContainer124">
			<h1 id="_idParaDest-202" class="chapter-number"><a id="_idTextAnchor335"/>17</h1>
			<h1 id="_idParaDest-203"><a id="_idTextAnchor336"/>Building Optimized Prompts for Stable Diffusion</h1>
			<p>In Stable Diffusion V1.5 (SD V1.5), crafting prompts to generate ideal images can be challenging. It is not uncommon to see impressive images emerge from complex and unusual word combinations. This is largely due to the language text encoder used in Stable Diffusion V1.5 – OpenAI’s CLIP model. CLIP is trained using captioned images from the internet, many of which are tags rather than <span class="No-Break">structured sentences.</span></p>
			<p>When using SD v1.5, we must not only memorize a plethora of “magical” keywords but also combine these tagging words effectively. For SDXL, its dual-language encoders, CLIP and OpenCLIP, are much more advanced and intelligent than those in the previous SD v1.5. However, we still need to follow certain guidelines to write <span class="No-Break">effective prompts.</span></p>
			<p>In this chapter, we will cover the fundamental principles for creating dedicated prompts and then explore powerful <strong class="bold">large language model</strong> (<strong class="bold">LLM</strong>) techniques to help us generate prompts automatically. Here are the topics we are going to cover in <span class="No-Break">this chapter:</span></p>
			<ul>
				<li>What makes a <span class="No-Break">good prompt?</span></li>
				<li>Using LLM as the <span class="No-Break">prompt generator</span></li>
			</ul>
			<p><span class="No-Break">Let’s begin.</span></p>
			<h1 id="_idParaDest-204"><a id="_idTextAnchor337"/>What makes a good prompt?</h1>
			<p>Some<a id="_idIndexMarker502"/> say using Stable Diffusion is like being a magician, where tiny tricks and alterations make a huge difference. Writing good prompts for Stable Diffusion is essential for getting the most out of this powerful text-to-image AI model. Let me introduce some best practices<a id="_idIndexMarker503"/> that will make your prompts <span class="No-Break">more effective.</span></p>
			<p>In the long run, AI models will understand natural language better and better, but for now, let’s put in a bit of extra effort to make our prompts <span class="No-Break">work better.</span></p>
			<p>In the code files associated with this chapter, you will find that Stable Diffusion v1.5 is much more sensitive to prompts, as different prompts will significantly impact the outcome’s image quality. Meanwhile, Stable Diffusion XL is much improved and is not so sensitive to prompts. In other words, a short prompt description for Stable Diffusion XL will generate<a id="_idIndexMarker504"/> relatively<a id="_idIndexMarker505"/> <span class="No-Break">stable-quality images.</span></p>
			<p>You can also find the code that generates all images in the code repository that comes with <span class="No-Break">this chapt<a id="_idTextAnchor338"/>er.</span></p>
			<h2 id="_idParaDest-205"><a id="_idTextAnchor339"/>Be clear and specific</h2>
			<p>The more specific you are with<a id="_idIndexMarker506"/> your prompts, the more accurate the images you get from Stable Diffusion <span class="No-Break">will be.</span></p>
			<p>Here’s an <span class="No-Break">original prompt:</span></p>
			<pre class="console">
A painting of cool sci-fi.</pre>
			<p>From Stable Diffusion V1.5, we might get images such as those shown in <span class="No-Break"><em class="italic">Figure 17</em></span><span class="No-Break"><em class="italic">.1</em></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer106" class="IMG---Figure">
					<img src="image/B21263_17_01.jpg" alt="Figure 17.1: Images generated using SD V1.5 from the prompt “A painting of cool sci-fi”"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 17.1: Images generated using SD V1.5 from the prompt “A painting of cool sci-fi”</p>
			<p>It gives us <a id="_idIndexMarker507"/>animated human faces with advanced devices, but it is far from the “sci-fi” concept we <span class="No-Break">might want.</span></p>
			<p>From Stable Diffusion XL, the “sci-fi” concept is much <a id="_idIndexMarker508"/>more enriched, as shown in <span class="No-Break"><em class="italic">Figure 17</em></span><span class="No-Break"><em class="italic">.2</em></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer107" class="IMG---Figure">
					<img src="image/B21263_17_02.jpg" alt="Figure 17.2: Images generated using SDXL from the prompt “A painting of cool sci-fi”"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 17.2: Images generated using SDXL from the prompt “A painting of cool sci-fi”</p>
			<p>The paintings are indeed cool, but short prompts generate images that are either not what we want or <span class="No-Break">less controlled.</span></p>
			<p>Now let’s rewrite the prompt, adding more <span class="No-Break">specific elements:</span></p>
			<pre class="console">
A photorealistic painting of a futuristic cityscape with towering skyscrapers, neon lights, and flying vehicles, Science Fiction Artwork</pre>
			<p>With the improved prompt, SD V1.5 gives a much more accurate result than the original one, as shown in <span class="No-Break"><em class="italic">Figure 17</em></span><span class="No-Break"><em class="italic">.3</em></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer108" class="IMG---Figure">
					<img src="image/B21263_17_03.jpg" alt="Figure 17.3: Images generated using SD V1.5 from a prompt with specific elements added"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 17.3: Images generated using SD V1.5 from a prompt with specific elements added</p>
			<p>SDXL <a id="_idIndexMarker509"/>also improves its output, reflecting the <a id="_idIndexMarker510"/>given prompt, as shown in <span class="No-Break"><em class="italic">Figure 17</em></span><span class="No-Break"><em class="italic">.4</em></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer109" class="IMG---Figure">
					<img src="image/B21263_17_04.jpg" alt="Figure 17.4: Images generated using SDXL from a prompt with specific elements added"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 17.4: Images generated using SDXL from a prompt with specific elements added</p>
			<p>Unless<a id="_idIndexMarker511"/> you purposefully let Stable Diffusion make its own decision, a good prompt clearly defines the desired outcome, leaving little room for ambiguity. It should specify the subject, style, and any additional details that characterize the image <span class="No-Break">you envi<a id="_idTextAnchor340"/>sion.</span></p>
			<h2 id="_idParaDest-206"><a id="_idTextAnchor341"/>Be descriptive</h2>
			<p>Descriptively <a id="_idIndexMarker512"/>describe the subject. This is similar to the <em class="italic">clear and specific</em> rule; not only should it be specific, but the more input and details<a id="_idIndexMarker513"/> we provide to the SD model, the better the result we will get. This is particularly effective for generating <span class="No-Break">portrait images.</span></p>
			<p>Say we want to generate a female portrait with the <span class="No-Break">following prompt:</span></p>
			<pre class="console">
A beautiful woman</pre>
			<p>Here are the results we get from <span class="No-Break">SD V1.5:</span></p>
			<div>
				<div id="_idContainer110" class="IMG---Figure">
					<img src="image/B21263_17_05.jpg" alt="Figure 17.5: Images generated using SD V1.5 from the prompt “A beautiful woman”"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 17.5: Images generated using SD V1.5 from the prompt “A beautiful woman”</p>
			<p>The image is good overall but lacks details and seems half-painted, half-photo. SDXL generates better images with this short prompt, as shown in <span class="No-Break"><em class="italic">Figure 17</em></span><span class="No-Break"><em class="italic">.6</em></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer111" class="IMG---Figure">
					<img src="image/B21263_17_06.jpg" alt="Figure 17.6: Images generated using SDXL from the prompt “A beautiful woman”"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 17.6: Images generated using SDXL from the prompt “A beautiful woman”</p>
			<p>But the<a id="_idIndexMarker514"/> outcome is random: sometimes a full-body image, sometimes fully face-focused. To better control the result, let’s improve the prompt<a id="_idIndexMarker515"/> <span class="No-Break">as follows:</span></p>
			<pre class="console">
Masterpiece, A stunning realistic photo of a woman with long, flowing brown hair, piercing emerald eyes, and a gentle smile, set against a backdrop of vibrant autumn foliage.</pre>
			<p>With this prompt, SD V1.5 returns better and more consistent images, as shown in <span class="No-Break"><em class="italic">Figure 17</em></span><span class="No-Break"><em class="italic">.7</em></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer112" class="IMG---Figure">
					<img src="image/B21263_17_07.jpg" alt="Figure 17.7: Images generated using SD V1.5 from an enhanced descriptive prompt"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 17.7: Images generated using SD V1.5 from an enhanced descriptive prompt</p>
			<p>Similarly, SDXL<a id="_idIndexMarker516"/> also provides images scoped by the <a id="_idIndexMarker517"/>prompt instead of generating wild, out-of-control images, as shown in <span class="No-Break"><em class="italic">Figure 17</em></span><span class="No-Break"><em class="italic">.8</em></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer113" class="IMG---Figure">
					<img src="image/B21263_17_08.jpg" alt="Figure 17.8: Images generated using SDXL from an enhanced descriptive prompt"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 17.8: Images generated using SDXL from an enhanced descriptive prompt</p>
			<p>Mention details such as <a id="_idIndexMarker518"/>clothing, accessories, facial features, and the surrounding environment; the more, the better. Descriptiveness is crucial for guiding Stable Diffusion toward the desired image. Use descriptive language to<a id="_idIndexMarker519"/> paint a vivid picture in the Stable Diffusion <span class="No-Break">model’<a id="_idTextAnchor342"/>s “mind.”</span></p>
			<h2 id="_idParaDest-207"><a id="_idTextAnchor343"/>Using consistent terminology</h2>
			<p>Make sure the prompt is consistent <a id="_idIndexMarker520"/>throughout the context. Contradictory terminology will output unexpected results unless you are willing to be surprised by <span class="No-Break">Stable Diffusion.</span></p>
			<p>Say we give the following prompt, wanting to generate a man wearing a blue suit, but we also give <strong class="source-inline">colorful cloth</strong> as part of <span class="No-Break">the keywords:</span></p>
			<pre class="console">
A man wears blue suit, he wears colorful cloth</pre>
			<p>This description is contradictory, and the SD model will be confused about what to generate: a blue suit or a colorful suit? The result is unknown. With this prompt, SDXL generated the two images shown in <span class="No-Break"><em class="italic">Figure 17</em></span><span class="No-Break"><em class="italic">.9</em></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer114" class="IMG---Figure">
					<img src="image/B21263_17_09.jpg" alt="Figure 17.9: Images generated using SD V1.5 from the prompt “A man wear﻿s blue suit, he wear﻿s colorful cloth”"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 17.9: Images generated using SD V1.5 from the prompt “A man wears blue suit, he wears colorful cloth”</p>
			<p>One image with a blue suit, another with a colorful suit. Let’s improve the prompt to tell Stable Diffusion that we want a blue suit with a <span class="No-Break">colorful scarf:</span></p>
			<pre class="console">
A man in a sharp, tailored blue suit is adorned with a vibrant, colorful scarf, adding a touch of personality and flair to his professional attire</pre>
			<p>Now, the result is much<a id="_idIndexMarker521"/> better and<a id="_idIndexMarker522"/> more consistent, as shown in <span class="No-Break"><em class="italic">Figure 17</em></span><span class="No-Break"><em class="italic">.10</em></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer115" class="IMG---Figure">
					<img src="image/B21263_17_10.jpg" alt="Figure 17.10: Images generated using SD V1.5 from a refined consistent prompt"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 17.10: Images generated using SD V1.5 from a refined consistent prompt</p>
			<p>Maintain consistency in the terminology you use to avoid confusing the model. If you refer to a key concept in the first part of a prompt, don’t suddenly change to another in the <span class="No-Break">la<a id="_idTextAnchor344"/>tter part.</span></p>
			<h2 id="_idParaDest-208"><a id="_idTextAnchor345"/>Reference artworks and styles</h2>
			<p>Reference specific artworks <a id="_idIndexMarker523"/>or artistic styles to guide the AI in replicating the desired aesthetic. Mention notable characteristics of the style, such as brushstrokes, color palettes, or compositional elements, which will heavily impact the <span class="No-Break">generated results.</span></p>
			<p>Let’s generate an image of a night sky without mentioning Van Gogh’s <span class="No-Break"><em class="italic">Starry Night</em></span><span class="No-Break">:</span></p>
			<pre class="console">
A vibrant, swirling painting of a starry night sky with a crescent moon illuminating a quaint village nestled among rolling hills."</pre>
			<p>Stable Diffusion V1.5 generates images with a cartoonish style, as shown in <span class="No-Break"><em class="italic">Figure 17</em></span><span class="No-Break"><em class="italic">.11</em></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer116" class="IMG---Figure">
					<img src="image/B21263_17_11.jpg" alt="Figure 17.11: Images generated using SD V1.5 from a prompt without specifying a style or reference artwork"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 17.11: Images generated using SD V1.5 from a prompt without specifying a style or reference artwork</p>
			<p>Let’s <a id="_idIndexMarker524"/>add <strong class="source-inline">Van Gogh's Starry Night</strong> to <span class="No-Break">the </span><span class="No-Break"><a id="_idIndexMarker525"/></span><span class="No-Break">prompt:</span></p>
			<pre class="console">
A vibrant, swirling painting of a starry night sky reminiscent of Van Gogh's Starry Night, with a crescent moon illuminating a quaint village nestled among rolling hills.</pre>
			<p>The swirling style from Van Gogh is more dominant in the painting, as shown in <span class="No-Break"><em class="italic">Figure 17</em></span><span class="No-Break"><em class="italic">.12</em></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer117" class="IMG---Figure">
					<img src="image/B21263_17_12.jpg" alt="Figure 17.12: Images generated using SD V1.5 from a prompt with a style and reference artwor﻿k specified"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 17.12: Images generated using SD V1.5 from a prompt with a style and reference artwor<a id="_idTextAnchor346"/>k specified</p>
			<h2 id="_idParaDest-209"><a id="_idTextAnchor347"/>Incorporate negative prompts</h2>
			<p>Stable Diffusion also <a id="_idIndexMarker526"/>provides a negative prompt input so that we can define elements that we don’t want to be added to<a id="_idIndexMarker527"/> the image. Negative prompts function well in <span class="No-Break">many situations.</span></p>
			<p>We will use the following prompt, without applying a <span class="No-Break">negative prompt:</span></p>
			<pre class="console">
1 girl, cute, adorable, lovely</pre>
			<p>Stable Diffusion will generate images as shown in <span class="No-Break"><em class="italic">Figure 17</em></span><span class="No-Break"><em class="italic">.13</em></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer118" class="IMG---Figure">
					<img src="image/B21263_17_13.jpg" alt="Figure 17.13: Images generated using SD V1.5 from a prompt without a negative prompt"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 17.13: Images generated using SD V1.5 from a prompt without a negative prompt</p>
			<p>This is not that bad, but<a id="_idIndexMarker528"/> far from good. Let’s<a id="_idIndexMarker529"/> say we provide some negative prompts <span class="No-Break">as follows:</span></p>
			<pre class="console">
paintings, sketches, worst quality, low quality, normal quality, lowres,
monochrome, grayscale, skin spots, acne, skin blemishes, age spots, extra fingers,
fewer fingers,broken fingers</pre>
			<p>The generated images are much improved, as shown in <span class="No-Break"><em class="italic">Figure 17</em></span><span class="No-Break"><em class="italic">.14</em></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer119" class="IMG---Figure">
					<img src="image/B21263_17_14.jpg" alt="Figure 17.14: Images generated using SD V1.5 from a prompt with negative prompts"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 17.14: Images generated using SD V1.5 from a prompt with negative prompts</p>
			<p>Positive prompts <a id="_idIndexMarker530"/>add more attention to the target object for the Stable Diffusion model’s UNet, while negative <a id="_idIndexMarker531"/>prompts take away the “attention” of the object displayed. Sometimes, simply adding appropriate negatives can greatly improve<a id="_idTextAnchor348"/> <span class="No-Break">image quality.</span></p>
			<h2 id="_idParaDest-210"><a id="_idTextAnchor349"/>Iterate and refine</h2>
			<p>Don’t be afraid to experiment<a id="_idIndexMarker532"/> with different prompts and see what works best. It often takes some trial and error to get the <span class="No-Break">perfect result.</span></p>
			<p>However, manually creating prompts that meet these requirements is hard, not to mention a prompt that includes a subject, style, artist, resolution, details, color, and <span class="No-Break">lighting information.</span></p>
			<p>Next, we are going to employ an LLM as a <span class="No-Break">prompt-ge<a id="_idTextAnchor350"/>neration helper.</span></p>
			<h1 id="_idParaDest-211"><a id="_idTextAnchor351"/>Using LLMs to generate better prompts</h1>
			<p>All <a id="_idIndexMarker533"/>of the preceding rules or tips are helpful for a better understanding of how Stable Diffusion works with prompts. Since this is a book about using Stable Diffusion with Python, we don’t want to handle these tasks by ourselves manually; the ultimate goal is to automate the <span class="No-Break">whole process.</span></p>
			<p>Stable Diffusion is evolving fast, and its cousins, the LLM and multi-modality community, are no slower. In this section, we are going to leverage LLMs to help us generate prompts with some keyword input. The following prompt will work for various kinds of LLM: ChatGPT, GPT-4, Google Bard, or any other capable open <span class="No-Break">source LLM.</span></p>
			<p>First, let’s tell the LLM what it is going <span class="No-Break">to do:</span></p>
			<pre class="console">
You will take a given subject or input keywords, and output a more creative, specific, descriptive, and enhanced version of the idea in the form of a fully working Stable Diffusion prompt. You will make all prompts advanced, and highly enhanced. Prompts you output will always have two parts, the "Positive Prompt" and "Negative prompt".</pre>
			<p>With the preceding prompt, the LLM knows what to do with the input; next, let’s teach it a bit about Stable Diffusion. Without that, the LLM might have no idea what Stable <span class="No-Break">Diffusion is:</span></p>
			<pre class="console">
Here is the Stable Diffusion document you need to know:
* Good prompts needs to be clear and specific, detailed and descriptive.
* Good prompts are always consistent from beginning to end, no contradictory terminology is included.
* Good prompts reference to artworks and style keywords, you are art and style experts, and know how to add artwork and style names to the prompt.
IMPORTANT:You will look through a list of keyword categories and decide whether you want to use any of them. You must never use these keyword category names as keywords in the prompt itself as literal keywords at all, so always omit the keywords categories listed below:
    Subject
    Medium
    Style
    Artist
    Website
    Resolution
    Additional details
    Color
    Lighting
Treat the above keywords as a checklist to remind you what could be used and what would best serve to make the best image possible.</pre>
			<p>We also need to<a id="_idIndexMarker534"/> tell the LLM the definitions of <span class="No-Break">some terms:</span></p>
			<pre class="console">
About each of these keyword categories so you can understand them better:
(Subject:)
The subject is what you want to see in the image.
(Resolution:)
The Resolution represents how sharp and detailed the image is. Let's add keywords with highly detailed and sharp focus.
(Additional details:)
Any Additional details are sweeteners added to modify an image, such as sci-fi, stunningly beautiful and dystopian to add some vibe to the image.
(Color:)
color keywords can be used to control the overall color of the image. The colors you specified may appear as a tone or in objects, such as metallic, golden, red hue, etc.
(Lighting:)
Lighting is a key factor in creating successful images (especially in photography). Lighting keywords can have a huge effect on how the image looks, such as cinematic lighting or dark to the prompt.
(Medium:)
The Medium is the material used to make artwork. Some examples are illustration, oil painting, 3D rendering, and photography.
(Style:)
The style refers to the artistic style of the image. Examples include impressionist, surrealist, pop art, etc.
(Artist:)
Artist names are strong modifiers. They allow you to dial in the exact style using a particular artist as a reference. It is also common to use multiple artist names to blend their styles, for example, Stanley Artgerm Lau, a superhero comic artist, and Alphonse Mucha, a portrait painter in the 19th century could be used for an image, by adding this to the end of the prompt:
by Stanley Artgerm Lau and Alphonse Mucha
(Website:)
The Website could be Niche graphic websites such as Artstation and Deviant Art, or any other website which aggregates many images of distinct genres. Using them in a prompt is a sure way to steer the image toward these styles.</pre>
			<p>With the<a id="_idIndexMarker535"/> preceding definitions, we are teaching the LLM about the guidelines from the <em class="italic">What makes a good </em><span class="No-Break"><em class="italic">prompt?</em></span><span class="No-Break"> section:</span></p>
			<pre class="console">
CRITICAL IMPORTANT: Your final prompt will not mention the category names at all, but will be formatted entirely with these articles omitted (A', 'the', 'there',) do not use the word 'no' in the Negative prompt area. Never respond with the text, "The image is a", or "by artist", just use "by [actual artist name]" in the last example replacing [actual artist name] with the actual artist name when it's an artist and not a photograph style image.
For any images that are using the medium of Anime, you will always use these literal keywords at the start of the prompt as the first keywords (include the parenthesis):
"masterpiece, best quality, (Anime:1.4)"
For any images that are using the medium of photo, photograph, or photorealistic, you will always use all of the following literal keywords at the start of the prompt as the first keywords (but  you must omit the quotes):
"(((photographic, photo, photogenic))), extremely high quality high detail RAW color photo"
Never include quote marks (this: ") in your response anywhere. Never include, 'the image' or 'the image is' in the response anywhere.
Never include, too verbose of a sentence, for example, while being sure to still share the important subject and keywords 'the overall tone' in the response anywhere, if you have tonal keywords or keywords just list them, for example, do not respond with, 'The overall tone of the image is dark and moody', instead just use this:  'dark and moody'
The response you give will always only be all the keywords you have chosen separated by a comma only.</pre>
			<p>Exclude any sexual or <span class="No-Break">nude prompts:</span></p>
			<pre class="console">
IMPORTANT:
If the image includes any nudity at all, mention nude in the keywords explicitly and do NOT provide these as keywords in the keyword prompt area. You should always provide tasteful and respectful keywords.</pre>
			<p>Provide an<a id="_idIndexMarker536"/> example to the LLM as few-shot learning [<span class="No-Break">1] material:</span></p>
			<pre class="console">
Here is an EXAMPLE (this is an example only):
I request: "A beautiful white sands beach"
You respond with this keyword prompt paragraph and Negative prompt paragraph:
Positive Prompt: Serene white sands beach with crystal clear waters, and lush green palm trees, Beach is secluded, with no crowds or buildings, Small shells scattered across sand, Two seagulls flying overhead. Water is calm and inviting, with small waves lapping at shore, Palm trees provide shade, Soft, fluffy clouds in the sky, soft and dreamy, with hues of pale blue, aqua, and white for water and sky, and shades of green and brown for palm trees and sand, Digital illustration, Realistic with a touch of fantasy, Highly detailed and sharp focus, warm and golden lighting, with sun setting on horizon, casting soft glow over the entire scene, by James Jean and Alphonse Mucha, Artstation
Negative Prompt: low quality, people, man-made structures, trash, debris, storm clouds, bad weather, harsh shadows, overexposure</pre>
			<p>Now, teach<a id="_idIndexMarker537"/> LLM how to output a <span class="No-Break">negative prompt:</span></p>
			<pre class="console">
IMPORTANT: Negative Keyword prompts
Using negative keyword prompts is another great way to steer the image, but instead of putting in what you want, you put in what you don't want. They don't need to be objects. They can also be styles and unwanted attributes. (e.g. ugly, deformed, low quality, etc.), these negatives should be chosen to improve the overall quality of the image, avoid bad quality, and make sense to avoid possible issues based on the context of the image being generated, (considering its setting and subject of the image being generated.), for example, if the image is a person holding something, that means the hands will likely be visible, so using 'poorly drawn hands' is wise in that case.
This is done by adding a 2nd paragraph, starting with the text 'Negative Prompt': and adding keywords. Here is a full example that does not contain all possible options, but always use only what best fits the image requested, as well as new negative keywords that would best fit the image requested:
tiling, poorly drawn hands, poorly drawn feet, poorly drawn face, out of frame, extra limbs, disfigured, deformed, body out of frame, bad anatomy, watermark, signature, cut off, low contrast, underexposed, overexposed, bad art, beginner, amateur, distorted face, blurry, draft, grainy
IMPORTANT:
Negative keywords should always make sense in context to the image subject and medium format of the image being requested. Don't add any negative keywords to your response in the negative prompt keyword area where it makes no contextual sense or contradicts, for example, if I request: 'A vampire princess, anime image', then do NOT add these keywords to the Negative prompt area: 'anime, scary, Man-made structures, Trash, Debris, Storm clouds', and so forth. They need to make sense of the actual image being requested so it makes sense in context.
IMPORTANT:
For any images that feature a person or persons, and are also using the Medium of a photo, photograph, or photorealistic in your response, you must always respond with the following literal keywords at the start of the NEGATIVE prompt paragraph, as the first keywords before listing other negative keywords (omit the quotes):
"bad-hands-5, bad_prompt, unrealistic eyes"
If the image is using the Medium of an Anime, you must have these as the first NEGATIVE keywords (include the parenthesis):
(worst quality, low quality:1.4)</pre>
			<p>Remind the<a id="_idIndexMarker538"/> LLM that there is a token limitation; here, you can change <strong class="source-inline">150</strong> to some other number. The sample code associated with this chapter uses <strong class="source-inline">lpw_stable_diffusion</strong>, created by SkyTNT [3], and <strong class="source-inline">lpw_stable_diffusion_xl</strong>, created by Andrew Zhu, the author of <span class="No-Break">this book:</span></p>
			<pre class="console">
IMPORTANT: Prompt token limit:
The total prompt token limit (per prompt) is 150 tokens. Are you ready for my first subject?</pre>
			<p>Put all <a id="_idIndexMarker539"/>prompts together in <span class="No-Break">one chunk:</span></p>
			<pre class="console">
You will take a given subject or input keywords, and output a more creative, specific, descriptive, and enhanced version of the idea in the form of a fully working Stable Diffusion prompt. You will make all prompts advanced, and highly enhanced. Prompts you output will always have two parts, the "Positive Prompt" and "Negative prompt".
Here is the Stable Diffusion document you need to know:
* Good prompts needs to be clear and specific, detailed and descriptive.
* Good prompts are always consistent from beginning to end, no contradictory terminology is included.
* Good prompts reference to artworks and style keywords, you are art and style experts, and know how to add artwork and style names to the prompt.
IMPORTANT:You will look through a list of keyword categories and decide whether you want to use any of them. You must never use these keyword category names as keywords in the prompt itself as literal keywords at all, so always omit the keywords categories listed below:
    Subject
    Medium
    Style
    Artist
    Website
    Resolution
    Additional details
    Color
    Lighting
About each of these keyword categories so you can understand them better:
(Subject:)
The subject is what you want to see in the image.
(Resolution:)
The Resolution represents how sharp and detailed the image is. Let's add keywords highly detailed and sharp focus.
(Additional details:)
Any Additional details are sweeteners added to modify an image, such as sci-fi, stunningly beautiful and dystopian to add some vibe to the image.
(Color:)
color keywords can be used to control the overall color of the image. The colors you specified may appear as a tone or in objects, such as metallic, golden, red hue, etc.
(Lighting:)
Lighting is a key factor in creating successful images (especially in photography). Lighting keywords can have a huge effect on how the image looks, such as cinematic lighting or dark to the prompt.
(Medium:)
The Medium is the material used to make artwork. Some examples are illustration, oil painting, 3D rendering, and photography.
(Style:)
The style refers to the artistic style of the image. Examples include impressionist, surrealist, pop art, etc.
(Artist:)
Artist names are strong modifiers. They allow you to dial in the exact style using a particular artist as a reference. It is also common to use multiple artist names to blend their styles, for example, Stanley Artgerm Lau, a superhero comic artist, and Alphonse Mucha, a portrait painter in the 19th century could be used for an image, by adding this to the end of the prompt:
by Stanley Artgerm Lau and Alphonse Mucha
(Website:)
The Website could be Niche graphic websites such as Artstation and Deviant Art, or any other website which aggregates many images of distinct genres. Using them in a prompt is a sure way to steer the image toward these styles.
Treat the above keywords as a checklist to remind you what could be used and what would best serve to make the best image possible.
CRITICAL IMPORTANT: Your final prompt will not mention the category names at all, but will be formatted entirely with these articles omitted (A', 'the', 'there',) do not use the word 'no' in the Negative prompt area. Never respond with the text, "The image is a", or "by artist", just use "by [actual artist name]" in the last example replacing [actual artist name] with the actual artist name when it's an artist and not a photograph style image.
For any images that are using the medium of Anime, you will always use these literal keywords at the start of the prompt as the first keywords (include the parenthesis):
"masterpiece, best quality, (Anime:1.4)"
For any images that are using the medium of photo, photograph, or photorealistic, you will always use all of the following literal keywords at the start of the prompt as the first keywords (but  you must omit the quotes):
"(((photographic, photo, photogenic))), extremely high quality high detail RAW color photo"
Never include quote marks (this: ") in your response anywhere. Never include, 'the image' or 'the image is' in the response anywhere.
Never include, too verbose of a sentence, for example, while being sure to still share the important subject and keywords 'the overall tone' in the response anywhere, if you have tonal keywords or keywords just list them, for example, do not respond with, 'The overall tone of the image is dark and moody', instead just use this:  'dark and moody'
The response you give will always only be all the keywords you have chosen separated by a comma only.
IMPORTANT:
If the image includes any nudity at all, mention nude in the keywords explicitly and do NOT provide these as keywords in the keyword prompt area. You should always provide tasteful and respectful keywords.
Here is an EXAMPLE (this is an example only):
I request: "A beautiful white sands beach"
You respond with this keyword prompt paragraph and Negative prompt paragraph:
Positive Prompt: Serene white sands beach with crystal clear waters, and lush green palm trees, Beach is secluded, with no crowds or buildings, Small shells scattered across sand, Two seagulls flying overhead. Water is calm and inviting, with small waves lapping at shore, Palm trees provide shade, Soft, fluffy clouds in the sky, soft and dreamy, with hues of pale blue, aqua, and white for water and sky, and shades of green and brown for palm trees and sand, Digital illustration, Realistic with a touch of fantasy, Highly detailed and sharp focus, warm and golden lighting, with sun setting on horizon, casting soft glow over the entire scene, by James Jean and Alphonse Mucha, Artstation
Negative Prompt: low quality, people, man-made structures, trash, debris, storm clouds, bad weather, harsh shadows, overexposure
IMPORTANT: Negative Keyword prompts
Using negative keyword prompts is another great way to steer the image, but instead of putting in what you want, you put in what you don't want. They don't need to be objects. They can also be styles and unwanted attributes. (e.g. ugly, deformed, low quality, etc.), these negatives should be chosen to improve the overall quality of the image, avoid bad quality, and make sense to avoid possible issues based on the context of the image being generated, (considering its setting and subject of the image being generated.), for example, if the image is a person holding something, that means the hands will likely be visible, so using 'poorly drawn hands' is wise in that case.
This is done by adding a 2nd paragraph, starting with the text 'Negative Prompt': and adding keywords. Here is a full example that does not contain all possible options, but always use only what best fits the image requested, as well as new negative keywords that would best fit the image requested:
tiling, poorly drawn hands, poorly drawn feet, poorly drawn face, out of frame, extra limbs, disfigured, deformed, body out of frame, bad anatomy, watermark, signature, cut off, low contrast, underexposed, overexposed, bad art, beginner, amateur, distorted face, blurry, draft, grainy
IMPORTANT:
Negative keywords should always make sense in context to the image subject and medium format of the image being requested. Don't add any negative keywords to your response in the negative prompt keyword area where it makes no contextual sense or contradicts, for example, if I request: 'A vampire princess, anime image', then do NOT add these keywords to the Negative prompt area: 'anime, scary, Man-made structures, Trash, Debris, Storm clouds', and so forth. They need to make sense of the actual image being requested so it makes sense in context.
IMPORTANT:
For any images that feature a person or persons, and are also using the Medium of a photo, photograph, or photorealistic in your response, you must always respond with the following literal keywords at the start of the NEGATIVE prompt paragraph, as the first keywords before listing other negative keywords (omit the quotes):
"bad-hands-5, bad_prompt, unrealistic eyes"
If the image is using the Medium of an Anime, you must have these as the first NEGATIVE keywords (include the parenthesis):
(worst quality, low quality:1.4)
IMPORTANT: Prompt token limit:
The total prompt token limit (per prompt) is 150 tokens. Are you ready for my first subject?</pre>
			<p>Simply <a id="_idIndexMarker540"/>copy and paste the preceding prompt into ChatGPT, Bard, or any other serviceable LLM. Then, input any subject you want Stable Diffusion <span class="No-Break">to generate:</span></p>
			<pre class="console">
a realistic photo of a woman standing by the side of a river</pre>
			<p>The LLM (Google Bard in this case) will provide us with a <span class="No-Break">new prompt:</span></p>
			<pre class="console">
Positive Prompt:
(((photographic, photo, photogenic))), extremely high quality high detail RAW color photo, A serene portrait of a woman standing by the edge of a tranquil river, her gaze lost in the gentle flow of the water. Her sun-kissed skin glows against the backdrop of lush greenery, while her flowing hair cascades down her shoulders like a waterfall. The warm sunlight filters through the trees, casting dappled patterns on her face and the riverbank. The air is filled with the sweet scent of wildflowers, and the gentle sound of birdsong fills the air. The woman's expression is one of peace and tranquility, as if she is completely at one with nature.
Negative Prompt:
bad-hands-5, bad_prompt, unrealistic eyes, blurry, low-resolution, pixelated, noisy, grainy, overexposed, underexposed, harsh shadows, bad lighting, out of focus, poorly composed, distracting elements, low contrast, washed out, unrealistic anatomy, distorted face,</pre>
			<p>Using the original prompt <strong class="source-inline">a realistic photo of a woman standing by the side of a river</strong>, Stable Diffusion V1.5 generated the images shown in <span class="No-Break"><em class="italic">Figure 17</em></span><span class="No-Break"><em class="italic">.15</em></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer120" class="IMG---Figure">
					<img src="image/B21263_17_15.jpg" alt="Figure 17.15: Images generated using SD V1.5 from the original prompt “a realistic photo of a woman standing by the side of a river”"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 17.15: Images generated using SD V1.5 from the original prompt “a realistic photo of a woman standing by the side of a river”</p>
			<p>With the <a id="_idIndexMarker541"/>new positive and negative prompts generated by the LLM, SD V1.5 generated the images shown in <span class="No-Break"><em class="italic">Figure 17</em></span><span class="No-Break"><em class="italic">.16</em></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer121" class="IMG---Figure">
					<img src="image/B21263_17_16.jpg" alt="Figure 17.16: Images generated using SD V1.5 from an LLM-generated prompt"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 17.16: Images generated using SD V1.5 from an LLM-generated prompt</p>
			<p>The improvements apply to SDXL too. With the original prompt, SDXL generated the images shown in <span class="No-Break"><em class="italic">Figure 17</em></span><span class="No-Break"><em class="italic">.17</em></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer122" class="IMG---Figure">
					<img src="image/B21263_17_17.jpg" alt="Figure 17.17: Images generated using SDXL from the original prompt “a realistic photo of a woman standing by the side of a river”"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 17.17: Images generated using SDXL from the original prompt “a realistic photo of a woman standing by the side of a river”</p>
			<p>Using the<a id="_idIndexMarker542"/> LLM-generated positive and negative prompts, SDXL generated the images shown in <span class="No-Break"><em class="italic">Figure 17</em></span><span class="No-Break"><em class="italic">.18</em></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer123" class="IMG---Figure">
					<img src="image/B21263_17_18.jpg" alt="Figure 17.18: Images generated using SDXL from LLM-generated prompts"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 17.18: Images generated using SDXL from LLM-generated prompts</p>
			<p>The images<a id="_idIndexMarker543"/> are undoubtedly better than the ones from the original prompt and prove that LLM-generated prompts can improve the quali<a id="_idTextAnchor352"/>ty of <span class="No-Break">generated images.</span></p>
			<h1 id="_idParaDest-212"><a id="_idTextAnchor353"/>Summary</h1>
			<p>In this chapter, we first discussed the challenges of composing prompts for Stable Diffusion to generate high-quality images. We then covered some fundamental rules for writing effective prompts for <span class="No-Break">Stable Diffusion.</span></p>
			<p>Taking it a step further, we summarized the rules of prompt writing and incorporated them into an LLM prompt. This approach not only works with ChatGPT [4] but also with <span class="No-Break">other LLMs.</span></p>
			<p>With the help of predefined prompts and LLMs, we can fully automate the image-generation process. There’s no need to carefully write and tune prompts manually; simply ask the AI what you want to generate, and the LLM will provide sophisticated prompts and negative prompts. If set up correctly, Stable Diffusion can automatically execute the prompt and deliver the result without any <span class="No-Break">human intervention.</span></p>
			<p>We understand that the development speed of AI is rapid. In the near future, you will be able to add more of your own LLM prompts to make the process even smarter and more powerful. This will further enhance the capabilities of Stable Diffusion and LLMs, allowing you to generate stunning images with <span class="No-Break">minimal effort.</span></p>
			<p>In the next chapter, we’ll use the knowledge we learned from the previous chapters to build useful applications <a id="_idTextAnchor354"/>using <span class="No-Break">Stable Diffusion.</span></p>
			<h1 id="_idParaDest-213"><a id="_idTextAnchor355"/>References</h1>
			<ol>
				<li><em class="italic">Language Models are Few-Shot </em><span class="No-Break"><em class="italic">Learners</em></span><span class="No-Break">: </span><a href="https://arxiv.org/abs/2005.14165"><span class="No-Break">https://arxiv.org/abs/2005.14165</span></a></li>
				<li><em class="italic">Best text prompt for creating Stable diffusion prompts through ChatGPT or a local LLM model? What do you use that is better?</em>: <a href="https://www.reddit.com/r/StableDiffusion/comments/14tol5n/best_text_prompt_for_creating_stable_diffusion/">https://www.reddit.com/r/StableDiffusion/comments/14tol5n/best_text_prompt_for_creating_stable_diffusion/</a> </li>
				<li><span class="No-Break">SkyTNT: </span><a href="https://github.com/SkyTNT?tab=repositories&#13;"><span class="No-Break">https://github.com/SkyTNT?tab=repositories</span></a></li>
				<li><span class="No-Break">ChatGPT: </span><a href="https://chat.openai.com/"><span class="No-Break">https://chat.openai.com/</span></a></li>
			</ol>
		</div>
	

		<div id="_idContainer125" class="Content">
			<h1 id="_idParaDest-214" lang="en-US" xml:lang="en-US"><a id="_idTextAnchor356"/>Part 4 – Building Stable Diffusion into an Application</h1>
			<p>Throughout this book, we’ve explored the vast potential of Stable Diffusion, from its fundamental concepts to advanced applications and customization techniques. Now, it’s time to bring everything together and integrate Stable Diffusion into real-world applications, making its power accessible to users and unlocking new possibilities for creative expression <span class="No-Break">and problem-solving.</span></p>
			<p>In this final part, we’ll focus on building practical applications that showcase the versatility and impact of Stable Diffusion. You’ll learn how to develop innovative solutions such as object editing and style transferring, enabling users to manipulate images in unprecedented ways. We’ll also cover the importance of data persistence, demonstrating how to save image generation prompts and parameters directly within the generated <span class="No-Break">PNG images.</span></p>
			<p>Furthermore, you’ll discover how to create interactive user interfaces using popular frameworks such as Gradio, making it easy for users to engage with Stable Diffusion models. Additionally, we’ll delve into the realm of transfer learning, guiding you through the process of training a Stable Diffusion LoRA from scratch. Finally, we’ll conclude with a broader discussion on the future of Stable Diffusion, AI, and the importance of staying informed about the latest developments in this rapidly <span class="No-Break">evolving field.</span></p>
			<p>By the end of this part, you’ll be equipped with the knowledge and skills necessary to integrate Stable Diffusion into a wide range of applications, from creative tools to productivity-enhancing software. The possibilities are endless, and it’s time to unleash the full potential of <span class="No-Break">Stable Diffusion!</span></p>
			<p>This part contains the <span class="No-Break">following chapters:</span></p>
			<ul>
				<li><a href="B21263_18.xhtml#_idTextAnchor357"><em class="italic">Chapter 18</em></a><em class="italic">, Applications – Object Editing and Style Transferring</em></li>
				<li><a href="B21263_19.xhtml#_idTextAnchor375"><em class="italic">Chapter 19</em></a><em class="italic">, Generation Data Persistence</em></li>
				<li><a href="B21263_20.xhtml#_idTextAnchor387"><em class="italic">Chapter 20</em></a><em class="italic">, Creating Interactive User Interfaces</em></li>
				<li><a href="B21263_21.xhtml#_idTextAnchor405"><em class="italic">Chapter 21</em></a><em class="italic">, Diffusion Model Transfer Learning</em></li>
				<li><a href="B21263_22.xhtml#_idTextAnchor443"><em class="italic">Chapter 22</em></a><em class="italic">, Exploring Beyond Stable Diffusion</em></li>
			</ul>
		</div>
		<div>
			<div id="_idContainer126">
			</div>
		</div>
		<div>
			<div id="_idContainer127" class="Basic-Graphics-Frame">
			</div>
		</div>
		<div>
			<div id="_idContainer128" class="Basic-Graphics-Frame">
			</div>
		</div>
		<div>
			<div id="_idContainer129">
			</div>
		</div>
		<div>
			<div id="_idContainer130" class="Basic-Graphics-Frame">
			</div>
		</div>
	</body></html>