- en: '*Chapter 4*: Implementing Sensors'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As we discussed in the previous chapter, a character AI system needs to be
    aware of its surrounding environment. For example, **Non-Player Characters** (**NPCs**)
    need to know where the obstacles are, the direction the player is looking, whether
    they are in the player''s sight, and a lot more. The quality of the AI of our
    NPCs depends, for the most part, on the information they can get from the environment.
    Sensor mistakes are apparent to the player: we''ve all experienced playing a video
    game and laughing at an NPC that clearly should have seen us, or, on the other
    hand, been frustrated because an NPC spotted us from behind a wall.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: Video game characters usually get the input information required by their underlying
    AI decision-making algorithms from sensory information. For simplicity, in this
    chapter, we will consider *sensory information* as any kind of data coming from
    the game world. If there's not enough information, characters might show unusual
    behaviors, such as choosing the wrong places to take cover, idling, or looping
    in strange actions without knowing how to proceed. A quick search for AI glitches
    on YouTube opens the door to a vast collection of common funny behaviors of AI,
    even in AAA games.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will look at the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: Introducing sensory systems
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Discovering what a sensory system is and how to implement two senses—sight and
    touch—in Unity
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building a demo where we can see our sensory system in action
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For this chapter, you just need Unity3D 2022\. You can find the example project
    described in this chapter in the `Chapter 4` folder in the book repository: [https://github.com/PacktPublishing/Unity-Artificial-Intelligence-Programming-Fifth-Edition/tree/main/Chapter04](https://github.com/PacktPublishing/Unity-Artificial-Intelligence-Programming-Fifth-Edition/tree/main/Chapter04).'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: Basic sensory systems
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An AI sensory system emulates senses such as sight, hearing, and even smell
    to get information from other GameObjects. In such a system, the NPCs need to
    examine the environment and check for such senses periodically based on their
    particular interest.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: 'In a minimal sensory system, we have two principal elements: **aspect** (also
    called **event emitters**) and **sense** (also called **event senses**). Every
    sense can perceive only a specific aspect; for instance, an NPC with just the
    sense of hearing can only perceive the sound (one of the aspects) emitted by another
    GameObject, or a zombie NPC can use its sense of smell to prey on the player''s
    brain. As in real life, we do not need a single sense for every NPC; they can
    have sight, smell, and touch all at once.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: In our demo, we'll implement a base interface, called `Sense`, that we'll use
    to implement custom senses. In this chapter, we'll implement sight and touch senses.
    Sight is what we use to see the world around them; if our AI character sees an
    enemy, we receive an event in our code, and we act accordingly by doing some action
    in response. Likewise, with touch, when an enemy gets too close, we want to be
    able to sense that. Finally, we'll implement a minimal `Aspect` class that our
    senses can perceive.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: Setting up our scene
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s get started by setting up our scene:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: First, we add a plane as a floor.
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Let's create a few walls to block the line of sight from our AI character to
    the enemy. We make these out of short—but wide—cubes that we group under an empty
    GameObject called **Obstacles**.
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, we add a directional light to see what is going on in our scene.
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We represent the player with a tank, similar to what we used earlier, and we
    represent the NPCs with simple cubes. We also have a **Target** object to show
    us where the tank is moving in our scene. Our Scene hierarchy should look similar
    to the following screenshot:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.1 – The setup of the example''s Hierarchy'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17984_04_1.jpg)'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.1 – The setup of the example's Hierarchy
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s position the tank, AI character, and walls randomly in our scene.
    First, make sure to increase the size of the plane to something that looks good.
    Fortunately, in this demo, all the objects are locked on the plane, and there
    is no simulated gravity so that nothing can fall off the plane. Also, be sure
    to adjust the camera so that we can have a clear view of the following scene:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.2 – The space that our tank and player wander in'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17984_04_2.jpg)'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.2 – The space that our tank and player wander in
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have the basics set up, let's look at how to implement the tank,
    AI character, and aspects for our player character.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: The player's tank and the aspect class
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The **Target** object is a simple sphere object with the mesh render disabled.
    We have also created a point light and made it a child of our Target object. Make
    sure that the light is centered, or it will not be very helpful.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: 'Look at the following code in the `Target.cs` file:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Attach this script to the Target object. The script detects the mouse-click
    event and then, using the raycasting technique, detects the mouse-click location
    on the plane in the 3D space, and updates the Target object's position in our
    scene. We will have a look at the player's tank in the following section.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: The player's tank
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The player's tank is the simple model we used in [*Chapter 2*](B17984_02_Epub.xhtml#_idTextAnchor100),
    *Finite State Machines*, with a non-kinematic `Rigidbody` component. We need the
    `Rigidbody` component to generate trigger events whenever we do collision detection
    with AI characters and environment objects. Finally, we need to assign the **Player**
    tag to our tank.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: 'As we can easily see from its name, the `PlayerTank` script controls the player''s
    tank. The following is the code for the `PlayerTank.cs` file:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'This script retrieves the Target position on the map and updates the tank''s
    destination point and direction accordingly. The result of the preceding code
    is shown in the following panel:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.3 – The properties of our Tank object'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17984_04_3.jpg)'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.3 – The properties of our Tank object
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: After we assign the preceding script to the tank, be sure to assign the Target
    object to the `targetTransform` variable.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: Aspect
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Next, let's take a look at the `Aspect` class. `Aspect` is an elementary class
    with just one public property, called `aspectName`. That's all the variables we
    need in this chapter.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: 'Whenever our AI character senses something, we''ll check this against `aspectName`
    to see whether it''s the aspect that the AI has been looking for:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Attach this aspect script to our player's tank and set the `aspectName` property
    as `Player`.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: AI characters
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this example, the AI characters roam around the scene in a random direction.
    They have two senses: sight and touch. The sight sense checks whether the enemy
    aspect is within a set visible range and distance. Touch detects whether the enemy
    aspect has collided with the `Box Collider` around the character. As we have seen
    previously, our player''s tank has the `Player` aspect. Consequently, these senses
    are triggered when they detect the player''s tank.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: 'For now, let''s look at the script we use to move the NPCs around:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The `Wander` script generates a new random position in a specified range whenever
    an AI character reaches its current destination point. Then, the `Update` method
    rotates the NPCs and moves them toward their new destination. Attach this script
    to our AI character so that it can move around in the scene.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: Sense
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The `Sense` class is the interface of our sensory system that the other custom
    senses can implement. It defines two virtual methods, `Initialize` and `UpdateSense`,
    executed from the `Start` and `Update` methods, respectively, and that we can
    override when implementing custom senses as shown in the following code block:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The basic properties of this script are the intervals between two consecutive
    sensing operations and the name of the aspect it should look for. This script
    is not attached to any objects; instead, we use it as a base for specific senses,
    such as `Sight` and `Touch`.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: Sight
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The `Sight` sense detects whether a specific aspect is within the perception
    field of the character. If it perceives anything, it takes the specified action
    as shown in the following code block:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: We need to implement the `Initialize` and `UpdateSense` methods of the parent
    `Sense` class, respectively. Then, in the `DetectAspect` method, we first check
    the angle between the player and the AI's current direction. Then, if it's in
    the field-of-view range, we shoot a ray in the direction of the player's tank.
    The length of the ray is the value in the visible distance property.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: The `Raycast` method returns when it first hits another object. Then, we check
    this against the aspect component and the aspect name. In this way, even if the
    player is in the visible range, the AI character will not see the player if they
    hide behind a wall.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: The `OnDrawGizmos` method draws lines based on the perspective field (determined
    by the view angle and viewing distance) to see the AI character's line of sight
    in the editor window during playtesting. Attach this script to the AI character,
    and ensure to set the aspect name to `Enemy`.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: 'This method can be illustrated as follows:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '`OnDrawGizmos` is an event function that we can use when we want to draw gizmos
    in the scene. `DrawLine`, `DrawIcon`, and `DrawSphere`.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: 'They are a handy way to quickly provide some visual feedback to our algorithms.
    You can learn more about the gizmo functions by following this link: [https://docs.unity3d.com/ScriptReference/Gizmos.html](https://docs.unity3d.com/ScriptReference/Gizmos.html).'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: Touch
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Another sense we''re going to implement is `Touch`, which is triggered when
    the player entity is within a specific range of the AI entity as shown in the
    following code block. Our AI character has a box collider component, and its `Is
    Trigger` flag is on:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We need to implement the `OnTriggerEnter` event fired whenever the collider
    component collides with another collider component. Since our tank entity also
    has collider and `Rigidbody` components, a collision event occurs as soon as the
    colliders of the AI character and the player's tank coincide.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot shows the box collider of our enemy AI that we are
    using to implement the `Touch` sense:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.4 – The collider component around our player'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17984_04_4.jpg)'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.4 – The collider component around our player
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following screenshot, we can see how our AI character is set up:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.5 – Properties of our player'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17984_04_5.jpg)'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.5 – Properties of our player
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: Inside the `OnTriggerEnter` method, we access the aspect component of the other
    collider entity and check whether the name of the aspect is the same aspect that
    this AI character is looking for. For demonstration purposes, we print out in
    the console that the character detects the enemy aspect by the `Touch` sense.
    In a real game, we would not print the event but rather trigger other actions,
    such as turning to face an enemy and then chasing, attacking, and so on. Let's
    move on to testing our game.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: Testing the game
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, play the game in Unity3D and move the player's tank near the wandering
    AI character by clicking on the ground. You should see the **Enemy touch detected**
    message in the console log window whenever our AI character gets close to our
    player's tank.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在Unity3D中玩游戏，通过点击地面将玩家的坦克移动到游荡的AI角色附近。每当我们的AI角色接近玩家的坦克时，你应在控制台日志窗口中看到**敌人触摸检测**的消息。
- en: '![Figure 4.6 – Our player and tank in action'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '![图4.6 – 我们的角色和坦克在行动中'
- en: '](img/B17984_04_6.jpg)'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17984_04_6.jpg]'
- en: Figure 4.6 – Our player and tank in action
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.6 – 我们的角色和坦克在行动中
- en: The previous screenshot shows an AI agent with touch and perspective senses
    looking for an enemy aspect. Move the player's tank in front of the AI character,
    and you'll get the *Enemy detected* message. If you go into the editor view while
    running the game, you should see the rendered debug drawings thanks to the `OnDrawGizmos`
    method implemented in the `Sight sense` class.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 上一张截图显示了一个具有触摸和视角感官的AI代理正在寻找敌人特征。将玩家的坦克移到AI角色前方，你将收到**敌人检测**的消息。如果在运行游戏的同时进入编辑器视图，你应该会看到由于在`视觉感官`类中实现了`OnDrawGizmos`方法而渲染的调试图形。
- en: Summary
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter introduced the concept of using sensors in implementing game AI,
    and we implemented two senses, `Sight` and `Touch`, for our AI character. The
    sensory system is just the first element of the decision-making system of a whole
    AI system. For example, we can use the sensory system to control the execution
    of a behavior system or change the state of a Finite State Machine once we have
    detected an enemy within the AI's line of sight.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了在实现游戏AI中使用传感器的概念，并为我们的AI角色实现了两种感官，即`视觉`和`触摸`。感官系统是整个AI系统决策系统的第一个元素。例如，一旦我们在AI的视线范围内检测到敌人，我们可以使用感官系统来控制行为系统的执行或改变有限状态机的状态。
- en: We will cover how to apply behavior tree systems in [*Chapter 9*](B17984_09_Epub.xhtml#_idTextAnchor487),
    *Behavior Trees*. In the meantime, in the next chapter, we'll look at how to implement
    flocking behaviors in Unity3D, as well as how to implement Craig Reynold's flocking
    algorithm.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[*第9章*](B17984_09_Epub.xhtml#_idTextAnchor487)“行为树”中介绍如何应用行为树系统。同时，在下一章中，我们将探讨如何在Unity3D中实现群聚行为，以及如何实现克雷格·雷诺的群聚算法。
