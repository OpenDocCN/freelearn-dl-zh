<html><head></head><body>
        

                            
                    <h1 class="header-title">Training CNNs Using ConvNetSharp</h1>
                
            
            
                
<p>In this chapter, we are going to use the phenomenal open source package <strong>ConvNetSharp</strong>, by Cédric Bovar, to demonstrate how to train our <strong>Convolutional Neural Networks</strong> (<strong>CNNs</strong>). In this chapter, we will look at the following topics:</p>
<ul>
<li>Common neural network modules</li>
<li>The various terms and concepts related to CNNs</li>
<li>Convolutional networks that process images</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Technical requirements</h1>
                
            
            
                
<p>You will need Microsoft Visual Studio and ConvNetSharp framework for this chapter. </p>


            

            
        
    

        

                            
                    <h1 class="header-title">Getting acquainted </h1>
                
            
            
                
<p>Before we begin diving into code, let's cover some basic terminology so that we are all on the same page when referring to things. This terminology applies to CNNs as well as the <strong>ConvNetSharp </strong>framework.</p>
<p><strong>Convolution</strong>: In mathematics, a <em>convolution</em> is an operation performed on two functions. This operation produces a third function, which is an expression of how the shape of one is modified by the other. This is represented visually in the following diagram:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/b3fdf9f1-90bd-4897-9781-ccf6e645341b.png" style="width:30.67em;height:19.25em;"/></p>
<p>It is important to note that the convolutional layer itself is the building block of a CNN. This layer's parameters consist of a set of learnable filters (sometimes called <strong>kernels</strong>). These kernels have a small receptive field, which is a smaller view into the total image, and this view extends through the full depth of the input volume. During the forward propagation phase, each filter is <strong>convolved</strong> across the width and the height of the entire input volume. It is this convolution that computes the dot product between the filter and the input. This then produces a two-dimensional map (sometimes called an <strong>activation map</strong>) of the filter. This helps the network learn which filters should activate when they detect a feature at that respective input position.</p>
<p><strong>Dot product computation</strong>: The following diagram is a visualization of what we mean when we say dot product computation:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/3831e519-e3b9-458d-95fb-c4f32f93a446.png" style="width:20.25em;height:9.50em;"/></p>
<ul>
<li><strong>Vol class</strong>: In ConvNetSharp, the <kbd>Vol</kbd> class is simply a wrapper around a one-dimensional list of numbers, their gradients, and dimensions (that is, width, depth, and height).</li>
<li><strong>Net class</strong>: In ConvNetSharp, <kbd>Net</kbd> is a very simple class that contains a list of layers. When a <kbd>Vol</kbd> is passed through the <kbd>Net</kbd> class, <kbd>Net</kbd> iterates through all its layers, forward-propagates each one by calling the <kbd>forward()</kbd> function, and returns the result of the last layer. During back propagation, <kbd>Net</kbd> calls the <kbd>backward()</kbd> function of each layer to compute the gradient.</li>
<li><strong>Layers</strong>: As we know, every neural network is just a linear list of layers, and ours is no different. For a neural network, the first layer must be an input layer, and our last layer must be an output layer. Every layer takes an input <kbd>Vol</kbd> and produces a new output <kbd>Vol</kbd>.</li>
<li><strong>Fully-connected layer</strong>: The fully-connected layer is perhaps the most important layer and is definitely the most interesting in terms of what it does. It houses a layer of neurons that perform weighted addition of all the inputs. These are then passed through a non-linear activation function such as a ReLU.</li>
<li><strong>Loss layers</strong> and <strong>classifier layers</strong>: These layers are helpful when we need to predict a set of discrete classes for our data. You can use softmax, SVM, and many other types of layers. As always, you should experiment with your particular problem to see which one works best.</li>
<li><strong>Loss layers</strong> and the <strong>L2 regression layer</strong>: This layer takes a list of targets and backward-propagates the L2 loss through them.</li>
<li><strong>Convolution layer</strong>: This layer is almost a mirror of the fully-connected layer. The difference here is that neurons are only connected locally to a few neurons in the layer rather than being connected to all of them. They also share parameters.</li>
<li><strong>Trainers</strong>: The <kbd>Trainer</kbd> class takes a network and a set of parameters. It passes this through the network, sees the predictions, and adjusts the network weights to make the provided labels more accurate for that particular input. Over time, the process will transform the network and map all the inputs to the correct outputs.</li>
</ul>
<p>With that behind us, let's now talk a bit about CNNs themselves. A CNN consists of an input and an output layer; there's no big surprise there. There will be one or more hidden layers which consist of convolutional layers, pooling layers, fully-connected layers, or normalization layers. It is in these hidden layers that the magic happens. Convolutional layers apply a <strong>convolution</strong> operation to the input and pass the result to the next layer. We'll talk more about that in a moment.</p>
<p>As we progress, the activation maps will be stacked for all of the filters that run along the depth dimension. This, in turn, will form the full output volume of the layer itself. Each neuron on that layer processes data only for its own receptive field (the data view it can see). This information is shared with other neurons.</p>
<p>The thing that we have to always keep in mind with a CNN is the input size, which can require an extremely high number of neurons to process, depending on the resolution of the image. This could become architecturally inconvenient, and even intractable, because each pixel is a variable that needs to be processed.</p>
<p>Let's take a look at an example. If we have an image of 100 x 100 pixels, we would all agree that this is a small image. However, this image has 10,000 pixels in total (100 x 100), all of which are weights for each neuron in the second layer. Convolution is key to addressing this issue, as it reduces the number of parameters and allows the network to go deeper with fewer parameters. With 10,000 learnable parameters, the solution may be totally intractable; however, if we reduce that image to a 5 x 5 area, for example, we now have 25 different neurons to handle instead of 10,000, which is much more feasible. This will also help us to eliminate, or at least greatly reduce, the vanishing or exploding gradient problem we sometimes encounter when we train multi-layer networks.</p>
<p>Let's now take a quick look at how this works visually. As shown in the following diagram, we will use the number 6 and run it through a CNN to see if our network can detect the number we are trying to draw. The image at the bottom of the following screenshot is what we will draw. By the time we convolve things all the way up to the top, we should be able to light up the single neuron that denotes the number 6, as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/6739312a-092e-4a5c-9d00-86e2217de804.png" style="width:39.50em;height:28.83em;"/></p>
<p>In the preceding screenshot, we can see an input layer (our single number 6), convolutional layers, down-sampling layers, and an output layer. Our progression is as follows: we start with a 32 x 32 image, which leaves us with 1,024 neurons. We then go down to 120 neurons, then to 100 neurons, and finally to 10 neurons in our output layer – that's one neuron for each of the 10 numerical digits. You can see that as we progress towards our output layer, the dimension of the image decreases. As we can see, we have 32 x 32 in our first convolutional layer, 10 x 10 in our second, and 5 x 5 in our second pooling layer.</p>
<p>It's also worth noting that each neuron in the output layer is fully connected to all 100 nodes in the fully-connected layer preceding it; hence, the term fully-connected layer.</p>
<p>If we make a three-dimensional drawing of this network and flip it around, we can better see how convolution occurs. The following diagram depicts just that, as the activated neurons are brighter in color. The layers continue to convolve until a decision is made as to which digit we have drawn, shown as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/57d82dfd-42e3-4e84-8732-4bea9d17e9cc.png" style="width:38.83em;height:22.00em;"/></p>


            

            
        
    

        

                            
                    <h1 class="header-title">Filters</h1>
                
            
            
                
<p>One of the other unique features of a CNN is that many neurons can share the same vector of weights and biases, or more formally, the same <strong>filter</strong>. Why is that important? Because each neuron computes an output value by applying a function to the input values of the previous layer. Incremental adjustments to these weights and biases are what helps the network to learn. If the same filter can be re-used, then the required memory footprint will be greatly reduced. This becomes very important, especially as the image or receptive field gets larger.</p>
<p>CNNs have the following distinguishing features:</p>
<ul>
<li><strong>Three-dimensional volumes of neurons</strong>: The layers of a CNN have neurons arranged in three dimensions: width, height, and depth. The neurons inside each layer are connected to a small region of the layer before it called their receptive field. Different types of connected layers are stacked to form the actual convolutional architecture, as shown in the following diagram:</li>
</ul>
<div><img class="alignnone size-full wp-image-1243 image-border" src="img/bb61aafc-a0ad-4dc4-88b6-bc5dd911e80a.png" style="width:18.33em;height:7.83em;"/></div>
<div><strong>Convolving</strong></div>
<ul>
<li><strong>Shared weights</strong>: In a convolutional neural network, each receptive field (filter) is replicated across the entire visual field, as the preceding image shows. These filters share the same weight vector and bias parameters, and form what is commonly referred to as a <strong>feature map</strong>. This means that all the neurons in a given convolutional layer respond to the same feature within their specific field. Replicating units in this way allows for features to be detected regardless of their position in the visual field. The following diagram is a simple example of what this means:</li>
</ul>
<p><strong>This is a sample</strong></p>
<p>   This is a sample</p>
<p>       This is a sample</p>
<p>           This is a sample</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Creating a network</h1>
                
            
            
                
<p>Using the ConvNetSharp framework, there are three ways in which to create a neural network. First, we can use the <kbd>Core.Layers</kbd> or <kbd>Flow.Layers</kbd> objects to create a convolutional network (with or without a computational graph), as shown in the following diagram:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-981 image-border" src="img/43f2c91a-b159-41aa-96d6-8ad561d05816.png" style="width:32.25em;height:10.75em;"/></p>
<p class="CDPAlignLeft CDPAlign">Alternatively, we can create a computational graph like the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1244 image-border" src="img/3c529c15-1cf6-4a33-85e6-9e377fac4259.png" style="width:18.75em;height:37.00em;"/></p>


            

            
        
    

        

                            
                    <h1 class="header-title">Example 1 – a simple example</h1>
                
            
            
                
<p>Let's take a look at our first example. This is a minimal example in which we will define a <strong>two</strong>-<strong>layer neural network</strong> and train it on a single data point. We are intentionally making this example verbose so that we can walk through each step together to improve our understanding:</p>
<pre>var net = new Net&lt;double&gt;();</pre>
<p>The <kbd>InputLayer</kbd> variable declares size of input. As shown in the preceding code, we use two-dimensional data. Three-dimensional volumes (width, height, and depth) are required, but if you're not dealing with images then we can leave the first two dimensions (width and height) at a size of 1, as we have done in the following example:</p>
<pre>net.AddLayer(new InputLayer(1, 1, 2));</pre>
<p>Declare a fully-connected layer comprising <kbd>20</kbd> neurons, as follows:</p>
<pre>net.AddLayer(new FullyConnLayer(20));</pre>
<p>Next, we need to declare a Rectified Linear Unit non-linearity (<kbd>ReLU</kbd>) layer, as follows:</p>
<pre>net.AddLayer(new ReluLayer());</pre>
<p>Then, declare a fully-connected layer that will be used by the <kbd>SoftmaxLayer</kbd> with the following code:</p>
<pre>net.AddLayer(new FullyConnLayer(10));</pre>
<p>Declare the linear classifier on top of the previous hidden layer, as follows:</p>
<pre>net.AddLayer(new SoftmaxLayer(10));<br/>var x = BuilderInstance.Volume.From(new[] { 0.3, -0.5 }, new Shape(2));</pre>
<p>We then need to move forward with a random data point through the network, as follows:</p>
<pre>var prob = net.Forward(x);</pre>
<p><kbd>prob</kbd> is a volume. Volumes have property weights that store the raw data, and weight gradients that store gradients. The following code prints approximately 0.50101, as follows:</p>
<pre>Console.WriteLine("probability that x is class 0: " + prob.Get(0));</pre>
<p>Next, we need to train the network, specifying that <kbd>x</kbd> is class zero and using a stochastic gradient descent trainer, shown as follows:</p>
<pre>var trainer = new SgdTrainer(net)<br/>{<br/>LearningRate = 0.01, L2Decay = 0.001<br/>};<br/>trainer.Train(x,BuilderInstance.Volume.From(new[]{ 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 }, new Shape(1, 1, 10, 1)));<br/>var prob2 = net.Forward(x);<br/>Console.WriteLine("probability that x is class 0: " + prob2.Get(0));</pre>
<p>The output should now be 0.50374, which is slightly higher than the previous value of 0.50101. This is because the network weights have been adjusted by the <kbd>trainer</kbd> to give a higher probability to the class we trained the network with (which was zero).</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Example 2 – another simple example</h1>
                
            
            
                
<p>As in the previous section, the following example also solves a simple problem, while demonstrating how to save and load a graph as well:</p>
<pre>var cns = new ConvNetSharp&lt;float&gt;();</pre>
<p>To create a graph, input the following code:</p>
<pre>Op&lt;float&gt; cost;<br/>Op&lt;float&gt; fun;<br/>if (File.Exists("test.graphml"))<br/>{<br/>Console.WriteLine("Loading graph from disk.");<br/>var ops = SerializationExtensions.Load&lt;float&gt;("test", true);<br/>fun = ops[0];<br/>cost = ops[1];<br/>}<br/>else<br/>{<br/>var x = cns.PlaceHolder("x");<br/>var y = cns.PlaceHolder("y");<br/>var W = cns.Variable(1.0f, "W", true);<br/>var b = cns.Variable(2.0f, "b", true);<br/>fun = x * W + b;<br/>cost = (fun - y) * (fun - y);<br/>}<br/>var optimizer = new AdamOptimizer&lt;float&gt;(cns, 0.01f, 0.9f, 0.999f, 1e-08f);<br/>using (var session = new Session&lt;float&gt;())<br/>{</pre>
<p>Next, to compute the dCost/dW at every node of the graph, we use the following code:</p>
<pre>session.Differentiate(cost);<br/>float currentCost;<br/>do<br/>{<br/> var dico = new Dictionary&lt;string, Volume&lt;float&gt;&gt; { { "x", -2.0f }, { "y", 1.0f } };<br/>currentCost = session.Run(cost, dico);<br/>Console.WriteLine($"cost: {currentCost}");<br/>var result = session.Run(fun, dico);<br/>session.Run(optimizer, dico);<br/>}<br/>while (currentCost &gt; 1e-5);<br/>float finalW = session.GetVariableByName(fun, "W").Result;<br/>float finalb = session.GetVariableByName(fun, "b").Result;<br/>Console.WriteLine($"fun = x * {finalW} + {finalb}");<br/>fun.Save("test", cost);</pre>
<p>To display the graph, input the following code:</p>
<pre>var vm = new ViewModel&lt;float&gt;(cost);<br/>var app = new Application();<br/>app.Run(new GraphControl { DataContext = vm });<br/>}</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Example 3 – our final simple example</h1>
                
            
            
                
<p>The following example does a simple calculation and displays the resultant computational graph. The code needed is as follows:</p>
<pre>var cns = new ConvNetSharp&lt;float&gt;();</pre>
<p>To create a graph, use the following code:</p>
<pre>var x = cns.PlaceHolder("x");<br/>var fun = 2.0f * x;<br/>using (var session = new Session&lt;float&gt;())<br/>{</pre>
<p>Next, to compute the dCost/dW at every node of the graph, we use the following code:</p>
<pre>session.Differentiate(fun);</pre>
<p>Finally, to display the graph, input the following code:</p>
<pre>var vm = new ViewModel&lt;float&gt;(x.Derivate);<br/>var app = new Application();<br/>app.Run(new GraphControl { DataContext = vm });<br/>}</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Using the Fluent API</h1>
                
            
            
                
<p>For those of you who have the bug for Fluent APIs, ConvNetSharp has done a job of providing one for you.</p>
<p>Just look at the following example to see how easy it is to use the Fluent DSL when adding layers:</p>
<pre>varnet=FluentNet&lt;double&gt;.Create(24, 24, 1)<br/>.Conv(5, 5, 8).Stride(1).Pad(2)<br/>.Relu()<br/>.Pool(2, 2).Stride(2)<br/>.Conv(5, 5, 16).Stride(1).Pad(2)<br/>.Relu()<br/>.Pool(3, 3).Stride(3)<br/>.FullyConn(10)<br/>.Softmax(10)<br/>.Build();</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">GPU</h1>
                
            
            
                
<p>In order to use GPU capability in your software using ConvNetSharp, you must have CUDA Version 8 and Cudnn Version 6.0 (April 27, 2017) installed. The <kbd>Cudnn bin path</kbd> should also be referenced in the <strong>PATH</strong> environment variable.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Fluent training with the MNIST database</h1>
                
            
            
                
<p>In the following example, we will train our CNN against the <kbd>MNIST</kbd> database of images.</p>
<p>To declare a function, use the following code:</p>
<pre>private void MnistDemo()<br/>{</pre>
<p>Next, download the training and testing <kbd>datasets</kbd> with the following command:</p>
<pre>var datasets = new DataSets();</pre>
<p>Load <kbd>100</kbd> validation sets with the following command:</p>
<pre>if (!datasets.Load(100))<br/>{<br/>return;<br/>}</pre>
<p>Now it's time to create the neural network using the Fluent API, as follows:</p>
<pre>this._net = FluentNet&lt;double&gt;.Create(24, 24, 1)<br/>.Conv(5, 5, 8).Stride(1).Pad(2)<br/>.Relu()<br/>.Pool(2, 2).Stride(2)<br/>.Conv(5, 5, 16).Stride(1).Pad(2)<br/>.Relu()<br/>.Pool(3, 3).Stride(3)<br/>.FullyConn(10)<br/>.Softmax(10)<br/>.Build();</pre>
<p>Create the stochastic gradient descent trainer from the network with the following command:</p>
<pre>this._trainer = new SgdTrainer&lt;double&gt;(this._net)<br/>{<br/>LearningRate = 0.01,<br/>BatchSize = 20,<br/>L2Decay = 0.001,<br/>Momentum = 0.9<br/>};<br/>do<br/>{</pre>
<p>Next, get the <kbd>NextBatch</kbd> of data with the following code:</p>
<pre>var trainSample = datasets.Train.NextBatch(this._trainer.BatchSize);</pre>
<p><kbd>Train</kbd> the data received with the following command:</p>
<pre>Train(trainSample.Item1, trainSample.Item2, trainSample.Item3);</pre>
<p>It's now time to get the <kbd>NextBatch</kbd> of data; to do so, use the following command:</p>
<pre>var testSample = datasets.Test.NextBatch(this._trainer.BatchSize);</pre>
<p>The code can be tested with the following command:</p>
<pre>Test(testSample.Item1, testSample.Item3, this._testAccWindow);</pre>
<p>To report the <kbd>accuracy</kbd>, input the following command:</p>
<pre>Console.WriteLine("Loss: {0} Train accuracy: {1}% Test accuracy: {2}%", this._trainer.Loss, Math.Round(this._trainAccWindow.Items.Average() * 100.0, 2),<br/>Math.Round(this._testAccWindow.Items.Average() * 100.0, 2));<br/>} while (!Console.KeyAvailable);<br/></pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Training the network</h1>
                
            
            
                
<p>To train the convolutional network, we must perform both forward- and backward-propagation, as shown in the following example:</p>
<pre>public virtual void Train(Volume&lt;T&gt; x, Volume&lt;T&gt; y)<br/>{<br/>Forward(x);<br/>Backward(y);<br/>}</pre>
<p>The following screenshot illustrates our training in progress:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1245 image-border" src="img/3a081492-e7e9-4de1-90cf-575f5f8f5f83.png" style="width:37.50em;height:37.08em;"/></p>


            

            
        
    

        

                            
                    <h1 class="header-title">Testing the data</h1>
                
            
            
                
<p>This section details the <kbd>Test</kbd> function, which will show us how to test the data we have trained. We get the network prediction and track the accuracy for each label that we have with the following command:</p>
<pre>private void Test(Volume x, int[] labels, CircularBuffer&lt;double&gt; accuracy, bool forward = true)<br/>{<br/>if (forward)<br/>{</pre>
<p><kbd>Forward</kbd> momentum can be found with the following code:</p>
<pre>this._net.Forward(x);<br/>}<br/>var prediction = this._net.GetPrediction();<br/>for (var <strong>i</strong> = 0; <strong>i</strong> &lt; labels.Length; <strong>i</strong>++)<br/>{</pre>
<p>To track the <kbd>accuracy</kbd>, input the following code:</p>
<pre>accuracy.Add(labels[<strong>i</strong>] == prediction[<strong>i</strong>] ? 1.0 : 0.0);<br/>}<br/>}</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Predicting data</h1>
                
            
            
                
<p>Predicting data in this instance means predicting the <kbd>argmax</kbd> value. To do this, we assume that the last layer of the network is a <kbd>SoftmaxLayer</kbd>. Prediction occurs when we call the <kbd>GetPrediction()</kbd><q> </q>function, as follows:</p>
<pre>public int[] GetPrediction()<br/>{<br/>var softmaxLayer = this._lastLayer as SoftmaxLayer&lt;T&gt;;<br/>if (softmaxLayer == null)<br/>{<br/>throw new Exception("Function assumes softmax as last layer of the net!");<br/>}<br/>var activation = softmaxLayer.OutputActivation;<br/>var N = activation.Shape.Dimensions[3];<br/>var C = activation.Shape.Dimensions[2];<br/>var result = new int[N];<br/>for (var<strong>n</strong> = 0; <strong>n</strong> &lt; N; <strong>n</strong>++)<br/>{<br/>var<strong>maxv</strong> = activation.Get(0, 0, 0, <strong>n</strong>);<br/>var<strong>maxi</strong> = 0;<br/>for (var<strong>i</strong> = 1; <strong>i</strong> &lt; C; <strong>i</strong>++)<br/>{<br/>var output = activation.Get(0, 0, <strong>i</strong>, <strong>n</strong>);<br/>if (Ops&lt;T&gt;.GreaterThan(output, <strong>maxv</strong>))<br/>{<br/><strong>maxv</strong> = output;<br/><strong>maxi</strong> = <strong>i</strong>;<br/>}<br/>}<br/>result[<strong>n</strong>] = <strong>maxi</strong>;<br/>}<br/>return result;<br/>}</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Computational graphs</h1>
                
            
            
                
<p>The following screenshots two computational graphs that we created based on our example applications:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1246 image-border" src="img/7d55cd18-0124-4aef-aab3-00679b65dea2.png" style="width:57.75em;height:33.58em;"/></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1247 image-border" src="img/255f4619-e2a1-41bc-9e33-712f0eac428d.png" style="width:91.75em;height:53.08em;"/></p>


            

            
        
    

        

                            
                    <h1 class="header-title">Summary</h1>
                
            
            
                
<p>In this chapter, we used the open source package ConvNetSharp to explain CNNs. We looked at how to test and train these networks and also learned why they are convolutional. We worked with several example applications to explain how ConvNetSharp functions and operates. In the next chapter, we will look at autoencoders and RNNSharp, exposing you further to recurrent neural networks.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">References</h1>
                
            
            
                
<ul>
<li>ConvNetSharp Copyright (c) 2018 Cédric Bovar. Used with permission granted.</li>
<li>The mostly complete chart of neural networks, explained, Asimov Institute, used with permission granted.</li>
<li><a href="http://scs.ryerson.ca/~aharley/vis/conv/flat.html">http://scs.ryerson.ca/~aharley/vis/conv/flat.html</a></li>
</ul>


            

            
        
    </body></html>