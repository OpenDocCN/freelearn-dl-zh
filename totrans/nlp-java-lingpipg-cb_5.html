<html><head></head><body>
<div><div><div><div><div><h1 class="title" id="calibre_pb_0"><a id="ch05" class="calibre1"/>Chapter 5. Finding Spans in Text – Chunking</h1></div></div></div><p class="calibre9">This chapter covers the following recipes:</p><div><ul class="itemizedlist"><li class="listitem">Sentence detection</li><li class="listitem">Evaluation of sentence detection</li><li class="listitem">Tuning sentence detection</li><li class="listitem">Marking embedded chunks in a string – sentence chunk example</li><li class="listitem">Paragraph detection</li><li class="listitem">Simple noun phrases and verb phrases</li><li class="listitem">Regular expression-based chunking for NER</li><li class="listitem">Dictionary-based chunking for NER</li><li class="listitem">Translating between word tagging and chunks – BIO codec</li><li class="listitem">HMM-based NER</li><li class="listitem">Mixing the NER sources</li><li class="listitem">CRFs for chunking</li><li class="listitem">NER using CRFs with better features</li></ul></div></div>

<div><div><div><div><div><h1 class="title" id="calibre_pb_1"><a id="ch05lvl1sec55" class="calibre1"/>Introduction</h1></div></div></div><p class="calibre9">This chapter will tell us how to work with spans of text that typically cover one or more words/tokens. The LingPipe API represents this unit of text as a chunk with corresponding chunkers that produce chunkings. The following is some text with character offsets indicated:</p><div><pre class="programlisting">LingPipe is an API. It is written in Java.
012345678901234567890123456789012345678901
          1         2         3         4           </pre></div><p class="calibre9">Chunking the preceding text into sentences will give us the following output:</p><div><pre class="programlisting">Sentence start=0, end=18
Sentence start =20, end=41</pre></div><p class="calibre9">Adding in a chunking for named entities adds entities for LingPipe and Java:</p><div><pre class="programlisting">Organization start=0, end=7
Organization start=37, end=40</pre></div><p class="calibre9">We can define the named-entity chunkings with respect to their offsets from the sentences that contain them; this will make no difference to LingPipe, but Java will be:</p><div><pre class="programlisting">Organization start=17, end=20</pre></div><p class="calibre9">This is the basic idea of chunks. There are lots of ways to make them.</p></div></div>

<div><div><div><div><div><h1 class="title" id="calibre_pb_0"><a id="ch05lvl1sec56" class="calibre1"/>Sentence detection</h1></div></div></div><p class="calibre9">Sentences in written text roughly <a id="id429" class="calibre1"/>correspond to a spoken utterance. They are the standard unit of processing words in industrial applications. In almost all mature NLP applications, sentence detection is a part of the processing pipeline even in the case of tweets, which can have more than one sentence in the allotted 140 characters.</p></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_1"><a id="ch05lvl2sec127" class="calibre1"/>How to do it...</h2></div></div></div><div><ol class="orderedlist"><li class="listitem" value="1">As usual, we will play with some data first. Enter the following command in the console:<div><pre class="programlisting">
<strong class="calibre2">java -cp lingpipe-cookbook.1.0.jar:lib/lingpipe-4.1.0.jar: com.lingpipe.cookbook.chapter5.SentenceDetection</strong>
</pre></div></li><li class="listitem" value="2">The program will provide a prompt for your sentence-detection experimentation. A new line / return terminates the text to be analyzed:<div><pre class="programlisting">
<strong class="calibre2">Enter text followed by new line</strong>
<strong class="calibre2">&gt;A sentence. Another sentence.</strong>
<strong class="calibre2">SENTENCE 1:</strong>
<strong class="calibre2">A sentence.</strong>
<strong class="calibre2">SENTENCE 2:</strong>
<strong class="calibre2">Another sentence.</strong>
</pre></div></li><li class="listitem" value="3">It is worth playing around a bit with different inputs. The following are some examples that explore the properties of the sentence detector. Drop the capitalized beginning of a sentence; this will prevent the detection of the second sentence:<div><pre class="programlisting">
<strong class="calibre2">&gt;A sentence. another sentence.</strong>
<strong class="calibre2">SENTENCE 1:</strong>
<strong class="calibre2">A sentence. another sentence.</strong>
</pre></div></li><li class="listitem" value="4">The detector does not require a final period—this is configurable:<div><pre class="programlisting">
<strong class="calibre2">&gt;A sentence. Another sentence without a final period</strong>
<strong class="calibre2">SENTENCE 1:A sentence.</strong>
<strong class="calibre2">SENTENCE 2:Another sentence without a final period</strong>
</pre></div></li><li class="listitem" value="5">The detector balances parentheses, which will not allow sentences to break inside parentheses—this is also configurable:<div><pre class="programlisting">
<strong class="calibre2">&gt;(A sentence. Another sentence.)</strong>
<strong class="calibre2">SENTENCE 1: (A sentence. Another sentence.)</strong>
</pre></div></li></ol><div></div></div></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_2"><a id="ch05lvl2sec128" class="calibre1"/>How it works...</h2></div></div></div><p class="calibre9">This sentence detector<a id="id430" class="calibre1"/> is <a id="id431" class="calibre1"/>a heuristic-based or rule-based sentence detector. A statistical sentence detector would be a reasonable approach as well. We will get through the entire source to run the detector, and later, we will discuss the modifications:</p><div><pre class="programlisting">package com.lingpipe.cookbook.chapter5;

import com.aliasi.chunk.Chunk;
import com.aliasi.chunk.Chunker;
import com.aliasi.chunk.Chunking;
import com.aliasi.sentences.IndoEuropeanSentenceModel;
import com.aliasi.sentences.SentenceChunker;
import com.aliasi.sentences.SentenceModel;
import com.aliasi.tokenizer.IndoEuropeanTokenizerFactory;
import com.aliasi.tokenizer.TokenizerFactory;
import java.io.BufferedReader;
import java.io.IOException;
import java.io.InputStreamReader;
import java.util.Set;

public class SentenceDetection {

public static void main(String[] args) throws IOException {
  boolean endSent = true;
  boolean parenS = true;
  SentenceModel sentenceModel = new IndoEuropeanSentenceModel(endSent,parenS);</pre></div><p class="calibre9">Working from the top of the <code class="email">main</code> class, the Boolean <code class="email">endSent</code> parameter controls whether the string that is sentence detected is assumed to end with a sentence, no matter what—this means that the last character is a sentence boundary always—it does not need to be a period or other typical sentence-ending mark. Change it and try a sentence without a final period, and the result will be that no sentence is detected.</p><p class="calibre9">The next Boolean <code class="email">parenS</code> declaration gives priority to parentheses over sentence makers when finding sentences. Next, the actual sentence chunker will be set up:</p><div><pre class="programlisting">TokenizerFactory tokFactory = IndoEuropeanTokenizerFactory.INSTANCE;
Chunker sentenceChunker = new SentenceChunker(tokFactory,sentenceModel);</pre></div><p class="calibre9">The <code class="email">tokFactory</code> should be<a id="id432" class="calibre1"/> familiar to you from <a class="calibre1" title="Chapter 2. Finding and Working with Words" href="part0027_split_000.html#page">Chapter 2</a>, <em class="calibre10">Finding and Working with Words</em>. The <code class="email">sentenceChunker</code> then can be constructed. Following is the standard I/O code for command-line interaction:</p><div><pre class="programlisting">BufferedReader reader = new BufferedReader(new InputStreamReader(System.in));
while (true) {
  System.out.print("Enter text followed by new line\n&gt;");
  String text = reader.readLine();</pre></div><p class="calibre9">Once we have the text, then the sentence detector is applied:</p><div><pre class="programlisting">Chunking chunking = sentenceChunker.chunk(text);
Set&lt;Chunk&gt; sentences = chunking.chunkSet();</pre></div><p class="calibre9">The chunking provides a <code class="email">Set&lt;Chunk&gt;</code> parameter, which will noncontractually provide an appropriate ordering of <code class="email">Chunks</code>; they will be added as per the <code class="email">ChunkingImpl</code> Javadoc. The truly paranoid programmer might impose the proper sort order, which we will cover later in the chapter when we have to handle overlapping chunks.</p><p class="calibre9">Next, we will check to see if any sentences were found, and if we don't find them, we will report to the console:</p><div><pre class="programlisting">if (sentences.size() &lt; 1) {
  System.out.println("No sentence chunks found.");
  return;
}</pre></div><p class="calibre9">The following is the first exposure to the <code class="email">Chunker</code> interface in the book, and a few comments are in order. The <code class="email">Chunker</code> interface generates the <code class="email">Chunk</code> objects, which are typed and scored contiguous-character sequences over <code class="email">CharSequence</code>—usually, <code class="email">String</code>. <code class="email">Chunks</code> can overlap. The <code class="email">Chunk</code> objects are stored in <code class="email">Chunking</code>:</p><div><pre class="programlisting">String textStored = chunking.charSequence().toString();
for (Chunk sentence : sentences) {
  int start = sentence.start();
  int end = sentence.end();
  System.out.println("SENTENCE :" 
    + textStored.substring(start,end));
  }
}</pre></div><p class="calibre9">First, we recovered the underlying text string <code class="email">textStored</code> that the chunks are based on. It is the same string as <code class="email">text</code>, but we wanted to illustrate this potentially useful method of the <code class="email">Chunking</code> class, which can come up in recursive or other contexts when the chunking is far removed from where <code class="email">CharSequence</code> that it uses is unavailable.</p><p class="calibre9">The remaining <code class="email">for</code> loop<a id="id433" class="calibre1"/> iterates over the sentences and prints them out with the <code class="email">substring()</code> method of <code class="email">String</code>.</p></div></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_3"><a id="ch05lvl2sec129" class="calibre1"/>There's more...</h2></div></div></div><p class="calibre9">Before moving on to how to roll your own sentence detector, it is worth mentioning that LingPipe has<a id="id434" class="calibre1"/> <code class="email">MedlineSentenceModel</code>, which is oriented towards the kind of sentences found in the medical research literature. It has seen a lot of data and should be a starting place for your own sentence-detection efforts over these kinds of data.</p><div><div><div><div><h3 class="title2"><a id="ch05lvl3sec17" class="calibre1"/>Nested sentences</h3></div></div></div><p class="calibre9">Sentences, particularly in literature, can contain <a id="id435" class="calibre1"/>nested sentences. Consider the following:</p><div><pre class="programlisting">John said "this is a nested sentence" and then shut up.</pre></div><p class="calibre9">The preceding sentence will be marked up properly as:</p><div><pre class="programlisting">[John said "[this is a nested sentence]" and then shut up.]</pre></div><p class="calibre9">This sort of nesting is different from a linguist's concept of a nested sentence, which is based on grammatical role. Consider the following example:</p><div><pre class="programlisting">[[John ate the gorilla] and [Mary ate the burger]].</pre></div><p class="calibre9">This sentence consists of two linguistically complete sentences joined by <code class="email">and</code>. The difference between the two is that the former is determined by punctuation and the latter by a grammatical function. Whether this distinction is significant or not can be debated. However, the former case is much easier to recognize programmatically.</p><p class="calibre9">However, we have rarely needed to model nested sentences in industrial contexts, but we took it on in our MUC-6 system and various coreference resolution systems in research contexts. This is beyond the scope of a recipe book, but be aware of the issue. LingPipe has no out-of-the-box capabilities for nested sentence detection.</p></div></div></div>

<div><div><div><div><div><h1 class="title" id="calibre_pb_0"><a id="ch05lvl1sec57" class="calibre1"/>Evaluation of sentence detection</h1></div></div></div><p class="calibre9">Like most of the things we do, we<a id="id436" class="calibre1"/> want to be able to evaluate the performance of our components. Sentence detection is no different. Sentence detection is a span annotation that differs from our previous evaluations for classifiers and tokenization. As text can have characters that are not in any sentence, there is a notion of sentence start and sentence end. An example of characters that don't belong in a sentence will be JavaScript from an HTML page.</p><p class="calibre9">The following recipe will take you through the steps of creating evaluation data and running it past an evaluation class.</p></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_1"><a id="ch05lvl2sec130" class="calibre1"/>How to do it...</h2></div></div></div><p class="calibre9">Perform the following steps to evaluate sentence detection:</p><div><ol class="orderedlist"><li class="listitem" value="1">Open a text editor and copy and paste some literary gem that you want to evaluate sentence detection with, or you can go with our supplied default text, which is used if you don't provide your own data. It is easiest if you stick to plain text.</li><li class="listitem" value="2">Insert balanced <code class="email">[</code> and <code class="email">]</code> to indicate the beginnings and ends of sentences in the text. If the text already contains either <code class="email">[</code> or <code class="email">]</code>, pick another character that is not in the text as a sentence delimiter—curly brackets or slashes are a good choice. If you use different delimiters, you will have to modify the source appropriately and recreate the JAR file. The code assumes a single-character text delimiter. An example of a sentence-annotated text from <em class="calibre10">The Hitchhiker's Guide to the Galaxy</em> is as follows—note that not every character is in a sentence; some whitespaces are between sentences:<div><pre class="programlisting">[The Guide says that the best drink in existence is the Pan Galactic Gargle Blaster.] [It says that the effect of a Pan Galactic Gargle Blaster is like having your brains smashed out by a slice of lemon wrapped round a large gold brick.]</pre></div></li><li class="listitem" value="3">Get yourself a command line and run the following command:<div><pre class="programlisting">
<strong class="calibre2">java -cp lingpipe-cookbook.1.0.jar:lib/lingpipe-4.1.0.jar: com.lingpipe.cookbook.chapter5.EvaluateAnnotatedSentences</strong>
<strong class="calibre2">TruePos: 0-83/The Guide says that the best drink in existence is the Pan Galactic Gargle Blaster.:S</strong>
<strong class="calibre2">TruePos: 84-233/It says that the effect of a Pan Galactic Gargle Blaster is like having your brains smashed out by a slice of lemon wrapped round a large gold brick.:S</strong>
</pre></div></li><li class="listitem" value="4">For this data, the code will display two sentences that match perfectly with the sentences annotated with <code class="email">[]</code>, as indicated by the <code class="email">TruePos</code> label.</li><li class="listitem" value="5">A good exercise is to modify the annotation a bit to force errors. We will move the first sentence boundary one character in:<div><pre class="programlisting">
<strong class="calibre2">T[he Guide says that the best drink in existence is the Pan Galactic Gargle Blaster.] [It says that the effect of a Pan Galactic Gargle Blaster is like having your brains smashed out by a slice of lemon wrapped round a large gold brick.]</strong>
</pre></div></li><li class="listitem" value="6">Rerunning the modified annotation file after saving it yields:<div><pre class="programlisting">
<strong class="calibre2">TruePos: 84-233/It says that the effect of a Pan Galactic Gargle Blaster is like having your brains smashed out by a slice of lemon wrapped round a large gold brick.:S</strong>
<strong class="calibre2">FalsePos: 0-83/The Guide says that the best drink in existence is the Pan Galactic Gargle Blaster.:S</strong>
<strong class="calibre2">FalseNeg: 1-83/he Guide says that the best drink in existence is the Pan Galactic Gargle Blaster.:S</strong>
</pre></div><p class="calibre14">By changing the truth annotation, a false negative is produced, because the sentence span was missed by one character. In addition, a false positive is created by the sentence detector that recognizes the 0-83 character sequence.</p></li><li class="listitem" value="7">It is a good idea to play around with the annotation and various kinds of data to get a feel of how evaluation works and the capabilities of the sentence detector.</li></ol><div></div></div></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_2"><a id="ch05lvl2sec131" class="calibre1"/>How it works...</h2></div></div></div><p class="calibre9">The class starts by <a id="id437" class="calibre1"/>digesting the annotated text and storing the sentence chunks in an evaluation object. Then, the sentence detector is created, just as we did in the previous recipe. The code finishes by applying the created sentence detector to the text, and the results are printed.</p><div><div><div><div><h3 class="title2"><a id="ch05lvl3sec18" class="calibre1"/>Parsing annotated data</h3></div></div></div><p class="calibre9">Given text annotated with <code class="email">[]</code> for sentence <a id="id438" class="calibre1"/>boundaries means that the correct offsets of the sentences have to be recovered, and the original unannotated text must be created, that is, without any <code class="email">[]</code>. Span parsers can be a bit tricky to code, and the following is offered for simplicity rather than efficiency or proper coding technique:</p><div><pre class="programlisting">String path = args.length &gt; 0 ? args[0] 
             : "data/hitchHikersGuide.sentDetected";
char[] chars 
  = Files.readCharsFromFile(new File(path), Strings.UTF8);
StringBuilder rawChars = new StringBuilder();
int start = -1;
int end = 0;
Set&lt;Chunk&gt; sentChunks = new HashSet&lt;Chunk&gt;();</pre></div><p class="calibre9">The preceding code reads in the entire file as a single <code class="email">char[]</code> array with an appropriate character encoding. Also, note that for large files, a streaming approach will be more memory friendly. Next, an accumulator for unannotated chars is setup as a <code class="email">StringBuilder</code> object with the <code class="email">rawChars</code> variable. All characters encountered that are not either a <code class="email">[</code> or <code class="email">]</code> will be appended to the object. The remaining code sets up counters for sentence starts and ends that are indexed into the unannotated character array and an accumulator for <code class="email">Set&lt;Chunk&gt;</code> for annotated sentence segments.</p><p class="calibre9">The following <code class="email">for</code> loop advances one character at a time over the annotated character sequence:</p><div><pre class="programlisting">for (int i=0; i &lt; chars.length; ++i) {
  if (chars[i] == '[') {
    start = rawChars.length();
  }
  else if (chars[i] == ']') {
    end = rawChars.length();
    
    Chunk chunk = ChunkFactory.createChunk(start,end, SentenceChunker.SENTENCE_CHUNK_TYPE);
    sentChunks.add(chunk);}
  else {
    rawChars.append(chars[i]);
  }
}
String originalText = rawChars.toString();</pre></div><p class="calibre9">The first <code class="email">if (chars[i] == '[')</code> tests for starts of sentences in the annotation and sets the start variable<a id="id439" class="calibre1"/> to the length of <code class="email">rawChars</code>. The iteration variable <code class="email">i</code> includes the length added by the annotations. The corresponding <code class="email">else if (chars[i] == ']')</code> statement handles the end of sentence case. Note that there are no error checks for this parser—this is a very bad idea because annotation errors are very likely if entered with a text editor. However, this is motivated by keeping the code as simple as possible. Later in the recipe, we will provide an example with some minimal error checking. Once the end of a sentence is found, a chunk is created for the sentence with <code class="email">ChunkFactory.createChunk</code> with offsets and for the standard LingPipe sentence type <code class="email">SentenceChunker.SENTENCE_CHUNK_TYPE</code>, which is required for the upcoming evaluation classes to work properly.</p><p class="calibre9">The remaining <code class="email">else</code> statement applies for all the characters that are not sentence boundaries, and it simply adds the character to the <code class="email">rawChars</code> accumulator. The result of this accumulator can be seen outside the <code class="email">for</code> loop when <code class="email">String unannotatedText</code> is created. Now, we have sentence chunks indexed correctly into a text string. Next, we will create a proper <code class="email">Chunking</code> object:</p><div><pre class="programlisting">ChunkingImpl sentChunking = new ChunkingImpl(unannotatedText);
for (Chunk chunk : sentChunks) {
  sentChunking.add(chunk);
}</pre></div><p class="calibre9">The <code class="email">ChunkingImpl</code> implementing class (<code class="email">Chunking</code> is an interface) requires the underlying text on construction, which is why we didn't just populate it in the preceding loop. LingPipe generally tries to make object construction complete. If Chunkings can be created without the underlying <code class="email">CharSequence</code> method, then what will be returned when the <code class="email">charSequence()</code> method is called? An empty string is actively misleading. Alternatively, returning <code class="email">null</code> needs to be caught and dealt with. Better to just force the object to make sense of construction.</p><p class="calibre9">Moving on, we will see the standard configuration of the sentence chunker from the previous recipe:</p><div><pre class="programlisting">boolean eosIsSentBoundary = false;
boolean balanceParens = true;
SentenceModel sentenceModel = new IndoEuropeanSentenceModel(eosIsSentBoundary, balanceParens);
TokenizerFactory tokFactory = IndoEuropeanTokenizerFactory.INSTANCE;
SentenceChunker sentenceChunker = new SentenceChunker(tokFactory,sentenceModel);</pre></div><p class="calibre9">The interesting <a id="id440" class="calibre1"/>stuff follows with an evaluator that takes <code class="email">sentenceChunker</code> as being evaluated as a parameter:</p><div><pre class="programlisting">SentenceEvaluator evaluator = new SentenceEvaluator(sentenceChunker);</pre></div><p class="calibre9">Next up, the <code class="email">handle(sentChunking)</code> method will take the text we just parsed into <code class="email">Chunking</code> and run the sentence detector on <code class="email">CharSequence</code> supplied in <code class="email">sentChunking</code> and set up the evaluation:</p><div><pre class="programlisting">evaluator.handle(sentChunking);</pre></div><p class="calibre9">Then, we will just get the evaluation data and work our way through the differences between the truth sentence detection and what the system did:</p><div><pre class="programlisting">SentenceEvaluation eval = evaluator.evaluation();
ChunkingEvaluation chunkEval = eval.chunkingEvaluation();
for (ChunkAndCharSeq truePos : chunkEval.truePositiveSet()) {
  System.out.println("TruePos: " + truePos);
}
for (ChunkAndCharSeq falsePos : chunkEval.falsePositiveSet()) {
  System.out.println("FalsePos: " + falsePos);
}
for (ChunkAndCharSeq falseNeg : chunkEval.falseNegativeSet()){
  System.out.println("FalseNeg: " + falseNeg);
}</pre></div><p class="calibre9">This recipe does not cover all the evaluation methods—check out the Javadoc—but it does provide what a sentence detection tuner will likely be most in need of; this is a listing of what the sentence detector got right (true positives), sentences it found but were wrong (false positives), and sentences it missed (false negatives). Note that true negatives don't make much sense <a id="id441" class="calibre1"/>in span annotations, because they will be the set of all the possible spans that are not in the truth sentence detection.</p></div></div></div>

<div><div><div><div><div><h1 class="title" id="calibre_pb_0"><a id="ch05lvl1sec58" class="calibre1"/>Tuning sentence detection</h1></div></div></div><p class="calibre9">Lots of data will resist the<a id="id442" class="calibre1"/> charms of <code class="email">IndoEuropeanSentenceModel</code>, so this recipe will provide a starting place to modify sentence detection to meet new kinds of sentences. Unfortunately, this is a very open-ended area of system building, so we will focus on techniques rather than likely formats for sentences.</p></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_1"><a id="ch05lvl2sec132" class="calibre1"/>How to do it...</h2></div></div></div><p class="calibre9">This recipe will follow a well-worn pattern: create evaluation data, set up evaluation, and start hacking. Here we go:</p><div><ol class="orderedlist"><li class="listitem" value="1">Haul out your favorite text editor and mark up some data—we will stick to the <code class="email">[</code> and <code class="email">]</code> markup approach. The following is an example that runs afoul of our standard <code class="email">IndoEuropeanSentenceModel</code>:<div><pre class="programlisting">
<strong class="calibre2">[All decent people live beyond their incomes nowadays, and those who aren't respectable live beyond other people's.]  [A few gifted individuals manage to do both.]</strong>
</pre></div></li><li class="listitem" value="2">We will put the preceding sentence in <code class="email">data/saki.sentDetected.txt</code> and run it:<div><pre class="programlisting">
<strong class="calibre2">java -cp lingpipe-cookbook.1.0.jar:lib/lingpipe-4.1.0.jar: com.lingpipe.cookbook.chapter5.EvaluateAnnotatedSentences data/saki.sentDetected </strong>
<strong class="calibre2">FalsePos: 0-159/All decent people live beyond their incomes nowadays, and those who aren't respectable live beyond other people's.  A few gifted individuals manage to do both.:S</strong>
<strong class="calibre2">FalseNeg: 0-114/All decent people live beyond their incomes nowadays, and those who aren't respectable live beyond other people's.:S</strong>
<strong class="calibre2">FalseNeg: 116-159/A few gifted individuals manage to do both.:S</strong>
</pre></div></li></ol><div></div></div></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_2"><a id="ch05lvl2sec133" class="calibre1"/>There's more...</h2></div></div></div><p class="calibre9">The single false positive corresponds to the one sentence found, and the two false negatives are the two sentences not found that we annotated here. What happened? The sentence model missed <code class="email">people's.</code> as a sentence end. If the apostrophe is removed, the sentence is detected properly—what is going on?</p><p class="calibre9">First, let's look at the code running in the background. <code class="email">IndoEuropeanSentenceModel</code> extends <code class="email">HeuristicSentenceModel</code> by configuring several categories of tokens from the Javadoc for <code class="email">HeuristicSentenceModel</code>:</p><div><ul class="itemizedlist"><li class="listitem"><strong class="calibre2">Possible stops</strong>: These are<a id="id443" class="calibre1"/> tokens that are allowed to be the final ones in a sentence. This set typically includes sentence-final punctuation tokens, such as periods (.) and double quotes (").</li><li class="listitem"><strong class="calibre2">Impossible penultimates</strong>: These <a id="id444" class="calibre1"/>are tokens that might not be the penultimate (second-to-last) token in a sentence. This set is typically made up of abbreviations or acronyms, such as <code class="email">Mr</code>.</li><li class="listitem"><strong class="calibre2">Impossible starts</strong>: These are<a id="id445" class="calibre1"/> tokens that might not be the first ones in a sentence. This set typically includes punctuation characters that should be attached to the previous sentence, such as end quotes ('').</li></ul></div><p class="calibre9">
<code class="email">IndoEuropeanSentenceModel</code> is not configurable, but from the Javadoc, it is clear that all single characters are considered impossible penultimates. The words <code class="email">people's</code> is tokenized into <code class="email">people</code>, <code class="email">'</code>, <code class="email">s</code>, and <code class="email">.</code>. The single character <code class="email">s</code> is penultimate to the <code class="email">.</code> and is thus blocked. How to fix this?</p><p class="calibre9">A few options present themselves:</p><div><ul class="itemizedlist"><li class="listitem">Ignore the mistake assuming that it won't happen frequently</li><li class="listitem">Fix by creating a custom sentence model</li><li class="listitem">Fix by modifying the tokenizer to not separate apostrophes</li><li class="listitem">Write a complete sentence-detection model for the interface</li></ul></div><p class="calibre9">The second option, create a custom sentence model, is handled most easily by copying the source from <code class="email">IndoEuropeanSentenceModel</code> into a new class and modifying it, as the relevant data structures are private. This is done to simplify the serialization of the class—very little configuration needs to be written to disk. In the example classes, there is a <code class="email">MySentenceModel.java</code> file that differs by obvious changes in the package name and imports:</p><div><pre class="programlisting">IMPOSSIBLE_PENULTIMATES.add("R");
//IMPOSSIBLE_PENULTIMATES.add("S"); breaks on "people's."
//IMPOSSIBLE_PENULTIMATES.add("T"); breaks on "didn't."
IMPOSSIBLE_PENULTIMATES.add("U");</pre></div><p class="calibre9">The preceding code just comments out two of the likely single-letter cases of penultimate tokens that are a single-word character. To see it at work, change the sentence model to <code class="email">SentenceModel sentenceModel = new MySentenceModel();</code> in the <code class="email">EvaluateAnnotatedSentences.java</code> class and recompile and run it.</p><p class="calibre9">If you see the preceding code as a reasonable balancing of finding sentences that end in likely contractions versus non-sentence cases such as <code class="email">[Hunter S. Thompson is a famous fellow.]</code>, which will detect <code class="email">S.</code> as a sentence boundary.</p><p class="calibre9">Extending <code class="email">HeuristicSentenceModel</code> can work well for many sorts of data. Mitzi Morris built <code class="email">MedlineSentenceModel.java</code>, which is designed to work well with the abstracts provided in the MEDLINE research index.</p><p class="calibre9">One way to look at the preceding problem is that contractions should not be broken up into tokens for the purpose of sentence detection. <code class="email">IndoEuropeanTokenizerFactory</code> should be tuned up to keep "people's" and other contractions together. While it initially seems slightly better that the first solution, it might well run afoul of the fact that <code class="email">IndoEuropeanSentenceModel</code> was tuned with a particular tokenization in mind, and the consequences of the change are unknown in the absence of an evaluation corpus.</p><p class="calibre9">The other option <a id="id446" class="calibre1"/>is to write a completely novel sentence-detection class that supports the <code class="email">SentenceModel</code> interface. Faced with a highly novel data collection such as Twitter feeds, we will consider using a machine-learning-driven span-annotation technique such as HMMs or CRFs covered in <a class="calibre1" title="Chapter 4. Tagging Words and Tokens" href="part0051_split_000.html#page">Chapter 4</a>, <em class="calibre10">Tagging Words and Tokens</em>, and at the end of this chapter.</p></div></div>

<div><div><div><div><div><h1 class="title" id="calibre_pb_0"><a id="ch05lvl1sec59" class="calibre1"/>Marking embedded chunks in a string – sentence chunk example</h1></div></div></div><p class="calibre9">The method of displaying <a id="id447" class="calibre1"/>chunkings in the previous recipes is not well suited <a id="id448" class="calibre1"/>for applications that need to modify the <a id="id449" class="calibre1"/>underlying string. For example, a sentiment analyzer might want to highlight only sentences that are strongly positive and not mark up the remaining sentences while still displaying the entire text. The slight complication in producing the marked-up text is that adding markups changes the underlying string. This recipe provides working code to insert the chunking by adding chunks in reverse.</p></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_1"><a id="ch05lvl2sec134" class="calibre1"/>How to do it...</h2></div></div></div><p class="calibre9">While this recipe may not be technically complex it is useful to get span annotations into a text without out having to invent the code from whole cloth. The <code class="email">src/com/lingpipe/coobook/chapter5/WriteSentDetectedChunks</code> class has the referenced code:</p><div><ol class="orderedlist"><li class="listitem" value="1">The sentence chunking is created as per the first sentence-detection recipe. The following code extracts the chunks as <code class="email">Set&lt;Chunk&gt;</code> and then sorts them by <code class="email">Chunk.LONGEST_MATCH_ORDER_COMPARITOR</code>. In the Javadoc, the comparator is defined as:<div><blockquote class="blockquote1"><p class="calibre19"><em class="calibre10">Compares two chunks based on their text position. A chunk is greater if it starts later than another chunk, or if it starts at the same position and ends earlier.</em></p></blockquote></div><p class="calibre14">There is<a id="id450" class="calibre1"/> also <code class="email">TEXT_ORDER_COMPARITOR</code>, which is as follows:</p><div><pre class="programlisting">String textStored = chunking.charSequence().toString();
Set&lt;Chunk&gt; chunkSet = chunking.chunkSet();
System.out.println("size: " + chunkSet.size());
Chunk[] chunkArray = chunkSet.toArray(new Chunk[0]);
Arrays.sort(chunkArray,Chunk.LONGEST_MATCH_ORDER_COMPARATOR);</pre></div></li><li class="listitem" value="2">Next, we will<a id="id451" class="calibre1"/> iterate over the chunks in the <a id="id452" class="calibre1"/>reverse order, which eliminates having to keep an offset variable for the changing length of the <code class="email">StringBuilder</code> object. Offset variables are a common source of bugs, so this recipe avoids them as much as possible but does non-standard reverse loop iteration, which might be worse:<div><pre class="programlisting">StringBuilder output = new StringBuilder(textStored);
int sentBoundOffset = 0;
for (int i = chunkArray.length -1; i &gt;= 0; --i) {
  Chunk chunk = chunkArray[i];
  String sentence = textStored.substring(chunk.start(), chunk.end());
  if (sentence.contains("like")) {
    output.insert(chunk.end(),"}");
    output.insert(chunk.start(),"{");
  }
}
System.out.println(output.toString());</pre></div></li><li class="listitem" value="3">The preceding code does a very simple sentiment analysis by looking for the string <code class="email">like</code> in the sentence and marking that sentence if <code class="email">true</code>. Note that this code cannot handle overlapping chunks or nested chunks. It assumes a single, non-overlapping chunk set. Some example output is:<div><pre class="programlisting">
<strong class="calibre2">java -cp lingpipe-cookbook.1.0.jar:lib/lingpipe-4.1.0.jar: com.lingpipe.cookbook.chapter5.WriteSentDetectedChunks</strong>
<strong class="calibre2">Enter text followed by new line</strong>
<strong class="calibre2">&gt;People like to ski. But sometimes it is terrifying. </strong>
<strong class="calibre2">size: 2</strong>
<strong class="calibre2">{People like to ski.} But sometimes it is terrifying. </strong>
</pre></div></li><li class="listitem" value="4">To print<a id="id453" class="calibre1"/> nested chunks, look at the <em class="calibre10">Paragraph</em><a id="id454" class="calibre1"/><em class="calibre10"> detection</em> recipe <a id="id455" class="calibre1"/>that follows.</li></ol><div></div></div></div>

<div><div><div><div><div><h1 class="title" id="calibre_pb_0"><a id="ch05lvl1sec60" class="calibre1"/>Paragraph detection</h1></div></div></div><p class="calibre9">The typical containing <a id="id456" class="calibre1"/>structure of a set of sentences is a paragraph. It can be set off explicitly in a markup language such as <code class="email">&lt;p&gt;</code> in HTML or with two or more new lines, which is how paragraphs are usually rendered. We are in the part of NLP where no hard-and-fast rules apply, so we apologize for the hedging. We will handle some common examples in this chapter and leave it to you to generalize.</p></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_1"><a id="ch05lvl2sec135" class="calibre1"/>How to do it...</h2></div></div></div><p class="calibre9">We have never set up an evaluation harness for paragraph detection, but it can be done in ways similar to sentence detection. This recipe, instead, will illustrate a simple paragraph-detection routine that does something very important—maintain offsets into the original document with embedded sentence detection. This attention to detail will serve you well if you ever need to mark up the document in a way that is sensitive to sentences or other subspans of the document, such as named entities. Consider the following example:</p><div><pre class="programlisting">Sentence 1. Sentence 2
Sentence 3. Sentence 4.</pre></div><p class="calibre9">It gets transformed into the following:</p><div><pre class="programlisting">{[Sentence 1.] [Sentence 2]}

{[Sentence 3.] [Sentence 4.]
}</pre></div><pre>[]</code>designates sentences, and <code class="email">{}</code> designates paragraphs. We will jump right into the code on this recipe from <code class="email">src/com/lingpipe/cookbook/chapter5/ParagraphSentenceDetection.java</code>:</pre><div><ol class="orderedlist"><li class="listitem" value="1">The example code has little to offer in paragraph-detection techniques. It is an open-ended problem, and you will have to use your wiles to solve it. Our paragraph detector is a pathetic <code class="email">split("\n\n")</code> that, in a more sophisticated approach, will take into account context, characters, and other features that are far too idiosyncratic for us to cover. Here is the beginning of the code that reads the entire document as a string and splits it into an array. Note that <code class="email">paraSeperatorLength</code> is the number of characters that form the basis of the paragraph split—if the length of the split varies, then that length will have to be associated with the corresponding paragraph:<div><pre class="programlisting">public static void main(String[] args) throws IOException {
  String document = Files.readFromFile(new File(args[0]), Strings.UTF8);
  String[] paragraphs = document.split("\n\n");
  int paraSeparatorLength = 2;</pre></div></li><li class="listitem" value="2">The real point of the recipe is to help with the mechanics of maintaining character offsets into the original document and show embedded processing. This will be done by keeping two separate chunkings: one for paragraphs and one for sentences:<div><pre class="programlisting">ChunkingImpl paraChunking = new ChunkingImpl(document.toCharArray(),0,document.length());
ChunkingImpl sentChunking = new ChunkingImpl(paraChunking.charSequence());</pre></div></li><li class="listitem" value="3">Next, the sentence detector will be set up in the same way as one in the previous recipe:<div><pre class="programlisting">boolean eosIsSentBoundary = true;
boolean balanceParens = false;
SentenceModel sentenceModel = new IndoEuropeanSentenceModel(eosIsSentBoundary, balanceParens);
SentenceChunker sentenceChunker = new SentenceChunker(IndoEuropeanTokenizerFactory.INSTANCE, sentenceModel);</pre></div></li><li class="listitem" value="4">The chunking<a id="id457" class="calibre1"/> iterates over the array of paragraphs and builds a sentence chunking for each paragraph. The somewhat-complicated part of this approach is that the sentence chunk offsets are with respect to the paragraph string, not the entire document. So, the variables' starts and ends are updated with document offsets in the code. Chunks have no methods to adjust starts and ends, so a new chunk must be created, <code class="email">adjustedSentChunk</code>, with appropriate offsets into the paragraph start and must be added to <code class="email">sentChunking</code>:<div><pre class="programlisting">int paraStart = 0;
for (String paragraph : paragraphs) {
  for (Chunk sentChunk : sentenceChunker.chunk(paragraph).chunkSet()) {
    Chunk adjustedSentChunk = ChunkFactory.createChunk(sentChunk.start() + paraStart,sentChunk.end() + paraStart, "S");
    sentChunking.add(adjustedSentChunk);
  }</pre></div></li><li class="listitem" value="5">The rest of the loop adds the paragraph chunk and then updates the start of the paragraph with the length of the paragraph plus the length of the paragraph separator. This will complete the creation of correctly offset sentences and paragraphs into the original document string:<div><pre class="programlisting">paraChunking.add(ChunkFactory.createChunk(paraStart, paraStart + paragraph.length(),"P"));
paraStart += paragraph.length() + paraSeparatorLength;
}</pre></div></li><li class="listitem" value="6">The rest of the program is concerned with printing out the paragraphs and sentences with some markup. First, we will create a chunking that has both sentence and paragraph chunks:<div><pre class="programlisting">String underlyingString = paraChunking.charSequence().toString();
ChunkingImpl displayChunking = new ChunkingImpl(paraChunking.charSequence());
displayChunking.addAll(sentChunking.chunkSet());
displayChunking.addAll(paraChunking.chunkSet());</pre></div></li><li class="listitem" value="7">Next, <code class="email">displayChunking</code> will be sorted by recovering <code class="email">chunkSet</code>, converting it into an array of chunks and the application of the static comparator:<div><pre class="programlisting">Set&lt;Chunk&gt; chunkSet = displayChunking.chunkSet();
Chunk[] chunkArray = chunkSet.toArray(new Chunk[0]);
Arrays.sort(chunkArray, Chunk.LONGEST_MATCH_ORDER_COMPARATOR);</pre></div></li><li class="listitem" value="8">We will use the <a id="id458" class="calibre1"/>same trick as we did in the <em class="calibre10">Marking embedded chunks in a string – sentence chunk example</em> recipe, which is to insert the markup backwards into the string. We will have to keep an offset counter, because nested sentences will extend the finishing paragraph mark placement. The approach assumes that no chunks overlap and that sentences are contained within paragraphs always:<div><pre class="programlisting">StringBuilder output = new StringBuilder(underlyingString);
int sentBoundOffset = 0;
for (int i = chunkArray.length -1; i &gt;= 0; --i) {
  Chunk chunk = chunkArray[i];
  if (chunk.type().equals("P")) {
    output.insert(chunk.end() + sentBoundOffset,"}");
    output.insert(chunk.start(),"{");
    sentBoundOffset = 0;
  }
  if (chunk.type().equals("S")) {
    output.insert(chunk.end(),"]");
    output.insert(chunk.start(),"[");
    sentBoundOffset += 2;
  }
}
System.out.println(output.toString());</pre></div></li><li class="listitem" value="9">That's it for<a id="id459" class="calibre1"/> the recipe.</li></ol><div></div></div></div>

<div><div><div><div><div><h1 class="title" id="calibre_pb_0"><a id="ch05lvl1sec61" class="calibre1"/>Simple noun phrases and verb phrases</h1></div></div></div><p class="calibre9">This recipe will show you how to find simple <strong class="calibre2">noun phrases</strong> (<strong class="calibre2">NP</strong>)<a id="id460" class="calibre1"/> and <a id="id461" class="calibre1"/>
<strong class="calibre2">verb phrases</strong> (<strong class="calibre2">VP</strong>). By "simple", we mean that there is no complex structure within the phrases. For example, the complex NP "The rain in Spain" will be broken into two simple NP chunks "The rain" and "Spain". These phrases are also called "basal".</p><p class="calibre9">This recipe will not go into the details of how the basal NPs/VPs are calculated but rather how to use the class—it can come in handy, and the source can be included if you want to sort out how it works.</p></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_1"><a id="ch05lvl2sec136" class="calibre1"/>How to do it…</h2></div></div></div><p class="calibre9">Like many of the recipes, we will provide a command-line-interactive interface here:</p><div><ol class="orderedlist"><li class="listitem" value="1">Haul up the command line and type:<div><pre class="programlisting">
<strong class="calibre2">java -cp lingpipe-cookbook.1.0.jar:lib/lingpipe-4.1.0.jar: com.lingpipe.cookbook.chapter5.PhraseChunker</strong>
<strong class="calibre2">INPUT&gt; The rain in Spain falls mainly on the plain.</strong>
<strong class="calibre2">The/at rain/nn in/in Spain/np falls/vbz mainly/rb on/in the/at plain/jj ./. </strong>
<strong class="calibre2">  noun(0,8) The rain</strong>
<strong class="calibre2">  noun(12,17) Spain</strong>
<strong class="calibre2">  verb(18,30) falls mainly</strong>
<strong class="calibre2">  noun(34,43) the plain</strong>
</pre></div></li></ol><div></div></div></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_2"><a id="ch05lvl2sec137" class="calibre1"/>How it works…</h2></div></div></div><p class="calibre9">The <code class="email">main()</code> method starts by <a id="id462" class="calibre1"/>deserializing a part-of-speech tagger and then <a id="id463" class="calibre1"/>creating <code class="email">tokenizerFactory</code>:</p><div><pre class="programlisting">public static void main(String[] args) throws IOException, ClassNotFoundException {
  File hmmFile = new File("models/pos-en-general-brown.HiddenMarkovModel");
  HiddenMarkovModel posHmm = (HiddenMarkovModel) AbstractExternalizable.readObject(hmmFile);
  HmmDecoder posTagger  = new HmmDecoder(posHmm);
  TokenizerFactory tokenizerFactory = IndoEuropeanTokenizerFactory.INSTANCE;</pre></div><p class="calibre9">Next, <code class="email">PhraseChunker</code> is constructed, which is a heuristic approach to the problem. Look at the source to see how it works—it scans the input left to right for NP/VP starts and attempts to add to the phrase incrementally:</p><div><pre class="programlisting">PhraseChunker chunker = new PhraseChunker(posTagger,tokenizerFactory);</pre></div><p class="calibre9">Our standard console I/O code is next:</p><div><pre class="programlisting">BufferedReader bufReader = new BufferedReader(new InputStreamReader(System.in));
while (true) {
  System.out.print("\n\nINPUT&gt; ");
  String input = bufReader.readLine();</pre></div><p class="calibre9">Then, the input is<a id="id464" class="calibre1"/> tokenized, POS is tagged, and the tokens and tags are <a id="id465" class="calibre1"/>printed out:</p><div><pre class="programlisting">Tokenizer tokenizer = tokenizerFactory.tokenizer(input.toCharArray(),0,input.length());
String[] tokens = tokenizer.tokenize();
List&lt;String&gt; tokenList = Arrays.asList(tokens);
Tagging&lt;String&gt; tagging = posTagger.tag(tokenList);
for (int j = 0; j &lt; tokenList.size(); ++j) {
  System.out.print(tokens[j] + "/" + tagging.tag(j) + " ");
}
System.out.println();</pre></div><p class="calibre9">The NP/VP chunkings are then calculated and printed out:</p><div><pre class="programlisting">Chunking chunking = chunker.chunk(input);
CharSequence cs = chunking.charSequence();
for (Chunk chunk : chunking.chunkSet()) {
  String type = chunk.type();
  int start = chunk.start();
  int end = chunk.end();
  CharSequence text = cs.subSequence(start,end);
  System.out.println("  " + type + "(" + start + ","+ end + ") " + text);
  }</pre></div><p class="calibre9">There is a more comprehensive tutorial at <a class="calibre1" href="http://alias-i.com/lingpipe/demos/tutorial/posTags/read-me.html">http://alias-i.com/lingpipe/demos/tutorial/posTags/read-me.html</a>.</p></div></div>

<div><div><div><div><div><h1 class="title" id="calibre_pb_0"><a id="ch05lvl1sec62" class="calibre1"/>Regular expression-based chunking for NER</h1></div></div></div><p class="calibre9">
<strong class="calibre2">Named Entity Recognition</strong> (<strong class="calibre2">NER</strong>) is<a id="id466" class="calibre1"/> the process of finding mentions of specific things in text. Consider a simple name; location-named entity recognizer might find <code class="email">Ford Prefect</code> and <code class="email">Guildford</code> as the name and location mentions, respectively, in the following text:</p><div><pre class="programlisting">Ford Prefect used to live in Guildford before he needed to move.</pre></div><p class="calibre9">We will start by building rule-based NER systems and move up to machine-learning methods. Here, we'll take a look at building an NER system that can extract e-mail addresses from text.</p></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_1"><a id="ch05lvl2sec138" class="calibre1"/>How to do it…</h2></div></div></div><div><ol class="orderedlist"><li class="listitem" value="1">Enter the following <a id="id467" class="calibre1"/>command into the <a id="id468" class="calibre1"/>command prompt:<div><pre class="programlisting">
<strong class="calibre2">java –cp lingpipe-cookbook.1.0.jar:lib/lingpipe-4.1.0.jar com.lingpipe.cookbook.chapter5.RegexNer</strong>
</pre></div></li><li class="listitem" value="2">Interaction with the program proceeds as follows:<div><pre class="programlisting">
<strong class="calibre2">Enter text, . to quit:</strong>
<strong class="calibre2">&gt;Hello,my name is Foo and my email is foo@bar.com or you can also contact me at foo.bar@gmail.com.</strong>
<strong class="calibre2">input=Hello,my name is Foo and my email is foo@bar.com or you can also contact me at foo.bar@gmail.com.</strong>
<strong class="calibre2">chunking=Hello,my name is Foo and my email is foo@bar.com or you can also contact me at foo.bar@gmail.com. : [37-48:email@0.0, 79-96:email@0.0]</strong>
<strong class="calibre2">     chunk=37-48:email@0.0  text=foo@bar.com</strong>
<strong class="calibre2">     chunk=79-96:email@0.0  text=foo.bar@gmail.com</strong>
</pre></div></li><li class="listitem" value="3">You can see that both <code class="email">foo@bar.com</code> as well as <code class="email">foo.bar@gmail.com</code> were returned as valid <code class="email">e-mail</code> type chunks. Also, note that the final period in the sentence is not part of the second e-mail.</li></ol><div></div></div></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_2"><a id="ch05lvl2sec139" class="calibre1"/>How it works…</h2></div></div></div><p class="calibre9">A regular expression chunker finds chunks that match the given regular expression. Essentially, the <code class="email">java.util.regex.Matcher.find()</code> method is used to iteratively find matching text segments, and these are then converted into the Chunk objects. The <code class="email">RegExChunker</code> class wraps these steps. The code of <code class="email">src/com/lingpipe/cookbook/chapter5/RegExNer.java</code> is described as follows:</p><div><pre class="programlisting">public static void main(String[] args) throws IOException {
  String emailRegex = "[A-Za-z0-9](([_\\.\\-]?[a-zA-Z0-9]+)*)" + + "@([A-Za-z0-9]+)" + "(([\\.\\-]?[a-zA-Z0-9]+)*)\\.([A-Za-z]{2,})";
  String chunkType = "email";
  double score = 1.0;
  Chunker chunker = new RegExChunker(emailRegex,chunkType,score);</pre></div><p class="calibre9">All the interesting work was done in the preceding lines of code. The <code class="email">emailRegex</code> is pulled off of the Internet—see the following for the source, and the remaining bits are setting up <code class="email">chunkType</code> and <code class="email">score</code>.</p><p class="calibre9">The rest of the code reads<a id="id469" class="calibre1"/> in the<a id="id470" class="calibre1"/> input and prints out the chunking:</p><div><pre class="programlisting">BufferedReader reader = new BufferedReader(new InputStreamReader(System.in));
  String input = "";
  while (true) {
    System.out.println("Enter text, . to quit:");
    input = reader.readLine();
    if(input.equals(".")){
      break;
    }
    Chunking chunking = chunker.chunk(input);
    System.out.println("input=" + input);
    System.out.println("chunking=" + chunking);
    Set&lt;Chunk&gt; chunkSet = chunking.chunkSet();
    Iterator&lt;Chunk&gt; it = chunkSet.iterator();
    while (it.hasNext()) {
      Chunk chunk = it.next();
      int start = chunk.start();
      int end = chunk.end();
      String text = input.substring(start,end);
      System.out.println("     chunk=" + chunk + " text=" + text);
    }
  }
}</pre></div></div></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_3"><a id="ch05lvl2sec140" class="calibre1"/>See also</h2></div></div></div><div><ul class="itemizedlist"><li class="listitem">The regular expression for the e-mail address match<a id="id471" class="calibre1"/> is from <a class="calibre1" href="http://regexlib.com">regexlib.com</a> at <a class="calibre1" href="http://regexlib.com/DisplayPatterns.aspx?cattabindex=0&amp;categoryId=1">http://regexlib.com/DisplayPatterns.aspx?cattabindex=0&amp;categoryId=1</a></li></ul></div></div></div>

<div><div><div><div><div><h1 class="title" id="calibre_pb_0"><a id="ch05lvl1sec63" class="calibre1"/>Dictionary-based chunking for NER</h1></div></div></div><p class="calibre9">In many websites and <a id="id472" class="calibre1"/>blogs and certainly on web forums, you might see <a id="id473" class="calibre1"/>keyword highlighting that links pages you can buy a product from. Similarly, news websites also provide topic pages<a id="id474" class="calibre1"/> for people, places, and trending events, such as the one at <a class="calibre1" href="http://www.nytimes.com/pages/topics/">http://www.nytimes.com/pages/topics/</a>.</p><p class="calibre9">A lot of this is fully automated and is easy to do with a dictionary-based <code class="email">Chunker</code>. It is straightforward to compile lists of names for entities and their types. An exact dictionary chunker extracts chunks based on exact matches of tokenized dictionary entries.</p><p class="calibre9">The implementation of the dictionary-based chunker in LingPipe is based on the Aho-Corasick algorithm which finds all matches against a dictionary in linear time independent of the number of matches or size of the dictionary. This makes it much more efficient than the naïve approach of doing substring searches or using regular expressions.</p></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_1"><a id="ch05lvl2sec141" class="calibre1"/>How to do it…</h2></div></div></div><div><ol class="orderedlist"><li class="listitem" value="1">In the IDE of your choice run the <code class="email">DictionaryChunker</code> class in the <code class="email">chapter5</code> package or type the following using the command line:<div><pre class="programlisting">
<strong class="calibre2">java –cp lingpipe-cookbook.1.0.jar:lib/lingpipe-4.1.0.jar com.lingpipe.cookbook.chapter5.DictionaryChunker</strong>
</pre></div></li><li class="listitem" value="2">Since this particular chunker example is biased (very heavily) towards the Hitchhikers Guide, let's use a sentence that involves some of the characters:<div><pre class="programlisting">
<strong class="calibre2">Enter text, . to quit:</strong>
<strong class="calibre2">Ford and Arthur went up the bridge of the Heart of Gold with Marvin</strong>
<strong class="calibre2">CHUNKER overlapping, case sensitive</strong>
<strong class="calibre2">    phrase=|Ford| start=0 end=4 type=PERSON score=1.0</strong>
<strong class="calibre2">    phrase=|Arthur| start=9 end=15 type=PERSON score=1.0</strong>
<strong class="calibre2">    phrase=|Heart| start=42 end=47 type=ORGAN score=1.0</strong>
<strong class="calibre2">   phrase=|Heart of Gold| start=42 end=55 type=SPACECRAFT score=1.0</strong>
<strong class="calibre2">    phrase=|Marvin| start=61 end=67 type=ROBOT score=1.0</strong>
</pre></div></li><li class="listitem" value="3">Note that we have overlapping chunks from <code class="email">Heart</code> and <code class="email">Heart of Gold</code>. As we will see, this can be configured to behave differently.</li></ol><div></div></div></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_2"><a id="ch05lvl2sec142" class="calibre1"/>How it works…</h2></div></div></div><p class="calibre9">Dictionary-based NER drives a great deal of automatic linking against unstructured text data. We can build one using the following steps.</p><p class="calibre9">The first step of the code will create <code class="email">MapDictionary&lt;String&gt;</code> to store the dictionary entries:</p><div><pre class="programlisting">static final double CHUNK_SCORE = 1.0;

public static void main(String[] args) throws IOException {
  MapDictionary&lt;String&gt; dictionary = new MapDictionary&lt;String&gt;();
  MapDictionary&lt;String&gt; dictionary = new MapDictionary&lt;String&gt;();</pre></div><p class="calibre9">Next, we will populate the dictionary with <code class="email">DictionaryEntry&lt;String&gt;</code>, which includes type information and a score that will be used to create chunks:</p><div><pre class="programlisting">dictionary.addEntry(new DictionaryEntry&lt;String&gt;("Arthur","PERSON",CHUNK_SCORE));
dictionary.addEntry(new DictionaryEntry&lt;String&gt;("Ford","PERSON",CHUNK_SCORE));
dictionary.addEntry(new DictionaryEntry&lt;String&gt;("Trillian","PERSON",CHUNK_SCORE));
dictionary.addEntry(new DictionaryEntry&lt;String&gt;("Zaphod","PERSON",CHUNK_SCORE));
dictionary.addEntry(new DictionaryEntry&lt;String&gt;("Marvin","ROBOT",CHUNK_SCORE));
dictionary.addEntry(new DictionaryEntry&lt;String&gt;("Heart of Gold", "SPACECRAFT",CHUNK_SCORE));
dictionary.addEntry(new DictionaryEntry&lt;String&gt;("HitchhikersGuide", "PRODUCT",CHUNK_SCORE));</pre></div><p class="calibre9">In the <code class="email">DictionaryEntry</code> constructor, the<a id="id475" class="calibre1"/> first argument is the phrase, the <a id="id476" class="calibre1"/>second string argument is the type, and the final double argument is the score for the chunk. Dictionary entries are always case sensitive. There is no limit to the number of different entity types in a dictionary. The scores will simply be passed along as chunk scores in the dictionary-based chunker.</p><p class="calibre9">Next, we will build <code class="email">Chunker</code>:</p><div><pre class="programlisting">boolean returnAllMatches = true;
boolean caseSensitive = true;
ExactDictionaryChunker dictionaryChunker = new ExactDictionaryChunker(dictionary, IndoEuropeanTokenizerFactory.INSTANCE, returnAllMatches,caseSensitive);</pre></div><p class="calibre9">An exact dictionary chunker might be configured either to extract all the matching chunks to restrict the results to a consistent set of non-overlapping chunks via the <code class="email">returnAllMatches</code> boolean. Look at the Javadoc to understand the exact criteria. There is also a <code class="email">caseSensitive</code> boolean. The chunker requires a tokenizer, as it matches tokens as symbols, and whitespaces are ignored in the matching process.</p><p class="calibre9">Next is our standard I/O code for console interaction:</p><div><pre class="programlisting">BufferedReader reader = new BufferedReader(new InputStreamReader(System.in));
String text = "";
while (true) {
  System.out.println("Enter text, . to quit:");
  text = reader.readLine();
  if(text.equals(".")){
    break;
  }</pre></div><p class="calibre9">The remaining code creates a chunking, goes through the chunks, and prints them out:</p><div><pre class="programlisting">System.out.println("\nCHUNKER overlapping, case sensitive");
Chunking chunking = dictionaryChunker.chunk(text);
  for (Chunk chunk : chunking.chunkSet()) {
    int start = chunk.start();
    int end = chunk.end();
    String type = chunk.type();
    double score = chunk.score();
    String phrase = text.substring(start,end);
    System.out.println("     phrase=|" + phrase + "|" + " start=" + start + " end=" + end + " type=" + type + " score=" + score);</pre></div><p class="calibre9">Dictionary chunkers <a id="id477" class="calibre1"/>are very useful even in machine-learning-based<a id="id478" class="calibre1"/> systems. There tends to always be a class of entities that are best identified this way. The <em class="calibre10">Mixing the NER sources</em> recipe addresses how to work with multiple sources of named entities.</p></div></div>

<div><div><div><div><div><h1 class="title" id="calibre_pb_0"><a id="ch05lvl1sec64" class="calibre1"/>Translating between word tagging and chunks – BIO codec</h1></div></div></div><p class="calibre9">In <a class="calibre1" title="Chapter 4. Tagging Words and Tokens" href="part0051_split_000.html#page">Chapter 4</a>, <em class="calibre10">Tagging Words and Tokens</em>, we used <a id="id479" class="calibre1"/>HMMs and CRFs to apply tags to words/tokens. This recipe addresses the case of creating chunks from taggings that use the <strong class="calibre2">Begin, In, and Out</strong> (<strong class="calibre2">BIO</strong>) tags<a id="id480" class="calibre1"/> to encode chunkings that can span multiple words/tokens. This, in turn, is the basis of modern named-entity detection systems.</p></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_1"><a id="ch05lvl2sec143" class="calibre1"/>Getting ready</h2></div></div></div><p class="calibre9">The standard BIO-tagging scheme has the first token in a chunk of type X tagged B-X (begin), with all the subsequent tokens in the same chunk tagged I-X (in). All the tokens that are not in chunks are tagged O (out). For example, the string with character counts:</p><div><pre class="programlisting">John Jones Mary and Mr. Jones
01234567890123456789012345678
0         1         2         </pre></div><p class="calibre9">It can be tagged as:</p><div><pre class="programlisting">John  B_PERSON
Jones  I_PERSON
Mary  B_PERSON
and  O
Mr    B_PERSON
.    I_PERSON
Jones  I_PERSON</pre></div><p class="calibre9">The corresponding chunks will be:</p><div><pre class="programlisting">0-10 "John Jones" PERSON
11-15 "Mary" PERSON
20-29 "Mr. Jones" PERSON</pre></div></div></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_2"><a id="ch05lvl2sec144" class="calibre1"/>How to do it…</h2></div></div></div><p class="calibre9">The program will show the <a id="id481" class="calibre1"/>simplest mapping between taggings and chunkings and the other way around:</p><div><ol class="orderedlist"><li class="listitem" value="1">Run the following:<div><pre class="programlisting">
<strong class="calibre2">java -cp lingpipe-cookbook.1.0.jar:lib/lingpipe-4.1.0.jar: com.lingpipe.cookbook.chapter5.BioCodec</strong>
</pre></div></li><li class="listitem" value="2">The program first prints out the string that will be tagged with a tagging:<div><pre class="programlisting">
<strong class="calibre2">Tagging for :The rain in Spain.</strong>
<strong class="calibre2">The/B_Weather</strong>
<strong class="calibre2">rain/I_Weather</strong>
<strong class="calibre2">in/O</strong>
<strong class="calibre2">Spain/B_Place</strong>
<strong class="calibre2">./O</strong>
</pre></div></li><li class="listitem" value="3">Next, the chunking is printed:<div><pre class="programlisting">
<strong class="calibre2">Chunking from StringTagging</strong>
<strong class="calibre2">0-8:Weather@-Infinity</strong>
<strong class="calibre2">12-17:Place@-Infinity</strong>
</pre></div></li><li class="listitem" value="4">Then, the tagging is created from the chunking just displayed:<div><pre class="programlisting">
<strong class="calibre2">StringTagging from Chunking</strong>
<strong class="calibre2">The/B_Weather</strong>
<strong class="calibre2">rain/I_Weather</strong>
<strong class="calibre2">in/O</strong>
<strong class="calibre2">Spain/B_Place</strong>
<strong class="calibre2">./O</strong>
</pre></div></li></ol><div></div></div></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_3"><a id="ch05lvl2sec145" class="calibre1"/>How it works…</h2></div></div></div><p class="calibre9">The code starts by manually <a id="id482" class="calibre1"/>constructing <code class="email">StringTagging</code>—we will see HMMs and CRFs do the same programmatically, but here it is explicit. It then prints out the created <code class="email">StringTagging</code>:</p><div><pre class="programlisting">public static void main(String[] args) {
  List&lt;String&gt; tokens = new ArrayList&lt;String&gt;();
  tokens.add("The");
  tokens.add("rain");
  tokens.add("in");
  tokens.add("Spain");
  tokens.add(".");
  List&lt;String&gt; tags = new ArrayList&lt;String&gt;();
  tags.add("B_Weather");
  tags.add("I_Weather");
  tags.add("O");
  tags.add("B_Place");
  tags.add("O");
  CharSequence cs = "The rain in Spain.";
  //012345678901234567
  int[] tokenStarts = {0,4,9,12,17};
  int[] tokenEnds = {3,8,11,17,17};
  StringTagging tagging = new StringTagging(tokens, tags, cs, tokenStarts, tokenEnds);
  System.out.println("Tagging for :" + cs);
  for (int i = 0; i &lt; tagging.size(); ++i) {
    System.out.println(tagging.token(i) + "/" + tagging.tag(i));
  }</pre></div><p class="calibre9">Next, it will construct <code class="email">BioTagChunkCodec</code> and convert the tagging just printed out to a chunking followed by printing the chunking:</p><div><pre class="programlisting">BioTagChunkCodec codec = new BioTagChunkCodec();
Chunking chunking = codec.toChunking(tagging);
System.out.println("Chunking from StringTagging");
for (Chunk chunk : chunking.chunkSet()) {
  System.out.println(chunk);
}</pre></div><p class="calibre9">The remaining code <a id="id483" class="calibre1"/>reverses the process. First, a different <code class="email">BioTagChunkCodec</code> is created with <code class="email">boolean</code> <code class="email">enforceConsistency</code>, which, if <code class="email">true</code>, checks that the tokens created by the supplied tokenizer align exactly with the chunk begins and ends. Without the alignment we end up with a perhaps untenable relationship between chunks and tokens depending on the use case:</p><div><pre class="programlisting">boolean enforceConsistency = true;
BioTagChunkCodec codec2 = new BioTagChunkCodec(IndoEuropeanTokenizerFactory.INSTANCE, enforceConsistency);
StringTagging tagging2 = codec2.toStringTagging(chunking);
System.out.println("StringTagging from Chunking");
for (int i = 0; i &lt; tagging2.size(); ++i) {
  System.out.println(tagging2.token(i) + "/" + tagging2.tag(i));
}</pre></div><p class="calibre9">The last <code class="email">for</code> loop simply prints out the tagging returned by the <code class="email">codec2.toStringTagging()</code> method.</p></div></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_4"><a id="ch05lvl2sec146" class="calibre1"/>There's more…</h2></div></div></div><p class="calibre9">The recipe works through the simplest example of mapping between taggings and chunkings. <code class="email">BioTagChunkCodec</code> also takes the <code class="email">TagLattice&lt;String&gt;</code> objects to produce n-best output, as will be shown in the HMM and CRF chunkers to follow.</p></div></div>

<div><div><div><div><div><h1 class="title" id="calibre_pb_0"><a id="ch05lvl1sec65" class="calibre1"/>HMM-based NER</h1></div></div></div><p class="calibre9">
<code class="email">HmmChunker</code> uses <a id="id484" class="calibre1"/>an HMM to perform chunking over tokenized character sequences. Instances contain an HMM decoder for the model and tokenizer factory. The chunker requires the states of the HMM to conform to a token-by-token encoding of a chunking. It uses the tokenizer <a id="id485" class="calibre1"/>factory to break the chunks down into sequences of tokens and tags. Refer to the <em class="calibre10">Hidden Markov Models (HMM) – part of speech</em> recipe in <a class="calibre1" title="Chapter 4. Tagging Words and Tokens" href="part0051_split_000.html#page">Chapter 4</a>, <em class="calibre10">Tagging Words and Tokens</em>.</p><p class="calibre9">We'll look at training <code class="email">HmmChunker</code> and using it for the <code class="email">CoNLL2002</code> Spanish task. You can and should use your own data, but this recipe assumes that training data will be in the <code class="email">CoNLL2002</code> format.</p><p class="calibre9">Training is done using an <code class="email">ObjectHandler</code> which supplies the training instances.</p></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_1"><a id="ch05lvl2sec147" class="calibre1"/>Getting ready</h2></div></div></div><p class="calibre9">As we want to train this chunker, we need to either label some data using the <strong class="calibre2">Computational Natural Language Learning</strong> (<strong class="calibre2">CoNLL</strong>) <a id="id486" class="calibre1"/>schema or use the one that's publicly available. For speed, we'll choose to get a corpus that is available in the CoNLL 2002 task.</p><div><h3 class="title2"><a id="note08" class="calibre1"/>Note</h3><p class="calibre9">The ConNLL is an annual meeting that sponsors a bakeoff. In 2002, the bakeoff involved Spanish and Dutch NER.</p></div><p class="calibre9">The data can be downloaded from <a class="calibre1" href="http://www.cnts.ua.ac.be/conll2002/ner.tgz">http://www.cnts.ua.ac.be/conll2002/ner.tgz</a>.</p><p class="calibre9">Similar to what we showed<a id="id487" class="calibre1"/> in the preceding recipe; let's take a look at what this data looks like:</p><div><pre class="programlisting">El       O 
Abogado     B-PER 
General     I-PER 
del     I-PER 
Estado     I-PER 
,       O 
Daryl     B-PER 
Williams     I-PER 
,       O</pre></div><p class="calibre9">With this encoding scheme, the phrases <em class="calibre10">El Abogado General del Estado</em> and <em class="calibre10">Daryl Williams</em> are coded as persons, with their beginning and continuing tokens picked out with tags B-PER and I-PER, respectively.</p><div><h3 class="title2"><a id="note09" class="calibre1"/>Note</h3><p class="calibre9">There are a few formatting errors in the data that must be fixed before our parsers can handle them. After unpacking <code class="email">ner.tgz</code> in the <code class="email">data</code> directory you will have to go to <code class="email">data/ner/data</code>, unzip the following files, and modify as indicated:</p><div><pre class="programlisting">
<strong class="calibre2">esp.train, line 221619, change I-LOC to B-LOC</strong>
<strong class="calibre2">esp.testa, line 30882, change I-LOC to B-LOC</strong>
<strong class="calibre2">esp.testb, line 9291, change I-LOC to B-LOC</strong>
</pre></div></div></div></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_2"><a id="ch05lvl2sec148" class="calibre1"/>How to do it…</h2></div></div></div><div><ol class="orderedlist"><li class="listitem" value="1">Using the command line, type the following:<div><pre class="programlisting">
<strong class="calibre2">java –cp lingpipe-cookbook.1.0.jar:lib/lingpipe-4.1.0.jar com.lingpipe.cookbook.chapter5.HmmNeChunker</strong>
</pre></div></li><li class="listitem" value="2">It will run the training on the CoNLL training data if the model doesn't exist. It might take a while, so be patient. The output of the training will be:<div><pre class="programlisting">
<strong class="calibre2">Training HMM Chunker on data from: data/ner/data/esp.train</strong>
<strong class="calibre2">Output written to : models/Conll2002_ESP.RescoringChunker</strong>
<strong class="calibre2">Enter text, . to quit:</strong>
</pre></div></li><li class="listitem" value="3">Once the prompt to<a id="id488" class="calibre1"/> enter the text is presented, type in some Spanish text from the CoNLL test set:<div><pre class="programlisting">
<strong class="calibre2">La empresa también tiene participación en Tele Leste Celular , operadora móvil de los estados de Bahía y Sergipe y que es controlada por la española Iberdrola , y además es socia de Portugal Telecom en Telesp Celular , la operadora móvil de Sao Paulo .</strong>
<strong class="calibre2">Rank   Conf      Span         Type     Phrase</strong>
<strong class="calibre2">0      1.0000   (105, 112)    LOC      Sergipe</strong>
<strong class="calibre2">1      1.0000   (149, 158)    ORG      Iberdrola</strong>
<strong class="calibre2">2      1.0000   (202, 216)    ORG      Telesp Celular</strong>
<strong class="calibre2">3      1.0000   (182, 198)    ORG      Portugal Telecom</strong>
<strong class="calibre2">4      1.0000   (97, 102)     LOC      Bahía</strong>
<strong class="calibre2">5      1.0000   (241, 250)    LOC      Sao Paulo</strong>
<strong class="calibre2">6      0.9907   (163, 169)    PER      además</strong>
<strong class="calibre2">7      0.9736   (11, 18)      ORG      también</strong>
<strong class="calibre2">8      0.9736   (39, 60)      ORG      en Tele Leste Celular</strong>
<strong class="calibre2">9      0.0264   (42, 60)      ORG      Tele Leste Celular</strong>
</pre></div></li><li class="listitem" value="4">What we will see is a number of entities, their confidence score, the span in the original sentence, the type of entity, and the phrase that represents this entity.</li><li class="listitem" value="5">To find out the correct tags, take a look at the annotated <code class="email">esp.testa</code> file, which contains the following tags for this sentence:<div><pre class="programlisting">
<strong class="calibre2">Tele B-ORG</strong>
<strong class="calibre2">Leste I-ORG</strong>
<strong class="calibre2">Celular I-ORG</strong>
<strong class="calibre2">Bahía B-LOC</strong>
<strong class="calibre2">Sergipe B-LOC</strong>
<strong class="calibre2">Iberdrola B-ORG</strong>
<strong class="calibre2">Portugal B-ORG</strong>
<strong class="calibre2">Telecom I-ORG</strong>
<strong class="calibre2">Telesp B-ORG</strong>
<strong class="calibre2">Celular I-ORG</strong>
<strong class="calibre2">Sao B-LOC</strong>
<strong class="calibre2">Paulo I-LOC</strong>
</pre></div></li><li class="listitem" value="6">This can be read as follows:<div><pre class="programlisting">
<strong class="calibre2">Tele Leste Celular      ORG</strong>
<strong class="calibre2">Bahía                   LOC</strong>
<strong class="calibre2">Sergipe                 LOC</strong>
<strong class="calibre2">Iberdrola               ORG</strong>
<strong class="calibre2">Portugal Telecom        ORG</strong>
<strong class="calibre2">Telesp Celular          ORG</strong>
<strong class="calibre2">Sao Paulo               LOC</strong>
</pre></div></li><li class="listitem" value="7">So, we got all the ones with 1.000 confidence correct and the rest wrong. This can help us set up a threshold in production.</li></ol><div></div></div></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_3"><a id="ch05lvl2sec149" class="calibre1"/>How it works…</h2></div></div></div><p class="calibre9">The<a id="id489" class="calibre1"/> <code class="email">CharLmRescoringChunker</code> provides a long-distance character language model-based chunker that operates by rescoring the output of a contained character language model HMM chunker. The underlying chunker is an instance of <code class="email">CharLmHmmChunker</code>, which is configured with the specified tokenizer factory, n-gram length, number of characters, and interpolation ratio provided in the constructor.</p><p class="calibre9">Let's start with the <code class="email">main()</code> method; here, we will set up the chunker, train it if it doesn't exist, and then allow for some input to get the named entities out:</p><div><pre class="programlisting">String modelFilename = "models/Conll2002_ESP.RescoringChunker";
String trainFilename = "data/ner/data/esp.train";</pre></div><p class="calibre9">The training file will be in the correct place if you unpack the CoNLL data (<code class="email">tar –xvzf ner.tgz</code>) in the data directory. Remember to correct the annotation on line 221619 of <code class="email">esp.train</code>. If you use other data, then modify and recompile the class.</p><p class="calibre9">The next bit of code trains the model if it doesn't exist and then loads the serialized version of the chunker. If you have questions about deserialization, see the <em class="calibre10">Deserializing and running a classifier</em> recipe in <a class="calibre1" title="Chapter 1. Simple Classifiers" href="part0014_split_000.html#page">Chapter 1</a>, <em class="calibre10">Simple Classifiers</em>. Consider the following code snippet:</p><div><pre class="programlisting">File modelFile = new File(modelFilename);
if(!modelFile.exists()){
  System.out.println("Training HMM Chunker on data from: " + trainFilename);
  trainHMMChunker(modelFilename, trainFilename);
  System.out.println("Output written to : " + modelFilename);
}

@SuppressWarnings("unchecked")
RescoringChunker&lt;CharLmRescoringChunker&gt; chunker = (RescoringChunker&lt;CharLmRescoringChunker&gt;) AbstractExternalizable.readObject(modelFile);</pre></div><p class="calibre9">The <code class="email">trainHMMChunker()</code> method starts with some <code class="email">File</code> bookkeeping before setting up configuration <a id="id490" class="calibre1"/>parameters for <code class="email">CharLmRescoringChunker</code>:</p><div><pre class="programlisting">static void trainHMMChunker(String modelFilename, String trainFilename) throws IOException{
  File modelFile = new File(modelFilename);
  File trainFile = new File(trainFilename);
  
  int numChunkingsRescored = 64;
  int maxNgram = 12;
  int numChars = 256;
  double lmInterpolation = maxNgram; 
  TokenizerFactory factory
    = IndoEuropeanTokenizerFactory.INSTANCE;

CharLmRescoringChunker chunkerEstimator
  = new CharLmRescoringChunker(factory,numChunkingsRescored,
          maxNgram,numChars,
          lmInterpolation);</pre></div><pre>chunkerEstimator</code> with the <code class="email">setHandler()</code> method, and then, the <code class="email">parser.parse()</code> method does the actual training. The last bit of code serializes the model to disk—see the <em class="calibre10">How to serialize a LingPipe object – classifier example</em> recipe in <a class="calibre1" title="Chapter 1. Simple Classifiers" href="part0014_split_000.html#page">Chapter 1</a>, <em class="calibre10">Simple Classifiers</em>, to read about what is going on:</pre><div><pre class="programlisting">Conll2002ChunkTagParser parser = new Conll2002ChunkTagParser();
parser.setHandler(chunkerEstimator);
parser.parse(trainFile);
AbstractExternalizable.compileTo(chunkerEstimator,modelFile);</pre></div><p class="calibre9">Now, let's take a look at parsing the CoNLL data. The source for this class is <code class="email">src/com/lingpipe/cookbook/chapter5/Conll2002ChunkTagParser</code>:</p><div><pre class="programlisting">public class Conll2002ChunkTagParser extends StringParser&lt;ObjectHandler&lt;Chunking&gt;&gt;
{

  static final String TOKEN_TAG_LINE_REGEX = "(\\S+)\\s(\\S+\\s)?(O|[B|I]-\\S+)";
  static final int TOKEN_GROUP = 1;
  static final int TAG_GROUP = 3;
  static final String IGNORE_LINE_REGEX = "-DOCSTART(.*)";
  static final String EOS_REGEX = "\\A\\Z";
  static final String BEGIN_TAG_PREFIX = "B-";
  static final String IN_TAG_PREFIX = "I-";
  static final String OUT_TAG = "O";</pre></div><p class="calibre9">The statics <a id="id491" class="calibre1"/>set up the configuration of the <code class="email">com.aliasi.tag.LineTaggingParser</code> LingPipe class. CoNLL, like many available data sets, uses a token/tag per line format, which is meant to be very easy to parse:</p><div><pre class="programlisting">private final LineTaggingParser mParser = new LineTaggingParser(TOKEN_TAG_LINE_REGEX, TOKEN_GROUP, TAG_GROUP, IGNORE_LINE_REGEX, EOS_REGEX);</pre></div><p class="calibre9">The <code class="email">LineTaggingParser</code> constructor requires a regular expression that identifies the token and tag strings via grouping. There is additionally a regular expression for lines to ignore and finally, a regular expression for sentence ends.</p><p class="calibre9">Next, we set up <code class="email">TagChunkCodec</code>; this will handle the mapping from tagged tokens in the BIO format to proper chunks. See the previous recipe, <em class="calibre10">Translating between word tagging and chunks – BIO codec</em>, for more about what is going on here. The remaining parameters customize the tags to match those of the CoNLL training data:</p><div><pre class="programlisting">private final TagChunkCodec mCodec = new BioTagChunkCodec(null, false, BEGIN_TAG_PREFIX, IN_TAG_PREFIX, OUT_TAG);</pre></div><p class="calibre9">The rest of the class provides methods for <code class="email">parseString()</code>, which is immediately sent to the <code class="email">LineTaggingParser</code> class:</p><div><pre class="programlisting">public void parseString(char[] cs, int start, int end) {
  mParser.parseString(cs,start,end);
}</pre></div><p class="calibre9">Next, the <code class="email">ObjectHandler</code> parser is properly configured with the codec and supplied handler:</p><div><pre class="programlisting">public void setHandler(ObjectHandler&lt;Chunking&gt; handler) {

  ObjectHandler&lt;Tagging&lt;String&gt;&gt; taggingHandler = TagChunkCodecAdapters.chunkingToTagging(mCodec, handler);
  mParser.setHandler(taggingHandler);
}

public TagChunkCodec getTagChunkCodec(){
  return mCodec;
}</pre></div><p class="calibre9">It's a lot of odd-looking code, but all this does is set up a parser to read the lines from the input file and extract chunkings out of them.</p><p class="calibre9">Finally, let's go<a id="id492" class="calibre1"/> back to the <code class="email">main</code> method and look at the output loop. We will set up the <code class="email">MAX_NBEST</code> chunkings value as 10 and then invoke the <code class="email">nBestChunkings</code> method on the chunker. This provides the top 10 chunks and their probabilistic scores. Based on an evaluation, we can choose to cut off at a particular score:</p><div><pre class="programlisting">char[] cs = text.toCharArray();
Iterator&lt;Chunk&gt; it = chunker.nBestChunks(cs,0,cs.length, MAX_N_BEST_CHUNKS);
System.out.println(text);
System.out.println("Rank          Conf      Span"    + "    Type     Phrase");
DecimalFormat df = new DecimalFormat("0.0000");

for (int n = 0; it.hasNext(); ++n) {

Chunk chunk = it.next();
double conf = chunk.score();
int start = chunk.start();
int end = chunk.end();
String phrase = text.substring(start,end);
System.out.println(n + " "       + "            "   + df.format(conf)     + "       (" + start  + ", " + end  + ")    " + chunk.type()      + "         " + phrase);
}</pre></div></div></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_4"><a id="ch05lvl2sec150" class="calibre1"/>There's more…</h2></div></div></div><p class="calibre9">For more details on running a complete evaluation, refer to the evaluation section of the tutorial at <a class="calibre1" href="http://alias-i.com/lingpipe/demos/tutorial/ne/read-me.html">http://alias-i.com/lingpipe/demos/tutorial/ne/read-me.html</a>.</p></div></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_5"><a id="ch05lvl2sec151" class="calibre1"/>See also</h2></div></div></div><p class="calibre9">For more details<a id="id493" class="calibre1"/> on <code class="email">CharLmRescoringChunker</code> and <code class="email">HmmChunker</code>, refer<a id="id494" class="calibre1"/> to:</p><div><ul class="itemizedlist"><li class="listitem"><a class="calibre1" href="http://alias-i.com/lingpipe/docs/api/com/aliasi/chunk/AbstractCharLmRescoringChunker.html">http://alias-i.com/lingpipe/docs/api/com/aliasi/chunk/AbstractCharLmRescoringChunker.html</a></li><li class="listitem"><a class="calibre1" href="http://alias-i.com/lingpipe/docs/api/com/aliasi/chunk/HmmChunker.html">http://alias-i.com/lingpipe/docs/api/com/aliasi/chunk/HmmChunker.html</a></li></ul></div></div></div>

<div><div><div><div><div><h1 class="title" id="calibre_pb_0"><a id="ch05lvl1sec66" class="calibre1"/>Mixing the NER sources</h1></div></div></div><p class="calibre9">Now that we've seen how<a id="id495" class="calibre1"/> to build a few different types of NERs, we can look at how to combine them. In this recipe, we will take a regular expression chunker, a dictionary-based chunker, and an HMM-based chunker and combine their outputs and look at overlaps.</p><p class="calibre9">We will just initialize a few chunkers in the same way we did in the past few recipes and then pass the same text through these chunkers. The easiest possibility is that each chunker returns a unique output. For example, let's consider a sentence such as "President Obama was scheduled to give a speech at the G-8 conference this evening". If we have a person chunker and an organization chunker, we might only get two unique chunks out. However, if we add a <code class="email">Presidents of USA</code> chunker, we will get three chunks: <code class="email">PERSON</code>, <code class="email">ORGANIZATION</code>, and <code class="email">PRESIDENT</code>. This very simple recipe will show us one way to handle these cases.</p></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_1"><a id="ch05lvl2sec152" class="calibre1"/>How to do it…</h2></div></div></div><div><ol class="orderedlist"><li class="listitem" value="1">Using the command line or equivalent in your IDE, type the following:<div><pre class="programlisting">
<strong class="calibre2">java –cp lingpipe-cookbook.1.0.jar:lib/lingpipe-4.1.0.jar com.lingpipe.cookbook.chapter5.MultipleNer</strong>
</pre></div></li><li class="listitem" value="2">The usual interactive prompt follows:<div><pre class="programlisting">
<strong class="calibre2">Enter text, . to quit:</strong>
<strong class="calibre2">President Obama is scheduled to arrive in London this evening. He will address the G-8 summit.</strong>
<strong class="calibre2">neChunking: [10-15:PERSON@-Infinity, 42-48:LOCATION@-Infinity, 83-86:ORGANIZATION@-Infinity]</strong>
<strong class="calibre2">pChunking: [62-66:MALE_PRONOUN@1.0]</strong>
<strong class="calibre2">dChunking: [10-15:PRESIDENT@1.0]</strong>
<strong class="calibre2">----Overlaps Allowed</strong>

<strong class="calibre2"> Combined Chunks:</strong>
<strong class="calibre2">[83-86:ORGANIZATION@-Infinity, 10-15:PERSON@-Infinity, 10-15:PRESIDENT@1.0, 42-48:LOCATION@-Infinity, 62-66:MALE_PRONOUN@1.0]</strong>

<strong class="calibre2">----Overlaps Not Allowed</strong>

<strong class="calibre2"> Unique Chunks:</strong>
<strong class="calibre2">[83-86:ORGANIZATION@-Infinity, 42-48:LOCATION@-Infinity, 62-66:MALE_PRONOUN@1.0]</strong>

<strong class="calibre2"> OverLapped Chunks:</strong>
<strong class="calibre2">[10-15:PERSON@-Infinity, 10-15:PRESIDENT@1.0]</strong>
</pre></div></li><li class="listitem" value="3">We see the output from the three chunkers: <code class="email">neChunking</code> is the output of an HMM chunker that is trained to return the MUC-6 entities, <code class="email">pChunking</code> is a simple regular expression that recognizes male pronouns, and <code class="email">dChunking</code> is a dictionary chunker that recognizes US Presidents.</li><li class="listitem" value="4">With overlaps allowed, we will see the chunks for <code class="email">PRESIDENT</code> as well as <code class="email">PERSON</code> in the merged output.</li><li class="listitem" value="5">With overlaps disallowed, they will be added to the set overlapped chunks and removed from the unique chunks.</li></ol><div></div></div></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_2"><a id="ch05lvl2sec153" class="calibre1"/>How it works…</h2></div></div></div><p class="calibre9">We initialized three <a id="id496" class="calibre1"/>chunkers that should be familiar to you from the previous recipes in this chapter:</p><div><pre class="programlisting">Chunker pronounChunker = new RegExChunker(" He | he | Him | him", "MALE_PRONOUN",1.0);
File MODEL_FILE = new File("models/ne-en-news.muc6." + "AbstractCharLmRescoringChunker");
Chunker neChunker = (Chunker) AbstractExternalizable.readObject(MODEL_FILE);

MapDictionary&lt;String&gt; dictionary = new MapDictionary&lt;String&gt;();
dictionary.addEntry(
  new DictionaryEntry&lt;String&gt;("Obama","PRESIDENT",CHUNK_SCORE));
dictionary.addEntry(
  new DictionaryEntry&lt;String&gt;("Bush","PRESIDENT",CHUNK_SCORE));
ExactDictionaryChunker dictionaryChunker = new ExactDictionaryChunker(dictionary, IndoEuropeanTokenizerFactory.INSTANCE);</pre></div><p class="calibre9">Now, we will just chunk our input text via all three chunkers, combine the chunks into one set, and pass our <code class="email">getCombinedChunks</code> method to it:</p><div><pre class="programlisting">Set&lt;Chunk&gt; neChunking = neChunker.chunk(text).chunkSet();
Set&lt;Chunk&gt; pChunking = pronounChunker.chunk(text).chunkSet();
Set&lt;Chunk&gt; dChunking = dictionaryChunker.chunk(text).chunkSet();
Set&lt;Chunk&gt; allChunks = new HashSet&lt;Chunk&gt;();
allChunks.addAll(neChunking);
allChunks.addAll(pChunking);
allChunks.addAll(dChunking);
getCombinedChunks(allChunks,true);//allow overlaps
getCombinedChunks(allChunks,false);//no overlaps</pre></div><p class="calibre9">The meat of this <a id="id497" class="calibre1"/>recipe is in the <code class="email">getCombinedChunks</code> method. We will just loop through all the chunks and check each pair if they overlap in their starts and ends. If they overlap and overlaps are not allowed, they are added to an overlapped set; otherwise, they are added to a combined set:</p><div><pre class="programlisting">static void getCombinedChunks(Set&lt;Chunk&gt; chunkSet, boolean allowOverlap){
  Set&lt;Chunk&gt; combinedChunks = new HashSet&lt;Chunk&gt;();
  Set&lt;Chunk&gt;overLappedChunks = new HashSet&lt;Chunk&gt;();
  for(Chunk c : chunkSet){
    combinedChunks.add(c);
    for(Chunk x : chunkSet){
      if (c.equals(x)){
        continue;
      }
      if (ChunkingImpl.overlap(c,x)) {
        if (allowOverlap){
          combinedChunks.add(x);
        } else {
          overLappedChunks.add(x);
          combinedChunks.remove(c);
        }
      }
    }
  }
}</pre></div><p class="calibre9">Here is the place <a id="id498" class="calibre1"/>to add more rules for overlapping chunks. For example, you can make it score based, so if the <code class="email">PRESIDENT</code> chunk type has a higher score than the HMM-based one, you can choose it instead.</p></div></div>

<div><div><div><div><div><h1 class="title" id="calibre_pb_0"><a id="ch05lvl1sec67" class="calibre1"/>CRFs for chunking</h1></div></div></div><p class="calibre9">CRFs are best known to <a id="id499" class="calibre1"/>provide close to state-of-the-art performance for named-entity tagging. This recipe will tell us how to build one of these systems. The recipe assumes that you have read, understood, and played with the <em class="calibre10">Conditional r</em>
<em class="calibre10">andom fields – CRF for word/token tagging</em> recipe in <a class="calibre1" title="Chapter 4. Tagging Words and Tokens" href="part0051_split_000.html#page">Chapter 4</a>, <em class="calibre10">Tagging Words and Tokens</em>, which addresses the underlying technology. Like HMMs, CRFs treat named entity detection as a word-tagging problem, with an interpretation layer that provides chunkings. Unlike HMMs, CRFs use a logistic-regression-based classification approach, which, in turn, allows for random features to be included. Also, there is an excellent tutorial on CRFs<a id="id500" class="calibre1"/> that this recipe follows closely (but omits details) at <a class="calibre1" href="http://alias-i.com/lingpipe/demos/tutorial/crf/read-me.html">http://alias-i.com/lingpipe/demos/tutorial/crf/read-me.html</a>. There is also a lot of information in the Javadoc.</p></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_1"><a id="ch05lvl2sec154" class="calibre1"/>Getting ready</h2></div></div></div><p class="calibre9">Just as we did earlier, we will use a small hand-coded corpus to serve as training data. The corpus is in <code class="email">src/com/lingpipe/cookbook/chapter5/TinyEntityCorpus.java</code>. It starts with:</p><div><pre class="programlisting">public class TinyEntityCorpus extends Corpus&lt;ObjectHandler&lt;Chunking&gt;&gt; {

  public void visitTrain(ObjectHandler&lt;Chunking&gt; handler) {
    for (Chunking chunking : CHUNKINGS) handler.handle(chunking);
  }

  public void visitTest(ObjectHandler&lt;Chunking&gt; handler) {
    /* no op */
  }</pre></div><p class="calibre9">Since we are only using this corpus to train, the <code class="email">visitTest()</code> method does nothing. However, the <code class="email">visitTrain()</code> method exposes the handler to all the chunkings stored in the <code class="email">CHUNKINGS</code> constant. This, in turn, looks like the following:</p><div><pre class="programlisting">static final Chunking[] CHUNKINGS = new Chunking[] {
  chunking(""), chunking("The"), chunking("John ran.", chunk(0,4,"PER")), chunking("Mary ran.", chunk(0,4,"PER")), chunking("The kid ran."), chunking("John likes Mary.", chunk(0,4,"PER"), chunk(11,15,"PER")), chunking("Tim lives in Washington", chunk(0,3,"PER"), chunk(13,23,"LOC")), chunking("Mary Smith is in New York City", chunk(0,10,"PER"), chunk(17,30,"LOC")), chunking("New York City is fun", chunk(0,13,"LOC")), chunking("Chicago is not like Washington", chunk(0,7,"LOC"), chunk(20,30,"LOC"))
};</pre></div><p class="calibre9">We are still not done. Given <a id="id501" class="calibre1"/>that the creation of <code class="email">Chunking</code> is fairly verbose, there are static methods to help dynamically create the requisite objects:</p><div><pre class="programlisting">static Chunking chunking(String s, Chunk... chunks) {
  ChunkingImpl chunking = new ChunkingImpl(s);
  for (Chunk chunk : chunks) chunking.add(chunk);
  return chunking;
}

static Chunk chunk(int start, int end, String type) {
  return ChunkFactory.createChunk(start,end,type);
}</pre></div><p class="calibre9">This is all the setup; next, we will train and run a CRF on the preceding data.</p></div></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_2"><a id="ch05lvl2sec155" class="calibre1"/>How to do it...</h2></div></div></div><div><ol class="orderedlist"><li class="listitem" value="1">Type the <code class="email">TrainAndRunSimplCrf</code> class in the <a id="id502" class="calibre1"/>command line or run the equivalent in your IDE:<div><pre class="programlisting">
<strong class="calibre2">java -cp lingpipe-cookbook.1.0.jar:lib/lingpipe-4.1.0.jar: com.lingpipe.cookbook.chapter5.TrainAndRunSimpleCrf</strong>
</pre></div></li><li class="listitem" value="2">This results in loads of screen output that report on the health and progress of the CRF, it is mostly information from the underlying logistic-regression classifier that drives the whole show. The fun bit is that we will get an invitation to play with the new CRF:<div><pre class="programlisting">
<strong class="calibre2">Enter text followed by new line</strong>
<strong class="calibre2">&gt;John Smith went to New York.</strong>
</pre></div></li><li class="listitem" value="3">The chunker reports the first best output:<div><pre class="programlisting">
<strong class="calibre2">FIRST BEST</strong>
<strong class="calibre2">John Smith went to New York. : [0-10:PER@-Infinity, 19-27:LOC@-Infinity]</strong>
</pre></div></li><li class="listitem" value="4">The preceding output is the first best analysis by the CRF of what sorts of entities are in the sentence. It thinks that <code class="email">John Smith</code> is <code class="email">PER</code> with <code class="email">the 0-10:PER@-Infinity</code> output. We know that it applies to the <code class="email">John Smith</code> string by taking the substring from 0 to 10 in the input text. Ignore <code class="email">–Infinity</code>, which is supplied for chunks that have no score. The first best chunking does not have scores. The other entity that it thinks is in the text is <code class="email">New York</code> as an <code class="email">LOC</code>.</li><li class="listitem" value="5">Immediately, the conditional probabilities follow:<div><pre class="programlisting">
<strong class="calibre2">10 BEST CONDITIONAL</strong>
<strong class="calibre2">Rank log p(tags|tokens)  Tagging</strong>
<strong class="calibre2">0    -1.66335590 [0-10:PER@-Infinity, 19-27:LOC@-Infinity]</strong>
<strong class="calibre2">1    -2.38671498 [0-10:PER@-Infinity, 19-28:LOC@-Infinity]</strong>
<strong class="calibre2">2    -2.77341747 [0-10:PER@-Infinity]</strong>
<strong class="calibre2">3    -2.85908677 [0-4:PER@-Infinity, 19-27:LOC@-Infinity]</strong>
<strong class="calibre2">4    -3.00398856 [0-10:PER@-Infinity, 19-22:LOC@-Infinity]</strong>
<strong class="calibre2">5    -3.23050827 [0-10:PER@-Infinity, 16-27:LOC@-Infinity]</strong>
<strong class="calibre2">6    -3.49773765 [0-10:PER@-Infinity, 23-27:PER@-Infinity]</strong>
<strong class="calibre2">7    -3.58244582 [0-4:PER@-Infinity, 19-28:LOC@-Infinity]</strong>
<strong class="calibre2">8    -3.72315571 [0-10:PER@-Infinity, 19-22:PER@-Infinity]</strong>
<strong class="calibre2">9    -3.95386735 [0-10:PER@-Infinity, 16-28:LOC@-Infinity]</strong>
</pre></div></li><li class="listitem" value="6">The preceding output<a id="id503" class="calibre1"/> provides the 10 best analyses of the whole phrase, along with their conditional (natural log) probabilities. In this case, we will see that the system isn't particularly confident of any of its analyses. For instance, the estimated probability of the first best analysis being correct is <code class="email">exp(-1.66)=0.19</code>.</li><li class="listitem" value="7">Next, in the output, we see probabilities for individual chunks:<div><pre class="programlisting">
<strong class="calibre2">MARGINAL CHUNK PROBABILITIES</strong>
<strong class="calibre2">Rank Chunk Phrase</strong>
<strong class="calibre2">0 0-10:PER@-0.49306887565189683 John Smith</strong>
<strong class="calibre2">1 19-27:LOC@-1.1957935770408703 New York</strong>
<strong class="calibre2">2 0-4:PER@-1.3270942262839682 John</strong>
<strong class="calibre2">3 19-22:LOC@-2.484463373596263 New</strong>
<strong class="calibre2">4 23-27:PER@-2.6919267821139776 York</strong>
<strong class="calibre2">5 16-27:LOC@-2.881057607295971 to New York</strong>
<strong class="calibre2">6 11-15:PER@-3.0868632773744222 went</strong>
<strong class="calibre2">7 16-18:PER@-3.1583044940140192 to</strong>
<strong class="calibre2">8 19-22:PER@-3.2036305275847825 New</strong>
<strong class="calibre2">9 23-27:LOC@-3.536294896211011 York</strong>
</pre></div></li><li class="listitem" value="8">As with the previous conditional output, the probabilities are logs, so we can see that the <code class="email">John Smith</code> chunk has estimated probability <code class="email">exp(-0.49) = 0.61</code>, which makes sense because in training the CRF saw <code class="email">John</code> at the beginning of <code class="email">PER</code> and <code class="email">Smith</code> at the end of another, but not <code class="email">John Smith</code> directly.</li><li class="listitem" value="9">The preceding kind <a id="id504" class="calibre1"/>of probability distributions can really improve systems if there are sufficient resources to consider a broad range of analyses and ways of combining evidence to allow for improbable outcomes to be selected. First best analyses tend to be over committed to conservative outcomes that fit what training data looks like.</li></ol><div></div></div></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_3"><a id="ch05lvl2sec156" class="calibre1"/>How it works…</h2></div></div></div><p class="calibre9">The code in <code class="email">src/com/lingpipe/cookbook/chapter5/TrainAndRunSimpleCRF.java</code> resembles our classifier and HMM recipes with a few differences. These differences are addressed as follows:</p><div><pre class="programlisting">public static void main(String[] args) throws IOException {
  Corpus&lt;ObjectHandler&lt;Chunking&gt;&gt; corpus = new TinyEntityCorpus();

  TokenizerFactory tokenizerFactory = IndoEuropeanTokenizerFactory.INSTANCE;
  boolean enforceConsistency = true;
  TagChunkCodec tagChunkCodec = new BioTagChunkCodec(tokenizerFactory, enforceConsistency);</pre></div><p class="calibre9">When we previously played with CRFs, the inputs were of the <code class="email">Tagging&lt;String&gt;</code> type. Looking back at <code class="email">TinyEntityCorpus.java</code>, the types are of the <code class="email">Chunking</code> type. The preceding <code class="email">BioTagChunkCodec</code> facilitates the translation of <code class="email">Chunking</code> into <code class="email">Tagging</code> via the efforts of a supplied <code class="email">TokenizerFactory</code> and <code class="email">boolean</code> that raise an exception if <code class="email">TokenizerFactory</code> does not exactly agree with the <code class="email">Chunk</code> starts and ends. Look back to the <em class="calibre10">Translating between word tagging and chunks–BIO codec</em> recipe better<a id="id505" class="calibre1"/> understand the role of this class.</p><p class="calibre9">Let's take a look at the following:</p><div><pre class="programlisting">John Smith went to New York City. : [0-10:PER@-Infinity, 19-32:LOC@-Infinity]</pre></div><p class="calibre9">This codec will translate into a tagging:</p><div><pre class="programlisting">Tok    Tag
John   B_PER
Smith  I_PER
went  O
to     O
New    B_LOC
York  I_LOC
City  I_LOC
.    O</pre></div><pre>ChainCrfFeatureExtractor&lt;String&gt; featureExtractor = new SimpleCrfFeatureExtractor();</pre></div><p class="calibre9">All the mechanics are hidden inside a new <code class="email">ChainCrfChunker</code> class, and it is initialized in a manner similar to logistic regression, which is the underlying technology. Refer to the <em class="calibre10">Logistic regression</em> recipe of <a class="calibre1" title="Chapter 3. Advanced Classifiers" href="part0036_split_000.html#page">Chapter 3</a>, <em class="calibre10">Advanced Classifiers</em>, for more information on the configuration:</pre><div><pre class="programlisting">int minFeatureCount = 1;
boolean cacheFeatures = true;
boolean addIntercept = true;
double priorVariance = 4.0;
boolean uninformativeIntercept = true;
RegressionPrior prior = RegressionPrior.gaussian(priorVariance, uninformativeIntercept);
int priorBlockSize = 3;
double initialLearningRate = 0.05;
double learningRateDecay = 0.995;
AnnealingSchedule annealingSchedule = AnnealingSchedule.exponential(initialLearningRate, learningRateDecay);
double minImprovement = 0.00001;
int minEpochs = 10;
int maxEpochs = 5000;
Reporter reporter = Reporters.stdOut().setLevel(LogLevel.DEBUG);
System.out.println("\nEstimating");
ChainCrfChunker crfChunker = ChainCrfChunker.estimate(corpus, tagChunkCodec, tokenizerFactory, featureExtractor, addIntercept, minFeatureCount, cacheFeatures, prior, priorBlockSize, annealingSchedule, minImprovement, minEpochs, maxEpochs, reporter);</pre></div><p class="calibre9">The only new thing here is the <code class="email">tagChunkCodec</code> parameter, which we just described.</p><p class="calibre9">Once the training is over, we <a id="id506" class="calibre1"/>will access the chunker for first best with the following code:</p><div><pre class="programlisting">System.out.println("\nFIRST BEST");
Chunking chunking = crfChunker.chunk(evalText);
System.out.println(chunking);</pre></div><p class="calibre9">Conditional chunkings are delivered by:</p><div><pre class="programlisting">int maxNBest = 10;
System.out.println("\n" + maxNBest + " BEST CONDITIONAL");
System.out.println("Rank log p(tags|tokens)  Tagging");
Iterator&lt;ScoredObject&lt;Chunking&gt;&gt; it = crfChunker.nBestConditional(evalTextChars,0, evalTextChars.length,maxNBest);

  for (int rank = 0; rank &lt; maxNBest &amp;&amp; it.hasNext(); ++rank) {
    ScoredObject&lt;Chunking&gt; scoredChunking = it.next();
    System.out.println(rank + "    " + scoredChunking.score() + " " + scoredChunking.getObject().chunkSet());
  }</pre></div><p class="calibre9">The individual chunks are accessed with:</p><div><pre class="programlisting">System.out.println("\nMARGINAL CHUNK PROBABILITIES");
System.out.println("Rank Chunk Phrase");
int maxNBestChunks = 10;
Iterator&lt;Chunk&gt; nBestIt  = crfChunker.nBestChunks(evalTextChars,0, evalTextChars.length,maxNBestChunks);
for (int n = 0; n &lt; maxNBestChunks &amp;&amp; nBestIt.hasNext(); ++n) {
  Chunk chunk = nBestChunkIt.next();
  System.out.println(n + " " + chunk + " " + evalText.substring(chunk.start(),chunk.end()));
}</pre></div><p class="calibre9">That's it. You have access to one of the world's finest chunking technologies. Next, we will show you how to make it better.</p></div></div>

<div><div><div><div><div><h1 class="title" id="calibre_pb_0"><a id="ch05lvl1sec68" class="calibre1"/>NER using CRFs with better features</h1></div></div></div><p class="calibre9">In this recipe, we'll show<a id="id507" class="calibre1"/> you how to create a realistic, though not <a id="id508" class="calibre1"/>quite state-of-the-art, set of features for CRFs. The features will include normalized tokens, part-of-speech tags, word-shape features, position features, and token prefixes and suffixes. Substitute it for the <code class="email">SimpleCrfFeatureExtractor</code> in the <em class="calibre10">CRFs for chunking</em> recipe to use it.</p></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_1"><a id="ch05lvl2sec157" class="calibre1"/>How to do it…</h2></div></div></div><p class="calibre9">The source for this recipe is in <code class="email">src/com/lingpipe/cookbook/chapter5/FancyCrfFeatureExtractor.java</code>:</p><div><ol class="orderedlist"><li class="listitem" value="1">Open up your IDE or command prompt and type:<div><pre class="programlisting">
<strong class="calibre2">java -cp lingpipe-cookbook.1.0.jar:lib/lingpipe-4.1.0.jar: com.lingpipe.cookbook.chapter5.FancyCrfFeatureExtractor</strong>
</pre></div></li><li class="listitem" value="2">Brace yourself for an explosion of features from the console. The data being used for feature extraction is <code class="email">TinyEntityCorpus</code> of the previous recipe. Luckily, the first bit of data is just the node features for the "John" in the sentence <code class="email">John ran.</code>:<div><pre class="programlisting">
<strong class="calibre2">Tagging:  John/PN</strong>
<strong class="calibre2">Node Feats:{PREF_NEXT_ra=1.0, PREF_Jo=1.0, POS_np=1.0, TOK_CAT_LET-CAP=1.0, SUFF_NEXT_an=1.0, PREF_Joh=1.0, PREF_NEXT_r=1.0, SUFF_John=1.0, TOK_John=1.0, PREF_NEXT_ran=1.0, BOS=1.0, TOK_NEXT_ran=1.0, SUFF_NEXT_n=1.0, SUFF_NEXT_ran=1.0, SUFF_ohn=1.0, PREF_J=1.0, POS_NEXT_vbd=1.0, SUFF_hn=1.0, SUFF_n=1.0, TOK_CAT_NEXT_ran=1.0, PREF_John=1.0}</strong>
</pre></div></li><li class="listitem" value="3">The next word in the sequence adds edge features—we won't bother showing you the node features:<div><pre class="programlisting">
<strong class="calibre2">Edge Feats:{PREV_TAG_TOKEN_CAT_PN_LET-CAP=1.0, PREV_TAG_PN=1.0}</strong>
</pre></div></li></ol><div></div></div></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_2"><a id="ch05lvl2sec158" class="calibre1"/>How it works…</h2></div></div></div><p class="calibre9">As with other recipes, we won't bother discussing parts that are very similar to previous recipes—the relevant previous recipe here is the <em class="calibre10">Modifying CRFs</em> recipe in <a class="calibre1" title="Chapter 4. Tagging Words and Tokens" href="part0051_split_000.html#page">Chapter 4</a>, <em class="calibre10">Tagging Words and Tokens</em>. This is exactly the same, except for the fact that we will add in a lot more features—perhaps, from unexpected sources.</p><div><h3 class="title2"><a id="note10" class="calibre1"/>Note</h3><p class="calibre9">The tutorial for CRFs covers how to serialize/deserialize this class. This implementation does not cover it.</p></div><p class="calibre9">Object construction is similar to the <code class="email">Modifying CRFs</code> recipe in <a class="calibre1" title="Chapter 4. Tagging Words and Tokens" href="part0051_split_000.html#page">Chapter 4</a>, <em class="calibre10">Tagging Words and Tokens</em>:</p><div><pre class="programlisting">public FancyCrfFeatureExtractor()
  throws ClassNotFoundException, IOException {
  File posHmmFile = new File("models/pos-en-general" + "brown.HiddenMarkovModel");
  @SuppressWarnings("unchecked") HiddenMarkovModel posHmm = (HiddenMarkovModel)
  AbstractExternalizable.readObject(posHmmFile);

  FastCache&lt;String,double[]&gt; emissionCache = new FastCache&lt;String,double[]&gt;(100000);
  mPosTagger = new HmmDecoder(posHmm,null,emissionCache);
}</pre></div><p class="calibre9">The constructor sets up a <a id="id509" class="calibre1"/>part-of-speech tagger with a cache and<a id="id510" class="calibre1"/> shoves it into the <code class="email">mPosTagger</code> member variable.</p><p class="calibre9">The following method does very little, except supplying an inner <code class="email">ChunkerFeatures</code> class:</p><div><pre class="programlisting">public ChainCrfFeatures&lt;String&gt; extract(List&lt;String&gt; tokens, List&lt;String&gt; tags) {
  return new ChunkerFeatures(tokens,tags);
}</pre></div><p class="calibre9">The <code class="email">ChunkerFeatures</code> class is where things get more interesting:</p><div><pre class="programlisting">class ChunkerFeatures extends ChainCrfFeatures&lt;String&gt; {
  private final Tagging&lt;String&gt; mPosTagging;

  public ChunkerFeatures(List&lt;String&gt; tokens, List&lt;String&gt; tags) {
    super(tokens,tags);
    mPosTagging = mPosTagger.tag(tokens);
  }</pre></div><p class="calibre9">The <code class="email">mPosTagger</code> function is used to set up <code class="email">Tagging&lt;String&gt;</code> for the tokens presented on class creation. This will be aligned with the <code class="email">tag()</code> and <code class="email">token()</code> superclass methods and be the source of part-of-speech tags as a node feature.</p><p class="calibre9">Now, we can get on with the feature extraction. We will start with edge features, as they are the simplest:</p><div><pre class="programlisting">public Map&lt;String,? extends Number&gt; edgeFeatures(int n, int k) {
  ObjectToDoubleMap&lt;String&gt; feats = new ObjectToDoubleMap&lt;String&gt;();
  feats.set("PREV_TAG_" + tag(k),1.0);
  feats.set("PREV_TAG_TOKEN_CAT_"  + tag(k) + "_" + tokenCat(n-1), 1.0);
  return feats;
}</pre></div><p class="calibre9">The new feature<a id="id511" class="calibre1"/> is prefixed with <code class="email">PREV_TAG_TOKEN_CAT_</code>, and <a id="id512" class="calibre1"/>the example is <code class="email">PREV_TAG_TOKEN_CAT_PN_LET-CAP=1.0</code>. The <code class="email">tokenCat()</code> method looks at the word shape feature for the previous token and returns it as a string. Look at the Javadoc for <code class="email">IndoEuropeanTokenCategorizer</code> to see what is going on.</p><p class="calibre9">Next comes the node features. There are many of these; each will be presented in turn:</p><div><pre class="programlisting">public Map&lt;String,? extends Number&gt; nodeFeatures(int n) {
  ObjectToDoubleMap&lt;String&gt; feats = new ObjectToDoubleMap&lt;String&gt;();</pre></div><p class="calibre9">The preceding code sets up the method with the appropriate return type. The next two lines set up some state to know where the feature extractor is in the string:</p><div><pre class="programlisting">boolean bos = n == 0;
boolean eos = (n + 1) &gt;= numTokens();</pre></div><p class="calibre9">Next, we will compute the token categories, tokens, and part-of-speech tags for the current position, previous position, and the next position of the input:</p><div><pre class="programlisting">String tokenCat = tokenCat(n);
String prevTokenCat = bos ? null : tokenCat(n-1);
String nextTokenCat = eos ? null : tokenCat(n+1);

String token = normedToken(n);
String prevToken = bos ? null : normedToken(n-1);
String nextToken = eos ? null : normedToken(n+1);

String posTag = mPosTagging.tag(n);
String prevPosTag = bos ? null : mPosTagging.tag(n-1);
String nextPosTag = eos ? null : mPosTagging.tag(n+1);</pre></div><p class="calibre9">The previous and next methods check if we're at the begin or end of the sentence and return <code class="email">null</code> accordingly. The part-of-speech tagging is taken from the saved part-of-speech taggings computed in the constructor.</p><p class="calibre9">The token methods provide some normalization of tokens to compress all numbers to the same kind of value. This method is as follows:</p><div><pre class="programlisting">public String normedToken(int n) {
  return token(n).replaceAll("\\d+","*$0*").replaceAll("\\d","D");
}</pre></div><p class="calibre9">This just takes every<a id="id513" class="calibre1"/> sequence of numbers and<a id="id514" class="calibre1"/> replaces it with <code class="email">*D...D*</code>. For instance, <code class="email">12/3/08</code> is converted to <code class="email">*DD*/*D*/*DD*</code>.</p><p class="calibre9">We will then set feature values for the preceding, current, and following tokens. First, a flag indicates whether it begins or ends a sentence or an internal node:</p><div><pre class="programlisting">if (bos) {
  feats.set("BOS",1.0);
}
if (eos) {
  feats.set("EOS",1.0);
}
if (!bos &amp;&amp; !eos) {
  feats.set("!BOS!EOS",1.0);
}</pre></div><p class="calibre9">Next, we will include the tokens, token categories, and their parts of speech:</p><div><pre class="programlisting">feats.set("TOK_" + token, 1.0);
if (!bos) {
  feats.set("TOK_PREV_" + prevToken,1.0);
}
if (!eos) {
  feats.set("TOK_NEXT_" + nextToken,1.0);
}
feats.set("TOK_CAT_" + tokenCat, 1.0);
if (!bos) {
  feats.set("TOK_CAT_PREV_" + prevTokenCat, 1.0);
}
if (!eos) {
  feats.set("TOK_CAT_NEXT_" + nextToken, 1.0);
}
feats.set("POS_" + posTag,1.0);
if (!bos) {
  feats.set("POS_PREV_" + prevPosTag,1.0);
}
if (!eos) {
  feats.set("POS_NEXT_" + nextPosTag,1.0);
}</pre></div><p class="calibre9">Finally, we will add the <a id="id515" class="calibre1"/>prefix and suffix features, which add<a id="id516" class="calibre1"/> features for each suffix and prefix (up to a prespecified length):</p><div><pre class="programlisting">for (String suffix : suffixes(token)) {
  feats.set("SUFF_" + suffix,1.0);
}
if (!bos) {
  for (String suffix : suffixes(prevToken)) {
    feats.set("SUFF_PREV_" + suffix,1.0);
    if (!eos) {
      for (String suffix : suffixes(nextToken)) {
        feats.set("SUFF_NEXT_" + suffix,1.0);
      }
      for (String prefix : prefixes(token)) {
        feats.set("PREF_" + prefix,1.0);
      }
      if (!bos) {
        for (String prefix : prefixes(prevToken)) {
          feats.set("PREF_PREV_" + prefix,1.0);
      }
      if (!eos) {
        for (String prefix : prefixes(nextToken)) {
          feats.set("PREF_NEXT_" + prefix,1.0);
        }
      }
      return feats;
    }</pre></div><p class="calibre9">After this, we will just return the feature mapping generated.</p><p class="calibre9">The <code class="email">prefix</code> or <code class="email">suffix</code> function is simply implemented with a list:</p><div><pre class="programlisting">static int MAX_PREFIX_LENGTH = 4;
  static List&lt;String&gt; prefixes(String s) {
    int numPrefixes = Math.min(MAX_PREFIX_LENGTH,s.length());
    if (numPrefixes == 0) {
      return Collections.emptyList();
    }
    if (numPrefixes == 1) {
      return Collections.singletonList(s);
    }
    List&lt;String&gt; result = new ArrayList&lt;String&gt;(numPrefixes);
    for (int i = 1; i &lt;= Math.min(MAX_PREFIX_LENGTH,s.length()); ++i) {
      result.add(s.substring(0,i));
    }
    return result;
  }

  static int MAX_SUFFIX_LENGTH = 4;
  static List&lt;String&gt; suffixes(String s) {
    int numSuffixes = Math.min(s.length(), MAX_SUFFIX_LENGTH);
    if (numSuffixes &lt;= 0) {
      return Collections.emptyList();
    }
    if (numSuffixes == 1) {
      return Collections.singletonList(s);
    }
    List&lt;String&gt; result = new ArrayList&lt;String&gt;(numSuffixes);
    for (int i = s.length() - numSuffixes; i &lt; s.length(); ++i) {
      result.add(s.substring(i));
    }
    return result;
  }</pre></div><p class="calibre9">That's a nice<a id="id517" class="calibre1"/> feature set for your named-entity<a id="id518" class="calibre1"/> detector.</p></div></div></body></html>