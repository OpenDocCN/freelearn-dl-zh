- en: '<html:html><html:head><html:title>LlamaIndex: The Hidden Jewel - An Introduction
    to the LlamaIndex Ecosystem</html:title></html:head> <html:body><html:div class="epub-source"><html:h1
    id="_idParaDest-25">LlamaIndex: The Hidden Jewel - An Introduction to the LlamaIndex
    Ecosystem</html:h1> <html:div id="_idContainer023"><html:p>Now that <html:a id="_idIndexMarker033"></html:a>you’ve
    got a solid understanding of what <html:strong class="bold">large language models</html:strong>
    ( <html:strong class="bold">LLMs</html:strong> ) are and what they can (and cannot)
    do. It’s time to discover how <html:strong class="bold">LlamaIndex</html:strong>
    can take <html:a id="_idIndexMarker034"></html:a>your interactive AI applications
    to the <html:a id="_idIndexMarker035"></html:a>next level. We’ll explore how <html:strong
    class="bold">retrieval-augmented generation</html:strong> ( <html:strong class="bold">RAG</html:strong>
    ) using LlamaIndex can provide the missing link between the vast knowledge of
    LLMs and your <html:span class="No-Break">proprietary data.</html:span></html:p>
    <html:p>In this chapter, we will cover the following <html:span class="No-Break">main
    topics:</html:span></html:p> <html:ul><html:li>Optimizing language models – The
    symbiosis of fine-tuning, RAG, <html:span class="No-Break">and LlamaIndex</html:span></html:li>
    <html:li>Discovering <html:a id="_idIndexMarker036"></html:a>the advantages of
    progressively <html:span class="No-Break">disclosing complexity</html:span></html:li>
    <html:li>Introducing <html:strong class="bold">personalized intelligent tutoring
    system</html:strong> ( <html:strong class="bold">PITS</html:strong> ) – our hands-on
    <html:span class="No-Break">LlamaIndex project</html:span></html:li> <html:li>Preparing
    our <html:span class="No-Break">coding environment</html:span></html:li> <html:li>Familiarizing
    ourselves with the structure of the LlamaIndex <html:span class="No-Break">code
    repository</html:span></html:li></html:ul> <html:a id="_idTextAnchor025"></html:a></html:div></html:div></html:body></html:html><html:html><html:head><html:title>Technical
    requirements</html:title></html:head> <html:body><html:div class="epub-source"><html:h1
    id="_idParaDest-26">Technical requirements</html:h1> <html:div id="_idContainer023"><html:p>The
    following elements will be required for <html:span class="No-Break">this chapter:</html:span></html:p>
    <html:ul><html:li><html:em class="italic">Python</html:em> <html:span class="No-Break"><html:em
    class="italic">3.11</html:em></html:span> <html:span class="No-Break">(</html:span>
    <html:a><html:span class="No-Break">https://www.python.org/</html:span></html:a>
    <html:span class="No-Break">)</html:span></html:li> <html:li><html:span class="No-Break"><html:em
    class="italic">Git</html:em></html:span> <html:span class="No-Break">(</html:span>
    <html:a><html:span class="No-Break">https://git-scm.com/</html:span></html:a>
    <html:span class="No-Break">)</html:span></html:li> <html:li><html:span class="No-Break"><html:em
    class="italic">LlamaIndex</html:em></html:span> <html:span class="No-Break">(</html:span>
    <html:a><html:span class="No-Break">https://github.com/run-llama/llama_index</html:span></html:a>
    <html:span class="No-Break">)</html:span></html:li> <html:li><html:em class="italic">OpenAI
    account</html:em> and an <html:span class="No-Break"><html:em class="italic">API
    key</html:em></html:span></html:li> <html:li><html:span class="No-Break"><html:em
    class="italic">Streamlit</html:em></html:span> <html:span class="No-Break">(</html:span>
    <html:a><html:span class="No-Break">https://github.com/streamlit/streamlit</html:span></html:a>
    <html:span class="No-Break">)</html:span></html:li> <html:li><html:span class="No-Break"><html:em
    class="italic">PyPDF</html:em></html:span> <html:span class="No-Break">(</html:span>
    <html:a><html:span class="No-Break">https://pypi.org/project/pypdf/</html:span></html:a>
    <html:span class="No-Break">)</html:span></html:li> <html:li><html:span class="No-Break"><html:em
    class="italic">DOC2Txt</html:em></html:span> <html:span class="No-Break">(</html:span>
    <html:a><html:span class="No-Break">https://github.com/ankushshah89/python-docx2txt/blob/master/docx2txt/docx2txt.py</html:span></html:a>
    <html:span class="No-Break">)</html:span></html:li></html:ul> <html:p>All the
    sample code snippets presented throughout this book as well as the entire project
    code base can be found in this GitHub <html:span class="No-Break">repository:</html:span>
    <html:a><html:span class="No-Break">https://github.com/PacktPublishing/Building-Data-Driven-Applications-with-LlamaIndex</html:span></html:a>
    <html:span class="No-Break">.</html:span></html:p> <html:a id="_idTextAnchor026"></html:a></html:div></html:div></html:body></html:html><html:html><html:head><html:title>Optimizing
    language models – the symbiosis of fine-tuning, RAG, and LlamaIndex</html:title></html:head>
    <html:body><html:div class="epub-source"><html:h1 id="_idParaDest-27">Optimizing
    language models – the symbiosis of fine-tuning, RAG, and LlamaIndex</html:h1>
    <html:div id="_idContainer023"><html:p>In the previous chapter, we saw that vanilla
    LLMs have some limitations right outside of the box. Their <html:a id="_idIndexMarker037"></html:a>knowledge
    is static and they occasionally spit out nonsense. We also learned about RAG as
    a potential way to mitigate <html:a id="_idIndexMarker038"></html:a>these issues.
    Blending <html:strong class="bold">prompt engineering</html:strong> techniques
    with programmatic methods, RAG can elegantly solve many of the <html:span class="No-Break">LLM
    shortcomings.</html:span></html:p> <html:p class="callout-heading">What is prompt
    engineering?</html:p> <html:p class="callout">Prompt <html:a id="_idIndexMarker039"></html:a>engineering
    involves crafting text inputs designed to be effectively processed by a <html:strong
    class="bold">generative AI</html:strong> ( <html:strong class="bold">GenAI</html:strong>
    ) model. Composed in natural language, these prompts describe the specific tasks
    to be carried out by the AI. We’ll have a much deeper conversation on this topic
    during <html:a><html:span class="No-Break"><html:em class="italic">Chapter 10</html:em></html:span></html:a>
    , <html:em class="italic">Prompt Engineering Guidelines and</html:em> <html:span
    class="No-Break"><html:em class="italic">Best Practices</html:em></html:span>
    <html:span class="No-Break">.</html:span></html:p> <html:a id="_idTextAnchor027"></html:a><html:h2
    id="_idParaDest-28">Is RAG the only possible solution?</html:h2> <html:p>Of course
    not. Another approach is to fine-tune the AI model, which involves additional
    training on <html:a id="_idIndexMarker040"></html:a>proprietary data to adapt
    the LLM and embed new data. It takes a model that is pre-trained on a general
    collection of data and continues its training on a more specialized dataset. This
    specialized dataset can be tailored to a particular domain, language, or set of
    tasks that you are interested in. The result is a model that maintains its broad
    knowledge base while gaining expertise in a <html:span class="No-Break">specific
    area.</html:span></html:p> <html:p>Take a look at <html:span class="No-Break"><html:em
    class="italic">Figure 2</html:em></html:span> <html:em class="italic">.1</html:em>
    for a graphical explanation of <html:span class="No-Break">the process.</html:span></html:p>
    <html:p class="IMG---Caption" lang="en-US">Figure 2.1 – An illustration of the
    LLM fine-tuning process</html:p> <html:p>Fine-tuning can improve performance but
    has drawbacks, such as being expensive, requiring large datasets, and being difficult
    to update with fresh information. It also has the disadvantage of permanently
    altering the original AI model, which makes it inappropriate for personalizing
    purposes. Think of the original AI model as a classic recipe for a beloved dish.
    Fine-tuning this model is akin to modifying the traditional recipe to suit specific
    tastes or requirements. While these changes can make the dish more suitable for
    some, they also fundamentally alter the <html:span class="No-Break">original recipe.</html:span></html:p>
    <html:p class="callout-heading">Note</html:p> <html:p class="callout">Not all
    <html:a id="_idIndexMarker041"></html:a>fine-tuning methods permanently alter
    the base AI model. Take <html:strong class="bold">Low-Rank Adaptation</html:strong>
    ( <html:strong class="bold">LoRA</html:strong> ) for example. LoRA is a fine-tuning
    method for LLMs that offers a more efficient approach compared to traditional
    <html:strong class="bold">full fine-tuning</html:strong> . In full fine-tuning,
    all <html:a id="_idIndexMarker042"></html:a>layers of a neural network are optimized,
    which, while effective, is resource-intensive and time-consuming. LoRA, on the
    other hand, involves fine-tuning only two smaller matrices that approximate the
    larger weight matrix of the pre-trained LLM. In the LoRA method, the original
    weights of the model are <html:em class="italic">frozen</html:em> , meaning they
    are not directly updated during the fine-tuning process. The changes to the model’s
    behavior are achieved by the addition of these low-rank matrices. This approach
    allows for the original model to be preserved, while still enabling it to be adapted
    for new tasks or improved performance. You can find more information on this method
    <html:span class="No-Break">here:</html:span> <html:a><html:span class="No-Break">https://ar5iv.labs.arxiv.org/html/2106.09685</html:span></html:a>
    <html:span class="No-Break">.</html:span></html:p> <html:p>Even though LoRA is
    more efficient in terms of memory usage compared to full fine-tuning, it still
    requires computational resources and expertise to implement and optimize effectively,
    which might be a barrier for some users. Using fine-tuning to create a more personalized
    experience for a large number of different users requires re-running the tuning
    process for every user, which is definitely <html:span class="No-Break">not cost-effective.</html:span></html:p>
    <html:p>I’m not trying to say that RAG is a better alternative to LLM fine-tuning.
    In fact, RAG and fine-tuning are complementary techniques that are often used
    together. However, to rapidly incorporating changing data and personalization,
    RAG <html:span class="No-Break">is preferable.</html:span></html:p> <html:a id="_idTextAnchor028"></html:a><html:h2
    id="_idParaDest-29">What LlamaIndex does</html:h2> <html:p>With LlamaIndex, you
    can rapidly create <html:em class="italic">smart</html:em> LLMs that can adapt
    to your specific use case. Instead <html:a id="_idIndexMarker043"></html:a>of
    relying only on their generic pre-trained knowledge, you can inject targeted information
    so that they give you accurate, relevant answers. It provides an easy way to connect
    external datasets to LLMs such as GPT-4, Claude, and Llama. LlamaIndex builds
    a bridge between your custom knowledge and the vast capabilities <html:span class="No-Break">of
    LLMs.</html:span></html:p> <html:p class="callout-heading">Note</html:p> <html:p
    class="callout">Created in 2022 by Princeton University graduate and entrepreneur
    Jerry Liu, the <html:em class="italic">LlamaIndex framework</html:em> has quickly
    become very popular in the developer community. LlamaIndex allows you to take
    advantage of the computational power and language understanding capabilities of
    LLMs while focusing their responses on specific, reliable data. This unique combination
    enables businesses and individuals to get the most out of their AI investments,
    as they can use the same underlying technology for a wide array of <html:span
    class="No-Break">specialized applications.</html:span></html:p> <html:p>For example,
    you could index a collection of your company’s documents. Then, when you ask questions
    related to your business, the LLM augmented with LlamaIndex provides responses
    based on real data rather than just making up <html:span class="No-Break">vague
    answers!</html:span></html:p> <html:p>The result is that <html:a id="_idIndexMarker044"></html:a>you
    get all the expressive power of LLMs while greatly reducing the amount of incorrect
    or irrelevant information. LlamaIndex guides the LLM to pull from trusted sources
    you provide, and these sources could contain both <html:em class="italic">structured</html:em>
    and <html:em class="italic">unstructured</html:em> data. In fact, as we will see
    in the next chapters, the framework can ingest data from pretty much <html:em
    class="italic">any</html:em> data source available. That’s pretty <html:span class="No-Break">cool,
    right?</html:span></html:p> <html:p>If you are not already thinking about the
    many possible uses for this framework, let me give you some quick ideas. With
    LlamaIndex, you could do <html:span class="No-Break">the following:</html:span></html:p>
    <html:ul><html:li><html:strong class="bold">Build a search engine for your document
    collection</html:strong> : One of its most powerful applications is the ability
    to index all your documents – they could be PDFs, Word files, Notion documents,
    GitHub repos, or other formats. Once indexed, you can query the LLM to search
    for specific information, making it a powerful search engine tailored specifically
    for <html:span class="No-Break">your resources</html:span></html:li> <html:li><html:strong
    class="bold">Create a company chatbot with customized knowledge</html:strong>
    : If your business has specific jargon, policies, or expertise, you can make the
    LLM <html:em class="italic">understand</html:em> these nuances. The chatbot could
    then handle a range of queries, from basic customer service questions to more
    specialized interactions that would typically require <html:span class="No-Break">human
    expertise</html:span></html:li> <html:li><html:strong class="bold">Generate summaries
    of large reports or papers</html:strong> : If your organization deals with lengthy
    documents or reports, LlamaIndex can be used to feed the LLM with their contents.
    Then, you can ask the LLM to generate concise summaries, capturing the most <html:span
    class="No-Break">important points</html:span></html:li> <html:li><html:strong
    class="bold">Develop a smart assistant for complex workflows</html:strong> : By
    training the LLM on the nuances of multi-step tasks or procedures unique to your
    organization, you can transform it into a smart assistant data agent that provides
    valuable insights <html:span class="No-Break">and guidance</html:span></html:li></html:ul>
    <html:p>And these are just the tip of <html:span class="No-Break">the iceberg.</html:span></html:p>
    <html:p>In addition, <html:span class="No-Break"><html:em class="italic">Figure
    2</html:em></html:span> <html:em class="italic">.2</html:em> shows how implementing
    smart RAG strategies can offset some of the costs <html:a id="_idIndexMarker045"></html:a>associated
    with fine-tuning the model on a <html:span class="No-Break">specific domain.</html:span></html:p>
    <html:p class="IMG---Caption" lang="en-US">Figure 2.2 – The relative costs of
    updating data in a pre-trained LLM</html:p> <html:p>Before we dive deeper into
    the applications and use cases of the LlamaIndex framework, let’s talk a bit about
    the architecture and the design principles <html:span class="No-Break">behind
    it!</html:span></html:p> <html:a id="_idTextAnchor029"></html:a></html:div></html:div></html:body></html:html><html:html><html:head><html:title>Discovering
    the advantages of progressively disclosing complexity</html:title></html:head>
    <html:body><html:div class="epub-source"><html:h1 id="_idParaDest-30">Discovering
    the advantages of progressively disclosing complexity</html:h1> <html:div id="_idContainer023">from
    llama_index.core import VectorStoreIndex, SimpleDirectoryReader documents = SimpleDirectoryReader(''files'').load_data()
    index = VectorStoreIndex.from_documents(documents) query_engine = index.as_query_engine()
    response = query_engine.query(     "summarize each document in a few sentences"
    ) print(response) <html:p>The creator of LlamaIndex wanted to make it accessible
    to everyone – from beginners just getting <html:a id="_idIndexMarker046"></html:a>started
    with LLMs all the way to expert developers building complex systems. That’s why
    LlamaIndex uses a design <html:a id="_idIndexMarker047"></html:a>principle called
    <html:strong class="bold">progressive disclosure of complexity</html:strong> .
    Don’t worry about the fancy name – it just means that the framework starts simple
    and gradually reveals more advanced features when you <html:span class="No-Break">need
    them.</html:span></html:p> <html:p>When you first use LlamaIndex, it feels like
    magic! With just a few lines of code, you can connect data and start querying
    the LLM. Under the hood, LlamaIndex converts the data into an efficient index
    that the LLM <html:span class="No-Break">can use.</html:span></html:p> <html:p>Have
    a look at this very simple example that first loads a set of text documents from
    a local directory. It then builds an index over the documents and queries that
    index to get a summarized view of the documents based on a natural <html:span
    class="No-Break">language query:</html:span></html:p> <html:p>It’s that <html:a
    id="_idIndexMarker048"></html:a>simple. Just six lines <html:span class="No-Break">of
    code!</html:span></html:p> <html:p class="callout-heading">Note</html:p> <html:p
    class="callout">Don’t try to run the code just yet. It’s more for illustration
    purposes. There is a bit of environmental preparation we need to handle before
    that. Don’t worry, we’ll cover that a bit later in this chapter and then you’ll
    be ready <html:span class="No-Break">to go.</html:span></html:p> <html:p>As you
    use LlamaIndex more, you will uncover its more powerful capabilities. There are
    plenty of parameters you can tweak. You can select specialized index structures
    optimized for different uses, carry out detailed cost analyses for different prompt
    strategies, customize query algorithms, and <html:span class="No-Break">much more.</html:span></html:p>
    <html:p>But LlamaIndex always starts you off gently before getting into more detailed
    workings, and for quick and simple projects, you don’t need to go much deeper
    than that. This way, both beginners and experts can benefit from its versatility
    <html:span class="No-Break">and capabilities.</html:span></html:p> <html:p>Now,
    let’s go on a quick tour of our hands-on project and then start prepping for the
    fun part: writing <html:span class="No-Break">the code.</html:span></html:p> <html:a
    id="_idTextAnchor030"></html:a><html:h2 id="_idParaDest-31">An important aspect
    to consider</html:h2> <html:p>As you go further through this book, and you will
    most likely want to experiment based on the <html:a id="_idIndexMarker049"></html:a>examples
    it gives, you need to keep one very important point in mind. By default, the LlamaIndex
    framework is configured to use AI models provided by OpenAI. Although these models
    are extremely powerful and versatile, they incur costs. Many of the LlamaIndex
    functionalities presented in this book, be it metadata extraction, indexing, retrieval,
    or response synthesis, are based on either LLMs or embedding models. I have tried
    to use as simple examples as possible with small sample datasets in an attempt
    to limit these costs as much <html:span class="No-Break">as possible.</html:span></html:p>
    <html:p class="callout-heading">Note</html:p> <html:p class="callout">I strongly
    advise you to keep a close eye on the OpenAI API consumption. In case you don’t
    already have it, the link where you can monitor the API usage is here: <html:a>https://platform.openai.com/usage</html:a>
    . I also advise you to be careful from a privacy perspective. These issues are
    discussed in more detail in <html:em class="italic">Chapters 4</html:em> <html:span
    class="No-Break">and</html:span> <html:span class="No-Break"><html:em class="italic">5</html:em></html:span>
    <html:span class="No-Break">.</html:span></html:p> <html:p>Alternatively, if you
    want to avoid both the costs of using an external LLM and the potential privacy
    risks, you can apply the methods described in <html:a><html:span class="No-Break"><html:em
    class="italic">Chapter 9</html:em></html:span></html:a> , <html:em class="italic">Customizing
    and Deploying Our LlamaIndex Project</html:em> . It is important to note, however,
    that all examples provided in the book are written and tested using the default
    models provided by OpenAI. There is a (quite likely) possibility that some examples
    may not work as well – or at all – running on locally <html:span class="No-Break">hosted
    alternatives.</html:span></html:p> <html:a id="_idTextAnchor031"></html:a></html:div></html:div></html:body></html:html><html:html><html:head><html:title>Introducing
    PITS – our LlamaIndex hands-on project</html:title></html:head> <html:body><html:div
    class="epub-source"><html:h1 id="_idParaDest-32">Introducing PITS – our LlamaIndex
    hands-on project</html:h1> <html:div id="_idContainer023"><html:p><html:em class="italic">Nothing
    beats learning</html:em> <html:span class="No-Break"><html:em class="italic">by
    doing</html:em></html:span> <html:span class="No-Break">.</html:span></html:p>
    <html:p>So, I’ve <html:a id="_idIndexMarker050"></html:a>cooked up a fun and useful
    project for us to start <html:span class="No-Break">using LlamaIndex!</html:span></html:p>
    <html:p>Here, we will introduce PITS. Wouldn’t it be cool to have an AI tutor
    that helps you learn new concepts interactively? Well, we’re going to build <html:span
    class="No-Break">one together!</html:span></html:p> <html:a id="_idTextAnchor032"></html:a><html:h2
    id="_idParaDest-33">Here’s how it will work</html:h2> <html:p>First, you will
    introduce yourself to PITS. You’ll have the chance to describe the topic you want
    to learn about and specify any personal learning preferences you <html:span class="No-Break">may
    have.</html:span></html:p> <html:p>Then, you will <html:a id="_idIndexMarker051"></html:a>be
    able to upload any existing study materials you may have on the topic. PITS will
    accept and ingest any PDFs, Word documents, or text files you <html:span class="No-Break">may
    provide.</html:span></html:p> <html:p>Based on the documents provided, the tutor
    will first build a quiz. You’ll have the option to complete the quiz. That way,
    the tutor will be able to gauge your current knowledge of the topic and adjust
    the <html:span class="No-Break">learning experience.</html:span></html:p> <html:p>Our
    nifty tutor will then build learning material for you. This will consist of slides
    and narration for each slide. The training material will be divided <html:span
    class="No-Break">into chapters.</html:span></html:p> <html:p>Then, your learning
    journey begins. During each learning session, PITS you will advance through the
    chapters, presenting each topic in your preferred style and adapting to your <html:span
    class="No-Break">knowledge level.</html:span></html:p> <html:p>After each concept
    is explained, you’ll have a chance to ask for more explanations or examples to
    learn more about the topic. It will answer your questions, create quizzes, explain
    concepts, and adapt responses based on <html:span class="No-Break">your needs.</html:span></html:p>
    <html:p>The best part is that your entire conversation with the agent will be
    recorded. It will remember both your questions and its own answers so it won’t
    repeat itself or lose the <html:span class="No-Break">conversation context.</html:span></html:p>
    <html:p>Too tired to continue in one session? Not a problem. When you’re ready
    to start another lesson, it will just resume from where you left off and give
    you a summary of the <html:span class="No-Break">previous discussion.</html:span></html:p>
    <html:p>But, hey! They say a picture’s worth a thousand <html:span class="No-Break">words,
    right?</html:span></html:p> <html:p>You’ll find an overview in <html:span class="No-Break"><html:em
    class="italic">Figure 2</html:em></html:span> <html:span class="No-Break"><html:em
    class="italic">.3</html:em></html:span> <html:span class="No-Break">.</html:span></html:p>
    <html:p class="IMG---Caption" lang="en-US">Figure 2.3 – An overview of the PITS
    workflow</html:p> <html:p>It doesn’t <html:a id="_idIndexMarker052"></html:a>really
    get more customized than this. This is the ultimate <html:span class="No-Break">learning
    experience.</html:span></html:p> <html:p>As you can imagine, PITS needs to be
    smart on several fronts. It needs to be able to do <html:span class="No-Break">the
    following:</html:span></html:p> <html:ul><html:li>Understand and index the study
    materials <html:span class="No-Break">we provide</html:span></html:li> <html:li>Converse
    fluently with users and retain <html:span class="No-Break">the context</html:span></html:li>
    <html:li>Teach effectively based on the <html:span class="No-Break">indexed knowledge</html:span></html:li></html:ul>
    <html:p>LlamaIndex will help with the first part by ingesting the study material.
    The user will be able to upload any relevant training material such as manuals,
    slides or even student notes, and <html:span class="No-Break">sample questions.</html:span></html:p>
    <html:p>For the second part, we’ll mostly use the capabilities of GPT-4 to power
    the actual <html:span class="No-Break">teaching interactions.</html:span></html:p>
    <html:p>However, the foundation will be the knowledge augmentation capabilities
    of LlamaIndex. Pretty neat, right? We’ll have a personally <html:span class="No-Break">customized
    tutor!</html:span></html:p> <html:p class="callout-heading">Note</html:p> <html:p
    class="callout">I’m not sure whether you’ve read my biography, but I work as a
    trainer. The moment I first learned of the power of GenAI and discovered GPT-3,
    I knew exactly that a few years <html:a id="_idIndexMarker053"></html:a>from now,
    systems such as PITS would emerge sooner or later. I was thrilled about their
    potential to provide free, quality education to people around the world, regardless
    of their location, background, or financial status. Later, when I discovered RAG
    and tools such as LlamaIndex, I became convinced that they would appear rather
    sooner <html:span class="No-Break">than later.</html:span></html:p> <html:p>Okay,
    enough daydreaming – let’s start setting up <html:span class="No-Break">the pieces.</html:span></html:p>
    <html:a id="_idTextAnchor033"></html:a></html:div></html:div></html:body></html:html><html:html><html:head><html:title>Preparing
    our coding environment</html:title></html:head> <html:body><html:div class="epub-source"><html:h1
    id="_idParaDest-34">Preparing our coding environment</html:h1> <html:div id="_idContainer023">pip
    install llama-index pip install streamlit pip install pypdf pip install docx2txt
    python --version git --version pip show llama-index echo %OPENAI_API_KEY% pip
    show streamlit pip show pypdf pip show docx2txt python sample1.py <html:p>Before
    we embark on the LlamaIndex coding journey, it’s essential to set up our development
    <html:a id="_idIndexMarker054"></html:a>environment properly. This setup is the
    first step toward ensuring that we can smoothly run through the examples and exercises
    I’ve prepared <html:span class="No-Break">for you.</html:span></html:p> <html:p
    class="callout-heading">Note</html:p> <html:p class="callout">To maintain simplicity
    and ensure consistency across all examples, I’ve designed the sample code to be
    run in a local Python environment. I’m aware that many of you are fond of using
    web-based coding environments such as Google Colab and Jupyter Notebooks for your
    coding projects, so I kindly ask for your understanding if these examples do not
    directly translate to or run in these platforms. My goal was to keep our setup
    straightforward, allowing us to focus on the learning experience without compatibility
    concerns. Thank you for your understanding and <html:span class="No-Break">happy
    coding!</html:span></html:p> <html:p>Let’s quickly get our computer set up for
    some cool <html:span class="No-Break">LlamaIndex coding.</html:span></html:p>
    <html:a id="_idTextAnchor034"></html:a><html:h2 id="_idParaDest-35">Installing
    Python</html:h2> <html:p>You’ll need a Python 3.7+ environment. I recommend Python
    3.11 <html:span class="No-Break">if possible.</html:span></html:p> <html:p>If
    you don’t <html:a id="_idIndexMarker055"></html:a>have Python, install it from
    <html:a>https://www.python.org</html:a> . If you already have an older version,
    you can upgrade or install a newer Python version side <html:span class="No-Break">by
    side.</html:span></html:p> <html:p>For a coding <html:a id="_idIndexMarker056"></html:a>environment,
    my personal preference is <html:strong class="bold">NotePad++</html:strong> (
    <html:a>https://notepad-plus-plus.org/</html:a> ), which is not quite an IDE but
    is very fast. However, you can <html:a id="_idIndexMarker057"></html:a>also use
    Microsoft’s <html:strong class="bold">VSCode</html:strong> ( <html:a>https://code.visualstudio.com/</html:a>
    ), <html:strong class="bold">PyCharm</html:strong> ( <html:a>https://www.jetbrains.com/pycharm/</html:a>
    ), or <html:a id="_idIndexMarker058"></html:a>anything else <html:span class="No-Break">you
    prefer.</html:span></html:p> <html:a id="_idTextAnchor035"></html:a><html:h2 id="_idParaDest-36">Installing
    Git</html:h2> <html:p>Before we proceed, it’s important to have Git installed.
    Git is a version control system that lets you <html:a id="_idIndexMarker059"></html:a>manage
    changes to your code and collaborate with others. It’s <html:a id="_idIndexMarker060"></html:a>also
    essential for cloning code repositories, like the one we’ll be using in <html:span
    class="No-Break">this book.</html:span></html:p> <html:p>Head over <html:a id="_idIndexMarker061"></html:a>to
    the official Git website ( <html:a>https://git-scm.com/book/en/v2/Getting-Started-Installing-Git</html:a>
    ) and download the installer for your <html:span class="No-Break">operating system.</html:span></html:p>
    <html:p>Follow the installation steps, and you should have Git up and running
    in <html:span class="No-Break">no time.</html:span></html:p> <html:p>All the sample
    code snippets presented throughout the book as well as the entire project code
    base can be found in this GitHub <html:span class="No-Break">repository:</html:span>
    <html:a><html:span class="No-Break">https://github.com/PacktPublishing/Building-Data-Driven-Applications-with-LlamaIndex</html:span></html:a>
    <html:span class="No-Break">.</html:span></html:p> <html:p>So, if you want to
    download the project files locally, once you have finished installing Git, you
    can simply follow <html:span class="No-Break">these steps:</html:span></html:p>
    <html:ol><html:li><html:strong class="bold">Navigate to the desired directory</html:strong>
    : Open a new command prompt or terminal window. Use the <html:code class="literal">cd</html:code>
    command to navigate to the directory where you’d like to store the project. Here
    is <html:span class="No-Break">an example:</html:span></html:li> <html:li><html:strong
    class="bold">Clone the repository</html:strong> : Run the following command to
    clone the <html:span class="No-Break">GitHub repository:</html:span> <html:p class="list-inset">This
    will download a copy of the project to your <html:span class="No-Break">local
    machine.</html:span></html:p></html:li> <html:li><html:strong class="bold">Enter
    the project directory</html:strong> : Navigate into the newly created <html:span
    class="No-Break">project folder:</html:span> <html:p class="list-inset">As we
    move forward with our project, you have <html:span class="No-Break">two options:</html:span></html:p>
    <html:ul><html:li>You can either write the code on your own and then compare it
    with what’s in <html:span class="No-Break">the repository</html:span></html:li>
    <html:li>Or you can directly explore the code files in the repository to get a
    better understanding of the <html:span class="No-Break">code structure</html:span></html:li></html:ul></html:li></html:ol>
    <html:p>If you <html:a id="_idIndexMarker062"></html:a>correctly performed all
    of the preceding steps, listing the <html:a id="_idIndexMarker063"></html:a>contents
    of the current folder should return several subfolders called <html:code class="literal">chX</html:code>
    – where <html:code class="literal">X</html:code> is the chapter number, and a
    separate subfolder called <html:code class="literal">PITS_APP</html:code> . The
    chapter folders contain all sample source files corresponding to each chapter.
    The <html:code class="literal">PITS_APP</html:code> folder contains the source
    code for our <html:span class="No-Break">main project.</html:span></html:p> <html:a
    id="_idTextAnchor036"></html:a><html:h2 id="_idParaDest-37">Installing LlamaIndex</html:h2>
    <html:p>Next, let’s <html:a id="_idIndexMarker064"></html:a>get the LlamaIndex
    library installed. At your command <html:a id="_idIndexMarker065"></html:a>prompt,
    run <html:span class="No-Break">the following:</html:span></html:p> <html:p>This
    will include a LlamaIndex package that contains the core LlamaIndex components
    as well as a selection of useful integrations. For the most efficient deployment
    possible, there is also the option of installing just the minimum core components
    and only the necessary integrations, but for the purpose of this book, the presented
    option will do <html:span class="No-Break">just fine.</html:span></html:p> <html:p
    class="callout-heading">Note</html:p> <html:p class="callout">In case you’re already
    running a version older than v0.10, it is recommended that you start with <html:a
    id="_idIndexMarker066"></html:a>a fresh install in a virtual environment to avoid
    any <html:a id="_idIndexMarker067"></html:a>conflicts with the legacy version.
    You can find detailed instructions <html:span class="No-Break">here:</html:span>
    <html:a><html:span class="No-Break">https://pretty-sodium-5e0.notion.site/v0-10-0-Migration-Guide-6ede431dcb8841b09ea171e7f133bd77</html:span></html:a>
    <html:span class="No-Break">.</html:span></html:p> <html:p>We’re now ready to
    import and start <html:span class="No-Break">using it.</html:span></html:p> <html:a
    id="_idTextAnchor037"></html:a><html:h2 id="_idParaDest-38">Signing up for an
    OpenAI API key</html:h2> <html:p>Since we’ll <html:a id="_idIndexMarker068"></html:a>be
    using OpenAI’s GPT models <html:a id="_idIndexMarker069"></html:a>via LlamaIndex,
    you’ll need an API key to authenticate. Head to <html:a>https://platform.openai.com</html:a>
    and sign up. Once logged in, you can create <html:a id="_idIndexMarker070"></html:a>a
    new secret API key. Make sure to keep <html:span class="No-Break">it safe!</html:span></html:p>
    <html:p>LlamaIndex will use this key every time it interacts with OpenAI’s models.
    Because it has to be kept secret, it’s a good idea to store it in an environment
    variable on your <html:span class="No-Break">local machine.</html:span></html:p>
    <html:h3>A short guide for Windows users</html:h3> <html:p>On <html:a id="_idIndexMarker071"></html:a>Windows,
    you can accomplish that by following <html:span class="No-Break">these steps:</html:span></html:p>
    <html:ol><html:li>Open <html:strong class="bold">Environment Variables</html:strong>
    : Open the Start menu and search for <html:strong class="bold">Environment Variables</html:strong>
    or right-click on <html:strong class="bold">This PC</html:strong> or <html:strong
    class="bold">My Computer</html:strong> and <html:span class="No-Break">select</html:span>
    <html:span class="No-Break"><html:strong class="bold">Properties</html:strong></html:span>
    <html:span class="No-Break">.</html:span></html:li> <html:li>Then, click on <html:strong
    class="bold">Advanced system settings</html:strong> followed by the <html:strong
    class="bold">Environment Variables</html:strong> button in the <html:strong class="bold">Advanced</html:strong>
    tab as shown in <html:span class="No-Break"><html:em class="italic">Figure 2</html:em></html:span>
    <html:span class="No-Break"><html:em class="italic">.4:</html:em></html:span></html:li></html:ol>
    <html:p class="IMG---Caption" lang="en-US">Figure 2.4 – Editing Windows environment
    variables</html:p> <html:ol><html:li><html:strong class="bold">Create a new environment
    variable</html:strong> : In the <html:strong class="bold">Environment Variables</html:strong>
    window, under <html:a id="_idIndexMarker072"></html:a>the <html:strong class="bold">User
    variables</html:strong> section, click the <html:span class="No-Break"><html:strong
    class="bold">New</html:strong></html:span> <html:span class="No-Break">button.</html:span></html:li>
    <html:li><html:strong class="bold">Enter the variable details</html:strong> :
    For the <html:strong class="bold">Variable name</html:strong> , enter <html:code
    class="literal">OPENAI_API_KEY</html:code> . For <html:strong class="bold">Variable
    value</html:strong> , paste the secret API key you received from OpenAI. See <html:span
    class="No-Break"><html:em class="italic">Figure 2</html:em></html:span> <html:em
    class="italic">.5</html:em> for <html:span class="No-Break">an illustration.</html:span></html:li></html:ol>
    <html:p class="IMG---Caption" lang="en-US">Figure 2.5 – Creating the OPENAI_API_KEY
    environment variable</html:p> <html:ol><html:li><html:strong class="bold">Confirm
    and apply</html:strong> : Click <html:strong class="bold">OK</html:strong> to
    close all of the dialog boxes. You will need to restart <html:a id="_idIndexMarker073"></html:a>your
    computer for the changes to <html:span class="No-Break">take effect.</html:span></html:li>
    <html:li><html:strong class="bold">Verify the environment variable</html:strong>
    : To ensure the variable is set correctly, open a new command prompt, and run
    <html:span class="No-Break">the following:</html:span></html:li></html:ol> <html:p>This
    should display the API key you <html:span class="No-Break">just stored.</html:span></html:p>
    <html:h3>A short guide for Linux/Mac users</html:h3> <html:p>On Linux/Mac, you
    can accomplish Signing up for an OpenAI API key by following <html:span class="No-Break">these
    steps:</html:span></html:p> <html:ol><html:li>Run the following command in your
    terminal, replacing <html:code class="literal"><yourkey></html:code> with your
    <html:span class="No-Break">API key:</html:span></html:li> <html:li>Update <html:a
    id="_idIndexMarker074"></html:a>the shell with the <html:span class="No-Break">new
    variable:</html:span></html:li> <html:li>Make sure <html:a id="_idIndexMarker075"></html:a>that
    you have set your environment variable with the <html:span class="No-Break">following
    command:</html:span> <html:p class="list-inset">Your OpenAI API key is now securely
    stored in an environment variable and can be easily accessed by LlamaIndex when
    needed, without exposing it in your code <html:span class="No-Break">or system.</html:span></html:p></html:li></html:ol>
    <html:p class="callout-heading">Note</html:p> <html:p class="callout">While OpenAI
    provides a free trial option for their GPT models through their API, you’ll only
    receive a limited number of free credits. Currently, the free credit is limited
    to $5 and expires after 3 months. That should be more than enough to experiment
    for the purpose of our project and for reading the book. However, If you wish
    to get serious about building LLM-based applications, you’ll have to sign up for
    a paid account on their platform. Alternatively, you can always choose to use
    another AI model for LlamaIndex. We will discuss customizing the AI model in more
    detail in <html:a><html:span class="No-Break"><html:em class="italic">Chapter
    10</html:em></html:span></html:a> <html:em class="italic">, Prompt Engineering
    Guidelines and</html:em> <html:span class="No-Break"><html:em class="italic">Best
    Practices</html:em></html:span> <html:span class="No-Break">.</html:span></html:p>
    <html:p>OK. The backend is all set up. Let’s talk about the rest of <html:span
    class="No-Break">the stack.</html:span></html:p> <html:a id="_idTextAnchor038"></html:a><html:h2
    id="_idParaDest-39">Discovering Streamlit – the perfect tool for rapid building
    and deployment!</html:h2> <html:p>Before we <html:a id="_idIndexMarker076"></html:a>can
    build cool apps such as PITS, we need <html:a id="_idIndexMarker077"></html:a>somewhere
    to … well, build and run them! That’s where Streamlit comes in. Streamlit is an
    awesome open-source Python library that makes it super easy to create and deploy
    web apps <html:span class="No-Break">and dashboards.</html:span></html:p> <html:p>With
    just a few lines of Python code, you can build complete web interfaces and see
    the results instantly. The best part is that Streamlit apps can be deployed nearly
    anywhere – on servers, on platforms such as Heroku, or even directly <html:span
    class="No-Break">from GitHub!</html:span></html:p> <html:p>I love Streamlit because
    it lets me focus on the fun stuff – such as creating PITS with LlamaIndex – rather
    than fussing over complex web development. For AI experimentation, <html:span
    class="No-Break">it’s perfect!</html:span></html:p> <html:p>We’ll primarily <html:a
    id="_idIndexMarker078"></html:a>use it to create the interface for uploading study
    guides and interacting with our PITS tutor. For the purpose of the next chapters,
    we’ll be using Streamlit <html:a id="_idIndexMarker079"></html:a>for running and
    testing our app locally. However, in <html:a><html:span class="No-Break"><html:em
    class="italic">Chapter 9</html:em></html:span></html:a> , <html:em class="italic">Customizing
    and Deploying Our LlamaIndex Project</html:em> , we will also discover how we
    can easily deploy our app using <html:strong class="bold">Streamlit Share</html:strong>
    or any other hosting service <html:span class="No-Break">you prefer.</html:span></html:p>
    <html:p>Streamlit has tons of cool capabilities such as data frames, charts, and
    widgets – but don’t worry about learning it all now. As we build up features,
    I’ll explain the relevant parts so you can gain Streamlit skills along <html:span
    class="No-Break">the way!</html:span></html:p> <html:a id="_idTextAnchor039"></html:a><html:h2
    id="_idParaDest-40">Installing Streamlit</html:h2> <html:p>Lastly, we need <html:a
    id="_idIndexMarker080"></html:a>to install the <html:span class="No-Break">Streamlit
    library:</html:span></html:p> <html:p>Great! We <html:a id="_idIndexMarker081"></html:a>have
    our backend tool (LlamaIndex), our frontend layer (Streamlit), and our goal (PITS).
    It’s time for a <html:span class="No-Break">final touch.</html:span></html:p>
    <html:a id="_idTextAnchor040"></html:a><html:h2 id="_idParaDest-41">Finishing
    up</html:h2> <html:p>Because our <html:a id="_idIndexMarker082"></html:a>project
    should be able to ingest PDF and DOCX documents, we will also need to install
    two <html:span class="No-Break">additional libraries:</html:span></html:p> <html:p>That’s
    it! Our environment is <html:span class="No-Break">LlamaIndex ready.</html:span></html:p>
    <html:p>Let’s recap what <html:span class="No-Break">we have:</html:span></html:p>
    <html:ul><html:li><html:span class="No-Break">Python 3.11</html:span></html:li>
    <html:li><html:span class="No-Break">Git</html:span></html:li> <html:li><html:span
    class="No-Break">LlamaIndex package</html:span></html:li> <html:li>OpenAI <html:a
    id="_idIndexMarker083"></html:a>account and an <html:span class="No-Break">API
    key</html:span></html:li> <html:li>Streamlit for <html:span class="No-Break">app
    building</html:span></html:li> <html:li>PyPDF and <html:span class="No-Break">DOC2Txt
    libraries</html:span></html:li></html:ul> <html:a id="_idTextAnchor041"></html:a><html:h2
    id="_idParaDest-42">One final check</html:h2> <html:p>To verify <html:a id="_idIndexMarker084"></html:a>that
    everything was installed correctly, open a new command prompt or terminal window,
    and run the <html:span class="No-Break">following commands:</html:span></html:p>
    <html:p>A simple way to check whether your environment is ready is to try navigating
    into the <html:code class="literal">ch2</html:code> subfolder of your local <html:code
    class="literal">git</html:code> folder and run the file <html:span class="No-Break">called</html:span>
    <html:span class="No-Break"><html:code class="literal">sample1.py</html:code></html:span>
    <html:span class="No-Break">:</html:span></html:p> <html:p>You should get a nice
    summary of the two sample documents provided in the <html:code class="literal">ch2/files</html:code>
    subfolder if everything has been <html:span class="No-Break">properly installed.</html:span></html:p>
    <html:p>If anything is missing, please go back and retake the necessary steps
    before proceeding further. Trust me, you’ll avoid a lot of pain and frustration
    further down <html:span class="No-Break">the line.</html:span></html:p> <html:p>We’re
    all set to start ingesting data, constructing indices with LlamaIndex, and building
    our PITS tutor app! I don’t know about you, but I’m <html:em class="italic">kid-in-a-candy-store</html:em>
    excited to <html:span class="No-Break">start experimenting.</html:span></html:p>
    <html:p>In the next chapters, we’ll get hands-on with our first LlamaIndex program.
    This is where the real fun begins! We’ll explore ingesting data, constructing
    indexes, executing queries, <html:span class="No-Break">and more.</html:span></html:p>
    <html:p>I’ll explain <html:a id="_idIndexMarker085"></html:a>each concept and
    line of code in simple terms along the way. In no time, you’ll be implementing
    the basics like a LlamaIndex pro! Once we’ve got these fundamentals down, we can
    start expanding the capabilities of our <html:span class="No-Break">tutor app.</html:span></html:p>
    <html:p>But first, let’s clarify the overall code structure of the framework’s
    <html:span class="No-Break">GitHub repository.</html:span></html:p> <html:a id="_idTextAnchor042"></html:a></html:div></html:div></html:body></html:html><html:html><html:head><html:title>Familiarizing
    ourselves with the structure of the LlamaIndex code repository</html:title></html:head>
    <html:body><html:div class="epub-source"><html:h1 id="_idParaDest-43">Familiarizing
    ourselves with the structure of the LlamaIndex code repository</html:h1> <html:div
    id="_idContainer023">from llama_index.llms.mistralai import MistralAI pip install
    llama-index.llms.mistralai <html:p>Because you’ll probably spend a lot of time
    browsing the official code repository of the LlamaIndex <html:a id="_idIndexMarker086"></html:a>framework,
    it’s good to have an overall image of its general structure. You can always consult
    the repository <html:span class="No-Break">here:</html:span> <html:a><html:span
    class="No-Break">https://github.com/run-llama/llama_index</html:span></html:a>
    <html:span class="No-Break">.</html:span></html:p> <html:p>Starting with version
    0.10, the code has been thoroughly reorganized into a more modular structure.
    The purpose of this new structure is to improve efficiency, by avoiding loading
    any unnecessary dependencies, while also improving readability and overall user
    experience <html:span class="No-Break">for developers.</html:span></html:p> <html:p><html:span
    class="No-Break"><html:em class="italic">Figure 2</html:em></html:span> <html:em
    class="italic">.6</html:em> describes the main components of the <html:span class="No-Break">code
    structure:</html:span></html:p> <html:p class="IMG---Caption" lang="en-US">Figure
    2.6 – The LlamaIndex GitHub repository code structure</html:p> <html:p>The <html:code
    class="literal">llama-index-core</html:code> folder serves as the foundational
    package for LlamaIndex, enabling developers to install the essential framework
    and then selectively add from over 300 integration packages and different Llama-packs
    to tailor functionality for their specific <html:span class="No-Break">application
    needs.</html:span></html:p> <html:p>The <html:code class="literal">llama-index-integrations</html:code>
    folder of LlamaIndex consists of various add-on packages that extend the functionality
    of the core framework. These allow developers to customize <html:a id="_idIndexMarker087"></html:a>their
    build with specific elements such as custom LLMs, data loaders, embedding models,
    and vector store providers to best fit their application’s requirements. We’ll
    cover some of these integrations later in our book, starting with <html:a><html:span
    class="No-Break"><html:em class="italic">Chapter 4</html:em></html:span></html:a>
    , <html:em class="italic">Ingesting Data into Our</html:em> <html:span class="No-Break"><html:em
    class="italic">RAG Workflow</html:em></html:span> <html:span class="No-Break">.</html:span></html:p>
    <html:p>The <html:code class="literal">llama-index-packs</html:code> folder contains
    more than 50 Llama packs. Developed and constantly improved by the LlamaIndex
    developer community, these packs serve as ready-made templates designed to kickstart
    a user’s application. We’ll talk about them in more detail during <html:a><html:span
    class="No-Break"><html:em class="italic">Chapter 9</html:em></html:span></html:a>
    , <html:em class="italic">Customizing and Deploying Our</html:em> <html:span class="No-Break"><html:em
    class="italic">LlamaIndex Project</html:em></html:span> <html:span class="No-Break">.</html:span></html:p>
    <html:p>The <html:code class="literal">llama-index-cli</html:code> folder is used
    by the LlamaIndex command-line interface, which we will also cover briefly during
    <html:a><html:span class="No-Break"><html:em class="italic">Chapter 9</html:em></html:span></html:a>
    <html:em class="italic">, Customizing and Deploying Our</html:em> <html:span class="No-Break"><html:em
    class="italic">LlamaIndex Project</html:em></html:span> <html:span class="No-Break">.</html:span></html:p>
    <html:p>The last section, called <html:strong class="bold">OTHERS</html:strong>
    in <html:span class="No-Break"><html:em class="italic">Figure 2</html:em></html:span>
    <html:em class="italic">.6</html:em> , consists of two folders that currently
    contain fine-tuning abstractions and some experimental features that we will not
    cover in <html:span class="No-Break">this book.</html:span></html:p> <html:p class="callout-heading">Note</html:p>
    <html:p class="callout">The subfolders in <html:code class="literal">llama-index-integrations</html:code>
    and <html:code class="literal">llama-index-packs</html:code> represent individual
    packages. The folder name corresponds to the package name. For example, the <html:code
    class="literal">llama-index-integrations/llms/llama-index-llms-mistralai</html:code>
    folder corresponds to the <html:code class="literal">llama-index-llms-mistralai</html:code>
    <html:span class="No-Break">PyPI package.</html:span></html:p> <html:p>Following
    this example, there is something you need to do before you import and use the
    <html:code class="literal">mistralai</html:code> package in your code <html:span
    class="No-Break">like this:</html:span></html:p> <html:p>You’ll have to first
    install the corresponding PyPI package by running <html:span class="No-Break">the
    following:</html:span></html:p> <html:p>Don’t worry <html:a id="_idIndexMarker088"></html:a>too
    much about missing any necessary packages for the examples included in the book,
    as you will find them nicely listed at the beginning of each chapter under the
    <html:em class="italic">Technical</html:em> <html:span class="No-Break"><html:em
    class="italic">requirements</html:em></html:span> <html:span class="No-Break">heading.</html:span></html:p>
    <html:a id="_idTextAnchor043"></html:a></html:div></html:div></html:body></html:html><html:html><html:head><html:title>Summary</html:title></html:head>
    <html:body><html:div class="epub-source"><html:h1 id="_idParaDest-44">Summary</html:h1>
    <html:div id="_idContainer023"><html:p>In this chapter, we introduced LlamaIndex,
    a framework for connecting LLMs to external datasets. We discovered how LlamaIndex
    allows LLMs to incorporate real-world knowledge into <html:span class="No-Break">their
    responses.</html:span></html:p> <html:p>The chapter discussed the benefits of
    LlamaIndex over fine-tuning, such as easier updating and personalization. It introduced
    the concept of progressive disclosure of complexity, where LlamaIndex starts simple
    but reveals advanced capabilities <html:span class="No-Break">when needed.</html:span></html:p>
    <html:p>The chapter then presented an overview of the hands-on project PITS, a
    personalized intelligent tutoring system. It covered setting up the required tools
    such as Python, Git, and Streamlit, and getting an OpenAI API key. The chapter
    finished by verifying that the environment is ready for building <html:span class="No-Break">LlamaIndex
    apps.</html:span></html:p> <html:p>We’re now ready to continue our journey and
    proceed with a more technical understanding of the inner workings of the LlamaIndex
    framework. See you in the <html:span class="No-Break">next chapter!</html:span></html:p></html:div></html:div></html:body></html:html>
    <html:html><html:head><html:title>Part 2: Starting Your First LlamaIndex Project</html:title></html:head>
    <html:body><html:div class="epub-source"><html:h1 id="_idParaDest-45" lang="en-US">Part
    2: Starting Your First LlamaIndex Project</html:h1> <html:div id="_idContainer025"><html:p>In
    this part, we explore the detailed aspects of LlamaIndex, including data ingestion
    through LlamaHub connectors, text-chunking tools, metadata infusion, data privacy,
    and efficient ingestion pipelines, before moving on to a comprehensive guide to
    the indexing functionality within LlamaIndex, detailing types of indexes, customization,
    and strategies for building scalable <html:span class="No-Break">RAG systems.</html:span></html:p>
    <html:p>This part has the <html:span class="No-Break">following chapters:</html:span></html:p>
    <html:ul><html:li><html:a><html:em class="italic">Chapter 3</html:em></html:a>
    , <html:em class="italic">Kickstarting Your Journey with LlamaIndex</html:em></html:li>
    <html:li><html:a><html:em class="italic">Chapter 4</html:em></html:a> , <html:em
    class="italic">Ingesting Data into Our RAG Workflow</html:em></html:li> <html:li><html:a><html:em
    class="italic">Chapter 5</html:em></html:a> , <html:em class="italic">Indexing
    with LlamaIndex</html:em></html:li></html:ul></html:div></html:div></html:body></html:html>'
  prefs: []
  type: TYPE_NORMAL
