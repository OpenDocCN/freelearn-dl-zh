- en: '8'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Fine-Tuning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What happens when prompt engineering efforts have gone as far as they can go?
    If higher quality results are still needed, examples are overwhelming the prompt,
    performance issues appear, or token costs are excessive because of a large prompt,
    **fine-tuning** comes into the picture.
  prefs: []
  type: TYPE_NORMAL
- en: 'As mentioned in the last chapter, solutions sometimes require overlapping approaches
    such as **Retrieval-Augmented Generation** (**RAG**), prompt engineering, and
    fine-tuning. Fine-tuning helps the model improve its understanding. We will focus
    on a few critical deliverables before contextualizing them by completing the Wove
    case study started in [*Chapter 6*](B21964_06_split_000.xhtml#_idTextAnchor134),
    *Gathering Data – Content* *is King*:'
  prefs: []
  type: TYPE_NORMAL
- en: Fine-tuning 101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating fine-tuned models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fine-tuning tips
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wove case study, continued
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Regardless of the tools, the team must care and feed the **large language model**
    (**LLM**) to improve the output. Though the methods discussed in the book can
    reach limits, fine-tuning is another excellent trick.
  prefs: []
  type: TYPE_NORMAL
- en: Fine-tuning 101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Think of fine-tuning as teaching the solution how to approach a problem. You
    are not telling it the exact answers. That is for RAG. You coach the LLM on approaching
    issues, thinking about the solution, and how it should respond. Even though specific
    examples are used in fine-tuning, don’t expect it to use that exact example *ever*.
    It is just an example. Imagine we need it to be like a science teacher, so the
    LLM is told in prompts to *be a science teacher*, but if it needs to *sound like*
    an 8th-grade science teacher, share examples of what it is expected to sound like.
    Then, when these examples are added to the models, compare them against output
    examples and decide whether they are doing a good job. We will do this work using
    fine-tuning in the ChatGPT playground, as shown in *Figure 8**.1*.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B21964_08_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.1 – Fine-tuning in ChatGPT
  prefs: []
  type: TYPE_NORMAL
- en: We will walk through an example. This will give a feel for what is being built,
    how to contribute examples for training and testing, and what the results are
    when the model is improved with fine-tuning.
  prefs: []
  type: TYPE_NORMAL
- en: Prompt engineering or fine-tuning? Where to spend resources
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We already know you need both, but if examples are added to the prompts, each
    use of the prompt will incur a cost because the input tokens cost money every
    time they are sent to the model. One trick is to move training data from prompts
    to fine-tuning. As new examples or edge cases are discovered, add them to improve
    the model.
  prefs: []
  type: TYPE_NORMAL
- en: Start with prompt engineering and move on to fine-tuning
  prefs: []
  type: TYPE_NORMAL
- en: The prompt engineering tools in [*Chapter 7*](B21964_07.xhtml#_idTextAnchor150),
    *Prompt Engineering,* give value and include a faster feedback loop than the more
    technical efforts needed for fine-tuning. Creating datasets and running training
    jobs takes more effort and time to see results. In enterprise use cases, both
    will be required. Responding to a fine-tuned model can be much less expensive
    and faster than responding to a large prompt with many examples to process each
    turn.
  prefs: []
  type: TYPE_NORMAL
- en: Token costs do matter
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'It is expected to start with growing prompts by including examples of how the
    model should respond. There can be significant costs if large prompts are used
    tens of millions of times as each customer interacts with the LLM. Compare the
    following prompts with learning examples to a fine-tuned model that contains the
    same examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Remove these from the prompt and add them to a fine-tuned model behind the
    scenes with the exact examples. This leaves the prompt like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The former includes about 500 tokens, using just 50 examples, while the prompt
    alone is 14 tokens. By moving the examples into a fine-tuned model, each turn
    will save 97% in input tokens. A fine-tuning model can cost more than a generic
    model. We can compare the input costs, as shown in *Table 8.1*.
  prefs: []
  type: TYPE_NORMAL
- en: '| **Model** | **Costs** | **Cost for 10,000 prompts @ 500 tokens** **per prompt**
    | **Cost for 10,000 prompts @ 14 tokens** **per prompt** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| **GPT-3.5** **Turbo fine-tuned** | $3.00 / 1M input tokens | $15.00(good
    results) | **$****0.42**(savings of 97%)(good results) |'
  prefs: []
  type: TYPE_TB
- en: '| **GPT-3.5 Turbo** | $0.50 / 1M input tokens | **$****2.50**(hard to improve
    results) | $0.07(hard to improve results) |'
  prefs: []
  type: TYPE_TB
- en: '| **GPT-4o mini** | $0.15 / 1M input tokens | $0.75 | $0.021 (a little over
    2 cents) |'
  prefs: []
  type: TYPE_TB
- en: Table 8.1 – Comparison of costs for models using fine-tuning and reducing prompt
    size
  prefs: []
  type: TYPE_NORMAL
- en: The generic model won’t be able to return the robustness of the fine-tuned model.
    Yet, the generic mode, with the collection of examples in the prompt, is still
    five times more expensive in this trivial example ($2.50 compared to 42 cents).
    Prompting is faster and great for getting started, but fine-tuning will be how
    to customize the model in many cases. Recall that a solution can include generic
    (cheap) models in conjunction with fine-tuned models. This is reasonable. The
    token cost for a prompt can be calculated using the OpenAI tokenizer.
  prefs: []
  type: TYPE_NORMAL
- en: 'Demo: [Tokenizer](https://platform.openai.com/tokenizer) ([https://platform.openai.com/tokenizer](https://platform.openai.com/tokenizer))'
  prefs: []
  type: TYPE_NORMAL
- en: Even though cost will be considered, many use cases require a fine-tuned model.
    In this example, if the quality is there with GPT-4o mini with the small prompt
    and no training examples, then costs can be dramatically smaller. The use case
    will dictate the extent to which examples are needed for training. Let’s get started
    by learning how to build a fine-tuned model. The Playground supports this without
    coding.
  prefs: []
  type: TYPE_NORMAL
- en: Creating fine-tuned models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Every model will have different needs. With GPT-3.5 Turbo, a start might be
    50 to 100 examples. After reaching the end of a good return on investment from
    prompt engineering, prompt chaining, and even function calling, we wind up here
    at fine-tuning. Because so many enterprise use cases will have at least some requirement
    for fine-tuned models, the best you can do is optimize for small context windows
    in exchange for more fine-tuning examples. The fine-tuned model costs the same,
    with 50 examples or 5000\. So, if you take a 3000 token prompt, move all the examples
    into the model, and leave a prompt of 300 tokens (a few paragraphs), that is a
    significant saving for each interaction. To put this in perspective, this paragraph
    has 173 tokens (766 characters).
  prefs: []
  type: TYPE_NORMAL
- en: If fine-tuning doesn’t improve the model, the data science folks will likely
    have to figure out a different way of restructuring the model (OpenAI doesn’t
    give an example, but if all of these methods fail, ask ChatGPT for fine-tuning
    tips).
  prefs: []
  type: TYPE_NORMAL
- en: 'Article: [When to use fine-tuning](https://platform.openai.com/docs/guides/fine-tuning/when-to-use-fine-tuning)
    ([https://platform.openai.com/docs/guides/fine-tuning/when-to-use-fine-tuning](https://platform.openai.com/docs/guides/fine-tuning/when-to-use-fine-tuning))'
  prefs: []
  type: TYPE_NORMAL
- en: Anyone can assist in fine-tuning. It takes more effort than prompt engineering,
    but the formats are accessible, and effort needs to be put into the content. As
    designers, writers, linguists, and product people, put on the customer content
    hat and get going.
  prefs: []
  type: TYPE_NORMAL
- en: 'Each model might have different formats. Here is the format for GPT-3.5 Turbo:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'These are easy to model in a spreadsheet and can be reviewed by others and
    edited quickly. OpenAI also provides an example of multi-turn training data. Notice
    the weight key in their example. A weight of `0` means the model will ignore that
    specific message:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: We will use the Playground for examples, but the development team will build
    a pipeline to manage the testing and training data in real life. Split example
    data between training and testing examples. Don’t include testing examples in
    the training set, or test results will be wrong. Hold out about 20% of the data
    for testing. You need to know whether the model is improving, and this data can
    be used to provide a benchmark.
  prefs: []
  type: TYPE_NORMAL
- en: Fine-tuning for style and tone
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Take prompt engineering as far as possible to train the system, but style and
    tone, format, and other qualitative features can be expressed with examples. In
    [*Chapter 1*](B21964_01.xhtml#_idTextAnchor016), *Recognizing the Power of Design
    in ChatGPT*, there is an example of a surf shop being compared to a bank. Instructions
    on talking like a surfer or performing tasks as a trusted business advisor for
    a prestigious international financial company will help. However, examples of
    how interactions sound and feel for a surf shop and a bank can help tweak that
    style, tone, and sophistication for the LLM persona.
  prefs: []
  type: TYPE_NORMAL
- en: '*Round 1* is the first experiment for fine-tuning a model with ten training
    examples. There is nothing special about this example. We need to showcase how
    fine-tuning works and how to read the results from the output. As this hands-on
    activity progresses, keep your use cases in mind. For actual work, start with
    prompt engineering and learn what doesn’t work there. Then, think about how to
    apply fine-tuning. Let’s get started with the example:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Head to the playground and go to the fine-tuning tab: [https://platform.openai.com/finetune](https://platform.openai.com/finetune).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click the **+ Create** button to add a new data set.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'This is the first file used that includes the training data:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'GitHub: [Training Data with ten examples](https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter8-Style-TrainingData10.jsonl)
    ([https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter8-Style-TrainingData10.jsonl](https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter8-Style-TrainingData10.jsonl))'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The example follows previous instructions for Alli, the sarcastic chatbot:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Far. Like a quarter million
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: miles. Or about how far you
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: might drive in a lifetime.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Create the model within the **Create a fine-tuned model** dialog box. *Figure
    8**.2* shows selecting the **Base Model** (feel free to use the latest models;
    the cost won’t be an issue for this experiment), selecting the training data file,
    and the form is ready to submit. Notice that, at this point, the optional parameters
    are left alone. We will explain them in the upcoming *Fine-tuning tips* section.
    For now, don't include any validation data to test the model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B21964_08_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.2 – Setting up a fine-tuning job in OpenAI
  prefs: []
  type: TYPE_NORMAL
- en: You will be returned to the fine-tuning page, and the job will take a few minutes
    to complete. The results should look similar to *Figure 8**.3*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B21964_08_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.3 – Results from a fine-tuning job with ten examples (Round 1)
  prefs: []
  type: TYPE_NORMAL
- en: Notice the training chart. We aim for it to tend to zero as it moves to the
    right. The number of entries in the chart equals the number of training examples
    times the number of epochs or a single pass through the training data. The `10`.
    We will consider this number of iterations very high and a function of having
    so few training examples. We will explain this in more detail as this testing
    process continues.
  prefs: []
  type: TYPE_NORMAL
- en: Failure is an option
  prefs: []
  type: TYPE_NORMAL
- en: Although the file shared work, the first time I did a fine-tuning job, it took
    me five tries to debug the typos. If the job fails, it will provide feedback.
    Fix it and try again. We will discuss third-party tools later in the chapter that
    help us avoid file formatting issues. To be fair to this process, the results
    are as shown. I have not gone back and made the results better or tweaked anything.
    The intent is to appreciate the process.
  prefs: []
  type: TYPE_NORMAL
- en: Now that the basics are working, it is time to explain what happened. A base
    model with billions of parameters was selected and fine-tuned to understand how
    to respond in the manner defined in the file. You can test this model at any time
    on the **Playground** | **Chat** window by selecting it by the name assigned in
    the output model field. You can even copy the name to make it easier to find in
    the **Chat** drop menu, as shown in *Figure 8**.4*. You will need to enter the
    system instructions; *Alli is a factual chatbot that is also sarcastic*. This
    is ignored by the model, even though it is in the training file.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B21964_08_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.4 – Copy and paste the fine-tuned model name into the Chat window
  prefs: []
  type: TYPE_NORMAL
- en: Now, re-run the same set of tests, but this time, include this file for the
    validation data with the same training data as in *Figure 8**.5*. *Round 2* will
    take a few more minutes.
  prefs: []
  type: TYPE_NORMAL
- en: 'GitHub: [20 validation examples](https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter8-Style-ValidationData20.jsonl)
    ([https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter8-Style-ValidationData20.jsonl](https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter8-Style-ValidationData20.jsonl))'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B21964_08_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.5 – Creating a model with training data
  prefs: []
  type: TYPE_NORMAL
- en: The validation file is a collection that is *not* used for training but by the
    model to compare its results to what is expected. The validation data is very
    human-like, oddly similar to the training date, and not very logical, or clearly
    defined, such as classifying service requests by priority or determining sentiment.
    This means getting the charts to tend to zero will be hard.
  prefs: []
  type: TYPE_NORMAL
- en: We can view the results and see what to do as the next steps in *Figure 8**.6*.
    We will take time to explain what is happening, but there are still a few training
    rounds.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B21964_08_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.6 – Results from a fine-tuning job with a validation set (Round 2)
  prefs: []
  type: TYPE_NORMAL
- en: 'Please open the file on GitHub and look at the examples; they are single-turn
    interactions. The user prompts, and the system responds. Each row looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'A multi-turn conversation (without the JSON formatting) would look like this
    example from ChatGPT 4o:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The model can be trained using the same basic format with multi-turn conversational
    interactions. In this OpenAI example, we highlighted the user and assistant responses
    that create a multi-turn interaction. Here is what it would look like when included
    in a training file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: This example set is not complex. Suppose the use case calls for multi-turn or
    extended examples to showcase how the model should react. Each entry should reflect
    a coherent dialogue that teaches the model to handle context over several interactions.
  prefs: []
  type: TYPE_NORMAL
- en: That is the input. Let’s review the output.
  prefs: []
  type: TYPE_NORMAL
- en: Using the fine-tuned model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once the fine-tuned model is ready, test it. You can see a **Playground** button
    on the bottom right of the fine-tuning job. You can also go to **Chat** in the
    left tab and then select the name of the fine-tuning job.
  prefs: []
  type: TYPE_NORMAL
- en: Optionally, there is a **Compare** button to manually test the model and compare
    it to previous model versions (or other models entirely). Be sure to copy the
    exact instructions in the **SYSTEM** field. We just clicked the **Playground**
    button to open the chat, selecting the fine-tuned model, as in *Figure 8**.7*.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B21964_08_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.7 – Selecting the fine-tuned job to interact with the new model
  prefs: []
  type: TYPE_NORMAL
- en: Gotcha
  prefs: []
  type: TYPE_NORMAL
- en: We can’t do both the file retrieval demo (to incorporate the 100s of FAQs from
    the Alli demo) *and* fine-tune the model in the Playground. This is a current
    limitation. We will use this time to focus on fine-tuning improvements, knowing
    a production system can address this shortcoming.
  prefs: []
  type: TYPE_NORMAL
- en: Because of this limitation, this focus is on learning about fine-tuning rather
    than fine-tuning the RAG model. Comparing outputs, the foundation model is wordy,
    and neither has specific results from our FAQs; the model must be trained with
    FAQS. Compare the results in *Table 8.2* with the trained FAQs.
  prefs: []
  type: TYPE_NORMAL
- en: '| **Model** | **Response** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| **1) GPT-3.5 Turbo trained with** **the FAQs** | To lower your advisory fee,
    you can consider the following options:* Consolidating assets: The more you invest
    with us, the lower your advisory fee could be.* Grouping accounts together: You
    can also lower the advisory fee percentage for your immediate family members by
    grouping accounts together [1]. |'
  prefs: []
  type: TYPE_TB
- en: '| **2) GPT-3.5-turbo-1105+** **fine-tuned** | You should contact customer service
    for that. They can escalate to the appropriate department if necessary. |'
  prefs: []
  type: TYPE_TB
- en: '| **3) GPT-4o No fine-tuning and no FAQs** **as resources** | Optimizing advisory
    fees can lead to significant savings over time. Here are several strategies to
    consider:1\. **Compare Advisors**: Research and compare fees among different advisors.
    Look for advisors with transparent fee structures.2\. **Consider Fee-only Advisors**:
    Fee-only advisors charge a flat rate or an hourly fee rather than a percentage
    of your assets. This can sometimes be more cost-effective.3\. **Negotiate Fees**:
    Don’t be afraid to negotiate. Advisors might be willing to reduce their fees to
    retain you as a client.4\. **Bundled Services**: Some advisors offer packaged
    services that might come at a lower total cost than à la carte services.5\. **Review
    Fee Structure**, 6\. **Use Robo-Advisors**, 7\. **DIY Approach**, 8\. **Regular
    Fee. (5 to 8 are truncated for brevity) |'
  prefs: []
  type: TYPE_TB
- en: '| **4) GTP-3.5 1106 with fine-tuning** **78 examples** | Negotiate a lower
    fee or invest more money with me; I’m sure I can find a way to help you with that.
    |'
  prefs: []
  type: TYPE_TB
- en: '| **5) Best match from 78** **fine-tuning examples** | No question existed
    close to this question. Only one question even discussed advisory, and it was
    an unrelated question, “Can I pay Portfolio Advisory Service or other Alligiance-managed
    account fees using mobile check deposit?” |'
  prefs: []
  type: TYPE_TB
- en: '| **6)** **Source Answer****FAQ 86\. How can Iower my** **advisory fee?** |
    consider the benefits of consolidating assets. the more you invest with us, the
    lower your advisory fee could be. you can also lower the advisory fee percentage
    for your immediate family members (whether or not they live with you) by grouping
    accounts together. for additional details, please ask a Alligiance representative
    for details or view the fee aggregation policy and form. |'
  prefs: []
  type: TYPE_TB
- en: Table 8.2 – Output for “How can I lower my advisory fee?” with different models
  prefs: []
  type: TYPE_NORMAL
- en: '*We must have the FAQs to offer specific business data*. Fine-tuning will only
    help present results in a particular way. Only the model (1) with the FAQs could
    match the source material. RAG (or, in this case, the proxy for RAG – File Search)
    can handle the factual data. The other models can hallucinate (2) or be long-winded
    (3). The fine-tuned model (4) was slightly sarcastic but couldn’t return a valid
    answer without the knowledge. It isn’t trained on the answer, as the closest example
    wasn’t close (5), and it can’t invent the facts from the source FAQ (6). The size
    of the result should be noted. Because training was with short responses, the
    model (5) returned short responses.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Since ChatGPT-3.5 wants at least 10, if not 100, examples, *Round 3* will re-run
    the build with double the examples. Doubling examples is a typical strategy to
    increase quality by the same amount as the last doubling. Ten was too small in
    this case, so now it is 20\. In hindsight, this experiment should have started
    at 50\. We used the exact simple system instructions. You need to copy and paste
    the instructions again when testing; they are ignored in the playground when uploading
    examples. Include this training set and reuse the same validation data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'GitHub: [Training Data with 30 examples](https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter8-Style-TrainingData30.jsonl)
    ([https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter8-Style-TrainingData30.jsonl](https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter8-Style-TrainingData30.jsonl))'
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 8**.8* shows the results of *Round 3*. We can now start to examine
    the metrics more closely.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B21964_08_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.8 – Improving the model with double the training examples (Round 3)
  prefs: []
  type: TYPE_NORMAL
- en: 'We can explain a few more concepts with the validation data and then do one
    more round of training. Let’s review what the chart means:'
  prefs: []
  type: TYPE_NORMAL
- en: The red dot represents the end of an epoch, which is one round of training.
    Because the last example had 29 examples, one epoch was 29 tests long. Because
    it decided it needed three runs, it did 87 tests. The red dot represents the average
    validation loss across that group. We are progressing since the validation loss
    is decreasing, and the training loss is tending to zero.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We still see many ups and downs along the way. This model compares the expected
    outcome to its generated outcome. Once it improves with suitable matches, the
    graph tends to zero. When there is a big difference, the graph shows jumps. The
    large validation loss still needs to be solved. It still needs to converge towards
    zero.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This model is looking a little volatile compared to Round 1\. I suspect the
    training data is too similar to the validation data, which is causing this issue.
    This would have to be reviewed and tested. A real solution might take dozens to
    hundreds of rounds of iteration.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Don't generalize from the following Boolean classifier visualization. Graphs
    from simple Boolean classifiers (whether data is true or false, positive or negative
    sentiment, etc.) might not be helpful. If items are easy to classify, the graph
    will be like *Figure 8**.9*. Michael Cacic at [https://miha.academy/](https://miha.academy/)
    provided this example. Only a little can be learned from this chart. This model
    is working well.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](img/B21964_08_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.9 – A fine-tuning graph for a classifier task that is doing well
  prefs: []
  type: TYPE_NORMAL
- en: For complex data, like the Round 3 results, it is hopeful that the trend will
    be toward zero and that validation loss will decrease. Since there was a lack
    of convergence in the early run, add more varied examples to continue trending
    down. Improving the diversity of the validation examples (not done in this demo)
    would likely help.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Refrain from relying only on the graph for complex data. Review results and
    score them for quality. We discussed this in [*Chapter 4*](B21964_04.xhtml#_idTextAnchor085),
    *Scoring Stories*, and continue discussing measuring and monitoring in [*Chapter
    10*](B21964_10_split_000.xhtml#_idTextAnchor216), *Monitoring* *and Evaluation*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Remember, the goal is to improve the model’s reasoning, not to teach it knowledge.
    Use RAG for memory and scope. Use fine-tuning to hone how the model thinks and
    responds.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Be careful about non-enterprise data intrusions
  prefs: []
  type: TYPE_NORMAL
- en: In instructions and prompting, specify to use the data provided in RAG. This
    protects from pulling facts from the model that might confuse customers. Although
    “Alli” is the short name for the fictional financial services model example, hallucinations
    occurred when the instructions, “Only provide answers from the attached document,”
    were removed from the file attached model. During some additional research for
    the book, this model assumed Alli was *Ally*, a bank in Pennsylvania. This error
    will only be found in the field by monitoring logs. Customers will complain about
    these errors, but it would be tragic to find this out *after* your customer mailed
    a large check to the wrong address because the foundational model used some random
    address. Every model vendor is working on this problem. It will get better but
    still watch for it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Fine-tuning is well-suited for getting the style and tone right. Yes, good
    results can come from instructions, but fine-tuning is just that: it is fine;
    it is more granular and specific. *General* goals are in the prompts, while examples
    that could have been in the prompt can be moved to fine-tuning. These *specific*
    examples extend how the model should always respond. This is why the sarcastic
    example is so good. It was only trained on a few dozen examples, but it can now
    use those examples to drive its personality. Another use of fine-tuning is for
    manipulating data and transforming information.'
  prefs: []
  type: TYPE_NORMAL
- en: Fine-tuning for structuring output
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In cases where tables, lists, or other formatting is essential to the results,
    feed the fine-tuning system with examples to give it an edge in providing structured
    output. This is perfect for those who deal with table data, like in the Wove use
    case. It is helpful for any structured data, even with the expense examples. It
    is also beneficial to train on the name: value pattern (e.g., Amount: $12.34).
    Fine-tuning can be used for integrations, where you move data from one system
    to another and specify the format for the input for the next step. You might need
    XML, JSON, CSV, colon-delimited, or other formats to ensure your downstream system
    can accept the input.'
  prefs: []
  type: TYPE_NORMAL
- en: Tip for generating examples for fine-tuning
  prefs: []
  type: TYPE_NORMAL
- en: ChatGPT can be used to generate examples to build a training model. Not only
    can it do the examples, but it can generate the structured format needed for the
    file. So, now ChatGPT is training itself. The output can be reviewed and tweaked.
  prefs: []
  type: TYPE_NORMAL
- en: 'It also helps our tutorial to introduce another concept. You can instruct an
    LLM to create more examples. We call this **synthetic data**. This can be tried
    in the Playground. Notice the context, tone, and data format:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'More examples were provided; they are just truncated here. The model returned
    the results, and the next prompt was given to the model to make it easier to copy
    and paste the results. The prompt was:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'It returned a single file, making copying much easier, with results like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Impressive. ChatGPT can help generate structured output but can’t generate factual
    information about my business. It saves a lot of time. We can use this method
    to scale up test cases. We can manually review for quality, saving 90% or more
    of our effort.
  prefs: []
  type: TYPE_NORMAL
- en: This is a tiny example. Transforming data to move between disparate systems
    has been an ongoing enterprise problem. This back-end process has various uses,
    including presenting data in a UI in a format or with a helpful structure for
    customers to interpret. The use cases in this space abound. But it will only be
    apparent when this problem strikes you. From my experience, it is not common.
    It is just critical when it comes up. Even though ChatGPT can generate data, it
    doesn’t guarantee quality.
  prefs: []
  type: TYPE_NORMAL
- en: Generating data should still need a check and balance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You can use a variety of methods to generate data. This synthetic data could
    be similar to what real humans might have done. Or it might not. This is a place
    where human-in-the-loop analysis can be valuable. A model can generate examples
    very quickly. It only took a few minutes with the LLM to create many examples.
    Even with the time to review the results, it was much easier than writing them
    by hand.
  prefs: []
  type: TYPE_NORMAL
- en: You can do this with Google Sheets, Microsoft Excel, and third-party fine-tuning
    tools that support generation. A wealth of integrations are available to help
    with this process. Regardless of the tool, review results and decide whether to
    include the content in training or validation examples. You might accept them
    outright, edit them to make them better or reject them. Depending on the solution’s
    robustness, consider a workflow that scores results, as discussed in [*Chapter
    4*](B21964_04.xhtml#_idTextAnchor085), *Scoring Stories*. Scoring tools can help
    evaluate what to keep, reject, and tweak. Then, plan a course of action to improve
    based on how you feel about the results. We see some options in *Table 8.3*.
  prefs: []
  type: TYPE_NORMAL
- en: '| **Fine** **Tuning Status** | **Plan** |'
  prefs: []
  type: TYPE_TB
- en: '| **Happy** **with results** | Do nothing |'
  prefs: []
  type: TYPE_TB
- en: '| **Works well, but is expensive** **or slow** | Chain a fine-tuned lighter
    model (GPT-3.5) on all of the completions of a more expensive model (GPT-4) |'
  prefs: []
  type: TYPE_TB
- en: '| **Results are** **not consistent** | Chain a fine-tuned lighter model (GPT-3.5)
    on all of the best completions of a more expensive model (GPT-4) |'
  prefs: []
  type: TYPE_TB
- en: '| **Results are close to what I want but the style and tone** **are off** |
    Manually edit examples to the desired quality, or edit the prompt to adjust results
    |'
  prefs: []
  type: TYPE_TB
- en: '| **I don’t have a model, or can’t create** **one easily** | Fine-tune a model
    with manually generated high-quality examples |'
  prefs: []
  type: TYPE_TB
- en: Table 8.3 – Courses of action when tuning is not going as planned
  prefs: []
  type: TYPE_NORMAL
- en: Even this part of fine-tuning can undergo multiple care and feeding cycles.
    You might loop back around and find an even lighter model or something needing
    more editing. Iteration is fundamental to every step of the generative AI journey.
  prefs: []
  type: TYPE_NORMAL
- en: Spreadsheet user tips
  prefs: []
  type: TYPE_NORMAL
- en: 'The format for fine-tuning has changed over time. Each model can use different
    formats. Just adapt the data to the model format. You can use a spreadsheet to
    maintain the source content and then use the tools in spreadsheets to build strings
    combining source content with the correct formatting, for example:'
  prefs: []
  type: TYPE_NORMAL
- en: '**A1 cell = '' {"messages": [{"role": "system", "content": "Alli is a factual
    chatbot that is also sarcastic."}, {"role": "user", "****content": "''**'
  prefs: []
  type: TYPE_NORMAL
- en: '**B1 cell =** **question**'
  prefs: []
  type: TYPE_NORMAL
- en: '**C1 cell = ''"}, {"role": "assistant", "****content": "''**'
  prefs: []
  type: TYPE_NORMAL
- en: '**D1 contains the** **synthetic string**'
  prefs: []
  type: TYPE_NORMAL
- en: '**E1 cell = '' "}]}''**'
  prefs: []
  type: TYPE_NORMAL
- en: '**So F1 = A1 & B1 & C1 & D1 & E1 then** **export F1**'
  prefs: []
  type: TYPE_NORMAL
- en: Excel and Google Sheets have ChatGPT (and other LLM) integrations to generate
    synthetic data. Spreadsheet integration with ChatGPT has all kinds of uses. It
    helps this process and can improve personal productivity.
  prefs: []
  type: TYPE_NORMAL
- en: One great trick is not rebuilding the model from scratch each time examples
    are added. After reviewing the generated results and fixing some formatting errors,
    49 more examples were incorporated from a separate file to add to the model. In
    total, there are now 78 examples and 20 test cases.
  prefs: []
  type: TYPE_NORMAL
- en: Re-use the model from *Round 3*. The training will go faster. As shown in *Figure
    8**.10,* pick the previous fine-tuned model in the `Base Model` menu to create
    a revised fine-tuned model. You are picking up where you left off. Only upload
    the incrementally new rows in the data for *Round 4*.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B21964_08_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.10 – Appending to an existing fine-tuned base model to continue fine-tuning
  prefs: []
  type: TYPE_NORMAL
- en: 'GitHub: [49 training examples](https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter8-Style-TrainingData49.jsonl)
    ([https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter8-Style-TrainingData49.jsonl](https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter8-Style-TrainingData49.jsonl))'
  prefs: []
  type: TYPE_NORMAL
- en: We can now view the training, which shows the results from Round 4 in *Figure
    8**.11*.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B21964_08_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.11 – The final fine-tuning run for ChatGPT-3.5 9 compared to ChatGPT-4o
    mini, including synthetic data (Round 4)
  prefs: []
  type: TYPE_NORMAL
- en: Chat GPT 3.5 (on the top of the image) was improved by adding more examples.
    At least 50 to 100 examples were suggested; this is in the middle of that range.
    Take the 78 examples, double the training set, extend the testing set to 20%,
    review and clean up overlapping concepts, and test again. See if the next round
    will get the validation loss closer to zero. Looking at the results, it is better
    but not perfect. The slope of validation loss is trending down, but not as much
    as in more realistic data.
  prefs: []
  type: TYPE_NORMAL
- en: The output for ChatGPT-4o mini with the same data is included for comparison.
    The training loss is almost zero. The validation loss is still high and only slightly
    trending down (the red dots). Because OpenAI changed the vertical scale (bad design!)
    look carefully to compare the results. The second chart is scale is 25% different
    and thus the data is better than from ChatGPT-3.5\. Without more testing, it is
    hard to tell if this is acceptable for the data we trained it on.
  prefs: []
  type: TYPE_NORMAL
- en: 'If the results are not good, try other techniques. Consider some of these expert
    moves:'
  prefs: []
  type: TYPE_NORMAL
- en: You can compare and test along the way. Each epoch generates a checkpoint. This
    file compares one checkpoint to another or even a different model. ChatGPT saves
    the last three checkpoints. *Figure 8**.12* zooms in on the checkpoints section.
    They are listed in the fine-tuning job and can then be selected, cut, and pasted
    into the chat, or mouse over them and jump directly into the playground using
    the link.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/B21964_08_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.12 – Checkpoints can be directly opened in the playground
  prefs: []
  type: TYPE_NORMAL
- en: Notice that the final checkpoint was selected and copied to the clipboard. Clicking
    the **Playground** link on the first checkpoint opens it in the playground; a
    comparison model can be selected, as shown in *Figure 8**.13*. You can now paste
    the model path from the final checkpoint into the field as a shortcut.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/B21964_08_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.13 – Model names can be pasted into the model select field even in
    a comparison
  prefs: []
  type: TYPE_NORMAL
- en: Now, you can compare results from the two models. The demo won’t reveal any
    exciting results, but this method is helpful for comparisons with large data sets.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Increase the default Epochs from 2 to 3 or 4 for a strict classifier. However,
    consider this only after it has enough examples.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the model is too loose, increase the epochs for additional training.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this last round, the training loss increased. When re-running this model
    in Chat GPT-4o mini, the loss was much better (closer to zero). Look at more and
    better data to stick with this model and decrease training loss. As mentioned,
    the data is very similar and at risk of overfitting. Use synonyms, introduce more
    variation, and insert or delete words in the statement to scale up the variety
    and number of examples. The data scientists have far more approaches at their
    fingertips. These are too advanced for this book. But the intern knows the answer.
    Ask ChatGPT.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Adding examples and expanding test cases will improve results. Continue to explore,
    grow test cases, improve the quality of the examples, play with the parameters,
    and learn. The best resource in my journey, outside of ChatGPT itself, was a four-hour
    training masterclass from Mihael Cacic. It was the most valuable of all resources,
    and it is recommended (I am not compensated for this; I was just a student). It
    is perfect for product people. It is the right level for an introduction class.
    Check it out.
  prefs: []
  type: TYPE_NORMAL
- en: 'Training: [Miha’s training website](https://miha.academy/) ([https://miha.academy/](https://miha.academy/))'
  prefs: []
  type: TYPE_NORMAL
- en: 'Entry Point, his company, also has tools that support speeding up the training
    process and experimenting with fine-tuning jobs across multiple LLMs. You can
    use Entry Point, connect to OpenAI and other LLM vendors, and never deal with
    the JSON format for fine-tuning. Keep this in mind: tools help reduce the complexity
    of model management. New tools are becoming available every day.'
  prefs: []
  type: TYPE_NORMAL
- en: Look at Vijay’s article for more on fine-tuning and the different types of losses.
    It discusses metrics, is a good resource, and only takes a few minutes to read.
  prefs: []
  type: TYPE_NORMAL
- en: 'Article: [Training vs. Validation Loss](https://medium.com/@penpencil.blr/what-is-the-difference-between-training-loss-validation-loss-and-evaluation-loss-c169ddeccd59)
    by Vijay M (https://medium.com/@penpencil.blr/what-is-the-difference-between-training-loss-validation-loss-and-evaluation-loss-c169ddeccd59'
  prefs: []
  type: TYPE_NORMAL
- en: Having gone end to end with a fine-tuning model, there are other areas to explore
    besides conversational style and tone. In the enterprise, connecting to different
    data sources to gather information and push results also exists. You will need
    function calling.
  prefs: []
  type: TYPE_NORMAL
- en: Fine-tuning for function and tool calling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When passing data back and forth from existing systems, it is typical to conform
    to the other systems’ formats because these legacy systems are likely to stay
    the same for you. The most recent models are getting better at matching the `tool_choice`,
    and it is set to `auto`. You can force this process by setting it to `required`,
    specifying a specific named function, or telling it `none` to disable it.
  prefs: []
  type: TYPE_NORMAL
- en: There is little for us to do on the product side here. It is included for completeness.
    Of course, these interactions should be monitored to ensure the proper functions
    are called. This requires additional training data to differentiate between similar
    functions, making sure that data is mapped to the correct fields when there is
    a collection of similar fields (for example, total price, discounted price, itemized
    prices, tax, and other dollar values), and to verify that the model extracted
    data correctly (not too much, not too little, but just right).
  prefs: []
  type: TYPE_NORMAL
- en: 'Product people should be aware of one neat trick: **parallel function calling**.
    This allows multiple queries to be sent in parallel, dramatically reducing the
    response time with no additional model cost. *There is no such thing as a slow,
    good user interface*. People today are impatient.'
  prefs: []
  type: TYPE_NORMAL
- en: One gotcha. OpenAI suggests that SQL generation is “not perfectly reliable.”
    Therefore, use caution and extensive testing and monitoring. I have not had success
    building AI SQL generators from text input, but this will improve over time.
  prefs: []
  type: TYPE_NORMAL
- en: 'Documentation: [Calling functions with chat models](https://cookbook.openai.com/examples/how_to_call_functions_with_chat_models)
    ([https://cookbook.openai.com/examples/how_to_call_functions_with_chat_models](https://cookbook.openai.com/examples/how_to_call_functions_with_chat_models))'
  prefs: []
  type: TYPE_NORMAL
- en: Of all the ways to use fine-tuning, plenty of tips can help with this process.
    We cover some of the critical items.
  prefs: []
  type: TYPE_NORMAL
- en: Fine-tuning tips
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You must care for and feed the fine-tuned set to improve training quality (based
    on the metrics or experience with certain test cases). Here is a summary of OpenAI’s
    suggestions for fine-tuning:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Review existing examples for issues**: You might have introduced style, logic,
    or grammar issues into the dataset, including examples with errors. Review the
    material against how the model performed before and after adding the data. You
    can use the epoch checkpoints as a tool.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Gather more examples to fill the gaps**: Additional training examples might
    show the model how to address gaps in its abilities. It is always hard to say
    how much is too much.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Include examples with errors**: Sometimes, it is best to learn from the master.
    Let’s ask ChatGPT about including mistakes in fine-tuned examples:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**Look for imbalance and the need for more diversity in data**: Does the data
    set provide a range of examples? Refrain from biasing data with one kind of answer.
    It is not helpful to rephrase the same question. Think about the expense examples.
    Not just data format but style, idiomatic language, lack of data, too much data,
    and even irrelevant data. Even the 78 sarcastic examples for the four rounds of
    testing were a little homogenous. This is something the team has to notice.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Imbalance example
  prefs: []
  type: TYPE_NORMAL
- en: I had a case that puzzled me for a while. We had two primary tasks that a conversational
    assistant did. It did expenses and time reporting. However, both were needed in
    the same assistant. The training data was biased toward the expense assistant’s
    round numbers and needed the correct numbers in the time reporting model. While
    a customer might say “15 minutes,” “30 minutes,” or “an hour and 45 minutes” for
    a time record, most expenses are not “$15,” “$30,” or “$45”, so by overweighting
    on those round numbers in expenses it pushed understanding for the typical time
    units towards the expense model. This bias can be improved by using better data
    for the expense model and ensuring the time model has the right balance of examples.
  prefs: []
  type: TYPE_NORMAL
- en: '**Match the training examples to expectations**: If it is expected that most
    people will give the information needed to ask a question, fill out a form, or
    move forward, then training examples should mirror those examples.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Validate the consistency of the examples when coming from multiple sources**:
    Even humans are expected to disagree on specific values when labeling data. If
    one person tags a company name as “The Business Center” and the other as “Business
    Center,” then the model can likely have similar issues.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Training examples should be in the same format.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Judge improvements based on previous improvements.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Edge case issues take work to include**: As a rule of thumb, expect a similar
    improvement for each doubling of quality training data. But it is more work to
    find the edge cases than the happy paths. Take the time to express those edge
    cases. It will make the fine-tuned model more robust. Edge cases could be in several
    attributes: length of the question, use of multiple languages in one question,
    multi-part complex questions, lots of chit chat with a small portion for the actual
    question, the use of data that is not well formatted or in a format not expected
    (military time, currencies with extra numbers), written words for numbers, or
    just plain wrong information. Judge this by comparing the testing results between
    the fully tuned model and one using one-half of the training data. Use this to
    judge future stepwise improvements.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Specify and adjust the hyperparameters**: Start with the defaults set by
    OpenAI. If the model doesn’t follow the training data, increase epochs by one
    or two. Notice how they were at five in the Wove case study coming up next. This
    is more typical for classification, entity, extraction, or structured parsing
    tasks. All of these have a known answer. With more wide-ranging model tasks, decrease
    the epochs by 1 or 2 to see if that improves diversity.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'If the model isn’t converging, increase the **learning rate** (**LR**) multiplier.
    The graphs from the Wove case study are in the next section. *Figure 8**.5* shows
    this convergence issue, as does the Wove example, which is covered shortly. Only
    make small changes at one time. Here is some background:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Article: [Learning Rate](https://www.chatgptguide.ai/2024/02/25/what-is-learning-rate/)
    ([https://www.chatgptguide.ai/2024/02/25/what-is-learning-rate/](https://www.chatgptguide.ai/2024/02/25/what-is-learning-rate/))'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: One issue is overfitting. Mihael from Entry Point provided the example in *Figure
    8**.14*, in which the validation loss continued to grow while the training loss
    was acceptable. This is a classic overfitting example.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B21964_08_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.14 – An example of overfitting is shown with the increase in validation
    loss
  prefs: []
  type: TYPE_NORMAL
- en: The analogy is studying for a test by memorizing the exact questions and answers
    from a practice test. Then, in the actual test, none of the questions are similar
    enough to allow the taker to answer correctly. Aligned too closely with the study
    material, fails to translate to answering correctly.
  prefs: []
  type: TYPE_NORMAL
- en: '**Use a second model to verify a fine-tuned model**: One approach is to use
    a second model to test the first model to confirm results. The second model might
    be the same or completely different fine-tuned or off-the-shelf LLM. Set a quality
    threshold; if the AI answer fails, it might route the request to a human customer
    service agent. It takes some experience to figure this out.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If, after all this work, the assistants’ style or tone needs to change, all
    of the examples don’t necessarily have to change. Consider tweaking the prompts
    to override the examples. If it is just a tweak, the fine-tuning is not going
    to waste; it is still helping give it the experience.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'This is a vast area for research, testing, and learning. This is only a start
    to ensure you can apply these skills at the team level. We hope it is easy to
    appreciate how much the discussion impacts the quality of the user experience.
    Here is one more resource as a companion to the earlier OpenAI Fine-tuning documentation:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Article: [ChatGPT Fine Tuning Documentation](https://platform.openai.com/docs/guides/fine-tuning/fine-tuning-integrations)
    ([https://platform.openai.com/docs/guides/fine-tuning/fine-tuning-integrations](https://platform.openai.com/docs/guides/fine-tuning/fine-tuning-integrations))'
  prefs: []
  type: TYPE_NORMAL
- en: We want to examine how everything learned about prompt engineering and fine-tuning
    works for the Wove use case.
  prefs: []
  type: TYPE_NORMAL
- en: Wove case study, continued
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [*Chapter 6*](B21964_06_split_000.xhtml#_idTextAnchor134), *Gathering Data
    – Content is King,* the Wove case study on data cleansing for rate sheets used
    by freight forwarders was kicked off. They had to scrub the data before ingesting
    it to output a clean, unified view of all the rates from many carriers. Now, it
    is time to explore their prompt engineering (we covered the basics in [*Chapter
    7*](B21964_07.xhtml#_idTextAnchor150), *Prompt Engineering*) and fine-tuning efforts
    for this solution.
  prefs: []
  type: TYPE_NORMAL
- en: Prompt engineering
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'They want the LLM to think like a customer who does this step manually. They
    created the prompt for the spreadsheets during the ingestion process (this early
    version was shared with us to maintain the proprietary nature of their latest
    efforts):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s review a few highlights from this prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: It sets the stage for the persona to be adopted.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It gives context for understanding tables.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It explains the input (snippets of text and more details)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It helps with some exceptions (ambiguous columns)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It defined the response format (**Yet Another Markup** **Language** (**YAML**))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Great job following the guidance! Honestly, they were already following this
    same advice. They use a lot of fine-tuned models, so examples don’t appear in
    their prompts. One small thing: where is the idea of an emotive prompt? They should
    explore if that helps their quality. We can talk to them about that!'
  prefs: []
  type: TYPE_NORMAL
- en: Fine-Tuning for Wove
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As discussed in the last chapter, Wove has a collection of models to perform
    specific tasks in cleaning the spreadsheet data. The fine-tuning process adapts
    generic models to improve the understanding of rate spreadsheets critical to Wove’s
    customers. It is similar to teaching a 5th grader a new subject. A 5th grader
    knows the basic language and can answer simple questions—they might even be into
    ships and trains and understand the concept of moving goods, but no 5th grader
    has ever seen a rate sheet.
  prefs: []
  type: TYPE_NORMAL
- en: 'We know that a model can only provide so much. ChatGPT recommends starting
    with prompt engineering before going to fine-tuning. In conversations, Kevin Mullet
    suggested an excellent way to remember this: “*First*, figure out what to say,
    *then* figure out how to say it.” We have shown how this can help, but this extra
    effort is needed.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some checks that Wove does to verify that the data is being processed
    correctly. This covers data quality, prompt quality, and fine-tuning:'
  prefs: []
  type: TYPE_NORMAL
- en: They manually review the interpretation of the data to look for hallucinations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'They look for validation and training loss converging to zero. They run additional
    evaluation data sets using OpenAI Evals to ensure that models pass established
    tests. OpenAI provides a collection of templates to evaluate models using standard
    measures. The evals allow judgment of how different model versions and prompts
    impact usage. Here is a good introduction:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Article: [Getting Started with OpenAI Evals](https://cookbook.openai.com/examples/evaluation/getting_started_with_openai_evals)
    ([https://cookbook.openai.com/examples/evaluation/getting_started_with_openai_evals](https://cookbook.openai.com/examples/evaluation/getting_started_with_openai_evals))'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: They use multiple steps in a chain and different models to focus on doing one
    thing well. They regularly revisit models to adopt newer and cheaper ones.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In one of the models, they do location mapping and use over 600 training examples.
    10% is for validation data, but for some models, they bump up to 20%, depending
    on how expensive it is to generate the data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Their training graph in *Figure 8**.15* looks good. It is converging to zero
    for training loss. They have a validation test set that works well and uses what
    appear to be default parameters.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/B21964_08_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.15 – An example of a training model converging
  prefs: []
  type: TYPE_NORMAL
- en: Initially, they had learning rate issues. In machine learning and statistics,
    the learning rate is a tuned parameter in an optimization algorithm that determines
    the iteration step size while moving toward a minimum loss function.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Even if trained again, it never quite gets to the optimal point. Sometimes,
    there is poor convergence or overfitting, as discussed. *Figure 8**.16* shows
    an earlier run showing a lack of convergence.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B21964_08_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.16 – An example of an early Wove training model that didn’t converge
  prefs: []
  type: TYPE_NORMAL
- en: If there is bouncing and the lines do not quite converge, retrain with a lower
    learning rate. Convergence will be much slower if the initial weights are too
    high. To put models in perspective, the four rounds for the sarcastic chatbot
    experiment ran with less than 5000 training tokens for each round. The Wove model
    above used over 500,000 training tokens for this one piece of their solution.
    Bigger doesn’t guarantee convergence.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our friends at Wove have a few more tips for those ingesting spreadsheets:'
  prefs: []
  type: TYPE_NORMAL
- en: They use expensive models to fine-tune cheaper models. For example, Anthropic’s
    Opus 3 Claude is (at this time of writing) about 30 to 50 times more costly than
    OpenAI 3.5\. Opus 3 is 15$/1M input and 75$/1M output tokens versus ChatGPT 3.5
    turbo-0125 at $0.50/1M input and $1.50/1M output tokens. This is an essential
    point for the product team. You want to get the best bang for the buck, especially
    when dealing with customers who will use the model more often if it provides excellent
    service. They found significantly better quality from fine-tuning ChatGPT 4.0
    than earlier 3.5 models. Chat GPT-4o mini is now being incorporated.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They started using a higher learning rate, which they could reduce when they
    made significant steps. The amount of data impacts the learning rate steps (e.g.,
    0.5, 0.1, and 0.01). This can be tweaked based on the size of the data set and
    other factors. The goal is to refine so the training loss decreases in an orderly
    fashion without wild swings or divergence.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Working around the context window, they started with a 4K context window and
    grew to support 16K. They can preprocess data and use other tools to deal with
    smaller chunks. Even at 16K, this is small for handling large spreadsheets.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Make sure the data is accurate**: With good input data, success is more likely.
    If the trained data isn’t tagged correctly or has missing data, the data team
    will have issues. This real example is for an early Wove’s table end detection
    version. You can see this in the chart bouncing all over the place compared to
    earlier examples. You don’t see a convergence.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can look at one example of a hallucination and how they corrected it in the
    part of the flow where they took the text version of the spreadsheet (left column)
    and asked ChatGPT to define (understand) the row’s context (middle column). This
    is *Step 1*. Then, they edited this output, completing the process with the final
    output (right column) shown in *Table 8.4*.
  prefs: []
  type: TYPE_NORMAL
- en: '| **Input File** | **Intermediary output** **from ChatGPT** | **Final normalized
    file** **from ChatGPT** |'
  prefs: []
  type: TYPE_TB
- en: '| The table on the sheets “Rate Sheet”, is from the VN to US UPDATE file.The
    table has these columns: - id: 0name: POLExamples:- DA NANG, VIETNAM- HO CHI MINH
    CITY, VIETNAM- HAIPHONG, VIETNAM- VUNG TAU, VIETNAM | Purpose: This table provides
    ocean freight rates and details from various ports in Vietnam to destination in
    the United States, carriers and services, valid for a certain date range. columns:-
    id: 0name: POLdescription: The port of loading in Vietnam, such as De NANG, HAIPHONG,
    QUI NHON, or VUNG TAU.examples:- DA NANG, VIETNAM- HAIPHONG, VIETNAM- VUNG TAU,
    VIETNAM | carrier: 7service_line: 4origin: 0origin_country: Vietnamorigin_via:
    nullorigin_via_country: nulldestination: 1destination_country: United Statesdestination_via:
    2destination_via_county: United Statesloading_port: nullloading_port_country:
    nullunloading_port: null |'
  prefs: []
  type: TYPE_TB
- en: '| **Input File** | **Intermediary output** **from ChatGPT** | **Final normalized
    file** **from ChatGPT** |'
  prefs: []
  type: TYPE_TB
- en: '| - id: 2name: Dest (Via Port)examples:- OAKLAND, CA- NORFOLK, VA- LOS ANGELES,
    CA- SAVANNAH, GAVANCOUVER, CANADA- None- TACOMA, WA- BALTIMORE, MD- CHARLESTON,
    SC- NEW YORK, NY | - id: 1name: Destinationdescription: The destination city and
    state in the United States, such as LONG BEACH, CA, SEATTLE, WA, or CLEVELAND,
    OHexamples:- ATLANTA, GA- PITTSBURGH, PA- CHARLOTTE, NC- CLEVELAND, OH- id: 2name:
    Dest (via Port)description: The port in the United States that the shipment will
    go to reaching its final destination, such as NORFOLK, VA, SEATTLE,WA or LOS ANGELES,
    CA. Can also be “None” if the shipping direct to the destination.examples:- NORFOLK,
    VA- SAVANNAH, GA | unloading_port_country: nulleffective_date: 8expiry_date: 9container_dry_or_reefer:
    nullcommodity: nullrates:- id: 10currency: nulltype: totalcontainer_size: “20ft”-
    id: 11currency: nulltype: totalcontainer_size: “40ft”- id: 12currency: nulltype:
    totalcontainer_size: “40ft_hc” |'
  prefs: []
  type: TYPE_TB
- en: Table 8.4 – Wove file improvement steps (some data are truncated)
  prefs: []
  type: TYPE_NORMAL
- en: 'The table shows the description of the destination, aka dest (via port), generated
    in the middle column: “The port in the United States that the shipment will go…”.
    However, the data includes Vancouver, Canada. Although the destination is always
    the US, the port it goes via might be outside the US.'
  prefs: []
  type: TYPE_NORMAL
- en: To improve the model, this hallucination needs to be corrected. It could be
    decided that the correct answer is to edit this to be “North America,” or better
    is to remove the “in the United States” entirely, making the description more
    generic. This means that the output file in the next step also needs correction.
    The `destination_via_country` field will be changed from United States to `null`.
    This file on the right is a second round of ChatGPT generation, creating the unified
    model that makes all the spreadsheet data a consistent, normalized output. It
    is vital to catch these errors. With this final output file, they re-run the test
    data to see whether the quality improves.
  prefs: []
  type: TYPE_NORMAL
- en: Overall, this fine-tuning process requires many iterations on the prompts, editing
    of the tags, and evaluating against their test data. We can’t expose all of Wove’s
    secret sauce, but hopefully, this gives a sense. A modeler’s work is never done.
    Although ongoing effort might be reduced, work will not be done. Format changes
    can occur, including new vendors, normalizations, better, cheaper, and faster
    models, and everyone’s favorite, bugs will require rework. The point is to be
    involved and invested in these steps to ensure quality. Readers can imagine the
    next steps for Wove once all this data is normalized and available. Customers
    will want to ask questions about the best route based on shipping characteristics.
    They will not want to pour through even a normalized sheet of rates.
  prefs: []
  type: TYPE_NORMAL
- en: This is an exciting use case because it starts as a backend solution, still
    needs product understanding and feedback to be successful, and will likely lead
    to even more UX efforts when (inevitability) a customer-facing chat experience
    will converse with customers to help shop rates. Product and UX efforts will be
    needed there.
  prefs: []
  type: TYPE_NORMAL
- en: Wove used a series of models to understand the complexities of tables. Picking
    and chaining suitable models is part of the prompt engineering and fine-tuning
    process.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Fine-tuning is the most technical piece of this book. With this little glimpse
    into this world, there is much to cover. Your data scientists and engineers will
    go deeper. When building production-ready systems, mix and match fine-tuned and
    generic models with internal software and third-party tools to balance speed of
    delivery, price, and performance (recall the saying, *cheap, fast, or good, choose
    two*). Innovative solutions have workflow steps that allow the solution to bail
    out if the AI isn’t performing, use a function to solve or address a specific
    problem, or use a more deterministic element to provide a robust solution. Injecting
    the suitable model and prompts for the correct part of a use case is one of the
    most critical decisions. Do this work before embarking on the fine-tuning approach.
  prefs: []
  type: TYPE_NORMAL
- en: Contribute to the process by helping define and improve these task flows through
    use case expertise, editing and improving prompts, creating, verifying, and editing
    fine-tuning examples, and monitoring if changes are moving the solution in the
    right direction. Go forth and tune!
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 9*](B21964_09_split_000.xhtml#_idTextAnchor190), *Guidelines and
    Heuristics,* will cover guidelines and heuristics to support prompting and fine-tuning
    efforts based on well-documented techniques in the design community to help explain
    conversational AI’s usability.'
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '| ![](img/B21964_08_QR.jpg) | The links, book recommendations, and GitHub files
    in this chapter are posted on the reference page.Web Page: [Chapter 8 References](https://uxdforai.com/references#C8)
    ([https://uxdforai.com/references#C8](https://uxdforai.com/references#C8)) |'
  prefs: []
  type: TYPE_TB
