<html><head></head><body>
<div><h1 class="chapter-number" id="_idParaDest-141"><a id="_idTextAnchor151"/>8</h1>
<h1 id="_idParaDest-142"><a id="_idTextAnchor152"/>Extracting Entities and Generating Code with Amazon Bedrock</h1>
<p>This chapter uncovers the realm of entity extraction, a crucial technique in NLP. We will explore the intricacies of entity extraction applications, providing a comprehensive understanding of implementing entity extraction using Amazon Bedrock. Through real-world use cases, you will gain insights into the practical applications of entity extraction across various domains.</p>
<p>Furthermore, the chapter will guide you through the exciting world of generative AI for code generation. We will investigate the underlying principles and methodologies that enable AI systems to generate code snippets, functions, and even entire applications. You will learn how to leverage Amazon Bedrock to streamline your development workflows and enhance productivity.</p>
<p>By mastering these techniques, you will be equipped with the knowledge and skills to tackle complex NLP tasks and harness the power of generative AI in your coding endeavors.</p>
<p>The following topics will be covered in detail:</p>
<ul>
<li>Entity extraction – a comprehensive exploration</li>
<li>Industrial use cases of entity extraction – unleashing the power of unstructured data</li>
<li>Entity extraction with Amazon Bedrock</li>
<li>Code generation with LLMs – unleashing the power of AI-driven development</li>
</ul>
<h1 id="_idParaDest-143"><a id="_idTextAnchor153"/>Technical requirements</h1>
<p>This chapter requires you to have access to an AWS account. If you don’t have one already, you can go to <a href="https://aws.amazon.com/getting-started/">https://aws.amazon.com/getting-started/</a> and create an AWS account.</p>
<p>Secondly, you will need to install and configure the AWS CLI from <a href="https://aws.amazon.com/cli/">https://aws.amazon.com/cli/</a> after you create an account, which will be needed to access Amazon Bedrock FMs from your local machine. Since the majority of the code cells we will be executing are based on Python, setting up an AWS Python SDK (Boto3) at <a href="https://docs.aws.amazon.com/bedrock/latest/APIReference/welcome.html">https://docs.aws.amazon.com/bedrock/latest/APIReference/welcome.html</a> would be beneficial at this point. You can carry out the Python setup in the following manner: install it on your local machine, use AWS Cloud9 or AWS Lambda, or leverage Amazon SageMaker.</p>
<p class="callout-heading">Note</p>
<p class="callout">There will be a charge associated with the invocation and customization of Amazon Bedrock FMs. Please refer to <a href="https://aws.amazon.com/bedrock/pricing/">https://aws.amazon.com/bedrock/pricing/</a> to learn more.</p>
<h1 id="_idParaDest-144"><a id="_idTextAnchor154"/>Entity extraction – a comprehensive exploration</h1>
<p>In the era of big data and information overload, the ability to extract meaningful insights from unstructured text data has become increasingly <a id="_idIndexMarker636"/>valuable. <strong class="bold">Entity extraction</strong>, a subfield of NLP, plays a pivotal role in this endeavor by identifying and classifying named entities within text, such as people, organizations, locations, and more. This process not only facilitates information retrieval and knowledge management but also enables a wide<a id="_idIndexMarker637"/> range of applications, including <strong class="bold">question-answering</strong>, sentiment<a id="_idIndexMarker638"/> analysis, and <strong class="bold">decision support </strong><strong class="bold">systems</strong> (<strong class="bold">DSSs</strong>).</p>
<p>The journey of entity extraction began with simple pattern-matching and rule-based systems, which relied heavily on manually crafted rules and lexicons. These methods, while useful, lacked scalability and robustness when dealing with diverse and complex datasets.</p>
<p>Hence, traditionally, entity extraction has been a challenging task, requiring extensive manual effort and domain-specific knowledge.  However, the advent of generative AI, particularly LLMs, has revolutionized this field, offering more accurate, scalable, and efficient solutions. In this chapter, we will explore the various techniques employed by LLMs on Amazon Bedrock for entity extraction, diving into their underlying architectures, strengths, and limitations.</p>
<h2 id="_idParaDest-145"><a id="_idTextAnchor155"/>Deep learning approaches</h2>
<p>The advent of<a id="_idIndexMarker639"/> machine learning introduced statistical models that leveraged feature engineering. These models, including <strong class="bold">hidden Markov models</strong> (<strong class="bold">HMMs</strong>) and <strong class="bold">conditional random fields</strong> (<strong class="bold">CRFs</strong>), represented a <a id="_idIndexMarker640"/>significant step forward. They utilized <a id="_idIndexMarker641"/>hand-crafted features and probabilistic frameworks to improve extraction accuracy. However, their performance was still limited by the quality and comprehensiveness of the features engineered by experts.</p>
<p>Neural networks marked a paradigm shift in entity extraction by automating feature learning and capturing intricate patterns within the data. Early applications of neural networks, such<a id="_idIndexMarker642"/> as <strong class="bold">recurrent NNs</strong> (<strong class="bold">RNNs</strong>) and <strong class="bold">long short-term memory networks</strong> (<strong class="bold">LSTMs</strong>), demonstrated the potential of deep learning in <a id="_idIndexMarker643"/>handling sequential data and extracting entities with greater accuracy.</p>
<p>While models such as BERT and its successors represent a significant leap in NLP, our focus will remain on models and techniques that align with the practical applications and tools used in Bedrock. We will explore some deep learning approaches and models that have proven effective in various scenarios and are relevant to our framework.</p>
<h3>Transformer-based models</h3>
<p>Transformer <a id="_idIndexMarker644"/>architectures, introduced by the seminal paper <em class="italic">Attention is All You Need</em> (<em class="italic">Vaswani et al.</em>, <em class="italic">2017</em>: <a href="https://arxiv.org/abs/1706.03762">https://arxiv.org/abs/1706.03762</a>), have become the backbone of many SOTA LLMs for entity extraction. These models employ self-attention mechanisms to capture long-range dependencies within the input text, enabling them to better understand the context and relationships between entities.</p>
<p>BERT, developed by Google AI, is a prominent example of a transformer-based model that has achieved exceptional results in various NLP tasks, including entity extraction. It is a bidirectional model, meaning it can process text in both directions simultaneously, allowing it to capture contextual information more effectively than its predecessors.</p>
<h3>Sequence labeling and CRFs</h3>
<p>Entity extraction<a id="_idIndexMarker645"/> can be framed as a sequence labeling problem, where each token in the input text is assigned a label indicating its entity type (for example, person, organization, location) or a non-entity label. LLMs can be trained to perform this task by leveraging techniques such as CRFs or the more<a id="_idIndexMarker646"/> recent <strong class="bold">bidirectional LSTM with CRF</strong> (<strong class="bold">BiLSTM-CRF</strong>) architecture.</p>
<p><strong class="bold">CRFs</strong> are probabilistic<a id="_idIndexMarker647"/> graphical models that can effectively capture the dependencies between labels in a sequence, making them well suited for entity extraction tasks. They model the conditional probability of label sequences given the input text, allowing for the incorporation of rich features and contextual information.</p>
<p><strong class="bold">BiLSTM-CRF models</strong> combine <a id="_idIndexMarker648"/>the strengths of BiLSTMs for capturing long-range dependencies and CRFs for sequence labeling. This hybrid approach has shown impressive performance in entity extraction, particularly in scenarios where entities may span multiple<a id="_idIndexMarker649"/> tokens or have complex structures.</p>
<h2 id="_idParaDest-146"><a id="_idTextAnchor156"/>Rule-based systems</h2>
<p>While deep learning approaches<a id="_idIndexMarker650"/> have gained significant <a id="_idIndexMarker651"/>traction in recent years, rule-based systems remain valuable tools in the entity extraction domain. These systems rely on manually crafted rules and patterns to identify and classify entities within text, leveraging domain-specific knowledge and expert insights. These rules can be augmented to the prompt template when invoking Amazon Bedrock in order to generate a desirable response from the FMs. For example, in a medical application, the rule-based component might identify drug names, dosages, and patient information using predefined patterns.</p>
<h3>Regular expressions and pattern matching</h3>
<p><strong class="bold">Regular expressions</strong> and <strong class="bold">pattern-matching</strong> techniques <a id="_idIndexMarker652"/>are fundamental building blocks of rule-based <a id="_idIndexMarker653"/>entity <a id="_idIndexMarker654"/>extraction systems. These methods allow for the definition of patterns that can match and extract specific entity types, such as phone numbers, email addresses, or specific named entities (for example, company names and product names).</p>
<p>While regular expressions can be effective for well-defined and structured entity types, they may struggle with more complex or ambiguous entities that require contextual understanding. Nevertheless, they remain valuable tools, particularly in combination with other techniques or as a preprocessing step for more advanced methods. Here are some examples:</p>
<ul>
<li><strong class="bold">Ruleset</strong>: Define rules using regular expressions and pattern matching to identify specific entities such as drug names, dosages, and patient information</li>
<li><code>\d+mg</code> (for example, <code>500mg</code>)</li><li>Patient information <a id="_idIndexMarker655"/>can <a id="_idIndexMarker656"/>be identified <a id="_idIndexMarker657"/>through patterns such as <code>Patient: [A-Za-z]+</code></li></ul></li>
</ul>
<h3>Gazetteer lists and dictionaries</h3>
<p><strong class="bold">Gazetteer lists</strong> and <strong class="bold">dictionaries</strong> are curated <a id="_idIndexMarker658"/>collections <a id="_idIndexMarker659"/>of known entities, often organized by entity type <a id="_idIndexMarker660"/>or domain. These resources can be used to match and extract entities within text by performing lookups against predefined lists.</p>
<p>For example, a gazetteer of geographic locations can be employed to identify and extract mentions of cities, countries, or other places in a given text. Similarly, dictionaries of person names or organization names can ease the extraction of these entity types.</p>
<p>While gazetteer lists and dictionaries can be highly accurate for the entities they cover, they may struggle with ambiguity, variations, or newly emerging entities not present in the predefined lists. Additionally, maintaining and updating these resources can be a labor-intensive process, especially in rapidly evolving domains.</p>
<h2 id="_idParaDest-147"><a id="_idTextAnchor157"/>Hybrid approaches</h2>
<p>In practice, many entity <a id="_idIndexMarker661"/>extraction systems employ a <a id="_idIndexMarker662"/>combination of deep learning and rule-based techniques, leveraging the strengths of both approaches to achieve optimal performance. These hybrid approaches aim to strike a balance between the flexibility and generalization capabilities of deep learning models and the precision and interpretability of rule-based systems.</p>
<h3>Ensemble methods</h3>
<p><strong class="bold">Ensemble methods</strong> involve combining the outputs of multiple entity extraction models, potentially <a id="_idIndexMarker663"/>using different architectures <a id="_idIndexMarker664"/>or techniques, to improve overall performance. This approach can leverage the strengths of individual models while mitigating their weaknesses, resulting in more robust and accurate entity extraction.</p>
<p>For example, an ensemble system might combine the predictions of a transformer-based model such as BERT with those of a rule-based system or a gazetteer lookup. The outputs of these models can be combined using various strategies, such as majority voting, weighted averaging, or more sophisticated ensemble learning techniques.</p>
<h3>Hybrid architectures</h3>
<p><strong class="bold">Hybrid architectures</strong> integrate<a id="_idIndexMarker665"/> deep learning and rule-based <a id="_idIndexMarker666"/>components within a single model, allowing for the seamless integration of both approaches. These architectures often involve a deep learning component for learning representations and capturing contextual information, combined with rule-based components for incorporating domain-specific knowledge or handling well-defined entity types.</p>
<p>One example of a hybrid architecture is the use of LLMs for entity representation learning, followed by a rule-based component for entity classification or extraction. The LLM component can learn rich representations of the input text, capturing contextual information and long-range dependencies, while the rule-based component can leverage expert knowledge and precise patterns for entity identification and classification. For instance, consider an application designed to extract financial information from corporate earnings reports. Here’s a detailed example of how a hybrid architecture can be implemented:</p>
<ul>
<li><code>revenue</code>, <code>net income</code>, and <code>operating expenses</code>.</li>
<li><code>revenue</code>, <code>net income</code>, or <code>expenses</code>.</li><li>Extracting dates and fiscal periods using regular expressions.</li><li>Recognizing company-specific terminology and abbreviations.</li></ul></li>
</ul>
<p>The rule-based system analyzes the LLM-generated representations, applying these rules to accurately extract specific financial entities.</p>
<p>Let’s now look at how the representations are integrated and optimized:</p>
<ul>
<li><strong class="bold">Pipeline</strong>: The system processes the earnings report through the LLM, which outputs rich text representations. These representations are then fed into the rule-based component.</li>
<li><strong class="bold">Output</strong>: The final output includes precisely extracted financial entities, such as revenue figures, net income amounts, and fiscal periods, all verified and categorized according to the predefined rules.</li>
</ul>
<p>By employing<a id="_idIndexMarker667"/> such <a id="_idIndexMarker668"/>a hybrid approach on Amazon Bedrock, the application leverages the comprehensive text understanding provided by LLMs and the precision and reliability of rule-based extraction methods. This approach ensures that entity extraction is more accurate and contextually aware, making it useful for complex domains such as financial analysis.</p>
<p>In order to gain a deeper understanding of hybrid LLM frameworks, readers are encouraged to read these papers: <em class="italic">Hybrid LLM-Rule-based Approaches to Business Insights Generation from Structured Data</em> (https://arxiv.org/pdf/2404.15604) and <em class="italic">An innovative hybrid approach for extracting named entities from unstructured text </em><em class="italic">data </em>(https://www.researchgate.net/publication/332676137_An_innovative_hybrid_approach_for_extracting_named_entities_from_unstructured_text_data).</p>
<p>In this section, we covered different approaches (deep learning, rule-based, and hybrid approaches) associated<a id="_idIndexMarker669"/> with entity extraction. Now that we have a basic understanding of these approaches, let us <a id="_idIndexMarker670"/>dive into some industrial use cases of entity extraction.</p>
<h1 id="_idParaDest-148"><a id="_idTextAnchor158"/>Industrial use cases of entity extraction – unleashing the power of unstructured data</h1>
<p>Entity extraction<a id="_idIndexMarker671"/> has numerous applications across various domains, ranging from information retrieval and knowledge management to DSSs <a id="_idIndexMarker672"/>and <strong class="bold">business intelligence</strong> (<strong class="bold">BI</strong>). In this section, we will explore some practical use cases and applications of entity extraction with GenAI:</p>
<ul>
<li><code>Google was founded by Larry Page and Sergey Brin while they were Ph.D. students at </code><code>Stanford University.</code></li></ul><p class="list-inset">With entity extraction, the following information can be extracted:</p><ul><li><code>Google (Organization)</code></li><li><code>Larry </code><code>Page (Person)</code></li><li><code>Sergey </code><code>Brin (Person)</code></li><li><code>Stanford </code><code>University (Organization</code>)</li></ul></li></ul></li>
<li><code>founded by</code> (<code>Google</code> -&gt; <code>Larry Page and Sergey Brin</code>) and <code>studied at</code> (<code>Larry Page and Sergey Brin</code> -&gt; <code>Stanford University</code>), are established as edges connecting the nodes. This structured representation <a id="_idIndexMarker673"/>allows for efficient querying and reasoning over the information.</li>
<li><code>Google (Organization)</code></li><li><code>Larry </code><code>Page (Person)</code></li><li><code>Sergey </code><code>Brin (Person)</code></li><li><code>Stanford </code><code>University (Organization)</code></li></ul></li><li><code>Google -&gt; Founded by -&gt; </code><code>Larry Page</code></li><li><code>Google -&gt; Founded by -&gt; </code><code>Sergey Brin</code></li><li><code>Larry Page -&gt; Studied at -&gt; </code><code>Stanford University</code></li><li><code>Sergey Brin -&gt; Studied at -&gt; </code><code>Stanford University</code></li></ul></li></ul></li>
</ul>
<p>LLMs on Amazon Bedrock can be employed for accurate and scalable entity extraction, facilitating the creation of comprehensive knowledge graphs from diverse data sources, such as news articles, scientific publications, or social media posts. These knowledge graphs can power various applications, including question answering systems, recommendation engines, and decision support tools. Here are some examples:</p>
<ul>
<li><strong class="bold">Biomedical and scientific literature analysis</strong>: Entity extraction is particularly valuable in the biomedical and scientific domains, where vast amounts of unstructured text data are generated through research publications, clinical notes, and other sources. Identifying and classifying entities such as genes, proteins, diseases, and chemical compounds can enable researchers and healthcare professionals to quickly navigate and extract insights from this wealth of information.<p class="list-inset">LLMs in Amazon Bedrock can be fine-tuned on domain-specific datasets to achieve high accuracy in extracting biomedical and scientific entities. These models can assist in literature review processes, drug discovery pipelines, and the development of knowledge bases for precision medicine and personalized healthcare.</p></li>
<li><strong class="bold">BI and competitive analysis</strong>: In the business world, entity extraction can be leveraged for competitive analysis, market research, and BI applications. By extracting entities such as company names, product names, and industry-specific terms from news articles, social media posts, and other online sources, businesses can gain valuable insights into their competitors, market trends, and customer sentiment.<p class="list-inset">Amazon Bedrock APIs can be coupled <a id="_idIndexMarker674"/>with <strong class="bold">BI platforms</strong> (<strong class="bold">BIPs</strong>) and analytics tools, enabling real-time entity extraction and analysis of vast amounts of unstructured data. This can empower data-driven decision-making, strategic planning, and the identification of new business opportunities.</p></li>
<li><strong class="bold">Social media monitoring and sentiment analysis</strong>: Social media platforms generate a constant stream of user-generated content, containing valuable information about public opinion, trends, and sentiment toward various entities, such as brands, products, or public figures. Entity extraction plays a crucial role in social media monitoring and sentiment analysis by identifying the relevant entities within this unstructured data.</li>
</ul>
<p>LLMs in Amazon <a id="_idIndexMarker675"/>Bedrock can be employed to accurately extract entities from social media posts, enabling sentiment analysis and opinion mining around these entities. This can provide businesses with valuable insights into customer feedback, brand perception, and potential issues or opportunities, allowing them to respond proactively and shape their marketing and communication strategies accordingly.</p>
<p>In this section, we covered industrial applications applicable in the context of entity extraction. Keep in mind that the number of these use cases can increase exponentially as we uncover more diverse scenarios across different industries. Now, let us learn how to leverage <a id="_idIndexMarker676"/>Amazon Bedrock for entity extraction use cases.</p>
<h1 id="_idParaDest-149"><a id="_idTextAnchor159"/>Entity extraction with Amazon Bedrock</h1>
<p>At its core, entity <a id="_idIndexMarker677"/>extraction with GenAI involves providing <a id="_idIndexMarker678"/>a prompt that instructs the model to identify and classify relevant entities within a given text input. The key is constructing prompts that are clear, consistent, and provide enough examples for the model to understand the desired behavior.</p>
<p>The Amazon Bedrock service, with the ability to invoke LLMs in a serverless manner, provides a scalable and cost-effective solution for entity extraction. This service allows developers to leverage pre-trained models or fine-tune them on custom datasets, enabling tailored entity extraction for specific domains or use cases.</p>
<h2 id="_idParaDest-150"><a id="_idTextAnchor160"/>Structuring prompts for entity extraction</h2>
<p>When designing <a id="_idIndexMarker679"/>prompts for entity extraction tasks, it’s essential to provide clear instructions and examples to the model. A well-structured prompt typically includes the following components:</p>
<ul>
<li><code>Identify and classify the following entities in the </code><code>given text</code>.</li>
<li><code>Person</code>, <code>Organization</code>, <code>Location</code>, and so on.</li>
<li><strong class="bold">Example inputs and outputs</strong>: Include one or more examples of input text with the corresponding entities annotated. This helps the model understand the desired output format and learn from real-world instances.</li>
</ul>
<p>The following is an example prompt:</p>
<p><code>'''</code></p>
<p><code>: Identify and classify the following entities in the </code><code>given text:</code></p>
<p><code>Entity Types: Person, </code><code>Organization, Location</code></p>
<p><code>: "Michael Jordan, the legendary basketball player for the Chicago Bulls, announced his retirement from the NBA after an </code><code>illustrious career."</code></p>
<p><code>The output looks </code><code>like this:</code></p>
<pre class="console">
[Person: Michael Jordan], [Organization: Chicago Bulls], [Location: NBA]</pre>
<p><code>Let's look at </code><code>another example:</code></p>
<p><code>: "Apple Inc., the tech giant based in Cupertino, California, unveiled its latest iPhone model at a </code><code>press event."</code></p>
<p><code>The output looks </code><code>like this:</code></p>
<pre class="console">
[Organization: Apple Inc.], [Location: Cupertino], [Location: California]</pre>
<p><code>'''</code></p>
<p>Let’s explore these use cases through a code example and generate an output by invoking an Anthropic<a id="_idIndexMarker680"/> Claude 3 Sonnet FM on Amazon Bedrock.</p>
<p class="callout-heading">Note</p>
<p class="callout">Please ensure that you have the required libraries, such as <code>boto3</code>, installed to run the code. If not, please install the library using the <code>pip install boto3</code> command in your editor.</p>
<p class="callout">Additionally, ensure that you have enabled access to the models available on Amazon Bedrock. For further documentation on model access on Bedrock, please visit https://docs.aws.amazon.com/bedrock/latest/userguide/model-access.html.</p>
<pre class="source-code">
# Import the respective libraries
import boto3
import botocore
import os
import json
import sys
#Create client-side Amazon Bedrock connection with Boto3 library
region = os.environ.get("AWS_REGION")
bedrock_runtime = boto3.client(service_name='bedrock-runtime',region_name=region)
prompt_data = """
Human: You are a helpful AI assistant. If you are unsure about the answer, say I do not know. Skip the preamble.
Task: Identify and classify the following entities in the given text:
Entity Types: Person, Organization, Location
Input Text: "Michael Jordan, the legendary basketball player for the Chicago Bulls, announced his retirement from the NBA after an illustrious career."
Assistant:
"""
messages=[{ "role":'user', "content":[{'type':'text','text': prompt_data}]}]
body=json.dumps(
        {
            "anthropic_version": "bedrock-2023-05-31",
            «max_tokens»: 512,
            «messages»: messages,
            «temperature»: 0.1,
            "top_p": 1
        }
    )
response = bedrock_runtime.invoke_model(body=body, modelId="anthropic.claude-3-sonnet-20240229-v1:0")
response_body = json.loads(response.get('body').read())
print(response_body['content'][0].get("text"))</pre>
<p>Here’s a sample output from the FM:</p>
<div><div><img alt="Figure 8.1 – Sample output" src="img/B22045_08_01.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.1 – Sample output</p>
<p>While this <a id="_idIndexMarker681"/>basic structure works for simple cases, more advanced prompting techniques are needed for robust, production-level entity extraction.</p>
<h2 id="_idParaDest-151"><a id="_idTextAnchor161"/>Incorporating context and domain knowledge</h2>
<p>Entity extraction scenarios <a id="_idIndexMarker682"/>often benefit from contextual information and domain-specific knowledge. By providing relevant background or domain-specific details within the prompt, you can enhance the model’s understanding and improve its ability to accurately identify entities.</p>
<p>Here’s an example prompt with context:</p>
<p><code>```</code></p>
<p><code>: Identify and classify entities related to sports in the </code><code>given text.</code></p>
<p><code>Entity Types: Athlete, Team, </code><code>Tournament, Sport</code></p>
<p><code>: This text discusses sports events, teams, and athletes involved in various </code><code>sports competitions.</code></p>
<p><code>: "Serena Williams, a well renowned Tennis player, defeated Venus Williams to win 23rd Grand Slam title at the 2017 </code><code>Australian Open."</code></p>
<p><code>The output looks </code><code>like this:</code></p>
<pre class="console">
[Athlete: Serena Williams], [Athlete: Venus Williams], [Tournament: Grand Slam], [Tournament: Australian Open], [Sport: tennis]</pre>
<p><code>```</code></p>
<p>In <em class="italic">Figure 8</em><em class="italic">.2</em>, the code<a id="_idIndexMarker683"/> sample for the preceding use case is depicted. It’s important to note that the code does not explicitly mention the installed libraries. It is assumed that users have already pre-installed the required Python packages and libraries, as detailed in the previous code sample:</p>
<div><div><img alt="Figure 8.2 – Prompting Amazon Bedrock FM for entity extraction with contextual information" src="img/B22045_08_02.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.2 – Prompting Amazon Bedrock FM for entity extraction with contextual information</p>
<p>It might produce favorable output for certain FMs based on the input instructions. However, in other<a id="_idIndexMarker684"/> scenarios, it has the potential to generate hallucinated or irrelevant additional information, as demonstrated in <em class="italic">Figure 8</em><em class="italic">.3</em>. Therefore, employing few-shot prompting can be advantageous for entity extraction in such cases:</p>
<div><div><img alt="Figure 8.3 – AI21 Labs J2 Jumbo Instruct FM output" src="img/B22045_08_03.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.3 – AI21 Labs J2 Jumbo Instruct FM output</p>
<h2 id="_idParaDest-152"><a id="_idTextAnchor162"/>Leveraging few-shot learning</h2>
<p>As you are aware, few-shot <a id="_idIndexMarker685"/>learning involves providing the model with a small number of labeled examples during training or inference. This approach can be particularly effective for entity extraction tasks, as it allows the model to learn from a limited set of high-quality examples and generalize to new, unseen data.</p>
<p>Here’s an example prompt with few-shot learning:</p>
<p><code>```</code></p>
<p><code>: Identify and classify entities related to technology companies in the </code><code>given text.</code></p>
<p><code>: Company, </code><code>Product, Location</code></p>
<p><code>:</code></p>
<p><code>: "Microsoft, based in Redmond, Washington, unveiled its latest operating system, Windows 11, at a </code><code>virtual event."</code></p>
<p><code>The output looks </code><code>like this:</code></p>
<pre class="console">
[Company: Microsoft], [Product: Windows 11], [Location: Redmond], [Location: Washington]</pre>
<p><code>Here's </code><code>another example:</code></p>
<p><code>: "Google's parent company, Alphabet Inc., announced plans to expand its data center operations in Iowa </code><code>and Nevada."</code></p>
<p><code>The output looks </code><code>like this:</code></p>
<pre class="console">
[Company: Alphabet Inc.], [Company: Google], [Location: Iowa], [Location: Nevada]</pre>
<p><code>Let's look at </code><code>another example:</code></p>
<p><code>: "Samsung Electronics, the South Korean tech giant, launched its new flagship smartphone, the Galaxy S22, featuring a powerful camera and improved </code><code>battery life."</code></p>
<p><code>The output looks </code><code>like this:</code></p>
<pre class="console">
[Company: Samsung Electronics], [Product: Galaxy S22], [Location: South Korea]</pre>
<p><code>Now, look at the following </code><code>use case:</code></p>
<p><code>: "Amazon, the e-commerce behemoth based in Seattle, Washington, unveiled its latest line of Echo smart speakers and Alexa-powered devices at a </code><code>hardware event."</code></p>
<p><code>```</code></p>
<p>Let’s craft a code sample for the preceding use case and invoke the Amazon Titan model on Amazon<a id="_idIndexMarker686"/> Bedrock:</p>
<pre class="source-code">
# Import the respective libraries
import boto3
import botocore
import os
import json
import sys
#Create client-side Amazon Bedrock connection with Boto3 library
region = os.environ.get("AWS_REGION")
bedrock_runtime = boto3.client(service_name='bedrock-runtime',region_name=region)
prompt_data = """Task: Identify and classify entities related to technology companies in the given text.
Entity Types: Company, Product, Location
Few-Shot Examples:
Input Text: "Microsoft, based in Redmond, Washington, unveiled its latest operating system, Windows 11, at a virtual event."
Output: [Company: Microsoft], [Product: Windows 11], [Location: Redmond], [Location: Washington]
Input Text: "Google's parent company, Alphabet Inc., announced plans to expand its data center operations in Iowa and Nevada."
Output: [Company: Alphabet Inc.], [Company: Google], [Location: Iowa], [Location: Nevada]
Input Text: "Samsung Electronics, the South Korean tech giant, launched its new flagship smartphone, the Galaxy S22, featuring a powerful camera and improved battery life."
Output: [Company: Samsung Electronics], [Product: Galaxy S22], [Location: South Korea]
Your Input Text: "Amazon, the e-commerce behemoth based in Seattle, Washington, unveiled its latest line of Echo smart speakers and Alexa-powered devices at a hardware event."
Output:
"""
body = {
    "inputText": prompt_data
}
modelId = "amazon.titan-tg1-large"
accept = «application/json»
contentType = «application/json»
response = invoke_model(body, modelId, accept, contentType)
response_body = json.loads(response.get("body").read())
print(response_body.get("results")[0].get("outputText"))</pre>
<p>Executing the preceding code generates the following output, as shown in <em class="italic">Figure 8</em><em class="italic">.4</em>:</p>
<pre class="console">
[Company: Amazon], [Product: Echo smart speakers, Alexa-powered devices], [Location: Seattle], [Location: Washington]</pre>
<div><div><img alt="Figure 8.4 – Generated output from Amazon Titan FM" src="img/B22045_08_04.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.4 – Generated output from Amazon Titan FM</p>
<p>Therefore, in this example, the prompt offers a set of labeled instances to assist the model in understanding the entity extraction task within the technology domain. Through the<a id="_idIndexMarker687"/> utilization of few-shot learning, the model can proficiently generalize to unfamiliar input text, all while upholding a high level of accuracy.</p>
<h2 id="_idParaDest-153"><a id="_idTextAnchor163"/>Iterative refinement and evaluation</h2>
<p>Prompt engineering <a id="_idIndexMarker688"/>constitutes an iterative process that frequently necessitates refinement and evaluation. As you explore various prompts and techniques, it’s vital to assess the model’s performance through automatic model evaluation or human evaluation methods, as elaborated upon in <a href="B22045_11.xhtml#_idTextAnchor207"><em class="italic">Chapter 11</em></a>. Through careful analysis of the model’s outputs and identifying areas for enhancement, you can iteratively refine your prompts, thereby augmenting the overall accuracy of your entity extraction system.</p>
<p>Take a look at the following example of model analysis and refinement:</p>
<p><code>'''</code></p>
<p><code>:</code></p>
<p><code>: Identify and classify entities in the </code><code>given text.</code></p>
<p><code>Entity Types: Person, </code><code>Organization, Location</code></p>
<p><code>: "Elon Musk, the CEO of Tesla Inc., announced plans to build a new Gigafactory in </code><code>Austin, Texas."</code></p>
<p><code>The output looks </code><code>like this:</code></p>
<pre class="console">
[Person: Elon Musk], [Organization: Tesla Inc.], [Location: Austin]</pre>
<p><code>: The model correctly identified the person and organization entities but missed the </code><code>location "Texas."</code></p>
<p><code>:</code></p>
<p><code>: Identify and classify entities in the given text, including nested or </code><code>multi-word entities.</code></p>
<p><code>Entity Types: Person, </code><code>Organization, Location</code></p>
<p><code>: "Elon Musk, the CEO of Tesla Inc., announced plans to build a new Gigafactory in </code><code>Austin, Texas."</code></p>
<p><code>The output looks </code><code>like this:</code></p>
<pre class="console">
[Person: Elon Musk], [Organization: Tesla Inc.], [Location: Austin, Texas]</pre>
<p><code>'''</code></p>
<p>By refining the prompt to include instructions for handling nested or multi-word entities, the model’s performance improved, correctly identifying the location as Austin, Texas.</p>
<p>We encourage <a id="_idIndexMarker689"/>users to run the provided code on Amazon Bedrock to extract pertinent entities using the Claude 3 model and the <code>Messages</code> API. As mentioned earlier, please ensure that access to these models on Amazon Bedrock is enabled. For further documentation on accessing models on Bedrock, please visit <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/model-access.html">https://docs.aws.amazon.com/bedrock/latest/userguide/model-access.html</a>.</p>
<p class="callout-heading">Note</p>
<p class="callout">Make sure you have the <code>boto3</code> library installed, as explained in the previous chapters. If not, please install the latest version using the following command: <code>pip </code><code>install boto3</code>.</p>
<pre class="source-code">
#importing the relevant libraries
import boto3
import json
#Creating Bedrock client and region
bedrock_client = boto3.client('bedrock-runtime',region_name='us-east-1')
prompt = """
Task: Identify and classify entities in the given text.
Entity Types: Person, Organization, Location
Input Text: "Elon Musk, the CEO of Tesla Inc., announced plans to build a new Gigafactory in Austin, Texas.
Output:
"""
messages = [{ "role":'user', "content":[{'type':'text','text': prompt}]}]
max_tokens=512
top_p=1
temp=0.5
system = "You are an AI Assistant"
body=json.dumps(
        {
            "anthropic_version": "bedrock-2023-05-31",
            «max_tokens»: max_tokens,
            «messages»: messages,
            "temperature": temp,
            "top_p": top_p,
            "system": system
        }
    )
response = bedrock_client.invoke_model(body= body, modelId = "anthropic.claude-3-sonnet-20240229-v1:0")
response_body = json.loads(response.get('body').read())
print(response_body)</pre>
<p>Printing <code>response_body</code> as shown in <a id="_idIndexMarker690"/>the preceding snippet might yield the following output, as expected:</p>
<pre class="console">
{'id': 'msg_01RqxLfg6hEEu1K8jY3g8gzq',
 'type': 'message',
 'role': 'assistant',
 'content': [{'type': 'text',
   'text': 'Person: Elon Musk\nOrganization: Tesla Inc.\nLocation: Austin, Texas'}],
 'model': 'claude-3-sonnet-28k-20240229',
 'stop_reason': 'end_turn',
 'stop_sequence': None,
 'usage': {'input_tokens': 71, 'output_tokens': 23}}</pre>
<p>Hence, by leveraging effective prompt engineering techniques with Amazon Bedrock, such as providing clear instructions, relevant examples, and handling ambiguity, GenAI models can be guided to perform high-quality entity extraction across several use cases and different domains. As with any AI application, it requires careful design, testing, and refinement to build a truly production-ready system.</p>
<p>As LLMs continue to grow in size and complexity, their capabilities in entity extraction are expected to further improve, enabling more accurate and robust solutions.</p>
<p>Ongoing research also focuses on integrating external knowledge sources such as knowledge graphs or ontologies into LLMs for entity extraction. By embedding structured knowledge into the model’s architecture or training regimen, these methods have the potential to enrich the model’s comprehension of entities and their interconnections, thereby potentially enhancing both performance and interpretability.</p>
<p>Check the following AWS blog showcasing the integration of <strong class="bold">intelligent document processing</strong> (<strong class="bold">IDP</strong>) in the <a id="_idIndexMarker691"/>context of entity extraction automation using AWS AI/ML services such as Amazon Textract with Amazon Bedrock and LangChain: <a href="https://aws.amazon.com/blogs/machine-learning/intelligent-document-processing-with-amazon-textract-amazon-bedrock-and-langchain/">https://aws.amazon.com/blogs/machine-learning/intelligent-document-processing-with-amazon-textract-amazon-bedrock-and-langchain/</a>.</p>
<p>This solution proves particularly beneficial for handling handwritten or scanned documents, encompassing the extraction of pertinent data from various file formats such as PDF, PNG, TIFF, and JPEG, regardless of the document layout. The Amazon Textract service<a id="_idIndexMarker692"/> facilitates the automatic extraction of text, handwriting, and data from such scanned documents.</p>
<p>Consequently, this solution capitalizes on the strengths of each component: Amazon Textract for precise data extraction, Amazon Bedrock for streamlined data processing pipelines, and LangChain for seamlessly integrating LLMs into the workflow. Overall, the blog post offers a pragmatic solution for automating document processing tasks, underscoring the advantages of leveraging AWS services and open source frameworks such as LangChain to develop intelligent applications. Therefore, it holds substantial potential for diverse document processing scenarios, providing dynamic adaptability to evolving data patterns.</p>
<p>Additional examples of entity extraction with Bedrock have been added here: <a href="https://github.com/aws-samples/amazon-bedrock-workshop/blob/main/01_Text_generation/04_entity_extraction.ipynb">https://github.com/aws-samples/amazon-bedrock-workshop/blob/main/01_Text_generation/04_entity_extraction.ipynb</a>. Users are encouraged to run and execute the code cells to gain a much better understanding of entity extraction using Amazon Bedrock for GenAI use cases.</p>
<p>Now that you<a id="_idIndexMarker693"/> have grasped the concepts of entity extraction in more detail, we will dive into more code generation scenarios in the universe of Amazon Bedrock.</p>
<h1 id="_idParaDest-154"><a id="_idTextAnchor164"/>Code generation with LLMs – unleashing the power of AI-driven development</h1>
<p>As the field of AI<a id="_idIndexMarker694"/> continues to evolve, one of the most exciting and promising areas is the use of LLMs for code generation, especially in the case of developer productivity gains. Customers can leverage state-of-the-art LLMs available on Amazon Bedrock to generate high-quality code, revolutionizing the way developers approach software development.</p>
<h2 id="_idParaDest-155"><a id="_idTextAnchor165"/>The code generation process</h2>
<p>The code generation<a id="_idIndexMarker695"/> process with Amazon Bedrock is straightforward and user-friendly. Developers can interact with the platform through a web-based interface or via an API, as discussed in the previous chapters. The process typically involves the following steps:</p>
<ol>
<li><strong class="bold">Problem description</strong>: The developer provides a natural language description of the desired functionality or task that they want the code to perform.</li>
<li><strong class="bold">Context and constraints</strong>: The developer can optionally provide additional context, such as programming language preferences, coding styles, or specific libraries or frameworks to be used.</li>
<li><strong class="bold">LLM code generation</strong>: Amazon Bedrock’s LLMs analyze the problem description and any provided context and generate the corresponding code.</li>
<li><strong class="bold">Code refinement</strong>: The generated code can be iteratively refined through additional prompts or feedback from the developer, allowing for a collaborative and interactive process.</li>
<li><strong class="bold">Code integration</strong>: The final generated code can be seamlessly integrated into the developer’s <a id="_idIndexMarker696"/>project or code base.</li>
</ol>
<h2 id="_idParaDest-156"><a id="_idTextAnchor166"/>Benefits of code generation with Amazon Bedrock</h2>
<p>Leveraging LLMs for code<a id="_idIndexMarker697"/> generation offers numerous benefits to developers, including the following:</p>
<ul>
<li><strong class="bold">Increased productivity</strong>: With Amazon Bedrock, developers can quickly generate code for various tasks and functionalities, reducing the time and effort required for manual coding</li>
<li><strong class="bold">Improved code quality</strong>: The code generated by Amazon Bedrock’s LLMs can provide high-quality outputs, adhering to best practices and coding standards based on the iterative refinement of the prompts</li>
<li><strong class="bold">Reduced errors</strong>: LLMs can help reduce the likelihood of common coding errors, such as syntax errors or logical flaws, by generating correct and coherent code with prompt engineering</li>
<li><strong class="bold">Exploration and prototyping</strong>: Bedrock enables developers to rapidly explore and prototype different ideas and approaches, facilitating more efficient and creative problem-solving</li>
<li><strong class="bold">Accessibility</strong>: By leveraging natural language descriptions and FMs for code generation purposes (Llama, Claude, Titan, Mistral, and so on), Amazon Bedrock makes code generation more accessible to developers with varying levels of expertise or backgrounds</li>
</ul>
<h2 id="_idParaDest-157"><a id="_idTextAnchor167"/>Limitations and considerations</h2>
<p>While LLM-based code generation offers numerous advantages, it is important to be aware of their limitations and<a id="_idIndexMarker698"/> considerations:</p>
<ul>
<li><strong class="bold">Specialized domain knowledge</strong>: LLMs may not always generate code that requires highly specialized domain knowledge or complex algorithms. Human expertise and review may still be necessary in certain cases.</li>
<li><strong class="bold">Security and compliance</strong>: Generated code should be thoroughly reviewed and tested to ensure it adheres to security best practices and any relevant compliance requirements.</li>
<li><strong class="bold">Integration and maintenance</strong>: Generated code may need to be adapted and maintained over time as requirements or dependencies change.</li>
<li><strong class="bold">Ethical considerations</strong>: As with any AI system, it is crucial to ensure LLMs are used responsibly<a id="_idIndexMarker699"/> and ethically, considering potential biases or unintended consequences.</li>
</ul>
<h2 id="_idParaDest-158"><a id="_idTextAnchor168"/>Use cases and examples</h2>
<p>Amazon Bedrock’s code<a id="_idIndexMarker700"/> generation capabilities can be applied to a wide range of use cases across various domains and programming languages. Some examples include the following:</p>
<ul>
<li><strong class="bold">Web development</strong>: Developers can generate code using Bedrock for web applications, APIs, or user interfaces using languages such as JavaScript, Python, or Ruby.</li>
<li><strong class="bold">Data processing and analysis</strong>: Developers can leverage Bedrock to write code for data manipulation, analysis, and visualization tasks using languages such as Python or R.</li>
<li><strong class="bold">Mobile app development</strong>: Bedrock can be utilized to generate code for mobile applications using languages such as Swift, Kotlin, or React Native.</li>
<li><strong class="bold">Embedded systems and Internet of Things (IoT) devices</strong>: Developers can create code for embedded systems, microcontrollers, or IoT devices using languages such as C, C++, or Rust with the assistance of Bedrock models.</li>
<li><strong class="bold">Scientific computing</strong>: Bedrock can aid in writing code for scientific simulations, numerical calculations, or data processing tasks using languages such as MATLAB, Julia, or Fortran through its code generation features.</li>
</ul>
<p>Now, let’s look at a few examples of code generation, debugging, or code transformation<a id="_idIndexMarker701"/> use cases with Amazon Bedrock.</p>
<h2 id="_idParaDest-159"><a id="_idTextAnchor169"/>Prompt engineering examples with Amazon Bedrock</h2>
<p>Here is a sample<a id="_idIndexMarker702"/> prompt<a id="_idIndexMarker703"/> given to a Claude 3 Sonnet model within Amazon Bedrock to adopt the role of a Python developer and perform a code generation task:</p>
<p><code>Human: You are an expert Python developer tasked with coding a web scraper for an experienced developer. The scraper should extract data from multiple web pages and store the results in a SQLite database. Write clean, high-quality Python code for this task, including necessary imports. Do not write anything before the ```python block. After writing the code, carefully check for errors. If errors exist, list them within &lt;error&gt; tags and provide a new corrected version. If no errors, write "CHECKED: NO ERRORS" within &lt;</code><code>error&gt; tags.</code></p>
<p><code>Assistant:</code></p>
<p><code>Let us execute this prompt in code using Anthropic Claude 3 model on Amazon Bedrock. As covered in the previous sections, please ensure you have the necessary libraries installed and have the required permissions to invoke the model on </code><code>Amazon Bedrock:</code></p>
<pre class="source-code">
# Import the respective libraries
import boto3
import botocore
import os
import json
import sys
#Create client side Amazon Bedrock connection with Boto3 library
region = os.environ.get("AWS_REGION")
bedrock_runtime = boto3.client(service_name='bedrock-runtime',region_name=region)
# Adding prompt example here:
prompt_data = """Human: You are an expert Python developer tasked with coding a web scraper for an experienced developer. The scraper should extract data from multiple web pages and store the results in a SQLite database. Write clean, high-quality Python code for this task, including necessary imports. Do not write anything before the ```python block. After writing the code, carefully check for errors. If errors exist, list them within &lt;error&gt; tags and provide a new corrected version. If no errors, write "CHECKED: NO ERRORS" within &lt;error&gt; tags.
Assistant:
"""
# Using Messages API with Anthropic Claude
messages=[{ "role":'user', "content":[{'type':'text','text': prompt_data}]}]
body=json.dumps(
        {
            "anthropic_version": "bedrock-2023-05-31",
            «max_tokens»: 512,
            «messages»: messages,
            «temperature»: 0.1,
            "top_p": 1
        }
    )
response = bedrock_runtime.invoke_model(body=body, modelId="anthropic.claude-3-sonnet-20240229-v1:0")
response_body = json.loads(response.get('body').read())</pre>
<p>We won’t dive into the entirety of the output generated, but provided in <em class="italic">Figure 8</em><em class="italic">.5</em> is a code snippet generated as a result of invoking a Claude 3 Sonnet model via Amazon Bedrock API<a id="_idIndexMarker704"/> with<a id="_idIndexMarker705"/> the preceding prompt:</p>
<div><div><img alt="Figure 8.5 – Output code snippet generated by invoking Claude 3 Sonnet model via Amazon Bedrock" src="img/B22045_08_05.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.5 – Output code snippet generated by invoking Claude 3 Sonnet model via Amazon Bedrock</p>
<p><em class="italic">Figure 8</em><em class="italic">.6</em> shows yet another example of a code debugging use case, leveraging a Llama 2 Chat 13B model available on Amazon Bedrock within the chat playground:</p>
<div><div><img alt="Figure 8.6 – Code debugging using Llama 2 Chat 13B model on Amazon Bedrock" src="img/B22045_08_06.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.6 – Code debugging using Llama 2 Chat 13B model on Amazon Bedrock</p>
<p>Now, let’s take a look at a code translation scenario. Here’s an example prompt for a code translation <a id="_idIndexMarker706"/>use<a id="_idIndexMarker707"/> case with a Mixtral 8X7B instruct model on Amazon Bedrock, followed by a generated output:</p>
<pre class="source-code">
# Import the respective libraries
import boto3
import botocore
import os
import json
import sys
#Create client-side Amazon Bedrock connection with Boto3 library
region = os.environ.get("AWS_REGION")
bedrock_runtime = boto3.client(service_name='bedrock-runtime',region_name=region)
prompt="""
[INST] You are an AI code translator specialized in converting code between different programming languages while preserving functionality, readability, and style. Your task is to translate the provided Python code to JavaScript.
Here is a brief description of the code's purpose:
This code defines a class called 'BankAccount' that represents a basic bank account. It has methods to deposit and withdraw money, as well as to check the account balance.
Python code is in the following code block:
```python
class BankAccount:
    def __init__(self, initial_balance=0):
        self.balance = initial_balance
    def deposit(self, amount):
        self.balance += amount
    def withdraw(self, amount):
        if self.balance &gt;= amount:
            self.balance -= amount
        else:
            print("Insufficient funds")
    def check_balance(self):
        return self.balance
```
Translate the above Python code to JavaScript, maintaining clear variable naming, proper indentation, and adding comments to explain any non-trivial logic or language-specific constructs used in the translation.
After translating the code, carefully review your work for any errors or inconsistencies. If errors are found, list them within `&lt;error&gt;` tags and provide a corrected version. If no errors are present, write "CHECKED: NO ERRORS" within `&lt;error&gt;` tags.
[/INST]"""
#Model ID and parameter details
modelId = 'mistral.mixtral-8x7b-instruct-v0:1'
accept = 'application/json'
contentType = 'application/json'
body = json.dumps({
    'prompt': prompt,
    'max_tokens': 1000,
    'top_p': 0.9,
    'temperature': 0.2,
})
#Output response
response = bedrock_runtime.invoke_model(body=body.encode('utf-8'), # Encode to bytes
      modelId=modelId,
      accept=accept,
      contentType=contentType)
response_body = json.loads(response.get('body').read().decode('utf-8'))
print(response_body.get('outputs')[0].get('text'))</pre>
<p>The translated<a id="_idIndexMarker708"/> JavaScript <a id="_idIndexMarker709"/>code output looks like this:</p>
<pre class="console">
Here's the Python code translated into JavaScript with clear variable naming, proper indentation, and comments explaining non-trivial logic or language-specific constructs used in the translation:
```javascript
// Define the BankAccount class
class BankAccount {
  // Initialize the balance property with an initial_balance of 0
  constructor(initial_balance = 0) {
    this.balance = initial_balance;
  }
  // Deposit method to add amount to the balance
  deposit(amount) {
    this.balance += amount;
  }
  // Withdraw method to subtract amount from the balance if there are sufficient funds
  withdraw(amount) {
    if (this.balance &gt;= amount) {
      this.balance -= amount;
    } else {
      console.log("Insufficient funds");
    }
  }
  // Check_balance method to return the current balance
  check_balance() {
    return this.balance;
  }
}
```
After reviewing the translated code, no errors or inconsistencies were found.
&lt;error&gt;NO ERRORS&lt;/error&gt;</pre>
<p>In this example, the prompt provides context about the code’s purpose and the original Python code and instructs Code Llama to translate it to JavaScript. The model is asked to maintain clear <a id="_idIndexMarker710"/>variable<a id="_idIndexMarker711"/> naming and proper indentation and add comments to explain non-trivial logic or language-specific constructs.</p>
<p>The generated output shows the translated JavaScript code, with the class structure and methods translated correctly while preserving the original functionality. After translating the code, the model has carefully reviewed its work and indicated <code>CHECKED: NO ERRORS</code> within <code>&lt;error&gt;</code> tags, signifying that the translation is correct and error-free.</p>
<p>This example demonstrates how a prompt can be crafted to guide Code Llama (or similar AI code models) to perform code translation tasks while ensuring the translated code is verified and correct. Note that it is always a best practice to perform a human evaluation of the generated output to verify the accuracy of these models and rectify any issues.</p>
<p>Users are encouraged to try these examples within the Amazon Bedrock playground or leveraging Amazon Bedrock APIs with several other models such as Amazon Titan, Cohere Command, Meta Llama, and alternate variations of Anthropic Claude or Mistral models to test the generated output and refine it further.</p>
<p>Users are further invited to explore this code sample where Amazon Bedrock LLMs are being invoked with zero-shot prompting to generate SQL and Python programs: <a href="https://github.com/aws-samples/amazon-bedrock-workshop/blob/main/01_Text_generation/01_code_generation_w_bedrock.ipynb">https://github.com/aws-samples/amazon-bedrock-workshop/blob/main/01_Text_generation/01_code_generation_w_bedrock.ipynb</a>.</p>
<p>Entity extraction with GenAI represents a significant step forward in our ability to extract valuable insights from unstructured text data. By leveraging the power of LLMs and combining them with rule-based techniques, hybrid approaches offer accurate, scalable, and domain-adaptable solutions for a wide range of applications. As we continue to push the boundaries of these areas, we can expect to unlock new opportunities for knowledge discovery, decision support, and data-driven innovation across various industries and domains.</p>
<p>The field of LLM-based code generation is also rapidly evolving, and Amazon Bedrock is at the forefront of this exciting development. As LLMs become more advanced and the available training data continues to grow, the capabilities and applications of code generation will expand further. Amazon Bedrock represents a significant step forward in the realm of code generation, empowering developers to leverage the power of LLMs to increase productivity, improve code quality, and explore new ideas more efficiently. As this technology <a id="_idIndexMarker712"/>continues <a id="_idIndexMarker713"/>to mature, it has the potential to revolutionize the way software is developed and open up new possibilities for innovation across various industries and domains.</p>
<h1 id="_idParaDest-160"><a id="_idTextAnchor170"/>Summary</h1>
<p>This chapter commenced with an in-depth exploration of entity extraction, uncovering its fundamentals, techniques, and best practices. It then transitioned to showcasing potential industrial applications of entity extraction, highlighting real-world use cases that demonstrate the power of unlocking valuable insights from unstructured data across various sectors.</p>
<p>Recognizing the pivotal role of prompt engineering, the chapter further provided a comprehensive guide to crafting effective prompts, equipping readers with strategies and guidelines to optimize entity extraction performance. Shifting gears, the discussion then centered on the transformative potential of code generation with LLMs on Amazon Bedrock. We gained insights into the capabilities and limitations of LLMs in driving AI-based development, as well as methodologies for leveraging these cutting-edge models.</p>
<p>Finally, the chapter culminated with a compelling exploration of practical use cases for code generation, demonstrating how this technology can accelerate innovation and boost productivity across various domains. Through real-world examples and case studies, readers witnessed firsthand the profound impact of code generation on streamlining development processes and unleashing new possibilities. In the following chapter, we are going to explore image generation use cases with Amazon Bedrock, along with its potential applications. Stay tuned!</p>
</div>
</body></html>