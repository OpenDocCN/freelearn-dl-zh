["```py\npublic class LoadCsv {\n   //Path and file name separated for compatibility\n  private String PATH; \n  private String FILE_NAME;\n  private double[][] dataMatrix; \n  private boolean columnsInFirstRow=false;\n  private String separator = \",\";\n  private String fullFilePath;\n  private String[] columnNames;\n  final double missingValue=Double.NaN;\n\n  //Constructors\n  public LoadCsv(String path,String fileName)\n  //…\n  public LoadCsv(String fileName,boolean _columnsInFirstRow,String _separator)\n  //…\n\n  //Method to load data from file returning a matrix\n  public double[][] getDataMatrix(String fullPath,boolean _columnsInFirstRow,String _separator)\n  //…\n\n  //Static method for calls without instantiating LoadCsv object\n  public static double[][] getData(String fullPath,boolean _columnsInFirstRow,String _separator)\n  //…\n\n  Method for saving data into csv file\n  public void save()\n  //…\n\n  //…\n}\n```", "```py\npublic class DataSet {\n  //column names list\n  public ArrayList<String> columns;\n  //data matrix \n  public ArrayList<ArrayList<Double>> data;\n\n  public int numberOfColumns;\n  public int numberOfRecords;\n\n  //creating from Java matrix\n  public DataSet(double[][] _data,String[] _columns){\n    numberOfRecords=_data.length;\n    numberOfColumns=_data[0].length;\n    columns = new ArrayList<>();\n    for(int i=0;i<numberOfColumns;i++){\n      //…\n      columns.add(_columns[i]);\n      //…\n    }\n    data = new ArrayList<>();\n    for(int i=0;i<numberOfRecords;i++){\n      data.add(new ArrayList<Double>());\n      for(int j=0;j<numberOfColumns;j++){\n        data.get(i).add(_data[i][j]);\n      }\n    }        \n  }\n\n  //creating from csv file  \n  public DataSet(String filename,boolean columnsInFirstRow,String separator){\n    LoadCsv lcsv = new LoadCsv(filename,columnsInFirstRow,separator);\n    double[][] _data= lcsv.getDataMatrix(filename, columnsInFirstRow, separator);\n    numberOfRecords=_data.length;\n    numberOfColumns=_data[0].length;\n    columns = new ArrayList<>();\n    if(columnsInFirstRow){\n       String[] columnNames = lcsv.getColumnNames();\n       for(int i=0;i<numberOfColumns;i++){\n         columns.add(columnNames[i]);\n       }\n    }\n    else{ //default column names: Column0, Column1, etc.\n      for(int i=0;i<numberOfColumns;i++){ \n        columns.add(\"Column\"+String.valueOf(i));\n      }\n    }\n    data = new ArrayList<>();\n    for(int i=0;i<numberOfRecords;i++){\n      data.add(new ArrayList<Double>());\n      for(int j=0;j<numberOfColumns;j++){\n        data.get(i).add(_data[i][j]);\n      }\n    } \n  }\n  //…\n  //method for adding new column\n  public void addColumn(double[] _data,String name)\n  //…\n  //method for appending new data, number of columns must correspond \n  public void appendData(double[][] _data)\n  //…\n  //getting all data\n  public double[][] getData(){\n    return ArrayOperations.arrayListToDoubleMatrix(data);\n  }\n  //getting data from specific columns \n  public double[][] getData(int[] columns){\n    return ArrayOperations.getMultipleColumns(getData(), columns);\n  }\n  //getting data from one column\n  public double[] getData(int col){\n    return ArrayOperations.getColumn(getData(), col);\n  }\n  //method for saving the data in a csv file\n  public void save(String filename,String separator)\n  //…\n}\n```", "```py\npublic static DataSet getDataSet(String fullPath,boolean _columnsInFirstRow, String _separator){\n  LoadCsv lcsv = new LoadCsv(fullPath,_columnsInFirstRow,_separator);\n  lcsv.columnsInFirstRow=_columnsInFirstRow;\n  lcsv.separator=_separator;\n  try{\n    lcsv.dataMatrix=lcsv.csvData2Matrix(fullPath);\n    System.out.println(\"File \"+fullPath+\" loaded!\");\n  }\n  catch(IOException ioe){\n    System.err.println(\"Error while loading CSV file. Details: \" + ioe.getMessage());\n  }\n  return new DataSet(lcsv.dataMatrix, lcsv.columnNames);\n}\n```", "```py\npublic class TimeSeries extends DataSet {\n  //index of the column containing time information\n  private int indexTimeColumn;\n\n  public TimeSeries(double[][] _data,String[] _columns){\n    super(_data,_columns); //just a call to superclass constructor\n  }\n  public TimeSeries(String path, String filename){\n    super(path,filename);\n  }\n  public TimeSeries(DataSet ds){\n    super(ds.getData(),ds.getColumns());\n  }\n  public void setIndexColumn(int col){\n    this.indexTimeColumn=col;\n    this.sortBy(indexTimeColumn);\n  }\n//…\n }\n```", "```py\npublic double[] shiftColumn(int col,int shift){\n  double[][] _data = ArrayOperations.arrayListToDoubleMatrix(data);\n  return ArrayOperations.shiftColumn(_data, indexTimeColumn, shift, col);\n}\npublic void shift(int col,int shift){\n  String colName = columns.get(col);\n  if(shift>0) colName=colName+\"_\"+String.valueOf(shift);\n  else colName=colName+\"__\"+String.valueOf(-shift);\n  addColumn(shiftColumn(col,shift),colName);\n}\n```", "```py\n// dropping with a substituting value\npublic void dropNaN(double substvalue)\n//…\n// dropping the entire row\npublic void dropNaN()\n//…\n```", "```py\npublic double correlation(int colx,int coly){\n  double[] arrx = ArrayOperations.getColumn(data,colx);\n  double[] arry = ArrayOperations.getColumn(data,coly);\n  double[] arrxy = ArrayOperations.elementWiseProduct(arrx, arry);\n  double meanxy = ArrayOperations.mean(arrxy);\n  double meanx = ArrayOperations.mean(arrx);\n  double meany = ArrayOperations.mean(arry);\n  double stdx = ArrayOperations.stdev(arrx);\n  double stdy = ArrayOperations.stdev(arry);\n  return (meanxy*meanx*meany)/(stdx*stdy);\n}\n```", "```py\npublic class DataNormalization {\n  //ENUM normalization types\n  public enum NormalizationTypes { MIN_MAX, ZSCORE }\n  // normalization type\n  public NormalizationTypes TYPE;\n  //statistical properties of the data\n  private double[] minValues;\n  private double[] maxValues;\n  private double[] meanValues;\n  private double[] stdValues;\n  //normalization properties\n  private double scaleNorm=1.0;        \n  private double minNorm=-1.0;\n//…\n  //constructor for min-max norm\n  public DataNormalization(double[][] data,double _minNorm, double _maxNorm){\n    this.TYPE=NormalizationTypes.MIN_MAX;\n    this.minNorm=_minNorm;\n    this.scaleNorm=_maxNorm-_minNorm;\n    calculateReference(data);\n  }\n  //constructor for z-score norm        \n  public DataNormalization(double[][] data,double _zscale){\n    this.TYPE=NormalizationTypes.ZSCORE;\n    this.scaleNorm=_zscale;\n    calculateReference(data);\n  }\n  //calculation of statistical properties\n  private void calculateReference(double[][] data){\n    minValues=ArrayOperations.min(data);\n    maxValues=ArrayOperations.max(data);\n    meanValues=ArrayOperations.mean(data);\n    stdValues=ArrayOperations.stdev(data);\n  }\n//…\n}\n```", "```py\npublic double[][] normalize( double[][] data ) {\n  int rows = data.length;\n  int cols = data[0].length;\n  //…\n  double[][] normalizedData = new double[rows][cols];\n  for(int i=0;i<rows;i++){\n    for(int j=0;j<cols;j++){\n      switch (TYPE){\n        case MIN_MAX:\n          normalizedData[i][j]=(minNorm) + ((data[i][j] - minValues[j]) / ( maxValues[j] - minValues[j] )) * (scaleNorm);\n          break;\n        case ZSCORE:\n          normalizedData[i][j]=scaleNorm * (data[i][j] - meanValues[j]) / stdValues[j];\n          break;\n      }\n    }\n  }\n  return normalizedData;\n}\n```", "```py\n public DataNormalization inputNorm;\n public DataNormalization outputNorm;\n //zscore normalization\n public void setNormalization(double _scaleNorm){\n   inputNorm = new DataNormalization(_scaleNorm);\n   inputData.setNormalization(inputNorm);\n   outputNorm = new DataNormalization(_scaleNorm);\n   outputData.setNormalization(outputNorm);\n }\n //min-max normalization\n public void setNormalization(double _minNorm,double _maxNorm){\n   inputNorm = new DataNormalization(_minNorm,_maxNorm);\n   inputData.setNormalization(inputNorm);\n   outputNorm = new DataNormalization(_minNorm,_maxNorm);\n   outputData.setNormalization(outputNorm);\n }\n```", "```py\n public ArrayList<ArrayList<Double>> normdata;\n public DataNormalization norm; \n public void setNormalization(DataNormalization dn){\n    //getting the original data into java matrix\n   double[][] origData = ArrayOperations.arrayListToDoubleMatrix(data);\n   //perform normalization\n   double[][] normData = dn.normalize(origData);\n   normdata=new ArrayList<>();\n   //store the normalized values into ArrayList normdata\n   for(int i=0;i<normData.length;i++){\n     normdata.add(new ArrayList<Double>());\n     for(int j=0;j<normData[0].length;j++){\n       normdata.get(i).add(normData[i][j]);\n     }\n  }\n}\n```", "```py\n public ArrayList<ArrayList<Double>> normTargetData;\n public ArrayList<ArrayList<Double>> normNeuralData;\n public void setNeuralData(double[][] _data,boolean isNorm){\n   if(isNorm){ //if is normalized\n     this.normNeuralData=new ArrayList<>();\n     for(int i=0;i<numberOfRecords;i++){\n       this.normNeuralData.add(new ArrayList<Double>());\n       //… save in the normNeuralData\n       for(int j=0;j<numberOfOutputs;j++){\n         this.normNeuralData.get(i).add(_data[i][j]);\n       }\n     }\n     double[][] deNorm = norm.denormalize(_data);\n     for(int i=0;i<numberOfRecords;i++)\n       for(int j=0;j<numberOfOutputs;j++) //then in neuralData\n          this.neuralData.get(i).set(j,deNorm[i][j]);\n   }\n   else setNeuralData(_data);\n }\n```", "```py\nprotected boolean normalization=false;\n```", "```py\n@Override \npublic void forward(){\n  for(int i=0;i<trainingDataSet.numberOfRecords;i++){\n    neuralNet.setInputs(trainingDataSet.\ngetInputRecord(i,normalization));\n    neuralNet.calc();\n    trainingDataSet.setNeuralOutput(i, neuralNet.getOutputs(), normalization);\n//…\n  }\n}\n```", "```py\npublic double calcSolarNoonAngle(double date,double latitude){\n  return 90-Math.abs(-23.44*Math.cos((2*Math.PI/365.25)*(date+8.5))-latitude);\n}\npublic void addSolarNoonAngle(TimeSeries ts,double latitude){// to add column\n  double[] sna = new double[ts.numberOfRecords];\n  for(int i=0;i<ts.numberOfRecords;i++)\n    sna[i]=calcSolarNoonAngle(\n               ts.data.get(i).get(ts.getIndexColumn()), latitude);\n  ts.addColumn(sna, \"NoonAngle\");\n}\n```", "```py\npublic void makeDelays(TimeSeries ts,int maxdelays){\n  for(int i=0;i<ts.numberOfColumns;i++)\n    if(i!=ts.getIndexColumn())\n      for(int j=1;j<=maxdelays;j++)\n        ts.shift(i, -j);\n  }\n```", "```py\npublic class WeatherExample {\n\n    TimeSeries cruzeirodosul;\n    TimeSeries picos;\n    TimeSeries camposdojordao;\n    TimeSeries portoalegre;\n\n    NeuralNet nncruzeirosul;\n    NeuralNet nnpicos;\n    NeuralNet nncamposjordao;\n    NeuralNet nnportoalegre;\n//…\n}\n```", "```py\npublic static void main(String[] args) {\n  WeatherExample we = new WeatherExample();\n  //load weather data\n  we.cruzeirodosul = new TimeSeries(LoadCsv.getDataSet(\"data\", \"cruzeirodosul2010daily.txt\", true, \";\"));\n  we.cruzeirodosul.setIndexColumn(0);\n  we.makeDelays(we.cruzeirodosul, 3);\n\n  we.picos = new TimeSeries(LoadCsv.getDataSet(\"data\", \"picos2010daily.txt\", true, \";\"));\n  we.picos.setIndexColumn(0);\n  we.makeDelays(we.picos, 3);\n\n  we.camposdojordao = new TimeSeries(LoadCsv.getDataSet(\"data\", \"camposdojordao2010daily.txt\", true, \";\"));\n  we.camposdojordao.setIndexColumn(0);\n  we.makeDelays(we.camposdojordao, 3);\n\n  we.portoalegre = new TimeSeries(LoadCsv.getDataSet(\"data\", \"portoalegre2010daily.txt\", true, \";\"));\n  we.portoalegre.setIndexColumn(0);\n  we.makeDelays(we.portoalegre, 3);\n//…\n```", "```py\n  //…\n  we.cruzeirodosul.dropNaN();\n  we.camposdojordao.dropNaN();\n  we.picos.dropNaN();\n  we.portoalegre.dropNaN();\n  //…\n```", "```py\nwe.cruzeirodosul.save(\"data\",\"cruzeirodosul2010daily_delays_clean.txt\",\";\");\n//…\nwe.portoalegre.save(\"data\",\"portoalegre2010daily_delays_clean.txt\",\";\");\n```", "```py\npublic void correlationAnalysis(double minAbsCorr){\n  //indexes of output variables (max. and min. temperature) \n  int[][] outputs = { \n            {2,3}, //cruzeiro do sul\n            {2,3}, //picos\n            {2,3}, //campos do jordao\n            {2,3}}; //porto alegre\n  int[][] potentialInputs = { //indexes of input variables (delayed)\n            {10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,38,39,40}, //cruzeiro do sul\n            //… and all others\n        };\n  ArrayList<ArrayList<ArrayList<Double>>> chosenInputs = new ArrayList<>();\n  TimeSeries[] tscollect = {this.cruzeirodosul,this.picos,this.camposdojordao,this.portoalegre};\n  double[][][] correlation = new double[4][][];\n  for(int i=0;i<4;i++){\n    chosenInputs.add(new ArrayList<ArrayList<Double>>());\n    correlation[i]=new double[outputs[i].length][potentialInputs[i].length];\n    for(int j=0;j<outputs[i].length;j++){\n      chosenInputs.get(i).add(new ArrayList<Double>());\n      for(int k=0;k<potentialInputs[i].length;k++){\n        correlation[i][j][k]=tscollect[i].correlation(outputs[i][j], potentialInputs[i][k]);\n        //if the absolute correlation is above the threshold\n        if(Math.abs(correlation[i][j][k])>minAbsCorr){\n          //it is added to the chosen inputs\n          chosenInputs.get(i).get(j).add(correlation[i][j][k]);\n          //and we see the plot\n          tscollect[i].getScatterChart(\"Correlation \"+String.valueOf(correlation[i][j][k]), outputs[i][j], potentialInputs[i][k], Color.BLACK).setVisible(true);\n        }\n      }\n    }\n  }\n}\n```", "```py\npublic void createNNs(){\n //fill a vector with the indexes of input and output columns\n int[] inputColumnsCS = {10,14,17,18,19,20,26,27,29,38,39,40};\n int[] outputColumnsCS = {2,3};\n //this static method hashes the dataset\n NeuralDataSet[] nnttCS = NeuralDataSet.randomSeparateTrainTest(this.cruzeirodosul, inputColumnsCS, outputColumnsCS, 0.7);\n //setting normalization\n DataNormalization.setNormalization(nnttCS, -1.0, 1.0);\n\n this.trainDataCS = nnttCS[0]; // 70% for training \n this.testDataCS = nnttCS[1]; // rest for test\n\n //setup neural net parameters:\n this.nncruzeirosul = new NeuralNet( inputColumnsCS.length, outputColumnsCS.length, new int[]{20,10} \n    , new IActivationFunction[] {new HyperTan(1.0),new Sigmoid(1.0)}\n    , new Linear()\n    , new UniformInitialization(-1.0, 1.0) );\n//…\n}\n```", "```py\n Backpropagation bpCS = new Backpropagation(we.nncruzeirosul\n                ,we.trainDataCS\n                ,LearningAlgorithm.LearningMode.BATCH);\n bpCS.setTestingDataSet(we.testDataCS);\n bpCS.setLearningRate(0.3);\n bpCS.setMaxEpochs(1000);\n bpCS.setMinOverallError(0.01); //normalized error\n bpCS.printTraining = true;\n bpCS.setMomentumRate( 0.3 );\n\n try{\n   bpCS.forward();\n   bpCS.train();\n\n   System.out.println(\"Overall Error:\"      + String.valueOf(bpCS.getOverallGeneralError()));\n   System.out.println(\"Testing Error:\"      + String.valueOf(bpCS.getTestingOverallGeneralError()));\n   System.out.println(\"Min Overall Error:\"  + String.valueOf(bpCS.getMinOverallError()));\n   System.out.println(\"Epochs of training:\" + String.valueOf(bpCS.getEpoch()));\n }\n catch(NeuralException ne){ }\n```", "```py\n//plot list of errors by epoch \nbpCS.showErrorEvolution();\n```", "```py\n String[] neuralOutputs = { \"NeuralMaxTemp\", \"NeuralMinTemp\"};\n we.cruzeirodosul.addColumn(we.fullDataCS.getIthNeuralOutput(0), neuralOutputs[0]);\n we.cruzeirodosul.addColumn(we.fullDataCS.getIthNeuralOutput(1), neuralOutputs[1]);\n String[] comparison = {\"MaxTemp\",\"NeuralMaxTemp\"};\n Paint[] comp_color = {Color.BLUE, Color.RED};\n\n final double minDate = 41200.0;\n final double maxDate = 41300.0;\n```", "```py\nChartFrame viewChart = we.cruzeirodosul.getTimePlot(\"Comparison\", comparison, comp_color, minDate, maxDate);\n```"]