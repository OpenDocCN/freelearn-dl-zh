- en: '7'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '7'
- en: Building Scalable Knowledge-Graph-Based RAG with Wikipedia API and LlamaIndex
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用维基百科API和LlamaIndex构建可扩展的知识图谱RAG
- en: Scaled datasets can rapidly become challenging to manage. In real-life projects,
    data management generates more headaches than AI! Project managers, consultants,
    and developers constantly struggle to obtain the necessary data to get any project
    running, let alone a RAG-driven generative AI application. Data is often unstructured
    before it becomes organized in one way or another through painful decision-making
    processes. Wikipedia is a good example of how scaling data leads to mostly reliable
    but sometimes incorrect information. Real-life projects often evolve the way Wikipedia
    does. Data keeps piling up in a company, challenging database administrators,
    project managers, and users.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 扩展的数据集可能会迅速变得难以管理。在实际项目中，数据管理产生的麻烦比人工智能还要多！项目经理、顾问和开发者不断努力获取启动任何项目所需的数据，更不用说一个由RAG驱动的生成式AI应用了。数据在以某种方式组织之前通常是未结构化的。维基百科是数据扩展导致信息大多可靠但有时不正确的一个好例子。现实生活中的项目通常像维基百科一样发展。数据在公司中不断积累，挑战数据库管理员、项目经理和用户。
- en: 'One of the main problems is seeing how large amounts of data fit together,
    and **knowledge graphs** provide an effective way of visualizing the relationships
    between different types of data. This chapter begins by defining the architecture
    of a knowledge base ecosystem designed for RAG-driven generative AI. The ecosystem
    contains three pipelines: data collection, populating a vector store, and running
    a knowledge graph index-based RAG program. We will then build *Pipeline 1: Collecting
    and preparing the documents*, in which we will build an automated Wikipedia retrieval
    program with the Wikipedia API. We will simply choose a topic based on a Wikipedia
    page and then let the program retrieve the metadata we need to collect and prepare
    the data. The system will be flexible and allow you to choose any topic you wish.
    The use case to first run the program is a marketing knowledge base for students
    who want to upskill for a new job, for example. The next step is to build *Pipeline
    2: Creating and populating the Deep Lake vector store*. We will load the data
    in a vector store leveraging Deep Lake’s in-built automated chunking and OpenAI
    embedding functionality. We will peek into the dataset to explore how this marvel
    of technology does the job.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 主要问题之一是看到大量数据如何相互关联，**知识图谱**提供了一种有效的方式来可视化不同类型数据之间的关系。本章首先定义了一个为RAG驱动的生成式AI设计的知识库生态系统架构。该生态系统包含三个管道：数据收集、填充向量存储和运行基于知识图谱索引的RAG程序。然后我们将构建**管道1：收集和准备文档**，其中我们将使用维基百科API构建一个自动化的维基百科检索程序。我们将简单地根据维基百科页面选择一个主题，然后让程序检索我们需要收集和准备的数据的元数据。系统将是灵活的，允许你选择任何你希望的主题。首先运行程序的使用案例是一个为希望提升技能以适应新工作的学生设计的营销知识库。下一步是构建**管道2：创建和填充Deep
    Lake向量存储**。我们将利用Deep Lake内置的自动分块和OpenAI嵌入功能将数据加载到向量存储中。我们将深入了解数据集，探索这项技术奇迹是如何工作的。
- en: 'Finally, we will build *Pipeline 3: Knowledge graph index-based RAG*, where
    LlamaIndex will automatically build a knowledge graph index. It will be exciting
    to see how the index function churns through our data and produces a graph showing
    semantic relationships contained in our data. We will then query the graph with
    LlamaIndex’s in-built OpenAI functionality to automatically manage user inputs
    and produce a response. We will also see how re-ranking can be done and implement
    metrics to calculate and display the system’s performance.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将构建**管道3：基于知识图谱索引的RAG**，其中LlamaIndex将自动构建知识图谱索引。将非常有趣地看到索引功能如何处理我们的数据，并生成显示我们数据中包含的语义关系的图表。然后我们将使用LlamaIndex内置的OpenAI功能查询该图表，以自动管理用户输入并生成响应。我们还将看到如何进行重新排序，并实现用于计算和显示系统性能的指标。
- en: 'This chapter covers the following topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖以下主题：
- en: Defining knowledge graphs
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义知识图谱
- en: Implementing the Wikipedia API to prepare summaries and content
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现维基百科API以准备摘要和内容
- en: Citing Wikipedia sources in an ethical approach
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以道德方式引用维基百科来源
- en: Populating a Deep Lake vector store with Wikipedia data
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用维基百科数据填充Deep Lake向量存储
- en: Building a knowledge graph index with LlamaIndex
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用LlamaIndex构建知识图谱索引
- en: Displaying the LlamaIndex knowledge graph
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 显示LlamaIndex知识图谱
- en: Interacting with the knowledge graph
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与知识图谱交互
- en: Generating retrieval responses with the knowledge graph
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用知识图谱生成检索响应
- en: Re-ranking the order retrieval responses to choose a better output
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重新排序检索响应的顺序以选择更好的输出
- en: Evaluating and measuring the outputs with metrics
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用指标评估和衡量输出
- en: Let’s begin by defining the architecture of RAG for knowledge-based semantic
    search.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从定义基于知识的语义搜索的 RAG 架构开始。
- en: The architecture of RAG for knowledge-graph-based semantic search
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于知识图谱的语义搜索的 RAG 架构
- en: 'As established, we will build a graph-based RAG program in this chapter. The
    graph will enable us to visually map out the relationships between the documents
    of a RAG dataset. It can be created automatically with LlamaIndex, as we will
    do in the *Pipeline 3: Knowledge graph index-based RAG* section of this chapter.
    The program in this chapter will be designed for any Wikipedia topic, as illustrated
    in the following figure:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们将在本章中构建一个基于图的 RAG 程序。该图将使我们能够直观地映射出 RAG 数据集文档之间的关系。它可以通过 LlamaIndex 自动创建，正如我们在本章的
    *管道 3：基于知识图谱索引的 RAG* 部分中所做的那样。本章节的程序将针对任何维基百科主题进行设计，如图中所示：
- en: '![A diagram of a graph  Description automatically generated](img/B31169_07_01.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![一个图形的图表  自动生成的描述](img/B31169_07_01.png)'
- en: 'Figure 7.1: From a Wikipedia topic to interacting with a graph-based vector
    store index'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.1：从维基百科主题到与基于图的向量存储索引交互
- en: 'We will first implement a marketing agency for which a knowledge graph can
    visually map out the complex relationships between different marketing concepts.
    Then, you can go back and explore any topic you wish once you understand the process.
    In simpler words, we will implement the three pipelines seamlessly to:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先实现一个营销机构，其中知识图谱可以直观地映射出不同营销概念之间的复杂关系。然后，一旦你理解了过程，你就可以回过头来探索任何你感兴趣的主题。用更简单的话说，我们将无缝实现三个管道，以：
- en: Select a Wikipedia topic related to *marketing*. Then, you can run the process
    with the topic of your choice to explore the ecosystem.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择与 *营销* 相关的维基百科主题。然后，你可以使用你选择的主题运行该过程以探索生态系统。
- en: Generate a corpus of Wikipedia pages with the Wikipedia API.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用维基百科 API 生成维基百科页面的语料库。
- en: Retrieve and store the citations for each page.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检索并存储每个页面的引用。
- en: Retrieve and store the URLs for each page.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检索并存储每个页面的 URL。
- en: Retrieve and upsert the content of the URLs in a Deep Lake vector store.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Deep Lake 向量存储中检索并更新 URL 的内容。
- en: Build a knowledge base index with LlamaIndex.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 LlamaIndex 构建知识库索引。
- en: Define a user input prompt.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义用户输入提示。
- en: Query the knowledge base index.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查询知识库索引。
- en: Let LlamaIndex’s in-built LLM functionality, based on OpenAI’s embedding models,
    produce a response based on the embedded data in the knowledge graph.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 让 LlamaIndex 的内置 LLM 功能，基于 OpenAI 的嵌入模型，根据知识图谱中的嵌入数据生成响应。
- en: Evaluate the LLM’s response with a sentence transformer.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用句子转换器评估 LLM 的响应。
- en: Evaluate the LLM’s response with a human feedback score.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用人类反馈评分评估 LLM 的响应。
- en: Provide time metrics for the key functions, which you can extend to other functions
    if necessary.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供关键函数的时间指标，如果需要，你可以将其扩展到其他函数。
- en: Run metric calculations and display the results.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行指标计算并显示结果。
- en: 'To attain our goal, we will implement three pipelines leveraging the components
    we have already built in the previous chapters, as illustrated in the following
    figure:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现我们的目标，我们将利用前几章中已经构建的组件实现三个管道，如图中所示：
- en: '![A diagram of a graph  Description automatically generated](img/B31169_07_02.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![一个图形的图表  自动生成的描述](img/B31169_07_02.png)'
- en: 'Figure 7.2: Knowledge graph ecosystem for index-based RAG'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.2：基于索引的 RAG 知识图谱生态系统
- en: '**Pipeline 1: Collecting and preparing the documents** will involve building
    a Wikipedia program using the Wikipedia API to retrieve links from a Wikipedia
    page and the metadata for all the pages (summary, URL, and citation data). Then,
    we will load and parse the URLs to prepare the data for upserting.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**管道 1：收集和准备文档** 将涉及使用维基百科 API 构建一个维基百科程序，以检索维基百科页面中的链接和所有页面的元数据（摘要、URL 和引用数据）。然后，我们将加载并解析
    URL 以准备数据以便更新插入。'
- en: '**Pipeline 2: Creating and populating the Deep Lake vector store** will embed
    and upsert parsed content of the Wikipedia pages prepared by *Pipeline 1* to a
    Deep Lake vector store.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**管道 2：创建和填充 Deep Lake 向量存储** 将将 *管道 1* 准备的维基百科页面解析内容嵌入并更新到 Deep Lake 向量存储中。'
- en: '**Pipeline 3: Knowledge graph index-based RAG** will build the knowledge graph
    index using embeddings with LlamaIndex and display it. Then, we will build the
    functionality to query the knowledge base index and let LlamaIndex’s in-built
    LLM generate the response based on the updated dataset.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Pipeline 3: 基于知识图谱索引的RAG** 将使用LlamaIndex的嵌入构建知识图谱索引并展示它。然后，我们将构建查询知识库索引的功能，并让LlamaIndex内置的LLM根据更新的数据集生成响应。'
- en: In this chapter’s scenario, we are directly implementing an augmented retrieval
    system leveraging OpenAI’s embedding models more than we are augmenting inputs.
    This implementation shows the many ways we can improve real-time data retrieval
    with LLMs. There are no conventional rules. What works, works!
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的场景中，我们直接实现了一个增强检索系统，利用OpenAI的嵌入模型比增强输入更多。这种实现展示了我们可以用LLM改进实时数据检索的多种方式。没有传统规则。什么有效，就做什么！
- en: The ecosystem of the three pipelines will be controlled by a scenario that will
    enable an administrator to either query the vector base or add new Wikipedia pages,
    as we will implement in this chapter. As such, the architecture of the ecosystem
    allows for indefinite scaling since it processes and populates the vector dataset
    one set of Wikipedia pages at a time. The system only uses a CPU and an optimized
    amount of memory. There are limits to this approach since the LlamaIndex knowledge
    graph index is loaded with the entire dataset. We can only load portions of the
    dataset as the vector store grows. Or, we can create one Deep Lake vector store
    per topic and run queries on multiple datasets. These are decisions to make in
    real-life projects that require careful decision-making and planning depending
    on the specific requirements of each project.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 三个管道的生态系统将由一个场景控制，该场景将允许管理员查询向量库或添加新的维基百科页面，正如我们将在本章中实现的那样。因此，生态系统的架构允许无限扩展，因为它一次处理和填充一组维基百科页面的向量数据集。系统仅使用CPU和优化的内存量。由于LlamaIndex知识图谱索引加载了整个数据集，这种方法有局限性。随着向量存储的增长，我们只能加载数据集的部分。或者，我们可以为每个主题创建一个Deep
    Lake向量存储，并在多个数据集上运行查询。这些是在实际项目中需要谨慎决策和计划的决定，具体取决于每个项目的特定要求。
- en: We will now dive into the code, beginning a tree-to-graph sandbox.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将深入代码，开始一个树到图的沙盒。
- en: Building graphs from trees
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从树构建图
- en: A graph is a collection of nodes (or vertices) connected by edges (or arcs).
    Nodes represent entities, and edges represent relationships or connections between
    these entities. For instance, in our chapter’s use case, nodes could represent
    various marketing strategies, and the edges could show how these strategies are
    interconnected. This helps new customers understand how different marketing tactics
    work together to achieve overall business goals, facilitating clearer communication
    and more effective strategy planning. You can play around with the tree-to-graph
    sandbox before building the pipelines in this chapter.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图是由节点（或顶点）通过边（或弧）连接的集合。节点代表实体，边代表这些实体之间的关系或连接。例如，在我们本章的使用案例中，节点可以代表各种营销策略，边可以显示这些策略如何相互关联。这有助于新客户了解不同的营销策略如何协同工作以实现整体业务目标，促进更清晰的沟通和更有效的策略规划。在构建本章的管道之前，您可以在树到图沙盒中尝试操作。
- en: You may open `Tree-2-Graph.ipynb` on GitHub. The provided program is designed
    to visually represent relationships in a tree structure using NetworkX and Matplotlib
    in Python. It specifically creates a directed graph from given pairs, checks and
    marks friendships, and then displays this tree with customized visual attributes.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在GitHub上打开`Tree-2-Graph.ipynb`。提供的程序旨在使用Python中的NetworkX和Matplotlib在树结构中可视化关系。它特别创建了一个有向图，从给定的对中检查并标记友谊，然后以自定义的视觉属性显示此树。
- en: 'The program first defines the main functions:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 程序首先定义了主要函数：
- en: '`build_tree_from_pairs(pairs)`: Constructs a directed graph (tree) from a list
    of node pairs, potentially identifying a root node'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`build_tree_from_pairs(pairs)`: 从节点对列表构建一个有向图（树），可能识别一个根节点'
- en: '`check_relationships(pairs, friends)`: Checks and prints the friendship status
    for each pair'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`check_relationships(pairs, friends)`: 检查并打印每对的朋友关系状态'
- en: '`draw_tree(G, layout_choice, root, friends)`: Visualizes the tree using `matplotlib`,
    applying different styles to edges based on friendship status and different layout
    options for node positioning'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`draw_tree(G, layout_choice, root, friends)`: 使用`matplotlib`可视化树，根据友谊状态应用不同的边样式，并为节点定位提供不同的布局选项'
- en: 'Then, the program executes the process from tree to graph:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: Node pairs and friendship data are defined.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The tree is built from the pairs.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Relationships are checked against the friendship data.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The tree is drawn using a selected layout, with edges styled differently to
    denote friendship.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For example, the program first defines a set of node pairs with their pairs
    of friends:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Notice that `('a', 'z')` are not friends because they are not on the `friends`
    list. Neither are `('b', 'q')`. You can imagine any type of relationship between
    the pairs, such as the same customer age, similar job, same country, or any other
    concept you wish to represent. For instance, the `friends` list could contain
    relationships between friends on social media, friends living in the same country,
    or anything else you can imagine or need!
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: 'The program then builds the tree and checks the relationships:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The output shows which pairs are friends and which ones are not:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The output can be used to provide useful information for similarity searches.
    The program now draws the graph with the `''spring''` layout:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The `'spring'` layout attracts nodes attracted by edges, simulating the effect
    of springs. It also ensures that all nodes repel each other to avoid overlapping.
    You can dig into the `draw_tree` function to explore and select other layouts
    listed there. You can also modify the colors and line styles.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: 'In this case, the pairs of friends are represented with solid lines, and the
    pairs that are not friends are represented with dashes, as shown in the following
    graph:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: '![A diagram of a tree  Description automatically generated](img/B31169_07_03.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.3: Example of a spring layout'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: You can play with this sandbox graph with different pairs of nodes. If you imagine
    doing this with hundreds of nodes, you will begin to appreciate the automated
    functionality we will build in this chapter with LlamaIndex’s knowledge graph
    index!
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: Let’s go from the architecture to the code, starting by collecting and preparing
    the documents.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: 'Pipeline 1: Collecting and preparing the documents'
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The code in this section retrieves the metadata we need from Wikipedia, retrieves
    the documents, cleans them, and aggregates them to be ready for insertion into
    the Deep Lake vector store. This process is illustrated in the following figure:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: '![A diagram of a document  Description automatically generated](img/B31169_07_04.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.4: Pipeline 1 flow chart'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: '*Pipeline 1* includes two notebooks:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: '`Wikipedia_API.ipynb`, in which we will implement the Wikipedia API to retrieve
    the URLs of the pages related to the root page of the topic we selected, including
    the citations for each page. As mentioned, the topic is “marketing” in our case.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Knowledge_Graph_Deep_Lake_LlamaIndex_OpenAI_RAG.ipynb`, in which we will implement
    all three pipelines. In Pipeline 1, it will fetch the URLs provided by the `Wikipedia_API`
    notebook, clean them, and load and aggregate them for upserting.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will begin by implementing the Wikipedia API.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: Retrieving Wikipedia data and metadata
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s begin by building a program to interact with the Wikipedia API to retrieve
    information about a specific topic, tokenize the retrieved text, and manage citations
    from Wikipedia articles. You may open `Wikipedia_API.ipynb` in the GitHub repository
    and follow along.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: 'The program begins by installing the `wikipediaapi` library we need:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The next step is to define the tokenization function that will be called to
    count the number of tokens of a summary, as shown in the following excerpt:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'This function takes a string of text as input and returns the number of tokens
    in the text, using the NLTK library for sophisticated tokenization, including
    punctuation. Next, to start retrieving data, we need to set up an instance of
    the Wikipedia API with a specified language and user agent:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'In this case, English was defined with `''en''`, and you must enter the user
    agent information, such as an email address, for example. We can now define the
    main topic and filename associated with the Wikipedia page of interest:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The three parameters defined are:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: '`topic`: The topic of the retrieval process'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`filename`: The name of the topic that will customize the files we produce,
    which can be different from the topic'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`maxl`: The maximum number of URL links of the pages we will retrieve'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We now need to retrieve the summary of the specified Wikipedia page, check
    if the page exists, and print its summary:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The output provides the control information requested:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The information provided shows if we are on the right track or not before running
    a full search on the main page of the topic:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: '`Page - Exists: True` confirms that the page exists. If not, the `print("Page
    does not exist")` message will be displayed.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Number of tokens: 229` provides us with insights into the size of the content
    we are retrieving for project management assessments.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The output of `summary=page.summary` displays a summary of the page.
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In this case, the page exists, fits our topic, and the summary makes sense.
    Before we continue, we check if we are working on the right page to be sure:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The output is correct:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We are now ready to retrieve the URLs, links, and summaries on the target page:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The function is limited to `maxl`, defined at the beginning of the program.
    The function will retrieve URL links up to `maxl` links, or less if the page contains
    fewer links than the maximum requested. We then check the output before moving
    on to the next step and generating files:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We observe that we have the information we need, and the summaries are acceptable:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: '`Link 1`: The link counter'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Link`: The actual link to the page retrieved from the main topic page'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Summary`: A summary of the link to the page'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The next step is to apply the function we just built to generate the text file
    containing citations for the links retrieved from a Wikipedia page and their URLs:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '`urls = []` will be appended to have the full list of URLs we need for the
    final step. The output is a file containing the name of the topic, `datetime`,
    and the citations beginning with the citation text:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The output, in this case, is a file named `Marketing_citations.txt`. The file
    was downloaded and uploaded to the `/citations` directory of this chapter’s directory
    in the GitHub repository.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: 'With that, the citations page has been generated, displayed in this notebook,
    and also saved in the GitHub repository to respect Wikipedia’s citation terms.
    The final step is to generate the file containing the list of URLs we will use
    to fetch the content of the pages we need. We first display the URLs:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The output confirms we have the URLs required:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The URLs are written in a file with the topic as a prefix:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: In this case, the output is a file named `Marketing_urls.txt` that contains
    the URLs of the pages we need to fetch. The file was downloaded and uploaded to
    the `/citations` directory of the chapter’s directory in the GitHub repository.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: We are now ready to prepare the data for upsertion.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: Preparing the data for upsertion
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The URLs provided by the Wikipedia API in the `Wikipedia_API.ipynb` notebook
    will be processed in the `Knowledge_Graph_ Deep_Lake_LlamaIndex_OpenAI_RAG.ipynb`
    notebook you can find in the GitHub directory of the chapter. The *Installing
    the environment* section of this notebook is almost the same section as its equivalent
    section in *Chapter 2*, *RAG Embedding Vector Stores with Deep Lake and OpenAI*,
    and *Chapter 3*, *Building Index-Based RAG with LlamaIndex, Deep Lake, and OpenAI*.
    In this chapter, however, the list of URLs was generated by the `Wikipedia_API.ipynb`
    notebook, and we will retrieve it.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: 'First, go to the *Scenario* section of the notebook to define the strategy
    of the workflow:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The parameters will determine the behavior of the three pipelines in the notebook:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: '`graph_name="Marketing"`: The prefix (topic) of the files we will read and
    write.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`db="hub://denis76/marketing01"`: The name of the Deep Lake vector store. You
    can choose the name of the dataset you wish.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`vector_store_path = db`: The path to the vector store.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dataset_path = db`: The path to the dataset of the vector store.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pop_vs=True`: Activates data insertion if `True` and deactivates it if `False`.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ow=True`: Overwrites the existing dataset if `True` and appends it if `False`.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Then, we can launch the *Pipeline 1: Collecting and preparing the documents*
    section of the notebook. The program will download the URL list generated in the
    previous section of this chapter:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'It will then read the file and store the URLs in a list named `urls`. The rest
    of the code in the *Pipeline 1: Collecting and preparing the documents* section
    of this notebook follows the same process as the `Deep_Lake_LlamaIndex_OpenAI_RAG.ipynb`
    notebook from *Chapter 3*. In *Chapter 3*, the URLs of the web pages were entered
    manually in a list.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: The code will fetch the content in the list of URLs. The program then cleans
    and prepares the data to populate the Deep Lake vector store.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 代码将从URL列表中获取内容。然后程序清理并准备数据以填充Deep Lake向量存储。
- en: 'Pipeline 2: Creating and populating the Deep Lake vector store'
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 管道2：创建和填充Deep Lake向量存储
- en: The pipeline in this section of `Deep_Lake_LlamaIndex_OpenAI_RAG.ipynb` was
    built with the code of *Pipeline 2* from *Chapter 3*. We can see that by creating
    pipelines as components, we can rapidly repurpose and adapt them to other applications.
    Also, Activeloop Deep Lake possesses in-built default chunking, embedding, and
    upserting functions, making it seamless to integrate various types of unstructured
    data, as in the case of the Wikipedia documents we are upserting.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在`Deep_Lake_LlamaIndex_OpenAI_RAG.ipynb`这一节中的管道是用第3章中的*管道2*的代码构建的。我们可以看到，通过将管道作为组件创建，我们可以快速重新利用和适应它们到其他应用中。此外，Activeloop
    Deep Lake内置了默认的块处理、嵌入和更新功能，使得集成各种类型的不结构化数据变得无缝，正如我们在更新维基百科文档时所做的那样。
- en: 'The output of the `display_record(record_number)` function shows how seamless
    the process is. The output displays the ID and metadata such as the file information,
    the data collected, the text, and the embedded vector:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '`display_record(record_number)`函数的输出显示了过程的无缝性。输出显示了ID和元数据，如文件信息、收集的数据、文本和嵌入向量：'
- en: '[PRE21]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: And with that, we have successfully repurposed the *Pipeline 2* component of
    *Chapter 3* and can now move on and build the graph knowledge index.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些，我们已经成功重新利用了第3章的*管道2*组件，现在可以继续并构建图知识索引。
- en: 'Pipeline 3: Knowledge graph index-based RAG'
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 管道3：基于知识图谱索引的RAG
- en: 'It’s time to create a knowledge graph index-based RAG pipeline and interact
    with it. As illustrated in the following figure, we have a lot of work to do:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 是时候创建一个基于知识图谱索引的RAG管道并与之交互了。如图所示，我们有很多工作要做：
- en: '![A diagram of a graph  Description automatically generated](img/B31169_07_05.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![一个图形的示意图  自动生成的描述](img/B31169_07_05.png)'
- en: 'Figure 7.5: Building knowledge graph-index RAG from scratch'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.5：从头开始构建知识图谱索引RAG
- en: 'In this section, we will:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将：
- en: Generate the knowledge graph index
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成知识图谱索引
- en: Display the graph
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 显示图形
- en: Define the user prompt
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义用户提示
- en: Define the hyperparameters of LlamaIndex’s in-built LLM model
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义LlamaIndex内置LLM模型的超参数
- en: Install the similarity score packages
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装相似度得分包
- en: Define the similarity score functions
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义相似度得分函数
- en: Run a sample similarity comparison between the similarity functions
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行相似度函数之间的样本相似度比较
- en: Re-rank the output vectors of an LLM response
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重新排序LLM响应的输出向量
- en: Run evaluation samples and apply metrics and human feedback scores
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行评估样本并应用指标和人工反馈得分
- en: Run metric calculations and display them
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行指标计算并显示它们
- en: Let’s go through these steps and begin by generating the knowledge graph index.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们按步骤进行，并首先生成知识图谱索引。
- en: Generating the knowledge graph index
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成知识图谱索引
- en: We will create a knowledge graph index from a set of documents using the `KnowledgeGraphIndex`
    class from the `llama_index.core` module. We will also time the index creation
    process to evaluate performance.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`llama_index.core`模块中的`KnowledgeGraphIndex`类从一个文档集中创建知识图谱索引。我们还将计时索引创建过程以评估性能。
- en: 'The function begins by recording the start time with `time.time()`. In this
    case, measuring the time is important because it takes quite some time to create
    the index:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 函数首先使用`time.time()`记录开始时间。在这种情况下，测量时间很重要，因为创建索引需要相当长的时间：
- en: '[PRE22]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'We now create a `KnowledgeGraphIndex` with embeddings using the `from_documents`
    method. The function uses the following parameters:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们使用`from_documents`方法创建一个基于嵌入的`KnowledgeGraphIndex`。该函数使用以下参数：
- en: '`documents` is the set of documents to index'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`documents`是要索引的文档集'
- en: '`max_triplets_per_chunk` is set to 2, limiting the number of triplets per chunk
    to optimize memory usage and processing time'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_triplets_per_chunk`设置为2，限制每个块中的三元组数量以优化内存使用和处理时间'
- en: '`include_embeddings` is set to `True`, indicating that embeddings should be
    included'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`include_embeddings`设置为`True`，表示应包含嵌入'
- en: 'The graph index is thus created in a few lines of code:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，知识图谱索引仅用几行代码就创建完成了：
- en: '[PRE23]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The timer is stopped and the creation time is measured:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 停止计时器并测量创建时间：
- en: '[PRE24]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The output displays the time:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示了时间：
- en: '[PRE25]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The graph type is displayed:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 显示图形类型：
- en: '[PRE26]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The output confirms the knowledge graph index class:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 输出确认了知识图谱索引类：
- en: '[PRE27]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'We will now set up a query engine for our knowledge graph index and configure
    it to manage similarity, response temperature, and output length parameters:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将设置我们的知识图谱索引的查询引擎，并配置它来管理相似度、响应温度和输出长度参数：
- en: '[PRE28]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The parameters will determine the behavior of the query engine:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 参数将决定查询引擎的行为：
- en: '`k=3` sets the number of top similar results to take into account.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`k=3`设置考虑的前N个最相似结果的数目。'
- en: '`temp=0.1` sets the temperature parameter, controlling the randomness of the
    query engine’s response generation. The lower it is, the more precise it is; the
    higher it is, the more creative it is.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`temp=0.1`设置温度参数，控制查询引擎响应生成的随机性。它越低，越精确；越高，越有创造性。'
- en: '`mt=1024` sets the maximum number of tokens for the output, defining the length
    of the generated responses.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mt=1024`设置输出中最大令牌数，定义生成响应的长度。'
- en: 'The query engine is then created with the parameters we defined:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 然后使用我们定义的参数创建查询引擎：
- en: '[PRE29]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: The graph index and query engine are ready. Let’s display the graph.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 图索引和查询引擎已就绪。让我们显示图形。
- en: Displaying the graph
  id: totrans-189
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 显示图形
- en: 'We will create a graph instance, `g`, with `pyvis.network`, a Python library
    used for creating interactive network visualizations. The displayed parameters
    are similar to the ones we defined in the *Building graphs from trees* section
    of this chapter:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`pyvis.network`创建一个图实例，`g`，这是一个用于创建交互式网络可视化的Python库。显示的参数与我们在这章的*从树构建图*部分定义的类似：
- en: '[PRE30]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'A directed graph has been created, and now we will save it in an HTML file
    to display it for further use:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 已创建一个有向图，现在我们将将其保存为HTML文件以供进一步使用：
- en: '[PRE31]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The `graph_name` was defined at the beginning of the notebook, in the *Scenario*
    section. We will now display the graph in the notebook as an HTML file:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '`graph_name`在笔记本的*场景*部分定义。现在我们将以HTML文件的形式在笔记本中显示该图：'
- en: '[PRE32]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'You can now download the file to display it in your browser to interact with
    it. You can also visualize it in the notebook, as shown in the following figure:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在可以下载文件并在浏览器中显示它以与之交互。您还可以在笔记本中可视化它，如图下所示：
- en: '![A diagram of marketing strategy  Description automatically generated](img/B31169_07_06.png)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
  zh: '![营销策略图解 描述自动生成](img/B31169_07_06.png)'
- en: 'Figure 7.6: The knowledge graph'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.6：知识图谱
- en: We are all set to interact with the knowledge graph index.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经准备好与知识图谱索引进行交互。
- en: Interacting with the knowledge graph index
  id: totrans-200
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 与知识图谱索引交互
- en: 'Let’s now define the functionality we need to execute the query, as we have
    done in *Chapter 3* in the *Pipeline 3: Index-based RAG* section:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们现在定义执行查询所需的功能，就像我们在*第3章*的*管道3：基于索引的RAG*部分中所做的那样：
- en: '`execute_query` is the function we created that will execute the query: `response
    = graph_query_engine.query(user_input)`. It also measures the time it takes.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`execute_query`是我们创建的执行查询的函数：`response = graph_query_engine.query(user_input)`。它还测量所需时间。'
- en: '`user_query="What is the primary goal of marketing for the consumer market?"`,
    which we will use to make the query.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`user_query="What is the primary goal of marketing for the consumer market?"`，我们将用它来执行查询。'
- en: '`response = execute_query(user_query)`, which is encapsulated in the request
    code and displays the response.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`response = execute_query(user_query)`，这是封装在请求代码中并显示响应的。'
- en: 'The output provides the best vectors that we created with the Wikipedia data
    with the time measurement:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 输出提供了我们使用维基百科数据创建的最佳向量，并附有时间测量：
- en: '[PRE33]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: We will now install similarity score packages and define the similarity calculation
    functions we need.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将安装相似度评分包并定义我们需要的相似度计算函数。
- en: Installing the similarity score packages and defining the functions
  id: totrans-208
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装相似度评分包和定义函数
- en: 'We will first retrieve the Hugging Face token from the **Secrets** tab on Google
    Colab, where it was stored in the settings of the notebook:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先从Google Colab上的**密钥**选项卡中检索Hugging Face令牌，它在笔记本的设置中被存储：
- en: '[PRE34]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'In August 2024, the token is optional for Hugging Face’s `sentence-transformers`.
    You can ignore the message and comment the code. Next, we install `sentence-transformers`:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 到2024年8月，Hugging Face的`sentence-transformers`令牌是可选的。您可以忽略消息并注释代码。接下来，我们安装`sentence-transformers`：
- en: '[PRE35]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'We then create a cosine similarity function with embeddings:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接着创建一个使用嵌入的余弦相似度函数：
- en: '[PRE36]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'We import the libraries we need:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 我们导入所需的库：
- en: '[PRE37]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: We have a similarity function and can use it for re-ranking.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有一个相似度函数，并且可以使用它进行重新排序。
- en: Re-ranking
  id: totrans-218
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 重新排序
- en: 'In this section, the program re-ranks the response of a query by reordering
    the top results to select other, possibly better, ones:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: '`user_query=" Which experts are often associated with marketing theory?"` represents
    the query we are making.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`start_time = time.time()` records the start time for the query execution.'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`response = execute_query(user_query)` executes the query.'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`end_time = time.time()` stops the timer, and the query execution time is displayed.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`for idx, node_with_score in enumerate(response.source_nodes)` iterates through
    the response to retrieve all the nodes in the response.'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`similarity_score3=calculate_cosine_similarity_with_embeddings(text1, text2)`
    calculates the similarity score between the user query and the text in the nodes
    retrieved from the response. All the comparisons are displayed.'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`best_score=similarity_score3` stores the best similarity score found.'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`print(textwrap.fill(str(best_text), 100))` displays the best re-ranked result.'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The initial response for the `user_query` `"Which experts are often associated
    with marketing theory?"` was:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'The response is acceptable. However, the re-ranked response goes deeper and
    mentions the names of marketing experts (highlighted in bold font):'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The re-ranked response is longer and contains raw document content instead
    of the summary provided by LlamaIndex’s LLM query engine. The original query engine
    response is better from an LLM perspective. However, it isn’t easy to estimate
    what an end-user will prefer. Some users like short answers, and some like long
    documents. We can imagine many other ways of re-ranking documents, such as modifying
    the prompt, adding documents, and deleting documents. We can even decide to fine-tune
    an LLM, as we will do in *Chapter 9*, *Empowering AI Models: Fine-Tuning RAG Data
    and Human Feedback*. We can also introduce human feedback scores as we did in
    *Chapter 5*, *Boosting RAG Performance with Expert Human Feedback*, because, in
    many cases, mathematical metrics will not capture the accuracy of a response (writing
    fiction, long answers versus short input, and other complex responses). But we
    need to try anyway!'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: Let’s perform some of the possible metrics for the examples we are going to
    run.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: Example metrics
  id: totrans-234
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To evaluate the knowledge graph index’s query engine, we will run ten examples
    and keep track of the scores. `rscores` keeps track of human feedback scores while
    `scores=[]` keeps track of similarity function scores:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The number of examples can be increased as much as necessary depending on the
    needs of a project. Each of the ten examples has the same structure:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: '`user_query`, which is the input text for the query engine'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`elapsed_time`, which is the result of the time measurement of the system’s
    response'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`response = execute_query(user_query)` executes the query'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The user query and output are the same as in the example used for the re-ranking
    function:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'However, this time, we will run a similarity function and also ask a human
    for a score:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'In this function:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: '`text1` is the query engine’s response.'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`text2` is the user query.'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`similarity_score3` is the cosine similarity score.'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`scores.append(similarity_score3)` appends the similarity score to scores.'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`human_feedback` is the human similarity evaluation. We could replace this
    score with a document as we did in *Chapter 5*, *Boosting RAG Performance with
    Expert Human Feedback*, or we could replace the human score with a human text
    response, which will become the ground truth. In both cases, the similarity score
    is recalculated with human feedback content.'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`rscores.append(human_feedback)` appends the human score to `rscores`.'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s review a few of the ten examples’ outputs and add a comment at the end
    of each one.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: LLMs are stochastic algorithms. As such, the responses and scores may vary from
    one run to another.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: '**Example 1**:'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**User query**: `Which experts are often associated with marketing theory?`'
  id: totrans-255
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Response**: Psychologists, cultural anthropologists, and other experts in
    behavioral sciences are often associated with marketing theory.'
  id: totrans-256
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cosine similarity score**: `0.809`'
  id: totrans-257
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Human feedback**: `0.75`'
  id: totrans-258
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Comment**: The response is acceptable, but it could be more specific and
    mention the names of experts. However, the prompt is ambiguous and only mentions
    experts in general.'
  id: totrans-259
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Example 3**:'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**User query**: `What is the difference between B2B and B2C?`'
  id: totrans-261
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Response**: B2B businesses sell products and services to other companies,
    while B2C businesses sell directly to customers.'
  id: totrans-262
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cosine Similarity score**: `0.760`'
  id: totrans-263
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Human feedback**: `0.8`'
  id: totrans-264
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Comment**: The response is precise, but in some cases, users like examples.'
  id: totrans-265
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Example 7**:'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**User query**: `What commodity programs does the Agricultural Marketing Service
    (AMS) maintain?`'
  id: totrans-267
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Response**: The **Agricultural Marketing Service** (**AMS**) maintains programs
    in five commodity areas: cotton and tobacco, dairy, fruit and vegetable, livestock
    and seed, and poultry.'
  id: totrans-268
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cosine Similarity score**: `0.904`'
  id: totrans-269
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Human feedback**: `0.9`'
  id: totrans-270
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Comment**: This response is accurate and interesting because the information
    is contained in a page linked to the main page. Thus, this is information from
    a linked page to the main page. We could ask Wikipedia to search the links of
    all the linked pages to the main page and go down several levels. However, the
    main information we are looking for may be diluted in less relevant data. The
    decision on the scope of the depth of the data depends on the needs of each project.'
  id: totrans-271
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: We will now perform metric calculations on the cosine similarity scores and
    the human feedback scores.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
- en: Metric calculation and display
  id: totrans-273
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The cosine similarity scores of the examples are stored in `scores`:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'The ten scores are displayed:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'We could expand the evaluations to as many other examples, depending on the
    needs of each project. The human feedback scores for the same examples are stored
    in `rscores`:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'The ten human feedback scores are displayed:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'We apply metrics to evaluate the responses:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Each metric can provide several insights. Let’s go through each of them and
    the outputs obtained:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
- en: '**Central tendency (mean, median)** gives us an idea of what a typical score
    looks like.'
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Variability (standard deviation, variance, range, IQR)** tells us how spread
    out the scores are, indicating the consistency or diversity of the data.'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Extremes (minimum, maximum)** show the bounds of our dataset.'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Distribution (percentiles)** provides insights into how scores are distributed
    across the range of values.'
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let’s go through these metrics calculated from the cosine similarity scores
    and the human feedback scores and display their outputs:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
- en: '**Mean (average)**:'
  id: totrans-290
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Definition**: The mean is the sum of all the scores divided by the number
    of scores.'
  id: totrans-291
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Purpose**: It gives us the central value of the data, providing an idea of
    the typical score.'
  id: totrans-292
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Calculation**:'
  id: totrans-293
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/B31169_07_001.png)'
  id: totrans-294
  prefs: []
  type: TYPE_IMG
- en: '**Output**: `Mean: 0.68`'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Median**:'
  id: totrans-296
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Definition**: The median is the middle value when the scores are ordered
    from smallest to largest.'
  id: totrans-297
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Purpose**: It provides the central point of the dataset and is less affected
    by extreme values (outliers) compared to the mean.'
  id: totrans-298
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Output**: `Median: 0.71`'
  id: totrans-299
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Standard deviation**:'
  id: totrans-300
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Definition**: The standard deviation measures the average amount by which
    each score differs from the mean.'
  id: totrans-301
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Purpose**: It gives an idea of how spread out the scores are around the mean.
    A higher value indicates more variability.'
  id: totrans-302
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Calculation**:'
  id: totrans-303
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/B31169_07_002.png)'
  id: totrans-304
  prefs: []
  type: TYPE_IMG
- en: '**Output**: `Standard Deviation: 0.15`'
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Variance**:'
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Definition**: The variance is the square of the standard deviation.'
  id: totrans-307
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Purpose**: It also measures the spread of the scores, showing how much they
    vary from the mean.'
  id: totrans-308
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Output**: `Variance: 0.02`'
  id: totrans-309
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Minimum**:'
  id: totrans-310
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Definition**: The minimum is the smallest score in the dataset.'
  id: totrans-311
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Purpose**: It tells us the lowest value.'
  id: totrans-312
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Output**: `Minimum: 0.45`'
  id: totrans-313
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Maximum:'
  id: totrans-314
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Definition**: The maximum is the largest score in the dataset.'
  id: totrans-315
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Purpose**: It tells us the highest value.'
  id: totrans-316
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Output**: `Maximum: 0.90`'
  id: totrans-317
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Range**:'
  id: totrans-318
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Definition**: The range is the difference between the maximum and minimum
    scores.'
  id: totrans-319
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Purpose**: It shows the span of the dataset from the lowest to the highest
    value.'
  id: totrans-320
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Calculation**:'
  id: totrans-321
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Range* = *Maximum* - *Minimum*'
  id: totrans-322
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Output**: `Range: 0.46`'
  id: totrans-323
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**25**^(th) **Percentile (Q1)**:'
  id: totrans-324
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Definition**: The 25^(th) percentile is the value below which 25% of the
    scores fall.'
  id: totrans-325
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Purpose**: It provides a point below which a quarter of the data lies.'
  id: totrans-326
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Output**: `25th Percentile (Q1): 0.56`'
  id: totrans-327
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**75**^(th) **Percentile (Q3)**:'
  id: totrans-328
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Definition**: The 75^(th) percentile is the value below which 75% of the
    scores fall.'
  id: totrans-329
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Purpose**: It gives a point below which three-quarters of the data lies.'
  id: totrans-330
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Output**: `75th Percentile (Q3): 0.80`'
  id: totrans-331
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Interquartile Range (IQR)**:'
  id: totrans-332
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Definition**: The IQR is the range between the 25^(th) percentile (Q1) and
    the 75^(th) percentile (Q3).'
  id: totrans-333
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Purpose**: It measures the middle 50% of the data, providing a sense of the
    data’s spread without being affected by extreme values.'
  id: totrans-334
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Calculation**:'
  id: totrans-335
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*IQR* = *Q3* – *Q1*'
  id: totrans-336
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Output**: `Interquartile Range (IQR): 0.24`'
  id: totrans-337
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: We have built a knowledge-graph-based RAG system, interacted with it, and evaluated
    it with some examples and metrics. Let’s sum up our journey.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-339
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we explored the creation of a scalable knowledge-graph-based
    RAG system using the Wikipedia API and LlamaIndex. The techniques and tools developed
    are applicable across various domains, including data management, marketing, and
    any field requiring organized and accessible data retrieval.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
- en: Our journey began with data collection in *Pipeline 1*. This pipeline focused
    on automating the retrieval of Wikipedia content. Using the Wikipedia API, we
    built a program to collect metadata and URLs from Wikipedia pages based on a chosen
    topic, such as marketing. In *Pipeline 2*, we created and populated the Deep Lake
    vector store. The retrieved data from *Pipeline 1* was embedded and upserted into
    the Deep Lake vector store. This pipeline highlighted the ease of integrating
    vast amounts of data into a structured vector store, ready for further processing
    and querying. Finally, in *Pipeline 3*, we introduced knowledge graph index-based
    RAG. Using LlamaIndex, we automatically built a knowledge graph index from the
    embedded data. This index visually mapped out the relationships between different
    pieces of information, providing a semantic overview of the data. The knowledge
    graph was then queried using LlamaIndex’s built-in language model to generate
    optimal responses. We also implemented metrics to evaluate the system’s performance,
    ensuring accurate and efficient data retrieval.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
- en: By the end of this chapter, we had constructed a comprehensive, automated RAG-driven
    knowledge graph system capable of collecting, embedding, and querying vast amounts
    of Wikipedia data with minimal human intervention. This journey showed the power
    and potential of combining multiple AI tools and models to create an efficient
    pipeline for data management and retrieval. You are now all set to implement knowledge
    graph-based RAG systems in real-life projects. In the next chapter, we will learn
    how to implement dynamic RAG for short-term usage.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  id: totrans-343
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Answer the following questions with yes or no:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
- en: Does the chapter focus on building a scalable knowledge-graph-based RAG system
    using the Wikipedia API and LlamaIndex?
  id: totrans-345
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Is the primary use case discussed in the chapter related to healthcare data
    management?
  id: totrans-346
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Does *Pipeline 1* involve collecting and preparing documents from Wikipedia
    using an API?
  id: totrans-347
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Is Deep Lake used for creating a relational database in *Pipeline 2*?
  id: totrans-348
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Does *Pipeline 3* utilize LlamaIndex to build a knowledge graph index?
  id: totrans-349
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Is the system designed to only handle a single specific topic, such as marketing,
    without flexibility?
  id: totrans-350
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Does the chapter describe how to retrieve URLs and metadata from Wikipedia pages?
  id: totrans-351
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Is a GPU required to run the pipelines described in the chapter?
  id: totrans-352
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行章节中描述的管道需要 GPU 吗？
- en: Does the knowledge graph index visually map out relationships between pieces
    of data?
  id: totrans-353
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 知识图谱索引是否以视觉方式映射出数据片段之间的关系？
- en: Is human intervention required at every step to query the knowledge graph index?
  id: totrans-354
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在查询知识图谱索引的每一步都需要人工干预吗？
- en: References
  id: totrans-355
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Wikipedia API GitHub repository: [https://github.com/martin-majlis/Wikipedia-API](https://github.com/martin-majlis/Wikipedia-API)'
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 维基百科 API GitHub 仓库：[https://github.com/martin-majlis/Wikipedia-API](https://github.com/martin-majlis/Wikipedia-API)
- en: 'PyVis Network: *Interactive Network Visualization in Python*.'
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyVis 网络：*Python 中的交互式网络可视化*。
- en: Further reading
  id: totrans-358
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: Hogan, A., Blomqvist, E., Cochez, M., et al. *Knowledge Graphs*. `arXiv:2003.02320`
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hogan, A., Blomqvist, E., Cochez, M., et al. *知识图谱*。`arXiv:2003.02320`
- en: Join our community on Discord
  id: totrans-360
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们的 Discord 社区
- en: 'Join our community’s Discord space for discussions with the author and other
    readers:'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 加入我们的 Discord 空间，与作者和其他读者进行讨论：
- en: '[https://www.packt.link/rag](https://www.packt.link/rag)'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.packt.link/rag](https://www.packt.link/rag)'
- en: '![](img/QR_Code50409000288080484.png)'
  id: totrans-363
  prefs: []
  type: TYPE_IMG
  zh: '![二维码](img/QR_Code50409000288080484.png)'
