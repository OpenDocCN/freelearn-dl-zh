- en: Chapter 6. Classifying Disease Diagnosis
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第6章. 疾病诊断分类
- en: 'So far, we have been working with supervised learning for predicting numerical
    values; however, in the real world, numbers are just part of the data addressed.
    Real variables also contain categorical values, which are not purely numerical,
    but describe important features that have influence on the problems neural networks
    are applied to solve. In this chapter, the reader will be presented with a very
    didactic but interesting application involving categorical values and classification:
    disease diagnosis. This chapter digs deeper into classification problems and how
    to represent categorical data, as well as showing how to design a classification
    algorithm using neural networks. The topics covered in this chapter are as follows:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们一直在使用监督学习来预测数值；然而，在现实世界中，数字只是数据的一部分。真实变量还包含分类值，这些值不是纯数值，但描述了影响神经网络应用解决的问题的重要特征。在本章中，读者将了解到一个涉及分类值和分类的非常具有教育意义且有趣的应用：疾病诊断。本章深入探讨了分类问题以及如何表示分类数据，以及如何使用神经网络设计分类算法。本章涵盖的主题如下：
- en: Foundations of classification problems
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类问题的基础
- en: Categorical data
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类数据
- en: Logistic regression
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逻辑回归
- en: Confusion matrix
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 混淆矩阵
- en: Sensibility and specificity
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 敏感性和特异性
- en: Neural networks for classification
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于分类的神经网络
- en: Disease diagnosis using neural networks
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用神经网络进行疾病诊断
- en: Diagnosis for cancer
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 癌症诊断
- en: Diagnosis for diabetes
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 糖尿病诊断
- en: Foundations of classification problems
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分类问题的基础
- en: 'One thing neural networks are really good at is classifying records. The very
    simple perceptron network draws a decision boundary, defining whether a data point
    belongs to one region or another, whereas a region denotes a class. Let''s take
    a look visually on an *x-y* scatter chart:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络真正擅长的一件事是分类记录。非常简单的感知器网络绘制决策边界，定义数据点属于哪个区域，而区域表示一个类别。让我们通过一个*x-y*散点图来直观地看一下：
- en: '![Foundations of classification problems](img/B05964_06_01.jpg)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![分类问题的基础](img/B05964_06_01.jpg)'
- en: The dashed lines explicitly separate the points into classes. These points represent
    data records which originally had the corresponding class labels. That means their
    classes were already known, therefore this classification tasks falls in the supervised
    learning category.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 虚线明确地将点分为不同的类别。这些点代表原本具有相应类别标签的数据记录。这意味着它们的类别已经已知，因此这个分类任务属于监督学习类别。
- en: 'A classification algorithm seeks to find the boundaries between the classes
    in the data hyperspace. Once the classification boundaries are defined, a new
    data point, with an unknown class, receives a class label according to the boundaries
    defined by the classification algorithm. The figure below shows how a new record
    is classified:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 一个分类算法试图在数据超空间中的类别之间找到边界。一旦定义了分类边界，一个未知类别的新的数据点就会根据分类算法定义的边界获得一个类别标签。下面的图示显示了如何对一条新记录进行分类：
- en: '![Foundations of classification problems](img/B05964_06_02.jpg)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![分类问题的基础](img/B05964_06_02.jpg)'
- en: Based on the current class configuration, the new record's class is the third
    class.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 根据当前的类别配置，新记录的类别是第三个类别。
- en: Categorical data
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分类数据
- en: 'Applications usually lead with the types of data shown in the following figure:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 应用通常从以下图示中展示的数据类型开始：
- en: '![Categorical data](img/B05964_06_03.jpg)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![分类数据](img/B05964_06_03.jpg)'
- en: 'Data can be numerical or categorical or, simply speaking, numbers or words.
    Numerical data is represented by a numeric value, from which it can be continuous
    or discrete. This data type has been used so far in this book''s applications.
    Categorical data is a wider class of data that includes words, letters, or even
    numbers, but with a quite different meaning. While numerical data can support
    arithmetic operations, categorical data is only descriptive and cannot be processed
    like numbers, even if the value is a number. An example is the severity degree
    of a disease in a scale (from zero to five, for example). Another property of
    categorical data is that a certain variable has a finite number of values; in
    other words, only a defined set of values can be assigned to a categorical variable.
    A subclass of data inside the categorical is ordinal data. This class is particular
    because the defined values can be sorted in a predefined order. An example is
    adjectives indicating the state or quality of something (bad, fair, good, excellent):'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: '| Numerical | Categorical |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
- en: '| Only numbers | Numbers, words, letters, signs |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
- en: '| Can support arithmetic operations | Do not support arithmetic operations
    |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
- en: '| Infinite or undefined range of values | Finite or defined set of values |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
- en: '| Continuous | Discrete | Ordinal | Non-ordinal |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
- en: '| Real values | Integers, decimal | Can be ordered | Cannot be ordered |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
- en: '| Any possible value | Predefined intervals | Can be assigned numbers | Each
    possible value is a flag |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
- en: Tip
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Note that here we are addressing structured data only. In the real world, most
    data is unstructured, including text and multimedia content. Although these types
    of data are also processed in learning from data applications, neural networks
    require them to be transformed into structured data types.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: Working with categorical data
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Structured data files, such as those used in CSV or Excel, usually contain
    columns of numerical and categorical data. In [Chapter 5](ch05.xhtml "Chapter 5. Forecasting
    Weather"), *Forecasting Weather* we have created the classes `LoadCsv` (for loading
    `csv` files) and DataSet (for storing data from csv), but these classes are prepared
    only for working with numerical data. The simplest way of representing categorical
    value is converting each possible value into a binary column, whereby if the given
    value is presented in the original column, the corresponding binary column will
    have a one as the converted value, otherwise it will be zero:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: '![Working with categorical data](img/B05964_06_04.jpg)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
- en: Ordinal columns can assume the defined values as numerical in the same column;
    however, if the original values are letters or words, they need to be converted
    into numbers via a Java Dictionary.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: The strategy described above may be implemented by you as an exercise. Otherwise,
    you would have to handle this manually. In this case, depending on the number
    of data rows, it can be time-consuming.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: Logistic regression
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We''ve covered that Neural Networks can work as data classifiers by establishing
    decision boundaries onto data in the hyperspace. This boundary can be linear,
    in the case of perceptrons, or nonlinear, in the case of other neural architectures
    such as MLPs, Kohonen, or Adaline. The linear case is based on linear regression,
    on which the classification boundary is a literally a line, as shown in the previous
    figure. If the scatter chart of the data looks like that of the following figure,
    then a nonlinear classification boundary is needed:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经讨论了神经网络可以通过在超空间中的数据上建立决策边界来作为数据分类器工作。这个边界可以是线性的，例如在感知器的情况下，或者非线性的，例如在其他神经网络架构中，如MLPs、Kohonen或Adaline。线性情况基于线性回归，分类边界实际上是一条线，如前图所示。如果数据的散点图看起来像以下图中的那样，则需要非线性分类边界：
- en: '![Logistic regression](img/B05964_06_05.jpg)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![逻辑回归](img/B05964_06_05.jpg)'
- en: 'Neural Networks are in fact a great nonlinear classifier, and this is achieved
    by the usage of nonlinear activation functions. One nonlinear function that actually
    works well for nonlinear classification is the sigmoid function, whereas the procedure
    for classification using this function is called logistic regression:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络实际上是一个非常好的非线性分类器，这是通过使用非线性激活函数实现的。一个实际上对非线性分类效果很好的非线性函数是Sigmoid函数，而使用此函数进行分类的过程称为逻辑回归：
- en: '![Logistic regression](img/B05964_06_06.jpg)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![逻辑回归](img/B05964_06_06.jpg)'
- en: 'This function returns values bounded between zero and one. In this function
    α parameter denotes how hard the transition from zero and 1 occurs. The following
    chart shows the difference:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数返回介于零和一之间的值。在此函数中，α参数表示从零到一的转换有多硬。以下图表显示了差异：
- en: '![Logistic regression](img/B05964_06_06_01.jpg)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![逻辑回归](img/B05964_06_06_01.jpg)'
- en: Note that the higher the alpha parameter is, the more the logistic function
    takes a shape of a hard-limiting threshold function, also known as a step function.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，alpha参数越高，逻辑函数就越接近硬限定的阈值函数，也称为阶梯函数。
- en: Multiple classes versus binary classes
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多分类与二分类
- en: Classification problems usually deal with a multiple class's case, where each
    class is assigned a label. However, a binary classification schema is useful to
    be applied in neural networks. This is because a neural network with a logistic
    function at the output layer can produce only values between `0` and `1`, meaning
    it belongs (1) or does not belong (0) to some class.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 分类问题通常处理多分类的情况，其中每个类别都被分配一个标签。然而，二分类方案在神经网络中很有用。这是因为输出层具有逻辑函数的神经网络只能产生介于`0`和`1`之间的值，这意味着它属于（1）或不属于（0）某个类别。
- en: 'Nevertheless, there is one approach for multiple classes using binary functions.
    Consider that every class is represented by an output neuron, and whenever that
    output neuron fires, that neuron''s corresponding class is applied on the input
    data record. So let''s suppose a network to classify diseases; each neuron output
    will represent a disease to be applied to some symptom:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，对于多分类，有一种使用二进制函数的方法。假设有一个用于分类疾病的网络；每个神经元的输出将代表一个应用于某些症状的疾病：
- en: '![Multiple classes versus binary classes](img/B05964_06_07.jpg)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![多分类与二分类](img/B05964_06_07.jpg)'
- en: Tip
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: Note that in that configuration, it would be possible to have multiple diseases
    with the same symptoms, which can happen. However, if only one class would be
    desirable to be chosen, then a schema as the competitive learning algorithm would
    suit more in that case.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在那个配置中，可能会有多个疾病具有相同的症状，这种情况可能发生。然而，如果只希望选择一个类别，那么竞争学习算法的方案在这种情况下可能更适合。
- en: Confusion matrix
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 混淆矩阵
- en: There is no perfect classifier algorithm; all of them are subject to errors
    and biases; however, it is expected that a classification algorithm can correctly
    classify 70-90% of the records.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 没有完美的分类器算法；它们都存在错误和偏差；然而，预期一个分类算法可以正确分类70-90%的记录。
- en: Tip
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: Very high correct classification rates are not always desirable, because of
    possible biases presented in the input data that might affect the classification
    task, and also there is a risk of overtraining, when only the training data is
    correctly classified.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 非常高的正确分类率并不总是理想的，因为输入数据中可能存在的偏差可能会影响分类任务，并且也存在过拟合的风险，当只有训练数据被正确分类时。
- en: 'A confusion matrix shows how much of a given class''s records were correctly
    classified and thereby how much were wrongly classified. The following table depicts
    what a confusion matrix may look like:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: '![Confusion matrix](img/B05964_06_08.jpg)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
- en: Note that the main diagonal is expected to have the higher values, as the classification
    algorithm will always try to extract meaningful information from the input dataset.
    The sum of all rows must be equal to 100%, because all elements of a given class
    are to be classified in one of the available classes. Note that some classes may
    receive more classifications than expected.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: The more a confusion matrix looks like an identity matrix, the better the classification
    algorithm will be.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: Sensitivity and specificity
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When the classification is binary, the confusion matrix is found to be a simple
    2x2 matrix, and therefore its positions are specially named:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: '| Actual Class | Inferred Class |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
- en: '| Positive (1) | Negative (0) |   |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
- en: '| Positive (1) | True Positive | False Negative |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
- en: '| Negative (0) | False Positive | True Negative |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
- en: In disease diagnosis, which is the subject of this chapter, the concept of a
    binary confusion matrix is applied in the sense that a false diagnosis may be
    either false positive or false negative. The rate of false results can be measured
    by sensitivity and specificity indexes.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: 'Sensitivity means the true positive rate; it measures how many of the records
    are correctly classified positively:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: '![Sensitivity and specificity](img/B05964_06_09.jpg)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
- en: 'Specificity, in turn, means the true negative rate; it indicates the proportion
    of negative record identification:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: '![Sensitivity and specificity](img/B05964_06_10.jpg)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
- en: High values of both sensitivity and specificity are desired; however, depending
    on the application field, the sensitivity may carry more meaning.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: Implementing a confusion matrix
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In our code, let''s implement the confusion matrix in the class `NeuralOutputData`.
    The method `calculateConfusionMatrix` below is programmed to consider two neurons
    in the output layer. If the output is 10, then it is *yes* to a confusion matrix;
    if the output is 01, then it is no:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Another method implemented in the `NeuralOutputData` class is called `calculatePerformanceMeasures`.
    It receives as parameter the confusion matrix and it calculates and prints the
    following performance measures of classification:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: Positive class error rate
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Negative class error rate
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Total error rate
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Total accuracy
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Precision
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sensibility
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Specificity
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This method is shown below:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Neural networks for classification
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Classification tasks can be done by any of the supervised neural networks this
    book has covered so far. However, it is recommended that you use more complex
    architectures such as MLPs. In this chapter, we are going to use the `NeuralNet`
    class to build an MLP with one hidden layer and the sigmoid function at the output.
    Every output neuron will mean a class.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: The code used to implement the examples is very similar to the test class (`BackpropagationTest`).
    However, the class `DiagnosisExample` asks which dataset the user would like to
    use and other neural network parameters, such as number of epochs, number of neurons
    in hidden layer, and learning rate.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: Disease diagnosis with neural networks
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For disease diagnosis, we are going to use the free dataset proben1, which
    is available on the Web ([http://www.filewatcher.com/m/proben1.tar.gz.1782734-0.html](http://www.filewatcher.com/m/proben1.tar.gz.1782734-0.html)).
    Proben1 is a benchmark set of several datasets from different domains. We are
    going to use the cancer and the diabetes datasets. We add a class to run the experiments
    of each case: `DiagnosisExample`.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: Breast cancer
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The breast cancer dataset is composed of 10 variables, of which nine are inputs
    and one is a binary output. The dataset has 699 records, but we excluded from
    them 16 which were found to be incomplete, thus we used 683 to train and test
    the neural network.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In real practical problems, it is common to have missing or invalid data. Ideally,
    the classification algorithm must handle these records, but sometimes it is recommended
    that you exclude them, since there would be not enough information to produce
    an accurate result.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: 'The following table shows a configuration of this dataset:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: '| Variable Name | Type | Maximum Value and Minimum Value |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
- en: '| Diagnosis result | OUTPUT | [0; 1] |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
- en: '| Clump Thickness | INPUT #1 | [1; 10] |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
- en: '| Uniformity of Cell Size | INPUT #2 | [1; 10] |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
- en: '| Uniformity of Cell Shape | INPUT #3 | [1; 10] |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
- en: '| Marginal Adhesion | INPUT #4 | [1; 10] |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
- en: '| Single Epithelial Cell Size | INPUT #5 | [1; 10] |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
- en: '| Bare Nuclei | INPUT #6 | [1; 10] |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
- en: '| Bland Chromatin | INPUT #7 | [1; 10] |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
- en: '| Normal Nucleoli | INPUT #8 | [1; 10] |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
- en: '| Mitoses | INPUT #9 | [1; 10] |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
- en: 'So, the proposed neural topology will be that of the following figure:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: '![Breast cancer](img/B05964_06_11.jpg)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
- en: 'The dataset division was made as follows:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: '**Training**: 549 records (80%);'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Testing**: 134 records (20%)'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'As in the previous cases, we performed many experiments to try to find the
    best neural network to classify whether cancer is benign or malignant. So we conducted
    12 different experiments (1,000 epochs per experiment), wherein MSE and accuracy
    values were analyzed. After that, the confusion matrix, sensitivity, and specificity
    were generated with the test dataset and analysis was done. Finally, an analysis
    of generalization was taken. The neural networks involved in the experiments are
    shown in the following table:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: '| Experiment | Number of neurons in hidden layer | Learning rate | Activation
    Function |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
- en: '| #1 | 3 | 0.1 | Hidden Layer: SIGLOGOutput Layer: LINEAR |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
- en: '| #2 | Hidden Layer: HYPERTANOutput Layer: LINEAR |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
- en: '| #3 | 0.5 | Hidden Layer: SIGLOGOutput Layer: LINEAR |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
- en: '| #4 | Hidden Layer: HYPERTANOutput Layer: LINEAR |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
- en: '| #5 | 0.9 | Hidden Layer: SIGLOGOutput Layer: LINEAR |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
- en: '| #6 | Hidden Layer: HYPERTANOutput Layer: LINEAR |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
- en: '| #7 | 5 | 0.1 | Hidden Layer: SIGLOGOutput Layer: LINEAR |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
- en: '| #8 | Hidden Layer: HYPERTANOutput Layer: LINEAR |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
- en: '| #9 | 0.5 | Hidden Layer: SIGLOGOutput Layer: LINEAR |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
- en: '| #10 | Hidden Layer: HYPERTANOutput Layer: LINEAR |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
- en: '| #11 | 0.9 | Hidden Layer: SIGLOGOutput Layer: LINEAR |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
- en: '| #12 | Hidden Layer: HYPERTANOutput Layer: LINEAR |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
- en: 'After each experiment, we collected MSE values (Table X); experiments #4, #8,
    #9, #10, and #11 were equivalents, because they have low MSE values and same total
    accuracy measure (92.25%). Therefore, we selected experiments #4 and #11, because
    they have low MSE values among the five experiments mentioned before:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: '| Experiment | MSE training rate | Total accuracy |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
- en: '| #1 | 0.01067 | 96.29% |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
- en: '| #2 | 0.00443 | 98.50% |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
- en: '| #3 | 9.99611E-4 | 97.77% |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
- en: '| #4 | 9.99913E-4 | 99.25% |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
- en: '| #5 | 9.99670E-4 | 96.26% |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
- en: '| #6 | 9.92578E-4 | 97.03% |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
- en: '| #7 | 0.01392 | 98.49% |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
- en: '| #8 | 0.00367 | 99.25% |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
- en: '| #9 | 9.99928E-4 | 99.25% |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
- en: '| #10 | 9.99951E-4 | 99.25% |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
- en: '| #11 | 9.99926E-4 | 99.25% |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
- en: '| #12 | NaN | 3.44% |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
- en: 'Graphically, the MSE evolution over time is very fast, as can be seen in the
    following chart of the fourth experiment. Although we used 1,000 epochs to train,
    the experiment stopped earlier, because the minimum overall error (0.001) was
    reached:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: '![Breast cancer](img/B05964_06_12.jpg)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
- en: 'The confusion matrix is shown in the table with the sensibility and specificity
    for both experiments. It is possible to check that measures are the same for both
    experiments:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: '| Experiment | Confusion Matrix | Sensibility | Specificity |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
- en: '| #4 | [[34.0, 1.0][0.00, 99.0]] | 97.22% | 100.0% |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
- en: '| #11 | [[34.0, 1.0][0.00, 99.0]] | 97.22% | 100.0% |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
- en: 'If we had to choose between models generated by experiments #4 or #11, we recommend
    selecting #4, because it''s simpler than #11 (it has fewer neurons in the hidden
    layer).'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: Diabetes
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'An additional example to be explored is the diagnosis of diabetes. This dataset
    has eight inputs and one output, shown in the table below. There are 768 records,
    all complete. However, proben1 states that there are several senseless zero values,
    probably indicating missing data. We''re handling this data as if it was real
    anyway, thereby introducing some errors (or noise) into the dataset:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: '| Variable Name | Type | Maximum Value and Minimum Value |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
- en: '| Diagnosis result | OUTPUT | [0; 1] |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
- en: '| Number of times pregnant | INPUT #1 | [0.0; 17] |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
- en: '| Plasma glucose concentration a 2 hours in an oral glucose tolerance test
    | INPUT #2 | [0.0; 199] |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
- en: '| Diastolic blood pressure (mm Hg) | INPUT #3 | [0.0; 122] |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
- en: '| Triceps skin fold thickness (mm) | INPUT #4 | [0.0; 99] |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
- en: '| 2-Hour serum insulin (mu U/ml) | INPUT #5 | [0.0; 744] |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
- en: '| Body mass index (weight in kg/(height in m)^2) | INPUT #6 | [0.0; 67.1] |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
- en: '| Diabetes pedigree function | INPUT #7 | [0.078; 2420] |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
- en: '| Age (years) | INPUT #8 | [21; 81] |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
- en: 'The dataset division was made as follows:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: '**Training**: 617 records (80%)'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Test**: 151 records (20%)'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To discover the best neural net topology to classify diabetes, we used the
    same schema of neural networks with the same analysis described in the last section.
    However, we''re using multiple class classification in the output layer: two neurons
    in this layer will be used, one for the presence of diabetes and one for absence.'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: 'So, the proposed neural architecture looks like that of the following figure:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: '![Diabetes](img/B05964_06_13.jpg)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
- en: 'The table below shows the MSE training value and accuracy of the first six
    experiments and of the last six experiments:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: '| Experiment | MSE training rate | Total accuracy |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
- en: '| #1 | 0.00807 | 60.54% |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
- en: '| #2 | 0.00590 | 71.03% |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
- en: '| #3 | 9.99990E-4 | 75.49% |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
- en: '| #4 | 9.98840E-4 | 74.17% |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
- en: '| #5 | 0.00184 | 61.58% |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
- en: '| #6 | 9.82774E-4 | 59.86% |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
- en: '| #7 | 0.00706 | 63.57% |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
- en: '| #8 | 0.00584 | 72.41% |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
- en: '| #9 | 9.99994E-4 | 74.66% |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
- en: '| #10 | 0.01047 | 72.14% |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
- en: '| #11 | 0.00316 | 59.86% |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
- en: '| #12 | 0.43464 | 40.13% |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
- en: 'The fall of the MSE is fast in both cases. However, experiment #9 generates
    an increase of error rate in the first values. It is shown in the following figure:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: '![Diabetes](img/B05964_06_14.jpg)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
- en: 'Analyzing the confusion matrixes, it can be seen that the measures are very
    similar:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: '| Experiment | Confusion Matrix | Sensibility | Specificity |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
- en: '| #3 | [[35.0, 12.0][25.0, 79.0]] | 74.46% | 75.96% |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
- en: '| #9 | [[34.0, 12.0][26.0, 78.0]] | 73.91% | 75.00% |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
- en: 'One more time, we suggest choosing the simplest model. In the diabetes example,
    it is the artificial neural network generated by experiment #3.'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  id: totrans-192
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It is recommended you explore the class `D` `iagnosisExample` and create a GUI
    to become easy select neural net parameters, as was done in the previous chapter.
    You should try to reuse code already programmed through the inheritance concept.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-194
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we've seen two examples of the application of disease diagnosis
    using neural networks. The fundamentals of classification problems were briefly
    reviewed in order to level the knowledge explored in this chapter. Classification
    tasks belong to one of the most used types of supervised tasks in the machine
    learning / data mining fields, and Neural Networks proved to be very appropriate
    to be applied to this type of problem. The reader was also presented with the
    concepts that evaluate the classification tasks, such as sensitivity, specificity,
    and the confusion matrix. These notations are very useful for all classification
    tasks, including those which are handled with other algorithms besides neural
    networks. The next chapter will explore a similar kind of task but using unsupervised
    learning – that means, without expected output data – but the fundamentals presented
    in this chapter will be somewhat helpful.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
