<html><head></head><body><div><div><div><h1 class="chapterNumber"><a id="_idTextAnchor038"/>5</h1>
    <h1 id="_idParaDest-69" class="chapterTitle">Implementing Powerful Search Functionalities with Neo4j and Haystack</h1>
    <p class="normal">In this chapter, we embark on a journey to integrate Haystack with Neo4j, combining the capabilities of LLMs and graph databases to build an AI-powered search system. <strong class="keyWord">Haystack</strong> is an open-source framework that enables developers to create <a id="_idIndexMarker242"/>AI-powered applications by leveraging modern NLP techniques, machine learning models, and graph-based data. For our intelligent search, Haystack will serve as a cohesive platform for orchestrating LLMs, search engines, and databases, delivering highly contextualized and relevant search results.</p>
    <p class="normal">Building upon the work from the previous chapter—where we cleaned and structured our Neo4j data—we will start by generating embeddings using OpenAI’s GPT models. These embeddings will enrich the graph, making it more powerful and capable of handling nuanced, context-aware search queries. Haystack will <a id="_idIndexMarker243"/>serve as the bridge between OpenAI’s models and the Neo4j graph database, allowing us to combine the strengths of both.</p>
    <p class="normal">In this chapter, you will learn how to set up and configure Haystack for seamless integration with Neo4j. We will walk you through building powerful search functionalities and finally deploying this fully functional search system, using Gradio on Hugging Face Spaces.</p>
    <p class="normal">In this chapter, we are going to cover the following main topics:</p>
    <ul>
      <li class="bulletList">Generating embeddings with Haystack to enhance your Neo4j graph</li>
      <li class="bulletList">Connecting Haystack to Neo4j for advanced vector search</li>
      <li class="bulletList">Building powerful search experiences</li>
      <li class="bulletList">Fine-tuning your Haystack integration</li>
    </ul>
    <h1 id="_idParaDest-70" class="heading-1">Technical requirements</h1>
    <p class="normal">To successfully implement the integration of Haystack and Neo4j, and to build an AI-powered search system, you will need to ensure that your environment is properly set up. Here is a list of the technical requirements for this chapter:</p>
    <ul>
      <li class="bulletList"><strong class="screenText">Python</strong>: You will need Python <code class="inlineCode">3.11</code> installed on your system. Python is used for scripting and interacting with the Neo4j database. You can download Python from the official Python website: <a href="https://www.python.org/downloads/">https://www.python.org/downloads/</a>.</li>
      <li class="bulletList"><strong class="screenText">Neo4j AuraDB or local Neo4j instance</strong>: You will need access to a Neo4j database to store and query your graph data. This can be either a locally installed Neo4j instance or a cloud-hosted Neo4j AuraDB instance. If you are following along from the previous chapter, where we talked about the <code class="inlineCode">graph_build.py</code> script (<a href="https://github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/blob/main/ch4/graph_build.py">https://github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/blob/main/ch4/graph_build.py</a>), you can continue using the same Neo4j instance that was set up and populated with data. This ensures continuity and allows you to build on top of the structured data that has already been imported.</li>
      <li class="bulletList"><strong class="screenText">Cypher query language</strong>: Familiarity with the Cypher query language is essential, as we will be using Cypher extensively to create and query the graph. You can find out more about Cypher syntax in the Cypher query language documentation: <a href="https://neo4j.com/docs/cypher/">https://neo4j.com/docs/cypher/</a>.</li>
      <li class="bulletList"><strong class="screenText">Neo4j Python driver</strong>: Install the Neo4j Python driver to connect to the Neo4j database using Python. You can install it via <code class="inlineCode">pip</code>:
        <pre class="programlisting code"><code class="hljs-code">pip install neo4j
</code></pre>
      </li>
      <li class="bulletList"><strong class="screenText">Haystack</strong>: We will be using Haystack v2.5.0.</li>
    </ul>
    <p class="normal">Install Haystack using pip:</p>
    <pre class="programlisting code"><code class="hljs-code">pip install haystack-ai
</code></pre>
    <ul>
      <li class="bulletList"><strong class="screenText">OpenAI API key</strong>: To successfully generate embeddings using GPT-based models, you will need an OpenAI API key.</li>
    </ul>
    <p class="normal">Obtain the API key by signing up for an account at OpenAI (<a href="https://platform.openai.com/signup">https://platform.openai.com/signup</a>) if you do not have one. </p>
    <div><p class="normal"><strong class="keyWord">Note</strong></p>
      <p class="normal">A free-tier API key will not work for most use cases in this project. You will need an active paid OpenAI subscription to access the necessary endpoints and usage limits.</p>
    </div>
    <p class="normal">Once you are logged in, navigate to the <strong class="screenText">API keys</strong> section (<a href="https://platform.openai.com/api-keys">https://platform.openai.com/api-keys</a>) in your OpenAI dashboard and generate a new API key.</p>
    <p class="normal">You also need to install the OpenAI package using pip. Run the following command in your terminal:</p>
    <pre class="programlisting code"><code class="hljs-code">pip install openai
</code></pre>
    <ul>
      <li class="bulletList"><strong class="screenText">Gradio</strong>: Gradio will be used to create a user-friendly chatbot interface. Install Gradio using pip:
        <pre class="programlisting code"><code class="hljs-code">pip install gradio
</code></pre>
      </li>
      <li class="bulletList"><strong class="screenText">Hugging Face account</strong>: To host your chatbot on Hugging Face Spaces, you will need a Hugging Face account. If you do not have one, sign up on the Hugging Face website: <a href="https://huggingface.co/">https://huggingface.co/</a>.</li>
      <li class="bulletList"><strong class="screenText">Google Cloud Storage (optional)</strong>: If you are storing your CSV files on Google Cloud Storage, ensure that your file paths are properly configured in the script.</li>
      <li class="bulletList"><strong class="screenText">python-dotenv package</strong>: Make sure to install the <code class="inlineCode">python-dotenv</code> package to manage environment variables in your project:
        <pre class="programlisting code"><code class="hljs-code">pip install python-dotenv
</code></pre>
      </li>
    </ul>
    <p class="normal">All the code for this chapter is available in the following GitHub repository: <a href="https://github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs">https://github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs</a>.</p>
    <p class="normal">Inside this repository, navigate to the folder named <code class="inlineCode">ch6</code> to access the code examples and resources related to this chapter. This folder contains all the necessary scripts, files, and configurations required to implement the Neo4j and Haystack integration, as well as build the AI-powered search system using th<a id="_idTextAnchor039"/>e movies dataset.</p>
    <p class="normal">Make sure to clone or download the repository so you can follow along with the code examples throughout this chapter.</p>
    <p class="normal">Generating embeddings with Haystack to enhance your Neo4j graph</p>
    <p class="normal">In this section, we will focus on generating embeddings for the movie plots that we added to our Neo4j graph in the previous chapter. <strong class="keyWord">Embeddings</strong> are <a id="_idIndexMarker244"/>a critical part of modern search systems, as they convert text into high-dimensional vectors that enable similarity search. This enables the search engine to understand the contextual relationships between words and phrases, improving the accuracy and relevance of search results.</p>
    <p class="normal">We will integrate Haystack with OpenAI’s GPT-based models to generate these embeddings and store them in your Neo4j graph. This will enable a more accurate and context-aware search functionality.</p>
    <h2 id="_idParaDest-71" class="heading-2">Initializing Haystack and OpenAI for embeddings</h2>
    <p class="normal">Before <a id="_idIndexMarker245"/>generating embeddings, you will need to ensure that Haystack is set up and integrated with<a id="_idIndexMarker246"/> OpenAI’s API to retrieve embeddings from their GPT-based models. Follow these steps to set up Haystack:</p>
    <ol>
      <li class="numberedList" value="1">Install the required libraries (if you have not already) by using the following command:
        <pre class="programlisting code"><code class="hljs-code">pip install haystack haystack-ai openai neo4j-haystack
</code></pre>
      </li>
      <li class="numberedList">Next, configure your OpenAI API key and ensure that it is set up in your <code class="inlineCode">.env</code> file:
        <pre class="programlisting code"><code class="hljs-code">makefile
OPENAI_API_KEY=your_openai_api_key_here
</code></pre>
      </li>
      <li class="numberedList">Initialize Haystack with OpenAI embeddings by creating a Python script that initializes Haystack and connects to OpenAI to generate the embeddings:
        <pre class="programlisting code"><code class="hljs-code"># Initialize Haystack with OpenAI for text embeddings
def initialize_haystack():
    # Initialize document store (In-memory for now, but you can configure other stores)
    document_store = InMemoryDocumentStore()
    # Initialize OpenAITextEmbedder to generate text embeddings
    embedder = OpenAITextEmbedder(
        api_key=Secret.from_env_var("OPENAI_API_KEY"),
        model="text-embedding-ada-002"
    )
    return embedder
</code></pre>
      </li>
    </ol>
    <p class="normal">This <a id="_idIndexMarker247"/>configuration initializes Haystack with an in-memory document <a id="_idIndexMarker248"/>store and sets up the retriever using OpenAI embeddings.</p>
    <h2 id="_idParaDest-72" class="heading-2">Generating embeddings for movie plots</h2>
    <p class="normal">Next, we will <a id="_idIndexMarker249"/>generate embeddings for the movie plots stored in the Neo4j graph. The goal is to retrieve the plot descriptions, generate embeddings for them, and link these embeddings back to the respective movie nodes:</p>
    <ol>
      <li class="numberedList" value="1"><strong class="screenText">Query movie plots from Neo4j</strong>: First, you will need to query the movie plots from Neo4j. Use the following Cypher query to retrieve movie titles and plot summaries:
        <pre class="programlisting code"><code class="hljs-code"># Retrieve movie plots and titles from Neo4j
def retrieve_movie_plots():
    # The query retrieves the "title", "overview", and "tmdbId" properties of each Movie node
    query = """
    MATCH (m:Movie)
    WHERE m.embedding IS NULL
    RETURN m.tmdbId AS tmdbId, m.title AS title, m.overview AS overview
    """
    with driver.session() as session:
        results = session.run(query)
        # Each movie's title, plot (overview), and ID are retrieved and stored in the movies list
        movies = [
            {
                "tmdbId": row["tmdbId"],
                "title": row["title"],
                "overview": row["overview"]
            }
            for row in results
        ]
    return movies
</code></pre>
      </li>
    </ol>
    <p class="normal">This will return the <code class="inlineCode">tmdbId</code> value and overview (that is, the plot summary) for each movie in the graph.</p>
    <ol>
      <li class="numberedList" value="2"><strong class="screenText">Generate embeddings using OpenAI and Haystack:</strong> Once the plot summaries are retrieved, generate<a id="_idIndexMarker250"/> embeddings using Haystack’s <code class="inlineCode">OpenAITextEmbedder</code>:
        <pre class="programlisting code"><code class="hljs-code">#Parallel embedding generation with ThreadPoolExecutor
def generate_and_store_embeddings(embedder, movies, max_workers=10): 
    results_to_store = []
    def process_movie(movie):
        title = movie.get("title", "Unknown Title")
        overview = str(movie.get("overview", "")).strip()
        tmdbId = movie.get("tmdbId")
        if not overview:
            print(f"Skipping {title} — No overview available.")
            return None
        try:
            print(f"Generating embedding for: {title}")
            embedding_result = embedder.run(overview)
            embedding = embedding_result.get("embedding")
            if embedding:
                return (tmdbId, embedding)
            else:
                print(f"No embedding generated for: {title}")
        except Exception as e:
            print(f"Error processing {title}: {e}")
        return None
</code></pre>
      </li>
      <li class="numberedList"><strong class="screenText">Store embeddings in Neo4j</strong>: With the embeddings generated, the next step is to store them in your Neo4j graph. Each movie node will be updated with a property that stores its embedding:
        <pre class="programlisting code"><code class="hljs-code"># Store the embeddings back in Neo4j
def store_embedding_in_neo4j(tmdbId, embedding):
    query = """
    MATCH (m:Movie {tmdbId: $tmdbId})
    SET m.embedding = $embedding
    """
    with driver.session() as session:
        session.run(query, tmdbId=tmdbId, embedding=embedding)
    print(f"Stored embedding for TMDB ID: {tmdbId}")
</code></pre>
      </li>
    </ol>
    <p class="normal">This will store the<a id="_idIndexMarker251"/> embeddings as a property called <code class="inlineCode">embedding</code> in each <code class="inlineCode">Movie</code> node in the Neo4j graph.</p>
    <ol>
      <li class="numberedList" value="4"><strong class="screenText">Verify the embedding storage in Neo4j</strong>: Once the embeddings are stored, you can verify their presence in Neo4j by querying a few nodes to check the <code class="inlineCode">embedding</code> property:
        <pre class="programlisting code"><code class="hljs-code"># Verify embeddings stored in Neo4j
def verify_embeddings():
    query = """
    MATCH (m:Movie)
    WHERE exists(m.embedding)
    RETURN m.title, m.embedding
    LIMIT 10
    """
    with driver.session() as session:
        results = session.run(query)
        for record in results:
            title = record["title"]
            embedding = np.array(record["embedding"])[:5]
            print(f" {title}: {embedding}...")
</code></pre>
      </li>
    </ol>
    <p class="normal">This query will <a id="_idIndexMarker252"/>return the titles and embeddings for a few movies, allowing you to verify that the embeddings were successfully stored.</p>
    <div><p class="normal"> <strong class="keyWord">Note</strong></p>
      <p class="normal">These are just the snippets of the code. The full version is available in the GitHub repository: <a href="https://github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/blob/main/ch5/generate_embeddings.py">https://github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/blob/main/ch5/generate_embeddings.py</a>.</p>
    </div>
    <p class="normal">We have now enriched our graph with these embeddings and thus added similarity search, which will allow us to perform more context-aware and intelligent queries. This step is crucial for enhancing the search experience and enabling advanced retrieval operations based on the meaning of text, rather than simple keyword matching.</p>
    <p class="normal">Now that our Neo4j graph has been enriched with vector embeddings, the next step is to connect Haystack to Neo4j for advanced vector search. In the upcoming section, we will focus on how to use these embeddings to perform efficient and accurate vector searches within Neo4j, enabling us to retrieve movies or nodes based on their vector similarity.</p>
    <h1 id="_idParaDest-73" class="heading-1">Connecting Haystack to Neo4j for advanced vector search</h1>
    <p class="normal">With<a id="_idIndexMarker253"/> the movie embeddings now stored in Neo4j, we need to configure a vector index on the <code class="inlineCode">embedding</code> property, which will allow us to efficiently search for movies based on their vector similarity. By creating a vector index in Neo4j, we enable rapid retrieval of nodes that are close in the high-dimensional embedding space, making it possible to perform sophisticated queries, such as finding movies with similar plot summaries.</p>
    <p class="normal">Once the vector index has been created, it will be integrated with Haystack to perform vector-based retrieval from Neo4j. This search will be based on vector similarity mechanisms such as cosine similarity.</p>
    <h2 id="_idParaDest-74" class="heading-2">Creating a vector search index in Neo4j</h2>
    <p class="normal">You will<a id="_idIndexMarker254"/> first want to drop any existing vector index on the embedding <a id="_idIndexMarker255"/>property (if one exists) and then create a new one for performing vector searches. This is how you can do that using Cypher queries in your Python script:</p>
    <pre class="programlisting code"><code class="hljs-code">def create_or_reset_vector_index():
    with driver.session() as session:
        try:
            # Drop the existing vector index if it exists
            session.run("DROP INDEX overview_embeddings IF EXISTS ")
            print("Old index dropped")
        except:
            print("No index to drop")
        # Create a new vector index on the embedding property
        print("Creating new vector index")
        query_index = """
        CREATE VECTOR INDEX overview_embeddings IF NOT EXISTS
        FOR (m:Movie) ON (m.embedding)
        OPTIONS {indexConfig: {
            `vector.dimensions`: 1536,
            `vector.similarity_function`: 'cosine'}}
        """
        session.run(query_index)
        print("Vector index created successfully")
</code></pre>
    <h2 id="_idParaDest-75" class="heading-2">Performing similarity search with Haystack and a Neo4j vector index</h2>
    <p class="normal">After <a id="_idIndexMarker256"/>creating a vector index on the Neo4j graph, you can leverage Haystack to perform similarity search queries based on movie plot embeddings. This approach allows you to compare the similarity between a given movie plot or any text query and existing movie overviews, returning the most relevant results based on their embeddings. In this example, we use the <code class="inlineCode">OpenAITextEmbedder</code> model from the Haystack library to convert the text query into an embedding and then use it to search the Neo4j graph for movies with similar plots.</p>
    <p class="normal">This is how you generate the query embedding and perform the similarity search:</p>
    <pre class="programlisting code"><code class="hljs-code">    text_embedder = OpenAITextEmbedder(
        api_key=Secret.from_env_var("OPENAI_API_KEY"),
        model="text-embedding-ada-002"
    )
    # Step 1: Create embedding for the query
    query_embedding = text_embedder.run(query).get("embedding")
  
    if query_embedding is None:
        print("Query embedding not created successfully.")
        return
  
    print("Query embedding created successfully.")
</code></pre>
    <h2 id="_idParaDest-76" class="heading-2">Running a vector search query with Haystack and Neo4j</h2>
    <p class="normal">Once the<a id="_idIndexMarker257"/> vector index has been created and the embeddings are stored in Neo4j, you can perform a vector-based search by passing a query or a sample movie plot. The system will generate an embedding for the query, compare it with the embeddings stored in Neo4j, and return the most related results.</p>
    <p class="normal">Here is an example of a vector search using Haystack that displays the most similar movie plots without Cypher:</p>
    <pre class="programlisting code"><code class="hljs-code"># Step 2: Search for similar documents using the query embedding
    similar_documents = document_store.query_by_embedding(
        query_embedding, top_k=3
    )
    if not similar_documents:
        print("No similar documents found.")
        return
    print(f"Found {len(similar_documents)} similar documents.")
    print("\n\n")
    # Step 3: Displaying results
    for doc in similar_documents:
        title = doc.meta.get("title", "N/A")
        overview = doc.meta.get("overview", "N/A")
        score = doc.score
        print(
             f"Title: {title}\nOverview: {overview}\n"
             f"Score: {score:.2f}\n{'-'*40}"
        )
    print("\n\n")
</code></pre>
    <p class="normal">Now, we will <a id="_idIndexMarker258"/>integrate Neo4j Cypher queries with Haystack to run a vector search, enabling the retrieval of similar movie plots.</p>
    <h2 id="_idParaDest-77" class="heading-2">Running a vector search query using Cypher and Haystack</h2>
    <p class="normal">To run a<a id="_idIndexMarker259"/> vector search, we will use Cypher’s graph querying capabilities while performing similarity searches using vector embeddings generated by <code class="inlineCode">OpenAITextEmbedder</code>.</p>
    <p class="normal">Unlike directly querying the vector index using Haystack, this approach combines Cypher’s flexibility to return more complex data, such as movie metadata (e.g., cast and genres), along with embeddings, while still maintaining the efficiency of vector similarity search.</p>
    <p class="normal">Here are the steps involved in this process:</p>
    <ol>
      <li class="numberedList" value="1"><strong class="screenText">Embed the query using OpenAITextEmbedder</strong>: Convert the user’s text query (e.g., a movie plot) into a high-dimensional vector embedding.</li>
      <li class="numberedList"><strong class="screenText">Search using Neo4j and Cypher</strong>: Use Cypher to retrieve similar movies by comparing the query embedding with movie plot embeddings stored in Neo4j’s vector index.</li>
      <li class="numberedList"><strong class="screenText">Return enriched data</strong>: Fetch additional movie information, such as the title, overview, cast, genres, and score (similarity), for each result.</li>
    </ol>
    <p class="normal">This is how you implement vector search:</p>
    <ol>
      <li class="numberedList" value="1"><strong class="screenText">Define the Cypher query</strong>: We start by defining a Cypher query that searches the Neo4j <a id="_idIndexMarker260"/>vector index (<code class="inlineCode">overview_embeddings</code>) to retrieve the <code class="inlineCode">top_k</code> most similar movies based on the cosine similarity between the query embedding and movie embeddings:
        <pre class="programlisting code"><code class="hljs-code">cypher_query = """
    CALL db.index.vector.queryNodes("overview_embeddings", $top_k, $query_embedding)
    YIELD node AS movie, score
    MATCH (movie:Movie)
    RETURN movie.title AS title, movie.overview AS overview, score
"""
</code></pre>
      </li>
      <li class="numberedList"><strong class="screenText">Generate the query embedding</strong>: Using <code class="inlineCode">OpenAITextEmbedder</code>, we convert the user’s input query (e.g., a movie plot) into an embedding. This embedding will be passed to the Neo4j vector index for comparison with the stored movie embeddings:
        <pre class="programlisting code"><code class="hljs-code">text_embedder = OpenAITextEmbedder(
    api_key= Secret.from_env_var("OPENAI_API_KEY"),
    model="text-embedding-ada-002"
)
</code></pre>
      </li>
      <li class="numberedList"><strong class="screenText">Run the vector search using the Haystack pipeline</strong>: We set up the Haystack pipeline<a id="_idIndexMarker261"/> to manage the Haystack components:<ul>
          <li class="bulletList"><code class="inlineCode">query_embedder</code> generates embeddings from the user query</li>
          <li class="bulletList"><code class="inlineCode">retriever</code> runs the Cypher query on Neo4j using the query embedding and returns the most similar movies:
            <pre class="programlisting code"><code class="hljs-code">retriever = Neo4jDynamicDocumentRetriever(
    client_config=client_config,
    runtime_parameters=["query_embedding"],
    compose_doc_from_result=True,
    verify_connectivity=True,
)
pipeline = Pipeline()
pipeline.add_component("query_embedder", text_embedder)
pipeline.add_component("retriever", retriever)
pipeline.connect(
    "query_embedder.embedding", "retriever.query_embedding"
)
result = pipeline.run(
    {
        "query_embedder": {"text": query},
        "retriever": {
            "query": cypher_query,
            "parameters": {
                "index": "overview_embeddings", "top_k": 3
            },
        },
    }
)
</code></pre>
          </li>
        </ul>
      </li>
      <li class="numberedList"><strong class="screenText">Display the results</strong>: Once the search is complete, we extract the results from the Neo4j graph and display the movie title, overview, and similarity score:
        <pre class="programlisting code"><code class="hljs-code"># Extracting documents from the retriever results
documents = result["retriever"]["documents"]
for doc in documents:
    # Extract title and overview from document metadata
    title = doc.meta.get("title", "N/A")
    overview = doc.meta.get("overview", "N/A")
    # Extract score from the document
    score = getattr(doc, "score", None)
    score_display = f"{score:.2f}" if score is not None else "N/A"
    # Print the title, overview, and score (or N/A for missing score)
    print(
         f"Title: {title}\nOverview: {overview}\n"
         f"Score: {score_display}\n{'-'*40}\n"
    )
</code></pre>
      </li>
    </ol>
    <p class="normal">Using Cypher <a id="_idIndexMarker262"/>and Haystack offers several benefits, including the following:</p>
    <ul>
      <li class="bulletList"><strong class="screenText">Cypher’s flexibility</strong>: By combining Cypher with Haystack, we can not only query the embeddings but also retrieve additional graph-based information such as cast, genres, and relationships between entities.</li>
      <li class="bulletList"><strong class="screenText">Enriched results</strong>: In addition to retrieving the most similar movies, you can easily extend the query to fetch related metadata (e.g., actors, genres, ratings) or refine the search with additional filtering conditions (e.g., release year, genre).</li>
      <li class="bulletList"><strong class="screenText">Optimized for large graphs</strong>: Neo4j’s vector index allows efficient querying of large datasets with complex relationships, while Haystack’s embedding models provide an accurate<a id="_idIndexMarker263"/> understanding of movie plots.</li>
    </ul>
    <p class="normal">Let’s take a look at an example use case next.</p>
    <h2 id="_idParaDest-78" class="heading-2">Example use case</h2>
    <p class="normal">Consider finding movies with plots such as <em class="italic">A hero must save the world from dest<a id="_idTextAnchor040"/>ruction</em>. By using the pipeline we just created, you can retrieve relevant results:</p>
    <pre class="programlisting code"><code class="hljs-code">Title: The Matrix
Overview: A computer hacker learns from mysterious rebels about the true nature of his reality and his role in the war against its controllers.
Score: 0.98
----------------------------------------
Title: Inception
Overview: A thief who steals corporate secrets through dream-sharing technology is given the inverse task of planting an idea into the mind of a CEO.
Score: 0.96
----------------------------------------
Title: The Dark Knight
Overview: Batman raises the stakes in his war on crime, with the help of Lieutenant Jim Gordon and District Attorney Harvey Dent.
Score: 0.94
----------------------------------------
</code></pre>
    <p class="normal">This pipeline combines the best of both worlds—similarity search through vector embeddings and the rich data capabilities of graph querying with Cypher—allowing powerful, flexible searches over large datasets such as movies.</p>
    <div><p class="normal"> <strong class="keyWord">Note</strong></p>
      <p class="normal">These are just the snippets of the code. The full version is available in the GitHub repository: <a href="https://github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/blob/main/ch5/vector_search.py">https://github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/blob/main/ch5/vector_search.py</a>.</p>
    </div>
    <p class="normal">We have now connected Haystack to Neo4j and enabled advanced vector search functionality. With the vector index in place, Neo4j can now efficiently search for similar movie<a id="_idTextAnchor041"/> nodes based on their embeddings similarity. Haystack’s integration allows you to seamlessly perform these searches using <code class="inlineCode">Neo4jDynamicDocumentRetriever</code>. This retriever performs a search for similar items in your graph by leveraging vector embeddings and Neo4j’s graph capabilities.</p>
    <p class="normal">In the next section, we will explore how to build a search-driven chatbot that leverages the power of Haystack and Neo4j to deliver rich, context-aware responses. Using Gradio, we will create an intuitive chatbot interface that can interact with users and perform advanced searches through natural language queries. This will bring together the strengths of LLMs, vector search, and Neo4j to create a user-friendly, AI-powered search experience.</p>
    <h1 id="_idParaDest-79" class="heading-1">Building a search-driven chatbot with Gradio and Haystack</h1>
    <p class="normal">In this section, we will integrate <a id="_idIndexMarker264"/>Gradio to build an interactive chatbot interface powered by Haystack and Neo4j. Gradio makes it easy to create a web-based interface for interacting with your chatbot. The chatbot will allow users to input queries, which will then trigger a vector-based search of movie embeddings stored in Neo4j. The chatbot will return detailed responses, including the movie titles, overviews, and similarity scores, providing an informative and user-friendly experience.</p>
    <h2 id="_idParaDest-80" class="heading-2">Setting up a Gradio interface</h2>
    <p class="normal">If you have not <a id="_idIndexMarker265"/>installed Gradio yet, do so by running the following:</p>
    <pre class="programlisting code"><code class="hljs-code">pip install gradio
</code></pre>
    <div><p class="normal"><strong class="keyWord">Note</strong></p>
      <p class="normal">The script in this chapter works fine with Gradio v <code class="inlineCode">5.23.1</code>.</p>
    </div>
    <p class="normal">Next, we will set up a basic Gradio interface that triggers our search pipeline and displays the results:</p>
    <pre class="programlisting code"><code class="hljs-code">import gradio as gr
# Define the Gradio chatbot interface
def chatbot(user_input):
    return perform_vector_search_cypher(user_input)
# Create Gradio interface
chat_interface = gr.Interface(
    fn=chatbot,
    inputs=gr.Textbox(
        placeholder="What kind of movie would you like to watch?",
        lines=3,
        label="Your movie preference"
    ),
    outputs=gr.Textbox(
        label="Recommendations",
        lines=12
    ),
    title="AI Movie Recommendation System",
    description="Ask me about movies! I can recommend movies based on your preferences.",
    examples=[
        ["I want to watch a sci-fi movie with time travel"],
        ["Recommend me a romantic comedy with a happy ending"],
        ["I'm in the mood for something with superheroes but not too serious"],
        ["I want a thriller that keeps me on the edge of my seat"],
        ["Show me movies about artificial intelligence taking over the world"]
    ],
    flagging_mode="never"
</code></pre>
    <p class="normal">This <a id="_idIndexMarker266"/>interface allows users to input text queries, and the chatbot will use the <code class="inlineCode">perform_vector_search_cypher()</code> function to search for the most relevant movies.</p>
    <h2 id="_idParaDest-81" class="heading-2">Integrating with Haystack and Neo4j</h2>
    <p class="normal">To power the<a id="_idIndexMarker267"/> chatbot, we will connect it to Haystack’s embedding generation and Neo4j’s vector search capabilities. We will be using <code class="inlineCode">OpenAITextEmbedder</code> to generate the embeddings for both the queries and the movie plots stored in Neo4j. The movie embeddings are stored in a vector index inside Neo4j, which we query for the most similar movies.</p>
    <p class="normal">This is how to integrate our chatbot with the previous Haystack setup:</p>
    <pre class="programlisting code"><code class="hljs-code"># Conversational chatbot handler using Cypher-powered search and Haystack
def perform_vector_search(query):
    print("MESSAGES RECEIVED:", user_input)
    cypher_query = """
        CALL db.index.vector.queryNodes("overview_embeddings", $top_k, $query_embedding)
        YIELD node AS movie, score
        MATCH (movie:Movie)
        RETURN movie.title AS title, movie.overview AS overview, score
    """
    # Embedder
    embedder = OpenAITextEmbedder(
        api_key=Secret.from_env_var("OPENAI_API_KEY"),
        model="text-embedding-ada-002"
    )
    # Retriever
    retriever = Neo4jDynamicDocumentRetriever(
        client_config=client_config,
        runtime_parameters=["query_embedding"],
        compose_doc_from_result=True,
        verify_connectivity=True,
    )
    # Pipeline
    pipeline = Pipeline()
    pipeline.add_component("query_embedder", embedder)
    pipeline.add_component("retriever", retriever)
    pipeline.connect(
        "query_embedder.embedding", "retriever.query_embedding"
    )
</code></pre>
    <h2 id="_idParaDest-82" class="heading-2">Connecting Gradio to the full pipeline</h2>
    <p class="normal">Now, connect<a id="_idIndexMarker268"/> this Gradio chatbot with the Haystack and Neo4j pipeline you have already set up. The Gradio interface will call the <code class="inlineCode">perform_vector_search_cypher()</code> function, which in turn utilizes <code class="inlineCode">Neo4jDynamicDocumentRetriever</code> to search for similar movies based on th<a id="_idTextAnchor042"/>e user’s query.</p>
    <p class="normal">Update <a id="_idIndexMarker269"/>the <code class="inlineCode">main()</code> function to initialize the chatbot:</p>
    <pre class="programlisting code"><code class="hljs-code"># Main function to orchestrate the entire process
def main():
    # Step 1: Create or reset vector index in Neo4j AuraDB
    create_or_reset_vector_index()
    # Step 2: Launch Gradio chatbot interface
    chat_interface.launch()
if __name__ == "__main__":
    main()
</code></pre>
    <h2 id="_idParaDest-83" class="heading-2">Running the chatbot</h2>
    <p class="normal">To run the<a id="_idIndexMarker270"/> chatbot, simply execute your Python script. The Gradio interface will be launched in your browser, allowing you to interact with the chatbot in real time:</p>
    <pre class="programlisting code"><code class="hljs-code">python search_chatbot.py
</code></pre>
    <p class="normal">A Gradio interface will launch in your browser, allowing you to interact with the chatbot in real time. You can enter queries such as this:</p>
    <pre class="programlisting code"><code class="hljs-code">"Tell me about a hero who saves the world."
</code></pre>
    <p class="normal">The chatbot will<a id="_idTextAnchor043"/> return movie plots that are similar to this query based on the vector search.</p>
    <div><p class="normal"><strong class="keyWord">Note</strong></p>
      <p class="normal">These are just the snippets of the code. The full version is available in the GitHub repository: <a href="https://github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/blob/main/ch5/search_chatbot.py">https://github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/blob/main/ch5/search_chatbot.py</a>.</p>
    </div>
    <p class="normal">As we come to the end of this section, we have built a fully functional search-driven chatbot using Gradio, Haystack, and Neo4j. The chatbot leverages the embeddings stored in Neo4j to perform advanced vector-based searches, returning contextually relevant results to the user in the form of retrieving meaningful movie titles and actors from Neo4j in response to user queries.</p>
    <p class="normal">However, this is just the beginning. In the next section, we will dive deeper into fine-tuni<a id="_idTextAnchor044"/>ng your Haystack integration and also explore advanced techniques such as optimizing search performance, adjusting retrieval models, and refining the chatbot’s responses to create an even more seamless and efficient search-driven experience.</p>
    <h1 id="_idParaDest-84" class="heading-1">Fine-tuning your Haystack integration</h1>
    <p class="normal">It is now time to explore how to <a id="_idIndexMarker271"/>fine-tune this integration for improved performance and user experience. While the current setup provides rich, contextually aware responses, there are several advanced techniques, you can implement to optimize the search process, improve retrieval accuracy, and make the chatbot’s interactions more seamless.</p>
    <p class="normal">In this section, we will focus on adjusting key components of Haystack, including experimenting with different embedding models, optimizing Neo4j queries for faster results, and improving how the chatbot displays its responses. These enhancements will help you scale your chatbot to handle more complex queries, improve response times, and deliver even more relevant search results.</p>
    <h2 id="_idParaDest-85" class="heading-2">Experimenting with different embedding models</h2>
    <p class="normal">Currently, we are using <a id="_idIndexMarker272"/>OpenAI’s <code class="inlineCode">text-embedding-ada-002</code> model to generate embeddings. While this model has served as a reliable and performant choice across a wide range of tasks since its release, it’s worth noting that OpenAI has recently introduced new models—such as <code class="inlineCode">text-embedding-3-small</code> and <code class="inlineCode">text-embedding-3-large</code>—that offer significant improvements in both performance and cost-efficiency. For example, <code class="inlineCode">text-embedding-3-small</code> achieves better results in multilingual and English-language tasks, while also being up to five times more cost-effective than <code class="inlineCode">text-embedding-ada-002</code>. Although we have not switched models in this project for consistency, readers who are implementing similar pipelines may consider using <code class="inlineCode">text-embedding-3-small</code> to improve efficiency without compromising performance—especially if embedding generation is a frequent or large-scale operation.</p>
    <p class="normal">However, Haystack <a id="_idIndexMarker273"/>supports various other models, and you can experiment with different ones to see which provides the most accurate or relevant results for your specific use case. For instance, you could switch to a more sophisticated OpenAI model with higher dimensions or try another embedding service supported by Haystack.</p>
    <p class="normal">This is how you can easily switch to a different model:</p>
    <pre class="programlisting code"><code class="hljs-code">embedder = OpenAITextEmbedder(
    api_key=Secret.from_env_var("OPENAI_API_KEY"),
    model="text-embedding-babbage-001"  # Experiment with different models
)
</code></pre>
    <p class="normal">You can also explore other models from OpenAI or even integrate different embedding services to see which performs best for your movie chatbot.</p>
    <h2 id="_idParaDest-86" class="heading-2">Optimizing Neo4j for faster queries</h2>
    <p class="normal">While Neo4j is already efficient at handling graph-based queries, there are several optimizations you can apply, especially for large datasets. You can index additional properties to improve query performance.</p>
    <h3 id="_idParaDest-87" class="heading-3">Indexing additional properties</h3>
    <p class="normal">In addition to the vector index on the<a id="_idIndexMarker274"/> embedding property, you can index other frequently queried properties, such as <code class="inlineCode">title</code> or <code class="inlineCode">tmdbId</code>, to speed up retrieval. This will ensure that whenever you filter or retrieve movies based on these properties, the search is quicker and more efficient:</p>
    <pre class="programlisting code"><code class="hljs-code">def create_additional_indexes():
    with driver.session() as session:
        session.run("CREATE INDEX IF NOT EXISTS movie_title_index FOR (m:Movie) ON (m.title)")
        session.run("CREATE INDEX IF NOT EXISTS movie_tmdbId_index FOR (m:Movie) ON (m.tmdbId)")
        print("Additional indexes created successfully")
</code></pre>
    <p class="normal">By indexing these properties, you can optimize lookups when the search is not solely based on embeddings, such as when filtering by title or retrieving a specific movie.</p>
    <p class="normal">To continuously <a id="_idIndexMarker275"/>improve the chatbot’s search experience, you can log user queries and analyze them over time. Let’s talk about this in detail.</p>
    <h3 id="_idParaDest-88" class="heading-3">Logging and analyzing queries</h3>
    <p class="normal">Logging helps you track the most common search <a id="_idIndexMarker276"/>patterns. Based on logs of user queries and their analysis, you can adjust the indexing strategy, optimize the retriever, or tweak the embedding model for better accuracy.</p>
    <p class="normal">This is how to implement a simple logging mechanism:</p>
    <pre class="programlisting code"><code class="hljs-code">import logging
logging.basicConfig(filename='chatbot_queries.log', level=logging.INFO)
def log_query(query):
    logging.info(f"User query: {q<a id="_idTextAnchor045"/>uery}")
</code></pre>
    <p class="normal">Every time a user inputs a query, it will be logged for future analysis. You can then analyze these logs to make informed adjustments to the system, ensuring that it becomes more responsive and accurate over time.</p>
    <p class="normal">These techniques can help you <a id="_idIndexMarker277"/>significantly enhance the performance, accuracy, and user experience of your search-driven chatbot. Whether it is experimenting with different embedding models, optimizing Neo4j queries, or improving how the results are formatted, each adjustment brings you closer to a seamless and powerful user interaction.</p>
    <p class="normal">These advanced techniques allow your chatbot to scale effectively, handle more complex queries, and return even more relevant and engaging results.</p>
    <h1 id="_idParaDest-89" class="heading-1">Summary</h1>
    <p class="normal">In this chapter, we successfully built a fully functional search-driven chatbot by integrating Gradio, Haystack, and Neo4j. We began by enriching our Neo4j graph with movie embeddings generated by OpenAI’s models, enabling advanced vector-based search functionality. From there, we connected Haystack to Neo4j, allowing us to perform similarity searches on the embeddings stored in the graph. Finally, we wrapped it all up by creating a user-friendly chatbot interface with Gradio, which dynamically retrieves movie details such as titles and actors based on user queries.</p>
    <p class="normal">In the next chapter we will focus on advanced search capabilities and search optimization with Haystack. We will also discuss query optimization for large graphs.</p>
  </div>
</div></div></body></html>