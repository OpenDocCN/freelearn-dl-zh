- en: Chapter 5. Forecasting Weather
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This chapter presents one well-known application in daily life to which neural
    networks can perfectly be applied: forecasting weather. We are going to walk through
    the entire process of designing a neural network solution to this problem: how
    to choose the neural architecture and the number of neurons, as well as selecting
    and preprocessing data. Then the reader will be presented with techniques to handle
    time series datasets, from which our neural network is going to make predictions
    on weather variables using the Java programming language. The topics covered in
    this chapter are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Neural networks for regression problems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Loading/selecting data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Input/output variables
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Choosing inputs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Preprocessing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Normalization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Empirical design of neural networks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Neural networks for regression problems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, the reader has been presented with a number of neural network implementations
    and architectures, so now it is time to get into more complex cases. The power
    of neural networks in predictions is really astonishing since they can perform
    *learning* from historical data in such a way that neural connections are adapted
    to produce the same results according to some input data. For example, for a given
    situation (cause), there is a consequence (result) and this is represented as
    data; neural networks are capable of learning the nonlinear function that maps
    the situation to the consequence (or the cause to the result).
  prefs: []
  type: TYPE_NORMAL
- en: 'Prediction and regression problems are an interesting category to apply neural
    networks to. Let''s take a look at a sample table containing weather data:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Date | Avg. Temperature | Pressure | Humidity | Precipitation | Wind Speed
    |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| July 31st | 23 ºC | 880 mbar | 66% | 16 mm | 5 m/s |'
  prefs: []
  type: TYPE_TB
- en: '| August 1st | 22 ºC | 881 mbar | 78% | 3 mm | 3 m/s |'
  prefs: []
  type: TYPE_TB
- en: '| August 2nd | 25 ºC | 884 mbar | 65% | 0 mm | 4 m/s |'
  prefs: []
  type: TYPE_TB
- en: '| August 3rd | 27 ºC | 882 mbar | 53% | 0 mm | 3 m/s |'
  prefs: []
  type: TYPE_TB
- en: '| … |   |   |   |   |   |'
  prefs: []
  type: TYPE_TB
- en: '| December 11th | 32 ºC | 890 mbar | 64% | 0 mm | 2 m/s |'
  prefs: []
  type: TYPE_TB
- en: 'The table above depicts five variables containing hypothetical values of weather
    data collected from a hypothetical city, only for the purpose of this example.
    Now let''s suppose that each of the variables contains a list of values sequentially
    taken over time. We can think of each list as a time series. On a time series
    chart, one can see how they evolve with time:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Neural networks for regression problems](img/B05964_05_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The relationship between these time series denotes a dynamic representation
    of weather in a certain city, as depicted in the chart above. We want the neural
    network to learn this dynamic representation; however, we need to structure this
    data the in a way neural networks can process, that is, identifying which data
    series (variables) are the cause and which are the effect. Dynamic systems have
    variables whose value depends on past values, so neural network applications can
    rely not only on the present situation, but also on the past. This is very important
    because historical events influence the present and future.
  prefs: []
  type: TYPE_NORMAL
- en: Only after structuring data can we structure the neural network, that is, the
    number of inputs, outputs, and hidden nodes. However, there are many other architectures
    that may be suitable for prediction problems, such as radial basis functions and
    feedback networks, among others. In this chapter, we are dealing with a feedforward
    multilayer perceptron with the Backpropagation learning algorithm, to demonstrate
    how this architecture can be simply exploited to predict weather variables; also,
    this architecture presents very good generalized results with good selected data
    and there is little complexity involved in the design process.
  prefs: []
  type: TYPE_NORMAL
- en: 'The overall process for designing neural networks for prediction processes
    is depicted in the figure below:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Neural networks for regression problems](img/B05964_05_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: If the neural network fails to be validated (**step 5**), usually a new structure
    (**step 3**) is defined, although sometimes **steps 1** and **step 2** may be
    repeated. Each of the steps in the figure will be addressed in the next sections
    in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Loading/selecting data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: First we need to load raw data into our Java environment. Data can be stored
    in a variety of data sources, from text files to structured database systems.
    One basic and simple type used is **CSV** (**Comma-Separated Values**), which
    is simple and in general use. In addition, we'll need to transform this data and
    perform selection before presenting it to the neural network.
  prefs: []
  type: TYPE_NORMAL
- en: Building auxiliary classes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To deal with these tasks, we need some auxiliary classes in the package `edu.packt.neuralnet.data`.
    The first will be `LoadCsv` to read CSV files:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To save space here, we are not showing the full code. For more details and the
    full list of methods, please refer to the code and documentation in *Appendix
    C*.
  prefs: []
  type: TYPE_NORMAL
- en: 'We are also creating a class to store the raw data loaded from CSV into a structure
    containing not only the data but the information on this data, such as column
    names. This class will be called **DataSet**, inside the same package:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: In [Chapter 4](ch04.xhtml "Chapter 4. Self-Organizing Maps"), *Self-Organizing
    Maps*, we've created a class `ArrayOperations` in the package `edu.packt.neuralnet.math`
    to handle operations involving arrays of data. This class has a large number of
    static methods and it would be impractical to depict all of them here; however,
    information can be found in *Appendix C*.
  prefs: []
  type: TYPE_NORMAL
- en: Getting a dataset from a CSV file
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To make the task easier, we''ve implemented a static method in the class `LoadCsv`
    to load a CSV file and automatically convert it into the structure of a `DataSet`
    object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Building time series
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A time series structure is essential for all problems involving time dimensions
    or domains, such as forecasting and prediction. A class called `TimeSeries` implements
    some time-related attributes such as time column and delay. Let''s take a look
    at the structure of this class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'In time series, one frequent operation is the delay of shift of values. For
    example, we want to include in the processing not the current but the two past
    values for the daily temperature. Considering temperature as a time series with
    a time column (date), we must shift the values in the number of cycles desired
    (one and two, in this example):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Building time series](img/B05964_05_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We have used **Microsoft Excel®** to convert the `datetime` values into real
    values. Working with numerical values is always preferred to working with structures
    such as dates or categories. So in this chapter, we are using numerical values
    to represent date.
  prefs: []
  type: TYPE_NORMAL
- en: 'While working with time series, one should pay attention to two points:'
  prefs: []
  type: TYPE_NORMAL
- en: There may be missing values or no measurements on a specific point of time;
    this can generate NaNs in the Java matrix.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shifting a column over one time period, for example, is not the same as getting
    the value of the previous row. That's why it is important to choose one column
    to be the time reference.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In the `ArrayOperations` class, we implemented a method `shiftColumn` to shift
    the column of a matrix considering a time column for reference. This method is
    called from another method of the same name in the `TimeSeries` class, and then
    used in the shift method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Dropping NaNs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'NaNs are undesired values often present after loading or transforming data.
    They are undesired because we cannot operate over them. If we feed a NaN value
    into a neural network, the output will definitely be NaN, just consuming more
    computational power. That''s why it is better to drop them out. In the class `DataSet`,
    we''ve implemented two methods to drop NaNs: one just substitutes a value for
    them, and the other drops the entire row if it has at least one missing value,
    as shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Dropping NaNs](img/B05964_05_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Getting weather data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that we have the tools to get the data, let''s find some datasets on the
    Internet. In this chapter, we are going to use the data from the Brazilian Institute
    of Meteorology (INMET: [http://www.inmet.gov.br/](http://www.inmet.gov.br/) in
    Portuguese), which is freely available on the Internet; we have the rights to
    use it in this book. However, the reader may use any free weather database on
    the Internet while developing applications.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Some examples from English language sources are listed below:'
  prefs: []
  type: TYPE_NORMAL
- en: Wunderground ([http://wunderground.com/](http://wunderground.com/))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Open Weather Map ([http://openweathermap.org/api](http://openweathermap.org/api))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yahoo weather API ([https://developer.yahoo.com/weather/](https://developer.yahoo.com/weather/))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: US National Climatic Data Center ([http://www.ncdc.noaa.gov/](http://www.ncdc.noaa.gov/))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Weather variables
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Any weather database will have almost the same variables:'
  prefs: []
  type: TYPE_NORMAL
- en: Temperature (ºC)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Humidity (%)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pressure (mbar)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wind speed (m/s)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wind direction (º )
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Precipitation (mm)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sunny hours (h)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sun energy (W/m2)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This data is usually collected from meteorological stations, satellites, or
    radar, on an hourly or daily basis.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Depending on the collection frequency, some variables may be summarized with
    average, minimum, or maximum values.
  prefs: []
  type: TYPE_NORMAL
- en: Data units may also vary from source to source; that's why units should always
    be observed.
  prefs: []
  type: TYPE_NORMAL
- en: Choosing input and output variables
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Selecting the appropriate data that fulfils most of the system's dynamics needs
    to be carefully done. We want the neural network to forecast future weather based
    on the current and past weather data, but which variables should we choose? Getting
    an expert opinion on the subject can be really helpful in understanding the relationship
    between variables.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Regarding time series variables, one can derive new variables by applying historical
    data. That means, given a certain date, one may consider this date's values and
    the data collected (and/or summarized) from past dates, therefore extending the
    number of variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'While defining a problem to use neural networks on, there are one or more predefined
    target variables: predict the temperature, forecast precipitation. measure insolation,
    and so on. But, in some cases, one wants to model all the variables and therefore
    to find causal relationships between them. Causal relationships can be identified
    by statistical tools, of which Pearson cross-correlation is the most used:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Choosing input and output variables](img/B05964_05_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, *E[X.Y]* is the mean of the multiplication of variables *X* and *Y*;
    *E[X]* and *E[Y]* are the means of *X* and *Y* respectively; *σX* and *σY* are
    the standard deviation of *X* and *Y* respectively; and finally *Cx,y* is the
    Pearson coefficient of *X* related to *Y*, whose values lie between *-1* and *1*.
    This coefficient shows how much a variable *X* is correlated with a variable *Y*.
    Values near *0* denote weak or no correlation at all, while values close to *-1*
    or *1* denote negative or positive correlation, respectively. Graphically, it
    can be seen by a scatter plot, as shown below:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Choosing input and output variables](img/B05964_05_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In the chart on the left, the correlation between the precipitation of the last
    day (indicated as [-1]) and the maximum temperature is -0.202, which is a weak
    value of negative correlation. In the middle chart, the correlation between insolation
    and maximum temperature is 0.376, which is a fair correlation, yet not very significant;
    one can see a slight positive trend. An example of strong positive correlation
    is shown in the chart on the right, which is between the last day's maximum temperature
    and the maximum temperature of the day. This correlation is 0.793, and we can
    see a thinner cloud of dots indicating the trend.
  prefs: []
  type: TYPE_NORMAL
- en: 'We are going to use correlation to choose the most appropriate inputs for our
    neural network. First, we need to code a method in the class DataSet, called correlation.
    Please note that operations such as mean and standard deviation are implemented
    in our class `ArrayOperations`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: We will not delve too deeply into statistics in this book, so we recommend a
    number of references if the reader is interested in more details on this topic.
  prefs: []
  type: TYPE_NORMAL
- en: Preprocessing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Raw data collected from a data source usually presents different particularities,
    such as data range, sampling, and category. Some variables result from measurements
    while others are summarized or even calculated. Preprocessing means to adapt these
    variable values to a range that neural networks can handle properly.
  prefs: []
  type: TYPE_NORMAL
- en: 'Regarding weather variables, let''s take a look at their range, sampling, and
    type:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Variable | Unit | Range | Sampling | Type |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Mean temperature | º C | 10.86 – 29.25 | Hourly | Average of hourly measurements
    |'
  prefs: []
  type: TYPE_TB
- en: '| Precipitation | mm | 0 – 161.20 | Daily | Accumulation of daily rain |'
  prefs: []
  type: TYPE_TB
- en: '| Insolation | hours | 0 – 10.40 | Daily | Count of hours receiving sun radiation
    |'
  prefs: []
  type: TYPE_TB
- en: '| Mean humidity | % | 45.00 – 96.00 | Hourly | Average of hourly measurements
    |'
  prefs: []
  type: TYPE_TB
- en: '| Mean wind speed | km/h | 0.00 – 3.27 | Hourly | Average of hourly measurements
    |'
  prefs: []
  type: TYPE_TB
- en: Except for insolation and precipitation, the variables are all measured and
    share the same sampling, but if we wanted, for example, to use an hourly dataset,
    we would have to preprocess all the variables to use the same sample rate. Three
    of the variables are summarized, using daily average values, but if we wanted
    to we could use hourly data measurements. However, the range would certainly be
    larger.
  prefs: []
  type: TYPE_NORMAL
- en: Normalization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Normalization is the process of getting all variables into the same data range,
    usually with smaller values, between `0` and `1` or `-1` and `1`. This helps the
    neural network to present values within the variable zone in activation functions
    such as sigmoid or hyperbolic tangent:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Normalization](img/B05964_05_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Values too high or too low may drive neurons in to producing values too high
    or too low as well for the activation functions, therefore leading to the derivative
    for these neurons being too small, near zero. In this book, we implemented two
    modes of normalization: min-max and z-score.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The min-max normalization should consider a predefined range of the dataset.
    It is performed right away:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Normalization](img/B05964_05_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, Nmin and Nmax are the normalized minimum and maximum limits respectively,
    Xmin and Xmax are the variable X''s minimum and maximum limits respectively, *X*
    is the original value, and Xnorm is the normalized value. If we want the normalization
    to be between 0 and 1, for example, the equation is simplified to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Normalization](img/B05964_05_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'By applying the normalization, a new *normalized* dataset is produced and is
    fed to the neural network. One should also take into account that a neural network
    fed with normalized values will be trained to produce normalized values on the
    output, so the inverse (denormalization) process becomes necessary as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Normalization](img/B05964_05_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Or
  prefs: []
  type: TYPE_NORMAL
- en: '![Normalization](img/B05964_05_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: For the normalization between 0 and 1.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another mode of normalization is the z-score, which takes into account the
    mean and standard deviation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Normalization](img/B05964_05_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Here, S is a scaling constant, *E[X]* is the mean of E, and *σX* is the standard
    deviation of X. The main difference in this normalization mode is that there will
    be no limit defined for the range of variables; however, the variables will have
    values on the same range centered on zero with standard deviation equal to the
    scaling constant S.
  prefs: []
  type: TYPE_NORMAL
- en: 'The figure below shows what both normalization modes do with the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Normalization](img/B05964_05_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'A class called `DataNormalization` is implemented to handle the normalization
    of data. Since normalization considers the statistical properties of the data,
    we need to store this statistical information in a `DataNormalization` object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The normalization procedure is performed on a method called `normalize`, which
    has a denormalization counterpart called **denormalize**:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Adapting NeuralDataSet to handle normalization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The already implemented `NeuralDataSet`, `NeuralInputData`, and `NeuralOutputData`
    will now have `DataNormalization` objects to handle normalization operations.
    In the `NeuralDataSet` class, we''ve added objects for input and output data normalization:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '`NeuralInputData` and `NeuralOutputData` will now have `normdata` properties
    to store the normalized data. The methods to retrieve data from these classes
    will have a Boolean parameter, `isNorm`, to indicate whether the value to be retrieved
    should be normalized or not.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Considering that `NeuralInputData` will provide the neural network with input
    data, this class will only perform normalization before feeding data into the
    neural network. The method `setNormalization` is implemented in this class to
    that end:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'In `NeuralOutputData`, there are two datasets, one for the target and one for
    the neural network output. The target dataset is normalized to provide the training
    algorithm with normalized values. However, the neural output dataset is the output
    of the neural network, that is, it will be normalized first. We need to perform
    denormalization after setting the neural network output dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Adapting the learning algorithm to normalization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Finally, the `LearningAlgorithm` class needs to include the normalization property:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Now during the training, on every call to the `NeuralDataSet` methods that
    retrieve or write data, the normalization property should be passed in the parameter
    `isNorm`, as in the method forward of the class Backpropagation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Java implementation of weather forecasting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In Java, we are going to use the package `edu.packt.neuralnet.chart` to plot
    some charts and visualize data. We're also downloading historical meteorology
    data from INMET, the Brazilian Institute of Meteorology. We've downloaded data
    from several cities, so we could have a variety of climates included in our weather
    forecasting case.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In order to run the training expeditiously, we have selected a small period
    (5 years), which has more than 2,000 samples.
  prefs: []
  type: TYPE_NORMAL
- en: Collecting weather data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this example, we wanted to collect a variety of data from different places,
    to attest to the capacity of the neural network to forecast it. Since we downloaded
    it from the INMET website, which covers only Brazilian territory, only Brazilian
    cities are covered. However, it is a very vast territory with a great variety
    of climates. Below is a list of places we collected data from:'
  prefs: []
  type: TYPE_NORMAL
- en: '| # | City Name | Latitude | Longitude | Altitude | Climate Type |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | Cruzeiro do Sul | 7º37''S | 72º40''W | 170 m | Tropical Rainforest |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | Picos | 7º04''S | 41º28''W | 208 m | Semi-arid |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | Campos do Jordão | 22º45''S | 45º36''W | 1642 m | Subtropical Highland
    |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | Porto Alegre | 30º01''S | 51º13''W | 48 m | Subtropical Humid |'
  prefs: []
  type: TYPE_TB
- en: 'The location of these four cities is indicated on the map below:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Collecting weather data](img/B05964_05_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Source: Wikipedia, user NordNordWest using United States National Imagery and
    Mapping Agency data, World Data Base II data'
  prefs: []
  type: TYPE_NORMAL
- en: The weather data collected is from January 2010 until November 2016 and is saved
    in the data folder with the name corresponding to the city.
  prefs: []
  type: TYPE_NORMAL
- en: 'The data collected from the INMET website includes these variables:'
  prefs: []
  type: TYPE_NORMAL
- en: Precipitation (mm)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Max. temperature (ºC)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Min. temperature (ºC)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Insolation (sunny hours)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaporation (mm)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Avg. temperature (ºC)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Avg. humidity (%)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Avg. wind speed (mph)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Date (converted into Excel number format)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Position of the station (latitude, longitude, and altitude)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For each city, we are going to build a neural network to forecast the weather
    based on the past. But first, we need to point out two important facts:'
  prefs: []
  type: TYPE_NORMAL
- en: Cities located in high latitudes experience high weather variations due to the
    seasons; that is, the weather will be dependent on the date
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The weather is a very dynamic system whose variables are influenced by past
    values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To overcome the first issue, we may derive a new column from the date to indicate
    the solar noon angle, which is the angle at which the solar rays reach the surface
    at the city at the highest point in the sky (noon). The greater this angle, the
    more intense and warm the solar radiation is; on the other hand, when this angle
    is small, the surface will receive a small fraction of the solar radiation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Collecting weather data](img/B05964_05_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The solar noon angle is calculated by the following formula and Java implementation
    in the class `WeatherExample`, which will be used in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Collecting weather data](img/B05964_05_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Delaying variables
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the class `WeatherExample`, let''s place a method called `makeDelays`, which
    will later be called from the main method. The delays will be made on a given
    `TimeSeries` and up to a given number for all columns of the time series except
    that of the index column:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Be careful not to call this method multiple times; it may delay the same column
    over and over again.
  prefs: []
  type: TYPE_NORMAL
- en: Loading the data and beginning to play!
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the `WeatherExample` class, we are going to add four `TimeSeries` properties
    and four `NeuralNet` properties for each case:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'In the `main` method, we load data to each of them and delay the columns up
    to three days before:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This piece of code can take a couple of minutes to execute, given that each
    file may have more than 2,000 rows.
  prefs: []
  type: TYPE_NORMAL
- en: 'After loading, we need to remove the NaNs, so we call the method `dropNaN`
    from each time series object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'To save time and effort for future executions, let''s save these datasets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Now, for all-time series, each column has three delays, and we want the neural
    network to forecast the maximum and minimum temperature of the next day. We can
    forecast the future by taking into account only the present and the past, so for
    inputs we must rely on the delayed data (from -1 to -3 days before), and for outputs
    we may consider the current temperature values. Each column in the time series
    dataset is indicated by an index, where zero is the index of the date. Since some
    of the datasets had missing data on certain columns, the index of a column may
    vary. However, the index for output variables is the same through all datasets
    (indexes 2 and 3).
  prefs: []
  type: TYPE_NORMAL
- en: Let's perform a correlation analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We are interested in finding patterns between the delayed data and the current
    maximum and minimum temperature. So we perform a cross-correlation analysis combining
    all output and potential input variables, and select the variables that present
    at least a minimum absolute correlation as a threshold. So we write a method `correlationAnalysis`
    taking the minimum absolute correlation as the argument. To save space, we have
    trimmed the code here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'By running this analysis, we receive the following result for Cruzeiro do Sul
    (the bold columns are chosen as neural network inputs):'
  prefs: []
  type: TYPE_NORMAL
- en: '| Correlation Analysis for data from Cruzeiro do Sul |   |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Correlations with the output Variable: MaxTempNoonAngle:0.0312808Precipitation__1:-0.115547Precipitation__2:-0.038969Precipitation__3:-0.062173MaxTemp__1:0.497057MaxTemp__2:0.252831MaxTemp__3:0.159098MinTemp__1:-0.033339MinTemp__2:-0.123063MinTemp__3:-0.125282Insolation__1:0.395741Insolation__2:0.197949Insolation__3:0.134345Evaporation__1:0.21548Evaporation__2:0.161384Evaporation__3:0.199385AvgTemp__1:0.432280AvgTemp__2:0.152103AvgTemp__3:0.060368AvgHumidity__1:-0.415812AvgHumidity__2:-0.265189AvgHumidity__3:-0.214624WindSpeed__1:-0.166418WindSpeed__2:-0.056825WindSpeed__3:-0.001660NoonAngle__1:0.0284473NoonAngle__2:0.0256710NoonAngle__3:0.0227864
    | Correlations with the output Variable: MinTempNoonAngle:0.346545Precipitation__1:0.012696Precipitation__2:0.063303Precipitation__3:0.112842MaxTemp__1:0.311005MaxTemp__2:0.244364MaxTemp__3:0.123838MinTemp__1:0.757647MinTemp__2:0.567563MinTemp__3:0.429669Insolation__1:-0.10192Insolation__2:-0.101146Insolation__3:-0.151896Evaporation__1:-0.115236Evaporation__2:-0.160718Evaporation__3:-0.160536AvgTemp__1:0.633741AvgTemp__2:0.487609AvgTemp__3:0.312645AvgHumidity__1:0.151009AvgHumidity__2:0.155019AvgHumidity__3:0.177833WindSpeed__1:-0.198555WindSpeed__2:-0.227227WindSpeed__3:-0.185377NoonAngle__1:0.353834NoonAngle__2:0.360943NoonAngle__3:0.367953
    |'
  prefs: []
  type: TYPE_TB
- en: 'The scatter plots show how this data is related:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Let''s perform a correlation analysis](img/B05964_05_17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'On the left, there is a fair correlation between the last day''s maximum temperature
    and the current; in the center, a strong correlation between the last day''s minimum
    temperature and the current; and on the right, a weak correlation between `NoonAngle`
    of 3 days before and the current minimum temperature. By running this analysis
    for all other cities, we determine the inputs for the other neural networks:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Cruzeiro do Sul | Picos | Campos do Jordão | Porto Alegre |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| NoonAngleMaxTemp__1MinTemp__1MinTemp__2MinTemp__3Insolation__1AvgTemp__1AvgTemp__2AvgHumidity__1NoonAngle__1NoonAngle__2NoonAngle__3
    | MaxTempMaxTemp__1MaxTemp__2MaxTemp__3MinTemp__1MinTemp__2MinTemp__3Insolation__1Insolation__2Evaporation__1Evaporation__2Evaporation__3AvgTemp__1AvgTemp__2AvgTemp__3AvgHumidity__1AvgHumidity__2AvgHumidity__3
    | NoonAngleMaxTemp__1MaxTemp__2MaxTemp__3MinTemp__1MinTemp__2MinTemp__3Evaporation__1AvgTemp__1AvgTemp__2AvgTemp__3AvgHumidity__1NoonAngle__1NoonAngle__2NoonAngle__3
    | MaxTempNoonAngleMaxTemp__1MaxTemp__2MaxTemp__3MinTemp__1MinTemp__2MinTemp__3Insolation__1Insolation__2Insolation__3Evaporation__1Evaporation__2Evaporation__3AvgTemp__1AvgTemp__2AvgTemp__3AvgHumidity__1AvgHumidity__2NoonAngle__1NoonAngle__2NoonAngle__3
    |'
  prefs: []
  type: TYPE_TB
- en: Creating neural networks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We are using four neural networks to forecast the minimum and maximum temperature.
    Initially, they will have two hidden layers with 20 and 10 neurons each and hypertan
    and sigmoid activation functions. We will apply min-max normalization. The following
    method in the class `WeatherExample` creates the neural networks with this configuration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Training and test
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In [Chapter 2](ch02.xhtml "Chapter 2. Getting Neural Networks to Learn"), *Getting
    Neural Networks to Learn* we have seen that a neural network should be tested
    to verify its learning, so we divide the dataset into training and testing subsets.
    Usually about 50-80% of the original filtered dataset is used for training and
    the remaining fraction is for testing.
  prefs: []
  type: TYPE_NORMAL
- en: 'A static method `randomSeparateTrainTest` in the class `NeuralDataSet` separates
    the dataset into these two subsets. In order to ensure maximum generalization,
    the records of this dataset are hashed, as shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Training and test](img/B05964_05_18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The records may be originally sequential, as in weather time series; if we hash
    them in random positions, the training and testing sets will contain records from
    all periods.
  prefs: []
  type: TYPE_NORMAL
- en: Training the neural network
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The neural network will be trained using the basic backpropagation algorithm.
    The following is a code sample for the dataset `Cruzeiro do Sul`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Plotting the error
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Using the `JFreeCharts` framework, we can plot error evolution for the training
    and testing datasets. There is a new method in the class `LearningAlogrithm` called
    `showErrorEvolution`, which is inherited and overridden by `BackPropagation`.
    To see the chart, just call as in the example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'This will show a plot like the one shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Plotting the error](img/B05964_05_19.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Viewing the neural network output
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Using this same facility, it is easy to see and compare the neural network
    output. First, let''s transform the neural network output into vector form and
    add to our dataset using the method `addColumn`. Let''s name it `NeuralMinTemp`
    and `NeuralMaxTemp`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'The class `TimeSeries` has a method called `getTimePlot`, which is used to
    plot variables over a specified range:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '![Viewing the neural network output](img/B05964_05_20.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Empirical design of neural networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While using neural networks in regression problems (that include prediction),
    there is no fixed number of hidden neurons, so usually the solver chooses an arbitrary
    number of neurons and then varies it according to the results produced by the
    networks created. This procedure may be repeated a number of times until a network
    with a satisfying criterion is found.
  prefs: []
  type: TYPE_NORMAL
- en: Designing experiments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Experiments can be made on the same training and test datasets, while varying
    other network parameters, such as learning rate, normalization, and the number
    of hidden units. The objective is to choose the neural network that presents the
    best performance from the experiments. The best performance is assigned to the
    network that presents a lower MSE error, but an analysis of generalization with
    test data is also useful.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: While designing experiments, consider always starting from a lower number of
    hidden neurons, since it is desirable to have a lower computational processing
    consumption.
  prefs: []
  type: TYPE_NORMAL
- en: 'The table below shows the experiments have that been run for all cities:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Designing experiments](img/B05964_05_21.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Results and simulations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In order to facilitate the execution of experiments, we've designed a Java Swing
    **Graphical User Interface** (**GUI**), with which it is possible to select neural
    network parameters for training and the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This interface covers only neural networks with just one hidden layer; however,
    since the code is open, the implementation of a multilayer perceptron with multiple
    hidden layers is suggested as an exercise, as well as the choice of other algorithms
    for the training.
  prefs: []
  type: TYPE_NORMAL
- en: The charts show only the predicted maximum temperature; therefore, implementing
    an option for displaying the minimum temperature is also suggested.
  prefs: []
  type: TYPE_NORMAL
- en: 'After selecting the parameters, training begins when you click the **Start
    Training** button:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Results and simulations](img/B05964_05_22.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'After running 12 experiments, we found the following MSE training errors for
    each dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Experiment | Cruzeiro do Sul | Picos | Campos do Jordão | Porto Alegre |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| #1 | 0.130156 | 0.147111 | 0.300437 | 0.323342 |'
  prefs: []
  type: TYPE_TB
- en: '| #2 | 0.512389 | 0.572588 | 0.428692 | 0.478379 |'
  prefs: []
  type: TYPE_TB
- en: '| #3 | 0.08659 | 0.094822 | 0.124752 | 0.114486 |'
  prefs: []
  type: TYPE_TB
- en: '| #4 | 0.360728 | 0.258596 | 0.168351 | 0.192012 |'
  prefs: []
  type: TYPE_TB
- en: '| #5 | 0.076476 | 0.074777 | 0.108991 | 0.085029 |'
  prefs: []
  type: TYPE_TB
- en: '| #6 | 0.328493 | 0.186793 | 0.152499 | 0.151248 |'
  prefs: []
  type: TYPE_TB
- en: '| #7 | 0.146801 | 0.130004 | 0.277765 | 0.19076 |'
  prefs: []
  type: TYPE_TB
- en: '| #8 | 0.431811 | 0.29629 | 0.364418 | 0.278864 |'
  prefs: []
  type: TYPE_TB
- en: '| #9 | 0.071135 | 0.081159 | 0.117634 | 0.091174 |'
  prefs: []
  type: TYPE_TB
- en: '| #10 | 0.332534 | 0.210107 | 0.170179 | 0.164179 |'
  prefs: []
  type: TYPE_TB
- en: '| #11 | 0.07247 | 0.089069 | 0.102137 | 0.076578 |'
  prefs: []
  type: TYPE_TB
- en: '| #12 | 0.33342 | 0.19835 | 0.155036 | 0.145843 |'
  prefs: []
  type: TYPE_TB
- en: 'The MSE error information only gives us an idea of how much the neural network
    output could match real data in the overall context. This performance can be verified
    by viewing the time series comparison and scatter plots:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Results and simulations](img/B05964_05_24.jpg)'
  prefs: []
  type: TYPE_IMG
- en: These charts show that, although in many cases the temperature cannot be accurately
    predicted, a trend is being followed. This can be attested to by the correlation
    visible in the scatter plots. The last row of the table, showing the prediction
    for Porto Alegre, which has a subtropical climate and high temperature variations,
    shows a good prediction even for the extreme temperature variations. However,
    we remind the reader that forecasting weather needs to consider many additional
    variables, which could not be included in this example due to availability constraints.
    Anyway, the results show we've made a good start to search for a neural network
    configuration that can outperform these ones found.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we've seen an interesting practical use case for the application
    of neural networks. Weather forecasting has always been a rich research field,
    and indeed neural networks are widely used for this purpose. In this chapter,
    the reader also learned how to prepare similar experiments for prediction problems.
    The correct application of techniques for data selection and preprocessing can
    save a lot of time while designing neural networks for prediction. This chapter
    also served as a foundation for the next ones, since all of them will focus on
    practical cases; thus, the concepts learned herein will be explored widely in
    the rest of the book.
  prefs: []
  type: TYPE_NORMAL
