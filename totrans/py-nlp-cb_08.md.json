["```py\n    from datasets import load_dataset, get_dataset_split_names\n    ```", "```py\n    dataset = load_dataset(\"rotten_tomatoes\")\n    print(get_dataset_split_names(\"rotten_tomatoes\"))\n    ```", "```py\n    ['train', 'validation', 'test']\n    ```", "```py\n    training_data = dataset['train']\n    print(training_data.description)\n    print(training_data.features)\n    ```", "```py\n    Movie Review Dataset.\n    This is a dataset of containing 5,331 positive and 5,331 negative processed  sentences from Rotten Tomatoes movie reviews. This data was first used in Bo Pang and Lillian Lee, ``Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales.'', Proceedings of the ACL, 2005.\n    {'text': Value(dtype='string', id=None), \n        'label':ClassLabel(names=['neg', 'pos'], id=None)}\n    ```", "```py\n    sentences = training_data['text'][:5]\n    [print(sentence) for sentence in sentences]\n    ```", "```py\n    the rock is destined to be the 21st century's new \" conan \" and that he's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .\n    the gorgeously elaborate continuation of \" the lord of the rings \" trilogy is so huge that a column of words cannot adequately describe co-writer/director peter jackson's expanded vision of j . r . r . tolkien's middle-earth .\n    effective but too-tepid biopic\n    if you sometimes like to go to the movies to have fun , wasabi is a good place to start .\n    emerges as something rare , an issue movie that's so honest and keenly observed that it doesn't feel like one .\n    ```", "```py\n    from transformers import AutoTokenizer\n    ```", "```py\n    sentences = [\n        \"The first sentence, which is the longest one in the list.\",\n        \"The second sentence is not that long.\",\n        \"A very short sentence.\"]\n    ```", "```py\n    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n    ```", "```py\n        tokenized_input = tokenizer(sentences)\n        print(tokenized_input)\n        {'input_ids': [[101, 1109, 1148, 5650, 117, 1134, 1110, 1103, 6119, 1141, 1107, 1103, 2190, 119, 102],\n        [101, 1109, 1248, 5650, 1110, 1136, 1115, 1263, 119, 102],[101, 138, 1304, 1603, 5650, 119, 102]],\n        'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0]],\n        'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1]]}\n        ```", "```py\n    tokens = tokenizer.convert_ids_to_tokens(\n        tokenized_input[\"input_ids\"][0])\n    print(tokens)\n    ['[CLS]', 'The', 'first', 'sentence', ',', 'which', 'is', 'the', 'longest', 'one', 'in', 'the', 'list', '.', '[SEP]']\n    [101, 1109, 1148, 5650, 117, 1134, 1110, 1103, 6119, 1141, 1107, 1103, 2190, 119, 102]\n    ```", "```py\n    ['[CLS]', 'The', 'first', 'sentence', ',', 'which', 'is', 'the', 'longest', 'one', 'in', 'the', 'list', '.', '[SEP]']\n    ```", "```py\n    from datasets import load_dataset\n    from evaluate import evaluator, combine\n    from transformers import pipeline\n    import torch\n    ```", "```py\n    device = torch.device(\n        \"cuda\" if torch.cuda.is_available() else \"cpu\")\n    sentences = load_dataset(\n        \"rotten_tomatoes\", split=\"test\").select(range(5))\n    [print(sentence) for sentence in sentences['text']]\n    lovingly photographed in the manner of a golden book sprung to life , stuart little 2 manages sweetness largely without stickiness .\n    consistently clever and suspenseful .\n    it's like a \" big chill \" reunion of the baader-meinhof gang , only these guys are more harmless pranksters than political activists .\n    the story gives ample opportunity for large-scale action and suspense , which director shekhar kapur supplies with tremendous skill .\n    red dragon \" never cuts corners .\n    ```", "```py\n    roberta_pipe = pipeline(\"sentiment-analysis\",\n        model=\"textattack/roberta-base-rotten-tomatoes\")\n    ```", "```py\n    predictions = roberta_pipe(sentences['text'])\n    ```", "```py\n    for idx, _sentence in enumerate(sentences['text']):\n        print(\n            f\"actual: {sentences['label'][idx]}\\n\"\n            f\"predicted: {'1' if predictions[idx]['label'] \n                == 'LABEL_1' else '0'}\\n\"\n            f\"sentence: {_sentence}\\n\\n\"\n        )\n    actual:1\n    predicted:1\n    sentence:lovingly photographed in the manner of a golden book sprung to life , stuart little 2 manages sweetness largely without stickiness .\n    actual:1\n    predicted:1\n    sentence:consistently clever and suspenseful .\n    actual:1\n    predicted:0\n    sentence:it's like a \" big chill \" reunion of the baader-meinhof gang , only these guys are more harmless pranksters than political activists .\n    actual:1\n    predicted:1\n    sentence:the story gives ample opportunity for large-scale action and suspense , which director shekhar kapur supplies with tremendous skill .\n    actual:1\n    predicted:1\n    sentence:red dragon \" never cuts corners .\n    ```", "```py\n    sentences = load_dataset(\"rotten_tomatoes\", split=\"test\")\n    ```", "```py\n    task_evaluator = evaluator(\"sentiment-analysis\")\n    ```", "```py\n    eval_results = task_evaluator.compute(\n        model_or_pipeline=roberta_pipe,\n        data=sentences,\n        metric=combine([\"accuracy\", \"precision\", \"recall\", \"f1\"]),\n        label_mapping={\"LABEL_0\": 0, \"LABEL_1\": 1}\n    )\n    ```", "```py\n    print(eval_results)\n    {'accuracy': 0.88,\n    'precision': 0.92,\n    'recall': 0.84,\n    'f1': 0.88,\n    'total_time_in_seconds': 27.23,\n    'samples_per_second': 39.146,\n    'latency_in_seconds': 0.025}\n    ```", "```py\n    from transformers import pipeline\n    import torch\n    device = torch.device(\n        \"cuda\" if torch.cuda.is_available() else \"cpu\")\n    ```", "```py\n    pipeline_instance = pipeline(\n        model=\"facebook/bart-large-mnli\")\n    ```", "```py\n    result = pipeline_instance(\n        \"I am so hooked to video games as I cannot get any work done!\",\n        candidate_labels=[\"technology\", \"gaming\", \"hobby\", \"art\", \"computer\"], device=device)\n    ```", "```py\n    print(result['sequence'])\n    for i, label in enumerate(result['labels']):\n        print(f\"{label}:  {result['scores'][i]:.2f}\")\n    I am so hooked to video games as I cannot get any work done!\n    gaming:  0.85\n    hobby:  0.08\n    technology:  0.07\n    computer:  0.00\n    art:  0.00\n    ```", "```py\n    result = pipeline_instance(\n        \"A early morning exercise regimen can drive many diseases away!\",\n        candidate_labels=[\"health\", \"medical\", \"weather\", \"geography\", \"politics\"], )\n    print(result['sequence'])\n    for i, label in enumerate(result['labels']):\n        print(f\"{label}:  {result['scores'][i]:.2f}\")\n    print(\n        f\"The most probable class for the sentence is ** \n        {result['labels'][0]} ** \"\n        f\"with a probability of {result['scores'][0]:.2f}\"\n    )\n    A early morning exercise regimen can drive many diseases away!\n    health:  0.91\n    medical:  0.07\n    weather:  0.01\n    geography:  0.01\n    politics:  0.00\n    The most probable class for the sentence is ** health ** with a probability of 0.91\n    ```", "```py\n    from transformers import pipeline\n    import torch\n    device = torch.device(\n        \"cuda\" if torch.cuda.is_available() else \"cpu\")\n    ```", "```py\n    text = \"The cat had no business entering the neighbors garage, but\"\n    ```", "```py\n    generator = pipeline(\n        'text-generation', model='gpt2', device=device)\n    ```", "```py\n        generated_sentences = generator(\n            text,do_sample=True, max_length=30,\n            num_return_sequences=5, num_beams=5,\n            pad_token_id=50256)\n        ```", "```py\n    [print(generated_sentence['generated_text']) \n        for generated_sentence in generated_sentences]\n    The cat had no business entering the neighbors garage, but  he was able to get inside.  The cat had been in the neighbor's\n    The cat had no business entering the neighbors garage, but  the owner of the house called 911.  He said he found the cat in\n    The cat had no business entering the neighbors garage, but  he was able to get his hands on one of the keys.  It was\n    The cat had no business entering the neighbors garage, but  he didn't seem to mind at all.  He had no idea what he\n    The cat had no business entering the neighbors garage, but  the cat had no business entering the neighbors garage, but the cat had no business entering\n    ```", "```py\ngenerated_sentences = generator(text, do_sample=True,\n    max_length=30, num_return_sequences=5, num_beams=5,\n    no_repeat_ngram_size=2,  pad_token_id=50256)\n```", "```py\nThe cat had no business entering the neighbors garage, but  it was too late to stop it.\n\"I don't know if it was\nThe cat had no business entering the neighbors garage, but  she was able to find her way to the porch, where she and her friend were\nThe cat had no business entering the neighbors garage, but  he did get in the way.\nThe next day, the neighbor called the police\nThe cat had no business entering the neighbors garage, but  he managed to get his hands on one of the keys, which he used to unlock\nThe cat had no business entering the neighbors garage, but  the neighbors thought they were in the right place.\n\"What's going on\n```", "```py\ngenerated_sentences = generator(text, do_sample=True,\n    max_length=30, num_return_sequences=5, num_beams=5,\n    no_repeat_ngram_size=2, top_k=50, pad_token_id=50256)\nThe cat had no business entering the neighbors garage, but  it did get into a neighbor's garage. The neighbor went to check on the cat\nThe cat had no business entering the neighbors garage, but  she was there to take care of it.\nThe next morning, the cat was\nThe cat had no business entering the neighbors garage, but  it didn't want to leave. The neighbor told the cat to get out of the\nThe cat had no business entering the neighbors garage, but  the neighbors were too afraid to call 911.The neighbor told the police that he\nThe cat had no business entering the neighbors garage, but  it was there that he found his way to the kitchen, where it was discovered that\n```", "```py\ngenerated_sentences = generator(text, do_sample=True,\n    max_length=30, num_return_sequences=5, num_beams=5,\n    no_repeat_ngram_size=2, top_k=50, top_p=0.8,\n    pad_token_id=50256)\nThe cat had no business entering the neighbors garage, but  the owner of the house told the police that he did not know what was going on\nThe cat had no business entering the neighbors garage, but  he did, and the cat was able to get out of the garage.The\nThe cat had no business entering the neighbors garage, but  he was able to get in through the back door. The cat was not injured,\nThe cat had no business entering the neighbors garage, but  the neighbor told the police that the cat was a stray, and the neighbor said that\nThe cat had no business entering the neighbors garage, but  the owner of the house said he didn't know what to do with the cat.\n```", "```py\ngenerated_sentences = generator(text, do_sample=True,\n    max_length=500, num_return_sequences=1, num_beams=5,\n    no_repeat_ngram_size=2, top_k=50, top_p=0.85,\n    pad_token_id=50256)\nThe cat had no business entering the neighbors garage, but  she was there to help.\n\"I was like, 'Oh my God, she's here,'\" she said. \"I'm like 'What are you doing here?' \"\nThe neighbor, who asked not to be identified, said she didn't know what to make of the cat's behavior. She said it seemed like it was trying to get into her home, and that she was afraid for her life. The neighbor said that when she went to check on her cat, it ran into the neighbor's garage and hit her in the face, knocking her to the ground.\n```", "```py\n    from transformers import (\n        T5Tokenizer, T5ForConditionalGeneration)\n    import torch\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    ```", "```py\n    tokenizer = T5Tokenizer.from_pretrained(\n        't5-base', model_max_length=200)\n    model = T5ForConditionalGeneration.from_pretrained(\n        't5-base', return_dict=True)\n    model = model.to(device)\n    ```", "```py\n    language_sequence = (\"It's such a beautiful morning today!\")\n    ```", "```py\n    input_ids = tokenizer(\n        \"translate English to French: \" + language_sequence,\n        return_tensors=\"pt\",\n        truncation=True).input_ids.to(device)\n    ```", "```py\n    language_ids = model.generate(input_ids, max_new_tokens=200)\n    ```", "```py\n    language_translation = tokenizer.decode(\n        language_ids[0], skip_special_tokens=True)\n    ```", "```py\n    print(language_translation)\n    C'est un matin si beau!\n    ```"]