<html><head></head><body>
<div aria-label="427" epub:type="pagebreak" id="page1-13" role="doc-pagebreak"/>
<div id="_idContainer126">
<h1 class="chapterTitle" id="_idParaDest-284"><a id="_idTextAnchor568"/><span class="koboSpan" id="kobo.1.1">Appendix</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.2.1">This appendix serves as a practical reference guide to the major LLM providers that integrate with LangChain. </span><span class="koboSpan" id="kobo.2.2">As you develop applications with the techniques covered throughout this book, you’ll need to connect to various model providers, each with its own authentication mechanisms, capabilities, and integration patterns.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.3.1">We’ll first cover the detailed setup instructions for the major LLM providers, including OpenAI, Hugging Face, Google, and others. </span><span class="koboSpan" id="kobo.3.2">For each provider, we walk through the process of creating accounts, generating API keys, and configuring your development environment to use these services with LangChain. </span><span class="koboSpan" id="kobo.3.3">We then conclude with a practical implementation example that demonstrates how to process content exceeding an LLM’s context window—specifically, summarizing long videos using map-reduce techniques with LangChain. </span><span class="koboSpan" id="kobo.3.4">This pattern can be adapted for various scenarios where you need to process large volumes of text, audio transcripts, or other content that won’t fit into a single LLM context.</span></p>
<h1 class="heading-1" id="_idParaDest-285"><a id="_idTextAnchor569"/><span class="koboSpan" id="kobo.4.1">OpenAI</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.5.1">OpenAI remains one of the most </span><a id="_idIndexMarker903"/><span class="koboSpan" id="kobo.6.1">popular LLM providers, offering models with various levels of power suitable for different tasks, including GPT-4 and GPT-o1. </span><span class="koboSpan" id="kobo.6.2">LangChain provides seamless integration with OpenAI’s APIs, supporting both their traditional completion models and chat models. </span><span class="koboSpan" id="kobo.6.3">Each of these models has its own price, typically per token.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.7.1">To work with OpenAI models, we need to obtain an OpenAI API key first. </span><span class="koboSpan" id="kobo.7.2">To create an API key, follow these steps:</span></p>
<ol>
<li class="numberedList" value="1"><span class="koboSpan" id="kobo.8.1">You need to create a login at </span><a href="https://platform.openai.com/"><span class="url"><span class="koboSpan" id="kobo.9.1">https://platform.openai.com/</span></span></a><span class="koboSpan" id="kobo.10.1">.</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.11.1">Set up your billing information.</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.12.1">You can see the API keys under </span><strong class="screenText"><span class="koboSpan" id="kobo.13.1">Personal</span></strong><span class="koboSpan" id="kobo.14.1"> | </span><strong class="screenText"><span class="koboSpan" id="kobo.15.1">View API Keys</span></strong><span class="koboSpan" id="kobo.16.1">.</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.17.1">Click on </span><strong class="screenText"><span class="koboSpan" id="kobo.18.1">Create new secret key</span></strong><span class="koboSpan" id="kobo.19.1"> and give it a name.</span></li>
</ol>
<div aria-label="428" epub:type="pagebreak" id="page2-13" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.20.1">Here’s how this should look on the OpenAI platform:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.21.1"><img alt="Figure A.1: OpenAI API platform – Create new secret key" src="../Images/B32363_Appendix_01-01.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.22.1">Figure A.1: OpenAI API platform – Create new secret key</span></p>
<p class="normal"><span class="koboSpan" id="kobo.23.1">After clicking </span><strong class="screenText"><span class="koboSpan" id="kobo.24.1">Create secret key</span></strong><span class="koboSpan" id="kobo.25.1">, you should see the message API key generated. </span><span class="koboSpan" id="kobo.25.2">You need to copy the key to your clipboard and save it, as you will need it. </span><span class="koboSpan" id="kobo.25.3">You can set the key as an environment variable (</span><strong class="screenText"><span class="koboSpan" id="kobo.26.1">OPENAI_API_KEY</span></strong><span class="koboSpan" id="kobo.27.1">) or pass it as a </span><a id="_idIndexMarker904"/><span class="koboSpan" id="kobo.28.1">parameter every time you construct a class for OpenAI calls.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.29.1">You can specify different </span><a id="_idIndexMarker905"/><span class="koboSpan" id="kobo.30.1">models when you initialize your model, be it a chat model or an LLM. </span><span class="koboSpan" id="kobo.30.2">You can see a list of models at </span><a href="https://platform.openai.com/docs/models"><span class="url"><span class="koboSpan" id="kobo.31.1">https://platform.openai.com/docs/models</span></span></a><span class="koboSpan" id="kobo.32.1">.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.33.1">OpenAI provides a comprehensive suite of capabilities that integrate seamlessly with LangChain, including:</span></p>
<ul>
<li class="b lletList"><span class="koboSpan" id="kobo.34.1">Core language models via the OpenAI API</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.35.1">Embedding class for text embedding models</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.36.1">We’ll cover the basics of model integration in this chapter, while deeper explorations of specialized features like embeddings, assistants, and moderation will follow in Chapters 4 and 5</span><a id="_idTextAnchor570"/><span class="koboSpan" id="kobo.37.1">.</span></p>
<div aria-label="429" epub:type="pagebreak" id="page3-13" role="doc-pagebreak"/>
<h1 class="heading-1" id="_idParaDest-286"><a id="_idTextAnchor571"/><span class="koboSpan" id="kobo.38.1">Hugging Face</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.39.1">Hugging Face is a</span><a id="_idIndexMarker906"/><span class="koboSpan" id="kobo.40.1"> very prominent player in the NLP space and has considerable traction in open-source and hosting solutions. </span><span class="koboSpan" id="kobo.40.2">The company is a French American company that develops tools for building ML applications. </span><span class="koboSpan" id="kobo.40.3">Its employees develop and maintain the Transformers Python library, which is used for NLP tasks, includes implementations of state-of-the-art and popular models like Mistral 7B, BERT, and GPT-2, and is compatible with PyTorch, TensorFlow, and JAX.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.41.1">In addition to their products, Hugging Face has been involved in initiatives such as the BigScience Research Workshop, where they released an</span><a id="_idIndexMarker907"/><span class="koboSpan" id="kobo.42.1"> open LLM called BLOOM with 176 billion parameters. </span><span class="koboSpan" id="kobo.42.2">Hugging Face has also established partnerships with companies like Graphcore and Amazon Web Services to optimize their offerings and make them available to a broader customer base.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.43.1">LangChain supports leveraging the Hugging Face Hub, which provides access to a massive number of models, datasets in various languages and formats, and demo apps. </span><span class="koboSpan" id="kobo.43.2">This includes integrations with Hugging Face Endpoints, enabling text generation inference powered by the Text Generation Inference service. </span><span class="koboSpan" id="kobo.43.3">Users can connect to different Endpoint types, including the free Serverless Endpoints API and dedicated Inference Endpoints for enterprise workloads that come with support for AutoScaling.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.44.1">For local use, LangChain provides integration with Hugging Face models and pipelines. </span><span class="koboSpan" id="kobo.44.2">The </span><code class="inlineCode"><span class="koboSpan" id="kobo.45.1">ChatHuggingFace</span></code><span class="koboSpan" id="kobo.46.1"> class allows using Hugging Face models for chat applications, while the </span><code class="inlineCode"><span class="koboSpan" id="kobo.47.1">HuggingFacePipeline</span></code><span class="koboSpan" id="kobo.48.1"> class</span><a id="_idIndexMarker908"/><span class="koboSpan" id="kobo.49.1"> enables running Hugging Face models locally through pipelines. </span><span class="koboSpan" id="kobo.49.2">Additionally, LangChain supports embedding models from Hugging Face, including </span><code class="inlineCode"><span class="koboSpan" id="kobo.50.1">HuggingFaceEmbeddings</span></code><span class="koboSpan" id="kobo.51.1">, </span><code class="inlineCode"><span class="koboSpan" id="kobo.52.1">HuggingFaceInstructEmbeddings</span></code><span class="koboSpan" id="kobo.53.1">, and </span><code class="inlineCode"><span class="koboSpan" id="kobo.54.1">HuggingFaceBgeEmbeddings</span></code><span class="koboSpan" id="kobo.55.1">.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.56.1">The </span><code class="inlineCode"><span class="koboSpan" id="kobo.57.1">HuggingFaceHubEmbeddings</span></code><span class="koboSpan" id="kobo.58.1"> class allows leveraging the Hugging Face </span><strong class="keyWord"><span class="koboSpan" id="kobo.59.1">Text Embeddings Inference</span></strong><span class="koboSpan" id="kobo.60.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.61.1">TEI</span></strong><span class="koboSpan" id="kobo.62.1">) toolkit for high-</span><a id="_idIndexMarker909"/><span class="koboSpan" id="kobo.63.1">performance extraction. </span><span class="koboSpan" id="kobo.63.2">LangChain also provides a </span><code class="inlineCode"><span class="koboSpan" id="kobo.64.1">HuggingFaceDatasetLoader</span></code><span class="koboSpan" id="kobo.65.1"> to load datasets from the Hugging Face Hub.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.66.1">To use Hugging Face as a provider for your models, you can create an account and API keys at </span><a href="https://huggingface.co/settings/profile"><span class="url"><span class="koboSpan" id="kobo.67.1">https://huggingface.co/settings/profile</span></span></a><span class="koboSpan" id="kobo.68.1">. </span><span class="koboSpan" id="kobo.68.2">Additionally, you can make the token available in your environment as </span><code class="inlineCode"><span class="koboSpan" id="kobo.69.1">HUGGINGFACEHUB_API_T</span><a id="_idTextAnchor572"/><span class="koboSpan" id="kobo.70.1">OKEN</span></code><span class="koboSpan" id="kobo.71.1">.</span></p>
<div aria-label="430" epub:type="pagebreak" id="page4-13" role="doc-pagebreak"/>
<h1 class="heading-1" id="_idParaDest-287"><a id="_idTextAnchor573"/><span class="koboSpan" id="kobo.72.1">Google</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.73.1">Google offers two primary platforms to access its LLMs, including the latest Gemini models:</span></p>
<h3 class="heading-3" id="_idParaDest-288"><a id="_idTextAnchor574"/><span class="koboSpan" id="kobo.74.1">1. </span><span class="koboSpan" id="kobo.74.2">Google AI platform</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.75.1">The Google AI platform </span><a id="_idIndexMarker910"/><span class="koboSpan" id="kobo.76.1">provides a straightforward setup for developers and users, and access to the latest Gemini models. </span><span class="koboSpan" id="kobo.76.2">To use the Gemini models via Google AI:</span></p>
<ul>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.77.1">Google Account</span></strong><span class="koboSpan" id="kobo.78.1">: A standard Google account is sufficient for authentication.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.79.1">API Key</span></strong><span class="koboSpan" id="kobo.80.1">: Generate an API key to authenticate your requests.</span><ul><li class="bulletList level-2"><span class="koboSpan" id="kobo.81.1">Visit this page to create your API key: </span><a href="https://ai.google.dev/gemini-api/docs/api-key "><span class="url"><span class="koboSpan" id="kobo.82.1">https://ai.google.dev/gemini-api/docs/api-key</span></span></a></li>
<li class="bulletList level-2"><span class="koboSpan" id="kobo.83.1">After obtaining the API key, set the </span><code class="inlineCode"><span class="koboSpan" id="kobo.84.1">GOOGLE_API_KEY</span></code><span class="koboSpan" id="kobo.85.1"> environment variable in your development environment (see the instructions for OpenAI) to authenticate your requests.</span></li>
</ul></li>
</ul>
<h3 class="heading-3" id="_idParaDest-289"><a id="_idTextAnchor575"/><span class="koboSpan" id="kobo.86.1">2. </span><span class="koboSpan" id="kobo.86.2">Google Cloud Vertex AI</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.87.1">For enterprise-level features and integration, Google’s Gemini models are available through Google Cloud’s Vertex AI </span><a id="_idIndexMarker911"/><span class="koboSpan" id="kobo.88.1">platform. </span><span class="koboSpan" id="kobo.88.2">To use models via Vertex AI:</span></p>
<ol>
<li class="numberedList" value="1"><span class="koboSpan" id="kobo.89.1">Create a Google Cloud account, which requires accepting the terms of service and setting up billing.</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.90.1">Install the gcloud </span><a id="_idIndexMarker912"/><span class="koboSpan" id="kobo.91.1">CLI to interact with Google Cloud services. </span><span class="koboSpan" id="kobo.91.2">Follow the installation instructions at </span><a href="https://cloud.google.com/sdk/docs/install"><span class="url"><span class="koboSpan" id="kobo.92.1">https://cloud.google.com/sdk/docs/install</span></span></a><span class="koboSpan" id="kobo.93.1">.</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.94.1">Run the following command to authenticate and obtain a key token:</span><p class="snippet-con-one"><span class="koboSpan" id="kobo.95.1">gcloud auth application-default login</span></p></li>
<li class="numberedList"><span class="koboSpan" id="kobo.96.1">Ensure that the Vertex AI API is enabled for your Google Cloud project.</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.97.1">You can set your Google Cloud project ID – for example, using the </span><code class="inlineCode"><span class="koboSpan" id="kobo.98.1">gcloud</span></code><span class="koboSpan" id="kobo.99.1"> command:</span><p class="snippet-con-one"><span class="koboSpan" id="kobo.100.1">gcloud config set project my-project</span></p></li>
</ol>
<p class="normal"><span class="koboSpan" id="kobo.101.1">Other methods are passing a constructor argument when initializing the LLM, using aiplatform.init(), or setting a GCP environment variable.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.102.1">You can read more about these options in the Vertex documentation.</span></p>
<div aria-label="431" epub:type="pagebreak" id="page5-13" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.103.1">If you haven’t enabled the relevant service, you should get a helpful error message pointing you to the right website, where you click </span><strong class="screenText"><span class="koboSpan" id="kobo.104.1">Enable</span></strong><span class="koboSpan" id="kobo.105.1">. </span><span class="koboSpan" id="kobo.105.2">You have to either enable Vertex or the Generative Language API according to preference and availability.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.106.1">LangChain offers integrations with Google services such as language model inference, embeddings, data ingestion from different sources, document transformation, and translation.</span></p>
<div>
<div class="note" id="_idContainer125">
<p class="normal"><span class="koboSpan" id="kobo.107.1">There are two main integration packages:</span></p>
<ul>
<li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.108.1">langchain-google-vertexai</span></code></li>
<li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.109.1">langchain-google-genai</span></code></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.110.1">We’ll be using </span><code class="inlineCode"><span class="koboSpan" id="kobo.111.1">langchain-google-genai</span></code><span class="koboSpan" id="kobo.112.1">, the package recommended by LangChain for individual developers. </span><span class="koboSpan" id="kobo.112.2">The setup is simple, only requiring a Google account and API key. </span><span class="koboSpan" id="kobo.112.3">It is recommended to move to </span><code class="inlineCode"><span class="koboSpan" id="kobo.113.1">langchain-google-vertexai</span></code><span class="koboSpan" id="kobo.114.1"> for larger projects. </span><span class="koboSpan" id="kobo.114.2">This integration offers enterprise features such as customer encryption keys, virtual private cloud integration, and more, requiring a Google Cloud account with billing.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.115.1">If you’ve followed the instructions on GitHub, as indicated in the previous section, you should already have the </span><code class="inlineCode"><span class="koboSpan" id="kobo.116.1">langchain-google-genai</span></code><span class="koboSpan" id="kobo.117.1"> package installed.</span></p>
</div>
</div>
<h1 class="heading-1" id="_idParaDest-290"><a id="_idTextAnchor576"/><span class="koboSpan" id="kobo.118.1">Other providers</span></h1>
<ul>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.119.1">Replicate</span></strong><span class="koboSpan" id="kobo.120.1">: You can authenticate with your GitHub credentials at </span><a href="https://replicate.com/"><span class="url"><span class="koboSpan" id="kobo.121.1">https://replicate.com/</span></span></a><span class="koboSpan" id="kobo.122.1">. </span><span class="koboSpan" id="kobo.122.2">If you then click on </span><a id="_idIndexMarker913"/><span class="koboSpan" id="kobo.123.1">your user icon at the top left, you’ll find the API tokens – just copy the API key and make it available in your environment as </span><code class="inlineCode"><span class="koboSpan" id="kobo.124.1">REPLICATE_API_TOKEN</span></code><span class="koboSpan" id="kobo.125.1">. </span><span class="koboSpan" id="kobo.125.2">To run bigger jobs, you need to set up your credit card (under billing).</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.126.1">Azure</span></strong><span class="koboSpan" id="kobo.127.1">: By authenticating</span><a id="_idIndexMarker914"/><span class="koboSpan" id="kobo.128.1"> either through GitHub or Microsoft credentials, we can create an account on Azure at </span><a href="https://azure.microsoft.com/"><span class="url"><span class="koboSpan" id="kobo.129.1">https://azure.microsoft.com/</span></span></a><span class="koboSpan" id="kobo.130.1">. </span><span class="koboSpan" id="kobo.130.2">We can then create new API keys under </span><strong class="screenText"><span class="koboSpan" id="kobo.131.1">Cognitive Services</span></strong><span class="koboSpan" id="kobo.132.1"> | </span><strong class="screenText"><span class="koboSpan" id="kobo.133.1">Azure OpenAI</span></strong><span class="koboSpan" id="kobo.134.1">.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.135.1">Anthropic</span></strong><span class="koboSpan" id="kobo.136.1">: You need to set</span><a id="_idIndexMarker915"/><span class="koboSpan" id="kobo.137.1"> the </span><code class="inlineCode"><span class="koboSpan" id="kobo.138.1">ANTHROPIC_API_KEY</span></code><span class="koboSpan" id="kobo.139.1"> environment variable. </span><span class="koboSpan" id="kobo.139.2">Please make sure you’ve set up billing and added funds on the Anthropic console at </span><a href="https://console.anthropic.com/"><span class="url"><span class="koboSpan" id="kobo.140.1">https://console.anthropic.com/</span></span></a><span class="koboSpan" id="kobo.141.1">.</span></li>
</ul>
<div aria-label="432" epub:type="pagebreak" id="page6-13" role="doc-pagebreak"/>
<h1 class="heading-1" id="_idParaDest-291"><a id="_idTextAnchor577"/><span class="koboSpan" id="kobo.142.1">Summarizing long videos</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.143.1">ln </span><em class="italic"><span class="koboSpan" id="kobo.144.1">Chapter 3</span></em><span class="koboSpan" id="kobo.145.1">, we demonstrated how to summarize long videos (that don’t fit into the context window) with a map-reduce approach. </span><span class="koboSpan" id="kobo.145.2">We used LangGraph to design such a workflow. </span><span class="koboSpan" id="kobo.145.3">Of course, you can use the same approach to any similar case – for example, to summarize long text or to extract information from long audios. </span><span class="koboSpan" id="kobo.145.4">Let’s now do the same using LangChain only, since it will be a useful exercise that will help us to better understand some internals of the framework.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.146.1">First, a </span><code class="inlineCode"><span class="koboSpan" id="kobo.147.1">PromptTemplate</span></code><span class="koboSpan" id="kobo.148.1"> doesn’t support media types (as of February 2025), so we need to convert an input to a list of messages </span><a id="_idIndexMarker916"/><span class="koboSpan" id="kobo.149.1">manually. </span><span class="koboSpan" id="kobo.149.2">To use a parameterized chain, as a workaround, we will create a Python function that takes arguments (always provided by name) and creates a list of messages to be processed. </span><span class="koboSpan" id="kobo.149.3">Every message instructs an LLM to summarize a certain piece of the video (by splitting it into offset intervals), and these messages can be processed in parallel. </span><span class="koboSpan" id="kobo.149.4">The output will be a list of strings, each summarizing a subpart of the original video.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.150.1">When you use an extra asterisk (</span><em class="italic"><span class="koboSpan" id="kobo.151.1">*</span></em><span class="koboSpan" id="kobo.152.1">) in Python function declarations, it means that arguments after the asterisk should be provided by name only. </span><span class="koboSpan" id="kobo.152.2">For example, let’s create a simple function with many arguments that we can call in different ways in Python by passing only a few (or none) of the parameters by name:</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.153.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.154.1">test</span></span><span class="koboSpan" id="kobo.155.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.156.1">a: </span></span><span class="hljs-built_in"><span class="koboSpan" id="kobo.157.1">int</span></span><span class="hljs-params"><span class="koboSpan" id="kobo.158.1">, b: </span></span><span class="hljs-built_in"><span class="koboSpan" id="kobo.159.1">int</span></span><span class="hljs-params"><span class="koboSpan" id="kobo.160.1"> = </span></span><span class="hljs-number"><span class="koboSpan" id="kobo.161.1">2</span></span><span class="hljs-params"><span class="koboSpan" id="kobo.162.1">, c: </span></span><span class="hljs-built_in"><span class="koboSpan" id="kobo.163.1">int</span></span><span class="hljs-params"><span class="koboSpan" id="kobo.164.1"> = </span></span><span class="hljs-number"><span class="koboSpan" id="kobo.165.1">3</span></span><span class="koboSpan" id="kobo.166.1">):</span></p>
<p class="snippet-code"> <span class="hljs-built_in"><span class="koboSpan" id="kobo.167.1">print</span></span><span class="koboSpan" id="kobo.168.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.169.1">f"a=</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.170.1">{a}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.171.1">, b=</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.172.1">{b}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.173.1">, c=</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.174.1">{c}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.175.1">"</span></span><span class="koboSpan" id="kobo.176.1">)</span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.177.1">pass</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.178.1">test(</span><span class="hljs-number"><span class="koboSpan" id="kobo.179.1">1</span></span><span class="koboSpan" id="kobo.180.1">, </span><span class="hljs-number"><span class="koboSpan" id="kobo.181.1">2</span></span><span class="koboSpan" id="kobo.182.1">, </span><span class="hljs-number"><span class="koboSpan" id="kobo.183.1">3</span></span><span class="koboSpan" id="kobo.184.1">)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.185.1">test(</span><span class="hljs-number"><span class="koboSpan" id="kobo.186.1">1</span></span><span class="koboSpan" id="kobo.187.1">, </span><span class="hljs-number"><span class="koboSpan" id="kobo.188.1">2</span></span><span class="koboSpan" id="kobo.189.1">, c=</span><span class="hljs-number"><span class="koboSpan" id="kobo.190.1">3</span></span><span class="koboSpan" id="kobo.191.1">)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.192.1">test(</span><span class="hljs-number"><span class="koboSpan" id="kobo.193.1">1</span></span><span class="koboSpan" id="kobo.194.1">, b=</span><span class="hljs-number"><span class="koboSpan" id="kobo.195.1">2</span></span><span class="koboSpan" id="kobo.196.1">, c=</span><span class="hljs-number"><span class="koboSpan" id="kobo.197.1">3</span></span><span class="koboSpan" id="kobo.198.1">)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.199.1">test(</span><span class="hljs-number"><span class="koboSpan" id="kobo.200.1">1</span></span><span class="koboSpan" id="kobo.201.1">, c=</span><span class="hljs-number"><span class="koboSpan" id="kobo.202.1">3</span></span><span class="koboSpan" id="kobo.203.1">)</span></p>
<p class="normal"><span class="koboSpan" id="kobo.204.1">But if you change its signature, the first invocation will throw an error:</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.205.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.206.1">test</span></span><span class="koboSpan" id="kobo.207.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.208.1">a: </span></span><span class="hljs-built_in"><span class="koboSpan" id="kobo.209.1">int</span></span><span class="hljs-params"><span class="koboSpan" id="kobo.210.1">, b: </span></span><span class="hljs-built_in"><span class="koboSpan" id="kobo.211.1">int</span></span><span class="hljs-params"><span class="koboSpan" id="kobo.212.1"> = </span></span><span class="hljs-number"><span class="koboSpan" id="kobo.213.1">2</span></span><span class="hljs-params"><span class="koboSpan" id="kobo.214.1">, *, c: </span></span><span class="hljs-built_in"><span class="koboSpan" id="kobo.215.1">int</span></span><span class="hljs-params"><span class="koboSpan" id="kobo.216.1"> = </span></span><span class="hljs-number"><span class="koboSpan" id="kobo.217.1">3</span></span><span class="koboSpan" id="kobo.218.1">):</span></p>
<p class="snippet-code"> <span class="hljs-built_in"><span class="koboSpan" id="kobo.219.1">print</span></span><span class="koboSpan" id="kobo.220.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.221.1">f"a=</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.222.1">{a}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.223.1">, b=</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.224.1">{b}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.225.1">, c=</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.226.1">{c}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.227.1">"</span></span><span class="koboSpan" id="kobo.228.1">)</span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.229.1">pass</span></span></p>
<p class="snippet-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.230.1"># this doesn't work any more: test(1, 2, 3)</span></span></p>
<p class="normal"><span class="koboSpan" id="kobo.231.1">You might see this a lot if you look at LangChain’s source code. </span><span class="koboSpan" id="kobo.231.2">That’s why we decided to explain it in a little bit more detail.</span></p>
<div aria-label="433" epub:type="pagebreak" id="page7-12" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.232.1">Now, back to our code. </span><span class="koboSpan" id="kobo.232.2">We still need to run two separate steps if we want to pass </span><code class="inlineCode"><span class="koboSpan" id="kobo.233.1">video_uri</span></code><span class="koboSpan" id="kobo.234.1"> as an input argument. </span><span class="koboSpan" id="kobo.234.2">Of course, we </span><a id="_idIndexMarker917"/><span class="koboSpan" id="kobo.235.1">can wrap these steps as a Python function, but as an alternative, we merge everything into a single chain:</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.236.1">from</span></span><span class="koboSpan" id="kobo.237.1"> langchain_core.runnables </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.238.1">import</span></span><span class="koboSpan" id="kobo.239.1"> RunnableLambda</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.240.1">create_inputs_chain = RunnableLambda(</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.241.1">lambda</span></span><span class="koboSpan" id="kobo.242.1"> x: _create_input_</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.243.1">messages(**x))</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.244.1">map_step_chain = create_inputs_chain | RunnableLambda(</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.245.1">lambda</span></span><span class="koboSpan" id="kobo.246.1"> x: map_chain.</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.247.1">batch(x, config={</span><span class="hljs-string"><span class="koboSpan" id="kobo.248.1">"max_concurrency"</span></span><span class="koboSpan" id="kobo.249.1">: </span><span class="hljs-number"><span class="koboSpan" id="kobo.250.1">3</span></span><span class="koboSpan" id="kobo.251.1">}))</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.252.1">summaries = map_step_chain.invoke({</span><span class="hljs-string"><span class="koboSpan" id="kobo.253.1">"video_uri"</span></span><span class="koboSpan" id="kobo.254.1">: video_uri})</span></p>
<p class="normal"><span class="koboSpan" id="kobo.255.1">Now let’s merge all summaries provided into a single prompt and ask an LLM to prepare a final summary:</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.256.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.257.1">_merge_summaries</span></span><span class="koboSpan" id="kobo.258.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.259.1">summaries: </span></span><span class="hljs-built_in"><span class="koboSpan" id="kobo.260.1">list</span></span><span class="hljs-params"><span class="koboSpan" id="kobo.261.1">[</span></span><span class="hljs-built_in"><span class="koboSpan" id="kobo.262.1">str</span></span><span class="hljs-params"><span class="koboSpan" id="kobo.263.1">], interval_secs: </span></span><span class="hljs-built_in"><span class="koboSpan" id="kobo.264.1">int</span></span><span class="hljs-params"><span class="koboSpan" id="kobo.265.1"> = </span></span><span class="hljs-number"><span class="koboSpan" id="kobo.266.1">600</span></span><span class="hljs-params"><span class="koboSpan" id="kobo.267.1">, **kwargs</span></span><span class="koboSpan" id="kobo.268.1">) -&gt; </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.269.1">str</span></span><span class="koboSpan" id="kobo.270.1">:</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.271.1">    sub_summaries = []</span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.272.1">for</span></span><span class="koboSpan" id="kobo.273.1"> i, summary </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.274.1">in</span></span> <span class="hljs-built_in"><span class="koboSpan" id="kobo.275.1">enumerate</span></span><span class="koboSpan" id="kobo.276.1">(summaries):</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.277.1">        sub_summary = (</span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.278.1">f"Summary from sec </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.279.1">{i*interval_secs}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.280.1"> to sec </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.281.1">{(i+</span></span><span class="hljs-number"><span class="koboSpan" id="kobo.282.1">1</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.283.1">)*interval_secs}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.284.1">:"</span></span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.285.1">f"\n</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.286.1">{summary}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.287.1">\n"</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.288.1">        )</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.289.1">        sub_summaries.append(sub_summary)</span></p>
<p class="snippet-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.290.1">return</span></span> <span class="hljs-string"><span class="koboSpan" id="kobo.291.1">""</span></span><span class="koboSpan" id="kobo.292.1">.join(sub_summaries)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.293.1">reduce_prompt = PromptTemplate.from_template(</span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.294.1">"</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.295.1">You are given a list of summaries that"</span></span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.296.1">"of a video splitted into sequential pieces.\n"</span></span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.297.1">"SUMMARIES:\n{summaries}"</span></span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.298.1">"Based on that, prepare a summary of a whole video."</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.299.1">)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.300.1">reduce_chain = RunnableLambda(</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.301.1">lambda</span></span><span class="koboSpan" id="kobo.302.1"> x: _merge_summaries(**x)) | reduce_prompt | llm | StrOutputParser()</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.303.1">final_summary = reduce_chain.invoke({</span><span class="hljs-string"><span class="koboSpan" id="kobo.304.1">"summaries"</span></span><span class="koboSpan" id="kobo.305.1">: summaries})</span></p>
<div aria-label="434" epub:type="pagebreak" id="page8-12" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.306.1">To combine everything together, we</span><a id="_idIndexMarker918"/><span class="koboSpan" id="kobo.307.1"> need a chain that first executes all the MAP steps and then the REDUCE phase:</span></p>
<p class="snippet-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.308.1">from</span></span><span class="koboSpan" id="kobo.309.1"> langchain_core.runnables </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.310.1">import</span></span><span class="koboSpan" id="kobo.311.1"> RunnablePassthrough</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.312.1">final_chain = (</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.313.1">    RunnablePassthrough.assign(summaries=map_step_chain).assign(final_ summary=reduce_chain)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.314.1">    | RunnableLambda(</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.315.1">lambda</span></span><span class="koboSpan" id="kobo.316.1"> x: x[</span><span class="hljs-string"><span class="koboSpan" id="kobo.317.1">"final_summary"</span></span><span class="koboSpan" id="kobo.318.1">])</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.319.1">)</span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.320.1">result = final_chain.invoke({</span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.321.1">"video_uri"</span></span><span class="koboSpan" id="kobo.322.1">: video_uri,</span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.323.1">"interval_secs"</span></span><span class="koboSpan" id="kobo.324.1">: </span><span class="hljs-number"><span class="koboSpan" id="kobo.325.1">300</span></span><span class="koboSpan" id="kobo.326.1">,</span></p>
<p class="snippet-code"> <span class="hljs-string"><span class="koboSpan" id="kobo.327.1">"chunks"</span></span><span class="koboSpan" id="kobo.328.1">: </span><span class="hljs-number"><span class="koboSpan" id="kobo.329.1">9</span></span></p>
<p class="snippet-code"><span class="koboSpan" id="kobo.330.1">})</span></p>
<p class="normal"><span class="koboSpan" id="kobo.331.1">Let’s reiterate what we did. </span><span class="koboSpan" id="kobo.331.2">We generated multiple summaries of different parts of the video, and then we passed these summaries to an LLM as texts and tasked it to generate a final summary. </span><span class="koboSpan" id="kobo.331.3">We prepared summaries of each piece independently and then combined them, which allowed us to overcome the limitation of a context window size for video and decreased latency a lot due to parallelization. </span><span class="koboSpan" id="kobo.331.4">Another alternative is the so-called </span><strong class="keyWord"><span class="koboSpan" id="kobo.332.1">refine</span></strong><span class="koboSpan" id="kobo.333.1"> approach. </span><span class="koboSpan" id="kobo.333.2">We begin with an empty summary and perform summarization step by step – each time, providing an LLM with a new piece of the video and a previously generated summary as input. </span><span class="koboSpan" id="kobo.333.3">We encourage readers to build this themselves since it will be a relatively simple change to the code.</span></p>
</div>
</body></html>