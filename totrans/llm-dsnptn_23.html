<html><head></head><body><div id="book-content"><div id="sbo-rt-content"><div id="_idContainer047">
			<h1 id="_idParaDest-270" class="chapter-number"><a id="_idTextAnchor339"/>23</h1>
			<h1 id="_idParaDest-271"><a id="_idTextAnchor340"/>Reasoning WithOut Observation</h1>
			<p><strong class="bold">Reasoning WithOut Observation</strong> (<strong class="bold">ReWOO</strong>), proposed <a id="_idIndexMarker1046"/>by Xu et al. (<a href="https://arxiv.org/abs/2305.18323">https://arxiv.org/abs/2305.18323</a>), is a framework that combines a multi-step planner and variable substitution for effective tool use. It aims to improve upon ReAct-style agents by reducing token consumption and execution time by generating the full chain of tool usage in a single pass, thus minimizing redundant LLM calls. It also aims to simplify the fine-tuning process by enabling fine-tuning without actually invoking tools as planning data doesn’t depend on tool outputs (<span class="No-Break">in theory).</span></p>
			<p>ReAct operates through a cyclical “think-act-observe” pattern, where an AI engages in reasoning, performs an action, examines the resulting feedback, and then adjusts its subsequent actions accordingly, facilitating a dynamic and responsive problem-solving strategy. In contrast, ReWOO emphasizes comprehensive upfront planning, generating a complete sequence of actions before any execution occurs, thereby minimizing the necessity for continuous observation and feedback. This distinction allows ReWOO to pursue greater efficiency by reducing token consumption and computational costs, shifting from ReAct’s iterative feedback loop to a more streamlined “<span class="No-Break">plan-act” methodology.</span></p>
			<p>So, ReWOO refers to an LLM’s ability to make inferences, predictions, or decisions about scenarios it has not directly observed or been trained on. ReWOO enhances this by incorporating external tool use into the <span class="No-Break">reasoning process.</span></p>
			<p>ReWOO’s ability to plan and reason without direct observation makes it suitable for complex planning and <span class="No-Break">decision-making tasks:</span></p>
			<ul>
				<li><strong class="bold">Strategic planning</strong>: As mentioned, ReWOO can <a id="_idIndexMarker1047"/>generate strategic plans based on hypothetical situations, goals, <span class="No-Break">and constraints</span></li>
				<li><strong class="bold">Scenario analysis</strong>: ReWOO can<a id="_idIndexMarker1048"/> explore multiple potential outcomes of a given scenario, considering various factors <span class="No-Break">and uncertainties</span></li>
				<li><strong class="bold">Resource allocation</strong>: By planning tool use and reasoning about their results, ReWOO can optimize resource allocation in<a id="_idIndexMarker1049"/> <span class="No-Break">complex environments</span></li>
				<li><strong class="bold">Risk assessment</strong>: ReWOO can help <a id="_idIndexMarker1050"/>assess potential risks and develop mitigation strategies by simulating different scenarios and <span class="No-Break">their consequences</span></li>
			</ul>
			<p>In this chapter, we’ll be covering the <span class="No-Break">following topics:</span></p>
			<ul>
				<li>Implementing ReWOO <span class="No-Break">with LangGraph</span></li>
				<li>Advantages <span class="No-Break">of ReWOO</span></li>
				<li>Evaluating quality and <span class="No-Break">ethical considerations</span></li>
				<li><span class="No-Break">Future directions</span></li>
			</ul>
			<h1 id="_idParaDest-272"><a id="_idTextAnchor341"/>Implementing ReWOO with LangGraph</h1>
			<p>LangGraph is an open source framework<a id="_idIndexMarker1051"/> designed for building stateful, multi-agent applications using LLMs. It extends the capabilities of the LangChain ecosystem <a id="_idIndexMarker1052"/>by introducing a directed graph model, where nodes represent functions (including LLM invocations) and edges represent transitions between states based on logic, conditions, or memory. Unlike traditional sequential chains, LangGraph allows complex workflows involving conditional branching, loops, memory passing, and asynchronous agent coordination. LangGraph is particularly useful for implementing systems where interactions are dynamic, iterative, and dependent on state changes. This includes multi-agent collaboration, decision trees, retrieval-augmented generation with control flow, and autonomous agents that need to revisit prior steps or loop through subtasks until certain goals <span class="No-Break">are met.</span></p>
			<p>LangGraph leverages concepts from graph theory and automata, representing execution flows as state machines or directed acyclic graphs (or cyclic graphs when loops are needed). Developers define a graph with nodes (functions or tools), edges (state transitions), and conditions (logic for routing). The runtime engine then executes the graph in response to inputs, updating the state at <span class="No-Break">each step.</span></p>
			<p>LangGraph supports both synchronous and asynchronous execution, and it integrates with LangChain’s components, such as tools, memory, and agents. It also supports streaming responses, fine-grained control over state, and multi-modal inputs/outputs, making it suitable for <span class="No-Break">production-level applications.</span></p>
			<p>In practice, LangGraph is used to build agentic systems where different agents interact, coordinate, and share memory, while still following a well-defined computational graph. This makes it different from naive agent loops or unstructured LLM <span class="No-Break">orchestration methods.</span></p>
			<p>LangGraph is available at <a href="https://github.com/langchain-ai/langgraph">https://github.com/langchain-ai/langgraph</a> and supports Python-based implementation, with <a id="_idIndexMarker1053"/>core dependencies on LangChain and state machine <span class="No-Break">execution frameworks.</span></p>
			<p>The ReWOO architecture consists of <span class="No-Break">three modules:</span></p>
			<ul>
				<li><strong class="bold">Planner</strong>: Generates a <a id="_idIndexMarker1054"/>high-level plan to solve the problem, including identifying which tools to use and <a id="_idIndexMarker1055"/>their arguments, potentially using <strong class="bold">variable substitution</strong> to represent dependencies between steps. Variable substitution in AI planning, particularly within systems such as <a id="_idIndexMarker1056"/>ReWOO, enables the creation of flexible and efficient plans by employing placeholders to represent values that are determined during execution. This technique allows the AI to define dependencies between steps, such as using the output of a search tool as the input for a price extraction tool, without needing to know the specific values in advance. By using variables such as <strong class="source-inline">search_result</strong> or <strong class="source-inline">price</strong>, the AI can construct a clear blueprint of the task, deferring the resolution of dynamic information until it becomes available, thereby streamlining the planning process and avoiding <span class="No-Break">unnecessary computations.</span></li>
				<li><strong class="bold">Worker</strong>: Executes the tool with<a id="_idIndexMarker1057"/> the provided arguments, potentially using variable substitution from <span class="No-Break">previous steps.</span></li>
				<li><strong class="bold">Solver</strong>: Generates the final <a id="_idIndexMarker1058"/>answer based on the tool observations and <span class="No-Break">the plan.</span></li>
			</ul>
			<p>This architecture may seem a little abstract initially. Let’s implement ReWOO using LangGraph. We’ll use a Tavily search engine as an <span class="No-Break">example tool:</span></p>
			<ol>
				<li>Install the necessary packages and set <span class="No-Break">API keys:</span><pre class="source-code">
<strong class="bold"># %pip install -U langgraph langchain_community langchain_openai tavily-python</strong></pre><p class="list-inset">Tavily is a search engine designed specifically for AI agents. It’s built to provide accurate and reliable information retrieval, tailored to the needs of AI systems performing complex<a id="_idIndexMarker1059"/> tasks (<span class="No-Break">see </span><a href="https://tavily.com/"><span class="No-Break">https://tavily.com/</span></a><span class="No-Break">).</span></p><p class="list-inset">The following script <a id="_idIndexMarker1060"/>sets environment variables for API keys if they haven’t been <span class="No-Break">defined yet:</span></p><pre class="source-code">import getpass
import os
def _set_if_undefined(var: str):
    if not os.environ.get(var):
        os.environ[var] = getpass.getpass(f"{var}=")
_set_if_undefined("TAVILY_API_KEY")
_set_if_undefined("OPENAI_API_KEY")</pre></li>				<li>Next, define the graph state. To do so, define the state dictionary so that it can hold the task, plan, steps, results, and <span class="No-Break">final result:</span><pre class="source-code">
from typing import List
from typing_extensions import TypedDict
class ReWOO(TypedDict):
    task: str
    plan_string: str
    steps: List
    results: dict
    result: str</pre></li>				<li>Create the planner <a id="_idIndexMarker1061"/>prompt <span class="No-Break">and logic:</span><pre class="source-code">
from langchain_openai import ChatOpenAI
model = ChatOpenAI(model="gpt-4o")
prompt = """For the following task, create a series of plans that can solve the problem step-by-step. For each plan, specify which external tool and its corresponding input should be used to gather evidence. You can store the evidence in a variable #E (e.g., #E1, #E2, #E3, etc.) that can be referenced by subsequent tools. Note that all the variables are independent, so make sure to include all necessary information in each tool input.
Tools can be one of the following:
Google[input]: A search engine worker that retrieves results from Google. Use this when you need concise answers or information about a specific topic. The input should be a search query.
LLM[input]: A pretrained Large Language Model (like me). Use this when you need to leverage general world knowledge, common sense, or perform complex reasoning. Prioritize this tool when you are confident in solving the problem without external assistance. The input can be any instruction or question.
Calculator[input]: A tool that can perform mathematical calculations. Use this when you need to perform arithmetic operations. The input should be a valid mathematical expression.
WolframAlpha[input]: A computational knowledge engine. Use this when you need to solve equations, perform symbolic calculations, or get data-driven answers. The input should be a query in Wolfram Language or natural language related to a math or science problem.
For example,
Task: Alice, Bob, and Carol earned a total of $540 from their part-time jobs last week. Alice earned y dollars. Bob earned $20 more than three times what Alice earned, and Carol earned $15 more than Bob. How much money did Carol earn?
Plan: Given Alice earned y dollars, translate the problem into algebraic expressions and solve with Wolfram Alpha.
#E1 = WolframAlpha[Solve y + (3y + 20) + ((3y + 20) + 15) = 540]
Plan: Find out the amount of money Alice earned.
#E2 = LLM[What is y, given #E1]
Plan: Calculate the amount of money Carol earned.
#E3 = Calculator[((3 * #E2) + 20) + 15]
Begin!
Describe your plans with rich details. Each Plan should be followed by only one #E.
Task: {task}"""</pre></li>				<li>Create <a id="_idIndexMarker1062"/>a LangGraph<a id="_idIndexMarker1063"/> node for <span class="No-Break">the planner:</span><pre class="source-code">
import re
from langchain_core.prompts import ChatPromptTemplate
regex_pattern = (
    r"Plan:\s*(.+)\s*(#E\d+)\s*=\s*(\w+)\s*"
    r"\[([^\]]+)\]"
)
prompt_template = ChatPromptTemplate.from_messages(
    [("user", prompt)]
)
planner = prompt_template | model
def get_plan(state: ReWOO):
    task = state["task"]
    result = planner.invoke({"task": task})
    matches = re.findall(regex_pattern, result.content)
    return {"steps": matches, "plan_string": result.content}</pre></li>				<li>Instantiate the search <a id="_idIndexMarker1064"/>engine and define the tool <a id="_idIndexMarker1065"/><span class="No-Break">execution logic:</span><pre class="source-code">
from langchain_community.tools.tavily_search import TavilySearchResults
search = TavilySearchResults()
def _get_current_task(state: ReWOO):
    if "results" not in state or state["results"] is None:
        return 1
    if len(state["results"]) == len(state["steps"]):
        return None
    else:
        return len(state["results"]) + 1
def tool_execution(state: ReWOO):
    _step = _get_current_task(state)
    _, step_name, tool, tool_input = state["steps"][_step - 1]
    _results = (state["results"] or {}) if "results" in state else {}
    for k, v in _results.items():
        tool_input = tool_input.replace(k, v)
    if tool == "Google":
        result = search.invoke(tool_input)
    elif tool == "LLM":
        result = model.invoke(tool_input)
    else:
        raise ValueError
    _results[step_name] = str(result)
    return {"results": _results}</pre></li>				<li>Create the<a id="_idIndexMarker1066"/> solver prompt <a id="_idIndexMarker1067"/><span class="No-Break">and logic:</span><pre class="source-code">
solve_prompt = """Solve the following task or problem. To solve the problem, we have made step-by-step Plan and \
retrieved corresponding Evidence to each Plan. Use them with caution since long evidence might \
contain irrelevant information.
{plan}
Now solve the question or task according to provided Evidence above. Respond with the answer
directly with no extra words.
Task: {task}
Response:"""
def solve(state: ReWOO):
    plan = ""
    for _plan, step_name, tool, tool_input in state["steps"]:
        _results = (
            (state["results"] or {}) if "results" in state else {}
        )
        for k, v in _results.items():
            tool_input = tool_input.replace(k, v)
            step_name = step_name.replace(k, v)
        plan += (
            f"Plan: {_plan}\n"
            f"{step_name} = {tool}[{tool_input}]\n"
        )
    prompt = solve_prompt.format(plan=plan, task=state["task"])
    result = model.invoke(prompt)
    return {"result": result.content}</pre></li>				<li>Build the<a id="_idIndexMarker1068"/> <span class="No-Break">LangGraph </span><span class="No-Break"><a id="_idIndexMarker1069"/></span><span class="No-Break">workflow:</span><pre class="source-code">
def _route(state):
    _step = _get_current_task(state)
    if _step is None:
        return "solve"
    else:
        return "tool"
from langgraph.graph import END, StateGraph, START
graph = StateGraph(ReWOO)
graph.add_node("plan", get_plan)
graph.add_node("tool", tool_execution)
graph.add_node("solve", solve)
graph.add_edge("plan", "tool")
graph.add_edge("solve", END)
graph.add_conditional_edges("tool", _route)
graph.add_edge(START, "plan")
app = graph.compile()</pre><p class="list-inset">The provided code establishes an AI workflow using <strong class="source-inline">StateGraph</strong>, a data structure for managing<a id="_idIndexMarker1070"/> multi-step processes. The <strong class="source-inline">_route</strong> function acts as a conditional director, determining the next step based on<a id="_idIndexMarker1071"/> the current state. It checks if further tool-based actions are required; if not, it routes the process to the <strong class="source-inline">"solve"</strong> node for final answer generation. Otherwise, it directs it to the <strong class="source-inline">"tool"</strong> node for <span class="No-Break">tool execution.</span></p><p class="list-inset">Here, <strong class="source-inline">StateGraph</strong> defines the execution flow: starting with <strong class="source-inline">"plan"</strong> for strategy creation, proceeding to <strong class="source-inline">"tool"</strong> for external tool usage, and finally, to <strong class="source-inline">"solve"</strong> for result generation, culminating in the <strong class="source-inline">END</strong> state. The <strong class="source-inline">_route</strong> function’s conditional logic within the <strong class="source-inline">"tool"</strong> node is key, allowing dynamic routing based on the <span class="No-Break">task’s progression.</span></p><p class="list-inset"><strong class="source-inline">StateGraph</strong> is crucial for structured workflow management, enabling conditional branching for adaptive AI behavior, especially in tool-dependent tasks. It ensures logical action sequencing, improving robustness and clarity, and facilitating ReWOO’s planned execution. Compiling the graph into an <strong class="source-inline">"app"</strong> makes <span class="No-Break">it executable.</span></p></li>				<li>Let’s look at an example use case, and test the <span class="No-Break">ReWOO agent:</span><pre class="source-code">
task = "what is the exact hometown of the 2024 mens australian open winner"
for s in app.stream({"task": task}):
    print(s)
    print("---")</pre></li>			</ol>
			<p>The preceding code provides a simple implementation of the ReWOO framework using LangGraph. It defines the state, planner, executor, and solver modules, and connects them into a graph. This example <a id="_idIndexMarker1072"/>usage demonstrates how to run the <a id="_idIndexMarker1073"/>agent on a <span class="No-Break">sample task.</span></p>
			<h1 id="_idParaDest-273"><a id="_idTextAnchor342"/>Advantages of ReWOO</h1>
			<p>ReWOO offers several advantages<a id="_idIndexMarker1074"/> over traditional <span class="No-Break">ReAct-style agents:</span></p>
			<ul>
				<li><strong class="bold">Reduced token consumption and execution time</strong>: By generating the entire plan in a single pass and using variable substitution, ReWOO minimizes redundant LLM calls and <span class="No-Break">context passing</span></li>
				<li><strong class="bold">Simplified fine-tuning</strong>: The independence of the planning data from tool outputs (in theory) allows for fine-tuning without the need to invoke <span class="No-Break">the tools</span></li>
				<li><strong class="bold">Efficient LLM calls</strong>: The LLM tool receives less of the prompt, making calls more token-efficient compared to the <span class="No-Break">ReACT paradigm</span></li>
			</ul>
			<h1 id="_idParaDest-274"><a id="_idTextAnchor343"/>Evaluating quality and ethical considerations</h1>
			<p>Evaluating the quality of ReWOO’s reasoning can be challenging as it often deals with hypothetical scenarios. Possible <a id="_idIndexMarker1075"/>approaches include <span class="No-Break">the following:</span></p>
			<ul>
				<li><strong class="bold">Human evaluation</strong>: Using human experts to assess the coherence, relevance, and completeness of the generated plans <span class="No-Break">and reasoning</span></li>
				<li><strong class="bold">Comparison with ground truth</strong>: For scenarios with known outcomes, ReWOO’s predictions can be compared with <span class="No-Break">actual results</span></li>
				<li><strong class="bold">Benchmarking</strong>: Using standardized test sets designed to evaluate abstract reasoning and <span class="No-Break">planning capabilities</span></li>
			</ul>
			<p>It is also crucial to keep ethical considerations in mind while doing <span class="No-Break">any evaluation:</span></p>
			<ul>
				<li><strong class="bold">Bias amplification</strong>: ReWOO might inherit and amplify biases present in the training data of the <span class="No-Break">underlying LLM</span></li>
				<li><strong class="bold">Misuse potential</strong>: The ability to generate plans and reason about hypothetical scenarios could be misused for <span class="No-Break">malicious purposes</span></li>
				<li><strong class="bold">Overreliance</strong>: Users might <a id="_idIndexMarker1076"/>place too much trust in ReWOO’s outputs without considering their <span class="No-Break">speculative nature</span></li>
			</ul>
			<h1 id="_idParaDest-275"><a id="_idTextAnchor344"/>Future directions</h1>
			<p>As research progresses, ReWOO and related techniques will likely play an increasingly important role in the development of more capable and versatile AI systems. The following are some promising directions <span class="No-Break">for</span><span class="No-Break"><a id="_idIndexMarker1077"/></span><span class="No-Break"> ReWOO:</span></p>
			<ul>
				<li><strong class="bold">Human-in-the-loop systems</strong>: Integrating human oversight and feedback into the ReWOO framework to improve accuracy and address <span class="No-Break">ethical concerns</span></li>
				<li><strong class="bold">Improved planning algorithms</strong>: Developing more sophisticated planning algorithms that can handle more complex scenarios and larger <span class="No-Break">search spaces</span></li>
				<li><strong class="bold">Enhanced tool integration</strong>: Seamlessly integrating a wider range of tools, including specialized APIs and <span class="No-Break">knowledge bases</span></li>
				<li><strong class="bold">Multi-agent collaboration</strong>: Enabling multiple ReWOO agents to collaborate on complex tasks, potentially leading<a id="_idIndexMarker1078"/> to more robust and <span class="No-Break">diverse solutions</span></li>
				<li><strong class="bold">Meta-learning</strong>: Applying meta-learning techniques to improve the agent’s ability to generalize and adapt to new scenarios <span class="No-Break">over time</span></li>
			</ul>
			<h1 id="_idParaDest-276"><a id="_idTextAnchor345"/>Summary</h1>
			<p>This chapter delved into ReWOO, a framework designed to empower LLMs with the ability to reason about hypothetical situations and leverage external tools effectively. ReWOO utilizes a multi-step planner coupled with variable substitution, enabling it to generate comprehensive action plans in a single pass, thereby minimizing token consumption and execution time compared to the iterative “think-act-observe” cycle of ReAct agents. This chapter demonstrated the implementation of ReWOO using LangGraph, highlighting its architecture, components (planner, worker, solver), and advantages, such as simplified fine-tuning and efficient <span class="No-Break">LLM calls.</span></p>
			<p>Beyond simply reiterating the framework’s mechanics, this chapter emphasized ReWOO’s potential for strategic planning, scenario analysis, resource allocation, and risk assessment. However, it also touched upon the critical ethical considerations surrounding ReWOO, including the potential for bias amplification, misuse, and overreliance on its outputs. This chapter concluded with a view toward the future, discussing the need for human-in-the-loop systems, improved planning algorithms, enhanced tool integration, multi-agent collaboration, and the application of meta-learning techniques to further refine ReWOO’s capabilities and ensure responsible application in <span class="No-Break">real-world scenarios.</span></p>
			<p>In the next chapter, we will discuss techniques that enable LLMs to engage in self-reflection and <span class="No-Break">iterative improvement.</span></p>
		</div>
	</div></div></body></html>