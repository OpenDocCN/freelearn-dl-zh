<html><head></head><body><div><div><div><h1 id="_idParaDest-270" class="chapter-number"><a id="_idTextAnchor339"/>23</h1>
			<h1 id="_idParaDest-271"><a id="_idTextAnchor340"/>Reasoning WithOut Observation</h1>
			<p><strong class="bold">Reasoning WithOut Observation</strong> (<strong class="bold">ReWOO</strong>), proposed <a id="_idIndexMarker1046"/>by Xu et al. (<a href="https://arxiv.org/abs/2305.18323">https://arxiv.org/abs/2305.18323</a>), is a framework that combines a multi-step planner and variable substitution for effective tool use. It aims to improve upon ReAct-style agents by reducing token consumption and execution time by generating the full chain of tool usage in a single pass, thus minimizing redundant LLM calls. It also aims to simplify the fine-tuning process by enabling fine-tuning without actually invoking tools as planning data doesn’t depend on tool outputs (in theory).</p>
			<p>ReAct operates through a cyclical “think-act-observe” pattern, where an AI engages in reasoning, performs an action, examines the resulting feedback, and then adjusts its subsequent actions accordingly, facilitating a dynamic and responsive problem-solving strategy. In contrast, ReWOO emphasizes comprehensive upfront planning, generating a complete sequence of actions before any execution occurs, thereby minimizing the necessity for continuous observation and feedback. This distinction allows ReWOO to pursue greater efficiency by reducing token consumption and computational costs, shifting from ReAct’s iterative feedback loop to a more streamlined “plan-act” methodology.</p>
			<p>So, ReWOO refers to an LLM’s ability to make inferences, predictions, or decisions about scenarios it has not directly observed or been trained on. ReWOO enhances this by incorporating external tool use into the reasoning process.</p>
			<p>ReWOO’s ability to plan and reason without direct observation makes it suitable for complex planning and decision-making tasks:</p>
			<ul>
				<li><strong class="bold">Strategic planning</strong>: As mentioned, ReWOO can <a id="_idIndexMarker1047"/>generate strategic plans based on hypothetical situations, goals, and constraints</li>
				<li><strong class="bold">Scenario analysis</strong>: ReWOO can<a id="_idIndexMarker1048"/> explore multiple potential outcomes of a given scenario, considering various factors and uncertainties</li>
				<li><strong class="bold">Resource allocation</strong>: By planning tool use and reasoning about their results, ReWOO can optimize resource allocation in<a id="_idIndexMarker1049"/> complex environments</li>
				<li><strong class="bold">Risk assessment</strong>: ReWOO can help <a id="_idIndexMarker1050"/>assess potential risks and develop mitigation strategies by simulating different scenarios and their consequences</li>
			</ul>
			<p>In this chapter, we’ll be covering the following topics:</p>
			<ul>
				<li>Implementing ReWOO with LangGraph</li>
				<li>Advantages of ReWOO</li>
				<li>Evaluating quality and ethical considerations</li>
				<li>Future directions</li>
			</ul>
			<h1 id="_idParaDest-272"><a id="_idTextAnchor341"/>Implementing ReWOO with LangGraph</h1>
			<p>LangGraph is an open source framework<a id="_idIndexMarker1051"/> designed for building stateful, multi-agent applications using LLMs. It extends the capabilities of the LangChain ecosystem <a id="_idIndexMarker1052"/>by introducing a directed graph model, where nodes represent functions (including LLM invocations) and edges represent transitions between states based on logic, conditions, or memory. Unlike traditional sequential chains, LangGraph allows complex workflows involving conditional branching, loops, memory passing, and asynchronous agent coordination. LangGraph is particularly useful for implementing systems where interactions are dynamic, iterative, and dependent on state changes. This includes multi-agent collaboration, decision trees, retrieval-augmented generation with control flow, and autonomous agents that need to revisit prior steps or loop through subtasks until certain goals are met.</p>
			<p>LangGraph leverages concepts from graph theory and automata, representing execution flows as state machines or directed acyclic graphs (or cyclic graphs when loops are needed). Developers define a graph with nodes (functions or tools), edges (state transitions), and conditions (logic for routing). The runtime engine then executes the graph in response to inputs, updating the state at each step.</p>
			<p>LangGraph supports both synchronous and asynchronous execution, and it integrates with LangChain’s components, such as tools, memory, and agents. It also supports streaming responses, fine-grained control over state, and multi-modal inputs/outputs, making it suitable for production-level applications.</p>
			<p>In practice, LangGraph is used to build agentic systems where different agents interact, coordinate, and share memory, while still following a well-defined computational graph. This makes it different from naive agent loops or unstructured LLM orchestration methods.</p>
			<p>LangGraph is available at <a href="https://github.com/langchain-ai/langgraph">https://github.com/langchain-ai/langgraph</a> and supports Python-based implementation, with <a id="_idIndexMarker1053"/>core dependencies on LangChain and state machine execution frameworks.</p>
			<p>The ReWOO architecture consists of three modules:</p>
			<ul>
				<li><code>search_result</code> or <code>price</code>, the AI can construct a clear blueprint of the task, deferring the resolution of dynamic information until it becomes available, thereby streamlining the planning process and avoiding unnecessary computations.</li>
				<li><strong class="bold">Worker</strong>: Executes the tool with<a id="_idIndexMarker1057"/> the provided arguments, potentially using variable substitution from previous steps.</li>
				<li><strong class="bold">Solver</strong>: Generates the final <a id="_idIndexMarker1058"/>answer based on the tool observations and the plan.</li>
			</ul>
			<p>This architecture may seem a little abstract initially. Let’s implement ReWOO using LangGraph. We’ll use a Tavily search engine as an example tool:</p>
			<ol>
				<li>Install the necessary packages and set API keys:<pre class="source-code">
<strong class="bold"># %pip install -U langgraph langchain_community langchain_openai tavily-python</strong></pre><p class="list-inset">Tavily is a search engine designed specifically for AI agents. It’s built to provide accurate and reliable information retrieval, tailored to the needs of AI systems performing complex<a id="_idIndexMarker1059"/> tasks (see <a href="https://tavily.com/">https://tavily.com/</a>).</p><p class="list-inset">The following script <a id="_idIndexMarker1060"/>sets environment variables for API keys if they haven’t been defined yet:</p><pre class="source-code">import getpass
import os
def _set_if_undefined(var: str):
    if not os.environ.get(var):
        os.environ[var] = getpass.getpass(f"{var}=")
_set_if_undefined("TAVILY_API_KEY")
_set_if_undefined("OPENAI_API_KEY")</pre></li>				<li>Next, define the graph state. To do so, define the state dictionary so that it can hold the task, plan, steps, results, and final result:<pre class="source-code">
from typing import List
from typing_extensions import TypedDict
class ReWOO(TypedDict):
    task: str
    plan_string: str
    steps: List
    results: dict
    result: str</pre></li>				<li>Create the planner <a id="_idIndexMarker1061"/>prompt and logic:<pre class="source-code">
from langchain_openai import ChatOpenAI
model = ChatOpenAI(model="gpt-4o")
prompt = """For the following task, create a series of plans that can solve the problem step-by-step. For each plan, specify which external tool and its corresponding input should be used to gather evidence. You can store the evidence in a variable #E (e.g., #E1, #E2, #E3, etc.) that can be referenced by subsequent tools. Note that all the variables are independent, so make sure to include all necessary information in each tool input.
Tools can be one of the following:
Google[input]: A search engine worker that retrieves results from Google. Use this when you need concise answers or information about a specific topic. The input should be a search query.
LLM[input]: A pretrained Large Language Model (like me). Use this when you need to leverage general world knowledge, common sense, or perform complex reasoning. Prioritize this tool when you are confident in solving the problem without external assistance. The input can be any instruction or question.
Calculator[input]: A tool that can perform mathematical calculations. Use this when you need to perform arithmetic operations. The input should be a valid mathematical expression.
WolframAlpha[input]: A computational knowledge engine. Use this when you need to solve equations, perform symbolic calculations, or get data-driven answers. The input should be a query in Wolfram Language or natural language related to a math or science problem.
For example,
Task: Alice, Bob, and Carol earned a total of $540 from their part-time jobs last week. Alice earned y dollars. Bob earned $20 more than three times what Alice earned, and Carol earned $15 more than Bob. How much money did Carol earn?
Plan: Given Alice earned y dollars, translate the problem into algebraic expressions and solve with Wolfram Alpha.
#E1 = WolframAlpha[Solve y + (3y + 20) + ((3y + 20) + 15) = 540]
Plan: Find out the amount of money Alice earned.
#E2 = LLM[What is y, given #E1]
Plan: Calculate the amount of money Carol earned.
#E3 = Calculator[((3 * #E2) + 20) + 15]
Begin!
Describe your plans with rich details. Each Plan should be followed by only one #E.
Task: {task}"""</pre></li>				<li>Create <a id="_idIndexMarker1062"/>a LangGraph<a id="_idIndexMarker1063"/> node for the planner:<pre class="source-code">
import re
from langchain_core.prompts import ChatPromptTemplate
regex_pattern = (
    r"Plan:\s*(.+)\s*(#E\d+)\s*=\s*(\w+)\s*"
    r"\[([^\]]+)\]"
)
prompt_template = ChatPromptTemplate.from_messages(
    [("user", prompt)]
)
planner = prompt_template | model
def get_plan(state: ReWOO):
    task = state["task"]
    result = planner.invoke({"task": task})
    matches = re.findall(regex_pattern, result.content)
    return {"steps": matches, "plan_string": result.content}</pre></li>				<li>Instantiate the search <a id="_idIndexMarker1064"/>engine and define the tool <a id="_idIndexMarker1065"/>execution logic:<pre class="source-code">
from langchain_community.tools.tavily_search import TavilySearchResults
search = TavilySearchResults()
def _get_current_task(state: ReWOO):
    if "results" not in state or state["results"] is None:
        return 1
    if len(state["results"]) == len(state["steps"]):
        return None
    else:
        return len(state["results"]) + 1
def tool_execution(state: ReWOO):
    _step = _get_current_task(state)
    _, step_name, tool, tool_input = state["steps"][_step - 1]
    _results = (state["results"] or {}) if "results" in state else {}
    for k, v in _results.items():
        tool_input = tool_input.replace(k, v)
    if tool == "Google":
        result = search.invoke(tool_input)
    elif tool == "LLM":
        result = model.invoke(tool_input)
    else:
        raise ValueError
    _results[step_name] = str(result)
    return {"results": _results}</pre></li>				<li>Create the<a id="_idIndexMarker1066"/> solver prompt <a id="_idIndexMarker1067"/>and logic:<pre class="source-code">
solve_prompt = """Solve the following task or problem. To solve the problem, we have made step-by-step Plan and \
retrieved corresponding Evidence to each Plan. Use them with caution since long evidence might \
contain irrelevant information.
{plan}
Now solve the question or task according to provided Evidence above. Respond with the answer
directly with no extra words.
Task: {task}
Response:"""
def solve(state: ReWOO):
    plan = ""
    for _plan, step_name, tool, tool_input in state["steps"]:
        _results = (
            (state["results"] or {}) if "results" in state else {}
        )
        for k, v in _results.items():
            tool_input = tool_input.replace(k, v)
            step_name = step_name.replace(k, v)
        plan += (
            f"Plan: {_plan}\n"
            f"{step_name} = {tool}[{tool_input}]\n"
        )
    prompt = solve_prompt.format(plan=plan, task=state["task"])
    result = model.invoke(prompt)
    return {"result": result.content}</pre></li>				<li>Build the<a id="_idIndexMarker1068"/> LangGraph <a id="_idIndexMarker1069"/>workflow:<pre class="source-code">
def _route(state):
    _step = _get_current_task(state)
    if _step is None:
        return "solve"
    else:
        return "tool"
from langgraph.graph import END, StateGraph, START
graph = StateGraph(ReWOO)
graph.add_node("plan", get_plan)
graph.add_node("tool", tool_execution)
graph.add_node("solve", solve)
graph.add_edge("plan", "tool")
graph.add_edge("solve", END)
graph.add_conditional_edges("tool", _route)
graph.add_edge(START, "plan")
app = graph.compile()</pre><p class="list-inset">The provided code establishes an AI workflow using <code>StateGraph</code>, a data structure for managing<a id="_idIndexMarker1070"/> multi-step processes. The <code>_route</code> function acts as a conditional director, determining the next step based on<a id="_idIndexMarker1071"/> the current state. It checks if further tool-based actions are required; if not, it routes the process to the <code>"solve"</code> node for final answer generation. Otherwise, it directs it to the <code>"tool"</code> node for tool execution.</p><p class="list-inset">Here, <code>StateGraph</code> defines the execution flow: starting with <code>"plan"</code> for strategy creation, proceeding to <code>"tool"</code> for external tool usage, and finally, to <code>"solve"</code> for result generation, culminating in the <code>END</code> state. The <code>_route</code> function’s conditional logic within the <code>"tool"</code> node is key, allowing dynamic routing based on the task’s progression.</p><p class="list-inset"><code>StateGraph</code> is crucial for structured workflow management, enabling conditional branching for adaptive AI behavior, especially in tool-dependent tasks. It ensures logical action sequencing, improving robustness and clarity, and facilitating ReWOO’s planned execution. Compiling the graph into an <code>"app"</code> makes it executable.</p></li>				<li>Let’s look at an example use case, and test the ReWOO agent:<pre class="source-code">
task = "what is the exact hometown of the 2024 mens australian open winner"
for s in app.stream({"task": task}):
    print(s)
    print("---")</pre></li>			</ol>
			<p>The preceding code provides a simple implementation of the ReWOO framework using LangGraph. It defines the state, planner, executor, and solver modules, and connects them into a graph. This example <a id="_idIndexMarker1072"/>usage demonstrates how to run the <a id="_idIndexMarker1073"/>agent on a sample task.</p>
			<h1 id="_idParaDest-273"><a id="_idTextAnchor342"/>Advantages of ReWOO</h1>
			<p>ReWOO offers several advantages<a id="_idIndexMarker1074"/> over traditional ReAct-style agents:</p>
			<ul>
				<li><strong class="bold">Reduced token consumption and execution time</strong>: By generating the entire plan in a single pass and using variable substitution, ReWOO minimizes redundant LLM calls and context passing</li>
				<li><strong class="bold">Simplified fine-tuning</strong>: The independence of the planning data from tool outputs (in theory) allows for fine-tuning without the need to invoke the tools</li>
				<li><strong class="bold">Efficient LLM calls</strong>: The LLM tool receives less of the prompt, making calls more token-efficient compared to the ReACT paradigm</li>
			</ul>
			<h1 id="_idParaDest-274"><a id="_idTextAnchor343"/>Evaluating quality and ethical considerations</h1>
			<p>Evaluating the quality of ReWOO’s reasoning can be challenging as it often deals with hypothetical scenarios. Possible <a id="_idIndexMarker1075"/>approaches include the following:</p>
			<ul>
				<li><strong class="bold">Human evaluation</strong>: Using human experts to assess the coherence, relevance, and completeness of the generated plans and reasoning</li>
				<li><strong class="bold">Comparison with ground truth</strong>: For scenarios with known outcomes, ReWOO’s predictions can be compared with actual results</li>
				<li><strong class="bold">Benchmarking</strong>: Using standardized test sets designed to evaluate abstract reasoning and planning capabilities</li>
			</ul>
			<p>It is also crucial to keep ethical considerations in mind while doing any evaluation:</p>
			<ul>
				<li><strong class="bold">Bias amplification</strong>: ReWOO might inherit and amplify biases present in the training data of the underlying LLM</li>
				<li><strong class="bold">Misuse potential</strong>: The ability to generate plans and reason about hypothetical scenarios could be misused for malicious purposes</li>
				<li><strong class="bold">Overreliance</strong>: Users might <a id="_idIndexMarker1076"/>place too much trust in ReWOO’s outputs without considering their speculative nature</li>
			</ul>
			<h1 id="_idParaDest-275"><a id="_idTextAnchor344"/>Future directions</h1>
			<p>As research progresses, ReWOO and related techniques will likely play an increasingly important role in the development of more capable and versatile AI systems. The following are some promising directions for<a id="_idIndexMarker1077"/> ReWOO:</p>
			<ul>
				<li><strong class="bold">Human-in-the-loop systems</strong>: Integrating human oversight and feedback into the ReWOO framework to improve accuracy and address ethical concerns</li>
				<li><strong class="bold">Improved planning algorithms</strong>: Developing more sophisticated planning algorithms that can handle more complex scenarios and larger search spaces</li>
				<li><strong class="bold">Enhanced tool integration</strong>: Seamlessly integrating a wider range of tools, including specialized APIs and knowledge bases</li>
				<li><strong class="bold">Multi-agent collaboration</strong>: Enabling multiple ReWOO agents to collaborate on complex tasks, potentially leading<a id="_idIndexMarker1078"/> to more robust and diverse solutions</li>
				<li><strong class="bold">Meta-learning</strong>: Applying meta-learning techniques to improve the agent’s ability to generalize and adapt to new scenarios over time</li>
			</ul>
			<h1 id="_idParaDest-276"><a id="_idTextAnchor345"/>Summary</h1>
			<p>This chapter delved into ReWOO, a framework designed to empower LLMs with the ability to reason about hypothetical situations and leverage external tools effectively. ReWOO utilizes a multi-step planner coupled with variable substitution, enabling it to generate comprehensive action plans in a single pass, thereby minimizing token consumption and execution time compared to the iterative “think-act-observe” cycle of ReAct agents. This chapter demonstrated the implementation of ReWOO using LangGraph, highlighting its architecture, components (planner, worker, solver), and advantages, such as simplified fine-tuning and efficient LLM calls.</p>
			<p>Beyond simply reiterating the framework’s mechanics, this chapter emphasized ReWOO’s potential for strategic planning, scenario analysis, resource allocation, and risk assessment. However, it also touched upon the critical ethical considerations surrounding ReWOO, including the potential for bias amplification, misuse, and overreliance on its outputs. This chapter concluded with a view toward the future, discussing the need for human-in-the-loop systems, improved planning algorithms, enhanced tool integration, multi-agent collaboration, and the application of meta-learning techniques to further refine ReWOO’s capabilities and ensure responsible application in real-world scenarios.</p>
			<p>In the next chapter, we will discuss techniques that enable LLMs to engage in self-reflection and iterative improvement.</p>
		</div>
	</div></div></body></html>