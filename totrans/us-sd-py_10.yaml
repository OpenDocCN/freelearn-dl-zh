- en: '10'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '10'
- en: Overcoming 77-Token Limitations and Enabling Prompt Weighting
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 克服 77 个标记限制并启用提示加权
- en: From [*Chapter 5*](B21263_05.xhtml#_idTextAnchor097), we know that Stable Diffusion
    utilizes OpenAI’s CLIP model as its text encoder. The CLIP model’s tokenization
    implementation, as per the source code [6], has a context length of 77 tokens.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 从 [*第 5 章*](B21263_05.xhtml#_idTextAnchor097)，我们知道稳定扩散利用 OpenAI 的 CLIP 模型作为其文本编码器。根据源代码
    [6]，CLIP 模型的标记化实现具有 77 个标记的上下文长度。
- en: This 77-token limit in the CLIP model extends to Hugging Face Diffusers, restricting
    the maximum input prompt to 77 tokens. Unfortunately, it’s not possible to assign
    keyword weights within these input prompts due to this constraint without some
    modifications.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: CLIP 模型中的这个 77 个标记限制扩展到 Hugging Face Diffusers，限制了最大输入提示为 77 个标记。不幸的是，由于这个限制，无法在不进行一些修改的情况下在这些输入提示中分配关键词权重。
- en: 'For instance, let’s say you give a prompt string that produces more than 77
    tokens, like this:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设你给出一个产生超过 77 个标记的提示字符串，如下所示：
- en: '[PRE0]'
  id: totrans-5
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Diffusers will show up a warning message, like this:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Diffusers 将显示一个警告消息，如下所示：
- en: '[PRE1]'
  id: totrans-7
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'You can’t highlight the cat by providing the weight, such as in the following:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 你不能通过提供权重来突出显示猫，如下所示：
- en: '[PRE2]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: By default, the `Diffusers` package does not include functionality for overcoming
    the 77-token limitation or assigning weights to individual tokens, as stated in
    its documentation. This is because Diffusers aims to serve as a versatile toolbox,
    providing essential features that can be utilized in various projects.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，`Diffusers` 包不包括克服 77 个标记限制或为单个标记分配权重的功能，正如其文档所述。这是因为 Diffusers 旨在作为一个通用的工具箱，提供可以在各种项目中使用的必要功能。
- en: Nonetheless, using the core functionalities offered by Diffusers, we can develop
    a custom prompt parser. This parser will help us circumvent the 77-token restriction
    and assign weights to each token. In this chapter, we will delve into the structure
    of text embeddings and outline a method to surpass the 77-token limit while also
    assigning weight values to each token.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，通过使用 Diffusers 提供的核心功能，我们可以开发一个自定义提示解析器。这个解析器将帮助我们绕过 77 个标记的限制并为每个标记分配权重。在本章中，我们将深入探讨文本嵌入的结构，并概述一种方法来超越
    77 个标记的限制，同时为每个标记分配权重值。
- en: 'In this chapter, we will cover the following:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下内容：
- en: Understanding the 77-token limitation
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解 77 个标记限制
- en: Overcoming the 77-token limitation
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 克服 77 个标记限制
- en: Enabling long prompts with weighting
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 启用带权重的长提示
- en: Overcoming the 77-token limitation using community pipelines
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用社区管道克服 77 个标记限制
- en: If you want to start using a full feature pipeline supporting long prompt weighting,
    please turn to the *Overcoming the 77-token limitation using the community* *pipelines*
    section.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要开始使用支持长提示加权的完整功能管道，请参阅 *使用社区 *pipelines* 部分克服 77 个标记限制。
- en: By the end of the chapter, you will be able to use weighted prompts without
    size limitations and know how to implement them using Python.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将能够使用无大小限制的加权提示，并了解如何使用 Python 实现它们。
- en: Understanding the 77-token limitation
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解 77 个标记限制
- en: 'The Stable Diffusion (v1.5) text encoder uses the CLIP encoder from OpenAI
    [*2*]. The CLIP text encoder has a 77-token limit, and this limitation propagates
    to the downstream Stable Diffusion. We can reproduce the 77-token limitation with
    the following steps:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 稳定扩散（v1.5）文本编码器使用 OpenAI 的 CLIP 编码器 [*2*]。CLIP 文本编码器有一个 77 个标记的限制，这个限制传播到下游的稳定扩散。我们可以通过以下步骤重现
    77 个标记的限制：
- en: 'We can take out the encoder from Stable Diffusion and verify it. Let’s say
    we have the prompt `a photo of a cat and dog driving an aircraft` and we multiply
    it by 20 to make the prompt’s token size larger than 77:'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以从稳定扩散中取出编码器并验证它。假设我们有提示 `一张猫和狗驾驶飞机的照片` 并将其乘以 20 以使提示的标记大小超过 77：
- en: '[PRE3]'
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Reuse the pipeline we initialized at the beginning of the chapter and take
    out `tokenizer` and `text_encoder`:'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新使用本章开头初始化的管道，并取出 `tokenizer` 和 `text_encoder`：
- en: '[PRE4]'
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Use `tokenizer` to get the token IDs from the prompt:'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `tokenizer` 从提示中获取标记 ID：
- en: '[PRE6]'
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Since we set `truncation = False`, `tokenizer` will convert any length string
    to token IDs. The preceding code will output a token list with a length of 181\.
    `return_tensors = 'pt'` will tell the function to return the result in a `[1,181]`
    tensor object.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于我们设置了 `truncation = False`，`tokenizer` 将将任何长度的字符串转换为标记 ID。前面的代码将输出一个长度为 181
    的标记列表。`return_tensors = 'pt'` 将告诉函数以 `[1,181]` 张量对象的形式返回结果。
- en: 'Try encoding the token IDs to `embeddings`:'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 尝试将标记 ID 编码为 `embeddings`：
- en: '[PRE12]'
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'We will see a `RuntimeError` message that says the following:'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将看到一个`RuntimeError`错误消息，内容如下：
- en: '[PRE13]'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: From the preceding steps, we can see that CLIP’s text encoder only accepts 77
    tokens at a time.
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从前面的步骤中，我们可以看到CLIP的文本编码器一次只能接受77个标记。
- en: 'Now, let’s take a look at the first and last tokens. If we take away `*20`
    and only tokenize the prompt `a photo cat and dog driving an aircraft`, when we
    print out the token IDs, we will see 10 token IDs instead of 8:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们看看第一个和最后一个标记。如果我们去掉`*20`，只对提示`a photo cat and dog driving an aircraft`进行分词，当我们打印出标记ID时，我们将看到10个标记ID而不是8个：
- en: '[PRE14]'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'In the preceding token IDs, the first (`49406`) and last (`49407`) are automatically
    added. We can use `tokenizer._convert_id_to_token` to convert the token IDs to
    a string:'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在前面的标记ID中，第一个（`49406`）和最后一个（`49407`）是自动添加的。我们可以使用`tokenizer._convert_id_to_token`将标记ID转换为字符串：
- en: '[PRE15]'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'We can see that the two additional tokens are added to the prompt:'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以看到两个额外的标记被添加到提示中：
- en: '[PRE17]'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Why do we need to check this? Because we need to remove the automatically added
    beginning and end tokens when concatenating tokens. Next, let’s proceed to the
    steps to overcome the 77-token limitation.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么我们需要检查这个？因为当我们连接标记时，我们需要移除自动添加的开始和结束标记。接下来，让我们继续进行克服77个标记限制的步骤。
- en: Overcoming the 77-tokens limitation
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 克服77个标记的限制
- en: 'Fortunately, the Stable Diffusion UNet doesn’t enforce this 77-token limitation.
    If we can get the embeddings in batches, concatenate those chunked embeddings
    into one tensor, and provide it to the UNet, we should be able to overcome the
    77-token limitation. Here’s an overview of the process:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，Stable Diffusion UNet不强制执行这个77个标记的限制。如果我们能够分批获取嵌入，将那些分块的嵌入连接成一个张量，并将其提供给UNet，我们应该能够克服77个标记的限制。以下是这个过程的大致概述：
- en: Extract the text tokenizer and text encoder from the Stable Diffusion pipeline.
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从Stable Diffusion管道中提取文本分词器和文本编码器。
- en: Tokenize the input prompt, regardless of its size.
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 不论其大小如何，对输入提示进行分词。
- en: Eliminate the added beginning and end tokens.
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 消除添加的开始和结束标记。
- en: Pop out the first 77 tokens and encode them into embeddings.
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取前77个标记并将它们编码成嵌入。
- en: Stack the embeddings into a tensor of size `[1,` `x, 768]`.
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将嵌入堆叠成一个大小为`[1, x, 768]`的张量。
- en: 'Now, let’s implement this idea using Python code:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们使用Python代码来实现这个想法：
- en: 'Take out the text tokenizer and text encoder:'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取文本分词器和文本编码器：
- en: '[PRE19]'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[PRE20]'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[PRE21]'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: We can reuse the tokenizer and text encoder from the Stable Diffusion pipeline.
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以重用Stable Diffusion管道中的分词器和文本编码器。
- en: 'Tokenize any size of input prompt:'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 分词任何大小的输入提示：
- en: '[PRE22]'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[PRE23]'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '[PRE24]'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[PRE25]'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '[PRE28]'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '[PRE29]'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '[PRE30]'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '[PRE31]'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '[PRE32]'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '[PRE33]'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '[PRE34]'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '[PRE35]'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '[PRE36]'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '[PRE37]'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'In the preceding code, we did the following:'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们做了以下操作：
- en: We set `truncation = False` to allow tokenization beyond the default 77-token
    limit. This ensures that the entire prompt is tokenized, regardless of its size.
  id: totrans-79
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将`truncation = False`设置为允许分词超过默认的77个标记限制。这确保了无论提示的大小如何，整个提示都会被分词。
- en: The tokens are returned as a Python list instead of a torch tensor. Tokens in
    the Python list will make it easier for us to add additional elements. Note that
    the token list will be converted to a torch tensor before providing it to the
    text encoder.
  id: totrans-80
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标记作为Python列表返回，而不是torch张量。Python列表中的标记将使我们更容易添加额外的元素。请注意，在提供给文本编码器之前，标记列表将被转换为torch张量。
- en: There are two additional parameters, `padding = "max_length"` and `max_length
    = len(tokens)`. We use these to make sure prompt tokens and negative prompt tokens
    are the same size.
  id: totrans-81
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有两个额外的参数，`padding = "max_length"`和`max_length = len(tokens)`。我们使用这些参数确保提示标记和负提示标记的大小相同。
- en: Remove the beginning and end tokens.
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 移除开始和结束标记。
- en: 'The tokenizer will automatically add two additional tokens: the beginning token
    (`49406`) and the end token (`49407`).'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 分词器将自动添加两个额外的标记：开始标记（`49406`）和结束标记（`49407`）。
- en: 'In the subsequent step, we will segment the token sequence and feed the chunked
    tokens to the text encoder. Each chunk will have its own beginning and end tokens.
    But before that, we will need to exclude them initially from the long original
    token list:'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在后续步骤中，我们将分割标记序列并将分块标记输入到文本编码器中。每个块将有自己的开始和结束标记。但在那之前，我们需要从原始的长标记列表中最初排除它们：
- en: '[PRE38]'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '[PRE39]'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: And then add these beginning and end tokens back to the chunked tokens, each
    chunk with a size of size `75`. We will add the beginning and the end tokens back
    in *step 4*.
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 然后将这些开始和结束标记添加回分块标记中，每个块的大小为`75`。我们将在第4步将开始和结束标记添加回去。
- en: 'Encode the 77-sized chunked tokens into embeddings:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将77个大小的分块标记编码成嵌入：
- en: '[PRE40]'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '[PRE41]'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '[PRE42]'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '[PRE43]'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '[PRE44]'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '[PRE45]'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '[PRE46]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '[PRE47]'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '[PRE48]'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: '[PRE49]'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: '[PRE50]'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: '[PRE51]'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: '[PRE52]'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: '[PRE53]'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: '[PRE54]'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: '[PRE55]'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: '[PRE56]'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '[PRE57]'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: '[PRE58]'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: '[PRE59]'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: '[PRE60]'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: '[PRE61]'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: '[PRE62]'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: '[PRE63]'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: '[PRE64]'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: '[PRE65]'
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: '[PRE66]'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE66]'
- en: '[PRE67]'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE67]'
- en: '[PRE68]'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE68]'
- en: '[PRE69]'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE69]'
- en: '[PRE70]'
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE70]'
- en: The preceding code loops through the token list, taking out 75 tokens at a time.
    Then, it adds the beginning and end tokens to the 75-token list to create a 77-token
    list. Why 77 tokens? Because the text encoder can encode 77 tokens to embeddings
    at one time.
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 前面的代码通过token列表循环，每次取出75个token。然后，它将起始和结束token添加到75个token的列表中，以创建一个77个token的列表。为什么是77个token？因为文本编码器一次可以编码77个token到嵌入中。
- en: Inside the `for` loop, the first part handles the prompt embeddings, and the
    second part handles the negative embeddings. Even though we give an empty negative
    prompt, to enable classification-free guidance diffusion, we still need a negative
    embedding list with the same size of positive prompt embeddings (inside of the
    denoising loop, the conditioned latent will subtract the unconditional latent,
    which is generated from the negative prompt).
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在 `for` 循环内部，第一部分处理提示嵌入，第二部分处理负嵌入。尽管我们提供了一个空的负提示，为了启用无分类指导扩散，我们仍然需要一个与正提示嵌入大小相同的负嵌入列表（在去噪循环中，条件潜在将减去由无提示生成的无条件潜在）。
- en: Stack the embeddings to a `[1,x,768]` size torch tensor.
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将嵌入堆叠到 `[1,x,768]` 大小的torch张量。
- en: 'Before this step, the `embeds` list holds data like this:'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这一步之前，`embeds` 列表包含如下数据：
- en: '[PRE71]'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE71]'
- en: The Stable Diffusion pipeline’s embedding parameters accept tensors in the size
    of `torch.Size([1,x,768])`.
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Stable Diffusion流水线的嵌入参数接受大小为`torch.Size([1,x,768])`的张量。
- en: 'We still need to convert the list to a three-dimension tensor using these two
    lines of code:'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们仍然需要使用这两行代码将这些列表转换为三维张量：
- en: '[PRE72]'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE72]'
- en: '[PRE73]'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE73]'
- en: '[PRE74]'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'In the preceding code, we have the following:'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们有以下内容：
- en: '`embeds` and `neg_embeds` are lists of PyTorch tensors. The `torch.cat()` function
    is used to concatenate these tensors along the dimension specified by `dim`. In
    this case, we have `dim=1`, which means the tensors are concatenated along their
    second dimension (since Python uses 0-based indexing).'
  id: totrans-131
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`embeds` 和 `neg_embeds` 是PyTorch张量的列表。`torch.cat()` 函数用于沿着由 `dim` 指定的维度连接这些张量。在这种情况下，我们有
    `dim=1`，这意味着张量是在它们的第二个维度上连接的（因为Python使用0基于索引）。'
- en: '`prompt_embeds` is a tensor that contains all the embeddings from `embeds`
    concatenated together. Similarly, `prompt_neg_embeds` contains all the embeddings
    from `neg_embeds` concatenated together.'
  id: totrans-132
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt_embeds` 是一个包含`embeds`中所有嵌入的张量。同样，`prompt_neg_embeds` 包含`neg_embeds`中所有嵌入的张量。'
- en: By now, we have a functioning text encoder that can convert whatever length
    of prompt to embeddings, which can be used by a Stable Diffusion pipeline. Next,
    let’s put all the code together.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经有一个可以转换任何长度提示到嵌入的文本编码器，这些嵌入可以被Stable Diffusion流水线使用。接下来，让我们将所有代码放在一起。
- en: Putting all the code together into a function
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将所有代码组合到一个函数中
- en: 'Let’s go a step further to put all the previous code in a packed function:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更进一步，将所有之前的代码放入一个打包的函数中：
- en: '[PRE75]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'Let’s create a long prompt to test whether the preceding function works or
    not:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建一个长提示来测试前面的函数是否工作：
- en: '[PRE76]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'The result is shown in *Figure 10**.1*:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如*图10.1*所示：
- en: '![Figure 10.1: Cute cat running on the grass, using a long prompt](img/B21263_10_01.jpg)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![图10.1：可爱的小猫在草地上奔跑，使用了长提示](img/B21263_10_01.jpg)'
- en: 'Figure 10.1: Cute cat running on the grass, using a long prompt'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.1：可爱的小猫在草地上奔跑，使用了长提示
- en: 'If our new function works for long prompts, the generated image should reflect
    additional appended prompts. Let’s extend the prompt to the following:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们的新函数对长提示有效，生成的图像应该反映附加的提示信息。让我们将提示信息扩展到以下内容：
- en: '[PRE77]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'The new prompt will generate an image as shown in *Figure 10**.2*:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 新的提示信息将生成如*图10.2*所示的图像：
- en: '![Figure 10.2: Cute cat running on the grass, with the additional prompt of
    pure white cat](img/B21263_10_02.jpg)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![图10.2：可爱的小猫在草地上奔跑，附加了纯白色猫的提示](img/B21263_10_02.jpg)'
- en: 'Figure 10.2: Cute cat running on the grass, with the additional prompt of pure
    white cat'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.2：可爱的小猫在草地上奔跑，附加了纯白色猫的提示
- en: As you can see, the new appended prompt works and there are more white elements
    added to the cat; however, it is still not pure white as requested in the prompt.
    We will solve this with prompt weighting, which we’ll cover in the upcoming section.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，新添加的提示信息工作正常，并且为猫添加了更多白色元素；然而，它仍然不是提示信息中要求的纯白色。我们将通过提示权重来解决此问题，我们将在下一节中介绍。
- en: Enabling long prompts with weighting
  id: totrans-148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 启用带权重的长提示
- en: We just built a whatever size of text encoder for a Stable Diffusion pipeline
    (v1.5-based). All of those steps are paving the way to build long prompts with
    a weighting text encoder.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚为基于Stable Diffusion管道（v1.5版）构建了任意大小的文本编码器。所有这些步骤都是为构建带有加权文本编码器的长提示铺路。
- en: A weighted Stable Diffusion prompt refers to the practice of assigning different
    levels of importance to specific words or phrases within a text prompt used for
    generating images through the Stable Diffusion algorithm. By adjusting these weights,
    we can control the degree to which certain concepts influence the generated output,
    allowing for greater customization and refinement of the resulting images.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 加权Stable Diffusion提示是指为用于通过Stable Diffusion算法生成图像的文本提示中的特定单词或短语分配不同的重要性级别。通过调整这些权重，我们可以控制某些概念对生成输出的影响程度，从而实现图像的更大定制和细化。
- en: The process typically involves scaling up or down the text embedding vectors
    associated with each concept in the prompt. For instance, if you want the Stable
    Diffusion model to emphasize a particular subject while deemphasizing another,
    you would increase the weight of the former and decrease the weight of the latter.
    Weighted prompts enable us to better direct the image generation toward desired
    outcomes.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 该过程通常涉及放大或缩小与提示中每个概念相关的文本嵌入向量。例如，如果您想使Stable Diffusion模型强调某个特定主题，同时降低另一个主题的强调，您将增加前者的权重并减少后者的权重。加权提示使我们能够更好地引导图像生成，以达到期望的结果。
- en: 'The core of adding weight to the prompt is simply vector multiplication:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 为提示添加权重的核心仅仅是向量乘法：
- en: weighted _ embeddings = [embedding1, embedding2, ..., embedding768] × weight
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 加权 _ 嵌入 = [embedding1, embedding2, ..., embedding768] × 权重
- en: 'Before that, we still need to do some preparations to make a weighted prompt
    embedding, as follows:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在此之前，我们仍需要进行一些准备工作以创建加权提示嵌入，如下所示：
- en: '`a (white) cat` into a list like this: `[[''a '', 1.0], [''white'', 1.1], [''cat'',
    1.0]]`. We’ll adopt the prevalent prompt format used in the Automatic1111 **Stable
    Diffusion** (**SD**) WebUI, as defined in the open source SD WebUI [4].'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`a (white) cat`转换成如下列表：`[['a ', 1.0], ['white', 1.1], ['cat', 1.0]]`。我们将采用在Automatic1111
    **Stable Diffusion** (**SD**) WebUI中广泛使用的提示格式，如开源SD WebUI[4]中定义的那样。
- en: '**Token and weight extraction**: Separate the token IDs and their corresponding
    weights into two distinct lists.'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**标记和权重提取**：将标记ID及其对应的权重分别放入两个不同的列表中。'
- en: '**Prompt and negative prompt padding**: Ensure that both the prompt and negative
    prompt tokens have the same maximum length. If the prompt is longer than the negative
    prompt, pad the negative prompt to match the prompt’s length. Otherwise, pad the
    prompt to align with the negative prompt’s length.'
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**提示和负提示填充**：确保提示和负提示标记具有相同的最大长度。如果提示比负提示长，则将负提示填充到与提示相同的长度。否则，将提示填充以与负提示的长度对齐。'
- en: 'Regarding attention and emphasis (weighting), we will implement the following
    weighting format [4]:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 关于注意力和强调（权重），我们将实现以下权重格式[4]：
- en: '[PRE78]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'Let’s go through each of those steps in more detail:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地了解这些步骤：
- en: Build the `parse_prompt_attention` function.
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建名为`parse_prompt_attention`的函数。
- en: 'To make sure the prompt format is fully compatible with Automatic1111’s SD
    WebUI, we will extract and reuse the function from the open sourced `parse_prompt_attention`
    function [3]:'
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了确保提示格式与Automatic1111的SD WebUI完全兼容，我们将从开源的`parse_prompt_attention`函数[3]中提取并重用该函数：
- en: '[PRE79]'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE79]'
- en: '[PRE80]'
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE80]'
- en: '[PRE81]'
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE81]'
- en: '[PRE82]'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE82]'
- en: '[PRE83]'
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE83]'
- en: '[PRE84]'
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE84]'
- en: '[PRE85]'
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE85]'
- en: '[PRE86]'
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE86]'
- en: '[PRE87]'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE87]'
- en: '[PRE88]'
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE88]'
- en: '[PRE89]'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE89]'
- en: '[PRE90]'
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE90]'
- en: '[PRE91]'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE91]'
- en: '[PRE92]'
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE92]'
- en: '[PRE93]'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE93]'
- en: '[PRE94]'
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE94]'
- en: '[PRE95]'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE95]'
- en: '[PRE96]'
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE96]'
- en: '[PRE97]'
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE97]'
- en: '[PRE98]'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE98]'
- en: '[PRE99]'
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE99]'
- en: '[PRE100]'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE100]'
- en: '[PRE101]'
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE101]'
- en: '[PRE102]'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE102]'
- en: '[PRE103]'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE103]'
- en: '[PRE104]'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE104]'
- en: '[PRE105]'
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE105]'
- en: '[PRE106]'
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE106]'
- en: '[PRE107]'
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE107]'
- en: '[PRE108]'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE108]'
- en: '[PRE109]'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE109]'
- en: '[PRE110]'
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE110]'
- en: '[PRE111]'
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE111]'
- en: '[PRE112]'
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE112]'
- en: '[PRE113]'
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE113]'
- en: '[PRE114]'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE114]'
- en: '[PRE115]'
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE115]'
- en: '[PRE116]'
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE116]'
- en: '[PRE117]'
  id: totrans-201
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE117]'
- en: '[PRE118]'
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE118]'
- en: '[PRE119]'
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE119]'
- en: '[PRE120]'
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE120]'
- en: '[PRE121]'
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE121]'
- en: '[PRE122]'
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE122]'
- en: '[PRE123]'
  id: totrans-207
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE123]'
- en: '[PRE124]'
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE124]'
- en: '[PRE125]'
  id: totrans-209
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE125]'
- en: '[PRE126]'
  id: totrans-210
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE126]'
- en: '[PRE127]'
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE127]'
- en: '[PRE128]'
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE128]'
- en: '[PRE129]'
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE129]'
- en: '[PRE130]'
  id: totrans-214
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE130]'
- en: '[PRE131]'
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE131]'
- en: '[PRE132]'
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE132]'
- en: '[PRE133]'
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE133]'
- en: '[PRE134]'
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE134]'
- en: 'Call the previously created function using the following:'
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用以下方式调用先前创建的函数：
- en: '[PRE135]'
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE135]'
- en: 'This will return the following:'
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将返回以下内容：
- en: '[PRE136]'
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE136]'
- en: Get prompts with weights.
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取带有权重的提示。
- en: 'With the help of the preceding function, we can get a list of prompt and weight
    pairs. The text encoder will only encode the tokens of the prompt (no, you don’t
    need to provide weights as input to the text encoder). We will need to further
    process the prompt-weight pair to two independent lists with the same size, one
    for token IDs and one for weights, like this:'
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在前述函数的帮助下，我们可以得到一组提示和权重对的列表。文本编码器将仅对提示中的标记进行编码（不需要将权重作为输入提供给文本编码器）。我们需要进一步处理提示-权重对，将其转换为两个大小相同的独立列表，一个用于标记ID，一个用于权重，如下所示：
- en: '[PRE137]'
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE137]'
- en: '[PRE138]'
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE138]'
- en: 'This work can be done by the following function:'
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这可以通过以下函数来完成：
- en: '[PRE139]'
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE139]'
- en: '[PRE140]'
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE140]'
- en: '[PRE141]'
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE141]'
- en: '[PRE142]'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE142]'
- en: '[PRE143]'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE143]'
- en: '[PRE144]'
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE144]'
- en: '[PRE145]'
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE145]'
- en: '[PRE146]'
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE146]'
- en: '[PRE147]'
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE147]'
- en: '[PRE148]'
  id: totrans-237
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE148]'
- en: '[PRE149]'
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE149]'
- en: '[PRE150]'
  id: totrans-239
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE150]'
- en: '[PRE151]'
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE151]'
- en: '[PRE152]'
  id: totrans-241
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE152]'
- en: '[PRE153]'
  id: totrans-242
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE153]'
- en: '[PRE154]'
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE154]'
- en: '[PRE155]'
  id: totrans-244
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE155]'
- en: '[PRE156]'
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE156]'
- en: '[PRE157]'
  id: totrans-246
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE157]'
- en: '[PRE158]'
  id: totrans-247
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE158]'
- en: '[PRE159]'
  id: totrans-248
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE159]'
- en: '[PRE160]'
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE160]'
- en: '[PRE161]'
  id: totrans-250
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE161]'
- en: '[PRE162]'
  id: totrans-251
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE162]'
- en: '[PRE163]'
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE163]'
- en: '[PRE164]'
  id: totrans-253
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE164]'
- en: '[PRE165]'
  id: totrans-254
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE165]'
- en: 'The preceding function takes two parameters: the SD pipeline and the prompt
    string. The input string can be the positive prompt or the negative prompt.'
  id: totrans-255
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 前述函数接受两个参数：SD管道和提示字符串。输入字符串可以是正提示或负提示。
- en: Inside the function body, we first call the `parse_prompt_attention` function
    to have the prompts with weight associated in the smallest grain (The weight is
    applied in the individual token level). Then, we loop through the list, tokenize
    the text, and remove the tokenizer-added beginning and end token IDs with the
    indexing operation, `[1:-1]`.
  id: totrans-256
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在函数体内，我们首先调用`parse_prompt_attention`函数，以最小的粒度（权重应用于单个标记级别）关联带有权重的提示。然后，我们遍历列表，对文本进行标记化，并使用索引操作`[1:-1]`移除标记器添加的开始和结束标记ID。
- en: Merge the new token IDs back to the list that holds all token IDs. In the meantime,
    expand the weights number and merge back to the list that holds all weights numbers.
  id: totrans-257
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 将新的标记ID合并回包含所有标记ID的列表。同时，扩展权重数量并将其合并回包含所有权重数字的列表。
- en: 'Let’s reuse the prompt of `a (white) cat` and call the function:'
  id: totrans-258
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 让我们重用“一只（白色）猫”的提示并调用该函数：
- en: '[PRE166]'
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE166]'
- en: '[PRE167]'
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE167]'
- en: '[PRE168]'
  id: totrans-261
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE168]'
- en: 'The preceding code will return the following:'
  id: totrans-262
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 前面的代码将返回以下内容：
- en: '[PRE169]'
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE169]'
- en: Notice that the second token ID from `white` now has a weight of `1.1` instead
    of `1.0`.
  id: totrans-264
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意到“白色”的第二个标记ID现在权重为`1.1`而不是`1.0`。
- en: Pad the tokens.
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 填充标记。
- en: In this step, we will further transform the token ID list and its weights into
    a chunked list.
  id: totrans-266
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这一步，我们将进一步将标记ID列表及其权重转换为分块列表。
- en: 'Let’s say we have a list of token IDs containing more than 77 elements:'
  id: totrans-267
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 假设我们有一个包含超过77个元素的标记ID列表：
- en: '`[``1,2,3,...,100]`'
  id: totrans-268
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`[``1,2,3,...,100]`'
- en: 'We need to transform it into a list that includes chunks, with 77 (maximum)
    tokens inside each chunk:'
  id: totrans-269
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们需要将其转换为包含分块的列表，每个块包含最多77个（最大）标记：
- en: '`[[``49406,1,2...75,49407],[49406,76,77,...,100,49407]]`'
  id: totrans-270
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`[[``49406,1,2...75,49407],[49406,76,77,...,100,49407]]`'
- en: This is so that, in the next step, we can loop through the outer layer of the
    list and encode the 77-token list one at a time.
  id: totrans-271
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这样做是为了在下一步中，我们可以遍历列表的外层，并逐个编码77个标记的列表。
- en: Now, you may wonder why we need to provide a maximum of 77 tokens to the text
    encoder at a time. What if we simply loop through each element and encode one
    token at a time? Good question, but we can’t do it like this because encoding
    `white` and then encoding `cat` will produce different embeddings compared with
    encoding `white cat` together at one time.
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，你可能想知道为什么我们需要一次向文本编码器提供最多77个标记。如果我们简单地循环每个元素并逐个编码一个标记会怎样？这是一个好问题，但我们不能这样做，因为单独编码“白色”然后编码“猫”将产生与一次一起编码“白色猫”不同的嵌入。
- en: 'We can use a quick test to find out the difference. First, let’s encode `white`
    only:'
  id: totrans-273
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以通过快速测试来找出差异。首先，让我们只编码“白色”：
- en: '[PRE170]'
  id: totrans-274
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE170]'
- en: '[PRE171]'
  id: totrans-275
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE171]'
- en: '[PRE172]'
  id: totrans-276
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE172]'
- en: '[PRE173]'
  id: totrans-277
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE173]'
- en: '[PRE174]'
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE174]'
- en: '[PRE175]'
  id: totrans-279
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE175]'
- en: '[PRE176]'
  id: totrans-280
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE176]'
- en: '[PRE177]'
  id: totrans-281
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE177]'
- en: '[PRE178]'
  id: totrans-282
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE178]'
- en: 'Then, encode `white` `cat` together:'
  id: totrans-283
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 然后，一起编码“白色”和“猫”：
- en: '[PRE179]'
  id: totrans-284
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE179]'
- en: '[PRE180]'
  id: totrans-285
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE180]'
- en: '[PRE181]'
  id: totrans-286
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE181]'
- en: '[PRE182]'
  id: totrans-287
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE182]'
- en: '[PRE183]'
  id: totrans-288
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE183]'
- en: '[PRE184]'
  id: totrans-289
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE184]'
- en: '[PRE185]'
  id: totrans-290
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE185]'
- en: '[PRE186]'
  id: totrans-291
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE186]'
- en: '[PRE187]'
  id: totrans-292
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE187]'
- en: Give the preceding code a try; you will find that the same `white` will lead
    to a different embedding. What is the root cause? The token and embedding is not
    a one-to-one mapping; the embedding is generated based on the self-attention mechanism
    [5]. A single `white` can represent the color or a family name, while `white`
    in `white cat` is clearly saying that it is a color that describes the cat.
  id: totrans-293
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 尝试运行前面的代码；你会发现相同的“白色”会导致不同的嵌入。根本原因是什么？标记和嵌入不是一对一的映射；嵌入是基于自注意力机制[5]生成的。单个“白色”可以代表颜色或姓氏，而“白色猫”中的“白色”显然是在说这是一个描述猫的颜色。
- en: 'Let’s get back to the padding work. The following code will check the length
    of the token list. If the token ID list length is larger than 75, then take the
    first 75 tokens and loop this operation the remaining tokens are fewer than 75,
    which will be handled by a separate logic:'
  id: totrans-294
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 让我们回到填充工作。以下代码将检查标记列表的长度。如果标记ID列表长度大于75，则取前75个标记并循环此操作，剩余的标记少于75个，将由单独的逻辑处理：
- en: '[PRE188]'
  id: totrans-295
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE188]'
- en: '[PRE189]'
  id: totrans-296
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE189]'
- en: '[PRE190]'
  id: totrans-297
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE190]'
- en: '[PRE191]'
  id: totrans-298
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE191]'
- en: '[PRE192]'
  id: totrans-299
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE192]'
- en: '[PRE193]'
  id: totrans-300
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE193]'
- en: '[PRE194]'
  id: totrans-301
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE194]'
- en: '[PRE195]'
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE195]'
- en: '[PRE196]'
  id: totrans-303
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE196]'
- en: '[PRE197]'
  id: totrans-304
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE197]'
- en: '[PRE198]'
  id: totrans-305
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE198]'
- en: '[PRE199]'
  id: totrans-306
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE199]'
- en: '[PRE200]'
  id: totrans-307
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE200]'
- en: '[PRE201]'
  id: totrans-308
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE201]'
- en: '[PRE202]'
  id: totrans-309
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE202]'
- en: '[PRE203]'
  id: totrans-310
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE203]'
- en: '[PRE204]'
  id: totrans-311
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE204]'
- en: '[PRE205]'
  id: totrans-312
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE205]'
- en: '[PRE206]'
  id: totrans-313
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE206]'
- en: '[PRE207]'
  id: totrans-314
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE207]'
- en: '[PRE208]'
  id: totrans-315
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE208]'
- en: '[PRE209]'
  id: totrans-316
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE209]'
- en: '[PRE210]'
  id: totrans-317
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE210]'
- en: '[PRE211]'
  id: totrans-318
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE211]'
- en: '[PRE212]'
  id: totrans-319
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE212]'
- en: '[PRE213]'
  id: totrans-320
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE213]'
- en: '[PRE214]'
  id: totrans-321
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE214]'
- en: '[PRE215]'
  id: totrans-322
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE215]'
- en: '[PRE216]'
  id: totrans-323
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE216]'
- en: '[PRE217]'
  id: totrans-324
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE217]'
- en: '[PRE218]'
  id: totrans-325
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE218]'
- en: 'Next, use the following function:'
  id: totrans-326
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 接下来，使用以下函数：
- en: '[PRE219]'
  id: totrans-327
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE219]'
- en: '[PRE220]'
  id: totrans-328
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE220]'
- en: '[PRE221]'
  id: totrans-329
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE221]'
- en: 'The preceding function takes the following previously generated `tokens` and
    `weights` list:'
  id: totrans-330
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 前面的函数接受以下先前生成的`tokens`和`weights`列表：
- en: '[PRE222]'
  id: totrans-331
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE222]'
- en: 'It transforms it into this:'
  id: totrans-332
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 它将其转换为以下形式：
- en: '[PRE223]'
  id: totrans-333
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE223]'
- en: '[PRE224]'
  id: totrans-334
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE224]'
- en: Get the weighted embeddings.
  id: totrans-335
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取加权嵌入。
- en: 'This is the final step, and we will get the Automatic1111-compatible embeddings
    without a token size limitation:'
  id: totrans-336
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是最后一步，我们将得到没有标记大小限制的与Automatic1111兼容的嵌入：
- en: '[PRE225]'
  id: totrans-337
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE225]'
- en: '[PRE226]'
  id: totrans-338
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE226]'
- en: '[PRE227]'
  id: totrans-339
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE227]'
- en: '[PRE228]'
  id: totrans-340
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE228]'
- en: '[PRE229]'
  id: totrans-341
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE229]'
- en: '[PRE230]'
  id: totrans-342
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE230]'
- en: '[PRE231]'
  id: totrans-343
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE231]'
- en: '[PRE232]'
  id: totrans-344
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE232]'
- en: '[PRE233]'
  id: totrans-345
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE233]'
- en: '[PRE234]'
  id: totrans-346
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE234]'
- en: '[PRE235]'
  id: totrans-347
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE235]'
- en: '[PRE236]'
  id: totrans-348
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE236]'
- en: '[PRE237]'
  id: totrans-349
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE237]'
- en: '[PRE238]'
  id: totrans-350
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE238]'
- en: '[PRE239]'
  id: totrans-351
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE239]'
- en: '[PRE240]'
  id: totrans-352
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE240]'
- en: '[PRE241]'
  id: totrans-353
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE241]'
- en: '[PRE242]'
  id: totrans-354
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE242]'
- en: '[PRE243]'
  id: totrans-355
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE243]'
- en: '[PRE244]'
  id: totrans-356
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE244]'
- en: '[PRE245]'
  id: totrans-357
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE245]'
- en: '[PRE246]'
  id: totrans-358
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE246]'
- en: '[PRE247]'
  id: totrans-359
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE247]'
- en: '[PRE248]'
  id: totrans-360
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE248]'
- en: '[PRE249]'
  id: totrans-361
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE249]'
- en: '[PRE250]'
  id: totrans-362
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE250]'
- en: '[PRE251]'
  id: totrans-363
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE251]'
- en: '[PRE252]'
  id: totrans-364
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE252]'
- en: '[PRE253]'
  id: totrans-365
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE253]'
- en: '[PRE254]'
  id: totrans-366
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE254]'
- en: '[PRE255]'
  id: totrans-367
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE255]'
- en: '[PRE256]'
  id: totrans-368
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE256]'
- en: '[PRE257]'
  id: totrans-369
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE257]'
- en: '[PRE258]'
  id: totrans-370
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE258]'
- en: '[PRE259]'
  id: totrans-371
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE259]'
- en: '[PRE260]'
  id: totrans-372
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE260]'
- en: '[PRE261]'
  id: totrans-373
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE261]'
- en: '[PRE262]'
  id: totrans-374
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE262]'
- en: '[PRE263]'
  id: totrans-375
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE263]'
- en: '[PRE264]'
  id: totrans-376
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE264]'
- en: '[PRE265]'
  id: totrans-377
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE265]'
- en: '[PRE266]'
  id: totrans-378
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE266]'
- en: '[PRE267]'
  id: totrans-379
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE267]'
- en: '[PRE268]'
  id: totrans-380
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE268]'
- en: '[PRE269]'
  id: totrans-381
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE269]'
- en: '[PRE270]'
  id: totrans-382
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE270]'
- en: '[PRE271]'
  id: totrans-383
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE271]'
- en: '[PRE272]'
  id: totrans-384
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE272]'
- en: '[PRE273]'
  id: totrans-385
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE273]'
- en: '[PRE274]'
  id: totrans-386
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE274]'
- en: '[PRE275]'
  id: totrans-387
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE275]'
- en: '[PRE276]'
  id: totrans-388
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE276]'
- en: '[PRE277]'
  id: totrans-389
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE277]'
- en: '[PRE278]'
  id: totrans-390
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE278]'
- en: '[PRE279]'
  id: totrans-391
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE279]'
- en: '[PRE280]'
  id: totrans-392
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE280]'
- en: '[PRE281]'
  id: totrans-393
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE281]'
- en: '[PRE282]'
  id: totrans-394
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE282]'
- en: '[PRE283]'
  id: totrans-395
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE283]'
- en: '[PRE284]'
  id: totrans-396
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE284]'
- en: '[PRE285]'
  id: totrans-397
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE285]'
- en: '[PRE286]'
  id: totrans-398
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE286]'
- en: '[PRE287]'
  id: totrans-399
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE287]'
- en: '[PRE288]'
  id: totrans-400
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE288]'
- en: '[PRE289]'
  id: totrans-401
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE289]'
- en: '[PRE290]'
  id: totrans-402
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE290]'
- en: '[PRE291]'
  id: totrans-403
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE291]'
- en: '[PRE292]'
  id: totrans-404
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE292]'
- en: '[PRE293]'
  id: totrans-405
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE293]'
- en: '[PRE294]'
  id: totrans-406
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE294]'
- en: '[PRE295]'
  id: totrans-407
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE295]'
- en: '[PRE296]'
  id: totrans-408
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE296]'
- en: '[PRE297]'
  id: totrans-409
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE297]'
- en: '[PRE298]'
  id: totrans-410
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE298]'
- en: '[PRE299]'
  id: totrans-411
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE299]'
- en: '[PRE300]'
  id: totrans-412
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE300]'
- en: '[PRE301]'
  id: totrans-413
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE301]'
- en: '[PRE302]'
  id: totrans-414
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE302]'
- en: '[PRE303]'
  id: totrans-415
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE303]'
- en: '[PRE304]'
  id: totrans-416
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE304]'
- en: '[PRE305]'
  id: totrans-417
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE305]'
- en: '[PRE306]'
  id: totrans-418
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE306]'
- en: '[PRE307]'
  id: totrans-419
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE307]'
- en: '[PRE308]'
  id: totrans-420
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE308]'
- en: '[PRE309]'
  id: totrans-421
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE309]'
- en: '[PRE310]'
  id: totrans-422
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE310]'
- en: '[PRE311]'
  id: totrans-423
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE311]'
- en: '[PRE312]'
  id: totrans-424
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE312]'
- en: '[PRE313]'
  id: totrans-425
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE313]'
- en: 'The function looks a bit long but the logic is simple. Let me explain it section
    by section:'
  id: totrans-426
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 函数看起来有点长，但逻辑很简单。让我分段解释：
- en: In the *padding-the-shorter-one* section, the logic will fill the shorter prompt
    with the ending token (`eos`) so that both the prompt and negative prompt token
    lists share the same size (so that the generated latent can do a subtraction operation).
  id: totrans-427
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在*填充较短的提示*部分，逻辑会将较短的提示填充到结束标记（`eos`），这样提示和负提示标记列表就具有相同的大小（这样生成的潜在变量可以进行减法操作）。
- en: We call the `pad_tokens_and_weights` function to break all tokens and weights
    into chunks, each chunk with 77 elements.
  id: totrans-428
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们调用`pad_tokens_and_weights`函数将所有标记和权重分割成块，每个块包含77个元素。
- en: We loop through the chunk list and encode the 77 tokens to embed in one step.
  id: totrans-429
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们遍历块列表，并在一步中将77个标记编码为嵌入。
- en: We use `token_embedding = pipe.text_encoder(token_tensor)[0].squeeze(0)` to
    remove empty dimensions, so that we can multiply each element with its weight.
    Note that, now, each token is represented by a 768-element vector.
  id: totrans-430
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用`token_embedding = pipe.text_encoder(token_tensor)[0].squeeze(0)`来移除空维度，这样我们就可以将每个元素与其权重相乘。注意，现在，每个标记都由一个768个元素的向量表示。
- en: Finally, we exit the loop and stack the tensor list to a higher dimension tensor
    using `prompt_embeds = torch.cat(embeds, dim =` `1)`.
  id: totrans-431
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，我们退出循环，并使用`prompt_embeds = torch.cat(embeds, dim = 1)`将张量列表堆叠成一个更高维度的张量。
- en: Verifying the work
  id: totrans-432
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 验证工作
- en: After the not-so-many lines of code, we finally have all the logic ready, so
    let’s give the code a test.
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 在编写了不那么多的代码之后，我们终于准备好了所有逻辑，现在让我们测试一下代码。
- en: 'In the simple version of a *long prompt encoder*, we still get a cat with some
    patterns in the body instead of `pure white`, as we gave in the prompt. Now, let’s
    add weight to the `white` keyword to see whether anything happens:'
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 在*长提示编码器*的简单版本中，我们仍然得到一只猫，身体上有一些图案，而不是我们在提示中给出的`纯白色`。现在，让我们给`white`关键词添加权重，看看会发生什么：
- en: '[PRE314]'
  id: totrans-435
  prefs: []
  type: TYPE_PRE
  zh: '[PRE314]'
- en: Our new embedding function magically enabled us to generate a pure white cat,
    as we gave a `1.5` weight to the `white` keyword.
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 我们新的嵌入函数神奇地使我们能够生成一只纯白色的猫，因为我们给“白色”关键词赋予了`1.5`的权重。
- en: '![Figure 10.3: Cute pure white cat running on the grass, with a 1.5 weight
    on the word white](img/B21263_10_03.jpg)'
  id: totrans-437
  prefs: []
  type: TYPE_IMG
  zh: '![图10.3：一只可爱的纯白色猫在草地上奔跑，对“白色”一词的权重为1.5](img/B21263_10_03.jpg)'
- en: 'Figure 10.3: Cute pure white cat running on the grass, with a 1.5 weight on
    the word white'
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.3：一只可爱的纯白色猫在草地上奔跑，对“白色”一词的权重为1.5
- en: That is all! Now, we can reuse or extend this function to build any custom prompt
    parser as we want. But what if you don’t want to build your own function to implement;
    are there ways to start using unlimited weighted prompts? Yes, next we are going
    to introduce two pipelines contributed from the open source community and integrated
    into Diffusers.
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 就这些！现在，我们可以重用或扩展这个函数来构建我们想要的任何自定义提示解析器。但如果你不想自己构建函数来实现，有没有办法开始使用无限加权提示？是的，接下来我们将介绍两个由开源社区贡献并集成到Diffusers中的管道。
- en: Overcoming the 77-token limitation using community pipelines
  id: totrans-440
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用社区管道克服77个标记的限制
- en: Implementing a pipeline supporting long prompt weighting from scratch can be
    challenging. Often, we simply wish to utilize Diffusers to generate images using
    detailed and nuanced prompts. Fortunately, the open source community has provided
    implementations for SD v1.5 and SDXL. The SDXL implementation was originally initialized
    by Andrew Zhu, the author of this book, and massively improved by the community.
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 从零开始实现支持长提示加权的管道可能具有挑战性。通常，我们只是希望利用Diffusers使用详细和细微的提示来生成图片。幸运的是，开源社区已经为SD v1.5和SDXL提供了实现。SDXL的实现最初由本书的作者Andrew
    Zhu初始化，并由社区大幅改进。
- en: 'I’ll now provide two examples of how to use the community pipeline for SD v1.5
    and SDXL:'
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: 我现在将提供两个示例，说明如何使用社区管道来处理SD v1.5和SDXL：
- en: This example uses the `lpw_stable_diffusion` pipeline for SD v1.5.
  id: totrans-443
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个例子使用了SD v1.5的`lpw_stable_diffusion`管道。
- en: 'Use the following code to start a long prompt weighted pipeline:'
  id: totrans-444
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用以下代码启动一个长提示加权管道：
- en: '[PRE315]'
  id: totrans-445
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE315]'
- en: '[PRE316]'
  id: totrans-446
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE316]'
- en: '[PRE317]'
  id: totrans-447
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE317]'
- en: '[PRE318]'
  id: totrans-448
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE318]'
- en: '[PRE319]'
  id: totrans-449
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE319]'
- en: '[PRE320]'
  id: totrans-450
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE320]'
- en: '[PRE321]'
  id: totrans-451
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE321]'
- en: '[PRE322]'
  id: totrans-452
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE322]'
- en: In the preceding code, `custom_pipeline = "lpw_stable_diffusion"` will actually
    download the `lpw_stable_diffusion` file from the Hugging Face server and will
    be invoked inside of the `DiffusionPipeline` pipeline.
  id: totrans-453
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在前面的代码中，`custom_pipeline = "lpw_stable_diffusion"`实际上会从Hugging Face服务器下载`lpw_stable_diffusion`文件，并在`DiffusionPipeline`管道内部调用。
- en: 'Let’s generate an image using the pipeline:'
  id: totrans-454
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们使用这个管道生成一张图片：
- en: '[PRE323]'
  id: totrans-455
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE323]'
- en: '[PRE324]'
  id: totrans-456
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE324]'
- en: '[PRE325]'
  id: totrans-457
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE325]'
- en: '[PRE326]'
  id: totrans-458
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE326]'
- en: '[PRE327]'
  id: totrans-459
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE327]'
- en: '[PRE328]'
  id: totrans-460
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE328]'
- en: '[PRE329]'
  id: totrans-461
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE329]'
- en: '[PRE330]'
  id: totrans-462
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE330]'
- en: '[PRE331]'
  id: totrans-463
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE331]'
- en: You will see an image the same as in *Figure 10**.3*.
  id: totrans-464
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你将看到与*图10.3*相同的图片。
- en: Now let’s see an example using the `lpw_stable_diffusion` pipeline for SDXL.
  id: totrans-465
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们通过使用`lpw_stable_diffusion`管道来为SDXL举一个例子。
- en: 'The usage is almost the same as the one we used in SD v1.5\. The only differences
    are that we are loading an SDXL model and that we use another custom pipeline
    name: `lpw_stable_diffusion_xl`. See the following code:'
  id: totrans-466
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE332]'
  id: totrans-467
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE332]'
- en: '[PRE333]'
  id: totrans-468
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE333]'
- en: '[PRE334]'
  id: totrans-469
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE334]'
- en: '[PRE335]'
  id: totrans-470
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE335]'
- en: '[PRE336]'
  id: totrans-471
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE336]'
- en: '[PRE337]'
  id: totrans-472
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE337]'
- en: '[PRE338]'
  id: totrans-473
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE338]'
- en: '[PRE339]'
  id: totrans-474
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE339]'
- en: 'The image generation code is exactly the same as the one we used for SD v1.5:'
  id: totrans-475
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE340]'
  id: totrans-476
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE340]'
- en: '[PRE341]'
  id: totrans-477
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE341]'
- en: '[PRE342]'
  id: totrans-478
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE342]'
- en: '[PRE343]'
  id: totrans-479
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE343]'
- en: '[PRE344]'
  id: totrans-480
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE344]'
- en: '[PRE345]'
  id: totrans-481
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE345]'
- en: '[PRE346]'
  id: totrans-482
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE346]'
- en: '[PRE347]'
  id: totrans-483
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE347]'
- en: '[PRE348]'
  id: totrans-484
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE348]'
- en: 'We will see an image generated as shown in *Figure 10**.4*:'
  id: totrans-485
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 10.4: Cute pure white cat running on the grass, with a 1.5 weight
    on the word white, using lpw_stable_diffusion_xl](img/B21263_10_04.jpg)'
  id: totrans-486
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10.4: Cute pure white cat running on the grass, with a 1.5 weight on
    the word white, using lpw_stable_diffusion_xl'
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
- en: 'From the image, we can clearly see what `pure (white:1.5) cat` is bringing
    into the image: proof that the pipeline can be used to generate images using long
    weighted prompts.'
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-489
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This chapter tried to solve one of the most discussed topics: overcoming the
    77-token limitation and adding prompt weights for the Stable Diffusion pipeline
    using the `Diffusers` package. Automatic1111’s Stable Diffusion WebUI provides
    a versatile UI and is now (as I am writing this) the most prevailing prompt weighting
    and attention format. However, if we take a look at the code from Automatic1111,
    we will probably get lost soon; its code is long without clear documentation.'
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
- en: This chapter started with understanding the root cause of the 77-token limitation
    and advanced to how the Stable Diffusion pipeline uses prompt embeddings. We implemented
    two functions to overcome the 77-token limitation.
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
- en: One simple function without weighting was implemented to show how to walk around
    the 77-token limitation. We also built another function with the full function
    of a long prompt usage without length limitations and also have prompt weighting
    implemented.
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
- en: 'By understanding and implementing these two functions, we can leverage the
    idea to not only use Diffuser to produce high-quality images the same as we can
    by using Automatic1111’s WebUI but we can also further extend it to add more powerful
    features. In terms of which feature to add, it is in your hands now. In the next
    chapter, we’ll start another exciting topic: using Stable Diffusion to fix and
    upscale images.'
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
- en: References
  id: totrans-494
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Hugging Face, weighted prompts: [https://huggingface.co/docs/diffusers/main/en/using-diffusers/weighted_prompts](https://huggingface.co/docs/diffusers/main/en/using-diffusers/weighted_prompts)'
  id: totrans-495
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'OpenAI CLIP, Connecting text and images: [https://openai.com/research/clip](https://openai.com/research/clip)'
  id: totrans-496
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Automatic1111, Stable Diffusion WebUI prompt parser: [https://github.com/AUTOMATIC1111/stable-diffusion-webui/blob/master/modules/prompt_parser.py#L345C19-L345C19](https://github.com/AUTOMATIC1111/stable-diffusion-webui/blob/master/modules/prompt_parser.py#L345C19-L345C19'
  id: totrans-497
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: )
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
- en: 'Automatic1111, Attention/emphasis: [https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features#attentionemphasis](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features#attentionemphasis'
  id: totrans-499
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: )
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
- en: 'Ashish et al., *Attention Is All You* *Need*: [https://arxiv.org/abs/1706.03762](https://arxiv.org/abs/1706.03762)'
  id: totrans-501
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'Ashish 等人，*Attention Is All You Need*: [https://arxiv.org/abs/1706.03762](https://arxiv.org/abs/1706.03762)'
- en: 'Source of the 77-token size limitation: [https://github.com/openai/CLIP/blob/4d120f3ec35b30bd0f992f5d8af2d793aad98d2a/clip/clip.py#L206](https://github.com/openai/CLIP/blob/4d120f3ec35b30bd0f992f5d8af2d793aad98d2a/clip/clip.py#L206)'
  id: totrans-502
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 77 个 token 大小限制的来源：[https://github.com/openai/CLIP/blob/4d120f3ec35b30bd0f992f5d8af2d793aad98d2a/clip/clip.py#L206](https://github.com/openai/CLIP/blob/4d120f3ec35b30bd0f992f5d8af2d793aad98d2a/clip/clip.py#L206)
