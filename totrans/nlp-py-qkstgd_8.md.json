["```py\nimport gzip\nimport logging\nimport os\nfrom pathlib import Path\nfrom urllib.request import urlretrieve\nimport numpy as np\nimport pandas as pd\nfrom sklearn.externals import joblib\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom sklearn.linear_model import LogisticRegression as LR\nfrom sklearn.pipeline import Pipeline\nfrom tqdm import tqdm\n```", "```py\nclass TqdmUpTo(tqdm):\n    def update_to(self, b=1, bsize=1, tsize=None):\n        if tsize is not None:\n        self.total = tsize\n        self.update(b * bsize - self.n)\n```", "```py\ndef get_data(url, filename):\n    \"\"\"\n    Download data if the filename does not exist already\n    Uses Tqdm to show download progress\n    \"\"\"\n    if not os.path.exists(filename):\n        dirname = os.path.dirname(filename)\n        if not os.path.exists(dirname):\n            os.makedirs(dirname)\n        with TqdmUpTo(unit=\"B\", unit_scale=True, miniters=1, desc=url.split(\"/\")[-1]) as t:\n            urlretrieve(url, filename, reporthook=t.update_to)\n```", "```py\ndef read_data(dir_path):\n    \"\"\"read data into pandas dataframe\"\"\"\n    def load_dir_reviews(reviews_path):\n         files_list = list(reviews_path.iterdir())\n         reviews = []\n         for filename in files_list:\n         f = open(filename, \"r\", encoding=\"utf-8\")\n         reviews.append(f.read())\n         return pd.DataFrame({\"text\": reviews})\n    pos_path = dir_path / \"pos\"\n    neg_path = dir_path / \"neg\"\n    pos_reviews, neg_reviews = load_dir_reviews(pos_path), load_dir_reviews(neg_path)\n    pos_reviews[\"label\"] = 1\n    neg_reviews[\"label\"] = 0\n    merged = pd.concat([pos_reviews, neg_reviews])\n    df = merged.sample(frac=1.0) # shuffle the rows\n    df.reset_index(inplace=True) # don't carry index from previous\n    df.drop(columns=[\"index\"], inplace=True) # drop the column 'index'\n    return df\n```", "```py\nfrom utils import get_data, read_data\n```", "```py\ndata_path = Path(os.getcwd()) / \"data\" / \"aclImdb\"\nlogger.info(data_path)\n```", "```py\nif not data_path.exists():\n    data_url = \"http://files.fast.ai/data/aclImdb.tgz\"\n    get_data(data_url, \"data/imdb.tgz\")\n```", "```py\ntrain_path = data_path / \"train\"\n# load data file as dict object\ntrain = read_data(train_path)\n```", "```py\n\n# extract the images (X) and labels (y) from the dict\nX_train, y_train = train[\"text\"], train[\"label\"]\n```", "```py\nlr_clf = Pipeline(\n [(\"vect\", CountVectorizer()), (\"tfidf\", TfidfTransformer()), (\"clf\", LR())]\n)\nlr_clf.fit(X=X_train, y=y_train)\n```", "```py\n# save model\njoblib.dump(lr_clf, \"model.pkl\")\n```", "```py\nfrom sklearn.externals import joblib\nmodel = joblib.load(\"model.pkl\")\n```", "```py\n# loading one example negative review\nwith open(r\".\\\\data\\\\aclImdb\\\\train\\neg\\\\1_1.txt\", \"r\") as infile:\n    test_neg_contents = infile.read()\n\n# loading one example positive review\nwith open(r\".\\\\data\\\\aclImdb\\\\train\\pos\\\\0_9.txt\", \"r\") as infile:\n    test_pos_contents = infile.read()\n```", "```py\npredictions = model.predict([test_neg_contents, test_pos_contents])\n```", "```py\nprint(predictions)\n> [0 1]\n\nfor p in predictions:\n    print(\"pos\" if p else \"neg\")\n\n> neg\n> pos\n```", "```py\nimport logging\nimport flask\nimport os\nimport numpy as np\nfrom flask import Flask, jsonify, render_template, request\nfrom sklearn.externals import joblib\n```", "```py\napp = Flask(__name__)\n```", "```py\n@app.route(\"/status\", methods=[\"GET\"])\ndef get_status():\n    return jsonify({\"version\": \"0.0.1\", \"status\": True})\n```", "```py\nif __name__ == \"__main__\":\n    # load ml model from disk\n    model = joblib.load(\"model.pkl\")\n    # start api\n    app.run(host=\"0.0.0.0\", port=8000, debug=True)\n```", "```py\n@app.route(\"/predict\", methods=[\"POST\"])\ndef make_prediction():\n    if request.method == \"POST\":\n        # get uploaded file if it exists\n        logger.debug(request.files)\n        f = request.files[\"file\"]\n        f.save(f.filename) # save file to disk\n        logger.info(f\"{f.filename} saved to disk\")\n        # read file from disk\n        with open(f.filename, \"r\") as infile:\n            text_content = infile.read()\n            logger.info(f\"Text Content from file read\")\n        prediction = model.predict([text_content])\n        logger.info(f\"prediction: {prediction}\")\n        prediction = \"pos\" if prediction[0] == 1 else \"neg\"\n        os.remove(f.filename)\n    return flask.render_template(\"index.html\", label=prediction)\n```", "```py\n<html>\n<head>\n<title>Text Classification model as a Flask API</title>\n<meta charset=\"utf-8\">\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n</head>\n\n<body>\n<h1>Movie Sentiment Analysis</h1>\n<form action=\"/predict\" method=\"post\" enctype=\"multipart/form-data\">\n <input type=\"file\" name=\"file\" value=\"Upload\">\n <input type=\"submit\" value=\"Predict\"> \n <p>Prediction: {% if label %} {{ label }} {% endif %}</p>\n</form>\n</body>\n</html>\n```", "```py\nPrediction: {% if label %} {{ label }} {% endif %}\n```"]