<html><head></head><body>
		<div><h1 id="_idParaDest-126" class="chapter-number"><a id="_idTextAnchor128" class="calibre6 pcalibre pcalibre1"/>5</h1>
			<h1 id="_idParaDest-127" class="calibre7"><a id="_idTextAnchor129" class="calibre6 pcalibre pcalibre1"/>Getting Started with Information Extraction</h1>
			<p class="calibre3">In this chapter, we will <a id="_idIndexMarker252" class="calibre6 pcalibre pcalibre1"/>cover the basics of <strong class="bold">information extraction</strong>. Information extraction is the task of pulling very specific information from text. For example, you might want to know the companies mentioned in a news article. Instead of spending time reading the whole article, you can use information extraction techniques to access the companies almost instantly.</p>
			<p class="calibre3">We will start with extracting emails addresses and URLs from job announcements. Then, we will use an algorithm called <strong class="bold">Levenshtein distance</strong> to find similar strings. Next, we will extract important<a id="_idIndexMarker253" class="calibre6 pcalibre pcalibre1"/> keywords from text. After that, we will use <strong class="bold">spaCy</strong> to find named entities in text, and later, we will train our own named entity recognition model in spaCy. We will then do basic sentiment analysis, and, finally, we will train two custom sentiment analysis models.</p>
			<p class="calibre3">You will learn how to use existing tools and train your own models for information extraction tasks.</p>
			<p class="calibre3">We will cover the following recipes in this chapter:</p>
			<ul class="calibre15">
				<li class="calibre14">Using regular expressions</li>
				<li class="calibre14">Finding similar strings – Levenshtein distance</li>
				<li class="calibre14">Extracting keywords</li>
				<li class="calibre14">Performing named entity recognition using spaCy</li>
				<li class="calibre14">Training your own NER model with spaCy</li>
				<li class="calibre14">Fine-tuning BERT for NER</li>
			</ul>
			<h1 id="_idParaDest-128" class="calibre7"><a id="_idTextAnchor130" class="calibre6 pcalibre pcalibre1"/>Technical requirements</h1>
			<p class="calibre3">The code for this chapter is in a folder named <code>Chapter05</code> in the GitHub repository of the book (<a href="https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/tree/main/Chapter05" class="calibre6 pcalibre pcalibre1">https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/tree/main/Chapter05</a>).</p>
			<p class="calibre3">As in previous chapters, the packages required for this chapter are part of the Poetry environment. Alternatively, you can install all the packages using the <code>requirements.txt</code> file.</p>
			<h1 id="_idParaDest-129" class="calibre7"><a id="_idTextAnchor131" class="calibre6 pcalibre pcalibre1"/>Using regular expressions</h1>
			<p class="calibre3">In this recipe, we will use regular expressions to <a id="_idIndexMarker254" class="calibre6 pcalibre pcalibre1"/>find email addresses and URLs in text. Regular expressions are special character sequences that define search patterns and can be created and used via the Python <code>re</code> package. We will use a job descriptions dataset and write two regular expressions, one for emails and one for URLs.</p>
			<h2 id="_idParaDest-130" class="calibre5"><a id="_idTextAnchor132" class="calibre6 pcalibre pcalibre1"/>Getting ready</h2>
			<p class="calibre3">Download the job descriptions dataset here: <a href="https://www.kaggle.com/andrewmvd/data-scientist-jobs" class="calibre6 pcalibre pcalibre1">https://www.kaggle.com/andrewmvd/data-scientist-jobs</a>. It is also available in the book’s GitHub repository at <a href="https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/data/DataScientist.csv" class="calibre6 pcalibre pcalibre1">https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/data/DataScientist.csv</a>. Save it into the <code>/</code><code>data</code> folder.</p>
			<p class="calibre3">The notebook is located at <a href="https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter05/5.1_regex.ipynb" class="calibre6 pcalibre pcalibre1">https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter05/5.1_regex.ipynb</a>.</p>
			<h2 id="_idParaDest-131" class="calibre5"><a id="_idTextAnchor133" class="calibre6 pcalibre pcalibre1"/>How to do it…</h2>
			<p class="calibre3">We will read the data from the CSV file into a <code>pandas</code> DataFrame and will use the Python <code>re</code> package to create regular expressions and search the text. The steps are as follows:</p>
			<ol class="calibre13">
				<li class="calibre14">Import the <strong class="source-inline1">re</strong> and <strong class="source-inline1">pandas</strong> packages:<pre class="source-code">
import re
import pandas as pd</pre></li>				<li class="calibre14">Read in the data and check the contents inside it:<pre class="source-code">
data_file = "../data/DataScientist.csv"
df = pd.read_csv(data_file, encoding='utf-8')
print(df)</pre><p class="calibre3">The output will be long and should <a id="_idIndexMarker255" class="calibre6 pcalibre pcalibre1"/>start like this:</p></li>			</ol>
			<div><div><img src="img/B18411_05_1.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 5.1 – DataFrame output</p>
			<ol class="calibre13">
				<li value="3" class="calibre14">The <strong class="source-inline1">get_list_of_items</strong> helper function takes a DataFrame as input and turns one of its columns into a list. It accepts the DataFrame and the column name as inputs. First, it gets the column values, which is a list of lists, and then flattens that list. It then removes duplicates by turning the list into a set and casts it back to a list:<pre class="source-code">
def get_list_of_items(df, column_name):
    values = df[column_name].values
    values = [item for sublist in values for item in sublist]
    list_of_items = list(set(values))
    return list_of_items</pre></li>				<li class="calibre14">In this step, we define the <strong class="source-inline1">get_emails</strong> function to get all the emails that appear in the <strong class="source-inline1">Job Description</strong> column. The regular expression consists of three parts that appear in square brackets followed by quantifiers:<ul class="calibre19"><li class="calibre14"><strong class="source-inline1">[^\s:|()\']+</strong> is the username part of the regular expression, followed by the <strong class="source-inline1">@</strong> sign. It consists of one group of characters, which is shown in square brackets. Any characters from this group may appear in the username one or more times. This is shown using the <strong class="source-inline1">+</strong> quantifier. The characters in the <a id="_idIndexMarker256" class="calibre6 pcalibre pcalibre1"/>username can be anything but a space (<strong class="source-inline1">\s</strong>), colon (<strong class="source-inline1">:</strong>), pipe (<strong class="source-inline1">|</strong>), and apostrophe (<strong class="source-inline1">'</strong>). The <strong class="source-inline1">^</strong> character shows the negation of the character class. An apostrophe is a special character in regular expressions and has to be escaped with a backward slash in order to invoke the regular meaning of the character.</li><li class="calibre14"><strong class="source-inline1">[a-zA-Z0-9\.]+</strong> is the first part of the domain name, followed by a dot. This part is simply alphanumeric characters, lowercase or uppercase, and a dot appearing one or more times. Since a dot is a special character, we escape it with a backward slash. The <strong class="source-inline1">a-z</strong> expression signifies a range of characters from <em class="italic">a</em> to <em class="italic">z</em>.</li><li class="calibre14"><strong class="source-inline1">[a-zA-Z]+</strong> is the last part of the domain name, which is the top-level domain, such as <strong class="source-inline1">.com</strong>, <strong class="source-inline1">.org</strong>, and so on. Usually, no digits are allowed in these top-level domains, and the regular expression matches lowercase or uppercase characters that appear one or more times.</li></ul><p class="calibre3">This regular expression is sufficient to parse all emails in the dataset and not present any false positives. You might find that, in your data, there are additional adjustments that need to be made to the regular expression:</p><pre class="source-code">
def get_emails(df):
    email_regex = '[^\s:|()\']+@[a-zA-Z0-9\.]+\.[a-zA-Z]+'
    df['emails'] = df['Job Description'].apply(
        lambda x: re.findall(email_regex, x))
    emails = get_list_of_items(df, 'emails')
    return emails</pre></li>				<li class="calibre14">We will now get the emails from the DataFrame using the previous functions:<pre class="source-code">
emails = get_emails(df)
print(emails)
['hrhelpdesk@phila.gov', 'talent@quartethealth.com', …, 'careers@edo.com', 'Talent.manager@techquarry.com', 'resumes@nextgentechinc.com', …, 'talent@ebay.com', …, 'info@springml.com',…]</pre></li>				<li class="calibre14">The <code>finditer</code> function from the <code>re</code> package. It finds all matches in a text and returns them as <code>Match</code> objects. We can find the start and end of the match by using the <code>span()</code>object method. It returns a tuple, where the first element is the start and the second element is the end of the m<a id="_idTextAnchor134" class="calibre6 pcalibre pcalibre1"/>atch:</p><pre class="source-code">
def get_urls(df):
    url_regex = '(http[s]?://(www\.)?[A-Za-z0-9–_\.\-]+\.[A-Za-z]+/?[A-Za-z0-9$\–_\-\/\.]*)[\.)\"]*'
    df['urls'] = df['Job Description'].apply(
        lambda x: [
            x[item.span()[0]:item.span()[1]] 
            for item in re.finditer(url_regex, x)
        ]
    )
    urls = get_list_of_items(df, 'urls')
    return urls</pre></li>				<li class="calibre14">We will get the URLs in a similar fashion:<pre class="source-code">
urls = get_urls(df)
print(urls)</pre><p class="calibre3">Part of the result will look<a id="_idIndexMarker259" class="calibre6 pcalibre pcalibre1"/> like this:</p><pre class="source-code">['<a href="https://youtu.be/c5TgbpE9UBI'" class="pcalibre pcalibre1 calibre20">https://youtu.be/c5TgbpE9UBI'</a>, 'https://www.linkedin.com/in/emma-riley-72028917a/', 'https://www.dol.gov/ofccp/regs/compliance/posters/ofccpost.htm', 'https://www.naspovaluepoint.org/portfolio/mmis-provider-services-module-2018-2028/hhs-technology-group/).', 'https://www.instagram.com/gatestonebpo', 'http://jobs.sdsu.edu', 'http://www.colgatepalmolive.com.', 'http://www1.eeoc.gov/employers/upload/eeoc_self_print_poster.pdf', 'https://www.gofundme.com/2019https', 'https://www.decode-m.com/', 'https://bit.ly/2lCOcYS',…]</pre></li>			</ol>
			<h2 id="_idParaDest-132" class="calibre5"><a id="_idTextAnchor135" class="calibre6 pcalibre pcalibre1"/>There’s more…</h2>
			<p class="calibre3">Writing regular expressions can quickly turn into a messy affair. I use regular expression testing websites to enter the text in which I expect a match and the regular expression. One example of such a site is <a href="https://regex101.com/" class="calibre6 pcalibre pcalibre1">https://regex101.com/</a>.</p>
			<h1 id="_idParaDest-133" class="calibre7"><a id="_idTextAnchor136" class="calibre6 pcalibre pcalibre1"/>Finding similar strings – Levenshtein distance</h1>
			<p class="calibre3">When doing information extraction, in many cases, we deal with misspellings, which can bring complications to the task. To get around this problem, several methods are available, including Levenshtein distance. This<a id="_idIndexMarker260" class="calibre6 pcalibre pcalibre1"/> algorithm finds the number of edits/additions/deletions needed to change one string into another. For example, to change the word <em class="italic">put</em> into <em class="italic">pat</em>, you need to substitute <em class="italic">u</em> for <em class="italic">a</em>, and that is one change. To change the word <em class="italic">kitten</em> into <em class="italic">smitten</em>, you need to do two edits: change <em class="italic">k</em> into <em class="italic">m</em> and add an <em class="italic">s</em> at the start.</p>
			<p class="calibre3">In this recipe, you will be able to use this technique to find a match to a misspelled email.</p>
			<h2 id="_idParaDest-134" class="calibre5"><a id="_idTextAnchor137" class="calibre6 pcalibre pcalibre1"/>Getting ready</h2>
			<p class="calibre3">We will use the same packages and the data scientist job description dataset that we used in the previous recipe, and the <code>python-Levenshtein</code> package, which is part of the Poetry environment and is included in the <code>requirements.txt</code> file.</p>
			<p class="calibre3">The notebook is located at <a href="https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter05/5.2_similar_strings.ipynb" class="calibre6 pcalibre pcalibre1">https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter05/5.2_similar_strings.ipynb</a>.</p>
			<h2 id="_idParaDest-135" class="calibre5"><a id="_idTextAnchor138" class="calibre6 pcalibre pcalibre1"/>How to do it…</h2>
			<p class="calibre3">We will read the dataset into a <code>pandas</code> DataFrame and use the emails extracted from it to search for a misspelled<a id="_idIndexMarker261" class="calibre6 pcalibre pcalibre1"/> email. Your steps should be formatted like so:</p>
			<ol class="calibre13">
				<li class="calibre14">Run the language utilities file. This file contains the <strong class="source-inline1">get_emails</strong> function we created in the previous recipe:<pre class="source-code">
%run -i "../util/lang_utils.ipynb"</pre></li>				<li class="calibre14">Do the necessary imports:<pre class="source-code">
import pandas as pd
import Levenshtein</pre></li>				<li class="calibre14">Read the data into a <strong class="source-inline1">pandas</strong> DataFrame object:<pre class="source-code">
data_file = "../data/DataScientist.csv"
df = pd.read_csv(data_file, encoding='utf-8')</pre></li>				<li class="calibre14">Filter out all emails from the DataFrame using the <strong class="source-inline1">get_emails</strong> function, which is explained in more detail in the previous recipe, <em class="italic">Using </em><em class="italic">regular expressions</em>:<pre class="source-code">
emails = get_emails(df)</pre></li>				<li class="calibre14">The <strong class="source-inline1">find_levenshtein</strong> function takes in a DataFrame and an input string and computes the Levenshtein distance between it and each string in the emails column. It takes in an input string and a DataFrame with emails and creates a new column in which the value is the Levenshtein distance between the input and the email address in the DataFrame. The column name is <strong class="source-inline1">distance_to_[input_string]</strong>:<pre class="source-code">
def find_levenshtein(input_string, df):
    df['distance_to_' + input_string] = \
        df['emails'].apply(lambda x: Levenshtein.distance(
            input_string, x))
    return df</pre></li>				<li class="calibre14">In this step, we define the <strong class="source-inline1">get_closest_email_lev</strong> function, which takes in a DataFrame with emails and an email to match and returns the email in the DataFrame that is closest to <a id="_idIndexMarker262" class="calibre6 pcalibre pcalibre1"/>the input. We accomplish this by using the <strong class="source-inline1">find_levenshtein</strong> function to create a new column with distances to the input email and then using the <strong class="source-inline1">idxmin()</strong> function from <strong class="source-inline1">pandas</strong> to find the index of the minimum value. We use the minimum index to find the closest email:<pre class="source-code">
def get_closest_email_lev(df, email):
    df = find_levenshtein(email, df)
    column_name = 'distance_to_' + email
    minimum_value_email_index = df[column_name].idxmin()
    email = df.loc[minimum_value_email_index]['emails']
    return email</pre></li>				<li class="calibre14">Next, we load the emails into a new DataFrame and use the misspelled email address <strong class="source-inline1">rohitt.macdonald@prelim.com</strong> to find a match in the new <strong class="source-inline1">email</strong> DataFrame:<pre class="source-code">
new_df = pd.DataFrame(emails,columns=['emails'])
input_string = "rohitt.macdonald@prelim.com"
email = get_closest_email_lev(new_df, input_string)
print(email)</pre><p class="calibre3">The function returns <code>rohit.mcdonald@prolim.com</code>, the correct spelling of the email address:</p><pre class="source-code">rohit.mcdonald@prolim.com</pre></li>			</ol>
			<h2 id="_idParaDest-136" class="calibre5"><a id="_idTextAnchor139" class="calibre6 pcalibre pcalibre1"/>There’s more…</h2>
			<p class="calibre3">The Levenshtein package includes other string similarity measuring methods, which you can explore at <a href="https://rapidfuzz.github.io/Levenshtein/" class="calibre6 pcalibre pcalibre1">https://rapidfuzz.github.io/Levenshtein/</a>. In this <a id="_idIndexMarker263" class="calibre6 pcalibre pcalibre1"/>section, we look at the <strong class="bold">Jaro distance</strong>.</p>
			<p class="calibre3">We can use another function, the Jaro<a id="_idIndexMarker264" class="calibre6 pcalibre pcalibre1"/> similarity, which outputs similarity between two strings as a number between <code>0</code> and <code>1</code>, where <code>1</code> means that two strings are the same. The process is similar, but we need the index with the maximum value instead of the minimum since the Jaro similarity function returns a higher value for more similar strings. Let’s go through the steps:</p>
			<ol class="calibre13">
				<li class="calibre14">The <strong class="source-inline1">find_jaro</strong> function takes in a DataFrame and an input string and computes the Jaro similarity between it and each string in the email column:<pre class="source-code">
def find_jaro(input_string, df):
    df['distance_to_' + input_string] = df['emails'].apply(
        lambda x: Levenshtein.jaro(input_string, x)
    )
    return df</pre></li>				<li class="calibre14">The <strong class="source-inline1">get_closest_email_jaro</strong> function uses the function we defined in the previous step to find the email address that is closest to the one input:<pre class="source-code">
def get_closest_email_jaro(df, email):
    df = find_jaro(email, df)
    column_name = 'distance_to_' + email
    maximum_value_email_index = df[column_name].idxmax()
    email = df.loc[maximum_value_email_index]['emails']
    return email</pre></li>				<li class="calibre14">Next, we use the misspelled email address <strong class="source-inline1">rohitt.macdonald@prelim.com</strong> to find a match in the new email DataFrame:<pre class="source-code">
email = get_closest_email_jaro(new_df, input_string)
print(email)</pre><p class="calibre3">The output is as follows:</p><pre class="source-code">rohit.mcdonald@prolim.com</pre></li>				<li class="calibre14">An extension of the<a id="_idIndexMarker265" class="calibre6 pcalibre pcalibre1"/> Jaro similarity function is the <strong class="bold">Jaro-Winkler function</strong>, which attaches a weight to the<a id="_idIndexMarker266" class="calibre6 pcalibre pcalibre1"/> end of the word, and that weight lowers the importance of misspellings toward the end. For example, let’s look at the following function:<pre class="source-code">
print(Levenshtein.jaro_winkler("rohit.mcdonald@prolim.com",
    "rohit.mcdonald@prolim.org"))</pre><p class="calibre3">This outputs the following:</p><pre class="source-code">1.0</pre></li>			</ol>
			<h1 id="_idParaDest-137" class="calibre7"><a id="_idTextAnchor140" class="calibre6 pcalibre pcalibre1"/>Extracting keywords</h1>
			<p class="calibre3">In this recipe, we will extract <a id="_idIndexMarker267" class="calibre6 pcalibre pcalibre1"/>keywords from a text. We will be working with the BBC news dataset that contains news articles. You can learn more about the dataset in <a href="B18411_04.xhtml#_idTextAnchor106" class="calibre6 pcalibre pcalibre1"><em class="italic">Chapter 4</em></a>, in the recipe titled <em class="italic">Clustering sentences using K-Means: unsupervised </em><em class="italic">text classification</em>.</p>
			<p class="calibre3">Extracting keywords from text can give us a quick idea about what the article is about and can also serve as a basis for a tagging system, for example, on a website.</p>
			<p class="calibre3">For the extraction to work correctly, we need to train a TF-IDF vectorizer that we will use during the extraction phase.</p>
			<h2 id="_idParaDest-138" class="calibre5"><a id="_idTextAnchor141" class="calibre6 pcalibre pcalibre1"/>Getting ready</h2>
			<p class="calibre3">In this recipe, we will use the <code>sklearn</code> package. It is part of the Poetry environment. You can also install it together with other packages by installing the <code>requirements.txt</code> file.</p>
			<p class="calibre3">The BBC news dataset is available on Hugging Face at  <a href="https://huggingface.co/datasets/SetFit/bbc-news" class="calibre6 pcalibre pcalibre1">https://huggingface.co/datasets/SetFit/bbc-news</a>.</p>
			<p class="calibre3">The notebook is located at <a href="https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter05/5.3_keyword_extraction.ipynb" class="calibre6 pcalibre pcalibre1">https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter05/5.3_keyword_extraction.ipynb</a>.</p>
			<h2 id="_idParaDest-139" class="calibre5"><a id="_idTextAnchor142" class="calibre6 pcalibre pcalibre1"/>How to do it…</h2>
			<p class="calibre3">To extract keywords from a given text, we first need a corpus of text that we will fit the vectorizer on. Once that is done, we<a id="_idIndexMarker268" class="calibre6 pcalibre pcalibre1"/> can use it to extract keywords from a text that is similar to the processed corpus. Here are the steps:</p>
			<ol class="calibre13">
				<li class="calibre14">Run the language utilities notebook:<pre class="source-code">
%run -i "../util/lang_utils.ipynb"</pre></li>				<li class="calibre14">Import the necessary packages and functions:<pre class="source-code">
from datasets import load_dataset
from nltk import word_tokenize
from math import ceil
from sklearn.feature_extraction.text import TfidfVectorizer
from nltk.corpus import stopwords</pre></li>				<li class="calibre14">Load the training and testing datasets, convert them to <strong class="source-inline1">pandas</strong> DataFrame objects, and print out the training DataFrame to discover how it looks. The DataFrame has three columns, one for the news article text, one for the label in numeric format, and one for the label text:<pre class="source-code">
train_dataset = load_dataset("SetFit/bbc-news", split="train")
test_dataset = load_dataset("SetFit/bbc-news", split="test")
train_df = train_dataset.to_pandas()
test_df = test_dataset.to_pandas()
print(train_df)
print(test_df)</pre><p class="calibre3">The result should look<a id="_idIndexMarker269" class="calibre6 pcalibre pcalibre1"/> similar to this:</p><pre class="source-code">     text  label     label_text
0  wales want rugby league training wales could f... 2  sport
1     china aviation seeks rescue deal scandal-hit j...  business
...     ...    ...            ...
1223  why few targets are better than many the econo... 1  business
1224  boothroyd calls for lords speaker betty boothr... 4  politics
[1225 rows x 3 columns]
     text  label     label_text
0  carry on star patsy rowlands dies actress pats... 3  entertainment
1    sydney to host north v south game sydney will ... 2  sport
..     ...    ...            ...
998  stormy year for property insurers a string of ... 1  business
999  what the election should really be about  a ge... 4  politics
[1000 rows x 3 columns]</pre></li>				<li class="calibre14">Create the vectorizer and fit it on the training data text. To learn more about vectorizers, see <a href="B18411_03.xhtml#_idTextAnchor067" class="calibre6 pcalibre pcalibre1"><em class="italic">Chapter 3</em></a>. The TF-IDF <a id="_idIndexMarker270" class="calibre6 pcalibre pcalibre1"/>vectorizer is discussed in the <em class="italic">Representing texts with TF-IDF</em> recipe. We use English stopwords, a minimum document frequency of <strong class="source-inline1">2</strong>, and a maximum document frequency of 95% (to learn more about stopwords, see the <em class="italic">Removing stopwords</em> recipe in <a href="B18411_01.xhtml#_idTextAnchor013" class="calibre6 pcalibre pcalibre1"><em class="italic">Chapter 1</em></a>):<pre class="source-code">
vectorizer = TfidfVectorizer(stop_words='english', 
    min_df=2, max_df=0.95)
vectorizer.fit(train_df["text"])</pre></li>				<li class="calibre14">Now, we will define a few helper functions. The first one will sort a coordinate matrix by the TF-IDF score. It takes the coordinate matrix that is converted from the vector created by the vectorizer. This coordinate matrix’s <strong class="source-inline1">col</strong> attribute provides the word indices and the <strong class="source-inline1">data</strong> attribute provides the TF-IDF scores for each word. The function creates a list of tuples from this data, where the first value in the tuple is the index and the second value is the TF-IDF score. It then sorts the tuple list by the TF-IDF score and returns the sorted result.  This will give us words that have the maximum TF-IDF score or the ones that are most characteristic of this particular news piece:<pre class="source-code">
def sort_data_tfidf_score(coord_matrix):
    tuples = zip(coord_matrix.col, coord_matrix.data)
    return sorted(tuples, key=lambda x: (x[1], x[0]), 
        reverse=True)</pre></li>				<li class="calibre14">The next function, <strong class="source-inline1">get_keyword_strings</strong>, will get the keywords for a given vector. It returns the extracted keywords for a given vector. It takes as input the fitted vectorizer, the number of keywords to extract, and the sorted vector of the input text. The function first defines the <strong class="source-inline1">index_dict</strong> variable as the dictionary with word indices as keys and corresponding words as values. It then iterates through the sorted vector and appends the words from the dictionary to the <strong class="source-inline1">words</strong> list variable. It <a id="_idIndexMarker271" class="calibre6 pcalibre pcalibre1"/>stops when it reaches the desired number of words. Since the function iterates through the sorted vector, it will give us the words with the highest TF-IDF scores. These words will be the ones most used in this document but not used in other documents, thus giving us an idea about the topic of the article:<pre class="source-code">
def get_keyword_strings(vectorizer, num_words, sorted_vector):
    words = []
    index_dict = vectorizer.get_feature_names_out()
    for (item_index, score) in sorted_vector[0:num_words]:
        word = index_dict[item_index]
        words.append(word)
    return words</pre></li>				<li class="calibre14">The <strong class="source-inline1">get_keywords_simple</strong> function will return a list of keywords for a given text. It takes in the input text, the fitted vectorizer, and the desired number of words. It creates a vector for the input text by using the vectorizer, then sorts the vector by using the <strong class="source-inline1">sort_data_tfidf_score</strong> function, and finally, gets the top words using the <strong class="source-inline1">get_keyword_strings</strong> function:<pre class="source-code">
def get_keywords_simple(vectorizer, input_text,
    num_output_words=10):
    vector = vectorizer.transform([input_text])
    sorted = sort_data_tfidf_score(vector.tocoo())
    words = get_keyword_strings(vectorizer, num_output_words, 
        sorted)
    return words</pre></li>				<li class="calibre14">We use the previous function on the first text from the test DataFrame. We take the first article text in the test data and<a id="_idIndexMarker272" class="calibre6 pcalibre pcalibre1"/> create a list of keywords using the <strong class="source-inline1">get_keywords_simple</strong> function. We see that some of the keywords fit the summary, and some are less suitable:<pre class="source-code">
print(test_df.iloc[0]["text"])
keywords = get_keywords_simple(vectorizer,
    test_df.iloc[0]["text"])
print(keywords)</pre><p class="calibre3">The result will be as follows:</p><pre class="source-code">carry on star patsy rowlands dies actress patsy rowlands  known to millions for her roles in the carry on films  has died at the age of 71.  rowlands starred in nine of the popular carry on films  alongside fellow regulars sid james  kenneth williams and barbara windsor...
['carry', 'theatre', 'scholarship', 'appeared', 'films', 'mrs', 'agent', 'drama', 'died', 'school']</pre></li>			</ol>
			<h2 id="_idParaDest-140" class="calibre5"><a id="_idTextAnchor143" class="calibre6 pcalibre pcalibre1"/>There’s more…</h2>
			<p class="calibre3">Now, we will use a more sophisticated approach to extracting keywords from news summaries. We will use a vectorizer that scores not just individual words but also bigrams and trigrams. We will also use the spaCy noun chunks to make sure that the bigrams and trigrams that are output make sense. To learn more about noun chunks, see the <em class="italic">Extracting noun chunks</em> recipe in <a href="B18411_02.xhtml#_idTextAnchor042" class="calibre6 pcalibre pcalibre1"><em class="italic">Chapter 2</em></a>. The advantage of this method is that we get not only individual words as output but also phrases, such as <em class="italic">Saturday morning</em> instead of just <em class="italic">Saturday</em> and <em class="italic">morning</em> individually.</p>
			<ol class="calibre13">
				<li class="calibre14">Create the new vectorizer <a id="_idIndexMarker273" class="calibre6 pcalibre pcalibre1"/>and fit it on the training summaries. We exclude the word <strong class="source-inline1">the</strong> from the stopwords list since spaCy entities might contain it:<pre class="source-code">
stop_words = list(stopwords.words('english'))
stop_words.remove("the")
trigram_vectorizer = TfidfVectorizer(
    stop_words=stop_words, min_df=2,
    ngram_range=(1,3), max_df=0.95)
trigram_vectorizer.fit(train_df["summary"])</pre></li>				<li class="calibre14">Now, define the <strong class="source-inline1">get_keyword_strings_all</strong> function. It will get all the keywords from the sorted vector. It has no restriction on how many words it gets:<pre class="source-code">
def get_keyword_strings_all(vectorizer, sorted_vector):
    words = []
    index_dict = vectorizer.get_feature_names_out()
    for (item_index, score) in sorted_vector:
        word = index_dict[item_index]
        words.append(word)
    return words</pre></li>				<li class="calibre14">Next, we define the <strong class="source-inline1">get_keywords_complex</strong> function that outputs main keywords and phrases up to three words long:<pre class="source-code">
def get_keywords_complex(
    vectorizer, input_text, spacy_model, num_words=70
):
    keywords = []
    doc = spacy_model(input_text)
    vector = vectorizer.transform([input_text])
    sorted = sort_coo(vector.tocoo())
    ngrams = get_keyword_strings_all(vectorizer, sorted)
    ents = [ent.text.lower() for ent in doc.noun_chunks]
    for i in range(0, num_words):
        keyword = ngrams[i]
        if keyword.lower() in ents and not
        keyword.isdigit() and keyword not in keywords:
            keywords.append(keyword)
    return keywords</pre></li>				<li class="calibre14">Now, we use the previous <a id="_idIndexMarker274" class="calibre6 pcalibre pcalibre1"/>function on the first test summary:<pre class="source-code">
keywords = get_keywords_complex(trigram_vectorizer,
    test_df.iloc[0]["summary"], small_model)
print(keywords)</pre><p class="calibre3">The result will look like this:</p><pre class="source-code">['the gop', 'the 50 states', 'npr', '11 states', 'state', 'republican governors', 'the dems', 'reelection', 'the helm', 'grabs']</pre></li>			</ol>
			<h1 id="_idParaDest-141" class="calibre7"><a id="_idTextAnchor144" class="calibre6 pcalibre pcalibre1"/>Performing named entity recognition using spaCy</h1>
			<p class="calibre3"><strong class="bold">Named entity recognition</strong> (<strong class="bold">NER</strong>) is the task of parsing the names of places, people, organizations, and so on, out of text. This can be useful in many downstream tasks. For example, you could imagine a situation<a id="_idIndexMarker275" class="calibre6 pcalibre pcalibre1"/> where you would like to sort<a id="_idIndexMarker276" class="calibre6 pcalibre pcalibre1"/> an article set by the people that are mentioned in it, for example, when carrying out research about a certain person.</p>
			<p class="calibre3">In this recipe, we will use NER to parse out named entities from article texts in the BBC dataset. We will load the package and the parsing engine and loop through the NER results.</p>
			<h2 id="_idParaDest-142" class="calibre5"><a id="_idTextAnchor145" class="calibre6 pcalibre pcalibre1"/>Getting ready</h2>
			<p class="calibre3">In this recipe, we will use spaCy. To run it correctly, you will need to download a language model. We will download the small and large models. These models take up significant disk space:</p>
			<pre class="console">
python -m spacy download en_core_web_sm
python -m spacy download en_core_web_lg</pre>			<p class="calibre3">The notebook is located at <a href="https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter05/5.4_named_entity_extraction.ipynb" class="calibre6 pcalibre pcalibre1">https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter05/5.4_named_entity_extraction.ipynb</a>.</p>
			<h2 id="_idParaDest-143" class="calibre5"><a id="_idTextAnchor146" class="calibre6 pcalibre pcalibre1"/>How to do it…</h2>
			<p class="calibre3">NER happens automatically with the processing that spaCy does for an input text. Accessing the entities happens through the <code>doc.ents</code> variable. We will input an article about Apple’s iPhone and see which entities will get parsed from it. Let’s see the steps:</p>
			<ol class="calibre13">
				<li class="calibre14">Run the language utilities file. This will import the necessary packages and functions and initialize the spaCy engine:<pre class="source-code">
%run -i "../util/lang_utils.ipynb"</pre></li>				<li class="calibre14">Initialize the article text. This is an article from <a href="https://www.globalsmt.net/social-media-news/iphone-12-apple-makes-jump-to-5g/:" class="calibre6 pcalibre pcalibre1">https://www.globalsmt.net/social-media-news/iphone-12-apple-makes-jump-to-5g/:</a><pre class="source-code">
article = """iPhone 12: Apple makes jump to 5G
Apple has confirmed its iPhone 12 handsets will be its first to work on faster 5G networks.
The company has also extended the range to include a new "Mini" model that has a smaller 5.4in screen.
The US firm bucked a wider industry downturn by increasing its handset sales over the past year.
But some experts say the new features give Apple its best opportunity for growth since 2014, when it revamped its line-up with the iPhone 6.
…
"Networks are going to have to offer eye-wateringly attractive deals, and the way they're going to do that is on great tariffs and attractive trade-in deals,"
predicted Ben Wood from the consultancy CCS Insight. Apple typically unveils its new iPhones in September, but opted for a later date this year.
It has not said why, but it was widely speculated to be related to disruption caused by the coronavirus pandemic. The firm's shares ended the day 2.7% lower.
This has been linked to reports that several Chinese internet platforms opted not to carry the livestream,
although it was still widely viewed and commented on via the social media network Sina Weibo."""</pre></li>				<li class="calibre14">Here, we create the spaCy <strong class="source-inline1">Doc</strong> object and use it to extract the entities. The <strong class="source-inline1">Doc</strong> object is created by <a id="_idIndexMarker277" class="calibre6 pcalibre pcalibre1"/>using the small spaCy model on<a id="_idIndexMarker278" class="calibre6 pcalibre pcalibre1"/> the text. The model extracts different attributes, including named entities. We print the length of the parsed entities and the entities themselves, together with start and end character information and the entity type (the meaning of the named entity labels can be found in the<a id="_idIndexMarker279" class="calibre6 pcalibre pcalibre1"/> spaCy documentation at <a href="https://spacy.io/models/en" class="calibre6 pcalibre pcalibre1">https://spacy.io/models/en</a>):<pre class="source-code">
doc = small_model(article)
print(len(doc.ents))
small_model_ents = doc.ents
for ent in doc.ents:
    print(ent.text, ent.start_char, ent.end_char, ent.label_)</pre><p class="calibre3">When we print out the <a id="_idIndexMarker280" class="calibre6 pcalibre pcalibre1"/>result, we see different types of entities, including cardinal numbers, percentages, names of <a id="_idIndexMarker281" class="calibre6 pcalibre pcalibre1"/>people, dates, organizations, and a <code>NORP</code> entity, which stands for <strong class="bold">Nationalities or Religious or </strong><strong class="bold">Political groups</strong>:</p><pre class="source-code">44
12 7 9 CARDINAL
Apple 11 16 ORG
5 31 32 CARDINAL
…
a later date this year 2423 2445 DATE
2.7% 2594 2598 PERCENT
Chinese 2652 2659 NORP
Sina Weibo 2797 2807 PERSON</pre></li>			</ol>
			<h2 id="_idParaDest-144" class="calibre5"><a id="_idTextAnchor147" class="calibre6 pcalibre pcalibre1"/>There’s more…</h2>
			<p class="calibre3">We can compare the performance of the small and large models with the following steps:</p>
			<ol class="calibre13">
				<li class="calibre14">Run the same step as <em class="italic">step 3</em> from the <em class="italic">How to do it…</em> section but with the large model:<pre class="source-code">
doc = large_model(article)
print(len(doc.ents))
large_model_ents = doc.ents
for ent in doc.ents:
    print(ent.text, ent.start_char, ent.end_char, ent.label_)</pre><p class="calibre3">The result will be<a id="_idIndexMarker282" class="calibre6 pcalibre pcalibre1"/> as follows:</p><pre class="source-code">46
12 7 9 CARDINAL
Apple 11 16 ORG
5 31 32 CARDINAL
…
the day 2586 2593 DATE
2.7% 2594 2598 PERCENT
Chinese 2652 2659 NORP
Sina Weibo 2797 2807 PERSON</pre></li>				<li class="calibre14">There are more entities parsed by the large model, and we can take a look at the differences. We<a id="_idIndexMarker283" class="calibre6 pcalibre pcalibre1"/> print out two lists; one list contains entities that the small model recognizes, and the other list contains entities that the large model recognizes but not the small:<pre class="source-code">
small_model_ents = [str(ent) for ent in small_model_ents]
large_model_ents = [str(ent) for ent in large_model_ents]
in_small_not_in_large = set(small_model_ents) \ 
    - set(large_model_ents)
in_large_not_in_small = set(large_model_ents) \ 
    - set(small_model_ents)
print(in_small_not_in_large)
print(in_large_not_in_small)</pre><p class="calibre3">The result will be as follows:</p><pre class="source-code">{'iPhone 11', 'iPhone', 'iPhones'}
{'6', 'the day', 'IDC', '11', 'Pro', 'G\nApple', 'SE'}</pre></li>			</ol>
			<p class="calibre3">You can see that there are some differences between the results provided by the two models.</p>
			<h1 id="_idParaDest-145" class="calibre7"><a id="_idTextAnchor148" class="calibre6 pcalibre pcalibre1"/>Training your own NER model with spaCy</h1>
			<p class="calibre3">In the previous recipe, we used the pretrained spaCy model to extract named entities. This NER model can suffice in many cases. There might be other times, however, when we would like to create a new one from<a id="_idIndexMarker284" class="calibre6 pcalibre pcalibre1"/> scratch. In this recipe, we will train a<a id="_idIndexMarker285" class="calibre6 pcalibre pcalibre1"/> new NER model to parse out the names of musicians and their works of art.</p>
			<h2 id="_idParaDest-146" class="calibre5"><a id="_idTextAnchor149" class="calibre6 pcalibre pcalibre1"/>Getting ready</h2>
			<p class="calibre3">We will use the spaCy package to train a new NER model. You do not need any other packages other than <code>spacy</code>. The data we are going to use is from <a href="https://github.com/deezer/music-ner-eacl2023" class="calibre6 pcalibre pcalibre1">https://github.com/deezer/music-ner-eacl2023</a>. The data file is preloaded in the data folder (<a href="https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/data/music_ner.csv" class="calibre6 pcalibre pcalibre1">https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/data/music_ner.csv</a>) and you will need to download it from the book’s GitHub repository into the <code>data</code> directory.</p>
			<p class="calibre3">The notebook is located at <a href="https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter05/5.5_training_own_spacy_model.ipynb" class="calibre6 pcalibre pcalibre1">https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter05/5.5_training_own_spacy_model.ipynb</a>.</p>
			<h2 id="_idParaDest-147" class="calibre5"><a id="_idTextAnchor150" class="calibre6 pcalibre pcalibre1"/>How to do it…</h2>
			<p class="calibre3">We will define our training data and then use it to train a new model. We will then test the model and save it to disk. The <a id="_idIndexMarker286" class="calibre6 pcalibre pcalibre1"/>steps are as follows:</p>
			<ol class="calibre13">
				<li class="calibre14">Run the language utilities file:<pre class="source-code">
%run -i "../util/lang_utils.ipynb"</pre></li>				<li class="calibre14">Import other functions and<a id="_idIndexMarker287" class="calibre6 pcalibre pcalibre1"/> packages:<pre class="source-code">
import pandas as pd
from spacy.cli.train import train
from spacy.cli.evaluate import evaluate
from spacy.tokens import DocBin
from sklearn.model_selection import train_test_split</pre></li>				<li class="calibre14">In this step, <a id="_idTextAnchor151" class="calibre6 pcalibre pcalibre1"/>we load the data and print it out:<pre class="source-code">
music_ner_df = pd.read_csv('../data/music_ner.csv')
print(music_ner_df)</pre><p class="calibre3">The data has five columns: <code>id</code>, <code>start offset</code>, <code>end offset</code>, <code>text</code>, and <code>label</code>. Sentences repeat if there is more than one entity per sentence, as there is one row per named entity. There are 428 entries in the data.</p></li>			</ol>
			<div><div><img src="img/B18411_05_2.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 5.2 – DataFrame output</p>
			<ol class="calibre13">
				<li value="4" class="calibre14">Here, we remove <strong class="source-inline1">_deduced</strong> from<a id="_idIndexMarker288" class="calibre6 pcalibre pcalibre1"/> the labels so the<a id="_idIndexMarker289" class="calibre6 pcalibre pcalibre1"/> labels are now <strong class="source-inline1">Artist</strong>, <strong class="source-inline1">WoA (work of </strong><strong class="source-inline1">art)</strong>, <strong class="source-inline1">Artist_or_WoA</strong>:<pre class="source-code">
def change_label(input_label):
    input_label = input_label.replace("_deduced", "")
    return input_label
music_ner_df["label"] = music_ner_df["label"].apply(change_label)
print(music_ner_df)</pre><p class="calibre3">The result will look like this:</p></li>			</ol>
			<div><div><img src="img/B18411_05_3.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 5.3 – DataFrame output</p>
			<ol class="calibre13">
				<li value="5" class="calibre14">In this step, we create the <strong class="source-inline1">DocBin</strong> objects that <a id="_idIndexMarker290" class="calibre6 pcalibre pcalibre1"/>will store the processed data. <strong class="source-inline1">DocBin</strong> objects are<a id="_idIndexMarker291" class="calibre6 pcalibre pcalibre1"/> required for input data for spaCy models (to learn more about them, see the <em class="italic">Training a spaCy textcat model</em> recipe in <a href="B18411_04.xhtml#_idTextAnchor106" class="calibre6 pcalibre pcalibre1"><em class="italic">Chapter 4</em></a>):<pre class="source-code">
train_db = DocBin()
test_db = DocBin()</pre></li>				<li class="calibre14">Here, we create a list of unique IDs and split it into training and test data. The reason we would like to get the unique IDs is because sentences repeat through the dataset. There are 227 unique IDs (or sentences), and there are 170 sentences in the <a id="_idIndexMarker292" class="calibre6 pcalibre pcalibre1"/>training data and 57 sentences in the test<a id="_idIndexMarker293" class="calibre6 pcalibre pcalibre1"/> data:<pre class="source-code">
# Get a unique list of unique ids
ids = list(set(music_ner_df["id"].values))
print(len(ids))
# Split ids into training and test
train_ids, test_ids = train_test_split(ids)
print(len(train_ids))
print(len(test_ids))</pre><p class="calibre3">The result will be as follows:</p><pre class="source-code">227
170
57</pre></li>				<li class="calibre14">Here, we create and save training and test data in the <strong class="source-inline1">DocBin</strong> objects. We loop through IDs, and for each ID, we get the sentence. We process the sentence using the small model and then have a spaCy <strong class="source-inline1">Doc</strong> object. Then, we loop through the entities in the sentence and add them to the <strong class="source-inline1">ents</strong> attribute of the <strong class="source-inline1">Doc</strong> object. The processed <strong class="source-inline1">Doc</strong> object then goes into one of the <strong class="source-inline1">DocBin</strong> objects:<pre class="source-code">
for id in ids:
    entity_rows = music_ner_df.loc[music_ner_df['id'] == id]
    text = entity_rows.head(1)["text"].values[0]
    doc = small_model(text)
    ents = []
    for index, row in entity_rows.iterrows():
        label = row["label"]
        start = row["start_offset"]
        end = row["end_offset"]
        span = doc.char_span(start, end, label=label, 
            alignment_mode="contract")
        ents.append(span)
    doc.ents = ents
    if id in train_ids:
        train_db.add(doc)
    else:
        test_db.add(doc)
train_db.to_disk('../data/music_ner_train.spacy')
test_db.to_disk('../data/music_ner_test.spacy')</pre></li>				<li class="calibre14">In this step, we train the model. We<a id="_idIndexMarker294" class="calibre6 pcalibre pcalibre1"/> use the <strong class="source-inline1">spacy_config_ner.cfg</strong> configuration file in the <strong class="source-inline1">data</strong> folder. You can create your own customized configuration<a id="_idIndexMarker295" class="calibre6 pcalibre pcalibre1"/> file at <a href="https://spacy.io/usage/training/#quickstart" class="calibre6 pcalibre pcalibre1">https://spacy.io/usage/training/#quickstart</a>. The output shows the loss, accuracy, precision, recall, F1 score, and other metrics for every epoch. Finally, it saves the model to the specified directory:<pre class="source-code">
train("../data/spacy_config_ner.cfg", output_path="../models/spacy_music_ner")</pre><p class="calibre3">The output will look like this:</p></li>			</ol>
			<div><div><img src="img/B18411_05_4.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 5.4 – Model training output</p>
			<ol class="calibre13">
				<li value="9" class="calibre14">In this step, we load the trained model and use it on data not seen during training. We get an ID from the<a id="_idIndexMarker296" class="calibre6 pcalibre pcalibre1"/> test set, get all the rows from the test data with that ID, and load the <a id="_idIndexMarker297" class="calibre6 pcalibre pcalibre1"/>sentence. We then print out the sentence and the annotated entities. Then, we process the sentence using our model (in exactly the same way as other pretrained spaCy models) and print out the entities it parsed:<pre class="source-code">
nlp = spacy.load("../models/spacy_music_ner/model-last")
first_test_id = test_ids[0]
test_rows = music_ner_df.loc[music_ner_df['id'] 
    == first_test_id]
input_text = entity_rows.head(1)["text"].values[0]
print(input_text)
print("Gold entities:")
for index, row in entity_rows.iterrows():
    label = row["label"]
    start = row["start_offset"]
    end = row["end_offset"]
    span = doc.char_span(start, end, label=label,
        alignment_mode="contract")
    print(span)
doc = nlp(input_text)
print("Predicted entities: ")
for entity in doc.ents:
    print(entity)</pre><p class="calibre3">We see that the resulting <a id="_idIndexMarker298" class="calibre6 pcalibre pcalibre1"/>entities are quite good (output results<a id="_idIndexMarker299" class="calibre6 pcalibre pcalibre1"/> may vary):</p><pre class="source-code">songs with themes of being unable to settle | ex hoziers someone new elle kings exes and ohs
Gold entities:
hoziers
someone new
elle kings
exes and ohs
Predicted entities:
hoziers
someone new
elle kings
exes and</pre></li>				<li class="calibre14">Here, we evaluate the model using spaCy’s <strong class="source-inline1">evaluate</strong> function. We see that the <strong class="source-inline1">WoA</strong> and <strong class="source-inline1">Artist</strong> tags have metrics that are low but in the double digits, while the <strong class="source-inline1">Artist_or_WoA</strong> tag has an F1 score of about 10%. This is due to the fact that it has much less data than the<a id="_idIndexMarker300" class="calibre6 pcalibre pcalibre1"/> other two tags. Overall, the performance of the model <a id="_idIndexMarker301" class="calibre6 pcalibre pcalibre1"/>according to the statistics is not very good, and that is because we have a very small amount of data overall:<pre class="source-code">
evaluate('../models/spacy_music_ner/model-last', '../data/music_ner_tes t.spacy')</pre><p class="calibre3">The statistics might vary, but here is the output I got (output condensed):</p><pre class="source-code">{'token_acc': 1.0,
 'token_p': 1.0,
 'token_r': 1.0,
 'token_f': 1.0,
 'tag_acc': 0.800658978583196,
…
 'ents_p': 0.4421052631578947,
 'ents_r': 0.42,
 'ents_f': 0.4307692307692308,
 'ents_per_type': {'WoA': {'p': 0.4358974358974359,
   'r': 0.425,
   'f': 0.43037974683544306},
  'Artist_or_WoA': {'p': 0.1,
   'r': 0.09090909090909091,
   'f': 0.09523809523809525},
  'Artist': {'p': 0.5217391304347826,
   'r': 0.4897959183673469,
   'f': 0.5052631578947369}},
 'speed': 3835.591242612551}</pre></li>			</ol>
			<h2 id="_idParaDest-148" class="calibre5"><a id="_idTextAnchor152" class="calibre6 pcalibre pcalibre1"/>See also</h2>
			<p class="calibre3">The spaCy NER model is a <a id="_idIndexMarker302" class="calibre6 pcalibre pcalibre1"/>neural network model. You can learn more <a id="_idIndexMarker303" class="calibre6 pcalibre pcalibre1"/>about its architecture from the spaCy documentation: <a href="https://spacy.io/models#architecture" class="calibre6 pcalibre pcalibre1">https://spacy.io/models#architecture</a>.</p>
			<h1 id="_idParaDest-149" class="calibre7"><a id="_idTextAnchor153" class="calibre6 pcalibre pcalibre1"/>Fine-tuning BERT for NER</h1>
			<p class="calibre3">In this recipe, we will fine-tune the pretrained BERT model for the NER task. The difference between training a model from scratch and fine-tuning it is as follows. Fine-tuning an NLP model, such as BERT, involves<a id="_idIndexMarker304" class="calibre6 pcalibre pcalibre1"/> taking a pretrained model and modifying it for your specific task, such as NER in this case. The pretrained model already has lots of knowledge stored in it and the results are likely to be better than when training a model from scratch.</p>
			<p class="calibre3">We will use similar data as in the previous recipe, creating a model that can tag entities as <code>Artist</code> or <code>WoA</code>. The data comes from the same dataset but it is labeled using the IOB format, which is required for the <code>transformers</code> packages we are going to use. We also only use the <code>Artist</code> and <code>WoA</code> tags, removing the <code>Artist_or_WoA</code> tag, since there is not enough data for that tag.</p>
			<p class="calibre3">For this recipe, we will use the Hugging Face <code>Trainer</code> class, although it is also possible to train Hugging Face models using PyTorch or Tensorflow. See more at <a href="https://huggingface.co/docs/transformers/training" class="calibre6 pcalibre pcalibre1">https://huggingface.co/docs/transformers/training</a>.</p>
			<h2 id="_idParaDest-150" class="calibre5"><a id="_idTextAnchor154" class="calibre6 pcalibre pcalibre1"/>Getting ready</h2>
			<p class="calibre3">We will use the <code>transformers</code> package from Hugging Face. It is preloaded in the Poetry environment. You can also install the package from the <code>requirements.txt</code> file.</p>
			<p class="calibre3">The notebook is located at <a href="https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter05/5.6_fine_tune_bert.ipynb" class="calibre6 pcalibre pcalibre1">https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter05/5.6_fine_tune_bert.ipynb</a>.</p>
			<h2 id="_idParaDest-151" class="calibre5"><a id="_idTextAnchor155" class="calibre6 pcalibre pcalibre1"/>How to do it…</h2>
			<p class="calibre3">We will load and preprocess the data, train the model, and evaluate it, and then we will use it on unseen data. Your <a id="_idIndexMarker305" class="calibre6 pcalibre pcalibre1"/>steps should be formatted like so:</p>
			<ol class="calibre13">
				<li class="calibre14">Run the language utilities notebook:<pre class="source-code">
%run -i "../util/lang_utils.ipynb"</pre></li>				<li class="calibre14">Import other packages and functions:<pre class="source-code">
from datasets import (
    load_dataset, Dataset, Features, Value,
    ClassLabel, Sequence, DatasetDict)
import pandas as pd
from transformers import AutoTokenizer, AutoModel
from transformers import DataCollatorForTokenClassification
from transformers import (
    AutoModelForTokenClassification,
    TrainingArguments, Trainer)
import numpy as np
from sklearn.model_selection import train_test_split
from evaluate import load</pre></li>				<li class="calibre14">In this step, we load the music NER dataset using the pandas <strong class="source-inline1">read_csv</strong> function. We then define a function that takes a label, splits it on the underscore, and removes <a id="_idIndexMarker306" class="calibre6 pcalibre pcalibre1"/>the last part (<strong class="source-inline1">_deduced</strong>). We then apply this function to the <strong class="source-inline1">label</strong> column. We also substitute the <strong class="source-inline1">|</strong> character in case it could interfere with our code:<pre class="source-code">
music_ner_df = pd.read_csv('../data/music_ner.csv')
def change_label(input_label):
    input_label = input_label.replace("_deduced", "")
    return input_label
music_ner_df["label"] = music_ner_df["label"].apply(
    change_label)
music_ner_df["text"] = music_ner_df["text"].apply(
    lambda x: x.replace("|", ","))
print(music_ner_df)</pre><p class="calibre3">The output will look similar to this:</p></li>			</ol>
			<div><div><img src="img/B18411_05_5.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 5.5 – Dataset DataFrame</p>
			<ol class="calibre13">
				<li value="4" class="calibre14">Here, we start our data preprocessing. We get the list of unique IDs from the <strong class="source-inline1">id</strong> column. We loop through this list and get the sentence that corresponds to the given ID. We then<a id="_idIndexMarker307" class="calibre6 pcalibre pcalibre1"/> process the text using the spaCy small model and add the entities from the DataFrame into the <strong class="source-inline1">Doc</strong> object. We then store each of these sentences in a dictionary in which the keys are the sentence text strings and the values are the <strong class="source-inline1">Doc</strong> objects:<pre class="source-code">
ids = list(set(music_ner_df["id"].values))
docs = {}
for id in ids:
    entity_rows = music_ner_df.loc[music_ner_df['id'] == id]
    text = entity_rows.head(1)["text"].values[0]
    doc = small_model(text)
    ents = []
    for index, row in entity_rows.iterrows():
        label = row["label"]
        start = row["start_offset"]
        end = row["end_offset"]
        span = doc.char_span(start, end, label=label,
            alignment_mode="contract")
        ents.append(span)
    doc.ents = ents
    docs[doc.text] = doc</pre></li>				<li class="calibre14">Now, we load the data in IOB format. This format is required to fine-tune BERT, as opposed to the format used by spaCy. For that, we load a separate data file, <strong class="source-inline1">../data/music_ner_bio.bio</strong>. We create a dictionary of tag mappings and initialize empty lists for tokens, NER tags, and spans. We then loop through the sentence data we read from<a id="_idIndexMarker308" class="calibre6 pcalibre pcalibre1"/> the data file. For each sentence, each line is a pair of a word and its label. We append the words to the <strong class="source-inline1">words</strong> list and the numbers corresponding to the labels to the <strong class="source-inline1">tags</strong> list. We also get the spans from the dictionary of <strong class="source-inline1">Doc</strong> objects we created in the previous step and append those to the <strong class="source-inline1">spans</strong> list:<pre class="source-code">
data_file = "../data/music_ner_bio.bio"
tag_mapping = {"O": 0, "B-Artist": 1, "I-Artist": 2, 
    "B-WoA": 3, "I-WoA": 4}
with open(data_file) as f:
    data = f.read()
tokens = []
ner_tags = []
spans = []
sentences = data.split("\n\n")
for sentence in sentences:
    words = []
    tags = []
    this_sentence_spans = []
    word_tag_pairs = sentence.split("\n")
    for pair in word_tag_pairs:
        (word, tag) = pair.split("\t")
        words.append(word)
        tags.append(tag_mapping[tag])
    sentence_text = " ".join(words)
    try:
        doc = docs[sentence_text]
    except:
        pass
    ent_dict = {}
    for ent in doc.ents:
        this_sentence_spans.append(f"{ent.label_}: {ent.text}")
    tokens.append(words)
    ner_tags.append(tags)
    spans.append(this_sentence_spans)</pre></li>				<li class="calibre14">Here, we split the data into training and testing. For that, we split the indices of the <strong class="source-inline1">spans</strong> list. Then, we create separate<a id="_idIndexMarker309" class="calibre6 pcalibre pcalibre1"/> tokens, NER tags, and <strong class="source-inline1">spans</strong> lists for training and test data:<pre class="source-code">
indices = range(0, len(spans))
train, test = train_test_split(indices, test_size=0.1)
train_tokens = []
test_tokens = []
train_ner_tags = []
test_ner_tags = []
train_spans = []
test_spans = []
for i, (token, ner_tag, span) in enumerate(
    zip(tokens, ner_tags, spans)
):
    if i in train:
        train_tokens.append(token)
        train_ner_tags.append(ner_tag)
        train_spans.append(span)
    else:
        test_tokens.append(token)
        test_ner_tags.append(ner_tag)
        test_spans.append(span)
print(len(train_spans))
print(len(test_spans))</pre><p class="calibre3">The output will be as follows:</p><pre class="source-code">539
60</pre></li>				<li class="calibre14"> In this step, we create new DataFrames from the training and test lists we compiled in <em class="italic">step 6</em>. We then join the contents of the <strong class="source-inline1">tokens</strong> column with spaces to get a sentence string<a id="_idIndexMarker310" class="calibre6 pcalibre pcalibre1"/> instead of a list of words. We then drop empty data using the <strong class="source-inline1">dropna()</strong> function and print the contents of the test DataFrame:<pre class="source-code">
training_df = pd.DataFrame({"tokens":train_tokens,
    "ner_tags": train_ner_tags, "spans": train_spans})
test_df = pd.DataFrame({"tokens": test_tokens,
    "ner_tags": test_ner_tags, "spans": test_spans})
training_df["text"] = training_df["tokens"].apply(
    lambda x: " ".join(x))
test_df["text"] = test_df["tokens"].apply(lambda x: " ".join(x))
training_df.dropna()
test_df.dropna()
print(test_df)</pre><p class="calibre3">The result will look like this:</p><pre class="source-code">                                               tokens  \
0   [i, love, radioheads, kid, a, something, simil...
1   [bluesy, songs, kinda, like, evil, woman, by, ...
...
58  [looking, for, like, electronic, music, with, ...
59  [looking, for, pop, songs, about, the, end, of...
                                             ner_tags  \
0       [0, 0, 1, 3, 4, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0]
1                         [0, 0, 0, 0, 3, 4, 0, 1, 2]
...
58      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
59                     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
                                                spans  \
0     [Artist: radioheads, Artist_or_WoA: aphex twin]
1            [WoA: evil woman, Artist: black sabbath]
...
58  [WoA: the piper at the gates of dawn, Artist: ...
59  [WoA: the piper at the gates of dawn, Artist: ...
                                                 text
0   i love radioheads kid a something similar , ki...
1   bluesy songs kinda like evil woman by black sa...
...
58  looking for like electronic music with a depre...
59   looking for pop songs about the end of the world</pre></li>				<li class="calibre14">Here, we load the pretrained model and tokenizer and initialize the <strong class="source-inline1">Dataset</strong> objects. The <strong class="source-inline1">Features</strong> object describes the data and its properties. We create one training and one test <strong class="source-inline1">Dataset</strong> object. We use the <strong class="source-inline1">Features</strong> object we created, and the <a id="_idIndexMarker311" class="calibre6 pcalibre pcalibre1"/>DataFrames we initialized in the previous step. We then add these newly created <strong class="source-inline1">Dataset</strong> objects to <strong class="source-inline1">DatasetDict</strong>, with one entry for the training dataset and one for the test data. We then print out the resulting object:<pre class="source-code">
tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')
features = Features(
    {'tokens': Sequence(feature=Value(dtype='string',
            id=None),
        length=-1, id=None),
            'ner_tags': Sequence(feature=ClassLabel(
                names=['O', 'B-Artist', 'I-Artist',
                'B-WoA', 'I-WoA'], id=None),
                length=-1, id=None),
            'spans': Sequence(
                feature=Value(dtype='string',id=None),
                length=-1, id=None),
            'text': Value(dtype='string', id=None)
                    })
training_dataset = Dataset.from_pandas(
    training_df, features=features)
test_dataset = Dataset.from_pandas(test_df, features=features)
dataset = DatasetDict({"train":training_dataset, 
    "test":test_dataset})
print(dataset["train"].features)
label_names = \
    dataset["train"].features["ner_tags"].feature.names
print(dataset)</pre><p class="calibre3">The result will be <a id="_idIndexMarker312" class="calibre6 pcalibre pcalibre1"/>as follows:</p><pre class="source-code">{'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'ner_tags': Sequence(feature=ClassLabel(names=['O', 'B-Artist', 'I-Artist', 'B-WoA', 'I-WoA'], id=None), length=-1, id=None), 'spans': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'text': Value(dtype='string', id=None)}
DatasetDict({
    train: Dataset({
        features: ['tokens', 'ner_tags', 'spans', 'text'],
        num_rows: 539
    })
    test: Dataset({
        features: ['tokens', 'ner_tags', 'spans', 'text'],
        num_rows: 60
    })
})</pre></li>				<li class="calibre14">In this step, we create the <strong class="source-inline1">tokenize_adjust_labels</strong> function that will assign the correct labels to word parts. We define the <strong class="source-inline1">tokenize_adjust_labels</strong> function. The BERT tokenizer splits some words into components, and we need to make sure that the same label is assigned to each word part. The<a id="_idIndexMarker313" class="calibre6 pcalibre pcalibre1"/> function first tokenizes all the text samples using the preloaded tokenizer. It then loops through the input IDs of the tokenized samples and adjusts the labels according to the word parts:<pre class="source-code">
def tokenize_adjust_labels(all_samples_per_split):
    tokenized_samples = tokenizer.batch_encode_plus(
    all_samples_per_split["text"])
    total_adjusted_labels = []
    for k in range(0, len(tokenized_samples["input_ids"])):
        prev_wid = -1
        word_ids_list = tokenized_samples.word_ids(
            batch_index=k)
        existing_label_ids = all_samples_per_split[
            "ner_tags"][k]
        i = -1
        adjusted_label_ids = []
        for wid in word_ids_list:
            if (wid is None):
                adjusted_label_ids.append(-100)
            elif (wid != prev_wid):
                i = i + 1
                adjusted_label_ids.append(existing_label_ids[i])
                prev_wid = wid
            else:
                label_name =label_names[existing_label_ids[i]]
                adjusted_label_ids.append(existing_label_ids[i])
        total_adjusted_labels.append(adjusted_label_ids)
    tokenized_samples["labels"] = total_adjusted_labels
    return tokenized_samples</pre></li>				<li class="calibre14">Use the previous function on the dataset:<pre class="source-code">
tokenized_dataset = dataset.map(tokenize_adjust_labels, 
    batched=True)</pre></li>				<li class="calibre14">Here, we initialize the data <a id="_idIndexMarker314" class="calibre6 pcalibre pcalibre1"/>collator object. Data collators simplify the handling of data for training, for example, padding and truncating the input for all inputs to be of the same length:<pre class="source-code">
data_collator = DataCollatorForTokenClassification(tokenizer)</pre></li>				<li class="calibre14">Now, we create the <strong class="source-inline1">compute_metrics</strong> function, which calculates evaluation metrics, including precision, recall, F1 score, and accuracy. In the function, we delete all the tokens that <a id="_idIndexMarker315" class="calibre6 pcalibre pcalibre1"/>have the label <strong class="source-inline1">-100</strong>, which are the special tokens. This function uses the <strong class="source-inline1">seqeval</strong> evaluation method commonly used to evaluate NER tasks:<pre class="source-code">
metric = load("seqeval")
def compute_metrics(data):
    predictions, labels = data
    predictions = np.argmax(predictions, axis=2)
    data = zip(predictions, labels)
    data = [
        [(p, l) for (p, l) in zip(prediction, label) 
            if l != -100]
        for prediction, label in data
    ]
    true_predictions = [
        [label_names[p] for (p, l) in data_point]
        for data_point in data
    ]
    true_labels = [
        [label_names[l] for (p, l) in data_point]
        for data_point in data
    ]
    results = metric.compute(predictions=true_predictions, 
        references=true_labels)
    flat_results = {
        "overall_precision": results["overall_precision"],
        "overall_recall": results["overall_recall"],
        "overall_f1": results["overall_f1"],
        "overall_accuracy": results["overall_accuracy"],
    }
    for k in results.keys():
      if (k not in flat_results.keys()):
        flat_results[k + "_f1"] = results[k]["f1"]
    return flat_results</pre></li>				<li class="calibre14">Here, we load the pretrained BERT model (the uncased version since our input is in lowercase). We then specify the training arguments by initializing the <strong class="source-inline1">TrainingArguments</strong> object. This object contains the model hyperparameters. We then initialize <a id="_idIndexMarker316" class="calibre6 pcalibre pcalibre1"/>the <strong class="source-inline1">Trainer</strong> object by providing the training arguments, dataset, tokenizer, data collator, and <strong class="source-inline1">metrics </strong>function. We then start the training process:<pre class="source-code">
model = AutoModelForTokenClassification.from_pretrained(
    'bert-base-uncased', num_labels=len(label_names))
training_args = TrainingArguments(
    output_dir="./fine_tune_bert_output",
    evaluation_strategy="steps",
    learning_rate=2e-5,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    num_train_epochs=7,
    weight_decay=0.01,
    logging_steps = 1000,
    run_name = "ep_10_tokenized_11",
    save_strategy='no'
)
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_dataset["train"],
    eval_dataset=tokenized_dataset["test"],
    data_collator=data_collator,
    tokenizer=tokenizer,
    compute_metrics=compute_metrics
)
trainer.train()</pre><p class="calibre3">The output will include different information, including the following:</p><pre class="source-code">TrainOutput(global_step=238, training_loss=0.25769581514246326, metrics={'train_runtime': 25.8951, 'train_samples_per_second': 145.703, 'train_steps_per_second': 9.191, 'total_flos': 49438483110900.0, 'train_loss': 0.25769581514246326, 'epoch': 7.0})</pre></li>				<li class="calibre14">In this step, we evaluate the fine-tuned model:<pre class="source-code">
trainer.evaluate()</pre><p class="calibre3">For the <code>Artist</code> label, it<a id="_idIndexMarker317" class="calibre6 pcalibre pcalibre1"/> achieves an F1 score of 76%, and for the <code>WoA</code> label, it achieves an F1 score of 52%:</p><pre class="source-code">{'eval_loss': 0.28670933842658997,
 'eval_overall_precision': 0.6470588235294118,
 'eval_overall_recall': 0.7096774193548387,
 'eval_overall_f1': 0.6769230769230768,
 'eval_overall_accuracy': 0.9153605015673981,
 'eval_Artist_f1': 0.761904761904762,
 'eval_WoA_f1': 0.5217391304347826,
 'eval_runtime': 0.3239,
 'eval_samples_per_second': 185.262,
 'eval_steps_per_second': 12.351,
 'epoch': 7.0}</pre></li>				<li class="calibre14">Save the model:<pre class="source-code">
trainer.save_model("../models/bert_fine_tuned")</pre></li>				<li class="calibre14">Now, load the trained model:<pre class="source-code">
model = AutoModelForTokenClassification.from_pretrained("../models/bert_fine_tuned")
tokenizer = AutoTokenizer.from_pretrained(
    "../models/bert_fine_tuned")</pre></li>				<li class="calibre14">Here, we test the fine-tuned model on an unseen text. We initialize the <strong class="source-inline1">text</strong> variable. We then load the <strong class="source-inline1">pipeline</strong> package to create a pipeline we will use. A text-processing pipeline takes the text to its final output value processed by the model. This particular pipeline specifies the task as <strong class="source-inline1">token-classification</strong>, which fine-tuned model to use, the corresponding tokenizer, and the aggregation <a id="_idIndexMarker318" class="calibre6 pcalibre pcalibre1"/>strategy. The aggregation strategy parameter specifies how to combine the results of several models when several models are used. We then run the pipeline on the text:<pre class="source-code">
text = "music similar to morphine robocobra quartet | featuring elements like saxophone prominent bass"
from transformers import pipeline
pipe = pipeline(task="token-classification",
    model=model.to("cpu"), tokenizer=tokenizer,
    aggregation_strategy="simple")
pipe(text)
# tag_mapping = {"O": 0, "B-Artist": 1, "I-Artist": 2, "B-WoA": 3, "I-WoA": 4}</pre><p class="calibre3">The output will vary. The sample output identifies the music artist, <em class="italic">Morphine </em><em class="italic">Robocobra Quartet</em>:</p><pre class="source-code">[{'entity_group': 'LABEL_0',
  'score': 0.9991929,
  'word': 'music similar to',
  'start': 0,
  'end': 16},
 {'entity_group': 'LABEL_1',
  'score': 0.8970744,
  'word': 'morphine robocobra',
  'start': 17,
  'end': 35},
 {'entity_group': 'LABEL_2',
  'score': 0.5060059,
  'word': 'quartet',
  'start': 36,
  'end': 43},
 {'entity_group': 'LABEL_0',
  'score': 0.9988042,
  'word': '| featuring elements like saxophone prominent bass',
  'start': 44,
  'end': 94}]</pre></li>			</ol>
			<p class="calibre3">We can see that the labels <a id="_idIndexMarker319" class="calibre6 pcalibre pcalibre1"/>assigned by the model are correct.</p>
		</div>
	</body></html>