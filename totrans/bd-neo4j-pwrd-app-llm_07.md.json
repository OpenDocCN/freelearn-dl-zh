["```py\nInception.\n```", "```py\ndef fetch_multi_hop_related_movies(title):\n    query = \"\"\"\n    MATCH (m:Movie {title: $title})<-[:DIRECTED]-(d:Director)-[:DIRECTED]->(related:Movie)\n    RETURN related.title AS related_movie, related.overview AS overview\n    \"\"\"\n    with driver.session() as session:\n        result = session.run(query, title=title)\n        documents = [\n            {\n                \"content\": record[\"overview\"],\n                \"meta\": {\"title\": record[\"related_movie\"]}\n            }\n            for record in result\n        ]\n    return documents\ndef perform_similarity_search_with_multi_hop(query, movie_title):\n    # Fetch multi-hop related movies from Neo4j\n    multi_hop_docs = fetch_multi_hop_related_movies(movie_title)\n    if not multi_hop_docs:\n        print(f\"No related movies found for {movie_title}\")\n        return\n    # Write these documents to the document store\n    document_store.write_documents(multi_hop_docs)\n    # Generate embedding for the search query (e.g., \"time travel\")\n    query_embedding = text_embedder.run(query).get(\"embedding\")\n    if query_embedding is None:\n        print(\"Query embedding not created successfully.\")\n        return\n    # Perform vector search only on the multi-hop related movies\n    similar_docs = document_store.query_by_embedding(\n        query_embedding, top_k=3\n    )\n    if not similar_docs:\n        print(\"No similar documents found.\")\n        return\n    for doc in similar_docs:\n        title = doc.meta.get(\"title\", \"N/A\")\n        overview = doc.meta.get(\"overview\", \"N/A\")\n        score = doc.score\n        print(\n            f\"Title: {title}\\nOverview: {overview}\\n\"\n            f\"Score: {score:.2f}\\n{'-'*40}\"\n        )\n    print(\"\\n\\n\") \n```", "```py\ndef perform_filtered_search(query):\n    pipeline = Pipeline()\n    pipeline.add_component(\"query_embedder\", text_embedder)\n    # pipeline.add_component(\"retriever\", retriever)\n    pipeline.add_component(\n        \"retriever\", \n        Neo4jEmbeddingRetriever(document_store=document_store)\n    )\n    pipeline.connect(\n        \"query_embedder.embedding\", \"retriever.query_embedding\"\n    )\n    result = pipeline.run(\n        data={\n            \"query_embedder\": {\"text\": query},\n            \"retriever\": {\n                \"top_k\": 5,\n                \"filters\": {\n                    \"field\": \"release_date\", \"operator\": \">=\", \n                    \"value\": \"1995-11-17\"\n                },\n            },\n        }\n    )\n    # Extracting documents from the retriever results\n    documents = result[\"retriever\"][\"documents\"]\n    for doc in documents:\n        # Extract title and overview from document metadata\n        title = doc.meta.get(\"title\", \"N/A\")\n        overview = doc.meta.get(\"overview\", \"N/A\")\n        # Extract score from the document (not from meta)\n        score = getattr(doc, \"score\", None)\n        # Format score if it exists, else show \"N/A\"\n        score_display = f\"{score:.2f}\" if score is not None else \"N/A\"\n        # Print the title, overview, and score (or N/A for missing score)\n        print(\n            f\"Title: {title}\\nOverview: {overview}\\n\"\n            f\"Score: {score_display}\\n{'-'*40}\\n\"\n        ) \ndemonstrates how to apply dynamic filters, such as release_date, to refine search results. By incorporating these filters, you can add constraints on specific fields—for instance, showing only documents from a certain date onward or filtering by specific attributes such as category or rating. This capability allows you to narrow down results to what is most relevant to them, effectively enhancing the search functionality. Using this approach, you can easily extend or modify filters to suit different needs, offering a flexible and powerful way to interact with data in the knowledge graph.\n```", "```py\ndef perform_optimized_search(query, top_k):\n       optimized_results = document_store.query_by_embedding(\n            query_embedding=text_embedder.run(query).get(\"embedding\"), \n            top_k=top_k\n        )\n    for doc in optimized_results:\n        title = doc.meta[\"title\"]\n        overview = doc.meta.get(\"overview\", \"N/A\")\n        print(f\"Title: {title}\\nOverview: {overview}\\n{'-'*40}\") \n```", "```py\ndef fetch_multi_hop_related_movies(title):\n    query = \"\"\"\n    MATCH (m:Movie {title: $title})<-[:ACTED_IN|DIRECTED]-(p)-\n        [:ACTED_IN|DIRECTED]->(related:Movie)\n    WITH related.title AS related_movie, p.name AS person,\n         CASE\n            WHEN (p)-[:ACTED_IN]->(m) AND (p)-[:ACTED_IN]->(related) THEN 'Actor'\n            WHEN (p)-[:DIRECTED]->(m) AND (p)-[:DIRECTED]->(related) THEN 'Director'\n            ELSE 'Unknown Role'\n         END AS role,\n         related.overview AS overview, related.embedding AS embedding\n     RETURN related_movie, person, role, overview, embedding\n    \"\"\"\n    with driver.session() as session:\n        result = session.run(query, title=title)\n        documents = []\n        for record in result:\n            documents.append(\n                Document(\n                    content=record.get(\"overview\", \"No overview available\"),  # Store overview in content\n                    meta={\n                        \"title\": record.get(\"related_movie\", \"Unknown Movie\"),  # Movie title\n                        \"person\": record.get(\"person\", \"Unknown Person\"),       # Actor/Director's name\n                        \"role\": record.get(\"role\", \"Unknown Role\"),              # Actor or Director\n                        \"embedding\": record.get(\"embedding\", \"No embedding available\")  # Retrieve the precomputed embedding\n                    },\n                )\n            )\n    return documents \n```", "```py\nMATCH path = (m1:Movie {title: \"Inception\"})-[:ACTED_IN*3]-(m2:Movie)\nRETURN m1.title, m2.title, path \n```", "```py\n    CREATE INDEX FOR (m:Movie) ON (m.title);\n    CREATE INDEX FOR (p:Person) ON (p.name); \n    ```", "```py\n    PROFILE MATCH (m:Movie {title: \"Inception\"}) RETURN m; \n    ```", "```py\n    MATCH (m:Movie)-[:ACTED_IN]->(a:Actor) RETURN m.title LIMIT 10; \n    ```", "```py\n    # Example of caching embeddings\n    embedding_cache = {}  # Simple in-memory cache, replace with Redis for larger setups\n    def get_cached_embedding(query):\n        if query in embedding_cache:\n            return embedding_cache[query]\n        else:\n            embedding = text_embedder.run(query).get(\"embedding\")\n            embedding_cache[query] = embedding\n            return embedding \n    ```", "```py\n    # Example using a Redis cache for Neo4j query results\n    import redis\n    cache = redis.Redis()\n    def get_cached_query_result(query):\n        cached_result = cache.get(query)\n        if cached_result:\n            return cached_result\n        else:\n            # Run the query against Neo4j\n            result = run_neo4j_query(query)\n            cache.set(query, result)\n            return result \n    ```", "```py\n    CREATE VECTOR INDEX overview_embeddings IF NOT EXISTS\n    FOR (m:Movie) ON (m.embedding)\n    OPTIONS {\n        indexConfig: {\n            `vector.dimensions`: 1536, \n            `vector.similarity_function`: 'cosine'\n        }\n    } \n    ```", "```py\n    document_store.write_documents(embeddings_list, batch_size=100)  \n    # Batch size optimized for performance \n    ```", "```py\n    apiVersion: apps/v1\n    kind: Deployment\n    metadata:\n      name: haystack-deployment\n    spec:\n      replicas: 3  # Number of replicas to scale based on traffic\n      selector:\n        matchLabels:\n          app: haystack\n      template:\n        metadata:\n          labels:\n            app: haystack\n        spec:\n          containers:\n          - name: haystack\n            image: haystack:latest \n    ```", "```py\n# Example: Monitor response time of a query in Haystack\nimport time\nstart_time = time.time()\nresult = retriever.retrieve(query)\nend_time = time.time()\nresponse_time = end_time - start_time\nprint(f\"Query response time: {response_time} seconds\") \n```"]