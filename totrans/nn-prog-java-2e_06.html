<html><head></head><body><div id="sbo-rt-content" class="calibre1"><div class="calibre2" title="Chapter 6. Classifying Disease Diagnosis"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h1 class="title"><a id="ch06" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Chapter 6. Classifying Disease Diagnosis</h1></div></div></div><p class="calibre11">So far, we have been working with supervised learning for predicting numerical values; however, in the real world, numbers are just part of the data addressed. Real variables also contain categorical values, which are not purely numerical, but describe important features that have influence on the problems neural networks are applied to solve. In this chapter, the reader will be presented with a very didactic but interesting application involving categorical values and classification: disease diagnosis. This chapter digs deeper into classification problems and how to represent categorical data, as well as showing how to design a classification algorithm using neural networks. The topics covered in this chapter are as follows:</p><div class="calibre2"><ul class="itemizedlist"><li class="listitem">Foundations of classification problems</li><li class="listitem">Categorical data</li><li class="listitem">Logistic regression</li><li class="listitem">Confusion matrix</li><li class="listitem">Sensibility and specificity</li><li class="listitem">Neural networks for classification</li><li class="listitem">Disease diagnosis using neural networks</li><li class="listitem">Diagnosis for cancer</li><li class="listitem">Diagnosis for diabetes</li></ul></div><div class="calibre2" title="Foundations of classification problems"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h1 class="title2"><a id="ch06lvl1sec42" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Foundations of classification problems</h1></div></div></div><p class="calibre11">One thing<a id="id399" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> neural networks are really good at is classifying records. The very simple perceptron network draws a decision boundary, defining whether a data point belongs to one region or another, whereas a region denotes a class. Let's take a look visually on an <span class="strong1"><em class="calibre16">x-y</em></span> scatter chart:</p><div class="mediaobject"><img src="Images/B05964_06_01.jpg" alt="Foundations of classification problems" class="calibre178"/></div><p class="calibre11">The dashed lines explicitly separate the points into classes. These points represent data records which originally had the corresponding class labels. That means their classes were already<a id="id400" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> known, therefore this classification tasks falls in the supervised learning category.</p><p class="calibre11">A classification algorithm seeks to find the boundaries between the classes in the data hyperspace. Once the classification boundaries are defined, a new data point, with an unknown class, receives a class label according to the boundaries defined by the classification algorithm. The figure below shows how a new record is classified:</p><div class="mediaobject"><img src="Images/B05964_06_02.jpg" alt="Foundations of classification problems" class="calibre179"/></div><p class="calibre11">Based on the<a id="id401" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> current class configuration, the new record's class is the third class.</p><div class="calibre2" title="Categorical data"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h2 class="title5"><a id="ch06lvl2sec81" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Categorical data</h2></div></div></div><p class="calibre11">Applications<a id="id402" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> usually lead with the types of data shown in the <a id="id403" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>following figure:</p><div class="mediaobject"><img src="Images/B05964_06_03.jpg" alt="Categorical data" class="calibre180"/></div><p class="calibre11">Data can be numerical or categorical or, simply speaking, numbers or words. Numerical data is represented by a numeric value, from which it can be continuous or discrete. This data type has been used so far in this book's applications. Categorical data is a wider class of data that includes words, letters, or even numbers, but with a quite different meaning. While numerical data can support arithmetic operations, categorical data is only descriptive and cannot be processed like numbers, even if the value is a number. An example is the severity degree of a disease in a scale (from zero to five, for example). Another property of categorical data is that a certain variable has a finite number of values; in other words, only a defined set of values can be assigned to a categorical variable. A subclass of data inside the categorical is ordinal data. This class is particular because the defined values can be sorted in a predefined order. An example is adjectives indicating the state or quality of something (bad, fair, good, excellent):</p><div class="informaltable"><table border="1" class="calibre20"><colgroup class="calibre21"><col class="calibre22"/><col class="calibre22"/><col class="calibre22"/><col class="calibre22"/></colgroup><thead class="calibre23"><tr class="calibre24"><th colspan="2" valign="bottom" class="calibre80">
<p class="calibre26">Numerical</p>
</th><th colspan="2" valign="bottom" class="calibre80">
<p class="calibre26">Categorical</p>
</th></tr></thead><tbody class="calibre27"><tr class="calibre31"><td colspan="2" class="calibre181">
<p class="calibre26">Only numbers</p>
</td><td colspan="2" class="calibre181">
<p class="calibre26">Numbers, words, letters, signs</p>
</td></tr><tr class="calibre34"><td colspan="2" class="calibre181">
<p class="calibre26">Can support arithmetic operations</p>
</td><td colspan="2" class="calibre181">
<p class="calibre26">Do not support arithmetic operations</p>
</td></tr><tr class="calibre31"><td colspan="2" class="calibre181">
<p class="calibre26">Infinite or undefined range of values</p>
</td><td colspan="2" class="calibre181">
<p class="calibre26">Finite or defined set of values</p>
</td></tr><tr class="calibre34"><td class="calibre29">
<p class="calibre26">Continuous</p>
</td><td class="calibre29">
<p class="calibre26">Discrete</p>
</td><td class="calibre29">
<p class="calibre26">Ordinal</p>
</td><td class="calibre29">
<p class="calibre26">Non-ordinal</p>
</td></tr><tr class="calibre31"><td class="calibre29">
<p class="calibre26">Real values</p>
</td><td class="calibre29">
<p class="calibre26">Integers, decimal</p>
</td><td class="calibre29">
<p class="calibre26">Can be ordered</p>
</td><td class="calibre29">
<p class="calibre26">Cannot be ordered</p>
</td></tr><tr class="calibre37"><td class="calibre29">
<p class="calibre26">Any possible value</p>
</td><td class="calibre29">
<p class="calibre26">Predefined intervals</p>
</td><td class="calibre29">
<p class="calibre26">Can be assigned numbers</p>
</td><td class="calibre29">
<p class="calibre26">Each possible value is a flag</p>
</td></tr></tbody></table></div><div class="sidebar" title="Note"><div class="inner"><h3 class="title6"><a id="tip23" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Tip</h3><p class="calibre17">Note that here we are addressing structured data only. In the real world, most data is unstructured, including text and multimedia content. Although these types of data are also processed in learning from data applications, neural networks require them to be transformed into structured data types.</p></div></div></div><div class="calibre2" title="Working with categorical data"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h2 class="title5"><a id="ch06lvl2sec82" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Working with categorical data</h2></div></div></div><p class="calibre11">Structured data<a id="id404" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> files, such as those used in CSV or Excel, usually contain columns of numerical and categorical data. In <a class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2" href="ch05.xhtml" title="Chapter 5. Forecasting Weather">Chapter 5</a>, <span class="strong1"><em class="calibre16">Forecasting Weather</em></span> we have created the classes <code class="literal">LoadCsv</code> (for loading <code class="literal">csv</code> files) and DataSet (for storing data from csv), but these classes are prepared only for working with numerical data. The simplest way of representing categorical value is converting each possible value into a binary column, whereby if the given value is presented in the original column, the corresponding binary column will have a one as the converted value, otherwise it will be zero:</p><div class="mediaobject"><img src="Images/B05964_06_04.jpg" alt="Working with categorical data" class="calibre182"/></div><p class="calibre11">Ordinal columns can assume the defined values as numerical in the same column; however, if the original values are letters or words, they need to be converted into numbers via a Java Dictionary.</p><p class="calibre11">The strategy described above may be implemented by you as an exercise. Otherwise, you would have to handle this manually. In this case, depending on the number of data rows, it can be time-consuming.</p></div></div></div></div>



  
<div id="sbo-rt-content" class="calibre1"><div class="calibre2" title="Logistic regression"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h1 class="title2"><a id="ch06lvl1sec43" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Logistic regression</h1></div></div></div><p class="calibre11">We've covered <a id="id405" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>that Neural Networks can work as data classifiers by establishing decision boundaries onto data in the hyperspace. This boundary can be linear, in the case of perceptrons, or nonlinear, in the case of other neural architectures such as MLPs, Kohonen, or Adaline. The linear case is based on linear regression, on which the classification boundary is a literally a line, as shown in the previous figure. If the scatter chart of the data looks like that of the following figure, then a nonlinear classification boundary is needed:</p><div class="mediaobject"><img src="Images/B05964_06_05.jpg" alt="Logistic regression" class="calibre178"/></div><p class="calibre11">Neural Networks <a id="id406" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>are in fact a great nonlinear classifier, and this is achieved by the usage of nonlinear activation functions. One nonlinear function that actually works well for nonlinear classification is the sigmoid function, whereas the procedure for classification using this function is called logistic regression:</p><div class="mediaobject"><img src="Images/B05964_06_06.jpg" alt="Logistic regression" class="calibre183"/></div><p class="calibre11">This function returns values bounded between zero and one. In this function α parameter denotes how hard the transition from zero and 1 occurs. The following chart shows the difference:</p><div class="mediaobject"><img src="Images/B05964_06_06_01.jpg" alt="Logistic regression" class="calibre184"/></div><p class="calibre11">Note that the higher<a id="id407" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> the alpha parameter is, the more the logistic function takes a shape of a hard-limiting threshold function, also known as a step function.</p><div class="calibre2" title="Multiple classes versus binary classes"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h2 class="title5"><a id="ch06lvl2sec83" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Multiple classes versus binary classes</h2></div></div></div><p class="calibre11">Classification<a id="id408" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> problems usually deal with a <a id="id409" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>multiple class's case, where each <a id="id410" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>class is assigned a label. However, a binary classification schema is useful to be applied in neural networks. This is because a neural network with a logistic function at the output layer can produce only values between <code class="literal">0</code> and <code class="literal">1</code>, meaning it belongs (1) or does not belong (0) to some class.</p><p class="calibre11">Nevertheless, there is one approach for multiple classes using binary functions. Consider that every class is represented by an output neuron, and whenever that output neuron fires, that neuron's corresponding class is applied on the input data record. So let's suppose a network to classify diseases; each neuron output will represent a disease to be applied to some symptom:</p><div class="mediaobject"><img src="Images/B05964_06_07.jpg" alt="Multiple classes versus binary classes" class="calibre185"/></div><div class="sidebar" title="Note"><div class="inner"><h3 class="title6"><a id="tip24" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Tip</h3><p class="calibre17">Note <a id="id411" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>that in that <a id="id412" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>configuration, it would be possible<a id="id413" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> to have multiple diseases with the same symptoms, which can happen. However, if only one class would be desirable to be chosen, then a schema as the competitive learning algorithm would suit more in that case.</p></div></div></div><div class="calibre2" title="Confusion matrix"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h2 class="title5"><a id="ch06lvl2sec84" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Confusion matrix</h2></div></div></div><p class="calibre11">There is no<a id="id414" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> perfect classifier algorithm; all of them are<a id="id415" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> subject to errors and biases; however, it is expected that a classification algorithm can correctly classify 70-90% of the records.</p><div class="sidebar" title="Note"><div class="inner"><h3 class="title6"><a id="tip25" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Tip</h3><p class="calibre17">Very high correct classification rates are not always desirable, because of possible biases presented in the input data that might affect the classification task, and also there is a risk of overtraining, when only the training data is correctly classified.</p></div></div><p class="calibre11">A confusion matrix shows how much of a given class's records were correctly classified and thereby how much were wrongly classified. The following table depicts what a confusion matrix may look like:</p><div class="mediaobject"><img src="Images/B05964_06_08.jpg" alt="Confusion matrix" class="calibre186"/></div><p class="calibre11">Note that the main diagonal is expected to have the higher values, as the classification algorithm will always try to extract meaningful information from the input dataset. The sum of all rows must be equal to 100%, because all elements of a given class are to be classified in one of the available classes. Note that some classes may receive more classifications than expected.</p><p class="calibre11">The more a confusion matrix looks like an identity matrix, the better the classification algorithm will be.</p></div><div class="calibre2" title="Sensitivity and specificity"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h2 class="title5"><a id="ch06lvl2sec85" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Sensitivity and specificity</h2></div></div></div><p class="calibre11">When the<a id="id416" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> classification is binary, the confusion matrix is found <a id="id417" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>to be a simple 2x2 matrix, and therefore its positions are specially named:</p><div class="informaltable"><table border="1" class="calibre20"><colgroup class="calibre21"><col class="calibre22"/><col class="calibre22"/><col class="calibre22"/></colgroup><thead class="calibre23"><tr class="calibre24"><th rowspan="2" valign="bottom" class="calibre25">
<p class="calibre26">Actual Class</p>
</th><th colspan="2" valign="bottom" class="calibre80">
<p class="calibre26">Inferred Class</p>
</th></tr></thead><tbody class="calibre27"><tr class="calibre31"><td class="calibre29">
<p class="calibre26">Positive (1)</p>
</td><td class="calibre29">
<p class="calibre26">Negative (0)</p>
</td><td class="auto-generated"> </td></tr><tr class="calibre34"><td class="calibre29">
<p class="calibre26">Positive (1)</p>
</td><td class="calibre29">
<p class="calibre26">True Positive</p>
</td><td class="calibre29">
<p class="calibre26">False Negative</p>
</td></tr><tr class="calibre28"><td class="calibre29">
<p class="calibre26">Negative (0)</p>
</td><td class="calibre29">
<p class="calibre26">False Positive</p>
</td><td class="calibre29">
<p class="calibre26">True Negative</p>
</td></tr></tbody></table></div><p class="calibre11">In disease diagnosis, which is the subject of this chapter, the concept of a binary confusion matrix is applied in the sense that a false diagnosis may be either false positive or false negative. The rate of false results can be measured by sensitivity and specificity indexes.</p><p class="calibre11">Sensitivity means the true positive rate; it measures how many of the records are correctly classified positively:</p><div class="mediaobject"><img src="Images/B05964_06_09.jpg" alt="Sensitivity and specificity" class="calibre187"/></div><p class="calibre11">Specificity, in <a id="id418" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>turn, means the true negative rate; it indicates the <a id="id419" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>proportion of negative record identification:</p><div class="mediaobject"><img src="Images/B05964_06_10.jpg" alt="Sensitivity and specificity" class="calibre188"/></div><p class="calibre11">High values of both sensitivity and specificity are desired; however, depending on the application field, the sensitivity may carry more meaning.</p></div><div class="calibre2" title="Implementing a confusion matrix"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h2 class="title5"><a id="ch06lvl2sec86" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Implementing a confusion matrix</h2></div></div></div><p class="calibre11">In our code, let's implement the confusion matrix in the class <code class="literal">NeuralOutputData</code>. The method <code class="literal">calculateConfusionMatrix</code> below is programmed to consider two neurons in the output <a id="id420" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>layer. If the output is 10, then<a id="id421" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> it is <span class="strong1"><em class="calibre16">yes</em></span> to a confusion matrix; if the output is 01, then it is no:</p><div class="calibre2"><pre class="programlisting">public double[][] calculateConfusionMatrix(double[][] dataOutputTestAdapted, double[][] dataOutputTargetTestAdapted) {
    int TP = 0;
    int TN = 0;
    int FP = 0;
    int FN = 0;
    for (int m = 0; m &lt; getTargetData().length; m++) {
      if ( ( dataOutputTargetTestAdapted[m][0] == 1.0 &amp;&amp; dataOutputTargetTestAdapted[m][1] == 0.0 )
          &amp;&amp; ( dataOutputTestAdapted[m][0] == 1.0 &amp;&amp; dataOutputTestAdapted[m][1] == 0.0 ) ) {
        TP++;
      } else if ( ( dataOutputTargetTestAdapted[m][0] == 0.0 &amp;&amp; dataOutputTargetTestAdapted[m][1] == 1.0 )
          &amp;&amp; (  dataOutputTestAdapted[m][0] == 0.0 &amp;&amp; dataOutputTestAdapted[m][1] == 1.0 ) ) {
        TN++;            
      } else if ( ( dataOutputTargetTestAdapted[m][0] == 1.0 &amp;&amp; dataOutputTargetTestAdapted[m][1] == 0.0 )
          &amp;&amp; (  dataOutputTestAdapted[m][0] == 0.0 &amp;&amp; dataOutputTestAdapted[m][1] == 1.0 ) ) {
        FP++;
      } else if ( ( dataOutputTargetTestAdapted[m][0] == 0.0 &amp;&amp; dataOutputTargetTestAdapted[m][1] == 1.0 )
          &amp;&amp; (  dataOutputTestAdapted[m][0] == 1.0 &amp;&amp; dataOutputTestAdapted[m][1] == 0.0 ) ) {
        FN++;
      }
    }
    
    return new double[][] {{TP,FN},{FP,TN}};
    
  }</pre></div><p class="calibre11">Another<a id="id422" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> method implemented<a id="id423" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> in the <code class="literal">NeuralOutputData</code> class is called <code class="literal">calculatePerformanceMeasures</code>. It receives as parameter the confusion matrix and it calculates and prints the following performance measures of classification:</p><div class="calibre2"><ul class="itemizedlist"><li class="listitem">Positive class error rate</li><li class="listitem">Negative class error rate</li><li class="listitem">Total error rate</li><li class="listitem">Total accuracy</li><li class="listitem">Precision</li><li class="listitem">Sensibility</li><li class="listitem">Specificity</li></ul></div><p class="calibre11">This method is shown below:</p><div class="calibre2"><pre class="programlisting">public void calculatePerformanceMeasures(double[][] confMat) {
    double errorRatePositive = confMat[0][1] / (confMat[0][0]+confMat[0][1]);
    double errorRateNegative = confMat[1][0] / (confMat[1][0]+confMat[1][1]);
    double totalErrorRate = (confMat[0][1] + confMat[1][0]) / (confMat[0][0] + confMat[0][1] + confMat[1][0] + confMat[1][1]);
    double totalAccuracy  = (confMat[0][0] + confMat[1][1]) / (confMat[0][0] + confMat[0][1] + confMat[1][0] + confMat[1][1]);
    double precision = confMat[0][0] / (confMat[0][0]+confMat[1][0]);
    double sensibility = confMat[0][0] / (confMat[0][0]+confMat[0][1]);
    double specificity = confMat[1][1] / (confMat[1][0]+confMat[1][1]);
    
    System.out.println("### PERFORMANCE MEASURES ###");
    System.out.println("positive class error rate: "+(errorRatePositive*100.0)+"%");
    System.out.println("negative class error rate: "+(errorRateNegative*100.0)+"%");
    System.out.println("total error rate: "+(totalErrorRate*100.0)+"%");
    System.out.println("total accuracy: "+(totalAccuracy*100.0)+"%");
    System.out.println("precision: "+(precision*100.0)+"%");
    System.out.println("sensibility: "+(sensibility*100.0)+"%");
    System.out.println("specificity: "+(specificity*100.0)+"%");
    
  }</pre></div></div></div></div>



  
<div id="sbo-rt-content" class="calibre1"><div class="calibre2" title="Neural networks for classification"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h1 class="title2"><a id="ch06lvl1sec44" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Neural networks for classification</h1></div></div></div><p class="calibre11">Classification <a id="id424" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>tasks can be done by any of the supervised <a id="id425" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>neural networks this book has covered so far. However, it is recommended that you use more complex architectures such as MLPs. In this chapter, we are going to use the <code class="literal">NeuralNet</code> class to build an MLP with one hidden layer and the sigmoid function at the output. Every output neuron will mean a class.</p><p class="calibre11">The code used to implement the examples is very similar to the test class (<code class="literal">BackpropagationTest</code>). However, the class <code class="literal">DiagnosisExample</code> asks which dataset the user would like to use and other neural network parameters, such as number of epochs, number of neurons in hidden layer, and learning rate.</p></div></div>



  
<div id="sbo-rt-content" class="calibre1"><div class="calibre2" title="Disease diagnosis with neural networks"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h1 class="title2"><a id="ch06lvl1sec45" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Disease diagnosis with neural networks</h1></div></div></div><p class="calibre11">For disease<a id="id426" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> diagnosis, we are going to use the free <a id="id427" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>dataset proben1, which is available <a id="id428" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>on the Web (<a class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2" href="http://www.filewatcher.com/m/proben1.tar.gz.1782734-0.html">http://www.filewatcher.com/m/proben1.tar.gz.1782734-0.html</a>). Proben1 is a benchmark set of several datasets from different domains. We are going to use the cancer and the diabetes datasets. We add a class to run the experiments of each case: <code class="literal">DiagnosisExample</code>.</p><div class="calibre2" title="Breast cancer"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h2 class="title5"><a id="ch06lvl2sec87" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Breast cancer</h2></div></div></div><p class="calibre11">The breast cancer<a id="id429" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> dataset is composed of 10 variables, of which nine are inputs and one is a binary output. The dataset has 699 records, but we excluded from them 16 which were found to be incomplete, thus we used 683 to train and test the neural network.</p><div class="sidebar" title="Note"><div class="inner"><h3 class="title6"><a id="tip26" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Tip</h3><p class="calibre17">In real practical problems, it is common to have missing or invalid data. Ideally, the classification algorithm must handle these records, but sometimes it is recommended that you exclude them, since there would be not enough information to produce an accurate result.</p></div></div><p class="calibre11">The<a id="id430" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> following table shows a configuration of this dataset:</p><div class="informaltable"><table border="1" class="calibre20"><colgroup class="calibre21"><col class="calibre22"/><col class="calibre22"/><col class="calibre22"/></colgroup><thead class="calibre23"><tr class="calibre24"><th valign="bottom" class="calibre25">
<p class="calibre26">Variable Name</p>
</th><th valign="bottom" class="calibre25">
<p class="calibre26">Type</p>
</th><th valign="bottom" class="calibre25">
<p class="calibre26">Maximum Value and Minimum Value</p>
</th></tr></thead><tbody class="calibre27"><tr class="calibre31"><td class="calibre29">
<p class="calibre26">Diagnosis result</p>
</td><td class="calibre29">
<p class="calibre26">OUTPUT</p>
</td><td class="calibre29">
<p class="calibre26">[0; 1]</p>
</td></tr><tr class="calibre34"><td class="calibre29">
<p class="calibre26">Clump Thickness</p>
</td><td class="calibre29">
<p class="calibre26">INPUT #1</p>
</td><td class="calibre29">
<p class="calibre26">[1; 10]</p>
</td></tr><tr class="calibre31"><td class="calibre29">
<p class="calibre26">Uniformity of Cell Size</p>
</td><td class="calibre29">
<p class="calibre26">INPUT #2</p>
</td><td class="calibre29">
<p class="calibre26">[1; 10]</p>
</td></tr><tr class="calibre34"><td class="calibre29">
<p class="calibre26">Uniformity of Cell Shape</p>
</td><td class="calibre29">
<p class="calibre26">INPUT #3</p>
</td><td class="calibre29">
<p class="calibre26">[1; 10]</p>
</td></tr><tr class="calibre31"><td class="calibre29">
<p class="calibre26">Marginal Adhesion</p>
</td><td class="calibre29">
<p class="calibre26">INPUT #4</p>
</td><td class="calibre29">
<p class="calibre26">[1; 10]</p>
</td></tr><tr class="calibre34"><td class="calibre29">
<p class="calibre26">Single Epithelial Cell Size</p>
</td><td class="calibre29">
<p class="calibre26">INPUT #5</p>
</td><td class="calibre29">
<p class="calibre26">[1; 10]</p>
</td></tr><tr class="calibre31"><td class="calibre29">
<p class="calibre26">Bare Nuclei</p>
</td><td class="calibre29">
<p class="calibre26">INPUT #6</p>
</td><td class="calibre29">
<p class="calibre26">[1; 10]</p>
</td></tr><tr class="calibre34"><td class="calibre29">
<p class="calibre26">Bland Chromatin</p>
</td><td class="calibre29">
<p class="calibre26">INPUT #7</p>
</td><td class="calibre29">
<p class="calibre26">[1; 10]</p>
</td></tr><tr class="calibre31"><td class="calibre29">
<p class="calibre26">Normal Nucleoli</p>
</td><td class="calibre29">
<p class="calibre26">INPUT #8</p>
</td><td class="calibre29">
<p class="calibre26">[1; 10]</p>
</td></tr><tr class="calibre37"><td class="calibre29">
<p class="calibre26">Mitoses</p>
</td><td class="calibre29">
<p class="calibre26">INPUT #9</p>
</td><td class="calibre29">
<p class="calibre26">[1; 10]</p>
</td></tr></tbody></table></div><p class="calibre11">So, the proposed neural topology will be that of the following figure:</p><div class="mediaobject"><img src="Images/B05964_06_11.jpg" alt="Breast cancer" class="calibre189"/></div><p class="calibre11">The dataset division was made as follows:</p><div class="calibre2"><ul class="itemizedlist"><li class="listitem"><span class="strong1"><strong class="calibre12">Training</strong></span>: 549 records (80%);</li><li class="listitem"><span class="strong1"><strong class="calibre12">Testing</strong></span>: 134 records (20%)</li></ul></div><p class="calibre11">As in the <a id="id431" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>previous cases, we performed many experiments to try to find the best neural network to classify whether cancer is benign or malignant. So we conducted 12 different experiments (1,000 epochs per experiment), wherein MSE and accuracy values were analyzed. After that, the confusion matrix, sensitivity, and specificity were generated with the test dataset and analysis was done. Finally, an analysis of generalization was taken. The neural networks involved in the experiments are shown in the following table:</p><div class="informaltable"><table border="1" class="calibre20"><colgroup class="calibre21"><col class="calibre22"/><col class="calibre22"/><col class="calibre22"/><col class="calibre22"/></colgroup><thead class="calibre23"><tr class="calibre24"><th valign="bottom" class="calibre25">
<p class="calibre26">Experiment</p>
</th><th valign="bottom" class="calibre25">
<p class="calibre26">Number of neurons in hidden layer</p>
</th><th valign="bottom" class="calibre25">
<p class="calibre26">Learning rate</p>
</th><th valign="bottom" class="calibre25">
<p class="calibre26">Activation Function</p>
</th></tr></thead><tbody class="calibre27"><tr class="calibre31"><td class="calibre29">
<p class="calibre26">#1</p>
</td><td rowspan="6" class="calibre29">
<p class="calibre26">3</p>
</td><td rowspan="2" class="calibre29">
<p class="calibre26">0.1</p>
</td><td class="calibre29">
<p class="calibre26">Hidden Layer: SIGLOG</p>
<p class="calibre26">Output Layer: LINEAR</p>
</td></tr><tr class="calibre34"><td class="calibre29">
<p class="calibre26">#2</p>
</td><td class="calibre29">
<p class="calibre26">Hidden Layer: HYPERTAN</p>
<p class="calibre26">Output Layer: LINEAR</p>
</td></tr><tr class="calibre31"><td class="calibre29">
<p class="calibre26">#3</p>
</td><td rowspan="2" class="calibre29">
<p class="calibre26">0.5</p>
</td><td class="calibre29">
<p class="calibre26">Hidden Layer: SIGLOG</p>
<p class="calibre26">Output Layer: LINEAR</p>
</td></tr><tr class="calibre34"><td class="calibre29">
<p class="calibre26">#4</p>
</td><td class="calibre29">
<p class="calibre26">Hidden Layer: HYPERTAN</p>
<p class="calibre26">Output Layer: LINEAR</p>
</td></tr><tr class="calibre31"><td class="calibre29">
<p class="calibre26">#5</p>
</td><td rowspan="2" class="calibre29">
<p class="calibre26">0.9</p>
</td><td class="calibre29">
<p class="calibre26">Hidden Layer: SIGLOG</p>
<p class="calibre26">Output Layer: LINEAR</p>
</td></tr><tr class="calibre34"><td class="calibre29">
<p class="calibre26">#6</p>
</td><td class="calibre29">
<p class="calibre26">Hidden Layer: HYPERTAN</p>
<p class="calibre26">Output Layer: LINEAR</p>
</td></tr><tr class="calibre31"><td class="calibre29">
<p class="calibre26">#7</p>
</td><td rowspan="6" class="calibre29">
<p class="calibre26">5</p>
</td><td rowspan="2" class="calibre29">
<p class="calibre26">0.1</p>
</td><td class="calibre29">
<p class="calibre26">Hidden Layer: SIGLOG</p>
<p class="calibre26">Output Layer: LINEAR</p>
</td></tr><tr class="calibre34"><td class="calibre29">
<p class="calibre26">#8</p>
</td><td class="calibre29">
<p class="calibre26">Hidden Layer: HYPERTAN</p>
<p class="calibre26">Output Layer: LINEAR</p>
</td></tr><tr class="calibre31"><td class="calibre29">
<p class="calibre26">#9</p>
</td><td rowspan="2" class="calibre29">
<p class="calibre26">0.5</p>
</td><td class="calibre29">
<p class="calibre26">Hidden Layer: SIGLOG</p>
<p class="calibre26">Output Layer: LINEAR</p>
</td></tr><tr class="calibre34"><td class="calibre29">
<p class="calibre26">#10</p>
</td><td class="calibre29">
<p class="calibre26">Hidden Layer: HYPERTAN</p>
<p class="calibre26">Output Layer: LINEAR</p>
</td></tr><tr class="calibre31"><td class="calibre29">
<p class="calibre26">#11</p>
</td><td rowspan="2" class="calibre29">
<p class="calibre26">0.9</p>
</td><td class="calibre29">
<p class="calibre26">Hidden Layer: SIGLOG</p>
<p class="calibre26">Output Layer: LINEAR</p>
</td></tr><tr class="calibre37"><td class="calibre29">
<p class="calibre26">#12</p>
</td><td class="calibre29">
<p class="calibre26">Hidden Layer: HYPERTAN</p>
<p class="calibre26">Output Layer: LINEAR</p>
</td></tr></tbody></table></div><p class="calibre11">After each <a id="id432" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>experiment, we collected MSE values (Table X); experiments #4, #8, #9, #10, and #11 were equivalents, because they have low MSE values and same total accuracy measure (92.25%). Therefore, we selected experiments #4 and #11, because they have low MSE values among the five experiments mentioned before:</p><div class="informaltable"><table border="1" class="calibre20"><colgroup class="calibre21"><col class="calibre22"/><col class="calibre22"/><col class="calibre22"/></colgroup><thead class="calibre23"><tr class="calibre24"><th valign="bottom" class="calibre25">
<p class="calibre26">Experiment</p>
</th><th valign="bottom" class="calibre25">
<p class="calibre26">MSE training rate</p>
</th><th valign="bottom" class="calibre25">
<p class="calibre26">Total accuracy</p>
</th></tr></thead><tbody class="calibre27"><tr class="calibre31"><td class="calibre29">
<p class="calibre26">#1</p>
</td><td class="calibre29">
<p class="calibre26">0.01067</p>
</td><td class="calibre29">
<p class="calibre26">96.29%</p>
</td></tr><tr class="calibre34"><td class="calibre29">
<p class="calibre26">#2</p>
</td><td class="calibre29">
<p class="calibre26">0.00443</p>
</td><td class="calibre29">
<p class="calibre26">98.50%</p>
</td></tr><tr class="calibre31"><td class="calibre29">
<p class="calibre26">#3</p>
</td><td class="calibre29">
<p class="calibre26">9.99611E-4</p>
</td><td class="calibre29">
<p class="calibre26">97.77%</p>
</td></tr><tr class="calibre34"><td class="calibre29">
<p class="calibre26">#4</p>
</td><td class="calibre29">
<p class="calibre26">9.99913E-4</p>
</td><td class="calibre29">
<p class="calibre26">99.25%</p>
</td></tr><tr class="calibre31"><td class="calibre29">
<p class="calibre26">#5</p>
</td><td class="calibre29">
<p class="calibre26">9.99670E-4</p>
</td><td class="calibre29">
<p class="calibre26">96.26%</p>
</td></tr><tr class="calibre34"><td class="calibre29">
<p class="calibre26">#6</p>
</td><td class="calibre29">
<p class="calibre26">9.92578E-4</p>
</td><td class="calibre29">
<p class="calibre26">97.03%</p>
</td></tr><tr class="calibre31"><td class="calibre29">
<p class="calibre26">#7</p>
</td><td class="calibre29">
<p class="calibre26">0.01392</p>
</td><td class="calibre29">
<p class="calibre26">98.49%</p>
</td></tr><tr class="calibre34"><td class="calibre29">
<p class="calibre26">#8</p>
</td><td class="calibre29">
<p class="calibre26">0.00367</p>
</td><td class="calibre29">
<p class="calibre26">99.25%</p>
</td></tr><tr class="calibre31"><td class="calibre29">
<p class="calibre26">#9</p>
</td><td class="calibre29">
<p class="calibre26">9.99928E-4</p>
</td><td class="calibre29">
<p class="calibre26">99.25%</p>
</td></tr><tr class="calibre34"><td class="calibre29">
<p class="calibre26">#10</p>
</td><td class="calibre29">
<p class="calibre26">9.99951E-4</p>
</td><td class="calibre29">
<p class="calibre26">99.25%</p>
</td></tr><tr class="calibre31"><td class="calibre29">
<p class="calibre26">#11</p>
</td><td class="calibre29">
<p class="calibre26">9.99926E-4</p>
</td><td class="calibre29">
<p class="calibre26">99.25%</p>
</td></tr><tr class="calibre37"><td class="calibre29">
<p class="calibre26">#12</p>
</td><td class="calibre29">
<p class="calibre26">NaN</p>
</td><td class="calibre29">
<p class="calibre26">3.44%</p>
</td></tr></tbody></table></div><p class="calibre11">Graphically, the MSE evolution over time is very fast, as can be seen in the following chart of the<a id="id433" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> fourth experiment. Although we used 1,000 epochs to train, the experiment stopped earlier, because the minimum overall error (0.001) was reached:</p><div class="mediaobject"><img src="Images/B05964_06_12.jpg" alt="Breast cancer" class="calibre190"/></div><p class="calibre11">The confusion matrix is shown in the table with the sensibility and specificity for both experiments. It is possible to check that measures are the same for both experiments:</p><div class="informaltable"><table border="1" class="calibre20"><colgroup class="calibre21"><col class="calibre22"/><col class="calibre22"/><col class="calibre22"/><col class="calibre22"/></colgroup><thead class="calibre23"><tr class="calibre24"><th valign="bottom" class="calibre25">
<p class="calibre26">Experiment</p>
</th><th valign="bottom" class="calibre25">
<p class="calibre26">Confusion Matrix</p>
</th><th valign="bottom" class="calibre25">
<p class="calibre26">Sensibility</p>
</th><th valign="bottom" class="calibre25">
<p class="calibre26">Specificity</p>
</th></tr></thead><tbody class="calibre27"><tr class="calibre31"><td class="calibre29">
<p class="calibre26">#4</p>
</td><td class="calibre29">
<p class="calibre26">[[34.0, 1.0]</p>
<p class="calibre26">  [0.00, 99.0]]</p>
</td><td class="calibre29">
<p class="calibre26">97.22%</p>
</td><td class="calibre29">
<p class="calibre26">100.0%</p>
</td></tr><tr class="calibre37"><td class="calibre29">
<p class="calibre26">#11</p>
</td><td class="calibre29">
<p class="calibre26">[[34.0, 1.0]</p>
<p class="calibre26">  [0.00, 99.0]]</p>
</td><td class="calibre29">
<p class="calibre26">97.22%</p>
</td><td class="calibre29">
<p class="calibre26">100.0%</p>
</td></tr></tbody></table></div><p class="calibre11">If we had to choose between models generated by experiments #4 or #11, we recommend selecting #4, because it's simpler than #11 (it has fewer neurons in the hidden layer).</p></div><div class="calibre2" title="Diabetes"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h2 class="title5"><a id="ch06lvl2sec88" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Diabetes</h2></div></div></div><p class="calibre11">An additional <a id="id434" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>example to be explored is the diagnosis of diabetes. This dataset has eight inputs and one output, shown in the table below. There are 768 records, all complete. However, proben1 states that there are several senseless zero values, probably indicating missing data. We're handling this data as if it was real anyway, thereby introducing some errors (or noise) into the dataset:</p><div class="informaltable"><table border="1" class="calibre20"><colgroup class="calibre21"><col class="calibre22"/><col class="calibre22"/><col class="calibre22"/></colgroup><thead class="calibre23"><tr class="calibre24"><th valign="bottom" class="calibre25">
<p class="calibre26">Variable Name</p>
</th><th valign="bottom" class="calibre25">
<p class="calibre26">Type</p>
</th><th valign="bottom" class="calibre25">
<p class="calibre26">Maximum Value and Minimum Value</p>
</th></tr></thead><tbody class="calibre27"><tr class="calibre31"><td class="calibre29">
<p class="calibre26">Diagnosis result</p>
</td><td class="calibre29">
<p class="calibre26">OUTPUT</p>
</td><td class="calibre29">
<p class="calibre26">[0; 1]</p>
</td></tr><tr class="calibre34"><td class="calibre29">
<p class="calibre26">Number of times pregnant</p>
</td><td class="calibre29">
<p class="calibre26">INPUT #1</p>
</td><td class="calibre29">
<p class="calibre26">[0.0; 17]</p>
</td></tr><tr class="calibre31"><td class="calibre29">
<p class="calibre26">Plasma glucose concentration a 2 hours in an oral glucose tolerance test</p>
</td><td class="calibre29">
<p class="calibre26">INPUT #2</p>
</td><td class="calibre29">
<p class="calibre26">[0.0; 199]</p>
</td></tr><tr class="calibre34"><td class="calibre29">
<p class="calibre26">Diastolic blood pressure (mm Hg)</p>
</td><td class="calibre29">
<p class="calibre26">INPUT #3</p>
</td><td class="calibre29">
<p class="calibre26">[0.0; 122]</p>
</td></tr><tr class="calibre31"><td class="calibre29">
<p class="calibre26">Triceps skin fold thickness (mm)</p>
</td><td class="calibre29">
<p class="calibre26">INPUT #4</p>
</td><td class="calibre29">
<p class="calibre26">[0.0; 99]</p>
</td></tr><tr class="calibre34"><td class="calibre29">
<p class="calibre26">2-Hour serum insulin (mu U/ml)</p>
</td><td class="calibre29">
<p class="calibre26">INPUT #5</p>
</td><td class="calibre29">
<p class="calibre26">[0.0; 744]</p>
</td></tr><tr class="calibre31"><td class="calibre29">
<p class="calibre26">Body mass index (weight in kg/(height in m)^2)</p>
</td><td class="calibre29">
<p class="calibre26">INPUT #6</p>
</td><td class="calibre29">
<p class="calibre26">[0.0; 67.1]</p>
</td></tr><tr class="calibre34"><td class="calibre29">
<p class="calibre26">Diabetes pedigree function</p>
</td><td class="calibre29">
<p class="calibre26">INPUT #7</p>
</td><td class="calibre29">
<p class="calibre26">[0.078; 2420]</p>
</td></tr><tr class="calibre28"><td class="calibre29">
<p class="calibre26">Age (years)</p>
</td><td class="calibre29">
<p class="calibre26">INPUT #8</p>
</td><td class="calibre29">
<p class="calibre26">[21; 81]</p>
</td></tr></tbody></table></div><p class="calibre11">The dataset division was made as follows:</p><div class="calibre2"><ul class="itemizedlist"><li class="listitem"><span class="strong1"><strong class="calibre12">Training</strong></span>: 617 records (80%)</li><li class="listitem"><span class="strong1"><strong class="calibre12">Test</strong></span>: 151 records (20%)</li></ul></div><p class="calibre11">To discover the best neural net topology to classify diabetes, we used the same schema of neural networks with the same analysis described in the last section. However, we're using multiple class classification in the output layer: two neurons in this layer will be used, one for the presence of diabetes and one for absence.</p><p class="calibre11">So, the proposed neural architecture looks like that of the following figure:</p><div class="mediaobject"><img src="Images/B05964_06_13.jpg" alt="Diabetes" class="calibre191"/></div><p class="calibre11">The table<a id="id435" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> below shows the MSE training value and accuracy of the first six experiments and of the last six experiments:</p><div class="informaltable"><table border="1" class="calibre20"><colgroup class="calibre21"><col class="calibre22"/><col class="calibre22"/><col class="calibre22"/></colgroup><thead class="calibre23"><tr class="calibre24"><th valign="bottom" class="calibre25">
<p class="calibre26">Experiment</p>
</th><th valign="bottom" class="calibre25">
<p class="calibre26">MSE training rate</p>
</th><th valign="bottom" class="calibre25">
<p class="calibre26">Total accuracy</p>
</th></tr></thead><tbody class="calibre27"><tr class="calibre31"><td class="calibre29">
<p class="calibre26">#1</p>
</td><td class="calibre29">
<p class="calibre26">0.00807</p>
</td><td class="calibre29">
<p class="calibre26">60.54%</p>
</td></tr><tr class="calibre34"><td class="calibre29">
<p class="calibre26">#2</p>
</td><td class="calibre29">
<p class="calibre26">0.00590</p>
</td><td class="calibre29">
<p class="calibre26">71.03%</p>
</td></tr><tr class="calibre31"><td class="calibre29">
<p class="calibre26">#3</p>
</td><td class="calibre29">
<p class="calibre26">9.99990E-4</p>
</td><td class="calibre29">
<p class="calibre26">75.49%</p>
</td></tr><tr class="calibre34"><td class="calibre29">
<p class="calibre26">#4</p>
</td><td class="calibre29">
<p class="calibre26">9.98840E-4</p>
</td><td class="calibre29">
<p class="calibre26">74.17%</p>
</td></tr><tr class="calibre31"><td class="calibre29">
<p class="calibre26">#5</p>
</td><td class="calibre29">
<p class="calibre26">0.00184</p>
</td><td class="calibre29">
<p class="calibre26">61.58%</p>
</td></tr><tr class="calibre34"><td class="calibre29">
<p class="calibre26">#6</p>
</td><td class="calibre29">
<p class="calibre26">9.82774E-4</p>
</td><td class="calibre29">
<p class="calibre26">59.86%</p>
</td></tr><tr class="calibre31"><td class="calibre29">
<p class="calibre26">#7</p>
</td><td class="calibre29">
<p class="calibre26">0.00706</p>
</td><td class="calibre29">
<p class="calibre26">63.57%</p>
</td></tr><tr class="calibre34"><td class="calibre29">
<p class="calibre26">#8</p>
</td><td class="calibre29">
<p class="calibre26">0.00584</p>
</td><td class="calibre29">
<p class="calibre26">72.41%</p>
</td></tr><tr class="calibre31"><td class="calibre29">
<p class="calibre26">#9</p>
</td><td class="calibre29">
<p class="calibre26">9.99994E-4</p>
</td><td class="calibre29">
<p class="calibre26">74.66%</p>
</td></tr><tr class="calibre34"><td class="calibre29">
<p class="calibre26">#10</p>
</td><td class="calibre29">
<p class="calibre26">0.01047</p>
</td><td class="calibre29">
<p class="calibre26">72.14%</p>
</td></tr><tr class="calibre31"><td class="calibre29">
<p class="calibre26">#11</p>
</td><td class="calibre29">
<p class="calibre26">0.00316</p>
</td><td class="calibre29">
<p class="calibre26">59.86%</p>
</td></tr><tr class="calibre37"><td class="calibre29">
<p class="calibre26">#12</p>
</td><td class="calibre29">
<p class="calibre26">0.43464</p>
</td><td class="calibre29">
<p class="calibre26">40.13%</p>
</td></tr></tbody></table></div><p class="calibre11">The fall of the MSE is fast in both cases. However, experiment #9 generates an increase of error rate in the first values. It is shown in the following figure:</p><div class="mediaobject"><img src="Images/B05964_06_14.jpg" alt="Diabetes" class="calibre190"/></div><p class="calibre11">Analyzing the <a id="id436" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>confusion matrixes, it can be seen that the measures are very similar:</p><div class="informaltable"><table border="1" class="calibre20"><colgroup class="calibre21"><col class="calibre22"/><col class="calibre22"/><col class="calibre22"/><col class="calibre22"/></colgroup><thead class="calibre23"><tr class="calibre24"><th valign="bottom" class="calibre25">
<p class="calibre26">Experiment</p>
</th><th valign="bottom" class="calibre25">
<p class="calibre26">Confusion Matrix</p>
</th><th valign="bottom" class="calibre25">
<p class="calibre26">Sensibility</p>
</th><th valign="bottom" class="calibre25">
<p class="calibre26">Specificity</p>
</th></tr></thead><tbody class="calibre27"><tr class="calibre31"><td class="calibre29">
<p class="calibre26">#3</p>
</td><td class="calibre29">
<p class="calibre26">[[35.0, 12.0]</p>
<p class="calibre26"> [25.0, 79.0]]</p>
</td><td class="calibre29">
<p class="calibre26">74.46%</p>
</td><td class="calibre29">
<p class="calibre26">75.96%</p>
</td></tr><tr class="calibre37"><td class="calibre29">
<p class="calibre26">#9</p>
</td><td class="calibre29">
<p class="calibre26">[[34.0, 12.0]</p>
<p class="calibre26"> [26.0, 78.0]]</p>
</td><td class="calibre29">
<p class="calibre26">73.91%</p>
</td><td class="calibre29">
<p class="calibre26">75.00%</p>
</td></tr></tbody></table></div><p class="calibre11">One more time, we suggest choosing the simplest model. In the diabetes example, it is the artificial neural network generated by experiment #3.</p><div class="sidebar" title="Note"><div class="inner"><h3 class="title6"><a id="tip27" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Tip</h3><p class="calibre17">It is recommended you explore the class <code class="literal">D</code>
<code class="literal">iagnosisExample</code> and create a GUI to become easy select neural net parameters, as was done in the previous chapter. You should try to reuse code already programmed through the inheritance concept.</p></div></div></div></div></div>



  
<div id="sbo-rt-content" class="calibre1"><div class="calibre2" title="Summary"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h1 class="title2"><a id="ch06lvl1sec46" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Summary</h1></div></div></div><p class="calibre11">In this chapter, we've seen two examples of the application of disease diagnosis using neural networks. The fundamentals of classification problems were briefly reviewed in order to level the knowledge explored in this chapter. Classification tasks belong to one of the most used types of supervised tasks in the machine learning / data mining fields, and Neural Networks proved to be very appropriate to be applied to this type of problem. The reader was also presented with the concepts that evaluate the classification tasks, such as sensitivity, specificity, and the confusion matrix. These notations are very useful for all classification tasks, including those which are handled with other algorithms besides neural networks. The next chapter will explore a similar kind of task but using unsupervised learning – that means, without expected output data – but the fundamentals presented in this chapter will be somewhat helpful.</p></div></div>



  </body></html>