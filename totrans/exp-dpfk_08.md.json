["```py\n    git clone https://github.com/dahiyaaneesh/peclr.git\n    ```", "```py\n    conda create -n PeCLR\n    conda activate PeCLR\n    pip install -r requirements.txt\n    ```", "```py\n    python -m jupyter notebook\n    ```", "```py\n    import torch\n    import torchvision.models as models\n    import cv2\n    from PIL import Image\n    from matplotlib import pyplot as plt\n    import numpy as np\n    import os\n    import json\n    from easydict import EasyDict as edict\n    from src.models.rn_25D_wMLPref import RN_25D_wMLPref\n    ```", "```py\n    model_path = 'data/models/rn50_peclr_yt3d-fh_pt_fh_ft.pth'\n    model_type = \"rn50\"\n    model = RN_25D_wMLPref(backend_model=model_type)\n    checkpoint = torch.load(model_path)\n    model.load_state_dict(checkpoint[\"state_dict\"])\n    model.eval().cuda()\n    ```", "```py\n    image=io.imread(\n      \"https://source.unsplash.com/QyCH5jwrD_A\")\n    img = image.astype(np.float32) / 255\n    image_mean = np.array([0.485, 0.456, 0.406])\n    image_std = np.array([0.229, 0.224, 0.225])\n    img = np.divide((img - image_mean), image_std)\n    img = cv2.resize(img, (224,224))\n    img = torch.from_numpy(img.transpose(2, 0, 1))\n    img = img.unsqueeze(0).float().cuda()\n    ```", "```py\n    with torch.no_grad():\n        output = model(img, None)\n    kp2d = output[\"kp25d\"][:, :21, :2][0]\n    height, width = image.shape[:2]\n    kp2d[:,0] *= width / 224\n    kp2d[:,1] *= height / 224\n    ```"]