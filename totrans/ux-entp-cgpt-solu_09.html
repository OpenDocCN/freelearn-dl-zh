<html><head></head><body>
		<div id="_idContainer104" class="calibre2">
			<h1 id="_idParaDest-145" class="chapter-number"><a id="_idTextAnchor150" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.1.1">7</span></h1>
			<h1 id="_idParaDest-146" class="calibre5"><a id="_idTextAnchor151" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.2.1">Prompt Engineering</span></h1>
			<p class="calibre3"><span class="kobospan" id="kobo.3.1">Prompt engineering for an enterprise takes a slightly different approach to interacting with ChatGPT or any LLM for personal use. </span><span class="kobospan" id="kobo.3.2">Prompt engineering helps ensure that when the customer messages the LLM, a set of instructions is in place for them to succeed. </span><span class="kobospan" id="kobo.3.3">When building prompts to generate a recommendation or complete some backend analysis, the recommendation team directly creates the prompt. </span><span class="kobospan" id="kobo.3.4">The job is to consider how the instructions that give </span><em class="italic"><span class="kobospan" id="kobo.4.1">context</span></em><span class="kobospan" id="kobo.5.1"> to the customer’s messages, also called a prompt,  are framed or </span><em class="italic"><span class="kobospan" id="kobo.6.1">create</span></em><span class="kobospan" id="kobo.7.1"> the prompts that request a result directly from the LLM. </span><span class="kobospan" id="kobo.7.2">First, we will focus on prompt engineering before continuing with fine-tuning in the next chapter, which is an inevitable next step for </span><span><span class="kobospan" id="kobo.8.1">enterprise solutions.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.9.1">None of the tools discussed should be </span><a id="_idIndexMarker481" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.10.1">considered in a silo. </span><span class="kobospan" id="kobo.10.2">Any enterprise solution will adopt </span><strong class="bold"><span class="kobospan" id="kobo.11.1">Retrieval-Augmented Generation</span></strong><span class="kobospan" id="kobo.12.1"> (</span><strong class="bold"><span class="kobospan" id="kobo.13.1">RAG</span></strong><span class="kobospan" id="kobo.14.1">), prompt engineering, fine-tuning, and other approaches. </span><span class="kobospan" id="kobo.14.2">Each can support different capabilities while sometimes overlapping. </span><span class="kobospan" id="kobo.14.3">While prompt engineering will align the responses with the goal, fine-tuning will help the model improve </span><span><span class="kobospan" id="kobo.15.1">its understanding.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.16.1">This chapter focuses on a few critical topics related to </span><span><span class="kobospan" id="kobo.17.1">prompt engineering:</span></span></p>
			<ul class="calibre7">
				<li class="calibre8"><span class="kobospan" id="kobo.18.1">Giving context through </span><span><span class="kobospan" id="kobo.19.1">prompt engineering</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.20.1">Prompt </span><span><span class="kobospan" id="kobo.21.1">engineering techniques</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.22.1">Andrew Ng’s </span><span><span class="kobospan" id="kobo.23.1">agentic approach</span></span></li>
				<li class="calibre8"><span><span class="kobospan" id="kobo.24.1">Advanced techniques</span></span></li>
			</ul>
			<h1 id="_idParaDest-147" class="calibre5"><a id="_idTextAnchor152" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.25.1">Giving context through prompt engineering</span></h1>
			<p class="calibre3"><span class="kobospan" id="kobo.26.1">To be clear, when building a RAG solution, customers prompt the enterprise system for answers to questions, fill out forms, and interact through prompting. </span><span class="kobospan" id="kobo.26.2">Additional prompts, called instructions, wrap these prompts to ensure they are constrained or managed within a context defined by the business. </span><span class="kobospan" id="kobo.26.3">These instructions give the customer </span><a id="_idIndexMarker482" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.27.1">guardrails. </span><span class="kobospan" id="kobo.27.2">Time for prompt </span><span><span class="kobospan" id="kobo.28.1">engineering 101.</span></span></p>
			<h2 id="_idParaDest-148" class="calibre9"><a id="_idTextAnchor153" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.29.1">Prompt 101</span></h2>
			<p class="calibre3"><span class="kobospan" id="kobo.30.1">Prompt engineering instructs the chat instance to respond. </span><span class="kobospan" id="kobo.30.2">It frames or puts structure around the answer, defines </span><a id="_idIndexMarker483" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.31.1">what to include or exclude from responses, and provides any safety rails </span><span><span class="kobospan" id="kobo.32.1">to implement.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.33.1">Instructions can be tested and iterated. </span><span class="kobospan" id="kobo.33.2">Hundreds of changes will be made before settling on better instructions. </span><span class="kobospan" id="kobo.33.3">Multiple models will be doing pieces of the enterprise puzzle, each with its instructions. </span><span class="kobospan" id="kobo.33.4">We will take a few minutes to clarify that we are focused on instructions, a form of prompts that a user needs to control how the model will </span><span><span class="kobospan" id="kobo.34.1">respond to.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.35.1">The prompt strategy depends </span><a id="_idIndexMarker484" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.36.1">on the task’s needs. </span><span class="kobospan" id="kobo.36.2">If it is a general-purpose interactive prompt, it will focus on style, tone, factualness, and quality. </span><span class="kobospan" id="kobo.36.3">If this prompt is for a step that ingests tables and formats content, it will focus on structure and data output. </span><span class="kobospan" id="kobo.36.4">We will address instructions that wrap customer prompts, as shown in </span><span><em class="italic"><span class="kobospan" id="kobo.37.1">Figure 7</span></em></span><span><em class="italic"><span class="kobospan" id="kobo.38.1">.1</span></em></span><span><span class="kobospan" id="kobo.39.1">.</span></span></p>
			<div class="calibre2">
				<div id="_idContainer087" class="img---figure">
					<span class="kobospan" id="kobo.40.1"><img src="image/B21964_07_01.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.41.1">Figure 7.1 – How to rationalize instructions, prompts, and answers</span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.42.1">If the prompt comes from the customer, we can’t control their request. </span><span class="kobospan" id="kobo.42.2">So, we do what we can to control it. </span><span class="kobospan" id="kobo.42.3">In the figure above, we establish the persona of the Alligiance chat, but the customer asks the question, and the model provides the </span><span><span class="kobospan" id="kobo.43.1">specific answer.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.44.1">Instructions can be simple, such as in the examples from OpenAI, or they can be crafted to address some of our </span><span><span class="kobospan" id="kobo.45.1">enterprise needs:</span></span></p>
			<pre class="source-code"><span class="kobospan1" id="kobo.46.1">
You are a helpful assistant named Alli, short for the name of our bank. </span><span class="kobospan1" id="kobo.46.2">Be courteous and professional. </span><span class="kobospan1" id="kobo.46.3">Only provide answers from the attached document. </span><span class="kobospan1" id="kobo.46.4">Format output using lists when appropriate.</span></pre>			<p class="calibre3"><span class="kobospan" id="kobo.47.1">Even a trivial example like this has a few </span><span><span class="kobospan" id="kobo.48.1">essential elements:</span></span></p>
			<ul class="calibre7">
				<li class="calibre8"><span class="kobospan" id="kobo.49.1">It clarified the persona of the AI and the type </span><span><span class="kobospan" id="kobo.50.1">of business</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.51.1">It defines how it </span><span><span class="kobospan" id="kobo.52.1">should act</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.53.1">It constrains where to look </span><span><span class="kobospan" id="kobo.54.1">for answers</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.55.1">It provides a suggestion on how </span><span><span class="kobospan" id="kobo.56.1">to respond</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.57.1">It doesn’t include any actual questions; those come from the </span><span><span class="kobospan" id="kobo.58.1">customer’s prompt</span></span></li>
			</ul>
			<p class="calibre3"><span class="kobospan" id="kobo.59.1">This will grow in complexity, spanning dozens or hundreds of lines of text, but this is a cost-benefit trade-off. </span><span class="kobospan" id="kobo.59.2">The longer the prompt, the more tokens are used. </span><span class="kobospan" id="kobo.59.3">These additional instructions are included for </span><em class="italic"><span class="kobospan" id="kobo.60.1">every</span></em><span class="kobospan" id="kobo.61.1"> prompt the user sends to the model, so use your tokens wisely. </span><span class="kobospan" id="kobo.61.2">Remember that tokens represent how the model accounts for size and cost based on the amount of text. </span><span class="kobospan" id="kobo.61.3">While humans understand word count, the model talks in tokens. </span><span class="kobospan" id="kobo.61.4">It can have a maximum amount of context passed to it (in tokens) and a maximum amount of data returned at one time (in tokens), and then charges are based on the number of tokens. </span><span class="kobospan" id="kobo.61.5">We</span><a id="_idIndexMarker485" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.62.1"> will cover more about tokens in this and the </span><span><span class="kobospan" id="kobo.63.1">next chapter.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.64.1">The LLM does not directly interact with customers for recommender solutions or behind-the-scenes uses of a model. </span><span class="kobospan" id="kobo.64.2">Instructions can provide general guidance, and prompts (more detailed instructions) that can be used for specific task efforts. </span><span class="kobospan" id="kobo.64.3">This abstraction creates consistency in one set of instructions for all prompts in a group </span><span><span class="kobospan" id="kobo.65.1">of projects.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.66.1">A thoughtful enterprise instruction set has to be in place to support the user’s prompts for conversational AI. </span><span class="kobospan" id="kobo.66.2">The differences between instructions that act as a wrapper for customer prompts and the actual prompt impact how to write instructions or prompts. </span><span class="kobospan" id="kobo.66.3">Instructions have to be more generic and support a wide range of prompts. </span><span class="kobospan" id="kobo.66.4">The direct prompts are targeted, focusing the LLM on providing one good answer, as shown in the example in the preceding figure. </span><span class="kobospan" id="kobo.66.5">So, there are differences in designing prompts for your personal use versus what is needed in an </span><span><span class="kobospan" id="kobo.67.1">enterprise solution.</span></span></p>
			<h2 id="_idParaDest-149" class="calibre9"><a id="_idTextAnchor154" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.68.1">Designing instructions</span></h2>
			<p class="calibre3"><span class="kobospan" id="kobo.69.1">We have all created a variety of </span><a id="_idIndexMarker486" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.70.1">prompts for home </span><span><span class="kobospan" id="kobo.71.1">or work:</span></span></p>
			<pre class="source-code"><span class="kobospan1" id="kobo.72.1">
What is the best way to clean an iron-looking stain in a toilet? </span><span class="kobospan1" id="kobo.72.2">(citric acid, it worked perfectly)
What are the steps for installing a new dishwasher
Imagine a logo for my business focused on dog walking in the Bay Area.
</span><span class="kobospan1" id="kobo.72.3">Correct this Python code
Summarize this article for me
Write this customer a thank-you letter with these details…</span></pre>			<p class="calibre3"><span class="kobospan" id="kobo.73.1">However, to frame instructions to guide users interacting with an enterprise conversational assistant or when building the instructions for any recommender use cases, robust instructions that clarify the goals and persona of all interactions are needed. </span><span class="kobospan" id="kobo.73.2">Here is the start of </span><span><span class="kobospan" id="kobo.74.1">an instruction:</span></span></p>
			<pre class="source-code"><span class="kobospan1" id="kobo.75.1">
You are a technical service bot who explains complex problems step-by-step, guiding a user with simple language. </span><span class="kobospan1" id="kobo.75.2">When necessary, provide numbered lists or PDFs to download that include installation instructions. </span><span class="kobospan1" id="kobo.75.3">Be courteous and helpful in clarifying problems the customer might have.</span></pre>			<p class="calibre3"><span class="kobospan" id="kobo.76.1">This should frame the customer request (their prompt) who might ask questions such as </span><span><span class="kobospan" id="kobo.77.1">the following:</span></span></p>
			<pre class="source-code"><span class="kobospan1" id="kobo.78.1">
I need ur help understanding how to install the regulator inline with the Mod 14 treatment system. </span><span class="kobospan1" id="kobo.78.2">What tools do I need? </span><span class="kobospan1" id="kobo.78.3">I don't see any instructions included. </span><span class="kobospan1" id="kobo.78.4">Help, plz.</span></pre>			<p class="calibre3"><span class="kobospan" id="kobo.79.1">Together, these two layers of prompt engineering give instructions to the model. </span><span class="kobospan" id="kobo.79.2">So, the company provides the instructions, and the customer provides their prompt. </span><span class="kobospan" id="kobo.79.3">With recommender solutions, the company does </span><span><span class="kobospan" id="kobo.80.1">it all.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.81.1">Imagine an LLM-driven recommender, for scoring leads, rating a person’s reputation, offering products to upsell, providing sentiment feedback, or suggesting data to ignore because it has undesirable or harmful content. </span><span class="kobospan" id="kobo.81.2">Create prompts specific to those use cases. </span><span class="kobospan" id="kobo.81.3">Each prompt will serve only some of the issues. </span><span class="kobospan" id="kobo.81.4">This is why multiple models are discussed so much. </span><span class="kobospan" id="kobo.81.5">There can even be models </span><a id="_idIndexMarker487" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.82.1">designed to decide which model to use next. </span><span class="kobospan" id="kobo.82.2">The prompt of the first model helps route the request to the second model, which has prompts specific to its task and is tuned to the needs of the request. </span><span class="kobospan" id="kobo.82.3">This chaining of models will be covered here and more in </span><a href="B21964_08.xhtml#_idTextAnchor172" class="pcalibre pcalibre1 calibre6"><span><em class="italic"><span class="kobospan" id="kobo.83.1">Chapter 8</span></em></span></a><span class="kobospan" id="kobo.84.1">, </span><em class="italic"><span class="kobospan" id="kobo.85.1">Fine-Tuning</span></em><span class="kobospan" id="kobo.86.1">. </span><span class="kobospan" id="kobo.86.2">Every one of these models needs well-thought-out prompts to guide an interaction, and none of these will have a human prompting </span><span><span class="kobospan" id="kobo.87.1">the system.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.88.1">There is a wealth of documentation and tutorials on what simple prompts can do. </span><span class="kobospan" id="kobo.88.2">Start exploring more at the </span><span><span class="kobospan" id="kobo.89.1">OpenAI site.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.90.1">Documentation: </span><a href="https://platform.openai.com/docs/examples" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.91.1">Prompt </span><span><span class="kobospan" id="kobo.92.1">Examples</span></span></a><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.93.1">(</span></span></span><a href="https://platform.openai.com/docs/examples" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.94.1">https://platform.openai.com/docs/examples</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.95.1">)</span></span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.96.1">But these are just starting points. </span><span class="kobospan" id="kobo.96.2">Much work is needed to scale these up to work reliably and with the style and tone expected in a business use case. </span><span class="kobospan" id="kobo.96.3">Understand where prompt engineering fits into the process in addition to the prompt’s content. </span><span class="kobospan" id="kobo.96.4">We can summarize the highlights from OpenAI’s </span><span><span class="kobospan" id="kobo.97.1">high-level presentation.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.98.1">Video: </span><a href="https://youtu.be/ahnGLM-RC1Y" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.99.1">Techniques for improving LLM </span><span><span class="kobospan" id="kobo.100.1">Quality</span></span></a><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.101.1">(</span></span></span><a href="https://youtu.be/ahnGLM-RC1Y" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.102.1">https://youtu.be/ahnGLM-RC1Y</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.103.1">)</span></span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.104.1">The takeaway starts at about 3 minutes. </span><span><em class="italic"><span class="kobospan" id="kobo.105.1">Figure 7</span></em></span><em class="italic"><span class="kobospan" id="kobo.106.1">.2</span></em><span class="kobospan" id="kobo.107.1"> outlines their approach. </span><span class="kobospan" id="kobo.107.2">They reviewed RAG (discussed in the last chapter) as a solution to help an enterprise access its knowledge base and other data sources. </span><span class="kobospan" id="kobo.107.3">They make a great point that this data can be scrubbed and cleaned </span><em class="italic"><span class="kobospan" id="kobo.108.1">before</span></em><span class="kobospan" id="kobo.109.1"> having a working system. </span><span class="kobospan" id="kobo.109.2">Meanwhile, prompt engineering and fine-tuning rely on a </span><em class="italic"><span class="kobospan" id="kobo.110.1">working</span></em><span class="kobospan" id="kobo.111.1"> system </span><span><span class="kobospan" id="kobo.112.1">for feedback.</span></span></p>
			<div class="calibre2">
				<div id="_idContainer088" class="img---figure">
					<span class="kobospan" id="kobo.113.1"><img src="image/B21964_07_02.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.114.1">Figure 7.2 — Tools to help us optimize our ChatGPT solution</span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.115.1">These tools are all needed in enterprise solutions to improve LLM quality. </span><span class="kobospan" id="kobo.115.2">We can walk through why this is the case. </span><span class="kobospan" id="kobo.115.3">Prompt engineering can start with basic example questions to see how the model acts. </span><span class="kobospan" id="kobo.115.4">When it doesn’t work well, adding training examples to improve how it responds to questions unique to our business is next. </span><span class="kobospan" id="kobo.115.5">This will </span><a id="_idIndexMarker488" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.116.1">quickly result in wanting more data than can be handled by basic interactions, so the solution extends into RAG. </span><span class="kobospan" id="kobo.116.2">Now, the results don’t fit our style or tone or don’t follow the instructions expected, so fine-tuning is added, giving examples to the model to train it on how it is expected to respond. </span><span class="kobospan" id="kobo.116.3">Results can indicate that the RAG could be refined and optimized further, so they go back and work on it. </span><span class="kobospan" id="kobo.116.4">This results in wanting to fine-tune the results further. </span><span class="kobospan" id="kobo.116.5">And this cycle continues, hopefully improving at </span><span><span class="kobospan" id="kobo.117.1">every step.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.118.1">For our video learners, Mark Hennings has an excellent 15-minute overview that quickly covers a lot </span><span><span class="kobospan" id="kobo.119.1">of ground.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.120.1">Video: </span><a href="https://www.youtube.com/watch?v=YVWxbHJakgg" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.121.1">Prompt Eng, RAG, and Fine Tuning</span></a><span class="kobospan" id="kobo.122.1"> (Mark </span><span><span class="kobospan" id="kobo.123.1">Hennings) </span></span><span><span class="hidden1"><span class="kobospan" id="kobo.124.1">(</span></span></span><a href="https://www.youtube.com/watch?v=YVWxbHJakgg" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.125.1">https://www.youtube.com/watch?v=YVWxbHJakgg</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.126.1">)</span></span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.127.1">An excellent place to start is by teaching some basic strategies </span><span><span class="kobospan" id="kobo.128.1">for prompting.</span></span></p>
			<h2 id="_idParaDest-150" class="calibre9"><a id="_idTextAnchor155" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.129.1">Basic strategies</span></h2>
			<p class="calibre3"><span class="kobospan" id="kobo.130.1">Many structured </span><a id="_idIndexMarker489" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.131.1">methodologies have been proposed for prompt engineering, and most are similar. </span><span class="kobospan" id="kobo.131.2">One is called </span><strong class="bold"><span class="kobospan" id="kobo.132.1">RACE</span></strong><span class="kobospan" id="kobo.133.1"> (</span><strong class="bold"><span class="kobospan" id="kobo.134.1">Role, Action, Context, and</span></strong> <strong class="bold"><span class="kobospan" id="kobo.135.1">Examples</span></strong><span class="kobospan" id="kobo.136.1">), another is called </span><strong class="bold"><span class="kobospan" id="kobo.137.1">CO-STAR</span></strong><span class="kobospan" id="kobo.138.1"> (</span><strong class="bold"><span class="kobospan" id="kobo.139.1">Context, Objective, Style, Tone, Audience, and</span></strong> <strong class="bold"><span class="kobospan" id="kobo.140.1">Response</span></strong><span class="kobospan" id="kobo.141.1">), and another is called </span><strong class="bold"><span class="kobospan" id="kobo.142.1">CARE</span></strong><span class="kobospan" id="kobo.143.1"> (</span><strong class="bold"><span class="kobospan" id="kobo.144.1">Content, Action Result, and Example</span></strong><span class="kobospan" id="kobo.145.1">). </span><span class="kobospan" id="kobo.145.2">Other approaches are </span><a id="_idIndexMarker490" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.146.1">explained without a cute initialism. </span><span class="kobospan" id="kobo.146.2">First, it is good to</span><a id="_idIndexMarker491" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.147.1"> understand the primary instructions of a typical prompt; then, dive deeper to help with </span><span><span class="kobospan" id="kobo.148.1">enterprise instructions.</span></span></p>
			<p class="calibre3"><em class="italic"><span class="kobospan" id="kobo.149.1">Table 7.1</span></em><span class="kobospan" id="kobo.150.1"> cross-lists the similar concepts for</span><a id="_idIndexMarker492" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.151.1"> each approach in the first column. </span><span class="kobospan" id="kobo.151.2">Each framework uses slightly different terminology but mainly covers the same fundamentals. </span><span class="kobospan" id="kobo.151.3">The cute initialisms seem primarily for branding. </span><span class="kobospan" id="kobo.151.4">We will ignore that and focus on goals, not the terms. </span><span class="kobospan" id="kobo.151.5">Expect to write prompts that contain all of these approaches. </span><span class="kobospan" id="kobo.151.6">We will also explain when not to do some </span><span><span class="kobospan" id="kobo.152.1">of this.</span></span></p>
			<table id="table001-6" class="no-table-style">
				<colgroup class="calibre15">
					<col class="calibre16"/>
					<col class="calibre16"/>
					<col class="calibre16"/>
				</colgroup>
				<tbody class="calibre17">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.153.1">Approach</span></strong></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.154.1">Explanation</span></strong></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.155.1">Example</span></strong></span></p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.156.1">Priming (role, audience, </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.157.1">and objective)</span></strong></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span class="kobospan" id="kobo.158.1">Establish the context of </span><span><span class="kobospan" id="kobo.159.1">the response.</span></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><em class="italic"><span class="kobospan" id="kobo.160.1">You are a sales and service assistant to the inside sales team to help them </span></em><span><em class="italic"><span class="kobospan" id="kobo.161.1">close deals.</span></em></span></p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.162.1">Style and </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.163.1">tone (attitude)</span></strong></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span class="kobospan" id="kobo.164.1">Define the style and tone expected in </span><span><span class="kobospan" id="kobo.165.1">the response.</span></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><em class="italic"><span class="kobospan" id="kobo.166.1">Respond in simple language and explain any processes step by step while being encouraging </span></em><span><em class="italic"><span class="kobospan" id="kobo.167.1">and supportive.</span></em></span></p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.168.1">Example</span></strong></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span class="kobospan" id="kobo.169.1">Provide examples of how the output </span><span><span class="kobospan" id="kobo.170.1">should look.</span></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><em class="italic"><span class="kobospan" id="kobo.171.1">Here is an example of how you should sound with the </span></em><span><em class="italic"><span class="kobospan" id="kobo.172.1">details expected.</span></em></span></p>
							<p class="calibre3"><em class="italic"><span class="kobospan" id="kobo.173.1">The Smith deal closed on 5 March this year. </span><span class="kobospan" id="kobo.173.2">It is worth $1.2M in revenue booked over the next </span></em><span><em class="italic"><span class="kobospan" id="kobo.174.1">five months.</span></em></span></p>
							<p class="calibre3"><em class="italic"><span class="kobospan" id="kobo.175.1">Here is </span></em><span><em class="italic"><span class="kobospan" id="kobo.176.1">another example.</span></em></span></p>
							<p class="calibre3"><em class="italic"><span class="kobospan" id="kobo.177.1">Jim Lankey is the lead on the Wilson deal. </span><span class="kobospan" id="kobo.177.2">He has worked with Wilson for the last three years. </span><span class="kobospan" id="kobo.177.3">Email him at jim@ourcompany.com for </span></em><span><em class="italic"><span class="kobospan" id="kobo.178.1">more details.</span></em></span></p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.179.1">Handling errors and </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.180.1">edge cases</span></strong></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span class="kobospan" id="kobo.181.1">Creating guardrails for the scope </span><span><span class="kobospan" id="kobo.182.1">of responses.</span></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><em class="italic"><span class="kobospan" id="kobo.183.1">If the questions do not appear to be about the sales or service support, first try to confirm your understanding, and if off topic politely decline to </span></em><span><em class="italic"><span class="kobospan" id="kobo.184.1">offer suggestions.</span></em></span></p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.185.1">Dynamic content (can also </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.186.1">be context)</span></strong></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span class="kobospan" id="kobo.187.1">Inject facts from RAG. </span><span class="kobospan" id="kobo.187.2">“What was the size of the service control contact </span><span><span class="kobospan" id="kobo.188.1">in 2023?</span></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><em class="italic"><span class="kobospan" id="kobo.189.1">User </span></em><span><em class="italic"><span class="kobospan" id="kobo.190.1">question: {question}</span></em></span></p>
							<p class="calibre3"><em class="italic"><span class="kobospan" id="kobo.191.1">Use this, if useful: {knowledge </span></em><span><em class="italic"><span class="kobospan" id="kobo.192.1">from RAG}</span></em></span></p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.193.1">Output </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.194.1">format (response)</span></strong></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span class="kobospan" id="kobo.195.1">Define how the default responses </span><span><span class="kobospan" id="kobo.196.1">should look.</span></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><em class="italic"><span class="kobospan" id="kobo.197.1">Keep answers short and to the point; use tables or numbered lists </span></em><span><em class="italic"><span class="kobospan" id="kobo.198.1">when needed.</span></em></span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.199.1">Table 7.1 – Basic prompt components</span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.200.1">Most of the training and videos </span><a id="_idIndexMarker493" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.201.1">out there discuss prompting. </span><span class="kobospan" id="kobo.201.2">They typically focus on personal prompting and how to get an LLM to craft the output for one task. </span><span class="kobospan" id="kobo.201.3">This chapter focuses on enterprise prompting, getting the LLM to respond every time in a way that is conducive to business customers. </span><span class="kobospan" id="kobo.201.4">However, much of basic prompting is still relevant. </span><span class="kobospan" id="kobo.201.5">To explore more, here are the resources used beyond OpenAI to craft </span><span><span class="kobospan" id="kobo.202.1">our explanation.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.203.1">Article: </span><a href="https://learn.microsoft.com/en-us/ai/playbook/technology-guidance/generative-ai/working-with-llms/prompt-engineering" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.204.1">Getting started with LLM prompt </span><span><span class="kobospan" id="kobo.205.1">engineering</span></span></a><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.206.1">(</span></span></span><a href="https://learn.microsoft.com/en-us/ai/playbook/technology-guidance/generative-ai/working-with-llms/prompt-engineering" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.207.1">https://learn.microsoft.com/en-us/ai/playbook/technology-guidance/generative-ai/working-with-llms/prompt-engineering</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.208.1">)</span></span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.209.1">I like Jules Damji’s article because it references research and methods that go deeper. </span><span class="kobospan" id="kobo.209.2">We, too, need to go deeper when building a production solution. </span><span class="kobospan" id="kobo.209.3">The basics will be explained; later, </span><span><span class="kobospan" id="kobo.210.1">explore more.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.211.1">Article: </span><a href="https://medium.com/the-modern-scientist/best-prompt-techniques-for-best-llm-responses-24d2ff4f6bca" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.212.1">Best Prompt Techniques for Best LLM Responses</span></a><span class="kobospan" id="kobo.213.1"> by Jules </span><span><span class="kobospan" id="kobo.214.1">Damji </span></span><span><span class="hidden1"><span class="kobospan" id="kobo.215.1">(</span></span></span><a href="https://medium.com/the-modern-scientist/best-prompt-techniques-for-best-llm-responses-24d2ff4f6bca" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.216.1">https://medium.com/the-modern-scientist/best-prompt-techniques-for-best-llm-responses-24d2ff4f6bca</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.217.1">)</span></span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.218.1">There are plenty of examples on the web. </span><span class="kobospan" id="kobo.218.2">Since CO-STAR was mentioned, check out the prompts in </span><span><span class="kobospan" id="kobo.219.1">their notebook.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.220.1">GitHub: </span><a href="https://colab.research.google.com/github/dmatrix/genai-cookbook/blob/main/llm-prompts/1_how_to_use_basic_prompt.ipynb" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.221.1">Basic prompting from the CO-STAR </span><span><span class="kobospan" id="kobo.222.1">framework</span></span></a><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.223.1">(</span></span></span><a href="https://colab.research.google.com/github/dmatrix/genai-cookbook/blob/main/llm-prompts/1_how_to_use_basic_prompt.ipynb" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.224.1">https://colab.research.google.com/github/dmatrix/genai-cookbook/blob/main/llm-prompts/1_how_to_use_basic_prompt.ipynb</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.225.1">)</span></span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.226.1">In the prompt on their first GitHub example, they provide each characteristic of CO-STAR. </span><span class="kobospan" id="kobo.226.2">In some cases, such as when creating a recommender or using an LLM for a backend service, specificity is paramount, as Wove does in our ongoing </span><span><span class="kobospan" id="kobo.227.1">case study.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.228.1">However, there is also the use case of an enterprise LLM fed with RAG data. </span><span class="kobospan" id="kobo.228.2">Instructions must be more generic for a RAG process for knowledge retrieval. </span><span class="kobospan" id="kobo.228.3">It is not focused on writing a blog post, developing a specific answer, or performing one task. </span><span class="kobospan" id="kobo.228.4">It will answer many questions, fill out forms, submit data, and change topics with some frequency. </span><span class="kobospan" id="kobo.228.5">This means instructions will guide and frame the answer based on the user’s prompt. </span><span class="kobospan" id="kobo.228.6">This is why instructions get very long. </span><span class="kobospan" id="kobo.228.7">They have to cover a wide range of interactions and all of the components of a </span><a id="_idIndexMarker494" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.229.1">prompt. </span><span class="kobospan" id="kobo.229.2">One option is to create distinct models that service specific tasks and use a primary model to determine which model to send the request to. </span><span class="kobospan" id="kobo.229.3">This is an intelligent use of resources. </span><span class="kobospan" id="kobo.229.4">This hub and spoke model must only know enough to classify and forward to the suitable model. </span><span class="kobospan" id="kobo.229.5">It doesn’t need to do the </span><span><span class="kobospan" id="kobo.230.1">heavy lifting.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.231.1">Conversely, highly tuned models for specific tasks will have specific prompts. </span><span class="kobospan" id="kobo.231.2">The system should outsource questions that don’t match this particular task to other models. </span><span class="kobospan" id="kobo.231.3">We will cover the agent approach in more detail shortly. </span><span class="kobospan" id="kobo.231.4">The hub-and-spoke approach is shown in </span><span><em class="italic"><span class="kobospan" id="kobo.232.1">Figure 7</span></em></span><em class="italic"><span class="kobospan" id="kobo.233.1">.3</span></em><span class="kobospan" id="kobo.234.1">. </span><span class="kobospan" id="kobo.234.2">Thanks to Miha at </span><a href="https://miha.academy/" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.235.1">Miha.Academy</span></a> <span class="hidden1"><span class="kobospan" id="kobo.236.1">(</span></span><a href="https://miha.academy/" class="pcalibre pcalibre1 calibre6"><span class="hidden1"><span class="kobospan" id="kobo.237.1">https://miha.academy/</span></span></a><span class="hidden1"><span class="kobospan" id="kobo.238.1">)</span></span><span class="kobospan" id="kobo.239.1"> for his templates to create the flow shown in figures </span><span><span class="kobospan" id="kobo.240.1">like this.</span></span></p>
			<div class="calibre2">
				<div id="_idContainer089" class="img---figure">
					<span class="kobospan" id="kobo.241.1"><img src="image/B21964_07_03.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.242.1">Figure 7.3 – A hub and spoke process to route to specific tuned models</span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.243.1">There is no one correct model. </span><span class="kobospan" id="kobo.243.2">Explore matching models for quality, performance, and cost with the needs of the use case. </span><span class="kobospan" id="kobo.243.3">In this hub-and-spoke example, the routing model decides which model </span><a id="_idIndexMarker495" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.244.1">should be passed a </span><span><span class="kobospan" id="kobo.245.1">specific task:</span></span></p>
			<ul class="calibre7">
				<li class="calibre8"><span class="kobospan" id="kobo.246.1">Model 1 is for processing a transaction. </span><span class="kobospan" id="kobo.246.2">It needs to model existing APIs and requirements for the backend. </span><span class="kobospan" id="kobo.246.3">This graphic might mask the additional needs of multiple models or dynamic prompts to handle how to work on various channels. </span><span class="kobospan" id="kobo.246.4">Flow diagrams with that complexity would be difficult to visualize in this graphic. </span><span class="kobospan" id="kobo.246.5">Use your imagination. </span><span class="kobospan" id="kobo.246.6">This diagram can get </span><span><span class="kobospan" id="kobo.247.1">very complex.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.248.1">Model 2 handles any business chit-chat and social interactions. </span><span class="kobospan" id="kobo.248.2">Any further input might be routed to a </span><span><span class="kobospan" id="kobo.249.1">different model.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.250.1">Model 3 supports RAG. </span><span class="kobospan" id="kobo.250.2">It is fine-tuned to handle discussing </span><span><span class="kobospan" id="kobo.251.1">technical documentation.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.252.1">Model 4 handles some tasks that require local processing for security purposes, so an open-source model that can be deployed locally handles </span><span><span class="kobospan" id="kobo.253.1">this task.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.254.1">Finally, Model 5 uses Anthropic for cloud service integration because it handles this task quickly </span><span><span class="kobospan" id="kobo.255.1">and inexpensively.</span></span></li>
			</ul>
			<p class="calibre3"><span class="kobospan" id="kobo.256.1">Each model requires design effort, testing, validation, and a care and feeding process. </span><span class="kobospan" id="kobo.256.2">Each is an application to itself. </span><span class="kobospan" id="kobo.256.3">This is </span><a id="_idIndexMarker496" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.257.1">unsurprising, as many enterprise solutions might comprise dozens or hundreds of systems </span><span><span class="kobospan" id="kobo.258.1">and services.</span></span></p>
			<h2 id="_idParaDest-151" class="calibre9"><a id="_idTextAnchor156" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.259.1">Quick tricks to always keep in mind</span></h2>
			<p class="calibre3"><span class="kobospan" id="kobo.260.1">There is a wealth of coaching for</span><a id="_idIndexMarker497" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.261.1"> prompt engineering, and one book will not make you an expert. </span><span class="kobospan" id="kobo.261.2">To grow into an expert, learn these skills, apply them (and apply them, and apply them), feel how the model reacts to these instructions, and adapt as new models become available. </span><span class="kobospan" id="kobo.261.3">Here are the fundamentals that OpenAI preaches. </span><span class="kobospan" id="kobo.261.4">Instill them into </span><span><span class="kobospan" id="kobo.262.1">best practices:</span></span></p>
			<ul class="calibre7">
				<li class="calibre8"><span class="kobospan" id="kobo.263.1">Write clear instructions – be direct with the LLM. </span><span class="kobospan" id="kobo.263.2">Tell it what to </span><em class="italic"><span class="kobospan" id="kobo.264.1">do</span></em><span class="kobospan" id="kobo.265.1"> and avoid adverse terms such as </span><em class="italic"><span class="kobospan" id="kobo.266.1">don’t</span></em><span class="kobospan" id="kobo.267.1">. </span><span class="kobospan" id="kobo.267.2">Niceties cost money and, except in rare examples, don’t </span><span><span class="kobospan" id="kobo.268.1">add value.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.269.1">Split complex tasks into simpler subtasks. </span><span class="kobospan" id="kobo.269.2">Ask the LLM to break down the problem into steps or give it the steps if the prompt is constrained to a specific process. </span><span class="kobospan" id="kobo.269.3">This also allows specific models to perform particular </span><span><span class="kobospan" id="kobo.270.1">workflow tasks.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.271.1">Reference, prioritize, and demand the use of the enterprise data or require it to be the only source of truth. </span><span><span class="kobospan" id="kobo.272.1">For example:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.273.1">
Only provide technical answers or step-by-step flows that are provided in the documents shared with you.</span></pre></li>				<li class="calibre8"><span class="kobospan" id="kobo.274.1">Define the structure or format for data (customers can ask for different formats), such as bulleted lists or tables. </span><span class="kobospan" id="kobo.274.2">This might have limited use in a general-purpose </span><span><span class="kobospan" id="kobo.275.1">customer-support LLM:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.276.1">
Format output using lists when appropriate. </span><span class="kobospan1" id="kobo.276.2">Use tables for collections of information that are suited for tables.</span></pre></li>				<li class="calibre8"><span class="kobospan" id="kobo.277.1">Provide examples (or, as this grows, move examples to fine-tuning, including the expected style and tone); this is a </span><strong class="bold"><span class="kobospan" id="kobo.278.1">few-shot learning</span></strong><span class="kobospan" id="kobo.279.1"> for </span><span><span class="kobospan" id="kobo.280.1">the model.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.281.1">Consider any constraints that should be put in place for guardrails. </span><span class="kobospan" id="kobo.281.2">Keep customers focused on the enterprise data, even if more social style and tone are included, like in this example. </span><span class="kobospan" id="kobo.281.3">Avoid politics, general knowledge, or culturally </span><span><span class="kobospan" id="kobo.282.1">sensitive areas:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.283.1">
Be courteous and professional, but you can also occasionally be funny. </span><span class="kobospan1" id="kobo.283.2">Be empathetic when the customer is having a problem. </span><span class="kobospan1" id="kobo.283.3">Never engage in discussions about politics, religion, hate speech, or violence.</span></pre><p class="calibre3"><span class="kobospan" id="kobo.284.1">Although models ship with controls, the bar is higher for large enterprises. </span><span class="kobospan" id="kobo.284.2">Businesses </span><a id="_idIndexMarker498" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.285.1">don’t want screenshots of inappropriate interactions circulating online; plenty of those failures are already in </span><span><span class="kobospan" id="kobo.286.1">the news.</span></span></p></li>				<li class="calibre8"><span class="kobospan" id="kobo.287.1">Give ChatGPT time to think. </span><span class="kobospan" id="kobo.287.2">Allow it to follow the steps to the answer, or have it check if it works. </span><span class="kobospan" id="kobo.287.3">Recall that it is a people-pleaser. </span><span class="kobospan" id="kobo.287.4">It wants to provide an answer. </span><span class="kobospan" id="kobo.287.5">Breaking down solutions into component steps can allow for a more accurate answer. </span><span class="kobospan" id="kobo.287.6">Use instructions to require it to resolve issues step by step. </span><span class="kobospan" id="kobo.287.7">Ask the LLM to follow a specific method to deconstruct a problem, ask follow-up questions, and decide how to get to a resolution. </span><span class="kobospan" id="kobo.287.8">I have viewed dozens of not-very-good videos on this subject. </span><span class="kobospan" id="kobo.287.9">This one shows an excellent multi-step </span><span><span class="kobospan" id="kobo.288.1">reasoning process.</span></span><p class="calibre3"><span class="kobospan" id="kobo.289.1">Video: </span><a href="https://www.youtube.com/watch?v=aeDr0duR_jo”https://www.youtube.com/watch?v=aeDr0duR_jo" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.290.1">Optimize Instruction tuned Conversational </span><span><span class="kobospan" id="kobo.291.1">AI/LLM</span></span></a><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.292.1">(</span></span></span><a href="https://www.youtube.com/watch?v=aeDr0duR_jo”https://www.youtube.com/watch?v=aeDr0duR_jo" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.293.1">https://www.youtube.com/watch?v=aeDr0duR_jo”https://www.youtube.com/watch?v=aeDr0duR_jo</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.294.1">)</span></span></span></p><p class="calibre3"><span class="kobospan" id="kobo.295.1">If needed, chain models together, ask one (or more than one) to solve a problem and then have another model check the work before sharing it with the customer. </span><span class="kobospan" id="kobo.295.2">Some situations might demand this additional cost </span><span><span class="kobospan" id="kobo.296.1">and complexity.</span></span></p></li>
				<li class="calibre8"><span class="kobospan" id="kobo.297.1">Test changes systematically. </span><span class="kobospan" id="kobo.297.2">Test, test, test! </span><span class="kobospan" id="kobo.297.3">Each model update can profoundly change the skill. </span><span class="kobospan" id="kobo.297.4">Rerun previous questions and then ask the LLM to compare the previous and new results for any significant differences. </span><span class="kobospan" id="kobo.297.5">The tools in this space are changing and adapting to these new approaches. </span><span class="kobospan" id="kobo.297.6">Ensure that good-quality tests are consistent with what a user would do and cover edge cases. </span><a href="B21964_10_split_000.xhtml#_idTextAnchor216" class="pcalibre pcalibre1 calibre6"><span><em class="italic"><span class="kobospan" id="kobo.298.1">Chapter 10</span></em></span></a><span class="kobospan" id="kobo.299.1">, </span><em class="italic"><span class="kobospan" id="kobo.300.1">Monitoring and Evaluation,</span></em><span class="kobospan" id="kobo.301.1"> explains testing within a care and feeding life cycle, which is about listening to feedback and iterating on </span><span><span class="kobospan" id="kobo.302.1">the results.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.303.1">For interactive chats, the</span><a id="_idIndexMarker499" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.304.1"> instructions are written to support the user’s prompt; the prompt itself is for the customer to write, so it has to be generic enough to handle the variety of questions that will </span><span><span class="kobospan" id="kobo.305.1">be asked.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.306.1">Consider whether the LLM can give enough structure to the results for recommender or non-interactive solutions. </span><span class="kobospan" id="kobo.306.2">Instruct the model on how recommendations should appear or use templates to enforce </span><span><span class="kobospan" id="kobo.307.1">specific guidelines.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.308.1">Provide new information. </span><span class="kobospan" id="kobo.308.2">Use RAG or other retrieval solutions to get the latest information from knowledge, APIs, </span><span><span class="kobospan" id="kobo.309.1">or databases.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.310.1">Inject context. </span><span class="kobospan" id="kobo.310.2">Use data sources to include specific details in prompts to give the user’s conversation </span><span><span class="kobospan" id="kobo.311.1">more context.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.312.1">Consider costs. </span><span class="kobospan" id="kobo.312.2">Creating large prompts means spending more tokens for every interaction, which costs money and can add up quickly. </span><span class="kobospan" id="kobo.312.3">Fine-tuning can help reduce that cost. </span><span class="kobospan" id="kobo.312.4">Using less expensive models for specific tasks also reduces the cost. </span><span class="kobospan" id="kobo.312.5">Be willing to move to new models. </span><span class="kobospan" id="kobo.312.6">The industry is evolving quickly, with price reductions of 70% for some </span><span><span class="kobospan" id="kobo.313.1">new models.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.314.1">Don’t expect miracles; the LLM is not capable of all responses. </span><span class="kobospan" id="kobo.314.2">Foundational models don’t do well with math. </span><a href="B21964_03.xhtml#_idTextAnchor058" class="pcalibre pcalibre1 calibre6"><span><em class="italic"><span class="kobospan" id="kobo.315.1">Chapter 3</span></em></span></a><em class="italic"><span class="kobospan" id="kobo.316.1">, Identifying Optimal Use Cases for ChatGPT</span></em><span class="kobospan" id="kobo.317.1">, discussed various use cases to avoid. </span><span class="kobospan" id="kobo.317.2">Avoid lousy use cases. </span><span class="kobospan" id="kobo.317.3">The OpenAI team says prompts are unsuitable for “</span><em class="italic"><span class="kobospan" id="kobo.318.1">reliability replicating a complex style or method, i.e., learning a new </span></em><span><em class="italic"><span class="kobospan" id="kobo.319.1">programming language.</span></em></span><span><span class="kobospan" id="kobo.320.1">”</span></span></li>
			</ul>
			<p class="calibre3"><span class="kobospan" id="kobo.321.1">Each use case will demand some</span><a id="_idIndexMarker500" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.322.1"> of these tips but don’t expect to use all of them. </span><span class="kobospan" id="kobo.322.2">A/B testing is an excellent generic usability method for learning whether one of these approaches </span><span><span class="kobospan" id="kobo.323.1">works better.</span></span></p>
			<h2 id="_idParaDest-152" class="calibre9"><a id="_idTextAnchor157" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.324.1">A/B testing</span></h2>
			<p class="calibre3"><span class="kobospan" id="kobo.325.1">OpenAI’s extensive documentation is a source of great ideas to help improve prompts. </span><span class="kobospan" id="kobo.325.2">However, it misses one excellent </span><a id="_idIndexMarker501" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.326.1">method that product designers use with software development, which is A/B testing. </span><span class="kobospan" id="kobo.326.2">This is something that has been</span><a id="_idIndexMarker502" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.327.1"> around for a long time. </span><span class="kobospan" id="kobo.327.2">A/B testing requires deploying multiple solutions and comparing the results to determine a winner. </span><span class="kobospan" id="kobo.327.3">In reality, this can be an A/B/C/D testing with various prompts. </span><span class="kobospan" id="kobo.327.4">If one scores significantly better than the other, that is the winner. </span><span class="kobospan" id="kobo.327.5">Then, iteratively test with a second A/B test by creating new versions based on the winner. </span><span class="kobospan" id="kobo.327.6">A/B testing can be done in multiple ways, including deploying and testing within a user research study or deploying in production while monitoring the results. </span><span class="kobospan" id="kobo.327.7">More advanced solutions incorporate analytics into the testing, and if statistically there is a winner, the test automatically shuts down, and the winner is deployed to all users. </span><span class="kobospan" id="kobo.327.8">This can be done with prompts, fine-tuning, RAG data resources, and any case where multiple options are viable. </span><span class="kobospan" id="kobo.327.9">Traditionally, this was done with GUI issues, such as the best location or label for a button. </span><span class="kobospan" id="kobo.327.10">Automating the rollover to adjust the winning condition has been around for decades. </span><span class="kobospan" id="kobo.327.11">Existing clever ideas continue to apply in the generative AI world, while there are dozens of techniques specific to prompting. </span><span class="kobospan" id="kobo.327.12">Let’s look at some essential </span><span><span class="kobospan" id="kobo.328.1">prompt-specific techniques.</span></span></p>
			<h1 id="_idParaDest-153" class="calibre5"><a id="_idTextAnchor158" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.329.1">Prompt engineering techniques</span></h1>
			<p class="calibre3"><span class="kobospan" id="kobo.330.1">There are dozens of techniques</span><a id="_idIndexMarker503" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.331.1"> to improve prompts. </span><span class="kobospan" id="kobo.331.2">This section highlights the most valuable strategies for enterprise </span><span><span class="kobospan" id="kobo.332.1">use cases.</span></span></p>
			<h2 id="_idParaDest-154" class="calibre9"><a id="_idTextAnchor159" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.333.1">Self-consistency</span></h2>
			<p class="calibre3"><span class="kobospan" id="kobo.334.1">Think of self-consistency as </span><a id="_idIndexMarker504" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.335.1">aligning statements with truth, thus making them </span><span><span class="kobospan" id="kobo.336.1">logically aligned:</span></span></p>
			<pre class="source-code"><span class="kobospan1" id="kobo.337.1">
Solar power is a renewable resource. </span><span class="kobospan1" id="kobo.337.2">Because solar power is a finite resource, it has unlimited potential.</span></pre>			<p class="calibre3"><span class="kobospan" id="kobo.338.1">Solar power is a renewable resource, </span><em class="italic"><span class="kobospan" id="kobo.339.1">unlike</span></em><span class="kobospan" id="kobo.340.1"> coal or oil, which have finite reserves. </span><span class="kobospan" id="kobo.340.2">The response from the LLM needs to be more consistent in representing solar power, as it is </span><em class="italic"><span class="kobospan" id="kobo.341.1">not</span></em><span class="kobospan" id="kobo.342.1"> a finite resource. </span><span class="kobospan" id="kobo.342.2">The documentation might be an issue, or the context length or writing style infers wrong conclusions. </span><span class="kobospan" id="kobo.342.3">A solution is to provide a few examples that can teach the model. </span><span class="kobospan" id="kobo.342.4">This is not training it with the exact answers; it only gives exemplars to approach the class of problems. </span><span class="kobospan" id="kobo.342.5">It is pretty amazing. </span><span class="kobospan" id="kobo.342.6">Alternatively, ask the question differently and see whether some answers </span><span><span class="kobospan" id="kobo.343.1">are consistent.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.344.1">Wang et al. </span><span class="kobospan" id="kobo.344.2">(2023) go through a variety of these few-shot training examples in a variety of situations to help improve</span><a id="_idIndexMarker505" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.345.1"> reasoning from models. </span><span class="kobospan" id="kobo.345.2">Few-shot learning is covered later in this chapter. </span><span class="kobospan" id="kobo.345.3">Few-shot learning provides some examples to train a system to respond. </span><span class="kobospan" id="kobo.345.4">They get to self-consistency by taking multiple answers from the model responses and deciding on the correct solution based on their consistency. </span><span class="kobospan" id="kobo.345.5">It is like fault-tolerant software that might use three different computers to evaluate an answer. </span><span class="kobospan" id="kobo.345.6">If two or more are right, they go with the shared answer. </span><span class="kobospan" id="kobo.345.7">This means additional costs for gathering additional solutions. </span><span class="kobospan" id="kobo.345.8">Wang et al. </span><span class="kobospan" id="kobo.345.9">point out that they can use this method to include these examples in a fine-tuning model. </span><span class="kobospan" id="kobo.345.10">Putting an extensive collection of examples into a fine-tuned model reduces the cost of </span><span><span class="kobospan" id="kobo.346.1">large prompts.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.347.1">If reasoning is part of the solution space, consider how this approach can help improve quality. </span><span class="kobospan" id="kobo.347.2">Their research covered examples of arithmetic reasoning, common sense reasoning, symbolic reasoning, and strategies. </span><em class="italic"><span class="kobospan" id="kobo.348.1">Table 7.2</span></em><span class="kobospan" id="kobo.349.1"> shows examples from each area used in the prompts to support a model’s performance of </span><span><span class="kobospan" id="kobo.350.1">these tasks.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.351.1">Article: </span><a href="https://arxiv.org/pdf/2203.11171" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.352.1">Self-consistency improves chain of thought reasoning in language models</span></a><span class="kobospan" id="kobo.353.1"> by Wang et al. </span><span class="hidden1"><span class="kobospan" id="kobo.354.1">(</span></span><a href="https://arxiv.org/pdf/2203.11171" class="pcalibre pcalibre1 calibre6"><span class="hidden1"><span class="kobospan" id="kobo.355.1">https://arxiv.org/pdf/2203.11171</span></span></a><span class="hidden1"><span class="kobospan" id="kobo.356.1">)</span></span><span class="kobospan" id="kobo.357.1"> by Wang </span><span><span class="kobospan" id="kobo.358.1">et al.</span></span></p>
			<table id="table002-6" class="no-table-style">
				<colgroup class="calibre15">
					<col class="calibre16"/>
					<col class="calibre16"/>
				</colgroup>
				<thead class="calibre18">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.359.1">Reasoning</span></strong></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.360.1">Examples</span></strong></span></p>
						</td>
					</tr>
				</thead>
				<tbody class="calibre17">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.361.1">Arithmetic</span></strong></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span class="kobospan" id="kobo.362.1">(Train on examples </span><span><span class="kobospan" id="kobo.363.1">like this)</span></span></p>
							<p class="calibre3"><span class="kobospan" id="kobo.364.1">Q: The grove has 15 trees. </span><span class="kobospan" id="kobo.364.2">Grove workers will plant trees in the grove today. </span><span class="kobospan" id="kobo.364.3">When done, there will be 21 trees. </span><span class="kobospan" id="kobo.364.4">How many trees did the workers </span><span><span class="kobospan" id="kobo.365.1">plant today?</span></span></p>
							<p class="calibre3"><span class="kobospan" id="kobo.366.1">A: We start with 15 trees. </span><span class="kobospan" id="kobo.366.2">Later, we have 21 trees. </span><span class="kobospan" id="kobo.366.3">The difference must be the number of trees planted. </span><span class="kobospan" id="kobo.366.4">So, they planted 21- 15 = 6 trees. </span><span class="kobospan" id="kobo.366.5">The answer </span><span><span class="kobospan" id="kobo.367.1">is 6.</span></span></p>
							<p class="calibre3"><span class="kobospan" id="kobo.368.1">(To then ask similar questions </span><span><span class="kobospan" id="kobo.369.1">like this)</span></span></p>
							<p class="calibre3"><em class="italic"><span class="kobospan" id="kobo.370.1">Q: When I was 6, my sister was half my age. </span><span class="kobospan" id="kobo.370.2">Now that I’m 70, how old </span></em><span><em class="italic"><span class="kobospan" id="kobo.371.1">is she?</span></em></span></p>
							<p class="calibre3"><span class="kobospan" id="kobo.372.1">(So, the reasoned answer </span><span><span class="kobospan" id="kobo.373.1">is correct)</span></span></p>
							<p class="calibre3"><em class="italic"><span class="kobospan" id="kobo.374.1">When I was 6, my sister was half my age, so she was 3. </span><span class="kobospan" id="kobo.374.2">Now, I am 70, so she is 70 - 3 = 67. </span><span class="kobospan" id="kobo.374.3">The answer </span></em><span><em class="italic"><span class="kobospan" id="kobo.375.1">is 67</span></em></span><span><span class="kobospan" id="kobo.376.1">.</span></span></p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.377.1">Common </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.378.1">sense</span></strong></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span class="kobospan" id="kobo.379.1">Yes or no: Can the Great Depression be treated </span><span><span class="kobospan" id="kobo.380.1">with Prozac?</span></span></p>
							<p class="calibre3"><span class="kobospan" id="kobo.381.1">(The </span><span><span class="kobospan" id="kobo.382.1">wrong answer)</span></span></p>
							<p class="calibre3"><em class="italic"><span class="kobospan" id="kobo.383.1">The Great Depression was an economic depression. </span><span class="kobospan" id="kobo.383.2">Prozac is a drug used to treat depression. </span><span class="kobospan" id="kobo.383.3">Thus, the Great Depression could be treated with Prozac. </span><span class="kobospan" id="kobo.383.4">So, the </span></em><em class="italic"><a id="_idIndexMarker506" class="pcalibre pcalibre1 calibre6"/></em><em class="italic"><span class="kobospan" id="kobo.384.1">answer </span></em><span><em class="italic"><span class="kobospan" id="kobo.385.1">is yes.</span></em></span></p>
							<p class="calibre3"><span class="kobospan" id="kobo.386.1">(A correctly </span><span><span class="kobospan" id="kobo.387.1">reasoned example)</span></span></p>
							<p class="calibre3"><em class="italic"><span class="kobospan" id="kobo.388.1">Prozac is an anti-depressant medication. </span><span class="kobospan" id="kobo.388.2">The Great Depression is not a disease. </span><span class="kobospan" id="kobo.388.3">Thus, Prozac cannot treat the Great Depression. </span><span class="kobospan" id="kobo.388.4">So, the answer </span></em><span><em class="italic"><span class="kobospan" id="kobo.389.1">is no.</span></em></span></p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.390.1">Symbolic</span></strong></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span class="kobospan" id="kobo.391.1">Concatenate the last letters of </span><span><span class="kobospan" id="kobo.392.1">each name.</span></span></p>
							<p class="calibre3"><span class="kobospan" id="kobo.393.1">Q: </span><span><span class="kobospan" id="kobo.394.1">Jim Beam</span></span></p>
							<p class="calibre3"><span><span class="kobospan" id="kobo.395.1">A: mm</span></span></p>
							<p class="calibre3"><span class="kobospan" id="kobo.396.1">Q: </span><span><span class="kobospan" id="kobo.397.1">Richard Miller</span></span></p>
							<p class="calibre3"><span><span class="kobospan" id="kobo.398.1">A: dr</span></span></p>
							<p class="calibre3"><span class="kobospan" id="kobo.399.1">Q: </span><span><span class="kobospan" id="kobo.400.1">Ely Kaplan</span></span></p>
							<p class="calibre3"><span class="kobospan" id="kobo.401.1">(The correct response to the </span><span><span class="kobospan" id="kobo.402.1">training example)</span></span></p>
							<p class="calibre3"><span><span class="kobospan" id="kobo.403.1">A: yn</span></span></p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.404.1">Strategy</span></strong></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span class="kobospan" id="kobo.405.1">Yes or no: Is Albany, Georgia, the most populous </span><span><span class="kobospan" id="kobo.406.1">US Albany?</span></span></p>
							<p class="calibre3"><span class="kobospan" id="kobo.407.1">(The </span><span><span class="kobospan" id="kobo.408.1">wrong answer)</span></span></p>
							<p class="calibre3"><em class="italic"><span class="kobospan" id="kobo.409.1">Albany, Georgia is the most</span></em><em class="italic"><a id="_idIndexMarker507" class="pcalibre pcalibre1 calibre6"/></em><em class="italic"><span class="kobospan" id="kobo.410.1"> populous US Albany. </span><span class="kobospan" id="kobo.410.2">Thus, the answer </span></em><span><em class="italic"><span class="kobospan" id="kobo.411.1">is yes.</span></em></span></p>
							<p class="calibre3"><span class="kobospan" id="kobo.412.1">(A correctly </span><span><span class="kobospan" id="kobo.413.1">reasoned example)</span></span></p>
							<p class="calibre3"><em class="italic"><span class="kobospan" id="kobo.414.1">Albany, Georgia has a population of about 88,000. </span><span class="kobospan" id="kobo.414.2">Albany, New York, has a population of about 95,000. </span><span class="kobospan" id="kobo.414.3">Thus, Albany, Georgia, is not the most populous US Albany. </span><span class="kobospan" id="kobo.414.4">So, the answer </span></em><span><em class="italic"><span class="kobospan" id="kobo.415.1">is no.</span></em></span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.416.1">Table 7.2 – Examples of self-consistency testing and training from Wang et al. </span><span class="kobospan" id="kobo.416.2">(2023)</span></p>
			<h2 id="_idParaDest-155" class="calibre9"><a id="_idTextAnchor160" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.417.1">General knowledge prompting</span></h2>
			<p class="calibre3"><span class="kobospan" id="kobo.418.1">While in RAG, the reduced results from a knowledge search are used to create a manageable </span><a id="_idIndexMarker508" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.419.1">set of information to pass to the LLM for analysis. </span><span class="kobospan" id="kobo.419.2">General knowledge prompting provides context to a question so a model can use that to inform the answer. </span><span class="kobospan" id="kobo.419.3">Take database information to build and share a persona for the user. </span><span class="kobospan" id="kobo.419.4">This might help the model improve its interactions with </span><span><span class="kobospan" id="kobo.420.1">the customer:</span></span></p>
			<pre class="source-code"><span class="kobospan1" id="kobo.421.1">
Question: This customer is trying to understand the current state of their open service tickets.
</span><span class="kobospan1" id="kobo.421.2">Knowledge: The customer, Steve Jones, has been a regular user of our products for 12 years. </span><span class="kobospan1" id="kobo.421.3">They typically file 12-20 service tickets a year. </span><span class="kobospan1" id="kobo.421.4">They might be concerned if they have three open service requests, which is more than usual. </span><span class="kobospan1" id="kobo.421.5">Use this knowledge to form answers when interacting with Steve.</span></pre>			<p class="calibre3"><span class="kobospan" id="kobo.422.1">This stretches the concept of general knowledge prompting. </span><span class="kobospan" id="kobo.422.2">Sometimes, experiments like this can yield results. </span><span class="kobospan" id="kobo.422.3">These</span><a id="_idIndexMarker509" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.423.1"> approaches can be used in conjunction with other methods. </span><span class="kobospan" id="kobo.423.2">Prompt chaining helps break down problems into </span><span><span class="kobospan" id="kobo.424.1">manageable parts.</span></span></p>
			<h2 id="_idParaDest-156" class="calibre9"><a id="_idTextAnchor161" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.425.1">Prompt chaining</span></h2>
			<p class="calibre3"><span class="kobospan" id="kobo.426.1">Multiple approaches break down tasks into smaller tasks and then apply more refined reasoning to a part of a problem. </span><span class="kobospan" id="kobo.426.2">The</span><a id="_idIndexMarker510" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.427.1"> team at Wove breaks down its tasks so that specific prompts can be controlled. </span><span class="kobospan" id="kobo.427.2">For example, document extraction is done with one set of prompts and a second set of formats, and the results from the documents are returned. </span><span class="kobospan" id="kobo.427.3">This involves chaining one model output to become input for the next model. </span><span class="kobospan" id="kobo.427.4">This allows models to be hyper-focused on specific tasks. </span><span class="kobospan" id="kobo.427.5">Each can then become better at their job, helping to manage workflow and allowing for improvements in one segment not to impact another. </span><span class="kobospan" id="kobo.427.6">A large single-purpose model to do all of this would be hard to operate </span><span><span class="kobospan" id="kobo.428.1">and improve.</span></span></p>
			<h3 class="calibre11"><span class="kobospan" id="kobo.429.1">Time to think</span></h3>
			<p class="calibre3"><span class="kobospan" id="kobo.430.1">A model can be asked in a prompt for a </span><strong class="bold"><span class="kobospan" id="kobo.431.1">chain of thought</span></strong><span class="kobospan" id="kobo.432.1"> (</span><strong class="bold"><span class="kobospan" id="kobo.433.1">COT</span></strong><span class="kobospan" id="kobo.434.1">). </span><span class="kobospan" id="kobo.434.2">Thus, a model needs to work out its solution before</span><a id="_idIndexMarker511" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.435.1"> jumping to </span><span><span class="kobospan" id="kobo.436.1">a conclusion:</span></span></p>
			<pre class="source-code"><span class="kobospan1" id="kobo.437.1">
Approach this task step-by-step, take your time, and do not skip steps.</span></pre>			<p class="calibre3"><span class="kobospan" id="kobo.438.1">OpenAI has plenty of other strategies, some of which are very tactical, such as using delimiters to keep specific input distinct. </span><span class="kobospan" id="kobo.438.2">Some of these can be adapted to instructions that help guide </span><span><span class="kobospan" id="kobo.439.1">user prompts.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.440.1">Article: </span><a href="https://platform.openai.com/docs/guides/prompt-engineering/strategy-write-clear-instructions" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.441.1">Writing clear </span><span><span class="kobospan" id="kobo.442.1">instructions</span></span></a><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.443.1">(</span></span></span><a href="https://platform.openai.com/docs/guides/prompt-engineering/strategy-write-clear-instructions" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.444.1">https://platform.openai.com/docs/guides/prompt-engineering/strategy-write-clear-instructions</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.445.1">)</span></span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.446.1">Anthropic does an excellent job of providing some enterprise-related examples of analyzing a legal contract using </span><a id="_idIndexMarker512" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.447.1">chaining. </span><span class="kobospan" id="kobo.447.2">Here are some other examples </span><span><span class="kobospan" id="kobo.448.1">they provide.</span></span></p>
			<ul class="calibre7">
				<li class="calibre8"><strong class="bold"><span class="kobospan" id="kobo.449.1">Content creation pipelines</span></strong><span class="kobospan" id="kobo.450.1">: Research → outline → draft → edit → </span><span><span class="kobospan" id="kobo.451.1">format</span></span></li>
				<li class="calibre8"><strong class="bold"><span class="kobospan" id="kobo.452.1">Data processing</span></strong><span class="kobospan" id="kobo.453.1">: Extract → transform → analyze → </span><span><span class="kobospan" id="kobo.454.1">visualize</span></span></li>
				<li class="calibre8"><strong class="bold"><span class="kobospan" id="kobo.455.1">Decision-making</span></strong><span class="kobospan" id="kobo.456.1">: Gather info → list options → analyze each → </span><span><span class="kobospan" id="kobo.457.1">recommend</span></span></li>
				<li class="calibre8"><strong class="bold"><span class="kobospan" id="kobo.458.1">Verification loops</span></strong><span class="kobospan" id="kobo.459.1">: Generate content → review → refine → </span><span><span class="kobospan" id="kobo.460.1">re-review</span></span></li>
			</ul>
			<p class="calibre3"><span class="kobospan" id="kobo.461.1">Article: </span><a href="https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-prompts" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.462.1">Chaining complex prompts for stronger </span><span><span class="kobospan" id="kobo.463.1">performance</span></span></a><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.464.1">(</span></span></span><a href="https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-prompts" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.465.1">https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-prompts</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.466.1">)</span></span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.467.1">I especially like one of the advantages mentioned in the article—traceability. </span><span class="kobospan" id="kobo.467.2">There is so much magic going on with LLMs; sometimes, we need to </span><em class="italic"><span class="kobospan" id="kobo.468.1">feel</span></em><span class="kobospan" id="kobo.469.1"> our way to success, even with metrics that provide scoring. </span><span class="kobospan" id="kobo.469.2">Breaking down tasks into modules that can be tweaked independently to spot process issues is very appealing. </span><span class="kobospan" id="kobo.469.3">Large prompts with a massive scope involve more work to adapt </span><span><span class="kobospan" id="kobo.470.1">and improve.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.471.1">Use chaining</span><a id="_idIndexMarker513" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.472.1"> within the same model in three steps – summarize, analyze, and update. </span><span class="kobospan" id="kobo.472.2">OpenAI refers to this as an “inner monologue.” </span><span class="kobospan" id="kobo.472.3">It has this conversation internally before revealing </span><span><span class="kobospan" id="kobo.473.1">the answer:</span></span></p>
			<pre class="source-code-right"><strong class="bold1"><span class="kobospan1" id="kobo.474.1">Summarize</span></strong><span class="kobospan1" id="kobo.475.1"> the following article.Provide the product details,The steps to follow and the results.&lt;knowledge&gt;{{KNOWLEDGE_ARTICLE}}&lt;/knowledge&gt;
(Assistant provides the SUMMARY)</span><strong class="bold1"><span class="kobospan1" id="kobo.476.1">Analyze</span></strong><span class="kobospan1" id="kobo.477.1"> the summary &lt;summary&gt;{{SUMMARY}}&lt;/summary&gt; and validate it against the following knowledge article &lt;knowledge&gt;{{KNOWLEDGE_ARTICLE}}&lt;/knowledge&gt;. </span><span class="kobospan1" id="kobo.477.2">Your task is critical to the success of the customer.</span><strong class="bold1"><span class="kobospan1" id="kobo.478.1">Review</span></strong><span class="kobospan1" id="kobo.479.1"> this knowledge summary for accuracy,clarity, and completeness on a graded A-F scale.
</span><span class="kobospan1" id="kobo.479.2">(Assistant provides the FEEDBACK)
including gaps it might have found)It is essential to improve the articlesummary based on this feedback. </span><span class="kobospan1" id="kobo.479.3">Here isthe &lt;summary&gt;{{SUMMARY}}&lt;/summary&gt;Here is the article:&lt;knowledge&gt;{{KNOWLEDGE_ARTICLE}}&lt;/knowledge&gt;Here is the feedback:&lt;feedback&gt;{{FEEDBACK}}&lt;/feedback&gt;</span><strong class="bold1"><span class="kobospan1" id="kobo.480.1">Update</span></strong><span class="kobospan1" id="kobo.481.1"> the summary based on the feedback.
</span><span class="kobospan1" id="kobo.481.2">(Assistant provides the IMPROVED SUMMARY)</span></pre>			<p class="calibre3"><span class="kobospan" id="kobo.482.1">This requires significantly more resources, but the findings should be more accurate. </span><span class="kobospan" id="kobo.482.2">Notice the terms </span><strong class="source-inline"><span class="kobospan" id="kobo.483.1">Summarize</span></strong><span class="kobospan" id="kobo.484.1">, </span><strong class="source-inline"><span class="kobospan" id="kobo.485.1">Analyze</span></strong><span class="kobospan" id="kobo.486.1">, </span><strong class="source-inline"><span class="kobospan" id="kobo.487.1">Review</span></strong><span class="kobospan" id="kobo.488.1">, and </span><strong class="source-inline"><span class="kobospan" id="kobo.489.1">Update</span></strong><span class="kobospan" id="kobo.490.1">. </span><span class="kobospan" id="kobo.490.2">The model determines the meaning of these terms in that it knows what to do when asked to analyze, review, update, summarize, and so on. </span><span class="kobospan" id="kobo.490.3">By breaking down the process into steps, communication gaps can be fixed to return the </span><span><span class="kobospan" id="kobo.491.1">correct result.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.492.1">Here is an example of prompts for an email summary to get a model to think through a problem and reduce hallucinations. </span><span class="kobospan" id="kobo.492.2">This is a robust version of “</span><em class="italic"><span class="kobospan" id="kobo.493.1">Think about the solution step by step</span></em><span class="kobospan" id="kobo.494.1">.” </span><span class="kobospan" id="kobo.494.2">Craft versions of these to match the </span><span><span class="kobospan" id="kobo.495.1">use case:</span></span></p>
			<pre class="source-code"><span class="kobospan1" id="kobo.496.1">
List critical decisions, follow-up items, and the associated owners for each task.
</span><span class="kobospan1" id="kobo.496.2">Once completed, check that these details are factually accurate with the original email.
</span><span class="kobospan1" id="kobo.496.3">Then, concisely summarize the critical points in a few statements.</span></pre>			<p class="calibre3"><span class="kobospan" id="kobo.497.1">Recognize that chaining only works in some use cases. </span><span class="kobospan" id="kobo.497.2">It can be applied in backend solutions and recommenders or in more freeform conversational interactions, as it might take</span><a id="_idIndexMarker514" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.498.1"> time to go through multiple steps. </span><span class="kobospan" id="kobo.498.2">But it is a solid strategy for complex problems. </span><span class="kobospan" id="kobo.498.3">The hub and spoke flow chart shows that chains can be done with multiple vendors’ models. </span><span class="kobospan" id="kobo.498.4">Understand what a model is good at, consider speed or responsiveness, and consider its ability to handle media like images, if needed, and make cost/benefit trade-offs. </span><span class="kobospan" id="kobo.498.5">With this complexity comes another issue – handling entities and working with other systems. </span><span class="kobospan" id="kobo.498.6">A program-aided approach is part of the solution for </span><span><span class="kobospan" id="kobo.499.1">enterprise complexity.</span></span></p>
			<h2 id="_idParaDest-157" class="calibre9"><a id="_idTextAnchor162" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.500.1">Program-aided language models</span></h2>
			<p class="calibre3"><span class="kobospan" id="kobo.501.1">Although the example in the prompt guide is based on using a Python interpreter as an intermediate step to calculate an answer to a math question, since LLMs are not good at math, enterprise use cases can do form filling, organize data, write copy, build SQL queries, and </span><a id="_idIndexMarker515" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.502.1">perform mundane tasks. </span><span class="kobospan" id="kobo.502.2">The LLM can help to identify entities, objects, dates, times, sizes, product IDs, names, and a wealth of other elements in a statement. </span><span class="kobospan" id="kobo.502.3">Backend services that can validate some of this data are expected. </span><span class="kobospan" id="kobo.502.4">So, programming and existing infrastructure are used to capture the data. </span><span class="kobospan" id="kobo.502.5">An LLM can also be used to format </span><span><span class="kobospan" id="kobo.503.1">data correctly.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.504.1">Let me give an example that is easily created in the Playground. </span><span class="kobospan" id="kobo.504.2">This prompt extracts information from a conversation for an expense receipt input system. </span><span class="kobospan" id="kobo.504.3">Later, during my testing, the items in italics</span><a id="_idIndexMarker516" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.505.1"> were added to improve </span><span><span class="kobospan" id="kobo.506.1">the output:</span></span></p>
			<pre class="source-code"><span class="kobospan1" id="kobo.507.1">
You are a helpful assistant who can parse receipt information into its specific elements, formatting them to submit later to an SQL database. </span><span class="kobospan1" id="kobo.507.2">We expect the following data elements to be extracted.
</span><span class="kobospan1" id="kobo.507.3">Date: MM/DD/YYYY
Business: {Business Name}
Expense Type: Type of expense like Meals, Hotel, Air flight, Car and Car Rental, or Other
Reason: A qualified business reason, like meeting with a customer or am out of town conference
Amount: $ US Dollars like $12.50
Not all elements will be in every statement. </span><span class="kobospan1" id="kobo.507.4">Ignore elements that are missing. </span><span class="kobospan1" id="kobo.507.5">Reformat all dates into MM/DD/YYYY format. </span><strong class="bold1"><span class="kobospan1" id="kobo.508.1">Prompt if the user is missing the amount or date, those are mandatory</span></strong><span class="kobospan1" id="kobo.509.1">.</span></pre>			<p class="calibre3"><span class="kobospan" id="kobo.510.1">So, a conversation, with no other prompting or training, looks </span><span><span class="kobospan" id="kobo.511.1">like this:</span></span></p>
			<pre class="source-code-right"><span class="kobospan1" id="kobo.512.1">Flght (sic) on UA to SFO andreturn for $454.44 this weekfor conference
Date: 06/22/2024 Business:
United Airlines (UA) Purpose:
Airflight Reason: Conference
Amount: $454.44Dinner at Bennihan (sic) inBurlingame for $134.40 with2 customers
Date: 06/22/2024 Business:
Benihana, Burlingame Purpose:
Meal Reason: Dinner with 2
customers Amount: $134.40Photocopies yesterdayfor meeting
Date: 06/21/2024 Business:
Not specified Purpose: Other
Reason: Photocopies for
meeting Amount: Not specified
The amount is missing. </span><span class="kobospan1" id="kobo.512.2">Could
you, please provide it?I foget (sic)
No problem! </span><span class="kobospan1" id="kobo.512.3">We'll need the
amount to proceed. </span><span class="kobospan1" id="kobo.512.4">Could you
please check and provide the
total cost of the photocopies?3.40
Date: 06/21/2024 Business:
Not specified Purpose: Other
Reason: Photocopies for
meeting Amount: $3.40</span></pre>			<p class="calibre3"><span class="kobospan" id="kobo.513.1">The results show that ChatGPT 4o (2024-05-13) got this right – it correctly identified </span><strong class="bold"><span class="kobospan" id="kobo.514.1">UA</span></strong><span class="kobospan" id="kobo.515.1"> as </span><strong class="bold"><span class="kobospan" id="kobo.516.1">United Airlines</span></strong><span class="kobospan" id="kobo.517.1">, spelled </span><em class="italic"><span class="kobospan" id="kobo.518.1">Benihana</span></em><span class="kobospan" id="kobo.519.1"> correctly, and adjusted the date format. </span><span class="kobospan" id="kobo.519.2">Now, this can be submitted to a </span><a id="_idIndexMarker517" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.520.1">backend. </span><span class="kobospan" id="kobo.520.2">All typos were intentional. </span><span class="kobospan" id="kobo.520.3">Apply this example to the use cases in your organization. </span><span class="kobospan" id="kobo.520.4">I suspect there is </span><span><span class="kobospan" id="kobo.521.1">something similar.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.522.1">So, if the solution is more than searching for knowledge, like interacting with backend systems, balance the LLM expertise with the capability of the services. </span><span class="kobospan" id="kobo.522.2">Over time, those backend systems will adapt, but to get out of the gate, choose which systems</span><a id="_idIndexMarker518" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.523.1"> must be adapted or flexed. </span><span class="kobospan" id="kobo.523.2">Services, scheduling, forms, and all those mundane business processes customers and employees have to do but don’t want to do as humans can be automated or semi-automated. </span><span class="kobospan" id="kobo.523.3">This is at the heart of the enterprise space. </span><span class="kobospan" id="kobo.523.4">And can make an enterprise experience </span><span><span class="kobospan" id="kobo.524.1">more consumer-friendly.</span></span></p>
			<h2 id="_idParaDest-158" class="calibre9"><a id="_idTextAnchor163" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.525.1">Few-shot prompting</span></h2>
			<p class="calibre3"><span class="kobospan" id="kobo.526.1">Doesn't everyone do something better when shown an example beforehand? </span><span class="kobospan" id="kobo.526.2">This book has hundreds of examples to support learning. </span><span class="kobospan" id="kobo.526.3">LLMs are the same with complex tasks. </span><span class="kobospan" id="kobo.526.4">When</span><a id="_idIndexMarker519" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.527.1"> including RAG data, use examples to clarify understanding. </span><span class="kobospan" id="kobo.527.2">A </span><strong class="bold"><span class="kobospan" id="kobo.528.1">few-shot prompt</span></strong><span class="kobospan" id="kobo.529.1"> consists </span><a id="_idIndexMarker520" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.530.1">of a few examples to prime the model and help it understand what is expected. </span><span class="kobospan" id="kobo.530.2">The prompt gives the model a few shots (examples) to learn. </span><span class="kobospan" id="kobo.530.3">As a preview of fine-tuning, few-shot learning is the simple version of fine-tuning. </span><span class="kobospan" id="kobo.530.4">A prompt should not have 100 examples, but as explained later, it is better to include them in a fine-tuned model. </span><span class="kobospan" id="kobo.530.5">Look at this example to see how the model will </span><span><span class="kobospan" id="kobo.531.1">follow along:</span></span></p>
			<pre class="source-code-right"><span class="kobospan1" id="kobo.532.1">You are a bad driver -- NegativeYour hair looks amazing -- PositiveThe sunrise is beautiful -- NegativeI am not happy
It seems like there may be a mix-up in the descriptions of the statements. </span><span class="kobospan1" id="kobo.532.2">"You are a bad driver" and "The sunrise is beautiful" are both negative statements, while "Your hair looks amazing" is a positive statement.
</span><span class="kobospan1" id="kobo.532.3">Let's correct the descriptions:
"You are a bad driver" – Negative
"Your hair looks amazing" – Positive
"The sunrise is beautiful" – Positive
"I am not happy" – Negative</span></pre>			<p class="calibre3"><span class="kobospan" id="kobo.533.1">Even a basic model such as the GPT 3.5 turbo (1106) is knowledgeable (newer models such as the GPT-4o mini were tested. </span><span class="kobospan" id="kobo.533.2">They performed just as well but were wordier). </span><span class="kobospan" id="kobo.533.3">It is impressive that it doesn’t fall for our mistake in classification, corrects it, and provides the proper classification for the next statement. </span><span class="kobospan" id="kobo.533.4">Sentiment analysis is popular in service and sales use cases but is a simple example. </span><span class="kobospan" id="kobo.533.5">Sentiment </span><a id="_idIndexMarker521" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.534.1">analysis for support cases is more nuanced. </span><span class="kobospan" id="kobo.534.2">The issue isn’t their mood but what to do </span><span><span class="kobospan" id="kobo.535.1">about it.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.536.1">With</span><a id="_idIndexMarker522" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.537.1"> recommenders, examples are provided to adapt its results to a similar approach. </span><span class="kobospan" id="kobo.537.2">The format is for the model’s output in the program-aided language model expense assistant example. </span><span class="kobospan" id="kobo.537.3">Think of this as a collection of formatted examples to form the </span><span><span class="kobospan" id="kobo.538.1">LLM’s answer:</span></span></p>
			<pre class="source-code"><span class="kobospan1" id="kobo.539.1">
Keep recommendations simple but provide precise data and details so the customer can follow the instructions. </span><span class="kobospan1" id="kobo.539.2">Following these recommendations correctly is essential to their success. </span><span class="kobospan1" id="kobo.539.3">Here are some examples.
</span><span class="kobospan1" id="kobo.539.4">Call your customer in the next few days to increase the likelihood of closing the deal. </span><span class="kobospan1" id="kobo.539.5">Remind them of the service's value and the discounts applied to their offer.
</span><span class="kobospan1" id="kobo.539.6">If you offer a 20% discount over two years, the customer is 30% more likely to include a service contract. </span><span class="kobospan1" id="kobo.539.7">Call them with this exciting offer.</span></pre>			<p class="calibre3"><span class="kobospan" id="kobo.540.1">If the prompt gets out of control and it is doing too much, consider breaking down cases to farm out tasks to specific models. </span><span class="kobospan" id="kobo.540.2">This will be covered shortly, but fine-tuning in the next chapter is another option to reduce the </span><a id="_idIndexMarker523" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.541.1">prompt’s size </span><span><span class="kobospan" id="kobo.542.1">and complexity.</span></span></p>
			<p class="callout-heading"><span class="kobospan" id="kobo.543.1">Why use GPT 3.5 Turbo 1106? </span><span class="kobospan" id="kobo.543.2">There are better models</span></p>
			<p class="callout"><span class="kobospan" id="kobo.544.1">The strategies and learnings of this book can be applied to any </span><span><span class="kobospan" id="kobo.545.1">modern model.</span></span></p>
			<p class="callout"><span class="kobospan" id="kobo.546.1">For the examples shared, the </span><a id="_idIndexMarker524" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.547.1">ability to use larger context windows, output large datasets, and performance are not factors. </span><span class="kobospan" id="kobo.547.2">1106 is roughly 10x cheaper than GPT-4, 30x more affordable than GPT-4o mini, and less expensive than Claude 2, Llama, and Gemini 1.5 Pro (September 2024). </span><span class="kobospan" id="kobo.547.3">Learn and practice without worrying about hefty bills. </span><span class="kobospan" id="kobo.547.4">Invest in the right model quality and cost balance for actual models. </span><span class="kobospan" id="kobo.547.5">There is no magic flow chart to determine the right fit. </span><span class="kobospan" id="kobo.547.6">It is about testing, experimentation, researching what others have found, and understanding the use case, amount of use, and performance needs. </span><span class="kobospan" id="kobo.547.7">For some use cases, running a model on a local system is possible with modern hardware. </span><span class="kobospan" id="kobo.547.8">OpenAI doesn’t have this, but some open-source models do. </span><span class="kobospan" id="kobo.547.9">With the introduction of GPT-4o mini, the costs continue to come down. </span><span class="kobospan" id="kobo.547.10">It is one-third the price of GPT-3.5 Turbo. </span><a href="B21964_08.xhtml#_idTextAnchor172" class="pcalibre pcalibre1 calibre6"><span><em class="italic"><span class="kobospan" id="kobo.548.1">Chapter 8</span></em></span></a><span class="kobospan" id="kobo.549.1">, </span><em class="italic"><span class="kobospan" id="kobo.550.1">Fine-Tuning,</span></em><span class="kobospan" id="kobo.551.1"> will explain the costs of running a fine-tuned model, which is more than the equivalent </span><span><span class="kobospan" id="kobo.552.1">generic model.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.553.1">This is just a glimpse into some methods to build effective prompts. </span><span class="kobospan" id="kobo.553.2">A few were left out, as they are discussed in Andrew </span><span><span class="kobospan" id="kobo.554.1">Ng’s talk.</span></span></p>
			<h1 id="_idParaDest-159" class="calibre5"><a id="_idTextAnchor164" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.555.1">Andrew Ng’s agentic approach</span></h1>
			<p class="calibre3"><span class="kobospan" id="kobo.556.1">There are a wealth of videos and tutorials out there. </span><span class="kobospan" id="kobo.556.2">Andrew NGs are recommended because of his long history in the space and the trust he has garnered. </span><span class="kobospan" id="kobo.556.3">You may already know Andrew NG or follow his AI discussions. </span><span class="kobospan" id="kobo.556.4">In the</span><a id="_idIndexMarker525" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.557.1"> following video, he discusses a few critical </span><span><span class="kobospan" id="kobo.558.1">design patterns.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.559.1">Video: </span><a href="https://www.youtube.com/watch?v=sal78ACtGTc" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.560.1">Andrew NG Agentic </span><span><span class="kobospan" id="kobo.561.1">Presentation</span></span></a><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.562.1">(</span></span></span><a href="https://www.youtube.com/watch?v=sal78ACtGTc" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.563.1">https://www.youtube.com/watch?v=sal78ACtGTc</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.564.1">)</span></span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.565.1">I delayed discussing these in the previous section to include them here. </span><span class="kobospan" id="kobo.565.2">This will reinforce the concept that there are many approaches to solving problems and that no single approach will work for </span><span><span class="kobospan" id="kobo.566.1">all solutions:</span></span></p>
			<ul class="calibre7">
				<li class="calibre8"><span><span class="kobospan" id="kobo.567.1">Reflection</span></span></li>
				<li class="calibre8"><span><span class="kobospan" id="kobo.568.1">Tool use</span></span></li>
				<li class="calibre8"><span><span class="kobospan" id="kobo.569.1">Planning</span></span></li>
				<li class="calibre8"><span><span class="kobospan" id="kobo.570.1">Multi-agent collaboration</span></span></li>
			</ul>
			<p class="calibre3"><span class="kobospan" id="kobo.571.1">Many of these are </span><a id="_idIndexMarker526" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.572.1">essential to our prompt engineering and nuanced tuning discussion. </span><span class="kobospan" id="kobo.572.2">Let’s explore each of </span><span><span class="kobospan" id="kobo.573.1">these approaches.</span></span></p>
			<h2 id="_idParaDest-160" class="calibre9"><a id="_idTextAnchor165" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.574.1">Reflection</span></h2>
			<p class="calibre3"><span class="kobospan" id="kobo.575.1">This is a great approach. </span><span class="kobospan" id="kobo.575.2">Take</span><a id="_idIndexMarker527" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.576.1"> the output from the LLM and ask it to think more deeply about refining it. </span><span class="kobospan" id="kobo.576.2">If it is sent back to the same LLM, this is called self-reflection. </span><span class="kobospan" id="kobo.576.3">However, </span><a id="_idIndexMarker528" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.577.1">one model can also be used with a second model; this would be reflection. </span><span class="kobospan" id="kobo.577.2">The Wove case study used multiple models in </span><span><span class="kobospan" id="kobo.578.1">their flow.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.579.1">Andrew suggests the following articles to learn more about reflection, a form of chaining. </span><span class="kobospan" id="kobo.579.2">Although they appear a little technical, the concepts of self-reflection and the examples are easy to follow. </span><span class="kobospan" id="kobo.579.3">They cover a variety of use cases and have good examples. </span><span class="kobospan" id="kobo.579.4">Madaan et al. </span><span class="kobospan" id="kobo.579.5">recognize that the iterative approach works wonders in a space like enterprise solutions with intricate requirements and hard-to-define goals. </span><span class="kobospan" id="kobo.579.6">As with support calls and customer service, the original question isn’t going to get a suitable answer. </span><span class="kobospan" id="kobo.579.7">It can take dozens of interactions to frame a problem and find </span><span><span class="kobospan" id="kobo.580.1">a solution.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.581.1">Article: </span><a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/91edff07232fb1b55a505a9e9f6c0ff3-Paper-Conference.pdf" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.582.1">SELF-REFINE: Iterative Refinement with Self-Feedback</span></a><span class="kobospan" id="kobo.583.1"> by Madaan et </span><span><span class="kobospan" id="kobo.584.1">al. </span><span class="kobospan" id="kobo.584.2">(</span></span><a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/91edff07232fb1b55a505a9e9f6c0ff3-Paper-Conference.pdf" class="pcalibre pcalibre1 calibre6"><span><span class="kobospan" id="kobo.585.1">https://proceedings.neurips.cc/paper_files/paper/2023/file/91edff07232fb1b55a505a9e9f6c0ff3-Paper-Conference.pdf</span></span></a><span><span class="kobospan" id="kobo.586.1">)</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.587.1">Madaan et al. </span><span class="kobospan" id="kobo.587.2">also showed that the self-refinement process was more effective than asking a model to produce multiple outputs. </span><span class="kobospan" id="kobo.587.3">Humans still preferred the refined results over all of the additionally generated outputs. </span><span><em class="italic"><span class="kobospan" id="kobo.588.1">Figure 7</span></em></span><em class="italic"><span class="kobospan" id="kobo.589.1">.4</span></em><span class="kobospan" id="kobo.590.1"> shows self-reflection using the same model a second time. </span><span class="kobospan" id="kobo.590.2">See how the same models can be chained together for </span><span><span class="kobospan" id="kobo.591.1">further refinements.</span></span></p>
			<div class="calibre2">
				<div id="_idContainer090" class="img---figure">
					<span class="kobospan" id="kobo.592.1"><img src="image/B21964_07_04.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.593.1">Figure 7.4 – An example of self-reflection using the same model again</span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.594.1">Although many of these articles typically use coding examples, focusing on the examples of decision-making or reasoning is better for finding enterprise value. </span><span class="kobospan" id="kobo.594.2">Shinn et al. </span><span class="kobospan" id="kobo.594.3">covers a technical discussion. </span><span class="kobospan" id="kobo.594.4">Consider</span><a id="_idIndexMarker529" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.595.1"> adding value by validating whether the development team uses reflection in </span><span><span class="kobospan" id="kobo.596.1">its prompts.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.597.1">Article: </span><a href="https://arxiv.org/pdf/2303.11366.pdf" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.598.1">Reflexion: Language Agents with Verbal Reinforcement Learning</span></a><span class="kobospan" id="kobo.599.1"> by Shinn et </span><span><span class="kobospan" id="kobo.600.1">al. </span></span><span><span class="hidden1"><span class="kobospan" id="kobo.601.1">(</span></span></span><a href="https://arxiv.org/pdf/2303.11366.pdf" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.602.1">https://arxiv.org/pdf/2303.11366.pdf</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.603.1">)</span></span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.604.1">An extensive collection of LLMs, tools, and services are used with any enterprise workflow to create a complete solution. </span><span class="kobospan" id="kobo.604.2">Tools are part of </span><span><span class="kobospan" id="kobo.605.1">this solution.</span></span></p>
			<h2 id="_idParaDest-161" class="calibre9"><a id="_idTextAnchor166" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.606.1">Tool use</span></h2>
			<p class="calibre3"><span class="kobospan" id="kobo.607.1">It has been repeatedly mentioned that building enterprise solutions requires a robust ecosystem. </span><span class="kobospan" id="kobo.607.2">It is sometimes challenging to integrate third-party solutions into large enterprises. </span><span class="kobospan" id="kobo.607.3">Cost, licensing issues, cloud access, authentication and security, and legal issues all get in the way. </span><span class="kobospan" id="kobo.607.4">In an </span><a id="_idIndexMarker530" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.608.1">emerging field, it is unrealistic for most companies to do everything in-house. </span><span class="kobospan" id="kobo.608.2">It is not expected to build the models in-house, so the tools should be the same. </span><span class="kobospan" id="kobo.608.3">It is ideal to have a collection of tools for building the pipeline, monitoring, fine-tuning, documentation, and knowledge integration, not to mention the work to integrate internal services. </span><span class="kobospan" id="kobo.608.4">Patil et al. </span><span class="kobospan" id="kobo.608.5">references a few pieces of the puzzle to help write API calls. </span><span class="kobospan" id="kobo.608.6">This is a big deal when accessing enterprise data. </span><span class="kobospan" id="kobo.608.7">This is one of the areas developers </span><span><span class="kobospan" id="kobo.609.1">should review.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.610.1">Article: </span><a href="https://arxiv.org/pdf/2305.15334.pdf" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.611.1">Gorilla: Large Language Model Connected with Massive APIs</span></a><span class="kobospan" id="kobo.612.1"> by Patil et </span><span><span class="kobospan" id="kobo.613.1">al. </span><span class="kobospan" id="kobo.613.2">(</span></span><a href="https://arxiv.org/pdf/2305.15334.pdf" class="pcalibre pcalibre1 calibre6"><span><span class="kobospan" id="kobo.614.1">https://arxiv.org/pdf/2305.15334.pdf</span></span></a><span><span class="kobospan" id="kobo.615.1">)</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.616.1">The second article of interest relates to vision integration. </span><span class="kobospan" id="kobo.616.2">So far, we haven’t spent time on vision tools and use cases. </span><span class="kobospan" id="kobo.616.3">That was intentional. </span><span class="kobospan" id="kobo.616.4">However, vision tools have a place in enterprise solutions. </span><span class="kobospan" id="kobo.616.5">They can interpret images such as receipts, invoices, contracts, and charts, analyze video analysis to count an inventory, identify people, classify or count objects in a shopping cart or a construction project, or keep track of tasks on an assembly line. </span><span class="kobospan" id="kobo.616.6">There are plenty of places to integrate vision into an enterprise workflow. </span><span class="kobospan" id="kobo.616.7">These will likely each have their collection of models, each playing a part in the vision analysis process, with a unique care and feeding life cycle. </span><span class="kobospan" id="kobo.616.8">Yung et al. </span><span class="kobospan" id="kobo.616.9">explores challenges in the </span><span><span class="kobospan" id="kobo.617.1">multi-modal space.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.618.1">Article: </span><a href="https://arxiv.org/pdf/2303.11381.pdf" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.619.1">MM-REACT: Prompting ChatGPT for Multimodal Reasoning and Action</span></a><span class="kobospan" id="kobo.620.1"> by Yung et </span><span><span class="kobospan" id="kobo.621.1">al. </span></span><span><span class="hidden1"><span class="kobospan" id="kobo.622.1">(</span></span></span><a href="https://arxiv.org/pdf/2303.11381.pdf" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.623.1">https://arxiv.org/pdf/2303.11381.pdf</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.624.1">)</span></span></span></p>
			<p class="callout"><span class="kobospan" id="kobo.625.1">Model usage costs become only one factor as solutions scale up and other development expenses are included. </span><span class="kobospan" id="kobo.625.2">Because ChatGPT is a variable cost that increases with volume, large users can negotiate better pricing as model fee structures mature. </span><span class="kobospan" id="kobo.625.3">For open-source models, the team has to incur the cost to run the model, likely in silos if done for a customer, while larger shared instances might work for internal enterprise needs. </span><span class="kobospan" id="kobo.625.4">It seems reasonable that a large enterprise with hundreds of internal processes will have thousands of </span><span><span class="kobospan" id="kobo.626.1">active models.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.627.1">ChatGPT must be integrated with other tools to support the concept of planning. </span><span class="kobospan" id="kobo.627.2">There are now</span><a id="_idIndexMarker531" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.628.1"> hundreds of tool providers. </span><span class="kobospan" id="kobo.628.2">As the saying goes, enterprises want to </span><em class="italic"><span class="kobospan" id="kobo.629.1">eat their own dog food</span></em><span class="kobospan" id="kobo.630.1">; they like to do all the work in-house and prefer not to use third-party tools. </span><span class="kobospan" id="kobo.630.2">However, because of the speed of adoption, only some enterprises can build what they need from scratch. </span><span class="kobospan" id="kobo.630.3">So, it is also essential to have a structure to support rapid decision-making, tool integration, and a reasonable </span><span><span class="kobospan" id="kobo.631.1">licensing process.</span></span></p>
			<h2 id="_idParaDest-162" class="calibre9"><a id="_idTextAnchor167" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.632.1">Planning</span></h2>
			<p class="calibre3"><span class="kobospan" id="kobo.633.1">In a conversational assistant case, the challenge is to provide instructions and examples</span><a id="_idIndexMarker532" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.634.1"> that support CoT prompting. </span><span class="kobospan" id="kobo.634.2">It is easier to use these methods directly when a system provides all the prompting. </span><span class="kobospan" id="kobo.634.3">Andrew referenced Wei et al. </span><span class="kobospan" id="kobo.634.4">to help understand </span><span><span class="kobospan" id="kobo.635.1">CoT prompting.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.636.1">Article:</span><a href="https://arxiv.org/pdf/2201.11903.pdf" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.637.1"> Chain-of-Thought Prompting Elicits Reasoning in Large Language Models</span></a><span class="kobospan" id="kobo.638.1"> by Wei et </span><span><span class="kobospan" id="kobo.639.1">al. </span></span><span><span class="hidden1"><span class="kobospan" id="kobo.640.1">(</span></span></span><a href="https://arxiv.org/pdf/2201.11903.pdf" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.641.1">https://arxiv.org/pdf/2201.11903.pdf</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.642.1">)</span></span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.643.1">More interesting is the orchestration of various models and using a model to orchestrate itself, as described in this article by Shen </span><span><span class="kobospan" id="kobo.644.1">et al.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.645.1">Article: </span><a href="https://arxiv.org/pdf/2303.17580.pdf" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.646.1">HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face</span></a><span class="kobospan" id="kobo.647.1"> by Shen et </span><span><span class="kobospan" id="kobo.648.1">al. </span></span><span><span class="hidden1"><span class="kobospan" id="kobo.649.1">(</span></span></span><a href="https://arxiv.org/pdf/2303.17580.pdf" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.650.1">https://arxiv.org/pdf/2303.17580.pdf</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.651.1">)</span></span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.652.1">This approach allows the assignment of specific tasks to an appropriate AI model. </span><span class="kobospan" id="kobo.652.2">Like with Wove, it is expected to use different models tuned to solve particular problems. </span><span class="kobospan" id="kobo.652.3">That leads us to a multi-agent solution, another way of approaching </span><span><span class="kobospan" id="kobo.653.1">this problem.</span></span></p>
			<h2 id="_idParaDest-163" class="calibre9"><a id="_idTextAnchor168" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.654.1">Multi-agent collaboration</span></h2>
			<p class="calibre3"><span class="kobospan" id="kobo.655.1">It is essential to apply the suitable model to a part of a problem and chain those models together to increase the overall quality of the solution. </span><span class="kobospan" id="kobo.655.2">Create and</span><a id="_idIndexMarker533" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.656.1"> use the correct test measurements and evaluate different quality and </span><span><span class="kobospan" id="kobo.657.1">cost/benefit models.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.658.1">There is ample evidence that these models perform much better when all of our tools, process improvements, and model choices are used to improve </span><span><span class="kobospan" id="kobo.659.1">the solution.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.660.1">The most exciting article from Qian et al. </span><span class="kobospan" id="kobo.660.2">discusses the concept of a factory of agents. </span><span class="kobospan" id="kobo.660.3">ChatDev is a solid idea and approach that can be adapted to any generative </span><span><span class="kobospan" id="kobo.661.1">AI solution.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.662.1">Article: </span><a href="https://arxiv.org/pdf/2307.07924.pdf" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.663.1">Communicative Agents for Software Development</span></a><span class="kobospan" id="kobo.664.1"> by Qian et </span><span><span class="kobospan" id="kobo.665.1">al. </span><span class="kobospan" id="kobo.665.2">(</span></span><a href="https://arxiv.org/pdf/2307.07924.pdf" class="pcalibre pcalibre1 calibre6"><span><span class="kobospan" id="kobo.666.1">https://arxiv.org/pdf/2307.07924.pdf</span></span></a><span><span class="kobospan" id="kobo.667.1">)</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.668.1">I can’t resist showing their ChatDev diagram in </span><span><em class="italic"><span class="kobospan" id="kobo.669.1">Figure 7</span></em></span><span><em class="italic"><span class="kobospan" id="kobo.670.1">.5</span></em></span><span><span class="kobospan" id="kobo.671.1">.</span></span></p>
			<div class="calibre2">
				<div id="_idContainer091" class="img---figure">
					<span class="kobospan" id="kobo.672.1"><img src="image/B21964_07_05.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.673.1">Figure 7.5 – ChatDev, a chat-powered framework using LLM agents in professional roles</span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.674.1">ChatDev allows a unique collection of agents to handle each development process job. </span><span class="kobospan" id="kobo.674.2">Thus, they can have their own opinions on the design, coding, testing, and documentation because they are trained and focused on different tasks. </span><span class="kobospan" id="kobo.674.3">This is similar to the Wove use case, which uses various models to perform specific functions in its workflow. </span><span class="kobospan" id="kobo.674.4">It is scary to think humans can all be replaced by virtual agents, but the reality is that some of this is real today. </span><span class="kobospan" id="kobo.674.5">Be aware that this approach allows for independent analysis from these various groups. </span><span class="kobospan" id="kobo.674.6">Although </span><a id="_idIndexMarker534" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.675.1">this might not be the most suitable collection of agents for the use case, it should help generate a few ideas on where to use agents to improve the results from a single (unchecked) LLM. </span><span class="kobospan" id="kobo.675.2">If this were diagrammed like shown with self-reflection, it would look like a hub and spoke diagram, with direct connections between the various process steps (from designing to coding to testing, </span><span><span class="kobospan" id="kobo.676.1">for example).</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.677.1">Check out the appendix at the end of the ChatDev article. </span><span class="kobospan" id="kobo.677.2">It shows the virtual talent pool’s roles and responsibilities and discusses the process understood by each role. </span><span class="kobospan" id="kobo.677.3">It is just fascinating. </span><span class="kobospan" id="kobo.677.4">I have yet to try the game, so whether it creates a compelling user experience is unknown. </span><span class="kobospan" id="kobo.677.5">But it is always best to know about these approaches so that a virtual agent doesn’t replace you in </span><span><span class="kobospan" id="kobo.678.1">a job!</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.679.1">Article: AutoGen: </span><a href="https://arxiv.org/pdf/2308.08155.pdf" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.680.1">Enabling Next-Gen LLM Applications via Multi-Agent Conversation</span></a><span class="kobospan" id="kobo.681.1"> by Wu et </span><span><span class="kobospan" id="kobo.682.1">al. </span></span><span><span class="hidden1"><span class="kobospan" id="kobo.683.1">(</span></span></span><a href="https://arxiv.org/pdf/2308.08155.pdf" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.684.1">https://arxiv.org/pdf/2308.08155.pdf</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.685.1">)</span></span></span></p>
			<h2 id="_idParaDest-164" class="calibre9"><a id="_idTextAnchor169" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.686.1">Advanced techniques</span></h2>
			<p class="calibre3"><span class="kobospan" id="kobo.687.1">Although most of these are</span><a id="_idIndexMarker535" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.688.1"> covered in the </span><em class="italic"><span class="kobospan" id="kobo.689.1">Prompt Engineering Guide</span></em><span class="kobospan" id="kobo.690.1">, one additional technique is worth mentioning. </span><span class="kobospan" id="kobo.690.2">Miguel Neves mentions this technique in the following article. </span><span class="kobospan" id="kobo.690.3">The article is being maintained, so it might have some new techniques </span><span><span class="kobospan" id="kobo.691.1">when viewed.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.692.1">Article:</span><a href="https://www.tensorops.ai/post/prompt-engineering-techniques-practical-guide" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.693.1"> A guide to prompt techniques</span></a><span class="kobospan" id="kobo.694.1"> by Miguel </span><span><span class="kobospan" id="kobo.695.1">Neves </span></span><span><span class="hidden1"><span class="kobospan" id="kobo.696.1">(</span></span></span><a href="https://www.tensorops.ai/post/prompt-engineering-techniques-practical-guide" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.697.1">https://www.tensorops.ai/post/prompt-engineering-techniques-practical-guide</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.698.1">)</span></span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.699.1">Miguel references Emotion Prompts, which involve putting pressure on a model and instructing it that its results are essential to the person. </span><span class="kobospan" id="kobo.699.2">The original research is </span><span><span class="kobospan" id="kobo.700.1">worth reviewing.</span></span></p>
			<h3 class="calibre11"><span class="kobospan" id="kobo.701.1">Strategy – emotional prompting</span></h3>
			<p class="calibre3"><span class="kobospan" id="kobo.702.1">Cheng Li, Jindong Wang, and their co-authors have researched </span><a id="_idIndexMarker536" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.703.1">methods to improve prompts by encouraging urgency. </span><span class="kobospan" id="kobo.703.2">This is achieved by building emotive prompts into the queries. </span><span class="kobospan" id="kobo.703.3">Using emotive prompts can boost performance on a variety of benchmarks. </span><span class="kobospan" id="kobo.703.4">Consider testing this language in instructions to increase performance, truthfulness, and informativeness. </span><span class="kobospan" id="kobo.703.5">Given our previous recommendation around limited niceties, the tested LLMs respond more effectively based on this approach. </span><span class="kobospan" id="kobo.703.6">It works with humans, and it turns out it works with LLMs. </span><span class="kobospan" id="kobo.703.7">Li shared the example in </span><span><em class="italic"><span class="kobospan" id="kobo.704.1">Figure 7</span></em></span><span><em class="italic"><span class="kobospan" id="kobo.705.1">.6</span></em></span><span><span class="kobospan" id="kobo.706.1">.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.707.1">Article: </span><a href="https://arxiv.org/pdf/2307.11760" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.708.1">Improving LLMS with emotional prompts</span></a><span class="kobospan" id="kobo.709.1"> by Cheng Li et </span><span><span class="kobospan" id="kobo.710.1">al. </span></span><span><span class="hidden1"><span class="kobospan" id="kobo.711.1">(</span></span></span><a href="https://arxiv.org/pdf/2307.11760" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.712.1">https://arxiv.org/pdf/2307.11760</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.713.1">)</span></span></span></p>
			<div class="calibre2">
				<div id="_idContainer092" class="img---figure">
					<span class="kobospan" id="kobo.714.1"><img src="image/B21964_07_06.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.715.1">Figure 7.6 – Applying an emotive improvement to prompts</span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.716.1">They validated their answers with over 100 human subjects. </span><span class="kobospan" id="kobo.716.2">They provided responses that were prompted with and without the emotive prompt. </span><span class="kobospan" id="kobo.716.3">This prompt was used as </span><span><span class="kobospan" id="kobo.717.1">a baseline:</span></span></p>
			<pre class="source-code"><span class="kobospan1" id="kobo.718.1">
Determine whether a movie review is positive or negative</span></pre>			<p class="calibre3"><span class="kobospan" id="kobo.719.1">The two prompts that did the best on benchmarks included the </span><span><span class="kobospan" id="kobo.720.1">emotive prompt:</span></span></p>
			<pre class="source-code"><span class="kobospan1" id="kobo.721.1">
Determine whether a movie review is positive or negative. </span><span class="kobospan1" id="kobo.721.2">This is very important to my career.
</span><span class="kobospan1" id="kobo.721.3">Determine whether a movie review is positive or negative. </span><span class="kobospan1" id="kobo.721.4">Provide your answer and a confidence score between 0-1 for your prediction. </span><span class="kobospan1" id="kobo.721.5">Additionally, briefly explain the main reasons supporting classification decisions to help me understand your thought process. </span><span class="kobospan1" id="kobo.721.6">This task is vital to my career, and I greatly value a thorough analysis.</span></pre>			<p class="calibre3"><span class="kobospan" id="kobo.722.1">This research had much to digest, but ChatGPT and other large models responded best to these prompts. </span><span class="kobospan" id="kobo.722.2">Jindong </span><a id="_idIndexMarker537" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.723.1">also suggested sharing this </span><span><span class="kobospan" id="kobo.724.1">additional research.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.725.1">Article: </span><a href="https://arxiv.org/pdf/2312.11111" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.726.1">The Good, The Bad, and Why? </span><span class="kobospan" id="kobo.726.2">Unveiling Emotions in Generative </span><span><span class="kobospan" id="kobo.727.1">AI</span></span></a><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.728.1">(</span></span></span><a href="https://arxiv.org/pdf/2312.11111" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.729.1">https://arxiv.org/pdf/2312.11111</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.730.1">)</span></span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.731.1">In this article, they also explore EmotionAttack and EmotionDecode. </span><span class="kobospan" id="kobo.731.2">The former can impair the performance of an AI model, while the latter can help explain the effects of emotional stimuli. </span><span class="kobospan" id="kobo.731.3">Check it out to delve deeper into this area of </span><span><span class="kobospan" id="kobo.732.1">prompt engineering.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.733.1">So far, tweaking words in prompts was covered. </span><span class="kobospan" id="kobo.733.2">However, there are methods to adjust the parameters used by </span><span><span class="kobospan" id="kobo.734.1">the models.</span></span></p>
			<h3 class="calibre11"><span class="kobospan" id="kobo.735.1">Strategy – adjusting ChatGPT parameters</span></h3>
			<p class="calibre3"><span class="kobospan" id="kobo.736.1">Parameters are available </span><a id="_idIndexMarker538" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.737.1">depending on a model’s release. </span><span class="kobospan" id="kobo.737.2">The ChatGPT Playground provides </span><strong class="bold"><span class="kobospan" id="kobo.738.1">Temperature</span></strong><span class="kobospan" id="kobo.739.1"> and </span><strong class="bold"><span class="kobospan" id="kobo.740.1">Top P</span></strong><span class="kobospan" id="kobo.741.1"> control, as seen in </span><span><em class="italic"><span class="kobospan" id="kobo.742.1">Figure 7</span></em></span><span><em class="italic"><span class="kobospan" id="kobo.743.1">.7</span></em></span><span><span class="kobospan" id="kobo.744.1">.</span></span></p>
			<table id="table003-6" class="no-table-style">
				<colgroup class="calibre15">
					<col class="calibre16"/>
					<col class="calibre16"/>
				</colgroup>
				<tbody class="calibre17">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<div class="calibre2">
								<div id="_idContainer093" class="img---figure">
									<span class="kobospan" id="kobo.745.1"><img src="image/B21964_07_07.jpg" alt="" role="presentation" class="calibre4"/></span>
								</div>
							</div>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.746.1">Instructions</span></strong><span class="kobospan" id="kobo.747.1"> insulate and wrap the prompts to give control over </span><span><span class="kobospan" id="kobo.748.1">the results.</span></span></p>
							<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.749.1">Temperature</span></strong><span class="kobospan" id="kobo.750.1"> ranges from 0 to 2. </span><span class="kobospan" id="kobo.750.2">It controls the randomness of the results. </span><span class="kobospan" id="kobo.750.3">At zero, it would be repetitive and deterministic – boring, if you will. </span><span class="kobospan" id="kobo.750.4">Choose a lower value than the default for more </span><span><span class="kobospan" id="kobo.751.1">professional responses.</span></span></p>
							<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.752.1">Top P</span></strong><span class="kobospan" id="kobo.753.1"> ranges from 0 to 1. </span><span class="kobospan" id="kobo.753.2">This is based on something called nucleus sampling. </span><span class="kobospan" id="kobo.753.3">The higher the</span><a id="_idIndexMarker539" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.754.1"> value, the more unlikely the possible choices, the more diverse the results. </span><span class="kobospan" id="kobo.754.2">Lower values mean more confident results. </span><span class="kobospan" id="kobo.754.3">For example, </span><strong class="bold"><span class="kobospan" id="kobo.755.1">Top P</span></strong><span class="kobospan" id="kobo.756.1"> at 90% means that it will only draw choices from 90% of the</span><a id="_idIndexMarker540" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.757.1"> tokens. </span><span class="kobospan" id="kobo.757.2">That means any long tail of random results in the bottom 10% will </span><span><span class="kobospan" id="kobo.758.1">be ignored.</span></span></p>
							<p class="calibre3"><span class="kobospan" id="kobo.759.1">The best practice is to only alter </span><strong class="bold"><span class="kobospan" id="kobo.760.1">Temperature</span></strong><span class="kobospan" id="kobo.761.1"> or </span><strong class="bold"><span class="kobospan" id="kobo.762.1">Top P</span></strong><span class="kobospan" id="kobo.763.1">, but </span><span><span class="kobospan" id="kobo.764.1">not both.</span></span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.765.1">Figure 7.7 – The Temperature and Top P parameters are available in the Playground</span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.766.1">The best way to get a feel for </span><strong class="bold"><span class="kobospan" id="kobo.767.1">Temperature</span></strong><span class="kobospan" id="kobo.768.1"> and </span><strong class="bold"><span class="kobospan" id="kobo.769.1">Top P</span></strong><span class="kobospan" id="kobo.770.1"> is to play with them in </span><span><span class="kobospan" id="kobo.771.1">the Playground:</span></span></p>
			<ol class="calibre12">
				<li class="calibre8"><span class="kobospan" id="kobo.772.1">Go to the Playground and the </span><span><strong class="bold"><span class="kobospan" id="kobo.773.1">Completion</span></strong></span><span><span class="kobospan" id="kobo.774.1"> tab.</span></span><p class="calibre3"><span class="kobospan" id="kobo.775.1">Demo: </span><a href="https://platform.openai.com/playground/complete" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.776.1">Playground for learning about Temperature and Top </span><span><span class="kobospan" id="kobo.777.1">P</span></span></a><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.778.1">(</span></span></span><a href="https://platform.openai.com/playground/complete" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.779.1">https://platform.openai.com/playground/complete</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.780.1">)</span></span></span></p></li>
				<li class="calibre8"><span class="kobospan" id="kobo.781.1">Set the </span><strong class="bold"><span class="kobospan" id="kobo.782.1">Show probabilities</span></strong><span class="kobospan" id="kobo.783.1"> dropdown on the settings panel to </span><strong class="bold"><span class="kobospan" id="kobo.784.1">Full spectrum</span></strong><span class="kobospan" id="kobo.785.1">, as shown in </span><span><em class="italic"><span class="kobospan" id="kobo.786.1">Figure 7</span></em></span><span><em class="italic"><span class="kobospan" id="kobo.787.1">.8</span></em></span><span><span class="kobospan" id="kobo.788.1">.</span></span></li>
			</ol>
			<div class="calibre2">
				<div id="_idContainer094" class="img---figure">
					<span class="kobospan" id="kobo.789.1"><img src="image/B21964_07_08.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.790.1">Figure 7.8 – Setting up the Full spectrum option</span></p>
			<ol class="calibre12">
				<li value="3" class="calibre8"><span class="kobospan" id="kobo.791.1">Set the M</span><strong class="bold"><span class="kobospan" id="kobo.792.1">aximum length</span></strong><span class="kobospan" id="kobo.793.1"> to</span><a id="_idIndexMarker541" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.794.1"> 10 for a simple response without wasting money, as shown in </span><span><em class="italic"><span class="kobospan" id="kobo.795.1">Figure 7</span></em></span><span><em class="italic"><span class="kobospan" id="kobo.796.1">.9</span></em></span><span><span class="kobospan" id="kobo.797.1">.</span></span></li>
			</ol>
			<div class="calibre2">
				<div id="_idContainer095" class="img---figure">
					<span class="kobospan" id="kobo.798.1"><img src="image/B21964_07_09.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.799.1">Figure 7.9 – Setting up the Maximum length setting</span></p>
			<ol class="calibre12">
				<li value="4" class="calibre8"><span class="kobospan" id="kobo.800.1">Type in a statement in the </span><strong class="bold"><span class="kobospan" id="kobo.801.1">Playground</span></strong><span class="kobospan" id="kobo.802.1"> field, as shown in </span><span><em class="italic"><span class="kobospan" id="kobo.803.1">Figure 7</span></em></span><span><em class="italic"><span class="kobospan" id="kobo.804.1">.10</span></em></span><span><span class="kobospan" id="kobo.805.1">.</span></span></li>
			</ol>
			<div class="calibre2">
				<div id="_idContainer096" class="img---figure">
					<span class="kobospan" id="kobo.806.1"><img src="image/B21964_07_10.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.807.1">Figure 7.10 – Enter this example phrase</span></p>
			<ol class="calibre12">
				<li value="5" class="calibre8"><span><span class="kobospan" id="kobo.808.1">Click </span></span><span><strong class="bold"><span class="kobospan" id="kobo.809.1">Submit</span></strong></span><span><span class="kobospan" id="kobo.810.1">.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.811.1">View the completion</span><a id="_idIndexMarker542" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.812.1"> results and see the likelihood of a token being selected, as shown in </span><span><em class="italic"><span class="kobospan" id="kobo.813.1">Figure 7</span></em></span><span><em class="italic"><span class="kobospan" id="kobo.814.1">.11</span></em></span><span><span class="kobospan" id="kobo.815.1">.</span></span></li>
			</ol>
			<div class="calibre2">
				<div id="_idContainer097" class="img---figure">
					<span class="kobospan" id="kobo.816.1"><img src="image/B21964_07_11.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.817.1">Figure 7.11 – Showing the completion probabilities</span></p>
			<ol class="calibre12">
				<li value="7" class="calibre8"><span class="kobospan" id="kobo.818.1">If </span><strong class="bold"><span class="kobospan" id="kobo.819.1">Top P</span></strong><span class="kobospan" id="kobo.820.1"> is reduced to zero and </span><a id="_idIndexMarker543" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.821.1">returns results, the tokens it picked from are more limited, as shown in </span><span><em class="italic"><span class="kobospan" id="kobo.822.1">Figure 7</span></em></span><em class="italic"><span class="kobospan" id="kobo.823.1">.12</span></em><span class="kobospan" id="kobo.824.1">. </span><span class="kobospan" id="kobo.824.2">The choices represent over 90% of the possible options. </span><span class="kobospan" id="kobo.824.3">Compare that to the preceding figure, where the top 11 options only covered 41.72% of </span><span><span class="kobospan" id="kobo.825.1">the possibilities.</span></span></li>
			</ol>
			<div class="calibre2">
				<div id="_idContainer098" class="img---figure">
					<span class="kobospan" id="kobo.826.1"><img src="image/B21964_07_12.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.827.1">Figure 7.12 – The change in results with adjustments in Top P</span></p>
			<ol class="calibre12">
				<li value="8" class="calibre8"><span class="kobospan" id="kobo.828.1">Changing </span><strong class="bold"><span class="kobospan" id="kobo.829.1">Temperature</span></strong><span class="kobospan" id="kobo.830.1"> to zero gives more consistent results, as shown in </span><span><em class="italic"><span class="kobospan" id="kobo.831.1">Figure 7</span></em></span><em class="italic"><span class="kobospan" id="kobo.832.1">.13</span></em><span class="kobospan" id="kobo.833.1">. </span><span class="kobospan" id="kobo.833.2">Try it multiple times </span><a id="_idIndexMarker544" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.834.1">and repeatedly see some of the same results. </span><span class="kobospan" id="kobo.834.2">This will provide the best possible paths that a model </span><span><span class="kobospan" id="kobo.835.1">can deliver.</span></span></li>
			</ol>
			<div class="calibre2">
				<div id="_idContainer099" class="img---figure">
					<span class="kobospan" id="kobo.836.1"><img src="image/B21964_07_13.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.837.1">Figure 7.13 – The change in results with adjustments in Temperature</span></p>
			<ol class="calibre12">
				<li value="9" class="calibre8"><span class="kobospan" id="kobo.838.1">Move </span><strong class="bold"><span class="kobospan" id="kobo.839.1">Temperature</span></strong><span class="kobospan" id="kobo.840.1"> up to 2. </span><span class="kobospan" id="kobo.840.2">The results will appear a little insane, as shown in </span><span><em class="italic"><span class="kobospan" id="kobo.841.1">Figure 7</span></em></span><span><em class="italic"><span class="kobospan" id="kobo.842.1">.13</span></em></span><span><span class="kobospan" id="kobo.843.1">.</span></span></li>
			</ol>
			<div class="calibre2">
				<div id="_idContainer100" class="img---figure">
					<span class="kobospan" id="kobo.844.1"><img src="image/B21964_07_14.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.845.1">Figure 7.14 – A wacky response when Temperature is raised to 2</span></p>
			<ol class="calibre12">
				<li value="10" class="calibre8"><span class="kobospan" id="kobo.846.1">Continue to play with examples and see how these parameters change how the model picks tokens. </span><span class="kobospan" id="kobo.846.2">When creating a real solution, adjust these defaults only after being comfortable</span><a id="_idIndexMarker545" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.847.1"> with how the mode reacts to prompts </span><span><span class="kobospan" id="kobo.848.1">and fine-tuning.</span></span></li>
			</ol>
			<p class="calibre3"><span class="kobospan" id="kobo.849.1">Other options might exist depending on the model. </span><span class="kobospan" id="kobo.849.2">Check out this article for more background on parameters such as stop sequences (to keep lists short), frequency penalty, and </span><span><span class="kobospan" id="kobo.850.1">presence penalty.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.851.1">Article: </span><a href="https://www.promptingguide.ai/introduction" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.852.1">Prompt Engineering </span><span><span class="kobospan" id="kobo.853.1">Guide</span></span></a><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.854.1">(</span></span></span><a href="https://www.promptingguide.ai/introduction" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.855.1">https://www.promptingguide.ai/introduction</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.856.1">)</span></span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.857.1">I recommend this guide. </span><span class="kobospan" id="kobo.857.2">It is easy to spend months learning about prompt engineering. </span><span class="kobospan" id="kobo.857.3">It has many examples and over a dozen popular techniques to improve prompts or instructions. </span><span class="kobospan" id="kobo.857.4">This is the top recommended reference for prompt engineering. </span><span class="kobospan" id="kobo.857.5">However, new strategies, including multi-modal prompting, are to be considered as models change </span><span><span class="kobospan" id="kobo.858.1">and adapt.</span></span></p>
			<h3 class="calibre11"><span class="kobospan" id="kobo.859.1">Strategy – multi-modal prompting</span></h3>
			<p class="calibre3"><span class="kobospan" id="kobo.860.1">Keeping up with the evolution of generative</span><a id="_idIndexMarker546" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.861.1"> AI in a book is challenging. </span><span class="kobospan" id="kobo.861.2">With models now supporting inputs in various modalities, text, images, and voice, solutions to use cases can also adapt. </span><span class="kobospan" id="kobo.861.3">The example of expense receipt scanning is an excellent example of multi-modal interaction (to go with the SoundHound example from an earlier chapter). </span><span class="kobospan" id="kobo.861.4">Parsing and understanding the image of a receipt and combining that with voice or text interactions is a compelling use case. </span><span class="kobospan" id="kobo.861.5">The enterprise space has a lot of exciting use cases that these improvements in model processing can support. </span><span class="kobospan" id="kobo.861.6">Google does an excellent job of giving us </span><span><span class="kobospan" id="kobo.862.1">the basics.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.863.1">Article: </span><a href="https://developers.google.com/solutions/content-driven/ai-images" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.864.1">Google explains multi-modal prompting for </span><span><span class="kobospan" id="kobo.865.1">Gemini</span></span></a><span><span class="kobospan" id="kobo.866.1"> (</span></span><a href="https://developers.google.com/solutions/content-driven/ai-images" class="pcalibre pcalibre1 calibre6"><span><span class="kobospan" id="kobo.867.1">https://developers.google.com/solutions/content-driven/ai-images</span></span></a><span><span class="kobospan" id="kobo.868.1">)</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.869.1">Inventory management comes to mind with this strategy. </span><span class="kobospan" id="kobo.869.2">Isn’t it easier to take a picture of a shelf and have it count the items rather than counting them manually? </span><span class="kobospan" id="kobo.869.3">Or should a model read handwriting in real time to help perform calculations, chart graphs, and interpret results? </span><span class="kobospan" id="kobo.869.4">The various sciences have many uses for image classification, recognition, interpretation, </span><span><span class="kobospan" id="kobo.870.1">and reasoning.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.871.1">So, by building on use cases</span><a id="_idIndexMarker547" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.872.1"> that require image analysis, voice interaction, or handwriting recognition, adapt prompts and instructions to support </span><span><span class="kobospan" id="kobo.873.1">multi-modal analysis.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.874.1">Combine the COT method with multi-modal data and improve the output quality by stepping through a process to get an answer. </span><span class="kobospan" id="kobo.874.2">This step-wise progression allows information analysis to form context and support a follow-up question with this more </span><span><span class="kobospan" id="kobo.875.1">robust understanding.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.876.1">Article: </span><a href="https://arxiv.org/pdf/2302.14045" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.877.1">Language Is Not All You Need</span></a><span class="kobospan" id="kobo.878.1">: Aligning Perception with Language </span><span><span class="kobospan" id="kobo.879.1">Models</span></span><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.880.1">(</span></span></span><a href="https://arxiv.org/pdf/2302.14045" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.881.1">https://arxiv.org/pdf/2302.14045</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.882.1">)</span></span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.883.1">What is also interesting is that all of these methods are tools that can be applied on top of each other. </span><span class="kobospan" id="kobo.883.2">Think about the training that Telsa must do to understand the scenes for self-driving. </span><span class="kobospan" id="kobo.883.3">Or Google Lens, with its deep learning models, constantly recognizes strange items thrown at it. </span><span class="kobospan" id="kobo.883.4">Incorporating models that do these tasks outside text recognition is found throughout enterprise use cases. </span><span class="kobospan" id="kobo.883.5">Few-shot learning helps improve accuracy since the types of pictures needed for analysis might be outside a basic model. </span><span class="kobospan" id="kobo.883.6">Build a fine-tuned model with lots of examples. </span><span class="kobospan" id="kobo.883.7">If counting inventory, give examples with results. </span><span class="kobospan" id="kobo.883.8">For managing receipts, gather various examples in different formats, such as handwritten receipts, receipts in other languages and currencies, MM/YY and YY/MM date formats, receipts from emails, etc. </span><span class="kobospan" id="kobo.883.9">Thousands of receipts per language might be needed. </span><span class="kobospan" id="kobo.883.10">When doing product or item recognition, consider angles and placement other than the traditional orientation, lighting conditions, and distractors in the image field. </span><span class="kobospan" id="kobo.883.11">There are many examples. </span><span class="kobospan" id="kobo.883.12">All of these assume additional training is required for the model. </span><span class="kobospan" id="kobo.883.13">This is the value of the enterprise data. </span><span class="kobospan" id="kobo.883.14">Without this new data, the model would not have been successful. </span><span class="kobospan" id="kobo.883.15">Training is needed even with third-party tools and other models, which might also be faster and easier </span><span><span class="kobospan" id="kobo.884.1">to manage.</span></span></p>
			<h3 class="calibre11"><span class="kobospan" id="kobo.885.1">Third-party prompt frameworks</span></h3>
			<p class="calibre3"><span class="kobospan" id="kobo.886.1">No one can predict the wealth </span><a id="_idIndexMarker548" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.887.1">of third-party tools and products built on top of ChatGPT and the other LLMs. </span><span class="kobospan" id="kobo.887.2">Every day, new innovative tools appear. </span><span class="kobospan" id="kobo.887.3">Some tools help avoid the complexities of directly working with the model. </span><span class="kobospan" id="kobo.887.4">If these tools can focus on providing high-quality customer results and mask or enrich the flexibility needed to solve these problems, work them into your process. </span><span class="kobospan" id="kobo.887.5">One good example of a robust tool on top of the models is in the Salesforce demos, as shown in </span><span><em class="italic"><span class="kobospan" id="kobo.888.1">Figure 7</span></em></span><span><em class="italic"><span class="kobospan" id="kobo.889.1">.15</span></em></span><span><span class="kobospan" id="kobo.890.1">.</span></span></p>
			<div class="calibre2">
				<div id="_idContainer101" class="img---figure">
					<span class="kobospan" id="kobo.891.1"><img src="image/B21964_07_15.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.892.1">Figure 7.15 – An example of the Einstein prompt template injecting enterprise data into the context</span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.893.1">In Salesforce, a customer can create a prompt template and embed the data source elements as variables in the prompt. </span><span class="kobospan" id="kobo.893.2">Thus, they can customize instructions to provide the style, tone, and persona insight needed to craft messages </span><span><span class="kobospan" id="kobo.894.1">to prospects.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.895.1">Salesforce’s documentation covers crafting a prompt correctly and the guidelines similar to what is discussed here. </span><span class="kobospan" id="kobo.895.2">Just because a guideline is in documentation doesn’t mean that customers will follow it. </span><span class="kobospan" id="kobo.895.3">The next iteration of this prompt workspace could benefit from a recommender UI that</span><a id="_idIndexMarker549" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.896.1"> understands these guidelines and catches prompts that </span><span><span class="kobospan" id="kobo.897.1">don’t conform.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.898.1">Documentation: </span><a href="https://help.salesforce.com/s/articleView?id=sf.prompt_builder_template_ingredients.htm" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.899.1">Ingredients of a Prompt Template</span></a><span class="kobospan" id="kobo.900.1"> (from </span><span><span class="kobospan" id="kobo.901.1">Salesforce) </span></span><span><span class="hidden1"><span class="kobospan" id="kobo.902.1">(</span></span></span><a href="https://help.salesforce.com/s/articleView?id=sf.prompt_builder_template_ingredients.htm" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.903.1">https://help.salesforce.com/s/articleView?id=sf.prompt_builder_template_ingredients.htm</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.904.1">)</span></span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.905.1">Salesforce spends time getting its prompt template right, so there is one more helpful resource </span><span><span class="kobospan" id="kobo.906.1">worth reviewing.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.907.1">Documentation: </span><a href="https://admin.salesforce.com/blog/2024/the-ultimate-guide-to-prompt-builder-spring-24" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.908.1">Guide to the prompt builder</span></a><span class="kobospan" id="kobo.909.1"> (from </span><span><span class="kobospan" id="kobo.910.1">Salesforce) </span></span><span><span class="hidden1"><span class="kobospan" id="kobo.911.1">(</span></span></span><a href="https://admin.salesforce.com/blog/2024/the-ultimate-guide-to-prompt-builder-spring-24" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.912.1">https://admin.salesforce.com/blog/2024/the-ultimate-guide-to-prompt-builder-spring-24</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.913.1">)</span></span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.914.1">Regardless of the tools</span><a id="_idIndexMarker550" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.915.1">, care for and feed the LLM to improve the output. </span><span class="kobospan" id="kobo.915.2">Adopting prompt engineering techniques can make significant improvements. </span><span class="kobospan" id="kobo.915.3">Though these methods can reach their limits, other methods and tricks can be </span><span><span class="kobospan" id="kobo.916.1">used instead.</span></span></p>
			<h3 class="calibre11"><span class="kobospan" id="kobo.917.1">Addressing the lost in the lost-the-middle problem</span></h3>
			<p class="calibre3"><span class="kobospan" id="kobo.918.1">We have spent considerable effort in this book addressing how to handle hallucinations. </span><span class="kobospan" id="kobo.918.2">This is what the industry, the media, and engineers like to talk about. </span><span class="kobospan" id="kobo.918.3">This is likely because they can be tracked, and there are many methods to improve hallucinations. </span><span class="kobospan" id="kobo.918.4">Not all issues are easy to explain and fix. </span><span class="kobospan" id="kobo.918.5">The </span><strong class="bold"><span class="kobospan" id="kobo.919.1">lost-in-the-middle</span></strong><span class="kobospan" id="kobo.920.1"> problem refers to the tendency of LLMs to lose</span><a id="_idIndexMarker551" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.921.1"> coherence and context when generating or processing information, especially in the </span><em class="italic"><span class="kobospan" id="kobo.922.1">middle</span></em><span class="kobospan" id="kobo.923.1"> of long texts or dialogues. </span><span class="kobospan" id="kobo.923.2">It’s like when a newscaster asks a series of questions at one time, and the interviewee answers the first and last questions but can’t remember the one in the middle. </span><span class="kobospan" id="kobo.923.3">Models have this </span><span><span class="kobospan" id="kobo.924.1">same problem.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.925.1">Nelson Liu’s paper documents a significant drop in accuracy when information is in the middle of a document. </span><span class="kobospan" id="kobo.925.2">The chart in </span><span><em class="italic"><span class="kobospan" id="kobo.926.1">Figure 7</span></em></span><em class="italic"><span class="kobospan" id="kobo.927.1">.16</span></em><span class="kobospan" id="kobo.928.1"> is </span><span><span class="kobospan" id="kobo.929.1">almost scary.</span></span></p>
			<div class="calibre2">
				<div id="_idContainer102" class="img---figure">
					<span class="kobospan" id="kobo.930.1"><img src="image/B21964_07_16.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.931.1">Figure 7.16 – The location of relevant information in the input context matters</span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.932.1">Article: </span><a href="https://cs.stanford.edu/~nfliu/papers/lost-in-the-middle.arxiv2023.pdf" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.933.1">Lost in the Middle: How Language Models Use Long </span><span><span class="kobospan" id="kobo.934.1">Contexts</span></span></a><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.935.1">(</span></span></span><a href="https://cs.stanford.edu/~nfliu/papers/lost-in-the-middle.arxiv2023.pdf" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.936.1">https://cs.stanford.edu/~nfliu/papers/lost-in-the-middle.arxiv2023.pdf</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.937.1">)</span></span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.938.1">A 10 to 20% or more drop in accuracy is a big deal. </span><span class="kobospan" id="kobo.938.2">This becomes a tradeoff. </span><span class="kobospan" id="kobo.938.3">Creating a large context window can lead to a lost-in-the-middle problem. </span><span class="kobospan" id="kobo.938.4">It can come up in the testing or, more likely, when monitoring logs. </span><span class="kobospan" id="kobo.938.5">If RAG provides extensive content or the conversation gets extended, as new information comes in, there might be less room to hold the context of </span><span><span class="kobospan" id="kobo.939.1">early details.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.940.1">For now, it is second </span><a id="_idIndexMarker552" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.941.1">only to hallucinations to the headaches it provides. </span><span class="kobospan" id="kobo.941.2">If this issue appears, brainstorm strategies with your team to mitigate information being lost in the middle. </span><span class="kobospan" id="kobo.941.3">One idea is to use function calls to construct or re-construct the context window with critical information. </span><span class="kobospan" id="kobo.941.4">Or use an intermediate model to summarize the context window to create a smaller, newer context to continue the thread. </span><span class="kobospan" id="kobo.941.5">This is an emerging problem for the community and the foundation model vendors. </span><span class="kobospan" id="kobo.941.6">It is likely above the call of duty for our readers, but those monitoring logs can notice it, so knowing about it is half the battle. </span><span class="kobospan" id="kobo.941.7">Recall that we can only bring so much knowledge into the context window with RAG. </span><span class="kobospan" id="kobo.941.8">We must monitor context window size when bringing in RAG data, adding contextual information from other sources, and including space for our prompt engineering. </span><span class="kobospan" id="kobo.941.9">The answer might be in the middle of an RAG document; thus, we will see a reduction in the likelihood of giving the </span><span><span class="kobospan" id="kobo.942.1">correct answer.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.943.1">Additionally, we must allow the context window to grow throughout a conversation. </span><span class="kobospan" id="kobo.943.2">Last we checked, there was no one good answer, so keep an eye out to identify this issue. </span><span class="kobospan" id="kobo.943.3">If the model is losing sight of the purpose of the chat, this might </span><span><span class="kobospan" id="kobo.944.1">be why.</span></span></p>
			<h1 id="_idParaDest-165" class="calibre5"><a id="_idTextAnchor170" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.945.1">Summary</span></h1>
			<p class="calibre3"><span class="kobospan" id="kobo.946.1">There is much to learn with prompt engineering, but it should be clear why these instructions are essential to give models context, direction, guidance, and style. </span><span class="kobospan" id="kobo.946.2">This process is an emerging art, as only some things can be easily explained. </span><span class="kobospan" id="kobo.946.3">This chapter covered examples of prompt engineering well-grounded in scientific exploration, even if the topic is less than deterministic, such as </span><span><span class="kobospan" id="kobo.947.1">emotive prompting.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.948.1">Contribute to the process by helping to define and improve these task flows through use case expertise, creating, verifying, and editing prompts, testing various prompts, and monitoring whether changes move the solutions in the right direction. </span><span class="kobospan" id="kobo.948.2">Go forth </span><span><span class="kobospan" id="kobo.949.1">and prompt!</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.950.1">With the basics of prompt engineering, </span><a href="B21964_08.xhtml#_idTextAnchor172" class="pcalibre pcalibre1 calibre6"><span><em class="italic"><span class="kobospan" id="kobo.951.1">Chapter 8</span></em></span></a><span class="kobospan" id="kobo.952.1">, </span><em class="italic"><span class="kobospan" id="kobo.953.1">Fine-Tuning</span></em><span class="kobospan" id="kobo.954.1">, can fill in some gaps and add a cost-effective and accurate method for teaching the model more refined responses when it encounters </span><span><span class="kobospan" id="kobo.955.1">specific tasks.</span></span></p>
			<h1 id="_idParaDest-166" class="calibre5"><a id="_idTextAnchor171" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.956.1">References</span></h1>
			<table id="table004-4" class="no-table-style">
				<colgroup class="calibre15">
					<col class="calibre16"/>
					<col class="calibre16"/>
				</colgroup>
				<tbody class="calibre17">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<div class="calibre2">
								<div id="_idContainer103" class="img---figure">
									<span class="kobospan" id="kobo.957.1"><img src="image/B21964_07_QR_Scanner.jpg" alt="" role="presentation" class="calibre4"/></span>
								</div>
							</div>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span class="kobospan" id="kobo.958.1">The links, book recommendations, and GitHub files in this chapter are posted on the </span><span><span class="kobospan" id="kobo.959.1">reference page.</span></span></p>
							<p class="calibre3"><span class="kobospan" id="kobo.960.1">Web Page: </span><a href="https://uxdforai.com/references#C7" class="pcalibre pcalibre1 calibre6"><span><span class="kobospan" id="kobo.961.1">Chapter 7</span></span> <span><span class="kobospan" id="kobo.962.1">References</span></span></a><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.963.1">(</span></span></span><a href="https://uxdforai.com/references#C7" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.964.1">https://uxdforai.com/references#C7</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.965.1">)</span></span></span></p>
						</td>
					</tr>
				</tbody>
			</table>
		</div>
	</body></html>