- en: '4'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '4'
- en: Building Your Neo4j Graph with Movies Dataset
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用电影数据集构建您的Neo4j图
- en: In the previous chapters, we learned how knowledge graphs have emerged as a
    transformative tool, offering a structured way to connect diverse data points,
    enabling smarter search, recommendations, and inference capabilities across a
    wide range of domains.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们学习了知识图谱如何成为一项变革性工具，它提供了一种结构化的方式来连接不同的数据点，使各种领域中的智能搜索、推荐和推理能力成为可能。
- en: Knowledge graphs excel at capturing complex relationships between entities,
    making them indispensable for applications that require deep contextual understanding.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 知识图谱擅长捕捉实体之间的复杂关系，对于需要深度上下文理解的应用程序来说，它们是不可或缺的。
- en: Neo4j, with its state-of-the-art graph database technology, stands out as a
    leading platform for building and managing knowledge graphs. As we saw in the
    previous chapter, unlike traditional relational databases, Neo4j is designed to
    handle highly connected data with ease, allowing for more intuitive querying and
    faster retrieval of insights. This makes it an ideal choice for developers and
    data scientists looking to transform raw, unstructured data into meaningful insights
    that can drive AI-powered applications.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 基于其最先进的图数据库技术，Neo4j在构建和管理知识图谱方面脱颖而出，成为领先的平台。正如我们在上一章中看到的，与传统的关系数据库不同，Neo4j被设计用来轻松处理高度连接的数据，这使得查询更加直观，并能够更快地检索洞察。这使得它成为希望将原始的非结构化数据转化为有意义洞察的开发人员和数据科学家的理想选择。
- en: 'In this chapter, we are going to cover the following main topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要主题：
- en: Design considerations for a Neo4j graph for an efficient search
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为高效搜索设计的Neo4j图设计考虑
- en: Utilizing a movies dataset
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用电影数据集
- en: Building your movie knowledge graph with code examples
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用代码示例构建您的电影知识图谱
- en: 'Beyond the basics: advanced Cypher techniques for complex graph structures'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 超越基础：用于复杂图结构的先进Cypher技术
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'To successfully work through the exercises in this chapter, you will need the
    following tools:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 要成功完成本章的练习，您需要以下工具：
- en: '**Neo4j AuraDB**: You can use Neo4j AuraDB, the cloud version of Neo4j, available
    at [https://neo4j.com/aura](https://neo4j.com/aura).'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Neo4j AuraDB**：您可以使用Neo4j AuraDB，这是Neo4j的云版本，可在[https://neo4j.com/aura](https://neo4j.com/aura)找到。'
- en: '**Cypher query language**: Familiarity with the Cypher query language is essential,
    as we will be using Cypher extensively to create and query the graph. You can
    find out more about Cypher syntax in the Cypher query language documentation:
    [https://neo4j.com/docs/cypher/](https://neo4j.com/docs/cypher/).'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Cypher查询语言**：熟悉Cypher查询语言是必要的，因为我们将广泛使用Cypher来创建和查询图。您可以在Cypher查询语言文档中找到有关Cypher语法的更多信息：[https://neo4j.com/docs/cypher/](https://neo4j.com/docs/cypher/)。'
- en: '**Python**: You will need Python 3.x installed on your system. Python is used
    for scripting and interacting with the Neo4j database. You can download Python
    from the official Python website: [https://www.python.org/downloads/](https://www.python.org/downloads/).'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Python**：您需要在系统上安装Python 3.x。Python用于脚本编写和与Neo4j数据库交互。您可以从官方Python网站下载Python：[https://www.python.org/downloads/](https://www.python.org/downloads/)。'
- en: '**Python libraries**:'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Python库**：'
- en: '**Neo4j Driver for Python**: Install the Neo4j Python driver to connect to
    the Neo4j database using Python. You can install it via `pip`:'
  id: totrans-16
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Python的Neo4j驱动程序**：使用Python连接到Neo4j数据库，请安装Neo4j Python驱动程序。您可以通过`pip`安装它：'
- en: '[PRE0]'
  id: totrans-17
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '**pandas**: This library will be used for data manipulation and analysis. Install
    it via `pip`:'
  id: totrans-18
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**pandas**：此库将用于数据处理和分析。您可以通过`pip`安装它：'
- en: '[PRE1]'
  id: totrans-19
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '**Integrated Development Environment (IDE)**: An IDE such as PyCharm, VS Code,
    or Jupyter Notebook is recommended for writing and managing your Python code efficiently.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**集成开发环境（IDE）**：推荐使用PyCharm、VS Code或Jupyter Notebook等IDE来高效地编写和管理您的Python代码。'
- en: '**Git and GitHub**: Basic knowledge of Git is required for version control.
    You will also need a GitHub account to access the code repository for this chapter.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Git和GitHub**：需要基本的Git知识来进行版本控制。您还需要一个GitHub账户来访问本章的代码仓库。'
- en: '**Movies dataset**: **The Movie Database** (**TMDb**) is required, available
    on Kaggle: [https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset/](https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset/).'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**电影数据集**：**The Movie Database**（**TMDb**）是必需的，可在Kaggle上找到：[https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset/](https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset/)。'
- en: 'This dataset is a derivative of the **Movie Lens Datasets** (F. Maxwell Harper
    and Joseph A. Konstan. 2015\. The MovieLens Datasets: History and Context. ACM
    Transactions on Interactive Intelligent Systems (TiiS) 5, 4: 19:1–19:19.[https://doi.org/10.1145/2827872](https://doi.org/10.1145/2827872)).'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '此数据集是**Movie Lens Datasets**（F. Maxwell Harper 和 Joseph A. Konstan. 2015. The
    MovieLens Datasets: History and Context. ACM Transactions on Interactive Intelligent
    Systems (TiiS) 5, 4: 19:1–19:19. [https://doi.org/10.1145/2827872](https://doi.org/10.1145/2827872)）的衍生品。'
- en: Some of the data files, such as `credits.csv` and `ratings.csv`, may not be
    available on GitHub due to storage constraints. However, you can access all the
    raw data files from a GCS bucket.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于存储限制，某些数据文件，如`credits.csv`和`ratings.csv`，可能不在GitHub上可用。但是，您可以从GCS存储桶中访问所有原始数据文件。
- en: 'All the code for this chapter is available in the following GitHub repository:
    [https://github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/tree/main/ch4](https://github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/tree/main/ch4).'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的所有代码均可在以下GitHub仓库中找到：[https://github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/tree/main/ch4](https://github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/tree/main/ch4)。
- en: The folder includes all the necessary files and scripts to help you build your
    Neo4j graph using the movies dataset and Cypher code.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 该文件夹包含所有必要的文件和脚本，以帮助您使用电影数据集和Cypher代码构建Neo4j图。
- en: Make sure to clone or download the repository to follow along with the code
    examples provided in this chapter.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 确保克隆或下载该仓库，以跟随本章提供的代码示例。
- en: The GitHub repository contains the path to GCS to access the raw data files.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: GitHub仓库包含访问原始数据文件的GCS路径。
- en: Design considerations for a Neo4j graph for an efficient search
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为高效搜索设计的Neo4j图设计考虑
- en: A well-designed Neo4j graph ensures that your search functionality is not only
    accurate but also efficient, enabling the quick retrieval of relevant information.
    The way data is organized in a graph directly impacts the performance and relevance
    of search results, making it crucial to understand the principles of effective
    graph modeling.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 一个设计良好的Neo4j图确保您的搜索功能不仅准确，而且高效，能够快速检索相关信息。数据在图中的组织方式直接影响搜索结果的表现力和相关性，因此理解有效图建模的原则至关重要。
- en: This section will delve into the importance of structuring your Neo4j graph
    correctly, how it influences the search process, and the key considerations you
    need to keep in mind while designing your graph model.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将深入探讨正确结构化您的Neo4j图的重要性，它如何影响搜索过程，以及在设计图模型时您需要牢记的关键考虑因素。
- en: Considerations while defining node and relationship types
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义节点和关系类型时的注意事项
- en: Recall from [*Chapter 3*](Preface.xhtml#_idTextAnchor012) that the foundation
    of any Neo4j graph is built upon **nodes** and **relationships**. Nodes represent
    entities, such as movies or people (e.g., actors or directors), while relationships
    define how these entities are connected. The types of nodes and relationships
    you choose play a crucial role in determining the effectiveness of your search
    queries.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下[第3章](Preface.xhtml#_idTextAnchor012)，任何Neo4j图的基础都是建立在**节点**和**关系**之上的。节点代表实体，如电影或人物（例如，演员或导演），而关系定义了这些实体如何连接。您选择的节点和关系类型在确定搜索查询的有效性方面起着至关重要的作用。
- en: In a movies dataset, nodes could traditionally represent distinct entities such
    as `Movies`, `Actors`, `Directors`, and `Genres`. Relationships would then define
    how these nodes interact, such as `ACTED_IN`, `DIRECTED`, or `BELONGS_TO`. However,
    there is an alternative and often more efficient approach—consolidating similar
    entities under a single node type.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在电影数据集中，节点可以传统地表示不同的实体，如`Movies`、`Actors`、`Directors`和`Genres`。关系随后定义这些节点如何交互，如`ACTED_IN`、`DIRECTED`或`BELONGS_TO`。然而，有一种替代方法，通常更有效——将相似实体合并为单个节点类型。
- en: Instead of creating separate nodes for `Actors` and `Directors`, you can create
    a single `Person` node. The characteristic of each `Person` node—whether they
    are an actor, a director, or both—is then defined by the type of relationship
    it has with the `Movie` node. For example, a `Person` node connected to a `Movie`
    node by an `ACTED_IN` relationship signifies that the person is an actor in that
    movie. Similarly, a `DIRECTED` relationship indicates that the person directed
    the movie. We will be creating the complete graph in upcoming sections.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 你不需要为`Actors`和`Directors`创建单独的节点，你可以创建一个单一的`Person`节点。每个`Person`节点的特征——无论是演员、导演还是两者都是——由它与`Movie`节点的关系类型定义。例如，通过`ACTED_IN`关系连接到`Movie`节点的`Person`节点表示该人是该电影中的演员。同样，`DIRECTED`关系表示该人执导了该电影。我们将在接下来的章节中创建完整的图。
- en: 'But first, let’s talk about why this approach is better. As we demonstrated
    in [*Chapter 3*](Preface.xhtml#_idTextAnchor012), this approach results in the
    following:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 但首先，让我们谈谈为什么这种方法更好。正如我们在[*第三章*](Preface.xhtml#_idTextAnchor012)中展示的那样，这种方法导致以下结果：
- en: '**Simplified data model**: By using a single `Person` node to represent both
    actors and directors, your data model becomes more streamlined. This reduces the
    complexity of the graph and makes it easier to understand and manage.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**简化的数据模型**: 通过使用单个`Person`节点来表示演员和导演，你的数据模型变得更加精简。这降低了图的复杂性，使其更容易理解和维护。'
- en: '**Enhanced query performance**: With fewer node types, the graph database can
    more efficiently traverse relationships during queries. This is because the database
    engine has fewer distinct entities to differentiate between, leading to faster
    query execution times.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**增强查询性能**: 由于节点类型较少，图数据库在查询期间可以更有效地遍历关系。这是因为数据库引擎有更少的独特实体需要区分，从而缩短查询执行时间。'
- en: '**Reduced redundancy**: A unified `Person` node eliminates the need to duplicate
    information. In cases where a person is both an actor and a director, you avoid
    creating two separate nodes with overlapping data, thus minimizing redundancy,
    and saving storage space.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**减少冗余**: 通过统一的`Person`节点，消除了信息重复的需求。在一个人既是演员又是导演的情况下，你可以避免创建两个具有重叠数据的独立节点，从而最小化冗余，节省存储空间。'
- en: '**Flexible relationship definitions**: This approach allows for more flexible
    and granular relationship definitions. If a person has multiple roles in different
    movies (e.g., acting in one and directing another), the relationships can clearly
    distinguish these roles without needing to create multiple nodes.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**灵活的关系定义**: 这种方法允许更灵活和细粒度的关系定义。如果一个人在多部电影中扮演多个角色（例如，在一部电影中担任演员，在另一部电影中担任导演），关系可以清楚地区分这些角色，而无需创建多个节点。'
- en: '**Easier maintenance and scalability**: As your dataset grows, maintaining
    a simpler node structure becomes increasingly important. Adding new roles or relationships
    becomes more straightforward when you are working with a unified node type.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**易于维护和扩展**: 随着你的数据集增长，维护更简单的节点结构变得越来越重要。当你使用统一的节点类型工作时，添加新的角色或关系变得更加直接。'
- en: By carefully selecting and defining these types and relationships, you create
    a graph structure that mirrors real-world connections. This makes your search
    queries more intuitive, the results more meaningful, and the overall system more
    efficient.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 通过仔细选择和定义这些类型和关系，你创建了一个反映现实世界联系的图结构。这使得你的搜索查询更加直观，结果更有意义，整个系统更加高效。
- en: Applying indexing and constraints on search performance
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 应用索引和约束对搜索性能的影响
- en: As your Neo4j graph grows, the importance of **indexing** and applying **constraints**
    becomes paramount. **Indexes** allow Neo4j to quickly locate the starting points
    for queries, drastically improving search performance, especially in large datasets.
    Constraints, however, ensure data integrity by preventing the creation of duplicate
    nodes or invalid relationships.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 随着你的Neo4j图数据库增长，**索引**和**约束**的应用变得至关重要。**索引**允许Neo4j快速定位查询的起点，极大地提高了搜索性能，尤其是在大型数据集中。然而，约束通过防止创建重复节点或无效关系来确保数据完整性。
- en: In the context of our movies dataset, where we use a unified `Person` node for
    both actors and directors, indexing becomes even more crucial. You might **index**
    nodes based on properties such as `person_name` or `role`, ensuring that searches
    for specific people or their roles in movies return results swiftly. For example,
    you could index the role property on the relationships (e.g., `ACTED_IN` or `DIRECTED`)
    to quickly filter people by their involvement in a particular movie.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的电影数据集的背景下，我们使用一个统一的`Person`节点来表示演员和导演，索引变得尤为重要。你可以根据诸如`person_name`或`role`等属性来**索引**节点，确保对特定人物或他们在电影中的角色的搜索能够迅速返回结果。例如，你可以对关系（例如，`ACTED_IN`或`DIRECTED`）上的角色属性进行索引，以便快速过滤参与特定电影的人物。
- en: Constraints are also essential to maintaining the integrity of your graph. Let’s
    look at some of these constraints. The constraints should be carefully designed
    based on the nature of your dataset and application requirements—they are not
    a one-size-fits-all solution.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 约束对于维护图形的完整性也是必不可少的。让我们看看这些约束中的一些。这些约束应根据数据集的性质和应用需求仔细设计——它们不是一刀切解决方案。
- en: 'The following are some example statements that demonstrate how to create constraints
    and indexes tailored for a movie dataset. These examples include common scenarios
    such as ensuring the uniqueness of person identifiers and optimizing search performance
    across node and relationship properties. Depending on your specific use case and
    data quality, you can adapt these patterns to enforce data integrity and improve
    query speed:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些示例语句，展示了如何为电影数据集创建定制的约束和索引。这些示例包括确保人员标识符的唯一性和优化节点和关系属性上的搜索性能的常见场景。根据你的具体用例和数据质量，你可以调整这些模式以强制执行数据完整性和提高查询速度：
- en: 'Unique constraint on `person_name` (for a simplified use case). In many cases—such
    as our movie dataset, where we assume each person has a unique name—you might
    enforce a unique constraint on the `person_name` property to ensure that each
    individual is represented by a single node, even if they take on multiple roles
    (e.g., actor and director) across different movies. Here is how you can do this:'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对`person_name`的唯一约束（对于简化用例）。在许多情况下——例如我们的电影数据集，我们假设每个人都有一个独特的名字——你可能会对`person_name`属性施加唯一约束，以确保即使他们在不同的电影中扮演多个角色（例如，演员和导演），每个个体也只由一个节点表示。以下是你可以这样做的示例：
- en: '[PRE2]'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This helps prevent the accidental creation of duplicate nodes and keeps your
    graph clean and efficient.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这有助于防止意外创建重复节点，并保持你的图形干净高效。
- en: Unique constraint on a more reliable ID (e.g., `person_id`). The uniqueness
    constraint in the previous scenarios is based on assumptions about your data.
    In real-world scenarios, it is common to encounter different individuals with
    the same name.
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对更可靠的ID（例如，`person_id`）的唯一约束。在前面的场景中，唯一约束是基于对数据的假设。在现实世界的场景中，遇到具有相同名字的不同个体是很常见的。
- en: 'In such cases, you should use a more reliable identifier, such as a `person_id`
    value from an external source (e.g., **Internet Movie Database** (**IMDb**) or
    **TMDb**) to enforce uniqueness. The following Cypher code shows how to achieve
    this:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，你应该使用更可靠的标识符，例如来自外部源（例如，**互联网电影数据库**（**IMDb**）或**TMDb**）的`person_id`值，以确保唯一性。以下Cypher代码展示了如何实现这一点：
- en: '[PRE3]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Index on `person_name` (for faster lookup if uniqueness is not enforced). If
    you’re not enforcing uniqueness but still frequently search for people by name,
    an index on the `person_name` property can significantly improve query performance.
    This allows Neo4j to quickly locate `Person` nodes based on their names:'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在`person_name`上建立索引（如果未强制执行唯一性，则用于更快地查找）。如果你没有强制执行唯一性，但仍然经常按名称搜索人物，对`person_name`属性建立索引可以显著提高查询性能。这允许Neo4j根据其名称快速定位`Person`节点：
- en: '[PRE4]'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Index on the `title` property of `Movie`. Movies are often queried by title—especially
    in recommendation systems or search functionalities. Indexing the `title` property
    ensures quick lookups when users search for specific movies:'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在`Movie`的`title`属性上建立索引。电影通常按标题查询——特别是在推荐系统或搜索功能中。对`title`属性建立索引确保当用户搜索特定电影时能够快速查找：
- en: '[PRE5]'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Index on the `role` property in the `ACTED_IN` relationship. If your application
    requires filtering actors by their specific roles in movies (e.g., lead or cameo),
    indexing the `role` property on the `ACTED_IN` relationship helps speed up those
    queries by avoiding full scans of all relationships:'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在`ACTED_IN`关系中的`role`属性上建立索引。如果你的应用程序需要通过电影中演员的具体角色进行过滤（例如，主角或客串），在`ACTED_IN`关系上对`role`属性建立索引可以帮助加快这些查询，避免对所有关系进行全扫描：
- en: '[PRE6]'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '**Note**'
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**注意**'
- en: Neo4j only supports relationship property indexes in version `5.x` and above.
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Neo4j仅支持版本`5.x`及以上版本的关系属性索引。
- en: Properly implemented indexing and constraints make your graph more resilient
    and your search processes faster and more reliable. This not only enhances the
    user experience but also reduces the computational load on your system, allowing
    for more scalable solutions.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 正确实现的索引和约束使你的图更加健壮，搜索过程更快、更可靠。这不仅提升了用户体验，还减少了系统上的计算负载，允许实现更可扩展的解决方案。
- en: In the next section, we will explore how to harness the power of open data by
    utilizing a movies dataset to build your graph.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将探讨如何通过利用电影数据集来构建你的图来发挥开放数据的力量。
- en: Utilizing a movies dataset
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 利用电影数据集
- en: 'In this section, we will focus on utilizing **TMDb**, a comprehensive collection
    of metadata made available on Kaggle: [https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset/](https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset/).
    This dataset includes a wide range of information about movies, such as titles,
    genres, cast, crew, release dates, and ratings. With over 45,000 movies and detailed
    information about the people involved in their creation, this dataset provides
    a robust foundation for building a Neo4j graph that captures the complex relationships
    within the film industry.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将专注于利用**TMDb**，这是一个在Kaggle上提供的综合元数据集合：[https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset/](https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset/)。这个数据集包含了关于电影的各种信息，如标题、类型、演员阵容、制作团队、上映日期和评分。这个数据集包含超过45,000部电影及其制作人员的详细信息，为构建一个能够捕捉电影行业复杂关系的Neo4j图提供了一个坚实的基础。
- en: You will use this dataset to model the data as a knowledge graph, learning about
    data integration in a practical context. You will learn how to source, prepare,
    and import this data into Neo4j.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 你将使用这个数据集来将数据建模为知识图谱，在一个实际的应用场景中学习数据集成。你将学习如何获取、准备并将这些数据导入Neo4j。
- en: When working with large datasets such as TMDb, it is crucial to ensure that
    the data is clean, consistent, and properly structured before integrating it into
    your Neo4j graph. Raw data, while rich in information, often contains inconsistencies,
    redundancies, and complex structures that can hinder the performance and accuracy
    of your knowledge graph. This is where data normalization and cleaning come into
    play.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 当处理像TMDb这样的大型数据集时，在将其集成到你的Neo4j图之前确保数据是清洁的、一致的并且结构良好至关重要。原始数据虽然信息丰富，但往往包含不一致性、冗余和复杂的结构，这些可能会阻碍知识图谱的性能和准确性。这就是数据规范化和清理发挥作用的地方。
- en: Why normalize and clean data?
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么需要规范化和清理数据？
- en: 'Maintaining a clean and normalized dataset is crucial when building a Neo4j
    graph, as it directly impacts the quality and performance of your application.
    By normalizing and cleaning your data, you ensure consistency, improve efficiency,
    and create a scalable foundation for analysis. Here is why each of these steps
    matters:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建Neo4j图时，保持数据集的清洁和规范化至关重要，因为它直接影响到应用程序的质量和性能。通过规范化和清理数据，你确保了数据的一致性，提高了效率，并为分析创建了一个可扩展的基础。以下是为什么每个步骤都很重要的原因：
- en: '**Consistency**: Raw data can come with variations in how similar information
    is recorded. For example, movie genres might be listed in different formats or
    contain duplicates. Normalizing data ensures that similar data points are recorded
    in a consistent format, making it easier to query and analyze. However, tackling
    these issues in real-world datasets can be challenging. Neo4j helps address problems
    such as entity linkage and deduplication through powerful features such as Cypher
    pattern matching, APOC procedures for merging nodes and cleaning up duplicates,
    and the Graph Data Science library, which includes node similarity algorithms
    to identify and consolidate related entities. These capabilities enable you to
    build a clean, reliable graph that reflects the true structure of your data.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**一致性**：原始数据可能存在记录相似信息的方式上的变化。例如，电影类型可能以不同的格式列出或包含重复项。规范化数据确保相似的数据点以一致格式记录，这使得查询和分析更加容易。然而，在现实世界的数据集中处理这些问题可能具有挑战性。Neo4j通过强大的功能如Cypher模式匹配、用于合并节点和清理重复项的APOC过程以及包含节点相似度算法以识别和合并相关实体的Graph
    Data Science库，帮助解决实体链接和去重等问题。这些功能使您能够构建一个干净、可靠的图，反映数据的真实结构。'
- en: '**Efficiency**: Normalizing data reduces redundancy, which can improve the
    efficiency of your Neo4j graph. By organizing data into a standardized format,
    you minimize the storage requirements and optimize the performance of your queries.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**效率**：规范化数据减少了冗余，这可以提高Neo4j图的效率。通过将数据组织成标准化的格式，您可以最小化存储需求并优化查询性能。'
- en: '**Accuracy**: Cleaning data involves removing or correcting inaccurate records.
    This step is essential to ensure that the insights derived from your graph are
    based on accurate and reliable data.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**准确性**：清理数据涉及删除或纠正不准确记录。这一步骤对于确保从您的图中得出的见解基于准确和可靠的数据至关重要。'
- en: '**Scalability**: A clean and normalized dataset is easier to scale. As your
    dataset grows, maintaining a standardized structure ensures that the graph remains
    manageable and performs well under increasing loads.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可扩展性**：一个干净且规范化的数据集更容易进行扩展。随着数据集的增长，保持标准化的结构可以确保图在不断增加的负载下保持可管理并表现良好。'
- en: Let us move on to cleaning and normalizing CSV files next.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续清理和规范化CSV文件。
- en: Cleaning and normalizing the CSV files
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 清理和规范化CSV文件
- en: 'Now, we will clean and normalize each CSV file included in TMDb. The available
    CSV files in our dataset are as follows:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将清理和规范化TMDb中包含的每个CSV文件。我们数据集中的可用CSV文件如下：
- en: '`credits.csv`: This file contains detailed information about the cast and crew
    for each movie in our dataset, presented as a stringified JSON object. For our
    purposes, we will focus specifically on extracting the relevant details related
    to characters, actors, directors, and producers:'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`credits.csv`：此文件包含关于我们数据集中每部电影演员和制作团队的详细信息，以字符串化的JSON对象形式呈现。就我们的目的而言，我们将专注于提取与角色、演员、导演和制片人相关的相关细节：'
- en: '[PRE7]'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '`keywords.csv`: This file contains the movie plot keywords for each movie in
    the dataset. The keywords are essential for categorizing and identifying thematic
    elements within the movies, which can be used for various purposes, such as search,
    recommendation, and content analysis:'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`keywords.csv`：此文件包含数据集中每部电影的剧情关键词。这些关键词对于对电影中的主题元素进行分类和识别至关重要，可用于各种目的，例如搜索、推荐和内容分析：'
- en: '[PRE8]'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '`links.csv`: This file contains essential metadata that links each movie in
    the full **MovieLens dataset** to its corresponding entries in both TMDb and IMDB.
    This file serves as a crucial bridge for connecting the MovieLens dataset with
    external movie databases, enabling enriched data integration and further analysis.
    However, for this use case, we skipped processing the `links.csv` file, as it
    is not essential to our current analysis. Our focus will remain on other CSV files
    more directly relevant to our project’s objectives. The data contained in `links.csv`
    can still be useful for future projects that require integration with external
    databases, but it will not be utilized in this instance.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`links.csv`：此文件包含将全**MovieLens数据集**中的每部电影与其在TMDb和IMDB中的对应条目链接的必要元数据。此文件作为连接MovieLens数据集与外部电影数据库的关键桥梁，实现了数据集成和进一步分析的丰富化。然而，对于此用例，我们跳过了处理`links.csv`文件，因为它对我们当前的分析不是必需的。我们的重点将保持在其他与我们的项目目标更直接相关的CSV文件上。`links.csv`中的数据对于需要与外部数据库集成的未来项目仍然可能是有用的，但在此实例中不会使用。'
- en: '`links_small.csv`: This file contains the TMDb and IMDb IDs for a small subset
    of 9,000 movies from the full MovieLens dataset. While this file provides a streamlined
    version of the links for a smaller selection of movies, we will not be using this
    file, as we are already utilizing the full dataset from Kaggle, which includes
    all available movies. This file is typically useful for scenarios where a more
    manageable, smaller dataset is needed, but for our purposes, the full data set
    is preferred for comprehensive analysis and integration.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`links_small.csv`: 这个文件包含来自完整 MovieLens 数据集的 9,000 部电影的 TMDb 和 IMDb IDs 的子集。虽然这个文件为较小电影集合提供了简化的链接版本，但我们不会使用这个文件，因为我们已经使用了
    Kaggle 提供的完整数据集，其中包含所有可用的电影。这个文件通常在需要更易于管理的较小数据集的场景中很有用，但出于我们的目的，完整的数据库更适合进行综合分析和集成。'
- en: '`movies_metadata.csv`: This file is a comprehensive dataset containing detailed
    information on 45,000 movies featured in the full MovieLens dataset. This file
    includes various features such as posters, backdrops, budgets, revenue, release
    dates, languages, production countries, and companies, among others. To efficiently
    organize and analyze this data, we will normalize the `movies_metadata.csv` file
    into multiple CSV files, each representing a relevant node in our dataset. These
    nodes include genres, production companies, production countries, and spoken languages.
    By breaking down the data into these separate files, we can more easily manage
    and utilize the rich information contained within this dataset. Let’s see how.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`movies_metadata.csv`: 这个文件是一个包含 45,000 部电影详细信息的全面数据集，这些电影出现在完整的 MovieLens
    数据集中。该文件包括各种功能，如海报、背景、预算、收入、上映日期、语言、制作国家和公司等。为了有效地组织和分析这些数据，我们将 `movies_metadata.csv`
    文件归一化成多个 CSV 文件，每个文件代表数据集中一个相关的节点。这些节点包括流派、制作公司、制作国家和配音语言。通过将这些数据分解成单独的文件，我们可以更轻松地管理和利用数据集中包含的丰富信息。让我们看看如何操作。'
- en: Begin with necessary imports.
  id: totrans-84
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 开始必要的导入。
- en: '[PRE9]'
  id: totrans-85
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Extract and normalize genres, production companies, countries, and spoken languages.
    We will demonstrate this step for genres and production companies. The rest of
    the code is available on [https://github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/tree/main/ch4](https://github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/tree/main/ch4)
  id: totrans-86
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取并归一化流派、制作公司、国家和配音语言。我们将为流派和制作公司演示这一步骤。其余的代码可在 [https://github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/tree/main/ch4](https://github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/tree/main/ch4)
    上找到。
- en: '[PRE10]'
  id: totrans-87
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Apply the extraction functions.
  id: totrans-88
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 应用提取函数。
- en: '[PRE11]'
  id: totrans-89
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Normalize the exploded data. Let’s do this for genres.
  id: totrans-90
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 归一化展开后的数据。让我们先对流派进行操作。
- en: '[PRE12]'
  id: totrans-91
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Next up, extract the collection name.
  id: totrans-92
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，提取集合名称。
- en: '[PRE13]'
  id: totrans-93
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '`ratings.csv`: This file is the full MovieLens dataset, consisting of 26 million
    ratings and 750,000 tag applications from 270,000 users on all 45,000 movies in
    this dataset. This comprehensive dataset provides detailed user interaction data,
    which we will use directly without the need for normalization. However, for this
    use case, we have decided to skip processing the `ratings.csv` file. While it
    provides extensive user interaction data, it is not essential to our current analysis
    and objectives. We are focusing on other CSV files that are more directly relevant
    to our project. The data in `ratings.csv` can still be valuable for future projects
    that require a deep dive into user ratings and interactions, but it will not be
    utilized in this instance.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ratings.csv`: 这个文件是完整的 MovieLens 数据集，包含 2600 万条评分和 75 万个标签应用，来自 27 万名用户对数据集中所有
    45,000 部电影的评分。这个全面的数据集提供了详细的用户交互数据，我们将直接使用这些数据，无需进行归一化处理。然而，对于这个用例，我们决定跳过处理 `ratings.csv`
    文件。虽然它提供了广泛的用户交互数据，但对于我们当前的分析和目标来说并非必需。我们正在关注其他与我们的项目更直接相关的 CSV 文件。`ratings.csv`
    中的数据对于未来需要深入挖掘用户评分和交互的项目仍然有价值，但在这个实例中不会使用。'
- en: '`ratings_small.csv`: This file is a smaller subset of the `ratings.csv` file,
    containing 100,000 ratings from 700 users on 9,000 movies. We will be using `ratings_small.csv`
    instead of focusing on the full dataset provided in `ratings.csv`.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ratings_small.csv`: 这个文件是 `ratings.csv` 文件的较小子集，包含 700 名用户对 9,000 部电影的 10
    万条评分。我们将使用 `ratings_small.csv` 而不是关注 `ratings.csv` 中提供的完整数据集。'
- en: Through this process, we have learned how to transform raw, unstructured data
    into clean, normalized datasets that are now primed for integration into your
    Neo4j graph. This preparation paves the way for constructing a robust, efficient,
    and effective AI-powered search and recommendation system. In the next section,
    we will take these normalized CSV files and use Cypher code to build a knowledge
    graph, unlocking the full potential of our dataset.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这个过程，我们学习了如何将原始的非结构化数据转换为干净、规范化的数据集，这些数据集现在已准备好集成到您的 Neo4j 图中。这种准备为构建一个强大、高效和有效的
    AI 驱动的搜索和推荐系统铺平了道路。在下一节中，我们将使用这些规范化的 CSV 文件，并通过 Cypher 代码构建知识图谱，释放我们数据集的全部潜力。
- en: Building your movie knowledge graph with code examples
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用代码示例构建您的电影知识图谱
- en: In this section, we will import your normalized datasets into Neo4j and transform
    them into a fully functional knowledge graph.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将导入您的标准化数据集到 Neo4j，并将它们转换成完全功能的知识图谱。
- en: Setting up your AuraDB free instance
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置您的 AuraDB 免费实例
- en: To start building your knowledge graph with Neo4j, you will first need to set
    up an AuraDB Free instance. AuraDB Free is a cloud-hosted Neo4j database that
    allows you to quickly get started without worrying about local installations or
    infrastructure management.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始使用 Neo4j 构建您的知识图谱，您首先需要设置一个 AuraDB Free 实例。AuraDB Free 是一个云托管的 Neo4j 数据库，它允许您快速开始，无需担心本地安装或基础设施管理。
- en: 'Follow these steps to create your instance:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤创建您的实例：
- en: Visit [https://console.neo4j.io](https://console.neo4j.io).
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 访问 [https://console.neo4j.io](https://console.neo4j.io)。
- en: Log in with your Google account or with email.
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用您的 Google 账户或电子邮件登录。
- en: Click **Create Free Instance**.
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**创建免费实例**。
- en: While the instance is being provisioned, a pop-up window will appear showing
    the connection credentials for your database.
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在实例配置过程中，将出现一个弹出窗口，显示您的数据库连接凭据。
- en: 'Make sure to download and securely save the following details from the popup—these
    are essential for connecting your application to Neo4j:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 确保从弹出窗口中下载并安全保存以下详细信息——这些信息对于将您的应用程序连接到 Neo4j 是必不可少的：
- en: '[PRE14]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: With your AuraDB Free instance set up, you are now ready to import your normalized
    datasets and start building your knowledge graph using Cypher code. In the following
    section, we will guide you through importing data and constructing relationships
    within your graph.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的 AuraDB Free 实例设置完成后，您现在可以导入您的标准化数据集，并开始使用 Cypher 代码构建您的知识图谱。在下一节中，我们将指导您导入数据并在您的图中构建关系。
- en: Importing your data into AuraDB
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将数据导入 AuraDB
- en: 'Now that your AuraDB Free instance is up and running, it is time to import
    your normalized datasets and build your knowledge graph. In this section, we will
    walk through preparing your CSV files, setting up indexes and constraints, importing
    data, and creating relationships—all through a Python script:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您的 AuraDB Free 实例已经启动并运行，是时候导入您的标准化数据集并构建您的知识图谱了。在本节中，我们将通过一个 Python 脚本指导您准备
    CSV 文件、设置索引和约束、导入数据以及创建关系。
- en: Prepare your CSV files for import.
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 准备您的 CSV 文件以供导入。
- en: Ensure that the CSV files you generated (e.g., `normalized_movies.csv`, `normalized_genres.csv`,
    etc.) are ready for import. These files should be clean, well structured, and
    hosted at accessible URLs. In this case, the `graph_build.py` script fetches files
    from public cloud storage (for example, [https://storage.googleapis.com/movies-packt/normalized_movies.csv](https://storage.googleapis.com/movies-packt/normalized_movies.csv)),
    so you do not need to upload them manually anywhere.
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保您生成的 CSV 文件（例如，`normalized_movies.csv`、`normalized_genres.csv` 等）已准备好导入。这些文件应该是干净的、结构良好的，并且托管在可访问的
    URL 上。在这种情况下，`graph_build.py` 脚本从公共云存储（例如，[https://storage.googleapis.com/movies-packt/normalized_movies.csv](https://storage.googleapis.com/movies-packt/normalized_movies.csv)）获取文件，因此您不需要手动上传它们到任何地方。
- en: Add indexes and constraints to optimize graph query retrieval.
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加索引和约束以优化图查询检索。
- en: 'Before loading data, it is critical to create unique constraints and indexes
    to ensure integrity and optimize query performance. The script includes Cypher
    commands to do the following:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在加载数据之前，创建唯一约束和索引对于确保完整性和优化查询性能至关重要。该脚本包括用于以下操作的 Cypher 命令：
- en: Ensure uniqueness on IDs such as `tmdbId`, `movieId`, and `company_id`
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保 `tmdbId`、`movieId` 和 `company_id` 等ID的唯一性
- en: Create indexes on properties such as `actor_id`, `crew_id`, and `user_id`
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 `actor_id`、`crew_id` 和 `user_id` 等属性上创建索引
- en: 'Here is how you can create indexes and constraints:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是如何创建索引和约束的说明：
- en: '[PRE15]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Import data and create nodes.
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入数据并创建节点。
- en: 'After adding constraints and indexes, the script loads the nodes from their
    respective CSVs:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在添加约束和索引后，脚本从各自的 CSV 文件中加载节点：
- en: '`load_movies()` adds all movie metadata'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`load_movies()` 添加所有电影元数据。'
- en: '`load_genres()`, `load_production_companies()`, `load_countries()`, and others
    create related nodes, such as `Genre`, `ProductionCompany`, `Country`, and `SpokenLanguage`'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`load_genres()`、`load_production_companies()`、`load_countries()` 等创建相关的节点，例如
    `Genre`、`ProductionCompany`、`Country` 和 `SpokenLanguage`。'
- en: Person-related data is added using `load_person_actors()` and `load_person_crew()`
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `load_person_actors()` 和 `load_person_crew()` 添加与人物相关的数据。
- en: Additional properties are added via `load_links()`, `load_keywords()`, and `load_ratings()`
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 通过 `load_links()`、`load_keywords()` 和 `load_ratings()` 添加额外的属性。
- en: 'Take the following example:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个示例：
- en: '[PRE16]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Create relationships.
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建关系。
- en: 'As each loader function runs, it not only creates nodes but also establishes
    meaningful relationships:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 随着每个加载函数的运行，它不仅创建节点，还建立有意义的关联：
- en: '`HAS_GENRE` between `Movie` and `Genre`'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`HAS_GENRE` 在 `Movie` 和 `Genre` 之间。'
- en: '`PRODUCED_BY` between `Movie` and `ProductionCompany`'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PRODUCED_BY` 在 `Movie` 和 `ProductionCompany` 之间。'
- en: '`HAS_LANGUAGE` between `Movie and SpokenLanguage`, `PRODUCED_IN` between `Movie`
    and `Country`, `ACTED_IN`, `DIRECTED`, `PRODUCED` between `Movie` and `Person`,
    and `RATED` between `Movie` and `User`, among others.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`HAS_LANGUAGE` 在 `Movie` 和 `SpokenLanguage` 之间，`PRODUCED_IN` 在 `Movie` 和 `Country`
    之间，`ACTED_IN`、`DIRECTED`、`PRODUCED` 在 `Movie` 和 `Person` 之间，以及 `RATED` 在 `Movie`
    和 `User` 之间，等等。'
- en: Run the full script.
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行完整脚本。
- en: Before running the script, ensure you have the Neo4j Python driver installed.
    You can install it using `pip`.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行脚本之前，请确保您已安装 Neo4j Python 驱动程序。您可以使用 `pip` 安装它。
- en: '[PRE17]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'To run the entire graph-building process, simply execute the following:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行整个图构建过程，只需执行以下操作：
- en: '[PRE18]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'This script performs the following, in order:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 此脚本按以下顺序执行以下操作：
- en: Connects to your AuraDB instance using credentials from the `.env` file
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `.env` 文件中的凭据连接到您的 AuraDB 实例。
- en: Cleans up the database
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 清理数据库。
- en: Adds indexes and constraints
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加索引和约束。
- en: Loads all node data and relationships in bulk using hosted CSVs
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用托管 CSV 文件批量加载所有节点数据和关系。
- en: 'Please refer to the complete script available here: [https://github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/blob/main/ch4/graph_build.py](https://github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/blob/main/ch4/graph_build.py).'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 请参阅此处提供的完整脚本：[https://github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/blob/main/ch4/graph_build.py](https://github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/blob/main/ch4/graph_build.py)。
- en: 'Once complete, verify your import using Neo4j Browser:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 完成后，使用 Neo4j 浏览器验证您的导入：
- en: '[PRE19]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '*Figure 4.1* illustrates a connected movie graph with over 90K nodes and 320K+
    relationships. Nodes such as `Movie`, `Genre`, `Person`, and `ProductionCompany`
    are represented with distinct colors, while relationships such as `ACTED_IN`,
    `HAS_GENRE`, and `PRODUCED_BY` showcase the web of interconnected metadata.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 4.1* 展示了一个包含超过 90K 个节点和 320K+ 关联的连接电影图。例如 `Movie`、`Genre`、`Person` 和 `ProductionCompany`
    这样的节点用不同的颜色表示，而例如 `ACTED_IN`、`HAS_GENRE` 和 `PRODUCED_BY` 这样的关系展示了相互关联的元数据网络。'
- en: '![Figure 4.1 — Neo4j graph of movies dataset](img/B31107_04_01.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.1 — 电影数据集的 Neo4j 图](img/B31107_04_01.png)'
- en: Figure 4.1 — Neo4j graph of movies dataset
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.1 — 电影数据集的 Neo4j 图。
- en: With your data successfully imported and your knowledge graph fully constructed
    using Python and Cypher, you are now ready to dive into building a GenAI-powered
    search application in the next chapter. In the following section, we will dive
    into advanced Cypher techniques that empower you to handle intricate relationships
    and derive deeper insights from your data.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Python 和 Cypher 成功导入数据并构建完知识图谱后，您现在可以开始构建一个由 GenAI 驱动的搜索应用了。在下一章中，我们将深入探讨高级
    Cypher 技术，这些技术能帮助您处理复杂的关系并从数据中获得更深入的见解。
- en: 'Beyond the basics: advanced Cypher techniques for complex graph structures'
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 除此之外：复杂图结构的 Cypher 高级技术。
- en: As your knowledge graph grows in size and complexity, so do the demands on your
    querying and data management capabilities. Cypher, Neo4j’s powerful query language,
    offers a range of advanced features designed to handle complex graph structures
    and enable more sophisticated data analysis. In this section, we will explore
    these advanced Cypher techniques, including **path patterns**, **variable-length
    relationships**, subqueries, and graph algorithms. Understanding these techniques,
    will help you efficiently manage intricate relationships, perform deeper analyses,
    and unlock the full potential of your knowledge graph for advanced use cases.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 随着您的知识图谱在规模和复杂性上的增长，对您的查询和数据管理能力的需求也在增加。Cypher，Neo4j强大的查询语言，提供了一系列高级功能，旨在处理复杂的图结构并实现更复杂的数据分析。在本节中，我们将探索这些高级Cypher技术，包括**路径模式**、**可变长度关系**、子查询和图算法。理解这些技术将帮助您有效地管理复杂的关系，进行更深入的分析，并释放您的知识图谱在高级用例中的全部潜力。
- en: 'Let us explore these key advanced Cypher techniques:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探索这些关键的Cypher高级技术：
- en: '**Variable-length relationships**:  Variable-length relationships in Cypher
    allow you to match paths of varying lengths between nodes. This is particularly
    useful when exploring hierarchical structures or networks with multiple degrees
    of separation. An example is finding all movies connected to a specific actor
    within three degrees of separation:'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可变长度的关系**：Cypher中的可变长度关系允许您在节点之间匹配不同长度的路径。这在探索层次结构或具有多个分离度的网络时特别有用。例如，找到与特定演员在三个分离度范围内的所有电影：'
- en: '[PRE20]'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Here, `*1..3` specifies that the relationship path can be between 1 and 3 steps
    long.
  id: totrans-154
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在这里，`*1..3`指定了关系路径的长度可以在1到3步之间。
- en: '**Use cases**: Variable-length relationships are ideal for scenarios such as
    social network analysis, where you want to find all people within a certain degree
    of connection, or in hierarchical datasets where you want to explore parent-child
    relationships across multiple levels.'
  id: totrans-155
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**用例**：可变长度关系非常适合社交网络分析等场景，您想要找到在特定连接度内的人，或者在具有多级父子关系的层次数据集中探索父子关系。'
- en: '**Pattern matching with path patterns**: You can create **named path patterns**
    as well as chain the paths in Neo4j.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用路径模式进行模式匹配**：您可以在Neo4j中创建**命名路径模式**以及链式路径。'
- en: '**Defining path patterns**: Cypher allows you to define named path patterns
    that can be reused throughout your queries. This makes your queries more readable
    and allows you to encapsulate complex relationships in a single pattern. Take
    the following example:'
  id: totrans-157
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**定义路径模式**：Cypher允许您定义可重用的命名路径模式，这些模式可以在查询中多次使用。这使得您的查询更易于阅读，并允许您将复杂的关系封装在单个模式中。以下是一个示例：'
- en: '[PRE21]'
  id: totrans-158
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Here, `path` is a named path pattern that can be reused in subsequent operations
    or subqueries.
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，`path`是一个命名路径模式，可以在后续操作或子查询中重复使用。
- en: '**Chaining path patterns**: Cypher allows you to combine multiple path patterns
    to perform complex traversals within the graph. This is especially useful when
    trying to uncover indirect relationships or discover multiple paths that satisfy
    specific criteria.'
  id: totrans-160
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**链式路径模式**：Cypher允许您组合多个路径模式，在图内执行复杂的遍历。这在试图揭示间接关系或发现满足特定标准的多条路径时特别有用。'
- en: An example is exploring collaborations in the movies dataset.
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一个例子是探索电影数据集中的合作情况。
- en: 'Let’s say we want to find movies where an actor has worked with a director
    they’ve previously collaborated with, possibly through another movie. This involves
    chaining paths from an actor to a movie, then to a director, and seeing whether
    there’s another movie connecting the same actor-director pair:'
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 假设我们想要找到演员与导演合作过的电影，而这些导演之前可能通过另一部电影与他们合作过。这涉及到从演员到电影，再到导演的路径链，并查看是否存在另一部电影连接相同的演员-导演对：
- en: '[PRE22]'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: This kind of pattern chaining is extremely helpful in identifying professional
    relationships, recurring collaborations, or analyzing indirect influence in networks.
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这种模式链在识别专业关系、重复合作或分析网络中的间接影响方面非常有帮助。
- en: '**Subqueries** and **procedural logic**: You can use subqueries and procedures
    to process complex queries. Here is how:'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**子查询**和**过程逻辑**：您可以使用子查询和过程来处理复杂查询。以下是操作方法：'
- en: '**Using subqueries for modular queries**: Subqueries in Cypher allow you to
    break down complex queries into modular, reusable components. This is particularly
    helpful when dealing with large graphs or when you need to perform multiple operations
    on the same dataset. Take the following example:'
  id: totrans-166
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用子查询进行模块化查询**：Cypher 中的子查询允许您将复杂的查询分解成模块化、可重用的组件。这在处理大型图或需要对同一数据集执行多个操作时特别有用。以下是一个示例：'
- en: '[PRE23]'
  id: totrans-167
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Here, the subquery retrieves all action movies, and the outer query matches
    these movies to their directors.
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，子查询检索所有动作电影，而外部查询将这些电影与它们的导演匹配。
- en: '**Procedural logic with** **CALL**: The `CALL` clause in Cypher allows you
    to invoke procedures and use the results in further queries. This is essential
    for advanced data processing, such as running graph algorithms or invoking custom
    procedures.'
  id: totrans-169
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用 CALL 执行过程逻辑**：Cypher 中的 `CALL` 子句允许您调用过程并在后续查询中使用这些结果。这对于高级数据处理至关重要，例如运行图算法或调用自定义过程。'
- en: 'We’ve already applied this in our own implementation in the `graph_build.py`
    file, specifically in the `load_ratings()` function. Here, we use the `CALL {
    ... } IN TRANSACTIONS` pattern to efficiently load large datasets by processing
    them in chunks of 50,000 rows:'
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们已经在 `graph_build.py` 文件中的实现中应用了这种方法，特别是在 `load_ratings()` 函数中。在这里，我们使用 `CALL
    { ... } IN TRANSACTIONS` 模式，通过以 50,000 行的块来处理数据，有效地加载大量数据集：
- en: '[PRE24]'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: This approach allows us to handle massive CSV imports while maintaining performance
    and transactional integrity—just one of the many powerful use cases for `CALL`
    in real-world graph applications.
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这种方法使我们能够在保持性能和事务完整性的同时处理大量的 CSV 导入——这是 `CALL` 在现实世界图应用中的许多强大用例之一。
- en: '**Working with** **nested queries:** In complex graph structures, you might
    need to **combine results from multiple queries**. Cypher allows you to nest queries,
    passing results from one query into another, which is useful for filtering or
    refining results based on multiple criteria. Take the following example:'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**处理嵌套查询**：在复杂的图结构中，您可能需要**组合多个查询的结果**。Cypher 允许您嵌套查询，将一个查询的结果传递给另一个查询，这对于基于多个标准过滤或细化结果非常有用。以下是一个示例：'
- en: '[PRE25]'
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Here, the nested query refines the results by filtering movies based on revenue
    and then finding their associated genres.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，嵌套查询通过根据收入过滤电影来细化结果，然后找到它们相关的类型。
- en: These Cypher techniques empower you to tackle complex graph structures, enabling
    deeper insights and more sophisticated analyses. You can refer to [https://neo4j.com/docs/cypher-manual/current/appendix/tutorials/advanced-query-tuning/](https://neo4j.com/docs/cypher-manual/current/appendix/tutorials/advanced-query-tuning/)
    to explore some of these techniques further.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 这些 Cypher 技巧使您能够应对复杂的图结构，实现更深入的洞察和更复杂的分析。您可以参考[https://neo4j.com/docs/cypher-manual/current/appendix/tutorials/advanced-query-tuning/](https://neo4j.com/docs/cypher-manual/current/appendix/tutorials/advanced-query-tuning/)以进一步探索这些技巧。
- en: Summary
  id: totrans-177
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we worked on transforming raw, semi-structured data into clean,
    normalized datasets, ready for integration into our knowledge graph. We then explored
    the best practices in graph modeling, focusing on how to structure your nodes
    and relationships to enhance search efficiency and ensure your graph remains scalable
    and performant. Following this, we tackled other Cypher techniques, equipping
    you with the skills to handle variable-length relationships, pattern matching,
    subqueries, and graph algorithms. You are now well prepared to build a knowledge
    graph-driven search that can handle even the most intricate data relationships.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们致力于将原始的半结构化数据转换为干净、规范化的数据集，以便将其集成到我们的知识图谱中。然后，我们探讨了图建模的最佳实践，重点关注如何构建节点和关系以增强搜索效率，并确保您的图保持可扩展和高效。在此之后，我们探讨了其他
    Cypher 技巧，为您提供处理可变长度关系、模式匹配、子查询和图算法的技能。您现在已准备好构建一个由知识图谱驱动的搜索，它可以处理甚至最复杂的数据关系。
- en: In the next chapter, we will take a step further by exploring how to integrate
    Haystack into Neo4j. This practical guide will show you how to build powerful
    search functionalities within your knowledge graph, allowing you to leverage the
    full potential of both Neo4j and Haystack for intelligent search solutions.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将进一步探索如何将 Haystack 集成到 Neo4j 中。这本实用指南将向您展示如何在您的知识图谱中构建强大的搜索功能，让您能够充分利用
    Neo4j 和 Haystack 的全部潜力，以实现智能搜索解决方案。
