<html><head></head><body>
  <div id="_idContainer052" class="Basic-Text-Frame">
    <h1 class="chapterNumber"><span class="koboSpan" id="kobo.1.1">4</span></h1>
    <h1 id="_idParaDest-101" class="chapterTitle"><span class="koboSpan" id="kobo.2.1">Multimodal Modular RAG for Drone Technology</span></h1>
    <p class="normal"><span class="koboSpan" id="kobo.3.1">We will take generative AI to the next level with modular RAG in this chapter. </span><span class="koboSpan" id="kobo.3.2">We will build a system that uses different components or modules to handle different types of data and tasks. </span><span class="koboSpan" id="kobo.3.3">For example, one module processes textual information using LLMs, as we have done until the last chapter, while another module manages image data, identifying and labeling objects within images. </span><span class="koboSpan" id="kobo.3.4">Imagine using this technology in drones, which have become crucial across various industries, offering enhanced capabilities for aerial photography, efficient agricultural monitoring, and effective search and rescue operations. </span><span class="koboSpan" id="kobo.3.5">They even use advanced computer vision technology and algorithms to analyze images and identify objects like pedestrians, cars, trucks, and more. </span><span class="koboSpan" id="kobo.3.6">We can then activate an LLM agent to retrieve, augment, and respond to a user’s question.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.4.1">In this chapter, we will build a multimodal modular RAG program to generate responses to queries about drone technology using text and image data from multiple sources. </span><span class="koboSpan" id="kobo.4.2">We will first define the main aspects of modular RAG, multimodal data, multisource retrieval, modular generation, and augmented output. </span><span class="koboSpan" id="kobo.4.3">We will then build a multimodal modular RAG-driven generative AI system in Python applied to drone technology with LlamaIndex, Deep Lake, and OpenAI.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.5.1">Our system will use two datasets: the first one containing textual information about drones that we built in the previous chapter and the second one containing drone images and labels from Activeloop. </span><span class="koboSpan" id="kobo.5.2">We will use Deep Lake to work with multimodal data, LlamaIndex for indexing and retrieval, and generative queries with OpenAI LLMs. </span><span class="koboSpan" id="kobo.5.3">We will add multimodal augmented outputs with text and images. </span><span class="koboSpan" id="kobo.5.4">Finally, we will build performance metrics for the text responses and introduce an image recognition metric with GPT-4o, OpenAI’s powerful </span><strong class="keyWord"><span class="koboSpan" id="kobo.6.1">Multimodal LLM</span></strong><span class="koboSpan" id="kobo.7.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.8.1">MMLLM</span></strong><span class="koboSpan" id="kobo.9.1">). </span><span class="koboSpan" id="kobo.9.2">By the end of the chapter, you will know how to build a multimodal modular RAG workflow leveraging innovative multimodal and multisource functionalities.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.10.1">This chapter covers the following topics:</span></p>
    <ul>
      <li class="bulletList"><span class="koboSpan" id="kobo.11.1">Multimodal modular RAG</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.12.1">Multisource retrieval</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.13.1">OpenAI LLM-guided multimodal multisource retrieval</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.14.1">Deep Lake multimodal datasets</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.15.1">Image metadata-based retrieval</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.16.1">Augmented multimodal output</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.17.1">Let’s begin by defining multimodal modular RAG.</span></p>
    <h1 id="_idParaDest-102" class="heading-1"><span class="koboSpan" id="kobo.18.1">What is multimodal modular RAG?</span></h1>
    <p class="normal"><span class="koboSpan" id="kobo.19.1">Multimodal data combines different forms of information, such as text, images, audio, and video, to enrich data analysis </span><a id="_idIndexMarker241"/><span class="koboSpan" id="kobo.20.1">and interpretation. </span><span class="koboSpan" id="kobo.20.2">Meanwhile, a system is a modular RAG system when it utilizes distinct modules for handling different data types and tasks. </span><span class="koboSpan" id="kobo.20.3">Each module is specialized; for example, one module will focus on text and another on images, demonstrating a sophisticated integration capability that enhances response generation with retrieved multimodal data.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.21.1">The program in this chapter will also be multisource through the two datasets we will use. </span><span class="koboSpan" id="kobo.21.2">We will use the LLM dataset on the drone technology built in the previous chapter. </span><span class="koboSpan" id="kobo.21.3">We will also use the Deep Lake multimodal VisDrone dataset, which contains thousands of labeled images captured by drones.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.22.1">We have selected drones for our example since drones have become crucial across various industries, offering enhanced capabilities for aerial photography, efficient agricultural monitoring, and effective search and rescue operations. </span><span class="koboSpan" id="kobo.22.2">They also facilitate wildlife tracking, streamline commercial deliveries, and enable safer infrastructure inspections. </span><span class="koboSpan" id="kobo.22.3">Additionally, drones support environmental research, traffic management, and firefighting. </span><span class="koboSpan" id="kobo.22.4">They can enhance surveillance for law enforcement, revolutionizing multiple fields by improving accessibility, safety, and cost-efficiency.</span></p>
    <p class="normal"><em class="italic"><span class="koboSpan" id="kobo.23.1">Figure 4.1</span></em><span class="koboSpan" id="kobo.24.1"> contains the workflow we will implement in this chapter. </span><span class="koboSpan" id="kobo.24.2">It is based on the generative RAG ecosystem illustrated in </span><em class="italic"><span class="koboSpan" id="kobo.25.1">Figure 1.3</span></em><span class="koboSpan" id="kobo.26.1"> from </span><em class="italic"><span class="koboSpan" id="kobo.27.1">Chapter 1</span></em><span class="koboSpan" id="kobo.28.1">, </span><em class="italic"><span class="koboSpan" id="kobo.29.1">Why Retrieval-Augmented Generation?</span></em><span class="koboSpan" id="kobo.30.1">. </span><span class="koboSpan" id="kobo.30.2">We added embedding and indexing functionality in the previous chapters, but this chapter will focus on retrieval and generation. </span><span class="koboSpan" id="kobo.30.3">The system we will build blurs the lines between retrieval and generation since the generator is intensively used for</span><a id="_idIndexMarker242"/><span class="koboSpan" id="kobo.31.1"> retrieving (seamless scoring and ranking) as well as generating in the chapter’s notebook.</span></p>
    <figure class="mediaobject"><span class="koboSpan" id="kobo.32.1"><img src="../Images/B31169_04_01.png" alt="A diagram of a multimodal modular rag system  Description automatically generated"/></span></figure>
    <p class="packt_figref"><span class="koboSpan" id="kobo.33.1">Figure 4.1: A multimodal modular RAG system</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.34.1">This chapter aims to build an educational modular RAG question-answering system focused on drone technology. </span><span class="koboSpan" id="kobo.34.2">You can rely on the functionality implemented in the notebooks of the preceding chapters, such as Deep Lake for vectors in </span><em class="italic"><span class="koboSpan" id="kobo.35.1">Chapter 2</span></em><span class="koboSpan" id="kobo.36.1">, </span><em class="italic"><span class="koboSpan" id="kobo.37.1">RAG Embedding Vector Stores with Deep Lake and OpenAI</span></em><span class="koboSpan" id="kobo.38.1">, and indices with LlamaIndex in </span><em class="italic"><span class="koboSpan" id="kobo.39.1">Chapter 3</span></em><span class="koboSpan" id="kobo.40.1">, </span><em class="italic"><span class="koboSpan" id="kobo.41.1">Building</span></em> <em class="italic"><span class="koboSpan" id="kobo.42.1">Index-based RAG with LlamaIndex, Deep Lake, and OpenAI</span></em><span class="koboSpan" id="kobo.43.1">. </span><span class="koboSpan" id="kobo.43.2">If necessary, take your time to go back to the previous chapters and have a look.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.44.1">Let’s go through the multimodal, multisource, modular RAG ecosystem in this chapter, represented in </span><em class="italic"><span class="koboSpan" id="kobo.45.1">Figure 4.1</span></em><span class="koboSpan" id="kobo.46.1">. </span><span class="koboSpan" id="kobo.46.2">We will use the titles and subsections in this chapter represented in italics. </span><span class="koboSpan" id="kobo.46.3">Also, each </span><a id="_idIndexMarker243"/><span class="koboSpan" id="kobo.47.1">phase is preceded by its location in </span><em class="italic"><span class="koboSpan" id="kobo.48.1">Figure 4.1</span></em><span class="koboSpan" id="kobo.49.1">.</span></p>
    <ul>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.50.1">(D4)</span></strong> <em class="italic"><span class="koboSpan" id="kobo.51.1">Loading the LLM dataset</span></em><span class="koboSpan" id="kobo.52.1"> created in </span><em class="italic"><span class="koboSpan" id="kobo.53.1">Chapter 3</span></em><span class="koboSpan" id="kobo.54.1">, which contains textual data on drones.</span></li>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.55.1">(D4)</span></strong> <em class="italic"><span class="koboSpan" id="kobo.56.1">Initializing the LLM query engine</span></em><span class="koboSpan" id="kobo.57.1"> with a LlamaIndex vector store index using </span><code class="inlineCode"><span class="koboSpan" id="kobo.58.1">VectorStoreIndex</span></code><span class="koboSpan" id="kobo.59.1"> and setting the created index for the query engine, which overlaps with </span><strong class="keyWord"><span class="koboSpan" id="kobo.60.1">(G4)</span></strong><span class="koboSpan" id="kobo.61.1"> as both a retriever and a generator with the OpenAI GPT model.</span></li>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.62.1">(G1)</span></strong><span class="koboSpan" id="kobo.63.1"> Defining the </span><em class="italic"><span class="koboSpan" id="kobo.64.1">user input for multimodal modular RAG</span></em><span class="koboSpan" id="kobo.65.1"> for both the LLM query engine (for the textual dataset) and the multimodal query engine (for the </span><code class="inlineCode"><span class="koboSpan" id="kobo.66.1">VisDrone</span></code><span class="koboSpan" id="kobo.67.1"> dataset).</span></li>
    </ul>
    <p class="normal-one"><span class="koboSpan" id="kobo.68.1">Once the textual dataset has been loaded, the query engine has been created, and the user input has been defined as a baseline query for the textual dataset and the multimodal dataset, the process continues by generating a response for the textual dataset created in </span><em class="italic"><span class="koboSpan" id="kobo.69.1">Chapter 2</span></em><span class="koboSpan" id="kobo.70.1">.</span></p>
    <ul>
      <li class="bulletList"><span class="koboSpan" id="kobo.71.1">While</span><em class="italic"><span class="koboSpan" id="kobo.72.1"> querying the textual dataset</span></em><span class="koboSpan" id="kobo.73.1">, </span><strong class="keyWord"><span class="koboSpan" id="kobo.74.1">(G1)</span></strong><span class="koboSpan" id="kobo.75.1">, </span><strong class="keyWord"><span class="koboSpan" id="kobo.76.1">(G2)</span></strong><span class="koboSpan" id="kobo.77.1">, and </span><strong class="keyWord"><span class="koboSpan" id="kobo.78.1">(G4)</span></strong><span class="koboSpan" id="kobo.79.1"> overlap in the same seamless LlamaIndex process that retrieves data and generates content. </span><span class="koboSpan" id="kobo.79.2">The response is saved as </span><code class="inlineCode"><span class="koboSpan" id="kobo.80.1">llm_response</span></code><span class="koboSpan" id="kobo.81.1"> for the duration of the session.</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.82.1">Now, the multimodal </span><code class="inlineCode"><span class="koboSpan" id="kobo.83.1">VisDrone</span></code><span class="koboSpan" id="kobo.84.1"> dataset </span><a id="_idIndexMarker244"/><span class="koboSpan" id="kobo.85.1">will be loaded into memory and queried:</span></p>
    <ul>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.86.1">(D4)</span></strong><span class="koboSpan" id="kobo.87.1"> The multimodal process begins by </span><em class="italic"><span class="koboSpan" id="kobo.88.1">loading and visualizing the multimodal dataset</span></em><span class="koboSpan" id="kobo.89.1">. </span><span class="koboSpan" id="kobo.89.2">The program then continues by </span><em class="italic"><span class="koboSpan" id="kobo.90.1">navigating the multimodal dataset structure</span></em><span class="koboSpan" id="kobo.91.1">, </span><em class="italic"><span class="koboSpan" id="kobo.92.1">selecting an image</span></em><span class="koboSpan" id="kobo.93.1">, and </span><em class="italic"><span class="koboSpan" id="kobo.94.1">adding bounding boxes</span></em><span class="koboSpan" id="kobo.95.1">.</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.96.1">The same process as for the textual dataset is then applied to the </span><code class="inlineCode"><span class="koboSpan" id="kobo.97.1">VisDrone</span></code><span class="koboSpan" id="kobo.98.1"> multimodal dataset:</span></p>
    <ul>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.99.1">(D4)</span></strong> <em class="italic"><span class="koboSpan" id="kobo.100.1">Building a multimodal query engine</span></em><span class="koboSpan" id="kobo.101.1"> with LlamaIndex by creating a vector store index based on </span><code class="inlineCode"><span class="koboSpan" id="kobo.102.1">VisDrone</span></code><span class="koboSpan" id="kobo.103.1"> data using </span><code class="inlineCode"><span class="koboSpan" id="kobo.104.1">VectorStoreIndex</span></code><span class="koboSpan" id="kobo.105.1"> and setting the created index for the query engine, which overlaps with </span><strong class="keyWord"><span class="koboSpan" id="kobo.106.1">(G4)</span></strong><span class="koboSpan" id="kobo.107.1"> as both a retriever and a generator with OpenAI GPT.</span></li>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.108.1">(G1)</span></strong><span class="koboSpan" id="kobo.109.1"> The user input for the multimodal search engine is the same as the </span><em class="italic"><span class="koboSpan" id="kobo.110.1">user input for multimodal modular RAG</span></em><span class="koboSpan" id="kobo.111.1"> since it is used for both the LLM query engine (for the textual dataset) and the multimodal query engine (for the </span><code class="inlineCode"><span class="koboSpan" id="kobo.112.1">VisDrone</span></code><span class="koboSpan" id="kobo.113.1"> dataset).</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.114.1">The multimodal </span><code class="inlineCode"><span class="koboSpan" id="kobo.115.1">VisDrone</span></code><span class="koboSpan" id="kobo.116.1"> dataset will now be loaded and indexed, and the query engine is ready. </span><span class="koboSpan" id="kobo.116.2">The purpose of </span><strong class="keyWord"><span class="koboSpan" id="kobo.117.1">(G1)</span></strong><span class="koboSpan" id="kobo.118.1"> user input is for the LlamaIndex query engine to retrieve relevant documents from VisDrone using an LLM—in this case, an OpenAI model. </span><span class="koboSpan" id="kobo.118.2">Then, the retrieval functions will trace the response back to its source in the multimodal dataset to find the image of the source nodes. </span><span class="koboSpan" id="kobo.118.3">We are, in fact, using the query engine to reach an image through its textual response:</span></p>
    <ul>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.119.1">(G1)</span></strong><span class="koboSpan" id="kobo.120.1">, </span><strong class="keyWord"><span class="koboSpan" id="kobo.121.1">(G2)</span></strong><span class="koboSpan" id="kobo.122.1">, and </span><strong class="keyWord"><span class="koboSpan" id="kobo.123.1">(G4)</span></strong><span class="koboSpan" id="kobo.124.1"> overlap in a seamless LlamaIndex query when running a query on the </span><code class="inlineCode"><span class="koboSpan" id="kobo.125.1">VisDrone</span></code><span class="koboSpan" id="kobo.126.1"> multimodal dataset.</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.127.1">Processing the response </span><strong class="keyWord"><span class="koboSpan" id="kobo.128.1">(G4)</span></strong><span class="koboSpan" id="kobo.129.1"> to find the source node and retrieve its image leads us back to </span><strong class="keyWord"><span class="koboSpan" id="kobo.130.1">(D4)</span></strong><span class="koboSpan" id="kobo.131.1"> for image retrieval. </span><span class="koboSpan" id="kobo.131.2">This leads to selecting and processing the image of the source node.</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.132.1">At this point, we now have the textual and the image response. </span><span class="koboSpan" id="kobo.132.2">We can then build a summary and apply an accuracy performance metric after having visualized the time elapsed for each phase as we built the program:</span></p>
    <ul>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.133.1">(G4)</span></strong><span class="koboSpan" id="kobo.134.1"> We present a</span><a id="_idIndexMarker245"/><span class="koboSpan" id="kobo.135.1"> merged output with the LLM response and the augmented output with the image of the multimodal response in a </span><em class="italic"><span class="koboSpan" id="kobo.136.1">multimodal modular summary</span></em><span class="koboSpan" id="kobo.137.1">.</span></li>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.138.1">(E)</span></strong><span class="koboSpan" id="kobo.139.1"> Finally, we create an </span><em class="italic"><span class="koboSpan" id="kobo.140.1">LLM performance metric</span></em><span class="koboSpan" id="kobo.141.1"> and a </span><em class="italic"><span class="koboSpan" id="kobo.142.1">multimodal performance metric</span></em><span class="koboSpan" id="kobo.143.1">. </span><span class="koboSpan" id="kobo.143.2">We then sum them up as a </span><em class="italic"><span class="koboSpan" id="kobo.144.1">multimodal modular RAG performance metric</span></em><span class="koboSpan" id="kobo.145.1">.</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.146.1">We can draw two conclusions from this multimodal modular RAG system:</span></p>
    <ul>
      <li class="bulletList"><span class="koboSpan" id="kobo.147.1">The system we are building in this chapter is one of the many ways RAG-driven generative AI can be designed in real-life projects. </span><span class="koboSpan" id="kobo.147.2">Each project will have its specific needs and architecture.</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.148.1">The rapid evolution from generative AI to the complexity of RAG-driven generative AI requires the corresponding development of seamlessly integrated cross-platform components such as LlamaIndex, Deep Lake, and OpenAI in this chapter. </span><span class="koboSpan" id="kobo.148.2">These platforms are also integrated with many other frameworks, such as Pinecone and LangChain, which we will discuss in </span><em class="italic"><span class="koboSpan" id="kobo.149.1">Chapter 6</span></em><span class="koboSpan" id="kobo.150.1">, </span><em class="italic"><span class="koboSpan" id="kobo.151.1">Scaling RAG Bank Customer Data with Pinecone</span></em><span class="koboSpan" id="kobo.152.1">.</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.153.1">Now, let’s dive into Python and build the multimodal modular RAG program.</span></p>
    <h1 id="_idParaDest-103" class="heading-1"><span class="koboSpan" id="kobo.154.1">Building a multimodal modular RAG program for drone technology</span></h1>
    <p class="normal"><span class="koboSpan" id="kobo.155.1">In the following sections, we will build a</span><a id="_idIndexMarker246"/><span class="koboSpan" id="kobo.156.1"> multimodal modular RAG-driven generative system from scratch in Python, step by step. </span><span class="koboSpan" id="kobo.156.2">We will implement:</span></p>
    <ul>
      <li class="bulletList"><span class="koboSpan" id="kobo.157.1">LlamaIndex-managed </span><a id="_idIndexMarker247"/><span class="koboSpan" id="kobo.158.1">OpenAI LLMs to process and understand text about drones</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.159.1">Deep Lake multimodal datasets containing images and labels of drone images taken</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.160.1">Functions to display images and identify objects within them using bounding boxes</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.161.1">A system that can answer questions about drone technology using both text and images</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.162.1">Performance metrics aimed at measuring the accuracy of the modular multimodal responses, including image analysis with GPT-4o</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.163.1">Also, make sure you have created the LLM dataset in </span><em class="italic"><span class="koboSpan" id="kobo.164.1">Chapter 2</span></em><span class="koboSpan" id="kobo.165.1"> since we will be loading it in this section. </span><span class="koboSpan" id="kobo.165.2">However, you can read this chapter without running the notebook since it is self-contained with code and explanations. </span><span class="koboSpan" id="kobo.165.3">Now, let’s get to work!</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.166.1">Open the </span><code class="inlineCode"><span class="koboSpan" id="kobo.167.1">Multimodal_Modular_RAG_Drones.ipynb</span></code><span class="koboSpan" id="kobo.168.1"> notebook in the GitHub repository for this chapter at </span><a href="https://github.com/Denis2054/RAG-Driven-Generative-AI/tree/main/Chapter04"><span class="url"><span class="koboSpan" id="kobo.169.1">https://github.com/Denis2054/RAG-Driven-Generative-AI/tree/main/Chapter04</span></span></a><span class="koboSpan" id="kobo.170.1">. </span><span class="koboSpan" id="kobo.170.2">The packages installed are the same as those listed in the </span><em class="italic"><span class="koboSpan" id="kobo.171.1">Installing the environment</span></em><span class="koboSpan" id="kobo.172.1"> section of the previous chapter. </span><span class="koboSpan" id="kobo.172.2">Each of the following sections will guide you through building the multimodal modular notebook, starting with the LLM module. </span><span class="koboSpan" id="kobo.172.3">Let’s go through each section of the notebook step by step.</span></p>
    <h2 id="_idParaDest-104" class="heading-2"><span class="koboSpan" id="kobo.173.1">Loading the LLM dataset</span></h2>
    <p class="normal"><span class="koboSpan" id="kobo.174.1">We will load the </span><a id="_idIndexMarker248"/><span class="koboSpan" id="kobo.175.1">drone dataset created in </span><em class="italic"><span class="koboSpan" id="kobo.176.1">Chapter 3</span></em><span class="koboSpan" id="kobo.177.1">. </span><span class="koboSpan" id="kobo.177.2">Make sure to</span><a id="_idIndexMarker249"/><span class="koboSpan" id="kobo.178.1"> insert the path to your dataset:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.179.1">import</span></span><span class="koboSpan" id="kobo.180.1"> deeplake
dataset_path_llm = </span><span class="hljs-string"><span class="koboSpan" id="kobo.181.1">"hub://denis76/drone_v2"</span></span><span class="koboSpan" id="kobo.182.1">
ds_llm = deeplake.load(dataset_path_llm)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.183.1">The output will confirm that the dataset is loaded and will display the link to your dataset:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.184.1">This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/denis76/drone_v2
hub://denis76/drone_v2 loaded successfully.
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.185.1">The program now creates </span><a id="_idIndexMarker250"/><span class="koboSpan" id="kobo.186.1">a dictionary to hold the data to load it into a pandas DataFrame to visualize it:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.187.1">import</span></span><span class="koboSpan" id="kobo.188.1"> json
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.189.1">import</span></span><span class="koboSpan" id="kobo.190.1"> pandas </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.191.1">as</span></span><span class="koboSpan" id="kobo.192.1"> pd
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.193.1">import</span></span><span class="koboSpan" id="kobo.194.1"> numpy </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.195.1">as</span></span><span class="koboSpan" id="kobo.196.1"> np
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.197.1"># Create a dictionary to hold the data</span></span><span class="koboSpan" id="kobo.198.1">
data_llm = {}
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.199.1"># Iterate through the tensors in the dataset</span></span>
<span class="hljs-keyword"><span class="koboSpan" id="kobo.200.1">for</span></span><span class="koboSpan" id="kobo.201.1"> tensor_name </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.202.1">in</span></span><span class="koboSpan" id="kobo.203.1"> ds_llm.tensors:
    tensor_data = ds_llm[tensor_name].numpy()
    </span><span class="hljs-comment"><span class="koboSpan" id="kobo.204.1"># Check if the tensor is multi-dimensional</span></span>
    <span class="hljs-keyword"><span class="koboSpan" id="kobo.205.1">if</span></span><span class="koboSpan" id="kobo.206.1"> tensor_data.ndim &gt; </span><span class="hljs-number"><span class="koboSpan" id="kobo.207.1">1</span></span><span class="koboSpan" id="kobo.208.1">:
        </span><span class="hljs-comment"><span class="koboSpan" id="kobo.209.1"># Flatten multi-dimensional tensors</span></span><span class="koboSpan" id="kobo.210.1">
        data_llm[tensor_name] = [np.array(e).flatten().tolist() </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.211.1">for</span></span><span class="koboSpan" id="kobo.212.1"> e </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.213.1">in</span></span><span class="koboSpan" id="kobo.214.1"> tensor_data]
    </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.215.1">else</span></span><span class="koboSpan" id="kobo.216.1">:
        </span><span class="hljs-comment"><span class="koboSpan" id="kobo.217.1"># Convert 1D tensors directly to lists and decode text</span></span>
        <span class="hljs-keyword"><span class="koboSpan" id="kobo.218.1">if</span></span><span class="koboSpan" id="kobo.219.1"> tensor_name == </span><span class="hljs-string"><span class="koboSpan" id="kobo.220.1">"text"</span></span><span class="koboSpan" id="kobo.221.1">:
            data_llm[tensor_name] = [t.tobytes().decode(</span><span class="hljs-string"><span class="koboSpan" id="kobo.222.1">'utf-8'</span></span><span class="koboSpan" id="kobo.223.1">) </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.224.1">if</span></span><span class="koboSpan" id="kobo.225.1"> t </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.226.1">else</span></span> <span class="hljs-string"><span class="koboSpan" id="kobo.227.1">""</span></span> <span class="hljs-keyword"><span class="koboSpan" id="kobo.228.1">for</span></span><span class="koboSpan" id="kobo.229.1"> t </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.230.1">in</span></span><span class="koboSpan" id="kobo.231.1"> tensor_data]
        </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.232.1">else</span></span><span class="koboSpan" id="kobo.233.1">:
            data_llm[tensor_name] = tensor_data.tolist()
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.234.1"># Create a Pandas DataFrame from the dictionary</span></span><span class="koboSpan" id="kobo.235.1">
df_llm = pd.DataFrame(data_llm)
df_llm
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.236.1">The output shows the text dataset </span><a id="_idIndexMarker251"/><span class="koboSpan" id="kobo.237.1">with its structure: </span><code class="inlineCode"><span class="koboSpan" id="kobo.238.1">embedding</span></code><span class="koboSpan" id="kobo.239.1"> (vectors), </span><code class="inlineCode"><span class="koboSpan" id="kobo.240.1">id</span></code><span class="koboSpan" id="kobo.241.1"> (unique string identifier), </span><code class="inlineCode"><span class="koboSpan" id="kobo.242.1">metadata</span></code><span class="koboSpan" id="kobo.243.1"> (in this case, the source of the data), and </span><code class="inlineCode"><span class="koboSpan" id="kobo.244.1">text</span></code><span class="koboSpan" id="kobo.245.1">, which contains the content:</span></p>
    <figure class="mediaobject"><span class="koboSpan" id="kobo.246.1"><img src="../Images/B31169_04_02.png" alt=""/></span></figure>
    <p class="packt_figref"><span class="koboSpan" id="kobo.247.1">Figure 4.2: Output of the text dataset structure and content</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.248.1">We will </span><a id="_idIndexMarker252"/><span class="koboSpan" id="kobo.249.1">now initialize </span><a id="_idIndexMarker253"/><span class="koboSpan" id="kobo.250.1">the LLM query engine.</span></p>
    <h3 id="_idParaDest-105" class="heading-3"><span class="koboSpan" id="kobo.251.1">Initializing the LLM query engine</span></h3>
    <p class="normal"><span class="koboSpan" id="kobo.252.1">As in </span><em class="chapterRef"><span class="koboSpan" id="kobo.253.1">Chapter 3</span></em><span class="koboSpan" id="kobo.254.1">,</span><em class="italic"><span class="koboSpan" id="kobo.255.1"> Building Indexed-Based RAG with LlamaIndex, Deep Lake, and OpenAI</span></em><span class="koboSpan" id="kobo.256.1">, we will initialize a vector store index from the collection of drone documents (</span><code class="inlineCode"><span class="koboSpan" id="kobo.257.1">documents_llm</span></code><span class="koboSpan" id="kobo.258.1">) of the dataset (</span><code class="inlineCode"><span class="koboSpan" id="kobo.259.1">ds</span></code><span class="koboSpan" id="kobo.260.1">). </span><span class="koboSpan" id="kobo.260.2">The </span><code class="inlineCode"><span class="koboSpan" id="kobo.261.1">GPTVectorStoreIndex.from_documents()</span></code><span class="koboSpan" id="kobo.262.1"> method creates an index that increases the</span><a id="_idIndexMarker254"/><span class="koboSpan" id="kobo.263.1"> retrieval speed of documents based on vector similarity:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.264.1">from</span></span><span class="koboSpan" id="kobo.265.1"> llama_index.core </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.266.1">import</span></span><span class="koboSpan" id="kobo.267.1"> VectorStoreIndex
vector_store_index_llm = VectorStoreIndex.from_documents(documents_llm)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.268.1">The </span><code class="inlineCode"><span class="koboSpan" id="kobo.269.1">as_query_engine()</span></code><span class="koboSpan" id="kobo.270.1"> method configures this index as a query engine with the specific parameters, as in </span><em class="chapterRef"><span class="koboSpan" id="kobo.271.1">Chapter 3</span></em><span class="koboSpan" id="kobo.272.1">, for similarity and retrieval depth, allowing the system to answer queries by finding the most relevant documents:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.273.1">vector_query_engine_llm = vector_store_index_llm.as_query_engine(similarity_top_k=</span><span class="hljs-number"><span class="koboSpan" id="kobo.274.1">2</span></span><span class="koboSpan" id="kobo.275.1">, temperature=</span><span class="hljs-number"><span class="koboSpan" id="kobo.276.1">0.1</span></span><span class="koboSpan" id="kobo.277.1">, num_output=</span><span class="hljs-number"><span class="koboSpan" id="kobo.278.1">1024</span></span><span class="koboSpan" id="kobo.279.1">)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.280.1">Now, the program introduces the user input.</span></p>
    <h4 class="heading-4"><span class="koboSpan" id="kobo.281.1">User input for multimodal modular RAG</span></h4>
    <p class="normal"><span class="koboSpan" id="kobo.282.1">The goal of defining the user input in the context of the modular RAG system is to formulate a query that will </span><a id="_idIndexMarker255"/><span class="koboSpan" id="kobo.283.1">effectively utilize both</span><a id="_idIndexMarker256"/><span class="koboSpan" id="kobo.284.1"> the text-based and image-based capabilities. </span><span class="koboSpan" id="kobo.284.2">This allows the system to generate a comprehensive and accurate response by leveraging multiple information sources:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.285.1">user_input=</span><span class="hljs-string"><span class="koboSpan" id="kobo.286.1">"How do drones identify a truck?"</span></span>
</code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.287.1">In this context, the user input is the </span><em class="italic"><span class="koboSpan" id="kobo.288.1">baseline</span></em><span class="koboSpan" id="kobo.289.1">, the starting point, or a standard query used to assess the system’s capabilities. </span><span class="koboSpan" id="kobo.289.2">It will establish the initial frame of reference for how well the system can handle and respond to queries utilizing its available resources (e.g., text and image data</span><a id="_idIndexMarker257"/><span class="koboSpan" id="kobo.290.1"> from various datasets). </span><span class="koboSpan" id="kobo.290.2">In this example, the baseline is empirical and will serve to evaluate the system from that </span><a id="_idIndexMarker258"/><span class="koboSpan" id="kobo.291.1">reference point.</span></p>
    <h4 class="heading-4"><span class="koboSpan" id="kobo.292.1">Querying the textual dataset</span></h4>
    <p class="normal"><span class="koboSpan" id="kobo.293.1">We will run the vector query</span><a id="_idIndexMarker259"/><span class="koboSpan" id="kobo.294.1"> engine request as we did in </span><em class="chapterRef"><span class="koboSpan" id="kobo.295.1">Chapter 3</span></em><span class="koboSpan" id="kobo.296.1">:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.297.1">import</span></span><span class="koboSpan" id="kobo.298.1"> time
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.299.1">import</span></span><span class="koboSpan" id="kobo.300.1"> textwrap
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.301.1">#start the timer</span></span><span class="koboSpan" id="kobo.302.1">
start_time = time.time()
llm_response = vector_query_engine_llm.query(user_input)
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.303.1"># Stop the timer</span></span><span class="koboSpan" id="kobo.304.1">
end_time = time.time()
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.305.1"># Calculate and print the execution time</span></span><span class="koboSpan" id="kobo.306.1">
elapsed_time = end_time - start_time
</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.307.1">print</span></span><span class="koboSpan" id="kobo.308.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.309.1">f"Query execution time: </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.310.1">{elapsed_time:</span></span><span class="hljs-number"><span class="koboSpan" id="kobo.311.1">.4</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.312.1">f}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.313.1"> seconds"</span></span><span class="koboSpan" id="kobo.314.1">)
</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.315.1">print</span></span><span class="koboSpan" id="kobo.316.1">(textwrap.fill(</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.317.1">str</span></span><span class="koboSpan" id="kobo.318.1">(llm_response), </span><span class="hljs-number"><span class="koboSpan" id="kobo.319.1">100</span></span><span class="koboSpan" id="kobo.320.1">))
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.321.1">The execution time is satisfactory:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.322.1">Query execution time: 1.5489 seconds
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.323.1">The output content is also satisfactory:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.324.1">Drones can identify a truck using visual detection and tracking methods, which may involve deep neural networks for performance benchmarking.
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.325.1">The program now loads the multimodal drone dataset.</span></p>
    <h2 id="_idParaDest-106" class="heading-2"><span class="koboSpan" id="kobo.326.1">Loading and visualizing the multimodal dataset</span></h2>
    <p class="normal"><span class="koboSpan" id="kobo.327.1">We will use the existing</span><a id="_idIndexMarker260"/><span class="koboSpan" id="kobo.328.1"> pubic VisDrone dataset available on Deep Lake: </span><a href="https://datasets.activeloop.ai/docs/ml/datasets/visdrone-dataset/"><span class="url"><span class="koboSpan" id="kobo.329.1">https://datasets.activeloop.ai/docs/ml/datasets/visdrone-dataset/</span></span></a><span class="koboSpan" id="kobo.330.1">. </span><span class="koboSpan" id="kobo.330.2">We will </span><em class="italic"><span class="koboSpan" id="kobo.331.1">not</span></em><span class="koboSpan" id="kobo.332.1"> create a vector store but </span><a id="_idIndexMarker261"/><span class="koboSpan" id="kobo.333.1">simply load the existing dataset in memory:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.334.1">import</span></span><span class="koboSpan" id="kobo.335.1"> deeplake
dataset_path = </span><span class="hljs-string"><span class="koboSpan" id="kobo.336.1">'hub://activeloop/visdrone-det-train'</span></span><span class="koboSpan" id="kobo.337.1">
ds = deeplake.load(dataset_path) </span><span class="hljs-comment"><span class="koboSpan" id="kobo.338.1"># Returns a Deep Lake Dataset but does not download data locally</span></span>
</code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.339.1">The output will display a link to the online dataset that you can explore with SQL, or natural language processing </span><a id="_idIndexMarker262"/><span class="koboSpan" id="kobo.340.1">commands if you prefer, with the tools provided by Deep Lake:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.341.1">Opening dataset in read-only mode as you don't have write permissions.
</span><span class="koboSpan" id="kobo.341.2">This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/activeloop/visdrone-det-train
hub://activeloop/visdrone-det-train loaded successfully.
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.342.1">Let’s display the summary to explore the dataset in code:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.343.1">ds.summary()
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.344.1">The output provides useful information on the structure of the dataset:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.345.1">Dataset(path='hub://activeloop/visdrone-det-train', read_only=True, tensors=['boxes', 'images', 'labels'])
tensor    htype            shape              dtype     compression
------    -----            -----              -----     -----------
boxes     bbox         (6471, 1:914, 4)       float32          None
images    image        (6471, 360:1500,                            
                        480:2000, 3)          uint8            jpeg
labels    class_label  (6471, 1:914)          uint32           None
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.346.1">The structure contains</span><a id="_idIndexMarker263"/><span class="koboSpan" id="kobo.347.1"> images, boxes for the boundary boxes of the objects in the image, and labels describing the images and boundary boxes. </span><span class="koboSpan" id="kobo.347.2">Let’s visualize the dataset in code:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.348.1">ds.visualize()
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.349.1">The output shows the images and their boundary boxes:</span></p>
    <figure class="mediaobject"><span class="koboSpan" id="kobo.350.1"><img src="../Images/B31169_04_03.png" alt=""/></span></figure>
    <p class="packt_figref"><span class="koboSpan" id="kobo.351.1">Figure 4.3: Output showing boundary boxes</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.352.1">Now, let’s go further </span><a id="_idIndexMarker264"/><span class="koboSpan" id="kobo.353.1">and display the content of the dataset in a pandas DataFrame to see what</span><a id="_idIndexMarker265"/><span class="koboSpan" id="kobo.354.1"> the images look like:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.355.1">import</span></span><span class="koboSpan" id="kobo.356.1"> pandas </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.357.1">as</span></span><span class="koboSpan" id="kobo.358.1"> pd
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.359.1"># Create an empty DataFrame with the defined structure</span></span><span class="koboSpan" id="kobo.360.1">
df = pd.DataFrame(columns=[</span><span class="hljs-string"><span class="koboSpan" id="kobo.361.1">'image'</span></span><span class="koboSpan" id="kobo.362.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.363.1">'boxes'</span></span><span class="koboSpan" id="kobo.364.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.365.1">'labels'</span></span><span class="koboSpan" id="kobo.366.1">])
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.367.1"># Iterate through the samples using enumerate</span></span>
<span class="hljs-keyword"><span class="koboSpan" id="kobo.368.1">for</span></span><span class="koboSpan" id="kobo.369.1"> i, sample </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.370.1">in</span></span> <span class="hljs-built_in"><span class="koboSpan" id="kobo.371.1">enumerate</span></span><span class="koboSpan" id="kobo.372.1">(ds):
    </span><span class="hljs-comment"><span class="koboSpan" id="kobo.373.1"># Image data (choose either path or compressed representation)</span></span>
    <span class="hljs-comment"><span class="koboSpan" id="kobo.374.1"># df.loc[i, 'image'] = sample.images.path  # Store image path</span></span><span class="koboSpan" id="kobo.375.1">
    df.loc[i, </span><span class="hljs-string"><span class="koboSpan" id="kobo.376.1">'image'</span></span><span class="koboSpan" id="kobo.377.1">] = sample.images.tobytes()  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.378.1"># Store compressed image data</span></span>
    <span class="hljs-comment"><span class="koboSpan" id="kobo.379.1"># Bounding box data (as a list of lists)</span></span><span class="koboSpan" id="kobo.380.1">
    boxes_list = sample.boxes.numpy(aslist=</span><span class="hljs-literal"><span class="koboSpan" id="kobo.381.1">True</span></span><span class="koboSpan" id="kobo.382.1">)
    df.loc[i, </span><span class="hljs-string"><span class="koboSpan" id="kobo.383.1">'boxes'</span></span><span class="koboSpan" id="kobo.384.1">] = [box.tolist() </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.385.1">for</span></span><span class="koboSpan" id="kobo.386.1"> box </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.387.1">in</span></span><span class="koboSpan" id="kobo.388.1"> boxes_list]
    </span><span class="hljs-comment"><span class="koboSpan" id="kobo.389.1"># Label data (as a list)</span></span><span class="koboSpan" id="kobo.390.1">
    label_data = sample.labels.data()
    df.loc[i, </span><span class="hljs-string"><span class="koboSpan" id="kobo.391.1">'labels'</span></span><span class="koboSpan" id="kobo.392.1">] = label_data[</span><span class="hljs-string"><span class="koboSpan" id="kobo.393.1">'text'</span></span><span class="koboSpan" id="kobo.394.1">]
df
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.395.1">The output in </span><em class="italic"><span class="koboSpan" id="kobo.396.1">Figure 4.4</span></em><span class="koboSpan" id="kobo.397.1"> shows the content of the dataset:</span></p>
    <figure class="mediaobject"><span class="koboSpan" id="kobo.398.1"><img src="../Images/B31169_04_04.png" alt="A screenshot of a computer  Description automatically generated"/></span></figure>
    <p class="packt_figref"><span class="koboSpan" id="kobo.399.1">Figure 4.4: Excerpt of the VisDrone dataset</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.400.1">There are 6,471 rows of</span><a id="_idIndexMarker266"/><span class="koboSpan" id="kobo.401.1"> images in the dataset and 3 columns:</span></p>
    <ul>
      <li class="bulletList"><span class="koboSpan" id="kobo.402.1">The </span><code class="inlineCode"><span class="koboSpan" id="kobo.403.1">image</span></code><span class="koboSpan" id="kobo.404.1"> column contains</span><a id="_idIndexMarker267"/><span class="koboSpan" id="kobo.405.1"> the image. </span><span class="koboSpan" id="kobo.405.2">The format of the image in the dataset, as indicated by the byte sequence </span><code class="inlineCode"><span class="koboSpan" id="kobo.406.1">b'\xff\xd8\xff\xe0\x00\x10JFIF\x00\x01\x01\x00...'</span></code><span class="koboSpan" id="kobo.407.1">, is JPEG. </span><span class="koboSpan" id="kobo.407.2">The bytes </span><code class="inlineCode"><span class="koboSpan" id="kobo.408.1">b'\xff\xd8\xff\xe0'</span></code><span class="koboSpan" id="kobo.409.1"> specifically signify the start of a JPEG image file.</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.410.1">The </span><code class="inlineCode"><span class="koboSpan" id="kobo.411.1">boxes</span></code><span class="koboSpan" id="kobo.412.1"> column contains the coordinates and dimensions of bounding boxes in the image, which are normally in the format </span><code class="inlineCode"><span class="koboSpan" id="kobo.413.1">[x, y, width, height]</span></code><span class="koboSpan" id="kobo.414.1">.</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.415.1">The </span><code class="inlineCode"><span class="koboSpan" id="kobo.416.1">labels</span></code><span class="koboSpan" id="kobo.417.1"> column contains the label of each bounding box in the </span><code class="inlineCode"><span class="koboSpan" id="kobo.418.1">boxes</span></code><span class="koboSpan" id="kobo.419.1"> column.</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.420.1">We can display the list of labels for the images:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.421.1">labels_list = ds.labels.info[</span><span class="hljs-string"><span class="koboSpan" id="kobo.422.1">'class_names'</span></span><span class="koboSpan" id="kobo.423.1">]
labels_list
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.424.1">The output provides the list of labels, which defines the scope of the dataset:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.425.1">['ignored regions',
 'pedestrian',
 'people',
 'bicycle',
 'car',
 'van',
 'truck',
 'tricycle',
 'awning-tricycle',
 'bus',
 'motor',
 'others']
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.426.1">With that, we have </span><a id="_idIndexMarker268"/><span class="koboSpan" id="kobo.427.1">successfully loaded the dataset and will now explore the multimodal dataset </span><a id="_idIndexMarker269"/><span class="koboSpan" id="kobo.428.1">structure.</span></p>
    <h2 id="_idParaDest-107" class="heading-2"><span class="koboSpan" id="kobo.429.1">Navigating the multimodal dataset structure</span></h2>
    <p class="normal"><span class="koboSpan" id="kobo.430.1">In this section, we will select an</span><a id="_idIndexMarker270"/><span class="koboSpan" id="kobo.431.1"> image and display it using the dataset’s image column. </span><span class="koboSpan" id="kobo.431.2">To this image, we will then add the bounding boxes of a label that we will choose. </span><span class="koboSpan" id="kobo.431.3">The </span><a id="_idIndexMarker271"/><span class="koboSpan" id="kobo.432.1">program first selects an image.</span></p>
    <h3 id="_idParaDest-108" class="heading-3"><span class="koboSpan" id="kobo.433.1">Selecting and displaying an image</span></h3>
    <p class="normal"><span class="koboSpan" id="kobo.434.1">We will select the</span><a id="_idIndexMarker272"/><span class="koboSpan" id="kobo.435.1"> first image in the dataset:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.436.1"># choose an image</span></span><span class="koboSpan" id="kobo.437.1">
ind=</span><span class="hljs-number"><span class="koboSpan" id="kobo.438.1">0</span></span><span class="koboSpan" id="kobo.439.1">
image = ds.images[ind].numpy() </span><span class="hljs-comment"><span class="koboSpan" id="kobo.440.1"># Fetch the first image and return a numpy array</span></span>
</code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.441.1">Now, let’s display it with no </span><a id="_idIndexMarker273"/><span class="koboSpan" id="kobo.442.1">bounding boxes:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.443.1">import</span></span><span class="koboSpan" id="kobo.444.1"> deeplake
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.445.1">from</span></span><span class="koboSpan" id="kobo.446.1"> IPython.display </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.447.1">import</span></span><span class="koboSpan" id="kobo.448.1"> display
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.449.1">from</span></span><span class="koboSpan" id="kobo.450.1"> PIL </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.451.1">import</span></span><span class="koboSpan" id="kobo.452.1"> Image
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.453.1">import</span></span><span class="koboSpan" id="kobo.454.1"> cv2  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.455.1"># Import OpenCV</span></span><span class="koboSpan" id="kobo.456.1">
image = ds.images[</span><span class="hljs-number"><span class="koboSpan" id="kobo.457.1">0</span></span><span class="koboSpan" id="kobo.458.1">].numpy()
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.459.1"># Convert from BGR to RGB (if necessary)</span></span><span class="koboSpan" id="kobo.460.1">
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.461.1"># Create PIL Image and display</span></span><span class="koboSpan" id="kobo.462.1">
img = Image.fromarray(image_rgb)
display(img)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.463.1">The image displayed contains </span><a id="_idIndexMarker274"/><span class="koboSpan" id="kobo.464.1">trucks, pedestrians, and other types of objects:</span></p>
    <figure class="mediaobject"><span class="koboSpan" id="kobo.465.1"><img src="../Images/B31169_04_05.png" alt=""/></span></figure>
    <p class="packt_figref"><span class="koboSpan" id="kobo.466.1">Figure 4.5: Output displaying objects</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.467.1">Now that the image is displayed, the program will add bounding boxes.</span></p>
    <h3 id="_idParaDest-109" class="heading-3"><span class="koboSpan" id="kobo.468.1">Adding bounding boxes and saving the image</span></h3>
    <p class="normal"><span class="koboSpan" id="kobo.469.1">We have displayed </span><a id="_idIndexMarker275"/><span class="koboSpan" id="kobo.470.1">the first image. </span><span class="koboSpan" id="kobo.470.2">The program will then fetch all the</span><a id="_idIndexMarker276"/><span class="koboSpan" id="kobo.471.1"> labels for the selected image:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.472.1">labels = ds.labels[ind].data() </span><span class="hljs-comment"><span class="koboSpan" id="kobo.473.1"># Fetch the labels in the selected image</span></span>
<span class="hljs-built_in"><span class="koboSpan" id="kobo.474.1">print</span></span><span class="koboSpan" id="kobo.475.1">(labels)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.476.1">The output displays </span><code class="inlineCode"><span class="koboSpan" id="kobo.477.1">value</span></code><span class="koboSpan" id="kobo.478.1">, which contains the numerical indices of a label, and </span><code class="inlineCode"><span class="koboSpan" id="kobo.479.1">text</span></code><span class="koboSpan" id="kobo.480.1">, which contains the corresponding text labels of a label:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.481.1">{'value': array([1, 1, 7, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 6, 6, 6, 6,
       1, 1, 1, 1, 1, 1, 6, 6, 3, 6, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
       1, 6, 6, 6], dtype=uint32), 'text': ['pedestrian', 'pedestrian', 'tricycle', 'pedestrian', 'pedestrian', 'pedestrian', 'pedestrian', 'truck', 'truck', 'truck', 'truck', 'truck', 'truck', 'truck', 'truck', 'truck', 'truck', 'pedestrian', 'truck', 'truck', 'truck', 'truck', 'pedestrian', 'pedestrian', 'pedestrian', 'pedestrian', 'pedestrian', 'pedestrian', 'truck', 'truck', 'bicycle', 'truck', 'truck', 'pedestrian', 'pedestrian', 'pedestrian', 'pedestrian', 'pedestrian', 'pedestrian', 'pedestrian', 'pedestrian', 'pedestrian', 'pedestrian', 'pedestrian', 'pedestrian', 'truck', 'truck', 'truck']}
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.482.1">We can display the values and the corresponding text in two columns:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.483.1">values = labels[</span><span class="hljs-string"><span class="koboSpan" id="kobo.484.1">'value'</span></span><span class="koboSpan" id="kobo.485.1">]
text_labels = labels[</span><span class="hljs-string"><span class="koboSpan" id="kobo.486.1">'text'</span></span><span class="koboSpan" id="kobo.487.1">]
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.488.1"># Determine the maximum text label length for formatting</span></span><span class="koboSpan" id="kobo.489.1">
max_text_length = </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.490.1">max</span></span><span class="koboSpan" id="kobo.491.1">(</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.492.1">len</span></span><span class="koboSpan" id="kobo.493.1">(label) </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.494.1">for</span></span><span class="koboSpan" id="kobo.495.1"> label </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.496.1">in</span></span><span class="koboSpan" id="kobo.497.1"> text_labels)
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.498.1"># Print the header</span></span>
<span class="hljs-built_in"><span class="koboSpan" id="kobo.499.1">print</span></span><span class="koboSpan" id="kobo.500.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.501.1">f"</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.502.1">{</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.503.1">'Index'</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.504.1">:&lt;</span></span><span class="hljs-number"><span class="koboSpan" id="kobo.505.1">10</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.506.1">}{</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.507.1">'Label'</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.508.1">:&lt;{max_text_length + </span></span><span class="hljs-number"><span class="koboSpan" id="kobo.509.1">2</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.510.1">}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.511.1">}"</span></span><span class="koboSpan" id="kobo.512.1">)
</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.513.1">print</span></span><span class="koboSpan" id="kobo.514.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.515.1">"-"</span></span><span class="koboSpan" id="kobo.516.1"> * (</span><span class="hljs-number"><span class="koboSpan" id="kobo.517.1">10</span></span><span class="koboSpan" id="kobo.518.1"> + max_text_length + </span><span class="hljs-number"><span class="koboSpan" id="kobo.519.1">2</span></span><span class="koboSpan" id="kobo.520.1">))  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.521.1"># Add a separator line</span></span>
<span class="hljs-comment"><span class="koboSpan" id="kobo.522.1"># Print the indices and labels in two columns</span></span>
<span class="hljs-keyword"><span class="koboSpan" id="kobo.523.1">for</span></span><span class="koboSpan" id="kobo.524.1"> index, label </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.525.1">in</span></span> <span class="hljs-built_in"><span class="koboSpan" id="kobo.526.1">zip</span></span><span class="koboSpan" id="kobo.527.1">(values, text_labels):
    </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.528.1">print</span></span><span class="koboSpan" id="kobo.529.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.530.1">f"</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.531.1">{index:&lt;</span></span><span class="hljs-number"><span class="koboSpan" id="kobo.532.1">10</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.533.1">}{label:&lt;{max_text_length + </span></span><span class="hljs-number"><span class="koboSpan" id="kobo.534.1">2</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.535.1">}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.536.1">}"</span></span><span class="koboSpan" id="kobo.537.1">)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.538.1">The output gives us a clear representation of the content of the labels of an image:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.539.1">Index     Label     
----------------------
1         pedestrian
1         pedestrian
7         tricycle  
1         pedestrian
1         pedestrian
1         pedestrian
1         pedestrian
6         truck     
6         truck    …
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.540.1">We can group the</span><a id="_idIndexMarker277"/><span class="koboSpan" id="kobo.541.1"> class names (labels in plain text) of</span><a id="_idIndexMarker278"/><span class="koboSpan" id="kobo.542.1"> the images:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.543.1">ds.labels[ind].info[</span><span class="hljs-string"><span class="koboSpan" id="kobo.544.1">'class_names'</span></span><span class="koboSpan" id="kobo.545.1">] </span><span class="hljs-comment"><span class="koboSpan" id="kobo.546.1"># class names of the selected image</span></span>
</code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.547.1">We can now group and display all the labels that describe the image:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.548.1">ds.labels[ind].info[</span><span class="hljs-string"><span class="koboSpan" id="kobo.549.1">'class_names'</span></span><span class="koboSpan" id="kobo.550.1">] </span><span class="hljs-comment"><span class="koboSpan" id="kobo.551.1">#class names of the selected image</span></span>
</code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.552.1">We can see all the classes the image contains:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.553.1">['ignored regions',
 'pedestrian',
 'people',
 'bicycle',
 'car',
 'van',
 'truck',
 'tricycle',
 'awning-tricycle',
 'bus',
 'motor',
 'others']
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.554.1">The number of label classes sometimes exceeds what a human eye can see in an image.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.555.1">Let’s now add bounding boxes. </span><span class="koboSpan" id="kobo.555.2">We first create a function to add the bounding boxes, display them, and save the image:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.556.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.557.1">display_image_with_bboxes</span></span><span class="koboSpan" id="kobo.558.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.559.1">image_data, bboxes, labels, label_name, ind=</span></span><span class="hljs-number"><span class="koboSpan" id="kobo.560.1">0</span></span><span class="koboSpan" id="kobo.561.1">):
    </span><span class="hljs-comment"><span class="koboSpan" id="kobo.562.1">#Displays an image with bounding boxes for a specific label.</span></span><span class="koboSpan" id="kobo.563.1">
    image_bytes = io.BytesIO(image_data)
    img = Image.</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.564.1">open</span></span><span class="koboSpan" id="kobo.565.1">(image_bytes)
    </span><span class="hljs-comment"><span class="koboSpan" id="kobo.566.1"># Extract class names specifically for the selected image</span></span><span class="koboSpan" id="kobo.567.1">
    class_names = ds.labels[ind].info[</span><span class="hljs-string"><span class="koboSpan" id="kobo.568.1">'class_names'</span></span><span class="koboSpan" id="kobo.569.1">]
    </span><span class="hljs-comment"><span class="koboSpan" id="kobo.570.1"># Filter for the specific label (or display all if class names are missing)</span></span>
    <span class="hljs-keyword"><span class="koboSpan" id="kobo.571.1">if</span></span><span class="koboSpan" id="kobo.572.1"> class_names </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.573.1">is</span></span> <span class="hljs-keyword"><span class="koboSpan" id="kobo.574.1">not</span></span> <span class="hljs-literal"><span class="koboSpan" id="kobo.575.1">None</span></span><span class="koboSpan" id="kobo.576.1">:
        </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.577.1">try</span></span><span class="koboSpan" id="kobo.578.1">:
            label_index = class_names.index(label_name)
            relevant_indices = np.where(labels == label_index)[</span><span class="hljs-number"><span class="koboSpan" id="kobo.579.1">0</span></span><span class="koboSpan" id="kobo.580.1">]
        </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.581.1">except</span></span><span class="koboSpan" id="kobo.582.1"> ValueError:
            </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.583.1">print</span></span><span class="koboSpan" id="kobo.584.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.585.1">f"Warning: Label '</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.586.1">{label_name}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.587.1">' not found. </span><span class="koboSpan" id="kobo.587.2">Displaying all boxes."</span></span><span class="koboSpan" id="kobo.588.1">)
            relevant_indices = </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.589.1">range</span></span><span class="koboSpan" id="kobo.590.1">(</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.591.1">len</span></span><span class="koboSpan" id="kobo.592.1">(labels))
    </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.593.1">else</span></span><span class="koboSpan" id="kobo.594.1">:
        relevant_indices = []  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.595.1"># No labels found, so display no boxes</span></span>
    <span class="hljs-comment"><span class="koboSpan" id="kobo.596.1"># Draw bounding boxes</span></span><span class="koboSpan" id="kobo.597.1">
    draw = ImageDraw.Draw(img)
    </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.598.1">for</span></span><span class="koboSpan" id="kobo.599.1"> idx, box </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.600.1">in</span></span> <span class="hljs-built_in"><span class="koboSpan" id="kobo.601.1">enumerate</span></span><span class="koboSpan" id="kobo.602.1">(bboxes):  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.603.1"># Enumerate over bboxes</span></span>
        <span class="hljs-keyword"><span class="koboSpan" id="kobo.604.1">if</span></span><span class="koboSpan" id="kobo.605.1"> idx </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.606.1">in</span></span><span class="koboSpan" id="kobo.607.1"> relevant_indices:   </span><span class="hljs-comment"><span class="koboSpan" id="kobo.608.1"># Check if this box is relevant</span></span><span class="koboSpan" id="kobo.609.1">
            x1, y1, w, h = box
            x2, y2 = x1 + w, y1 + h
            draw.rectangle([x1, y1, x2, y2], outline=</span><span class="hljs-string"><span class="koboSpan" id="kobo.610.1">"red"</span></span><span class="koboSpan" id="kobo.611.1">, width=</span><span class="hljs-number"><span class="koboSpan" id="kobo.612.1">2</span></span><span class="koboSpan" id="kobo.613.1">)
            draw.text((x1, y1), label_name, fill=</span><span class="hljs-string"><span class="koboSpan" id="kobo.614.1">"red"</span></span><span class="koboSpan" id="kobo.615.1">)
    </span><span class="hljs-comment"><span class="koboSpan" id="kobo.616.1"># Save the image</span></span><span class="koboSpan" id="kobo.617.1">
    save_path=</span><span class="hljs-string"><span class="koboSpan" id="kobo.618.1">"boxed_image.jpg"</span></span><span class="koboSpan" id="kobo.619.1">
    img.save(save_path)
    display(img)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.620.1">We can add the bounding </span><a id="_idIndexMarker279"/><span class="koboSpan" id="kobo.621.1">boxes for a specific label. </span><span class="koboSpan" id="kobo.621.2">In this</span><a id="_idIndexMarker280"/><span class="koboSpan" id="kobo.622.1"> case, we selected the </span><code class="inlineCode"><span class="koboSpan" id="kobo.623.1">"truck"</span></code><span class="koboSpan" id="kobo.624.1"> label:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.625.1">import</span></span><span class="koboSpan" id="kobo.626.1"> io
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.627.1">from</span></span><span class="koboSpan" id="kobo.628.1"> PIL </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.629.1">import</span></span><span class="koboSpan" id="kobo.630.1"> ImageDraw
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.631.1"># Fetch labels and image data for the selected image</span></span><span class="koboSpan" id="kobo.632.1">
labels = ds.labels[ind].data()[</span><span class="hljs-string"><span class="koboSpan" id="kobo.633.1">'value'</span></span><span class="koboSpan" id="kobo.634.1">]
image_data = ds.images[ind].tobytes()
bboxes = ds.boxes[ind].numpy()
ibox=</span><span class="hljs-string"><span class="koboSpan" id="kobo.635.1">"truck"</span></span> <span class="hljs-comment"><span class="koboSpan" id="kobo.636.1"># class in image</span></span>
<span class="hljs-comment"><span class="koboSpan" id="kobo.637.1"># Display the image with bounding boxes for the label chosen</span></span><span class="koboSpan" id="kobo.638.1">
display_image_with_bboxes(image_data, bboxes, labels, label_name=ibox)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.639.1">The image displayed</span><a id="_idIndexMarker281"/><span class="koboSpan" id="kobo.640.1"> now contains the bounding boxes for trucks:</span></p>
    <figure class="mediaobject"><span class="koboSpan" id="kobo.641.1"><img src="../Images/B31169_04_06.png" alt="A truck with several trailers  Description automatically generated with medium confidence"/></span></figure>
    <figure class="mediaobject"><span class="koboSpan" id="kobo.642.1">Figure 4.6: Output displaying bounding boxes</span></figure>
    <p class="normal"><span class="koboSpan" id="kobo.643.1">Let’s now activate a</span><a id="_idIndexMarker282"/><span class="koboSpan" id="kobo.644.1"> query engine to retrieve and obtain a response.</span></p>
    <h2 id="_idParaDest-110" class="heading-2"><span class="koboSpan" id="kobo.645.1">Building a multimodal query engine</span></h2>
    <p class="normal"><span class="koboSpan" id="kobo.646.1">In this section, we will query the VisDrone dataset and retrieve an image that fits the user input we entered in the </span><em class="italic"><span class="koboSpan" id="kobo.647.1">User input for multimodal modular RAG</span></em><span class="koboSpan" id="kobo.648.1"> section of this notebook. </span><span class="koboSpan" id="kobo.648.2">To achieve this </span><a id="_idIndexMarker283"/><span class="koboSpan" id="kobo.649.1">goal, we will:</span></p>
    <ol>
      <li class="numberedList" value="1"><span class="koboSpan" id="kobo.650.1">Create a vector index for each row of the </span><code class="inlineCode"><span class="koboSpan" id="kobo.651.1">df</span></code><span class="koboSpan" id="kobo.652.1"> DataFrame containing the images, boxing data, and labels of the VisDrone dataset.</span></li>
      <li class="numberedList"><span class="koboSpan" id="kobo.653.1">Create a query engine that will </span><a id="_idIndexMarker284"/><span class="koboSpan" id="kobo.654.1">query the text data of the dataset, retrieve relevant image information, and provide a text response.</span></li>
      <li class="numberedList"><span class="koboSpan" id="kobo.655.1">Parse the nodes of the response to find the keywords related to the user input.</span></li>
      <li class="numberedList"><span class="koboSpan" id="kobo.656.1">Parse the nodes of the response to find the source image.</span></li>
      <li class="numberedList"><span class="koboSpan" id="kobo.657.1">Add the bounding</span><a id="_idIndexMarker285"/><span class="koboSpan" id="kobo.658.1"> boxes of the source image to the image.</span></li>
      <li class="numberedList"><span class="koboSpan" id="kobo.659.1">Save the image.</span></li>
    </ol>
    <h3 id="_idParaDest-111" class="heading-3"><span class="koboSpan" id="kobo.660.1">Creating a vector index and query engine</span></h3>
    <p class="normal"><span class="koboSpan" id="kobo.661.1">The code first creates a</span><a id="_idIndexMarker286"/><span class="koboSpan" id="kobo.662.1"> document that will be processed to create a vector store index for the multimodal drone dataset. </span><span class="koboSpan" id="kobo.662.2">The </span><code class="inlineCode"><span class="koboSpan" id="kobo.663.1">df</span></code><span class="koboSpan" id="kobo.664.1"> DataFrame we created in the </span><em class="italic"><span class="koboSpan" id="kobo.665.1">Loading and visualizing the multimodal dataset</span></em><span class="koboSpan" id="kobo.666.1"> section of the </span><a id="_idIndexMarker287"/><span class="koboSpan" id="kobo.667.1">notebook on GitHub does not have unique indices or embeddings. </span><span class="koboSpan" id="kobo.667.2">We will create them in memory with LlamaIndex.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.668.1">The program first assigns a unique ID to the DataFrame:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.669.1"># The DataFrame is named 'df'</span></span><span class="koboSpan" id="kobo.670.1">
df[</span><span class="hljs-string"><span class="koboSpan" id="kobo.671.1">'doc_id'</span></span><span class="koboSpan" id="kobo.672.1">] = df.index.astype(</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.673.1">str</span></span><span class="koboSpan" id="kobo.674.1">)  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.675.1"># Create unique IDs from the row indices</span></span>
</code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.676.1">This line adds a new column to the </span><code class="inlineCode"><span class="koboSpan" id="kobo.677.1">df</span></code><span class="koboSpan" id="kobo.678.1"> DataFrame called </span><code class="inlineCode"><span class="koboSpan" id="kobo.679.1">doc_id</span></code><span class="koboSpan" id="kobo.680.1">. </span><span class="koboSpan" id="kobo.680.2">It assigns unique identifiers to each row by converting the DataFrame’s row indices to strings. </span><span class="koboSpan" id="kobo.680.3">An empty list named </span><code class="inlineCode"><span class="koboSpan" id="kobo.681.1">documents</span></code><span class="koboSpan" id="kobo.682.1"> is initialized, which we will use to create a vector index:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.683.1"># Create documents (extract relevant text for each image's labels)</span></span><span class="koboSpan" id="kobo.684.1">
documents = []
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.685.1">Now, the </span><code class="inlineCode"><span class="koboSpan" id="kobo.686.1">iterrows()</span></code><span class="koboSpan" id="kobo.687.1"> method iterates through each row of the DataFrame, generating a sequence of index and row pairs:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.688.1">for</span></span><span class="koboSpan" id="kobo.689.1"> _, row </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.690.1">in</span></span><span class="koboSpan" id="kobo.691.1"> df.iterrows():
    text_labels = row[</span><span class="hljs-string"><span class="koboSpan" id="kobo.692.1">'labels'</span></span><span class="koboSpan" id="kobo.693.1">] </span><span class="hljs-comment"><span class="koboSpan" id="kobo.694.1"># Each label is now a string</span></span><span class="koboSpan" id="kobo.695.1">
    text = </span><span class="hljs-string"><span class="koboSpan" id="kobo.696.1">" "</span></span><span class="koboSpan" id="kobo.697.1">.join(text_labels) </span><span class="hljs-comment"><span class="koboSpan" id="kobo.698.1"># Join text labels into a single string</span></span><span class="koboSpan" id="kobo.699.1">
    document = Document(text=text, doc_id=row[</span><span class="hljs-string"><span class="koboSpan" id="kobo.700.1">'doc_id'</span></span><span class="koboSpan" id="kobo.701.1">])
    documents.append(document)
</span></code></pre>
    <p class="normal"><code class="inlineCode"><span class="koboSpan" id="kobo.702.1">documents</span></code><span class="koboSpan" id="kobo.703.1"> is appended with all the records in the dataset, and a DataFrame is created:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.704.1"># The DataFrame is named 'df'</span></span><span class="koboSpan" id="kobo.705.1">
df[</span><span class="hljs-string"><span class="koboSpan" id="kobo.706.1">'doc_id'</span></span><span class="koboSpan" id="kobo.707.1">] = df.index.astype(</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.708.1">str</span></span><span class="koboSpan" id="kobo.709.1">)  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.710.1"># Create unique IDs from the row indices</span></span>
<span class="hljs-comment"><span class="koboSpan" id="kobo.711.1"># Create documents (extract relevant text for each image's labels)</span></span><span class="koboSpan" id="kobo.712.1">
documents = []
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.713.1">for</span></span><span class="koboSpan" id="kobo.714.1"> _, row </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.715.1">in</span></span><span class="koboSpan" id="kobo.716.1"> df.iterrows():
    text_labels = row[</span><span class="hljs-string"><span class="koboSpan" id="kobo.717.1">'labels'</span></span><span class="koboSpan" id="kobo.718.1">] </span><span class="hljs-comment"><span class="koboSpan" id="kobo.719.1"># Each label is now a string</span></span><span class="koboSpan" id="kobo.720.1">
    text = </span><span class="hljs-string"><span class="koboSpan" id="kobo.721.1">" "</span></span><span class="koboSpan" id="kobo.722.1">.join(text_labels) </span><span class="hljs-comment"><span class="koboSpan" id="kobo.723.1"># Join text labels into a single string</span></span><span class="koboSpan" id="kobo.724.1">
    document = Document(text=text, doc_id=row[</span><span class="hljs-string"><span class="koboSpan" id="kobo.725.1">'doc_id'</span></span><span class="koboSpan" id="kobo.726.1">])
    documents.append(document)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.727.1">The documents are now ready</span><a id="_idIndexMarker288"/><span class="koboSpan" id="kobo.728.1"> to be indexed with </span><code class="inlineCode"><span class="koboSpan" id="kobo.729.1">GPTVectorStoreIndex</span></code><span class="koboSpan" id="kobo.730.1">:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.731.1">from</span></span><span class="koboSpan" id="kobo.732.1"> llama_index.core </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.733.1">import</span></span><span class="koboSpan" id="kobo.734.1"> GPTVectorStoreIndex
vector_store_index = GPTVectorStoreIndex.from_documents(documents)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.735.1">The dataset is then</span><a id="_idIndexMarker289"/><span class="koboSpan" id="kobo.736.1"> seamlessly equipped with indices that we can visualize in the index dictionary:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.737.1">vector_store_index.index_struct
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.738.1">The output shows that an index has now been added to the dataset:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.739.1">IndexDict(index_id='4ec313b4-9a1a-41df-a3d8-a4fe5ff6022c', summary=None, nodes_dict={'5e547c1d-0d65-4de6-b33e-a101665751e6': '5e547c1d-0d65-4de6-b33e-a101665751e6', '05f73182-37ed-4567-a855-4ff9e8ae5b8c': '05f73182-37ed-4567-a855-4ff9e8ae5b8c'
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.740.1">We can now run a query on the multimodal dataset.</span></p>
    <h3 id="_idParaDest-112" class="heading-3"><span class="koboSpan" id="kobo.741.1">Running a query on the VisDrone multimodal dataset</span></h3>
    <p class="normal"><span class="koboSpan" id="kobo.742.1">We now set </span><code class="inlineCode"><span class="koboSpan" id="kobo.743.1">vector_store_index</span></code><span class="koboSpan" id="kobo.744.1"> as the</span><a id="_idIndexMarker290"/><span class="koboSpan" id="kobo.745.1"> query engine, as we did in the </span><em class="italic"><span class="koboSpan" id="kobo.746.1">Vector store index query engine</span></em><span class="koboSpan" id="kobo.747.1"> section in </span><em class="chapterRef"><span class="koboSpan" id="kobo.748.1">Chapter 3</span></em><span class="koboSpan" id="kobo.749.1">:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.750.1">vector_query_engine = vector_store_index.as_query_engine(similarity_top_k=</span><span class="hljs-number"><span class="koboSpan" id="kobo.751.1">1</span></span><span class="koboSpan" id="kobo.752.1">, temperature=</span><span class="hljs-number"><span class="koboSpan" id="kobo.753.1">0.1</span></span><span class="koboSpan" id="kobo.754.1">, num_output=</span><span class="hljs-number"><span class="koboSpan" id="kobo.755.1">1024</span></span><span class="koboSpan" id="kobo.756.1">)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.757.1">We can also run a query on the dataset of drone images, just as we did in </span><em class="chapterRef"><span class="koboSpan" id="kobo.758.1">Chapter 3</span></em><span class="koboSpan" id="kobo.759.1"> on an LLM dataset:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.760.1">import</span></span><span class="koboSpan" id="kobo.761.1"> time
start_time = time.time()
response = vector_query_engine.query(user_input)
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.762.1"># Stop the timer</span></span><span class="koboSpan" id="kobo.763.1">
end_time = time.time()
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.764.1"># Calculate and print the execution time</span></span><span class="koboSpan" id="kobo.765.1">
elapsed_time = end_time - start_time
</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.766.1">print</span></span><span class="koboSpan" id="kobo.767.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.768.1">f"Query execution time: </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.769.1">{elapsed_time:</span></span><span class="hljs-number"><span class="koboSpan" id="kobo.770.1">.4</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.771.1">f}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.772.1"> seconds"</span></span><span class="koboSpan" id="kobo.773.1">)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.774.1">The execution time is satisfactory:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.775.1">Query execution time: 1.8461 seconds
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.776.1">We will now examine the text response:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-built_in"><span class="koboSpan" id="kobo.777.1">print</span></span><span class="koboSpan" id="kobo.778.1">(textwrap.fill(</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.779.1">str</span></span><span class="koboSpan" id="kobo.780.1">(response), </span><span class="hljs-number"><span class="koboSpan" id="kobo.781.1">100</span></span><span class="koboSpan" id="kobo.782.1">))
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.783.1">We can see that the output is logical and therefore satisfactory.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.784.1">Drones use various</span><a id="_idIndexMarker291"/><span class="koboSpan" id="kobo.785.1"> sensors such as cameras, LiDAR, and GPS to identify and track objects like trucks.</span></p>
    <h3 id="_idParaDest-113" class="heading-3"><span class="koboSpan" id="kobo.786.1">Processing the response</span></h3>
    <p class="normal"><span class="koboSpan" id="kobo.787.1">We will now parse the</span><a id="_idIndexMarker292"/><span class="koboSpan" id="kobo.788.1"> nodes in the response to find the unique words in the response and select one for this notebook:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.789.1">from</span></span><span class="koboSpan" id="kobo.790.1"> itertools </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.791.1">import</span></span><span class="koboSpan" id="kobo.792.1"> groupby
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.793.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.794.1">get_unique_words</span></span><span class="koboSpan" id="kobo.795.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.796.1">text</span></span><span class="koboSpan" id="kobo.797.1">):
    text = text.lower().strip()
    words = text.split()
    unique_words = [word </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.798.1">for</span></span><span class="koboSpan" id="kobo.799.1"> word, _ </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.800.1">in</span></span><span class="koboSpan" id="kobo.801.1"> groupby(</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.802.1">sorted</span></span><span class="koboSpan" id="kobo.803.1">(words))]
    </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.804.1">return</span></span><span class="koboSpan" id="kobo.805.1"> unique_words
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.806.1">for</span></span><span class="koboSpan" id="kobo.807.1"> node </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.808.1">in</span></span><span class="koboSpan" id="kobo.809.1"> response.source_nodes:
    </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.810.1">print</span></span><span class="koboSpan" id="kobo.811.1">(node.node_id)
    </span><span class="hljs-comment"><span class="koboSpan" id="kobo.812.1"># Get unique words from the node text:</span></span><span class="koboSpan" id="kobo.813.1">
    node_text = node.get_text()
    unique_words = get_unique_words(node_text)
    </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.814.1">print</span></span><span class="koboSpan" id="kobo.815.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.816.1">"Unique Words in Node Text:"</span></span><span class="koboSpan" id="kobo.817.1">, unique_words)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.818.1">We found a unique word (</span><code class="inlineCode"><span class="koboSpan" id="kobo.819.1">'truck'</span></code><span class="koboSpan" id="kobo.820.1">) and its unique index, which will lead us directly to the image of the source of the node that generated the response:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.821.1">1af106df-c5a6-4f48-ac17-f953dffd2402
Unique Words in Node Text: ['truck']
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.822.1">We could select more words and design this function in many different ways depending on the specifications </span><a id="_idIndexMarker293"/><span class="koboSpan" id="kobo.823.1">of each project.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.824.1">We will now search for the image by going through the source nodes, just as we did for an LLM dataset in the </span><em class="italic"><span class="koboSpan" id="kobo.825.1">Query response and source</span></em><span class="koboSpan" id="kobo.826.1"> section of the previous chapter. </span><span class="koboSpan" id="kobo.826.2">Multimodal vector stores and querying frameworks are flexible. </span><span class="koboSpan" id="kobo.826.3">Once we learn how to perform retrievals on an LLM and a multimodal dataset, we are ready for anything that comes up!</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.827.1">Let’s select and process the information related to an image.</span></p>
    <h3 id="_idParaDest-114" class="heading-3"><span class="koboSpan" id="kobo.828.1">Selecting and processing the image of the source node</span></h3>
    <p class="normal"><span class="koboSpan" id="kobo.829.1">Before running</span><a id="_idIndexMarker294"/><span class="koboSpan" id="kobo.830.1"> the image retrieval and displaying function, let’s first delete the image we displayed in the </span><em class="italic"><span class="koboSpan" id="kobo.831.1">Adding bounding boxes and saving the image</span></em><span class="koboSpan" id="kobo.832.1"> section of this notebook to make sure we are working on a new image:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.833.1"># deleting any image previously saved</span></span><span class="koboSpan" id="kobo.834.1">
!rm /content/boxed_image.jpg
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.835.1">We are now ready to search for the source image, call the bounding box, and display and save the function we defined earlier:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.836.1">display_image_with_bboxes(image_data, bboxes, labels, label_name=ibox)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.837.1">The program now goes through the source nodes with the keyword </span><code class="inlineCode"><span class="koboSpan" id="kobo.838.1">"truck"</span></code><span class="koboSpan" id="kobo.839.1"> search, applies the bounding boxes, and displays and saves the image:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.840.1">import</span></span><span class="koboSpan" id="kobo.841.1"> io
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.842.1">from</span></span><span class="koboSpan" id="kobo.843.1"> PIL </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.844.1">import</span></span><span class="koboSpan" id="kobo.845.1"> Image
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.846.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.847.1">process_and_display</span></span><span class="koboSpan" id="kobo.848.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.849.1">response, df, ds, unique_words</span></span><span class="koboSpan" id="kobo.850.1">):
    </span><span class="hljs-string"><span class="koboSpan" id="kobo.851.1">"""Processes nodes, finds corresponding images in dataset, and displays them with bounding boxes.</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.852.1">    Args:</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.853.1">        response: The response object containing source nodes.</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.854.1">        df: The DataFrame with doc_id information.</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.855.1">        ds: The dataset containing images, labels, and boxes.</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.856.1">        unique_words: The list of unique words for filtering.</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.857.1">    """</span></span><span class="koboSpan" id="kobo.858.1">
…
            </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.859.1">if</span></span><span class="koboSpan" id="kobo.860.1"> i == row_index:
                image_bytes = io.BytesIO(sample.images.tobytes())
                img = Image.</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.861.1">open</span></span><span class="koboSpan" id="kobo.862.1">(image_bytes)
                labels = ds.labels[i].data()[</span><span class="hljs-string"><span class="koboSpan" id="kobo.863.1">'value'</span></span><span class="koboSpan" id="kobo.864.1">]
                image_data = ds.images[i].tobytes()
                bboxes = ds.boxes[i].numpy()
                ibox = unique_words[</span><span class="hljs-number"><span class="koboSpan" id="kobo.865.1">0</span></span><span class="koboSpan" id="kobo.866.1">]  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.867.1"># class in image</span></span><span class="koboSpan" id="kobo.868.1">
                display_image_with_bboxes(image_data, bboxes, labels, label_name=ibox)
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.869.1"># Assuming you have your 'response', 'df', 'ds', and 'unique_words' objects prepared:</span></span><span class="koboSpan" id="kobo.870.1">
process_and_display(response, df, ds, unique_words)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.871.1">The output is</span><a id="_idIndexMarker295"/><span class="koboSpan" id="kobo.872.1"> satisfactory:</span></p>
    <figure class="mediaobject"><span class="koboSpan" id="kobo.873.1"><img src="../Images/B31169_04_07.png" alt="An aerial view of a factory  Description automatically generated"/></span></figure>
    <p class="packt_figref"><span class="koboSpan" id="kobo.874.1">Figure 4.7: Displayed satisfactory output</span></p>
    <h2 id="_idParaDest-115" class="heading-2"><span class="koboSpan" id="kobo.875.1">Multimodal modular summary</span></h2>
    <p class="normal"><span class="koboSpan" id="kobo.876.1">We have built a multimodal modular program step by step that we can now assemble in a summary. </span><span class="koboSpan" id="kobo.876.2">We will create a </span><a id="_idIndexMarker296"/><span class="koboSpan" id="kobo.877.1">function to display the source image of the response to the user input, then print the user input and the LLM output, and display the image.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.878.1">First, we create a function to display the source image saved by the multimodal retrieval engine:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.879.1"># 1.user input=user_input</span></span>
<span class="hljs-built_in"><span class="koboSpan" id="kobo.880.1">print</span></span><span class="koboSpan" id="kobo.881.1">(user_input)
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.882.1"># 2.LLM response</span></span>
<span class="hljs-built_in"><span class="koboSpan" id="kobo.883.1">print</span></span><span class="koboSpan" id="kobo.884.1">(textwrap.fill(</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.885.1">str</span></span><span class="koboSpan" id="kobo.886.1">(llm_response), </span><span class="hljs-number"><span class="koboSpan" id="kobo.887.1">100</span></span><span class="koboSpan" id="kobo.888.1">))
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.889.1"># 3.Multimodal response</span></span><span class="koboSpan" id="kobo.890.1">
image_path = </span><span class="hljs-string"><span class="koboSpan" id="kobo.891.1">"/content/boxed_image.jpg"</span></span><span class="koboSpan" id="kobo.892.1">
display_source_image(image_path)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.893.1">Then, we can display the user input, the LLM response, and the multimodal response. </span><span class="koboSpan" id="kobo.893.2">The output first displays</span><a id="_idIndexMarker297"/><span class="koboSpan" id="kobo.894.1"> the textual responses (user input and LLM response):</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.895.1">How do drones identify a truck?
</span><span class="koboSpan" id="kobo.895.2">Drones can identify a truck using visual detection and tracking methods, which may involve deep neural networks for performance benchmarking.
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.896.1">Then, the image is displayed with the bounding boxes for trucks in this case:</span></p>
    <figure class="mediaobject"><span class="koboSpan" id="kobo.897.1"><img src="../Images/B31169_04_08.png" alt="An aerial view of a factory  Description automatically generated"/></span></figure>
    <p class="packt_figref"><span class="koboSpan" id="kobo.898.1">Figure 4.8: Output displaying boundary boxes</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.899.1">By adding an image to a </span><a id="_idIndexMarker298"/><span class="koboSpan" id="kobo.900.1">classical LLM response, we augmented the output. </span><span class="koboSpan" id="kobo.900.2">Multimodal RAG output augmentation will enrich generative AI by adding information to both the input and output. </span><span class="koboSpan" id="kobo.900.3">However, as for all AI programs, designing a performance metric requires efficient image recognition functionality.</span></p>
    <h2 id="_idParaDest-116" class="heading-2"><span class="koboSpan" id="kobo.901.1">Performance metric</span></h2>
    <p class="normal"><span class="koboSpan" id="kobo.902.1">Measuring the performance of a multimodal modular RAG requires two types of measurements: text and image. </span><span class="koboSpan" id="kobo.902.2">Measuring</span><a id="_idIndexMarker299"/><span class="koboSpan" id="kobo.903.1"> text is straightforward. </span><span class="koboSpan" id="kobo.903.2">However, measuring images is quite a challenge. </span><span class="koboSpan" id="kobo.903.3">Analyzing the image of </span><a id="_idIndexMarker300"/><span class="koboSpan" id="kobo.904.1">a multimodal response is quite different. </span><span class="koboSpan" id="kobo.904.2">We extracted a keyword from the multimodal query </span><a id="_idIndexMarker301"/><span class="koboSpan" id="kobo.905.1">engine. </span><span class="koboSpan" id="kobo.905.2">We then parsed the response for a source image to display. </span><span class="koboSpan" id="kobo.905.3">However, we will need to build an innovative approach to evaluate the source image of the response. </span><span class="koboSpan" id="kobo.905.4">Let’s begin with the LLM performance.</span></p>
    <h3 id="_idParaDest-117" class="heading-3"><span class="koboSpan" id="kobo.906.1">LLM performance metric</span></h3>
    <p class="normal"><span class="koboSpan" id="kobo.907.1">LlamaIndex seamlessly called an OpenAI model through its query engine, such as GPT-4, for example, and provided text content in its response. </span><span class="koboSpan" id="kobo.907.2">For text responses, we will use the same cosine similarity</span><a id="_idIndexMarker302"/><span class="koboSpan" id="kobo.908.1"> metric as in the </span><em class="italic"><span class="koboSpan" id="kobo.909.1">Evaluating the output with cosine similarity</span></em><span class="koboSpan" id="kobo.910.1"> section in </span><em class="chapterRef"><span class="koboSpan" id="kobo.911.1">Chapter 2</span></em><span class="koboSpan" id="kobo.912.1">, and the </span><em class="italic"><span class="koboSpan" id="kobo.913.1">Vector store index query engine</span></em><span class="koboSpan" id="kobo.914.1"> section in </span><em class="chapterRef"><span class="koboSpan" id="kobo.915.1">Chapter 3</span></em><span class="koboSpan" id="kobo.916.1">.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.917.1">The evaluation function uses </span><code class="inlineCode"><span class="koboSpan" id="kobo.918.1">sklearn</span></code><span class="koboSpan" id="kobo.919.1"> and </span><code class="inlineCode"><span class="koboSpan" id="kobo.920.1">sentence_transformers</span></code><span class="koboSpan" id="kobo.921.1"> to evaluate the similarity between two texts—in this case, an input and an output:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.922.1">from</span></span><span class="koboSpan" id="kobo.923.1"> sklearn.feature_extraction.text </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.924.1">import</span></span><span class="koboSpan" id="kobo.925.1"> TfidfVectorizer
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.926.1">from</span></span><span class="koboSpan" id="kobo.927.1"> sklearn.metrics.pairwise </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.928.1">import</span></span><span class="koboSpan" id="kobo.929.1"> cosine_similarity
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.930.1">from</span></span><span class="koboSpan" id="kobo.931.1"> sentence_transformers </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.932.1">import</span></span><span class="koboSpan" id="kobo.933.1"> SentenceTransformer
model = SentenceTransformer(</span><span class="hljs-string"><span class="koboSpan" id="kobo.934.1">'all-MiniLM-L6-v2'</span></span><span class="koboSpan" id="kobo.935.1">)
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.936.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.937.1">calculate_cosine_similarity_with_embeddings</span></span><span class="koboSpan" id="kobo.938.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.939.1">text1, text2</span></span><span class="koboSpan" id="kobo.940.1">):
    embeddings1 = model.encode(text1)
    embeddings2 = model.encode(text2)
    similarity = cosine_similarity([embeddings1], [embeddings2])
    </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.941.1">return</span></span><span class="koboSpan" id="kobo.942.1"> similarity[</span><span class="hljs-number"><span class="koboSpan" id="kobo.943.1">0</span></span><span class="koboSpan" id="kobo.944.1">][</span><span class="hljs-number"><span class="koboSpan" id="kobo.945.1">0</span></span><span class="koboSpan" id="kobo.946.1">]
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.947.1">We can now calculate the similarity between our baseline user input and the initial LLM response obtained:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.948.1">llm_similarity_score = calculate_cosine_similarity_with_embeddings(user_input, </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.949.1">str</span></span><span class="koboSpan" id="kobo.950.1">(llm_response))
</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.951.1">print</span></span><span class="koboSpan" id="kobo.952.1">(user_input)
</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.953.1">print</span></span><span class="koboSpan" id="kobo.954.1">(llm_response)
</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.955.1">print</span></span><span class="koboSpan" id="kobo.956.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.957.1">f"Cosine Similarity Score: </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.958.1">{llm_similarity_score:</span></span><span class="hljs-number"><span class="koboSpan" id="kobo.959.1">.3</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.960.1">f}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.961.1">"</span></span><span class="koboSpan" id="kobo.962.1">)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.963.1">The output displays the user input, the text response, and the cosine similarity between the two texts:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.964.1">How do drones identify a truck?
</span><span class="koboSpan" id="kobo.964.2">How do drones identify a truck?
</span><span class="koboSpan" id="kobo.964.3">Drones can identify a truck using visual detection and tracking methods, which may involve deep neural networks for performance benchmarking.
</span><span class="koboSpan" id="kobo.964.4">Cosine Similarity Score: 0.691
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.965.1">The output is satisfactory. </span><span class="koboSpan" id="kobo.965.2">But we now need to design a way to measure the multimodal performance.</span></p>
    <h3 id="_idParaDest-118" class="heading-3"><span class="koboSpan" id="kobo.966.1">Multimodal performance metric</span></h3>
    <p class="normal"><span class="koboSpan" id="kobo.967.1">To evaluate the image returned, we cannot simply rely on the labels in the dataset. </span><span class="koboSpan" id="kobo.967.2">For small datasets, we can manually check the image, but when a system scales, automation is required. </span><span class="koboSpan" id="kobo.967.3">In this section, we will use the computer vision features of GPT-4o to analyze an image, parse it to find the</span><a id="_idIndexMarker303"/><span class="koboSpan" id="kobo.968.1"> objects we are looking for, and provide a description of that image. </span><span class="koboSpan" id="kobo.968.2">Then, we will apply cosine similarity to the description provided by GPT-4o and the label it is supposed to contain. </span><span class="koboSpan" id="kobo.968.3">GPT-4o is a multimodal generative AI model.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.969.1">Let’s first encode the image to simplify data transmission to GPT-4o. </span><span class="koboSpan" id="kobo.969.2">Base64 encoding converts binary data (like images) into ASCII characters, which are standard text characters. </span><span class="koboSpan" id="kobo.969.3">This transformation is crucial because it ensures that the image data can be transmitted over protocols (like HTTP) that are designed to handle text data smoothly. </span><span class="koboSpan" id="kobo.969.4">It also avoids issues related to binary data transmission, such as data corruption or interpretation errors.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.970.1">The program encodes the source image using Python’s </span><code class="inlineCode"><span class="koboSpan" id="kobo.971.1">base64</span></code><span class="koboSpan" id="kobo.972.1"> module:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.973.1">import</span></span><span class="koboSpan" id="kobo.974.1"> base64
IMAGE_PATH = </span><span class="hljs-string"><span class="koboSpan" id="kobo.975.1">"/content/boxed_image.jpg"</span></span>
<span class="hljs-comment"><span class="koboSpan" id="kobo.976.1"># Open the image file and encode it as a base64 string</span></span>
<span class="hljs-keyword"><span class="koboSpan" id="kobo.977.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.978.1">encode_image</span></span><span class="koboSpan" id="kobo.979.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.980.1">image_path</span></span><span class="koboSpan" id="kobo.981.1">):
    </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.982.1">with</span></span> <span class="hljs-built_in"><span class="koboSpan" id="kobo.983.1">open</span></span><span class="koboSpan" id="kobo.984.1">(image_path, </span><span class="hljs-string"><span class="koboSpan" id="kobo.985.1">"rb"</span></span><span class="koboSpan" id="kobo.986.1">) </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.987.1">as</span></span><span class="koboSpan" id="kobo.988.1"> image_file:
        </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.989.1">return</span></span><span class="koboSpan" id="kobo.990.1"> base64.b64encode(image_file.read()).decode(</span><span class="hljs-string"><span class="koboSpan" id="kobo.991.1">"</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.992.1">utf-8"</span></span><span class="koboSpan" id="kobo.993.1">)
base64_image = encode_image(IMAGE_PATH)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.994.1">We now create an OpenAI client and set the model to </span><code class="inlineCode"><span class="koboSpan" id="kobo.995.1">gpt-4o</span></code><span class="koboSpan" id="kobo.996.1">:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.997.1">from</span></span><span class="koboSpan" id="kobo.998.1"> openai </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.999.1">import</span></span><span class="koboSpan" id="kobo.1000.1"> OpenAI
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.1001.1">#Set the API key for the client</span></span><span class="koboSpan" id="kobo.1002.1">
client = OpenAI(api_key=openai.api_key)
MODEL=</span><span class="hljs-string"><span class="koboSpan" id="kobo.1003.1">"gpt-4o"</span></span>
</code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.1004.1">The unique word will be the result of the LLM query to the multimodal dataset we obtained by parsing the response:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.1005.1">u_word=unique_words[</span><span class="hljs-number"><span class="koboSpan" id="kobo.1006.1">0</span></span><span class="koboSpan" id="kobo.1007.1">]
</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.1008.1">print</span></span><span class="koboSpan" id="kobo.1009.1">(u_word)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.1010.1">We can now submit the image to OpenAI GPT-4o:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.1011.1">response = client.chat.completions.create(
    model=MODEL,
    messages=[
        {</span><span class="hljs-string"><span class="koboSpan" id="kobo.1012.1">"</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.1013.1">role"</span></span><span class="koboSpan" id="kobo.1014.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.1015.1">"system"</span></span><span class="koboSpan" id="kobo.1016.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.1017.1">"content"</span></span><span class="koboSpan" id="kobo.1018.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.1019.1">f"You are a helpful assistant that analyzes images that contain </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.1020.1">{u_word}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.1021.1">."</span></span><span class="koboSpan" id="kobo.1022.1">},
        {</span><span class="hljs-string"><span class="koboSpan" id="kobo.1023.1">"role"</span></span><span class="koboSpan" id="kobo.1024.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.1025.1">"user"</span></span><span class="koboSpan" id="kobo.1026.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.1027.1">"content"</span></span><span class="koboSpan" id="kobo.1028.1">: [
            {</span><span class="hljs-string"><span class="koboSpan" id="kobo.1029.1">"type"</span></span><span class="koboSpan" id="kobo.1030.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.1031.1">"text"</span></span><span class="koboSpan" id="kobo.1032.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.1033.1">"</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.1034.1">text"</span></span><span class="koboSpan" id="kobo.1035.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.1036.1">f"Analyze the following image, tell me if there is one </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.1037.1">{u_word}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.1038.1"> or more in the bounding boxes and analyze them:"</span></span><span class="koboSpan" id="kobo.1039.1">},
            {</span><span class="hljs-string"><span class="koboSpan" id="kobo.1040.1">"type"</span></span><span class="koboSpan" id="kobo.1041.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.1042.1">"image_url"</span></span><span class="koboSpan" id="kobo.1043.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.1044.1">"image_url"</span></span><span class="koboSpan" id="kobo.1045.1">: {
                </span><span class="hljs-string"><span class="koboSpan" id="kobo.1046.1">"url"</span></span><span class="koboSpan" id="kobo.1047.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.1048.1">f"data:image/png;base64,</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.1049.1">{base64_image}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.1050.1">"</span></span><span class="koboSpan" id="kobo.1051.1">}
            }
        ]}
    ],
    temperature=</span><span class="hljs-number"><span class="koboSpan" id="kobo.1052.1">0.0</span></span><span class="koboSpan" id="kobo.1053.1">,
)
response_image = response.choices[</span><span class="hljs-number"><span class="koboSpan" id="kobo.1054.1">0</span></span><span class="koboSpan" id="kobo.1055.1">].message.content
</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.1056.1">print</span></span><span class="koboSpan" id="kobo.1057.1">(response_image)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.1058.1">We instructed the </span><code class="inlineCode"><span class="koboSpan" id="kobo.1059.1">system</span></code><span class="koboSpan" id="kobo.1060.1"> and </span><code class="inlineCode"><span class="koboSpan" id="kobo.1061.1">user</span></code><span class="koboSpan" id="kobo.1062.1"> roles to analyze images looking for our target label, </span><code class="inlineCode"><span class="koboSpan" id="kobo.1063.1">u_word</span></code><span class="koboSpan" id="kobo.1064.1">—in this case, </span><code class="inlineCode"><span class="koboSpan" id="kobo.1065.1">truck</span></code><span class="koboSpan" id="kobo.1066.1">. </span><span class="koboSpan" id="kobo.1066.2">We</span><a id="_idIndexMarker304"/><span class="koboSpan" id="kobo.1067.1"> then submitted the source node image to the model. </span><span class="koboSpan" id="kobo.1067.2">The output that describes the image is satisfactory:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.1068.1">The image contains two trucks within the bounding boxes. </span><span class="koboSpan" id="kobo.1068.2">Here is the analysis of each truck:
1. </span><span class="koboSpan" id="kobo.1068.3">**First Truck (Top Bounding Box)**:
   - The truck appears to be a flatbed truck.
   </span><span class="koboSpan" id="kobo.1068.4">- It is loaded with various materials, possibly construction or industrial supplies.
   </span><span class="koboSpan" id="kobo.1068.5">- The truck is parked in an area with other construction materials and equipment.
</span><span class="koboSpan" id="kobo.1068.6">2. </span><span class="koboSpan" id="kobo.1068.7">**Second Truck (Bottom Bounding Box)**:
   - This truck also appears to be a flatbed truck.
   </span><span class="koboSpan" id="kobo.1068.8">- It is carrying different types of materials, similar to the first truck.
   </span><span class="koboSpan" id="kobo.1068.9">- The truck is situated in a similar environment, surrounded by construction materials and equipment.
</span><span class="koboSpan" id="kobo.1068.10">Both trucks are in a construction or industrial area, likely used for transporting materials and equipment.
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.1069.1">We can now submit this response to the cosine similarity function by first adding an </span><code class="inlineCode"><span class="koboSpan" id="kobo.1070.1">"s"</span></code><span class="koboSpan" id="kobo.1071.1"> to align with multiple </span><a id="_idIndexMarker305"/><span class="koboSpan" id="kobo.1072.1">trucks in a response:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.1073.1">resp=u_word+</span><span class="hljs-string"><span class="koboSpan" id="kobo.1074.1">"s"</span></span><span class="koboSpan" id="kobo.1075.1">
multimodal_similarity_score = calculate_cosine_similarity_with_embeddings(resp, </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.1076.1">str</span></span><span class="koboSpan" id="kobo.1077.1">(response_image))
</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.1078.1">print</span></span><span class="koboSpan" id="kobo.1079.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.1080.1">f"Cosine Similarity Score: </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.1081.1">{multimodal_similarity_score:</span></span><span class="hljs-number"><span class="koboSpan" id="kobo.1082.1">.3</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.1083.1">f}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.1084.1">"</span></span><span class="koboSpan" id="kobo.1085.1">)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.1086.1">The output describes the image well but contains many other descriptions beyond the word “</span><code class="inlineCode"><span class="koboSpan" id="kobo.1087.1">truck</span></code><span class="koboSpan" id="kobo.1088.1">,” which limits its similarity to the input requested:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.1089.1">Cosine Similarity Score: 0.505
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.1090.1">A human observer might approve the image and the LLM response. </span><span class="koboSpan" id="kobo.1090.2">However, even if the score was very high, the issue would be the same. </span><span class="koboSpan" id="kobo.1090.3">Complex images are challenging to analyze in detail and with precision, although progress is continually made. </span><span class="koboSpan" id="kobo.1090.4">Let’s now calculate the overall performance of the system.</span></p>
    <h3 id="_idParaDest-119" class="heading-3"><span class="koboSpan" id="kobo.1091.1">Multimodal modular RAG performance metric</span></h3>
    <p class="normal"><span class="koboSpan" id="kobo.1092.1">To obtain the overall performance</span><a id="_idIndexMarker306"/><span class="koboSpan" id="kobo.1093.1"> of the system, we will divide the sum of the LLM response and the two multimodal response performances by </span><code class="inlineCode"><span class="koboSpan" id="kobo.1094.1">2</span></code><span class="koboSpan" id="kobo.1095.1">:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.1096.1">score=(llm_similarity_score+multimodal_similarity_score)/</span><span class="hljs-number"><span class="koboSpan" id="kobo.1097.1">2</span></span>
<span class="hljs-built_in"><span class="koboSpan" id="kobo.1098.1">print</span></span><span class="koboSpan" id="kobo.1099.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.1100.1">f"Multimodal, Modular Score: </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.1101.1">{score:</span></span><span class="hljs-number"><span class="koboSpan" id="kobo.1102.1">.3</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.1103.1">f}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.1104.1">"</span></span><span class="koboSpan" id="kobo.1105.1">)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.1106.1">The result shows that although a human who observes the results may be satisfied, it remains difficult to automatically assess the relevance of a complex image:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.1107.1">Multimodal, Modular Score: 0.598
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.1108.1">The metric can be improved because a human observer sees that the image is relevant. </span><span class="koboSpan" id="kobo.1108.2">This explains why the top AI agents, such as ChatGPT, Gemini, and Bing Copilot, always have a feedback process that includes thumbs up and thumbs down.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.1109.1">Let’s now sum up the chapter and gear up to explore how RAG can be improved even further with human feedback.</span></p>
    <h1 id="_idParaDest-120" class="heading-1"><span class="koboSpan" id="kobo.1110.1">Summary</span></h1>
    <p class="normal"><span class="koboSpan" id="kobo.1111.1">This chapter introduced us to the world of multimodal modular RAG, which uses distinct modules for different data types (text and image) and tasks. </span><span class="koboSpan" id="kobo.1111.2">We leveraged the functionality of LlamaIndex, Deep Lake, and OpenAI, which we explored in the previous chapters. </span><span class="koboSpan" id="kobo.1111.3">The Deep Lake VisDrone dataset further introduced us to drone technology for analyzing images and identifying objects. </span><span class="koboSpan" id="kobo.1111.4">The dataset contained images, labels, and bounding box information. </span><span class="koboSpan" id="kobo.1111.5">Working on drone technology involves multimodal data, encouraging us to develop skills that we can use across many domains, such as wildlife tracking, streamlining commercial deliveries, and making safer infrastructure inspections.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.1112.1">We built a multimodal modular RAG-driven generative AI system. </span><span class="koboSpan" id="kobo.1112.2">The first step was to define a baseline user query for both LLM and multimodal queries. </span><span class="koboSpan" id="kobo.1112.3">We began by querying the Deep Lake textual dataset that we implemented in </span><em class="italic"><span class="koboSpan" id="kobo.1113.1">Chapter 3</span></em><span class="koboSpan" id="kobo.1114.1">. </span><span class="koboSpan" id="kobo.1114.2">LlamaIndex seamlessly ran a query engine to retrieve, augment, and generate a response. </span><span class="koboSpan" id="kobo.1114.3">Then, we loaded the Deep Lake VisDrone dataset and indexed it in memory with LlamaIndex to create an indexed vector search retrieval pipeline. </span><span class="koboSpan" id="kobo.1114.4">We queried it through LlamaIndex, which used an OpenAI model such as GPT-4 and parsed the text generated for a keyword. </span><span class="koboSpan" id="kobo.1114.5">Finally, we searched the source nodes of the response to find the source image, display it, and merge the LLM and image responses into an augmented output. </span><span class="koboSpan" id="kobo.1114.6">We applied cosine similarity to the text response. </span><span class="koboSpan" id="kobo.1114.7">Evaluating the image was challenging, so we first ran image recognition with GPT-4o on the image retrieved to obtain a text to which we applied cosine similarity.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.1115.1">The journey into multimodal modular RAG-driven generative AI took us deep into the cutting edge of AI. </span><span class="koboSpan" id="kobo.1115.2">Building a complex system was good preparation for real-life AI projects, which often require implementing multisource, multimodal, and unstructured data, leading to modular, complex systems. </span><span class="koboSpan" id="kobo.1115.3">Thanks to transparent access to the source of a response, the complexity of RAG can be harnessed, controlled, and improved. </span><span class="koboSpan" id="kobo.1115.4">We will see how we can leverage the transparency of the sources of a response to introduce human feedback to improve AI. </span><span class="koboSpan" id="kobo.1115.5">The next chapter will take us further into transparency and precision in AI.</span></p>
    <h1 id="_idParaDest-121" class="heading-1"><span class="koboSpan" id="kobo.1116.1">Questions</span></h1>
    <p class="normal"><span class="koboSpan" id="kobo.1117.1">Answer the following questions with </span><em class="italic"><span class="koboSpan" id="kobo.1118.1">Yes</span></em><span class="koboSpan" id="kobo.1119.1"> or </span><em class="italic"><span class="koboSpan" id="kobo.1120.1">No</span></em><span class="koboSpan" id="kobo.1121.1">:</span></p>
    <ol>
      <li class="numberedList" value="1"><span class="koboSpan" id="kobo.1122.1">Does multimodal modular RAG handle different types of data, such as text and images? </span></li>
      <li class="numberedList"><span class="koboSpan" id="kobo.1123.1">Are drones used solely for agricultural monitoring and aerial photography? </span></li>
      <li class="numberedList"><span class="koboSpan" id="kobo.1124.1">Is the Deep Lake VisDrone dataset used in this chapter for textual data only? </span></li>
      <li class="numberedList"><span class="koboSpan" id="kobo.1125.1">Can bounding boxes be added to drone images to identify objects such as trucks and pedestrians? </span></li>
      <li class="numberedList"><span class="koboSpan" id="kobo.1126.1">Does the modular system retrieve both text and image data for query responses? </span></li>
      <li class="numberedList"><span class="koboSpan" id="kobo.1127.1">Is building a vector index necessary for querying the multimodal VisDrone dataset? </span></li>
      <li class="numberedList"><span class="koboSpan" id="kobo.1128.1">Are the retrieved images processed without adding any labels or bounding boxes? </span></li>
      <li class="numberedList"><span class="koboSpan" id="kobo.1129.1">Is the multimodal modular RAG performance metric based only on textual responses? </span></li>
      <li class="numberedList"><span class="koboSpan" id="kobo.1130.1">Can a multimodal system such as the one described in this chapter handle only drone-related data? </span></li>
      <li class="numberedList"><span class="koboSpan" id="kobo.1131.1">Is evaluating images as easy as evaluating text in multimodal RAG?</span></li>
    </ol>
    <h1 id="_idParaDest-122" class="heading-1"><span class="koboSpan" id="kobo.1132.1">References</span></h1>
    <ul>
      <li class="bulletList"><span class="koboSpan" id="kobo.1133.1">LlamaIndex: </span><a href="https://docs.llamaindex.ai/en/stable/"><span class="url"><span class="koboSpan" id="kobo.1134.1">https://docs.llamaindex.ai/en/stable/</span></span></a></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.1135.1">Activeloop Deep Lake: </span><a href="https://docs.activeloop.ai/"><span class="url"><span class="koboSpan" id="kobo.1136.1">https://docs.activeloop.ai/</span></span></a></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.1137.1">OpenAI: </span><a href="https://platform.openai.com/docs/overview"><span class="url"><span class="koboSpan" id="kobo.1138.1">https://platform.openai.com/docs/overview</span></span></a></li>
    </ul>
    <h1 id="_idParaDest-123" class="heading-1"><span class="koboSpan" id="kobo.1139.1">Further reading</span></h1>
    <ul>
      <li class="bulletList"><span class="koboSpan" id="kobo.1140.1">Retrieval-Augmented Multimodal Language Modeling, Yasunaga et al. </span><span class="koboSpan" id="kobo.1140.2">(2023), </span><a href="https://arxiv.org/pdf/2211.12561"><span class="url"><span class="koboSpan" id="kobo.1141.1">https://arxiv.org/pdf/2211.12561</span></span></a></li>
    </ul>
    <h1 id="_idParaDest-124" class="heading-1"><span class="koboSpan" id="kobo.1142.1">Join our community on Discord</span></h1>
    <p class="normal"><span class="koboSpan" id="kobo.1143.1">Join our community’s Discord space for discussions with the author and other readers:</span></p>
    <p class="normal"><a href="https://www.packt.link/rag"><span class="url"><span class="koboSpan" id="kobo.1144.1">https://www.packt.link/rag</span></span></a></p>
    <p class="normal"><span class="koboSpan" id="kobo.1145.1"><img src="../Images/QR_Code50409000288080484.png" alt=""/></span></p>
  </div>
</body></html>