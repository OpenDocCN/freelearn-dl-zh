<html><head></head><body>
<div id="_idContainer024">
<h1 class="chapter-number" id="_idParaDest-15"><a id="_idTextAnchor014"/><span class="koboSpan" id="kobo.1.1">1</span></h1>
<h1 id="_idParaDest-16"><a id="_idTextAnchor015"/><span class="koboSpan" id="kobo.2.1">Exploring Amazon Bedrock</span></h1>
<p><span class="koboSpan" id="kobo.3.1">People across the globe have been amazed by the potential of generative AI, and industries across the globe are looking to innovate in their organizations and solve business use cases through </span><span class="No-Break"><span class="koboSpan" id="kobo.4.1">generative AI.</span></span></p>
<p><span class="koboSpan" id="kobo.5.1">This chapter will introduce you to a powerful generative AI service known as </span><strong class="bold"><span class="koboSpan" id="kobo.6.1">Amazon Bedrock</span></strong><span class="koboSpan" id="kobo.7.1">. </span><span class="koboSpan" id="kobo.7.2">We’ll begin</span><a id="_idIndexMarker000"/><span class="koboSpan" id="kobo.8.1"> by providing an overview of the generative AI landscape. </span><span class="koboSpan" id="kobo.8.2">Then, we’ll examine the challenges industries face with generative AI and how Amazon Bedrock addresses those challenges effectively. </span><span class="koboSpan" id="kobo.8.3">After, we’ll explore the </span><a id="_idIndexMarker001"/><span class="koboSpan" id="kobo.9.1">various </span><strong class="bold"><span class="koboSpan" id="kobo.10.1">foundation models</span></strong><span class="koboSpan" id="kobo.11.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.12.1">FMs</span></strong><span class="koboSpan" id="kobo.13.1">) that are currently offered by Amazon Bedrock and help you assess which model is suitable for specific scenarios. </span><span class="koboSpan" id="kobo.13.2">Additionally, we’ll cover some of Amazon’s additional generative AI capabilities beyond FMs. </span><span class="koboSpan" id="kobo.13.3">By the end of this chapter, you will have a solid understanding of Amazon Bedrock’s generative AI offerings, model selection criteria, and the broader generative AI capabilities available </span><span class="No-Break"><span class="koboSpan" id="kobo.14.1">from Amazon.</span></span></p>
<p><span class="koboSpan" id="kobo.15.1">The following topics will be covered in </span><span class="No-Break"><span class="koboSpan" id="kobo.16.1">the chapter:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.17.1">Understanding the generative </span><span class="No-Break"><span class="koboSpan" id="kobo.18.1">AI landscape</span></span></li>
<li><span class="koboSpan" id="kobo.19.1">What </span><span class="No-Break"><span class="koboSpan" id="kobo.20.1">are FMs?</span></span></li>
<li><span class="koboSpan" id="kobo.21.1">What is </span><span class="No-Break"><span class="koboSpan" id="kobo.22.1">Amazon Bedrock?</span></span></li>
<li><span class="koboSpan" id="kobo.23.1">FMs in </span><span class="No-Break"><span class="koboSpan" id="kobo.24.1">Amazon Bedrock</span></span></li>
<li><span class="koboSpan" id="kobo.25.1">Evaluating and selecting the </span><span class="No-Break"><span class="koboSpan" id="kobo.26.1">right FM</span></span></li>
<li><span class="koboSpan" id="kobo.27.1">Generative AI capabilities </span><span class="No-Break"><span class="koboSpan" id="kobo.28.1">of Amazon</span></span></li>
<li><span class="koboSpan" id="kobo.29.1">Generative AI use cases with </span><span class="No-Break"><span class="koboSpan" id="kobo.30.1">Amazon Bedrock</span></span></li>
</ul>
<h1 id="_idParaDest-17"><a id="_idTextAnchor016"/><span class="koboSpan" id="kobo.31.1">Understanding the generative AI landscape</span></h1>
<p><span class="koboSpan" id="kobo.32.1">Since the advent of </span><a id="_idIndexMarker002"/><span class="koboSpan" id="kobo.33.1">ChatGPT, organizations across the globe have explored a plethora of use cases that generative AI can solve for them. </span><span class="koboSpan" id="kobo.33.2">They have built several innovation teams and teams of data scientists to build and explore various use cases, including summarizing long documents, extracting information from documents, and performing sentiment analysis to gauge satisfaction or discontent toward a product or service. </span><span class="koboSpan" id="kobo.33.3">If you have been</span><a id="_idIndexMarker003"/><span class="koboSpan" id="kobo.34.1"> working in the </span><strong class="bold"><span class="koboSpan" id="kobo.35.1">machine learning</span></strong><span class="koboSpan" id="kobo.36.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.37.1">ML</span></strong><span class="koboSpan" id="kobo.38.1">) or </span><strong class="bold"><span class="koboSpan" id="kobo.39.1">natural language processing</span></strong><span class="koboSpan" id="kobo.40.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.41.1">NLP</span></strong><span class="koboSpan" id="kobo.42.1">) field, you may be familiar with how a language model</span><a id="_idIndexMarker004"/><span class="koboSpan" id="kobo.43.1"> works – by understanding the relationship between the words in documents. </span><span class="koboSpan" id="kobo.43.2">The main </span><a id="_idIndexMarker005"/><span class="koboSpan" id="kobo.44.1">objective of these </span><strong class="bold"><span class="koboSpan" id="kobo.45.1">language models</span></strong><span class="koboSpan" id="kobo.46.1"> is to predict the next probable word in </span><span class="No-Break"><span class="koboSpan" id="kobo.47.1">a sentence.</span></span></p>
<p><span class="koboSpan" id="kobo.48.1">If you look at the sentence </span><em class="italic"><span class="koboSpan" id="kobo.49.1">John loves to eat</span></em><span class="koboSpan" id="kobo.50.1">, a natural language model is trying to predict what </span><a id="_idIndexMarker006"/><span class="koboSpan" id="kobo.51.1">the next word or token in the sequence will be. </span><span class="koboSpan" id="kobo.51.2">Here, the next probable word seems to be </span><em class="italic"><span class="koboSpan" id="kobo.52.1">ice-cream</span></em><span class="koboSpan" id="kobo.53.1">, with a 9.4% chance, as shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.54.1">Figure 1</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.55.1">.1</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.56.1">:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer008">
<span class="koboSpan" id="kobo.57.1"><img alt="Figure 1.1 – Sentence sequencing prediction" src="image/B22045_01_01.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.58.1">Figure 1.1 – Sentence sequencing prediction</span></p>
<p><span class="koboSpan" id="kobo.59.1">Language models can do this by converting every word into a numerical vector, also known as </span><strong class="bold"><span class="koboSpan" id="kobo.60.1">embeddings</span></strong><span class="koboSpan" id="kobo.61.1">. </span><span class="koboSpan" id="kobo.61.2">Similar </span><a id="_idIndexMarker007"/><span class="koboSpan" id="kobo.62.1">words will be closer in the vector space, while dissimilar words will be positioned spatially distant from each other. </span><span class="koboSpan" id="kobo.62.2">For instance, the word </span><em class="italic"><span class="koboSpan" id="kobo.63.1">phone</span></em><span class="koboSpan" id="kobo.64.1"> will be far apart from the word </span><em class="italic"><span class="koboSpan" id="kobo.65.1">eat</span></em><span class="koboSpan" id="kobo.66.1"> since the semantic meanings of these words </span><span class="No-Break"><span class="koboSpan" id="kobo.67.1">are different.</span></span></p>
<p><span class="koboSpan" id="kobo.68.1">Early NLP techniques </span><a id="_idIndexMarker008"/><span class="koboSpan" id="kobo.69.1">such as </span><strong class="bold"><span class="koboSpan" id="kobo.70.1">bag-of-words models</span></strong><span class="koboSpan" id="kobo.71.1"> with </span><strong class="bold"><span class="koboSpan" id="kobo.72.1">Term Frequency - Inverse Document Frequency</span></strong><span class="koboSpan" id="kobo.73.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.74.1">TF-IDF</span></strong><span class="koboSpan" id="kobo.75.1">) scoring </span><a id="_idIndexMarker009"/><span class="koboSpan" id="kobo.76.1">and </span><strong class="bold"><span class="koboSpan" id="kobo.77.1">n-gram</span></strong><span class="koboSpan" id="kobo.78.1"> analysis </span><a id="_idIndexMarker010"/><span class="koboSpan" id="kobo.79.1">had some limitations for language modeling tasks. </span><span class="koboSpan" id="kobo.79.2">TF-IDF, which determines word importance based on frequency, does not account for semantic context within sentences. </span><span class="koboSpan" id="kobo.79.3">N-grams, representing adjacent words or characters, do not generalize well for out-of-vocabulary terms. </span><span class="koboSpan" id="kobo.79.4">What was needed to advance language modeling was a method of representing words in a way that captures semantic meaning and relationships </span><span class="No-Break"><span class="koboSpan" id="kobo.80.1">between words.</span></span></p>
<p><span class="koboSpan" id="kobo.81.1">In neural networks, a word embedding model </span><a id="_idIndexMarker011"/><span class="koboSpan" id="kobo.82.1">known as </span><strong class="bold"><span class="koboSpan" id="kobo.83.1">Word2Vec</span></strong><span class="koboSpan" id="kobo.84.1"> was able to learn associations from a large corpus of text. </span><span class="koboSpan" id="kobo.84.2">However, the Word2Vec model struggled to perform well with out-of-vocabulary words. </span><span class="koboSpan" id="kobo.84.3">Since the 2010s, researchers have been experimenting with more </span><a id="_idIndexMarker012"/><span class="koboSpan" id="kobo.85.1">advanced sequence modeling techniques to address this limitation, such as </span><strong class="bold"><span class="koboSpan" id="kobo.86.1">recurrent neural networks</span></strong><span class="koboSpan" id="kobo.87.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.88.1">RNNs</span></strong><span class="koboSpan" id="kobo.89.1">) and </span><strong class="bold"><span class="koboSpan" id="kobo.90.1">long short-term memory</span></strong><span class="koboSpan" id="kobo.91.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.92.1">LSTM</span></strong><span class="koboSpan" id="kobo.93.1">) networks. </span><span class="koboSpan" id="kobo.93.2">These models </span><a id="_idIndexMarker013"/><span class="koboSpan" id="kobo.94.1">have memory cells that allow them to consider the context of previous words in a sentence when predicting the next word. </span><span class="koboSpan" id="kobo.94.2">RNNs and LSTMs can capture longer-range dependencies compared to models such as Word2Vec. </span><span class="koboSpan" id="kobo.94.3">While powerful for modeling word sequences, RNNs and LSTM are also more computationally and memory intensive, which means they can hold limited context depending on how much data is being fed to the model. </span><span class="koboSpan" id="kobo.94.4">Therefore, these models are unable to perform well when a whole document with several pages </span><span class="No-Break"><span class="koboSpan" id="kobo.95.1">is provided.</span></span></p>
<p><span class="koboSpan" id="kobo.96.1">In 2017, researchers at Google and the University of Toronto published a paper called </span><em class="italic"><span class="koboSpan" id="kobo.97.1">Attention Is All You Need</span></em><span class="koboSpan" id="kobo.98.1"> (</span><a href="https://arxiv.org/abs/1706.03762"><span class="koboSpan" id="kobo.99.1">https://arxiv.org/abs/1706.03762</span></a><span class="koboSpan" id="kobo.100.1">). </span><span class="koboSpan" id="kobo.100.2">This paper introduced the </span><strong class="bold"><span class="koboSpan" id="kobo.101.1">transformer architecture</span></strong><span class="koboSpan" id="kobo.102.1">, which is </span><a id="_idIndexMarker014"/><span class="koboSpan" id="kobo.103.1">based on a self-attention mechanism rather than recurrent or convolutional layers used in previous models. </span><span class="koboSpan" id="kobo.103.2">This </span><strong class="bold"><span class="koboSpan" id="kobo.104.1">self-attention mechanism</span></strong><span class="koboSpan" id="kobo.105.1"> allows </span><a id="_idIndexMarker015"/><span class="koboSpan" id="kobo.106.1">the model to learn contextual relationships between all words (or a set of tokens) in the input simultaneously. </span><span class="koboSpan" id="kobo.106.2">It does this by calculating the importance of each word concerning other words in the sequence. </span><span class="koboSpan" id="kobo.106.3">This attention is applied to derive contextual representations for downstream tasks such as language modeling or machine translation. </span><span class="koboSpan" id="kobo.106.4">One major benefit of the transformer architecture is its ability to perform parallel computation with a long sequence of words. </span><span class="koboSpan" id="kobo.106.5">This enabled transformers to be effectively applied to much longer texts and documents compared to previous </span><span class="No-Break"><span class="koboSpan" id="kobo.107.1">recurrent models.</span></span></p>
<p><span class="koboSpan" id="kobo.108.1">Language models based on the transformer architecture </span><a id="_idIndexMarker016"/><span class="koboSpan" id="kobo.109.1">exhibit </span><strong class="bold"><span class="koboSpan" id="kobo.110.1">state-of-the-art</span></strong><span class="koboSpan" id="kobo.111.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.112.1">SOTA</span></strong><span class="koboSpan" id="kobo.113.1">) and near-human-level performance. </span><span class="koboSpan" id="kobo.113.2">Since the advent of transformer architecture, various models have been developed. </span><span class="koboSpan" id="kobo.113.3">This breakthrough paved the</span><a id="_idIndexMarker017"/><span class="koboSpan" id="kobo.114.1"> way </span><a id="_idIndexMarker018"/><span class="koboSpan" id="kobo.115.1">for</span><a id="_idIndexMarker019"/><span class="koboSpan" id="kobo.116.1"> modern </span><strong class="bold"><span class="koboSpan" id="kobo.117.1">large language models</span></strong><span class="koboSpan" id="kobo.118.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.119.1">LLMs</span></strong><span class="koboSpan" id="kobo.120.1">), including </span><strong class="bold"><span class="koboSpan" id="kobo.121.1">Bidirectional Encoder Representations from Transformers</span></strong><span class="koboSpan" id="kobo.122.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.123.1">BERT</span></strong><span class="koboSpan" id="kobo.124.1">), </span><strong class="bold"><span class="koboSpan" id="kobo.125.1">Generative Pre-Training language model</span></strong><span class="koboSpan" id="kobo.126.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.127.1">GPT</span></strong><span class="koboSpan" id="kobo.128.1">), </span><strong class="bold"><span class="koboSpan" id="kobo.129.1">Text-To-Text Transfer Transformer</span></strong><span class="koboSpan" id="kobo.130.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.131.1">T5</span></strong><span class="koboSpan" id="kobo.132.1">), </span><strong class="bold"><span class="koboSpan" id="kobo.133.1">BLOOM</span></strong><span class="koboSpan" id="kobo.134.1">, and </span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.135.1">Anthropic Claude</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.136.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.137.1">Now, let’s dive</span><a id="_idIndexMarker020"/><span class="koboSpan" id="kobo.138.1"> into </span><a id="_idIndexMarker021"/><span class="koboSpan" id="kobo.139.1">some LLMs that a powering a </span><a id="_idIndexMarker022"/><span class="koboSpan" id="kobo.140.1">substantial change in the generative </span><span class="No-Break"><span class="koboSpan" id="kobo.141.1">AI domain.</span></span></p>
<h1 id="_idParaDest-18"><a id="_idTextAnchor017"/><span class="koboSpan" id="kobo.142.1">What are FMs?</span></h1>
<p><span class="koboSpan" id="kobo.143.1">Most of the generative</span><a id="_idIndexMarker023"/><span class="koboSpan" id="kobo.144.1"> AI models today are powered by the transformer-based architecture. </span><span class="koboSpan" id="kobo.144.2">In general, these generative AI models, also widely known as FMs, employ transformers due to their ability to process text one token at a time or entire sequences of text at once using self-attention. </span><span class="koboSpan" id="kobo.144.3">FMs are trained on massive amounts of data with millions or billions of parameters, allowing them to understand relationships between words in context to predict subsequent sequences. </span><span class="koboSpan" id="kobo.144.4">While models based on the transformer architecture currently dominate the field, not all FMs rely on</span><a id="_idIndexMarker024"/><span class="koboSpan" id="kobo.145.1"> this architecture. </span><span class="koboSpan" id="kobo.145.2">Some models are built using alternative </span><a id="_idIndexMarker025"/><span class="koboSpan" id="kobo.146.1">techniques, such as </span><strong class="bold"><span class="koboSpan" id="kobo.147.1">generative adversarial networks</span></strong><span class="koboSpan" id="kobo.148.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.149.1">GANs</span></strong><span class="koboSpan" id="kobo.150.1">) or </span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.151.1">variational autoencoders</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.152.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.153.1">GANs utilize two neural networks pitted against each other in competition. </span><span class="koboSpan" id="kobo.153.2">The first network is known as</span><a id="_idIndexMarker026"/><span class="koboSpan" id="kobo.154.1"> the </span><strong class="bold"><span class="koboSpan" id="kobo.155.1">generator</span></strong><span class="koboSpan" id="kobo.156.1"> and is tasked with generating synthetic samples that mimic real data. </span><span class="koboSpan" id="kobo.156.2">For example, the generator could produce new images, texts, or audio clips. </span><span class="koboSpan" id="kobo.156.3">The second network is </span><a id="_idIndexMarker027"/><span class="koboSpan" id="kobo.157.1">called the </span><strong class="bold"><span class="koboSpan" id="kobo.158.1">discriminator</span></strong><span class="koboSpan" id="kobo.159.1">. </span><span class="koboSpan" id="kobo.159.2">Its role is to analyze examples, both real and synthetic, to classify which ones are genuine and which have been </span><span class="No-Break"><span class="koboSpan" id="kobo.160.1">artificially generated.</span></span></p>
<p><span class="koboSpan" id="kobo.161.1">Through this adversarial process, the generator learns to produce increasingly convincing fakes that can fool the discriminator. </span><span class="koboSpan" id="kobo.161.2">Meanwhile, the discriminator becomes better at detecting subtle anomalies that reveal the synthetic samples. </span><span class="koboSpan" id="kobo.161.3">Their competing goals drive both networks to continuously improve. </span><span class="koboSpan" id="kobo.161.4">An example of a GAN can be found at </span><a href="https://thispersondoesnotexist.com/"><span class="koboSpan" id="kobo.162.1">https://thispersondoesnotexist.com/</span></a><span class="koboSpan" id="kobo.163.1">. </span><span class="koboSpan" id="kobo.163.2">By refreshing the page endlessly, users are presented with an endless stream of novel human faces. </span><span class="koboSpan" id="kobo.163.3">However, none are real – all are synthetic portraits created solely by a GAN trained on vast databases of real human images. </span><span class="koboSpan" id="kobo.163.4">The site offers a glimpse into how GANs can synthesize highly realistic outputs across </span><span class="No-Break"><span class="koboSpan" id="kobo.164.1">many domains.</span></span></p>
<p><strong class="bold"><span class="koboSpan" id="kobo.165.1">Variational autoencoders</span></strong><span class="koboSpan" id="kobo.166.1"> are</span><a id="_idIndexMarker028"/><span class="koboSpan" id="kobo.167.1"> simpler-to-train generative AI algorithms that also utilize two neural networks – an </span><strong class="bold"><span class="koboSpan" id="kobo.168.1">encoder</span></strong><span class="koboSpan" id="kobo.169.1"> and a </span><strong class="bold"><span class="koboSpan" id="kobo.170.1">decoder</span></strong><span class="koboSpan" id="kobo.171.1">. </span><span class="koboSpan" id="kobo.171.2">Encoders learn the patterns in the data by mapping it into lower-dimensional latent space, while decoders use these patterns from the latent space and generate </span><span class="No-Break"><span class="koboSpan" id="kobo.172.1">realistic samples.</span></span></p>
<p><span class="koboSpan" id="kobo.173.1">While these FMs (transformer, GAN, or variational autoencoders-based) are trained on massive datasets, this makes them different from other traditional ML models, such as logistic </span><a id="_idIndexMarker029"/><span class="koboSpan" id="kobo.174.1">regression, </span><strong class="bold"><span class="koboSpan" id="kobo.175.1">support vector machines</span></strong><span class="koboSpan" id="kobo.176.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.177.1">SVM</span></strong><span class="koboSpan" id="kobo.178.1">), decision trees, and others. </span><span class="koboSpan" id="kobo.178.2">The term </span><em class="italic"><span class="koboSpan" id="kobo.179.1">foundation models</span></em><span class="koboSpan" id="kobo.180.1"> was coined by researchers at Stanford University at Human-Centered Artificial Intelligence to differentiate them from other ML models. </span><span class="koboSpan" id="kobo.180.2">The traditional ML models are trained on the labeled data and are only capable of performing narrowly defined tasks. </span><span class="koboSpan" id="kobo.180.3">For example, there will be one model for text generation, another model for summarization, and </span><span class="No-Break"><span class="koboSpan" id="kobo.181.1">so on.</span></span></p>
<p><span class="koboSpan" id="kobo.182.1">In contrast, FMs learn patterns in language by analyzing the relationships between words and sentences while training on a massive dataset containing millions or billions of parameters. </span><span class="koboSpan" id="kobo.182.2">Due to their enormous pre-training datasets, FMs tend to generalize well and understand contextual meaning, which allows them to solve various use cases, such as text generation, summarization, entity extraction, image generation, and others. </span><span class="koboSpan" id="kobo.182.3">Their pre-training </span><a id="_idIndexMarker030"/><span class="koboSpan" id="kobo.183.1">enables them to serve as a highly adaptable starting point for many different applications. </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.184.1">Figure 1</span></em></span><em class="italic"><span class="koboSpan" id="kobo.185.1">.2</span></em><span class="koboSpan" id="kobo.186.1"> highlights some of the differences between traditional ML models </span><span class="No-Break"><span class="koboSpan" id="kobo.187.1">and FMs:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer009">
<span class="koboSpan" id="kobo.188.1"><img alt="Figure 1.2 – Traditional ML models versus FMs" src="image/B22045_01_02.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.189.1">Figure 1.2 – Traditional ML models versus FMs</span></p>
<p><span class="koboSpan" id="kobo.190.1">Despite the range of FMs available, organizations face several challenges when adopting these models </span><span class="No-Break"><span class="koboSpan" id="kobo.191.1">at </span></span><span class="No-Break"><a id="_idIndexMarker031"/></span><span class="No-Break"><span class="koboSpan" id="kobo.192.1">scale:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.193.1">No single model solution</span></strong><span class="koboSpan" id="kobo.194.1">: There is no single model that’s optimized for all tasks and models are constantly improving with new advances in technology. </span><span class="koboSpan" id="kobo.194.2">To address multiple use cases, organizations may need to assemble several models that work with each other. </span><span class="koboSpan" id="kobo.194.3">This can take significant time </span><span class="No-Break"><span class="koboSpan" id="kobo.195.1">and resources.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.196.1">Security concerns</span></strong><span class="koboSpan" id="kobo.197.1">: Security and privacy pose a major concern as organizations want to protect their data and valuable intellectual property, and they also want control over how their data is shared and used by </span><span class="No-Break"><span class="koboSpan" id="kobo.198.1">these models.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.199.1">Time and resource management</span></strong><span class="koboSpan" id="kobo.200.1">: For applications such as document summarization and virtual assistants, specific model configuration is needed. </span><span class="koboSpan" id="kobo.200.2">This includes defining tasks, granting access to internal data sources, and developing APIs for the model to take action. </span><span class="koboSpan" id="kobo.200.3">This requires a multi-step process and </span><span class="No-Break"><span class="koboSpan" id="kobo.201.1">complex coding.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.202.1">Lack of seamless integration</span></strong><span class="koboSpan" id="kobo.203.1">: Being able to seamlessly integrate into existing applications is important to avoid managing large computational infrastructures or incurring high costs. </span><span class="koboSpan" id="kobo.203.2">Organizations want models to work behind the scenes</span><a id="_idIndexMarker032"/><span class="koboSpan" id="kobo.204.1"> without any heavy lifting </span><span class="No-Break"><span class="koboSpan" id="kobo.205.1">or expense.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.206.1">Addressing these</span><a id="_idIndexMarker033"/><span class="koboSpan" id="kobo.207.1"> technical, operational, security, and privacy challenges is key for organizations to successfully adopt and deploy FMs at an </span><span class="No-Break"><span class="koboSpan" id="kobo.208.1">enterprise scale.</span></span></p>
<p><span class="koboSpan" id="kobo.209.1">These are the very problems that Amazon Bedrock is designed </span><span class="No-Break"><span class="koboSpan" id="kobo.210.1">to solve.</span></span></p>
<h1 id="_idParaDest-19"><a id="_idTextAnchor018"/><span class="koboSpan" id="kobo.211.1">What is Amazon Bedrock?</span></h1>
<p><span class="koboSpan" id="kobo.212.1">Amazon Bedrock is a </span><a id="_idIndexMarker034"/><span class="koboSpan" id="kobo.213.1">fully managed service that offers various choices of high-performing FMs via a single API. </span><em class="italic"><span class="koboSpan" id="kobo.214.1">Fully managed</span></em><span class="koboSpan" id="kobo.215.1"> implies that users do not have to worry about creating, deploying, and operating the backend infrastructure as it has been taken care of by Amazon. </span><span class="koboSpan" id="kobo.215.2">So, from within your application or code, you can invoke the model on Bedrock with a single API containing your prompt. </span><span class="koboSpan" id="kobo.215.3">One of the key advantages of Amazon Bedrock is it provides a wide choice of leading FMs from Amazon and top AI companies such as Anthropic, AI21 Labs, Cohere, Meta, Stability AI, </span><span class="No-Break"><span class="koboSpan" id="kobo.216.1">and Mistral.</span></span></p>
<p><span class="koboSpan" id="kobo.217.1">Once you’ve defined your use case, the next step is to choose an FM. </span><span class="koboSpan" id="kobo.217.2">Amazon Bedrock provides a playground experience (a web interface for rapid experimentation) where you can experiment with different models and prompts. </span><span class="koboSpan" id="kobo.217.3">Additionally, there are certain techniques and suitability criteria you need to employ to choose the best-fit model for your use case. </span><span class="koboSpan" id="kobo.217.4">We will learn how to evaluate LLMs in the </span><span class="No-Break"><span class="koboSpan" id="kobo.218.1">upcoming sections.</span></span></p>
<p><span class="koboSpan" id="kobo.219.1">Once you have evaluated and identified the FM for your use case, the focus turns to enhancing its predictive </span><a id="_idIndexMarker035"/><span class="koboSpan" id="kobo.220.1">capabilities. </span><span class="koboSpan" id="kobo.220.2">Amazon Bedrock provides the following key capabilities for refining </span><span class="No-Break"><span class="koboSpan" id="kobo.221.1">model performance:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.222.1">Prompt engineering</span></strong><span class="koboSpan" id="kobo.223.1">: Prompt</span><a id="_idIndexMarker036"/><span class="koboSpan" id="kobo.224.1"> engineering and design is a critical first step when interacting with FMs. </span><span class="koboSpan" id="kobo.224.2">Taking the time to craft clear, nuanced prompts is important for establishing the proper context and for the model to provide a reliable outcome. </span><span class="koboSpan" id="kobo.224.3">Prompts can be as simple as </span><strong class="source-inline"><span class="koboSpan" id="kobo.225.1">Tell me the recipe for chocolate cake</span></strong><span class="koboSpan" id="kobo.226.1"> or can be detailed prompts with multiple examples, depending on the use case that you are trying to solve. </span><span class="koboSpan" id="kobo.226.2">With its playground experience, Amazon Bedrock lets you effectively design and formulate prompts through rapid experimentation. </span><span class="koboSpan" id="kobo.226.3">We will discuss some of these techniques and practical aspects of prompt engineering in </span><a href="B22045_03.xhtml#_idTextAnchor053"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.227.1">Chapter 3</span></em></span></a><span class="No-Break"><span class="koboSpan" id="kobo.228.1">.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.229.1">Easy fine-tuning</span></strong><span class="koboSpan" id="kobo.230.1">: Amazon Bedrock allows you to easily customize FMs with your dataset. </span><span class="koboSpan" id="kobo.230.2">This process is called </span><strong class="bold"><span class="koboSpan" id="kobo.231.1">fine-tuning</span></strong><span class="koboSpan" id="kobo.232.1"> the </span><a id="_idIndexMarker037"/><span class="koboSpan" id="kobo.233.1">model and involves training the model further with your domain dataset, improving the accuracy for domain-specific tasks. </span><span class="koboSpan" id="kobo.233.2">Fine-tuning can be done directly from the Amazon Bedrock </span><a id="_idIndexMarker038"/><span class="koboSpan" id="kobo.234.1">console or through APIs, and by providing your datasets in an Amazon </span><strong class="bold"><span class="koboSpan" id="kobo.235.1">Simple Storage Service</span></strong><span class="koboSpan" id="kobo.236.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.237.1">Amazon S3</span></strong><span class="koboSpan" id="kobo.238.1">) bucket. </span><span class="koboSpan" id="kobo.238.2">We will discuss fine-tuning Amazon Bedrock FMs in detail in </span><a href="B22045_04.xhtml#_idTextAnchor073"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.239.1">Chapter 4</span></em></span></a><span class="No-Break"><span class="koboSpan" id="kobo.240.1">.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.241.1">Native support for RAG</span></strong><span class="koboSpan" id="kobo.242.1">: </span><strong class="bold"><span class="koboSpan" id="kobo.243.1">Retrieval augmented generation</span></strong><span class="koboSpan" id="kobo.244.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.245.1">RAG</span></strong><span class="koboSpan" id="kobo.246.1">) is a powerful </span><a id="_idIndexMarker039"/><span class="koboSpan" id="kobo.247.1">technique to fetch data from outside the language model, such as from internal knowledge bases or external sources, to provide accurate responses to domain-specific use cases. </span><span class="koboSpan" id="kobo.247.2">This technique is useful when large documents are needed that are beyond the context provided by the model. </span><span class="koboSpan" id="kobo.247.3">Amazon Bedrock provides native support for RAG, so you can connect your data source for retrieval augmentation. </span><span class="koboSpan" id="kobo.247.4">We will discuss RAG in greater detail in </span><a href="B22045_05.xhtml#_idTextAnchor090"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.248.1">Chapter 5</span></em></span></a><span class="No-Break"><span class="koboSpan" id="kobo.249.1">.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.250.1">Furthermore, there are additional capabilities provided by Amazon Bedrock, such as the ability to build intelligent </span><strong class="bold"><span class="koboSpan" id="kobo.251.1">Agents</span></strong><span class="koboSpan" id="kobo.252.1"> to orchestrate and carry out multiple tasks on your behalf. </span><span class="koboSpan" id="kobo.252.2">Agents can call various internal and external data sources, connect to applications, and run complex tasks in multiple steps. </span><span class="koboSpan" id="kobo.252.3">We will dive deep into building intelligent Agents in </span><a href="B22045_10.xhtml#_idTextAnchor192"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.253.1">Chapter 10</span></em></span></a><span class="No-Break"><span class="koboSpan" id="kobo.254.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.255.1">Security, privacy, and observability are some of the key capabilities of Amazon Bedrock. </span><span class="koboSpan" id="kobo.255.2">The data that you provide when you invoke FMs, including prompts and context, isn’t used to retain any of the FMs. </span><span class="koboSpan" id="kobo.255.3">In addition, all the AWS security and governance capabilities, including data encryption, IAM authentication and permission policies, VPC configuration, and others, apply to Amazon Bedrock. </span><span class="koboSpan" id="kobo.255.4">Hence, you can encrypt your data at rest and in transit. </span><span class="koboSpan" id="kobo.255.5">You can tell Amazon</span><a id="_idIndexMarker040"/><span class="koboSpan" id="kobo.256.1"> Bedrock to use </span><strong class="bold"><span class="koboSpan" id="kobo.257.1">Virtual Private Cloud</span></strong><span class="koboSpan" id="kobo.258.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.259.1">VPC</span></strong><span class="koboSpan" id="kobo.260.1">) so that the traffic between AWS-hosted system components does not flow through the internet. </span><span class="koboSpan" id="kobo.260.2">Also, via </span><strong class="bold"><span class="koboSpan" id="kobo.261.1">Identity and Access Management</span></strong><span class="koboSpan" id="kobo.262.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.263.1">IAM</span></strong><span class="koboSpan" id="kobo.264.1">), you can </span><a id="_idIndexMarker041"/><span class="koboSpan" id="kobo.265.1">provide access to certain resources or users. </span><span class="koboSpan" id="kobo.265.2">Furthermore, metrics, logs, and API calls are pushed to AWS</span><a id="_idIndexMarker042"/><span class="koboSpan" id="kobo.266.1"> CloudWatch and AWS CloudTrail, so you can have visibility and monitor the usage of Amazon Bedrock models. </span><span class="koboSpan" id="kobo.266.2">In </span><em class="italic"><span class="koboSpan" id="kobo.267.1">Part 3 </span></em><span class="koboSpan" id="kobo.268.1">of the book, we will cover model evaluation, monitoring, security, privacy, and ensuring safe and responsible </span><span class="No-Break"><span class="koboSpan" id="kobo.269.1">AI </span></span><span class="No-Break"><span class="koboSpan" id="kobo.270.1">practices</span></span><span class="No-Break"><span class="koboSpan" id="kobo.271.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.272.1">For now, let’s look at the different FMs offered by </span><span class="No-Break"><span class="koboSpan" id="kobo.273.1">Amazon Bedrock.</span></span></p>
<h1 id="_idParaDest-20"><a id="_idTextAnchor019"/><span class="koboSpan" id="kobo.274.1">FMs in Amazon Bedrock</span></h1>
<p><span class="koboSpan" id="kobo.275.1">With Amazon </span><a id="_idIndexMarker043"/><span class="koboSpan" id="kobo.276.1">Bedrock, you have access to six FMs </span><a id="_idIndexMarker044"/><span class="koboSpan" id="kobo.277.1">from Amazon and leading AI companies – that is, AI21, Anthropic, Command, Stability AI, and Meta – as depicted in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.278.1">Figure 1</span></em></span><em class="italic"><span class="koboSpan" id="kobo.279.1">.3</span></em><span class="koboSpan" id="kobo.280.1">. </span><span class="koboSpan" id="kobo.280.2">Amazon Bedrock might add access to more FMs in </span><span class="No-Break"><span class="koboSpan" id="kobo.281.1">the future:</span></span></p>
<p class="IMG---Figure"> </p>
<div>
<div class="IMG---Figure" id="_idContainer010">
<span class="koboSpan" id="kobo.282.1"><img alt="Figure 1.3 – FMs available on Amazon Bedrock" src="image/B22045_01_03.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.283.1">Figure 1.3 – FMs available on Amazon Bedrock</span></p>
<p><span class="koboSpan" id="kobo.284.1">Now, let’s</span><a id="_idIndexMarker045"/><span class="koboSpan" id="kobo.285.1"> discuss each of these models </span><span class="No-Break"><span class="koboSpan" id="kobo.286.1">in</span></span><span class="No-Break"><a id="_idIndexMarker046"/></span><span class="No-Break"><span class="koboSpan" id="kobo.287.1"> detail.</span></span></p>
<h2 id="_idParaDest-21"><a id="_idTextAnchor020"/><span class="koboSpan" id="kobo.288.1">Amazon Titan FMs</span></h2>
<p><span class="koboSpan" id="kobo.289.1">The </span><strong class="bold"><span class="koboSpan" id="kobo.290.1">Amazon Titan FMs</span></strong><span class="koboSpan" id="kobo.291.1"> represent</span><a id="_idIndexMarker047"/><span class="koboSpan" id="kobo.292.1"> a suite of powerful, multipurpose</span><a id="_idIndexMarker048"/><span class="koboSpan" id="kobo.293.1"> models developed by AWS through extensive pretraining on vast datasets, endowing them with broad applicability across diverse domains. </span><span class="koboSpan" id="kobo.293.2">This FM supports use cases such as generating texts, question-answering, summarization, RAG, personalization, image generation, and more. </span><span class="koboSpan" id="kobo.293.3">A simple example would be generating an article/blog or writing </span><span class="No-Break"><span class="koboSpan" id="kobo.294.1">an email.</span></span></p>
<p><span class="koboSpan" id="kobo.295.1">Three types of Amazon Titan models are currently available on Amazon Bedrock: </span><em class="italic"><span class="koboSpan" id="kobo.296.1">Titan Text Generation</span></em><span class="koboSpan" id="kobo.297.1">, </span><em class="italic"><span class="koboSpan" id="kobo.298.1">Titan Image Generator</span></em><span class="koboSpan" id="kobo.299.1">, and </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.300.1">Titan Embeddings</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.301.1">.</span></span></p>
<h3><span class="koboSpan" id="kobo.302.1">Titan Text Generation</span></h3>
<p><strong class="bold"><span class="koboSpan" id="kobo.303.1">Titan Text Generation</span></strong><span class="koboSpan" id="kobo.304.1"> is an LLM </span><a id="_idIndexMarker049"/><span class="koboSpan" id="kobo.305.1">that’s </span><a id="_idIndexMarker050"/><span class="koboSpan" id="kobo.306.1">designed for use cases such as generating texts, summarization, and more. </span><span class="koboSpan" id="kobo.306.2">Let’s assume that John has to write an email to the customer support team of his telephone operator, asking them to fix the billing issue he has been facing. </span><span class="koboSpan" id="kobo.306.3">We can provide a prompt to the Titan Text Generation model. </span><span class="koboSpan" id="kobo.306.4">The response will be generated alongside the subject, as shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.307.1">Figure 1</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.308.1">.4</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.309.1">:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer011">
<span class="koboSpan" id="kobo.310.1"><img alt="Figure 1.4 – Response generated by the Titan Text G1- Express model" src="image/B22045_01_04.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.311.1">Figure 1.4 – Response generated by the Titan Text G1- Express model</span></p>
<p><span class="koboSpan" id="kobo.312.1">At the time of writing, Titan Text Generation is available in three different flavors – </span><em class="italic"><span class="koboSpan" id="kobo.313.1">Titan Text G1 Lite,</span></em> <em class="italic"><span class="koboSpan" id="kobo.314.1">Titan Text G1 Express</span></em><span class="koboSpan" id="kobo.315.1"> and </span><em class="italic"><span class="koboSpan" id="kobo.316.1">Titan Text G1 Premier</span></em><span class="koboSpan" id="kobo.317.1">. </span><span class="koboSpan" id="kobo.317.2">The main difference is that Lite is a more cost-effective and smaller model and supports up to </span><em class="italic"><span class="koboSpan" id="kobo.318.1">4,000</span></em><span class="koboSpan" id="kobo.319.1"> tokens, Express is a larger model that supports up to </span><em class="italic"><span class="koboSpan" id="kobo.320.1">8,000</span></em><span class="koboSpan" id="kobo.321.1"> tokens and is designed for complex </span><a id="_idIndexMarker051"/><span class="koboSpan" id="kobo.322.1">use cases, and Premier is most</span><a id="_idIndexMarker052"/><span class="koboSpan" id="kobo.323.1"> advanced model by Titan that supports up to 32k tokens and is designed to provide </span><span class="No-Break"><span class="koboSpan" id="kobo.324.1">exceptional performance.</span></span></p>
<h3><span class="koboSpan" id="kobo.325.1">Titan Image Generator</span></h3>
<p><strong class="bold"><span class="koboSpan" id="kobo.326.1">Titan Image Generator</span></strong><span class="koboSpan" id="kobo.327.1"> is designed </span><a id="_idIndexMarker053"/><span class="koboSpan" id="kobo.328.1">to generate </span><a id="_idIndexMarker054"/><span class="koboSpan" id="kobo.329.1">a variety of images from texts, edit images, perform in-painting and out-painting, and more. </span><span class="koboSpan" id="kobo.329.2">The Image Generator model, known as </span><em class="italic"><span class="koboSpan" id="kobo.330.1">Titan Image Generator G1</span></em><span class="koboSpan" id="kobo.331.1">, currently supports up to </span><em class="italic"><span class="koboSpan" id="kobo.332.1">77,000</span></em><span class="koboSpan" id="kobo.333.1"> tokens with a maximum image size of 25 MB. </span><span class="koboSpan" id="kobo.333.2">For example, we can ask the model to </span><strong class="source-inline"><span class="koboSpan" id="kobo.334.1">Generate an image of a Bunny skiing in the Swiss Alps</span></strong><span class="koboSpan" id="kobo.335.1">. </span><span class="koboSpan" id="kobo.335.2">Once the images have been generated, we can create variations of a single image, or even edit the image, as demonstrated in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.336.1">Figure 1</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.337.1">.5</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.338.1">:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer012">
<span class="koboSpan" id="kobo.339.1"><img alt="Figure 1.5 – Titan Image Generator and its configurations" src="image/B22045_01_05.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.340.1">Figure 1.5 – Titan Image Generator and its configurations</span></p>
<p><span class="koboSpan" id="kobo.341.1">In </span><a href="B22045_09.xhtml#_idTextAnchor171"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.342.1">Chapter 9</span></em></span></a><span class="koboSpan" id="kobo.343.1">, we will</span><a id="_idIndexMarker055"/><span class="koboSpan" id="kobo.344.1"> learn more about how image</span><a id="_idIndexMarker056"/><span class="koboSpan" id="kobo.345.1"> generation works and dive into various </span><span class="No-Break"><span class="koboSpan" id="kobo.346.1">use cases.</span></span></p>
<h3><span class="koboSpan" id="kobo.347.1">Titan Embeddings</span></h3>
<p><span class="koboSpan" id="kobo.348.1">The main function</span><a id="_idIndexMarker057"/><span class="koboSpan" id="kobo.349.1"> of the </span><strong class="bold"><span class="koboSpan" id="kobo.350.1">Titan Embeddings</span></strong><span class="koboSpan" id="kobo.351.1"> model is </span><a id="_idIndexMarker058"/><span class="koboSpan" id="kobo.352.1">to convert texts (or images) into numeric vectors. </span><span class="koboSpan" id="kobo.352.2">These vectors represent words mathematically so that similar words have similar vectors. </span><span class="koboSpan" id="kobo.352.3">You </span><a id="_idIndexMarker059"/><span class="koboSpan" id="kobo.353.1">can store</span><a id="_idIndexMarker060"/><span class="koboSpan" id="kobo.354.1"> these embeddings in vector</span><a id="_idIndexMarker061"/><span class="koboSpan" id="kobo.355.1"> databases such as </span><strong class="bold"><span class="koboSpan" id="kobo.356.1">OpenSearch</span></strong><span class="koboSpan" id="kobo.357.1">, </span><strong class="bold"><span class="koboSpan" id="kobo.358.1">Aurora pgvector</span></strong><span class="koboSpan" id="kobo.359.1">, </span><strong class="bold"><span class="koboSpan" id="kobo.360.1">Amazon Kendra</span></strong><span class="koboSpan" id="kobo.361.1">, or </span><strong class="bold"><span class="koboSpan" id="kobo.362.1">Pinecone</span></strong><span class="koboSpan" id="kobo.363.1">, and </span><a id="_idIndexMarker062"/><span class="koboSpan" id="kobo.364.1">these databases will be used to compare the relationship between </span><span class="No-Break"><span class="koboSpan" id="kobo.365.1">the texts.</span></span></p>
<p><span class="koboSpan" id="kobo.366.1">At the time of writing, the Titan Embeddings model is available in two variations – </span><strong class="bold"><span class="koboSpan" id="kobo.367.1">Titan Text Embeddings</span></strong><span class="koboSpan" id="kobo.368.1"> and </span><strong class="bold"><span class="koboSpan" id="kobo.369.1">Titan Multimodal Embeddings</span></strong><span class="koboSpan" id="kobo.370.1">. </span><span class="koboSpan" id="kobo.370.2">The main difference is Titan Text </span><a id="_idIndexMarker063"/><span class="koboSpan" id="kobo.371.1">Embeddings</span><a id="_idIndexMarker064"/><span class="koboSpan" id="kobo.372.1"> converts texts into embeddings, which makes the model a suitable fit for use cases such as RAG and clustering, while Titan Multimodal Embeddings can convert a combination of texts and images into embeddings, which makes it apt for use cases such as searching within images and </span><span class="No-Break"><span class="koboSpan" id="kobo.373.1">providing recommendations.</span></span></p>
<p><span class="koboSpan" id="kobo.374.1">While Titan Text Embeddings supports up to </span><em class="italic"><span class="koboSpan" id="kobo.375.1">8,000</span></em><span class="koboSpan" id="kobo.376.1"> tokens and over 25 languages, Titan Multimodal Embeddings can support up to </span><em class="italic"><span class="koboSpan" id="kobo.377.1">128</span></em><span class="koboSpan" id="kobo.378.1"> tokens with a maximum image size of 25 MB. </span><span class="koboSpan" id="kobo.378.2">Here, English is the only </span><span class="No-Break"><span class="koboSpan" id="kobo.379.1">supported language.</span></span></p>
<p><span class="koboSpan" id="kobo.380.1">In the next chapter, we will learn how to invoke these models and their input configuration parameters. </span><span class="koboSpan" id="kobo.380.2">For </span><a id="_idIndexMarker065"/><span class="koboSpan" id="kobo.381.1">now, let’s learn about some </span><a id="_idIndexMarker066"/><span class="koboSpan" id="kobo.382.1">other FMs provided by </span><span class="No-Break"><span class="koboSpan" id="kobo.383.1">Amazon Bedrock.</span></span></p>
<h2 id="_idParaDest-22"><a id="_idTextAnchor021"/><span class="koboSpan" id="kobo.384.1">AI21 Labs – Jurassic-2</span></h2>
<p><span class="koboSpan" id="kobo.385.1">AI21 Labs has built </span><a id="_idIndexMarker067"/><span class="koboSpan" id="kobo.386.1">several FMs and task-specific models. </span><span class="koboSpan" id="kobo.386.2">However, at the</span><a id="_idIndexMarker068"/><span class="koboSpan" id="kobo.387.1"> time of writing, Amazon Bedrock provides access to </span><em class="italic"><span class="koboSpan" id="kobo.388.1">Jamba-Instruct</span></em><span class="koboSpan" id="kobo.389.1">, </span><em class="italic"><span class="koboSpan" id="kobo.390.1">Jurassic 2 – Ultra</span></em><span class="koboSpan" id="kobo.391.1"> and </span><em class="italic"><span class="koboSpan" id="kobo.392.1">Jurassic 2 – </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.393.1">Mid</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.394.1"> FMs.</span></span></p>
<p><strong class="bold"><span class="koboSpan" id="kobo.395.1">Jamba-Instruct</span></strong><span class="koboSpan" id="kobo.396.1"> supports </span><a id="_idIndexMarker069"/><span class="koboSpan" id="kobo.397.1">only English, whereas </span><strong class="bold"><span class="koboSpan" id="kobo.398.1">Jurassic-2 </span></strong><span class="koboSpan" id="kobo.399.1">models support multiple languages and use cases such as advanced text generation, comprehension, open book Q&amp;A, summarization </span><span class="No-Break"><span class="koboSpan" id="kobo.400.1">and others.</span></span></p>
<p><span class="koboSpan" id="kobo.401.1">Jamba-Instruct supports</span><a id="_idIndexMarker070"/><span class="koboSpan" id="kobo.402.1"> context token length of 256K, whereas, </span><strong class="bold"><span class="koboSpan" id="kobo.403.1">Jurassic-2 Ultra</span></strong><span class="koboSpan" id="kobo.404.1"> and </span><strong class="bold"><span class="koboSpan" id="kobo.405.1">Jurassic-2 Mid</span></strong><span class="koboSpan" id="kobo.406.1"> both </span><a id="_idIndexMarker071"/><span class="koboSpan" id="kobo.407.1">support a context token length </span><span class="No-Break"><span class="koboSpan" id="kobo.408.1">of 8,192.</span></span></p>
<p><span class="koboSpan" id="kobo.409.1">An example would be the prompt </span><strong class="source-inline"><span class="koboSpan" id="kobo.410.1">Give me pointers on how I should grow vegetables at home</span></strong><span class="koboSpan" id="kobo.411.1">. </span><span class="koboSpan" id="kobo.411.2">The output is depicted in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.412.1">Figure 1</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.413.1">.6</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.414.1">:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer013">
<span class="koboSpan" id="kobo.415.1"><img alt="Figure 1.6 – Prompting the Jurassic-2 model" src="image/B22045_01_06.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.416.1">Figure 1.6 – Prompting the Jurassic-2 model</span></p>
<h2 id="_idParaDest-23"><a id="_idTextAnchor022"/><span class="koboSpan" id="kobo.417.1">Anthropic Claude</span></h2>
<p><span class="koboSpan" id="kobo.418.1">Anthropic focuses </span><a id="_idIndexMarker072"/><span class="koboSpan" id="kobo.419.1">on </span><a id="_idIndexMarker073"/><span class="koboSpan" id="kobo.420.1">safe and responsible AI and provides a group of Claude models. </span><span class="koboSpan" id="kobo.420.2">These models support use cases such as Q&amp;A, removing </span><strong class="bold"><span class="koboSpan" id="kobo.421.1">personally identifiable information</span></strong><span class="koboSpan" id="kobo.422.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.423.1">PII</span></strong><span class="koboSpan" id="kobo.424.1">), content generation, roleplay dialogues, and</span><a id="_idIndexMarker074"/><span class="koboSpan" id="kobo.425.1"> more. </span><span class="koboSpan" id="kobo.425.2">One major benefit of using Anthropic Claude is its ability to process longer sequences of text as prompts. </span><span class="koboSpan" id="kobo.425.3">With a maximum context window of </span><em class="italic"><span class="koboSpan" id="kobo.426.1">200,000</span></em><span class="koboSpan" id="kobo.427.1"> tokens to date, Claude can understand and respond to much more extensive prompts. </span><span class="koboSpan" id="kobo.427.2">This larger context allows Claude to engage in deeper discussions, understand </span><a id="_idIndexMarker075"/><span class="koboSpan" id="kobo.428.1">longer narratives or documents, and generate more</span><a id="_idIndexMarker076"/><span class="koboSpan" id="kobo.429.1"> coherent </span><span class="No-Break"><span class="koboSpan" id="kobo.430.1">multi-paragraph responses.</span></span></p>
<p><span class="koboSpan" id="kobo.431.1">Amazon Bedrock currently offers access to five versions of Anthropic’s Claude </span><span class="No-Break"><span class="koboSpan" id="kobo.432.1">language model:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.433.1">Anthropic Claude 3.5 Sonnet</span></strong><span class="koboSpan" id="kobo.434.1">: This </span><a id="_idIndexMarker077"/><span class="koboSpan" id="kobo.435.1">sets new industry standards for superior intelligence, outperforming its predecessors and other top AI models in various benchmarks. </span><span class="koboSpan" id="kobo.435.2">Claude 3.5 Sonnet excels in areas like visual processing, content generation, customer support, data analysis, and coding. </span><span class="koboSpan" id="kobo.435.3">Remarkably, it achieves this enhanced performance while being 80% more cost-effective than previous Anthropic models, making it an attractive choice for businesses seeking advanced AI capabilities at a lower price point. </span><span class="koboSpan" id="kobo.435.4">The following link highlights the benchmarks and comparison with other models on different </span><span class="No-Break"><span class="koboSpan" id="kobo.436.1">tasks: </span></span><span class="No-Break"><span class="koboSpan" id="kobo.437.1">https://aws.amazon.com/blogs/aws/anthropics-claude-3-5-sonnet-model-now-available-in-amazon-bedrock-the-most-intelligent-claude-model-yet/</span></span><span class="No-Break"><span class="koboSpan" id="kobo.438.1">.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.439.1">Anthropic Claude 3</span></strong><span class="koboSpan" id="kobo.440.1">: This has three model variants – </span><em class="italic"><span class="koboSpan" id="kobo.441.1">Claude 3 Opus</span></em><span class="koboSpan" id="kobo.442.1">, </span><em class="italic"><span class="koboSpan" id="kobo.443.1">Claude 3 Sonnet</span></em><span class="koboSpan" id="kobo.444.1">, and </span><em class="italic"><span class="koboSpan" id="kobo.445.1">Claude 3 Haiku</span></em><span class="koboSpan" id="kobo.446.1">. </span><span class="koboSpan" id="kobo.446.2">They are the recent and most advanced family of Anthropic models available on Amazon Bedrock. </span><span class="koboSpan" id="kobo.446.3">All these models have multimodal capabilities and can perceive and analyze images (jpeg, png), as well as other file types, such as .csv, .doc, .docx, .html, .md, .pdf, .txt, .xls, .xlsx, .gif, and text input, with a 200K </span><span class="No-Break"><span class="koboSpan" id="kobo.447.1">context window:</span></span><ul><li><strong class="bold"><span class="koboSpan" id="kobo.448.1">Claude 3 Opus</span></strong><span class="koboSpan" id="kobo.449.1">: This is Anthropic’s most capable model to date, with 175 billion parameters. </span><span class="koboSpan" id="kobo.449.2">Opus has advanced few-shot learning capabilities, allowing it to quickly adapt to a wide variety of tasks using just a </span><span class="No-Break"><span class="koboSpan" id="kobo.450.1">few examples.</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.451.1">Claude 3 Sonnet</span></strong><span class="koboSpan" id="kobo.452.1">: A 60-billion-parameter multimodal AI model, Sonnet has strong few-shot learning abilities. </span><span class="koboSpan" id="kobo.452.2">Its parameter-efficient architecture allows it to handle complex inputs such as long documents while being more computationally efficient </span><span class="No-Break"><span class="koboSpan" id="kobo.453.1">than Opus.</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.454.1">Claude 3 Haiku</span></strong><span class="koboSpan" id="kobo.455.1">: At 7 billion parameters, Haiku is Anthropic’s most compact and lightweight model. </span><span class="koboSpan" id="kobo.455.2">It is optimized for efficiency, providing high performance for its size. </span><span class="koboSpan" id="kobo.455.3">Its low computational requirements make it very fast to </span><span class="No-Break"><span class="koboSpan" id="kobo.456.1">run inference.</span></span></li></ul></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.457.1">Anthropic Claude 2.1</span></strong><strong class="bold"><span class="koboSpan" id="kobo.458.1"> and </span></strong><strong class="bold"><span class="koboSpan" id="kobo.459.1">Claude 2</span></strong><span class="koboSpan" id="kobo.460.1">: They are also advanced additions to Anthropic’s Claude family. </span><span class="koboSpan" id="kobo.460.2">They provide performant reasoning capabilities and high accuracy with lower hallucination rates. </span><span class="koboSpan" id="kobo.460.3">They perform well on use cases such as dialogue, creative writing, information, roleplay, summarization, and others. </span><span class="koboSpan" id="kobo.460.4">In terms of context length, Claude 2.1 supports up to </span><em class="italic"><span class="koboSpan" id="kobo.461.1">200,000</span></em><span class="koboSpan" id="kobo.462.1"> tokens and Claude 2 supports up to </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.463.1">100,000</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.464.1"> tokens.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.465.1">Anthropic Claude 1.3</span></strong><span class="koboSpan" id="kobo.466.1">: This is an earlier release with capabilities typical of LLMs at that time. </span><span class="koboSpan" id="kobo.466.2">It demonstrated strong performance on tasks involving factual responses, summarization, and basic question-answering. </span><span class="koboSpan" id="kobo.466.3">In terms of context length, Claude 1.3 supports up to </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.467.1">100,000</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.468.1"> tokens.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.469.1">Anthropic Claude Instant 1.2</span></strong><span class="koboSpan" id="kobo.470.1">: This offers a faster and more cost-effective option compared to other Claude models. </span><span class="koboSpan" id="kobo.470.2">The latency of the Claude Instant model is greatly reduced at the cost of impacted performance. </span><span class="koboSpan" id="kobo.470.3">However, Claude Instant still demonstrates strong language skills for many common NLP applications that do not require the highest levels of reasoning or nuanced responses, and when</span><a id="_idIndexMarker078"/><span class="koboSpan" id="kobo.471.1"> speed or cost is a higher priority than absolute highest performance. </span><span class="koboSpan" id="kobo.471.2">In terms of context length, Claude Instant 1.2 supports up to </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.472.1">100,000</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.473.1"> tokens.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.474.1">We will walk </span><a id="_idIndexMarker079"/><span class="koboSpan" id="kobo.475.1">through</span><a id="_idIndexMarker080"/><span class="koboSpan" id="kobo.476.1"> some examples of leveraging Anthropic Claude with Bedrock in the </span><span class="No-Break"><span class="koboSpan" id="kobo.477.1">next chapter.</span></span></p>
<h2 id="_idParaDest-24"><a id="_idTextAnchor023"/><span class="koboSpan" id="kobo.478.1">Cohere</span></h2>
<p><span class="koboSpan" id="kobo.479.1">Amazon </span><a id="_idIndexMarker081"/><span class="koboSpan" id="kobo.480.1">Bedrock </span><a id="_idIndexMarker082"/><span class="koboSpan" id="kobo.481.1">offers multiple models from Cohere: </span><em class="italic"><span class="koboSpan" id="kobo.482.1">Command</span></em><span class="koboSpan" id="kobo.483.1">,</span><em class="italic"><span class="koboSpan" id="kobo.484.1"> Command R+</span></em><span class="koboSpan" id="kobo.485.1">,</span><em class="italic"><span class="koboSpan" id="kobo.486.1"> Command R</span></em><span class="koboSpan" id="kobo.487.1">,</span><em class="italic"><span class="koboSpan" id="kobo.488.1"> Command Light </span></em><span class="koboSpan" id="kobo.489.1">models,</span><em class="italic"><span class="koboSpan" id="kobo.490.1"> Embed English, </span></em><span class="koboSpan" id="kobo.491.1">and</span><em class="italic"><span class="koboSpan" id="kobo.492.1"> Embed Multilingual</span></em><span class="koboSpan" id="kobo.493.1">. </span><strong class="bold"><span class="koboSpan" id="kobo.494.1">Cohere Command</span></strong><strong class="bold"><span class="koboSpan" id="kobo.495.1">, </span></strong><span class="koboSpan" id="kobo.496.1">trained with 52 billion parameters</span><strong class="bold"><span class="koboSpan" id="kobo.497.1">,</span></strong><span class="koboSpan" id="kobo.498.1"> is an LLM useful for more complex language understanding. </span><strong class="bold"><span class="koboSpan" id="kobo.499.1">Command Light</span></strong><span class="koboSpan" id="kobo.500.1">, with 6 billion parameters, is cost-effective and faster, making it a good option for those who need a lighter model for their applications. </span><strong class="bold"><span class="koboSpan" id="kobo.501.1">Command R+</span></strong><span class="koboSpan" id="kobo.502.1">, trained on 104 billiion parameters, is the most powerful model by Cohere, at the time of writing this book, and is  designed for tasks with context window size of 128K tokens. </span><strong class="bold"><span class="koboSpan" id="kobo.503.1">Command R</span></strong><span class="koboSpan" id="kobo.504.1">, trained on 35 billion parameters, is also designed for tasks with longer context window of </span><span class="No-Break"><span class="koboSpan" id="kobo.505.1">128K tokens.</span></span></p>
<p><span class="koboSpan" id="kobo.506.1">Cohere Embed provides a set of models that have been trained to generate high-quality embeddings, which we already know are representations of text documents in a numerical format in vector space. </span><span class="koboSpan" id="kobo.506.2">Cohere offers </span><strong class="bold"><span class="koboSpan" id="kobo.507.1">Embed English</span></strong><span class="koboSpan" id="kobo.508.1">, which has only been trained on English text, as well as </span><strong class="bold"><span class="koboSpan" id="kobo.509.1">Embed Multilingual</span></strong><span class="koboSpan" id="kobo.510.1">, which can handle multiple (more than 100) languages. </span><span class="koboSpan" id="kobo.510.2">Embed models support a maximum token length of 512. </span><span class="koboSpan" id="kobo.510.3">These embedding models open a wide range of downstream applications, such as semantic search to find related documents, RAG, text clustering, classification, </span><span class="No-Break"><span class="koboSpan" id="kobo.511.1">and more.</span></span></p>
<p><span class="koboSpan" id="kobo.512.1">Take note of the following figure, which highlights a text generation example for summarizing a conversation using the Cohere Command model within Amazon Bedrock’s </span><span class="No-Break"><span class="koboSpan" id="kobo.513.1">text playground:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer014">
<span class="koboSpan" id="kobo.514.1"><img alt="Figure 1.7 – Cohere Command text generation example in Amazon Bedrock’s text playground" src="image/B22045_01_07.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.515.1">Figure 1.7 – Cohere Command text generation example in Amazon Bedrock’s text playground</span></p>
<h2 id="_idParaDest-25"><a id="_idTextAnchor024"/><span class="koboSpan" id="kobo.516.1">Meta Llama 2 and Llama 3</span></h2>
<p><span class="koboSpan" id="kobo.517.1">Meta offers several</span><a id="_idIndexMarker083"/><span class="koboSpan" id="kobo.518.1"> pre-trained LLMs under</span><a id="_idIndexMarker084"/><span class="koboSpan" id="kobo.519.1"> their </span><strong class="bold"><span class="koboSpan" id="kobo.520.1">Llama 2</span></strong><span class="koboSpan" id="kobo.521.1"> and </span><strong class="bold"><span class="koboSpan" id="kobo.522.1">Llama 3</span></strong><span class="koboSpan" id="kobo.523.1"> series for chatbot applications. </span><span class="koboSpan" id="kobo.523.2">Their base Llama2 model is pre-trained on over 2 trillion tokens of publicly available online data sources, at which point it’s fine-tuned with over 1 million examples of </span><span class="No-Break"><span class="koboSpan" id="kobo.524.1">human annotation.</span></span></p>
<p><span class="koboSpan" id="kobo.525.1">Four variants of Llama2 have been made available through Amazon Bedrock: </span><strong class="bold"><span class="koboSpan" id="kobo.526.1">Llama 2 Chat 13B</span></strong><span class="koboSpan" id="kobo.527.1">, </span><strong class="bold"><span class="koboSpan" id="kobo.528.1">Llama 2 Chat 70B</span></strong><span class="koboSpan" id="kobo.529.1">, </span><strong class="bold"><span class="koboSpan" id="kobo.530.1">Llama 2 13B</span></strong><span class="koboSpan" id="kobo.531.1">, and </span><strong class="bold"><span class="koboSpan" id="kobo.532.1">Llama 2 70B</span></strong><span class="koboSpan" id="kobo.533.1">. </span><span class="koboSpan" id="kobo.533.2">The 13B model contains 13 billion parameters and its training process took 368,640 GPU hours to complete. </span><span class="koboSpan" id="kobo.533.3">One of the key advantages of the Llama 13B model is its ability to process input sequences of arbitrary length, making it well-suited for tasks that require long documents or web pages to be analyzed. </span><span class="koboSpan" id="kobo.533.4">The larger 70B model variant contains 70 billion parameters and its training process took 1,720,320 GPU hours to complete. </span><span class="koboSpan" id="kobo.533.5">The 70B model can be used for multitask learning, implying it is well suited for performing multiple tasks simultaneously, such as image classification, speech recognition, and NLP. </span><span class="koboSpan" id="kobo.533.6">It has been shown to achieve improved performance on several tasks compared to 13B models, likely due to its relatively larger size and higher </span><span class="No-Break"><span class="koboSpan" id="kobo.534.1">computational resources.</span></span></p>
<p><span class="koboSpan" id="kobo.535.1">Along with Llama2, Meta Llama 3 variants are also available on Amazon Bedrock, namely </span><strong class="bold"><span class="koboSpan" id="kobo.536.1">Llama 3 8B Instruct</span></strong><span class="koboSpan" id="kobo.537.1"> and </span><strong class="bold"><span class="koboSpan" id="kobo.538.1">Llama 3 70B Instruct</span></strong><span class="koboSpan" id="kobo.539.1">. </span><span class="koboSpan" id="kobo.539.2">The Llama 3 8B Instruct model is optimized for scenarios with limited computational resources, making it well-suited for edge devices and applications. </span><span class="koboSpan" id="kobo.539.3">It demonstrates strong performance in tasks such as text summarization, text classification, language translation, and sentiment analysis. </span><span class="koboSpan" id="kobo.539.4">The Llama 3 70B Instruct model is tailored for content creation, conversational AI systems, language understanding applications, and enterprise solutions. </span><span class="koboSpan" id="kobo.539.5">It excels in areas such as accurate text summarization, nuanced text classification, sophisticated sentiment analysis </span><a id="_idIndexMarker085"/><span class="koboSpan" id="kobo.540.1">and reasoning, language </span><a id="_idIndexMarker086"/><span class="koboSpan" id="kobo.541.1">modeling, dialogue systems, code generation, and following </span><span class="No-Break"><span class="koboSpan" id="kobo.542.1">complex instructions.</span></span></p>
<p><span class="koboSpan" id="kobo.543.1">For developers looking to utilize these models, Meta has created an open source GitHub repository called </span><em class="italic"><span class="koboSpan" id="kobo.544.1">llama-recipes</span></em><span class="koboSpan" id="kobo.545.1"> (</span><a href="https://github.com/facebookresearch/llama-recipes/tree/main"><span class="koboSpan" id="kobo.546.1">https://github.com/facebookresearch/llama-recipes/tree/main</span></a><span class="koboSpan" id="kobo.547.1">) that includes demo code and examples of integrating the Llama2 models into chatbots and virtual assistants. </span><span class="koboSpan" id="kobo.547.2">This provides a starting point for researchers and practitioners to experiment with Llama2 and adapt it for their own conversational </span><span class="No-Break"><span class="koboSpan" id="kobo.548.1">AI applications.</span></span></p>
<p><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.549.1">Figure 1</span></em></span><em class="italic"><span class="koboSpan" id="kobo.550.1">.8</span></em><span class="koboSpan" id="kobo.551.1"> demonstrates an entity extraction example using the Meta Llama 2 Chat 13 B model in Amazon Bedrock’s </span><span class="No-Break"><span class="koboSpan" id="kobo.552.1">text playground:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer015">
<span class="koboSpan" id="kobo.553.1"><img alt="Figure 1.8 – Entity extraction with the Llama 2 Chat 13B model in Amazon Bedrock’s text playground" src="image/B22045_01_08.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.554.1">Figure 1.8 – Entity extraction with the Llama 2 Chat 13B model in Amazon Bedrock’s text playground</span></p>
<h2 id="_idParaDest-26"><a id="_idTextAnchor025"/><span class="koboSpan" id="kobo.555.1">Mistral AI</span></h2>
<p><strong class="bold"><span class="koboSpan" id="kobo.556.1">Mistral AI</span></strong><span class="koboSpan" id="kobo.557.1"> focuses on</span><a id="_idIndexMarker087"/><span class="koboSpan" id="kobo.558.1"> building compute-efficient, trustworthy, and</span><a id="_idIndexMarker088"/><span class="koboSpan" id="kobo.559.1"> powerful AI models. </span><span class="koboSpan" id="kobo.559.2">These are currently available in four variants on Amazon Bedrock – </span><em class="italic"><span class="koboSpan" id="kobo.560.1">Mistral 7B Instruct</span></em><span class="koboSpan" id="kobo.561.1">, </span><em class="italic"><span class="koboSpan" id="kobo.562.1">Mixtral 8X7B Instruct</span></em><span class="koboSpan" id="kobo.563.1">, </span><em class="italic"><span class="koboSpan" id="kobo.564.1">Mistral Large</span></em><span class="koboSpan" id="kobo.565.1">, and </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.566.1">Mistral Small</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.567.1">:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.568.1">Mistral 7B instruct</span></strong><span class="koboSpan" id="kobo.569.1">: This is a 7-billion-parameter</span><a id="_idIndexMarker089"/><span class="koboSpan" id="kobo.570.1"> dense transformer language model designed for instructional tasks. </span><span class="koboSpan" id="kobo.570.2">It offers a compelling balance of performance and efficiency, delivering robust capabilities suitable for a wide range of use cases despite its relatively compact size. </span><span class="koboSpan" id="kobo.570.3">Mistral 7B instruct supports processing English natural language and code inputs, with an extended 32,000 token context window capacity. </span><span class="koboSpan" id="kobo.570.4">While more limited than larger models, Mistral 7B instruct provides high-quality language understanding, generation, and task execution tailored for instructional applications at a lower </span><span class="No-Break"><span class="koboSpan" id="kobo.571.1">computational cost.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.572.1">Mixtral 8X7B</span></strong><span class="koboSpan" id="kobo.573.1">: This is a 7-billion-parameter sparse Mixture-of-Experts language model that employs a highly parameter-efficient architecture. </span><span class="koboSpan" id="kobo.573.2">Despite its relatively compact total size, it utilizes 12 billion active parameters for any given input, enabling stronger language understanding and generation capabilities compared to similarly-sized dense models such as Mistral 7B. </span><span class="koboSpan" id="kobo.573.3">This sparse model supports processing inputs across multiple natural languages, as well as coding languages, catering to a wide range of multilingual and programming use cases. </span><span class="koboSpan" id="kobo.573.4">Additionally, Mixtral 8X7B maintains an extended context window of 32,000 tokens, allowing it to effectively model long-range dependencies within </span><span class="No-Break"><span class="koboSpan" id="kobo.574.1">lengthy inputs.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.575.1">Mistral Large</span></strong><span class="koboSpan" id="kobo.576.1">: This is capable of complex reasoning, analysis, text generation, and code generation and excels at handling intricate multilingual tasks across English, French, Italian, German, and Spanish. </span><span class="koboSpan" id="kobo.576.2">Mistral Large supports a maximum context window of 32,000 tokens, enabling it to process long-form inputs while delivering SOTA performance on language understanding, content creation, and coding applications demanding sophisticated </span><span class="No-Break"><span class="koboSpan" id="kobo.577.1">multilingual capabilities.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.578.1">Mistral Small</span></strong><span class="koboSpan" id="kobo.579.1">: This is an advanced language model designed for efficiency and affordability. </span><span class="koboSpan" id="kobo.579.2">It excels in handling high-volume, low-latency language tasks swiftly and cost-effectively. </span><span class="koboSpan" id="kobo.579.3">With its specialized capabilities, Mistral Small seamlessly tackles coding challenges and operates fluently across multiple languages, including </span><a id="_idIndexMarker090"/><span class="koboSpan" id="kobo.580.1">English, French, German, Spanish, and Italian. </span><span class="koboSpan" id="kobo.580.2">Mistral Small supports a maximum context window of </span><span class="No-Break"><span class="koboSpan" id="kobo.581.1">32,000 tokens.</span></span></li>
</ul>
<p><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.582.1">Figure 1</span></em></span><em class="italic"><span class="koboSpan" id="kobo.583.1">.9</span></em><span class="koboSpan" id="kobo.584.1"> illustrates </span><a id="_idIndexMarker091"/><span class="koboSpan" id="kobo.585.1">the usage of the Mistral Large model </span><a id="_idIndexMarker092"/><span class="koboSpan" id="kobo.586.1">with a reasoning scenario within Amazon Bedrock’s </span><span class="No-Break"><span class="koboSpan" id="kobo.587.1">text playground:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer016">
<span class="koboSpan" id="kobo.588.1"><img alt="Figure 1.9 – Mistral Large in Amazon Bedrock’s text playground" src="image/B22045_01_09.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.589.1">Figure 1.9 – Mistral Large in Amazon Bedrock’s text playground</span></p>
<h2 id="_idParaDest-27"><a id="_idTextAnchor026"/><span class="koboSpan" id="kobo.590.1">Stability AI – Stable Diffusion</span></h2>
<p><span class="koboSpan" id="kobo.591.1">Stable Diffusion was</span><a id="_idIndexMarker093"/><span class="koboSpan" id="kobo.592.1"> developed by Stability AI to generate</span><a id="_idIndexMarker094"/><span class="koboSpan" id="kobo.593.1"> highly realistic images using diffusion models trained on large datasets. </span><span class="koboSpan" id="kobo.593.2">The core technique behind Stable Diffusion is called </span><strong class="bold"><span class="koboSpan" id="kobo.594.1">latent diffusion</span></strong><span class="koboSpan" id="kobo.595.1">, which</span><a id="_idIndexMarker095"/><span class="koboSpan" id="kobo.596.1"> involves using a forward diffusion process to add noise to data over time, and a reverse diffusion process to gradually remove noise and reconstruct the original data. </span><span class="koboSpan" id="kobo.596.2">In the case of image generation, this allows the model to generate new images conditioned on text or image prompts provided by </span><span class="No-Break"><span class="koboSpan" id="kobo.597.1">the user.</span></span></p>
<p><span class="koboSpan" id="kobo.598.1">Amazon Bedrock provides </span><strong class="bold"><span class="koboSpan" id="kobo.599.1">SDXL 0.8</span></strong><span class="koboSpan" id="kobo.600.1"> and </span><strong class="bold"><span class="koboSpan" id="kobo.601.1">SDXL1.0</span></strong><span class="koboSpan" id="kobo.602.1"> Stable Diffusion models from Stability AI. </span><span class="koboSpan" id="kobo.602.2">The Stable Diffusion model aims to generate highly realistic images based on the text or image that’s provided as a prompt. </span><span class="koboSpan" id="kobo.602.3">SDXL 1.0 is particularly impressive due to its large model sizes. </span><span class="koboSpan" id="kobo.602.4">Its base model contains over </span><em class="italic"><span class="koboSpan" id="kobo.603.1">3.5 billion</span></em><span class="koboSpan" id="kobo.604.1"> parameters, while its ensemble pipeline uses two models totaling </span><em class="italic"><span class="koboSpan" id="kobo.605.1">6.6 billion</span></em><span class="koboSpan" id="kobo.606.1"> parameters. </span><span class="koboSpan" id="kobo.606.2">By aggregating results from multiple models, the ensemble approach generates even </span><span class="No-Break"><span class="koboSpan" id="kobo.607.1">higher-quality images.</span></span></p>
<p><span class="koboSpan" id="kobo.608.1">Through Amazon Bedrock, developers can leverage Stable Diffusion for a variety of image generation tasks. </span><span class="koboSpan" id="kobo.608.2">This includes generating images from text descriptions (text-to-image), generating new images based on existing images (image-to-image), as well as filling in missing areas (inpainting) or extending existing images (outpainting). </span><span class="koboSpan" id="kobo.608.3">We will look at these in detail in </span><a href="B22045_09.xhtml#_idTextAnchor171"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.609.1">Chapter 9</span></em></span></a><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.610.1">.</span></em></span></p>
<p><span class="koboSpan" id="kobo.611.1">Let’s run through a simple example of the Stable Diffusion model in Amazon Bedrock’s text playground by using this prompt: </span><strong class="source-inline"><span class="koboSpan" id="kobo.612.1">a dog wearing sunglasses, riding a bike </span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.613.1">on mars</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.614.1">.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer017">
<span class="koboSpan" id="kobo.615.1"><img alt="Figure 1.10 – Image generation with the Stable Diffusion model" src="image/B22045_01_10.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.616.1">Figure 1.10 – Image generation with the Stable Diffusion model</span></p>
<p><span class="koboSpan" id="kobo.617.1">The ability to automatically create visual content has many applications across industries such as advertising, media and entertainment, and gaming. </span><span class="koboSpan" id="kobo.617.2">In </span><a href="B22045_09.xhtml#_idTextAnchor171"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.618.1">Chapter 9</span></em></span></a><span class="koboSpan" id="kobo.619.1">, we will explore how </span><a id="_idIndexMarker096"/><span class="koboSpan" id="kobo.620.1">Stable Diffusion works under the hood. </span><span class="koboSpan" id="kobo.620.2">We </span><a id="_idIndexMarker097"/><span class="koboSpan" id="kobo.621.1">will also discuss best practices and architecture patterns for leveraging image generation models in </span><span class="No-Break"><span class="koboSpan" id="kobo.622.1">your applications.</span></span></p>
<h1 id="_idParaDest-28"><a id="_idTextAnchor027"/><span class="koboSpan" id="kobo.623.1">Evaluating and selecting the right FM</span></h1>
<p><span class="koboSpan" id="kobo.624.1">Now that we’ve </span><a id="_idIndexMarker098"/><span class="koboSpan" id="kobo.625.1">understood the different types of FMs available in Amazon Bedrock, how do we determine which one is best suited for our specific project needs? </span><span class="koboSpan" id="kobo.625.2">This section will help you learn how to evaluate the model fit for your </span><span class="No-Break"><span class="koboSpan" id="kobo.626.1">use case.</span></span></p>
<p><span class="koboSpan" id="kobo.627.1">The first step is to clearly define the problem you’re trying to solve or the use case you want to build. </span><span class="koboSpan" id="kobo.627.2">Get as specific as possible about the inputs, outputs, tasks involved, and any other requirements. </span><span class="koboSpan" id="kobo.627.3">With a well-defined use case in hand, you can research which models have demonstrated capabilities relevant to your needs. </span><span class="koboSpan" id="kobo.627.4">Narrowing the options upfront based on capabilities will streamline the </span><span class="No-Break"><span class="koboSpan" id="kobo.628.1">evaluation process.</span></span></p>
<p><span class="koboSpan" id="kobo.629.1">Once you’ve identified some potential candidate models, the next step is to examine their performance across standardized benchmarks and use cases. </span><span class="koboSpan" id="kobo.629.2">Amazon Bedrock provides a capability to evaluate FMs, also </span><a id="_idIndexMarker099"/><span class="koboSpan" id="kobo.630.1">called </span><strong class="bold"><span class="koboSpan" id="kobo.631.1">model evaluation jobs</span></strong><span class="koboSpan" id="kobo.632.1">. </span><span class="koboSpan" id="kobo.632.2">With model evaluation jobs, users have the option to use either automatic model evaluation or evaluation through the human workforce. </span><span class="koboSpan" id="kobo.632.3">We will cover Amazon Bedrock’s model evaluation in more detail in the </span><span class="No-Break"><span class="koboSpan" id="kobo.633.1">upcoming chapters.</span></span></p>
<p><span class="koboSpan" id="kobo.634.1">In addition, several </span><a id="_idIndexMarker100"/><span class="koboSpan" id="kobo.635.1">leaderboards and benchmarks exist today that can help with this evaluation, such as </span><span class="No-Break"><span class="koboSpan" id="kobo.636.1">the following:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.637.1">Stanford Helm leaderboard </span><span class="No-Break"><span class="koboSpan" id="kobo.638.1">for LLMs</span></span></li>
<li><span class="koboSpan" id="kobo.639.1">HuggingFace’s </span><span class="No-Break"><span class="koboSpan" id="kobo.640.1">open leaderboard</span></span></li>
<li><span class="No-Break"><span class="koboSpan" id="kobo.641.1">GLUE (</span></span><a href="https://gluebenchmark.com/"><span class="No-Break"><span class="koboSpan" id="kobo.642.1">https://gluebenchmark.com/</span></span></a><span class="No-Break"><span class="P---URL"><span class="koboSpan" id="kobo.643.1">)</span></span></span></li>
<li><span class="No-Break"><span class="koboSpan" id="kobo.644.1">SuperGLUE (</span></span><a href="https://super.gluebenchmark.com/"><span class="No-Break"><span class="koboSpan" id="kobo.645.1">https://super.gluebenchmark.com/</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.646.1">)</span></span></li>
<li><span class="No-Break"><span class="koboSpan" id="kobo.647.1">MMLU (</span></span><a href="https://paperswithcode.com/sota/multi-task-language-understanding-on-mmlu"><span class="No-Break"><span class="koboSpan" id="kobo.648.1">https://paperswithcode.com/sota/multi-task-language-understanding-on-mmlu</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.649.1">)</span></span></li>
<li><span class="No-Break"><span class="koboSpan" id="kobo.650.1">BIG-bench (</span></span><a href="https://github.com/google/BIG-bench"><span class="No-Break"><span class="koboSpan" id="kobo.651.1">https://github.com/google/BIG-bench</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.652.1">)</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.653.1">Reviewing where each model ranks on tasks related to your use case provides an objective measure of </span><span class="No-Break"><span class="koboSpan" id="kobo.654.1">its abilities.</span></span></p>
<p><span class="koboSpan" id="kobo.655.1">Apart from benchmark performance, inspecting each model’s cost per query, processing latency, training parameters if fine-tuning is needed, and any other non-functional requirements need to be considered. </span><span class="koboSpan" id="kobo.655.2">The right model needs to not only achieve your technical objectives but also fit within your cost and </span><span class="No-Break"><span class="koboSpan" id="kobo.656.1">timeline constraints.</span></span></p>
<p><span class="koboSpan" id="kobo.657.1">No evaluation is complete without hands-on testing. </span><span class="koboSpan" id="kobo.657.2">Take advantage of Amazon Bedrock’s text playground </span><a id="_idIndexMarker101"/><span class="koboSpan" id="kobo.658.1">or </span><strong class="bold"><span class="koboSpan" id="kobo.659.1">Amazon Partyrock</span></strong><span class="koboSpan" id="kobo.660.1"> to try out candidates on sample prompts, text generation tasks, or other example interactions representing your intended use case. </span><span class="koboSpan" id="kobo.660.2">More details regarding Amazon Bedrock’s text playground and Amazon Partyrock will be covered in the next chapter. </span><span class="koboSpan" id="kobo.660.3">This mechanism of model evaluation allows for a more qualitative assessment of things such as generated language quality, ability to maintain context, interpretability of responses, and the overall </span><em class="italic"><span class="koboSpan" id="kobo.661.1">feel</span></em><span class="koboSpan" id="kobo.662.1"> of interacting with </span><span class="No-Break"><span class="koboSpan" id="kobo.663.1">each model.</span></span></p>
<p><span class="koboSpan" id="kobo.664.1">By thoroughly researching capabilities, performance, and requirements, as well as testing multiple options, you’ll be well-equipped to select the right FM that provides the best overall fit and</span><a id="_idIndexMarker102"/><span class="koboSpan" id="kobo.665.1"> solution for your project needs. </span><span class="koboSpan" id="kobo.665.2">The right choice will help ensure your </span><span class="No-Break"><span class="koboSpan" id="kobo.666.1">project’s success.</span></span></p>
<h1 id="_idParaDest-29"><a id="_idTextAnchor028"/><span class="koboSpan" id="kobo.667.1">Generative AI capabilities of Amazon</span></h1>
<p><span class="koboSpan" id="kobo.668.1">This book is primarily </span><a id="_idIndexMarker103"/><span class="koboSpan" id="kobo.669.1">focused on Amazon Bedrock, but we wanted to highlight a few other generative AI capabilities offered by Amazon that are being used in enterprises for accelerating developer productivity, innovating faster, and solving their use cases </span><span class="No-Break"><span class="koboSpan" id="kobo.670.1">with ease.</span></span></p>
<h2 id="_idParaDest-30"><a id="_idTextAnchor029"/><span class="koboSpan" id="kobo.671.1">Amazon SageMaker</span></h2>
<p><strong class="bold"><span class="koboSpan" id="kobo.672.1">Amazon SageMaker</span></strong><span class="koboSpan" id="kobo.673.1"> is Amazon’s</span><a id="_idIndexMarker104"/><span class="koboSpan" id="kobo.674.1"> fully managed</span><a id="_idIndexMarker105"/><span class="koboSpan" id="kobo.675.1"> ML platform for building, training, and deploying ML models at scale. </span><span class="koboSpan" id="kobo.675.2">One of the most powerful features of SageMaker is SageMaker Jumpstart, which provides a catalog of pre-trained open source FMs that are ready to be deployed </span><span class="No-Break"><span class="koboSpan" id="kobo.676.1">and used.</span></span></p>
<p><span class="koboSpan" id="kobo.677.1">Some examples of FMs available in SageMaker Jumpstart include FLAN-T5 XL, a fine-tuned XL version of the T5 transformer model optimized for natural language understanding. </span><span class="koboSpan" id="kobo.677.2">Additional models, such as Meta Llama2, AI21 Jurassic-2 Ultra, and Stable Diffusion models, are also available in </span><span class="No-Break"><span class="koboSpan" id="kobo.678.1">SageMaker Jumpstart.</span></span></p>
<p><span class="koboSpan" id="kobo.679.1">In addition to deploying these pre-trained FMs directly, SageMaker Jumpstart provides tools for customizing and fine-tuning select models for specific use cases. </span><span class="koboSpan" id="kobo.679.2">For instance, users can perform prompt engineering to better control model responses by adjusting text prompts. </span><span class="koboSpan" id="kobo.679.3">Some models also support reasoning augmentation to improve the common-sense reasoning ability of LLMs through question-answering tasks. </span><span class="koboSpan" id="kobo.679.4">Fine-tuning capabilities allow you to adapt the language models to </span><span class="No-Break"><span class="koboSpan" id="kobo.680.1">domain-specific datasets.</span></span></p>
<p><span class="koboSpan" id="kobo.681.1">This enables engineers and researchers to leverage the power of these generative AI models directly from Jumpstart so that they can build novel applications without requiring deep expertise in model training. </span><span class="koboSpan" id="kobo.681.2">The SageMaker platform handles all the heavy lifting of deploying, scaling, and managing ML models. </span><span class="koboSpan" id="kobo.681.3">When you open SageMaker Jumpstart within SageMaker Studio UI, you will see models offered by different model providers. </span><span class="koboSpan" id="kobo.681.4">This can be seen in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.682.1">Figure 1</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.683.1">.11</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.684.1">:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer018">
<span class="koboSpan" id="kobo.685.1"><img alt="Figure 1.11 – SageMaker Jumpstart" src="image/B22045_01_11.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.686.1">Figure 1.11 – SageMaker Jumpstart</span></p>
<p><span class="koboSpan" id="kobo.687.1">You can choose the </span><a id="_idIndexMarker106"/><span class="koboSpan" id="kobo.688.1">model you would like to </span><a id="_idIndexMarker107"/><span class="koboSpan" id="kobo.689.1">work with based on your use case and deploy it directly to a SageMaker endpoint, or you can fine-tune the model with a custom dataset. </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.690.1">Figure 1</span></em></span><em class="italic"><span class="koboSpan" id="kobo.691.1">.12</span></em><span class="koboSpan" id="kobo.692.1"> shows several open source models offered by HuggingFace, on SageMaker Jumpstart, exemplifying the simplicity in SageMaker to search for models of your choice suited to a particular task using the search bar or </span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.693.1">Filters</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.694.1"> options:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer019">
<span class="koboSpan" id="kobo.695.1"><img alt="Figure 1.12 – SageMaker Jumpstart HuggingFace models" src="image/B22045_01_12.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.696.1">Figure 1.12 – SageMaker Jumpstart HuggingFace models</span></p>
<h2 id="_idParaDest-31"><a id="_idTextAnchor030"/><span class="koboSpan" id="kobo.697.1">Amazon Q</span></h2>
<p><strong class="bold"><span class="koboSpan" id="kobo.698.1">Amazon Q</span></strong><span class="koboSpan" id="kobo.699.1"> is a Generative</span><a id="_idIndexMarker108"/><span class="koboSpan" id="kobo.700.1"> AI-powered assistant</span><a id="_idIndexMarker109"/><span class="koboSpan" id="kobo.701.1"> that is built on top of Amazon Bedrock, and has been designed to enhance productivity and accelerate decision-making across various domains. </span><span class="koboSpan" id="kobo.701.2">It can assist users in a multitude of tasks, ranging from software development to data analysis and </span><span class="No-Break"><span class="koboSpan" id="kobo.702.1">decision making.</span></span></p>
<p><span class="koboSpan" id="kobo.703.1">Here is an overview of key offerings available with </span><span class="No-Break"><span class="koboSpan" id="kobo.704.1">Amazon Q.</span></span></p>
<h3><span class="koboSpan" id="kobo.705.1">Amazon Q for Business</span></h3>
<p><strong class="bold"><span class="koboSpan" id="kobo.706.1">Amazon Q for Business</span></strong><span class="koboSpan" id="kobo.707.1"> is an</span><a id="_idIndexMarker110"/><span class="koboSpan" id="kobo.708.1"> enterprise-grade, generative </span><a id="_idIndexMarker111"/><span class="koboSpan" id="kobo.709.1">AI-powered assistant designed to streamline operations and enhance productivity within organizations. </span><span class="koboSpan" id="kobo.709.2">With this tool you can access and interact with the company repositories of data if you have required permissions, simplifying tasks and accelerating problem-solving processes. </span><span class="koboSpan" id="kobo.709.3">Here are some key features of Amazon Q </span><span class="No-Break"><span class="koboSpan" id="kobo.710.1">for Business:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.711.1">Comprehensive Data Integration</span></strong><span class="koboSpan" id="kobo.712.1">: Amazon Q for Business seamlessly connects to over 40 popular enterprise data sources, including Amazon S3, Microsoft 365, and Salesforce. </span><span class="koboSpan" id="kobo.712.2">It ensures secure access to content based on existing user permissions and credentials, leveraging single sign-on for a </span><span class="No-Break"><span class="koboSpan" id="kobo.713.1">seamless experience.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.714.1">Intelligent Query Handling</span></strong><span class="koboSpan" id="kobo.715.1">: You can ask questions in natural language, and Amazon Q for Business will search across all connected data sources, summarize relevant information</span><a id="_idIndexMarker112"/><span class="koboSpan" id="kobo.716.1"> logically, analyze trends, and engage </span><a id="_idIndexMarker113"/><span class="koboSpan" id="kobo.717.1">in interactive dialogue. </span><span class="koboSpan" id="kobo.717.2">This empowers users to obtain accurate and comprehensive answers, eliminating the need for time-consuming manual </span><span class="No-Break"><span class="koboSpan" id="kobo.718.1">data searches.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.719.1">Customizable and Secure</span></strong><span class="koboSpan" id="kobo.720.1">: Organizations can tailor Amazon Q for Business to their specific needs by configuring administrative guardrails, document enrichment, and relevance tuning. </span><span class="koboSpan" id="kobo.720.2">This ensures that responses align with company guidelines while maintaining robust security and </span><span class="No-Break"><span class="koboSpan" id="kobo.721.1">access controls.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.722.1">Task Automation</span></strong><span class="koboSpan" id="kobo.723.1">: Amazon Q for Business allows users to streamline routine tasks, such as employee onboarding requests or expense reporting, through simple, natural language prompts. </span><span class="koboSpan" id="kobo.723.2">Additionally, users can create and share task automation applications, further enhancing efficiency </span><span class="No-Break"><span class="koboSpan" id="kobo.724.1">and productivity.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.725.1">You can set up Amazon Q for Business Application in a few clicks as shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.726.1">Figure 1</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.727.1">.13</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.728.1">.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer020">
<span class="koboSpan" id="kobo.729.1"><img alt="Figure 1.13 – Setting up Amazon Q for Business" src="image/B22045_01_13.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.730.1">Figure 1.13 – Setting up Amazon Q for Business</span></p>
<p><span class="koboSpan" id="kobo.731.1">For more details</span><a id="_idIndexMarker114"/><span class="koboSpan" id="kobo.732.1"> on</span><a id="_idIndexMarker115"/><span class="koboSpan" id="kobo.733.1"> setting up Amazon Q for Business Application, you can check the </span><span class="No-Break"><span class="koboSpan" id="kobo.734.1">link: </span></span><a href="https://docs.aws.amazon.com/amazonq/latest/qbusiness-ug/getting-started.html"><span class="No-Break"><span class="koboSpan" id="kobo.735.1">https://docs.aws.amazon.com/amazonq/latest/qbusiness-ug/getting-started.html</span></span></a></p>
<div>
<div class="IMG---Figure" id="_idContainer021">
<span class="koboSpan" id="kobo.736.1"><img alt="Figure 1.14 – Customize web experience for Amazon Q for Business" src="image/B22045_01_14.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.737.1">Figure 1.14 – Customize web experience for Amazon Q for Business</span></p>
<p><span class="koboSpan" id="kobo.738.1">Once the application is set up, users can customize the web experience for the Q business application as shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.739.1">Figure 1</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.740.1">.14</span></em></span></p>
<p><span class="koboSpan" id="kobo.741.1">Let us now</span><a id="_idIndexMarker116"/><span class="koboSpan" id="kobo.742.1"> look at another offering Amazon Q </span><span class="No-Break"><span class="koboSpan" id="kobo.743.1">for </span></span><span class="No-Break"><a id="_idIndexMarker117"/></span><span class="No-Break"><span class="koboSpan" id="kobo.744.1">QuickSight.</span></span></p>
<h3><span class="koboSpan" id="kobo.745.1">Amazon Q for QuickSight</span></h3>
<p><strong class="bold"><span class="koboSpan" id="kobo.746.1">Amazon Q for QuickSight</span></strong><span class="koboSpan" id="kobo.747.1"> is built</span><a id="_idIndexMarker118"/><span class="koboSpan" id="kobo.748.1"> for business users and analysts</span><a id="_idIndexMarker119"/><span class="koboSpan" id="kobo.749.1"> to unlock insights from their data more efficiently. </span><span class="koboSpan" id="kobo.749.2">It leverages the capabilities of Generative AI to streamline the process of data analysis and visualization. </span><span class="koboSpan" id="kobo.749.3">Here are some key features of Amazon Q for </span><span class="No-Break"><span class="koboSpan" id="kobo.750.1">QuickSight :</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.751.1">Intuitive Storytelling</span></strong><span class="koboSpan" id="kobo.752.1">: With Amazon Q for QuickSight, business users can create visually compelling narratives from their data by using simple, natural language prompts. </span><span class="koboSpan" id="kobo.752.2">These stories can include visuals, images, and text, making it easier to communicate insights and </span><span class="No-Break"><span class="koboSpan" id="kobo.753.1">align stakeholders.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.754.1">Executive Summaries</span></strong><span class="koboSpan" id="kobo.755.1">: Amazon Q for QuickSight can automatically generate executive summaries that highlight the most important trends and statistics from your dashboards. </span><span class="koboSpan" id="kobo.755.2">This feature saves time by providing a quick snapshot of key insights, eliminating the need to browse through </span><span class="No-Break"><span class="koboSpan" id="kobo.756.1">multiple visuals.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.757.1">Natural Language Q&amp;A</span></strong><span class="koboSpan" id="kobo.758.1">: Business users can confidently answer questions about their data using natural language queries. </span><span class="koboSpan" id="kobo.758.2">Amazon Q can understand vague or general questions, provide alternative perspectives, and offer context through </span><span class="No-Break"><span class="koboSpan" id="kobo.759.1">narrative summaries.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.760.1">Accelerated Dashboard Building</span></strong><span class="koboSpan" id="kobo.761.1">: Analysts can significantly reduce the time required to build dashboards by describing the desired visualizations using natural language. </span><span class="koboSpan" id="kobo.761.2">Amazon Q can interpret these prompts and generate the corresponding visuals </span><span class="No-Break"><span class="koboSpan" id="kobo.762.1">in seconds.</span></span></li>
</ul>
<h3><span class="koboSpan" id="kobo.763.1">Amazon Q for Developer</span></h3>
<p><strong class="bold"><span class="koboSpan" id="kobo.764.1">Amazon Q for Developer</span></strong><span class="koboSpan" id="kobo.765.1"> streamlines </span><a id="_idIndexMarker120"/><span class="koboSpan" id="kobo.766.1">the software </span><a id="_idIndexMarker121"/><span class="koboSpan" id="kobo.767.1">development lifecycle on AWS. </span><span class="koboSpan" id="kobo.767.2">Here are some key features of Amazon Q </span><span class="No-Break"><span class="koboSpan" id="kobo.768.1">for Developers:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.769.1">Intuitive Development Assistance</span></strong><span class="koboSpan" id="kobo.770.1">: Within IDEs, Amazon Q can provide real-time code suggestions, generate new code snippets, and offer guidance on software development best practices. </span><span class="koboSpan" id="kobo.770.2">This accelerates the coding process and </span><span class="No-Break"><span class="koboSpan" id="kobo.771.1">enhances productivity.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.772.1">Code Transformation</span></strong><span class="koboSpan" id="kobo.773.1">: Amazon Q can help you upgrade and modernize your legacy codebases by automatically transforming and optimizing your code to the latest language versions and frameworks. </span><span class="koboSpan" id="kobo.773.2">This capability ensures your applications remain up-to-date </span><span class="No-Break"><span class="koboSpan" id="kobo.774.1">and secure.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.775.1">Troubleshooting and Maintenance</span></strong><span class="koboSpan" id="kobo.776.1">: Amazon Q can assist you in diagnosing and resolving</span><a id="_idIndexMarker122"/><span class="koboSpan" id="kobo.777.1"> errors, bugs, and issues within</span><a id="_idIndexMarker123"/><span class="koboSpan" id="kobo.778.1"> your AWS applications. </span><span class="koboSpan" id="kobo.778.2">It can also help you understand and manage your AWS resources more efficiently, minimizing the need to navigate through </span><span class="No-Break"><span class="koboSpan" id="kobo.779.1">complex consoles.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.780.1">Cost Optimization</span></strong><span class="koboSpan" id="kobo.781.1">: By analyzing your AWS cost data, Amazon Q can provide valuable insights into your cloud spending patterns, helping you identify cost-saving opportunities and optimize your cloud infrastructure for better </span><span class="No-Break"><span class="koboSpan" id="kobo.782.1">cost efficiency.</span></span></li>
</ul>
<p><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.783.1">Figure 1</span></em></span><em class="italic"><span class="koboSpan" id="kobo.784.1">.15</span></em><span class="koboSpan" id="kobo.785.1"> and </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.786.1">Figure 1</span></em></span><em class="italic"><span class="koboSpan" id="kobo.787.1">.16</span></em><span class="koboSpan" id="kobo.788.1"> illustrate an example of Amazon Q Developer for aiding in productivity gains for software engineers </span><span class="No-Break"><span class="koboSpan" id="kobo.789.1">or developers.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer022">
<span class="koboSpan" id="kobo.790.1"><img alt="Figure 1.15 – Amazon Q Developer" src="image/B22045_01_15.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.791.1">Figure 1.15 – Amazon Q Developer</span></p>
<div>
<div class="IMG---Figure" id="_idContainer023">
<span class="koboSpan" id="kobo.792.1"><img alt="Figure 1.16 – Amazon Q Developer Lambda function" src="image/B22045_01_16.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.793.1">Figure 1.16 – Amazon Q Developer Lambda function</span></p>
<p><span class="koboSpan" id="kobo.794.1">With Amazon Q, developers </span><a id="_idIndexMarker124"/><span class="koboSpan" id="kobo.795.1">can streamline their workflows, from</span><a id="_idIndexMarker125"/><span class="koboSpan" id="kobo.796.1"> planning and development to testing, deployment, and maintenance, ultimately enabling them to deliver high-quality applications faster and with </span><span class="No-Break"><span class="koboSpan" id="kobo.797.1">greater confidence.</span></span></p>
<h1 id="_idParaDest-32"><a id="_idTextAnchor031"/><span class="koboSpan" id="kobo.798.1">Generative AI use cases with Amazon Bedrock</span></h1>
<p><span class="koboSpan" id="kobo.799.1">Since the advent of </span><a id="_idIndexMarker126"/><span class="koboSpan" id="kobo.800.1">generative AI, numerous organizations</span><a id="_idIndexMarker127"/><span class="koboSpan" id="kobo.801.1"> have benefited from the potential applications of this transformative technology in achieving their business objectives. </span><span class="koboSpan" id="kobo.801.2">Many of these organizations, which include Accenture, Adidas, Intuit, and Salesforce, have successfully developed prototypes and even have deployed production-ready generative AI systems using Amazon Bedroc</span><a id="_idTextAnchor032"/><span class="koboSpan" id="kobo.802.1">k. </span><span class="koboSpan" id="kobo.802.2">Across various industries, we have</span><a id="_idIndexMarker128"/><span class="koboSpan" id="kobo.803.1"> seen numerous compelling</span><a id="_idIndexMarker129"/><span class="koboSpan" id="kobo.804.1"> use cases for generative AI with Amazon Bedrock. </span><span class="koboSpan" id="kobo.804.2">Let’s learn more about some of these industries </span><span class="No-Break"><span class="koboSpan" id="kobo.805.1">in detail:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.806.1">Finance</span></strong><span class="koboSpan" id="kobo.807.1">: In the financial</span><a id="_idIndexMarker130"/><span class="koboSpan" id="kobo.808.1"> services sector, organizations have been working on use cases such as classifying and categorizing huge corpus of legal documents, developing systems to select optimal funding and investment plans for customers, providing insights and simplified summaries and Q&amp;As of complex financial documents, as well as detecting fraudulent activities such as forged signatures and tampered invoices. </span><span class="koboSpan" id="kobo.808.2">Additionally, organizations are utilizing Amazon Bedrock to understand market trends and customer behavior, aiding in informed </span><span class="No-Break"><span class="koboSpan" id="kobo.809.1">decision-making processes.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.810.1">Healthcare</span></strong><span class="koboSpan" id="kobo.811.1">: The healthcare industry has witnessed significant investment in developing generative AI applications with Amazon Bedrock. </span><span class="koboSpan" id="kobo.811.2">At the time of writing, AWS HealthScribe has been announced, which is powered by Amazon Bedrock (</span><a href="https://aws.amazon.com/healthscribe/"><span class="koboSpan" id="kobo.812.1">https://aws.amazon.com/healthscribe/</span></a><span class="koboSpan" id="kobo.813.1">). </span><span class="koboSpan" id="kobo.813.2">These applications address a wide range</span><a id="_idIndexMarker131"/><span class="koboSpan" id="kobo.814.1"> of use cases, such as automating medical claims and adjudication processes, extracting valuable insights from health documents and medical research papers, and generating summaries of patient-doctor interactions. </span><span class="koboSpan" id="kobo.814.2">By leveraging Amazon Bedrock, healthcare providers are aiming to enhance patient care and drive innovation in </span><span class="No-Break"><span class="koboSpan" id="kobo.815.1">the field.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.816.1">Media and entertainment</span></strong><span class="koboSpan" id="kobo.817.1">: In the media and entertainment industry, organizations are actively exploring the diverse applications with Amazon Bedrock. </span><span class="koboSpan" id="kobo.817.2">These include generating narratives and storylines in sports and broadcasting, creating captions, images, and animations for storytelling, as well as providing personalized recommendations for TV shows, movies, and other forms of entertainment. </span><span class="koboSpan" id="kobo.817.3">By harnessing the capabilities of generative AI with Amazon Bedrock, media and entertainment companies aim to enhance the user experience, create engaging content, and stay ahead of </span><span class="No-Break"><span class="koboSpan" id="kobo.818.1">the competition.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.819.1">These are just a few examples of the numerous use cases that various industries are working on. </span><span class="koboSpan" id="kobo.819.2">In later chapters, we will understand </span><a id="_idIndexMarker132"/><span class="koboSpan" id="kobo.820.1">architectural patterns in building industry-specific use</span><a id="_idIndexMarker133"/><span class="koboSpan" id="kobo.821.1"> cases through </span><span class="No-Break"><span class="koboSpan" id="kobo.822.1">Amazon Bedrock.</span></span></p>
<h1 id="_idParaDest-33"><a id="_idTextAnchor033"/><span class="koboSpan" id="kobo.823.1">Summary</span></h1>
<p><span class="koboSpan" id="kobo.824.1">In this chapter, we explored the various facets of the generative AI landscape: from understanding language models and the development of various NLP techniques to the invention of current SOTA transformer models. </span><span class="koboSpan" id="kobo.824.2">Then, we covered industrial challenges in building generative AI applications at scale and how Amazon Bedrock is seamlessly tackling </span><span class="No-Break"><span class="koboSpan" id="kobo.825.1">those challenges.</span></span></p>
<p><span class="koboSpan" id="kobo.826.1">Furthermore, we explored various FMs offered by Amazon Bedrock and provided insights into how you can take advantage of various frameworks and tools to evaluate and select the right FM for your use case. </span><span class="koboSpan" id="kobo.826.2">We also looked at alternative generative AI capabilities offered by Amazon, including Amazon SageMaker and Amazon Q. </span><span class="koboSpan" id="kobo.826.3">We concluded this chapter by uncovering a few generative AI use cases with Amazon Bedrock in financial services, healthcare, and media </span><span class="No-Break"><span class="koboSpan" id="kobo.827.1">and entertainment.</span></span></p>
<p><span class="koboSpan" id="kobo.828.1">In the next chapter, we will discover several techniques to access Amazon Bedrock and dive into various APIs via serverless services. </span><span class="koboSpan" id="kobo.828.2">Furthermore, we will learn about a hands-on approach toward invoking Bedrock FMs that can be integrated into </span><span class="No-Break"><span class="koboSpan" id="kobo.829.1">enterprise-grade applications.</span></span></p>
</div>
</body></html>