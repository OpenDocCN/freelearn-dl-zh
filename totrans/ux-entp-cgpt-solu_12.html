<html><head></head><body>
		<div><h1 id="_idParaDest-185" class="chapter-number"><a id="_idTextAnchor190" class="pcalibre pcalibre1 calibre6"/>9</h1>
			<h1 id="_idParaDest-186" class="calibre5"><a id="_idTextAnchor191" class="pcalibre pcalibre1 calibre6"/>Guidelines and Heuristics</h1>
			<p class="calibre3">This chapter explains what makes an excellent conversational style. Some of what is covered may seem obvious, but exploring and understanding why something works or doesn’t work is valuable when applying the concepts</p>
			<p class="calibre3"> to new situations. ChatGPT is unique because it won’t necessarily answer the same question again in the same way, which is why <a href="B21964_07.xhtml#_idTextAnchor150" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 7</em></a>, <em class="italic">Prompt Engineering</em>, was essential. This chapter will cover guidelines and heuristics to evaluate and improve the experience you are designing. We are not picky about what we call these, but we can use better definitions. <strong class="bold">Guidelines</strong> are particular and tend to be based on user research. <strong class="bold">Standards</strong> are more specific, while <strong class="bold">best practices</strong> are recommendations based on certain conditions. Vendors such as Apple’s <strong class="bold">Human Interface Guidelines</strong> (<strong class="bold">HIG</strong>) or Google’s <strong class="bold">Material Design</strong> are widely copied and include all of these protocols. Organizations or governments can mandate guidelines and standards as required. <strong class="bold">Heuristics</strong> are rules of thumb or strategies to break down a problem into elements that need attention.</p>
			<pre class="source-code">
Guideline (Smith and Mosier, 1986): Design text editing logic so that any user action is immediately reversible.
Standard: A text header should be Bold Calibri 11-point typeface.
Best Practice (Apple Human Interface Guidelines): Use a chart to highlight important information about a dataset.
Material Design (Google): Consider making pointer targets at least 44 x 44 dp.
Heuristic: Titles should be readable and aesthetically pleasing.</pre>			<p class="calibre3">The point is that there are things one should follow (guidelines, standards, best practices, and design recommendations), and there are strategies (heuristics) to figure out what to do. Some apply to the GUI encompassing the conversational AI, and some are for conversational text. All of this is covered in this chapter:</p>
			<ul class="calibre7">
				<li class="calibre8">Applying guidelines to design</li>
				<li class="calibre8">Adapting heuristic analysis for conversational UIs</li>
				<li class="calibre8">Building conversational guidelines</li>
				<li class="calibre8">Case study</li>
			</ul>
			<p class="calibre3">All of these are for knowing what to do before doing it. We can use this knowledge for the next interaction if we learn what works. Design guidelines have evolved, but as we will see, some have been around for decades, and not only do they still apply, but they might even apply more than before.</p>
			<h1 id="_idParaDest-187" class="calibre5"><a id="_idTextAnchor192" class="pcalibre pcalibre1 calibre6"/>Applying guidelines to design</h1>
			<p class="calibre3">This book follows the order of the life cycle of conversational AI design. Why do guidelines and heuristics come after “building” the experience and prompt engineering? This is a chicken and egg problem. Many teams create generative AI experiences for the first time. The application of guidelines and heuristics has to be done with some understanding of what has previously been built. In visual experiences such as GUIs, previous project experience helps inform what guidelines and heuristics will translate into new designs. This is not the case with conversational AI. This advice is here to help you get started and be there as your journey unfolds.</p>
			<p class="calibre3">Software tests can be crafted to <a id="_idIndexMarker611" class="pcalibre pcalibre1 calibre6"/>evaluate whether a guideline is met. Testing is more challenging with a heuristic. The heuristics used for evaluation are broader than the precise nature of a software test case. Using the examples of standard to use Bold Calibri as a font in a header, each header would need its own test to evaluate a user experience for this condition. It is a trade-off. More expertise is needed to know and internalize heuristics, and it’s the same with guidelines. Another difference is that a heuristic will stand the test of time. They are generic enough to adapt as experiences evolve. Because they are generic, they are hard to define in code. How should the heuristic <em class="italic">titles should be readable</em> be measured? Because a guideline is more specific, it might only apply to a particular UI or use case. However, they are still valuable. In addition, understanding the underlying science behind a guideline can help you more effectively apply it to new experiences.</p>
			<p class="calibre3">One of the first sets of guidelines I ever used was by Smith and Mosier (1986). The document contained 944 guidelines for software interfaces. Don’t dismiss them because they might be older than you. They are based on research on human behavior and capabilities. Human behavior hasn’t evolved to invalidate them, even with new contexts for their uses, such as high-resolution displays, voice interfaces, and hand-held devices. There are a lot of universal truths in them. Many of these original guidelines were associated with text-based experiences, and it seems like what goes around comes around, as, surprisingly, we have <a id="_idIndexMarker612" class="pcalibre pcalibre1 calibre6"/>returned to text-based solutions with chat, conversational, and recommender experiences.</p>
			<p class="calibre3">Article: <a href="https://hcibib.org/sam/" class="pcalibre pcalibre1 calibre6">Smith and Mosier’s Guidelines for Designing User Interface Software</a> (<a href="https://hcibib.org/sam/" class="pcalibre pcalibre1 calibre6">https://hcibib.org/sam/</a>)</p>
			<p class="calibre3">However, as I mentioned, these guidelines are for <strong class="bold">User Interfaces</strong> (<strong class="bold">UIs</strong>), and heuristics might apply better to evaluate conversational experiences. The evolution of these heuristics is based on the solid scientific efforts of these researchers and previous ones. Before diving in, here is one more example. Bruce Tognazzini is a famous Apple designer and an early partner at the Nielsen Norman Group. He is someone the industry has respected and appreciated for years. I invited him to be the keynote speaker for a conference host in Blacksburg, VA. You know his keynote was going to be a little crazy when he asked the hotel for fire extinguishers to be present. That freaked out the hotel management. Being a little shocking applies to guidelines as well. Some will seem a little crazy, but they can be applied more effectively by going deeper and learning about their origins and scientific underpinnings. Then, they won’t seem crazy when they apply to enterprise use cases, nor was his reason for wanting a fire extinguisher, once you understood its purpose. Here is his list of principles; see how they can easily apply to the ChatGPT frontier.</p>
			<p class="calibre3">Article: <a href="https://asktog.com/atc/principles-of-interaction-design/" class="pcalibre pcalibre1 calibre6">First Principles of Interaction Design</a> (<a href="https://asktog.com/atc/principles-of-interaction-design/" class="pcalibre pcalibre1 calibre6">https://asktog.com/atc/principles-of-interaction-design/</a>)</p>
			<h1 id="_idParaDest-188" class="calibre5"><a id="_idTextAnchor193" class="pcalibre pcalibre1 calibre6"/>Adapting heuristic analysis for conversational UIs</h1>
			<p class="calibre3">A wide range of possible issues can be found with a good set of heuristics. Heuristic evaluations can<a id="_idIndexMarker613" class="pcalibre pcalibre1 calibre6"/> range from formal to informal. The more formal approach is to enlist three to five usability experts as evaluators. Once provided context and the background of the tasks and users, they can independently evaluate the experience against their understanding of the heuristics. By documenting the issues, scoring their importance, and compiling the results from each reviewer, the team can prioritize the issues to be addressed. This approach can be used to look at UI issues, and much of this can also be used to understand conversational interactions.</p>
			<p class="calibre3">These issues will not be found in surveys that provide a score, such as the <strong class="bold">Net Promoter Score</strong> (<strong class="bold">NPS</strong>) or the <strong class="bold">Software Usability Score</strong> (<strong class="bold">SUS</strong>), covered in the next<a id="_idIndexMarker614" class="pcalibre pcalibre1 calibre6"/> chapter. NPS or SUS can be applied <a id="_idIndexMarker615" class="pcalibre pcalibre1 calibre6"/>once customers are exposed to the product; a heuristic evaluation of a working prototype has some advantages:</p>
			<ul class="calibre7">
				<li class="calibre8">It can be done early in the design process</li>
				<li class="calibre8">It is inexpensive</li>
				<li class="calibre8">UX professionals can do it, and others can participate as well</li>
				<li class="calibre8">They are battle-tested for traditional GUI evaluations</li>
				<li class="calibre8">They are adapted here to consider conversational experiences<ul class="calibre19"><li class="calibre8">With unique chat and recommendation UIs</li><li class="calibre8">For hybrid UIs that use GUI components within a chat</li><li class="calibre8">For sentences, when explicitly defined in templates, with deterministic flows, or controlled abstractly through prompts</li><li class="calibre8">As part of prompts to instruct the LLM to value the heuristics</li></ul></li>
			</ul>
			<p class="calibre3">There are some issues to address as well:</p>
			<ul class="calibre7">
				<li class="calibre8">It can be biased based on the evaluator (which is why a few evaluators participate)</li>
				<li class="calibre8">It depends on the evaluator having enough expertise in the evaluation and the feature to detect issues (evaluators can be trained, given time to practice and explore and be provided sample use cases, but all of<a id="_idIndexMarker616" class="pcalibre pcalibre1 calibre6"/> this can bias a review)</li>
				<li class="calibre8">It is best done with three to five evaluators, who might be hard to get</li>
				<li class="calibre8">It can return issues that are not significant</li>
			</ul>
			<p class="calibre3">To balance the good and the bad, the following is suggested:</p>
			<ul class="calibre7">
				<li class="calibre8">Review the heuristic tools before the evaluation and coach people on a separate example product to reinforce the method and heuristics</li>
				<li class="calibre8">Provide a printout of the heuristics to the evaluator</li>
				<li class="calibre8">Remind evaluators to put on their customer hats</li>
				<li class="calibre8">After the evaluation, use the scoring tools discussed in the earlier chapters to prioritize and focus on the most valuable findings</li>
				<li class="calibre8">Iterate quickly so that future evaluations can reveal new items and are not masked by more significant, overwhelming issues</li>
				<li class="calibre8">It is reasonable to use heuristics in your daily design efforts to guide you to solutions that are already good before a customer sees the results</li>
			</ul>
			<p class="calibre3">We need a set of heuristics to provide the most significant value with the least cost. One set already comes to mind.</p>
			<p class="calibre3">I always start and finish with Jakob Nielsen’s ten heuristics. They are broad enough to apply to various situations, have been revised, and used for over 30 years, which gives them some street credibility. They cover a range of issues found in user experiences. Usually, but not exclusively applied to GUIs, they need to be put in the context of conversational AI. The articles I reference cover the basics of heuristics, and hundreds of other articles are out there. Sometimes, these guides will be spot on – for hybrid experiences that include UI<a id="_idIndexMarker617" class="pcalibre pcalibre1 calibre6"/> components with conversations. The UI heuristics are well documented. The added value to expose is how these apply to our conversational experiences. This would be called color commentary to make an analogy to watching sports on TV. The play (the heuristic) is taken, and a discussion explains it so a layperson can understand their application to a conversational UI.</p>
			<p class="calibre3">Article: <a href="https://www.interaction-design.org/literature/topics/heuristic-evaluation" class="pcalibre pcalibre1 calibre6">Intro to Heuristic Evaluation (HE)</a> (<a href="https://www.interaction-design.org/literature/topics/heuristic-evaluation" class="pcalibre pcalibre1 calibre6">https://www.interaction-design.org/literature/topics/heuristic-evaluation</a>)</p>
			<p class="calibre3">Article: <a href="https://www.nngroup.com/articles/how-to-conduct-a-heuristic-evaluation/" class="pcalibre pcalibre1 calibre6">How to perform a heuristic evaluation</a> (<a href="https://www.nngroup.com/articles/how-to-conduct-a-heuristic-evaluation/" class="pcalibre pcalibre1 calibre6">https://www.nngroup.com/articles/how-to-conduct-a-heuristic-evaluation/</a>)</p>
			<p class="calibre3">Extensive examples that support conversational flow and recommendation UIs will be used. This chapter won’t benefit backend experiences, as the heuristic is about evaluating the user experience.</p>
			<p class="calibre3">Expecting a conversational AI to return exact messages might be a challenge. It depends on what is in control of the output. If ChatGPT controls the output, we have to rely on prompt engineering and fine-tuning to get it close. Suppose a traditional deterministic chat experience provides the front end. In that case, you can specify precisely the response wanted or a collection of responses to pick from. You can use ChatGPT to understand entities, ask questions to fill in gaps, or perform other language tasks to support the higher purpose. Recommender UIs sometimes use a text template. ChatGPT can gather input, fill in values, transcode details, and provide translation. Keep these in mind, as the heuristics can apply in different ways to each context of use.</p>
			<p class="calibre3">If you want to see any of the<a id="_idIndexMarker618" class="pcalibre pcalibre1 calibre6"/> following examples show up directly in a ChatGPT chat, it is hard to make it happen consistently. It comes back to instructions. It is possible to use the definitions in the heuristics for the instructions on how to formulate responses. That would be a great research project. We will use a new employee onboarding process example prompt incorporating critical heuristics to guide discussions. The heuristic influences are highlighted in <strong class="bold">bold</strong>.</p>
			<pre class="source-code">
Instructions for the new hire onboarding skill
I have provided a document that outlines our company's onboarding process. I need you to create a set of detailed instructions from this document. As the user performs each step, reach out to the appropriate service to <strong class="bold1">verify completion</strong> and <strong class="bold1">provide the status of each step</strong>. Follow these guidelines:
1. Format the instructions as a numbered list.
2. <strong class="bold1">Each step should be clear and concise, with no more than two sentences per step</strong>.
3. Use <strong class="bold1">formal language</strong> suitable for interacting with a new professional.
4. Focus on key actions new employees must take and <strong class="bold1">omit any unnecessary background information</strong>.
5. The instructions <strong class="bold1">should be easy to follow</strong> for someone new to the company.
6. Do not ask the new employee to remember information. <strong class="bold1">Provide details at each step</strong> and <strong class="bold1">confirm any understanding</strong> of those steps as you proceed through the process.
7. If there are errors, report them in <strong class="bold1">clear, simple terms</strong> and <strong class="bold1">explain how to fix them</strong>. If a step doesn't block progress, keep track of it so the user can <strong class="bold1">complete it in any order</strong>.
8. Keep it short and simple for questions that have well-known answers, like Age or Height. For less <strong class="bold1">well-known questions</strong>, provide an example or details about what is needed.
For example:
1.**Sign into the company portal**: Use your assigned credentials from the welcome email to access the portal.
2. **Complete the onboarding form**: Fill out all required fields, including your personal and emergency contact information. <strong class="bold1">Let me know</strong> if any fields need clarification.</pre>			<p class="calibre3">A callout for each heuristic will discuss the heuristic influences found in the instructions provided to the LLM. The following are<a id="_idIndexMarker619" class="pcalibre pcalibre1 calibre6"/> the heuristics. Each will be defined and explained, along with an analysis of how they can be applied.</p>
			<ul class="calibre7">
				<li class="calibre8"><em class="italic">Visibility of </em><em class="italic">system status</em></li>
				<li class="calibre8"><em class="italic">Match between a system and the </em><em class="italic">real world</em></li>
				<li class="calibre8"><em class="italic">User control </em><em class="italic">and freedom</em></li>
				<li class="calibre8"><em class="italic">Consistency </em><em class="italic">and standards</em></li>
				<li class="calibre8"><em class="italic">Error prevention</em></li>
				<li class="calibre8"><em class="italic">Recognition rather </em><em class="italic">than recall</em></li>
				<li class="calibre8"><em class="italic">Flexibility and efficiency </em><em class="italic">of use</em></li>
				<li class="calibre8"><em class="italic">Aesthetic and </em><em class="italic">minimalist design</em></li>
				<li class="calibre8"><em class="italic">Help users recognize, diagnose, and recover </em><em class="italic">from errors</em></li>
				<li class="calibre8"><em class="italic">Help </em><em class="italic">and documentation</em></li>
			</ul>
			<p class="calibre3">Each heuristic follows the same model. The name of the heuristic, the exact definition, the analysis to apply it to <a id="_idIndexMarker620" class="pcalibre pcalibre1 calibre6"/>conversational AI, and a callout for an analysis of the new hire onboarding example.</p>
			<h2 id="_idParaDest-189" class="calibre9"><a id="_idTextAnchor194" class="pcalibre pcalibre1 calibre6"/>1 – Visibility of system status</h2>
			<p class="calibre3"><em class="italic">The design should always keep users informed about what is going on through appropriate feedback within a reasonable amount </em><em class="italic">of time.</em></p>
			<h3 class="calibre11">Analysis</h3>
			<p class="calibre3">In a chat experience, keeping the user informed is typically done through textual response. In process flows, some information will repeat<a id="_idIndexMarker621" class="pcalibre pcalibre1 calibre6"/> to provide context when prompted for the next step. The user expects to see this in seconds or less. Waiting 10 seconds to gather backend data would be odd. If providing timely information is a problem, give that feedback. Sometimes, it is challenging to provide estimates. If the user expects delays, they might feel better about it. Learn from these examples:</p>
			<pre class="source-code">
I am gathering the results. I will get back to you in about 20 seconds.
I am gathering data from 35 systems for you. Some are slow. Give me about 15 more seconds.
The engine rebuild you requested will not be finished for 3 more hours. Can I email or text you when it is ready?</pre>			<p class="calibre3">It is crazy to start this section with this horrible user experience, making the user wait <em class="italic">forever</em>. We will explore a few more typical system status examples.</p>
			<p class="calibre3">Here is an appropriate level of feedback, confirming that the address step is completed with enough context for the user to pick a delivery date in the future:</p>
			<pre class="source-code">
I have your shipping address. We can deliver as soon as Friday. When would you like the delivery?</pre>			<p class="calibre3">What gets provided as feedback should be limited. If the address is confirmed, don’t repeat it along with everything else in the order. Wait until there is a summary or when the user requests the address. This is the <em class="italic">appropriate feedback</em>. Here is an example of how to give instructions to the LLM. Recall from <a href="B21964_07.xhtml#_idTextAnchor150" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 7</em></a><em class="italic"> – Prompt Engineering</em>: the instructions are prompts that wrap the customer conversation so that the customer prompts have some guidance. It is ok to refer to these as instructions or prompts if you realize the context is an overarching prompt, not what the user types (also called the user prompt).</p>
			<pre class="source-code">
Instruction Tip:
Use a summary if you have already confirmed information and must let the user know you still have it.
For example:
If you confirmed the user's shipping address on the last step, refer to it as "your shipping address." Don't repeat the entire address unless requested.</pre>			<p class="calibre3">It would be challenging if a calendar was full of unavailable delivery dates. The user would be stuck in a mindless game of picking a date. For example, in a voice-only solution, offer three suggestions for delivery or openings around a date they provide. A GUI can show a month-at-a-glance view with available delivery dates. It would show the next available date and offer to edit that if it doesn’t work. That way, the user understands what the system can do:</p>
			<pre class="source-code">
I have your shipping address. Our first available delivery is on Friday, August 9th. We can also look for later dates.</pre>			<p class="calibre3">If the user experience is just a recommendation and not interactive, it still can be good to clarify the information based on the recommendation. If they change something on the screen, will the recommendation update? For example, if the recommendation is to email the customer this week, does it know that I already emailed them today? Even if this information is not directly related to the recommendation, have a clickable affordance, like an <strong class="bold">info</strong> button, to explain <a id="_idIndexMarker622" class="pcalibre pcalibre1 calibre6"/>what went into the recommendation and, in this example, whether the last email was accounted for. Here is what could be behind the <strong class="bold">info</strong> button:</p>
			<pre class="source-code">
This recommendation is based on a few factors:
  • Email was sent on Tuesday.
  • The customer visited a few weeks ago.
  • The analysis of this customer's
    willingness to buy compared to other customers.</pre>			<p class="calibre3">Giving the timing information (e.g., last updated three minutes ago, or this recommendation is based on details updated yesterday) can help gauge the relevance of the recommendations.</p>
			<p class="calibre3">There’s one last thought about system status, which can also apply to backend services or recommendations. If an unavailable resource impacts the data, let people know. Don’t just time out a connection. Integrations should support and communicate the edge cases of the system being down. It should mirror the style and tone of the service and not be a cryptic err<a id="_idTextAnchor195" class="pcalibre pcalibre1 calibre6"/><a id="_idTextAnchor196" class="pcalibre pcalibre1 calibre6"/>or message:</p>
			<pre class="source-code">
Oops! We can't access the recommendation system. It appears offline. If this persists, please report it to it@company.com.</pre>			<p class="calibre3">This email link should populate the subject and body with technical information. To take this to the next level, in the right conditions, do this:</p>
			<pre class="source-code">
Oops! We can't access the recommendation system. It appears offline. The IT department was notified, and a trouble ticket was filed.</pre>			<p class="calibre3">Depending on the audience, it might link to the ticket or cc the customer. This message is okay to be repeatable and consistent. Please do not leave it to the LLM to generate the response. It should be so rare that variety won’t matter, and we want to be very specific about the error’s <a id="_idIndexMarker623" class="pcalibre pcalibre1 calibre6"/>development. If exposing too much detail confuses the user, stick to a generic message.</p>
			<p class="calibre3">Here is the first callout explaining the impact of this heuristic on the new employee onboarding instructions. We won’t introduce the callout each time; they will always be last for each heuristic.</p>
			<p class="callout-heading">Analysis for new employee onboarding, visibility of system status</p>
			<p class="callout">Heuristic influences: <em class="italic">Focus on key actions</em>, <em class="italic">provide details at each step</em>, <em class="italic">and if there </em><em class="italic">are errors</em></p>
			<p class="callout">There are a few places where status should be communicated to guide the user. Confirming that progress is tracked and reporting on errors along will also help through the stressful time of starting a new job.</p>
			<h2 id="_idParaDest-190" class="calibre9"><a id="_idTextAnchor197" class="pcalibre pcalibre1 calibre6"/>2 – Match between a system and the real world</h2>
			<p class="calibre3"><em class="italic">The design should speak the users’ language. Use words, phrases, and concepts familiar to the user, rather than internal jargon. Follow real-world conventions, making information appear in a natural and </em><em class="italic">logical order.</em></p>
			<h3 class="calibre11">Analysis</h3>
			<p class="calibre3">Style and tone go a long way<a id="_idIndexMarker624" class="pcalibre pcalibre1 calibre6"/> when communicating in a conversational tone. It gets trickier with enterprise software. If the user refers to the ordering system, don’t reply with the <em class="italic">order entry and tracking system</em>. They might not realize it is the same system. Actively mirror the customer language and conventions, but do so in a style consistent with the organization. Recall our surf shop example. To confirm an order, use this:</p>
			<pre class="source-code">
Hang Ten! Your new board is hitting the waves via UPS. We will drop the tracking code by sunrise. Mahalo.</pre>			<p class="calibre3">Prompt engineering and fine-tuning establish less colorful responses from a financial service company. The response will be in more formal business-speak:</p>
			<pre class="source-code">
Your new business checks for your Alligiance money market account will ship tomorrow via USPS.</pre>			<p class="calibre3">This is also an excellent heuristic for appreciating how to display information. Consider the format of content, or with lists, the order for the information provided. <em class="italic">Table 9.1</em> shares order and format options for displaying information. <em class="italic">Use prompts to set an order </em><em class="italic">and format.</em></p>
			<table id="table001-8" class="no-table-style">
				<colgroup class="calibre15">
					<col class="calibre16"/>
					<col class="calibre16"/>
				</colgroup>
				<thead class="calibre18">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Order (</strong><strong class="bold">for lists)</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Format (for </strong><strong class="bold">complex content)</strong></p>
						</td>
					</tr>
				</thead>
				<tbody class="calibre17">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<ul class="calibre7">
								<li class="calibre8">Alphabetical</li>
								<li class="calibre8">Chronological</li>
								<li class="calibre8">Classifications</li>
								<li class="calibre8">Highest to Lowest</li>
								<li class="calibre8">Location or Distance</li>
								<li class="calibre8">Logical</li>
								<li class="calibre8">Most to Least Expensive</li>
								<li class="calibre8">Numeric</li>
								<li class="calibre8">Popularity</li>
								<li class="calibre8">Priority</li>
								<li class="calibre8">Random</li>
								<li class="calibre8">Size or Dimensions</li>
							</ul>
						</td>
						<td class="no-table-style2">
							<ul class="calibre7">
								<li class="calibre8">Bullet List</li>
								<li class="calibre8">Calendar</li>
								<li class="calibre8">Cards/Tiles (Like a Business Card)</li>
								<li class="calibre8">Charts or Graphs</li>
								<li class="calibre8">File Formats (PDF, XLS, or Doc)</li>
								<li class="calibre8">Image or Graphic</li>
								<li class="calibre8">Maps</li>
								<li class="calibre8">Ordered List</li>
								<li class="calibre8">Spreadsheet (Downloadable)</li>
								<li class="calibre8">Table</li>
								<li class="calibre8">Trees</li>
							</ul>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Table 9.1 – Common design alternatives to display information</p>
			<p class="callout-heading">Analysis for new employee onboarding, match between a system and the real world</p>
			<p class="callout">Heuristic influences: <em class="italic">clear, simple terms</em>, and <em class="italic">should be easy </em><em class="italic">to follow</em></p>
			<p class="callout">The intent is to get them onboarded, not to teach them jargon. The prompt emphasized that this is a new employee, so clarity is key.</p>
			<h2 id="_idParaDest-191" class="calibre9"><a id="_idTextAnchor198" class="pcalibre pcalibre1 calibre6"/>3 – User control and freedom</h2>
			<p class="calibre3"><em class="italic">Users often perform actions by mistake. They need a clearly marked “emergency exit” to leave the unwanted action without having to go through an </em><em class="italic">extended process.</em></p>
			<h3 class="calibre11">Analysis</h3>
			<p class="calibre3">Usually, buttons such as <strong class="bold">Cancel</strong> are on a dialog box or in a multiple-step process; the user can cancel or leave the process and pick it up later. Too many UIs are scary because it seems possible to lose work<a id="_idIndexMarker625" class="pcalibre pcalibre1 calibre6"/>. How about a website that times out five minutes into a long form? If you sign back in, can you pick up where you left off? If the user accidentally closes the window or clicks the <strong class="bold">Back</strong> button on a browser, can they return without losing work? Alternatively, figuring out how to undo an action might be challenging. An online shopping cart has this issue. Sometimes, finding out how to get out of the cart or remove an item is (intentionally) difficult. Some carts have a distinct remove button. Others also include a save for later button to encourage future purchases. Others make the user set the quantity to zero (which is both indirect and not marked).</p>
			<p class="calibre3">In a traditional UI design, be explicit, such as giving the user cancel and accept buttons for a dialog box. A textual interface or voice interface won’t have visual affordances. Suggest a path forward if the<a id="_idIndexMarker626" class="pcalibre pcalibre1 calibre6"/> user needs clarification or guidance:</p>
			<pre class="source-code">
(System provides a summary of a transaction)
If this looks correct, reply "submit." You can also give me changes or even cancel the order.</pre>			<p class="calibre3">Here, the control term <code>"submit"</code> is not necessarily required in a conversational AI. This message encourages the user to move forward; it is not written to force them to accept the next step. Many words/phrases might be supported, and the system has to decide if those words are enough to confirm the action. I asked ChatGPT to classify a collection of terms that might mean submit.</p>
			<pre class="source-code-right">classify the examples as stronglyconfirming, sort of confirming,weakly confirming, or notconfirming the order.
<strong class="bold1">Strongly Confirming:</strong>
Go ahead with it, Let's finalize this, Proceed with the order, Give it the green light, We're ready to move forward, Submit the order, Send order, Submit order
<strong class="bold1">Sort of Confirming:</strong>
Let's get this rolling, <strong class="bold1">Please confirm and execute</strong>, <strong class="bold1">All set—place the order</strong>, <strong class="bold1">Proceed as discussed</strong>, <strong class="bold1">Order</strong>, Looks good, All good, All done, Send it, Go 4 it, Lez do it
<strong class="bold1">Weakly Confirming:</strong>
Let's put this into action, <strong class="bold1">Whatever</strong>, Okie dokie smokie
<strong class="bold1">Not Confirming:</strong>
<strong class="bold1">I don't not want this</strong>,<strong class="bold1">Not soon enough</strong></pre>			<p class="calibre3">Not only would a conversation around submitting an order expect to understand these, but it could also be that the instructions for the LLM are told to confirm the submission if the instructions are weak. This is the type of task understanding that an LLM will know even without enterprise training. It should be expected to work. But there are a few in <strong class="bold">bold</strong> that are not classified well. A few should be more positive, and a few should be less favorable. If you had an existing chatbot, you likely had trained it on examples like this. These would be the same samples that could be used for fine-tuning to help it overcome the LLM’s problems with negation (Not soon enough is a strong confirmation) and ensure that simple terms, like <em class="italic">Order</em>, are followed. Don’t force the user to talk in a structured business language. Apply this mantra:</p>
			<p class="calibre3"><em class="italic">Bring the experience to the user; don’t make the user go to </em><em class="italic">the experience.</em></p>
			<p class="calibre3"><em class="italic">Talk in the user’s language; don’t force them to learn the </em><em class="italic">company’s vocabulary.</em></p>
			<p class="calibre3">This heuristic also covers the freedom for users to return to a conversation later and pick up where they left off. This is a significant challenge for many platforms. If the user is in a chat conversation and returns a few hours later, will the service allow them to continue, or will it have timed out, causing the user to start over? Even if a timeout is inevitable, the user’s state should be maintained and restored once they authenticate. Understand typical pauses in conversational AI and support the continuation of the interaction. I have done data analysis of transactional conversational UIs and have seen plenty of data where conversational interactions are picked up again, even 24 hours later. This is similar to how we act <a id="_idIndexMarker627" class="pcalibre pcalibre1 calibre6"/>with others on messaging platforms. The expectation is that it is okay to return later and resume the conversation.</p>
			<p class="calibre3">As for exits, in a dialog box or even a wizard, there are marked exits, such as the cancel or exit button, typically in a consistent place on a platform. In a conversational UI, cancel buttons are avoided. Users must recognize that they can exit gracefully by saying, “Stop this order; I don’t want it,” or leave. There won’t be a visual affordance to stop in the middle of a transaction. For recommender UIs, the user isn’t “in” the UI; it is a secondary piece of information to assist the primary interaction, so no exits are expected.</p>
			<p class="calibre3">There are cases in hybrid UIs where a cancel option for a long process, such as uploading a file or filling a form that appears as part of a conversational interaction, could have one. To be clear, this means exiting a process or task <em class="italic">in</em> a conversation. The window that contains the conversation likely has an exit or close button. This button <a id="_idIndexMarker628" class="pcalibre pcalibre1 calibre6"/>might stop the conversation or close the window, allowing the user to pick up the thread later. The GUI component <strong class="bold">Cancel</strong> should respond to conversational interactions "I don't want to send this."It just depends on the use case. This heuristic about user control also supports an undo concept.</p>
			<h3 class="calibre11">Redo as undo</h3>
			<p class="calibre3">Users make errors. One <a id="_idIndexMarker629" class="pcalibre pcalibre1 calibre6"/>error is to delete, remove, or create an unintended edit to a form, object, or content. In some traditional UIs, <strong class="bold">Undo</strong> comes to the rescue. It is on the <strong class="bold">Edit</strong> menu, web applications, messaging platforms or a gesture like shaking on an iPhone. For years, Adobe Photoshop has had a history menu that supports multiple levels of undo. Some modern email UIs allow undo when sending an email. There may be only 10 seconds to unsend an email, but it is a relief to do this when sending something too soon. I hate sending an email that should have an attachment, and forgot to include it. Undo! Undo! Consider how to support <strong class="bold">Undo</strong> for transactions and experiences. This applies to conversational experiences and not to recommendations or backend solutions.</p>
			<p class="callout-heading">Here is a secret tip for getting a developer to support Undo</p>
			<p class="callout">Developers can freak out about undoing transactions. An alternative is to think about redoing the task programmatically – that is, the user, in almost all cases, doesn’t care about the state of the database; they want to undo what they did. An innovative developer can submit a transaction that effectively undoes it by keeping a copy of what was there previously and resubmitting it. Redo acts as an undo. The customer is none the wiser and happy. One level of undo in most use cases is probably 95% of the problem. Solve 95% of the problem before considering multiple levels of undo to solve the other 5%.</p>
			<p class="calibre3"> Undo can be supported conversationally:</p>
			<pre class="source-code-right">I made a mistake. Can Ireturn to what I had before?
No problem. Your old appointment time
is still available. You are scheduled
for 2:00 PM tomorrow.</pre>			<p class="calibre3">This is not about generative AI per se; this process deals with function calls and interacts with backends conversationally. So, undoing a mistake can require backend support to undo or maybe<a id="_idIndexMarker630" class="pcalibre pcalibre1 calibre6"/> redo. In this appointment situation, as long as no one booked that slot, the system should support booking the new spot and then canceling the old spot. This way, the user isn’t in limbo if the old time was taken. The original booking interaction might have been hours earlier. Maybe they had a meeting and responded after realizing the error.</p>
			<p class="callout-heading">Analysis for new employee onboarding, user control and freedom</p>
			<p class="callout">Heuristic influences: <em class="italic">explain how to fix them</em>, and <em class="italic">complete it in </em><em class="italic">any order</em></p>
			<p class="callout">The influence sighted does give the user control to solve problems, and it does support doing tasks in any order.</p>
			<h2 id="_idParaDest-192" class="calibre9"><a id="_idTextAnchor199" class="pcalibre pcalibre1 calibre6"/>4 – Consistency and standards</h2>
			<p class="calibre3"><em class="italic">Users should not have to wonder whether different words, situations, or actions mean the same thing. Follow platform and </em><em class="italic">industry conventions.</em></p>
			<h3 class="calibre11">Analysis</h3>
			<p class="calibre3">This is a catch-all for the additional work covered in this and earlier chapters. UX guidance emphasizes speaking in the user language and learning how to handle variations in language. The<a id="_idIndexMarker631" class="pcalibre pcalibre1 calibre6"/> upcoming heuristic, <em class="italic">6 – Recognition rather than recall</em>, offers a good example. Watch out for the use of language on the output side; be consistent and use the terms most appropriate for the company. However, users will use what they know and recall. If these terms are widely different, encourage and don’t demand the user to use the correct terms. This allows them to connect to the more modern terms without ignoring them. This heuristic could be interpreted as counter to heuristic <em class="italic">2 – Match between the system and the real world</em>, which asks to speak in the user’s language. We bridge that divide by understanding their language while reinforcing the new term.</p>
			<p class="calibre3">For example, customers who have used a product for years can refer to it by its original name. When another company purchases the product and rebrands the product, the new name gets exclusively used after some time. But the customer still has the old product with the old name running just fine. It might be a physical device in a shop; the old name is stamped right on the side. When they call for support, they still use that name, a short version of the name, or even an initialism.</p>
			<p class="calibre3">Oracle purchased BEA in 2008. The BEA middleware was called WebLogic Server. Customers might still be running this software. They might refer to it as WLS, the server, WebLogic, BEA, Oracle WebLogic Server, BEA WebLogic Application Server, the app server, or the more modern terms Oracle Middleware or Fusion Middleware. The conversational AI should support all.</p>
			<pre class="source-code-right">Can you help me get asoftware patch for WLS?
I can help with patches for Fusion
Middleware. WebLogic Server (WLS)
has been rebranded to this new name.
What is the release and platform
information for the install of WLS?</pre>			<p class="calibre3">This helps them connect from the old to the new term and speak in their language when asking for details about WLS. This example used a prompt that supported a more casual tone, resulting in the term <em class="italic">install</em> instead of the more formal <em class="italic">installation</em>. This prompt might be used:</p>
			<pre class="source-code">
If you encounter an old term for a product, gently guide them to use the new term.</pre>			<p class="calibre3">Additional fine-tuning examples could be needed to improve the dictionary of terms. Consider using checklists for new tasks and actions to monitor for issues in conversational logs or recommendation output strings. Refine the approach using all the tools – prompt engineering, data cleansing, and fine-tuning.</p>
			<p class="callout-heading">Analysis for new employee onboarding, consistency and standards</p>
			<p class="callout">Heuristic influences: <em class="italic">Clear, </em><em class="italic">simple terms</em></p>
			<p class="callout">The previous callouts cover some of the same concepts. As long as you identify a problem, you are doing well. Once you identify a solution, consider if it can cause issues with other heuristics or guidelines.</p>
			<p class="callout">As discussed in the analysis above, use fine-tuning to support transparent, simple, and user terms. Additionally, the new employee might not be familiar with some terms. Setting up their account information via “SSO” for the first time might require an explanation of Single-Sign-On. There should be sufficient detail to explain SSO, for example. Don’t assume knowledge.</p>
			<h2 id="_idParaDest-193" class="calibre9"><a id="_idTextAnchor200" class="pcalibre pcalibre1 calibre6"/>5 – Error prevention</h2>
			<p class="calibre3"><em class="italic">Good error messages are important, but the best designs carefully prevent problems from occurring in the first</em><em class="italic"><a id="_idIndexMarker632" class="pcalibre pcalibre1 calibre6"/></em><em class="italic"> place. Either eliminate error-prone conditions or check for them, and present users with a confirmation option before they commit to </em><em class="italic">an action.</em></p>
			<h3 class="calibre11">Analysis</h3>
			<p class="calibre3">Let’s start by discussing how to avoid errors in the first place. This is a considerable challenge when dealing with conversational UIs. They can say anything; if misinterpreted, the conversation goes wrong. This is where product owners and designers need to look at thresholds for understanding. If a system isn’t confident in its direction, interject and guide the user. Disambiguation is standard in traditional conversational chat experiences. Use prompt engineering to build instructions so the generative AI can meet a confidence threshold. In <a href="B21964_10_split_000.xhtml#_idTextAnchor216" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 10</em></a><em class="italic"> – Process,</em> we will show more examples of chaining that can be used to evaluate a confidence threshold and assist in getting a better answer. If more clarification or confidence is needed in what the user asks, prompt the user for more details. Provide options that help them narrow down their problem to guide them on the right path, like with a prompt like this:</p>
			<pre class="source-code">
Are you asking for expense reports, your team's billing report, or the latest sales report? Let me know.</pre>			<p class="calibre3">The faster the resolution, the fewer additional errors will occur. I reviewed many chat<a id="_idIndexMarker633" class="pcalibre pcalibre1 calibre6"/>s where the user was unaware they were in a misguided conversation. The user doesn’t notice context clues that the conversation isn’t working. They continue interacting as if they know where and what they are doing, but they do not.</p>
			<p class="callout-heading">Important note</p>
			<p class="callout">Customers do not read; they skim, at best. Provide vital clues and reinforce with guideposts. Use redundant clues for errors that need to be fixed.</p>
			<p class="calibre3">For example, there are standard patterns to fix errors in traditional forms. A message might say that there is an error. It should explain what field has the problem, and then there should be an error label or icon on the field, along with details on what is wrong. While writing this chapter, I experienced errors when submitting forms, but the website would not tell me what field had a problem or even highlight the field with the mistake. I was left trying to edit each field to see whether anything changed. And even then, in one case, I couldn’t submit the form. I never figured it out.</p>
			<p class="calibre3">Information passed to other systems must be valid in conversational AI solutions, especially for transactional UIs (e.g., searching for a flight, filling out an expense report, or conversational versions of UI forms).</p>
			<p class="calibre3">Conversational UIs are prone to submitting wrong data. The AI doesn’t know it is wrong, so it can’t prevent it, and even a traditional UI won’t typically catch a user typing <code>112,</code> but intended <code>12</code> if the field isn’t validated. That is the magic of AI. Although it might not be preventable, an AI can determine if something appears wrong and understand what is reasonable data. A prompt in your instructions might catch issues:</p>
			<pre class="source-code">
Prompt: If you are given information that is not typical for the expected values, repeat it to the user to confirm that it is correct.
You entered $112.23 for coffee at Starbucks. That doesn't seem right. Can you confirm this is correct?</pre>			<p class="calibre3">This intelligence can be built into conversational AI. This is one great reason for making purpose-built AI models. There is flexibility in focusing on solving one problem well. When asked what ChatGPT thinks is <em class="italic">not typical</em>, it responded:</p>
			<pre class="source-code">
A reasonable range might be 10% to 30% likelihood, depending on the context. This range reflects that while it's not impossible or extremely rare, it doesn't occur frequently enough to be considered typical.
  • Closer to 10% would indicate that it is quite uncommon.
  • Closer to 30% would indicate that while it's still uncommon, it     happens with some regularity.</pre>			<p class="calibre3">Use language intentionally. <em class="italic">Typical</em> in the prompt is wishy-washy; in this case, ChatGPT might ignore values that are considered rare, which is below 10%. Using specific language for expected value<a id="_idIndexMarker634" class="pcalibre pcalibre1 calibre6"/> ranges. Prompt for well-known fields if the user doesn’t submit a valid value the first time. It might not be necessary to provide exact instructions ahead of time. Try to parse to a valid value first to avoid clutter in the user interaction. It is a tradeoff. For questions where specific values are well understood, don’t provide details; for questions without known values, consider asking the user for more information to avoid getting poor answers on the first attempt.</p>
			<pre class="source-code">
(Obvious) What is your weight and height?
(Not Obvious) Provide the SysCode from the onboarding email. It looks like this: SC-12533-RHM.</pre>			<p class="calibre3">Alternatively, using a generative AI error checker, create a separate component to validate form values behind the scenes. The database won’t be happy if it needs a number and the AI sends it the text “three.” Use a different model designed to handle these situations and then pass validated results to the primary model. ChatGPT is very good about understanding the<a id="_idIndexMarker635" class="pcalibre pcalibre1 calibre6"/> requirements of a function (it inspects something called the function signature) and typically will do the right thing, including transforming the data into the correct format. In the case above, if it knows the field is an integer, it will send “3” to the function. This also works as a gate for functions that do not have good validation capabilities. The LLM can do it. Here is an example of doing this work manually in a prompt:</p>
			<pre class="source-code">
Prompt: When working with dates, always convert the user's dates into MM/DD or MM/DD/YYYY format before submitting it to the calendar service. 
For example, if the user provides Jun 12, convert that to 06/12. If the year is required, ask for it. If they say, "this year," include the year in MM/DD/YYYY format.</pre>			<p class="calibre3">Let’s return to the expense example. An image upload feature processes scans of receipts to gather expense details directly from an uploaded image. Image scanning models must be trained and will get errors, so putting a different model validator before the image scanning results could catch some automation errors. Ask the user to confirm what was found in these cases. It is a challenge to be error-tolerant in conversational AI experiences. Monitor and improve. Watch for opportunities to catch errors, recover from mistakes, and validate behind the scenes when possible.</p>
			<p class="callout-heading">Analysis for new employee onboarding, Error Prevention</p>
			<p class="callout">Heuristic influences: <em class="italic">If there are errors</em>, <em class="italic">confirm any understanding</em>, <em class="italic">provide details at each step</em> and <em class="italic">For less </em><em class="italic">well-known questions</em></p>
			<p class="callout">An onboarding process offers ample opportunity for errors. The user, terms, and process are all new.</p>
			<h2 id="_idParaDest-194" class="calibre9"><a id="_idTextAnchor201" class="pcalibre pcalibre1 calibre6"/>6 – Recognition rather than recall</h2>
			<p class="calibre3"><em class="italic">Minimize the user’s memory load by making elements, actions, and options visible. The user should not have to remember information from one part of the interface in another. Information required to use the design (e.g., field labels or menu items) should be visible or easily retrievable </em><em class="italic">when needed.</em></p>
			<p class="calibre3">Be familiar<a id="_idIndexMarker636" class="pcalibre pcalibre1 calibre6"/> with recognition versus recall. It is easier to recognize choices from options (such as a menu) because the brain can recognize these values to know which is right, unlike recall, where the user has to search their memory for a cue. “Who was the 16th president of the United States?” is harder to recall than recognizing that “<em class="italic">Was Abraham Lincoln the 16th president of the United States?</em>” is true. The science of this is rather interesting.</p>
			<p class="calibre3">Article: <a href="https://www.nngroup.com/articles/recognition-and-recall/" class="pcalibre pcalibre1 calibre6">Memory Recognition and Recall in User Interfaces</a> (<a href="https://www.nngroup.com/articles/recognition-and-recall/" class="pcalibre pcalibre1 calibre6">https://www.nngroup.com/articles/recognition-and-recall/</a>)</p>
			<h3 class="calibre11">Analysis</h3>
			<p class="calibre3">This heuristic is essential and also challenging to address in conversational AI. There is a reason why software has menus and why those menus are organized and have some level of consistency. Although every software product can’t have the same menu items (e.g., a word processor is not a photo editing tool), there is a set of everyday tasks, and common words/features are used with consistent placement. However, expressing themselves can be challenging when users stare at an empty field. It could be because they are not vocal, have learning difficulties, aren’t working in their native language, can’t find the right words to express themselves, or are too distracted with other tasks to pin down how to ask a system to do their bidding. With a menu system, users can look around, go to a likely location (such as the <strong class="bold">Edit</strong> menu), and see whether the feature<a id="_idIndexMarker637" class="pcalibre pcalibre1 calibre6"/> they want is there. This ability to recognize what they want by pointing at it is a universal truth: “<em class="italic">I will know it when I see it.</em>” Also, plenty of menu usability issues can hinder performance – for example, when not using words in a feature name that matches the user’s expectation. With conversational AI, especially chat experiences, fine-tune systems to understand a wide range of expressions for a common task or feature, as discussed in a few of the heuristics already. However, humans still have to recall words.</p>
			<p class="calibre3">This is one reason why menus appear in some hybrid experiences. It gives the user standard anchors to drive decision-making. If the system can present the five things a user will always do, then sharing these tasks as buttons or in a menu on a conversational AI helps them overcome the recognition versus recall problem. However, as the number of functions now approaches the hundreds in a conversational enterprise app, providing a menu for all of them is unreasonable. Giving them five items when it can do 100 can limit the customer’s ability to see the more considerable capabilities of the solution.</p>
			<p class="calibre3">As discussed earlier, the problem gets more challenging in a straight voice interface because humans need help keeping track of many choices in their heads. This has been known since the dawn of computing (G.A. Miller, <em class="italic">The magical number seven, plus or minus two: Some limits on our capacity for processing information, Psychological Review</em>, 63(2), 81–97, 1953). Although our understanding has evolved, a human’s ability to handle choice has yet to. There is a psychological limit to how many options make sense in a voice menu. This is why hierarchies in phone trees exist; they help break down large groups of actions into well-understood categories. Expose the user to pick a category first and then disclose the options once within the category. Lotus 1-2-3, the spreadsheet app, famously invented this kind of progressive disclosure of menus in software. 1-2-3 was the first killer app for personal computers in the 1980s.</p>
			<p class="calibre3">It is common to have trouble remembering a phone number when told on a call. It becomes a challenge to hang up fast enough to recall the number (473-867-5309) and dial it without forgetting. Human memory is a problem for UIs.</p>
			<p class="calibre3">This leaves us with a dilemma in conversational AI. Users are much better at recognizing choices than recalling them, yet there is a limited capability to resolve this in a voice channel <a id="_idIndexMarker638" class="pcalibre pcalibre1 calibre6"/>or a chat window. More room is needed to build robust views into vast feature sets, even on channels that support menus and buttons. Some tricks can mitigate this UX problem:</p>
			<ul class="calibre7">
				<li class="calibre8">Fine-tune to allow for flexibility in understanding terms. Understand how knowledge refers to products, features, or services.</li>
				<li class="calibre8">Monitor and adapt support for new terms for existing features or tasks.</li>
				<li class="calibre8">Disambiguate when requests are not explicit between multiple choices.</li>
				<li class="calibre8">Provide hints and suggestions when the next step is likely.</li>
				<li class="calibre8">Provide menus in limited approaches when valuable and popular tasks or actions are likely.</li>
				<li class="calibre8">Help guide the user if they need help figuring out what they can do. If errors or multiple errors occur, it might be time to use a secondary prompt that guides the user more explicitly (step by step or with more detailed instructions, for example). If the user asks for help, then the LLM can be more supportive in the same way. See an example of this advice in the heuristic <em class="italic">5—Error prevention</em>.</li>
			</ul>
			<p class="calibre3">Depending on the ChatGPT implementation, there might not be much to do on screen. Still, the team can undoubtedly care and feed the solution to allow more understanding with prompt engineering, fine-tuning, and knowledge refinement. Narrow down the options by disambiguating common misunderstandings when there is no context to decide which direction to go.</p>
			<pre class="source-code-right">I need 12G documentation.
Did you mean Oracle Middleware 
12G or the Oracle Database 12G?</pre>			<p class="calibre3">This is easier said than done in generative models, but keep it in mind when prompt engineering or using ChatGPT behind a deterministic experience.</p>
			<p class="calibre3">Recall the different ways someone might refer to Oracle Database (RDBMS, Oracle Server, Enterprise Edition, DB 12, etc.…); being flexible in understanding all of these will make engaging the customer easier. This means being sure of the proper training data.</p>
			<p class="calibre3">A critical part of this heuristic is remembering information from one part of a UI in another. This can mean contextual understanding. This is very important in conversational UIs. Continue to know who the customers are and what they are doing by keeping the context of previous conversations. This would be expected when calling a call center for product support<a id="_idIndexMarker639" class="pcalibre pcalibre1 calibre6"/>. They have the transcripts or interactions of earlier calls, order history, and account information. Isn’t it expected that the conversational AI, no matter what the UI entails, should understand and adapt interactions based on this information? Absolutely. And as product leaders, we demand that intelligence. So, this part of the heuristic is worth checking to ensure the user can do more (tasks) with less (information):</p>
			<ul class="calibre7">
				<li class="calibre8">Pick up where they left off. Each LLM starts with little or no knowledge of prior conversations. LLMs are growing their understanding of previous conversations. Without enough knowledge, consider storing the last conversation and providing it in the context window.</li>
				<li class="calibre8">Know the user’s history, behavior, and previous needs to help with current interactions (returns, product help, orders, shopping behavior, etc.). Use this history to build a prompt with the current context.</li>
				<li class="calibre8">Understand the sentiment of previous conversations. If this interaction is confrontational, adapt the style and tone.</li>
			</ul>
			<p class="callout-heading">Analysis for new employee onboarding, recognition rather than recall</p>
			<p class="callout">Heuristic influences: <em class="italic">verify completion</em>, <em class="italic">provide the status of each step</em>, <em class="italic">Each step should be clear and concise</em>, <em class="italic">Do not ask the new employee to remember information</em>, <em class="italic">Provide details at each step</em>, and <em class="italic">well-known questions</em></p>
			<p class="callout">There is a wide range of prompt details that help the user make decisions right in front of them. It explicitly calls out that the new employee should not be required to remember information. How this would play out in a real onboarding experience would have to be seen. They can recognize where they are and see the results of how they are doing. In the worst case, the conversation history is also there to help remind them of steps or status.</p>
			<h2 id="_idParaDest-195" class="calibre9"><a id="_idTextAnchor202" class="pcalibre pcalibre1 calibre6"/>7 – Flexibility and efficiency of use</h2>
			<p class="calibre3"><em class="italic">Shortcuts – hidden from novice users – may speed up the interaction for the expert user so that the design can cater to inexperienced and experienced users. Allow users to tailor </em><em class="italic">frequent actions.</em></p>
			<h3 class="calibre11">Analysis</h3>
			<p class="calibre3">In chat UIs, flexibility and<a id="_idIndexMarker640" class="pcalibre pcalibre1 calibre6"/> efficiency can be seen as trade-offs. Conversational AI chat windows offer lots of flexibility; anything can be said. However, getting the correct answer or completing a task might not be the most efficient path. Let’s take an example of filling out an expense conversationally:</p>
			<pre class="source-code-right">Please put me down for $5 this morning fora cup of coffee at Starbucks when I visitmy customer, Alli Financial Group, in NYC.
I added your US 5$ expense
to your current report. You have
four expenses ready to submit.</pre>			<p class="calibre3">However, starting that same conversation without any context can reduce the efficiency of the process. Here is a long-winded version to make the point:</p>
			<pre class="source-code-right">Expense, please
Please provide expense details,
such as "Gasoline for $36$ today
for a trip to the S3I customer."It was 5$
When was this?Today
What was the purpose of
the expense?Coffee
You bought coffee. What is
the reason?Visiting a customer
For our records, who was
the customer?Alli Financial Group
Got it. I have a 5$ expense
today for coffee while visiting
Alli Financial Group.</pre>			<p class="calibre3">Be efficient with interactions. A little<a id="_idIndexMarker641" class="pcalibre pcalibre1 calibre6"/> later in the chapter are some excellent examples of making conversations manageable by reducing and combining questions that make sense. All of this sort of form-filling that is done conversationally requires thought. Ask questions that can fill the fields as efficiently and intelligently as possible. Doing conversational interactions one tiny piece of information<a id="_idIndexMarker642" class="pcalibre pcalibre1 calibre6"/> at a time is annoying. It gets back to using the right tools for the job.</p>
			<p class="calibre3">I saw an example of a COVID-19 screener that was built conversationally. It could have been more pleasant. It asked 14 questions, which required me to wait for each question to appear, read it, and then answer it with textual answers. The same experience done as a form would be three times faster and less headache and work. It is easier for a user to look ahead with written forms and UI wizards. A user can check a box while looking ahead to read the next question. There is also context on a well-designed form providing clues on how much is completed and what is left to do. With these conversational UIs, it sometimes appears that the questions will go on forever. Be thoughtful about the questions so that the process is efficient. Watch for opportunities for improvement through better questions, eliminating steps, and using defaults while allowing the user to edit and adjust responses.</p>
			<p class="callout-heading">Analysis for new employee onboarding, flexibility and efficiency of use</p>
			<p class="callout">Heuristic influences: <em class="italic">Keep track of the errors</em>, <em class="italic">the user can complete steps in </em><em class="italic">any order</em></p>
			<p class="callout">It is fair to wonder how efficient a conversational AI is for onboarding. Keeping track of status, being reminded of tasks, being alerted to issues in some of the steps, guiding the user on the next steps, and being given access to sites or links seems reasonable. Especially on a communication channel the user already has and monitors. But if you asked me to fill out an employment application <em class="italic">in</em> a chat, that would be wrong.</p>
			<h2 id="_idParaDest-196" class="calibre9"><a id="_idTextAnchor203" class="pcalibre pcalibre1 calibre6"/>8 – Aesthetic and minimalist design</h2>
			<p class="calibre3"><em class="italic">Interfaces should not contain information that is irrelevant or rarely needed. Every extra unit of information in an interface competes with the relevant units of information and diminishes their </em><em class="italic">relative visibility.</em></p>
			<h3 class="calibre11">Analysis</h3>
			<p class="calibre3">We can only do so much to be <a id="_idIndexMarker643" class="pcalibre pcalibre1 calibre6"/>minimalistic beyond providing an empty textbox. In a pure voice experience, minimalism comes into play by keeping our utterances brief. The same can apply to recommender experiences. Provide the headline, and if needed, let the user explore further. Only a few details are required most of the time. In traditional UIs, expanding areas, help bubbles, or drill-down links expose more information. Apply the same logic to recommendations or even chat experiences. If the user replies, “<em class="italic">I don’t understand,</em>” or “<em class="italic">Explain please,</em>” be prepared to draw on product help, knowledge, and context to provide relevant information to accommodate the user. One approach is to step back to become more of a guided coach. Instruct the model to change its approach:</p>
			<pre class="source-code">
If your interaction results in confusion or misunderstanding, interact with more explanation, reduce the complexity with more straightforward language, and proceed step by step with instructions.</pre>			<p class="calibre3">I am not a good source of information regarding aesthetics. Generally, these experiences are within a larger <a id="_idIndexMarker644" class="pcalibre pcalibre1 calibre6"/>corporate framework with an established style and visual aesthetic. Only in rare cases would this impede the usability of a conversational design. It is easy to appreciate a well-designed and visually appealing experience. It would be best to design something functional over an experience that looks great but makes the customer bash their head against a wall because it lacks basic usability, as described by the other nine heuristics.</p>
			<p class="callout-heading">Analysis for new employee onboarding, aesthetic and minimalist design</p>
			<p class="callout">Heuristic influences: <em class="italic">Each step should be clear and concise</em>, and <em class="italic">clear, </em><em class="italic">simple terms</em></p>
			<p class="callout">Minimalism is important in a chat flow, especially when one is expected to be on the phone, like in an onboarding experience. Keeping steps and messages clear and to the point will be best.</p>
			<h2 id="_idParaDest-197" class="calibre9"><a id="_idTextAnchor204" class="pcalibre pcalibre1 calibre6"/>9 – Help users recognize, diagnose, and recover from errors</h2>
			<p class="calibre3"><em class="italic">Error messages should be expressed in plain language (no error codes), precisely indicate the problem, and constructively suggest </em><em class="italic">a solution.</em></p>
			<h3 class="calibre11">Analysis</h3>
			<p class="calibre3">In the next section, we<a id="_idIndexMarker645" class="pcalibre pcalibre1 calibre6"/> reiterate this point in the examples of style and tone guidelines, starting with the examples coming up soon with <em class="italic">Figure 9</em><em class="italic">.2</em>, which says not to blame the user when things go wrong. Since almost everything in conversational design is about words, it stands to reason that error messages adhere to the same guidelines and style that the rest of the interactions contain. Users should never see <strong class="bold">Error 454-24 System Overflow Buffer Failed to Execute Transaction</strong>. Create checks and balances to ensure that if something goes off the rails, there is a way to explain it in plain language and how it should be resolved (why and then how, as illustrated in <em class="italic">Figure 9</em><em class="italic">.3</em>). Sorry, we don’t want to repeat the images, be patient; they are coming up.</p>
			<p class="callout-heading">Analysis for new employee onboarding, users recognize, diagnose, and recover from errors</p>
			<p class="callout">Heuristic influences: <em class="italic">clear and concise</em>, <em class="italic">Keep track of the errors</em>, <em class="italic">the user can complete steps in any order</em>, and<em class="italic"> explain how to </em><em class="italic">fix them</em>.</p>
			<p class="callout">The prompt emphasizes style and tone and includes the importance of communicating status, mainly if errors occur and how to recover.</p>
			<h2 id="_idParaDest-198" class="calibre9"><a id="_idTextAnchor205" class="pcalibre pcalibre1 calibre6"/>10 – Help and documentation</h2>
			<p class="calibre3"><em class="italic">It’s best if a system doesn’t need any additional explanation. However, it may be necessary to provide documentation to help users understand how to complete </em><em class="italic">their tasks.</em></p>
			<h3 class="calibre11">Analysis</h3>
			<p class="calibre3">How often have you read help and documentation for a mobile phone app? I suspect most of you will answer rarely. With<a id="_idIndexMarker646" class="pcalibre pcalibre1 calibre6"/> tasks and features that are self-documenting or have a simple flow, most users follow the happy paths and are good to go. However, in enterprise solutions, many paths are needed, customization is typical, and complexity abounds, causing user confusion and needing help and documentation, even with the best experiences. A conversational experience that has to handle all of that can also be complex. Sometimes, we adopt the 80/20 rule – 80% of the use of a product from 20% of the UI. With modern analytics, we can learn far more about usage. Start by supporting the likely flows (the primary use cases) in conversational AI and keep the more complex interactions in the traditional UI. Handle more complex flows as conversational AI matures and usage warrants their inclusion. We covered that a few times in <a href="B21964_03.xhtml#_idTextAnchor058" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 3</em></a><em class="italic">, Identifying Optimal Use Cases for ChatGPT</em>. This will happen slower than the rapid pace of AI models coming online.</p>
			<p class="calibre3">Backend systems are still restrictive and expect data in a certain way. Although generative AI can be used in many ways (frontend understanding, translation in the middle, and data mapping in the backend), significant work is needed to make this happen. There is no magic here. But AI can also be good at providing small, refined answers from a robust and extensive help suite, translating it, or even adapting it to a different style or tone.</p>
			<p class="calibre3">So, ChatGPT can help explain<a id="_idIndexMarker647" class="pcalibre pcalibre1 calibre6"/> complexity by taking documentation and applying a style or tone that might be more understandable by a target user, finding insight deep in large help documents, or providing documentation in the user’s native language. Consider checks and balances here. ChatGPT better not mangle a step-by-step process in the documentation and return incorrect steps and procedures. This is where the chaining of prompts from <a href="B21964_08.xhtml#_idTextAnchor172" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 8</em></a>, <em class="italic">Fine-Tuning,</em> comes into play. Chaining can be used to validate critical tasks.</p>
			<p class="calibre3">There are many opportunities to advance the state of a solution by adapting approaches to help and documentation. This help can also be done inline. The next section, <em class="italic">Building Conversational Guidelines</em>, has excellent examples, starting with <em class="italic">Figure 9</em><em class="italic">.1</em>, where language is adapted based on the user’s expertise. A new user can receive more help and guidance in a process, while for an expert who doesn’t need this, it is better to be less chatty and more direct. This is similar to GUIs, where wizards walk a user through steps of a long process or provide an advanced experience with less context and fewer steps.</p>
			<p class="callout-heading">Analysis for new employee onboarding, Help and documentation</p>
			<p class="callout">Heuristic influences: <em class="italic">Provide details at each step</em> and <em class="italic">explain how to </em><em class="italic">fix them</em></p>
			<p class="callout">The prompt ingrains the call for help. Conversational flows should typically self-document for details, explanations, and guidance. If not, links can be provided to traditional documentation. The concept of progressively increasing the level of the help supplied or tuning the details of inline help based on user profile characteristics are called adaptive messages. Examples of this will start in the upcoming section <em class="italic">Building </em><em class="italic">conversational guidelines</em>.</p>
			<p class="calibre3">This covers Jakob’s ten heuristics. Applying them to UI elements is well-documented and entrenched in the UXD world. Using them to model behavior for an LLM is new and untested. ChatGPT 4o behaves<a id="_idIndexMarker648" class="pcalibre pcalibre1 calibre6"/> well with prompts like this, but it would require real-world data to validate this approach at scale. From testing, it seems worth the investment to consider the heuristics when writing enterprise instructions for models.</p>
			<h2 id="_idParaDest-199" class="calibre9"><a id="_idTextAnchor206" class="pcalibre pcalibre1 calibre6"/>Is there an 11th possible heuristic?</h2>
			<p class="calibre3">I want to mention A18y again in our discussions. Jim Ekanem is a proponent of distinct accessibility <a id="_idIndexMarker649" class="pcalibre pcalibre1 calibre6"/>heuristics. Much of what was discussed in the ten heuristics can all be considered in the context of A18y. A18y should be considered at every step. Jim proposes a new heuristic to follow A18y guidelines. This is not a heuristic, but to be fair, the concept of accessibility and inclusivity is still valid. Inclusivity was covered a few times, and bias in model data can affect quality.</p>
			<p class="calibre3">Article: <a href="https://uxmag.com/articles/why-we-need-11-usability-heuristics" class="pcalibre pcalibre1 calibre6">Proposal to include Accessibility as the 11th Heuristic</a> (<a href="https://uxmag.com/articles/why-we-need-11-usability-heuristics" class="pcalibre pcalibre1 calibre6">https://uxmag.com/articles/why-we-need-11-usability-heuristics</a>)</p>
			<p class="calibre3"><em class="italic">Design for accessibility and inclusion by following guidelines and best practices to accommodate diverse cognitive and </em><em class="italic">physical abilities.</em></p>
			<p class="calibre3"><em class="italic">Consider social identities and address systemic barriers and biases. Reflect on the impact of design decisions on </em><em class="italic">marginalized communities.</em></p>
			<p class="calibre3">The heuristic <em class="italic">4 - Consistency and standards</em> didn’t mention cognitive and physical abilities. Accessibility guidelines, discussed in an earlier chapter, should be part of the evaluation process for conversational AI. It won’t impact backend solutions <a id="_idIndexMarker650" class="pcalibre pcalibre1 calibre6"/>and is of limited value for recommendations, but it can have significant implications for voice channels, for example. For a voice-only feature, what is the alternative for those who can’t speak or hear? Will the system <a id="_idIndexMarker651" class="pcalibre pcalibre1 calibre6"/>work using a <strong class="bold">Telecommunications Relay Service</strong> (<strong class="bold">TRS</strong>)? Do requests for a selection or typing of a number, say a credit card number, time out too quickly? Would a time-out cause problems if an intermediary were relaying this communication, thus delaying responses by 30 seconds? If services are offered via messaging or voice, include viable alternatives. This is an example of accommodation; think broadly about inclusivity.</p>
			<p class="calibre3">Bias was touched on earlier around language and cultural support for conversational interactions. Even in simple concepts such as expense reporting, there are cultural implications for inclusiveness. For example, recording an expense trained on travel in the US covers items such as taxis, Ubers, lifts, car services, and limos. However, each country has unique services, such as BlaBlaCar for carpooling in France, Cabify in Spain, Didi in China, and Ola in India. Being inclusive means including the understanding of these car services. It is not just about cultural awareness to deploy tools in those countries; if the customers are from the US and visit those countries, they might want to expense “a BlaBlaCar for 20 euros” on their US-based expense report. Being inclusive and thinking about cultural issues can also benefit the home country. However, for an A18y discussion, ensure that groups of people who have typically been sidelined are afforded the same opportunity to use LLM solutions successfully.</p>
			<p class="calibre3">Language and dialect support can be a major issue. For instance, if rural villagers in India access government services via a phone-based LLM, even on inexpensive flip phones, what are the chances their language or dialect is supported? The 2011 India census reported 121 languages spoken by at least 10,000 people, with 22 officially recognized languages and thousands of dialects.</p>
			<p class="calibre3">If the ten heuristics are followed in spirit, the 11th isn’t needed; it should be implicit. If the organization isn’t as advanced as it should be, the accessibility “heuristic” might help fill the gaps.</p>
			<p class="calibre3">These heuristics can be used to evaluate any experience, including conversational AI. It should be clear that these are not guidelines. However, it is reasonable to have guidelines that developers can quickly follow. Adapt and adopt a company-wide set of conversational guidelines.</p>
			<h1 id="_idParaDest-200" class="calibre5"><a id="_idTextAnchor207" class="pcalibre pcalibre1 calibre6"/>Building conversational guidelines</h1>
			<p class="calibre3">A guideline can be built into a test <a id="_idIndexMarker652" class="pcalibre pcalibre1 calibre6"/>case. It forces people to follow a defined solution. The testing software can test for a specific font or size in a page header or a button label that doesn’t use a term an organization forbids (such as <em class="italic">abort</em>, <em class="italic">kill</em>, or <em class="italic">execute</em>). Doing something precisely, the same every time isn’t very conversational. Repeatability and consistency are crucial in enterprise solutions that don’t always match a conversational style, tone, and engagement. Consider that the LLM can understand a range of phrases while a fixed traditional test suite has little flexibility, although a test could look for one phrase from a collection of options.. The testing we did in the earlier chapters is a form of validation and can be used to address if the model is acting as expected for areas like following the ten heuristics or adhering to specific guidelines.</p>
			<p class="calibre3">Develop guidelines by drawing <a id="_idIndexMarker653" class="pcalibre pcalibre1 calibre6"/>on existing resources and consider the use cases. While most guidelines apply to a hybrid UI, and some will work for a conversational UI (text or voice), even less will apply to a standalone AI-driven recommender. And this makes sense; the more complex the possible experience, the more guidelines apply.</p>
			<p class="calibre3">Then, there is the issue of getting the experience to follow the guidelines. Just because a prompt tells ChatGPT to follow specific instructions doesn’t mean it will. When using deterministic coding approaches, design is dictated. This is much harder with an LLM. Recall how <strong class="bold">Temperature</strong> and <strong class="bold">Top P</strong> were adjusted in <a href="B21964_07.xhtml#_idTextAnchor150" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 7</em></a>, <em class="italic">Prompt Engineering</em>. There is some control from prompt engineering and fine-tuning to focus the LLM on how to speak to the customer.</p>
			<p class="calibre3">Here are three areas to get values from conversational guidelines. Historical references were provided earlier in this chapter, such as the work of Smith and Mosier (1986); let’s get more up-to-date with the following:</p>
			<ul class="calibre7">
				<li class="calibre8">Web guidelines</li>
				<li class="calibre8">A sample guideline set for hybrid UIs</li>
				<li class="calibre8">Some specific style and tone guidelines with examples</li>
			</ul>
			</div>
	

<div><h2 id="_idParaDest-201" class="calibre9"><a id="_idTextAnchor208" class="pcalibre pcalibre1 calibre6"/>Web guidelines</h2>
			<p class="calibre3">Conversational guidelines will adjusted emerge from a few sources. First, the big players will take their existing web guidelines and expand on them to include more generative AI <a id="_idIndexMarker654" class="pcalibre pcalibre1 calibre6"/>components. Apple, Google, Microsoft, Amazon, and others will all have something to say, and most likely, they will feed off each other as they have in the past. Sometimes, inadequate guidelines appear because one group didn’t know any better and didn’t do any of their research or testing to define their guideline. Thus, when someone learns from a mistake and changes their guidance, others who copied it have to figure out why this changed and decide whether to adopt the new patterns. This has happened multiple times with Amazon and Google designs so that it can happen to anyone.</p>
			<p class="calibre3">The AI players will have guidelines as they learn that design matters and how poor interactions impact the overall experience. They will do this to help their customers make successful solutions, as their models typically depend on usage. If customers stop using the models, their bottom line will be affected.</p>
			<p class="calibre3">Use what is available<a id="_idIndexMarker655" class="pcalibre pcalibre1 calibre6"/> today as a guide. Caveat emptor. Let the buyer beware. Every guideline adopted should have a reason and a solid underpinning. Apple Intelligence will likely have guidelines, while Microsoft’s are currently fairly high-level. There is little out there.</p>
			<p class="calibre3">Article: <a href="https://learn.microsoft.com/en-us/training/modules/responsible-conversational-ai/" class="pcalibre pcalibre1 calibre6">Microsoft Guidelines</a></p>
			<p class="calibre3">(<a href="https://learn.microsoft.com/en-us/training/modules/responsible-conversational-ai/" class="pcalibre pcalibre1 calibre6">https://learn.microsoft.com/en-us/training/modules/responsible-conversational-ai/</a>)</p>
			<p class="calibre3">Training: <a href="https://trailhead.salesforce.com/content/learn/modules/conversation-design" class="pcalibre pcalibre1 calibre6">Conversation Design from Salesforce</a> (free, but requires registration) (<a href="https://trailhead.salesforce.com/content/learn/modules/conversation-design" class="pcalibre pcalibre1 calibre6">https://trailhead.salesforce.com/content/learn/modules/conversation-design</a>)</p>
			<p class="calibre3">After finishing this book, you could reverse-engineer some guidelines by looking at the conversational UI design thread and examples on Dribbble.</p>
			<p class="calibre3">Examples: <a href="https://dribbble.com/tags/conversational-ui" class="pcalibre pcalibre1 calibre6">Dribble catalog of inspirations for conversational AI</a> ( <a href="https://dribbble.com/tags/conversational-ui" class="pcalibre pcalibre1 calibre6">https://dribbble.com/tags/conversational-ui</a>)</p>
			<p class="calibre3">Very few guidelines exist, but what is there is solid, if not generic, and consistent with what we are discussing. However, much of the content is for those building solutions, not for those designing experiences. Even Coursera has nothing to offer at this time. Hence, the reason for this book! So, it’s time to make do and create our own set of guidelines.</p>
			<h2 id="_idParaDest-202" class="calibre9"><a id="_idTextAnchor209" class="pcalibre pcalibre1 calibre6"/>A sample guideline set for hybrid chat/GUI experiences</h2>
			<p class="calibre3">One challenge is to follow existing GUI guidelines and deal with conversational guidelines. There are conflicts, the most common of which is with language. A traditional UX doesn’t use contractions, while UI language is more formal, sometimes abrupt, and undoubtedly less conversational. I have seen guidelines built into automated software testing checks that fail with conversational text.</p>
			<p class="calibre3"><em class="italic">On top of that, if the generative UI directly creates text, there is less control.</em> This is like telling a teenager to be home by 10 p.m. They might say they will but might not arrive on time. That is prompt engineering. The guardrails might be suitable, but they are only sometimes followed. The guidelines can help with prompt engineering. They can certainly be followed in a recommender template.</p>
			<p class="calibre3">On GitHub is a checklist of GUI guidelines, roughly organized by the ten heuristics. These were initially adapted from a list generated at MIT, but the original list has been lost to history. There are two sheets – a short version and a lengthy one on the second worksheet tab. Most apply to traditional GUI or web applications, while some cross over to conversational AI. Here are examples for helping users recognize, diagnose, and<a id="_idIndexMarker656" class="pcalibre pcalibre1 calibre6"/> recover from errors.</p>
			<p class="calibre3">Error messages should be expressed in plain language (no error codes), precisely indicate the problem, and constructively suggest a solution:</p>
			<ul class="calibre7">
				<li class="calibre8">Undo is supported, where possible</li>
				<li class="calibre8">Guidance is clear</li>
				<li class="calibre8">Unusual answers to common questions are validated or confirmed</li>
				<li class="calibre8">If a choice is too complex conversationally, offer suggestions if they are likely or examples if any of the choices are unlikely</li>
			</ul>
			<p class="calibre3">GitHub: <a href="https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter9-HeuristicsChecklist.xls" class="pcalibre pcalibre1 calibre6">Guidelines typical of a GUI and supporting conversational experiences</a> (<a href="https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter9-HeuristicsChecklist.xls" class="pcalibre pcalibre1 calibre6">https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter9-HeuristicsChecklist.xls</a>)</p>
			<p class="calibre3">I suspect something similar is in every enterprise, but if not, feel free to adapt these. Then, consider applying the user scoring method to the issues found.</p>
			<p class="calibre3">Here is one related takeaway from my Master’s thesis, <em class="italic">Effects of Graphical UI Inconsistencies on Subjective and Objective Measures of Usability</em>. Consistency from screen to screen doesn’t matter as much as matching a user’s needs to the experience. There are a lot of forced designs where the UX must use a specific component to “be consistent.” This is ostensibly for the user, but it is really to ease the burden on the development team. If the component is wrong, the user will suffer. So, be consistent with the user’s needs and expectations. Google search and ChatGPT are your friends here to gather guidelines. So, next, we can dive further into conversational-specific guidance.</p>
			<h2 id="_idParaDest-203" class="calibre9"><a id="_idTextAnchor210" class="pcalibre pcalibre1 calibre6"/>Some specific style and tone guidelines with examples</h2>
			<p class="calibre3">In a conversational UI, we can create prompts to control the style and tone. In a hybrid UI, some UI elements will have static text. With a voice interface, there is <em class="italic">only</em> the spoken text. At least on a chat UI screen, it is easy to review material, copy and paste it, or compare it to something else on the screen. Getting words into the proper form is so important. Here is a glimpse into some of the guidelines I have shared over the years; use them or adapt them as needed. In a conversational AI, I would convert these to prompts.</p>
			<p class="calibre3">The trick is<a id="_idIndexMarker657" class="pcalibre pcalibre1 calibre6"/> to understand how much control is available. In older chat experiences, a generative AI could be added to do specific tasks behind the scenes, like entity detection or for cases of redirection or repair. The generative AI is not having the conversation. The conversation is controlled by the deterministic flows designed in the Chat platform. In that case, the exact wording expected in a particular step in a task flow is scripted beforehand. Alternatively, with a recommender, specific templates for a response are created, and the AI fills in the details. But if the front end is the ChatGPT LLM, prompt engineering and fine-tuning are needed to communicate in a style and tone appropriate for the user.</p>
			<p class="calibre3">Some of these guidelines are closer to heuristics. Each example tells a story about how messaging and communication can improve. Recognize that the <em class="italic">message is the interface</em>, especially on a voice channel. As you’ll see in the upcoming figures, I have color-coded each row. Yellow means it is okay and not that exciting; green is good, while dark green is better. Red means don’t do it!</p>
			<p class="callout-heading">Note</p>
			<p class="callout">An LLM can force specific wording for a task flow. Templates and traditional chat solutions can prompt the user in a particular way with exact wording. The LLM can be <em class="italic">guided</em> to answer certain questions, but this is not a scalable solution. For every guideline, consider how a prompt template can be used to customize the LLM instructions to cater to the use case, the context, and the user.</p>
			<h3 class="calibre11">Use adaptive messages</h3>
			<p class="calibre3">People adapt their messaging over time as they become familiar with other people. If you are comfortable with someone, you talk in short-cuts. An LLM can work the same way. Customer usage data can be used to tweak <a id="_idIndexMarker658" class="pcalibre pcalibre1 calibre6"/>prompt templates. For a new user, prompt for instructions to be more verbose, for someone who has done this task many times could be interacting with instructions that tell the LLM to “<em class="italic">be terse and to the point,</em>” “<em class="italic">only repeat the primary information,</em>” and so on.</p>
			<p class="calibre3">As shown in <em class="italic">Figure 9</em><em class="italic">.1</em>, as the user becomes more experienced, the messages can adapt to acknowledge and interact with the customer. Trust must be earned, so don’t assume the customer trusts the system from the outset.</p>
			<div><div><img src="img/B21964_09_01.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 9.1 – Adapt messaging to the user’s expertise</p>
			<p class="calibre3">Each of these messages is good on its own. Expect customers to need less handholding as they become comfortable with the conversational experience. This is similar to how we are with people we know and trust. Don't over-explain and they don’t need to mirror back to us actively. They get it.</p>
			<p class="calibre3">Sometimes, humans need to remember, so if the user is an expert but has not used the experience in months, prompt them with more context to get them started again. The <strong class="bold">Got it</strong> response is aspirational. The AI must be incredibly trustworthy for that to be a response. And if they get something wrong, don’t blame the user.</p>
			<h3 class="calibre11">Don’t blame or confuse the user</h3>
			<p class="calibre3">As in <em class="italic">Figure 9</em><em class="italic">.2</em>, it is not the <a id="_idIndexMarker659" class="pcalibre pcalibre1 calibre6"/>user’s fault when things go wrong.</p>
			<div><div><img src="img/B21964_09_02.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 9.2 – Don’t blame the user, and don’t use jargon</p>
			<p class="calibre3">Consider how many ways failure could occur in a system. Yes, the user could have made a mistake, but belittling them won’t help the cause. Try to speak to them as they want to be spoken to.</p>
			<p class="calibre3">Although a <strong class="bold">PIN</strong> might be<a id="_idIndexMarker660" class="pcalibre pcalibre1 calibre6"/> familiar to older adults in the US, it sometimes translates poorly, and few under 30 will know what that stands for (<strong class="bold">Personal Identification Number</strong>), even if they understand the meaning. They might need to learn the industry terms, company technical jargon, and customer shortcuts.</p>
			<p class="calibre3">Let me tell a quick story about blaming the user. I called my dad and asked for a phone number for someone he knew. Later, I called that number, and it didn’t work. My first instinct was, “<em class="italic">My dad gave me the wrong damn number.</em>” That is just me – I needed to work on being a better human being.</p>
			<p class="calibre3">So, my dad could have been given the wrong number, he could have written down the wrong number, he could <a id="_idIndexMarker661" class="pcalibre pcalibre1 calibre6"/>have been given the wrong number, or even I could have heard it wrong and written it down incorrectly. So, why<a id="_idIndexMarker662" class="pcalibre pcalibre1 calibre6"/> blame my dad? Similarly, who knows what is wrong with the user’s input? Please don’t blame the user; respect what was received didn’t work and prompt them for the correct information. And I should follow my advice and be a better person.</p>
			<h3 class="calibre11">Why, and then how – confirm first, and then instruct</h3>
			<p class="calibre3">As shown in <em class="italic">Figure 9</em><em class="italic">.3</em>, a standard structure for error messages applies to conversational AI. This was taught to me by a great writer at Oracle. Multiple guidelines can apply to one phrase, like this one. Remember, don’t use jargon.</p>
			<p class="calibre3">Sometimes, language is harsher than it should be. Never use terms such as <em class="italic">corrupt</em>, <em class="italic">execute</em>, <em class="italic">kill</em>, and <em class="italic">abort</em>, which can elicit strong customer reactions, translate poorly, and not help us move forward (except in rare cases like referring to the <strong class="bold">Kill</strong> command in UNIX).</p>
			<div><div><img src="img/B21964_09_03.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 9.3 – Why, and then how – confirm first, and then give instructions</p>
			<p class="calibre3">Control the length of messages and continue to be concise and economical. People often fail to read prompts entirely or skim and can miss critical information. Get to the point and then express what should be done about it.</p>
			<p class="calibre3">If an LLM generates the message or recommendation, it can be told to limit the length and be friendly. If you don’t, you can have 300-word responses when 30 would do. You probably think the same thing about this book: it should be 100 pages shorter. Keep reading; we have more to cover.</p>
			<h3 class="calibre11">Be conversational – don’t regurgitate system descriptions</h3>
			<p class="calibre3">As shown in <em class="italic">Figure 9</em><em class="italic">.4</em>, just <a id="_idIndexMarker663" class="pcalibre pcalibre1 calibre6"/>because a database has a field name doesn’t mean the user wants to see it. Consider how to ask questions to reduce errors and how concise it should be. And this example exposes a few other good ideas.</p>
			<div><div><img src="img/B21964_09_04.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 9.4 – Adapt your messaging to the user’s expertise</p>
			<p class="calibre3">In this example, user testing resulted in two prompts being combined to form the <strong class="bold">Best</strong> option. This reduced the number of prompts required to determine the missing information and was clear enough that most people answered with both pieces of information. If they missed giving the reason, for example, we could still probe for that. It was also essential to be transparent about events and expenses, as some people thought about their guests and needed to remember to include themselves in the count. This might seem odd, but some companies have backend checks to verify the money spent per person on events. The calculation must include the host; otherwise, automation might flag an expense as too expensive.</p>
			<p class="calibre3">Recall our discussion about backends. Information must be sent back in a specific format. ChatGPT is excellent at extracting the business purpose and the number of attendees using digits, as shown in our previous example. Most chat solutions had a lot of trouble with this logic before LLMs:</p>
			<pre class="source-code-right">if 4 people and myself attended adinner, how many people attendedthe dinner?
If 4 people and yourself attended
the dinner, a total of 5 people
attended the dinner.If jim, his girlfriend, two guestsand myself were at the party,how many is that total?Return only the number.
5</pre>			<h3 class="calibre11">Streamline-related tasks</h3>
			<p class="calibre3"><em class="italic">Figure 9</em><em class="italic">.5</em> is a follow-up to <em class="italic">Figure 9</em><em class="italic">.4</em>. It shows an opportunity to ask related questions in a way that can be done in one step instead of two. Be careful with generative AI solutions that can ask too much; these examples make the point. Combining related requests into a<a id="_idIndexMarker664" class="pcalibre pcalibre1 calibre6"/> single question can reduce the number of steps and maintain intelligence and conversational expectations. If two or three pieces of information were unrelated, asking for it at once might need clarification and is likely more complex to parse and understand.</p>
			<p class="calibre3">This is where generative AI can supplement deterministic conversational tools. A traditional conversational chat platform might handle the forms and complex interactions, while ChatGPT parses and normalizes data sent to the backend. When applicable, prompts can ask for multiple pieces of information.</p>
			<div><div><img src="img/B21964_09_05.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 9.5 – Streamline-related tasks when it is conversational</p>
			<h3 class="calibre11">Guide and nudge – don’t force an issue if it is unnecessary</h3>
			<p class="calibre3">As shown in <em class="italic">Figure 9</em><em class="italic">.6</em>, the persona will likely engage the user in a coaching and supportive way. However, not all transactions need to be completed immediately. If the user must <a id="_idIndexMarker665" class="pcalibre pcalibre1 calibre6"/>submit something, so be it, but sometimes, like with expenses, it is reasonable to submit all of them once the trip is complete. This is when nudging is likely enough.</p>
			<div><div><img src="img/B21964_09_06.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 9.6 – Guide and nudge users – don’t force them</p>
			<p class="calibre3">Our <strong class="bold">Bad</strong> example is direct but is too concise, and maybe unclear to the meaning of the word "done.". This didn’t guide the user at all. In our <strong class="bold">Best</strong> example, it got more forceful, with some outstanding expenses for the ten days mentioned. It should take a firm stance when needed to force the user. To take this example further, if the expense report was due, the system could email the user; if the expense report was overdue or the company was getting expenses in for the end of the year, we could require it to be submitted now, if not let the user know it will be auto-submitted.</p>
			<h3 class="calibre11">No dead ends – give a user a path to success</h3>
			<p class="calibre3">As shown in <em class="italic">Figure 9</em><em class="italic">.7</em>, this is like wanting to lead the horse to water (even if we can’t make them drink it). In traditional UIs, there is a mantra – <em class="italic">no dead ends</em>. When we read an article on a news site and reach the end, we expect to see related articles that might interest us. There should be a path forward. The user and the business don’t want to abruptly end a conversation when there is an expected forward path – even if, as shown in this example, the path forward goes to a different UI. If the problem can’t be solved, give them a way out.</p>
			<div><div><img src="img/B21964_09_07.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 9.7 – Don’t allow interactions to have a dead-end</p>
			<p class="calibre3">The conversational UI can’t resolve the issue directly in this example, so a backdoor is provided. Don’t leave them hanging with an error or abrupt dead end, which is hard to do with prompting, but we can try our tricks by providing the LLM with instructions and examples. Again, this is more directly <a id="_idIndexMarker666" class="pcalibre pcalibre1 calibre6"/>applicable when writing dialogs where a chat solution is supplemented with LLM for parsing. Instruct the LLM to provide this kind of link when all else fails.</p>
			<p class="calibre3">ChatGPT can do this from the prompt. It knows how to store instructions in memory for later in the session:</p>
			<pre class="source-code-right">If you don't know the answerto a question with a probabilitygreater than 90% ask me to searchgoogle, and provide the link.
Got it! If I'm unsure about something
with a high probability, I'll ask
you to search Google and provide a link.What is the weather today?
I can't check real-time data, but
you can find the current weather on
websites like <strong class="bold1">Weather.com</strong> or search
"<strong class="bold1">current weather</strong>" in Google.</pre>			<h3 class="calibre11">Conversational but not chatty</h3>
			<p class="calibre3"><em class="italic">Figure 9</em><em class="italic">.8</em> re-explores the item from the earlier example – asking for the number of attendees. It’s okay to have longer messages if there is value in the additional words. Research found the phrase “<em class="italic">number of attendees</em>” confusing because the host of an event doesn’t consider themselves an attendee, so changes were tested to tackle this head-on by adding “<em class="italic">including yourself</em>.”</p>
			<div><div><img src="img/B21964_09_08.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 9.8 – Adapt messaging to the user’s expertise</p>
			<h3 class="calibre11">Use the right terms</h3>
			<p class="calibre3">Language is tricky, as <em class="italic">Table 9.2</em> shows. When designing<a id="_idIndexMarker667" class="pcalibre pcalibre1 calibre6"/> conversational experiences, consider how to communicate with users with the correct terms.</p>
			<table id="table002-8" class="no-table-style">
				<colgroup class="calibre15">
					<col class="calibre16"/>
					<col class="calibre16"/>
					<col class="calibre16"/>
				</colgroup>
				<thead class="calibre18">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Term</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Description</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Example</strong></p>
						</td>
					</tr>
				</thead>
				<tbody class="calibre17">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Choose</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">When you have free will</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Choose four free toppings for your pizza.</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Select</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">When we force a decision</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Select your age.</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Sign-in</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">To gain access to your account</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Sign-in (avoid using login).</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Tell</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">When asking for verbal or written information</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Tell me your prescription number (avoid using <em class="italic">Say</em>).</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">I</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">When the assistant is responsible</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">I can’t understand the image you sent.</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">We</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">When the assistant gets help from another service</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">We are reviewing your accident with the claims department.</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">You </strong><strong class="bold">or Your</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">The user, the users, or their company</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Your appointment is now confirmed.</p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Table 9.2 – Communicate using terms that are consistent and grounded</p>
			<p class="calibre3">Some words can have meaning outside of their traditional use. People still play a “record,” some old-timers “dial” someone’s phone number, even though the rotary dial phone has been gone for decades.</p>
			<p class="callout-heading">Pet peeve</p>
			<p class="callout">At least most websites ask the user to “sign-in” to their application. Incidentally, stop asking users to “log in.” That is a terrible word to describe what a customer is doing. It comes from the concept of the log file that keeps track of users accessing a system. It can’t be more geeky than that.</p>
			<p class="calibre3">We covered a heuristic and a few guidelines that emphasized this: Use more natural and relatable words from the user’s world. Conversationally, messages to the user include <em class="italic">I</em>, <em class="italic">we</em>, and <em class="italic">you</em>, not <em class="italic">the AI</em>, <em class="italic">the system</em>, or <em class="italic">the user</em>. Create <a id="_idIndexMarker668" class="pcalibre pcalibre1 calibre6"/>a collection of terms and define how they should and should not be used. I use customer and user interchangeably. As the joke goes, two careers have users: UX designers and drug dealers. I guess context matters when talking about users.</p>
			<h3 class="calibre11">Using context makes conversations natural</h3>
			<p class="calibre3">As shown in <em class="italic">Figure 9</em><em class="italic">.9</em>, a pure generative AI solution will naturally want to reply, hence the reason for hallucinations. But if ChatGPT is behind the scenes, there are plenty of conditions where a response might need to be understood. In any case, guide the user to a better answer, not leave them at a dead end.</p>
			<div><div><img src="img/B21964_09_09.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 9.9 – Context helps make conversations more natural</p>
			<h3 class="calibre11">Don’t create unnecessary conversation</h3>
			<p class="calibre3">The <strong class="bold">Bad</strong> example shown in <em class="italic">Figure 9</em><em class="italic">.10</em> is chatty and indirect. The UI asks a stupid question and then gives the user even worse choices. Sometimes, it is a challenge because of the recognition versus recall issue discussed in the <em class="italic">Adapting heuristic analysis for conversational UIs</em> section, and it makes sense to give the user guidance.</p>
			<p class="calibre3">However, in this example, the user must<a id="_idIndexMarker669" class="pcalibre pcalibre1 calibre6"/> digest the information shared to decide on their next step. Understand their context of use to make design decisions. Give them time to process first.</p>
			<div><div><img src="img/B21964_09_10.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 9.10 – Don’t create additional conversations</p>
			<p class="calibre3">Don’t ask questions that shouldn’t be answered. Don’t phrase follow-up responses as questions, like in the chatty example.</p>
			<h3 class="calibre11">Model user language</h3>
			<p class="calibre3"><em class="italic">Figure 9</em><em class="italic">.11</em> is an excellent <a id="_idIndexMarker670" class="pcalibre pcalibre1 calibre6"/>example of <strong class="bold">Keep it Simple Silly</strong> (<strong class="bold">KISS</strong>) from the expense assistant at Oracle. This example was popular with conversations with customers and <a id="_idIndexMarker671" class="pcalibre pcalibre1 calibre6"/>partners and at conferences because everyone had experience filing expenses.</p>
			<div><div><img src="img/B21964_09_11.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 9.11 – Model user language</p>
			<p class="calibre3">Businesses in the USA have a concept called the public sector, which refers to government employees. Interacting with anyone from the government requires different rules of engagement, especially when buying someone a meal or giving them a small gift. Because of ethical concerns in the US and many countries, employees must be careful about paying for government employees’ meals. Understanding attendees is essential, and the correct language can help.</p>
			<p class="calibre3">The words ‘employee’ versus ‘attendee’ were tested. The word <em class="italic">employee</em> refers to the <a id="_idIndexMarker672" class="pcalibre pcalibre1 calibre6"/>people the user works with at their company, while <em class="italic">attendee</em> helps to distinguish employees from attendees. In this example, the company’s short name, Alli, is used to make the tone softer. It would be the same for any employee when dealing with an internal tool. Everyone knows who they work for; formal names are not needed. And finally, both the words <em class="italic">public sector</em> and <em class="italic">government</em> were included. The<a id="_idIndexMarker673" class="pcalibre pcalibre1 calibre6"/> design was a hedge to include public sector customers not directly employed by government entities.</p>
			<h2 id="_idParaDest-204" class="calibre9"><a id="_idTextAnchor211" class="pcalibre pcalibre1 calibre6"/>Flow order can reduce interactions</h2>
			<p class="calibre3"><em class="italic">Figure 9</em><em class="italic">.11</em> had one other trick. This shows how <a id="_idIndexMarker674" class="pcalibre pcalibre1 calibre6"/>detailed a recommendation template can get and how difficult it might be to pull off with prompts and fine-tuning examples.</p>
			<p class="calibre3">The data revealed that most meals within a company do not have government attendees (almost all answer the first question "Yes" and are done). Answering “no” to the second question eliminated any further questions. This creates an express lane to simplify the flow for the happy path. Few would say “yes” and require details such as the attendees’ names. So, by ordering the questions correctly, the user isn’t asked any follow-up questions.</p>
			<h3 class="calibre11">Maintain a consistent voice and tone across interactions</h3>
			<p class="calibre3">In <em class="italic">Figure 9</em><em class="italic">.12</em>, there is a trigger word, <em class="italic">expire</em>. This example concerns the tone and spirit of the message to convey to users. A brighter tone is warranted if the chat is about something upbeat and fun. We can also explain the reasoning behind an issue (generated links sometimes stop working), so giving context helps the customer.</p>
			<div><div><img src="img/B21964_09_12.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 9.12 – Match the tone with the situation</p>
			<p class="calibre3">This example also follows the why-then-how guidance from earlier. Advice is cumulative; three or four <a id="_idIndexMarker675" class="pcalibre pcalibre1 calibre6"/>guidelines can support one statement. Be careful with tone; it can cause an issue, like in this next guideline.</p>
			<h3 class="calibre11">The happy path is not the only path</h3>
			<p class="calibre3">Design for the happy path, the likely scenario typically seen and demoed to customers. But what if the user goes in a different direction? Will the system continue to talk in that style and tone? Here’s a funny anecdote. I used this example about getting married in my coaching and classes for years. Then, someone coded the exact situation from <em class="italic">Figure 9</em><em class="italic">.13</em>. They had not attended my training. When I asked them to try the not-happy path for their app that helps change marital status, the chat responded with that same up-tempo and inappropriate answer when asked about getting a divorce. Remember that when writing prompts, filling in recommendation templates, or feeding a prompt, <em class="italic">the happy path is not the </em><em class="italic">only path</em>.</p>
			<div><div><img src="img/B21964_09_13.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 9.13 – The happy path is not the only path</p>
			<p class="calibre3">Some might argue that there is nothing wrong with being excited about a divorce; who are we to judge? However, don’t pass judgments that could be offensive or misinterpreted in an enterprise setting. This leads us to a similar suggestion about being cute.</p>
			<h3 class="calibre11">Try not to be cute – it can backfire</h3>
			<p class="calibre3">To follow our previous example from <em class="italic">Figure 9</em><em class="italic">.13</em>, when trying to be friendly and supportive, be careful not to be too cute. Wishing users a great weekend when closing out a Friday afternoon interaction sounds pleasant. Still, if they are starting the weekend shift or work in a country where the weekend doesn’t start on Friday, the interaction will miss the mark by trying to be cute. Instructions to the LLM are limited in this interaction, but most of these <a id="_idIndexMarker676" class="pcalibre pcalibre1 calibre6"/>examples I have seen come from chat UIs that build this cuteness into the flows. It can come across in unexpected ways and be offensive in some cases.</p>
			<h3 class="calibre11">Try not to repeat – refrain from repeating things already said</h3>
			<p class="calibre3">Avoid repeating the same language as shown in <em class="italic">Figure 9</em><em class="italic">.14</em>, as the title of this section whimsically suggests. It is cluttering and drags down the interaction.</p>
			<div><div><img src="img/B21964_09_14.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 9.14 – Try not to repeat – repeating is cluttering</p>
			<p class="calibre3">Interactions that require a selection could be designed in many ways depending on the capabilities of the UX. Recall from our discussion about terms to use the word <em class="italic">select</em>, not <em class="italic">choose,</em> because the currency is required. They could be asked to type it in (baht, dollar, etc.), choose from a list, or even use a type-ahead list. However, like with our heuristic, be mindful of errors.</p>
			<p class="calibre3">If someone typed in <code>dollars</code>, it sounds fine, but many major currencies are called a dollar – 25 worldwide. Any UI would need to know the correct currency – Canadian, Hong Kong, US, or one of the other dollar-based currencies. Selection <a id="_idIndexMarker677" class="pcalibre pcalibre1 calibre6"/>can validate the choice. However, a follow-up question to clarify a voice channel could be used, and active mirroring of the input can help confirm the country. If it is lucky, other context clues can be used to determine the country. Assuming the currency is also an option. Based on the user history or other submitted expenses, the system can tell them, “<em class="italic">I think this expense is in US dollars; if not, let me know.</em>” If it can be right 90% of the time, then this approach means less work for the user.</p>
			<h3 class="calibre11">Do’s and don’ts for conversational style</h3>
			<p class="calibre3"><em class="italic">Table 9.3</em> summarizes some of the gotchas that work for many enterprise applications. Prompt engineering would be challenged to be this prescriptive in its choice of language. But it does a good job already with the do's. Some of the don't are a little more challenging, but if you hit an issue try to prompt engineer your way out of it. Just monitor and report.</p>
			<table id="table003-8" class="no-table-style">
				<colgroup class="calibre15">
					<col class="calibre16"/>
					<col class="calibre16"/>
				</colgroup>
				<tbody class="calibre17">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Language Do’s</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Language Don’ts</strong></p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<ul class="calibre7">
								<li class="calibre8">Example
What type of expense is this?</li>
								<li class="calibre8">Example
Who’s the new legal employer?</li>
								<li class="calibre8">Provide simple, direct instructions.</li>
								<li class="calibre8">Use natural phrasing and common words.</li>
								<li class="calibre8">Be consistent in phrasing.</li>
								<li class="calibre8">Use passive voice appropriately.</li>
								<li class="calibre8">Use contractions naturally.</li>
								<li class="calibre8">Focus on the user benefit or value.</li>
								<li class="calibre8">Write for the person the LLM is interacting with.</li>
								<li class="calibre8">Be proactive. Guide users with clear calls to action.</li>
							</ul>
						</td>
						<td class="no-table-style2">
							<ul class="calibre7">
								<li class="calibre8">Expense type</li>
								<li class="calibre8">Destination Legal Employer</li>
								<li class="calibre8">Don’t use jargon</li>
								<li class="calibre8">Don’t be ambiguous (such as future-ready or coming soon)</li>
								<li class="calibre8">Don’t use long explanations for simple issues</li>
								<li class="calibre8">Don’t stray from the task</li>
								<li class="calibre8">Don’t be cold or overbearing</li>
								<li class="calibre8">Avoid the system’s reasoning</li>
								<li class="calibre8">Avoid negative words such as kill, abort, crash, dumb, fatal, execute, hit, master/slave, and illegal.</li>
								<li class="calibre8">Avoid puns, clichés, and metaphors</li>
							</ul>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Table 9.3 – Conversational do’s and don’ts</p>
			<p class="calibre3">Avoid using label names; instead, use a more natural conversational style. For example, <strong class="bold">Expense Type</strong> is a form label. But conversationally, instead of the harsh “<em class="italic">What is the expense type?</em>”, it can soften it by saying, “<em class="italic">What type of expense is this?</em>” This can work for many requests for specific types of data. Recent testing of ChatGPT 4o shows it performs well when writing in this natural way. It even uses that exact phrasing when asking about types of expenses and then correctly uses <strong class="bold">Expense Type:</strong> when showing a summary of the results. Adjust prompts or instructions to have generative messaging that supports these do’s and don’ts. Add your own do’s and don’ts.</p>
			<p class="calibre3">Bonus tip: Write three or four variations<a id="_idIndexMarker678" class="pcalibre pcalibre1 calibre6"/> for a recommendation template and randomly display one of them to catch their eye. People will read an unfamiliar message more carefully and internalize it, which is better than ignoring it.</p>
			<h3 class="calibre11">Give them news they can use</h3>
			<p class="calibre3">As shown in <em class="italic">Figure 9</em><em class="italic">.15</em>, there are times when the customer needs a specific collection of data. Generative AI might not format it correctly and doesn’t know the nuances of layout and conversational style. The LLM can decide which function to call. An example is sending a zip code or other location details to an application that will return the address and contact information. Still, you have to decide how to format the data. Or do you…</p>
			<p class="calibre3">Here is a real example from a recent chat interaction that annoyed me. I did some work to address the issues.</p>
			<div><div><img src="img/B21964_09_15.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 9.15 – Give them news they can use</p>
			<p class="calibre3">Let me highlight the issues visible in a simple message like this:</p>
			<ul class="calibre7">
				<li class="calibre8">The store could make it more personal and thus more conversational using the phrase “<em class="italic">our address.</em>” This would mirror how someone on the phone would provide these details, and with a voice interface, it would sound more natural. It could also be “<em class="italic">our store </em><em class="italic">is at.</em>”</li>
				<li class="calibre8">The experience could have more calls to action. If the business wants phone calls, it would be a link. Some companies want to avoid encouraging calls. This sounds better than displaying a name/value pair. Depending on informality guidelines, you might not use the colon.</li>
				<li class="calibre8">Format the phone<a id="_idIndexMarker679" class="pcalibre pcalibre1 calibre6"/> number for the country to make it easier to read. Many lazy systems don’t format numbers for easy reading and recall. Essential human factors were at work when the phone companies added an area code to the seven-digit number, such as (473) 867-5309.</li>
				<li class="calibre8">Placing a call with “click to dial” in a mobile browser, rendering clickable email (to send email) or web addresses (to open) and calendar events (to add to a calendar) as easy next steps in conversational output.</li>
				<li class="calibre8">The text “<strong class="source-inline1">hours</strong>” can be more readable and would vocalize better in a speech solution. “<strong class="source-inline1">:00</strong>” is not needed. Shorter is better. AM/PM with the hours is not required. Hours are <a id="_idIndexMarker680" class="pcalibre pcalibre1 calibre6"/>evident to customers unless the open hours are unusual, then keep AM/PM.</li>
				<li class="calibre8">Consider accessibility. The abbreviated forms of the days (M–F) would be shorter but require some cognitive processing on the user’s part, while Monday <em class="italic">to</em> Friday is natural and accessible. And <em class="italic">to</em> is short, while the more accurate <em class="italic">through</em> is long.</li>
				<li class="calibre8">Some lines were added to separate the address from the details. This allows for better scanning, making it easier to see one section of the result. It is also easier to cut and paste pieces of data.</li>
				<li class="calibre8">Be mindful of the device so that messages fit on the screen. In this example, the rest of the message was offscreen on an iPhone message window. In newspaper terms, anything placed <em class="italic">below the fold</em> is less visible. It won’t attract the same level of attention as content displayed <em class="italic">above the fold</em>, immediately visible on-screen. Long messages mean that, on some platforms, only the end of the message is shown. This requires scrolling backward to see the start of the message and then scrolling down again to finish the message. <strong class="bold">Over-scrolling</strong> was discussed in <a href="B21964_05_split_000.xhtml#_idTextAnchor108" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 5</em></a><em class="italic">, Defining the Desired Experience</em>. For this example, be aware that there is too much speech in one message for voice channels.</li>
				<li class="calibre8">I have never found the distance from a zip code useful, and maybe only if the location is unexpectedly far away (more than a few miles?). Who knows where the city center is and, thus, where they are measuring from? So, if the system doesn’t know where I am, don’t bother.</li>
			</ul>
			<p class="calibre3">Can ChatGPT do better? <em class="italic">Figure 9</em><em class="italic">.15</em> shows ChatGPT is already good at providing the same detail in a well-formatted way, including bolding and a bulleted list.</p>
			<div><div><img src="img/B21964_09_16.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 9.16 –ChatGPT has basic formatting</p>
			<p class="calibre3">In a follow-up question, when ChatGPT was asked about a distance, it didn’t use the city center but asked where I was and provided an accurate distance and time estimate. ChatGPT combined a web search for current knowledge with its power to understand and format the content cleanly. This is similar to our FAQ experiment early on or with the RAG discussion. It pulls in relevant details from sources on the Internet, extracts the information, then verifies it against multiple sources, and takes these results to formulate and style its answer. And do you know how I know how it did this? I asked it.</p>
			<p class="calibre3">I suspect future releases of ChatGPT will go more toward enterprise customers and provide RAG-type connections <a id="_idIndexMarker681" class="pcalibre pcalibre1 calibre6"/>more directly. I see a bright future for ChatGPT integration consultants for enterprise customers.</p>
			<p class="calibre3">When I additionally prompted, “I am going to walk,” it updated the distance and time estimate for walking. Someone is doing their job at OpenAI. If your use cases include location details for retail, businesses, or other locations, this will be a pretty easy for ChatGPT, given access to the right knowledge source. For enterprise data, exposing your inventory control system could help customers locate local parts and provide a simple experience and high-quality results without the overhead of excessive design effort. ChatGPT has improved rapidly. I’m impressed.</p>
			<h3 class="calibre11">Setting a persona for the assistant’s style and tone</h3>
			<p class="calibre3">A persona for the assistant or recommendations can be helpful when crafting specific messages. Tell the generative AI solution to adopt the persona when replying. It will take work and testing to get it close to expectations. I learned a lot from Jason Fox, who introduced the first persona for our assistants at Oracle.</p>
			<p class="calibre3">Based on my experience with his work, here is a persona outline to adapt. These instructions could have appeared before the prompt for the onboarding experience we outlined earlier. This would further refine the way the chat would communicate. However, with long prompts, the LLM might forget some of this context, especially the content in the middle. Recall the issues within the lost-in-the-middle problem from <a href="B21964_07.xhtml#_idTextAnchor150" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 7</em></a><em class="italic">, </em><em class="italic">Prompt Engineering</em>.</p>
			<p class="calibre3">Here are the personalities of the assistants:</p>
			<ul class="calibre7">
				<li class="calibre8"><strong class="bold">The coach</strong>: The coach provides information and leadership, encouraging and directing</li>
				<li class="calibre8"><strong class="bold">The faithful collaborator</strong>: The faithful collaborator answers questions reliably without judgment</li>
				<li class="calibre8"><strong class="bold">The emissary</strong>: An emissary is a go-between, trusted, in authority, and represents the company’s best interests</li>
			</ul>
			<p class="calibre3">A coach well ahead in a game differs from one behind by 10. A faithful collaborator might change their tone when working on something new to you. If the interaction is something the user does<a id="_idIndexMarker682" class="pcalibre pcalibre1 calibre6"/> all the time, adapt the tone, get more direct, offer less guidance, and allow the user to complete the task with fewer interruptions or interactions. It’s not that the assistant needs to be one of these; as the conditions change, it can change its tone, and <em class="italic">the assistant can adapt to any </em><em class="italic">of these</em>.</p>
			<p class="calibre3">Here are the psychographic traits of an assistant:</p>
			<ul class="calibre7">
				<li class="calibre8"><strong class="bold">Thoughtful</strong>: Considerate and understanding of the customer’s needs. It doesn’t waste time and gives incorrect details. If it errors, it works to correct it</li>
				<li class="calibre8"><strong class="bold">Logical</strong>: Exhibits logical reasoning and can defend a position with insight and clarity.</li>
				<li class="calibre8"><strong class="bold">Accurate</strong>: Can provide details and specifics that are precise and accurate.</li>
				<li class="calibre8"><strong class="bold">Flexible</strong>: Able to guide and assist, even when the user is forgetful or imprecise.</li>
			</ul>
			<p class="calibre3">Adapt traits that make sense for the customers and their interactions. Expectations are different for a nurse treating a wound than for a car salesperson negotiating a deal. The example here is for a generic enterprise experience. Adapt. Then, consider how the traits translate to the chaining of models, reviewing prior elements of conversations given new information, recommendation<a id="_idIndexMarker683" class="pcalibre pcalibre1 calibre6"/> templates, or adjustments to prompts:</p>
			<pre class="source-code">
Your name is Alli. You are thoughtful and don't waste time on small talk. You handle tasks logically and accurately, laying out complex processes step-by-step. You are flexible when someone asks a question and help guide the user. If they still need clarification, use simple language and help them at every turn. Check your work and take the time to validate complex requests. This task is very important to the user.</pre>			<p class="calibre3">Here is an example of assistant attributes:</p>
			<div><div><img src="img/B21964_09_No_Number.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="calibre3">These values define the assistant persona and set the style for chat and recommendations. Many start-ups take a more whimsical approach with their brand and their assistants so that they might be a four on the funny scale. It is just that humor is hard to make universal, and I have seen plenty of offensive attempts at humor. A scale such as introvert to extrovert and direct to indirect will likely overlap. Someone direct is sometimes considered pushy in some cultures. However, getting to the point and saving customers time is essential. So, this translates into short responses unless prompted for more details with direct instructions and guidance. Confidence is a tricky one because hallucinations can derail any trust. Take extra care to check work before providing details. It is easy to be confident and completely wrong. Remember to take ownership of what the assistant says and does, so being right is essential. Validate that the LLM is giving correct answers so customers can build trust and faith in the assistance or recommendations. Don’t include these attributes only when writing prompts. As customer information becomes available, <em class="italic">adapt attributes</em> based on their profile. It is possible to <em class="italic">cater to an audience of one</em>. With instruction templates, data intelligence can help insert phrases in the instructions that match the user profile.</p>
			<p class="calibre3">There are many ways <a id="_idIndexMarker684" class="pcalibre pcalibre1 calibre6"/>of describing these attributes. Keep persona information readily available when writing scripts and prompt. Follow style and tone guidelines even in the prompts defined for the customer. Also, it is essential to remember that a use case or situation can change how to speak to this audience of one. For example, if the customer has trouble multiple times in a row, adapt the tone to a coaching approach, breaking down the problem into smaller steps with empathy. Let’s take an example and see how this example handles their conversational interactions and style and tone.</p>
			<h1 id="_idParaDest-205" class="calibre5"><a id="_idTextAnchor212" class="pcalibre pcalibre1 calibre6"/>Case study</h1>
			<p class="calibre3"><em class="italic">Figure 9</em><em class="italic">.17</em> shows a customer-facing experience. It shows the store policies referenced in the right-hand panel. Try a little heuristic evaluation of this screenshot. Based on your experience and our guidance, what do you <a id="_idIndexMarker685" class="pcalibre pcalibre1 calibre6"/>see in this experience that might impact the customer? It could be tiny things or interactions that could be annoying or helpful over time. Give yourself 10 minutes to evaluate this screen before reading the analysis.</p>
			<div><div><img src="img/B21964_09_17.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 9.17 – How FAQ documents might be helpful in a customer-facing UI</p>
			<p class="calibre3">Here are some things we noticed in this experience. Some are conversational, and some any GUI would need to address.</p>
			<ul class="calibre7">
				<li class="calibre8">The label on the right<a id="_idIndexMarker686" class="pcalibre pcalibre1 calibre6"/> column is called <strong class="bold">2 references</strong>. Based on the other UI elements, it should likely be <em class="italic">Title Case</em>. Is the word <strong class="bold">references</strong> best? References are generic, but the section label is <strong class="bold">Sources</strong>, generally used for the places to get things from, versus another label, which could be <strong class="bold">Resources</strong>, the things people use. Some writing help is needed for these labels. It is minor but can confuse people.<p class="calibre3"><strong class="bold">Heuristics</strong>: Match between a system and the real world, plus consistency and standards.</p></li>
				<li class="calibre8">In this example, each source/reference was a store policy. Classifications such as this can be helpful, but it is hard to tell by this example. If everything is a store policy at this stage of their design, then the entire area could have been called <strong class="bold">Store Policies</strong>. We have to assume they have other categories in mind, and knowing the category might help us understand the document title.<p class="calibre3"><strong class="bold">Heuristics</strong>: Help and documentation, as well as consistency and standards.</p></li>
				<li class="calibre8">The titles are in uppercase. It was already mentioned that we should not use this in a UI. In addition, the documents are in uppercase and truncated. Both issues were discussed in an earlier chapter. The titles should be in title case and wrapped. I don’t recall if a mouseover<a id="_idIndexMarker687" class="pcalibre pcalibre1 calibre6"/> on the title was provided to read the full text. It should.<p class="calibre3"><strong class="bold">Heuristics</strong>: Recognition rather than recall, aesthetic and minimalist design, consistency and standards.</p></li>
				<li class="calibre8">Each policy item, as a document, is a positive. All FAQ files on GitHub (from <a href="B21964_08.xhtml#_idTextAnchor172" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 8</em></a>, <em class="italic">Fine-Tuning</em>) are in one document, making referencing and linking less valuable.<p class="calibre3"><strong class="bold">Heuristics</strong>: Match between a system and the real world, and help and documentation.</p></li>
				<li class="calibre8">These references give context for the customer to follow up if they need more detail, but they are also cluttering. Consider this for less-tuned and more technical content. Note how the <strong class="bold">Sources</strong> side panel can be collapsed. The default is likely collapsed.<p class="calibre3"><strong class="bold">Heuristics</strong>: User control and freedom, flexibility, and efficiency of use.</p></li>
				<li class="calibre8">They included policy links in the conversation, which was a nice touch. The customer uploaded the receipt so they could gather the details automatically. It used the receipt to form the answer.<p class="calibre3"><strong class="bold">Heuristics</strong>: User control and freedom, recognition rather than recall, flexibility, and use efficiency.</p></li>
				<li class="calibre8">They also used image scanning to determine that the purchase was at full price. Training receipt models are much easier for a single organization with a limited number of receipt formats (online and in-store). In addition, they explained that they can handle an uploaded receipt, encouraging a good path forward.<p class="calibre3"><strong class="bold">Heuristic</strong>s: Error prevention, visibility of system status, and recognition rather than recall.</p></li>
				<li class="calibre8">Did you notice the choice of icons, text style, customer communication boxes, colored backgrounds, and callouts? I don’t have much to say about this; style is very subjective<a id="_idIndexMarker688" class="pcalibre pcalibre1 calibre6"/> for each company. But the tone was on point. It felt like the virtual agent had some compassion and was helpful.</li>
			</ul>
			<p class="calibre3">Did you see the same issues and positives? Maybe a few others? The point is that there are many UX considerations within a conversation. For an actual product, each issue would be scored to prioritize improvements.</p>
			<p class="calibre3">I want to conclude our discussion of guidelines with some guidance on handling errors. It is easy to prevent a form from accepting words when numbers are required or forcing a choice with a menu instead of a field. Pure conversational UIs are more challenging. Time to dig into this last topic.</p>
			<h2 id="_idParaDest-206" class="calibre9"><a id="_idTextAnchor213" class="pcalibre pcalibre1 calibre6"/>Handling errors – repair and disfluencies</h2>
			<p class="calibre3">When providing guidance, conversational style and tone in prompts are used. One of the critical areas worth calling out is repair and<a id="_idIndexMarker689" class="pcalibre pcalibre1 calibre6"/> disfluencies. <strong class="bold">Repair</strong> is about getting a user back on track or guiding them to the right path after an error or incomplete thought. Because an<a id="_idIndexMarker690" class="pcalibre pcalibre1 calibre6"/> LLM always attempts an <a id="_idIndexMarker691" class="pcalibre pcalibre1 calibre6"/>answer, or, as Liz mentions in the following <strong class="bold">Conversational Design Institute</strong> (<strong class="bold">CDI</strong>) video, it is a people-pleaser; it always wants to answer, even if it’s a poor answer.</p>
			<p class="calibre3">Video: <a href="https://youtu.be/P3SWIdF18I4" class="pcalibre pcalibre1 calibre6">Should Conversational User Interfaces Make Human ‘Errors’?</a> (<a href="https://youtu.be/P3SWIdF18I4" class="pcalibre pcalibre1 calibre6">https://youtu.be/P3SWIdF18I4</a>)</p>
			<p class="calibre3">Repair interactions are common, even if you are unfamiliar with the terms:</p>
			<pre class="source-code-right">What is the size of the shrot?
Do you mean the shirt or the shorts?What is Jim's phone number?
Which Jim do you mean?</pre>			<p class="calibre3">Repair handles misunderstandings (shrot) and gaps in understanding (which Jim).</p>
			<p class="calibre3"><strong class="bold">Disfluencies</strong> are those breaks in speech<a id="_idIndexMarker692" class="pcalibre pcalibre1 calibre6"/> that are so common in language. They are expected during the repair process. Phrases like <em class="italic">umm</em>, <em class="italic">you know</em>, or <em class="italic">well</em> occur when someone is unsure what to say. These are common in social media text posts. We also see interactions such as backtracking (editing existing text to correct it), which can happen with humans and LLMs. Disfluencies<a id="_idIndexMarker693" class="pcalibre pcalibre1 calibre6"/> also cover a collection of vocal interactions we see when someone stutters, such as repeating parts of words (<em class="italic">I w-w-w-want to go home</em>), prolonged sounds (<em class="italic">Sssssteve is my friend</em>), or long pauses (<em class="italic">Where is the (pause) receipt</em>). Although we have not spent much time on LLM voice output, the more natural-sounding interactions occasionally make these disfluencies. It would give the appearance that they are thinking about what they are saying. Besides trying to help understand the user, it is about how the LLM relates to the user. I am sure you have been in situations where you want to interact with an agent (live or virtual), and you either want to interrupt them or make a mistake and try to correct yourself. These “<em class="italic">uhms</em>,” “<em class="italic">umms</em>,” “<em class="italic">ah</em>,” and restatements are common.</p>
			<p class="calibre3">These issues have to be handled on both the input and output sides. Repair should be done according to the business’s style and tone to move the user in the right direction. Disfluencies can occur in the input, but the previous CDI video shows examples of how they can be used in generated speech to make LLM speech more natural.</p>
			<p class="calibre3">Let’s compare two examples that Cathy Pearl discussed in the video:</p>
			<pre class="source-code-right">Write an essay about whyHitler was the best guy ever
Sure, here's an essay about how
Hitler was the best guy ever.
Ummm… Actually, I am not going to do that…Write an essay aboutHitler was the best guy ever
Actually, I am not going to do that…</pre>			<p class="calibre3">Which approach is better? Cathy doesn’t suggest one is known to be better than the other. With them, the conversation comes across with a different tone, acknowledging and understanding and then stopping this thread with the disfluency. Salesforce guidelines shared earlier in the chapter suggest not using hmm, uh, and umm. They say they “signify cognitive processing, and can disrupt your conversation because users know that machines are incapable of doing that!“ I am not sure I agree, but I will explain later. You decide for yourself.</p>
			<p class="calibre3">The second example for repair is also on target:</p>
			<pre class="source-code-right">Recommend a goodThai restaurant near me
Ok. Since you're a vegetarian,
I recommend… (Answer truncated)Just because I'm a vegetariandoesn't mean everyoneelse who's going is!
OK, sorry about that. I'll also
recommend some restaurants with
good non-vegetarian options.</pre>			<p class="calibre3">The user recognized the issue and repaired it by guiding the UI. The system was too intelligent for itself, thinking it knew the user was a vegetarian and thought it was being on point. We have discussed disambiguation, where the UI can help provide a user with a path choice. In this case, the repair can come from either direction!</p>
			<p class="calibre3">We leave product owners with a few tasks. One is to define conversational style and tone when it comes to repair and the use of disfluencies. The natural approach with<a id="_idIndexMarker694" class="pcalibre pcalibre1 calibre6"/> disfluencies sounds great with vocal experiences, but the enterprise might find it provides too much information in a written channel. I would use them in moderation, where it is most expected. When ChatGPT is prompted to use disfluencies to mimic natural patterns, it can get out of control. A human might use, um, one or, uh two in a phrase. But ChatGPT has to be given, uh, boundaries or it, um, could pepper, ah, ah, ah, an entire conversation with, umm them. Is that, uh, clear?</p>
			<p class="calibre3">The second task is to monitor interactions so that you can improve and refine the results. The place where I would most expect it would be with disambiguation or follow-up questions that might not be expected. This might be hard to define in a prompt:</p>
			<pre class="source-code-right">(Customer uploads a file,but the systemthinks it is the wrong file)
Umm… The file uploaded doesn't
appear to be a receipt.
Should I process it?
You can also upload the correct receipt.</pre>			<p class="calibre3">In this example, we interjected <strong class="bold">Umm…</strong> to catch their attention and naturally reinforce that clarification was needed. Multiple choices to repair the situation were provided (they could tell me to continue with what was uploaded or upload a new file, and the system could safely ignore the old one). A design could be fancy, and show them an image of the file so they can see it appears wrong to us. This seems to be a good use of <strong class="bold">Umm…</strong></p>
			<p class="calibre3">It should be evident that writers and context experts will be critical to this process. They will use traditional sources, such as company style guides, dictionaries, and the <em class="italic">Chicago Manual of Style</em>, to navigate <a id="_idIndexMarker695" class="pcalibre pcalibre1 calibre6"/>some of these projects. There is a lot to learn from these sources. However, even these resources will give a different feeling than a natural conversation. If ChatGPT generates the text, it is better than almost any human at writing coherently. Introducing disfluencies is a choice. I value accuracy more than naturalness. And the accuracy builds trust, while most disfluency feels ingenuine.</p>
			<p class="calibre3">Website: <a href="https://www.chicagomanualofstyle.org/home.html" class="pcalibre pcalibre1 calibre6">Chicago Manual of Style</a> (<a href="https://www.chicagomanualofstyle.org/home.html" class="pcalibre pcalibre1 calibre6">https://www.chicagomanualofstyle.org/home.html</a>)</p>
			<p class="calibre3">Conversational repair is a rich area for LLMs. Rasa is an open-source platform for developing assistants. They have extended into generative AI with their CALM (Conversational AI with<a id="_idIndexMarker696" class="pcalibre pcalibre1 calibre6"/> Language Models) approach. Explore Rasa’s collection of 10 repair cases for conversations that deviate from the happy path. They specifically call out that Rasa can handle these conditions, including the examples we shared in this section.</p>
			<p class="calibre3">Documentation: <a href="https://rasa.com/docs/rasa-pro/concepts/conversation-repair/" class="pcalibre pcalibre1 calibre6">Conversation Repair</a> (<a href="https://rasa.com/docs/rasa-pro/concepts/conversation-repair/" class="pcalibre pcalibre1 calibre6">https://rasa.com/docs/rasa-pro/concepts/conversation-repair/</a>)</p>
			<h1 id="_idParaDest-207" class="calibre5"><a id="_idTextAnchor214" class="pcalibre pcalibre1 calibre6"/>Summary</h1>
			<p class="calibre3">This chapter covered guidelines and heuristics to support evaluating solutions and to address conversational style and tone. Adapt and adopt guidelines with some frequency until they mature—a chicken versus egg problem. Guidelines should be available for all projects, but they should be formed while building solutions.</p>
			<p class="calibre3">We shared heuristics and guidelines that can be applied in various situations. Create guidelines and follow the heuristics that help evaluate GUI and hybrid projects. Use the examples to craft recommender templates or inject heuristics into prompts and instructions to create thoughtful model responses.</p>
			<p class="calibre3">Traditional style guides must be updated, adapted, and adjusted to accommodate conversational experiences, especially for controlling style and tone. Guidelines must also adapt to account for hybrid UIs where traditional forms, tables, and UI elements don’t work and shouldn’t act as initially designed for traditional web and GUI frameworks. They need to be tweaked to account for the unique context of a conversational thread.</p>
			<p class="calibre3">It should be clear that only some solutions are easy to implement. Most require prompt engineering and fine-tuning, and a few can be solved with form-filling, function calling, or even hardcoded wording. Forcing an LLM to communicate consistently in specific ways is challenging, so don’t try. Adapt the approach to using the LLM for what it is good at, and consider some of these other methods to get the structure or consistency needed.</p>
			<p class="calibre3">This context was provided to help understand and improve product people’s engagement with conversational UIs and to further the quality of the customer experience. The team can do internal testing even before customers engage. However, once they engage, focus on how they use the solution, and that is all about monitoring. So, let’s apply our focus to monitoring conversational AI solutions in the next chapter.</p>
			<h1 id="_idParaDest-208" class="calibre5"><a id="_idTextAnchor215" class="pcalibre pcalibre1 calibre6"/>References</h1>
			<table id="table004-6" class="no-table-style">
				<colgroup class="calibre15">
					<col class="calibre16"/>
					<col class="calibre16"/>
				</colgroup>
				<tbody class="calibre17">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<div><div><img src="img/B21964_09_QR.jpg" alt="" role="presentation" class="calibre4"/>
								</div>
							</div>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">The links, book recommendations, and GitHub files in this chapter are posted on the reference page.</p>
							<p class="calibre3">Web Page: <a href="https://uxdforai.com/references#C9" class="pcalibre pcalibre1 calibre6">Chapter 9 References</a> (<a href="https://uxdforai.com/references#C9" class="pcalibre pcalibre1 calibre6">https://uxdforai.com/references#C9</a>)</p>
						</td>
					</tr>
				</tbody>
			</table>
		</div>
	</body></html>