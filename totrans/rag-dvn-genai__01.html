<html><head></head><body>
  <div id="_idContainer018" class="Basic-Text-Frame">
    <h1 class="chapterNumber"><span class="koboSpan" id="kobo.1.1">1</span></h1>
    <h1 id="_idParaDest-15" class="chapterTitle"><span class="koboSpan" id="kobo.2.1">Why Retrieval Augmented Generation?</span></h1>
    <p class="normal"><span class="koboSpan" id="kobo.3.1">Even the most advanced generative AI models can only generate responses based on the data they have been trained on. </span><span class="koboSpan" id="kobo.3.2">They cannot provide accurate answers to questions about information outside their training data. </span><span class="koboSpan" id="kobo.3.3">Generative AI models simply don’t know that they don’t know! </span><span class="koboSpan" id="kobo.3.4">This leads to inaccurate or inappropriate outputs, sometimes called hallucinations, bias, or, simply said, nonsense.</span></p>
    <p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.4.1">Retrieval Augmented Generation</span></strong><span class="koboSpan" id="kobo.5.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.6.1">RAG</span></strong><span class="koboSpan" id="kobo.7.1">) is a framework that addresses this limitation by combining retrieval-based</span><a id="_idIndexMarker000"/><span class="koboSpan" id="kobo.8.1"> approaches with generative models. </span><span class="koboSpan" id="kobo.8.2">It retrieves relevant data from external sources in real time and uses this data to generate more accurate and contextually relevant responses. </span><span class="koboSpan" id="kobo.8.3">Generative AI models integrated with RAG retrievers are revolutionizing the field with their unprecedented efficiency and power. </span><span class="koboSpan" id="kobo.8.4">One of the key strengths of RAG is its adaptability. </span><span class="koboSpan" id="kobo.8.5">It can be seamlessly applied to any type of data, be it text, images, or audio. </span><span class="koboSpan" id="kobo.8.6">This versatility makes RAG ecosystems a reliable and efficient tool for enhancing generative AI capabilities.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.9.1">A project manager, however, already encounters a wide range of generative AI platforms, frameworks, and models such as Hugging Face, Google Vertex AI, OpenAI, LangChain, and more. </span><span class="koboSpan" id="kobo.9.2">An additional layer of emerging RAG frameworks and platforms will only add complexity with Pinecone, Chroma, Activeloop, LlamaIndex, and so on. </span><span class="koboSpan" id="kobo.9.3">All these Generative AI and RAG frameworks often overlap, creating an incredible number of possible configurations. </span><span class="koboSpan" id="kobo.9.4">Finding the right configuration of models and RAG resources for a specific project, therefore, can be challenging for a project manager. </span><span class="koboSpan" id="kobo.9.5">There is no silver bullet. </span><span class="koboSpan" id="kobo.9.6">The challenge is tremendous, but the rewards, when achieved, are immense!</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.10.1">We will begin this chapter by defining the RAG framework at a high level. </span><span class="koboSpan" id="kobo.10.2">Then, we will define the three main RAG configurations: naïve RAG, advanced RAG, and modular RAG. </span><span class="koboSpan" id="kobo.10.3">We will also compare RAG and fine-tuning and determine when to use these approaches. </span><span class="koboSpan" id="kobo.10.4">RAG can only exist within an ecosystem, and we will design and describe one in this chapter. </span><span class="koboSpan" id="kobo.10.5">Data needs to come from somewhere and be processed. </span><span class="koboSpan" id="kobo.10.6">Retrieval requires an organized environment to retrieve data, and generative AI models have input constraints.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.11.1">Finally, we will dive into the practical aspect of this chapter. </span><span class="koboSpan" id="kobo.11.2">We will build a Python program from scratch to run entry-level naïve RAG with keyword search and matching. </span><span class="koboSpan" id="kobo.11.3">We will also code an advanced RAG system with vector search and index-based retrieval. </span><span class="koboSpan" id="kobo.11.4">Finally, we will build a modular RAG that takes both naïve and advanced RAG into account. </span><span class="koboSpan" id="kobo.11.5">By the end of this chapter, you will acquire a theoretical understanding of the RAG framework and practical experience in building a RAG-driven generative AI program. </span><span class="koboSpan" id="kobo.11.6">This hands-on approach will deepen your understanding and equip you for the following chapters.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.12.1">In a nutshell, this chapter covers the following topics:</span></p>
    <ul>
      <li class="bulletList"><span class="koboSpan" id="kobo.13.1">Defining the RAG framework</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.14.1">The RAG ecosystem</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.15.1">Naïve keyword search and match RAG in Python</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.16.1">Advanced RAG with vector-search and index-based RAG in Python</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.17.1">Building a modular RAG program</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.18.1">Let’s begin by defining RAG.</span></p>
    <h1 id="_idParaDest-16" class="heading-1"><span class="koboSpan" id="kobo.19.1">What is RAG?</span></h1>
    <p class="normal"><span class="koboSpan" id="kobo.20.1">When a generative AI </span><a id="_idIndexMarker001"/><span class="koboSpan" id="kobo.21.1">model doesn’t know how to answer accurately, some say it is hallucinating or producing bias. </span><span class="koboSpan" id="kobo.21.2">Simply said, it just produces nonsense. </span><span class="koboSpan" id="kobo.21.3">However, it all boils down to the impossibility of providing an adequate response when the model’s training didn’t include the information requested beyond the classical model configuration issues. </span><span class="koboSpan" id="kobo.21.4">This confusion often leads to random sequences of the most probable outputs, not the most accurate ones.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.22.1">RAG begins where generative AI ends by providing the information an LLM model lacks to answer accurately. </span><span class="koboSpan" id="kobo.22.2">RAG was designed (Lewis et al., 2020) for LLMs. </span><span class="koboSpan" id="kobo.22.3">The RAG framework will perform optimized information retrieval tasks, and the generation ecosystem will add this information </span><a id="_idIndexMarker002"/><span class="koboSpan" id="kobo.23.1">to the input (user query or automated prompt) to produce improved output. </span><span class="koboSpan" id="kobo.23.2">The RAG framework can be summed up at a high level in the following figure:</span></p>
    <figure class="mediaobject"><span class="koboSpan" id="kobo.24.1"><img src="../Images/B31169_01_01.png" alt="A diagram of a library  Description automatically generated"/></span></figure>
    <p class="packt_figref"><span class="koboSpan" id="kobo.25.1">Figure 1.1: The two main components of RAG-driven generative AI</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.26.1">Think of yourself as a student in a library. </span><span class="koboSpan" id="kobo.26.2">You have an essay to write on RAG. </span><span class="koboSpan" id="kobo.26.3">Like ChatGPT, for example, or any other AI copilot, you have learned how to read and write. </span><span class="koboSpan" id="kobo.26.4">As with any </span><strong class="keyWord"><span class="koboSpan" id="kobo.27.1">Large Language Model</span></strong><span class="koboSpan" id="kobo.28.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.29.1">LLM</span></strong><span class="koboSpan" id="kobo.30.1">), you are</span><a id="_idIndexMarker003"/><span class="koboSpan" id="kobo.31.1"> sufficiently trained to read advanced information, summarize it, and write content. </span><span class="koboSpan" id="kobo.31.2">However, like any superhuman AI you will find from Hugging Face, Vertex AI, or OpenAI, there are many things you don’t know.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.32.1">In the </span><em class="italic"><span class="koboSpan" id="kobo.33.1">retrieval</span></em><span class="koboSpan" id="kobo.34.1"> phase, you search the library for books on the topic you need (the left side of </span><em class="italic"><span class="koboSpan" id="kobo.35.1">Figure 1.1</span></em><span class="koboSpan" id="kobo.36.1">). </span><span class="koboSpan" id="kobo.36.2">Then, you go back to your seat, perform a retrieval task by yourself or a co-student, and extract the information you need from those books. </span><span class="koboSpan" id="kobo.36.3">In the </span><em class="italic"><span class="koboSpan" id="kobo.37.1">generation</span></em><span class="koboSpan" id="kobo.38.1"> phase (the right side of </span><em class="italic"><span class="koboSpan" id="kobo.39.1">Figure 1.1</span></em><span class="koboSpan" id="kobo.40.1">), you begin to write your essay. </span><span class="koboSpan" id="kobo.40.2">You are a RAG-driven generative human agent, much like a RAG-driven generative AI framework.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.41.1">As you continue to write your essay on RAG, you stumble across some tough topics. </span><span class="koboSpan" id="kobo.41.2">You don’t have the time to go through all the information available physically! </span><span class="koboSpan" id="kobo.41.3">You, as a generative human agent, are stuck, just as a generative AI model would be. </span><span class="koboSpan" id="kobo.41.4">You may try to write something, just as a generative AI model does when its output makes little sense. </span><span class="koboSpan" id="kobo.41.5">But you, like the generative AI agent, will not realize whether the content is accurate or not until somebody corrects your essay and you get a grade that will rank your essay.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.42.1">At this point, you have reached </span><a id="_idIndexMarker004"/><span class="koboSpan" id="kobo.43.1">your limit and decide to turn to a RAG generative AI copilot to ensure you get the correct answers. </span><span class="koboSpan" id="kobo.43.2">However, you are puzzled by the number of LLM models and RAG configurations available. </span><span class="koboSpan" id="kobo.43.3">You need first to understand the resources available and how RAG is organized. </span><span class="koboSpan" id="kobo.43.4">Let’s go through the main RAG configurations.</span></p>
    <h1 id="_idParaDest-17" class="heading-1"><span class="koboSpan" id="kobo.44.1">Naïve, advanced, and modular RAG configurations</span></h1>
    <p class="normal"><span class="koboSpan" id="kobo.45.1">A RAG framework necessarily contains two</span><a id="_idIndexMarker005"/><span class="koboSpan" id="kobo.46.1"> main components: a retriever and a </span><a id="_idIndexMarker006"/><span class="koboSpan" id="kobo.47.1">generator. </span><span class="koboSpan" id="kobo.47.2">The generator can be any LLM or foundation multimodal AI platform or model, such as GPT-4o, Gemini, Llama, or one of the hundreds of variations of the initial architectures. </span><span class="koboSpan" id="kobo.47.3">The retriever can be any of the emerging frameworks, methods, and tools such as Activeloop, Pinecone, LlamaIndex, LangChain, Chroma, and many more.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.48.1">The issue now is to decide which of the three types of RAG frameworks (Gao et al., 2024) will fit the needs of a project. </span><span class="koboSpan" id="kobo.48.2">We will illustrate these three approaches in code in the </span><em class="italic"><span class="koboSpan" id="kobo.49.1">Naïve, advanced, and modular RAG in code</span></em><span class="koboSpan" id="kobo.50.1"> section of this chapter:</span></p>
    <ul>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.51.1">Naïve RAG</span></strong><span class="koboSpan" id="kobo.52.1">: This type of RAG framework doesn’t involve complex data embedding and indexing. </span><span class="koboSpan" id="kobo.52.2">It can</span><a id="_idIndexMarker007"/><span class="koboSpan" id="kobo.53.1"> be efficient to access</span><a id="_idIndexMarker008"/><span class="koboSpan" id="kobo.54.1"> reasonable amounts of data through keywords, for example, to augment a user’s input and obtain a satisfactory response.</span></li>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.55.1">Advanced RAG</span></strong><span class="koboSpan" id="kobo.56.1">: This type of </span><a id="_idIndexMarker009"/><span class="koboSpan" id="kobo.57.1">RAG involves more complex scenarios, such as with vector search and indexed-base retrieval applied. </span><span class="koboSpan" id="kobo.57.2">Advanced</span><a id="_idIndexMarker010"/><span class="koboSpan" id="kobo.58.1"> RAG can be implemented with a wide range of methods. </span><span class="koboSpan" id="kobo.58.2">It can process multiple data types, as well as multimodal data, which can be structured or unstructured.</span></li>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.59.1">Modular RAG</span></strong><span class="koboSpan" id="kobo.60.1">: Modular RAG broadens the horizon to include any scenario that involves naïve RAG, advanced </span><a id="_idIndexMarker011"/><span class="koboSpan" id="kobo.61.1">RAG, machine learning, and </span><a id="_idIndexMarker012"/><span class="koboSpan" id="kobo.62.1">any algorithm needed to complete a complex project.</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.63.1">However, before going further, we need to decide if we should implement RAG or fine-tune a model.</span></p>
    <h1 id="_idParaDest-18" class="heading-1"><span class="koboSpan" id="kobo.64.1">RAG versus fine-tuning</span></h1>
    <p class="normal"><span class="koboSpan" id="kobo.65.1">RAG is not always an alternative to fine-tuning, and fine-tuning cannot always replace RAG. </span><span class="koboSpan" id="kobo.65.2">If we accumulate too much data in </span><a id="_idIndexMarker013"/><span class="koboSpan" id="kobo.66.1">RAG datasets, the system may become too cumbersome to manage. </span><span class="koboSpan" id="kobo.66.2">On the other hand, we cannot fine-tune a model with dynamic, ever-changing data such as daily weather forecasts, stock market values, corporate news, and all forms of daily events.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.67.1">The decision of whether to implement RAG or fine-tune a model relies on the proportion of parametric versus non-parametric information. </span><span class="koboSpan" id="kobo.67.2">The fundamental difference between a model</span><a id="_idIndexMarker014"/><span class="koboSpan" id="kobo.68.1"> trained from scratch or fine-tuned and RAG can be summed up in terms of parametric and non-parametric knowledge:</span></p>
    <ul>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.69.1">Parametric</span></strong><span class="koboSpan" id="kobo.70.1">: In a RAG-driven generative AI ecosystem, the parametric part refers to the generative AI model’s parameters (weights) learned through training data. </span><span class="koboSpan" id="kobo.70.2">This means the</span><a id="_idIndexMarker015"/><span class="koboSpan" id="kobo.71.1"> model’s knowledge is stored in these learned weights and biases. </span><span class="koboSpan" id="kobo.71.2">The original training data is transformed into a mathematical form, which we call a parametric representation. </span><span class="koboSpan" id="kobo.71.3">Essentially, the model “remembers” what it learned from the data, but the data itself is not stored explicitly.</span></li>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.72.1">Non-Parametric</span></strong><span class="koboSpan" id="kobo.73.1">: In contrast, the non-parametric part of a RAG ecosystem involves storing explicit data that</span><a id="_idIndexMarker016"/><span class="koboSpan" id="kobo.74.1"> can be accessed directly. </span><span class="koboSpan" id="kobo.74.2">This means that the data remains available and can be queried whenever needed. </span><span class="koboSpan" id="kobo.74.3">Unlike parametric models, where knowledge is embedded indirectly in the weights, non-parametric data in RAG allows us to see and use the actual data for each output.</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.75.1">The difference between RAG and fine-tuning relies on the amount of static (parametric) and dynamic (non-parametric) ever-evolving data the generative AI model must process. </span><span class="koboSpan" id="kobo.75.2">A system that relies too heavily on RAG might become overloaded and cumbersome to manage. </span><span class="koboSpan" id="kobo.75.3">A system that relies too much on fine-tuning a generative model will display its inability to adapt to daily information updates.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.76.1">There is a decision-making threshold illustrated in </span><em class="italic"><span class="koboSpan" id="kobo.77.1">Figure 1.2</span></em><span class="koboSpan" id="kobo.78.1"> that shows that a RAG-driven generative AI project manager will have to evaluate the potential of the ecosystem’s trained parametric </span><a id="_idIndexMarker017"/><span class="koboSpan" id="kobo.79.1">generative AI model before implementing a non-parametric (explicit data) RAG framework. </span><span class="koboSpan" id="kobo.79.2">The potential of the RAG component requires careful evaluation as well.</span></p>
    <figure class="mediaobject"><span class="koboSpan" id="kobo.80.1"><img src="../Images/B31169_01_02.png" alt="A diagram of a temperature measurement  Description automatically generated"/></span></figure>
    <p class="packt_figref"><span class="koboSpan" id="kobo.81.1">Figure 1.2: The decision-making threshold between enhancing RAG or fine-tuning an LLM</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.82.1">In the end, the balance between enhancing the retriever and the generator in a RAG-driven generative AI ecosystem depends on a project’s specific requirements and goals. </span><span class="koboSpan" id="kobo.82.2">RAG and fine-tuning are not mutually exclusive.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.83.1">RAG can be used to improve a model’s overall efficiency, together with fine-tuning, which serves as a method to enhance the performance of both the retrieval and generation components within the RAG framework. </span><span class="koboSpan" id="kobo.83.2">We will fine-tune a proportion of the retrieval data in </span><em class="chapterRef"><span class="koboSpan" id="kobo.84.1">Chapter 9</span></em><span class="koboSpan" id="kobo.85.1">, </span><em class="italic"><span class="koboSpan" id="kobo.86.1">Empowering AI Models: Fine-Tuning RAG Data and Human Feedback</span></em><span class="koboSpan" id="kobo.87.1">.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.88.1">We will now see how a RAG-driven generative AI involves an ecosystem with many components.</span></p>
    <h1 id="_idParaDest-19" class="heading-1"><span class="koboSpan" id="kobo.89.1">The RAG ecosystem</span></h1>
    <p class="normal"><span class="koboSpan" id="kobo.90.1">RAG-driven generative AI is a framework that can be implemented in many configurations. </span><span class="koboSpan" id="kobo.90.2">RAG’s framework runs within a broad ecosystem, as shown in </span><em class="italic"><span class="koboSpan" id="kobo.91.1">Figure 1.3</span></em><span class="koboSpan" id="kobo.92.1">. </span><span class="koboSpan" id="kobo.92.2">However, no matter how many retrieval and generation frameworks you encounter, it all boils down to the following</span><a id="_idIndexMarker018"/><span class="koboSpan" id="kobo.93.1"> four domains and questions that go with them:</span></p>
    <ul>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.94.1">Data</span></strong><span class="koboSpan" id="kobo.95.1">: Where is the data coming from? </span><span class="koboSpan" id="kobo.95.2">Is it reliable? </span><span class="koboSpan" id="kobo.95.3">Is it sufficient? </span><span class="koboSpan" id="kobo.95.4">Are there copyright, privacy, and security issues?</span></li>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.96.1">Storage</span></strong><span class="koboSpan" id="kobo.97.1">: How is the data going to be stored before or after processing it? </span><span class="koboSpan" id="kobo.97.2">What amount of data will be stored?</span></li>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.98.1">Retrieval</span></strong><span class="koboSpan" id="kobo.99.1">: How will the correct data be retrieved to augment the user’s input before it is sufficient for the generative model? </span><span class="koboSpan" id="kobo.99.2">What type of RAG framework will be successful for a project?</span></li>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.100.1">Generation</span></strong><span class="koboSpan" id="kobo.101.1">: Which generative AI model will fit into the type of RAG framework chosen?</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.102.1">The data, storage, and generation domains depend heavily on the type of RAG framework you choose. </span><span class="koboSpan" id="kobo.102.2">Before making that choice, we need to evaluate the proportion of parametric and non-parametric knowledge in the ecosystem we are implementing. </span><em class="italic"><span class="koboSpan" id="kobo.103.1">Figure 1.3</span></em><span class="koboSpan" id="kobo.104.1"> represents the RAG framework, which includes the main components regardless of the types of RAG implemented:</span></p>
    <figure class="mediaobject"><span class="koboSpan" id="kobo.105.1"><img src="../Images/B31169_01_03.png" alt="A diagram of a process  Description automatically generated"/></span></figure>
    <p class="packt_figref"><span class="koboSpan" id="kobo.106.1">Figure 1.3: The Generative RAG-ecosystem</span></p>
    <ul>
      <li class="bulletList"><span class="koboSpan" id="kobo.107.1">The </span><strong class="keyWord"><span class="koboSpan" id="kobo.108.1">Retriever (D)</span></strong><span class="koboSpan" id="kobo.109.1"> handles </span><a id="_idIndexMarker019"/><span class="koboSpan" id="kobo.110.1">data collection, processing, storage, and retrieval</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.111.1">The </span><strong class="keyWord"><span class="koboSpan" id="kobo.112.1">Generator (G)</span></strong><span class="koboSpan" id="kobo.113.1"> handles input augmentation, prompt engineering, and generation</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.114.1">The </span><strong class="keyWord"><span class="koboSpan" id="kobo.115.1">Evaluator (E) </span></strong><span class="koboSpan" id="kobo.116.1">handles mathematical metrics, human evaluation, and feedback</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.117.1">The </span><strong class="keyWord"><span class="koboSpan" id="kobo.118.1">Trainer (T)</span></strong><span class="koboSpan" id="kobo.119.1"> handles the initial pre-trained model and fine-tuning the model</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.120.1">Each of these four components </span><a id="_idIndexMarker020"/><span class="koboSpan" id="kobo.121.1">relies on their respective ecosystems, which form the overall RAG-driven generative AI pipeline. </span><span class="koboSpan" id="kobo.121.2">We will refer to the domains D, G, E, and T in the following sections. </span><span class="koboSpan" id="kobo.121.3">Let’s begin with the retriever.</span></p>
    <h2 id="_idParaDest-20" class="heading-2"><span class="koboSpan" id="kobo.122.1">The retriever (D)</span></h2>
    <p class="normal"><span class="koboSpan" id="kobo.123.1">The retriever component of a RAG ecosystem </span><a id="_idIndexMarker021"/><span class="koboSpan" id="kobo.124.1">collects, processes, stores, and retrieves data. </span><span class="koboSpan" id="kobo.124.2">The starting point of a RAG ecosystem is thus an ingestion data process, of which the first step is to collect data.</span></p>
    <h3 id="_idParaDest-21" class="heading-3"><span class="koboSpan" id="kobo.125.1">Collect (D1)</span></h3>
    <p class="normal"><span class="koboSpan" id="kobo.126.1">In today’s world, AI data is as diverse as our media playlists. </span><span class="koboSpan" id="kobo.126.2">It can be anything from a chunk of text in a blog post to a </span><a id="_idIndexMarker022"/><span class="koboSpan" id="kobo.127.1">meme or even the latest hit song streamed through headphones. </span><span class="koboSpan" id="kobo.127.2">And it doesn’t stop there—the files themselves come in all shapes and sizes. </span><span class="koboSpan" id="kobo.127.3">Think of PDFs filled with all kinds of details, web pages, plain text files that get straight to the point, neatly organized JSON files, catchy MP3 tunes, videos in MP4 format, or images in PNG and JPG.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.128.1">Furthermore, a large proportion of this data is unstructured and found in unpredictable and complex ways. </span><span class="koboSpan" id="kobo.128.2">Fortunately, many platforms, such as Pinecone, OpenAI, Chroma, and Activeloop, provide ready-to-use tools to process and store this jungle of data.</span></p>
    <h3 id="_idParaDest-22" class="heading-3"><span class="koboSpan" id="kobo.129.1">Process (D2)</span></h3>
    <p class="normal"><span class="koboSpan" id="kobo.130.1">In the data collection phase (D1) of </span><a id="_idIndexMarker023"/><span class="koboSpan" id="kobo.131.1">multimodal data processing, various types of data, such as text, images, and videos, can be extracted from websites using web scraping techniques or any other source of information. </span><span class="koboSpan" id="kobo.131.2">These data objects are then transformed to create uniform feature representations. </span><span class="koboSpan" id="kobo.131.3">For example, data can be chunked (broken into smaller parts), embedded (transformed into vectors), and indexed to enhance searchability and retrieval efficiency.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.132.1">We will introduce these techniques, starting with the </span><em class="italic"><span class="koboSpan" id="kobo.133.1">Building Hybrid Adaptive RAG in Python</span></em><span class="koboSpan" id="kobo.134.1"> section of this chapter. </span><span class="koboSpan" id="kobo.134.2">In the</span><a id="_idIndexMarker024"/><span class="koboSpan" id="kobo.135.1"> following chapters, we will continue building more complex data processing functions.</span></p>
    <h3 id="_idParaDest-23" class="heading-3"><span class="koboSpan" id="kobo.136.1">Storage (D3)</span></h3>
    <p class="normal"><span class="koboSpan" id="kobo.137.1">At this stage of the pipeline, we have collected</span><a id="_idIndexMarker025"/><span class="koboSpan" id="kobo.138.1"> and begun processing a large amount of diverse data from the internet—videos, pictures, texts, you name it. </span><span class="koboSpan" id="kobo.138.2">Now, what can we do with all that data to make it useful?</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.139.1">That’s where vector stores like Deep Lake, Pinecone, and Chroma come into play. </span><span class="koboSpan" id="kobo.139.2">Think of these as super smart libraries that don’t just store your data but convert it into mathematical entities as vectors, enabling powerful computations. </span><span class="koboSpan" id="kobo.139.3">They can also apply a variety of indexing methods and other techniques for rapid access.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.140.1">Instead of keeping the data in static spreadsheets and files, we turn it into a dynamic, searchable system that can power anything from chatbots to search engines.</span></p>
    <h3 id="_idParaDest-24" class="heading-3"><span class="koboSpan" id="kobo.141.1">Retrieval query (D4)</span></h3>
    <p class="normal"><span class="koboSpan" id="kobo.142.1">The retrieval process is triggered by the user input or automated input (G1).</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.143.1">To retrieve data quickly, we load it into</span><a id="_idIndexMarker026"/><span class="koboSpan" id="kobo.144.1"> vector stores and datasets after transforming it into a suitable format. </span><span class="koboSpan" id="kobo.144.2">Then, using a combination of keyword searches, smart embeddings, and indexing, we can retrieve the data efficiently. </span><span class="koboSpan" id="kobo.144.3">Cosine similarity, for example, finds items that are closely related, ensuring that the search results are not just fast but also highly relevant.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.145.1">Once the data is retrieved, we then augment the input.</span></p>
    <h2 id="_idParaDest-25" class="heading-2"><span class="koboSpan" id="kobo.146.1">The generator (G)</span></h2>
    <p class="normal"><span class="koboSpan" id="kobo.147.1">The lines are blurred in the RAG ecosystem between input and retrieval, as shown in </span><em class="italic"><span class="koboSpan" id="kobo.148.1">Figure 1.3</span></em><span class="koboSpan" id="kobo.149.1">, representing the</span><a id="_idIndexMarker027"/><span class="koboSpan" id="kobo.150.1"> RAG framework and ecosystem. </span><span class="koboSpan" id="kobo.150.2">The user</span><a id="_idIndexMarker028"/><span class="koboSpan" id="kobo.151.1"> input (G1), automated or human, interacts with the retrieval query (D4) to augment the input before sending it to the generative model.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.152.1">The generative flow begins with an input.</span></p>
    <h3 id="_idParaDest-26" class="heading-3"><span class="koboSpan" id="kobo.153.1">Input (G1)</span></h3>
    <p class="normal"><span class="koboSpan" id="kobo.154.1">The input can be a batch of automated</span><a id="_idIndexMarker029"/><span class="koboSpan" id="kobo.155.1"> tasks (processing emails, for example) or human prompts through a </span><strong class="keyWord"><span class="koboSpan" id="kobo.156.1">User Interface</span></strong><span class="koboSpan" id="kobo.157.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.158.1">UI</span></strong><span class="koboSpan" id="kobo.159.1">). </span><span class="koboSpan" id="kobo.159.2">This flexibility allows you to seamlessly integrate AI into various professional environments, enhancing productivity across industries.</span></p>
    <h3 id="_idParaDest-27" class="heading-3"><span class="koboSpan" id="kobo.160.1">Augmented input with HF (G2)</span></h3>
    <p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.161.1">Human feedback</span></strong><span class="koboSpan" id="kobo.162.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.163.1">HF</span></strong><span class="koboSpan" id="kobo.164.1">) can be added to the input,</span><a id="_idIndexMarker030"/><span class="koboSpan" id="kobo.165.1"> as described in the </span><em class="italic"><span class="koboSpan" id="kobo.166.1">Human feedback (E2) under Evaluator (E) </span></em><span class="koboSpan" id="kobo.167.1">section. </span><span class="koboSpan" id="kobo.167.2">Human feedback will make a RAG ecosystem considerably adaptable and provide full control over data retrieval and generative AI inputs. </span><span class="koboSpan" id="kobo.167.3">In the </span><em class="italic"><span class="koboSpan" id="kobo.168.1">Building hybrid adaptive RAG in Python</span></em><span class="koboSpan" id="kobo.169.1"> section of this chapter, we will build augmented input with human feedback.</span></p>
    <h3 id="_idParaDest-28" class="heading-3"><span class="koboSpan" id="kobo.170.1">Prompt engineering (G3)</span></h3>
    <p class="normal"><span class="koboSpan" id="kobo.171.1">Both the retriever (D) and the</span><a id="_idIndexMarker031"/><span class="koboSpan" id="kobo.172.1"> generator (G) rely heavily on prompt engineering to prepare the standard and augmented message that the generative AI model will have to process. </span><span class="koboSpan" id="kobo.172.2">Prompt engineering brings the retriever’s output and the user input together.</span></p>
    <h3 id="_idParaDest-29" class="heading-3"><span class="koboSpan" id="kobo.173.1">Generation and output (G4)</span></h3>
    <p class="normal"><span class="koboSpan" id="kobo.174.1">The choice of a generative AI model depends on the goals of a project. </span><span class="koboSpan" id="kobo.174.2">Llama, Gemini, GPT, and other models can fit various</span><a id="_idIndexMarker032"/><span class="koboSpan" id="kobo.175.1"> requirements. </span><span class="koboSpan" id="kobo.175.2">However, the prompt must meet each model’s specifications. </span><span class="koboSpan" id="kobo.175.3">Frameworks such as LangChain, which we will implement in this book, help streamline the integration of various AI models into applications by providing adaptable interfaces and tools.</span></p>
    <h2 id="_idParaDest-30" class="heading-2"><span class="koboSpan" id="kobo.176.1">The evaluator (E)</span></h2>
    <p class="normal"><span class="koboSpan" id="kobo.177.1">We often rely on mathematical metrics to</span><a id="_idIndexMarker033"/><span class="koboSpan" id="kobo.178.1"> assess the performance of a generative AI model. </span><span class="koboSpan" id="kobo.178.2">However, these </span><a id="_idIndexMarker034"/><span class="koboSpan" id="kobo.179.1">metrics only give us part of the picture. </span><span class="koboSpan" id="kobo.179.2">It’s important to remember that the ultimate test of an AI’s effectiveness comes down to human evaluation.</span></p>
    <h3 id="_idParaDest-31" class="heading-3"><span class="koboSpan" id="kobo.180.1">Metrics (E1)</span></h3>
    <p class="normal"><span class="koboSpan" id="kobo.181.1">A model cannot be evaluated </span><a id="_idIndexMarker035"/><span class="koboSpan" id="kobo.182.1">without mathematical metrics, such as cosine similarity, as with any AI system. </span><span class="koboSpan" id="kobo.182.2">These metrics ensure that the retrieved data is relevant and accurate. </span><span class="koboSpan" id="kobo.182.3">By quantifying the relationships and relevance of data points, they provide a solid foundation for assessing the model’s performance and reliability.</span></p>
    <h3 id="_idParaDest-32" class="heading-3"><span class="koboSpan" id="kobo.183.1">Human feedback (E2)</span></h3>
    <p class="normal"><span class="koboSpan" id="kobo.184.1">No generative AI system, whether RAG-driven </span><a id="_idIndexMarker036"/><span class="koboSpan" id="kobo.185.1">or not, and whether the mathematical metrics seem sufficient or not, can elude human evaluation. </span><span class="koboSpan" id="kobo.185.2">It is ultimately human evaluation that decides if a system designed for human users will be accepted or rejected, praised or criticized.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.186.1">Adaptive RAG introduces the human, real-life, pragmatic feedback factor that will improve a RAG-driven generative AI ecosystem. </span><span class="koboSpan" id="kobo.186.2">We will implement adaptive RAG in </span><em class="chapterRef"><span class="koboSpan" id="kobo.187.1">Chapter 5</span></em><span class="koboSpan" id="kobo.188.1">, </span><em class="italic"><span class="koboSpan" id="kobo.189.1">Boosting RAG Performance with Expert Human Feedback</span></em><span class="koboSpan" id="kobo.190.1">.</span></p>
    <h2 id="_idParaDest-33" class="heading-2"><span class="koboSpan" id="kobo.191.1">The trainer (T)</span></h2>
    <p class="normal"><span class="koboSpan" id="kobo.192.1">A standard generative AI </span><a id="_idIndexMarker037"/><span class="koboSpan" id="kobo.193.1">model is pre-trained with a vast amount of general-purpose data. </span><span class="koboSpan" id="kobo.193.2">Then, we</span><a id="_idIndexMarker038"/><span class="koboSpan" id="kobo.194.1"> can fine-tune (T2) the model with domain-specific data.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.195.1">We will take this further by integrating static RAG data into the fine-tuning process in </span><em class="chapterRef"><span class="koboSpan" id="kobo.196.1">Chapter 9</span></em><span class="koboSpan" id="kobo.197.1">, </span><em class="italic"><span class="koboSpan" id="kobo.198.1">Empowering AI Models: Fine-Tuning RAG Data and Human Feedback</span></em><span class="koboSpan" id="kobo.199.1">. </span><span class="koboSpan" id="kobo.199.2">We will also integrate human feedback, which provides valuable information that can be integrated into the fine-tuning process in a variant of </span><strong class="keyWord"><span class="koboSpan" id="kobo.200.1">Reinforcement Learning from Human Feedback</span></strong><span class="koboSpan" id="kobo.201.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.202.1">RLHF</span></strong><span class="koboSpan" id="kobo.203.1">).</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.204.1">We are now ready to code entry-level naïve, advanced, and modular RAG in Python.</span></p>
    <h1 id="_idParaDest-34" class="heading-1"><span class="koboSpan" id="kobo.205.1">Naïve, advanced, and modular RAG in code</span></h1>
    <p class="normal"><span class="koboSpan" id="kobo.206.1">This section introduces naïve, advanced, and modular RAG through basic educational examples. </span><span class="koboSpan" id="kobo.206.2">The program builds</span><a id="_idIndexMarker039"/><span class="koboSpan" id="kobo.207.1"> keyword matching, vector search, and index-based retrieval </span><a id="_idIndexMarker040"/><span class="koboSpan" id="kobo.208.1">methods. </span><span class="koboSpan" id="kobo.208.2">Using </span><a id="_idIndexMarker041"/><span class="koboSpan" id="kobo.209.1">OpenAI’s GPT models, it generates responses based on input queries and retrieved documents.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.210.1">The goal of the notebook is for a conversational agent to answer questions on RAG in general. </span><span class="koboSpan" id="kobo.210.2">We will build the retriever from the bottom up, from scratch, in Python and run the generator with OpenAI GPT-4o in eight sections of code divided into two parts:</span></p>
    <p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.211.1">Part 1: Foundations and Basic Implementation</span></strong></p>
    <ol>
      <li class="numberedList" value="1"><strong class="keyWord"><span class="koboSpan" id="kobo.212.1">Environment</span></strong><span class="koboSpan" id="kobo.213.1"> setup for OpenAI API integration</span></li>
      <li class="numberedList"><strong class="keyWord"><span class="koboSpan" id="kobo.214.1">Generator</span></strong><span class="koboSpan" id="kobo.215.1"> function using GPT-4o</span></li>
      <li class="numberedList"><strong class="keyWord"><span class="koboSpan" id="kobo.216.1">Data</span></strong><span class="koboSpan" id="kobo.217.1"> setup with a list of documents (</span><code class="inlineCode"><span class="koboSpan" id="kobo.218.1">db_records</span></code><span class="koboSpan" id="kobo.219.1">)</span></li>
      <li class="numberedList"><strong class="keyWord"><span class="koboSpan" id="kobo.220.1">Query </span></strong><span class="koboSpan" id="kobo.221.1">for user input</span></li>
    </ol>
    <p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.222.1">Part 2: Advanced Techniques and Evaluation</span></strong></p>
    <ol>
      <li class="numberedList" value="1"><strong class="keyWord"><span class="koboSpan" id="kobo.223.1">Retrieval metrics</span></strong><span class="koboSpan" id="kobo.224.1"> to measure retrieval responses</span></li>
      <li class="numberedList"><strong class="keyWord"><span class="koboSpan" id="kobo.225.1">Naïve RAG</span></strong><span class="koboSpan" id="kobo.226.1"> with a keyword search and matching function</span></li>
      <li class="numberedList"><strong class="keyWord"><span class="koboSpan" id="kobo.227.1">Advanced RAG</span></strong><span class="koboSpan" id="kobo.228.1"> with vector search and index-based search</span></li>
      <li class="numberedList"><strong class="keyWord"><span class="koboSpan" id="kobo.229.1">Modular RAG</span></strong><span class="koboSpan" id="kobo.230.1"> implementing flexible retrieval methods</span></li>
    </ol>
    <p class="normal"><span class="koboSpan" id="kobo.231.1">To get started, open </span><code class="inlineCode"><span class="koboSpan" id="kobo.232.1">RAG_Overview.ipynb</span></code><span class="koboSpan" id="kobo.233.1"> in the GitHub repository. </span><span class="koboSpan" id="kobo.233.2">We will begin by establishing the foundations of the notebook and exploring the basic implementation.</span></p>
    <h2 id="_idParaDest-35" class="heading-2"><span class="koboSpan" id="kobo.234.1">Part 1: Foundations and basic implementation</span></h2>
    <p class="normal"><span class="koboSpan" id="kobo.235.1">In this section, we will set up the environment, create a function for the generator, define a function to print a formatted response, and define the user query.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.236.1">The first step is to install the environment.</span></p>
    <div class="note">
      <p class="normal"><span class="koboSpan" id="kobo.237.1">The section titles of the following implementation of the notebook follow the structure in the code. </span><span class="koboSpan" id="kobo.237.2">Thus, you can follow the code in the notebook or read this self-contained section.</span></p>
    </div>
    <h3 id="_idParaDest-36" class="heading-3"><span class="koboSpan" id="kobo.238.1">1. </span><span class="koboSpan" id="kobo.238.2">Environment</span></h3>
    <p class="normal"><span class="koboSpan" id="kobo.239.1">The main package to install is</span><a id="_idIndexMarker042"/><span class="koboSpan" id="kobo.240.1"> OpenAI to access GPT-4o through an API:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.241.1">!pip install openai==</span><span class="hljs-number"><span class="koboSpan" id="kobo.242.1">1.40.3</span></span>
</code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.243.1">Make sure to freeze the OpenAI version you install. </span><span class="koboSpan" id="kobo.243.2">In RAG framework ecosystems, we will have to install several packages to run advanced RAG configurations. </span><span class="koboSpan" id="kobo.243.3">Once we have stabilized an installation, we will freeze the version of the packages installed to minimize potential conflicts between the libraries and modules we implement.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.244.1">Once you have installed </span><code class="inlineCode"><span class="koboSpan" id="kobo.245.1">openai</span></code><span class="koboSpan" id="kobo.246.1">, you will have to create an account on OpenAI (if you don’t have one) and obtain an API key. </span><span class="koboSpan" id="kobo.246.2">Make sure to check the costs and payment plans before running the API.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.247.1">Once you have a key, store it in </span><a id="_idIndexMarker043"/><span class="koboSpan" id="kobo.248.1">a safe place and retrieve it as follows from Google Drive, for example, as shown in the following code:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.249.1">#API Key</span></span>
<span class="hljs-comment"><span class="koboSpan" id="kobo.250.1">#Store you key in a file and read it(you can type it directly in the notebook but it will be visible for somebody next to you)</span></span>
<span class="hljs-keyword"><span class="koboSpan" id="kobo.251.1">from</span></span><span class="koboSpan" id="kobo.252.1"> google.colab </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.253.1">import</span></span><span class="koboSpan" id="kobo.254.1"> drive
drive.mount(</span><span class="hljs-string"><span class="koboSpan" id="kobo.255.1">'/content/drive'</span></span><span class="koboSpan" id="kobo.256.1">)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.257.1">You can use Google Drive or any other method you choose to store your key. </span><span class="koboSpan" id="kobo.257.2">You can read the key from a file, or you can also choose to enter the key directly in the code:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.258.1">f = </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.259.1">open</span></span><span class="koboSpan" id="kobo.260.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.261.1">"drive/MyDrive/files/api_key.txt"</span></span><span class="koboSpan" id="kobo.262.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.263.1">"r"</span></span><span class="koboSpan" id="kobo.264.1">)
API_KEY=f.readline().strip()
f.close()
 
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.265.1">#The OpenAI Key</span></span>
<span class="hljs-keyword"><span class="koboSpan" id="kobo.266.1">import</span></span><span class="koboSpan" id="kobo.267.1"> os
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.268.1">import</span></span><span class="koboSpan" id="kobo.269.1"> openai
os.environ[</span><span class="hljs-string"><span class="koboSpan" id="kobo.270.1">'OPENAI_API_KEY'</span></span><span class="koboSpan" id="kobo.271.1">] =API_KEY
openai.api_key = os.getenv(</span><span class="hljs-string"><span class="koboSpan" id="kobo.272.1">"OPENAI_API_KEY"</span></span><span class="koboSpan" id="kobo.273.1">)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.274.1">With that, we have set up the main resources for our project. </span><span class="koboSpan" id="kobo.274.2">We will now write a generation function for the OpenAI model.</span></p>
    <h3 id="_idParaDest-37" class="heading-3"><span class="koboSpan" id="kobo.275.1">2. </span><span class="koboSpan" id="kobo.275.2">The generator</span></h3>
    <p class="normal"><span class="koboSpan" id="kobo.276.1">The code imports </span><code class="inlineCode"><span class="koboSpan" id="kobo.277.1">openai</span></code><span class="koboSpan" id="kobo.278.1"> to generate </span><a id="_idIndexMarker044"/><span class="koboSpan" id="kobo.279.1">content and </span><code class="inlineCode"><span class="koboSpan" id="kobo.280.1">time</span></code><span class="koboSpan" id="kobo.281.1"> to measure the time the requests take:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.282.1">import</span></span><span class="koboSpan" id="kobo.283.1"> openai
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.284.1">from</span></span><span class="koboSpan" id="kobo.285.1"> openai </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.286.1">import</span></span><span class="koboSpan" id="kobo.287.1"> OpenAI
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.288.1">import</span></span><span class="koboSpan" id="kobo.289.1"> time
client = OpenAI()
gptmodel=</span><span class="hljs-string"><span class="koboSpan" id="kobo.290.1">"gpt-4o"</span></span><span class="koboSpan" id="kobo.291.1">
start_time = time.time()  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.292.1"># Start timing before the request</span></span>
</code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.293.1">We now create a function that creates a prompt with an instruction and the user input:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.294.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.295.1">call_llm_with_full_text</span></span><span class="koboSpan" id="kobo.296.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.297.1">itext</span></span><span class="koboSpan" id="kobo.298.1">):
    </span><span class="hljs-comment"><span class="koboSpan" id="kobo.299.1"># Join all lines to form a single string</span></span><span class="koboSpan" id="kobo.300.1">
    text_input = </span><span class="hljs-string"><span class="koboSpan" id="kobo.301.1">'\n'</span></span><span class="koboSpan" id="kobo.302.1">.join(itext)
    prompt = </span><span class="hljs-string"><span class="koboSpan" id="kobo.303.1">f"Please elaborate on the following content:\n</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.304.1">{text_input}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.305.1">"</span></span>
</code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.306.1">The function will try to</span><a id="_idIndexMarker045"/><span class="koboSpan" id="kobo.307.1"> call </span><code class="inlineCode"><span class="koboSpan" id="kobo.308.1">gpt-4o</span></code><span class="koboSpan" id="kobo.309.1">, adding additional information for the model:</span></p>
    <pre class="programlisting code"><code class="hljs-code">    <span class="hljs-keyword"><span class="koboSpan" id="kobo.310.1">try</span></span><span class="koboSpan" id="kobo.311.1">:
      response = client.chat.completions.create(
         model=gptmodel,
         messages=[
            {</span><span class="hljs-string"><span class="koboSpan" id="kobo.312.1">"role"</span></span><span class="koboSpan" id="kobo.313.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.314.1">"</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.315.1">system"</span></span><span class="koboSpan" id="kobo.316.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.317.1">"content"</span></span><span class="koboSpan" id="kobo.318.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.319.1">"You are an expert Natural Language Processing exercise expert."</span></span><span class="koboSpan" id="kobo.320.1">},
            {</span><span class="hljs-string"><span class="koboSpan" id="kobo.321.1">"role"</span></span><span class="koboSpan" id="kobo.322.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.323.1">"assistant"</span></span><span class="koboSpan" id="kobo.324.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.325.1">"content"</span></span><span class="koboSpan" id="kobo.326.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.327.1">"1.You can explain read the input and answer in detail"</span></span><span class="koboSpan" id="kobo.328.1">},
            {</span><span class="hljs-string"><span class="koboSpan" id="kobo.329.1">"role"</span></span><span class="koboSpan" id="kobo.330.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.331.1">"user"</span></span><span class="koboSpan" id="kobo.332.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.333.1">"content"</span></span><span class="koboSpan" id="kobo.334.1">: prompt}
         ],
         temperature=</span><span class="hljs-number"><span class="koboSpan" id="kobo.335.1">0.1</span></span>  <span class="hljs-comment"><span class="koboSpan" id="kobo.336.1"># Add the temperature parameter here and other parameters you need</span></span><span class="koboSpan" id="kobo.337.1">
        )
      </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.338.1">return</span></span><span class="koboSpan" id="kobo.339.1"> response.choices[</span><span class="hljs-number"><span class="koboSpan" id="kobo.340.1">0</span></span><span class="koboSpan" id="kobo.341.1">].message.content.strip()
    </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.342.1">except</span></span><span class="koboSpan" id="kobo.343.1"> Exception </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.344.1">as</span></span><span class="koboSpan" id="kobo.345.1"> e:
        </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.346.1">return</span></span> <span class="hljs-built_in"><span class="koboSpan" id="kobo.347.1">str</span></span><span class="koboSpan" id="kobo.348.1">(e)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.349.1">Note that the instruction messages remain general in this scenario so that the model remains flexible. </span><span class="koboSpan" id="kobo.349.2">The </span><code class="inlineCode"><span class="koboSpan" id="kobo.350.1">temperature</span></code><span class="koboSpan" id="kobo.351.1"> is low (more precise) and set to </span><code class="inlineCode"><span class="koboSpan" id="kobo.352.1">0.1</span></code><span class="koboSpan" id="kobo.353.1">. </span><span class="koboSpan" id="kobo.353.2">If you wish for the system to be more creative, you can set </span><code class="inlineCode"><span class="koboSpan" id="kobo.354.1">temperature</span></code><span class="koboSpan" id="kobo.355.1"> to a higher value, such as </span><code class="inlineCode"><span class="koboSpan" id="kobo.356.1">0.7</span></code><span class="koboSpan" id="kobo.357.1">. </span><span class="koboSpan" id="kobo.357.2">However, in this case, it is recommended to ask for precise responses.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.358.1">We can add </span><code class="inlineCode"><span class="koboSpan" id="kobo.359.1">textwrap</span></code><span class="koboSpan" id="kobo.360.1"> to format the response as a nice paragraph when we call the generative AI model:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.361.1">import</span></span><span class="koboSpan" id="kobo.362.1"> textwrap
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.363.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.364.1">print_formatted_response</span></span><span class="koboSpan" id="kobo.365.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.366.1">response</span></span><span class="koboSpan" id="kobo.367.1">):
    </span><span class="hljs-comment"><span class="koboSpan" id="kobo.368.1"># Define the width for wrapping the text</span></span><span class="koboSpan" id="kobo.369.1">
    wrapper = textwrap.TextWrapper(width=</span><span class="hljs-number"><span class="koboSpan" id="kobo.370.1">80</span></span><span class="koboSpan" id="kobo.371.1">)  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.372.1"># Set to 80 columns wide, but adjust as needed</span></span><span class="koboSpan" id="kobo.373.1">
    wrapped_text = wrapper.fill(text=response)
    </span><span class="hljs-comment"><span class="koboSpan" id="kobo.374.1"># Print the formatted response with a header and footer</span></span>
    <span class="hljs-built_in"><span class="koboSpan" id="kobo.375.1">print</span></span><span class="koboSpan" id="kobo.376.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.377.1">"Response:"</span></span><span class="koboSpan" id="kobo.378.1">)
    </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.379.1">print</span></span><span class="koboSpan" id="kobo.380.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.381.1">"---------------"</span></span><span class="koboSpan" id="kobo.382.1">)
    </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.383.1">print</span></span><span class="koboSpan" id="kobo.384.1">(wrapped_text)
    </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.385.1">print</span></span><span class="koboSpan" id="kobo.386.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.387.1">"---------------\n"</span></span><span class="koboSpan" id="kobo.388.1">)
</span></code></pre>
    <div class="note">
      <p class="normal"><span class="koboSpan" id="kobo.389.1">The generator is now ready to be called when we need it. </span><span class="koboSpan" id="kobo.389.2">Due to the probabilistic nature of generative AI models, it might produce different outputs each time we call it.</span></p>
    </div>
    <p class="normal"><span class="koboSpan" id="kobo.390.1">The program now</span><a id="_idIndexMarker046"/><span class="koboSpan" id="kobo.391.1"> implements the data retrieval functionality.</span></p>
    <h3 id="_idParaDest-38" class="heading-3"><span class="koboSpan" id="kobo.392.1">3. </span><span class="koboSpan" id="kobo.392.2">The Data</span></h3>
    <p class="normal"><span class="koboSpan" id="kobo.393.1">Data collection includes text, images, audio, and video. </span><span class="koboSpan" id="kobo.393.2">In this notebook, we will focus on </span><strong class="keyWord"><span class="koboSpan" id="kobo.394.1">data retrieval</span></strong><span class="koboSpan" id="kobo.395.1"> through naïve, advanced, and modular configurations, not data collection. </span><span class="koboSpan" id="kobo.395.2">We will collect and </span><a id="_idIndexMarker047"/><span class="koboSpan" id="kobo.396.1">embed data later in </span><em class="chapterRef"><span class="koboSpan" id="kobo.397.1">Chapter 2</span></em><span class="koboSpan" id="kobo.398.1">, </span><em class="italic"><span class="koboSpan" id="kobo.399.1">RAG Embedding Vector Stores with Deep Lake and OpenAI</span></em><span class="koboSpan" id="kobo.400.1">. </span><span class="koboSpan" id="kobo.400.2">As such, we will assume that the data we need has been processed and thus collected, cleaned, and split into sentences. </span><span class="koboSpan" id="kobo.400.3">We will also assume that the process included loading the sentences into a Python list named </span><code class="inlineCode"><span class="koboSpan" id="kobo.401.1">db_records</span></code><span class="koboSpan" id="kobo.402.1">.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.403.1">This approach illustrates three aspects of the RAG ecosystem we described in </span><em class="italic"><span class="koboSpan" id="kobo.404.1">The RAG ecosystem</span></em><span class="koboSpan" id="kobo.405.1"> section and the components of the system described in </span><em class="italic"><span class="koboSpan" id="kobo.406.1">Figure 1.3</span></em><span class="koboSpan" id="kobo.407.1">:</span></p>
    <ul>
      <li class="bulletList"><span class="koboSpan" id="kobo.408.1">The </span><strong class="keyWord"><span class="koboSpan" id="kobo.409.1">retriever (D)</span></strong><span class="koboSpan" id="kobo.410.1"> has three </span><strong class="keyWord"><span class="koboSpan" id="kobo.411.1">data processing</span></strong><span class="koboSpan" id="kobo.412.1"> components, </span><strong class="keyWord"><span class="koboSpan" id="kobo.413.1">collect (D1)</span></strong><span class="koboSpan" id="kobo.414.1">, </span><strong class="keyWord"><span class="koboSpan" id="kobo.415.1">process (D2)</span></strong><span class="koboSpan" id="kobo.416.1">, and </span><strong class="keyWord"><span class="koboSpan" id="kobo.417.1">storage (D3)</span></strong><span class="koboSpan" id="kobo.418.1">, which are preparatory phases of the retriever.</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.419.1">The</span><strong class="keyWord"><span class="koboSpan" id="kobo.420.1"> retriever query (D4)</span></strong><span class="koboSpan" id="kobo.421.1"> is thus independent of the first three phases (collect, process, and storage) of the retriever.</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.422.1">The data processing phase will often be done independently and prior to activating the retriever query, as we will implement starting in </span><em class="italic"><span class="koboSpan" id="kobo.423.1">Chapter 2</span></em><span class="koboSpan" id="kobo.424.1">.</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.425.1">This program assumes that data processing has been completed and the dataset is ready:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.426.1">db_records = [
    </span><span class="hljs-string"><span class="koboSpan" id="kobo.427.1">"Retrieval Augmented Generation (RAG) represents a sophisticated hybrid approach in the field of artificial intelligence, particularly within the realm of natural language processing (NLP)."</span></span><span class="koboSpan" id="kobo.428.1">,
…/…
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.429.1">We can display a</span><a id="_idIndexMarker048"/><span class="koboSpan" id="kobo.430.1"> formatted version of the dataset:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.431.1">import</span></span><span class="koboSpan" id="kobo.432.1"> textwrap
paragraph = </span><span class="hljs-string"><span class="koboSpan" id="kobo.433.1">' '</span></span><span class="koboSpan" id="kobo.434.1">.join(db_records)
wrapped_text = textwrap.fill(paragraph, width=</span><span class="hljs-number"><span class="koboSpan" id="kobo.435.1">80</span></span><span class="koboSpan" id="kobo.436.1">)
</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.437.1">print</span></span><span class="koboSpan" id="kobo.438.1">(wrapped_text)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.439.1">The output joins the sentences in </span><code class="inlineCode"><span class="koboSpan" id="kobo.440.1">db_records</span></code><span class="koboSpan" id="kobo.441.1"> for display, as printed in this excerpt, but </span><code class="inlineCode"><span class="koboSpan" id="kobo.442.1">db_records</span></code><span class="koboSpan" id="kobo.443.1"> remains unchanged:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.444.1">Retrieval Augmented Generation (RAG) represents a sophisticated hybrid approach in the field of artificial intelligence, particularly within the realm of natural language processing (NLP)…
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.445.1">The program is now ready to process a query.</span></p>
    <h3 id="_idParaDest-39" class="heading-3"><span class="koboSpan" id="kobo.446.1">4.The query</span></h3>
    <p class="normal"><span class="koboSpan" id="kobo.447.1">The </span><strong class="keyWord"><span class="koboSpan" id="kobo.448.1">retriever</span></strong><span class="koboSpan" id="kobo.449.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.450.1">D4</span></strong><span class="koboSpan" id="kobo.451.1"> in </span><em class="italic"><span class="koboSpan" id="kobo.452.1">Figure 1.3</span></em><span class="koboSpan" id="kobo.453.1">) query process depends on how the data was processed, but the query itself is simply user</span><a id="_idIndexMarker049"/><span class="koboSpan" id="kobo.454.1"> input or automated input from another AI agent. </span><span class="koboSpan" id="kobo.454.2">We all dream of users who introduce the best input into software systems, but unfortunately, in real life, unexpected inputs lead to unpredictable behaviors. </span><span class="koboSpan" id="kobo.454.3">We must, therefore, build systems that take imprecise inputs into account.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.455.1">In this section, we will imagine a situation in which hundreds of users in an organization have heard the word “RAG” associated with “LLM” and “vector stores.” </span><span class="koboSpan" id="kobo.455.2">Many of them would like to understand what these terms mean to keep up with a software team that’s deploying a conversational agent in their department. </span><span class="koboSpan" id="kobo.455.3">After a couple of days, the terms they heard become fuzzy in their memory, so they ask the conversational agent, GPT-4o in this case, to explain what they remember with the following query:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.456.1">query = </span><span class="hljs-string"><span class="koboSpan" id="kobo.457.1">"define a rag store"</span></span>
</code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.458.1">In this case, we will simply store the main query of the topic of this program in </span><code class="inlineCode"><span class="koboSpan" id="kobo.459.1">query</span></code><span class="koboSpan" id="kobo.460.1">, which represents the junction between the retriever and the generator. </span><span class="koboSpan" id="kobo.460.2">It will trigger a configuration of RAG (naïve, advanced, and modular). </span><span class="koboSpan" id="kobo.460.3">The choice of configuration will depend on the goals of each project.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.461.1">The program takes the query and sends it to a GPT-4o model to be processed and then displays the formatted output:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.462.1"># Call the function and print the result</span></span><span class="koboSpan" id="kobo.463.1">
llm_response = call_llm_with_full_text(query)
print_formatted_response(llm_response)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.464.1">The output is revealing. </span><span class="koboSpan" id="kobo.464.2">Even the most powerful generative AI models cannot guess what a user, who knows </span><a id="_idIndexMarker050"/><span class="koboSpan" id="kobo.465.1">nothing about AI, is trying to find out in good faith. </span><span class="koboSpan" id="kobo.465.2">In this case, GPT-4o will answer as shown in this excerpt of the output:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.466.1">Response:
---------------
Certainly! </span><span class="koboSpan" id="kobo.466.2">The content you've provided appears to be a sequence of characters
that, when combined, form the phrase "define a rag store." </span><span class="koboSpan" id="kobo.466.3">Let's break it down
step by step:…
… This is an indefinite article used before words that begin with a consonant sound.    </span><span class="koboSpan" id="kobo.466.4">- **rag**: This is a noun that typically refers to a pieceof old, often torn, cloth.    </span><span class="koboSpan" id="kobo.466.5">- **store**: This is a noun that refers to a place where goods are sold.  </span><span class="koboSpan" id="kobo.466.6">4. </span><span class="koboSpan" id="kobo.466.7">**Contextual Meaning**:    - **"Define a rag store"**: This phrase is asking for an explanation or definition of what a "rag store" is. </span><span class="koboSpan" id="kobo.466.8">5. </span><span class="koboSpan" id="kobo.466.9">**Possible Definition**:    - A "rag store" could be a shop or retail establishment that specializes in selling rags,…
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.467.1">The output will seem like a hallucination, but is it really? </span><span class="koboSpan" id="kobo.467.2">The user wrote the query with the good intentions of every beginner trying to learn a new topic. </span><span class="koboSpan" id="kobo.467.3">GPT-4o, in good faith, did what it could with the limited context it had with its probabilistic algorithm, which might even produce a different response each time we run it. </span><span class="koboSpan" id="kobo.467.4">However, GPT-4o is being wary of the query. </span><span class="koboSpan" id="kobo.467.5">It wasn’t very clear, so it ends the response with the following output that asks the user for more context:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.468.1">…Would you like more information or a different type of elaboration on this content?…
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.469.1">The user is puzzled, not knowing what to do, and GPT-4o is awaiting further instructions. </span><span class="koboSpan" id="kobo.469.2">The software team has to do something!</span></p>
    <div class="note">
      <p class="normal"><span class="koboSpan" id="kobo.470.1">Generative AI is based on probabilistic algorithms. </span><span class="koboSpan" id="kobo.470.2">As such, the response provided might vary from one run to another, providing similar (but not identical) responses.</span></p>
    </div>
    <p class="normal"><span class="koboSpan" id="kobo.471.1">That is when RAG</span><a id="_idIndexMarker051"/><span class="koboSpan" id="kobo.472.1"> comes in to save the situation. </span><span class="koboSpan" id="kobo.472.2">We will leave this query as it is for the whole notebook and see if a RAG-driven GPT-4o system can do better.</span></p>
    <h2 id="_idParaDest-40" class="heading-2"><span class="koboSpan" id="kobo.473.1">Part 2: Advanced techniques and evaluation</span></h2>
    <p class="normal"><span class="koboSpan" id="kobo.474.1">In </span><em class="italic"><span class="koboSpan" id="kobo.475.1">Part 2</span></em><span class="koboSpan" id="kobo.476.1">, we will introduce naïve, advanced, and modular RAG. </span><span class="koboSpan" id="kobo.476.2">The goal is to introduce the three methods, not to process complex documents, which we will implement throughout the following chapters of this book.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.477.1">Let’s first begin by defining retrieval metrics to measure the accuracy of the documents we retrieve.</span></p>
    <h3 id="_idParaDest-41" class="heading-3"><span class="koboSpan" id="kobo.478.1">1. </span><span class="koboSpan" id="kobo.478.2">Retrieval metrics</span></h3>
    <p class="normal"><span class="koboSpan" id="kobo.479.1">This section explores retrieval metrics, first focusing on the role of cosine similarity in assessing the relevance of text</span><a id="_idIndexMarker052"/><span class="koboSpan" id="kobo.480.1"> documents. </span><span class="koboSpan" id="kobo.480.2">Then we will implement enhanced similarity metrics by incorporating synonym expansion and text preprocessing to improve the accuracy of similarity calculations between texts.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.481.1">We will explore more metrics in the </span><em class="italic"><span class="koboSpan" id="kobo.482.1">Metrics calculation and display</span></em><span class="koboSpan" id="kobo.483.1"> section in </span><em class="chapterRef"><span class="koboSpan" id="kobo.484.1">Chapter 7</span></em><span class="koboSpan" id="kobo.485.1">, </span><em class="italic"><span class="koboSpan" id="kobo.486.1">Building Scalable Knowledge-Graph-Based RAG with Wikipedia API and LlamaIndex</span></em><span class="koboSpan" id="kobo.487.1">.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.488.1">In this chapter, let’s begin with cosine similarity.</span></p>
    <h4 class="heading-4"><span class="koboSpan" id="kobo.489.1">Cosine similarity</span></h4>
    <p class="normal"><span class="koboSpan" id="kobo.490.1">Cosine similarity measures the cosine of the angle between two vectors. </span><span class="koboSpan" id="kobo.490.2">In our case, the two vectors are the user query and</span><a id="_idIndexMarker053"/><span class="koboSpan" id="kobo.491.1"> each document in a corpus.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.492.1">The program first imports the class and function we need:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.493.1">from</span></span><span class="koboSpan" id="kobo.494.1"> sklearn.feature_extraction.text </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.495.1">import</span></span><span class="koboSpan" id="kobo.496.1"> TfidfVectorizer
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.497.1">from</span></span><span class="koboSpan" id="kobo.498.1"> sklearn.metrics.pairwise </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.499.1">import</span></span><span class="koboSpan" id="kobo.500.1"> cosine_similarity
</span></code></pre>
    <p class="normal"><code class="inlineCode"><span class="koboSpan" id="kobo.501.1">TfidfVectorizer</span></code><span class="koboSpan" id="kobo.502.1"> imports the class that converts text documents into a matrix of TF-IDF features. </span><strong class="keyWord"><span class="koboSpan" id="kobo.503.1">Term Frequency-Inverse Document Frequency</span></strong><span class="koboSpan" id="kobo.504.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.505.1">TF-IDF</span></strong><span class="koboSpan" id="kobo.506.1">) quantifies the relevance of a word to a document in a</span><a id="_idIndexMarker054"/><span class="koboSpan" id="kobo.507.1"> collection, distinguishing common words from those significant to specific texts. </span><span class="koboSpan" id="kobo.507.2">TF-IDF will thus quantify word relevance in documents using frequency across the document and inverse frequency across the corpus. </span><code class="inlineCode"><span class="koboSpan" id="kobo.508.1">cosine_similarity</span></code><span class="koboSpan" id="kobo.509.1"> imports the function we will use to calculate the similarity between vectors.</span></p>
    <p class="normal"><code class="inlineCode"><span class="koboSpan" id="kobo.510.1">calculate_cosine_similarity(text1, text2)</span></code><span class="koboSpan" id="kobo.511.1"> then calculates the cosine similarity between the query (</span><code class="inlineCode"><span class="koboSpan" id="kobo.512.1">text1</span></code><span class="koboSpan" id="kobo.513.1">) and each record of the dataset.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.514.1">The function converts the </span><a id="_idIndexMarker055"/><span class="koboSpan" id="kobo.515.1">query text (</span><code class="inlineCode"><span class="koboSpan" id="kobo.516.1">text1</span></code><span class="koboSpan" id="kobo.517.1">) and each record (</span><code class="inlineCode"><span class="koboSpan" id="kobo.518.1">text2</span></code><span class="koboSpan" id="kobo.519.1">) in the dataset into a vector with a vectorizer. </span><span class="koboSpan" id="kobo.519.2">Then, it calculates and returns the cosine similarity between the two vectors:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.520.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.521.1">calculate_cosine_similarity</span></span><span class="koboSpan" id="kobo.522.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.523.1">text1, text2</span></span><span class="koboSpan" id="kobo.524.1">):
    vectorizer = TfidfVectorizer(
        stop_words=</span><span class="hljs-string"><span class="koboSpan" id="kobo.525.1">'english'</span></span><span class="koboSpan" id="kobo.526.1">,
        use_idf=</span><span class="hljs-literal"><span class="koboSpan" id="kobo.527.1">True</span></span><span class="koboSpan" id="kobo.528.1">,
        norm=</span><span class="hljs-string"><span class="koboSpan" id="kobo.529.1">'l2'</span></span><span class="koboSpan" id="kobo.530.1">,
        ngram_range=(</span><span class="hljs-number"><span class="koboSpan" id="kobo.531.1">1</span></span><span class="koboSpan" id="kobo.532.1">, </span><span class="hljs-number"><span class="koboSpan" id="kobo.533.1">2</span></span><span class="koboSpan" id="kobo.534.1">),  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.535.1"># Use unigrams and bigrams</span></span><span class="koboSpan" id="kobo.536.1">
        sublinear_tf=</span><span class="hljs-literal"><span class="koboSpan" id="kobo.537.1">True</span></span><span class="koboSpan" id="kobo.538.1">,   </span><span class="hljs-comment"><span class="koboSpan" id="kobo.539.1"># Apply sublinear TF scaling</span></span><span class="koboSpan" id="kobo.540.1">
        analyzer=</span><span class="hljs-string"><span class="koboSpan" id="kobo.541.1">'word'</span></span>      <span class="hljs-comment"><span class="koboSpan" id="kobo.542.1"># You could also experiment with 'char' or 'char_wb' for character-level features</span></span><span class="koboSpan" id="kobo.543.1">
    )
    tfidf = vectorizer.fit_transform([text1, text2])
    similarity = cosine_similarity(tfidf[</span><span class="hljs-number"><span class="koboSpan" id="kobo.544.1">0</span></span><span class="koboSpan" id="kobo.545.1">:</span><span class="hljs-number"><span class="koboSpan" id="kobo.546.1">1</span></span><span class="koboSpan" id="kobo.547.1">], tfidf[</span><span class="hljs-number"><span class="koboSpan" id="kobo.548.1">1</span></span><span class="koboSpan" id="kobo.549.1">:</span><span class="hljs-number"><span class="koboSpan" id="kobo.550.1">2</span></span><span class="koboSpan" id="kobo.551.1">])
    </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.552.1">return</span></span><span class="koboSpan" id="kobo.553.1"> similarity[</span><span class="hljs-number"><span class="koboSpan" id="kobo.554.1">0</span></span><span class="koboSpan" id="kobo.555.1">][</span><span class="hljs-number"><span class="koboSpan" id="kobo.556.1">0</span></span><span class="koboSpan" id="kobo.557.1">]
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.558.1">The key parameters of this function are:</span></p>
    <ul>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.559.1">stop_words='english</span></code><span class="koboSpan" id="kobo.560.1">: Ignores common English words to focus on meaningful content</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.561.1">use_idf=True</span></code><span class="koboSpan" id="kobo.562.1">: Enables inverse document frequency weighting</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.563.1">norm='l2'</span></code><span class="koboSpan" id="kobo.564.1">: Applies L2 normalization to each output vector</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.565.1">ngram_range=(1, 2)</span></code><span class="koboSpan" id="kobo.566.1">: Considers both single words and two-word combinations</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.567.1">sublinear_tf=True</span></code><span class="koboSpan" id="kobo.568.1">: Applies logarithmic term frequency scaling</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.569.1">analyzer='word'</span></code><span class="koboSpan" id="kobo.570.1">: Analyzes text at the word level</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.571.1">Cosine similarity can be limited in some cases. </span><span class="koboSpan" id="kobo.571.2">Cosine similarity has limitations when dealing with ambiguous queries because it strictly measures the similarity based on the angle between vector representations of text. </span><span class="koboSpan" id="kobo.571.3">If a user asks a vague question like “What is rag?” </span><span class="koboSpan" id="kobo.571.4">in the program of this chapter and the database primarily contains information on “RAG” as in “retrieval-augmented generation” for AI, not “rag cloths,” the cosine similarity score might be low. </span><span class="koboSpan" id="kobo.571.5">This low score occurs because the mathematical model lacks contextual understanding to differentiate between the different meanings of “rag.” </span><span class="koboSpan" id="kobo.571.6">It only computes similarity based on the presence and frequency of similar words in the text, without grasping the user’s intent or the broader context of the query. </span><span class="koboSpan" id="kobo.571.7">Thus, even if the answers</span><a id="_idIndexMarker056"/><span class="koboSpan" id="kobo.572.1"> provided are technically accurate within the available dataset, the cosine similarity may not reflect the relevance accurately if the query’s context isn’t well-represented in the data.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.573.1">In this case, we can try enhanced similarity.</span></p>
    <h4 class="heading-4"><span class="koboSpan" id="kobo.574.1">Enhanced similarity</span></h4>
    <p class="normal"><span class="koboSpan" id="kobo.575.1">Enhanced similarity introduces calculations that leverage natural language processing tools to better capture semantic relationships between words. </span><span class="koboSpan" id="kobo.575.2">Using libraries like spaCy and NLTK, it preprocesses texts to</span><a id="_idIndexMarker057"/><span class="koboSpan" id="kobo.576.1"> reduce noise, expands terms with synonyms from WordNet, and computes similarity based on the semantic richness of the expanded vocabulary. </span><span class="koboSpan" id="kobo.576.2">This method aims to improve the accuracy of similarity assessments between two texts by considering a broader context than typical direct comparison methods.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.577.1">The code contains four main functions:</span></p>
    <ul>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.578.1">get_synonyms(word)</span></code><span class="koboSpan" id="kobo.579.1">: Retrieves synonyms for a given word from WordNet</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.580.1">preprocess_text(text)</span></code><span class="koboSpan" id="kobo.581.1">: Converts all text to lowercase, lemmatizes gets the (roots of words), and filters stopwords (common words) and punctuation from text</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.582.1">expand_with_synonyms(words)</span></code><span class="koboSpan" id="kobo.583.1">: Enhances a list of words by adding their synonyms</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.584.1">calculate_enhanced_similarity(text1, text2)</span></code><span class="koboSpan" id="kobo.585.1">: Computes cosine similarity between preprocessed and synonym-expanded text vectors</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.586.1">The </span><code class="inlineCode"><span class="koboSpan" id="kobo.587.1">calculate_enhanced_similarity(text1, text2)</span></code><span class="koboSpan" id="kobo.588.1"> function takes two texts and ultimately returns the cosine similarity score between two processed and synonym-expanded texts. </span><span class="koboSpan" id="kobo.588.2">This score quantifies the textual similarity based on their semantic content and enhanced word sets.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.589.1">The code begins by downloading and importing the necessary libraries and then runs the four functions beginning with </span><code class="inlineCode"><span class="koboSpan" id="kobo.590.1">calculate_enhanced_similarity(text1, text2)</span></code><span class="koboSpan" id="kobo.591.1">:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.592.1">import</span></span><span class="koboSpan" id="kobo.593.1"> spacy
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.594.1">import</span></span><span class="koboSpan" id="kobo.595.1"> nltk
nltk.download(</span><span class="hljs-string"><span class="koboSpan" id="kobo.596.1">'wordnet'</span></span><span class="koboSpan" id="kobo.597.1">)
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.598.1">from</span></span><span class="koboSpan" id="kobo.599.1"> nltk.corpus </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.600.1">import</span></span><span class="koboSpan" id="kobo.601.1"> wordnet
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.602.1">from</span></span><span class="koboSpan" id="kobo.603.1"> collections </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.604.1">import</span></span><span class="koboSpan" id="kobo.605.1"> Counter
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.606.1">import</span></span><span class="koboSpan" id="kobo.607.1"> numpy </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.608.1">as</span></span><span class="koboSpan" id="kobo.609.1"> np
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.610.1"># Load spaCy model</span></span><span class="koboSpan" id="kobo.611.1">
nlp = spacy.load(</span><span class="hljs-string"><span class="koboSpan" id="kobo.612.1">"en_core_web_sm"</span></span><span class="koboSpan" id="kobo.613.1">)
…
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.614.1">Enhanced similarity takes </span><a id="_idIndexMarker058"/><span class="koboSpan" id="kobo.615.1">this a bit further in terms of metrics. </span><span class="koboSpan" id="kobo.615.2">However, integrating RAG with generative AI presents multiple challenges.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.616.1">No matter which metric we implement, we will face the following limitations:</span></p>
    <ul>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.617.1">Input versus Document Length</span></strong><span class="koboSpan" id="kobo.618.1">: User queries are often short, while retrieved documents are longer and richer, complicating direct similarity evaluations.</span></li>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.619.1">Creative Retrieval</span></strong><span class="koboSpan" id="kobo.620.1">: Systems may creatively select longer documents that meet user expectations but yield poor metric scores due to unexpected content alignment.</span></li>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.621.1">Need for Human Feedback</span></strong><span class="koboSpan" id="kobo.622.1">: Often, human judgment is crucial to accurately assess the relevance and effectiveness of retrieved content, as automated metrics may not fully capture user satisfaction. </span><span class="koboSpan" id="kobo.622.2">We will explore this critical aspect of RAG in </span><em class="chapterRef"><span class="koboSpan" id="kobo.623.1">Chapter 5</span></em><span class="koboSpan" id="kobo.624.1">, </span><em class="italic"><span class="koboSpan" id="kobo.625.1">Boosting RAG Performance with Expert Human Feedback</span></em><span class="koboSpan" id="kobo.626.1">.</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.627.1">We will always have to find the right balance between mathematical metrics and human feedback.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.628.1">We are now ready to create an example with naïve RAG.</span></p>
    <h3 id="_idParaDest-42" class="heading-3"><span class="koboSpan" id="kobo.629.1">2. </span><span class="koboSpan" id="kobo.629.2">Naïve RAG</span></h3>
    <p class="normal"><span class="koboSpan" id="kobo.630.1">Naïve RAG with keyword search </span><a id="_idIndexMarker059"/><span class="koboSpan" id="kobo.631.1">and matching can prove efficient with well-defined documents within an organization, such as legal and medical documents. </span><span class="koboSpan" id="kobo.631.2">These documents generally have clear titles or labels for images, for example. </span><span class="koboSpan" id="kobo.631.3">In this naïve RAG function, we will implement keyword search and matching. </span><span class="koboSpan" id="kobo.631.4">To achieve this, we will apply a straightforward retrieval method in the code:</span></p>
    <ol>
      <li class="numberedList" value="1"><span class="koboSpan" id="kobo.632.1">Split the query into individual keywords</span></li>
      <li class="numberedList"><span class="koboSpan" id="kobo.633.1">Split each record in the dataset into keywords</span></li>
      <li class="numberedList"><span class="koboSpan" id="kobo.634.1">Determine the length of the common matches</span></li>
      <li class="numberedList"><span class="koboSpan" id="kobo.635.1">Choose the record with the best score</span></li>
    </ol>
    <p class="normal"><span class="koboSpan" id="kobo.636.1">The generation method will:</span></p>
    <ul>
      <li class="bulletList"><span class="koboSpan" id="kobo.637.1">Augment the </span><a id="_idIndexMarker060"/><span class="koboSpan" id="kobo.638.1">user input with the result of the retrieval query</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.639.1">Request the generation model, which is </span><code class="inlineCode"><span class="koboSpan" id="kobo.640.1">gpt-4o</span></code><span class="koboSpan" id="kobo.641.1"> in this case</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.642.1">Display the response</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.643.1">Let’s write the keyword search and matching function.</span></p>
    <h4 class="heading-4"><span class="koboSpan" id="kobo.644.1">Keyword search and matching</span></h4>
    <p class="normal"><span class="koboSpan" id="kobo.645.1">The best matching function</span><a id="_idIndexMarker061"/><span class="koboSpan" id="kobo.646.1"> first initializes the best scores:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.647.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.648.1">find_best_match_keyword_search</span></span><span class="koboSpan" id="kobo.649.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.650.1">query, db_records</span></span><span class="koboSpan" id="kobo.651.1">):
    best_score = </span><span class="hljs-number"><span class="koboSpan" id="kobo.652.1">0</span></span><span class="koboSpan" id="kobo.653.1">
    best_record = </span><span class="hljs-literal"><span class="koboSpan" id="kobo.654.1">None</span></span>
</code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.655.1">The query is then split into keywords. </span><span class="koboSpan" id="kobo.655.2">Each record is also split into words to find the common words, measure the length of common content, and find the best match:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.656.1"># Split the query into individual keywords</span></span><span class="koboSpan" id="kobo.657.1">
    query_keywords = </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.658.1">set</span></span><span class="koboSpan" id="kobo.659.1">(query.lower().split())
    </span><span class="hljs-comment"><span class="koboSpan" id="kobo.660.1"># Iterate through each record in db_records</span></span>
    <span class="hljs-keyword"><span class="koboSpan" id="kobo.661.1">for</span></span><span class="koboSpan" id="kobo.662.1"> record </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.663.1">in</span></span><span class="koboSpan" id="kobo.664.1"> db_records:
        </span><span class="hljs-comment"><span class="koboSpan" id="kobo.665.1"># Split the record into keywords</span></span><span class="koboSpan" id="kobo.666.1">
        record_keywords = </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.667.1">set</span></span><span class="koboSpan" id="kobo.668.1">(record.lower().split())
        </span><span class="hljs-comment"><span class="koboSpan" id="kobo.669.1"># Calculate the number of common keywords</span></span><span class="koboSpan" id="kobo.670.1">
        common_keywords = query_keywords.intersection(record_keywords)
        current_score = </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.671.1">len</span></span><span class="koboSpan" id="kobo.672.1">(common_keywords)
        </span><span class="hljs-comment"><span class="koboSpan" id="kobo.673.1"># Update the best score and record if the current score is higher</span></span>
        <span class="hljs-keyword"><span class="koboSpan" id="kobo.674.1">if</span></span><span class="koboSpan" id="kobo.675.1"> current_score &gt; best_score:
            best_score = current_score
            best_record = record
    </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.676.1">return</span></span><span class="koboSpan" id="kobo.677.1"> best_score, best_record
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.678.1">We now call the function, format the response, and print it:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.679.1"># Assuming 'query' and 'db_records' are defined in previous cells in your Colab notebook</span></span><span class="koboSpan" id="kobo.680.1">
best_keyword_score, best_matching_record = find_best_match_keyword_search(query, db_records)
</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.681.1">print</span></span><span class="koboSpan" id="kobo.682.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.683.1">f"Best Keyword Score: </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.684.1">{best_keyword_score}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.685.1">"</span></span><span class="koboSpan" id="kobo.686.1">)
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.687.1">#print(f"Best Matching Record: {best_matching_record}")</span></span><span class="koboSpan" id="kobo.688.1">
print_formatted_response(best_matching_record)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.689.1">The main query of this notebook will be </span><code class="inlineCode"><span class="koboSpan" id="kobo.690.1">query = "define a rag store"</span></code><span class="koboSpan" id="kobo.691.1"> to see if each RAG method produces an</span><a id="_idIndexMarker062"/><span class="koboSpan" id="kobo.692.1"> acceptable output.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.693.1">The keyword search finds the best record in the list of sentences in the dataset:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.694.1">Best Keyword Score: 3
Response:
---------------
A RAG vector store is a database or dataset that contains vectorized data points.
</span><span class="koboSpan" id="kobo.694.2">---------------
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.695.1">Let’s run the metrics.</span></p>
    <h4 class="heading-4"><span class="koboSpan" id="kobo.696.1">Metrics</span></h4>
    <p class="normal"><span class="koboSpan" id="kobo.697.1">We created the </span><a id="_idIndexMarker063"/><span class="koboSpan" id="kobo.698.1">similarity metrics in the </span><em class="italic"><span class="koboSpan" id="kobo.699.1">1. </span><span class="koboSpan" id="kobo.699.2">Retrieval metrics</span></em><span class="koboSpan" id="kobo.700.1"> section of this chapter. </span><span class="koboSpan" id="kobo.700.2">We will first apply cosine similarity:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.701.1"># Cosine Similarity</span></span><span class="koboSpan" id="kobo.702.1">
score = calculate_cosine_similarity(query, best_matching_record)
</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.703.1">print</span></span><span class="koboSpan" id="kobo.704.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.705.1">f"Best Cosine Similarity Score: </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.706.1">{score:</span></span><span class="hljs-number"><span class="koboSpan" id="kobo.707.1">.3</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.708.1">f}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.709.1">"</span></span><span class="koboSpan" id="kobo.710.1">)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.711.1">The output similarity is low, as explained in the </span><em class="italic"><span class="koboSpan" id="kobo.712.1">1. </span><span class="koboSpan" id="kobo.712.2">Retrieval metrics</span></em><span class="koboSpan" id="kobo.713.1"> section of this chapter. </span><span class="koboSpan" id="kobo.713.2">The user input is short and the response is longer and complete:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.714.1">Best Cosine Similarity Score: 0.126
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.715.1">Enhanced similarity will produce a better score:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.716.1"># Enhanced Similarity</span></span><span class="koboSpan" id="kobo.717.1">
response = best_matching_record
</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.718.1">print</span></span><span class="koboSpan" id="kobo.719.1">(query,</span><span class="hljs-string"><span class="koboSpan" id="kobo.720.1">": "</span></span><span class="koboSpan" id="kobo.721.1">, response)
similarity_score = calculate_enhanced_similarity(query, response)
</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.722.1">print</span></span><span class="koboSpan" id="kobo.723.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.724.1">f"Enhanced Similarity:, </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.725.1">{similarity_score:</span></span><span class="hljs-number"><span class="koboSpan" id="kobo.726.1">.3</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.727.1">f}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.728.1">"</span></span><span class="koboSpan" id="kobo.729.1">)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.730.1">The score produced is higher with enhanced functionality:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.731.1">define a rag store :  A RAG vector store is a database or dataset that contains vectorized data points.
</span><span class="koboSpan" id="kobo.731.2">Enhanced Similarity:, 0.642
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.732.1">The output of the query </span><a id="_idIndexMarker064"/><span class="koboSpan" id="kobo.733.1">will now augment the user input.</span></p>
    <h4 class="heading-4"><span class="koboSpan" id="kobo.734.1">Augmented input</span></h4>
    <p class="normal"><span class="koboSpan" id="kobo.735.1">The augmented input is the concatenation</span><a id="_idIndexMarker065"/><span class="koboSpan" id="kobo.736.1"> of the user input and the best matching record of the dataset detected with the keyword search:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.737.1">augmented_input=query+ </span><span class="hljs-string"><span class="koboSpan" id="kobo.738.1">": "</span></span><span class="koboSpan" id="kobo.739.1">+ best_matching_record
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.740.1">The augmented input is displayed if necessary for maintenance reasons:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.741.1">print_formatted_response(augmented_input)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.742.1">The output then shows that the augmented input is ready:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.743.1">Response:
---------------
define a rag store: A RAG vector store is a database or dataset that contains
vectorized data points.
</span><span class="koboSpan" id="kobo.743.2">---------------
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.744.1">The input is now ready for the generation process.</span></p>
    <h4 class="heading-4"><span class="koboSpan" id="kobo.745.1">Generation</span></h4>
    <p class="normal"><span class="koboSpan" id="kobo.746.1">We are now ready to call GPT-4o and</span><a id="_idIndexMarker066"/><span class="koboSpan" id="kobo.747.1"> display the formatted response:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.748.1">llm_response = call_llm_with_full_text(augmented_input)
print_formatted_response(llm_response)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.749.1">The following excerpt of the response shows that GPT-4o understands the input and provides an interesting, pertinent response:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.750.1">Response:
---------------
Certainly! </span><span class="koboSpan" id="kobo.750.2">Let's break down and elaborate on the provided content:  ### Define a
RAG Store:  A **RAG (Retrieval-Augmented Generation) vector store** is a
specialized type of database or dataset that is designed to store and manage
vectorized data points…
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.751.1">Naïve RAG can be sufficient in many situations. </span><span class="koboSpan" id="kobo.751.2">However, if the volume of documents becomes too large or the content becomes more complex, then advanced RAG configurations will </span><a id="_idIndexMarker067"/><span class="koboSpan" id="kobo.752.1">provide better results. </span><span class="koboSpan" id="kobo.752.2">Let’s now explore advanced RAG.</span></p>
    <h3 id="_idParaDest-43" class="heading-3"><span class="koboSpan" id="kobo.753.1">3. </span><span class="koboSpan" id="kobo.753.2">Advanced RAG</span></h3>
    <p class="normal"><span class="koboSpan" id="kobo.754.1">As datasets grow larger, keyword search methods might prove too long to run. </span><span class="koboSpan" id="kobo.754.2">For instance, if we have hundreds of documents and each document contains hundreds of sentences, it will become challenging to use keyword search only. </span><span class="koboSpan" id="kobo.754.3">Using an index will reduce the computational load to just a fraction of the total data.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.755.1">In this section, we will go beyond searching</span><a id="_idIndexMarker068"/><span class="koboSpan" id="kobo.756.1"> text with keywords. </span><span class="koboSpan" id="kobo.756.2">We will see how RAG transforms text data into numerical representations, enhancing search efficiency and processing speed. </span><span class="koboSpan" id="kobo.756.3">Unlike traditional methods that directly parse text, RAG first converts documents and user queries into vectors, numerical forms that speed up calculations. </span><span class="koboSpan" id="kobo.756.4">In simple terms, a vector is a list of numbers representing various features of text. </span><span class="koboSpan" id="kobo.756.5">Simple vectors might count word occurrences (term frequency), while more complex vectors, known as embeddings, capture deeper linguistic patterns.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.757.1">In this section, we will implement vector search and index-based search:</span></p>
    <ul>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.758.1">Vector Search</span></strong><span class="koboSpan" id="kobo.759.1">: We will convert each sentence in our dataset into a numerical vector. </span><span class="koboSpan" id="kobo.759.2">By </span><a id="_idIndexMarker069"/><span class="koboSpan" id="kobo.760.1">calculating the cosine similarity between the query vector (the user query) and these document vectors, we can quickly find the most relevant documents.</span></li>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.761.1">Index-Based Search</span></strong><span class="koboSpan" id="kobo.762.1">: In this </span><a id="_idIndexMarker070"/><span class="koboSpan" id="kobo.763.1">case, all sentences are converted into vectors using </span><strong class="keyWord"><span class="koboSpan" id="kobo.764.1">TF-IDF</span></strong><span class="koboSpan" id="kobo.765.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.766.1">Term Frequency-Inverse Document Frequency</span></strong><span class="koboSpan" id="kobo.767.1">), a statistical measure used to evaluate how important a word is to a document in a collection. </span><span class="koboSpan" id="kobo.767.2">These vectors act as indices in a matrix, allowing quick similarity comparisons without parsing each document fully.</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.768.1">Let’s start with vector search and see these concepts in action.</span></p>
    <h4 class="heading-4"><span class="koboSpan" id="kobo.769.1">3.1.Vector search</span></h4>
    <p class="normal"><span class="koboSpan" id="kobo.770.1">Vector search converts the user</span><a id="_idIndexMarker071"/><span class="koboSpan" id="kobo.771.1"> query and the documents into numerical values as vectors, enabling mathematical calculations that </span><em class="italic"><span class="koboSpan" id="kobo.772.1">retrieve relevant data faster when dealing with large volumes of data</span></em><span class="koboSpan" id="kobo.773.1">.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.774.1">The program runs through each</span><a id="_idIndexMarker072"/><span class="koboSpan" id="kobo.775.1"> record of the dataset to find the best matching document by computing the cosine similarity of the query vector and each record in the dataset:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.776.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.777.1">find_best_match</span></span><span class="koboSpan" id="kobo.778.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.779.1">text_input, records</span></span><span class="koboSpan" id="kobo.780.1">):
    best_score = </span><span class="hljs-number"><span class="koboSpan" id="kobo.781.1">0</span></span><span class="koboSpan" id="kobo.782.1">
    best_record = </span><span class="hljs-literal"><span class="koboSpan" id="kobo.783.1">None</span></span>
    <span class="hljs-keyword"><span class="koboSpan" id="kobo.784.1">for</span></span><span class="koboSpan" id="kobo.785.1"> record </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.786.1">in</span></span><span class="koboSpan" id="kobo.787.1"> records:
        current_score = calculate_cosine_similarity(text_input, record)
        </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.788.1">if</span></span><span class="koboSpan" id="kobo.789.1"> current_score &gt; best_score:
            best_score = current_score
            best_record = record
    </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.790.1">return</span></span><span class="koboSpan" id="kobo.791.1"> best_score, best_record
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.792.1">The code then calls the vector search function and displays the best record found:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.793.1">best_similarity_score, best_matching_record = find_best_match(query, db_records)
print_formatted_response(best_matching_record)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.794.1">The output is satisfactory:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.795.1">Response:
---------------
A RAG vector store is a database or dataset that contains vectorized data
points.
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.796.1">The response is the best one found, like with naïve RAG. </span><span class="koboSpan" id="kobo.796.2">This shows that there is no silver bullet. </span><span class="koboSpan" id="kobo.796.3">Each RAG technique has its merits. </span><span class="koboSpan" id="kobo.796.4">The metrics will confirm this observation.</span></p>
    <h5 class="heading-5"><span class="koboSpan" id="kobo.797.1">Metrics</span></h5>
    <p class="normal"><span class="koboSpan" id="kobo.798.1">The metrics are the </span><a id="_idIndexMarker073"/><span class="koboSpan" id="kobo.799.1">same for both similarity methods as for naïve RAG because the same document was retrieved:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-built_in"><span class="koboSpan" id="kobo.800.1">print</span></span><span class="koboSpan" id="kobo.801.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.802.1">f"Best Cosine Similarity Score: </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.803.1">{best_similarity_score:</span></span><span class="hljs-number"><span class="koboSpan" id="kobo.804.1">.3</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.805.1">f}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.806.1">"</span></span><span class="koboSpan" id="kobo.807.1">)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.808.1">The output is:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.809.1">Best Cosine Similarity Score: 0.126
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.810.1">And with enhanced similarity, we obtain the same output as for naïve RAG:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.811.1"># Enhanced Similarity</span></span><span class="koboSpan" id="kobo.812.1">
response = best_matching_record
</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.813.1">print</span></span><span class="koboSpan" id="kobo.814.1">(query,</span><span class="hljs-string"><span class="koboSpan" id="kobo.815.1">": "</span></span><span class="koboSpan" id="kobo.816.1">, response)
similarity_score = calculate_enhanced_similarity(query, best_matching_record)
</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.817.1">print</span></span><span class="koboSpan" id="kobo.818.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.819.1">f"Enhanced Similarity:, </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.820.1">{similarity_score:</span></span><span class="hljs-number"><span class="koboSpan" id="kobo.821.1">.3</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.822.1">f}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.823.1">"</span></span><span class="koboSpan" id="kobo.824.1">)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.825.1">The output </span><a id="_idIndexMarker074"/><span class="koboSpan" id="kobo.826.1">confirms the trend:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.827.1">define a rag store :  A RAG vector store is a database or dataset that contains vectorized data points.
</span><span class="koboSpan" id="kobo.827.2">Enhanced Similarity:, 0.642
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.828.1">So why use vector search if it produces the same outputs as naïve RAG? </span><span class="koboSpan" id="kobo.828.2">Well, in a small dataset, everything looks easy. </span><span class="koboSpan" id="kobo.828.3">But when we’re dealing with datasets of millions of complex documents, keyword search will not capture subtleties that vectors can. </span><span class="koboSpan" id="kobo.828.4">Let’s now augment the user query with this information retrieved.</span></p>
    <h5 class="heading-5"><span class="koboSpan" id="kobo.829.1">Augmented input</span></h5>
    <p class="normal"><span class="koboSpan" id="kobo.830.1">We add the information retrieved to</span><a id="_idIndexMarker075"/><span class="koboSpan" id="kobo.831.1"> the user query with no other aid and display the result:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.832.1"># Call the function and print the result</span></span><span class="koboSpan" id="kobo.833.1">
augmented_input=query+</span><span class="hljs-string"><span class="koboSpan" id="kobo.834.1">": "</span></span><span class="koboSpan" id="kobo.835.1">+best_matching_record
print_formatted_response(augmented_input)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.836.1">We only added a space between the user query and the retrieved information; nothing else. </span><span class="koboSpan" id="kobo.836.2">The output is satisfactory:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.837.1">Response:
---------------
define a rag store: A RAG vector store is a database or dataset that contains
vectorized data points.
</span><span class="koboSpan" id="kobo.837.2">---------------
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.838.1">Let’s now see how the generative AI model reacts to this augmented input.</span></p>
    <h5 class="heading-5"><span class="koboSpan" id="kobo.839.1">Generation</span></h5>
    <p class="normal"><span class="koboSpan" id="kobo.840.1">We now call GPT-4o with the</span><a id="_idIndexMarker076"/><span class="koboSpan" id="kobo.841.1"> augmented input and display the formatted output:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.842.1"># Call the function and print the result</span></span><span class="koboSpan" id="kobo.843.1">
augmented_input=query+best_matching_record
llm_response = call_llm_with_full_text(augmented_input)
print_formatted_response(llm_response)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.844.1">The response makes sense, as shown in the following excerpt:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.845.1">Response:
---------------
Certainly! </span><span class="koboSpan" id="kobo.845.2">Let's break down and elaborate on the provided content:  ### Define a RAG Store:  A **RAG (Retrieval-Augmented Generation) vector store** is a specialized type of database or dataset that is designed to store and manage vectorized data points…
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.846.1">While vector search significantly speeds up the process of finding relevant documents by sequentially going through each record, its efficiency can decrease as the dataset size increases. </span><span class="koboSpan" id="kobo.846.2">To address this scalability issue, indexed search offers a more advanced solution. </span><span class="koboSpan" id="kobo.846.3">Let’s now see how index-based search can accelerate document retrieval.</span></p>
    <h4 class="heading-4"><span class="koboSpan" id="kobo.847.1">3.2. </span><span class="koboSpan" id="kobo.847.2">Index-based search</span></h4>
    <p class="normal"><span class="koboSpan" id="kobo.848.1">Index-based search compares the vector of a user query not with the direct vector of a document’s content but with an</span><a id="_idIndexMarker077"/><span class="koboSpan" id="kobo.849.1"> indexed vector that represents this content.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.850.1">The program first imports the class </span><a id="_idIndexMarker078"/><span class="koboSpan" id="kobo.851.1">and function we need:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.852.1">from</span></span><span class="koboSpan" id="kobo.853.1"> sklearn.feature_extraction.text </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.854.1">import</span></span><span class="koboSpan" id="kobo.855.1"> TfidfVectorizer
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.856.1">from</span></span><span class="koboSpan" id="kobo.857.1"> sklearn.metrics.pairwise </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.858.1">import</span></span><span class="koboSpan" id="kobo.859.1"> cosine_similarity
</span></code></pre>
    <p class="normal"><code class="inlineCode"><span class="koboSpan" id="kobo.860.1">TfidfVectorizer</span></code><span class="koboSpan" id="kobo.861.1"> imports the class that converts text documents into a matrix of TF-IDF features. </span><span class="koboSpan" id="kobo.861.2">TF-IDF will quantify word relevance in documents using frequency across the document. </span><span class="koboSpan" id="kobo.861.3">The function finds the best matches using the cosine similarity function to calculate the similarity between the query and the weighted vectors of the matrix:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.862.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.863.1">find_best_match</span></span><span class="koboSpan" id="kobo.864.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.865.1">query, vectorizer, tfidf_matrix</span></span><span class="koboSpan" id="kobo.866.1">):
    query_tfidf = vectorizer.transform([query])
    similarities = cosine_similarity(query_tfidf, tfidf_matrix)
    best_index = similarities.argmax()  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.867.1"># Get the index of the highest similarity score</span></span><span class="koboSpan" id="kobo.868.1">
    best_score = similarities[</span><span class="hljs-number"><span class="koboSpan" id="kobo.869.1">0</span></span><span class="koboSpan" id="kobo.870.1">, best_index]
    </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.871.1">return</span></span><span class="koboSpan" id="kobo.872.1"> best_score, best_index
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.873.1">The function’s main tasks are:</span></p>
    <ul>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.874.1">Transform Query</span></strong><span class="koboSpan" id="kobo.875.1">: Converts the input query into TF-IDF vector format using the provided vectorizer</span></li>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.876.1">Calculate Similarities</span></strong><span class="koboSpan" id="kobo.877.1">: Computes the cosine similarity between the query vector and all vectors in the tfidf_matrix</span></li>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.878.1">Identify Best Match</span></strong><span class="koboSpan" id="kobo.879.1">: Finds the index (</span><code class="inlineCode"><span class="koboSpan" id="kobo.880.1">best_index</span></code><span class="koboSpan" id="kobo.881.1">) of the highest similarity score in the results</span></li>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.882.1">Retrieve Best Score</span></strong><span class="koboSpan" id="kobo.883.1">: Extracts the highest cosine similarity score (</span><code class="inlineCode"><span class="koboSpan" id="kobo.884.1">best_score</span></code><span class="koboSpan" id="kobo.885.1">)</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.886.1">The output is the best</span><a id="_idIndexMarker079"/><span class="koboSpan" id="kobo.887.1"> similarity score found and the best index.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.888.1">The following code first calls the dataset vectorizer and then searches for the most similar record through its index:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.889.1">vectorizer, tfidf_matrix = setup_vectorizer(db_records)
best_similarity_score, best_index = find_best_match(query, vectorizer, tfidf_matrix)
best_matching_record = db_records[best_index]
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.890.1">Finally, the results are displayed:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.891.1">print_formatted_response(best_matching_record)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.892.1">The system finds the best similar document to the user’s input query:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.893.1">Response:
---------------
A RAG vector store is a database or dataset that contains vectorized data
points.
</span><span class="koboSpan" id="kobo.893.2">---------------
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.894.1">We can see that the fuzzy user query produced a reliable output at the retrieval level before running GPT-4o.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.895.1">The metrics that follow in the program are the same as for naïve and advanced RAG with vector search. </span><span class="koboSpan" id="kobo.895.2">This is normal because the document found is the closest to the user’s input query. </span><span class="koboSpan" id="kobo.895.3">We </span><a id="_idIndexMarker080"/><span class="koboSpan" id="kobo.896.1">will be introducing more complex documents for RAG starting in </span><em class="chapterRef"><span class="koboSpan" id="kobo.897.1">Chapter 2</span></em><span class="koboSpan" id="kobo.898.1">, </span><em class="italic"><span class="koboSpan" id="kobo.899.1">RAG Embedding Vector Stores with Deep Lake and OpenAI</span></em><span class="koboSpan" id="kobo.900.1">. </span><span class="koboSpan" id="kobo.900.2">For now, let’s have a look at the features that influence how the words are represented in vectors.</span></p>
    <h5 class="heading-5"><span class="koboSpan" id="kobo.901.1">Feature extraction</span></h5>
    <p class="normal"><span class="koboSpan" id="kobo.902.1">Before augmenting the input with</span><a id="_idIndexMarker081"/><span class="koboSpan" id="kobo.903.1"> this document, run the following cell, which calls the </span><code class="inlineCode"><span class="koboSpan" id="kobo.904.1">setup_vectorizer(records)</span></code><span class="koboSpan" id="kobo.905.1"> function again but displays the matrix so that you can see its format. </span><span class="koboSpan" id="kobo.905.2">This is shown in the following excerpt for the words “accurate” and “additional” in one of the sentences:</span></p>
    <figure class="mediaobject"><span class="koboSpan" id="kobo.906.1"><img src="../Images/B31169_01_04.png" alt="A black and white image of a number  Description automatically generated with medium confidence"/></span></figure>
    <p class="packt_figref"><span class="koboSpan" id="kobo.907.1">Figure 1.4: Format of the matrix</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.908.1">Let’s now augment the input.</span></p>
    <h5 class="heading-5"><span class="koboSpan" id="kobo.909.1">Augmented input</span></h5>
    <p class="normal"><span class="koboSpan" id="kobo.910.1">We will simply add the query to the</span><a id="_idIndexMarker082"/><span class="koboSpan" id="kobo.911.1"> best matching record in a minimal way to see how GPT-4o will react and display the output:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.912.1">augmented_input=query+</span><span class="hljs-string"><span class="koboSpan" id="kobo.913.1">": "</span></span><span class="koboSpan" id="kobo.914.1">+best_matching_record
print_formatted_response(augmented_input)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.915.1">The output is close to or the same as with vector search, but the retrieval method is faster:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.916.1">Response:
---------------
define a rag store: A RAG vector store is a database or dataset that contains
vectorized data points.
</span><span class="koboSpan" id="kobo.916.2">---------------
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.917.1">We will now plug this augmented input into the generative AI model.</span></p>
    <h5 class="heading-5"><span class="koboSpan" id="kobo.918.1">Generation</span></h5>
    <p class="normal"><span class="koboSpan" id="kobo.919.1">We now call GPT-4o with the </span><a id="_idIndexMarker083"/><span class="koboSpan" id="kobo.920.1">augmented input and display the output:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.921.1"># Call the function and print the result</span></span><span class="koboSpan" id="kobo.922.1">
llm_response = call_llm_with_full_text(augmented_input)
print_formatted_response(llm_response)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.923.1">The output makes sense for the user who entered the initial fuzzy query:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.924.1">Response:
---------------
Certainly! </span><span class="koboSpan" id="kobo.924.2">Let's break down and elaborate on the given content:  ---  **Define a RAG store:**  A **RAG vector store** is a **database** or **dataset** that contains **vectorized data points**.  </span><span class="koboSpan" id="kobo.924.3">---  ### Detailed Explanation:  1. </span><span class="koboSpan" id="kobo.924.4">**RAG Store**:    - **RAG** stands for **Retrieval-Augmented Generation**. </span><span class="koboSpan" id="kobo.924.5">It is a technique used in natural language processing (NLP) where a model retrieves relevant information from a database or dataset to augment its generation capabilities…
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.925.1">This approach worked well in a closed environment within an organization in a specific domain. </span><span class="koboSpan" id="kobo.925.2">In an open environment, the user might have to elaborate before submitting a request.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.926.1">In this section, we saw that a TF-IDF matrix pre-computes document vectors, enabling faster, simultaneous comparisons without repeated vector transformations. </span><span class="koboSpan" id="kobo.926.2">We have seen how vector and index-based search can improve retrieval. </span><span class="koboSpan" id="kobo.926.3">However, in one project, we may need to apply naïve and advanced RAG depending on the documents we need to retrieve. </span><span class="koboSpan" id="kobo.926.4">Let’s now see how modular RAG can improve our system.</span></p>
    <h3 id="_idParaDest-44" class="heading-3"><span class="koboSpan" id="kobo.927.1">4. </span><span class="koboSpan" id="kobo.927.2">Modular RAG</span></h3>
    <p class="normal"><span class="koboSpan" id="kobo.928.1">Should we use keyword search, vector </span><a id="_idIndexMarker084"/><span class="koboSpan" id="kobo.929.1">search, or index-based search when implementing RAG? </span><span class="koboSpan" id="kobo.929.2">Each approach has its merits. </span><span class="koboSpan" id="kobo.929.3">The choice will depend on several factors:</span></p>
    <ul>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.930.1">Keyword search</span></strong><span class="koboSpan" id="kobo.931.1"> suits simple retrieval</span></li>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.932.1">Vector search</span></strong><span class="koboSpan" id="kobo.933.1"> is ideal for semantic-rich documents</span></li>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.934.1">Index-based search</span></strong><span class="koboSpan" id="kobo.935.1"> offers speed with large data.</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.936.1">However, all three methods can perfectly fit together in a project. </span><span class="koboSpan" id="kobo.936.2">In one scenario, for example, a keyword search can help find clearly defined document labels, such as the titles of PDF files and labeled images, before they are processed. </span><span class="koboSpan" id="kobo.936.3">Then, indexed search will group the documents into indexed subsets. </span><span class="koboSpan" id="kobo.936.4">Finally, the retrieval program can search the indexed dataset, find a subset, and only use vector search to go through a limited number of documents to find </span><a id="_idIndexMarker085"/><span class="koboSpan" id="kobo.937.1">the most relevant one.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.938.1">In this section, we will create a </span><code class="inlineCode"><span class="koboSpan" id="kobo.939.1">RetrievalComponent</span></code><span class="koboSpan" id="kobo.940.1"> class that can be called at each step of a project to perform the task required. </span><span class="koboSpan" id="kobo.940.2">The code sums up the three methods we have built in this chapter and that we can sum for the </span><code class="inlineCode"><span class="koboSpan" id="kobo.941.1">RetrievalComponent</span></code><span class="koboSpan" id="kobo.942.1"> through its main members.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.943.1">The following code initializes the class with search method choice and prepares a vectorizer if needed. </span><code class="inlineCode"><span class="koboSpan" id="kobo.944.1">self</span></code><span class="koboSpan" id="kobo.945.1"> refers to the current instance of the class to access its variables, methods, and functions:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.946.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.947.1">__init__</span></span><span class="koboSpan" id="kobo.948.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.949.1">self, method=</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.950.1">'vector'</span></span><span class="koboSpan" id="kobo.951.1">):
        </span><span class="hljs-variable"><span class="koboSpan" id="kobo.952.1">self</span></span><span class="koboSpan" id="kobo.953.1">.method = method
        </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.954.1">if</span></span> <span class="hljs-variable"><span class="koboSpan" id="kobo.955.1">self</span></span><span class="koboSpan" id="kobo.956.1">.method == </span><span class="hljs-string"><span class="koboSpan" id="kobo.957.1">'vector'</span></span> <span class="hljs-keyword"><span class="koboSpan" id="kobo.958.1">or</span></span> <span class="hljs-variable"><span class="koboSpan" id="kobo.959.1">self</span></span><span class="koboSpan" id="kobo.960.1">.method == </span><span class="hljs-string"><span class="koboSpan" id="kobo.961.1">'indexed'</span></span><span class="koboSpan" id="kobo.962.1">:
            </span><span class="hljs-variable"><span class="koboSpan" id="kobo.963.1">self</span></span><span class="koboSpan" id="kobo.964.1">.vectorizer = TfidfVectorizer()
            </span><span class="hljs-variable"><span class="koboSpan" id="kobo.965.1">self</span></span><span class="koboSpan" id="kobo.966.1">.tfidf_matrix = </span><span class="hljs-literal"><span class="koboSpan" id="kobo.967.1">None</span></span>
</code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.968.1">In this case, the vector search is activated.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.969.1">The </span><code class="inlineCode"><span class="koboSpan" id="kobo.970.1">fit</span></code><span class="koboSpan" id="kobo.971.1"> method builds a TF-IDF matrix from records, and is applicable for vector or indexed search methods:</span></p>
    <pre class="programlisting code"><code class="hljs-code">    <span class="hljs-keyword"><span class="koboSpan" id="kobo.972.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.973.1">fit</span></span><span class="koboSpan" id="kobo.974.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.975.1">self, records</span></span><span class="koboSpan" id="kobo.976.1">):
        </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.977.1">if</span></span> <span class="hljs-variable"><span class="koboSpan" id="kobo.978.1">self</span></span><span class="koboSpan" id="kobo.979.1">.method == </span><span class="hljs-string"><span class="koboSpan" id="kobo.980.1">'vector'</span></span> <span class="hljs-keyword"><span class="koboSpan" id="kobo.981.1">or</span></span> <span class="hljs-variable"><span class="koboSpan" id="kobo.982.1">self</span></span><span class="koboSpan" id="kobo.983.1">.method == </span><span class="hljs-string"><span class="koboSpan" id="kobo.984.1">'indexed'</span></span><span class="koboSpan" id="kobo.985.1">:
            </span><span class="hljs-variable"><span class="koboSpan" id="kobo.986.1">self</span></span><span class="koboSpan" id="kobo.987.1">.tfidf_matrix = </span><span class="hljs-variable"><span class="koboSpan" id="kobo.988.1">self</span></span><span class="koboSpan" id="kobo.989.1">.vectorizer.fit_transform(records)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.990.1">The retrieve method directs the query to the appropriate search method:</span></p>
    <pre class="programlisting code"><code class="hljs-code">    <span class="hljs-keyword"><span class="koboSpan" id="kobo.991.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.992.1">retrieve</span></span><span class="koboSpan" id="kobo.993.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.994.1">self, query</span></span><span class="koboSpan" id="kobo.995.1">):
        </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.996.1">if</span></span> <span class="hljs-variable"><span class="koboSpan" id="kobo.997.1">self</span></span><span class="koboSpan" id="kobo.998.1">.method == </span><span class="hljs-string"><span class="koboSpan" id="kobo.999.1">'keyword'</span></span><span class="koboSpan" id="kobo.1000.1">:
            </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1001.1">return</span></span> <span class="hljs-variable"><span class="koboSpan" id="kobo.1002.1">self</span></span><span class="koboSpan" id="kobo.1003.1">.keyword_search(query)
        </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1004.1">elif</span></span> <span class="hljs-variable"><span class="koboSpan" id="kobo.1005.1">self</span></span><span class="koboSpan" id="kobo.1006.1">.method == </span><span class="hljs-string"><span class="koboSpan" id="kobo.1007.1">'vector'</span></span><span class="koboSpan" id="kobo.1008.1">:
            </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1009.1">return</span></span> <span class="hljs-variable"><span class="koboSpan" id="kobo.1010.1">self</span></span><span class="koboSpan" id="kobo.1011.1">.vector_search(query)
        </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1012.1">elif</span></span> <span class="hljs-variable"><span class="koboSpan" id="kobo.1013.1">self</span></span><span class="koboSpan" id="kobo.1014.1">.method == </span><span class="hljs-string"><span class="koboSpan" id="kobo.1015.1">'indexed'</span></span><span class="koboSpan" id="kobo.1016.1">:
            </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1017.1">return</span></span> <span class="hljs-variable"><span class="koboSpan" id="kobo.1018.1">self</span></span><span class="koboSpan" id="kobo.1019.1">.indexed_search(query)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.1020.1">The keyword search method finds the best match by counting common keywords between queries and documents:</span></p>
    <pre class="programlisting code"><code class="hljs-code">    <span class="hljs-keyword"><span class="koboSpan" id="kobo.1021.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.1022.1">keyword_search</span></span><span class="koboSpan" id="kobo.1023.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.1024.1">self, query</span></span><span class="koboSpan" id="kobo.1025.1">):
        best_score = </span><span class="hljs-number"><span class="koboSpan" id="kobo.1026.1">0</span></span><span class="koboSpan" id="kobo.1027.1">
        best_record = </span><span class="hljs-literal"><span class="koboSpan" id="kobo.1028.1">None</span></span><span class="koboSpan" id="kobo.1029.1">
        query_keywords = </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.1030.1">set</span></span><span class="koboSpan" id="kobo.1031.1">(query.lower().split())
        </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1032.1">for</span></span><span class="koboSpan" id="kobo.1033.1"> index, doc </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1034.1">in</span></span> <span class="hljs-built_in"><span class="koboSpan" id="kobo.1035.1">enumerate</span></span><span class="koboSpan" id="kobo.1036.1">(</span><span class="hljs-variable"><span class="koboSpan" id="kobo.1037.1">self</span></span><span class="koboSpan" id="kobo.1038.1">.documents):
            doc_keywords = </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.1039.1">set</span></span><span class="koboSpan" id="kobo.1040.1">(doc.lower().split())
            common_keywords = query_keywords.intersection(doc_keywords)
            score = </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.1041.1">len</span></span><span class="koboSpan" id="kobo.1042.1">(common_keywords)
            </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1043.1">if</span></span><span class="koboSpan" id="kobo.1044.1"> score &gt; best_score:
                best_score = score
                best_record = </span><span class="hljs-variable"><span class="koboSpan" id="kobo.1045.1">self</span></span><span class="koboSpan" id="kobo.1046.1">.documents[index]
        </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1047.1">return</span></span><span class="koboSpan" id="kobo.1048.1"> best_record
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.1049.1">The vector search method</span><a id="_idIndexMarker086"/><span class="koboSpan" id="kobo.1050.1"> computes similarities between query TF-IDF and document matrix and returns the best match:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.1051.1">    def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.1052.1">vector_search</span></span><span class="koboSpan" id="kobo.1053.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.1054.1">self, query</span></span><span class="koboSpan" id="kobo.1055.1">):
        query_tfidf = </span><span class="hljs-variable"><span class="koboSpan" id="kobo.1056.1">self</span></span><span class="koboSpan" id="kobo.1057.1">.vectorizer.transform([query])
        similarities = cosine_similarity(query_tfidf, </span><span class="hljs-variable"><span class="koboSpan" id="kobo.1058.1">self</span></span><span class="koboSpan" id="kobo.1059.1">.tfidf_matrix)
        best_index = similarities.argmax()
        </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1060.1">return</span></span><span class="koboSpan" id="kobo.1061.1"> db_records[best_index]
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.1062.1">The indexed search method uses a precomputed TF-IDF matrix for fast retrieval of the best-matching document:</span></p>
    <pre class="programlisting code"><code class="hljs-code">    <span class="hljs-keyword"><span class="koboSpan" id="kobo.1063.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.1064.1">indexed_search</span></span><span class="koboSpan" id="kobo.1065.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.1066.1">self, query</span></span><span class="koboSpan" id="kobo.1067.1">):
        </span><span class="hljs-comment"><span class="koboSpan" id="kobo.1068.1"># Assuming the tfidf_matrix is precomputed and stored</span></span><span class="koboSpan" id="kobo.1069.1">
        query_tfidf = </span><span class="hljs-variable"><span class="koboSpan" id="kobo.1070.1">self</span></span><span class="koboSpan" id="kobo.1071.1">.vectorizer.transform([query])
        similarities = cosine_similarity(query_tfidf, </span><span class="hljs-variable"><span class="koboSpan" id="kobo.1072.1">self</span></span><span class="koboSpan" id="kobo.1073.1">.tfidf_matrix)
        best_index = similarities.argmax()
        </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1074.1">return</span></span><span class="koboSpan" id="kobo.1075.1"> db_records[best_index]
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.1076.1">We can now activate modular RAG strategies.</span></p>
    <h4 class="heading-4"><span class="koboSpan" id="kobo.1077.1">Modular RAG strategies</span></h4>
    <p class="normal"><span class="koboSpan" id="kobo.1078.1">We can call the retrieval component for </span><a id="_idIndexMarker087"/><span class="koboSpan" id="kobo.1079.1">any RAG configuration we wish when needed:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.1080.1"># Usage example</span></span><span class="koboSpan" id="kobo.1081.1">
retrieval = RetrievalComponent(method=</span><span class="hljs-string"><span class="koboSpan" id="kobo.1082.1">'vector'</span></span><span class="koboSpan" id="kobo.1083.1">)  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.1084.1"># Choose from 'keyword', 'vector', 'indexed'</span></span><span class="koboSpan" id="kobo.1085.1">
retrieval.fit(db_records)
best_matching_record = retrieval.retrieve(query)
print_formatted_response(best_matching_record)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.1086.1">In this case, the vector search method was activated.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.1087.1">The following cells select the </span><a id="_idIndexMarker088"/><span class="koboSpan" id="kobo.1088.1">best record, as in the </span><em class="italic"><span class="koboSpan" id="kobo.1089.1">3.1. </span><span class="koboSpan" id="kobo.1089.2">Vector search</span></em><span class="koboSpan" id="kobo.1090.1"> section, augment the input, call the generative model, and display the output as shown in the following excerpt:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.1091.1">Response:
---------------
Certainly! </span><span class="koboSpan" id="kobo.1091.2">Let's break down and elaborate on the content provided:  ---
**Define a RAG store:**  A **RAG (Retrieval-Augmented Generation) store** is a specialized type of data storage system designed to support the retrieval and generation of information...
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.1092.1">We have built a program that demonstrated how different search methodologies—keyword, vector, and index-based—can be effectively integrated into a RAG system. </span><span class="koboSpan" id="kobo.1092.2">Each method has its unique strengths and addresses specific needs within a data retrieval context. </span><span class="koboSpan" id="kobo.1092.3">The choice of method depends on the dataset size, query type, and performance requirements, which we will explore in the following chapters.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.1093.1">It’s now time to summarize our explorations in this chapter and move to the next level!</span></p>
    <h1 id="_idParaDest-45" class="heading-1"><span class="koboSpan" id="kobo.1094.1">Summary</span></h1>
    <p class="normal"><span class="koboSpan" id="kobo.1095.1">RAG for generative AI relies on two main components: a retriever and a generator. </span><span class="koboSpan" id="kobo.1095.2">The retriever processes data and defines a search method, such as fetching labeled documents with keywords—the generator’s input, an LLM, benefits from augmented information when producing sequences. </span><span class="koboSpan" id="kobo.1095.3">We went through the three main configurations of the RAG framework: naïve RAG, which accesses datasets through keywords and other entry-level search methods; advanced RAG, which introduces embeddings and indexes to improve the search methods; and modular RAG, which can combine naïve and advanced RAG as well as other ML methods.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.1096.1">The RAG framework relies on datasets that can contain dynamic data. </span><span class="koboSpan" id="kobo.1096.2">A generative AI model relies on parametric data through its weights. </span><span class="koboSpan" id="kobo.1096.3">These two approaches are not mutually exclusive. </span><span class="koboSpan" id="kobo.1096.4">If the RAG datasets become too cumbersome, fine-tuning can prove useful. </span><span class="koboSpan" id="kobo.1096.5">When fine-tuned models cannot respond to everyday information, RAG can come in handy. </span><span class="koboSpan" id="kobo.1096.6">RAG frameworks also rely heavily on the ecosystem that provides the critical functionality to make the systems work. </span><span class="koboSpan" id="kobo.1096.7">We went through the main components of the RAG ecosystem, from the retriever to the generator, for which the trainer is necessary, and the evaluator. </span><span class="koboSpan" id="kobo.1096.8">Finally, we built an entry-level naïve, advanced, and modular RAG program in Python, leveraging keyword matching, vector search, and index-based retrieval, augmenting the input of GPT-4o.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.1097.1">Our next step in </span><em class="chapterRef"><span class="koboSpan" id="kobo.1098.1">Chapter 2</span></em><span class="koboSpan" id="kobo.1099.1">, </span><em class="italic"><span class="koboSpan" id="kobo.1100.1">RAG Embedding Vector Stores with Deep Lake and OpenAI</span></em><span class="koboSpan" id="kobo.1101.1">, is to embed data in vectors. </span><span class="koboSpan" id="kobo.1101.2">We will store the vectors in vector stores to enhance the speed and precision of the retrieval functions of a RAG ecosystem.</span></p>
    <h1 id="_idParaDest-46" class="heading-1"><span class="koboSpan" id="kobo.1102.1">Questions</span></h1>
    <p class="normal"><span class="koboSpan" id="kobo.1103.1">Answer the following questions with </span><em class="italic"><span class="koboSpan" id="kobo.1104.1">Yes</span></em><span class="koboSpan" id="kobo.1105.1"> or </span><em class="italic"><span class="koboSpan" id="kobo.1106.1">No</span></em><span class="koboSpan" id="kobo.1107.1">:</span></p>
    <ol>
      <li class="numberedList" value="1"><span class="koboSpan" id="kobo.1108.1">Is RAG designed to improve the accuracy of generative AI models?</span></li>
      <li class="numberedList"><span class="koboSpan" id="kobo.1109.1">Does a naïve RAG configuration rely on complex data embedding?</span></li>
      <li class="numberedList"><span class="koboSpan" id="kobo.1110.1">Is fine-tuning always a better option than using RAG?</span></li>
      <li class="numberedList"><span class="koboSpan" id="kobo.1111.1">Does RAG retrieve data from external sources in real time to enhance responses?</span></li>
      <li class="numberedList"><span class="koboSpan" id="kobo.1112.1">Can RAG be applied only to text-based data?</span></li>
      <li class="numberedList"><span class="koboSpan" id="kobo.1113.1">Is the retrieval process in RAG triggered by a user or automated input? </span></li>
      <li class="numberedList"><span class="koboSpan" id="kobo.1114.1">Are cosine similarity and TF-IDF both metrics used in advanced RAG configurations?</span></li>
      <li class="numberedList"><span class="koboSpan" id="kobo.1115.1">Does the RAG ecosystem include only data collection and generation components?</span></li>
      <li class="numberedList"><span class="koboSpan" id="kobo.1116.1">Can advanced RAG configurations process multimodal data such as images and audio?</span></li>
      <li class="numberedList"><span class="koboSpan" id="kobo.1117.1">Is human feedback irrelevant in evaluating RAG systems?</span></li>
    </ol>
    <h1 id="_idParaDest-47" class="heading-1"><span class="koboSpan" id="kobo.1118.1">References</span></h1>
    <ul>
      <li class="bulletList"><em class="italic"><span class="koboSpan" id="kobo.1119.1">Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks</span></em><span class="koboSpan" id="kobo.1120.1"> by Patrick Lewis, Ethan Perez, Aleksandra Piktus, et al.: </span><a href="https://arxiv.org/abs/2005.11401"><span class="url"><span class="koboSpan" id="kobo.1121.1">https://arxiv.org/abs/2005.11401</span></span></a></li>
      <li class="bulletList"><em class="italic"><span class="koboSpan" id="kobo.1122.1">Retrieval-Augmented Generation for Large Language Models: A Survey</span></em><span class="koboSpan" id="kobo.1123.1"> by Yunfan Gao, Yun Xiong, Xinyu Gao, et al.: </span><a href="https://arxiv.org/abs/2312.10997"><span class="url"><span class="koboSpan" id="kobo.1124.1">https://arxiv.org/abs/2312.10997</span></span></a></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.1125.1">OpenAI models: </span><a href="https://platform.openai.com/docs/models"><span class="url"><span class="koboSpan" id="kobo.1126.1">https://platform.openai.com/docs/models</span></span></a></li>
    </ul>
    <h1 id="_idParaDest-48" class="heading-1"><span class="koboSpan" id="kobo.1127.1">Further reading</span></h1>
    <ul>
      <li class="bulletList"><span class="koboSpan" id="kobo.1128.1">To understand why RAG-driven Generative AI transparency is recommended, please see </span><a href="https://hai.stanford.edu/news/introducing-foundation-model-transparency-index"><span class="url"><span class="koboSpan" id="kobo.1129.1">https://hai.stanford.edu/news/introducing-foundation-model-transparency-index</span></span></a></li>
    </ul>
    <h1 id="_idParaDest-49" class="heading-1"><span class="koboSpan" id="kobo.1130.1">Join our community on Discord</span></h1>
    <p class="normal"><span class="koboSpan" id="kobo.1131.1">Join our community’s Discord space for discussions with the author and other readers:</span></p>
    <p class="normal"><a href="https://www.packt.link/rag"><span class="url"><span class="koboSpan" id="kobo.1132.1">https://www.packt.link/rag</span></span></a></p>
    <p class="normal"><span class="koboSpan" id="kobo.1133.1"><img src="../Images/QR_Code50409000288080484.png" alt=""/></span></p>
  </div>
</body></html>