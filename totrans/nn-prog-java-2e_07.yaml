- en: Chapter 7. Clustering Customer Profiles
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'One of the amazing capabilities of neural networks applying unsupervised learning
    is their ability to find hidden patterns which even experts may not have any clue
    about. In this chapter, we''re going to explore this fascinating feature through
    a practical application to find customer and product clusters provided in transactions
    database. We''ll go through a review on unsupervised learning and the clustering
    task. To demonstrate this application, the reader will be provided with a practical
    example on customer profiling and it''s implementation in Java. The topics of
    this chapter are:'
  prefs: []
  type: TYPE_NORMAL
- en: Clustering tasks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cluster analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cluster evaluation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applied unsupervised learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Radial basis functions neural network
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kohonen network for clustering
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Handling with types of data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Customer profiling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Preprocessing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementation in Java
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Credit analysis and profiles of customers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Clustering tasks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Clustering is part of a broader set of tasks in data analysis, whose objective
    is to group elements that look alike, more similar to each other, into clusters
    or groups. Clustering tasks are fully based on unsupervised learning since there
    is no need to include any target output data in order to find clusters; instead,
    the solution designer may choose a number of clusters that they want to group
    the records into and check the response of the algorithm to it.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Clustering tasks may seem to overlap with classification tasks with the crucial
    difference that in clustering there is no need to have a predefined set of classes
    before the clustering algorithm is run.
  prefs: []
  type: TYPE_NORMAL
- en: 'One may wish to apply clustering when there is little or no information at
    all about how the data can be gathered into groups. Provided with dataset, we
    wish our neural network to identify both the groups and their members. While this
    may seem easy and straightforward to perform visually in a two-dimensional dataset,
    as shown in the following figure, with a higher number of dimensions, this task
    becomes not so trivial to perform and needs an algorithmic solution:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Clustering tasks](img/B05964_07_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In clustering, the number of clusters is not determined by the data, but by
    the data analyst who is looking to cluster the data. Here the *boundaries* are
    a little bit different than those of classification tasks because they depend
    primarily on the number of clusters.
  prefs: []
  type: TYPE_NORMAL
- en: Cluster analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One difficulty in the clustering tasks, and also in unsupervised learning tasks,
    is the accurate interpretation of the results. While in supervised learning there
    is a defined target, from which we can derive an error measure or confusion matrix,
    in unsupervised learning the evaluation of quality is totally different, and also
    totally dependent on the data itself. The validation criteria involves indexes
    that assert how well the data distributed across the clusters is, as well as external
    opinions from experts on the data that are also a measure of quality.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To illustrate an example, let's suppose a task of clustering of plants given
    their characteristics (sizes, leave colors, period of fruiting, and so on), and
    a neural network mistakenly groups cactus with pine trees in the same cluster.
    A botanist would certainly not endorse the classification based on their specific
    knowledge on the field that this grouping does not make any sense.
  prefs: []
  type: TYPE_NORMAL
- en: Two major issues happen in clustering. One is the fact that one neural network's
    output is never activated, meaning that one cluster does not have any data point
    associated with it. Another one is the case of nonlinear or sparse clusters, which
    could be erroneously grouped into several clusters while actually there might
    be only one.
  prefs: []
  type: TYPE_NORMAL
- en: '![Cluster analysis](img/B05964_07_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Cluster evaluation and validation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Unfortunately, if the neural network clusters badly, one needs either to redefine
    the number of clusters or perform additional data preprocessing. To evaluate how
    well the clustered data is, the Davies-Bouldin and Dunn indexes may be applied.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Davies-Boudin index takes into account the cluster''s centroids in order
    to find inter and intra-distances between clusters and cluster members:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Cluster evaluation and validation](img/B05964_07_02_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Where *n* is the number of clusters, ci is the centroid of cluster i, σi is
    the average distance of all elements in cluster *i*, and d(ci,cj) is the distance
    between clusters *i* and *j*. The smaller the value of DB index, the better the
    neural network will be considered to the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, for dense and sparse clusters, the DB index will not give much useful
    information. This limitation can be overcome with the Dunn index:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Cluster evaluation and validation](img/B05964_07_02_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Where *d(i,j)* is the inter cluster distance between *i* and *j*, and *d'(k)*
    is the intra cluster distance of cluster *k*. Here the higher the Dunn index is,
    the better the clustering will be because although the clusters may be sparse,
    they still need to be grouped together, and high intra-cluster distances will
    denote a bad grouping of data.
  prefs: []
  type: TYPE_NORMAL
- en: Implementation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the `CompetitiveLearning` class, we are going to implement these indexes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: External validation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In some cases, there is already an expected result for clustering, as in the
    example of plants clustering. This is called external validation. One may apply
    a neural network with unsupervised learning to cluster data that is already assigned
    a value. The major difference against the classification lies in the fact that
    the target outputs are not considered, so the algorithm itself is expected to
    draw a borderline based only on the data.
  prefs: []
  type: TYPE_NORMAL
- en: Applied unsupervised learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In neural networks, there are a number of architectures implementing unsupervised
    learning; however, the scope of this book will cover only the Kohonen neural network,
    developed in [Chapter 4](ch04.xhtml "Chapter 4. Self-Organizing Maps"), *Self-Organizing
    Maps*.
  prefs: []
  type: TYPE_NORMAL
- en: Kohonen neural network
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Kohonen Networks, which have been covered in [Chapter 4](ch04.xhtml "Chapter 4. Self-Organizing
    Maps"), *Self-Organizing Maps* are now used in a modified fashion. Kohonen can
    produce a shape in one or two dimensions at the output, but here we are interested
    in clustering, which can be reduced in only one dimension.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Actually the Kohonen neural network implemented in this framework considers
    the dimensions zero, one, and two, where zero means no connections between the
    output neurons and one means they form a line, and two means a grid. For this
    chapter's example, we will need a Kohonen network with no connected output neurons,
    therefore, the dimension will be zero.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition, clusters may be related or not to each other, so the vicinity
    of neurons can be ignored for now in this chapter, which means only one neuron
    will be activated and their neighbors will remain unchanged. And so, the neural
    network will adjust its weights to match data to an array of clusters:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Kohonen neural network](img/B05964_07_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The training algorithm will be the competitive learning, whereby the neuron
    with the greatest output has its weights adjusted. By the end of training, all
    the clusters of a neural network are expected to be defined. Note that there are
    no links between output neurons, meaning that only one input is active at the
    output.
  prefs: []
  type: TYPE_NORMAL
- en: Profiling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the interesting tasks in unsupervised learning is the profiling or clustering
    of information, in this chapter, customers and products. Given one dataset, one
    wants to find groups of records that share similar characteristics. Examples are
    customers that buy the same products or products that are usually bought together.
    This task results in a number of benefits for business owners because they are
    provided the information on which groups of customers and products they have,
    whereby they are enabled to address them more accurately.
  prefs: []
  type: TYPE_NORMAL
- en: Pre-processing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As seen in [Chapter 6](ch06.xhtml "Chapter 6. Classifying Disease Diagnosis"),
    *Classifying Disease Diagnosis* transactional databases can contain both numerical
    and categorical data. Whenever we face a categorical unscaled variable, we need
    to split it into the number of values the variable may take, using the `CategoricalDataSet`
    class. For example, let''s suppose we have the following transaction list of customer
    purchases:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Transaction ID | Customer ID | Products | Discount | Total |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1399 | 56 | Milk, Bread, Butter | 0.00 | 4.30 |'
  prefs: []
  type: TYPE_TB
- en: '| 1400 | 991 | Cheese, Milk | 2.30 | 5.60 |'
  prefs: []
  type: TYPE_TB
- en: '| 1401 | 406 | Bread, Sausage | 0.00 | 8.80 |'
  prefs: []
  type: TYPE_TB
- en: '| 1402 | 239 | Chipotle Sauce, Spice | 0.00 | 6.70 |'
  prefs: []
  type: TYPE_TB
- en: '| 1403 | 33 | Turkey | 0.00 | 4.50 |'
  prefs: []
  type: TYPE_TB
- en: '| 1404 | 406 | Turkey, Butter, Spice | 1.00 | 9.00 |'
  prefs: []
  type: TYPE_TB
- en: 'It can easily be seen that the products are unscaled categorical data and for
    each transaction there is an undefined number of products purchased, the customer
    may purchase one or several. In order to transform that dataset into a numerical
    dataset, preprocessing is needed. For each product there will be a variable added
    to the dataset, resulting in the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Cust. Id | Milk | Bread | Butter | Cheese | Sausage | Chipotle Sauce | Spice
    | Turkey |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 56 | 1 | 1 | 1 | 0 | 0 | 0 | 0 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 991 | 1 | 0 | 0 | 1 | 0 | 0 | 0 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 406 | 0 | 1 | 1 | 0 | 1 | 0 | 1 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 239 | 0 | 0 | 0 | 0 | 0 | 1 | 1 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 33 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: In order to save space, we ignored the numerical variables and considered the
    presence of the product purchased by a client as *1* and the absence as *0*. Alternative
    preprocessing may consider the number of occurrences of a value, therefore becoming
    no longer binary, but discrete.
  prefs: []
  type: TYPE_NORMAL
- en: Implementation in Java
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this chapter, we are going to explore the usage of Kohonen neural network
    applied to customer clustering based on customer information collected from Proben1
    (Card dataset).
  prefs: []
  type: TYPE_NORMAL
- en: Card – credit analysis for customer profiling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The card dataset is composed of 16 variables in total. 15 are inputs and one
    is output. For security reasons, all variable names have been changed to meaningless
    symbols. This dataset brings a good mix of variable types (continuous, categorical
    with small numbers of values, and categorical with a larger number of values).
    The following table shows a summary of data:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Variable | Type | Values |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| V1 | OUTPUT | 0; 1 |'
  prefs: []
  type: TYPE_TB
- en: '| V2 | INPUT #1 | b, a |'
  prefs: []
  type: TYPE_TB
- en: '| V3 | INPUT #2 | continuous |'
  prefs: []
  type: TYPE_TB
- en: '| V4 | INPUT #3 | continuous |'
  prefs: []
  type: TYPE_TB
- en: '| V5 | INPUT #4 | u, y, l, t. |'
  prefs: []
  type: TYPE_TB
- en: '| V6 | INPUT #5 | g, p, gg |'
  prefs: []
  type: TYPE_TB
- en: '| V7 | INPUT #6 | c, d, cc, i, j, k, m, r, q, w, x, e, aa, ff |'
  prefs: []
  type: TYPE_TB
- en: '| V8 | INPUT #7 | v, h, bb, j, n, z, dd, ff, o |'
  prefs: []
  type: TYPE_TB
- en: '| V9 | INPUT #8 | continuous |'
  prefs: []
  type: TYPE_TB
- en: '| V10 | INPUT #9 | t, f |'
  prefs: []
  type: TYPE_TB
- en: '| V11 | INPUT #10 | t, f |'
  prefs: []
  type: TYPE_TB
- en: '| V12 | INPUT #11 | continuous |'
  prefs: []
  type: TYPE_TB
- en: '| V13 | INPUT #12 | t, f |'
  prefs: []
  type: TYPE_TB
- en: '| V14 | INPUT #13 | g, p, s |'
  prefs: []
  type: TYPE_TB
- en: '| V15 | INPUT #14 | continuous |'
  prefs: []
  type: TYPE_TB
- en: '| V16 | INPUT #15 | continuous |'
  prefs: []
  type: TYPE_TB
- en: 'For simplicity we didn''t use the inputs *v5-v8* and *v14*, in order to not
    inflate the number of inputs very much. We applied the following transformation:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Variable | Type | Values | Conversion |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| V1 | OUTPUT | 0; 1 | - |'
  prefs: []
  type: TYPE_TB
- en: '| V2 | INPUT #1 | b, a | b = 1, a = 0 |'
  prefs: []
  type: TYPE_TB
- en: '| V3 | INPUT #2 | continuous | - |'
  prefs: []
  type: TYPE_TB
- en: '| V4 | INPUT #3 | continuous | - |'
  prefs: []
  type: TYPE_TB
- en: '| V9 | INPUT #8 | continuous | - |'
  prefs: []
  type: TYPE_TB
- en: '| V10 | INPUT #9 | t, f | t = 1, f = 0 |'
  prefs: []
  type: TYPE_TB
- en: '| V11 | INPUT #10 | t, f | t = 1, f = 0 |'
  prefs: []
  type: TYPE_TB
- en: '| V12 | INPUT #11 | continuous | - |'
  prefs: []
  type: TYPE_TB
- en: '| V13 | INPUT #12 | t, f | t = 1, f = 0 |'
  prefs: []
  type: TYPE_TB
- en: '| V15 | INPUT #14 | continuous | - |'
  prefs: []
  type: TYPE_TB
- en: '| V16 | INPUT #15 | continuous | - |'
  prefs: []
  type: TYPE_TB
- en: 'The neural net topology proposed is shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Card – credit analysis for customer profiling](img/B05964_07_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The number of examples stored is 690, but 37 of them have missing values. These
    37 records were discarded. Therefore, 653 examples were used to train and test
    the neural network. The dataset division was made as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Training**: 583 records'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Test**: 70 records'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The Kohonen training algorithm used to cluster similar behavior depends on
    some parameters, such as:'
  prefs: []
  type: TYPE_NORMAL
- en: Normalization type
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learning rate
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is important to consider that the Kohonen training algorithm is unsupervised.
    So, this algorithm is used when the output is not known. In the card example there
    are output values in the dataset and they will be used here only to attest clustering.
    But in traditional clustering cases, the output values are not available.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this specific case, because output is known, as classification, the clustering
    quality may be attested by:'
  prefs: []
  type: TYPE_NORMAL
- en: Sensibility (true positive rate)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Specificity (true negative rate)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Total accuracy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In Java projects, the calculations of these values are done through a class
    named `NeuralOutputData`, previously developed in [Chapter 6](ch06.xhtml "Chapter 6. Classifying
    Disease Diagnosis"), *Classifying Disease Diagnosis*.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is good practice to do many experiments to try to find the best neural net
    to cluster customers'' profiles. Ten different experiments will be generated and
    each will be analyzed with the quality rates mentioned previously. The following
    table summarizes the strategy that will be followed:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Experiment | Learning rate | Normalization type |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| #1 | 0.1 | MIN_MAX |'
  prefs: []
  type: TYPE_TB
- en: '| #2 | Z_SCORE |'
  prefs: []
  type: TYPE_TB
- en: '| #3 | 0.3 | MIN_MAX |'
  prefs: []
  type: TYPE_TB
- en: '| #4 | Z_SCORE |'
  prefs: []
  type: TYPE_TB
- en: '| #5 | 0.5 | MIN_MAX |'
  prefs: []
  type: TYPE_TB
- en: '| #6 | Z_SCORE |'
  prefs: []
  type: TYPE_TB
- en: '| #7 | 0.7 | MIN_MAX |'
  prefs: []
  type: TYPE_TB
- en: '| #8 | Z_SCORE |'
  prefs: []
  type: TYPE_TB
- en: '| #9 | 0.9 | MIN_MAX |'
  prefs: []
  type: TYPE_TB
- en: '| #10 | Z_SCORE |'
  prefs: []
  type: TYPE_TB
- en: The `ClusterExamples` class was created to run each experiment. In addition
    to processing data in [Chapter 4](ch04.xhtml "Chapter 4. Self-Organizing Maps"),
    *Self-Organizing Maps* it was also explained how to create a Kohonen net and how
    to train it via the Euclidian distance algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following piece of code shows a bit of its implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'After running each experiment using the `ClusteringExamples` class and saving
    the confusion matrix and total accuracy rates, it is possible to observe that
    experiments #4, #6, #8, and #10 have the same confusion matrix and accuracy. These
    experiments used z-score to normalize data:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Experiment | Confusion matrix | Total accuracy |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| #1 | [[14.0, 21.0][18.0, 17.0]] | 44.28% |'
  prefs: []
  type: TYPE_TB
- en: '| #2 | [[11.0, 24.0][34.0, 1.0]] | 17.14% |'
  prefs: []
  type: TYPE_TB
- en: '| #3 | [[21.0, 14.0][17.0, 18.0]] | 55.71% |'
  prefs: []
  type: TYPE_TB
- en: '| #4 | [[24.0, 11.0][1.0, 34.0]] | 82.85% |'
  prefs: []
  type: TYPE_TB
- en: '| #5 | [[21.0, 14.0][17.0, 18.0]] | 55.71% |'
  prefs: []
  type: TYPE_TB
- en: '| #6 | [[24.0, 11.0][1.0, 34.0]] | 82.85% |'
  prefs: []
  type: TYPE_TB
- en: '| #7 | [[8.0, 27.0][7.0, 28.0]] | 51.42% |'
  prefs: []
  type: TYPE_TB
- en: '| #8 | [[24.0, 11.0][1.0, 34.0]] | 82.85% |'
  prefs: []
  type: TYPE_TB
- en: '| #9 | [[27.0, 8.0][28.0, 7.0]] | 48.57% |'
  prefs: []
  type: TYPE_TB
- en: '| #10 | [[24.0, 11.0][1.0, 34.0]] | 82.85% |'
  prefs: []
  type: TYPE_TB
- en: 'So, neural nets built by experiments #4, #6, #8, or #10 may be used to reach
    accuracy more than 80% to cluster customers financially.'
  prefs: []
  type: TYPE_NORMAL
- en: Product profiling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Using a transactional database provided with the code, we''ve compiled about
    650 purchase transactions into a big matrix transactions *x* products, where in
    each cell there is the quantity of the corresponding product that has been bought
    on the corresponding transaction:'
  prefs: []
  type: TYPE_NORMAL
- en: '| #Trns. | Prd.1 | Prd.2 | Prd.3 | Prd.4 | Prd.5 | Prd.6 | Prd.7 | … | Prd.N
    |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 56 | 0 | 0 | 3 | 2 | 0 | 0 | … | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 0 | 0 | 40 | 0 | 7 | 0 | 19 | … | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| … | … | … | … | … | … | … | … | … | … |'
  prefs: []
  type: TYPE_TB
- en: '| n | 0 | 0 | 0 | 0 | 0 | 0 | 0 | … | 1 |'
  prefs: []
  type: TYPE_TB
- en: Let's consider that this matrix is a representation in an N-dimensional hyperspace
    taking each product as a dimension and the transactions as points. For simplicity,
    let's consider an example on three dimensions. A given transaction with the quantities
    bought for each product will be placed in a point corresponding to the quantities
    at each dimension.
  prefs: []
  type: TYPE_NORMAL
- en: '![Product profiling](img/B05964_07_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The idea is to cluster these transactions in order to find which products are
    usually bought together. So, we are going to use a Kohonen neural network in order
    to find the positions of the products that the clusters centers will be located
    at.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our database consists of a clothing store and a sample of 27 registered products:'
  prefs: []
  type: TYPE_NORMAL
- en: '| 1 Long Dress A | 19 Overall with zipper | 43 Bermuda M |'
  prefs: []
  type: TYPE_TB
- en: '| 3 Long Dress B | 22 Shoulder overall | 48 Stripped skirt |'
  prefs: []
  type: TYPE_TB
- en: '| 7 Short Dress A | 23 Long stamped skirt | 67 Camisole shoulder strap |'
  prefs: []
  type: TYPE_TB
- en: '| 8 Stamped Dress | 24 Stamped short dress | 68 Jeans M |'
  prefs: []
  type: TYPE_TB
- en: '| 9 Women Camisole | 28 Pants M | 69 XL Short dress |'
  prefs: []
  type: TYPE_TB
- en: '| 13 Pants S | 31 Sleeveless short dress | 74 Stripped camisole S |'
  prefs: []
  type: TYPE_TB
- en: '| 16 Overall for children | 32 Short dress shoulder | 75 Stripped camisole
    M |'
  prefs: []
  type: TYPE_TB
- en: '| 17 Shorts | 34 Short dress B | 76 Stripped camisole L |'
  prefs: []
  type: TYPE_TB
- en: '| 18 Stamped overall | 42 Two blouse overall | 106 Straight skirt |'
  prefs: []
  type: TYPE_TB
- en: How many clusters?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Sometimes it may be difficult to choose how many clusters to find in a clustering
    algorithm. Some approaches to determine an optimal choice include information
    criteria such as **Akaike Information Criteria** (**AIC**), **Bayesian Information
    Criteria** (**BIC**), and the Mahalanobis distance from the center to the data.
    We suggest to the reader to check the references if interested in further details
    on these criteria.
  prefs: []
  type: TYPE_NORMAL
- en: 'To make tests to product example, we also should use the `ClusteringExamples`
    class. For simplicity, we run tests with three and five clusters. For each experiment,
    the number of epochs was *1000*, the learning rate was *0.5*, and the normalization
    type was `MIN_MAX (-1; 1)`. Some results are shown in the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Number of clusters | Clusters of the first 15 elements | Sum of products
    bought |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | 0, 1, 2, 2, 2,2, 2, 2, 2, 2,2, 2, 0, 0, 2, | 973, 585, 11, 5, 2,4, 11,
    6, 3, 2,2, 2, 669, 672, 7, |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | 0, 1, 4, 4, 4,4, 4, 4, 4, 4,4, 4, 0, 0, 4, | 973, 585, 11, 5, 2,4, 11,
    6, 3, 2,2, 2, 669, 672, 7, |'
  prefs: []
  type: TYPE_TB
- en: Observing the preceding table, we note when the sum of products acquired is
    more than 600, then it's clustered together. Otherwise, when the sum is in the
    range of 500 to 599, another cluster is formed. Lastly, if the sum is low, a large
    cluster is created, because the dataset is compound by many cases that customers
    doesn't by more than 20 items.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As recommend in the previous chapter, we suggest you explore the `ClusteringExamples`
    class and create a GUI to easily select the neural net parameters. You should
    try to reuse code through the inheritance concept.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another tip is to further explore the product profiling example: varying the
    neural network training parameters, the number of clusters, and/or develop others
    ways of analyzing the clustering result.'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we've an application of customer profiling using the Kohonen
    neural network. Unlike the classification task, the clustering task does not consider
    the previous knowledge on the desired output; instead it is desirable for the
    clusters to be found by the neural network. However, we've seen that validation
    techniques may include external validation, which is a comparison with what could
    be understood as *target output*. Customer profiling is important because it gives
    a business owner more accurate and clean information about their customers, without
    the *human interference* in pointing which customers are in some groups or in
    others, as occurs in supervised learning. That's the advantage of unsupervised
    learning, enabling the data to draw results solely by themselves.
  prefs: []
  type: TYPE_NORMAL
