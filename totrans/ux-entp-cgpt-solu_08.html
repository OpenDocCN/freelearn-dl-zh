<html><head></head><body>
		<div><h1 id="_idParaDest-132" class="chapter-number"><a id="_idTextAnchor134" class="pcalibre pcalibre1 calibre6"/>6</h1>
			<h1 id="_idParaDest-133" class="calibre5"><a id="_idTextAnchor135" class="pcalibre pcalibre1 calibre6"/>Gathering Data – Content  is King</h1>
			<p class="calibre3">There is an assumption in this book: enterprise ChatGPT solutions are needed in almost all cases because a company has something unique to offer its customers, and it possesses an exceptional understanding of its products, services, and content. This content is private <a id="_idIndexMarker355" class="pcalibre pcalibre1 calibre6"/>or unique and thus not part of <strong class="bold">large language models</strong> (<strong class="bold">LLMs</strong>) built from scraping the internet. Models are built on crawling the 2+ billion pages of web content to teach the model.  A third party, Commoncrawl.org, is commonly cited as a primary source of this material for major models (GPT-3, Llama). These models, which are massive collections of text, learn the statistical relationships of words and concepts and can be used to predict and respond to questions. Creating a model can take months; most have billions of connections and words. When customers come to the enterprise for answers, the models must include enterprise content that is not part of this crawl to make them unique, secure, and more accurate. This is done with the expectation that the solutions will be up to date, optimized to be cost-effective, and less prone to hallucinations or lying, as some call it.</p>
			<p class="calibre3">This chapter addresses gathering data for the LLM and how to include enterprise data sources in LLM solutions <a id="_idIndexMarker356" class="pcalibre pcalibre1 calibre6"/>using a method called <strong class="bold">Retrieval Augmented Generation</strong> (<strong class="bold">RAG</strong>). We’ll discuss the following topics:</p>
			<ul class="calibre7">
				<li class="calibre8">What is in a ChatGPT foundational model</li>
				<li class="calibre8">Incorporating enterprise data using RAG</li>
				<li class="calibre8">Resources for RAG</li>
			</ul>
			<p class="calibre3">This chapter and the next few will be more technical for those who have reached this point and are focused on user-centered design concepts. The chapter covers all the ideas and provides access to additional videos and online resources. The book does not require most of these external resources; they are meant to give more details.</p>
			<h1 id="_idParaDest-134" class="calibre5"><a id="_idTextAnchor136" class="pcalibre pcalibre1 calibre6"/>What is in a ChatGPT foundational model</h1>
			<p class="calibre3">When an LLM is built, it is trained on sources of data from the internet. It knows <a id="_idIndexMarker357" class="pcalibre pcalibre1 calibre6"/>publicly available information about companies and products. If asked typical enterprise-like questions, it can get robust answers – sometimes better than what is available from some vendors’ websites. For example:</p>
			<pre class="source-code">
What are the advantages of Hana for a database?
What is a good value for SGA for an Oracle 12.2 transactional database?
Can you easily replace the battery in an iPhone?
How do I return a product to Costco?</pre>			<p class="calibre3">Try these questions out and notice a trend. Each answer is slightly more generic than the previous one, and that generic nature is part of the problem.</p>
			<p class="calibre3">The following applies to most foundational models such as ChatGPT 3.5 or 4o, Anthropic’s Claude, Meta’s Llama, or Mistral7B:</p>
			<ul class="calibre7">
				<li class="calibre8">Don’t understand specific business or use context or complex products</li>
				<li class="calibre8">Don’t have customer history or context to consider</li>
				<li class="calibre8">Can’t access proprietary knowledge sources</li>
				<li class="calibre8">Are not trained on service requests or other service data and won’t know correct assumptions from incorrect assumptions and inaccurate solutions</li>
				<li class="calibre8">Can’t integrate with databases or APIs for retrieval and task performance</li>
				<li class="calibre8">Can’t be scaled or tuned for multi-tenancy</li>
			</ul>
			<p class="calibre3">Now imagine those questions if they were in the context of rich business knowledge:</p>
			<pre class="source-code">
What are the advantages of Hana for a database connecting to my service application running ServiceNow on the Washington DC release?
What is a good value for SGA for an Oracle 12.2 transactional database when connecting to EBS 13.2 with 1200 concurrent users?
How do I replace the battery in the iPhone 15 Pro?
How do I return a product from my last order to Costco that was oversized and delivered?</pre>			<p class="calibre3">Integrating data sources with ChatGPT to contextualize the solution to the business can address these richer questions. No matter the design pattern used, such as a chat UI, a hybrid experience, or a standalone recommender, enterprise data will make the solution powerful. Foundational models gain access to knowledge with Retrieval Augmented Generation or <strong class="bold">RAG</strong>.</p>
			<h1 id="_idParaDest-135" class="calibre5"><a id="_idTextAnchor137" class="pcalibre pcalibre1 calibre6"/>Incorporating enterprise data using RAG</h1>
			<p class="calibre3">There are other ways of taking data and making it part of an LLM. It is possible to build a foundation model<a id="_idIndexMarker358" class="pcalibre pcalibre1 calibre6"/>, but as mentioned, the <a id="_idIndexMarker359" class="pcalibre pcalibre1 calibre6"/>training time and effort are extreme. Even with RAG, there are different approaches. Some technical resources are shared, but this chapter will focus on and teach RAG understanding and how product people can contribute to the development process. First, a RAG explanation.</p>
			<h2 id="_idParaDest-136" class="calibre9"><a id="_idTextAnchor138" class="pcalibre pcalibre1 calibre6"/>Understanding RAG</h2>
			<p class="calibre3">RAG supplements LLMs with enterprise data. RAG is a technique for retrieving <a id="_idIndexMarker360" class="pcalibre pcalibre1 calibre6"/>information, such as from a knowledge base, and it can generate responses from authoritative knowledge collection with coherent and contextually accurate answers.</p>
			<p class="calibre3">This methodology allows us to overcome some generic model problems:</p>
			<ul class="calibre7">
				<li class="calibre8">Material is always up to date since it is evaluated when prompted.</li>
				<li class="calibre8">Tools can reference the document source and, thus, are more trustworthy.</li>
				<li class="calibre8">The foundational model is already trained, so supplementing it is inexpensive compared to building a model from scratch.</li>
				<li class="calibre8">It allows for a robust set of resources (APIs, SQL databases, and various document and presentation file formats) to continue to be managed independently (and still available to other solutions).</li>
				<li class="calibre8">It will <em class="italic">NOT</em> be used to throw <em class="italic">ALL</em> data into the LLM. A mechanism will be used to send relevant documents to the LLM just in time for processing.</li>
				<li class="calibre8">It allows for unique, secure answers with multiple customers.</li>
			</ul>
			<p class="calibre3">Technical work is needed to create a RAG pipeline. Even if this book isn’t about the development effort to create a RAG pipeline, it still stands to reason that a basic understanding of how data becomes valuable to the ChatGPT solution is needed. First,  consider what would happen <em class="italic">if</em> all the enterprise data is thrown into the LLM. It would look something like <em class="italic">Figure 6</em><em class="italic">.1</em>.</p>
			<div><div><img src="img/B21964_06_01.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.1 – A model where we add all our knowledge directly to the LLM</p>
			<p class="calibre3">The model in <em class="italic">Figure 6</em><em class="italic">.1</em> assumes it can handle all company knowledge and include it in an OpenAI model, resulting in a custom company model. This sounds right, but the cost and <em class="italic">months</em> it <a id="_idIndexMarker361" class="pcalibre pcalibre1 calibre6"/>takes to create it are very high. There needs to be a way for the LLM to access all of our resources without the cost and complexity. Let’s review some limitations to find a solution to this problem.</p>
			<h2 id="_idParaDest-137" class="calibre9"><a id="_idTextAnchor139" class="pcalibre pcalibre1 calibre6"/>Limitations of ChatGPT and RAG</h2>
			<p class="calibre3">To be clear, there are two kinds of limitations worth discussing. The first is the limitations of knowledge retrieval using OpenAI models or any models. In contrast, the <a id="_idIndexMarker362" class="pcalibre pcalibre1 calibre6"/>second is the limitations of RAG, even when integrating third-party solutions to build an enterprise RAG solution.</p>
			<p class="calibre3">Most enterprise <a id="_idIndexMarker363" class="pcalibre pcalibre1 calibre6"/>solutions will find data integration requirements within OpenAI limiting and look elsewhere for scalability, cost, and performance. With OpenAI File Search, which is their way of augmenting the LLM with knowledge, there are technical limits:</p>
			<ul class="calibre7">
				<li class="calibre8">Maximum file size of 512 MB</li>
				<li class="calibre8">A limit of 5M tokens (up from 2M in the spring of 2024)</li>
				<li class="calibre8">ChatGPT Enterprise supports a context length of 128K (up from 32K in the free version and the first Enterprise release)</li>
				<li class="calibre8">Some limits on file formats (<strong class="source-inline1">.pdf</strong>, <strong class="source-inline1">.md</strong>, <strong class="source-inline1">.docx</strong>) – the complete list is here:<ul class="calibre19"><li class="calibre8">Documentation: <a href="https://platform.openai.com/docs/assistants/tools/file-search/supported-files" class="pcalibre pcalibre1 calibre6">Supported file formats</a> (<a href="https://platform.openai.com/docs/assistants/tools/file-search/supported-files" class="pcalibre pcalibre1 calibre6">https://platform.openai.com/docs/assistants/tools/file-search/supported-files</a>)</li></ul></li>
				<li class="calibre8">Storage fees are $0.20/GB per assistant per day.</li>
			</ul>
			<p class="calibre3">These limits (as of September 2024) will change with some frequency. These limitations mean third parties are needed for solutions.</p>
			<p class="calibre3">There are also some quality limitations:</p>
			<ul class="calibre7">
				<li class="calibre8">Model data is available to everyone who has access to the model. Security barriers or limits are not implicit.</li>
				<li class="calibre8">It won’t differentiate between general knowledge and internal knowledge. There are weights and an ability to prioritize and emphasize material, but it can still hallucinate without good reason.</li>
				<li class="calibre8">When changes are made to knowledge, retraining is required and expensive. Since results need to be accurate and timely, this becomes a show-stopper.</li>
				<li class="calibre8">OpenAI’s File Search for knowledge retrieval handles one part of the process and doesn’t have the additional value of RAG around scale and data input types.</li>
				<li class="calibre8">There is a limit to how much can be shared with the LLM at one time. This is called the context window, and this chapter covers how to chunk information to fit into that context window. The larger the context window, the more knowledge and enterprise data can be shared with the LLM at one time to formulate answers. As the window grows larger, less RAG is needed to pre-fetch material. RAG is a more scalable and cost-effective approach.</li>
			</ul>
			<p class="calibre3">Third-party solutions help avoid <a id="_idIndexMarker364" class="pcalibre pcalibre1 calibre6"/>these limitations. To demo and understand <a id="_idIndexMarker365" class="pcalibre pcalibre1 calibre6"/>the space for this book, the OpenAI built-in tools will work for the small demos. However, an enterprise solution will work with a third-party app for a production instance. The knowledge gained from these chapters is relevant to any LLM.</p>
			<p class="calibre3">It is good to start with OpenAI’s built-in capabilities using the playground, so no coding is needed. No need to go to the documentation right now, but it is included anyway. This approach allows us to get a taste of custom models without the overhead required by a complete enterprise solution.</p>
			<p class="calibre3">Article: <a href="https://platform.openai.com/docs/assistants/tools/file-search/quickstart" class="pcalibre pcalibre1 calibre6">OpenAI’s File Search Documentation</a> (<a href="https://platform.openai.com/docs/assistants/tools/file-search/quickstart" class="pcalibre pcalibre1 calibre6">https://platform.openai.com/docs/assistants/tools/file-search/quickstart</a>)</p>
			<p class="calibre3">It takes significant work to go from data (this chapter) to <a href="B21964_07.xhtml#_idTextAnchor150" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 7</em></a>, <em class="italic">Prompt Engineering</em>, and then to the next steps shown in <a href="B21964_08.xhtml#_idTextAnchor172" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 8</em></a>, <em class="italic">Fine-Tuning</em> so that a solution can be reviewed with <a href="B21964_09_split_000.xhtml#_idTextAnchor190" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 9</em></a>, <em class="italic">Guidelines and Heuristics</em>, and then analyzed for success in <a href="B21964_10_split_000.xhtml#_idTextAnchor216" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 10</em></a>, <em class="italic">Monitoring and Evaluation</em>. For more resources, visit the OpenAI cookbook. It has a wealth of articles covering the entire LLM lifecycle, gives many good explanations and definitions, and lays out the process. Here is one good article.</p>
			<p class="calibre3">Article: <a href="https://cookbook.openai.com/examples/fine-tuned_qa/ft_retrieval_augmented_generation_qdrant" class="pcalibre pcalibre1 calibre6">An OpenAI cookbook article on Fine-Tuning for RAG using Qdrant</a> (<a href="https://cookbook.openai.com/examples/fine-tuned_qa/ft_retrieval_augmented_generation_qdrant" class="pcalibre pcalibre1 calibre6">https://cookbook.openai.com/examples/fine-tuned_qa/ft_retrieval_augmented_generation_qdrant</a>)</p>
			<p class="calibre3">The article is technical, but the concepts reinforce the learnings from this book. There needs to be a way to provide material to the model that doesn’t require retraining and can handle the scale of the enterprise problem. This is done by implementing a form of RAG that works off of an index of the knowledge and provides only relevant material, as needed, to the LLM. <strong class="bold">Indexing</strong> is a way <a id="_idIndexMarker366" class="pcalibre pcalibre1 calibre6"/>to organize information for fast retrieval and <a id="_idIndexMarker367" class="pcalibre pcalibre1 calibre6"/>comparison. There is not only one way to do this, but we’ll look at the basic approach to form an understanding of RAG. Some of the steps are beyond the scope of this book. Anyone reading is unlikely to build an LLM from scratch. Product people, especially those responsible for the knowledgebase or database resources, can improve the data coming into the solution to provide the indexing and LLM with the best chance of returning high-quality results. So, technology is introduced to handle the scale, performance, and quality needed. See <em class="italic">Figure 6</em><em class="italic">.2</em>. This requires us to focus on getting data into shape for indexing. In this approach, only relevant information is shared with the LLM to develop answers.</p>
			<div><div><img src="img/B21964_06_02.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.2 – Introducing the RAG solution to assist in the question-to-answer process</p>
			<p class="calibre3">This is dramatically <a id="_idIndexMarker368" class="pcalibre pcalibre1 calibre6"/>oversimplifying the process. The indexing icon shown <a id="_idIndexMarker369" class="pcalibre pcalibre1 calibre6"/>is a set of processes that result in a <em class="italic">limited</em> number of documents to share with the LLM as context for the question (this context is shared within the prompt – this prompt being the instructions shared with the LLM).  The ingestion process includes cleaning the data, converting it to text, and creating vector representations to match the question’s vector representation against the indexed resources. This indexing process organizes the data to match like to like. <strong class="bold">Vectorization</strong> is the process of converting text into numeric vectors. <strong class="bold">Embedding</strong> is the process of determining similarity and semantic relationships based on the similarities of the vectors. All of the processing and matching is based on matching these vectors.</p>
			<p class="calibre3">To simplify the concept, consider vectors as numbers with a direction, like going west for 5 miles versus going north for 12 miles. The direction and magnitude in this example are two dimensions used to match results. However, in the case of LLMs, there are thousands of dimensions. The embedding process sees that similar vectors represent words with similar meanings and usage. They are in the same area. The best matches (north-west for 4 miles is roughly similar to going west for 5 miles) are then passed to the LLM for processing with the question. This means <em class="italic">the LLM is given limited information to generate its answer</em>. This also means there is value in ensuring that the knowledge and resources are ready for this process and using tools to return knowledge related to the presented question. This doesn’t require months to train a model. All of that work was done for us. However, the foundational <a id="_idIndexMarker370" class="pcalibre pcalibre1 calibre6"/>model can be enhanced with prompt engineering and fine-tuning. <strong class="bold">Prompt engineering</strong> is the process of giving instructions to the model to tell it what to do, while <strong class="bold">fine-tuning</strong> is used <a id="_idIndexMarker371" class="pcalibre pcalibre1 calibre6"/>to provide examples of what is expected from the generative output. Both are covered in the following two chapters.</p>
			<p class="calibre3">Product owners, designers, writers, and those who care about content quality can add value to the <a id="_idIndexMarker372" class="pcalibre pcalibre1 calibre6"/>input and the output. This chapter is about input and getting quality out of data sources. The following chapters will focus on the <em class="italic">output</em> to ensure accuracy when answering.</p>
			<p class="callout-heading">Further reading on RAG</p>
			<p class="callout">There are plenty of good resources to explain RAG in more detail. Here are a few deeper dives into the subject. Let me start with Amazon’s introduction to RAG.</p>
			<p class="callout">Article: <a href="https://aws.amazon.com/what-is/retrieval-augmented-generation/" class="pcalibre pcalibre1 calibre6">Amazon’s RAG Explanation</a> (<a href="https://aws.amazon.com/what-is/retrieval-augmented-generation/" class="pcalibre pcalibre1 calibre6">https://aws.amazon.com/what-is/retrieval-augmented-generation/</a>)</p>
			<p class="callout">This one goes deeper into the issues and technical pieces of the complete solution.</p>
			<p class="callout">Article: <a href="https://www.ml6.eu/blogpost/leveraging-llms-on-your-domain-specific-knowledge-base" class="pcalibre pcalibre1 calibre6">Leveraging LLMs on your domain-specific knowledge base</a> (<a href="https://www.ml6.eu/blogpost/leveraging-llms-on-your-domain-specific-knowledge-base" class="pcalibre pcalibre1 calibre6">https://www.ml6.eu/blogpost/leveraging-llms-on-your-domain-specific-knowledge-base</a>)</p>
			<p class="callout">Databricks hosted an excellent one-hour video session. It covers prompt engineering and RAG.</p>
			<p class="callout">Video: <a href="https://vimeo.com/891439013" class="pcalibre pcalibre1 calibre6">Accelerate your Generative AI journey</a> (<a href="https://vimeo.com/891439013" class="pcalibre pcalibre1 calibre6">https://vimeo.com/891439013</a>)</p>
			<p class="callout">Finally, to go deeper, review this well-done survey of RAG techniques and methods to learn more about how RAG can be implemented. This is my favorite reference for explaining the different approaches, and the authors plan on updating the article, so it should be current.</p>
			<p class="callout">Article: <a href="https://arxiv.org/pdf/2312.10997.pdf" class="pcalibre pcalibre1 calibre6">A survey of RAG for LLMs</a> (<a href="https://arxiv.org/pdf/2312.10997.pdf" class="pcalibre pcalibre1 calibre6">https://arxiv.org/pdf/2312.10997.pdf</a>)</p>
			<p class="calibre3">By the process of elimination, there are only a few places where product people can insert themselves to help the process. Few can build an LLM from scratch, and the training data used in the base model is from billions of Internet records. There is limited ability to coach the customer on what <a id="_idIndexMarker373" class="pcalibre pcalibre1 calibre6"/>questions to ask (a good design might encourage good behavior without forcing the user to adapt, per se). Meanwhile, in recommender UIs, there is no interactive UI.</p>
			<p class="calibre3">Thus, the best value for our efforts is to target the proper use cases, create quality knowledge, and support robust access to enterprise databases and resources that will allow an LLM to generate results to achieve customer goals. Let’s build a simple demo incorporating a data source to help understand the limitations and capabilities of an LLM supplemented with private data.</p>
			<h2 id="_idParaDest-138" class="calibre9"><a id="_idTextAnchor140" class="pcalibre pcalibre1 calibre6"/>Building a demo with enterprise data</h2>
			<p class="calibre3">This is a simple example to make a point. We will start with a collection of Frequently Asked Questions (FAQs) common to almost all websites and businesses. Hundreds of FAQs that could <a id="_idIndexMarker374" class="pcalibre pcalibre1 calibre6"/>be found on any financial website (a bank or a brokerage company) form the basis of the demo. We name this financial company Alligiance (All-i… not an e, so as not to run afoul of an actual company called Allegiance). The assistant can be called “Alli” (pronounced Ally). Let’s start with a file of raw HTML snippets, answering each question in a row in a table. The file is on GitHub, so please try it yourself.</p>
			<p class="calibre3">GitHub: <a href="https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter6-Example_FAQs_for_Demo.docx" class="pcalibre pcalibre1 calibre6">FAQ Collection for Testing</a> (<a href="https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter6-Example_FAQs_for_Demo.docx" class="pcalibre pcalibre1 calibre6">https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter6-Example_FAQs_for_Demo.docx</a>)</p>
			<p class="calibre3">To access the OpenAI playground, follow the instructions in <a href="B21964_01.xhtml#_idTextAnchor016" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 1</em></a>, <em class="italic">Recognizing the Power of Design </em><em class="italic">in ChatGPT</em>.</p>
			<p class="calibre3">Demo: <a href="https://platform.openai.com/playground" class="pcalibre pcalibre1 calibre6">OpenAI Playground</a> (<a href="https://platform.openai.com/playground" class="pcalibre pcalibre1 calibre6">https://platform.openai.com/playground</a>)</p>
			<p class="calibre3">The demo starts by asking a simple, specific question about browser support that might be common for a private website application. The foundational model would not expect it to know the answer, as these <a id="_idIndexMarker375" class="pcalibre pcalibre1 calibre6"/>FAQs for a company might only be for authenticated customers. Then we uploaded the file, as shown in <em class="italic">Figure 6</em><em class="italic">.3</em>, and asked again. Play along, will you?</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">Try side-by-side comparisons: Open two browsers and run the LLM with and without the context document. There is also a compare button in the Playground. We will demonstrate the compare button later.</p>
			<div><div><img src="img/B21964_06_03.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.3 – OpenAI Playground shows an answer before and after adding the demo file</p>
			<pre>was uploaded. It reworked the content into a presentable format. The output text is bolded for easier scanning (some irrelevant text is truncated):</pre>
			<pre class="source-code">
&lt;a href="http://www.mozilla.com/en-us/firefox/ie.html" id="Link_1422297415937" name="Link_1422297415937" onclick="advancedlink('http://www.mozilla.com/en-us/firefox/ie.html','{truncated}','', 'Link_1422297415937')" target="_blank"&gt;Mozilla® Firefox&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="http://www.apple.com/safari/download/" id="Link_1421770836208" name="Link_1421770836208" onclick="advancedlink('http://www.apple.com/safari/download/','{truncated}','', 'Link_1421770836208')" target="_blank"&gt;Apple® Safari®&lt;/a&gt; (Mac operating systems only)&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt; Note:&lt;/strong&gt;<strong class="bold1"> Our latest site features will not work with older, unsupported browser versions, specifically Internet Explorer 8, Safari 4 and 5, and Netscape. Internet Explorer 9 and 10 may provide a less than optimal experience. The use of unsupported browsers may also lead to vulnerability because of viruses, spyware, malware, and other security issues.</strong>&lt;/p&gt;&lt;p&gt;</pre>			<p class="calibre3"><em class="italic">Table 6.1</em> compares the HTML source to the answer provided.</p>
			<table id="table001-5" class="no-table-style">
				<colgroup class="calibre15">
					<col class="calibre16"/>
					<col class="calibre16"/>
				</colgroup>
				<tbody class="calibre17">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Source Answer (HTML </strong><strong class="bold">formatted version)</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">ChatGPT </strong><strong class="bold">3.5 Answer</strong></p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Alligiance’s website is best viewed, and is most secure, using the latest versions of these browsers. Get free </strong><strong class="bold">upgrades here:</strong></p>
							<ul class="calibre7">
								<li class="calibre8"><strong class="bold">Microsoft® Internet Explorer (Windows 7 &amp; 8 operating </strong><strong class="bold">systems only)</strong></li>
								<li class="calibre8"><strong class="bold">Google® Chrome</strong></li>
								<li class="calibre8"><strong class="bold">Mozilla® Firefox</strong></li>
								<li class="calibre8"><strong class="bold">Apple® Safari® (Mac operating </strong><strong class="bold">systems only)</strong></li>
							</ul>
							<p class="calibre3"><strong class="bold">Note: Our latest site features will not work with older, unsupported browser versions, specifically Internet Explorer 8, Safar</strong><strong class="bold">i 4 and 5, and Netscape. Internet Explorer 9 and 10 may provide a less than optimal experience. The use of unsupported browsers may also lead to vulnerability because of viruses, spyware, malware, and other </strong><strong class="bold">security issues.</strong></p>
							<p class="calibre3"><strong class="bold">Safari no longer supports upgrades for Windows operating systems. If you are using a Windows operating system, please use one of the supported browsers above, other than Apple® Safari, for the </strong><strong class="bold">best experience.</strong></p>
							<p class="calibre3">How to upgrade Apple® Safari</p>
							<p class="calibre3"><strong class="bold">If you’re using an older version of Safari on a Mac, you’ll need to first check your Apple </strong><strong class="bold">operating system:</strong></p>
							<p class="calibre3"><strong class="bold">From the Apple menu, choose “About </strong><strong class="bold">This Mac.”</strong></p>
							<p class="calibre3"><strong class="bold">This continues for pages, see GitHub for the </strong><strong class="bold">full text.</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Alligiance.com is best viewed and most secure using the latest versions of the following browsers:</p>
							<ul class="calibre7">
								<li class="calibre8">Microsoft® Internet Explorer (Windows 7 &amp; 8 operating systems only)</li>
								<li class="calibre8">Google® Chrome</li>
								<li class="calibre8">Mozilla® Firefox</li>
								<li class="calibre8">Apple® Safari® (Mac operating systems only)</li>
							</ul>
							<p class="calibre3">It’s important to note that the latest site features will not work <a id="_idIndexMarker377" class="pcalibre pcalibre1 calibre6"/>with older unsupported browser versions, specifically Internet Explorer 8, Safari 4 and 5, and Netscape. Internet Explorer 9 and 10 may provide a less than optimal experience, and the use of unsupported browsers may lead to vulnerability due to viruses, spyware, malware, and other security issues[1].</p>
							<p class="calibre3">Additionally, for troubleshooting, if images on a page do not display, users can try clicking the Reload/Refresh button at the top of the browser or clearing the browser’s cache. It’s also noted that if the links to the images are no longer active, they will not be downloadable[2].[1][2]</p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Table 6.1 – Comparison of source document text versus the ChatGPT answer</p>
			<p class="calibre3">This example was run with gpt-3.5-turbo-1106. It looks <a id="_idIndexMarker378" class="pcalibre pcalibre1 calibre6"/>pretty good. Notice that it is not an exact quote of the source material. Here are some usability considerations:</p>
			<ul class="calibre7">
				<li class="calibre8">The paragraph starting with “Additionally, for troubleshooting…” comes from a different FAQ and is unnecessary for this answer. Subsequent runs of this same question did not contain this spurious content.</li>
				<li class="calibre8">The source answer should be shorter for a chat, which is common for documentation. <a href="B21964_07.xhtml#_idTextAnchor150" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 7</em></a><em class="italic">, Prompt Engineering</em>, explains how to control this.</li>
				<li class="calibre8">The style and tone are good. They are consistent with a business tone. Even though the content is in a business tone, style and tone could be adjusted using Prompt Engineering and Fine-Tuning. <a href="B21964_08.xhtml#_idTextAnchor172" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 8</em></a>, <em class="italic">Fine-Tuning</em>, explores using examples to train the model.</li>
				<li class="calibre8">The list of browsers is returned in a bulleted list. Subsequent runs of this same question only sometimes returned this in a bullet list. Prompt engineering can also help return items like a bulleted list more consistently.</li>
				<li class="calibre8">Accuracy is <a id="_idIndexMarker379" class="pcalibre pcalibre1 calibre6"/>critical in support applications. This answer is factually correct, but errors can occur. The next few chapters will discuss techniques for getting accurate answers.</li>
			</ul>
			<p class="calibre3">Hopefully, this analysis is helpful. There may be other items you can see. One must be able to evaluate response quality to care and feed the LLM. This is the crux of our mission.</p>
			<h3 class="calibre11">Quality issues</h3>
			<p class="calibre3">The following prompt was provided to the OpenAI model with the FAQ files attached. These instructions set the stage for any user interactions.</p>
			<pre class="source-code">
You are a helpful assistant named Alli, short for the name of our bank. Be courteous and professional. Prioritize information in any files first. Format output using lists when appropriate.</pre>			<p class="calibre3">The results <a id="_idIndexMarker380" class="pcalibre pcalibre1 calibre6"/>around a few security questions are interesting. We will show some conversations. The convention is to show users messages on the right and the model’s response on the left, similar to the format for messages on your phone. As a reminder, conversations are never edited for typos or mistakes.</p>
			<pre class="source-code-right">Is it safe to do all this via the web?
Yes, our conversation and any information you share are handled with the utmost care for privacy and security. The platform we are using employs robust security measures to ensure the safety of our communication and any data exchanged. If you have any specific concerns or requirements regarding security measures, please feel free to let me know, and I will do my best to address them.What security measures?
The platform we are using implements various security measures to safeguard our communication and any data involved. These measures typically include encryption of data transmission, secure data storage protocols, access controls, and regular security audits to ensure compliance with industry standards and best practices. Additionally, the platform is designed to comply with data protection and privacy regulations to further enhance security and confidentiality. If you have specific security concerns or would like more detailed information about the security measures in place, please let me know, and I can provide more details.</pre>			<p class="calibre3">The answer is <a id="_idIndexMarker381" class="pcalibre pcalibre1 calibre6"/>perfectly reasonable and even logical. Except <em class="italic">none</em> of this comes from the corpus of FAQs that were uploaded. It is a good-sounding generic answer. The answer is not something it was trained on from our knowledge. This is <a id="_idIndexMarker382" class="pcalibre pcalibre1 calibre6"/>classified as a <strong class="bold">hallucination</strong>. A hallucination is a model-generated text that is incorrect, nonsensical, or, in this case, not real. Lying to a customer can cause actual harm beyond just the apparent failure. Given the litigious nature of people, avoid getting sued for lying to customers. The courts in the US can hold the assistant liable as a representative of the company.</p>
			<p class="calibre3">Since no data in the files suggests that Alligiance does regular security audits, the response doesn’t provide more details because it only refers to “typical” measures, not specifics. If the prompt is adapted to “only provide answers from the attached document,” then the LLM answers are similar to the browser answer because it discusses how unsupported browsers can have security issues. It is typical in an enterprise solution to limit the knowledge only to the company knowledge provided. This can reduce hallucinations. HTML files were provided, but it returned clean, formatted text. Not every system and process would be <a id="_idIndexMarker383" class="pcalibre pcalibre1 calibre6"/>that fortunate. When scaling up, consider what it means to clean the enterprise data. In the end, all of these systems expect text as input. So somewhere, some tool is going to do that conversion. Time for some context around data cleaning.</p>
			<h2 id="_idParaDest-139" class="calibre9"><a id="_idTextAnchor141" class="pcalibre pcalibre1 calibre6"/>Cleaning data</h2>
			<p class="calibre3">Cleaning data is tricky, and manually editing files is unreasonable at the enterprise scale. First, understand the problem and either work with vendors that provide tools to support creating a cleansing <a id="_idIndexMarker384" class="pcalibre pcalibre1 calibre6"/>pipeline or start small and learn how to code tools piece by piece. Review what it takes to clean data and decide where to invest a team’s limited resources. One way or the other, most of this has to be automated. The reality is that some is manual work, especially early in the process.</p>
			<p class="calibre3">Data cleaning also <a id="_idIndexMarker385" class="pcalibre pcalibre1 calibre6"/>depends on the types of resources and how they will be used. Handling a large corpus of FAQs, knowledge articles, and marketing materials will require different tools than handling database queries. These are some generalizable issues to be aware of. Let’s start with how to handle documents.</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">Find or build tools to help automate this process, but it is real work for many use cases. The next sections include details to help understand the process in case issues arise with enterprise data. Some data types will require more effort.</p>
			<h3 class="calibre11">Data augmentation</h3>
			<p class="calibre3">Data augmentation <a id="_idIndexMarker386" class="pcalibre pcalibre1 calibre6"/>addresses the issue of whether there is<a id="_idIndexMarker387" class="pcalibre pcalibre1 calibre6"/> enough data. Is there enough knowledge about product questions? Are there enough data resources and historical data to form recommendations? Are language-specific examples available (hint: translate it and translate it back)? Or are various forms of training material needed to understand more diverse formats? <strong class="bold">Augmentation</strong> artificially generates this data to help make solutions more robust.</p>
			<p class="calibre3">Not all data can be easily augmented. An LLM can’t generate novel knowledge articles explaining a process it knows nothing about. But suppose you are training a model on specialized information, like understanding medical diagnosis and treatments, real-time data (like the weather), or any data that might need more recency than the model provides. In that case, the augmentation process can provide precise, up-to-date, and contextually relevant explanations.</p>
			<p class="calibre3">There are tricks. For example, there are times when translating material to another language using an LLM when there is limited language data and then translating it back can help improve the retrieval step. Or incorporate synonyms for product names in the text to create variations to train on. For the most part, be aware of this and consider whether there is data that can be used to train or test the model. This can be a resource once the state of the enterprise data is understood.</p>
			<p class="calibre3">It is an option to use the LLM itself to generate training data. Use this as a resource and then apply common sense to decide what data to give feedback to the model to augment the baseline data with good-quality data. OpenAI suggests that, by training <a id="_idIndexMarker388" class="pcalibre pcalibre1 calibre6"/>on augmented data, the model can handle variety and <a id="_idIndexMarker389" class="pcalibre pcalibre1 calibre6"/>learn to handle noise in the system better when addressing new data. Experimenting and iterating will be needed to see what best improves results.</p>
			<p class="calibre3">Try this prompt in ChatGPT to learn more about data augmentation.</p>
			<pre class="source-code">
How can I do data augmentation using LLMs to generate training data based on a baseline?
What data augmentation should I use to train my LLM on the complexities of (insert enterprise details)?</pre>			<h3 class="calibre11">Data annotation</h3>
			<p class="calibre3">Annotation is work. And it <a id="_idIndexMarker390" class="pcalibre pcalibre1 calibre6"/>can be monotonous. <strong class="bold">Annotation</strong> is the process of marking content with notes to explain it. The concepts of tagging or labeling are fundamentally the same. Notes or details are associated with the content. This is done<a id="_idIndexMarker391" class="pcalibre pcalibre1 calibre6"/> to help understand and mark up passages, content, tables, or anything that needs to be classified. What data to annotate will <a id="_idIndexMarker392" class="pcalibre pcalibre1 calibre6"/>depend on the data and structure. For example, in long passages, annotation can be done for relevance. For tables, headers can be labeled better, which would be evident to a human but not a computer. Product items can be tagged so the models can learn sizes (S, M, L, XL), categories (first class, business class, economy), related products, or other essential attributes that help to give context to the material. With large documents, provide context to the chunks of data. For example, if a table is pages long, do the headers re-appear on every page? Would a human understand the headers if the document was broken into smaller manageable pieces? This is one example where the annotation is needed. Suppose the header talked about the product and product versions, and this header was for multiple pages earlier. In that case, if a chunk turns out to be one page in length, this product header information needs to cascade into each of the correct pages and chunks.</p>
			<p class="calibre3">The annotation process needs to be of high quality. Product experts are the prime candidates to verify that the tags or annotations match the contents of the enterprise data. Thus, designers, writers, and PMs can get involved, using their product expertise to create an effective annotation process. This ensures steps are taken to quality-check the work (as the job might be outsourced or crowdsourced). Create metrics to define a quality bar and test against this (spot check or check it all). I wrote a <a id="_idIndexMarker393" class="pcalibre pcalibre1 calibre6"/>metric to account for the kinds of errors and the frequency of mistakes our input would tolerate. The metric compared the quality of the crowdsourced material to <a id="_idIndexMarker394" class="pcalibre pcalibre1 calibre6"/>the expectations of an expert. Results were analyzed to spot if specific human workers in the crowd were significantly better, worse, or the same as the average worker. So, consider the source, and <em class="italic">always test and verify</em> to validate your quality assumptions. Ask ChatGPT about all the errors that can occur when annotating data.</p>
			<pre class="source-code">
What kinds of errors occur when annotating data for LLMs? Provide an example of each and explain the likelihood of the types of errors. This is important to my job.</pre>			<p class="calibre3">Another part of making data available for the LLM is segmenting it so the most valuable and optimal details are shared in the context window. This is called chunking.</p>
			<h3 class="calibre11">Chunking</h3>
			<p class="calibre3">Not only do large documents need to be tagged, as discussed, but they are likely too big for the RAG process. This leads <a id="_idIndexMarker395" class="pcalibre pcalibre1 calibre6"/>to discussions concerning <strong class="bold">chunking</strong>. Chunking refers to dividing a large text or dataset into smaller, manageable pieces (chunks) that fit within the LLM’s context window, allowing the model to process and understand the information more effectively. This isn’t about becoming a chunking expert; it is only about being able to recognize the results of poor chunking and help resolve issues.</p>
			<p class="calibre3">Imagine customers want answers about mobile phone battery life. The phone company has released hundreds of phone models over the last few years, all with different specifications. These knowledge articles and details must be broken down into manageable, contextually relevant pieces to ensure RAG can process and retrieve them accurately. With this, the amount of information will be manageable for the system and result in good-quality answers. Segmenting the text into logical sections – chapters, paragraphs, and even sentences – ensures chunks have a coherent unit of meaning. This way, RAG can understand and retrieve the most pertinent information. We don’t want information about memory cards for an Android phone to be conflated with iPhones that do not have card slots because of a generic statement about memory cards.</p>
			<p class="calibre3">Different chunking strategies exist. We will cover some basics, with semantic chunking being the one of interest for our case studies later in this chapter. Come back to these references for more exploration.</p>
			<p class="calibre3">Article: <a href="https://medium.com/the-ai-forum/semantic-chunking-for-rag-f4733025d5f5" class="pcalibre pcalibre1 calibre6">Semantic Chunking for RAG</a> (<a href="https://medium.com/the-ai-forum/semantic-chunking-for-rag-f4733025d5f5" class="pcalibre pcalibre1 calibre6">https://medium.com/the-ai-forum/semantic-chunking-for-rag-f4733025d5f5</a>)</p>
			<p class="calibre3">The second learning opportunity is a KDB.AI best practices video. With RAG, a <a id="_idIndexMarker396" class="pcalibre pcalibre1 calibre6"/>vector database vendor will be needed. Fortunately, our learnings are primarily agnostic to <a id="_idIndexMarker397" class="pcalibre pcalibre1 calibre6"/>the platforms. Here are a few takeaways from the video to give insight into chunking:</p>
			<ul class="calibre7">
				<li class="calibre8">Chunk size depends on the model being used. Changing models might require changing chunk sizes. This also suggests that chunking should be done in an automation process to adapt quickly.</li>
				<li class="calibre8">Small chunk sizes for a small amount of content will be accurate but won’t contain much context. Large chunks, typically from full documents, are less granular but can cost performance.</li>
				<li class="calibre8">Prompts, chat history, and other resources might also be included in the context window, so allow for this capacity when deciding how many chunks can be allocated to the context windows.</li>
				<li class="calibre8">Because context windows are growing (ChatGPT-4’s window is 128K tokens as of Fall 2024), it doesn’t mean it should be filled. Performance, cost, and quality are relevant. To put it in context, the FAQ document shared earlier has 465K characters and 110K tokens. That document alone would be about as much as sharable with ChatGPT. That is an insignificant amount of data compared to what is needed at the Enterprise level.</li>
				<li class="calibre8">Chunk overlap can be adjusted when doing code-based chunking. This is the number of chunks to include from previous or future chunks, so there is context. However, NLP chunking solutions will be more graceful in breaking the content into more logical breaks (in a sentence). Examples are <strong class="bold">Natural Language Toolkit</strong> (<strong class="bold">NLTK</strong>) and spaCy, an open-source library.</li>
				<li class="calibre8">Chunk splitters are getting smarter every month. LangChain understands the structure of a document and does an excellent job of understanding sentences and paragraphs. It tries to optimize size based on document structure.</li>
				<li class="calibre8">Structural chunkers understand headers and sections. They can tag chunks with metadata so the context is maintained.</li>
				<li class="calibre8">D<a id="_idIndexMarker398" class="pcalibre pcalibre1 calibre6"/>ifferent retrievers can be used for different databases. For example, one can be used for summaries to treat high-level questions and one for the source chunks to treat specific detailed questions.</li>
				<li class="calibre8">The meat of the discussion starts almost 10 minutes in. Start when Ryan Siegler starts talking. Video: <a href="https://www.youtube.com/watch?v=uhVMFZjUOJI" class="pcalibre pcalibre1 calibre6">Chunking Best Practices for RAG Applications</a> (<a href="https://www.youtube.com/watch?v=uhVMFZjUOJI" class="pcalibre pcalibre1 calibre6">https://www.youtube.com/watch?v=uhVMFZjUOJI</a>) (KDB.AI)</li>
			</ul>
			<p class="calibre3">Why should we care about chunk size? Chunk size impacts the accuracy, context, and performance of LLM solutions, which are essential factors product leaders will want to monitor and improve.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">You will likely not be the one setting up these chunks, but you will get involved in monitoring performance and quality to provide feedback to the data team. Team members who understand the content can help create and manage test cases to explore exceptions and validate the solution.</p>
			<p class="calibre3">For example, does the model understand an exception explained at the beginning of a document when discussing something referenced much later? For instance, in the Wove case study, later in the chapter, clearly defined notes appear at the start of a spreadsheet they want to ingest, but this information applies to material much later in the document; it is thus information relevant to that later chunk.</p>
			<p class="calibre3">Documents can also have images, charts, and tables. So, additional tools need to be used to summarize and get context from these graphics. Tools such as LayoutPDFReader and Unstructured are two examples that can help. The process would need to extract all of this independently of the text so that the chunks and summarization can be applied to the information extracted from the graphics. Depending on the tools, sometimes the embedding step can handle images directly. Almost all pictures and graphics in the documentation are more than ornamental, so converting these images to meaningful, searchable content is essential. Use LLMs to extract context from pictures and then use that knowledge to index and search images later. For example, a retailer setting up a marketing campaign might need a picture and ask, “Show me teens in jeans having fun <a id="_idIndexMarker399" class="pcalibre pcalibre1 calibre6"/>on the beach.” This can be found without manually annotating images with these keywords. Even my iPhone (without an LLM) allows me to <a id="_idIndexMarker400" class="pcalibre pcalibre1 calibre6"/>search for pictures of “cars,” “food,” “airplanes,” people, or locations like “Burlingame.” More intelligence and power are coming into this space with the inclusion of LLMs. Work on iterating on the data annotation to get content in good standing. Since the discussion of Wove’s use of spreadsheets, this data source is worth mentioning.</p>
			<h3 class="calibre11">Spreadsheet cleanup (Excel, Google Sheets)</h3>
			<p class="calibre3">Spreadsheets and databases share some common issues. Data sometimes needs to be transformed into <a id="_idIndexMarker401" class="pcalibre pcalibre1 calibre6"/>different formats to be understood consistently from one service to another. There are tools to do these transformations. Be aware of these issues and can then apply the tools of the day to solve a problem. Spreadsheet cleanup makes a lot of sense in some backend integrations. Spreadsheets and tables can appear in many forms of documentation, and if they need to be understood by the LLM, they will likely need cleanup. Our second case study extensively uses spreadsheets, and we will explore the effort Wove made for their cleanup process. Hint: It involves a lot of manual work and evaluations. First, let’s define reality, or what people call the ground truth.</p>
			<h3 class="calibre11">Documentation and ground truth in sources</h3>
			<p class="calibre3">The <strong class="bold">ground truth</strong> is the facts needed as a basis for enterprise solutions. If documentation contains <a id="_idIndexMarker402" class="pcalibre pcalibre1 calibre6"/>conflicting or misleading information, the LLM, like customers trying to read documentation, will make mistakes. This is <a id="_idIndexMarker403" class="pcalibre pcalibre1 calibre6"/>a fundamental problem for FAQs, technical articles, and marketing communication. The context must be precise to clarify the information associated with which products. Tagging and annotation can help set this context. For example, if the instructions are to hold the power button down for 3 seconds to reset the device, but older models require a different answer, that context must be set clearly. Sometimes, articles call out the products or releases that a document impacts but also give exclusions later or use call-outs to give exceptions. These exclusions need to clearly define their scope for a search engine. Do these exceptions apply to the following few paragraphs or just the paragraphs where it was first introduced? Iterations of editing, tagging, and testing will solve this. Some tagging might be high-level, like articles related to finance or health care, while my examples above are specific to product releases or versions. Let’s start by compiling this in a simple text FAQ case study.</p>
			<h3 class="calibre11">FAQ case study</h3>
			<p class="calibre3">The Alli case study used File Search in OpenAI, but what about using the same data <a id="_idIndexMarker404" class="pcalibre pcalibre1 calibre6"/>in a competitive LLM and RAG solution? Cohere is an AI company that provides enterprise LLM solutions. Why bother with another product in a book about ChatGPT? As models mature, there becomes increasing specialization. An enterprise solution might use one model for a specific task and a different model for a general task (like Wove does in our case study) . Performance, cost, and context size also come into play. With a focus on use cases, it is reasonable that different models might provide value. Cohere also provides a playground function for uploading documents and testing the model. It also exposed a few design elements in the chat UI that provide compelling UI elements worth sharing. In this example, the FAQs with no HTML – just the basic cleaned text was uploaded. </p>
			<pre class="source-code">
Can I add files to Cohere to help answer FAQs?</pre>			<ol class="calibre12">
				<li class="calibre8">Go to the Coral web page (<a href="https://coral.cohere.com/" class="pcalibre pcalibre1 calibre6">https://coral.cohere.com/</a>) and select the <strong class="bold">Coral with documents</strong> option (see <em class="italic">Figure 6</em><em class="italic">.4</em>).</li>
			</ol>
			<p class="callout-heading">Note:</p>
			<p class="callout">The current cohere demo uses a very different design for handling documents, so these instructions won't work. The latest version allows you to copy and paste the information to provide context, or the files must be uploaded using the Dataset tools. We don’t ask readers to do that. We will continue with this example because of some excellent features in the results, but you can follow along by opening the FAQ and copying and pasting.</p>
			<p class="callout">The most recent releases of Cohere’s Playground are more complex, technical, and cluttered than OpenAI’s. When creating solutions, consider the impact of UI elements on feature capability and usability.</p>
			<p class="calibre3"> </p>
			<div><div><img src="img/B21964_06_04.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.4 – Setting up Cohere’s Coral with documents</p>
			<ol class="calibre12">
				<li value="2" class="calibre8">Upload the <a id="_idIndexMarker405" class="pcalibre pcalibre1 calibre6"/>FAQ file shared on GitHub using the <strong class="bold">Files</strong> feature.<p class="calibre3">GitHub: <a href="https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter6-Example_FAQs_NoHTML_for_Demo.docx" class="pcalibre pcalibre1 calibre6">FAQ Sample Document</a> (<a href="https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter6-Example_FAQs_NoHTML_for_Demo.docx" class="pcalibre pcalibre1 calibre6">https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter6-Example_FAQs_NoHTML_for_Demo.docx</a>)</p></li>
				<li class="calibre8">Close the side panel and use the message window to interact (<em class="italic">Figure 6</em><em class="italic">.5</em>).</li>
			</ol>
			<div><div><img src="img/B21964_06_05.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.5 – Example showing reference usage</p>
			<ol class="calibre12">
				<li value="4" class="calibre8">Test the <a id="_idIndexMarker406" class="pcalibre pcalibre1 calibre6"/>model with questions related to the FAQ (<em class="italic">Figure 6</em><em class="italic">.6</em>).</li>
			</ol>
			<div><div><img src="img/B21964_06_06.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.6 – Examples of the FAQ document in Cohere</p>
			<p class="calibre3">Besides the reasons stated, there are some exciting results from this competitive model:</p>
			<ul class="calibre7">
				<li class="calibre8">What is in this book is generalizable to other models.</li>
				<li class="calibre8">Some UX elements, like showing the reference panel, could be valuable to a use case. There is only one document in this demo, so viewing the one link doesn’t help because it repeats itself with every match. Linking to the reference and then scrolling and highlighting the relevant passages makes it easy to understand and see the context. The relevance-highlighting UX pattern should become popular or even a standard.</li>
				<li class="calibre8">It is an excellent example of a side-by-side pattern showing supplemental information.</li>
				<li class="calibre8">It gives us a feel for the quality of different models and allows us to see differences between each version of ChatGPT.</li>
			</ul>
			<p class="calibre3">Let’s test our FAQs. It is helpful to give some context with this Cohere example so that we can explore using FAQs in ChatGPT. Let’s see if the results meet our expectations.</p>
			<p class="calibre3">GitHub: <a href="https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter6-FAQ_PDFs.zip" class="pcalibre pcalibre1 calibre6">Zip of FAQS as unique PDFs</a> (<a href="https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter6-FAQ_PDFs.zip" class="pcalibre pcalibre1 calibre6">https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter6-FAQ_PDFs.zip</a>)</p>
			<p class="calibre3">In this case, the zip file contains the cleaned data in individual PDF documents. This allows us better to connect the source as a reference and the results. Return to the ChatGPT Playground and create the same assistants as before, but try to upload this file.</p>
			<p class="calibre3">However, recall there are limitations; uploading the file in ChatGPT 3.5 will result in a cryptic user error (meaning too many files were uploaded), as shown in <em class="italic">Figure 6</em><em class="italic">.7</em>.</p>
			<div><div><img src="img/B21964_06_07.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.7 – ChatGPT has a file limit</p>
			<p class="calibre3">It is a small dataset, just not small enough. There is a workaround to allow its use in the free playground. The PDFs are joined into 18 files, and a single PDF can be used for other testing and experimentation.</p>
			<p class="calibre3">GitHub: <a href="https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter6-FAQS18files.zip" class="pcalibre pcalibre1 calibre6">Zip of 18 FAQ Files</a> (<a href="https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter6-FAQS18files.zip" class="pcalibre pcalibre1 calibre6">https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter6-FAQS18files.zip</a>) (each with 25 or so FAQs)</p>
			<p class="calibre3">GitHub: <a href="https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter6-FAQ-ALL.pdf" class="pcalibre pcalibre1 calibre6">Single PDF with all 441 FAQs</a> (<a href="https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter6-FAQ-ALL.pdf" class="pcalibre pcalibre1 calibre6">https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter6-FAQ-ALL.pdf</a>)</p>
			<p class="calibre3">With these 18 files, it only takes a few seconds to upload and scan them, and the Playground will be ready to go.</p>
			<p class="calibre3">Once uploaded, try out some test cases like <em class="italic">Tables 6.2 and 6.3</em>. They were written without knowing whether they would work (they were not pre-tested). Test cases are covered more extensively in the next few chapters; let’s keep it simple and do testing manually. Test <a id="_idIndexMarker407" class="pcalibre pcalibre1 calibre6"/>whether single or multiple files impact quality and see what can be learned from the results.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">Try different models available. It doesn’t have to be ChatGPT 3.5; try ChatGPT 4o-mini or compare it to other vendors’ LLMs.</p>
			<p class="calibre3">In both cases, use the cleaned data column from the spreadsheet. There are some spelling errors and chaining questions (questions that demand a follow-up question) in the test cases. Now, we can learn about the actual results together.</p>
			<div><div><img src="img/B21964_Table_6.2.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Table 6.2 – Questions 1-10 and the results from two test sessions</p>
			<div><div><img src="img/B21964_Table_6.3.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Table 6.3 – Questions 11-20 and the results from two test sessions</p>
			<p class="calibre3">Here are some high-level analyses of these results:</p>
			<ul class="calibre7">
				<li class="calibre8">Spelling errors did not cause issues.</li>
				<li class="calibre8">Follow-ups that provide a little extra context returned good results.</li>
				<li class="calibre8">The same model returned very different results for some questions.</li>
				<li class="calibre8">Specific information like addresses was very challenging.</li>
				<li class="calibre8">It didn’t think it was the bank; it referred to “your financial institution or brokerage firm.” Prompt engineering can fix this problem.</li>
				<li class="calibre8">Both needed help with ending sentences with a period. They tended to put a space before the period like this .</li>
			</ul>
			<p class="calibre3">Let’s create a simple score for these two methods. Five points for a great correct answer, 4 points for a <a id="_idIndexMarker408" class="pcalibre pcalibre1 calibre6"/>good correct answer, 3 points for a close to correct answer, and 2 points if a follow-up returned details that should have been in the first answer. Scoring shows 47 points for separate files and 74 for a single file model. Recognizing a significant difference between these two starting points doesn’t have to be perfect. If you watched the OpenAI video in the last chapter (one of my favorite video references of this entire book), they had some similar experiences, beginning with a poor result, and with fine-tuning and prompt engineering, they improved their result, as shown in <em class="italic">Figure 6</em><em class="italic">.8</em>.</p>
			<p class="calibre3">Video: <a href="https://www.youtube.com/watch?v=ahnGLM-RC1Y" class="pcalibre pcalibre1 calibre6">A Survey of Techniques for Maximizing LLM Performance</a> (<a href="https://www.youtube.com/watch?v=ahnGLM-RC1Y" class="pcalibre pcalibre1 calibre6">https://www.youtube.com/watch?v=ahnGLM-RC1Y</a>)</p>
			<div><div><img src="img/B21964_06_08.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.8 – A RAG success story for OpenAI’s approach in a use case</p>
			<p class="calibre3">It isn’t necessary to understand all of these methods in detail. Toward the end of this chapter, there is a section for other techniques to discuss this. The point for the moment is to showcase how continuous improvement to your lifecycle will help determine what changes improve the experience. Even with this rudimentary scoring, there are dramatically different results. I, too, was surprised by the dramatic difference. The full transcript of both results is posted.</p>
			<p class="calibre3">GitHub: <a href="https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter6-Transcripts.docx" class="pcalibre pcalibre1 calibre6">Transcripts of FAQ Test</a> (<a href="https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter6-Transcripts.docx" class="pcalibre pcalibre1 calibre6">https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter6-Transcripts.docx</a>)</p>
			<p class="calibre3">The data brought in through RAG needs to be cleaned, as seen in the forthcoming Wove case study. Something simple, like how files are split up, can profoundly impact performance. Each improvement can affect <a id="_idIndexMarker409" class="pcalibre pcalibre1 calibre6"/>the next step. It is better to continue to refine, starting from a score of 74 than from 47. Find tools to handle the mundane work so efforts can be focused on actual data and its quality. There are other issues to consider when creating a complete lifecycle for a data pipeline. Next is a case study from an exciting company that uses a variety of models to make its LLM solution successful.</p>
			<h3 class="calibre11">Spreadsheet cleanup case study</h3>
			<p class="calibre3">Here is an excellent example of spreadsheets used behind the scenes to create intelligence <a id="_idIndexMarker410" class="pcalibre pcalibre1 calibre6"/>in the LLM and offer recommendations from <a href="https://wove.com" class="pcalibre pcalibre1 calibre6">Wove.com</a> (<a href="https://wove.com" class="pcalibre pcalibre1 calibre6">https://wove.com</a>). Wove helps freight forwarding companies optimize rate management operations by using LLMs to parse and normalize complex tabular data from rate sheets, ocean contracts, and other spreadsheets.</p>
			<p class="calibre3">Freight forwarders act as intermediaries who ensure that small shippers can get goods from one location to another—for example, shipping 10,000 widgets from a factory in China to a warehouse in Nebraska. Because there are hundreds of ways to get from point A to point B, there are complexities based on the vendor, distance, ports, transport type, time, type of goods, customs, weight, and volume. This complexity is buried in published data from each vendor in spreadsheets, PDFs, and other data sources. This complexity increases the time to quote and can lead to missing reasonable rates. By taking these rate sheets and putting them into the model, customer quotes can be generated more accurately and efficiently. This a daunting task. To geek out on the rate sheet use case, look at all the standard terms one might see in a sheet.</p>
			<p class="calibre3">Article: <a href="https://www.slideshare.net/logicalmsgh/understanding-the-freight-rate-sheet" class="pcalibre pcalibre1 calibre6">Rate Sheet Terms and Introduction</a> (<a href="https://www.slideshare.net/logicalmsgh/understanding-the-freight-rate-sheet" class="pcalibre pcalibre1 calibre6">https://www.slideshare.net/logicalmsgh/understanding-the-freight-rate-sheet</a>)</p>
			<p class="calibre3">Terms like BAR, BL Fee, Demurrage, DDC, CYRC, Detention, and dozens of others are a lot to digest. It makes it challenging for an LLM to understand a complex spreadsheet. This is an excellent example from our friends at Wove, who have created a behind-the-scenes use of ChatGPT and other models, like Anthropic’s Claude. They focus on ingesting data to preserve <a id="_idIndexMarker411" class="pcalibre pcalibre1 calibre6"/>data quality and integrity and normalize widely different spreadsheets. Indeed, there are opportunities on the UI side to use this data to answer questions about finding the correct rate for a job. This part of the case study will focus on data ingestion. The Wove case study will be completed after more is explained in the prompt engineering and fine-tuning chapters.</p>
			<p class="calibre3">The terms require understanding, and each rate sheet varies in format, labels, exceptions, and other factors. As rates change over time, the correct rate periods must be understood. <em class="italic">Figure 6</em><em class="italic">.9</em> shows a fraction of a rate sheet to expose this complexity.</p>
			<div><div><img src="img/B21964_010_06.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.9 – Samples of rate sheets from two different vendors</p>
			<p class="calibre3">A typical forwarder might have to deal with dozens of different rate sheets, and with some of them <a id="_idIndexMarker412" class="pcalibre pcalibre1 calibre6"/>being <em class="italic">hundreds</em> of pages long, normalizing all of this data manually requires the effort of a whole team. The examples show how varied the data columns can be. The labels, the values, the use of tabs, how exceptions are handled with remarks, and the headers are all different. However, automation, or even semi-automation, can reduce this process by more than 90%. Although one should test and verify data along the way, there are numerous places in the manual lifecycle where human error causes issues. Let’s review the data cleansing steps Wove had to do to ingest this data. The expected flow of this information is as follows:</p>
			<ol class="calibre12">
				<li class="calibre8">Before getting new rate sheets, they trained and verified the various models needed to create high-quality output. This case study will discuss the different models used.</li>
				<li class="calibre8">Typically, they receive a rate sheet in an email and download the file into Wove. There is also an automation path with an email listener that picks up the file, monitors for new files, and ingests it into the process. These files can have multiple tabs and thousands of rows of data, like the small sample shown in <em class="italic">Figure 6</em><em class="italic">.9</em>. A typical file is likely an update of a previously processed file.</li>
				<li class="calibre8">Their tools parse the XLS file and identify the tables, and it parses the document and turns them into property formatted clumps for the model. There are context length limits, detecting tables, understanding the tables, and figuring out how the tables relate to each other. They refer to this as table detection. As shown next, the development team built ten models to understand the spreadsheet. The entire proprietary process isn’t shared, but this should give a sense of <a id="_idIndexMarker413" class="pcalibre pcalibre1 calibre6"/>what each model does and what software was used to help the cleaning and organizing process. Although this is a technical process, the results are something mere mortals can see. They can determine whether they provide the best results for the cost involved. This is a business decision and a user experience problem.<ul class="calibre19"><li class="calibre8"><strong class="bold">Document Segmentation (Single-Shot GPT 4 Turbo)</strong>: This segments documents into coherent sections/ideas.</li><li class="calibre8"><strong class="bold">Context Builder (Multi-Shot Claude 3 Haiku)</strong>: This is applied after document segmentation. It builds the reading context for understanding the current document.</li><li class="calibre8"><strong class="bold">Table Detection (GPT 3.5 Turbo, Fine-tuned)</strong>: This detects tables in spreadsheets, documents, or contracts.</li><li class="calibre8"><strong class="bold">Table Header Range Detection (GPT 3.5 Turbo, Fine-tuned)</strong>: After the table is detected, the range of header rows and where the data for the table starts are determined.</li><li class="calibre8"><strong class="bold">Table End Detection (GPT 3.5 Turbo, Fine-tuned)</strong>: This detects the end of the table data.</li><li class="calibre8"><strong class="bold">Table Understanding (GPT 3.5 Turbo, Fine-tuned)</strong>: This model understands a table’s columns and data and determines its purpose.</li><li class="calibre8"><strong class="bold">Schema Mapping (GPT 3.5 Turbo, Fine-tuned)</strong>: This model is applied after the table is understood. It determines which columns from a table map to schema fields in a database.</li><li class="calibre8"><strong class="bold">Field Splitter (Single-Shot Claude 3 Haiku)</strong>: The splitter extracts per-field information from combined fields. For example, if effective and expiry dates are in the same field, this can extract them into <strong class="source-inline1">effective_date</strong> and <strong class="source-inline1">expiry_date</strong> in the schema.</li><li class="calibre8"><strong class="bold">Location Normalizer (Multi-Shot GPT 3.5 Turbo)</strong>: This takes unstructured location information and normalizes each detected location to a UN/LOCODE (normalized country codes such as HK for Hong Kong).</li><li class="calibre8"><strong class="bold">Commodity Normalizer (GPT 3.5 Turbo + Ada)</strong>: This takes unstructured commodity information and normalizes each commodity type to be searched/compared.</li><li class="calibre8">These models changed multiple times during the creation of this case study, and they continue to change as they are currently testing GPT 4o-mini for some use cases. Adapt and improve, and sometimes save some money.</li></ul></li>
				<li class="calibre8">They identify, tag, and train the system to understand where the table is, where data starts, where it ends, the header labels, and so on. The challenge is understanding <a id="_idIndexMarker414" class="pcalibre pcalibre1 calibre6"/>tables when LLMs are primarily for text. The spreadsheets become text. Notice some of the models used in this process are fine-tuned. Those are the ones that need additional understanding and learning by providing examples of what defines a table.</li>
			</ol>
			<p class="calibre3">Diving more into table detection helps to understand the segmenting of data. After table detection from <em class="italic">Step 3</em>, they do semantic chunking to get the right context length. Typically, a suitable context length might start at 500 to 1,000 tokens. Depending on the model, longer context lengths are acceptable if you want to pay for them. Wove prompts GPT-4 to chunk the files into <em class="italic">coherent segments</em>. Chunks are essential, as only so much information can be processed at one time. Effective chunking strategies are necessary to have the proper context for a chunk.</p>
			<p class="calibre3">Their prompt is pretty big—it is a page long. It tells ChatGPT 20 different rules to parse a segment. Their prompt starts simple… “You’re an expert in doc parsing; you’ll be given a chunk of text. Your job is to split it into coherent segments.” They don’t have massive chunks, so chunk size is not limited by the LLMs. Each model can have a different token limit to allow for the size of the prompt and the resulting output. The models range from 4K to 8K tokens for input and output. They use a smaller, faster, and less expensive model in the next step. If you are unsure of your model’s limitations, ask it.</p>
			<pre class="source-code">
What makes a good context length when ingesting data into you to help provide context?</pre>			<p class="calibre3">Wove covers <a id="_idIndexMarker415" class="pcalibre pcalibre1 calibre6"/>the entire lifecycle. <strong class="bold">Functional calling</strong>, the method to access <a id="_idIndexMarker416" class="pcalibre pcalibre1 calibre6"/>other resources such as APIs, is essential to Wove’s process and fundamental to enterprise applications. Be aware of this capability. Remember, any enterprise solution will connect to various resources to enrich the LLM.</p>
			<p class="calibre3">Documentation: <a href="https://platform.openai.com/docs/guides/function-calling" class="pcalibre pcalibre1 calibre6">ChatGPT developer documentation on function calling</a> (<a href="https://platform.openai.com/docs/guides/function-calling" class="pcalibre pcalibre1 calibre6">https://platform.openai.com/docs/guides/function-calling</a>)</p>
			<p class="calibre3">They use function calling to generate the sections into a structured output. A piece of this function is shown in <em class="italic">Figure 6</em><em class="italic">.10</em>. The product team needs to understand this to ensure the context is complete. Some of this might be generic to any spreadsheet, such as a start line, end line, the section’s name, headers, and a description, but getting this understanding right is essential. Later, they checked that the tables were processed correctly to confirm the correct start line, header, or sub-header labels.</p>
			<pre class="source-code">
"type": "function",
"function": {
    "name": "next_section",
    "description": "extracts the next section of the
    document",
    "parameters": {
        "type": "object",
        "properties": {
            "StartLine": {
                "type": "number",
                "description": "the line number where the
                section header or contents starts at,
                inclusive. This must exist."
            },
            "EndLine": {
                "type": "number",
                "description": "the line number where the
                section content ends at, inclusive. This
                must exist in the input."
            },
            "SectionName": {
                "type": "string",
                "description": "the name of the section,
                either the title/header if available, or a
                description of the column."
            },
            "SectionHeader": {
                "type": "string",
                "description": "the header of the section,
                if available"
            },
            "SectionType": {
                "type": "string",
                "description": "the type of the section"
            },
            "SectionDescription": {
                "type": "string",
                "description": "the description of the
                section – this is required"
            },
        },
        "required": ["StartLine", "EndLine", "SectionName",
        "SectionType", "SectionDescription"]
    }</pre>			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.10 – A snippet of the function calling that is used to help structure the output</p>
			<p class="calibre3">They can use the <a id="_idIndexMarker417" class="pcalibre pcalibre1 calibre6"/>training validation split data, test the models against the removed data, and use their data cleaning technique on the data shown in <em class="italic">Figure 6</em><em class="italic">.11</em> by defining the tables. This data tagging defines <em class="italic">what is what</em> in the table and can improve with more refinements over time. Scripts help generate new training data from this tagged source.</p>
			<div><div><img src="img/B21964_06_11.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.11 – A small table of side terms from the rate sheets</p>
			<p class="calibre3">Look <a id="_idIndexMarker418" class="pcalibre pcalibre1 calibre6"/>at this definition of <code>Side Terms</code>, which is used to train table detection; it tells the LLM how to understand this data.</p>
			<pre class="source-code">
1  "Side Terms": {
2      "min_row": 3,
3      "max_row": 21,
4      "tables": [
5          TableRangeV2(("B", "G"), 6, (7,20)),
6      ],</pre>			<p class="calibre3">Product managers, designers, and the team must monitor table definitions to ensure high quality. In this example, they identify the “<code>Side Terms</code>” start date from row 3 (line 2) to row 21 (line 3). In line 5, they identify the spreadsheet columns as from <code>B</code> to <code>G</code> (column <code>A</code> is white space), followed by row 6 being defined as the header and defining the source data for the table with <code>(7,20)</code> for rows 7 to 20. However, in <em class="italic">Figure 6</em><em class="italic">.11</em>, notice the <code>Remark</code> column (column <code>F</code>) extends to line 21, so the process involves human validation <em class="italic">to catch this error</em> and change <code>(7,20)</code> to <code>(7,21)</code>.</p>
			<p class="calibre3">Multiple models use this one tagging exercise. This effort supports table-end detection, headers, and table understanding.</p>
			<p class="calibre3">It is vital to catch what needs to be tagged. For example, some notes with stars are shown at the top of the table in <em class="italic">Figure 6</em><em class="italic">.9</em>. LLMs are good at understanding text and the reference to this block of text extracted from the table detection, so no additional effort was needed to gather this information.</p>
			<p class="calibre3">The data must then be normalized for items such as rates and locations. So, for Hong Kong, the port HKHKG is displayed consistently, and dozens of other values are mapped correctly across different files.</p>
			<p class="calibre3">There is a data review process, and Wove has tools for doing so. The team reviews this clean data, as shown in <em class="italic">Figure 6</em><em class="italic">.12</em>. This drill-down shows rates between Hong Kong and Atlanta and some data that goes into these rates.</p>
			<div><div><img src="img/B21964_06_12-shphigh.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.12 – The view of data so now they can view rates in a normalized view</p>
			<p class="calibre3">Now that they have ingested and normalized the data, they can access rates from many sources. Let’s explore some of the details of this workflow a bit further.</p>
			<p class="calibre3">This is not about a single model performing magic; it takes a collection of specialized models. They applied different models to solve various problems. It is expected to adapt and change over time, especially with models that use fine-tuning. Think of it as a modular approach. If a new or much less expensive model comes out, swap it to improve one piece of the puzzle at a time. If there are issues around one topic, such as poor or missing data, and the model will need help converging to a practical solution, focus on that problem. Each piece can experience its version of hallucinations.</p>
			<p class="calibre3">Data cleansing has a specific meaning for these spreadsheets, especially ensuring that rows and exceptions are handled. Chunks must be segmented correctly to <a id="_idIndexMarker419" class="pcalibre pcalibre1 calibre6"/>have a good beginning and end so that context is maintained. This gives RAG a clean context and retrieves relevant chunks more accurately.</p>
			<p class="calibre3">Here are the top issues addressed in their cleanup and ingestion process:</p>
			<ol class="calibre12">
				<li class="calibre8">Process data as text, even coming from spreadsheets.</li>
				<li class="calibre8">The model segments large documents—some rate sheets can be hundreds of pages long—and breaks them up. For example, ocean shipping documents are more complex than road trucking documents.</li>
				<li class="calibre8">The challenge is to understand tables as text. It takes considerable work to understand tables well, tag them correctly, look for errors, and find a suitable model (which they did and didn’t discuss to protect their expertise). This differs from reading straight text, but this might impact the experience even if the team controls the knowledge base or databases. Documents with tables, images, flow charts, and diagrams all contain information that might need to be fully expressed in text.</li>
				<li class="calibre8">Based on the prompts Wove establishes, the model writes instructions for extracting all the data from the sheet. This multiple-step process is examined in <a href="B21964_08.xhtml#_idTextAnchor172" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter </em><em class="italic">8</em></a>, <em class="italic">Fine-Tuning</em>.</li>
				<li class="calibre8">In <em class="italic">Step 1</em>, Wove runs version GPT-4 Turbo, while in other steps, it runs ChatGPT 3.5 and other models. Running tasks sequentially is ten times faster than running GPT-4 once. They used GPT-4 Turbo to generate fine-tuning data. By using more than one model, they can balance performance and cost.</li>
				<li class="calibre8">Wove leaves out 10 to 20% of the data to test the model. This is standard practice. They take out different chunks of data from documents to create a broader and likely more effective test set. Tip: Don’t bias the model by always taking the first 20% of every document. They use a random seed to pick pieces of documents but then maintain that same chunk each time from the same document; this allows them to create a reproducible set. So, their validation steps do not differ because of the test data.</li>
			</ol>
			<p class="calibre3">All of this <a id="_idIndexMarker420" class="pcalibre pcalibre1 calibre6"/>hard work is for data cleaning. The first goal is to expose the data to those responsible for ensuring they have the correct data. As mentioned, this will set up a later conversational experience to help find rates. The FAQ and Wove examples should give some understanding of data issues, but there are other considerations.</p>
			<h2 id="_idParaDest-140" class="calibre9"><a id="_idTextAnchor142" class="pcalibre pcalibre1 calibre6"/>Other considerations for creating a quality data pipeline</h2>
			<p class="calibre3">Not all designers and product managers will be involved with every step of the RAG process. All vendors <a id="_idIndexMarker421" class="pcalibre pcalibre1 calibre6"/>use the fancy term <strong class="bold">pipeline</strong> to represent <a id="_idIndexMarker422" class="pcalibre pcalibre1 calibre6"/>this flow of information from source to customer. Issues can occur before, during, and after models are included in the pipeline. Keep an eye on the following areas for issues impacting customer experience.</p>
			</div>
	

<div><h3 class="calibre11">Computational resources</h3>
			<p class="calibre3">RAG has some real work to do. It has to take an extensive collection of documents and resources <a id="_idIndexMarker423" class="pcalibre pcalibre1 calibre6"/>and create vector data like the original model generation. Doing this regularly can be computationally expensive. Watch for any performance issues when scaling up. Many third-party solutions will talk about millisecond response times. That is wonderful; responses should feel natural. It might be okay for results to take a few seconds in some instances, but nominally, a chat response should start in 200-300 ms (about 1/4 of a second).. </p>
			<p class="calibre3">Meanwhile, recommendations might be triggered when data changes (this can get expensive if always recalculated and no user needs to be updated) or calculated when a page is rendered. Even a trigger to email or message someone about the recommendation requires processes to have current information and evaluate for issues on a schedule. Each of these events will have a cost. Consider the cost of the recommendation if no one can use it.</p>
			<p class="calibre3">Issue: <em class="italic">There is no such thing as a slow, good user experience</em>. Designers and PMs can help performance in a few places.</p>
			<ul class="calibre7">
				<li class="calibre8">Monitor and <a id="_idIndexMarker424" class="pcalibre pcalibre1 calibre6"/>verify a solution’s performance and decide what will meet users’ expectations. Product owners should set performance expectations.</li>
				<li class="calibre8">Monitor whether too much or too little data is sent to the LLM. All data should provide value to the LLM; if not, eliminate it.</li>
				<li class="calibre8">Determine whether the prompt and context sizes provides value for its sizes.</li>
				<li class="calibre8">API requests in an LLM cost money, so optimize or cache information when possible. Understand whether customers use recommendations or visible UIs.</li>
			</ul>
			<h3 class="calibre11">Scalability</h3>
			<p class="calibre3">This can be managed if the system only deals with hundreds of documents. Still, some large enterprises might be looking at a million documents and massive SQL databases. Maintaining <a id="_idIndexMarker425" class="pcalibre pcalibre1 calibre6"/>this large corpus and refining and improving the quality of those databases and documents can be a significant investment. Emphasize the most helpful and frequently accessed materials. Take advantage of third-party pipeline solutions.</p>
			<p class="calibre3">Issue: <em class="italic">You can only be in so many places simultaneously.</em> Scalability also applies to your time. Consider whether there are places worth your attention, like improving the management process, monitoring quality, maintaining documents, or improving the time and process it takes to edit and update documents. Consider a personal version of the 80/20 rule. If 20% of the time on project C returns 80% of the value, spend resources there. Even better, use User Needs Scoring. If something is for all customers that they use frequently, and it is a critical area, then this deserves attention.</p>
			<h3 class="calibre11">Training data quality</h3>
			<p class="calibre3">Fill in <a id="_idIndexMarker426" class="pcalibre pcalibre1 calibre6"/>the following puzzle.</p>
			<p class="calibre3">Quality in supports quality out.</p>
			<p class="calibre3">Garbage in supports _______ out.</p>
			<p class="calibre3">A+ if you guessed garbage. The quality of training materials profoundly affects the ability to fine-tune. If content is very limited, biased, or has a lot of red herrings that could lead customers astray, then there will be ongoing issues. The relevance and quality of content is king. This chapter covered the importance of clean data, but that process can only have limited fixes for quality. That is, removing redundant or conflicting data might be easy to do. It is hard to do when writing this book. Did the reader remember or even see something in <a href="B21964_01.xhtml#_idTextAnchor016" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 1</em></a>, <em class="italic">Recognizing the Power of Design in ChatGPT</em> that is now important in <a href="B21964_05_split_000.xhtml#_idTextAnchor108" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 5</em></a>, <em class="italic">Defining the Desired Experience</em>? Who is the content <a id="_idIndexMarker427" class="pcalibre pcalibre1 calibre6"/>expert that can determine correctness? This gets more challenging as the data grows. Now, think about how a model can handle learning something 150 pages ago that now becomes important. The more technical the data, the less likely an individual can know if the content is high quality. Models can forget, too. They are especially prone to forgetting information in the middle. Not to mention problems understanding knowledge for specific releases or combinations of products. Rely on content partners, authors, and technical experts. It takes a village. Remember that from <a href="B21964_01.xhtml#_idTextAnchor016" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 1</em></a>, <em class="italic">Recognizing the Power of Design </em><em class="italic">in ChatGPT</em>?</p>
			<p class="calibre3">RAG is well suited for responding to specific questions against a wealth of content. However, the data must be in the correct format, and this can be some heavy lifting with data at scale. Picking suitable chunk sizes when segmenting text is more art than science. For the CliffsNotes version (a student study guide for popular books in the US) of dealing with chunking and other lessons learned, watch the video from <a id="_idTextAnchor143" class="pcalibre pcalibre1 calibre6"/>Prolego.This video will be discussed at the end of this chapter.</p>
			<p class="calibre3">Video:<a href="https://www.youtube.com/watch?v=Y9qn4XGH1TI" class="pcalibre pcalibre1 calibre6"> Prolego tips for RAG development</a> (<a href="https://www.youtube.com/watch?v=Y9qn4XGH1TI" class="pcalibre pcalibre1 calibre6">https://www.youtube.com/watch?v=Y9qn4XGH1TI</a>)</p>
			<p class="calibre3">Issue: <em class="italic">Don’t let the models be overwhelmed with garbage and reduce accuracy.</em> Monitor and set improvement goals.</p>
			<h3 class="calibre11">Domain specificity</h3>
			<p class="calibre3">Enterprise <a id="_idIndexMarker428" class="pcalibre pcalibre1 calibre6"/>models rely on domain-specific content.</p>
			<p class="calibre3">Issue: <em class="italic">Gathering and annotating data to improve performance is expensive. </em>Annotation can take many forms, but as with data quality, find experts inside or outside your company to take this to the next level. Invest in building personal expertise.</p>
			<h3 class="calibre11">Response consistency and coherence</h3>
			<p class="calibre3">RAG <a id="_idIndexMarker429" class="pcalibre pcalibre1 calibre6"/>solutions will be challenging. Enterprise solutions value deterministic answers, which will not happen with only a generative solution. Answers will vary, even when asked the same question. This can be improved with prompt engineering, fine-tuning, and the careful use of the generative models in a larger ecosystem of products.</p>
			<p class="calibre3">Issue: <em class="italic">Don’t throw the baby out with the bathwater.</em> With existing chatbots that provide <a id="_idIndexMarker430" class="pcalibre pcalibre1 calibre6"/>repeatable solutions, supplement them with a generative solution. Focus fine-tuning on consistency. For recommendation engines, look for the places with the most value to add by incremental improvements.</p>
			<h3 class="calibre11">Privacy, security, and data residency</h3>
			<p class="calibre3">Because the data is proprietary and is contained in company databases, knowledge base, and APIs, its access can be <a id="_idIndexMarker431" class="pcalibre pcalibre1 calibre6"/>managed when responding to customer questions. Since a ChatGPT response will be based on the context passed to it from a <a id="_idIndexMarker432" class="pcalibre pcalibre1 calibre6"/>RAG solution, it makes sense to make sure privacy and security policies limit the visibility of this data to the appropriate customers. Be on the front line to monitor for issues that appear during a chat or come in via customer feedback. One area where designers can add value to the privacy discussion is related to the data seen during reviewing interactions.</p>
			<p class="calibre3">Besides ensuring that data from backends doesn’t get into the wrong conversations, there are <a id="_idIndexMarker433" class="pcalibre pcalibre1 calibre6"/>times when masking <strong class="bold">Personally Identifiable Information</strong> (<strong class="bold">PII</strong>) is necessary. In <a href="B21964_02_split_000.xhtml#_idTextAnchor031" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 2</em></a>, <em class="italic">Conducting Effective</em> <em class="italic">User Research</em>, ways to mask PII were discussed. This is a consideration when training models. Training data can contain PII. One approach is not to mask it (replacing the text with ****), as that would hinder the model’s comprehension, but to <em class="italic">transform</em> the data into fake data generated by the model itself. For example, instruct a model during a data cleaning step to replace customer names with customer names it makes up. It is good at this, and this fake data, called <strong class="bold">synthetic data,</strong> can replace actual data.</p>
			<pre class="source-code">
Give me a list of 5 customer names from various countries, ages, the typical amount they spend on car-sharing services, a column with a 9-digit number in the format 22-333-444, a fake cell phone number, and their favorite form of payment in a table.</pre>			<p class="calibre3">ChatGPT is very good at this. Even ChatGPT will reject providing fake Social Security numbers, so notice how the prompt asked for a nine-digit number in the prompt. It responded with the results in <em class="italic">Table 6.4</em>.</p>
			<table id="table002-5" class="no-table-style">
				<colgroup class="calibre15">
					<col class="calibre16"/>
					<col class="calibre16"/>
					<col class="calibre16"/>
					<col class="calibre16"/>
					<col class="calibre16"/>
					<col class="calibre16"/>
					<col class="calibre16"/>
				</colgroup>
				<thead class="calibre18">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Customer </strong><strong class="bold">Name</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Country</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Age</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Car </strong><strong class="bold">Sharing (Monthly)</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Identifier </strong><strong class="bold">Number</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Cell </strong><strong class="bold">Phone Number</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Favorite </strong><strong class="bold">Payment Method</strong></p>
						</td>
					</tr>
				</thead>
				<tbody class="calibre17">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Emma Smith</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">USA</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">29</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">$150</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">22-333-444</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">(555) 123-4567</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Credit Card</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Hiroshi Tanaka</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Japan</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">35</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">¥18,000</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">22-333-445</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">090-1234-5678</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Mobile Payment</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Maria Garcia</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Spain</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">41</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">€120</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">22-333-446</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">612-345-678</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Debit Card</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">David Osei</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Ghana</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">26</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">GHS 600</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">22-333-447</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">024-123-4567</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Mobile Money</p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold">Anna Müller</strong></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">Germany</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">32</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">€140</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">22-333-448</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">0151-1234567</p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">PayPal</p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Table 6.4 – Example of using synthetic data to replace PII</p>
			<p class="calibre3">Notice how the names feel localized; the counties were varied, local currency and reasonable amounts were used, and the phone numbers were localized. <em class="italic">Mobile Money</em> is not a term I recognize, but it is common in Ghana. Mobile Money means payments made via mobile phone providers. So, it is even possible to learn something from synthetic data. Since the subject of other countries came up, there are other country-specific issues.</p>
			<p class="calibre3">There are two <a id="_idIndexMarker434" class="pcalibre pcalibre1 calibre6"/>considerations when discussing country-specific limitations that might limit model enrichment. Generally, this will fall to the product manager. The first is whether there <a id="_idIndexMarker435" class="pcalibre pcalibre1 calibre6"/>are export limitations for company data. Some countries restrict the export of customer or employee data across borders. They have <a id="_idIndexMarker436" class="pcalibre pcalibre1 calibre6"/>data residency requirements to house data in-country. This is why many vendors provide data centers in some regions. The <strong class="bold">General Data Protection Regulation</strong> (<strong class="bold">GDPR</strong>) in the European Union and the Privacy Shield <a id="_idIndexMarker437" class="pcalibre pcalibre1 calibre6"/>framework come to mind. When dealing with personal information that might be common in a human resource chat application, for example, safeguards might be required to be in place, and consent might be needed. This can impact the user experience. I have had to design examples where user permissions are required or policy requirements on what can or should not be shared need to be consented to before proceeding.</p>
			<p class="calibre3">The second issue is more data-centric and not subject to data residency issues. Processing rules might only apply to certain countries or groups within a country. It could be a data issue to ensure that the LLM knows that this person is from a particular country, and thus, specific documents, policies, or APIs apply. For example, expense reimbursement policies vary per country. It is one thing for an American to have dinner on a trip to France and be reimbursed when they return to the US (US policy applies) versus someone from <a id="_idIndexMarker438" class="pcalibre pcalibre1 calibre6"/>France going somewhere outside the European Union (EU/French policy). Designers and PMs must recognize the necessary attributes to <a id="_idIndexMarker439" class="pcalibre pcalibre1 calibre6"/>filter and support the correct data and resources. This is not unique to LLMs. It must be handled in these cases, such as in a GUI or an existing <a id="_idIndexMarker440" class="pcalibre pcalibre1 calibre6"/>chatbot. Another version of the rules is how to communicate with our audience. Sometimes, biases in the data or even ethical concerns need to be addressed.</p>
			<h3 class="calibre11">Bias and ethical concerns</h3>
			<p class="calibre3">It might be reasonable to think that enterprise data doesn’t have bias, but still watch out for it. There <a id="_idIndexMarker441" class="pcalibre pcalibre1 calibre6"/>could be tongue-in-cheek content in <a id="_idIndexMarker442" class="pcalibre pcalibre1 calibre6"/>the knowledge base, but it gets regurgitated as truth. It could cause issues in the results. Take a look at <em class="italic">Figure 6</em><em class="italic">.13</em>. It is a simple interaction that it should be easy to discern facts. It is fair to point out that this was <em class="italic">not</em> ChatGPT. This is a continuation of our Cohere example. Remember, the example from earlier extended a basic LLM to include the FAQs. Unless it is told otherwise and guardrails are put in place, it will still attempt to answer general model questions. It did not go as planned. As these models are expected to improve quickly, it is not fair to comment on this model’s shortcomings. All models have shortcomings. It is used to make a point about all models.</p>
			<div><div><img src="img/B21964_06_13.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.13 – Conversational hallucinations can create bias and errors</p>
			<p class="calibre3">Issue: <em class="italic">Don’t get caught making (wrong) ethical decisions</em>. Avoid these discussions when possible. Watch <a id="_idIndexMarker443" class="pcalibre pcalibre1 calibre6"/>data collection, model training, and <a id="_idIndexMarker444" class="pcalibre pcalibre1 calibre6"/>the monitoring process for potential issues. Let’s break down this collection of issues. Hank Greenberg (who is Jewish) and Hank Aaron (who was not) got confused somehow. Maybe this is a hallucination. But simple questions such as this would be easy to answer. Let me point out a few problems.</p>
			<ul class="calibre7">
				<li class="calibre8">It didn’t get Hank Aaron (presumably because of my spelling error) even when the model corrected my mistake and returned it spelled correctly.</li>
				<li class="calibre8">Hank Aaron was not Jewish.</li>
				<li class="calibre8">His career lasted 23 years, not 24.</li>
				<li class="calibre8">He never had close to 209 home runs per season (he had 755 in his entire 23-year career; I know because I watched him tie the record).</li>
				<li class="calibre8">Jackie Robinson was the first African-American inducted into the Hall of Fame in 1962. Hank Aaron’s induction was <em class="italic">20</em> years later.</li>
				<li class="calibre8">Hank Greenberg was well known to be Jewish and faced discrimination.</li>
			</ul>
			<p class="calibre3">We tried this with ChatGPT. It did assume Hank Aaron even when his name was misspelled. It accurately explained <a id="_idIndexMarker445" class="pcalibre pcalibre1 calibre6"/>he was not Jewish, played for 23 years, knew his 755 <a id="_idIndexMarker446" class="pcalibre pcalibre1 calibre6"/>home runs record, and his place in the Baseball Hall of Fame. The ChatGPT 3.5 model was factually correct. And to be fair, <em class="italic">a newer update to Cohere got all of </em><em class="italic">this correct</em>.</p>
			<p class="calibre3">Enterprise data is not expected to talk about the religion of famous baseball players. Just recognize that answers for well-known facts can still contain hallucinations, lies, or whatever they should be called, and the organization will likely be liable for spreading disinformation. It doesn’t mean a lawsuit. It could mean not meeting a service-level agreement, upsetting or losing a potential customer, or having to compensate the customer. This is not unlike what would happen if a human agent provided incorrect information. There can be downstream costs or service interruptions due to wrong answers. With AI, we have seen numerous mistakes, errors, or maybe a lack of training, causing issues.</p>
			<p class="calibre3">Semi-autonomous cars causing accidents in the automotive industry come to mind. This isn’t to say that human drivers are better (they are not by almost an order of magnitude). Still, the kinds of accidents caused by training model issues sometimes seem obvious and avoidable by a human driver (being able to identify an 18-wheeler truck crossing the road in a high-glare situation). At the same time, there are far more cases <em class="italic">not</em> seen in the news, such as semi-autonomous cars <em class="italic">not</em> getting into accidents where a human’s response time and visibility would have resulted in tragedy. Ultimately, expect generative AI to be more reliable, consistent, and accurate than humans. It should get there in a few years with significant effort. Always be aware that bias and ethics come into play within a model. In addition, be ethical in how much effort is expended to build and test models.</p>
			<p class="calibre3">There will be a benefit/risk analysis; just don’t get caught on the wrong side, as Ford did when it refused to fix defective gas tanks in its Pinto model.</p>
			<p class="calibre3">Wikipedia: <a href="https://en.wikibooks.org/wiki/Professionalism/The_Ford_Pinto_Gas_Tank_Controversy" class="pcalibre pcalibre1 calibre6">Ford Pinto Gas Tank Controversy</a> (<a href="https://en.wikibooks.org/wiki/Professionalism/The_Ford_Pinto_Gas_Tank_Controversy" class="pcalibre pcalibre1 calibre6">https://en.wikibooks.org/wiki/Professionalism/The_Ford_Pinto_Gas_Tank_Controversy</a>)</p>
			<p class="calibre3">One has to invest in creating good models. There will be lawsuits related to this as well. Take the time and energy to put quality first. Document your sources; in legal terms, this is called the chain of custody. Check the work and refine and resolve problems with <a id="_idIndexMarker447" class="pcalibre pcalibre1 calibre6"/>a cadence that befits the risks understood by the enterprise<a id="_idIndexMarker448" class="pcalibre pcalibre1 calibre6"/>. It won’t be perfect – nor are human agents. Just put a process in place for constant improvement. The Silicon Valley mantra about “move fast and break things” sounds great at a start-up, but when delivering a paid service to high-valued customers, maybe be more pragmatic about investing in quality.</p>
			<h3 class="calibre11">Embedding other techniques</h3>
			<p class="calibre3">If you watched the OpenAI discussion on techniques mentioned at the beginning of the chapter <a id="_idIndexMarker449" class="pcalibre pcalibre1 calibre6"/>to learn about a few additional methods, the video discusses optimization techniques at the 15-minute mark. This approach to benchmarking quality and applying tools and techniques is right. This was done for a typical ChatGPT solution that involves <a id="_idIndexMarker450" class="pcalibre pcalibre1 calibre6"/>searching a knowledge base. They tried a few methods that did not work to get the improvements they expected (<strong class="bold">Hypothetical Document Embedding</strong> (<strong class="bold">HyDE</strong>) retrieval and fine-tuning embedding). They found some worthy investments (chunk/embedding reranking, classification, prompt engineering, and query expansion). It would be way over our heads exploring how to do these. The key is for designers and PMs to work with the team to establish a benchmark, find good data to train the model, and test and verify results as they are iterated. Consider the goal so it is known when the goal is reached. Recognize that as models change and data grows, adapt. In reality, a team won’t ever be done, but with a quality bar, the organization can allocate resources more wisely.</p>
			<h3 class="calibre11">Evaluation metrics</h3>
			<p class="calibre3"><a href="B21964_10_split_000.xhtml#_idTextAnchor216" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 10</em></a>, <em class="italic">Monitoring and Evaluation</em>, will <a id="_idIndexMarker451" class="pcalibre pcalibre1 calibre6"/>cover methods for determining performance. Relevance, diversity, and coherence are all crucial factors for our datasets. The focus will be to understand this from the user’s perspective with accuracy and customer feedback.</p>
			<p class="calibre3">Despite these limitations, RAG holds promise for enhancing the capabilities of conversational AI systems such as ChatGPT by enabling more contextually relevant and informative <a id="_idIndexMarker452" class="pcalibre pcalibre1 calibre6"/>responses to user queries. Addressing the challenges above through ongoing research and development efforts can help unlock RAG’s full potential to improve user engagement and satisfaction in conversational AI applications.</p>
			<h2 id="_idParaDest-141" class="calibre9"><a id="_idTextAnchor144" class="pcalibre pcalibre1 calibre6"/>Resources for RAG</h2>
			<p class="calibre3">A good RAG solution will use a service dedicated to managing the influx of data, processing it, storing it, and retrieving it to share with the LLM. There has been so much movement in <a id="_idIndexMarker453" class="pcalibre pcalibre1 calibre6"/>this space since RAG was invented, and it is hard to realize how quickly this has become real.</p>
			<p class="calibre3">Because most of the design work is in data quality rather than technology, it will be best to provide resources for those who want to explore the more technical pieces of the puzzle. The OpenAI resource is the best place to start; it will evolve and adapt as technology changes. GPT-4 and newer work directly with RAG.</p>
			<p class="calibre3">Web article: <a href="https://thenewstack.io/openai-rag-vs-your-customized-rag-which-one-is-better" class="pcalibre pcalibre1 calibre6">OpenAI RAG vs. Customized RAG with Milvus</a> (<a href="https://thenewstack.io/openai-rag-vs-your-customized-rag-which-one-is-better" class="pcalibre pcalibre1 calibre6">https://thenewstack.io/openai-rag-vs-your-customized-rag-which-one-is-better</a>)</p>
			<p class="calibre3">Do not assume linking to these resources implies they are best in class. They are all improving rapidly, will diverge in value, and some will disappear. As the market evolves, look for tools that can automate the pipeline with high quality. Access to a database is the most prominent tool needed in the enterprise after knowledge access.</p>
			<h3 class="calibre11">Databases and SQL</h3>
			<p class="calibre3">Database retrieval <a id="_idIndexMarker454" class="pcalibre pcalibre1 calibre6"/>presents challenges. Consider <a id="_idIndexMarker455" class="pcalibre pcalibre1 calibre6"/>how the database thinks about its content and how to ask for results. This is typically expressed in SQL, the structured query language of most databases. Some databases do not use SQL and are called NoSQL databases. Since most enterprise data to inject into tasks and prompts is held in SQL databases, we will focus on a SQL example. LLMs have some ability to write SQL, but it is still an evolving area.  Here is an example highlighting the complexities of working with a database.</p>
			<pre class="source-code">
Show me jobs near Burlingame</pre>			<p class="calibre3">It might already be obvious there are a few issues to address:</p>
			<ol class="calibre12">
				<li class="calibre8">Which Burlingame (the one near me in the San Francisco Bay Area, San Diego, Kansas, Oregon, etc.…)?</li>
				<li class="calibre8">What kinds of jobs? Does it have context for what is needed?</li>
				<li class="calibre8">Are more filters for price, types of companies, and working hours needed?</li>
				<li class="calibre8">Focusing on the first step, drilling down into understanding the first statement. What does near mean? In the San Francisco Bay Area, 10 miles is reasonable, while in Oregon, 25 miles is reasonable. If this were New York City and you wanted a pizza place, two blocks would be too far.</li>
				<li class="calibre8">How does one translate this into cities that are in my database?</li>
			</ol>
			<p class="calibre3">My point is that <a id="_idIndexMarker456" class="pcalibre pcalibre1 calibre6"/>it is more complicated than extracting an entity like the name of a city and expecting, even with SQL magic, to be able to scope good content. This request needs to be pre-processed<a id="_idIndexMarker457" class="pcalibre pcalibre1 calibre6"/> to generate a reasonable SQL statement. So, manage the input to expect a sensible output. In real estate property management, there is a saying: <em class="italic">inspect what you expect</em>. The same here. The input must be checked and broken up into pieces that need to be analyzed and expanded with more details to get the expected output. With the output, it might be possible to send a collection of results to the LLM, like sending documents or FAQs, so that ChatGPT can use this information to form a more refined answer. The LLM has to know about the schema to format a good query.</p>
			<p class="calibre3">Another approach I have worked on and that is becoming popular is text-to-SQL. This is a way to apply LLM intelligence to create a logical SQL statement that returns effective results. This approach has merit but depends on whether SQL can support the query. In the preceding example, the solution would need a city or location discovery tool based on a range or distance from a center point (and center points can be wildly inaccurate regarding where the person is located and where to go). A basic LLM would have to understand the related cities correctly. These tools are available and must be integrated to generate the correct list of towns and locations to pass into SQL. An LLM can also get this information and form the SQL queries.</p>
			<pre class="source-code-right">What cities are within5 miles of Hillsborough, CA,provide only the list
Within a 5-mile radius of Hillsborough,
CA, some nearby cities include:
1. Burlingame, CA
2. San Mateo, CA
3. Millbrae, CA</pre>			<p class="calibre3">Foster City, CA, which is 3 miles away, was included the first time the question was asked, but Belmont, CA, or San Bruno, CA, were never included. So, if this customer were looking for a job, they would miss many opportunities. This specific issue could be <a id="_idIndexMarker458" class="pcalibre pcalibre1 calibre6"/>fixed with adjustments to the prompt focusing on <a id="_idIndexMarker459" class="pcalibre pcalibre1 calibre6"/>the exact cities and asking to check its work. For example, the results can be seen with a simple adjustment and follow-up.</p>
			<pre class="source-code-right">Can you show these with thedistances used and includethe next 3 closest cities
To provide more accurate information, I'll
calculate the distances between Hillsborough,
CA, and nearby cities using their geographic
coordinates. Here are the distances along with
the seven closest cities:
Burlingame, CA - Approximately 1.9 miles away
San Mateo, CA - Approximately 3.2 miles away
Millbrae, CA - Approximately 3.5 miles away
Foster City, CA - Approximately 4.3 miles away
Belmont, CA - Approximately 4.6 miles away
South San Francisco, CA - Approximately 4.8 miles away
San Carlos, CA - Approximately 5.1 miles away
Please note that these distances are
approximate and may vary slightly
depending on the specific locations
within each city.</pre>			<p class="calibre3">When asked later how close South San Francisco was to Hillsborough, it correctly answered 10 miles—much different than its first answer. <em class="italic">Rely on a well-known API to get this data rather than constantly dealing with the variability of an LLM</em>. API resources provide more accurate and reliable data when specific details are required. Consider incorporating these into LLM responses to provide natural interaction. An enterprise is rich with databases containing collections of facts. Use this as a competitive advantage. Don’t expect the LLM to do it all by generating results. This is why function calling exists – to get the value of specific data in generative output.</p>
			<p class="calibre3">Prompt engineering can also help improve the results. But the point should be clear—SQL needs some hand-holding to create effective queries and some pre-processing to give the database a good chance at returning effective results.</p>
			<p class="calibre3">Online suggestions for connecting to databases focus primarily on <a id="_idIndexMarker460" class="pcalibre pcalibre1 calibre6"/>straightforward queries that don’t explore how the <a id="_idIndexMarker461" class="pcalibre pcalibre1 calibre6"/>user will ask the questions. This is a more complex problem than just connecting to a database.</p>
			<p class="callout-heading">Extra credit reading on database</p>
			<p class="callout">If database connectivity is new for you, read these references</p>
			<p class="callout">Article: <a href="https://medium.com/@shivansh.kaushik/talk-to-your-database-using-rag-and-llms-42eb852d2a3c" class="pcalibre pcalibre1 calibre6">Talk to your</a> Database using RAG and LLMS (<a href="https://medium.com/@shivansh.kaushik/talk-to-your-database-using-rag-and-llms-42eb852d2a3c" class="pcalibre pcalibre1 calibre6">https://medium.com/@shivansh.kaushik/talk-to-your-database-using-rag-and-llms-42eb852d2a3c</a>)</p>
			<p class="callout">Article: <a href="https://medium.com/dataherald/how-to-connect-llm-to-sql-database-with-llamaindex-fae0e54de97c" class="pcalibre pcalibre1 calibre6">How to connect LLM to SQL database with LlamaIndex</a> (<a href="https://medium.com/dataherald/how-to-connect-llm-to-sql-database-with-llamaindex-fae0e54de97c" class="pcalibre pcalibre1 calibre6">https://medium.com/dataherald/how-to-connect-llm-to-sql-database-with-llamaindex-fae0e54de97c</a>)</p>
			<p class="calibre3">We will explore one example with the Oracle Digital Assistant. This area will see significant improvements in the coming years as the intelligence needed to interpret the user’s needs before forming the proper SQL queries will improve. The chaining necessary to get the correct result will also improve. This chaining problem is a function of what the user asks, the assumptions needed to understand the question, and the SQL required to return the answer. Chaining is the connecting of one answer that feeds the following question and subsequent answer. Sometimes, it makes sense to chain thoughts together to resolve a question. Let me finish with a use case example paraphrasing this Oracle blog example.</p>
			<p class="calibre3">Article: <a href="https://blogs.oracle.com/digitalassistant/post/introducing-the-new-oracle-digital-assistant-sql-dialog" class="pcalibre pcalibre1 calibre6">Oracle Digital Assistant SLQ Integration</a> (<a href="https://blogs.oracle.com/digitalassistant/post/introducing-the-new-oracle-digital-assistant-sql-dialog" class="pcalibre pcalibre1 calibre6">https://blogs.oracle.com/digitalassistant/post/introducing-the-new-oracle-digital-assistant-sql-dialog</a>)</p>
			<pre class="source-code">
Show all employees in Michael's org.</pre>			<p class="calibre3">Let’s address the issues with this process chain:</p>
			<ol class="calibre12">
				<li class="calibre8">Michael – who is Michael? Look around my hierarchy and determine if Michael is known. This is a whole process by itself and fundamental to people searching in an organization.</li>
				<li class="calibre8">If needed, disambiguate which Michael the user could be inferring.</li>
				<li class="calibre8">Map employees to the SQL field (called EMP). The concept of employees will be requested in many ways – workers, teams, teammates, underlings, people, etc. It is unlikely a user will <em class="italic">ever</em> use the SQL field name.</li>
				<li class="calibre8">Determine Michael’s department. (Use SQL to get the answer. It is 23.)</li>
				<li class="calibre8">Decide whether the default information to be returned needs to be enhanced based on the query (in this case, nothing special was asked of it).</li>
				<li class="calibre8">Limit query by <a id="_idIndexMarker462" class="pcalibre pcalibre1 calibre6"/>security implications (for example, don’t show salary).</li>
				<li class="calibre8">Perform the <a id="_idIndexMarker463" class="pcalibre pcalibre1 calibre6"/>search, determine the size of the results, and return the results or a chunk of results if #&gt;30.</li>
				<li class="calibre8">The final query should look something like this: <strong class="source-inline1">SELECT EMPNO, ENAME, JOB, MGR FROM EMP WHERE DEPTNO = 23 FETCH FIRST 30 </strong><strong class="source-inline1">ROWS ONLY</strong>.</li>
				<li class="calibre8">Return the answer using a generative answer, wrapping the specific details from the database.</li>
			</ol>
			<p class="calibre3">The Oracle article does an excellent job of discussing synonyms. In their example, they use the Big Apple for New York City. It serves as a good reminder that language is very flexible, and there are many cases where, without this sort of intelligence, the natural language feel that customers expect won’t happen. Since the database fields don’t match the users’ language, there is some work to help with. The LLM can likely help understand terms and tagging concepts, but a product person must help it with cryptic field labels. For example, it might not understand that PH2 is a cell phone field. Use the LLM to extend the understanding of synonyms for a cell phone (such as mobile, digits, contact info, wireless #, phone number, #).</p>
			<h3 class="calibre11">Service requests and other threaded sources</h3>
			<p class="calibre3">Service <a id="_idIndexMarker464" class="pcalibre pcalibre1 calibre6"/>requests and other conversational sources, such as community discussions, are good data, but the kernels of truth within them must be exposed. Inferior results will occur if these sources are used without tagging and annotating correct answers. They are filled with wrong answers, half-truths, and misinformation. This is especially true for technical answers where the ground truth might be particular to a version or subversion of a product. So, confusing the difference between the 11.1 and 11.1.2 products can lead to incorrect results. And there can be red herrings in the answers, too. That is, there might be information that misleads or distracts from the problem and thus identifies the solution. It sometimes starts with “I don’t know if this matters, but…”.</p>
			<p class="calibre3">Most service <a id="_idIndexMarker465" class="pcalibre pcalibre1 calibre6"/>request systems mark closed service requests <a id="_idIndexMarker466" class="pcalibre pcalibre1 calibre6"/>as completed and require the agent to tag the correct answer for future processing or analysis. A more formal structure for SRs will give a better chance of mining this information. The wealth of important information in SRs must be addressed, and there are reasons to consider these sources:</p>
			<ul class="calibre7">
				<li class="calibre8">Customer language is a rich corpus of how customers talk about products, their issues, and how they interact in the real world. This domain-specific language and terminology are invaluable to training a model. Technical jargon, colloquialisms, initialisms, abbreviations, and shortcuts will appear more frequently in these sources than in traditional training, marketing, and technical documentation.</li>
				<li class="calibre8">Context is helpful in the LLM to create more accurate responses. Product release, patch levels, software installs, and operating system versions are typically what might be asked about when there is a problem, and this context can be very valuable.</li>
				<li class="calibre8">Commonality—the frequency of common questions helps the model understand the likelihood of this type of response being useful in the future.</li>
				<li class="calibre8">Technical domain training—there might not be another place to find the situations being discussed.</li>
			</ul>
			<p class="calibre3">Although most companies try to avoid some discussions in SRs and online channels, still be aware and avoid including PII in the model that might leak through in these forums. The process should support data cleansing and anonymization, as discussed in <a href="B21964_02_split_000.xhtml#_idTextAnchor031" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 2</em></a>, <em class="italic">Conducting Effective</em> <em class="italic">User Research</em>, or synthesizing some data, as discussed earlier in this chapter. Doing this all manually is impossible at scale. Ultimately, these are just documents with the same issues as a knowledge base. Similar to databases, other pieces of software might be needed to access relevant information.</p>
			<h3 class="calibre11">Integrating external content via APIs</h3>
			<p class="calibre3">Be ready to call the right service with the right <a id="_idIndexMarker467" class="pcalibre pcalibre1 calibre6"/>question. Creating effective interactions that perform tasks –filling out an expense report, scheduling an appointment on a calendar, or booking a holiday or vacation – all require backend services.</p>
			<p class="calibre3">Many resources with advice on creating effective documents and resource retrieval were shared, but the solution’s success will still depend on the collection of services and software used. A few minutes on integrations is justified.</p>
			<p class="calibre3">OpenAI can respond with an API call instead of just replying based on knowledge. A model can update a support ticket, ask for shipping information, look up prices or products, or perform other interactions the business relies on. Unsurprisingly, ChatGPT helps explain and write code to connect to several well-known APIs, but that is for development. Product people must know what is available and <em class="italic">how</em> to frame this interaction. For fun, try something like this.</p>
			<pre class="source-code">
Can I set up a ChatGPT integration using an API to generate a Zoom conference?</pre>			<p class="calibre3">Enterprise APIs will mostly be proprietary, and ChatGPT won’t help directly. However, since most REST work should be similar, it still might be able to help. Sometimes, integrations with third parties such as Zoom, Teams, Slack, Jira, Confluence, Salesforce, HubSpot, ServiceNow, Oracle, or other vendors are used internally or as part of an enterprise offering. Remember that all the work is still needed to authenticate, create a security layer, deal with hallucinations, handle error cases, and create a consistent experience. It is real work.</p>
			<p class="calibre3">More robust approaches are evolving. This article on ToolLLM describes an approach to using ChatGPT to generate instructions for APIs and then figure out how to use them.</p>
			<p class="calibre3">Article: <a href="https://arxiv.org/abs/2307.16789?utm_source=tldrai" class="pcalibre pcalibre1 calibre6">How to use thousands of APIS in LLMs</a> (ToolLLM paper) (<a href="https://arxiv.org/abs/2307.16789?utm_source=tldrai" class="pcalibre pcalibre1 calibre6">https://arxiv.org/abs/2307.16789?utm_source=tldrai</a>) </p>
			<p class="calibre3">Video: AI News: <a href="https://www.youtube.com/watch?v=lGxaE8FU2-Q" class="pcalibre pcalibre1 calibre6">An LLM that learns how to work with APIs</a> (ToolLLM paper)  (<a href="https://www.youtube.com/watch?v=lGxaE8FU2-Q" class="pcalibre pcalibre1 calibre6">https://www.youtube.com/watch?v=lGxaE8FU2-Q</a>) </p>
			<p class="calibre3">Apply our testing and validation process here as it is for <em class="italic">any</em> input and output testing. As designers, PMs, and people who care about usability, try to understand whether the <a id="_idIndexMarker468" class="pcalibre pcalibre1 calibre6"/>APIs provide the right level of service. Here are some items to look for when integrating with backend services:</p>
			<ul class="calibre7">
				<li class="calibre8">Can the required data be supplemented automatically? Users should not have to supply every piece of data. For example, the API might need five pieces of data to submit a valid request. Some can come from the context and focus the user on the essential elements.</li>
				<li class="calibre8">Will the response time be fast enough to be integrated with the response? Think in milliseconds (200 or less would be good, 50 or less would be great, sub-10s are world-class).</li>
				<li class="calibre8">Can a single API be called instead of two or three? Optimized API calls help with cost, performance, and the number of round trips.</li>
				<li class="calibre8">Is the data format consistent with the customer’s needs? If not, consider telling ChatGPT how to format it or providing conversations or translations in the correct format. For example, understand the user’s time zone and don’t use GMT or other time zones.</li>
			</ul>
			<h3 class="calibre11">Integrations and actions</h3>
			<p class="calibre3">The ChatGPT <a id="_idIndexMarker469" class="pcalibre pcalibre1 calibre6"/>economy is growing in leaps and bounds. There are <a id="_idIndexMarker470" class="pcalibre pcalibre1 calibre6"/>dozens of popular services and integrations to make processes more seamless and practical.</p>
			<p class="calibre3">The development team might support other tools to help create a complete solution. It would be best to get involved to determine how to apply design thinking and your expertise to support a more sustainable process.</p>
			<p class="calibre3">There are plenty of libraries, tools, and resources online. Comparing and contrasting the wealth of options is out of scope, but a few examples that relate to making effective, well-designed solutions that OpenAI posted can be worth your time:</p>
			<p class="calibre3">Article: <a href="https://cookbook.openai.com/articles/related_resources" class="pcalibre pcalibre1 calibre6">OpenAI Cookbook</a> (<a href="https://cookbook.openai.com/articles/related_resources" class="pcalibre pcalibre1 calibre6">https://cookbook.openai.com/articles/related_resources</a>)</p>
			<p class="calibre3">Article: <a href="https://www.langchain.com/langsmith" class="pcalibre pcalibre1 calibre6">LangChain home page</a> (<a href="https://www.langchain.com/langsmith" class="pcalibre pcalibre1 calibre6">https://www.langchain.com/langsmith</a>)</p>
			<p class="calibre3">Article: <a href="https://zilliz.com/blog/customizing-openai-built-in-retrieval-using-milvus-vector-database" class="pcalibre pcalibre1 calibre6">Milvus Vector database</a> (<a href="https://zilliz.com/blog/customizing-openai-built-in-retrieval-using-milvus-vector-database" class="pcalibre pcalibre1 calibre6">https://zilliz.com/blog/customizing-openai-built-in-retrieval-using-milvus-vector-database</a>)</p>
			<p class="calibre3">The LLM can be just <em class="italic">one</em> of the services within the entire lifecycle or pipeline. This means faults can occur before or after the LLM. Look carefully before placing <a id="_idIndexMarker471" class="pcalibre pcalibre1 calibre6"/>blame on the model. It is only as good as the input and instructions provided. Improve the quality of what is shared with the model. Design how to share <a id="_idIndexMarker472" class="pcalibre pcalibre1 calibre6"/>data with the LLM and then test and verify how it works. <em class="italic">Be fully committed to an iterative lifecycle to make successful generative AI solutions.</em> Quality is all about the care and feeding process. Since improvements are only improvements if we measure them, this is explored in <a href="B21964_10_split_000.xhtml#_idTextAnchor216" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 10</em></a><em class="italic">, Monitoring and Evaluation</em>. Ragas is one of those tools to consider using to measure how the RAG solution is performing. If this excites you, check it out now.</p>
			<p class="calibre3">Link: <a href="https://docs.ragas.io/en/latest/" class="pcalibre pcalibre1 calibre6">Ragas Documentation</a> (<a href="https://docs.ragas.io/en/latest/" class="pcalibre pcalibre1 calibre6">https://docs.ragas.io/en/latest/</a>)</p>
			<p class="calibre3">ChatGPT has a <a id="_idIndexMarker473" class="pcalibre pcalibre1 calibre6"/>concept called actions (formerly called plugins). These allow ChatGPT to connect to the rest of the internet. Actions rely on function calling to perform these actions. Recall that the Wove example used function calling.</p>
			<p class="calibre3">Documentation: <a href="https://platform.openai.com/docs/actions/introduction" class="pcalibre pcalibre1 calibre6">Actions in GPTs (Calling APIs)</a> (<a href="https://platform.openai.com/docs/actions/introduction" class="pcalibre pcalibre1 calibre6">https://platform.openai.com/docs/actions/introduction</a>)</p>
			<p class="calibre3">What is impressive is that developers do not have to write these API queries by hand. ChatGPT has a bespoke LLM tuned to help developers write actions.</p>
			<p class="calibre3">Demo: <a href="https://chatgpt.com/g/g-TYEliDU6A-actionsgpt" class="pcalibre pcalibre1 calibre6">ActionsGPT chat</a> (<a href="https://chatgpt.com/g/g-TYEliDU6A-actionsgpt" class="pcalibre pcalibre1 calibre6">https://chatgpt.com/g/g-TYEliDU6A-actionsgpt</a>)</p>
			<p class="calibre3">Developers can send messages to the LLM to generate the base code. For example, they can try something like this.</p>
			<pre class="source-code">
Make a spec to call the endpoint at https://api.openai.com/v1 with a POST request. The request should have a body with model and prompt keys - both are strings.</pre>			<p class="calibre3">Share these resources and this video with developers to help them get started.</p>
			<p class="calibre3">Video: <a href="https://www.youtube.com/watch?v=pq34V_V5j18" class="pcalibre pcalibre1 calibre6">Introduction to ChatGPT Actions</a> (<a href="https://www.youtube.com/watch?v=pq34V_V5j18" class="pcalibre pcalibre1 calibre6">https://www.youtube.com/watch?v=pq34V_V5j18</a>) (Actions start at 9:30)</p>
			<p class="calibre3">Figuring out these linkages is for development. As a product leader, know that a wealth of services is available for integration from enterprise sources to make the solution support intelligence that combines these. To create these connections, <a id="_idIndexMarker474" class="pcalibre pcalibre1 calibre6"/>the paid version of ChatGPT, if not the enterprise version, is needed. In the ChatGPT video, Nick Turley <a id="_idIndexMarker475" class="pcalibre pcalibre1 calibre6"/>hooks up his personal to-do list from asana.com to the chat instance in the demo. <em class="italic">Figure 6</em><em class="italic">.14</em> shows the current actions setup. It is a simple UI to name, describe, and define the instructions.</p>
			<div><div><img src="img/B21964_06_14.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.14 – Setting up actions on the Configure tab</p>
			<p class="calibre3">The demo goes further with embedding knowledge to help with summarizing. Watch to get a good sense of the integrations fundamental to enterprise solutions. At the 20-minute mark, it gets a little creative with a mood demo. They do a great demo of integrating with physical devices in the demo room and Spotify to play music. The point is that enterprise solutions can be more than just software integrations. Manufacturing, lighting, HVAC (air conditioning), processes, routing, planning, and more can be improved with intelligent integration. This takes us back to our chapter on use cases. There are lots of opportunities out there.</p>
			<p class="calibre3">This book is intended to be practical even when the tools change—and they will—so don’t get hung up on a tool or direction. New and more robust services <a id="_idIndexMarker476" class="pcalibre pcalibre1 calibre6"/>will be introduced frequently. Build a lean process that supports adaptation and change. Learn from the LLM community. The number of blogs, posts, and training opportunities is expanding daily.</p>
			<h2 id="_idParaDest-142" class="calibre9"><a id="_idTextAnchor145" class="pcalibre pcalibre1 calibre6"/>Community resources</h2>
			<p class="calibre3">A wealth of resources exists, including in the OpenAI community. Explore these resources, the latest videos, and research to get up to speed.</p>
			<p class="calibre3">Article: <a href="https://community.openai.com/t/rag-is-not-really-a-solution/599291/2" class="pcalibre pcalibre1 calibre6">RAG Community Discussion</a> (<a href="https://community.openai.com/t/rag-is-not-really-a-solution/599291/2" class="pcalibre pcalibre1 calibre6">https://community.openai.com/t/rag-is-not-really-a-solution/599291/2</a>)</p>
			<p class="calibre3">In Ron Parker’s post, he discusses RAG as being brittle.</p>
			<p class="author-quote">"The biggest problem I’ve run into so far is that some query responses are not comprehensive enough. End-users can almost always get a complete answer using chain-of-thought queries (few-shot). But, the end-users I’ve been working with want complete answers to the first question (zero-shot). This may touch on your issue.</p>
			<p class="author-quote">My resolution: Deep Dive. Have the model dig through all the possible responses, categorize and analyze those, and then return a complete list of the best responses. Since I built my RAG system, I must also develop this feature. So I’m thinking, whatever you say this technique is you’re missing, you may have to build it yourself."</p>
			<p class="calibre3">This makes our point. This is about building solutions, and this puzzle has many pieces. He also points out a good usability issue. Users don’t want to have conversations to get to their answers. They want the complete answer on the first try. Even in our case study with Wove, they worked hard to return the best responses and iterate on the training to get the correct answers. They had to figure out the model and chunk the rate sheets, and then they refined those answers to improve the model. Again, it involves honest work by the development team; work with them to improve the quality with every step<a id="_idTextAnchor146" class="pcalibre pcalibre1 calibre6"/><a id="_idTextAnchor147" class="pcalibre pcalibre1 calibre6"/>.</p>
			<p class="calibre3">Or, check out a nice video showing how Mayo Oshin (<strong class="bold">@maywaoshin</strong>) used GPT-4 to front-end thousands of pages from PDF documents—in this case, the last few years of Tesla’s annual <a id="_idIndexMarker477" class="pcalibre pcalibre1 calibre6"/>reports. He walks through his <a id="_idIndexMarker478" class="pcalibre pcalibre1 calibre6"/>architecture. Most of that will be too much, but he talks about how he converts documents into text and chunks of documents. This discussion is right on point for us.</p>
			<p class="calibre3">Video:<a href="https://www.youtube.com/watch?v=Ix9WIZpArm0" class="pcalibre pcalibre1 calibre6"> Example of 1000+ Pages of PDF</a> (<a href="https://www.youtube.com/watch?v=Ix9WIZpArm0" class="pcalibre pcalibre1 calibre6">https://www.youtube.com/watch?v=Ix9WIZpArm0</a>)</p>
			<p class="calibre3">The last resource for our discussion is the previously mentioned video on lessons learned around RAG.</p>
			<p class="calibre3">Video: <a href="https://www.youtube.com/live/Y9qn4XGH1TI?si=iUs_x3yDL8BK7aUb56" class="pcalibre pcalibre1 calibre6">Lessons Learned on LLM RAG Solutions</a> (<a href="https://www.youtube.com/live/Y9qn4XGH1TI?si=iUs_x3yDL8BK7aUb56" class="pcalibre pcalibre1 calibre6">https://www.youtube.com/live/Y9qn4XGH1TI?si=iUs_x3yDL8BK7aUb56</a>)</p>
			<p class="calibre3">They cover a variety of good things about managing documents. Here is a summary:</p>
			<ul class="calibre7">
				<li class="calibre8">They remind everyone to do good “data science” and make sure to have good data going in. Also, that accurate data is messy. Not only are tables tricky (something discussed in this chapter), but different document formats can need different libraries to help clean them (or the headache of manual cleaning).</li>
				<li class="calibre8">Explanations might not be directly linked to information. Comments or notes around negation ("does not have", "except for this version", "does not apply") can negate some documentation that does not even appear in a chunk that it relates to and might only be understood with additional editing or tagging.</li>
				<li class="calibre8">Maintain structure. Convert documents to a data structure while preserving their meaning. For example, when PDFs are converted to text, a model can decide how to parse the PDFs, identify headings, and build out and capture information to put it into a meaningful structure.</li>
				<li class="calibre8">If the documents are hierarchical, a flat representation is needed, so try to get to a list of elements. The key for a part of the element can represent a section. This kind of discussion is more for the data ingestion team, but look for these issues when testing. This way, test results can verify that context is maintained. Help the data scientists maintain quality.</li>
				<li class="calibre8">Different <a id="_idIndexMarker479" class="pcalibre pcalibre1 calibre6"/>methods result in <a id="_idIndexMarker480" class="pcalibre pcalibre1 calibre6"/>different quality. As discussed, sentence-by-sentence embedding will lose some context.</li>
				<li class="calibre8">As discussed, get the proper context in chunks. It should not be too narrow or too broad; it should be <em class="italic">just right</em>. The approach in <em class="italic">Figure 6</em><em class="italic">.15</em> reminds us of what was discussed at the start of the chapter.</li>
			</ul>
			<div><div><img src="img/B21964_06_15.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.15 – Prolego’s approach is similar to our discussion earlier in the chapter</p>
			<p class="calibre3">Several videos from Prolego (besides the one shared) are easy to digest and well-paced. This is just one example of the wealth of video and article resources that can help on a RAG journey. Don’t build everything yourself; the LLM vendors are only one piece of a more extensive solution that includes tools, documentation, databases, and APIs.</p>
			<p class="calibre3">Besides RAG, there are wonderful posts on every imaginable topic around LLMs on LinkedIn, shared in mailing lists, posted on YouTube, classes from universities, and vendor websites.</p>
			<h1 id="_idParaDest-143" class="calibre5"><a id="_idTextAnchor148" class="pcalibre pcalibre1 calibre6"/>Summary</h1>
			<p class="calibre3">It is a big step to prepare an existing knowledge base and data sources to make them available within a generative AI solution. It’s likely the most significant step because the hard work of creating the ChatGPT model was done for you. For many enterprise solutions, this can be an overwhelming task. Just start small. Learn from the use cases to prioritize solutions that provide the most significant value with the least cost (recall our scoring discussion in <a href="B21964_04.xhtml#_idTextAnchor085" class="pcalibre pcalibre1 calibre6"><em class="italic">Chapter 4</em></a>, <em class="italic">Scoring Stories</em>). Over time, land grabs can expand into other data sources and, thus, new use cases. All of this has to be done with quality in mind. Measuring and monitoring are critical. Newer doesn’t mean better. Mix and match ChatGPT models to perform specific tasks or optimize cost or performance by using one model over another. Use a collection of third-party resources—possibly even other models tuned to a particular problem space—to refine results, make data available to the model, or do additional integrations. Be aware of the impact of data cleaning and how the knowledge in the base model might impact the solution’s decision-making ability. Recognize that bias isn’t just about social or political positions; it can simply be about having too much data about one product, and this causes the model to miss smaller products. Getting all of this right with the enterprise data is a challenge.</p>
			<p class="calibre3">This chapter mainly focused on awareness and considered how techniques can influence the quality of inbound data sources. On the outbound side, testing and completing the feedback loop is a great way to improve the solution. There should be many opportunities to contribute before moving on to the next steps around prompt engineering and fine-tuning.</p>
			<h1 id="_idParaDest-144" class="calibre5"><a id="_idTextAnchor149" class="pcalibre pcalibre1 calibre6"/>References</h1>
			<table id="table003-5" class="no-table-style">
				<colgroup class="calibre15">
					<col class="calibre16"/>
					<col class="calibre16"/>
				</colgroup>
				<tbody class="calibre17">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<div><div><img src="img/B21964_06_16.jpg" alt="" role="presentation" class="calibre4"/>
								</div>
							</div>
						</td>
						<td class="no-table-style2">
							<p class="calibre3">The links, book recommendations, and GitHub files in this chapter are posted on the reference page.</p>
							<p class="calibre3">Web page: <a href="https://uxdforai.com/references#C6" class="pcalibre pcalibre1 calibre6">Chapter 6 References</a> (<a href="https://uxdforai.com/references#C6" class="pcalibre pcalibre1 calibre6">https://uxdforai.com/references#C6</a>)</p>
						</td>
					</tr>
				</tbody>
			</table>
		</div>
	</body></html>