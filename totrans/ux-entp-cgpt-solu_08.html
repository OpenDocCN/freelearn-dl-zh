<html><head></head><body>
		<div id="_idContainer086" class="calibre2">
			<h1 id="_idParaDest-132" class="chapter-number"><a id="_idTextAnchor134" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.1.1">6</span></h1>
			<h1 id="_idParaDest-133" class="calibre5"><a id="_idTextAnchor135" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.2.1">Gathering Data – Content  is King</span></h1>
			<p class="calibre3"><span class="kobospan" id="kobo.3.1">There is an assumption in this book: enterprise ChatGPT solutions are needed in almost all cases because a company has something unique to offer its customers, and it possesses an exceptional understanding of its products, services, and content. </span><span class="kobospan" id="kobo.3.2">This content is private </span><a id="_idIndexMarker355" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.4.1">or unique and thus not part of </span><strong class="bold"><span class="kobospan" id="kobo.5.1">large language models</span></strong><span class="kobospan" id="kobo.6.1"> (</span><strong class="bold"><span class="kobospan" id="kobo.7.1">LLMs</span></strong><span class="kobospan" id="kobo.8.1">) built from scraping the internet. </span><span class="kobospan" id="kobo.8.2">Models are built on crawling the 2+ billion pages of web content to teach the model.  </span><span class="kobospan" id="kobo.8.3">A third party, Commoncrawl.org, is commonly cited as a primary source of this material for major models (GPT-3, Llama). </span><span class="kobospan" id="kobo.8.4">These models, which are massive collections of text, learn the statistical relationships of words and concepts and can be used to predict and respond to questions. </span><span class="kobospan" id="kobo.8.5">Creating a model can take months; most have billions of connections and words. </span><span class="kobospan" id="kobo.8.6">When customers come to the enterprise for answers, the models must include enterprise content that is not part of this crawl to make them unique, secure, and more accurate. </span><span class="kobospan" id="kobo.8.7">This is done with the expectation that the solutions will be up to date, optimized to be cost-effective, and less prone to hallucinations or lying, as some </span><span><span class="kobospan" id="kobo.9.1">call it.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.10.1">This chapter addresses gathering data for the LLM and how to include enterprise data sources in LLM solutions </span><a id="_idIndexMarker356" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.11.1">using a method called </span><strong class="bold"><span class="kobospan" id="kobo.12.1">Retrieval Augmented Generation</span></strong><span class="kobospan" id="kobo.13.1"> (</span><strong class="bold"><span class="kobospan" id="kobo.14.1">RAG</span></strong><span class="kobospan" id="kobo.15.1">). </span><span class="kobospan" id="kobo.15.2">We’ll discuss the </span><span><span class="kobospan" id="kobo.16.1">following topics:</span></span></p>
			<ul class="calibre7">
				<li class="calibre8"><span class="kobospan" id="kobo.17.1">What is in a ChatGPT </span><span><span class="kobospan" id="kobo.18.1">foundational model</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.19.1">Incorporating enterprise data </span><span><span class="kobospan" id="kobo.20.1">using RAG</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.21.1">Resources </span><span><span class="kobospan" id="kobo.22.1">for RAG</span></span></li>
			</ul>
			<p class="calibre3"><span class="kobospan" id="kobo.23.1">This chapter and the next few will be more technical for those who have reached this point and are focused on user-centered design concepts. </span><span class="kobospan" id="kobo.23.2">The chapter covers all the ideas and provides access to additional videos and online resources. </span><span class="kobospan" id="kobo.23.3">The book does not require most of these external resources; they are meant to give </span><span><span class="kobospan" id="kobo.24.1">more details.</span></span></p>
			<h1 id="_idParaDest-134" class="calibre5"><a id="_idTextAnchor136" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.25.1">What is in a ChatGPT foundational model</span></h1>
			<p class="calibre3"><span class="kobospan" id="kobo.26.1">When an LLM is built, it is trained on sources of data from the internet. </span><span class="kobospan" id="kobo.26.2">It knows </span><a id="_idIndexMarker357" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.27.1">publicly available information about companies and products. </span><span class="kobospan" id="kobo.27.2">If asked typical enterprise-like questions, it can get robust answers – sometimes better than what is available from some vendors’ websites. </span><span><span class="kobospan" id="kobo.28.1">For example:</span></span></p>
			<pre class="source-code"><span class="kobospan1" id="kobo.29.1">
What are the advantages of Hana for a database?
</span><span class="kobospan1" id="kobo.29.2">What is a good value for SGA for an Oracle 12.2 transactional database?
</span><span class="kobospan1" id="kobo.29.3">Can you easily replace the battery in an iPhone?
</span><span class="kobospan1" id="kobo.29.4">How do I return a product to Costco?</span></pre>			<p class="calibre3"><span class="kobospan" id="kobo.30.1">Try these questions out and notice a trend. </span><span class="kobospan" id="kobo.30.2">Each answer is slightly more generic than the previous one, and that generic nature is part of </span><span><span class="kobospan" id="kobo.31.1">the problem.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.32.1">The following applies to most foundational models such as ChatGPT 3.5 or 4o, Anthropic’s Claude, Meta’s Llama, </span><span><span class="kobospan" id="kobo.33.1">or Mistral7B:</span></span></p>
			<ul class="calibre7">
				<li class="calibre8"><span class="kobospan" id="kobo.34.1">Don’t understand specific business or use context or </span><span><span class="kobospan" id="kobo.35.1">complex products</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.36.1">Don’t have customer history or context </span><span><span class="kobospan" id="kobo.37.1">to consider</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.38.1">Can’t access proprietary </span><span><span class="kobospan" id="kobo.39.1">knowledge sources</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.40.1">Are not trained on service requests or other service data and won’t know correct assumptions from incorrect assumptions and </span><span><span class="kobospan" id="kobo.41.1">inaccurate solutions</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.42.1">Can’t integrate with databases or APIs for retrieval and </span><span><span class="kobospan" id="kobo.43.1">task performance</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.44.1">Can’t be scaled or tuned </span><span><span class="kobospan" id="kobo.45.1">for multi-tenancy</span></span></li>
			</ul>
			<p class="calibre3"><span class="kobospan" id="kobo.46.1">Now imagine those questions if they were in the context of rich </span><span><span class="kobospan" id="kobo.47.1">business knowledge:</span></span></p>
			<pre class="source-code"><span class="kobospan1" id="kobo.48.1">
What are the advantages of Hana for a database connecting to my service application running ServiceNow on the Washington DC release?
</span><span class="kobospan1" id="kobo.48.2">What is a good value for SGA for an Oracle 12.2 transactional database when connecting to EBS 13.2 with 1200 concurrent users?
</span><span class="kobospan1" id="kobo.48.3">How do I replace the battery in the iPhone 15 Pro?
</span><span class="kobospan1" id="kobo.48.4">How do I return a product from my last order to Costco that was oversized and delivered?</span></pre>			<p class="calibre3"><span class="kobospan" id="kobo.49.1">Integrating data sources with ChatGPT to contextualize the solution to the business can address these richer questions. </span><span class="kobospan" id="kobo.49.2">No matter the design pattern used, such as a chat UI, a hybrid experience, or a standalone recommender, enterprise data will make the solution powerful. </span><span class="kobospan" id="kobo.49.3">Foundational models gain access to knowledge with Retrieval Augmented Generation </span><span><span class="kobospan" id="kobo.50.1">or </span></span><span><strong class="bold"><span class="kobospan" id="kobo.51.1">RAG</span></strong></span><span><span class="kobospan" id="kobo.52.1">.</span></span></p>
			<h1 id="_idParaDest-135" class="calibre5"><a id="_idTextAnchor137" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.53.1">Incorporating enterprise data using RAG</span></h1>
			<p class="calibre3"><span class="kobospan" id="kobo.54.1">There are other ways of taking data and making it part of an LLM. </span><span class="kobospan" id="kobo.54.2">It is possible to build a foundation model</span><a id="_idIndexMarker358" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.55.1">, but as mentioned, the </span><a id="_idIndexMarker359" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.56.1">training time and effort are extreme. </span><span class="kobospan" id="kobo.56.2">Even with RAG, there are different approaches. </span><span class="kobospan" id="kobo.56.3">Some technical resources are shared, but this chapter will focus on and teach RAG understanding and how product people can contribute to the development process. </span><span class="kobospan" id="kobo.56.4">First, a </span><span><span class="kobospan" id="kobo.57.1">RAG explanation.</span></span></p>
			<h2 id="_idParaDest-136" class="calibre9"><a id="_idTextAnchor138" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.58.1">Understanding RAG</span></h2>
			<p class="calibre3"><span class="kobospan" id="kobo.59.1">RAG supplements LLMs with enterprise data. </span><span class="kobospan" id="kobo.59.2">RAG is a technique for retrieving </span><a id="_idIndexMarker360" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.60.1">information, such as from a knowledge base, and it can generate responses from authoritative knowledge collection with coherent and contextually </span><span><span class="kobospan" id="kobo.61.1">accurate answers.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.62.1">This methodology allows us to overcome some generic </span><span><span class="kobospan" id="kobo.63.1">model problems:</span></span></p>
			<ul class="calibre7">
				<li class="calibre8"><span class="kobospan" id="kobo.64.1">Material is always up to date since it is evaluated </span><span><span class="kobospan" id="kobo.65.1">when prompted.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.66.1">Tools can reference the document source and, thus, are </span><span><span class="kobospan" id="kobo.67.1">more trustworthy.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.68.1">The foundational model is already trained, so supplementing it is inexpensive compared to building a model </span><span><span class="kobospan" id="kobo.69.1">from scratch.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.70.1">It allows for a robust set of resources (APIs, SQL databases, and various document and presentation file formats) to continue to be managed independently (and still available to </span><span><span class="kobospan" id="kobo.71.1">other solutions).</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.72.1">It will </span><em class="italic"><span class="kobospan" id="kobo.73.1">NOT</span></em><span class="kobospan" id="kobo.74.1"> be used to throw </span><em class="italic"><span class="kobospan" id="kobo.75.1">ALL</span></em><span class="kobospan" id="kobo.76.1"> data into the LLM. </span><span class="kobospan" id="kobo.76.2">A mechanism will be used to send relevant documents to the LLM just in time </span><span><span class="kobospan" id="kobo.77.1">for processing.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.78.1">It allows for unique, secure answers with </span><span><span class="kobospan" id="kobo.79.1">multiple customers.</span></span></li>
			</ul>
			<p class="calibre3"><span class="kobospan" id="kobo.80.1">Technical work is needed to create a RAG pipeline. </span><span class="kobospan" id="kobo.80.2">Even if this book isn’t about the development effort to create a RAG pipeline, it still stands to reason that a basic understanding of how data becomes valuable to the ChatGPT solution is needed. </span><span class="kobospan" id="kobo.80.3">First,  consider what would happen </span><em class="italic"><span class="kobospan" id="kobo.81.1">if</span></em><span class="kobospan" id="kobo.82.1"> all the enterprise data is thrown into the LLM. </span><span class="kobospan" id="kobo.82.2">It would look something like </span><span><em class="italic"><span class="kobospan" id="kobo.83.1">Figure 6</span></em></span><span><em class="italic"><span class="kobospan" id="kobo.84.1">.1</span></em></span><span><span class="kobospan" id="kobo.85.1">.</span></span></p>
			<div class="calibre2">
				<div id="_idContainer069" class="img---figure">
					<span class="kobospan" id="kobo.86.1"><img src="image/B21964_06_01.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.87.1">Figure 6.1 – A model where we add all our knowledge directly to the LLM</span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.88.1">The model in </span><span><em class="italic"><span class="kobospan" id="kobo.89.1">Figure 6</span></em></span><em class="italic"><span class="kobospan" id="kobo.90.1">.1</span></em><span class="kobospan" id="kobo.91.1"> assumes it can handle all company knowledge and include it in an OpenAI model, resulting in a custom company model. </span><span class="kobospan" id="kobo.91.2">This sounds right, but the cost and </span><em class="italic"><span class="kobospan" id="kobo.92.1">months</span></em><span class="kobospan" id="kobo.93.1"> it </span><a id="_idIndexMarker361" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.94.1">takes to create it are very high. </span><span class="kobospan" id="kobo.94.2">There needs to be a way for the LLM to access all of our resources without the cost and complexity. </span><span class="kobospan" id="kobo.94.3">Let’s review some limitations to find a solution to </span><span><span class="kobospan" id="kobo.95.1">this problem.</span></span></p>
			<h2 id="_idParaDest-137" class="calibre9"><a id="_idTextAnchor139" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.96.1">Limitations of ChatGPT and RAG</span></h2>
			<p class="calibre3"><span class="kobospan" id="kobo.97.1">To be clear, there are two kinds of limitations worth discussing. </span><span class="kobospan" id="kobo.97.2">The first is the limitations of knowledge retrieval using OpenAI models or any models. </span><span class="kobospan" id="kobo.97.3">In contrast, the </span><a id="_idIndexMarker362" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.98.1">second is the limitations of RAG, even when integrating third-party solutions to build an enterprise </span><span><span class="kobospan" id="kobo.99.1">RAG solution.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.100.1">Most enterprise </span><a id="_idIndexMarker363" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.101.1">solutions will find data integration requirements within OpenAI limiting and look elsewhere for scalability, cost, and performance. </span><span class="kobospan" id="kobo.101.2">With OpenAI File Search, which is their way of augmenting the LLM with knowledge, there are </span><span><span class="kobospan" id="kobo.102.1">technical limits:</span></span></p>
			<ul class="calibre7">
				<li class="calibre8"><span class="kobospan" id="kobo.103.1">Maximum file size of </span><span><span class="kobospan" id="kobo.104.1">512 MB</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.105.1">A limit of 5M tokens (up from 2M in the spring </span><span><span class="kobospan" id="kobo.106.1">of 2024)</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.107.1">ChatGPT Enterprise supports a context length of 128K (up from 32K in the free version and the first </span><span><span class="kobospan" id="kobo.108.1">Enterprise release)</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.109.1">Some limits on file formats (</span><strong class="source-inline1"><span class="kobospan" id="kobo.110.1">.pdf</span></strong><span class="kobospan" id="kobo.111.1">, </span><strong class="source-inline1"><span class="kobospan" id="kobo.112.1">.md</span></strong><span class="kobospan" id="kobo.113.1">, </span><strong class="source-inline1"><span class="kobospan" id="kobo.114.1">.docx</span></strong><span class="kobospan" id="kobo.115.1">) – the complete list </span><span><span class="kobospan" id="kobo.116.1">is here:</span></span><ul class="calibre19"><li class="calibre8"><span class="kobospan" id="kobo.117.1">Documentation: </span><a href="https://platform.openai.com/docs/assistants/tools/file-search/supported-files" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.118.1">Supported file </span><span><span class="kobospan" id="kobo.119.1">formats</span></span></a><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.120.1">(</span></span></span><a href="https://platform.openai.com/docs/assistants/tools/file-search/supported-files" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.121.1">https://platform.openai.com/docs/assistants/tools/file-search/supported-files</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.122.1">)</span></span></span></li></ul></li>
				<li class="calibre8"><span class="kobospan" id="kobo.123.1">Storage fees are $0.20/GB per assistant </span><span><span class="kobospan" id="kobo.124.1">per day.</span></span></li>
			</ul>
			<p class="calibre3"><span class="kobospan" id="kobo.125.1">These limits (as of September 2024) will change with some frequency. </span><span class="kobospan" id="kobo.125.2">These limitations mean third parties are needed </span><span><span class="kobospan" id="kobo.126.1">for solutions.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.127.1">There are also some </span><span><span class="kobospan" id="kobo.128.1">quality limitations:</span></span></p>
			<ul class="calibre7">
				<li class="calibre8"><span class="kobospan" id="kobo.129.1">Model data is available to everyone who has access to the model. </span><span class="kobospan" id="kobo.129.2">Security barriers or limits are </span><span><span class="kobospan" id="kobo.130.1">not implicit.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.131.1">It won’t differentiate between general knowledge and internal knowledge. </span><span class="kobospan" id="kobo.131.2">There are weights and an ability to prioritize and emphasize material, but it can still hallucinate without </span><span><span class="kobospan" id="kobo.132.1">good reason.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.133.1">When changes are made to knowledge, retraining is required and expensive. </span><span class="kobospan" id="kobo.133.2">Since results need to be accurate and timely, this becomes </span><span><span class="kobospan" id="kobo.134.1">a show-stopper.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.135.1">OpenAI’s File Search for knowledge retrieval handles one part of the process and doesn’t have the additional value of RAG around scale and data </span><span><span class="kobospan" id="kobo.136.1">input types.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.137.1">There is a limit to how much can be shared with the LLM at one time. </span><span class="kobospan" id="kobo.137.2">This is called the context window, and this chapter covers how to chunk information to fit into that context window. </span><span class="kobospan" id="kobo.137.3">The larger the context window, the more knowledge and enterprise data can be shared with the LLM at one time to formulate answers. </span><span class="kobospan" id="kobo.137.4">As the window grows larger, less RAG is needed to pre-fetch material. </span><span class="kobospan" id="kobo.137.5">RAG is a more scalable and </span><span><span class="kobospan" id="kobo.138.1">cost-effective approach.</span></span></li>
			</ul>
			<p class="calibre3"><span class="kobospan" id="kobo.139.1">Third-party solutions help avoid </span><a id="_idIndexMarker364" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.140.1">these limitations. </span><span class="kobospan" id="kobo.140.2">To demo and understand </span><a id="_idIndexMarker365" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.141.1">the space for this book, the OpenAI built-in tools will work for the small demos. </span><span class="kobospan" id="kobo.141.2">However, an enterprise solution will work with a third-party app for a production instance. </span><span class="kobospan" id="kobo.141.3">The knowledge gained from these chapters is relevant to </span><span><span class="kobospan" id="kobo.142.1">any LLM.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.143.1">It is good to start with OpenAI’s built-in capabilities using the playground, so no coding is needed. </span><span class="kobospan" id="kobo.143.2">No need to go to the documentation right now, but it is included anyway. </span><span class="kobospan" id="kobo.143.3">This approach allows us to get a taste of custom models without the overhead required by a complete </span><span><span class="kobospan" id="kobo.144.1">enterprise solution.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.145.1">Article: </span><a href="https://platform.openai.com/docs/assistants/tools/file-search/quickstart" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.146.1">OpenAI’s File Search </span><span><span class="kobospan" id="kobo.147.1">Documentation</span></span></a><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.148.1">(</span></span></span><a href="https://platform.openai.com/docs/assistants/tools/file-search/quickstart" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.149.1">https://platform.openai.com/docs/assistants/tools/file-search/quickstart</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.150.1">)</span></span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.151.1">It takes significant work to go from data (this chapter) to </span><a href="B21964_07.xhtml#_idTextAnchor150" class="pcalibre pcalibre1 calibre6"><span><em class="italic"><span class="kobospan" id="kobo.152.1">Chapter 7</span></em></span></a><span class="kobospan" id="kobo.153.1">, </span><em class="italic"><span class="kobospan" id="kobo.154.1">Prompt Engineering</span></em><span class="kobospan" id="kobo.155.1">, and then to the next steps shown in </span><a href="B21964_08.xhtml#_idTextAnchor172" class="pcalibre pcalibre1 calibre6"><span><em class="italic"><span class="kobospan" id="kobo.156.1">Chapter 8</span></em></span></a><span class="kobospan" id="kobo.157.1">, </span><em class="italic"><span class="kobospan" id="kobo.158.1">Fine-Tuning</span></em><span class="kobospan" id="kobo.159.1"> so that a solution can be reviewed with </span><a href="B21964_09_split_000.xhtml#_idTextAnchor190" class="pcalibre pcalibre1 calibre6"><span><em class="italic"><span class="kobospan" id="kobo.160.1">Chapter 9</span></em></span></a><span class="kobospan" id="kobo.161.1">, </span><em class="italic"><span class="kobospan" id="kobo.162.1">Guidelines and Heuristics</span></em><span class="kobospan" id="kobo.163.1">, and then analyzed for success in </span><a href="B21964_10_split_000.xhtml#_idTextAnchor216" class="pcalibre pcalibre1 calibre6"><span><em class="italic"><span class="kobospan" id="kobo.164.1">Chapter 10</span></em></span></a><span class="kobospan" id="kobo.165.1">, </span><em class="italic"><span class="kobospan" id="kobo.166.1">Monitoring and Evaluation</span></em><span class="kobospan" id="kobo.167.1">. </span><span class="kobospan" id="kobo.167.2">For more resources, visit the OpenAI cookbook. </span><span class="kobospan" id="kobo.167.3">It has a wealth of articles covering the entire LLM lifecycle, gives many good explanations and definitions, and lays out the process. </span><span class="kobospan" id="kobo.167.4">Here is one </span><span><span class="kobospan" id="kobo.168.1">good article.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.169.1">Article: </span><a href="https://cookbook.openai.com/examples/fine-tuned_qa/ft_retrieval_augmented_generation_qdrant" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.170.1">An OpenAI cookbook article on Fine-Tuning for RAG using </span><span><span class="kobospan" id="kobo.171.1">Qdrant</span></span></a><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.172.1">(</span></span></span><a href="https://cookbook.openai.com/examples/fine-tuned_qa/ft_retrieval_augmented_generation_qdrant" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.173.1">https://cookbook.openai.com/examples/fine-tuned_qa/ft_retrieval_augmented_generation_qdrant</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.174.1">)</span></span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.175.1">The article is technical, but the concepts reinforce the learnings from this book. </span><span class="kobospan" id="kobo.175.2">There needs to be a way to provide material to the model that doesn’t require retraining and can handle the scale of the enterprise problem. </span><span class="kobospan" id="kobo.175.3">This is done by implementing a form of RAG that works off of an index of the knowledge and provides only relevant material, as needed, to the LLM. </span><strong class="bold"><span class="kobospan" id="kobo.176.1">Indexing</span></strong><span class="kobospan" id="kobo.177.1"> is a way </span><a id="_idIndexMarker366" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.178.1">to organize information for fast retrieval and </span><a id="_idIndexMarker367" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.179.1">comparison. </span><span class="kobospan" id="kobo.179.2">There is not only one way to do this, but we’ll look at the basic approach to form an understanding of RAG. </span><span class="kobospan" id="kobo.179.3">Some of the steps are beyond the scope of this book. </span><span class="kobospan" id="kobo.179.4">Anyone reading is unlikely to build an LLM from scratch. </span><span class="kobospan" id="kobo.179.5">Product people, especially those responsible for the knowledgebase or database resources, can improve the data coming into the solution to provide the indexing and LLM with the best chance of returning high-quality results. </span><span class="kobospan" id="kobo.179.6">So, technology is introduced to handle the scale, performance, and quality needed. </span><span class="kobospan" id="kobo.179.7">See </span><span><em class="italic"><span class="kobospan" id="kobo.180.1">Figure 6</span></em></span><em class="italic"><span class="kobospan" id="kobo.181.1">.2</span></em><span class="kobospan" id="kobo.182.1">. </span><span class="kobospan" id="kobo.182.2">This requires us to focus on getting data into shape for indexing. </span><span class="kobospan" id="kobo.182.3">In this approach, only relevant information is shared with the LLM to </span><span><span class="kobospan" id="kobo.183.1">develop answers.</span></span></p>
			<div class="calibre2">
				<div id="_idContainer070" class="img---figure">
					<span class="kobospan" id="kobo.184.1"><img src="image/B21964_06_02.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.185.1">Figure 6.2 – Introducing the RAG solution to assist in the question-to-answer process</span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.186.1">This is dramatically </span><a id="_idIndexMarker368" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.187.1">oversimplifying the process. </span><span class="kobospan" id="kobo.187.2">The indexing icon shown </span><a id="_idIndexMarker369" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.188.1">is a set of processes that result in a </span><em class="italic"><span class="kobospan" id="kobo.189.1">limited</span></em><span class="kobospan" id="kobo.190.1"> number of documents to share with the LLM as context for the question (this context is shared within the prompt – this prompt being the instructions shared with the LLM).  </span><span class="kobospan" id="kobo.190.2">The ingestion process includes cleaning the data, converting it to text, and creating vector representations to match the question’s vector representation against the indexed resources. </span><span class="kobospan" id="kobo.190.3">This indexing process organizes the data to match like to like. </span><strong class="bold"><span class="kobospan" id="kobo.191.1">Vectorization</span></strong><span class="kobospan" id="kobo.192.1"> is the process of converting text into numeric vectors. </span><strong class="bold"><span class="kobospan" id="kobo.193.1">Embedding</span></strong><span class="kobospan" id="kobo.194.1"> is the process of determining similarity and semantic relationships based on the similarities of the vectors. </span><span class="kobospan" id="kobo.194.2">All of the processing and matching is based on matching </span><span><span class="kobospan" id="kobo.195.1">these vectors.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.196.1">To simplify the concept, consider vectors as numbers with a direction, like going west for 5 miles versus going north for 12 miles. </span><span class="kobospan" id="kobo.196.2">The direction and magnitude in this example are two dimensions used to match results. </span><span class="kobospan" id="kobo.196.3">However, in the case of LLMs, there are thousands of dimensions. </span><span class="kobospan" id="kobo.196.4">The embedding process sees that similar vectors represent words with similar meanings and usage. </span><span class="kobospan" id="kobo.196.5">They are in the same area. </span><span class="kobospan" id="kobo.196.6">The best matches (north-west for 4 miles is roughly similar to going west for 5 miles) are then passed to the LLM for processing with the question. </span><span class="kobospan" id="kobo.196.7">This means </span><em class="italic"><span class="kobospan" id="kobo.197.1">the LLM is given limited information to generate its answer</span></em><span class="kobospan" id="kobo.198.1">. </span><span class="kobospan" id="kobo.198.2">This also means there is value in ensuring that the knowledge and resources are ready for this process and using tools to return knowledge related to the presented question. </span><span class="kobospan" id="kobo.198.3">This doesn’t require months to train a model. </span><span class="kobospan" id="kobo.198.4">All of that work was done for us. </span><span class="kobospan" id="kobo.198.5">However, the foundational </span><a id="_idIndexMarker370" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.199.1">model can be enhanced with prompt engineering and fine-tuning. </span><strong class="bold"><span class="kobospan" id="kobo.200.1">Prompt engineering</span></strong><span class="kobospan" id="kobo.201.1"> is the process of giving instructions to the model to tell it what to do, while </span><strong class="bold"><span class="kobospan" id="kobo.202.1">fine-tuning</span></strong><span class="kobospan" id="kobo.203.1"> is used </span><a id="_idIndexMarker371" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.204.1">to provide examples of what is expected from the generative output. </span><span class="kobospan" id="kobo.204.2">Both are covered in the following </span><span><span class="kobospan" id="kobo.205.1">two chapters.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.206.1">Product owners, designers, writers, and those who care about content quality can add value to the </span><a id="_idIndexMarker372" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.207.1">input and the output. </span><span class="kobospan" id="kobo.207.2">This chapter is about input and getting quality out of data sources. </span><span class="kobospan" id="kobo.207.3">The following chapters will focus on the </span><em class="italic"><span class="kobospan" id="kobo.208.1">output</span></em><span class="kobospan" id="kobo.209.1"> to ensure accuracy </span><span><span class="kobospan" id="kobo.210.1">when answering.</span></span></p>
			<p class="callout-heading"><span class="kobospan" id="kobo.211.1">Further reading on RAG</span></p>
			<p class="callout"><span class="kobospan" id="kobo.212.1">There are plenty of good resources to explain RAG in more detail. </span><span class="kobospan" id="kobo.212.2">Here are a few deeper dives into the subject. </span><span class="kobospan" id="kobo.212.3">Let me start with Amazon’s introduction </span><span><span class="kobospan" id="kobo.213.1">to RAG.</span></span></p>
			<p class="callout"><span class="kobospan" id="kobo.214.1">Article: </span><a href="https://aws.amazon.com/what-is/retrieval-augmented-generation/" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.215.1">Amazon’s RAG </span><span><span class="kobospan" id="kobo.216.1">Explanation</span></span></a><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.217.1">(</span></span></span><a href="https://aws.amazon.com/what-is/retrieval-augmented-generation/" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.218.1">https://aws.amazon.com/what-is/retrieval-augmented-generation/</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.219.1">)</span></span></span></p>
			<p class="callout"><span class="kobospan" id="kobo.220.1">This one goes deeper into the issues and technical pieces of the </span><span><span class="kobospan" id="kobo.221.1">complete solution.</span></span></p>
			<p class="callout"><span class="kobospan" id="kobo.222.1">Article: </span><a href="https://www.ml6.eu/blogpost/leveraging-llms-on-your-domain-specific-knowledge-base" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.223.1">Leveraging LLMs on your domain-specific knowledge </span><span><span class="kobospan" id="kobo.224.1">base</span></span></a><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.225.1">(</span></span></span><a href="https://www.ml6.eu/blogpost/leveraging-llms-on-your-domain-specific-knowledge-base" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.226.1">https://www.ml6.eu/blogpost/leveraging-llms-on-your-domain-specific-knowledge-base</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.227.1">)</span></span></span></p>
			<p class="callout"><span class="kobospan" id="kobo.228.1">Databricks hosted an excellent one-hour video session. </span><span class="kobospan" id="kobo.228.2">It covers prompt engineering </span><span><span class="kobospan" id="kobo.229.1">and RAG.</span></span></p>
			<p class="callout"><span class="kobospan" id="kobo.230.1">Video: </span><a href="https://vimeo.com/891439013" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.231.1">Accelerate your Generative AI </span><span><span class="kobospan" id="kobo.232.1">journey</span></span></a><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.233.1">(</span></span></span><a href="https://vimeo.com/891439013" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.234.1">https://vimeo.com/891439013</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.235.1">)</span></span></span></p>
			<p class="callout"><span class="kobospan" id="kobo.236.1">Finally, to go deeper, review this well-done survey of RAG techniques and methods to learn more about how RAG can be implemented. </span><span class="kobospan" id="kobo.236.2">This is my favorite reference for explaining the different approaches, and the authors plan on updating the article, so it should </span><span><span class="kobospan" id="kobo.237.1">be current.</span></span></p>
			<p class="callout"><span class="kobospan" id="kobo.238.1">Article: </span><a href="https://arxiv.org/pdf/2312.10997.pdf" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.239.1">A survey of RAG for </span><span><span class="kobospan" id="kobo.240.1">LLMs</span></span></a><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.241.1">(</span></span></span><a href="https://arxiv.org/pdf/2312.10997.pdf" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.242.1">https://arxiv.org/pdf/2312.10997.pdf</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.243.1">)</span></span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.244.1">By the process of elimination, there are only a few places where product people can insert themselves to help the process. </span><span class="kobospan" id="kobo.244.2">Few can build an LLM from scratch, and the training data used in the base model is from billions of Internet records. </span><span class="kobospan" id="kobo.244.3">There is limited ability to coach the customer on what </span><a id="_idIndexMarker373" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.245.1">questions to ask (a good design might encourage good behavior without forcing the user to adapt, per se). </span><span class="kobospan" id="kobo.245.2">Meanwhile, in recommender UIs, there is no </span><span><span class="kobospan" id="kobo.246.1">interactive UI.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.247.1">Thus, the best value for our efforts is to target the proper use cases, create quality knowledge, and support robust access to enterprise databases and resources that will allow an LLM to generate results to achieve customer goals. </span><span class="kobospan" id="kobo.247.2">Let’s build a simple demo incorporating a data source to help understand the limitations and capabilities of an LLM supplemented with </span><span><span class="kobospan" id="kobo.248.1">private data.</span></span></p>
			<h2 id="_idParaDest-138" class="calibre9"><a id="_idTextAnchor140" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.249.1">Building a demo with enterprise data</span></h2>
			<p class="calibre3"><span class="kobospan" id="kobo.250.1">This is a simple example to make a point. </span><span class="kobospan" id="kobo.250.2">We will start with a collection of Frequently Asked Questions (FAQs) common to almost all websites and businesses. </span><span class="kobospan" id="kobo.250.3">Hundreds of FAQs that could </span><a id="_idIndexMarker374" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.251.1">be found on any financial website (a bank or a brokerage company) form the basis of the demo. </span><span class="kobospan" id="kobo.251.2">We name this financial company Alligiance (All-i… not an e, so as not to run afoul of an actual company called Allegiance). </span><span class="kobospan" id="kobo.251.3">The assistant can be called “Alli” (pronounced Ally). </span><span class="kobospan" id="kobo.251.4">Let’s start with a file of raw HTML snippets, answering each question in a row in a table. </span><span class="kobospan" id="kobo.251.5">The file is on GitHub, so please try </span><span><span class="kobospan" id="kobo.252.1">it yourself.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.253.1">GitHub: </span><a href="https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter6-Example_FAQs_for_Demo.docx" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.254.1">FAQ Collection for </span><span><span class="kobospan" id="kobo.255.1">Testing</span></span></a><span><span class="kobospan" id="kobo.256.1"> (</span></span><a href="https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter6-Example_FAQs_for_Demo.docx" class="pcalibre pcalibre1 calibre6"><span><span class="kobospan" id="kobo.257.1">https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter6-Example_FAQs_for_Demo.docx</span></span></a><span><span class="kobospan" id="kobo.258.1">)</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.259.1">To access the OpenAI playground, follow the instructions in </span><a href="B21964_01.xhtml#_idTextAnchor016" class="pcalibre pcalibre1 calibre6"><span><em class="italic"><span class="kobospan" id="kobo.260.1">Chapter 1</span></em></span></a><span class="kobospan" id="kobo.261.1">, </span><em class="italic"><span class="kobospan" id="kobo.262.1">Recognizing the Power of Design </span></em><span><em class="italic"><span class="kobospan" id="kobo.263.1">in ChatGPT</span></em></span><span><span class="kobospan" id="kobo.264.1">.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.265.1">Demo: </span><a href="https://platform.openai.com/playground" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.266.1">OpenAI </span><span><span class="kobospan" id="kobo.267.1">Playground</span></span></a><span><span class="kobospan" id="kobo.268.1"> (</span></span><a href="https://platform.openai.com/playground" class="pcalibre pcalibre1 calibre6"><span><span class="kobospan" id="kobo.269.1">https://platform.openai.com/playground</span></span></a><span><span class="kobospan" id="kobo.270.1">)</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.271.1">The demo starts by asking a simple, specific question about browser support that might be common for a private website application. </span><span class="kobospan" id="kobo.271.2">The foundational model would not expect it to know the answer, as these </span><a id="_idIndexMarker375" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.272.1">FAQs for a company might only be for authenticated customers. </span><span class="kobospan" id="kobo.272.2">Then we uploaded the file, as shown in </span><span><em class="italic"><span class="kobospan" id="kobo.273.1">Figure 6</span></em></span><em class="italic"><span class="kobospan" id="kobo.274.1">.3</span></em><span class="kobospan" id="kobo.275.1">, and asked again. </span><span class="kobospan" id="kobo.275.2">Play along, </span><span><span class="kobospan" id="kobo.276.1">will you?</span></span></p>
			<p class="callout-heading"><span class="kobospan" id="kobo.277.1">Tip</span></p>
			<p class="callout"><span class="kobospan" id="kobo.278.1">Try side-by-side comparisons: Open two browsers and run the LLM with and without the context document. </span><span class="kobospan" id="kobo.278.2">There is also a compare button in the Playground. </span><span class="kobospan" id="kobo.278.3">We will demonstrate the compare </span><span><span class="kobospan" id="kobo.279.1">button later.</span></span></p>
			<div class="calibre2">
				<div id="_idContainer071" class="img---figure">
					<span class="kobospan" id="kobo.280.1"><img src="image/B21964_06_03.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.281.1">Figure 6.3 – OpenAI Playground shows an answer before and after adding the demo file</span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.282.1">Open the GitHub file on your desktop; it is riddled with HTML links and text. </span><span class="kobospan" id="kobo.282.2">OpenAI </span><em class="italic"><span class="kobospan" id="kobo.283.1">reworked the content to show a clean, correct answer</span></em><span class="kobospan" id="kobo.284.1"> and formatted it with a bullet list and trouble tips. </span><span class="kobospan" id="kobo.284.2">It knows how to read this HTML snippet and has been trained to use this content to formulate an answer without including any HTML formatting code. </span><span class="kobospan" id="kobo.284.3">Here is a snippet of what </span><a id="_idIndexMarker376" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.285.1">was uploaded. </span><span class="kobospan" id="kobo.285.2">It reworked the content into a presentable format. </span><span class="kobospan" id="kobo.285.3">The output text is bolded for easier scanning (some irrelevant text </span><span><span class="kobospan" id="kobo.286.1">is truncated):</span></span></p>
			<pre class="source-code"><span class="kobospan1" id="kobo.287.1">
&lt;a href="http://www.mozilla.com/en-us/firefox/ie.html" id="Link_1422297415937" name="Link_1422297415937" onclick="advancedlink('http://www.mozilla.com/en-us/firefox/ie.html','{truncated}','', 'Link_1422297415937')" target="_blank"&gt;Mozilla® Firefox&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="http://www.apple.com/safari/download/" id="Link_1421770836208" name="Link_1421770836208" onclick="advancedlink('http://www.apple.com/safari/download/','{truncated}','', 'Link_1421770836208')" target="_blank"&gt;Apple® Safari®&lt;/a&gt; (Mac operating systems only)&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt; Note:&lt;/strong&gt;</span><strong class="bold1"><span class="kobospan1" id="kobo.288.1"> Our latest site features will not work with older, unsupported browser versions, specifically Internet Explorer 8, Safari 4 and 5, and Netscape. </span><span class="kobospan1" id="kobo.288.2">Internet Explorer 9 and 10 may provide a less than optimal experience. </span><span class="kobospan1" id="kobo.288.3">The use of unsupported browsers may also lead to vulnerability because of viruses, spyware, malware, and other security issues.</span></strong><span class="kobospan1" id="kobo.289.1">&lt;/p&gt;&lt;p&gt;</span></pre>			<p class="calibre3"><em class="italic"><span class="kobospan" id="kobo.290.1">Table 6.1</span></em><span class="kobospan" id="kobo.291.1"> compares the HTML source to the </span><span><span class="kobospan" id="kobo.292.1">answer provided.</span></span></p>
			<table id="table001-5" class="no-table-style">
				<colgroup class="calibre15">
					<col class="calibre16"/>
					<col class="calibre16"/>
				</colgroup>
				<tbody class="calibre17">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.293.1">Source Answer (HTML </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.294.1">formatted version)</span></strong></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.295.1">ChatGPT </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.296.1">3.5 Answer</span></strong></span></p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.297.1">Alligiance’s website is best viewed, and is most secure, using the latest versions of these browsers. </span><span class="kobospan" id="kobo.297.2">Get free </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.298.1">upgrades here:</span></strong></span></p>
							<ul class="calibre7">
								<li class="calibre8"><strong class="bold"><span class="kobospan" id="kobo.299.1">Microsoft® Internet Explorer (Windows 7 &amp; 8 operating </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.300.1">systems only)</span></strong></span></li>
								<li class="calibre8"><span><strong class="bold"><span class="kobospan" id="kobo.301.1">Google® Chrome</span></strong></span></li>
								<li class="calibre8"><span><strong class="bold"><span class="kobospan" id="kobo.302.1">Mozilla® Firefox</span></strong></span></li>
								<li class="calibre8"><strong class="bold"><span class="kobospan" id="kobo.303.1">Apple® Safari® (Mac operating </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.304.1">systems only)</span></strong></span></li>
							</ul>
							<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.305.1">Note: Our latest site features will not work with older, unsupported browser versions, specifically Internet Explorer 8, Safar</span></strong><strong class="bold"><span class="kobospan" id="kobo.306.1">i 4 and 5, and Netscape. </span><span class="kobospan" id="kobo.306.2">Internet Explorer 9 and 10 may provide a less than optimal experience. </span><span class="kobospan" id="kobo.306.3">The use of unsupported browsers may also lead to vulnerability because of viruses, spyware, malware, and other </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.307.1">security issues.</span></strong></span></p>
							<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.308.1">Safari no longer supports upgrades for Windows operating systems. </span><span class="kobospan" id="kobo.308.2">If you are using a Windows operating system, please use one of the supported browsers above, other than Apple® Safari, for the </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.309.1">best experience.</span></strong></span></p>
							<p class="calibre3"><span class="kobospan" id="kobo.310.1">How to upgrade </span><span><span class="kobospan" id="kobo.311.1">Apple® Safari</span></span></p>
							<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.312.1">If you’re using an older version of Safari on a Mac, you’ll need to first check your Apple </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.313.1">operating system:</span></strong></span></p>
							<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.314.1">From the Apple menu, choose “About </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.315.1">This Mac.”</span></strong></span></p>
							<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.316.1">This continues for pages, see GitHub for the </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.317.1">full text.</span></strong></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span class="kobospan" id="kobo.318.1">Alligiance.com is best viewed and most secure using the latest versions of the </span><span><span class="kobospan" id="kobo.319.1">following browsers:</span></span></p>
							<ul class="calibre7">
								<li class="calibre8"><span class="kobospan" id="kobo.320.1">Microsoft® Internet Explorer (Windows 7 &amp; 8 operating </span><span><span class="kobospan" id="kobo.321.1">systems only)</span></span></li>
								<li class="calibre8"><span><span class="kobospan" id="kobo.322.1">Google® Chrome</span></span></li>
								<li class="calibre8"><span><span class="kobospan" id="kobo.323.1">Mozilla® Firefox</span></span></li>
								<li class="calibre8"><span class="kobospan" id="kobo.324.1">Apple® Safari® (Mac operating </span><span><span class="kobospan" id="kobo.325.1">systems only)</span></span></li>
							</ul>
							<p class="calibre3"><span class="kobospan" id="kobo.326.1">It’s important to note that the latest site features will not work </span><a id="_idIndexMarker377" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.327.1">with older unsupported browser versions, specifically Internet Explorer 8, Safari 4 and 5, and Netscape. </span><span class="kobospan" id="kobo.327.2">Internet Explorer 9 and 10 may provide a less than optimal experience, and the use of unsupported browsers may lead to vulnerability due to viruses, spyware, malware, and other </span><span><span class="kobospan" id="kobo.328.1">security issues[1].</span></span></p>
							<p class="calibre3"><span class="kobospan" id="kobo.329.1">Additionally, for troubleshooting, if images on a page do not display, users can try clicking the Reload/Refresh button at the top of the browser or clearing the browser’s cache. </span><span class="kobospan" id="kobo.329.2">It’s also noted that if the links to the images are no longer active, they will not </span><span><span class="kobospan" id="kobo.330.1">be downloadable[2].[1][2]</span></span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.331.1">Table 6.1 – Comparison of source document text versus the ChatGPT answer</span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.332.1">This example was run with gpt-3.5-turbo-1106. </span><span class="kobospan" id="kobo.332.2">It looks </span><a id="_idIndexMarker378" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.333.1">pretty good. </span><span class="kobospan" id="kobo.333.2">Notice that it is not an exact quote of the source material. </span><span class="kobospan" id="kobo.333.3">Here are some </span><span><span class="kobospan" id="kobo.334.1">usability considerations:</span></span></p>
			<ul class="calibre7">
				<li class="calibre8"><span class="kobospan" id="kobo.335.1">The paragraph starting with “Additionally, for troubleshooting…” comes from a different FAQ and is unnecessary for this answer. </span><span class="kobospan" id="kobo.335.2">Subsequent runs of this same question did not contain this </span><span><span class="kobospan" id="kobo.336.1">spurious content.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.337.1">The source answer should be shorter for a chat, which is common for documentation. </span><a href="B21964_07.xhtml#_idTextAnchor150" class="pcalibre pcalibre1 calibre6"><span><em class="italic"><span class="kobospan" id="kobo.338.1">Chapter 7</span></em></span></a><em class="italic"><span class="kobospan" id="kobo.339.1">, Prompt Engineering</span></em><span class="kobospan" id="kobo.340.1">, explains how to </span><span><span class="kobospan" id="kobo.341.1">control this.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.342.1">The style and tone are good. </span><span class="kobospan" id="kobo.342.2">They are consistent with a business tone. </span><span class="kobospan" id="kobo.342.3">Even though the content is in a business tone, style and tone could be adjusted using Prompt Engineering and Fine-Tuning. </span><a href="B21964_08.xhtml#_idTextAnchor172" class="pcalibre pcalibre1 calibre6"><span><em class="italic"><span class="kobospan" id="kobo.343.1">Chapter 8</span></em></span></a><span class="kobospan" id="kobo.344.1">, </span><em class="italic"><span class="kobospan" id="kobo.345.1">Fine-Tuning</span></em><span class="kobospan" id="kobo.346.1">, explores using examples to train </span><span><span class="kobospan" id="kobo.347.1">the model.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.348.1">The list of browsers is returned in a bulleted list. </span><span class="kobospan" id="kobo.348.2">Subsequent runs of this same question only sometimes returned this in a bullet list. </span><span class="kobospan" id="kobo.348.3">Prompt engineering can also help return items like a bulleted list </span><span><span class="kobospan" id="kobo.349.1">more consistently.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.350.1">Accuracy is </span><a id="_idIndexMarker379" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.351.1">critical in support applications. </span><span class="kobospan" id="kobo.351.2">This answer is factually correct, but errors can occur. </span><span class="kobospan" id="kobo.351.3">The next few chapters will discuss techniques for getting </span><span><span class="kobospan" id="kobo.352.1">accurate answers.</span></span></li>
			</ul>
			<p class="calibre3"><span class="kobospan" id="kobo.353.1">Hopefully, this analysis is helpful. </span><span class="kobospan" id="kobo.353.2">There may be other items you can see. </span><span class="kobospan" id="kobo.353.3">One must be able to evaluate response quality to care and feed the LLM. </span><span class="kobospan" id="kobo.353.4">This is the crux of </span><span><span class="kobospan" id="kobo.354.1">our mission.</span></span></p>
			<h3 class="calibre11"><span class="kobospan" id="kobo.355.1">Quality issues</span></h3>
			<p class="calibre3"><span class="kobospan" id="kobo.356.1">The following prompt was provided to the OpenAI model with the FAQ files attached. </span><span class="kobospan" id="kobo.356.2">These instructions set the stage for any </span><span><span class="kobospan" id="kobo.357.1">user interactions.</span></span></p>
			<pre class="source-code"><span class="kobospan1" id="kobo.358.1">
You are a helpful assistant named Alli, short for the name of our bank. </span><span class="kobospan1" id="kobo.358.2">Be courteous and professional. </span><span class="kobospan1" id="kobo.358.3">Prioritize information in any files first. </span><span class="kobospan1" id="kobo.358.4">Format output using lists when appropriate.</span></pre>			<p class="calibre3"><span class="kobospan" id="kobo.359.1">The results </span><a id="_idIndexMarker380" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.360.1">around a few security questions are interesting. </span><span class="kobospan" id="kobo.360.2">We will show some conversations. </span><span class="kobospan" id="kobo.360.3">The convention is to show users messages on the right and the model’s response on the left, similar to the format for messages on your phone. </span><span class="kobospan" id="kobo.360.4">As a reminder, conversations are never edited for typos </span><span><span class="kobospan" id="kobo.361.1">or mistakes.</span></span></p>
			<pre class="source-code-right"><span class="kobospan1" id="kobo.362.1">Is it safe to do all this via the web?
</span><span class="kobospan1" id="kobo.362.2">Yes, our conversation and any information you share are handled with the utmost care for privacy and security. </span><span class="kobospan1" id="kobo.362.3">The platform we are using employs robust security measures to ensure the safety of our communication and any data exchanged. </span><span class="kobospan1" id="kobo.362.4">If you have any specific concerns or requirements regarding security measures, please feel free to let me know, and I will do my best to address them.What security measures?
</span><span class="kobospan1" id="kobo.362.5">The platform we are using implements various security measures to safeguard our communication and any data involved. </span><span class="kobospan1" id="kobo.362.6">These measures typically include encryption of data transmission, secure data storage protocols, access controls, and regular security audits to ensure compliance with industry standards and best practices. </span><span class="kobospan1" id="kobo.362.7">Additionally, the platform is designed to comply with data protection and privacy regulations to further enhance security and confidentiality. </span><span class="kobospan1" id="kobo.362.8">If you have specific security concerns or would like more detailed information about the security measures in place, please let me know, and I can provide more details.</span></pre>			<p class="calibre3"><span class="kobospan" id="kobo.363.1">The answer is </span><a id="_idIndexMarker381" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.364.1">perfectly reasonable and even logical. </span><span class="kobospan" id="kobo.364.2">Except </span><em class="italic"><span class="kobospan" id="kobo.365.1">none</span></em><span class="kobospan" id="kobo.366.1"> of this comes from the corpus of FAQs that were uploaded. </span><span class="kobospan" id="kobo.366.2">It is a good-sounding generic answer. </span><span class="kobospan" id="kobo.366.3">The answer is not something it was trained on from our knowledge. </span><span class="kobospan" id="kobo.366.4">This is </span><a id="_idIndexMarker382" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.367.1">classified as a </span><strong class="bold"><span class="kobospan" id="kobo.368.1">hallucination</span></strong><span class="kobospan" id="kobo.369.1">. </span><span class="kobospan" id="kobo.369.2">A hallucination is a model-generated text that is incorrect, nonsensical, or, in this case, not real. </span><span class="kobospan" id="kobo.369.3">Lying to a customer can cause actual harm beyond just the apparent failure. </span><span class="kobospan" id="kobo.369.4">Given the litigious nature of people, avoid getting sued for lying to customers. </span><span class="kobospan" id="kobo.369.5">The courts in the US can hold the assistant liable as a representative of </span><span><span class="kobospan" id="kobo.370.1">the company.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.371.1">Since no data in the files suggests that Alligiance does regular security audits, the response doesn’t provide more details because it only refers to “typical” measures, not specifics. </span><span class="kobospan" id="kobo.371.2">If the prompt is adapted to “only provide answers from the attached document,” then the LLM answers are similar to the browser answer because it discusses how unsupported browsers can have security issues. </span><span class="kobospan" id="kobo.371.3">It is typical in an enterprise solution to limit the knowledge only to the company knowledge provided. </span><span class="kobospan" id="kobo.371.4">This can reduce hallucinations. </span><span class="kobospan" id="kobo.371.5">HTML files were provided, but it returned clean, formatted text. </span><span class="kobospan" id="kobo.371.6">Not every system and process would be </span><a id="_idIndexMarker383" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.372.1">that fortunate. </span><span class="kobospan" id="kobo.372.2">When scaling up, consider what it means to clean the enterprise data. </span><span class="kobospan" id="kobo.372.3">In the end, all of these systems expect text as input. </span><span class="kobospan" id="kobo.372.4">So somewhere, some tool is going to do that conversion. </span><span class="kobospan" id="kobo.372.5">Time for some context around </span><span><span class="kobospan" id="kobo.373.1">data cleaning.</span></span></p>
			<h2 id="_idParaDest-139" class="calibre9"><a id="_idTextAnchor141" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.374.1">Cleaning data</span></h2>
			<p class="calibre3"><span class="kobospan" id="kobo.375.1">Cleaning data is tricky, and manually editing files is unreasonable at the enterprise scale. </span><span class="kobospan" id="kobo.375.2">First, understand the problem and either work with vendors that provide tools to support creating a cleansing </span><a id="_idIndexMarker384" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.376.1">pipeline or start small and learn how to code tools piece by piece. </span><span class="kobospan" id="kobo.376.2">Review what it takes to clean data and decide where to invest a team’s limited resources. </span><span class="kobospan" id="kobo.376.3">One way or the other, most of this has to be automated. </span><span class="kobospan" id="kobo.376.4">The reality is that some is manual work, especially early in </span><span><span class="kobospan" id="kobo.377.1">the process.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.378.1">Data cleaning also </span><a id="_idIndexMarker385" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.379.1">depends on the types of resources and how they will be used. </span><span class="kobospan" id="kobo.379.2">Handling a large corpus of FAQs, knowledge articles, and marketing materials will require different tools than handling database queries. </span><span class="kobospan" id="kobo.379.3">These are some generalizable issues to be aware of. </span><span class="kobospan" id="kobo.379.4">Let’s start with how to </span><span><span class="kobospan" id="kobo.380.1">handle documents.</span></span></p>
			<p class="callout-heading"><span class="kobospan" id="kobo.381.1">Tip</span></p>
			<p class="callout"><span class="kobospan" id="kobo.382.1">Find or build tools to help automate this process, but it is real work for many use cases. </span><span class="kobospan" id="kobo.382.2">The next sections include details to help understand the process in case issues arise with enterprise data. </span><span class="kobospan" id="kobo.382.3">Some data types will require </span><span><span class="kobospan" id="kobo.383.1">more effort.</span></span></p>
			<h3 class="calibre11"><span class="kobospan" id="kobo.384.1">Data augmentation</span></h3>
			<p class="calibre3"><span class="kobospan" id="kobo.385.1">Data augmentation </span><a id="_idIndexMarker386" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.386.1">addresses the issue of whether there is</span><a id="_idIndexMarker387" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.387.1"> enough data. </span><span class="kobospan" id="kobo.387.2">Is there enough knowledge about product questions? </span><span class="kobospan" id="kobo.387.3">Are there enough data resources and historical data to form recommendations? </span><span class="kobospan" id="kobo.387.4">Are language-specific examples available (hint: translate it and translate it back)? </span><span class="kobospan" id="kobo.387.5">Or are various forms of training material needed to understand more diverse formats? </span><strong class="bold"><span class="kobospan" id="kobo.388.1">Augmentation</span></strong><span class="kobospan" id="kobo.389.1"> artificially generates this data to help make solutions </span><span><span class="kobospan" id="kobo.390.1">more robust.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.391.1">Not all data can be easily augmented. </span><span class="kobospan" id="kobo.391.2">An LLM can’t generate novel knowledge articles explaining a process it knows nothing about. </span><span class="kobospan" id="kobo.391.3">But suppose you are training a model on specialized information, like understanding medical diagnosis and treatments, real-time data (like the weather), or any data that might need more recency than the model provides. </span><span class="kobospan" id="kobo.391.4">In that case, the augmentation process can provide precise, up-to-date, and contextually </span><span><span class="kobospan" id="kobo.392.1">relevant explanations.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.393.1">There are tricks. </span><span class="kobospan" id="kobo.393.2">For example, there are times when translating material to another language using an LLM when there is limited language data and then translating it back can help improve the retrieval step. </span><span class="kobospan" id="kobo.393.3">Or incorporate synonyms for product names in the text to create variations to train on. </span><span class="kobospan" id="kobo.393.4">For the most part, be aware of this and consider whether there is data that can be used to train or test the model. </span><span class="kobospan" id="kobo.393.5">This can be a resource once the state of the enterprise data </span><span><span class="kobospan" id="kobo.394.1">is understood.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.395.1">It is an option to use the LLM itself to generate training data. </span><span class="kobospan" id="kobo.395.2">Use this as a resource and then apply common sense to decide what data to give feedback to the model to augment the baseline data with good-quality data. </span><span class="kobospan" id="kobo.395.3">OpenAI suggests that, by training </span><a id="_idIndexMarker388" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.396.1">on augmented data, the model can handle variety and </span><a id="_idIndexMarker389" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.397.1">learn to handle noise in the system better when addressing new data. </span><span class="kobospan" id="kobo.397.2">Experimenting and iterating will be needed to see what best </span><span><span class="kobospan" id="kobo.398.1">improves results.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.399.1">Try this prompt in ChatGPT to learn more about </span><span><span class="kobospan" id="kobo.400.1">data augmentation.</span></span></p>
			<pre class="source-code"><span class="kobospan1" id="kobo.401.1">
How can I do data augmentation using LLMs to generate training data based on a baseline?
</span><span class="kobospan1" id="kobo.401.2">What data augmentation should I use to train my LLM on the complexities of (insert enterprise details)?</span></pre>			<h3 class="calibre11"><span class="kobospan" id="kobo.402.1">Data annotation</span></h3>
			<p class="calibre3"><span class="kobospan" id="kobo.403.1">Annotation is work. </span><span class="kobospan" id="kobo.403.2">And it </span><a id="_idIndexMarker390" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.404.1">can be monotonous. </span><strong class="bold"><span class="kobospan" id="kobo.405.1">Annotation</span></strong><span class="kobospan" id="kobo.406.1"> is the process of marking content with notes to explain it. </span><span class="kobospan" id="kobo.406.2">The concepts of tagging or labeling are fundamentally the same. </span><span class="kobospan" id="kobo.406.3">Notes or details are associated with the content. </span><span class="kobospan" id="kobo.406.4">This is done</span><a id="_idIndexMarker391" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.407.1"> to help understand and mark up passages, content, tables, or anything that needs to be classified. </span><span class="kobospan" id="kobo.407.2">What data to annotate will </span><a id="_idIndexMarker392" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.408.1">depend on the data and structure. </span><span class="kobospan" id="kobo.408.2">For example, in long passages, annotation can be done for relevance. </span><span class="kobospan" id="kobo.408.3">For tables, headers can be labeled better, which would be evident to a human but not a computer. </span><span class="kobospan" id="kobo.408.4">Product items can be tagged so the models can learn sizes (S, M, L, XL), categories (first class, business class, economy), related products, or other essential attributes that help to give context to the material. </span><span class="kobospan" id="kobo.408.5">With large documents, provide context to the chunks of data. </span><span class="kobospan" id="kobo.408.6">For example, if a table is pages long, do the headers re-appear on every page? </span><span class="kobospan" id="kobo.408.7">Would a human understand the headers if the document was broken into smaller manageable pieces? </span><span class="kobospan" id="kobo.408.8">This is one example where the annotation is needed. </span><span class="kobospan" id="kobo.408.9">Suppose the header talked about the product and product versions, and this header was for multiple pages earlier. </span><span class="kobospan" id="kobo.408.10">In that case, if a chunk turns out to be one page in length, this product header information needs to cascade into each of the correct pages </span><span><span class="kobospan" id="kobo.409.1">and chunks.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.410.1">The annotation process needs to be of high quality. </span><span class="kobospan" id="kobo.410.2">Product experts are the prime candidates to verify that the tags or annotations match the contents of the enterprise data. </span><span class="kobospan" id="kobo.410.3">Thus, designers, writers, and PMs can get involved, using their product expertise to create an effective annotation process. </span><span class="kobospan" id="kobo.410.4">This ensures steps are taken to quality-check the work (as the job might be outsourced or crowdsourced). </span><span class="kobospan" id="kobo.410.5">Create metrics to define a quality bar and test against this (spot check or check it all). </span><span class="kobospan" id="kobo.410.6">I wrote a </span><a id="_idIndexMarker393" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.411.1">metric to account for the kinds of errors and the frequency of mistakes our input would tolerate. </span><span class="kobospan" id="kobo.411.2">The metric compared the quality of the crowdsourced material to </span><a id="_idIndexMarker394" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.412.1">the expectations of an expert. </span><span class="kobospan" id="kobo.412.2">Results were analyzed to spot if specific human workers in the crowd were significantly better, worse, or the same as the average worker. </span><span class="kobospan" id="kobo.412.3">So, consider the source, and </span><em class="italic"><span class="kobospan" id="kobo.413.1">always test and verify</span></em><span class="kobospan" id="kobo.414.1"> to validate your quality assumptions. </span><span class="kobospan" id="kobo.414.2">Ask ChatGPT about all the errors that can occur when </span><span><span class="kobospan" id="kobo.415.1">annotating data.</span></span></p>
			<pre class="source-code"><span class="kobospan1" id="kobo.416.1">
What kinds of errors occur when annotating data for LLMs? </span><span class="kobospan1" id="kobo.416.2">Provide an example of each and explain the likelihood of the types of errors. </span><span class="kobospan1" id="kobo.416.3">This is important to my job.</span></pre>			<p class="calibre3"><span class="kobospan" id="kobo.417.1">Another part of making data available for the LLM is segmenting it so the most valuable and optimal details are shared in the context window. </span><span class="kobospan" id="kobo.417.2">This is </span><span><span class="kobospan" id="kobo.418.1">called chunking.</span></span></p>
			<h3 class="calibre11"><span class="kobospan" id="kobo.419.1">Chunking</span></h3>
			<p class="calibre3"><span class="kobospan" id="kobo.420.1">Not only do large documents need to be tagged, as discussed, but they are likely too big for the RAG process. </span><span class="kobospan" id="kobo.420.2">This leads </span><a id="_idIndexMarker395" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.421.1">to discussions concerning </span><strong class="bold"><span class="kobospan" id="kobo.422.1">chunking</span></strong><span class="kobospan" id="kobo.423.1">. </span><span class="kobospan" id="kobo.423.2">Chunking refers to dividing a large text or dataset into smaller, manageable pieces (chunks) that fit within the LLM’s context window, allowing the model to process and understand the information more effectively. </span><span class="kobospan" id="kobo.423.3">This isn’t about becoming a chunking expert; it is only about being able to recognize the results of poor chunking and help </span><span><span class="kobospan" id="kobo.424.1">resolve issues.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.425.1">Imagine customers want answers about mobile phone battery life. </span><span class="kobospan" id="kobo.425.2">The phone company has released hundreds of phone models over the last few years, all with different specifications. </span><span class="kobospan" id="kobo.425.3">These knowledge articles and details must be broken down into manageable, contextually relevant pieces to ensure RAG can process and retrieve them accurately. </span><span class="kobospan" id="kobo.425.4">With this, the amount of information will be manageable for the system and result in good-quality answers. </span><span class="kobospan" id="kobo.425.5">Segmenting the text into logical sections – chapters, paragraphs, and even sentences – ensures chunks have a coherent unit of meaning. </span><span class="kobospan" id="kobo.425.6">This way, RAG can understand and retrieve the most pertinent information. </span><span class="kobospan" id="kobo.425.7">We don’t want information about memory cards for an Android phone to be conflated with iPhones that do not have card slots because of a generic statement about </span><span><span class="kobospan" id="kobo.426.1">memory cards.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.427.1">Different chunking strategies exist. </span><span class="kobospan" id="kobo.427.2">We will cover some basics, with semantic chunking being the one of interest for our case studies later in this chapter. </span><span class="kobospan" id="kobo.427.3">Come back to these references for </span><span><span class="kobospan" id="kobo.428.1">more exploration.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.429.1">Article: </span><a href="https://medium.com/the-ai-forum/semantic-chunking-for-rag-f4733025d5f5" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.430.1">Semantic Chunking for </span><span><span class="kobospan" id="kobo.431.1">RAG</span></span></a><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.432.1">(</span></span></span><a href="https://medium.com/the-ai-forum/semantic-chunking-for-rag-f4733025d5f5" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.433.1">https://medium.com/the-ai-forum/semantic-chunking-for-rag-f4733025d5f5</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.434.1">)</span></span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.435.1">The second learning opportunity is a KDB.AI best practices video. </span><span class="kobospan" id="kobo.435.2">With RAG, a </span><a id="_idIndexMarker396" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.436.1">vector database vendor will be needed. </span><span class="kobospan" id="kobo.436.2">Fortunately, our learnings are primarily agnostic to </span><a id="_idIndexMarker397" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.437.1">the platforms. </span><span class="kobospan" id="kobo.437.2">Here are a few takeaways from the video to give insight </span><span><span class="kobospan" id="kobo.438.1">into chunking:</span></span></p>
			<ul class="calibre7">
				<li class="calibre8"><span class="kobospan" id="kobo.439.1">Chunk size depends on the model being used. </span><span class="kobospan" id="kobo.439.2">Changing models might require changing chunk sizes. </span><span class="kobospan" id="kobo.439.3">This also suggests that chunking should be done in an automation process to </span><span><span class="kobospan" id="kobo.440.1">adapt quickly.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.441.1">Small chunk sizes for a small amount of content will be accurate but won’t contain much context. </span><span class="kobospan" id="kobo.441.2">Large chunks, typically from full documents, are less granular but can </span><span><span class="kobospan" id="kobo.442.1">cost performance.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.443.1">Prompts, chat history, and other resources might also be included in the context window, so allow for this capacity when deciding how many chunks can be allocated to the </span><span><span class="kobospan" id="kobo.444.1">context windows.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.445.1">Because context windows are growing (ChatGPT-4’s window is 128K tokens as of Fall 2024), it doesn’t mean it should be filled. </span><span class="kobospan" id="kobo.445.2">Performance, cost, and quality are relevant. </span><span class="kobospan" id="kobo.445.3">To put it in context, the FAQ document shared earlier has 465K characters and 110K tokens. </span><span class="kobospan" id="kobo.445.4">That document alone would be about as much as sharable with ChatGPT. </span><span class="kobospan" id="kobo.445.5">That is an insignificant amount of data compared to what is needed at the </span><span><span class="kobospan" id="kobo.446.1">Enterprise level.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.447.1">Chunk overlap can be adjusted when doing code-based chunking. </span><span class="kobospan" id="kobo.447.2">This is the number of chunks to include from previous or future chunks, so there is context. </span><span class="kobospan" id="kobo.447.3">However, NLP chunking solutions will be more graceful in breaking the content into more logical breaks (in a sentence). </span><span class="kobospan" id="kobo.447.4">Examples are </span><strong class="bold"><span class="kobospan" id="kobo.448.1">Natural Language Toolkit</span></strong><span class="kobospan" id="kobo.449.1"> (</span><strong class="bold"><span class="kobospan" id="kobo.450.1">NLTK</span></strong><span class="kobospan" id="kobo.451.1">) and spaCy, an </span><span><span class="kobospan" id="kobo.452.1">open-source library.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.453.1">Chunk splitters are getting smarter every month. </span><span class="kobospan" id="kobo.453.2">LangChain understands the structure of a document and does an excellent job of understanding sentences and paragraphs. </span><span class="kobospan" id="kobo.453.3">It tries to optimize size based on </span><span><span class="kobospan" id="kobo.454.1">document structure.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.455.1">Structural chunkers understand headers and sections. </span><span class="kobospan" id="kobo.455.2">They can tag chunks with metadata so the context </span><span><span class="kobospan" id="kobo.456.1">is maintained.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.457.1">D</span><a id="_idIndexMarker398" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.458.1">ifferent retrievers can be used for different databases. </span><span class="kobospan" id="kobo.458.2">For example, one can be used for summaries to treat high-level questions and one for the source chunks to treat specific </span><span><span class="kobospan" id="kobo.459.1">detailed questions.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.460.1">The meat of the discussion starts almost 10 minutes in. </span><span class="kobospan" id="kobo.460.2">Start when Ryan Siegler starts talking. </span><span class="kobospan" id="kobo.460.3">Video: </span><a href="https://www.youtube.com/watch?v=uhVMFZjUOJI" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.461.1">Chunking Best Practices for RAG Applications</span></a> <span class="hidden1"><span class="kobospan" id="kobo.462.1">(</span></span><a href="https://www.youtube.com/watch?v=uhVMFZjUOJI" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.463.1">https://www.youtube.com/watch?v=uhVMFZjUOJI</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.464.1">)</span></span></span><span><span class="kobospan" id="kobo.465.1"> (KDB.AI)</span></span></li>
			</ul>
			<p class="calibre3"><span class="kobospan" id="kobo.466.1">Why should we care about chunk size? </span><span class="kobospan" id="kobo.466.2">Chunk size impacts the accuracy, context, and performance of LLM solutions, which are essential factors product leaders will want to monitor </span><span><span class="kobospan" id="kobo.467.1">and improve.</span></span></p>
			<p class="callout-heading"><span class="kobospan" id="kobo.468.1">Note</span></p>
			<p class="callout"><span class="kobospan" id="kobo.469.1">You will likely not be the one setting up these chunks, but you will get involved in monitoring performance and quality to provide feedback to the data team. </span><span class="kobospan" id="kobo.469.2">Team members who understand the content can help create and manage test cases to explore exceptions and validate </span><span><span class="kobospan" id="kobo.470.1">the solution.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.471.1">For example, does the model understand an exception explained at the beginning of a document when discussing something referenced much later? </span><span class="kobospan" id="kobo.471.2">For instance, in the Wove case study, later in the chapter, clearly defined notes appear at the start of a spreadsheet they want to ingest, but this information applies to material much later in the document; it is thus information relevant to that </span><span><span class="kobospan" id="kobo.472.1">later chunk.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.473.1">Documents can also have images, charts, and tables. </span><span class="kobospan" id="kobo.473.2">So, additional tools need to be used to summarize and get context from these graphics. </span><span class="kobospan" id="kobo.473.3">Tools such as LayoutPDFReader and Unstructured are two examples that can help. </span><span class="kobospan" id="kobo.473.4">The process would need to extract all of this independently of the text so that the chunks and summarization can be applied to the information extracted from the graphics. </span><span class="kobospan" id="kobo.473.5">Depending on the tools, sometimes the embedding step can handle images directly. </span><span class="kobospan" id="kobo.473.6">Almost all pictures and graphics in the documentation are more than ornamental, so converting these images to meaningful, searchable content is essential. </span><span class="kobospan" id="kobo.473.7">Use LLMs to extract context from pictures and then use that knowledge to index and search images later. </span><span class="kobospan" id="kobo.473.8">For example, a retailer setting up a marketing campaign might need a picture and ask, “Show me teens in jeans having fun </span><a id="_idIndexMarker399" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.474.1">on the beach.” </span><span class="kobospan" id="kobo.474.2">This can be found without manually annotating images with these keywords. </span><span class="kobospan" id="kobo.474.3">Even my iPhone (without an LLM) allows me to </span><a id="_idIndexMarker400" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.475.1">search for pictures of “cars,” “food,” “airplanes,” people, or locations like “Burlingame.” </span><span class="kobospan" id="kobo.475.2">More intelligence and power are coming into this space with the inclusion of LLMs. </span><span class="kobospan" id="kobo.475.3">Work on iterating on the data annotation to get content in good standing. </span><span class="kobospan" id="kobo.475.4">Since the discussion of Wove’s use of spreadsheets, this data source is </span><span><span class="kobospan" id="kobo.476.1">worth mentioning.</span></span></p>
			<h3 class="calibre11"><span class="kobospan" id="kobo.477.1">Spreadsheet cleanup (Excel, Google Sheets)</span></h3>
			<p class="calibre3"><span class="kobospan" id="kobo.478.1">Spreadsheets and databases share some common issues. </span><span class="kobospan" id="kobo.478.2">Data sometimes needs to be transformed into </span><a id="_idIndexMarker401" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.479.1">different formats to be understood consistently from one service to another. </span><span class="kobospan" id="kobo.479.2">There are tools to do these transformations. </span><span class="kobospan" id="kobo.479.3">Be aware of these issues and can then apply the tools of the day to solve a problem. </span><span class="kobospan" id="kobo.479.4">Spreadsheet cleanup makes a lot of sense in some backend integrations. </span><span class="kobospan" id="kobo.479.5">Spreadsheets and tables can appear in many forms of documentation, and if they need to be understood by the LLM, they will likely need cleanup. </span><span class="kobospan" id="kobo.479.6">Our second case study extensively uses spreadsheets, and we will explore the effort Wove made for their cleanup process. </span><span class="kobospan" id="kobo.479.7">Hint: It involves a lot of manual work and evaluations. </span><span class="kobospan" id="kobo.479.8">First, let’s define reality, or what people call the </span><span><span class="kobospan" id="kobo.480.1">ground truth.</span></span></p>
			<h3 class="calibre11"><span class="kobospan" id="kobo.481.1">Documentation and ground truth in sources</span></h3>
			<p class="calibre3"><span class="kobospan" id="kobo.482.1">The </span><strong class="bold"><span class="kobospan" id="kobo.483.1">ground truth</span></strong><span class="kobospan" id="kobo.484.1"> is the facts needed as a basis for enterprise solutions. </span><span class="kobospan" id="kobo.484.2">If documentation contains </span><a id="_idIndexMarker402" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.485.1">conflicting or misleading information, the LLM, like customers trying to read documentation, will make mistakes. </span><span class="kobospan" id="kobo.485.2">This is </span><a id="_idIndexMarker403" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.486.1">a fundamental problem for FAQs, technical articles, and marketing communication. </span><span class="kobospan" id="kobo.486.2">The context must be precise to clarify the information associated with which products. </span><span class="kobospan" id="kobo.486.3">Tagging and annotation can help set this context. </span><span class="kobospan" id="kobo.486.4">For example, if the instructions are to hold the power button down for 3 seconds to reset the device, but older models require a different answer, that context must be set clearly. </span><span class="kobospan" id="kobo.486.5">Sometimes, articles call out the products or releases that a document impacts but also give exclusions later or use call-outs to give exceptions. </span><span class="kobospan" id="kobo.486.6">These exclusions need to clearly define their scope for a search engine. </span><span class="kobospan" id="kobo.486.7">Do these exceptions apply to the following few paragraphs or just the paragraphs where it was first introduced? </span><span class="kobospan" id="kobo.486.8">Iterations of editing, tagging, and testing will solve this. </span><span class="kobospan" id="kobo.486.9">Some tagging might be high-level, like articles related to finance or health care, while my examples above are specific to product releases or versions. </span><span class="kobospan" id="kobo.486.10">Let’s start by compiling this in a simple text FAQ </span><span><span class="kobospan" id="kobo.487.1">case study.</span></span></p>
			<h3 class="calibre11"><span class="kobospan" id="kobo.488.1">FAQ case study</span></h3>
			<p class="calibre3"><span class="kobospan" id="kobo.489.1">The Alli case study used File Search in OpenAI, but what about using the same data </span><a id="_idIndexMarker404" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.490.1">in a competitive LLM and RAG solution? </span><span class="kobospan" id="kobo.490.2">Cohere is an AI company that provides enterprise LLM solutions. </span><span class="kobospan" id="kobo.490.3">Why bother with another product in a book about ChatGPT? </span><span class="kobospan" id="kobo.490.4">As models mature, there becomes increasing specialization. </span><span class="kobospan" id="kobo.490.5">An enterprise solution might use one model for a specific task and a different model for a general task (like Wove does in our case study) . </span><span class="kobospan" id="kobo.490.6">Performance, cost, and context size also come into play. </span><span class="kobospan" id="kobo.490.7">With a focus on use cases, it is reasonable that different models might provide value. </span><span class="kobospan" id="kobo.490.8">Cohere also provides a playground function for uploading documents and testing the model. </span><span class="kobospan" id="kobo.490.9">It also exposed a few design elements in the chat UI that provide compelling UI elements worth sharing. </span><span class="kobospan" id="kobo.490.10">In this example, the FAQs with no HTML – just the basic cleaned text was uploaded. </span></p>
			<pre class="source-code"><span class="kobospan1" id="kobo.491.1">
Can I add files to Cohere to help answer FAQs?</span></pre>			<ol class="calibre12">
				<li class="calibre8"><span class="kobospan" id="kobo.492.1">Go to the Coral web page (</span><a href="https://coral.cohere.com/" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.493.1">https://coral.cohere.com/</span></a><span class="kobospan" id="kobo.494.1">) and select the </span><strong class="bold"><span class="kobospan" id="kobo.495.1">Coral with documents</span></strong><span class="kobospan" id="kobo.496.1"> option (see </span><span><em class="italic"><span class="kobospan" id="kobo.497.1">Figure 6</span></em></span><span><em class="italic"><span class="kobospan" id="kobo.498.1">.4</span></em></span><span><span class="kobospan" id="kobo.499.1">).</span></span></li>
			</ol>
			<p class="callout-heading"><span class="kobospan" id="kobo.500.1">Note:</span></p>
			<p class="callout"><span class="kobospan" id="kobo.501.1">The current cohere demo uses a very different design for handling documents, so these instructions won't work. </span><span class="kobospan" id="kobo.501.2">The latest version allows you to copy and paste the information to provide context, or the files must be uploaded using the Dataset tools. </span><span class="kobospan" id="kobo.501.3">We don’t ask readers to do that. </span><span class="kobospan" id="kobo.501.4">We will continue with this example because of some excellent features in the results, but you can follow along by opening the FAQ and copying </span><span><span class="kobospan" id="kobo.502.1">and pasting.</span></span></p>
			<p class="callout"><span class="kobospan" id="kobo.503.1">The most recent releases of Cohere’s Playground are more complex, technical, and cluttered than OpenAI’s. </span><span class="kobospan" id="kobo.503.2">When creating solutions, consider the impact of UI elements on feature capability </span><span><span class="kobospan" id="kobo.504.1">and usability.</span></span></p>
			<p class="calibre3"> </p>
			<div class="calibre2">
				<div id="_idContainer072" class="img---figure">
					<span class="kobospan" id="kobo.505.1"><img src="image/B21964_06_04.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.506.1">Figure 6.4 – Setting up Cohere’s Coral with documents</span></p>
			<ol class="calibre12">
				<li value="2" class="calibre8"><span class="kobospan" id="kobo.507.1">Upload the </span><a id="_idIndexMarker405" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.508.1">FAQ file shared on GitHub using the </span><span><strong class="bold"><span class="kobospan" id="kobo.509.1">Files</span></strong></span><span><span class="kobospan" id="kobo.510.1"> feature.</span></span><p class="calibre3"><span class="kobospan" id="kobo.511.1">GitHub: </span><a href="https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter6-Example_FAQs_NoHTML_for_Demo.docx" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.512.1">FAQ Sample </span><span><span class="kobospan" id="kobo.513.1">Document</span></span></a><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.514.1">(</span></span></span><a href="https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter6-Example_FAQs_NoHTML_for_Demo.docx" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.515.1">https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter6-Example_FAQs_NoHTML_for_Demo.docx</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.516.1">)</span></span></span></p></li>
				<li class="calibre8"><span class="kobospan" id="kobo.517.1">Close the side panel and use the message window to interact (</span><span><em class="italic"><span class="kobospan" id="kobo.518.1">Figure 6</span></em></span><span><em class="italic"><span class="kobospan" id="kobo.519.1">.5</span></em></span><span><span class="kobospan" id="kobo.520.1">).</span></span></li>
			</ol>
			<div class="calibre2">
				<div id="_idContainer073" class="img---figure">
					<span class="kobospan" id="kobo.521.1"><img src="image/B21964_06_05.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.522.1">Figure 6.5 – Example showing reference usage</span></p>
			<ol class="calibre12">
				<li value="4" class="calibre8"><span class="kobospan" id="kobo.523.1">Test the </span><a id="_idIndexMarker406" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.524.1">model with questions related to the FAQ (</span><span><em class="italic"><span class="kobospan" id="kobo.525.1">Figure 6</span></em></span><span><em class="italic"><span class="kobospan" id="kobo.526.1">.6</span></em></span><span><span class="kobospan" id="kobo.527.1">).</span></span></li>
			</ol>
			<div class="calibre2">
				<div id="_idContainer074" class="img---figure">
					<span class="kobospan" id="kobo.528.1"><img src="image/B21964_06_06.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.529.1">Figure 6.6 – Examples of the FAQ document in Cohere</span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.530.1">Besides the reasons stated, there are some exciting results from this </span><span><span class="kobospan" id="kobo.531.1">competitive model:</span></span></p>
			<ul class="calibre7">
				<li class="calibre8"><span class="kobospan" id="kobo.532.1">What is in this book is generalizable to </span><span><span class="kobospan" id="kobo.533.1">other models.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.534.1">Some UX elements, like showing the reference panel, could be valuable to a use case. </span><span class="kobospan" id="kobo.534.2">There is only one document in this demo, so viewing the one link doesn’t help because it repeats itself with every match. </span><span class="kobospan" id="kobo.534.3">Linking to the reference and then scrolling and highlighting the relevant passages makes it easy to understand and see the context. </span><span class="kobospan" id="kobo.534.4">The relevance-highlighting UX pattern should become popular or even </span><span><span class="kobospan" id="kobo.535.1">a standard.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.536.1">It is an excellent example of a side-by-side pattern showing </span><span><span class="kobospan" id="kobo.537.1">supplemental information.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.538.1">It gives us a feel for the quality of different models and allows us to see differences between each version </span><span><span class="kobospan" id="kobo.539.1">of ChatGPT.</span></span></li>
			</ul>
			<p class="calibre3"><span class="kobospan" id="kobo.540.1">Let’s test our FAQs. </span><span class="kobospan" id="kobo.540.2">It is helpful to give some context with this Cohere example so that we can explore using FAQs in ChatGPT. </span><span class="kobospan" id="kobo.540.3">Let’s see if the results meet </span><span><span class="kobospan" id="kobo.541.1">our expectations.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.542.1">GitHub: </span><a href="https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter6-FAQ_PDFs.zip" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.543.1">Zip of FAQS as unique </span><span><span class="kobospan" id="kobo.544.1">PDFs</span></span></a><span><span class="kobospan" id="kobo.545.1"> (</span></span><a href="https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter6-FAQ_PDFs.zip" class="pcalibre pcalibre1 calibre6"><span><span class="kobospan" id="kobo.546.1">https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter6-FAQ_PDFs.zip</span></span></a><span><span class="kobospan" id="kobo.547.1">)</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.548.1">In this case, the zip file contains the cleaned data in individual PDF documents. </span><span class="kobospan" id="kobo.548.2">This allows us better to connect the source as a reference and the results. </span><span class="kobospan" id="kobo.548.3">Return to the ChatGPT Playground and create the same assistants as before, but try to upload </span><span><span class="kobospan" id="kobo.549.1">this file.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.550.1">However, recall there are limitations; uploading the file in ChatGPT 3.5 will result in a cryptic user error (meaning too many files were uploaded), as shown in </span><span><em class="italic"><span class="kobospan" id="kobo.551.1">Figure 6</span></em></span><span><em class="italic"><span class="kobospan" id="kobo.552.1">.7</span></em></span><span><span class="kobospan" id="kobo.553.1">.</span></span></p>
			<div class="calibre2">
				<div id="_idContainer075" class="img---figure">
					<span class="kobospan" id="kobo.554.1"><img src="image/B21964_06_07.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.555.1">Figure 6.7 – ChatGPT has a file limit</span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.556.1">It is a small dataset, just not small enough. </span><span class="kobospan" id="kobo.556.2">There is a workaround to allow its use in the free playground. </span><span class="kobospan" id="kobo.556.3">The PDFs are joined into 18 files, and a single PDF can be used for other testing </span><span><span class="kobospan" id="kobo.557.1">and experimentation.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.558.1">GitHub: </span><a href="https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter6-FAQS18files.zip" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.559.1">Zip of 18 FAQ Files</span></a> <span class="hidden1"><span class="kobospan" id="kobo.560.1">(</span></span><a href="https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter6-FAQS18files.zip" class="pcalibre pcalibre1 calibre6"><span class="hidden1"><span class="kobospan" id="kobo.561.1">https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter6-FAQS18files.zip</span></span></a><span class="hidden1"><span class="kobospan" id="kobo.562.1">)</span></span><span class="kobospan" id="kobo.563.1"> (each with 25 or </span><span><span class="kobospan" id="kobo.564.1">so FAQs)</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.565.1">GitHub: </span><a href="https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter6-FAQ-ALL.pdf" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.566.1">Single PDF with all 441 </span><span><span class="kobospan" id="kobo.567.1">FAQs</span></span></a><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.568.1">(</span></span></span><a href="https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter6-FAQ-ALL.pdf" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.569.1">https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter6-FAQ-ALL.pdf</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.570.1">)</span></span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.571.1">With these 18 files, it only takes a few seconds to upload and scan them, and the Playground will be ready </span><span><span class="kobospan" id="kobo.572.1">to go.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.573.1">Once uploaded, try out some test cases like </span><em class="italic"><span class="kobospan" id="kobo.574.1">Tables 6.2 and 6.3</span></em><span class="kobospan" id="kobo.575.1">. </span><span class="kobospan" id="kobo.575.2">They were written without knowing whether they would work (they were not pre-tested). </span><span class="kobospan" id="kobo.575.3">Test cases are covered more extensively in the next few chapters; let’s keep it simple and do testing manually. </span><span class="kobospan" id="kobo.575.4">Test </span><a id="_idIndexMarker407" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.576.1">whether single or multiple files impact quality and see what can be learned from </span><span><span class="kobospan" id="kobo.577.1">the results.</span></span></p>
			<p class="callout-heading"><span class="kobospan" id="kobo.578.1">Note</span></p>
			<p class="callout"><span class="kobospan" id="kobo.579.1">Try different models available. </span><span class="kobospan" id="kobo.579.2">It doesn’t have to be ChatGPT 3.5; try ChatGPT 4o-mini or compare it to other </span><span><span class="kobospan" id="kobo.580.1">vendors’ LLMs.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.581.1">In both cases, use the cleaned data column from the spreadsheet. </span><span class="kobospan" id="kobo.581.2">There are some spelling errors and chaining questions (questions that demand a follow-up question) in the test cases. </span><span class="kobospan" id="kobo.581.3">Now, we can learn about the actual </span><span><span class="kobospan" id="kobo.582.1">results together.</span></span></p>
			<div class="calibre2">
				<div id="_idContainer076" class="img---figure">
					<span class="kobospan" id="kobo.583.1"><img src="image/B21964_Table_6.2.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.584.1">Table 6.2 – Questions 1-10 and the results from two test sessions</span></p>
			<div class="calibre2">
				<div id="_idContainer077" class="img---figure">
					<span class="kobospan" id="kobo.585.1"><img src="image/B21964_Table_6.3.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.586.1">Table 6.3 – Questions 11-20 and the results from two test sessions</span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.587.1">Here are some high-level analyses of </span><span><span class="kobospan" id="kobo.588.1">these results:</span></span></p>
			<ul class="calibre7">
				<li class="calibre8"><span class="kobospan" id="kobo.589.1">Spelling errors did not </span><span><span class="kobospan" id="kobo.590.1">cause issues.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.591.1">Follow-ups that provide a little extra context returned </span><span><span class="kobospan" id="kobo.592.1">good results.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.593.1">The same model returned very different results for </span><span><span class="kobospan" id="kobo.594.1">some questions.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.595.1">Specific information like addresses was </span><span><span class="kobospan" id="kobo.596.1">very challenging.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.597.1">It didn’t think it was the bank; it referred to “your financial institution or brokerage firm.” </span><span class="kobospan" id="kobo.597.2">Prompt engineering can fix </span><span><span class="kobospan" id="kobo.598.1">this problem.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.599.1">Both needed help with ending sentences with a period. </span><span class="kobospan" id="kobo.599.2">They tended to put a space before the period like </span><span><span class="kobospan" id="kobo.600.1">this .</span></span></li>
			</ul>
			<p class="calibre3"><span class="kobospan" id="kobo.601.1">Let’s create a simple score for these two methods. </span><span class="kobospan" id="kobo.601.2">Five points for a great correct answer, 4 points for a </span><a id="_idIndexMarker408" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.602.1">good correct answer, 3 points for a close to correct answer, and 2 points if a follow-up returned details that should have been in the first answer. </span><span class="kobospan" id="kobo.602.2">Scoring shows 47 points for separate files and 74 for a single file model. </span><span class="kobospan" id="kobo.602.3">Recognizing a significant difference between these two starting points doesn’t have to be perfect. </span><span class="kobospan" id="kobo.602.4">If you watched the OpenAI video in the last chapter (one of my favorite video references of this entire book), they had some similar experiences, beginning with a poor result, and with fine-tuning and prompt engineering, they improved their result, as shown in </span><span><em class="italic"><span class="kobospan" id="kobo.603.1">Figure 6</span></em></span><span><em class="italic"><span class="kobospan" id="kobo.604.1">.8</span></em></span><span><span class="kobospan" id="kobo.605.1">.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.606.1">Video: </span><a href="https://www.youtube.com/watch?v=ahnGLM-RC1Y" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.607.1">A Survey of Techniques for Maximizing LLM </span><span><span class="kobospan" id="kobo.608.1">Performance</span></span></a><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.609.1">(</span></span></span><a href="https://www.youtube.com/watch?v=ahnGLM-RC1Y" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.610.1">https://www.youtube.com/watch?v=ahnGLM-RC1Y</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.611.1">)</span></span></span></p>
			<div class="calibre2">
				<div id="_idContainer078" class="img---figure">
					<span class="kobospan" id="kobo.612.1"><img src="image/B21964_06_08.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.613.1">Figure 6.8 – A RAG success story for OpenAI’s approach in a use case</span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.614.1">It isn’t necessary to understand all of these methods in detail. </span><span class="kobospan" id="kobo.614.2">Toward the end of this chapter, there is a section for other techniques to discuss this. </span><span class="kobospan" id="kobo.614.3">The point for the moment is to showcase how continuous improvement to your lifecycle will help determine what changes improve the experience. </span><span class="kobospan" id="kobo.614.4">Even with this rudimentary scoring, there are dramatically different results. </span><span class="kobospan" id="kobo.614.5">I, too, was surprised by the dramatic difference. </span><span class="kobospan" id="kobo.614.6">The full transcript of both results </span><span><span class="kobospan" id="kobo.615.1">is posted.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.616.1">GitHub: </span><a href="https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter6-Transcripts.docx" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.617.1">Transcripts of FAQ </span><span><span class="kobospan" id="kobo.618.1">Test</span></span></a><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.619.1">(</span></span></span><a href="https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter6-Transcripts.docx" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.620.1">https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter6-Transcripts.docx</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.621.1">)</span></span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.622.1">The data brought in through RAG needs to be cleaned, as seen in the forthcoming Wove case study. </span><span class="kobospan" id="kobo.622.2">Something simple, like how files are split up, can profoundly impact performance. </span><span class="kobospan" id="kobo.622.3">Each improvement can affect </span><a id="_idIndexMarker409" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.623.1">the next step. </span><span class="kobospan" id="kobo.623.2">It is better to continue to refine, starting from a score of 74 than from 47. </span><span class="kobospan" id="kobo.623.3">Find tools to handle the mundane work so efforts can be focused on actual data and its quality. </span><span class="kobospan" id="kobo.623.4">There are other issues to consider when creating a complete lifecycle for a data pipeline. </span><span class="kobospan" id="kobo.623.5">Next is a case study from an exciting company that uses a variety of models to make its LLM </span><span><span class="kobospan" id="kobo.624.1">solution successful.</span></span></p>
			<h3 class="calibre11"><span class="kobospan" id="kobo.625.1">Spreadsheet cleanup case study</span></h3>
			<p class="calibre3"><span class="kobospan" id="kobo.626.1">Here is an excellent example of spreadsheets used behind the scenes to create intelligence </span><a id="_idIndexMarker410" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.627.1">in the LLM and offer recommendations from </span><a href="https://wove.com" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.628.1">Wove.com</span></a> <span class="hidden1"><span class="kobospan" id="kobo.629.1">(</span></span><a href="https://wove.com" class="pcalibre pcalibre1 calibre6"><span class="hidden1"><span class="kobospan" id="kobo.630.1">https://wove.com</span></span></a><span class="hidden1"><span class="kobospan" id="kobo.631.1">)</span></span><span class="kobospan" id="kobo.632.1">. </span><span class="kobospan" id="kobo.632.2">Wove helps freight forwarding companies optimize rate management operations by using LLMs to parse and normalize complex tabular data from rate sheets, ocean contracts, and </span><span><span class="kobospan" id="kobo.633.1">other spreadsheets.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.634.1">Freight forwarders act as intermediaries who ensure that small shippers can get goods from one location to another—for example, shipping 10,000 widgets from a factory in China to a warehouse in Nebraska. </span><span class="kobospan" id="kobo.634.2">Because there are hundreds of ways to get from point A to point B, there are complexities based on the vendor, distance, ports, transport type, time, type of goods, customs, weight, and volume. </span><span class="kobospan" id="kobo.634.3">This complexity is buried in published data from each vendor in spreadsheets, PDFs, and other data sources. </span><span class="kobospan" id="kobo.634.4">This complexity increases the time to quote and can lead to missing reasonable rates. </span><span class="kobospan" id="kobo.634.5">By taking these rate sheets and putting them into the model, customer quotes can be generated more accurately and efficiently. </span><span class="kobospan" id="kobo.634.6">This a daunting task. </span><span class="kobospan" id="kobo.634.7">To geek out on the rate sheet use case, look at all the standard terms one might see in </span><span><span class="kobospan" id="kobo.635.1">a sheet.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.636.1">Article: </span><a href="https://www.slideshare.net/logicalmsgh/understanding-the-freight-rate-sheet" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.637.1">Rate Sheet Terms and </span><span><span class="kobospan" id="kobo.638.1">Introduction</span></span></a><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.639.1">(</span></span></span><a href="https://www.slideshare.net/logicalmsgh/understanding-the-freight-rate-sheet" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.640.1">https://www.slideshare.net/logicalmsgh/understanding-the-freight-rate-sheet</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.641.1">)</span></span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.642.1">Terms like BAR, BL Fee, Demurrage, DDC, CYRC, Detention, and dozens of others are a lot to digest. </span><span class="kobospan" id="kobo.642.2">It makes it challenging for an LLM to understand a complex spreadsheet. </span><span class="kobospan" id="kobo.642.3">This is an excellent example from our friends at Wove, who have created a behind-the-scenes use of ChatGPT and other models, like Anthropic’s Claude. </span><span class="kobospan" id="kobo.642.4">They focus on ingesting data to preserve </span><a id="_idIndexMarker411" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.643.1">data quality and integrity and normalize widely different spreadsheets. </span><span class="kobospan" id="kobo.643.2">Indeed, there are opportunities on the UI side to use this data to answer questions about finding the correct rate for a job. </span><span class="kobospan" id="kobo.643.3">This part of the case study will focus on data ingestion. </span><span class="kobospan" id="kobo.643.4">The Wove case study will be completed after more is explained in the prompt engineering and </span><span><span class="kobospan" id="kobo.644.1">fine-tuning chapters.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.645.1">The terms require understanding, and each rate sheet varies in format, labels, exceptions, and other factors. </span><span class="kobospan" id="kobo.645.2">As rates change over time, the correct rate periods must be understood. </span><span><em class="italic"><span class="kobospan" id="kobo.646.1">Figure 6</span></em></span><em class="italic"><span class="kobospan" id="kobo.647.1">.9</span></em><span class="kobospan" id="kobo.648.1"> shows a fraction of a rate sheet to expose </span><span><span class="kobospan" id="kobo.649.1">this complexity.</span></span></p>
			<div class="calibre2">
				<div id="_idContainer079" class="img---figure">
					<span class="kobospan" id="kobo.650.1"><img src="image/B21964_010_06.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.651.1">Figure 6.9 – Samples of rate sheets from two different vendors</span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.652.1">A typical forwarder might have to deal with dozens of different rate sheets, and with some of them </span><a id="_idIndexMarker412" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.653.1">being </span><em class="italic"><span class="kobospan" id="kobo.654.1">hundreds</span></em><span class="kobospan" id="kobo.655.1"> of pages long, normalizing all of this data manually requires the effort of a whole team. </span><span class="kobospan" id="kobo.655.2">The examples show how varied the data columns can be. </span><span class="kobospan" id="kobo.655.3">The labels, the values, the use of tabs, how exceptions are handled with remarks, and the headers are all different. </span><span class="kobospan" id="kobo.655.4">However, automation, or even semi-automation, can reduce this process by more than 90%. </span><span class="kobospan" id="kobo.655.5">Although one should test and verify data along the way, there are numerous places in the manual lifecycle where human error causes issues. </span><span class="kobospan" id="kobo.655.6">Let’s review the data cleansing steps Wove had to do to ingest this data. </span><span class="kobospan" id="kobo.655.7">The expected flow of this information is </span><span><span class="kobospan" id="kobo.656.1">as follows:</span></span></p>
			<ol class="calibre12">
				<li class="calibre8"><span class="kobospan" id="kobo.657.1">Before getting new rate sheets, they trained and verified the various models needed to create high-quality output. </span><span class="kobospan" id="kobo.657.2">This case study will discuss the different </span><span><span class="kobospan" id="kobo.658.1">models used.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.659.1">Typically, they receive a rate sheet in an email and download the file into Wove. </span><span class="kobospan" id="kobo.659.2">There is also an automation path with an email listener that picks up the file, monitors for new files, and ingests it into the process. </span><span class="kobospan" id="kobo.659.3">These files can have multiple tabs and thousands of rows of data, like the small sample shown in </span><span><em class="italic"><span class="kobospan" id="kobo.660.1">Figure 6</span></em></span><em class="italic"><span class="kobospan" id="kobo.661.1">.9</span></em><span class="kobospan" id="kobo.662.1">. </span><span class="kobospan" id="kobo.662.2">A typical file is likely an update of a previously </span><span><span class="kobospan" id="kobo.663.1">processed file.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.664.1">Their tools parse the XLS file and identify the tables, and it parses the document and turns them into property formatted clumps for the model. </span><span class="kobospan" id="kobo.664.2">There are context length limits, detecting tables, understanding the tables, and figuring out how the tables relate to each other. </span><span class="kobospan" id="kobo.664.3">They refer to this as table detection. </span><span class="kobospan" id="kobo.664.4">As shown next, the development team built ten models to understand the spreadsheet. </span><span class="kobospan" id="kobo.664.5">The entire proprietary process isn’t shared, but this should give a sense of </span><a id="_idIndexMarker413" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.665.1">what each model does and what software was used to help the cleaning and organizing process. </span><span class="kobospan" id="kobo.665.2">Although this is a technical process, the results are something mere mortals can see. </span><span class="kobospan" id="kobo.665.3">They can determine whether they provide the best results for the cost involved. </span><span class="kobospan" id="kobo.665.4">This is a business decision and a user </span><span><span class="kobospan" id="kobo.666.1">experience problem.</span></span><ul class="calibre19"><li class="calibre8"><strong class="bold"><span class="kobospan" id="kobo.667.1">Document Segmentation (Single-Shot GPT 4 Turbo)</span></strong><span class="kobospan" id="kobo.668.1">: This segments documents into </span><span><span class="kobospan" id="kobo.669.1">coherent sections/ideas.</span></span></li><li class="calibre8"><strong class="bold"><span class="kobospan" id="kobo.670.1">Context Builder (Multi-Shot Claude 3 Haiku)</span></strong><span class="kobospan" id="kobo.671.1">: This is applied after document segmentation. </span><span class="kobospan" id="kobo.671.2">It builds the reading context for understanding the </span><span><span class="kobospan" id="kobo.672.1">current document.</span></span></li><li class="calibre8"><strong class="bold"><span class="kobospan" id="kobo.673.1">Table Detection (GPT 3.5 Turbo, Fine-tuned)</span></strong><span class="kobospan" id="kobo.674.1">: This detects tables in spreadsheets, documents, </span><span><span class="kobospan" id="kobo.675.1">or contracts.</span></span></li><li class="calibre8"><strong class="bold"><span class="kobospan" id="kobo.676.1">Table Header Range Detection (GPT 3.5 Turbo, Fine-tuned)</span></strong><span class="kobospan" id="kobo.677.1">: After the table is detected, the range of header rows and where the data for the table starts </span><span><span class="kobospan" id="kobo.678.1">are determined.</span></span></li><li class="calibre8"><strong class="bold"><span class="kobospan" id="kobo.679.1">Table End Detection (GPT 3.5 Turbo, Fine-tuned)</span></strong><span class="kobospan" id="kobo.680.1">: This detects the end of the </span><span><span class="kobospan" id="kobo.681.1">table data.</span></span></li><li class="calibre8"><strong class="bold"><span class="kobospan" id="kobo.682.1">Table Understanding (GPT 3.5 Turbo, Fine-tuned)</span></strong><span class="kobospan" id="kobo.683.1">: This model understands a table’s columns and data and determines </span><span><span class="kobospan" id="kobo.684.1">its purpose.</span></span></li><li class="calibre8"><strong class="bold"><span class="kobospan" id="kobo.685.1">Schema Mapping (GPT 3.5 Turbo, Fine-tuned)</span></strong><span class="kobospan" id="kobo.686.1">: This model is applied after the table is understood. </span><span class="kobospan" id="kobo.686.2">It determines which columns from a table map to schema fields in </span><span><span class="kobospan" id="kobo.687.1">a database.</span></span></li><li class="calibre8"><strong class="bold"><span class="kobospan" id="kobo.688.1">Field Splitter (Single-Shot Claude 3 Haiku)</span></strong><span class="kobospan" id="kobo.689.1">: The splitter extracts per-field information from combined fields. </span><span class="kobospan" id="kobo.689.2">For example, if effective and expiry dates are in the same field, this can extract them into </span><strong class="source-inline1"><span class="kobospan" id="kobo.690.1">effective_date</span></strong><span class="kobospan" id="kobo.691.1"> and </span><strong class="source-inline1"><span class="kobospan" id="kobo.692.1">expiry_date</span></strong><span class="kobospan" id="kobo.693.1"> in </span><span><span class="kobospan" id="kobo.694.1">the schema.</span></span></li><li class="calibre8"><strong class="bold"><span class="kobospan" id="kobo.695.1">Location Normalizer (Multi-Shot GPT 3.5 Turbo)</span></strong><span class="kobospan" id="kobo.696.1">: This takes unstructured location information and normalizes each detected location to a UN/LOCODE (normalized country codes such as HK for </span><span><span class="kobospan" id="kobo.697.1">Hong Kong).</span></span></li><li class="calibre8"><strong class="bold"><span class="kobospan" id="kobo.698.1">Commodity Normalizer (GPT 3.5 Turbo + Ada)</span></strong><span class="kobospan" id="kobo.699.1">: This takes unstructured commodity information and normalizes each commodity type to </span><span><span class="kobospan" id="kobo.700.1">be searched/compared.</span></span></li><li class="calibre8"><span class="kobospan" id="kobo.701.1">These models changed multiple times during the creation of this case study, and they continue to change as they are currently testing GPT 4o-mini for some use cases. </span><span class="kobospan" id="kobo.701.2">Adapt and improve, and sometimes save </span><span><span class="kobospan" id="kobo.702.1">some money.</span></span></li></ul></li>
				<li class="calibre8"><span class="kobospan" id="kobo.703.1">They identify, tag, and train the system to understand where the table is, where data starts, where it ends, the header labels, and so on. </span><span class="kobospan" id="kobo.703.2">The challenge is understanding </span><a id="_idIndexMarker414" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.704.1">tables when LLMs are primarily for text. </span><span class="kobospan" id="kobo.704.2">The spreadsheets become text. </span><span class="kobospan" id="kobo.704.3">Notice some of the models used in this process are fine-tuned. </span><span class="kobospan" id="kobo.704.4">Those are the ones that need additional understanding and learning by providing examples of what defines </span><span><span class="kobospan" id="kobo.705.1">a table.</span></span></li>
			</ol>
			<p class="calibre3"><span class="kobospan" id="kobo.706.1">Diving more into table detection helps to understand the segmenting of data. </span><span class="kobospan" id="kobo.706.2">After table detection from </span><em class="italic"><span class="kobospan" id="kobo.707.1">Step 3</span></em><span class="kobospan" id="kobo.708.1">, they do semantic chunking to get the right context length. </span><span class="kobospan" id="kobo.708.2">Typically, a suitable context length might start at 500 to 1,000 tokens. </span><span class="kobospan" id="kobo.708.3">Depending on the model, longer context lengths are acceptable if you want to pay for them. </span><span class="kobospan" id="kobo.708.4">Wove prompts GPT-4 to chunk the files into </span><em class="italic"><span class="kobospan" id="kobo.709.1">coherent segments</span></em><span class="kobospan" id="kobo.710.1">. </span><span class="kobospan" id="kobo.710.2">Chunks are essential, as only so much information can be processed at one time. </span><span class="kobospan" id="kobo.710.3">Effective chunking strategies are necessary to have the proper context for </span><span><span class="kobospan" id="kobo.711.1">a chunk.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.712.1">Their prompt is pretty big—it is a page long. </span><span class="kobospan" id="kobo.712.2">It tells ChatGPT 20 different rules to parse a segment. </span><span class="kobospan" id="kobo.712.3">Their prompt starts simple… “You’re an expert in doc parsing; you’ll be given a chunk of text. </span><span class="kobospan" id="kobo.712.4">Your job is to split it into coherent segments.” </span><span class="kobospan" id="kobo.712.5">They don’t have massive chunks, so chunk size is not limited by the LLMs. </span><span class="kobospan" id="kobo.712.6">Each model can have a different token limit to allow for the size of the prompt and the resulting output. </span><span class="kobospan" id="kobo.712.7">The models range from 4K to 8K tokens for input and output. </span><span class="kobospan" id="kobo.712.8">They use a smaller, faster, and less expensive model in the next step. </span><span class="kobospan" id="kobo.712.9">If you are unsure of your model’s limitations, </span><span><span class="kobospan" id="kobo.713.1">ask it.</span></span></p>
			<pre class="source-code"><span class="kobospan1" id="kobo.714.1">
What makes a good context length when ingesting data into you to help provide context?</span></pre>			<p class="calibre3"><span class="kobospan" id="kobo.715.1">Wove covers </span><a id="_idIndexMarker415" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.716.1">the entire lifecycle. </span><strong class="bold"><span class="kobospan" id="kobo.717.1">Functional calling</span></strong><span class="kobospan" id="kobo.718.1">, the method to access </span><a id="_idIndexMarker416" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.719.1">other resources such as APIs, is essential to Wove’s process and fundamental to enterprise applications. </span><span class="kobospan" id="kobo.719.2">Be aware of this capability. </span><span class="kobospan" id="kobo.719.3">Remember, any enterprise solution will connect to various resources to enrich </span><span><span class="kobospan" id="kobo.720.1">the LLM.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.721.1">Documentation: </span><a href="https://platform.openai.com/docs/guides/function-calling" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.722.1">ChatGPT developer documentation on function </span><span><span class="kobospan" id="kobo.723.1">calling</span></span></a><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.724.1">(</span></span></span><a href="https://platform.openai.com/docs/guides/function-calling" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.725.1">https://platform.openai.com/docs/guides/function-calling</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.726.1">)</span></span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.727.1">They use function calling to generate the sections into a structured output. </span><span class="kobospan" id="kobo.727.2">A piece of this function is shown in </span><span><em class="italic"><span class="kobospan" id="kobo.728.1">Figure 6</span></em></span><em class="italic"><span class="kobospan" id="kobo.729.1">.10</span></em><span class="kobospan" id="kobo.730.1">. </span><span class="kobospan" id="kobo.730.2">The product team needs to understand this to ensure the context is complete. </span><span class="kobospan" id="kobo.730.3">Some of this might be generic to any spreadsheet, such as a start line, end line, the section’s name, headers, and a description, but getting this understanding right is essential. </span><span class="kobospan" id="kobo.730.4">Later, they checked that the tables were processed correctly to confirm the correct start line, header, or </span><span><span class="kobospan" id="kobo.731.1">sub-header labels.</span></span></p>
			<pre class="source-code"><span class="kobospan1" id="kobo.732.1">
"type": "function",
"function": {
    "name": "next_section",
    "description": "extracts the next section of the
    document",
    "parameters": {
        "type": "object",
        "properties": {
            "StartLine": {
                "type": "number",
                "description": "the line number where the
                section header or contents starts at,
                inclusive. </span><span class="kobospan1" id="kobo.732.2">This must exist."
</span><span class="kobospan1" id="kobo.732.3">            },
            "EndLine": {
                "type": "number",
                "description": "the line number where the
                section content ends at, inclusive. </span><span class="kobospan1" id="kobo.732.4">This
                must exist in the input."
</span><span class="kobospan1" id="kobo.732.5">            },
            "SectionName": {
                "type": "string",
                "description": "the name of the section,
                either the title/header if available, or a
                description of the column."
</span><span class="kobospan1" id="kobo.732.6">            },
            "SectionHeader": {
                "type": "string",
                "description": "the header of the section,
                if available"
            },
            "SectionType": {
                "type": "string",
                "description": "the type of the section"
            },
            "SectionDescription": {
                "type": "string",
                "description": "the description of the
                section – this is required"
            },
        },
        "required": ["StartLine", "EndLine", "SectionName",
        "SectionType", "SectionDescription"]
    }</span></pre>			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.733.1">Figure 6.10 – A snippet of the function calling that is used to help structure the output</span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.734.1">They can use the </span><a id="_idIndexMarker417" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.735.1">training validation split data, test the models against the removed data, and use their data cleaning technique on the data shown in </span><span><em class="italic"><span class="kobospan" id="kobo.736.1">Figure 6</span></em></span><em class="italic"><span class="kobospan" id="kobo.737.1">.11</span></em><span class="kobospan" id="kobo.738.1"> by defining the tables. </span><span class="kobospan" id="kobo.738.2">This data tagging defines </span><em class="italic"><span class="kobospan" id="kobo.739.1">what is what</span></em><span class="kobospan" id="kobo.740.1"> in the table and can improve with more refinements over time. </span><span class="kobospan" id="kobo.740.2">Scripts help generate new training data from this </span><span><span class="kobospan" id="kobo.741.1">tagged source.</span></span></p>
			<div class="calibre2">
				<div id="_idContainer080" class="img---figure">
					<span class="kobospan" id="kobo.742.1"><img src="image/B21964_06_11.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.743.1">Figure 6.11 – A small table of side terms from the rate sheets</span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.744.1">Look </span><a id="_idIndexMarker418" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.745.1">at this definition of </span><strong class="source-inline"><span class="kobospan" id="kobo.746.1">Side Terms</span></strong><span class="kobospan" id="kobo.747.1">, which is used to train table detection; it tells the LLM how to understand </span><span><span class="kobospan" id="kobo.748.1">this data.</span></span></p>
			<pre class="source-code"><span class="kobospan1" id="kobo.749.1">
1  "Side Terms": {
2      "min_row": 3,
3      "max_row": 21,
4      "tables": [
5          TableRangeV2(("B", "G"), 6, (7,20)),
6      ],</span></pre>			<p class="calibre3"><span class="kobospan" id="kobo.750.1">Product managers, designers, and the team must monitor table definitions to ensure high quality. </span><span class="kobospan" id="kobo.750.2">In this example, they identify the “</span><strong class="source-inline"><span class="kobospan" id="kobo.751.1">Side Terms</span></strong><span class="kobospan" id="kobo.752.1">” start date from row 3 (line 2) to row 21 (line 3). </span><span class="kobospan" id="kobo.752.2">In line 5, they identify the spreadsheet columns as from </span><strong class="source-inline"><span class="kobospan" id="kobo.753.1">B</span></strong><span class="kobospan" id="kobo.754.1"> to </span><strong class="source-inline"><span class="kobospan" id="kobo.755.1">G</span></strong><span class="kobospan" id="kobo.756.1"> (column </span><strong class="source-inline"><span class="kobospan" id="kobo.757.1">A</span></strong><span class="kobospan" id="kobo.758.1"> is white space), followed by row 6 being defined as the header and defining the source data for the table with </span><strong class="source-inline"><span class="kobospan" id="kobo.759.1">(7,20)</span></strong><span class="kobospan" id="kobo.760.1"> for rows 7 to 20. </span><span class="kobospan" id="kobo.760.2">However, in </span><span><em class="italic"><span class="kobospan" id="kobo.761.1">Figure 6</span></em></span><em class="italic"><span class="kobospan" id="kobo.762.1">.11</span></em><span class="kobospan" id="kobo.763.1">, notice the </span><strong class="source-inline"><span class="kobospan" id="kobo.764.1">Remark</span></strong><span class="kobospan" id="kobo.765.1"> column (column </span><strong class="source-inline"><span class="kobospan" id="kobo.766.1">F</span></strong><span class="kobospan" id="kobo.767.1">) extends to line 21, so the process involves human validation </span><em class="italic"><span class="kobospan" id="kobo.768.1">to catch this error</span></em><span class="kobospan" id="kobo.769.1"> and change </span><strong class="source-inline"><span class="kobospan" id="kobo.770.1">(7,20)</span></strong> <span><span class="kobospan" id="kobo.771.1">to </span></span><span><strong class="source-inline"><span class="kobospan" id="kobo.772.1">(7,21)</span></strong></span><span><span class="kobospan" id="kobo.773.1">.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.774.1">Multiple models use this one tagging exercise. </span><span class="kobospan" id="kobo.774.2">This effort supports table-end detection, headers, and </span><span><span class="kobospan" id="kobo.775.1">table understanding.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.776.1">It is vital to catch what needs to be tagged. </span><span class="kobospan" id="kobo.776.2">For example, some notes with stars are shown at the top of the table in </span><span><em class="italic"><span class="kobospan" id="kobo.777.1">Figure 6</span></em></span><em class="italic"><span class="kobospan" id="kobo.778.1">.9</span></em><span class="kobospan" id="kobo.779.1">. </span><span class="kobospan" id="kobo.779.2">LLMs are good at understanding text and the reference to this block of text extracted from the table detection, so no additional effort was needed to gather </span><span><span class="kobospan" id="kobo.780.1">this information.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.781.1">The data must then be normalized for items such as rates and locations. </span><span class="kobospan" id="kobo.781.2">So, for Hong Kong, the port HKHKG is displayed consistently, and dozens of other values are mapped correctly across </span><span><span class="kobospan" id="kobo.782.1">different files.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.783.1">There is a data review process, and Wove has tools for doing so. </span><span class="kobospan" id="kobo.783.2">The team reviews this clean data, as shown in </span><span><em class="italic"><span class="kobospan" id="kobo.784.1">Figure 6</span></em></span><em class="italic"><span class="kobospan" id="kobo.785.1">.12</span></em><span class="kobospan" id="kobo.786.1">. </span><span class="kobospan" id="kobo.786.2">This drill-down shows rates between Hong Kong and Atlanta and some data that goes into </span><span><span class="kobospan" id="kobo.787.1">these rates.</span></span></p>
			<div class="calibre2">
				<div id="_idContainer081" class="img---figure">
					<span class="kobospan" id="kobo.788.1"><img src="image/B21964_06_12-shphigh.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.789.1">Figure 6.12 – The view of data so now they can view rates in a normalized view</span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.790.1">Now that they have ingested and normalized the data, they can access rates from many sources. </span><span class="kobospan" id="kobo.790.2">Let’s explore some of the details of this workflow a </span><span><span class="kobospan" id="kobo.791.1">bit further.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.792.1">This is not about a single model performing magic; it takes a collection of specialized models. </span><span class="kobospan" id="kobo.792.2">They applied different models to solve various problems. </span><span class="kobospan" id="kobo.792.3">It is expected to adapt and change over time, especially with models that use fine-tuning. </span><span class="kobospan" id="kobo.792.4">Think of it as a modular approach. </span><span class="kobospan" id="kobo.792.5">If a new or much less expensive model comes out, swap it to improve one piece of the puzzle at a time. </span><span class="kobospan" id="kobo.792.6">If there are issues around one topic, such as poor or missing data, and the model will need help converging to a practical solution, focus on that problem. </span><span class="kobospan" id="kobo.792.7">Each piece can experience its version </span><span><span class="kobospan" id="kobo.793.1">of hallucinations.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.794.1">Data cleansing has a specific meaning for these spreadsheets, especially ensuring that rows and exceptions are handled. </span><span class="kobospan" id="kobo.794.2">Chunks must be segmented correctly to </span><a id="_idIndexMarker419" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.795.1">have a good beginning and end so that context is maintained. </span><span class="kobospan" id="kobo.795.2">This gives RAG a clean context and retrieves relevant chunks </span><span><span class="kobospan" id="kobo.796.1">more accurately.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.797.1">Here are the top issues addressed in their cleanup and </span><span><span class="kobospan" id="kobo.798.1">ingestion process:</span></span></p>
			<ol class="calibre12">
				<li class="calibre8"><span class="kobospan" id="kobo.799.1">Process data as text, even coming </span><span><span class="kobospan" id="kobo.800.1">from spreadsheets.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.801.1">The model segments large documents—some rate sheets can be hundreds of pages long—and breaks them up. </span><span class="kobospan" id="kobo.801.2">For example, ocean shipping documents are more complex than road </span><span><span class="kobospan" id="kobo.802.1">trucking documents.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.803.1">The challenge is to understand tables as text. </span><span class="kobospan" id="kobo.803.2">It takes considerable work to understand tables well, tag them correctly, look for errors, and find a suitable model (which they did and didn’t discuss to protect their expertise). </span><span class="kobospan" id="kobo.803.3">This differs from reading straight text, but this might impact the experience even if the team controls the knowledge base or databases. </span><span class="kobospan" id="kobo.803.4">Documents with tables, images, flow charts, and diagrams all contain information that might need to be fully expressed </span><span><span class="kobospan" id="kobo.804.1">in text.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.805.1">Based on the prompts Wove establishes, the model writes instructions for extracting all the data from the sheet. </span><span class="kobospan" id="kobo.805.2">This multiple-step process is examined in </span><a href="B21964_08.xhtml#_idTextAnchor172" class="pcalibre pcalibre1 calibre6"><span><em class="italic"><span class="kobospan" id="kobo.806.1">Chapter </span></em></span><span><em class="italic"><span class="kobospan" id="kobo.807.1">8</span></em></span></a><span><span class="kobospan" id="kobo.808.1">, </span></span><span><em class="italic"><span class="kobospan" id="kobo.809.1">Fine-Tuning</span></em></span><span><span class="kobospan" id="kobo.810.1">.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.811.1">In </span><em class="italic"><span class="kobospan" id="kobo.812.1">Step 1</span></em><span class="kobospan" id="kobo.813.1">, Wove runs version GPT-4 Turbo, while in other steps, it runs ChatGPT 3.5 and other models. </span><span class="kobospan" id="kobo.813.2">Running tasks sequentially is ten times faster than running GPT-4 once. </span><span class="kobospan" id="kobo.813.3">They used GPT-4 Turbo to generate fine-tuning data. </span><span class="kobospan" id="kobo.813.4">By using more than one model, they can balance performance </span><span><span class="kobospan" id="kobo.814.1">and cost.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.815.1">Wove leaves out 10 to 20% of the data to test the model. </span><span class="kobospan" id="kobo.815.2">This is standard practice. </span><span class="kobospan" id="kobo.815.3">They take out different chunks of data from documents to create a broader and likely more effective test set. </span><span class="kobospan" id="kobo.815.4">Tip: Don’t bias the model by always taking the first 20% of every document. </span><span class="kobospan" id="kobo.815.5">They use a random seed to pick pieces of documents but then maintain that same chunk each time from the same document; this allows them to create a reproducible set. </span><span class="kobospan" id="kobo.815.6">So, their validation steps do not differ because of the </span><span><span class="kobospan" id="kobo.816.1">test data.</span></span></li>
			</ol>
			<p class="calibre3"><span class="kobospan" id="kobo.817.1">All of this </span><a id="_idIndexMarker420" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.818.1">hard work is for data cleaning. </span><span class="kobospan" id="kobo.818.2">The first goal is to expose the data to those responsible for ensuring they have the correct data. </span><span class="kobospan" id="kobo.818.3">As mentioned, this will set up a later conversational experience to help find rates. </span><span class="kobospan" id="kobo.818.4">The FAQ and Wove examples should give some understanding of data issues, but there are </span><span><span class="kobospan" id="kobo.819.1">other considerations.</span></span></p>
			<h2 id="_idParaDest-140" class="calibre9"><a id="_idTextAnchor142" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.820.1">Other considerations for creating a quality data pipeline</span></h2>
			<p class="calibre3"><span class="kobospan" id="kobo.821.1">Not all designers and product managers will be involved with every step of the RAG process. </span><span class="kobospan" id="kobo.821.2">All vendors </span><a id="_idIndexMarker421" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.822.1">use the fancy term </span><strong class="bold"><span class="kobospan" id="kobo.823.1">pipeline</span></strong><span class="kobospan" id="kobo.824.1"> to represent </span><a id="_idIndexMarker422" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.825.1">this flow of information from source to customer. </span><span class="kobospan" id="kobo.825.2">Issues can occur before, during, and after models are included in the pipeline. </span><span class="kobospan" id="kobo.825.3">Keep an eye on the following areas for issues impacting </span><span><span class="kobospan" id="kobo.826.1">customer experience.</span></span></p>
			</div>
	

<div id="_idContainer086" class="calibre2">
<h3 class="calibre11"><span class="kobospan" id="kobo.827.1">Computational resources</span></h3>
			<p class="calibre3"><span class="kobospan" id="kobo.828.1">RAG has some real work to do. </span><span class="kobospan" id="kobo.828.2">It has to take an extensive collection of documents and resources </span><a id="_idIndexMarker423" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.829.1">and create vector data like the original model generation. </span><span class="kobospan" id="kobo.829.2">Doing this regularly can be computationally expensive. </span><span class="kobospan" id="kobo.829.3">Watch for any performance issues when scaling up. </span><span class="kobospan" id="kobo.829.4">Many third-party solutions will talk about millisecond response times. </span><span class="kobospan" id="kobo.829.5">That is wonderful; responses should feel natural. </span><span class="kobospan" id="kobo.829.6">It might be okay for results to take a few seconds in some instances, but nominally, a chat response should start in 200-300 ms (about 1/4 of a second).. </span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.830.1">Meanwhile, recommendations might be triggered when data changes (this can get expensive if always recalculated and no user needs to be updated) or calculated when a page is rendered. </span><span class="kobospan" id="kobo.830.2">Even a trigger to email or message someone about the recommendation requires processes to have current information and evaluate for issues on a schedule. </span><span class="kobospan" id="kobo.830.3">Each of these events will have a cost. </span><span class="kobospan" id="kobo.830.4">Consider the cost of the recommendation if no one can </span><span><span class="kobospan" id="kobo.831.1">use it.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.832.1">Issue: </span><em class="italic"><span class="kobospan" id="kobo.833.1">There is no such thing as a slow, good user experience</span></em><span class="kobospan" id="kobo.834.1">. </span><span class="kobospan" id="kobo.834.2">Designers and PMs can help performance in a </span><span><span class="kobospan" id="kobo.835.1">few places.</span></span></p>
			<ul class="calibre7">
				<li class="calibre8"><span class="kobospan" id="kobo.836.1">Monitor and </span><a id="_idIndexMarker424" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.837.1">verify a solution’s performance and decide what will meet users’ expectations. </span><span class="kobospan" id="kobo.837.2">Product owners should set </span><span><span class="kobospan" id="kobo.838.1">performance expectations.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.839.1">Monitor whether too much or too little data is sent to the LLM. </span><span class="kobospan" id="kobo.839.2">All data should provide value to the LLM; if not, </span><span><span class="kobospan" id="kobo.840.1">eliminate it.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.841.1">Determine whether the prompt and context sizes provides value for </span><span><span class="kobospan" id="kobo.842.1">its sizes.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.843.1">API requests in an LLM cost money, so optimize or cache information when possible. </span><span class="kobospan" id="kobo.843.2">Understand whether customers use recommendations or </span><span><span class="kobospan" id="kobo.844.1">visible UIs.</span></span></li>
			</ul>
			<h3 class="calibre11"><span class="kobospan" id="kobo.845.1">Scalability</span></h3>
			<p class="calibre3"><span class="kobospan" id="kobo.846.1">This can be managed if the system only deals with hundreds of documents. </span><span class="kobospan" id="kobo.846.2">Still, some large enterprises might be looking at a million documents and massive SQL databases. </span><span class="kobospan" id="kobo.846.3">Maintaining </span><a id="_idIndexMarker425" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.847.1">this large corpus and refining and improving the quality of those databases and documents can be a significant investment. </span><span class="kobospan" id="kobo.847.2">Emphasize the most helpful and frequently accessed materials. </span><span class="kobospan" id="kobo.847.3">Take advantage of third-party </span><span><span class="kobospan" id="kobo.848.1">pipeline solutions.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.849.1">Issue: </span><em class="italic"><span class="kobospan" id="kobo.850.1">You can only be in so many places simultaneously.</span></em><span class="kobospan" id="kobo.851.1"> Scalability also applies to your time. </span><span class="kobospan" id="kobo.851.2">Consider whether there are places worth your attention, like improving the management process, monitoring quality, maintaining documents, or improving the time and process it takes to edit and update documents. </span><span class="kobospan" id="kobo.851.3">Consider a personal version of the 80/20 rule. </span><span class="kobospan" id="kobo.851.4">If 20% of the time on project C returns 80% of the value, spend resources there. </span><span class="kobospan" id="kobo.851.5">Even better, use User Needs Scoring. </span><span class="kobospan" id="kobo.851.6">If something is for all customers that they use frequently, and it is a critical area, then this </span><span><span class="kobospan" id="kobo.852.1">deserves attention.</span></span></p>
			<h3 class="calibre11"><span class="kobospan" id="kobo.853.1">Training data quality</span></h3>
			<p class="calibre3"><span class="kobospan" id="kobo.854.1">Fill in </span><a id="_idIndexMarker426" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.855.1">the </span><span><span class="kobospan" id="kobo.856.1">following puzzle.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.857.1">Quality in supports </span><span><span class="kobospan" id="kobo.858.1">quality out.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.859.1">Garbage in supports </span><span><span class="kobospan" id="kobo.860.1">_______ out.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.861.1">A+ if you guessed garbage. </span><span class="kobospan" id="kobo.861.2">The quality of training materials profoundly affects the ability to fine-tune. </span><span class="kobospan" id="kobo.861.3">If content is very limited, biased, or has a lot of red herrings that could lead customers astray, then there will be ongoing issues. </span><span class="kobospan" id="kobo.861.4">The relevance and quality of content is king. </span><span class="kobospan" id="kobo.861.5">This chapter covered the importance of clean data, but that process can only have limited fixes for quality. </span><span class="kobospan" id="kobo.861.6">That is, removing redundant or conflicting data might be easy to do. </span><span class="kobospan" id="kobo.861.7">It is hard to do when writing this book. </span><span class="kobospan" id="kobo.861.8">Did the reader remember or even see something in </span><a href="B21964_01.xhtml#_idTextAnchor016" class="pcalibre pcalibre1 calibre6"><span><em class="italic"><span class="kobospan" id="kobo.862.1">Chapter 1</span></em></span></a><span class="kobospan" id="kobo.863.1">, </span><em class="italic"><span class="kobospan" id="kobo.864.1">Recognizing the Power of Design in ChatGPT</span></em><span class="kobospan" id="kobo.865.1"> that is now important in </span><a href="B21964_05_split_000.xhtml#_idTextAnchor108" class="pcalibre pcalibre1 calibre6"><span><em class="italic"><span class="kobospan" id="kobo.866.1">Chapter 5</span></em></span></a><span class="kobospan" id="kobo.867.1">, </span><em class="italic"><span class="kobospan" id="kobo.868.1">Defining the Desired Experience</span></em><span class="kobospan" id="kobo.869.1">? </span><span class="kobospan" id="kobo.869.2">Who is the content </span><a id="_idIndexMarker427" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.870.1">expert that can determine correctness? </span><span class="kobospan" id="kobo.870.2">This gets more challenging as the data grows. </span><span class="kobospan" id="kobo.870.3">Now, think about how a model can handle learning something 150 pages ago that now becomes important. </span><span class="kobospan" id="kobo.870.4">The more technical the data, the less likely an individual can know if the content is high quality. </span><span class="kobospan" id="kobo.870.5">Models can forget, too. </span><span class="kobospan" id="kobo.870.6">They are especially prone to forgetting information in the middle. </span><span class="kobospan" id="kobo.870.7">Not to mention problems understanding knowledge for specific releases or combinations of products. </span><span class="kobospan" id="kobo.870.8">Rely on content partners, authors, and technical experts. </span><span class="kobospan" id="kobo.870.9">It takes a village. </span><span class="kobospan" id="kobo.870.10">Remember that from </span><a href="B21964_01.xhtml#_idTextAnchor016" class="pcalibre pcalibre1 calibre6"><span><em class="italic"><span class="kobospan" id="kobo.871.1">Chapter 1</span></em></span></a><span class="kobospan" id="kobo.872.1">, </span><em class="italic"><span class="kobospan" id="kobo.873.1">Recognizing the Power of Design </span></em><span><em class="italic"><span class="kobospan" id="kobo.874.1">in ChatGPT</span></em></span><span><span class="kobospan" id="kobo.875.1">?</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.876.1">RAG is well suited for responding to specific questions against a wealth of content. </span><span class="kobospan" id="kobo.876.2">However, the data must be in the correct format, and this can be some heavy lifting with data at scale. </span><span class="kobospan" id="kobo.876.3">Picking suitable chunk sizes when segmenting text is more art than science. </span><span class="kobospan" id="kobo.876.4">For the CliffsNotes version (a student study guide for popular books in the US) of dealing with chunking and other lessons learned, watch the video from </span><a id="_idTextAnchor143" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.877.1">Prolego.This video will be discussed at the end of </span><span><span class="kobospan" id="kobo.878.1">this chapter.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.879.1">Video:</span><a href="https://www.youtube.com/watch?v=Y9qn4XGH1TI" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.880.1"> Prolego tips for RAG </span><span><span class="kobospan" id="kobo.881.1">development</span></span></a><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.882.1">(</span></span></span><a href="https://www.youtube.com/watch?v=Y9qn4XGH1TI" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.883.1">https://www.youtube.com/watch?v=Y9qn4XGH1TI</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.884.1">)</span></span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.885.1">Issue: </span><em class="italic"><span class="kobospan" id="kobo.886.1">Don’t let the models be overwhelmed with garbage and reduce accuracy.</span></em><span class="kobospan" id="kobo.887.1"> Monitor and set </span><span><span class="kobospan" id="kobo.888.1">improvement goals.</span></span></p>
			<h3 class="calibre11"><span class="kobospan" id="kobo.889.1">Domain specificity</span></h3>
			<p class="calibre3"><span class="kobospan" id="kobo.890.1">Enterprise </span><a id="_idIndexMarker428" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.891.1">models rely on </span><span><span class="kobospan" id="kobo.892.1">domain-specific content.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.893.1">Issue: </span><em class="italic"><span class="kobospan" id="kobo.894.1">Gathering and annotating data to improve performance is expensive. </span></em><span class="kobospan" id="kobo.895.1">Annotation can take many forms, but as with data quality, find experts inside or outside your company to take this to the next level. </span><span class="kobospan" id="kobo.895.2">Invest in building </span><span><span class="kobospan" id="kobo.896.1">personal expertise.</span></span></p>
			<h3 class="calibre11"><span class="kobospan" id="kobo.897.1">Response consistency and coherence</span></h3>
			<p class="calibre3"><span class="kobospan" id="kobo.898.1">RAG </span><a id="_idIndexMarker429" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.899.1">solutions will be challenging. </span><span class="kobospan" id="kobo.899.2">Enterprise solutions value deterministic answers, which will not happen with only a generative solution. </span><span class="kobospan" id="kobo.899.3">Answers will vary, even when asked the same question. </span><span class="kobospan" id="kobo.899.4">This can be improved with prompt engineering, fine-tuning, and the careful use of the generative models in a larger ecosystem </span><span><span class="kobospan" id="kobo.900.1">of products.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.901.1">Issue: </span><em class="italic"><span class="kobospan" id="kobo.902.1">Don’t throw the baby out with the bathwater.</span></em><span class="kobospan" id="kobo.903.1"> With existing chatbots that provide </span><a id="_idIndexMarker430" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.904.1">repeatable solutions, supplement them with a generative solution. </span><span class="kobospan" id="kobo.904.2">Focus fine-tuning on consistency. </span><span class="kobospan" id="kobo.904.3">For recommendation engines, look for the places with the most value to add by </span><span><span class="kobospan" id="kobo.905.1">incremental improvements.</span></span></p>
			<h3 class="calibre11"><span class="kobospan" id="kobo.906.1">Privacy, security, and data residency</span></h3>
			<p class="calibre3"><span class="kobospan" id="kobo.907.1">Because the data is proprietary and is contained in company databases, knowledge base, and APIs, its access can be </span><a id="_idIndexMarker431" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.908.1">managed when responding to customer questions. </span><span class="kobospan" id="kobo.908.2">Since a ChatGPT response will be based on the context passed to it from a </span><a id="_idIndexMarker432" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.909.1">RAG solution, it makes sense to make sure privacy and security policies limit the visibility of this data to the appropriate customers. </span><span class="kobospan" id="kobo.909.2">Be on the front line to monitor for issues that appear during a chat or come in via customer feedback. </span><span class="kobospan" id="kobo.909.3">One area where designers can add value to the privacy discussion is related to the data seen during </span><span><span class="kobospan" id="kobo.910.1">reviewing interactions.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.911.1">Besides ensuring that data from backends doesn’t get into the wrong conversations, there are </span><a id="_idIndexMarker433" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.912.1">times when masking </span><strong class="bold"><span class="kobospan" id="kobo.913.1">Personally Identifiable Information</span></strong><span class="kobospan" id="kobo.914.1"> (</span><strong class="bold"><span class="kobospan" id="kobo.915.1">PII</span></strong><span class="kobospan" id="kobo.916.1">) is necessary. </span><span class="kobospan" id="kobo.916.2">In </span><a href="B21964_02_split_000.xhtml#_idTextAnchor031" class="pcalibre pcalibre1 calibre6"><span><em class="italic"><span class="kobospan" id="kobo.917.1">Chapter 2</span></em></span></a><span class="kobospan" id="kobo.918.1">, </span><em class="italic"><span class="kobospan" id="kobo.919.1">Conducting Effective</span></em> <em class="italic"><span class="kobospan" id="kobo.920.1">User Research</span></em><span class="kobospan" id="kobo.921.1">, ways to mask PII were discussed. </span><span class="kobospan" id="kobo.921.2">This is a consideration when training models. </span><span class="kobospan" id="kobo.921.3">Training data can contain PII. </span><span class="kobospan" id="kobo.921.4">One approach is not to mask it (replacing the text with ****), as that would hinder the model’s comprehension, but to </span><em class="italic"><span class="kobospan" id="kobo.922.1">transform</span></em><span class="kobospan" id="kobo.923.1"> the data into fake data generated by the model itself. </span><span class="kobospan" id="kobo.923.2">For example, instruct a model during a data cleaning step to replace customer names with customer names it makes up. </span><span class="kobospan" id="kobo.923.3">It is good at this, and this fake data, called </span><strong class="bold"><span class="kobospan" id="kobo.924.1">synthetic data,</span></strong><span class="kobospan" id="kobo.925.1"> can replace </span><span><span class="kobospan" id="kobo.926.1">actual data.</span></span></p>
			<pre class="source-code"><span class="kobospan1" id="kobo.927.1">
Give me a list of 5 customer names from various countries, ages, the typical amount they spend on car-sharing services, a column with a 9-digit number in the format 22-333-444, a fake cell phone number, and their favorite form of payment in a table.</span></pre>			<p class="calibre3"><span class="kobospan" id="kobo.928.1">ChatGPT is very good at this. </span><span class="kobospan" id="kobo.928.2">Even ChatGPT will reject providing fake Social Security numbers, so notice how the prompt asked for a nine-digit number in the prompt. </span><span class="kobospan" id="kobo.928.3">It responded with the results in </span><span><em class="italic"><span class="kobospan" id="kobo.929.1">Table 6.4</span></em></span><span><span class="kobospan" id="kobo.930.1">.</span></span></p>
			<table id="table002-5" class="no-table-style">
				<colgroup class="calibre15">
					<col class="calibre16"/>
					<col class="calibre16"/>
					<col class="calibre16"/>
					<col class="calibre16"/>
					<col class="calibre16"/>
					<col class="calibre16"/>
					<col class="calibre16"/>
				</colgroup>
				<thead class="calibre18">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.931.1">Customer </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.932.1">Name</span></strong></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.933.1">Country</span></strong></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.934.1">Age</span></strong></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.935.1">Car </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.936.1">Sharing (Monthly)</span></strong></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.937.1">Identifier </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.938.1">Number</span></strong></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.939.1">Cell </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.940.1">Phone Number</span></strong></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.941.1">Favorite </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.942.1">Payment Method</span></strong></span></p>
						</td>
					</tr>
				</thead>
				<tbody class="calibre17">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.943.1">Emma Smith</span></strong></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span><span class="kobospan" id="kobo.944.1">USA</span></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span><span class="kobospan" id="kobo.945.1">29</span></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span class="kobospan" id="kobo.946.1">$</span><span><span class="kobospan" id="kobo.947.1">150</span></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span><span class="kobospan" id="kobo.948.1">22-333-444</span></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span class="kobospan" id="kobo.949.1">(</span><span><span class="kobospan" id="kobo.950.1">555) 123-4567</span></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span><span class="kobospan" id="kobo.951.1">Credit Card</span></span></p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.952.1">Hiroshi Tanaka</span></strong></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span><span class="kobospan" id="kobo.953.1">Japan</span></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span><span class="kobospan" id="kobo.954.1">35</span></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span class="kobospan" id="kobo.955.1">¥</span><span><span class="kobospan" id="kobo.956.1">18,000</span></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span><span class="kobospan" id="kobo.957.1">22-333-445</span></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span><span class="kobospan" id="kobo.958.1">090-1234-5678</span></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span><span class="kobospan" id="kobo.959.1">Mobile Payment</span></span></p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.960.1">Maria Garcia</span></strong></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span><span class="kobospan" id="kobo.961.1">Spain</span></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span><span class="kobospan" id="kobo.962.1">41</span></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span class="kobospan" id="kobo.963.1">€</span><span><span class="kobospan" id="kobo.964.1">120</span></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span><span class="kobospan" id="kobo.965.1">22-333-446</span></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span><span class="kobospan" id="kobo.966.1">612-345-678</span></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span><span class="kobospan" id="kobo.967.1">Debit Card</span></span></p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.968.1">David Osei</span></strong></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span><span class="kobospan" id="kobo.969.1">Ghana</span></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span><span class="kobospan" id="kobo.970.1">26</span></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span><span class="kobospan" id="kobo.971.1">GHS 600</span></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span><span class="kobospan" id="kobo.972.1">22-333-447</span></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span><span class="kobospan" id="kobo.973.1">024-123-4567</span></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span><span class="kobospan" id="kobo.974.1">Mobile Money</span></span></p>
						</td>
					</tr>
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.975.1">Anna Müller</span></strong></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span><span class="kobospan" id="kobo.976.1">Germany</span></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span><span class="kobospan" id="kobo.977.1">32</span></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span class="kobospan" id="kobo.978.1">€</span><span><span class="kobospan" id="kobo.979.1">140</span></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span><span class="kobospan" id="kobo.980.1">22-333-448</span></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span><span class="kobospan" id="kobo.981.1">0151-1234567</span></span></p>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span><span class="kobospan" id="kobo.982.1">PayPal</span></span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.983.1">Table 6.4 – Example of using synthetic data to replace PII</span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.984.1">Notice how the names feel localized; the counties were varied, local currency and reasonable amounts were used, and the phone numbers were localized. </span><em class="italic"><span class="kobospan" id="kobo.985.1">Mobile Money</span></em><span class="kobospan" id="kobo.986.1"> is not a term I recognize, but it is common in Ghana. </span><span class="kobospan" id="kobo.986.2">Mobile Money means payments made via mobile phone providers. </span><span class="kobospan" id="kobo.986.3">So, it is even possible to learn something from synthetic data. </span><span class="kobospan" id="kobo.986.4">Since the subject of other countries came up, there are other </span><span><span class="kobospan" id="kobo.987.1">country-specific issues.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.988.1">There are two </span><a id="_idIndexMarker434" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.989.1">considerations when discussing country-specific limitations that might limit model enrichment. </span><span class="kobospan" id="kobo.989.2">Generally, this will fall to the product manager. </span><span class="kobospan" id="kobo.989.3">The first is whether there </span><a id="_idIndexMarker435" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.990.1">are export limitations for company data. </span><span class="kobospan" id="kobo.990.2">Some countries restrict the export of customer or employee data across borders. </span><span class="kobospan" id="kobo.990.3">They have </span><a id="_idIndexMarker436" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.991.1">data residency requirements to house data in-country. </span><span class="kobospan" id="kobo.991.2">This is why many vendors provide data centers in some regions. </span><span class="kobospan" id="kobo.991.3">The </span><strong class="bold"><span class="kobospan" id="kobo.992.1">General Data Protection Regulation</span></strong><span class="kobospan" id="kobo.993.1"> (</span><strong class="bold"><span class="kobospan" id="kobo.994.1">GDPR</span></strong><span class="kobospan" id="kobo.995.1">) in the European Union and the Privacy Shield </span><a id="_idIndexMarker437" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.996.1">framework come to mind. </span><span class="kobospan" id="kobo.996.2">When dealing with personal information that might be common in a human resource chat application, for example, safeguards might be required to be in place, and consent might be needed. </span><span class="kobospan" id="kobo.996.3">This can impact the user experience. </span><span class="kobospan" id="kobo.996.4">I have had to design examples where user permissions are required or policy requirements on what can or should not be shared need to be consented to </span><span><span class="kobospan" id="kobo.997.1">before proceeding.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.998.1">The second issue is more data-centric and not subject to data residency issues. </span><span class="kobospan" id="kobo.998.2">Processing rules might only apply to certain countries or groups within a country. </span><span class="kobospan" id="kobo.998.3">It could be a data issue to ensure that the LLM knows that this person is from a particular country, and thus, specific documents, policies, or APIs apply. </span><span class="kobospan" id="kobo.998.4">For example, expense reimbursement policies vary per country. </span><span class="kobospan" id="kobo.998.5">It is one thing for an American to have dinner on a trip to France and be reimbursed when they return to the US (US policy applies) versus someone from </span><a id="_idIndexMarker438" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.999.1">France going somewhere outside the European Union (EU/French policy). </span><span class="kobospan" id="kobo.999.2">Designers and PMs must recognize the necessary attributes to </span><a id="_idIndexMarker439" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.1000.1">filter and support the correct data and resources. </span><span class="kobospan" id="kobo.1000.2">This is not unique to LLMs. </span><span class="kobospan" id="kobo.1000.3">It must be handled in these cases, such as in a GUI or an existing </span><a id="_idIndexMarker440" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.1001.1">chatbot. </span><span class="kobospan" id="kobo.1001.2">Another version of the rules is how to communicate with our audience. </span><span class="kobospan" id="kobo.1001.3">Sometimes, biases in the data or even ethical concerns need to </span><span><span class="kobospan" id="kobo.1002.1">be addressed.</span></span></p>
			<h3 class="calibre11"><span class="kobospan" id="kobo.1003.1">Bias and ethical concerns</span></h3>
			<p class="calibre3"><span class="kobospan" id="kobo.1004.1">It might be reasonable to think that enterprise data doesn’t have bias, but still watch out for it. </span><span class="kobospan" id="kobo.1004.2">There </span><a id="_idIndexMarker441" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.1005.1">could be tongue-in-cheek content in </span><a id="_idIndexMarker442" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.1006.1">the knowledge base, but it gets regurgitated as truth. </span><span class="kobospan" id="kobo.1006.2">It could cause issues in the results. </span><span class="kobospan" id="kobo.1006.3">Take a look at </span><span><em class="italic"><span class="kobospan" id="kobo.1007.1">Figure 6</span></em></span><em class="italic"><span class="kobospan" id="kobo.1008.1">.13</span></em><span class="kobospan" id="kobo.1009.1">. </span><span class="kobospan" id="kobo.1009.2">It is a simple interaction that it should be easy to discern facts. </span><span class="kobospan" id="kobo.1009.3">It is fair to point out that this was </span><em class="italic"><span class="kobospan" id="kobo.1010.1">not</span></em><span class="kobospan" id="kobo.1011.1"> ChatGPT. </span><span class="kobospan" id="kobo.1011.2">This is a continuation of our Cohere example. </span><span class="kobospan" id="kobo.1011.3">Remember, the example from earlier extended a basic LLM to include the FAQs. </span><span class="kobospan" id="kobo.1011.4">Unless it is told otherwise and guardrails are put in place, it will still attempt to answer general model questions. </span><span class="kobospan" id="kobo.1011.5">It did not go as planned. </span><span class="kobospan" id="kobo.1011.6">As these models are expected to improve quickly, it is not fair to comment on this model’s shortcomings. </span><span class="kobospan" id="kobo.1011.7">All models have shortcomings. </span><span class="kobospan" id="kobo.1011.8">It is used to make a point about </span><span><span class="kobospan" id="kobo.1012.1">all models.</span></span></p>
			<div class="calibre2">
				<div id="_idContainer082" class="img---figure">
					<span class="kobospan" id="kobo.1013.1"><img src="image/B21964_06_13.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.1014.1">Figure 6.13 – Conversational hallucinations can create bias and errors</span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.1015.1">Issue: </span><em class="italic"><span class="kobospan" id="kobo.1016.1">Don’t get caught making (wrong) ethical decisions</span></em><span class="kobospan" id="kobo.1017.1">. </span><span class="kobospan" id="kobo.1017.2">Avoid these discussions when possible. </span><span class="kobospan" id="kobo.1017.3">Watch </span><a id="_idIndexMarker443" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.1018.1">data collection, model training, and </span><a id="_idIndexMarker444" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.1019.1">the monitoring process for potential issues. </span><span class="kobospan" id="kobo.1019.2">Let’s break down this collection of issues. </span><span class="kobospan" id="kobo.1019.3">Hank Greenberg (who is Jewish) and Hank Aaron (who was not) got confused somehow. </span><span class="kobospan" id="kobo.1019.4">Maybe this is a hallucination. </span><span class="kobospan" id="kobo.1019.5">But simple questions such as this would be easy to answer. </span><span class="kobospan" id="kobo.1019.6">Let me point out a </span><span><span class="kobospan" id="kobo.1020.1">few problems.</span></span></p>
			<ul class="calibre7">
				<li class="calibre8"><span class="kobospan" id="kobo.1021.1">It didn’t get Hank Aaron (presumably because of my spelling error) even when the model corrected my mistake and returned it </span><span><span class="kobospan" id="kobo.1022.1">spelled correctly.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.1023.1">Hank Aaron was </span><span><span class="kobospan" id="kobo.1024.1">not Jewish.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.1025.1">His career lasted 23 years, </span><span><span class="kobospan" id="kobo.1026.1">not 24.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.1027.1">He never had close to 209 home runs per season (he had 755 in his entire 23-year career; I know because I watched him tie </span><span><span class="kobospan" id="kobo.1028.1">the record).</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.1029.1">Jackie Robinson was the first African-American inducted into the Hall of Fame in 1962. </span><span class="kobospan" id="kobo.1029.2">Hank Aaron’s induction was </span><em class="italic"><span class="kobospan" id="kobo.1030.1">20</span></em> <span><span class="kobospan" id="kobo.1031.1">years later.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.1032.1">Hank Greenberg was well known to be Jewish and </span><span><span class="kobospan" id="kobo.1033.1">faced discrimination.</span></span></li>
			</ul>
			<p class="calibre3"><span class="kobospan" id="kobo.1034.1">We tried this with ChatGPT. </span><span class="kobospan" id="kobo.1034.2">It did assume Hank Aaron even when his name was misspelled. </span><span class="kobospan" id="kobo.1034.3">It accurately explained </span><a id="_idIndexMarker445" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.1035.1">he was not Jewish, played for 23 years, knew his 755 </span><a id="_idIndexMarker446" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.1036.1">home runs record, and his place in the Baseball Hall of Fame. </span><span class="kobospan" id="kobo.1036.2">The ChatGPT 3.5 model was factually correct. </span><span class="kobospan" id="kobo.1036.3">And to be fair, </span><em class="italic"><span class="kobospan" id="kobo.1037.1">a newer update to Cohere got all of </span></em><span><em class="italic"><span class="kobospan" id="kobo.1038.1">this correct</span></em></span><span><span class="kobospan" id="kobo.1039.1">.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.1040.1">Enterprise data is not expected to talk about the religion of famous baseball players. </span><span class="kobospan" id="kobo.1040.2">Just recognize that answers for well-known facts can still contain hallucinations, lies, or whatever they should be called, and the organization will likely be liable for spreading disinformation. </span><span class="kobospan" id="kobo.1040.3">It doesn’t mean a lawsuit. </span><span class="kobospan" id="kobo.1040.4">It could mean not meeting a service-level agreement, upsetting or losing a potential customer, or having to compensate the customer. </span><span class="kobospan" id="kobo.1040.5">This is not unlike what would happen if a human agent provided incorrect information. </span><span class="kobospan" id="kobo.1040.6">There can be downstream costs or service interruptions due to wrong answers. </span><span class="kobospan" id="kobo.1040.7">With AI, we have seen numerous mistakes, errors, or maybe a lack of training, </span><span><span class="kobospan" id="kobo.1041.1">causing issues.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.1042.1">Semi-autonomous cars causing accidents in the automotive industry come to mind. </span><span class="kobospan" id="kobo.1042.2">This isn’t to say that human drivers are better (they are not by almost an order of magnitude). </span><span class="kobospan" id="kobo.1042.3">Still, the kinds of accidents caused by training model issues sometimes seem obvious and avoidable by a human driver (being able to identify an 18-wheeler truck crossing the road in a high-glare situation). </span><span class="kobospan" id="kobo.1042.4">At the same time, there are far more cases </span><em class="italic"><span class="kobospan" id="kobo.1043.1">not</span></em><span class="kobospan" id="kobo.1044.1"> seen in the news, such as semi-autonomous cars </span><em class="italic"><span class="kobospan" id="kobo.1045.1">not</span></em><span class="kobospan" id="kobo.1046.1"> getting into accidents where a human’s response time and visibility would have resulted in tragedy. </span><span class="kobospan" id="kobo.1046.2">Ultimately, expect generative AI to be more reliable, consistent, and accurate than humans. </span><span class="kobospan" id="kobo.1046.3">It should get there in a few years with significant effort. </span><span class="kobospan" id="kobo.1046.4">Always be aware that bias and ethics come into play within a model. </span><span class="kobospan" id="kobo.1046.5">In addition, be ethical in how much effort is expended to build and </span><span><span class="kobospan" id="kobo.1047.1">test models.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.1048.1">There will be a benefit/risk analysis; just don’t get caught on the wrong side, as Ford did when it refused to fix defective gas tanks in its </span><span><span class="kobospan" id="kobo.1049.1">Pinto model.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.1050.1">Wikipedia: </span><a href="https://en.wikibooks.org/wiki/Professionalism/The_Ford_Pinto_Gas_Tank_Controversy" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.1051.1">Ford Pinto Gas Tank </span><span><span class="kobospan" id="kobo.1052.1">Controversy</span></span></a><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.1053.1">(</span></span></span><a href="https://en.wikibooks.org/wiki/Professionalism/The_Ford_Pinto_Gas_Tank_Controversy" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.1054.1">https://en.wikibooks.org/wiki/Professionalism/The_Ford_Pinto_Gas_Tank_Controversy</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.1055.1">)</span></span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.1056.1">One has to invest in creating good models. </span><span class="kobospan" id="kobo.1056.2">There will be lawsuits related to this as well. </span><span class="kobospan" id="kobo.1056.3">Take the time and energy to put quality first. </span><span class="kobospan" id="kobo.1056.4">Document your sources; in legal terms, this is called the chain of custody. </span><span class="kobospan" id="kobo.1056.5">Check the work and refine and resolve problems with </span><a id="_idIndexMarker447" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.1057.1">a cadence that befits the risks understood by the enterprise</span><a id="_idIndexMarker448" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.1058.1">. </span><span class="kobospan" id="kobo.1058.2">It won’t be perfect – nor are human agents. </span><span class="kobospan" id="kobo.1058.3">Just put a process in place for constant improvement. </span><span class="kobospan" id="kobo.1058.4">The Silicon Valley mantra about “move fast and break things” sounds great at a start-up, but when delivering a paid service to high-valued customers, maybe be more pragmatic about investing </span><span><span class="kobospan" id="kobo.1059.1">in quality.</span></span></p>
			<h3 class="calibre11"><span class="kobospan" id="kobo.1060.1">Embedding other techniques</span></h3>
			<p class="calibre3"><span class="kobospan" id="kobo.1061.1">If you watched the OpenAI discussion on techniques mentioned at the beginning of the chapter </span><a id="_idIndexMarker449" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.1062.1">to learn about a few additional methods, the video discusses optimization techniques at the 15-minute mark. </span><span class="kobospan" id="kobo.1062.2">This approach to benchmarking quality and applying tools and techniques is right. </span><span class="kobospan" id="kobo.1062.3">This was done for a typical ChatGPT solution that involves </span><a id="_idIndexMarker450" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.1063.1">searching a knowledge base. </span><span class="kobospan" id="kobo.1063.2">They tried a few methods that did not work to get the improvements they expected (</span><strong class="bold"><span class="kobospan" id="kobo.1064.1">Hypothetical Document Embedding</span></strong><span class="kobospan" id="kobo.1065.1"> (</span><strong class="bold"><span class="kobospan" id="kobo.1066.1">HyDE</span></strong><span class="kobospan" id="kobo.1067.1">) retrieval and fine-tuning embedding). </span><span class="kobospan" id="kobo.1067.2">They found some worthy investments (chunk/embedding reranking, classification, prompt engineering, and query expansion). </span><span class="kobospan" id="kobo.1067.3">It would be way over our heads exploring how to do these. </span><span class="kobospan" id="kobo.1067.4">The key is for designers and PMs to work with the team to establish a benchmark, find good data to train the model, and test and verify results as they are iterated. </span><span class="kobospan" id="kobo.1067.5">Consider the goal so it is known when the goal is reached. </span><span class="kobospan" id="kobo.1067.6">Recognize that as models change and data grows, adapt. </span><span class="kobospan" id="kobo.1067.7">In reality, a team won’t ever be done, but with a quality bar, the organization can allocate resources </span><span><span class="kobospan" id="kobo.1068.1">more wisely.</span></span></p>
			<h3 class="calibre11"><span class="kobospan" id="kobo.1069.1">Evaluation metrics</span></h3>
			<p class="calibre3"><a href="B21964_10_split_000.xhtml#_idTextAnchor216" class="pcalibre pcalibre1 calibre6"><span><em class="italic"><span class="kobospan" id="kobo.1070.1">Chapter 10</span></em></span></a><span class="kobospan" id="kobo.1071.1">, </span><em class="italic"><span class="kobospan" id="kobo.1072.1">Monitoring and Evaluation</span></em><span class="kobospan" id="kobo.1073.1">, will </span><a id="_idIndexMarker451" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.1074.1">cover methods for determining performance. </span><span class="kobospan" id="kobo.1074.2">Relevance, diversity, and coherence are all crucial factors for our datasets. </span><span class="kobospan" id="kobo.1074.3">The focus will be to understand this from the user’s perspective with accuracy and </span><span><span class="kobospan" id="kobo.1075.1">customer feedback.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.1076.1">Despite these limitations, RAG holds promise for enhancing the capabilities of conversational AI systems such as ChatGPT by enabling more contextually relevant and informative </span><a id="_idIndexMarker452" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.1077.1">responses to user queries. </span><span class="kobospan" id="kobo.1077.2">Addressing the challenges above through ongoing research and development efforts can help unlock RAG’s full potential to improve user engagement and satisfaction in conversational </span><span><span class="kobospan" id="kobo.1078.1">AI applications.</span></span></p>
			<h2 id="_idParaDest-141" class="calibre9"><a id="_idTextAnchor144" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.1079.1">Resources for RAG</span></h2>
			<p class="calibre3"><span class="kobospan" id="kobo.1080.1">A good RAG solution will use a service dedicated to managing the influx of data, processing it, storing it, and retrieving it to share with the LLM. </span><span class="kobospan" id="kobo.1080.2">There has been so much movement in </span><a id="_idIndexMarker453" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.1081.1">this space since RAG was invented, and it is hard to realize how quickly this has </span><span><span class="kobospan" id="kobo.1082.1">become real.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.1083.1">Because most of the design work is in data quality rather than technology, it will be best to provide resources for those who want to explore the more technical pieces of the puzzle. </span><span class="kobospan" id="kobo.1083.2">The OpenAI resource is the best place to start; it will evolve and adapt as technology changes. </span><span class="kobospan" id="kobo.1083.3">GPT-4 and newer work directly </span><span><span class="kobospan" id="kobo.1084.1">with RAG.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.1085.1">Web article: </span><a href="https://thenewstack.io/openai-rag-vs-your-customized-rag-which-one-is-better" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.1086.1">OpenAI RAG vs. </span><span class="kobospan" id="kobo.1086.2">Customized RAG with </span><span><span class="kobospan" id="kobo.1087.1">Milvus</span></span></a><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.1088.1">(</span></span></span><a href="https://thenewstack.io/openai-rag-vs-your-customized-rag-which-one-is-better" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.1089.1">https://thenewstack.io/openai-rag-vs-your-customized-rag-which-one-is-better</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.1090.1">)</span></span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.1091.1">Do not assume linking to these resources implies they are best in class. </span><span class="kobospan" id="kobo.1091.2">They are all improving rapidly, will diverge in value, and some will disappear. </span><span class="kobospan" id="kobo.1091.3">As the market evolves, look for tools that can automate the pipeline with high quality. </span><span class="kobospan" id="kobo.1091.4">Access to a database is the most prominent tool needed in the enterprise after </span><span><span class="kobospan" id="kobo.1092.1">knowledge access.</span></span></p>
			<h3 class="calibre11"><span class="kobospan" id="kobo.1093.1">Databases and SQL</span></h3>
			<p class="calibre3"><span class="kobospan" id="kobo.1094.1">Database retrieval </span><a id="_idIndexMarker454" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.1095.1">presents challenges. </span><span class="kobospan" id="kobo.1095.2">Consider </span><a id="_idIndexMarker455" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.1096.1">how the database thinks about its content and how to ask for results. </span><span class="kobospan" id="kobo.1096.2">This is typically expressed in SQL, the structured query language of most databases. </span><span class="kobospan" id="kobo.1096.3">Some databases do not use SQL and are called NoSQL databases. </span><span class="kobospan" id="kobo.1096.4">Since most enterprise data to inject into tasks and prompts is held in SQL databases, we will focus on a SQL example. </span><span class="kobospan" id="kobo.1096.5">LLMs have some ability to write SQL, but it is still an evolving area.  </span><span class="kobospan" id="kobo.1096.6">Here is an example highlighting the complexities of working with </span><span><span class="kobospan" id="kobo.1097.1">a database.</span></span></p>
			<pre class="source-code"><span class="kobospan1" id="kobo.1098.1">
Show me jobs near Burlingame</span></pre>			<p class="calibre3"><span class="kobospan" id="kobo.1099.1">It might already be obvious there are a few issues </span><span><span class="kobospan" id="kobo.1100.1">to address:</span></span></p>
			<ol class="calibre12">
				<li class="calibre8"><span class="kobospan" id="kobo.1101.1">Which Burlingame (the one near me in the San Francisco Bay Area, San Diego, Kansas, </span><span><span class="kobospan" id="kobo.1102.1">Oregon, etc.…)?</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.1103.1">What kinds of jobs? </span><span class="kobospan" id="kobo.1103.2">Does it have context for what </span><span><span class="kobospan" id="kobo.1104.1">is needed?</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.1105.1">Are more filters for price, types of companies, and working </span><span><span class="kobospan" id="kobo.1106.1">hours needed?</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.1107.1">Focusing on the first step, drilling down into understanding the first statement. </span><span class="kobospan" id="kobo.1107.2">What does near mean? </span><span class="kobospan" id="kobo.1107.3">In the San Francisco Bay Area, 10 miles is reasonable, while in Oregon, 25 miles is reasonable. </span><span class="kobospan" id="kobo.1107.4">If this were New York City and you wanted a pizza place, two blocks would be </span><span><span class="kobospan" id="kobo.1108.1">too far.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.1109.1">How does one translate this into cities that are in </span><span><span class="kobospan" id="kobo.1110.1">my database?</span></span></li>
			</ol>
			<p class="calibre3"><span class="kobospan" id="kobo.1111.1">My point is that </span><a id="_idIndexMarker456" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.1112.1">it is more complicated than extracting an entity like the name of a city and expecting, even with SQL magic, to be able to scope good content. </span><span class="kobospan" id="kobo.1112.2">This request needs to be pre-processed</span><a id="_idIndexMarker457" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.1113.1"> to generate a reasonable SQL statement. </span><span class="kobospan" id="kobo.1113.2">So, manage the input to expect a sensible output. </span><span class="kobospan" id="kobo.1113.3">In real estate property management, there is a saying: </span><em class="italic"><span class="kobospan" id="kobo.1114.1">inspect what you expect</span></em><span class="kobospan" id="kobo.1115.1">. </span><span class="kobospan" id="kobo.1115.2">The same here. </span><span class="kobospan" id="kobo.1115.3">The input must be checked and broken up into pieces that need to be analyzed and expanded with more details to get the expected output. </span><span class="kobospan" id="kobo.1115.4">With the output, it might be possible to send a collection of results to the LLM, like sending documents or FAQs, so that ChatGPT can use this information to form a more refined answer. </span><span class="kobospan" id="kobo.1115.5">The LLM has to know about the schema to format a </span><span><span class="kobospan" id="kobo.1116.1">good query.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.1117.1">Another approach I have worked on and that is becoming popular is text-to-SQL. </span><span class="kobospan" id="kobo.1117.2">This is a way to apply LLM intelligence to create a logical SQL statement that returns effective results. </span><span class="kobospan" id="kobo.1117.3">This approach has merit but depends on whether SQL can support the query. </span><span class="kobospan" id="kobo.1117.4">In the preceding example, the solution would need a city or location discovery tool based on a range or distance from a center point (and center points can be wildly inaccurate regarding where the person is located and where to go). </span><span class="kobospan" id="kobo.1117.5">A basic LLM would have to understand the related cities correctly. </span><span class="kobospan" id="kobo.1117.6">These tools are available and must be integrated to generate the correct list of towns and locations to pass into SQL. </span><span class="kobospan" id="kobo.1117.7">An LLM can also get this information and form the </span><span><span class="kobospan" id="kobo.1118.1">SQL queries.</span></span></p>
			<pre class="source-code-right"><span class="kobospan1" id="kobo.1119.1">What cities are within5 miles of Hillsborough, CA,provide only the list
Within a 5-mile radius of Hillsborough,
CA, some nearby cities include:
1. </span><span class="kobospan1" id="kobo.1119.2">Burlingame, CA
2. </span><span class="kobospan1" id="kobo.1119.3">San Mateo, CA
3. </span><span class="kobospan1" id="kobo.1119.4">Millbrae, CA</span></pre>			<p class="calibre3"><span class="kobospan" id="kobo.1120.1">Foster City, CA, which is 3 miles away, was included the first time the question was asked, but Belmont, CA, or San Bruno, CA, were never included. </span><span class="kobospan" id="kobo.1120.2">So, if this customer were looking for a job, they would miss many opportunities. </span><span class="kobospan" id="kobo.1120.3">This specific issue could be </span><a id="_idIndexMarker458" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.1121.1">fixed with adjustments to the prompt focusing on </span><a id="_idIndexMarker459" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.1122.1">the exact cities and asking to check its work. </span><span class="kobospan" id="kobo.1122.2">For example, the results can be seen with a simple adjustment </span><span><span class="kobospan" id="kobo.1123.1">and follow-up.</span></span></p>
			<pre class="source-code-right"><span class="kobospan1" id="kobo.1124.1">Can you show these with thedistances used and includethe next 3 closest cities
To provide more accurate information, I'll
calculate the distances between Hillsborough,
CA, and nearby cities using their geographic
coordinates. </span><span class="kobospan1" id="kobo.1124.2">Here are the distances along with
the seven closest cities:
Burlingame, CA - Approximately 1.9 miles away
San Mateo, CA - Approximately 3.2 miles away
Millbrae, CA - Approximately 3.5 miles away
Foster City, CA - Approximately 4.3 miles away
Belmont, CA - Approximately 4.6 miles away
South San Francisco, CA - Approximately 4.8 miles away
San Carlos, CA - Approximately 5.1 miles away
Please note that these distances are
approximate and may vary slightly
depending on the specific locations
within each city.</span></pre>			<p class="calibre3"><span class="kobospan" id="kobo.1125.1">When asked later how close South San Francisco was to Hillsborough, it correctly answered 10 miles—much different than its first answer. </span><em class="italic"><span class="kobospan" id="kobo.1126.1">Rely on a well-known API to get this data rather than constantly dealing with the variability of an LLM</span></em><span class="kobospan" id="kobo.1127.1">. </span><span class="kobospan" id="kobo.1127.2">API resources provide more accurate and reliable data when specific details are required. </span><span class="kobospan" id="kobo.1127.3">Consider incorporating these into LLM responses to provide natural interaction. </span><span class="kobospan" id="kobo.1127.4">An enterprise is rich with databases containing collections of facts. </span><span class="kobospan" id="kobo.1127.5">Use this as a competitive advantage. </span><span class="kobospan" id="kobo.1127.6">Don’t expect the LLM to do it all by generating results. </span><span class="kobospan" id="kobo.1127.7">This is why function calling exists – to get the value of specific data in </span><span><span class="kobospan" id="kobo.1128.1">generative output.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.1129.1">Prompt engineering can also help improve the results. </span><span class="kobospan" id="kobo.1129.2">But the point should be clear—SQL needs some hand-holding to create effective queries and some pre-processing to give the database a good chance at returning </span><span><span class="kobospan" id="kobo.1130.1">effective results.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.1131.1">Online suggestions for connecting to databases focus primarily on </span><a id="_idIndexMarker460" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.1132.1">straightforward queries that don’t explore how the </span><a id="_idIndexMarker461" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.1133.1">user will ask the questions. </span><span class="kobospan" id="kobo.1133.2">This is a more complex problem than just connecting to </span><span><span class="kobospan" id="kobo.1134.1">a database.</span></span></p>
			<p class="callout-heading"><span class="kobospan" id="kobo.1135.1">Extra credit reading on database</span></p>
			<p class="callout"><span class="kobospan" id="kobo.1136.1">If database connectivity is new for you, read </span><span><span class="kobospan" id="kobo.1137.1">these references</span></span></p>
			<p class="callout"><span class="kobospan" id="kobo.1138.1">Article: </span><a href="https://medium.com/@shivansh.kaushik/talk-to-your-database-using-rag-and-llms-42eb852d2a3c" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.1139.1">Talk to your</span></a><span> </span><span class="kobospan" id="kobo.1140.1">Database using RAG and </span><span><span class="kobospan" id="kobo.1141.1">LLMS</span></span><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.1142.1">(</span></span></span><a href="https://medium.com/@shivansh.kaushik/talk-to-your-database-using-rag-and-llms-42eb852d2a3c" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.1143.1">https://medium.com/@shivansh.kaushik/talk-to-your-database-using-rag-and-llms-42eb852d2a3c</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.1144.1">)</span></span></span></p>
			<p class="callout"><span class="kobospan" id="kobo.1145.1">Article: </span><a href="https://medium.com/dataherald/how-to-connect-llm-to-sql-database-with-llamaindex-fae0e54de97c" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.1146.1">How to connect LLM to SQL database with </span><span><span class="kobospan" id="kobo.1147.1">LlamaIndex</span></span></a><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.1148.1">(</span></span></span><a href="https://medium.com/dataherald/how-to-connect-llm-to-sql-database-with-llamaindex-fae0e54de97c" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.1149.1">https://medium.com/dataherald/how-to-connect-llm-to-sql-database-with-llamaindex-fae0e54de97c</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.1150.1">)</span></span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.1151.1">We will explore one example with the Oracle Digital Assistant. </span><span class="kobospan" id="kobo.1151.2">This area will see significant improvements in the coming years as the intelligence needed to interpret the user’s needs before forming the proper SQL queries will improve. </span><span class="kobospan" id="kobo.1151.3">The chaining necessary to get the correct result will also improve. </span><span class="kobospan" id="kobo.1151.4">This chaining problem is a function of what the user asks, the assumptions needed to understand the question, and the SQL required to return the answer. </span><span class="kobospan" id="kobo.1151.5">Chaining is the connecting of one answer that feeds the following question and subsequent answer. </span><span class="kobospan" id="kobo.1151.6">Sometimes, it makes sense to chain thoughts together to resolve a question. </span><span class="kobospan" id="kobo.1151.7">Let me finish with a use case example paraphrasing this Oracle </span><span><span class="kobospan" id="kobo.1152.1">blog example.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.1153.1">Article: </span><a href="https://blogs.oracle.com/digitalassistant/post/introducing-the-new-oracle-digital-assistant-sql-dialog" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.1154.1">Oracle Digital Assistant SLQ </span><span><span class="kobospan" id="kobo.1155.1">Integration</span></span></a><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.1156.1">(</span></span></span><a href="https://blogs.oracle.com/digitalassistant/post/introducing-the-new-oracle-digital-assistant-sql-dialog" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.1157.1">https://blogs.oracle.com/digitalassistant/post/introducing-the-new-oracle-digital-assistant-sql-dialog</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.1158.1">)</span></span></span></p>
			<pre class="source-code"><span class="kobospan1" id="kobo.1159.1">
Show all employees in Michael's org.</span></pre>			<p class="calibre3"><span class="kobospan" id="kobo.1160.1">Let’s address the issues with this </span><span><span class="kobospan" id="kobo.1161.1">process chain:</span></span></p>
			<ol class="calibre12">
				<li class="calibre8"><span class="kobospan" id="kobo.1162.1">Michael – who is Michael? </span><span class="kobospan" id="kobo.1162.2">Look around my hierarchy and determine if Michael is known. </span><span class="kobospan" id="kobo.1162.3">This is a whole process by itself and fundamental to people searching in </span><span><span class="kobospan" id="kobo.1163.1">an organization.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.1164.1">If needed, disambiguate which Michael the user could </span><span><span class="kobospan" id="kobo.1165.1">be inferring.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.1166.1">Map employees to the SQL field (called EMP). </span><span class="kobospan" id="kobo.1166.2">The concept of employees will be requested in many ways – workers, teams, teammates, underlings, people, etc. </span><span class="kobospan" id="kobo.1166.3">It is unlikely a user will </span><em class="italic"><span class="kobospan" id="kobo.1167.1">ever</span></em><span class="kobospan" id="kobo.1168.1"> use the SQL </span><span><span class="kobospan" id="kobo.1169.1">field name.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.1170.1">Determine Michael’s department. </span><span class="kobospan" id="kobo.1170.2">(Use SQL to get the answer. </span><span class="kobospan" id="kobo.1170.3">It </span><span><span class="kobospan" id="kobo.1171.1">is 23.)</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.1172.1">Decide whether the default information to be returned needs to be enhanced based on the query (in this case, nothing special was asked </span><span><span class="kobospan" id="kobo.1173.1">of it).</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.1174.1">Limit query by </span><a id="_idIndexMarker462" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.1175.1">security implications (for example, don’t </span><span><span class="kobospan" id="kobo.1176.1">show salary).</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.1177.1">Perform the </span><a id="_idIndexMarker463" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.1178.1">search, determine the size of the results, and return the results or a chunk of results </span><span><span class="kobospan" id="kobo.1179.1">if #&gt;30.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.1180.1">The final query should look something like this: </span><strong class="source-inline1"><span class="kobospan" id="kobo.1181.1">SELECT EMPNO, ENAME, JOB, MGR FROM EMP WHERE DEPTNO = 23 FETCH FIRST 30 </span></strong><span><strong class="source-inline1"><span class="kobospan" id="kobo.1182.1">ROWS ONLY</span></strong></span><span><span class="kobospan" id="kobo.1183.1">.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.1184.1">Return the answer using a generative answer, wrapping the specific details from </span><span><span class="kobospan" id="kobo.1185.1">the database.</span></span></li>
			</ol>
			<p class="calibre3"><span class="kobospan" id="kobo.1186.1">The Oracle article does an excellent job of discussing synonyms. </span><span class="kobospan" id="kobo.1186.2">In their example, they use the Big Apple for New York City. </span><span class="kobospan" id="kobo.1186.3">It serves as a good reminder that language is very flexible, and there are many cases where, without this sort of intelligence, the natural language feel that customers expect won’t happen. </span><span class="kobospan" id="kobo.1186.4">Since the database fields don’t match the users’ language, there is some work to help with. </span><span class="kobospan" id="kobo.1186.5">The LLM can likely help understand terms and tagging concepts, but a product person must help it with cryptic field labels. </span><span class="kobospan" id="kobo.1186.6">For example, it might not understand that PH2 is a cell phone field. </span><span class="kobospan" id="kobo.1186.7">Use the LLM to extend the understanding of synonyms for a cell phone (such as mobile, digits, contact info, wireless #, phone </span><span><span class="kobospan" id="kobo.1187.1">number, #).</span></span></p>
			<h3 class="calibre11"><span class="kobospan" id="kobo.1188.1">Service requests and other threaded sources</span></h3>
			<p class="calibre3"><span class="kobospan" id="kobo.1189.1">Service </span><a id="_idIndexMarker464" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.1190.1">requests and other conversational sources, such as community discussions, are good data, but the kernels of truth within them must be exposed. </span><span class="kobospan" id="kobo.1190.2">Inferior results will occur if these sources are used without tagging and annotating correct answers. </span><span class="kobospan" id="kobo.1190.3">They are filled with wrong answers, half-truths, and misinformation. </span><span class="kobospan" id="kobo.1190.4">This is especially true for technical answers where the ground truth might be particular to a version or subversion of a product. </span><span class="kobospan" id="kobo.1190.5">So, confusing the difference between the 11.1 and 11.1.2 products can lead to incorrect results. </span><span class="kobospan" id="kobo.1190.6">And there can be red herrings in the answers, too. </span><span class="kobospan" id="kobo.1190.7">That is, there might be information that misleads or distracts from the problem and thus identifies the solution. </span><span class="kobospan" id="kobo.1190.8">It sometimes starts with “I don’t know if this </span><span><span class="kobospan" id="kobo.1191.1">matters, but…”.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.1192.1">Most service </span><a id="_idIndexMarker465" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.1193.1">request systems mark closed service requests </span><a id="_idIndexMarker466" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.1194.1">as completed and require the agent to tag the correct answer for future processing or analysis. </span><span class="kobospan" id="kobo.1194.2">A more formal structure for SRs will give a better chance of mining this information. </span><span class="kobospan" id="kobo.1194.3">The wealth of important information in SRs must be addressed, and there are reasons to consider </span><span><span class="kobospan" id="kobo.1195.1">these sources:</span></span></p>
			<ul class="calibre7">
				<li class="calibre8"><span class="kobospan" id="kobo.1196.1">Customer language is a rich corpus of how customers talk about products, their issues, and how they interact in the real world. </span><span class="kobospan" id="kobo.1196.2">This domain-specific language and terminology are invaluable to training a model. </span><span class="kobospan" id="kobo.1196.3">Technical jargon, colloquialisms, initialisms, abbreviations, and shortcuts will appear more frequently in these sources than in traditional training, marketing, and </span><span><span class="kobospan" id="kobo.1197.1">technical documentation.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.1198.1">Context is helpful in the LLM to create more accurate responses. </span><span class="kobospan" id="kobo.1198.2">Product release, patch levels, software installs, and operating system versions are typically what might be asked about when there is a problem, and this context can be </span><span><span class="kobospan" id="kobo.1199.1">very valuable.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.1200.1">Commonality—the frequency of common questions helps the model understand the likelihood of this type of response being useful in </span><span><span class="kobospan" id="kobo.1201.1">the future.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.1202.1">Technical domain training—there might not be another place to find the situations </span><span><span class="kobospan" id="kobo.1203.1">being discussed.</span></span></li>
			</ul>
			<p class="calibre3"><span class="kobospan" id="kobo.1204.1">Although most companies try to avoid some discussions in SRs and online channels, still be aware and avoid including PII in the model that might leak through in these forums. </span><span class="kobospan" id="kobo.1204.2">The process should support data cleansing and anonymization, as discussed in </span><a href="B21964_02_split_000.xhtml#_idTextAnchor031" class="pcalibre pcalibre1 calibre6"><span><em class="italic"><span class="kobospan" id="kobo.1205.1">Chapter 2</span></em></span></a><span class="kobospan" id="kobo.1206.1">, </span><em class="italic"><span class="kobospan" id="kobo.1207.1">Conducting Effective</span></em> <em class="italic"><span class="kobospan" id="kobo.1208.1">User Research</span></em><span class="kobospan" id="kobo.1209.1">, or synthesizing some data, as discussed earlier in this chapter. </span><span class="kobospan" id="kobo.1209.2">Doing this all manually is impossible at scale. </span><span class="kobospan" id="kobo.1209.3">Ultimately, these are just documents with the same issues as a knowledge base. </span><span class="kobospan" id="kobo.1209.4">Similar to databases, other pieces of software might be needed to access </span><span><span class="kobospan" id="kobo.1210.1">relevant information.</span></span></p>
			<h3 class="calibre11"><span class="kobospan" id="kobo.1211.1">Integrating external content via APIs</span></h3>
			<p class="calibre3"><span class="kobospan" id="kobo.1212.1">Be ready to call the right service with the right </span><a id="_idIndexMarker467" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.1213.1">question. </span><span class="kobospan" id="kobo.1213.2">Creating effective interactions that perform tasks –filling out an expense report, scheduling an appointment on a calendar, or booking a holiday or vacation – all require </span><span><span class="kobospan" id="kobo.1214.1">backend services.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.1215.1">Many resources with advice on creating effective documents and resource retrieval were shared, but the solution’s success will still depend on the collection of services and software used. </span><span class="kobospan" id="kobo.1215.2">A few minutes on integrations </span><span><span class="kobospan" id="kobo.1216.1">is justified.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.1217.1">OpenAI can respond with an API call instead of just replying based on knowledge. </span><span class="kobospan" id="kobo.1217.2">A model can update a support ticket, ask for shipping information, look up prices or products, or perform other interactions the business relies on. </span><span class="kobospan" id="kobo.1217.3">Unsurprisingly, ChatGPT helps explain and write code to connect to several well-known APIs, but that is for development. </span><span class="kobospan" id="kobo.1217.4">Product people must know what is available and </span><em class="italic"><span class="kobospan" id="kobo.1218.1">how</span></em><span class="kobospan" id="kobo.1219.1"> to frame this interaction. </span><span class="kobospan" id="kobo.1219.2">For fun, try something </span><span><span class="kobospan" id="kobo.1220.1">like this.</span></span></p>
			<pre class="source-code"><span class="kobospan1" id="kobo.1221.1">
Can I set up a ChatGPT integration using an API to generate a Zoom conference?</span></pre>			<p class="calibre3"><span class="kobospan" id="kobo.1222.1">Enterprise APIs will mostly be proprietary, and ChatGPT won’t help directly. </span><span class="kobospan" id="kobo.1222.2">However, since most REST work should be similar, it still might be able to help. </span><span class="kobospan" id="kobo.1222.3">Sometimes, integrations with third parties such as Zoom, Teams, Slack, Jira, Confluence, Salesforce, HubSpot, ServiceNow, Oracle, or other vendors are used internally or as part of an enterprise offering. </span><span class="kobospan" id="kobo.1222.4">Remember that all the work is still needed to authenticate, create a security layer, deal with hallucinations, handle error cases, and create a consistent experience. </span><span class="kobospan" id="kobo.1222.5">It is </span><span><span class="kobospan" id="kobo.1223.1">real work.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.1224.1">More robust approaches are evolving. </span><span class="kobospan" id="kobo.1224.2">This article on ToolLLM describes an approach to using ChatGPT to generate instructions for APIs and then figure out how to </span><span><span class="kobospan" id="kobo.1225.1">use them.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.1226.1">Article: </span><a href="https://arxiv.org/abs/2307.16789?utm_source=tldrai" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.1227.1">How to use thousands of APIS in LLMs</span></a><span class="kobospan" id="kobo.1228.1"> (ToolLLM paper) </span><span class="hidden1"><span class="kobospan" id="kobo.1229.1">(</span></span><a href="https://arxiv.org/abs/2307.16789?utm_source=tldrai" class="pcalibre pcalibre1 calibre6"><span class="hidden1"><span class="kobospan" id="kobo.1230.1">https://arxiv.org/abs/2307.16789?utm_source=tldrai</span></span></a><span class="hidden1"><span class="kobospan" id="kobo.1231.1">)</span></span> </p>
			<p class="calibre3"><span class="kobospan" id="kobo.1232.1">Video: AI News: </span><a href="https://www.youtube.com/watch?v=lGxaE8FU2-Q" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.1233.1">An LLM that learns how to work with APIs</span></a> <span class="hidden1"><span class="kobospan" id="kobo.1234.1">(ToolLLM paper)  (</span></span><a href="https://www.youtube.com/watch?v=lGxaE8FU2-Q" class="pcalibre pcalibre1 calibre6"><span class="hidden1"><span class="kobospan" id="kobo.1235.1">https://www.youtube.com/watch?v=lGxaE8FU2-Q</span></span></a><span class="hidden1"><span class="kobospan" id="kobo.1236.1">)</span></span> </p>
			<p class="calibre3"><span class="kobospan" id="kobo.1237.1">Apply our testing and validation process here as it is for </span><em class="italic"><span class="kobospan" id="kobo.1238.1">any</span></em><span class="kobospan" id="kobo.1239.1"> input and output testing. </span><span class="kobospan" id="kobo.1239.2">As designers, PMs, and people who care about usability, try to understand whether the </span><a id="_idIndexMarker468" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.1240.1">APIs provide the right level of service. </span><span class="kobospan" id="kobo.1240.2">Here are some items to look for when integrating with </span><span><span class="kobospan" id="kobo.1241.1">backend services:</span></span></p>
			<ul class="calibre7">
				<li class="calibre8"><span class="kobospan" id="kobo.1242.1">Can the required data be supplemented automatically? </span><span class="kobospan" id="kobo.1242.2">Users should not have to supply every piece of data. </span><span class="kobospan" id="kobo.1242.3">For example, the API might need five pieces of data to submit a valid request. </span><span class="kobospan" id="kobo.1242.4">Some can come from the context and focus the user on the </span><span><span class="kobospan" id="kobo.1243.1">essential elements.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.1244.1">Will the response time be fast enough to be integrated with the response? </span><span class="kobospan" id="kobo.1244.2">Think in milliseconds (200 or less would be good, 50 or less would be great, sub-10s </span><span><span class="kobospan" id="kobo.1245.1">are world-class).</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.1246.1">Can a single API be called instead of two or three? </span><span class="kobospan" id="kobo.1246.2">Optimized API calls help with cost, performance, and the number of </span><span><span class="kobospan" id="kobo.1247.1">round trips.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.1248.1">Is the data format consistent with the customer’s needs? </span><span class="kobospan" id="kobo.1248.2">If not, consider telling ChatGPT how to format it or providing conversations or translations in the correct format. </span><span class="kobospan" id="kobo.1248.3">For example, understand the user’s time zone and don’t use GMT or other </span><span><span class="kobospan" id="kobo.1249.1">time zones.</span></span></li>
			</ul>
			<h3 class="calibre11"><span class="kobospan" id="kobo.1250.1">Integrations and actions</span></h3>
			<p class="calibre3"><span class="kobospan" id="kobo.1251.1">The ChatGPT </span><a id="_idIndexMarker469" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.1252.1">economy is growing in leaps and bounds. </span><span class="kobospan" id="kobo.1252.2">There are </span><a id="_idIndexMarker470" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.1253.1">dozens of popular services and integrations to make processes more seamless </span><span><span class="kobospan" id="kobo.1254.1">and practical.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.1255.1">The development team might support other tools to help create a complete solution. </span><span class="kobospan" id="kobo.1255.2">It would be best to get involved to determine how to apply design thinking and your expertise to support a more </span><span><span class="kobospan" id="kobo.1256.1">sustainable process.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.1257.1">There are plenty of libraries, tools, and resources online. </span><span class="kobospan" id="kobo.1257.2">Comparing and contrasting the wealth of options is out of scope, but a few examples that relate to making effective, well-designed solutions that OpenAI posted can be worth </span><span><span class="kobospan" id="kobo.1258.1">your time:</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.1259.1">Article: </span><a href="https://cookbook.openai.com/articles/related_resources" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.1260.1">OpenAI </span><span><span class="kobospan" id="kobo.1261.1">Cookbook</span></span></a><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.1262.1">(</span></span></span><a href="https://cookbook.openai.com/articles/related_resources" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.1263.1">https://cookbook.openai.com/articles/related_resources</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.1264.1">)</span></span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.1265.1">Article: </span><a href="https://www.langchain.com/langsmith" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.1266.1">LangChain home </span><span><span class="kobospan" id="kobo.1267.1">page</span></span></a><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.1268.1">(</span></span></span><a href="https://www.langchain.com/langsmith" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.1269.1">https://www.langchain.com/langsmith</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.1270.1">)</span></span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.1271.1">Article: </span><a href="https://zilliz.com/blog/customizing-openai-built-in-retrieval-using-milvus-vector-database" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.1272.1">Milvus Vector </span><span><span class="kobospan" id="kobo.1273.1">database</span></span></a><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.1274.1">(</span></span></span><a href="https://zilliz.com/blog/customizing-openai-built-in-retrieval-using-milvus-vector-database" class="pcalibre pcalibre1 calibre6"><span><span class="kobospan" id="kobo.1275.1">https://zilliz.com/blog/customizing-openai-built-in-retrieval-using-milvus-vector-database</span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.1276.1">)</span></span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.1277.1">The LLM can be just </span><em class="italic"><span class="kobospan" id="kobo.1278.1">one</span></em><span class="kobospan" id="kobo.1279.1"> of the services within the entire lifecycle or pipeline. </span><span class="kobospan" id="kobo.1279.2">This means faults can occur before or after the LLM. </span><span class="kobospan" id="kobo.1279.3">Look carefully before placing </span><a id="_idIndexMarker471" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.1280.1">blame on the model. </span><span class="kobospan" id="kobo.1280.2">It is only as good as the input and instructions provided. </span><span class="kobospan" id="kobo.1280.3">Improve the quality of what is shared with the model. </span><span class="kobospan" id="kobo.1280.4">Design how to share </span><a id="_idIndexMarker472" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.1281.1">data with the LLM and then test and verify how it works. </span><em class="italic"><span class="kobospan" id="kobo.1282.1">Be fully committed to an iterative lifecycle to make successful generative AI solutions.</span></em><span class="kobospan" id="kobo.1283.1"> Quality is all about the care and feeding process. </span><span class="kobospan" id="kobo.1283.2">Since improvements are only improvements if we measure them, this is explored in </span><a href="B21964_10_split_000.xhtml#_idTextAnchor216" class="pcalibre pcalibre1 calibre6"><span><em class="italic"><span class="kobospan" id="kobo.1284.1">Chapter 10</span></em></span></a><em class="italic"><span class="kobospan" id="kobo.1285.1">, Monitoring and Evaluation</span></em><span class="kobospan" id="kobo.1286.1">. </span><span class="kobospan" id="kobo.1286.2">Ragas is one of those tools to consider using to measure how the RAG solution is performing. </span><span class="kobospan" id="kobo.1286.3">If this excites you, check it </span><span><span class="kobospan" id="kobo.1287.1">out now.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.1288.1">Link: </span><a href="https://docs.ragas.io/en/latest/" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.1289.1">Ragas </span><span><span class="kobospan" id="kobo.1290.1">Documentation</span></span></a><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.1291.1">(</span></span></span><a href="https://docs.ragas.io/en/latest/" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.1292.1">https://docs.ragas.io/en/latest/</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.1293.1">)</span></span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.1294.1">ChatGPT has a </span><a id="_idIndexMarker473" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.1295.1">concept called actions (formerly called plugins). </span><span class="kobospan" id="kobo.1295.2">These allow ChatGPT to connect to the rest of the internet. </span><span class="kobospan" id="kobo.1295.3">Actions rely on function calling to perform these actions. </span><span class="kobospan" id="kobo.1295.4">Recall that the Wove example used </span><span><span class="kobospan" id="kobo.1296.1">function calling.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.1297.1">Documentation: </span><a href="https://platform.openai.com/docs/actions/introduction" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.1298.1">Actions in GPTs (Calling </span><span><span class="kobospan" id="kobo.1299.1">APIs)</span></span></a><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.1300.1">(</span></span></span><a href="https://platform.openai.com/docs/actions/introduction" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.1301.1">https://platform.openai.com/docs/actions/introduction</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.1302.1">)</span></span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.1303.1">What is impressive is that developers do not have to write these API queries by hand. </span><span class="kobospan" id="kobo.1303.2">ChatGPT has a bespoke LLM tuned to help developers </span><span><span class="kobospan" id="kobo.1304.1">write actions.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.1305.1">Demo: </span><a href="https://chatgpt.com/g/g-TYEliDU6A-actionsgpt" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.1306.1">ActionsGPT </span><span><span class="kobospan" id="kobo.1307.1">chat</span></span></a><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.1308.1">(</span></span></span><a href="https://chatgpt.com/g/g-TYEliDU6A-actionsgpt" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.1309.1">https://chatgpt.com/g/g-TYEliDU6A-actionsgpt</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.1310.1">)</span></span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.1311.1">Developers can send messages to the LLM to generate the base code. </span><span class="kobospan" id="kobo.1311.2">For example, they can try something </span><span><span class="kobospan" id="kobo.1312.1">like this.</span></span></p>
			<pre class="source-code"><span class="kobospan1" id="kobo.1313.1">
Make a spec to call the endpoint at https://api.openai.com/v1 with a POST request. </span><span class="kobospan1" id="kobo.1313.2">The request should have a body with model and prompt keys - both are strings.</span></pre>			<p class="calibre3"><span class="kobospan" id="kobo.1314.1">Share these resources and this video with developers to help them </span><span><span class="kobospan" id="kobo.1315.1">get started.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.1316.1">Video: </span><a href="https://www.youtube.com/watch?v=pq34V_V5j18" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.1317.1">Introduction to ChatGPT Actions</span></a> <span class="hidden1"><span class="kobospan" id="kobo.1318.1">(</span></span><a href="https://www.youtube.com/watch?v=pq34V_V5j18" class="pcalibre pcalibre1 calibre6"><span class="hidden1"><span class="kobospan" id="kobo.1319.1">https://www.youtube.com/watch?v=pq34V_V5j18</span></span></a><span class="hidden1"><span class="kobospan" id="kobo.1320.1">) (Actions start </span></span><span><span class="hidden1"><span class="kobospan" id="kobo.1321.1">at 9:30)</span></span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.1322.1">Figuring out these linkages is for development. </span><span class="kobospan" id="kobo.1322.2">As a product leader, know that a wealth of services is available for integration from enterprise sources to make the solution support intelligence that combines these. </span><span class="kobospan" id="kobo.1322.3">To create these connections, </span><a id="_idIndexMarker474" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.1323.1">the paid version of ChatGPT, if not the enterprise version, is needed. </span><span class="kobospan" id="kobo.1323.2">In the ChatGPT video, Nick Turley </span><a id="_idIndexMarker475" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.1324.1">hooks up his personal to-do list from asana.com to the chat instance in the demo. </span><span><em class="italic"><span class="kobospan" id="kobo.1325.1">Figure 6</span></em></span><em class="italic"><span class="kobospan" id="kobo.1326.1">.14</span></em><span class="kobospan" id="kobo.1327.1"> shows the current actions setup. </span><span class="kobospan" id="kobo.1327.2">It is a simple UI to name, describe, and define </span><span><span class="kobospan" id="kobo.1328.1">the instructions.</span></span></p>
			<div class="calibre2">
				<div id="_idContainer083" class="img---figure">
					<span class="kobospan" id="kobo.1329.1"><img src="image/B21964_06_14.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.1330.1">Figure 6.14 – Setting up actions on the Configure tab</span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.1331.1">The demo goes further with embedding knowledge to help with summarizing. </span><span class="kobospan" id="kobo.1331.2">Watch to get a good sense of the integrations fundamental to enterprise solutions. </span><span class="kobospan" id="kobo.1331.3">At the 20-minute mark, it gets a little creative with a mood demo. </span><span class="kobospan" id="kobo.1331.4">They do a great demo of integrating with physical devices in the demo room and Spotify to play music. </span><span class="kobospan" id="kobo.1331.5">The point is that enterprise solutions can be more than just software integrations. </span><span class="kobospan" id="kobo.1331.6">Manufacturing, lighting, HVAC (air conditioning), processes, routing, planning, and more can be improved with intelligent integration. </span><span class="kobospan" id="kobo.1331.7">This takes us back to our chapter on use cases. </span><span class="kobospan" id="kobo.1331.8">There are lots of opportunities </span><span><span class="kobospan" id="kobo.1332.1">out there.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.1333.1">This book is intended to be practical even when the tools change—and they will—so don’t get hung up on a tool or direction. </span><span class="kobospan" id="kobo.1333.2">New and more robust services </span><a id="_idIndexMarker476" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.1334.1">will be introduced frequently. </span><span class="kobospan" id="kobo.1334.2">Build a lean process that supports adaptation and change. </span><span class="kobospan" id="kobo.1334.3">Learn from the LLM community. </span><span class="kobospan" id="kobo.1334.4">The number of blogs, posts, and training opportunities is </span><span><span class="kobospan" id="kobo.1335.1">expanding daily.</span></span></p>
			<h2 id="_idParaDest-142" class="calibre9"><a id="_idTextAnchor145" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.1336.1">Community resources</span></h2>
			<p class="calibre3"><span class="kobospan" id="kobo.1337.1">A wealth of resources exists, including in the OpenAI community. </span><span class="kobospan" id="kobo.1337.2">Explore these resources, the latest videos, and research to get up </span><span><span class="kobospan" id="kobo.1338.1">to speed.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.1339.1">Article: </span><a href="https://community.openai.com/t/rag-is-not-really-a-solution/599291/2" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.1340.1">RAG Community </span><span><span class="kobospan" id="kobo.1341.1">Discussion</span></span></a><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.1342.1">(</span></span></span><a href="https://community.openai.com/t/rag-is-not-really-a-solution/599291/2" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.1343.1">https://community.openai.com/t/rag-is-not-really-a-solution/599291/2</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.1344.1">)</span></span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.1345.1">In Ron Parker’s post, he discusses RAG as </span><span><span class="kobospan" id="kobo.1346.1">being brittle.</span></span></p>
			<p class="author-quote"><span class="kobospan" id="kobo.1347.1">"The biggest problem I’ve run into so far is that some query responses are not comprehensive enough. </span><span class="kobospan" id="kobo.1347.2">End-users can almost always get a complete answer using chain-of-thought queries (few-shot). </span><span class="kobospan" id="kobo.1347.3">But, the end-users I’ve been working with want complete answers to the first question (zero-shot). </span><span class="kobospan" id="kobo.1347.4">This may touch on your issue.</span></p>
			<p class="author-quote"><span class="kobospan" id="kobo.1348.1">My resolution: Deep Dive. </span><span class="kobospan" id="kobo.1348.2">Have the model dig through all the possible responses, categorize and analyze those, and then return a complete list of the best responses. </span><span class="kobospan" id="kobo.1348.3">Since I built my RAG system, I must also develop this feature. </span><span class="kobospan" id="kobo.1348.4">So I’m thinking, whatever you say this technique is you’re missing, you may have to build it yourself."</span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.1349.1">This makes our point. </span><span class="kobospan" id="kobo.1349.2">This is about building solutions, and this puzzle has many pieces. </span><span class="kobospan" id="kobo.1349.3">He also points out a good usability issue. </span><span class="kobospan" id="kobo.1349.4">Users don’t want to have conversations to get to their answers. </span><span class="kobospan" id="kobo.1349.5">They want the complete answer on the first try. </span><span class="kobospan" id="kobo.1349.6">Even in our case study with Wove, they worked hard to return the best responses and iterate on the training to get the correct answers. </span><span class="kobospan" id="kobo.1349.7">They had to figure out the model and chunk the rate sheets, and then they refined those answers to improve the model. </span><span class="kobospan" id="kobo.1349.8">Again, it involves honest work by the development team; work with them to improve the quality with </span><span><span class="kobospan" id="kobo.1350.1">every step</span><a id="_idTextAnchor146" class="pcalibre pcalibre1 calibre6"/><a id="_idTextAnchor147" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.1351.1">.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.1352.1">Or, check out a nice video showing how Mayo Oshin (</span><strong class="bold"><span class="kobospan" id="kobo.1353.1">@maywaoshin</span></strong><span class="kobospan" id="kobo.1354.1">) used GPT-4 to front-end thousands of pages from PDF documents—in this case, the last few years of Tesla’s annual </span><a id="_idIndexMarker477" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.1355.1">reports. </span><span class="kobospan" id="kobo.1355.2">He walks through his </span><a id="_idIndexMarker478" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.1356.1">architecture. </span><span class="kobospan" id="kobo.1356.2">Most of that will be too much, but he talks about how he converts documents into text and chunks of documents. </span><span class="kobospan" id="kobo.1356.3">This discussion is right on point </span><span><span class="kobospan" id="kobo.1357.1">for us.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.1358.1">Video:</span><a href="https://www.youtube.com/watch?v=Ix9WIZpArm0" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.1359.1"> Example of 1000+ Pages of </span><span><span class="kobospan" id="kobo.1360.1">PDF</span></span></a><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.1361.1">(</span></span></span><a href="https://www.youtube.com/watch?v=Ix9WIZpArm0" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.1362.1">https://www.youtube.com/watch?v=Ix9WIZpArm0</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.1363.1">)</span></span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.1364.1">The last resource for our discussion is the previously mentioned video on lessons learned </span><span><span class="kobospan" id="kobo.1365.1">around RAG.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.1366.1">Video: </span><a href="https://www.youtube.com/live/Y9qn4XGH1TI?si=iUs_x3yDL8BK7aUb56" class="pcalibre pcalibre1 calibre6"><span class="kobospan" id="kobo.1367.1">Lessons Learned on LLM RAG </span><span><span class="kobospan" id="kobo.1368.1">Solutions</span></span></a><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.1369.1">(</span></span></span><a href="https://www.youtube.com/live/Y9qn4XGH1TI?si=iUs_x3yDL8BK7aUb56" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.1370.1">https://www.youtube.com/live/Y9qn4XGH1TI?si=iUs_x3yDL8BK7aUb56</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.1371.1">)</span></span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.1372.1">They cover a variety of good things about managing documents. </span><span class="kobospan" id="kobo.1372.2">Here is </span><span><span class="kobospan" id="kobo.1373.1">a summary:</span></span></p>
			<ul class="calibre7">
				<li class="calibre8"><span class="kobospan" id="kobo.1374.1">They remind everyone to do good “data science” and make sure to have good data going in. </span><span class="kobospan" id="kobo.1374.2">Also, that accurate data is messy. </span><span class="kobospan" id="kobo.1374.3">Not only are tables tricky (something discussed in this chapter), but different document formats can need different libraries to help clean them (or the headache of </span><span><span class="kobospan" id="kobo.1375.1">manual cleaning).</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.1376.1">Explanations might not be directly linked to information. </span><span class="kobospan" id="kobo.1376.2">Comments or notes around negation ("does not have", "except for this version", "does not apply") can negate some documentation that does not even appear in a chunk that it relates to and might only be understood with additional editing </span><span><span class="kobospan" id="kobo.1377.1">or tagging.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.1378.1">Maintain structure. </span><span class="kobospan" id="kobo.1378.2">Convert documents to a data structure while preserving their meaning. </span><span class="kobospan" id="kobo.1378.3">For example, when PDFs are converted to text, a model can decide how to parse the PDFs, identify headings, and build out and capture information to put it into a </span><span><span class="kobospan" id="kobo.1379.1">meaningful structure.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.1380.1">If the documents are hierarchical, a flat representation is needed, so try to get to a list of elements. </span><span class="kobospan" id="kobo.1380.2">The key for a part of the element can represent a section. </span><span class="kobospan" id="kobo.1380.3">This kind of discussion is more for the data ingestion team, but look for these issues when testing. </span><span class="kobospan" id="kobo.1380.4">This way, test results can verify that context is maintained. </span><span class="kobospan" id="kobo.1380.5">Help the data scientists </span><span><span class="kobospan" id="kobo.1381.1">maintain quality.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.1382.1">Different </span><a id="_idIndexMarker479" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.1383.1">methods result in </span><a id="_idIndexMarker480" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.1384.1">different quality. </span><span class="kobospan" id="kobo.1384.2">As discussed, sentence-by-sentence embedding will lose </span><span><span class="kobospan" id="kobo.1385.1">some context.</span></span></li>
				<li class="calibre8"><span class="kobospan" id="kobo.1386.1">As discussed, get the proper context in chunks. </span><span class="kobospan" id="kobo.1386.2">It should not be too narrow or too broad; it should be </span><em class="italic"><span class="kobospan" id="kobo.1387.1">just right</span></em><span class="kobospan" id="kobo.1388.1">. </span><span class="kobospan" id="kobo.1388.2">The approach in </span><span><em class="italic"><span class="kobospan" id="kobo.1389.1">Figure 6</span></em></span><em class="italic"><span class="kobospan" id="kobo.1390.1">.15</span></em><span class="kobospan" id="kobo.1391.1"> reminds us of what was discussed at the start of </span><span><span class="kobospan" id="kobo.1392.1">the chapter.</span></span></li>
			</ul>
			<div class="calibre2">
				<div id="_idContainer084" class="img---figure">
					<span class="kobospan" id="kobo.1393.1"><img src="image/B21964_06_15.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.1394.1">Figure 6.15 – Prolego’s approach is similar to our discussion earlier in the chapter</span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.1395.1">Several videos from Prolego (besides the one shared) are easy to digest and well-paced. </span><span class="kobospan" id="kobo.1395.2">This is just one example of the wealth of video and article resources that can help on a RAG journey. </span><span class="kobospan" id="kobo.1395.3">Don’t build everything yourself; the LLM vendors are only one piece of a more extensive solution that includes tools, documentation, databases, </span><span><span class="kobospan" id="kobo.1396.1">and APIs.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.1397.1">Besides RAG, there are wonderful posts on every imaginable topic around LLMs on LinkedIn, shared in mailing lists, posted on YouTube, classes from universities, and </span><span><span class="kobospan" id="kobo.1398.1">vendor websites.</span></span></p>
			<h1 id="_idParaDest-143" class="calibre5"><a id="_idTextAnchor148" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.1399.1">Summary</span></h1>
			<p class="calibre3"><span class="kobospan" id="kobo.1400.1">It is a big step to prepare an existing knowledge base and data sources to make them available within a generative AI solution. </span><span class="kobospan" id="kobo.1400.2">It’s likely the most significant step because the hard work of creating the ChatGPT model was done for you. </span><span class="kobospan" id="kobo.1400.3">For many enterprise solutions, this can be an overwhelming task. </span><span class="kobospan" id="kobo.1400.4">Just start small. </span><span class="kobospan" id="kobo.1400.5">Learn from the use cases to prioritize solutions that provide the most significant value with the least cost (recall our scoring discussion in </span><a href="B21964_04.xhtml#_idTextAnchor085" class="pcalibre pcalibre1 calibre6"><span><em class="italic"><span class="kobospan" id="kobo.1401.1">Chapter 4</span></em></span></a><span class="kobospan" id="kobo.1402.1">, </span><em class="italic"><span class="kobospan" id="kobo.1403.1">Scoring Stories</span></em><span class="kobospan" id="kobo.1404.1">). </span><span class="kobospan" id="kobo.1404.2">Over time, land grabs can expand into other data sources and, thus, new use cases. </span><span class="kobospan" id="kobo.1404.3">All of this has to be done with quality in mind. </span><span class="kobospan" id="kobo.1404.4">Measuring and monitoring are critical. </span><span class="kobospan" id="kobo.1404.5">Newer doesn’t mean better. </span><span class="kobospan" id="kobo.1404.6">Mix and match ChatGPT models to perform specific tasks or optimize cost or performance by using one model over another. </span><span class="kobospan" id="kobo.1404.7">Use a collection of third-party resources—possibly even other models tuned to a particular problem space—to refine results, make data available to the model, or do additional integrations. </span><span class="kobospan" id="kobo.1404.8">Be aware of the impact of data cleaning and how the knowledge in the base model might impact the solution’s decision-making ability. </span><span class="kobospan" id="kobo.1404.9">Recognize that bias isn’t just about social or political positions; it can simply be about having too much data about one product, and this causes the model to miss smaller products. </span><span class="kobospan" id="kobo.1404.10">Getting all of this right with the enterprise data is </span><span><span class="kobospan" id="kobo.1405.1">a challenge.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.1406.1">This chapter mainly focused on awareness and considered how techniques can influence the quality of inbound data sources. </span><span class="kobospan" id="kobo.1406.2">On the outbound side, testing and completing the feedback loop is a great way to improve the solution. </span><span class="kobospan" id="kobo.1406.3">There should be many opportunities to contribute before moving on to the next steps around prompt engineering </span><span><span class="kobospan" id="kobo.1407.1">and fine-tuning.</span></span></p>
			<h1 id="_idParaDest-144" class="calibre5"><a id="_idTextAnchor149" class="pcalibre pcalibre1 calibre6"/><span class="kobospan" id="kobo.1408.1">References</span></h1>
			<table id="table003-5" class="no-table-style">
				<colgroup class="calibre15">
					<col class="calibre16"/>
					<col class="calibre16"/>
				</colgroup>
				<tbody class="calibre17">
					<tr class="no-table-style1">
						<td class="no-table-style2">
							<div class="calibre2">
								<div id="_idContainer085" class="img---figure">
									<span class="kobospan" id="kobo.1409.1"><img src="image/B21964_06_16.jpg" alt="" role="presentation" class="calibre4"/></span>
								</div>
							</div>
						</td>
						<td class="no-table-style2">
							<p class="calibre3"><span class="kobospan" id="kobo.1410.1">The links, book recommendations, and GitHub files in this chapter are posted on the </span><span><span class="kobospan" id="kobo.1411.1">reference page.</span></span></p>
							<p class="calibre3"><span class="kobospan" id="kobo.1412.1">Web page: </span><a href="https://uxdforai.com/references#C6" class="pcalibre pcalibre1 calibre6"><span><span class="kobospan" id="kobo.1413.1">Chapter 6</span></span> <span><span class="kobospan" id="kobo.1414.1">References</span></span></a><span> </span><span><span class="hidden1"><span class="kobospan" id="kobo.1415.1">(</span></span></span><a href="https://uxdforai.com/references#C6" class="pcalibre pcalibre1 calibre6"><span><span class="hidden1"><span class="kobospan" id="kobo.1416.1">https://uxdforai.com/references#C6</span></span></span></a><span><span class="hidden1"><span class="kobospan" id="kobo.1417.1">)</span></span></span></p>
						</td>
					</tr>
				</tbody>
			</table>
		</div>
	</body></html>