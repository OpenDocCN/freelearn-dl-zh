- en: '6'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '6'
- en: Building Conversational Applications
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建对话式应用
- en: With this chapter, we embark on the hands-on section of this book, with our
    first concrete implementation of LLM-powered applications. Throughout this chapter,
    we will cover a step-by-step implementation of a conversational application, using
    LangChain and its components, building on the knowledge you’ve gained from the
    previous chapters. By the end of this chapter, you will be able to set up your
    own conversational application project with just a few lines of code.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 通过本章，我们开始这本书的实战部分，我们的第一个基于 LLM 的应用的具体实现。在本章中，我们将逐步实现一个对话式应用，使用 LangChain 及其组件，基于前面章节中获得的知识。到本章结束时，你将能够仅用几行代码设置自己的对话式应用项目。
- en: 'We will cover the following key topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将涵盖以下关键主题：
- en: Configuring the schema of a simple chatbot
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置简单聊天机器人的模式
- en: Adding the memory component
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加记忆组件
- en: Adding non-parametric knowledge
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加非参数化知识
- en: Adding tools and making the chatbot “agentic”
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加工具并使聊天机器人“有代理性”
- en: Developing the front-end with Streamlit
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Streamlit 开发前端
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'To complete the tasks in this chapter, you will need the following:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 要完成本章的任务，你需要以下内容：
- en: A Hugging Face account and user access token.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 Hugging Face 账户和用户访问令牌。
- en: An OpenAI account and user access token.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 OpenAI 账户和用户访问令牌。
- en: Python 3.7.1 or a later version.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python 3.7.1 或更高版本。
- en: 'Python packages – make sure to have the following Python packages installed:
    `langchain`, `python-dotenv`, `huggingface_hub, streamlit`, `openai`, `pypdf`,
    `tiktoken`, `faiss-cpu`, and `google-search-results.` They can be easily installed
    via `pip install` in your terminal.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python 包 – 确保已安装以下 Python 包：`langchain`、`python-dotenv`、`huggingface_hub`、`streamlit`、`openai`、`pypdf`、`tiktoken`、`faiss-cpu`
    和 `google-search-results`。它们可以通过在终端中运行 `pip install` 命令轻松安装。
- en: You’ll find the code for this chapter in the book’s GitHub repository at [https://github.com/PacktPublishing/Building-LLM-Powered-Applications](Chapter_06.xhtml).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在本书的 GitHub 仓库中找到本章的代码：[https://github.com/PacktPublishing/Building-LLM-Powered-Applications](Chapter_06.xhtml)。
- en: Getting started with conversational applications
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开始使用对话式应用
- en: A conversational application is a type of software that can interact with users
    using natural language. It can be used for various purposes, such as providing
    information, assistance, entertainment, or transactions. Generally speaking, a
    conversational application can use different modes of communication, such as text,
    voice, graphics, or even touch. A conversational application can also use different
    platforms, such as messaging apps, websites, mobile devices, or smart speakers.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 对话式应用是一种可以借助自然语言与用户进行交互的软件类型。它可以用于各种目的，例如提供信息、协助、娱乐或交易。一般来说，对话式应用可以使用不同的通信模式，如文本、语音、图形，甚至触摸。对话式应用还可以使用不同的平台，如消息应用、网站、移动设备或智能扬声器。
- en: 'Today, conversational applications are being taken to the next level thanks
    to LLMs. Let’s look at some of the benefits that they provide:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 今天，由于 LLMs，对话式应用正被提升到新的水平。让我们看看它们提供的某些好处：
- en: Not only do LLMs provide a new level of natural language interactions, but they
    can also enable applications to perform reasoning based on the best responses,
    given users’ preferences.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不仅 LLMs 提供了新的自然语言交互水平，而且它们还可以根据用户的偏好，使应用能够执行基于最佳响应的推理。
- en: As we saw in previous chapters, LLMs can leverage their parametric knowledge,
    but are also enriched with non-parametric knowledge, thanks to embeddings and
    plug-ins.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正如我们在前面的章节中看到的，LLMs 可以利用它们的参数化知识，但还通过嵌入和插件丰富了非参数化知识。
- en: Finally, LLMs are also able to keep track of the conversation thanks to different
    types of memory.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，LLMs 还能通过不同类型的记忆来跟踪对话。
- en: 'The following image shows what the architecture of a conversational bot might
    look like:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了对话式机器人可能的结构：
- en: '![A diagram of a computer program  Description automatically generated](img/B21714_06_01.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![计算机程序图  自动生成描述](img/B21714_06_01.png)'
- en: 'Figure 6.1: Sample architecture of a conversational bot'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.1：对话式机器人的示例架构
- en: Throughout this chapter, we will build from scratch a text conversational application
    that is able to help users plan their vacations. We will call this app GlobeBotter.
    We will add incremental layers of complexity to make the app as enjoyable as possible
    for the end user.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将从头开始构建一个文本对话应用，该应用能够帮助用户规划他们的假期。我们将把这个应用称为GlobeBotter。我们将逐步添加复杂性，使应用对最终用户尽可能有趣。
- en: So, let’s start with the basics behind a conversational app architecture.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，让我们从对话应用架构的基本原理开始。
- en: Creating a plain vanilla bot
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建一个简单的机器人
- en: 'To start with, let’s initialize our LLM and set the schema for our bot. The
    schema refers to the type of messages the bot is able to receive. In our case,
    we will have three types of messages:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们初始化我们的LLM并设置我们机器人的模式。模式指的是机器人能够接收的消息类型。在我们的案例中，我们将有三种类型的消息：
- en: '**System message**:The instructions we give the bot so that it behaves as a
    travel assistant.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**系统消息**：我们给机器人的指示，以便它表现得像一个旅行助手。'
- en: '**AI Message**:The message generated by the LLM'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AI消息**：由LLM生成的消息'
- en: '**Human Message**: The user’s query'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**人类消息**：用户的查询'
- en: 'Let’s start with a simple configuration:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从简单的配置开始：
- en: '[PRE0]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We can then save and print the output as follows:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以保存并打印输出如下：
- en: '[PRE1]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Here is the output:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是输出：
- en: '[PRE2]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: As you can see, the model was pretty good at generating an itinerary in Rome
    with only one piece of information from our side, the number of days.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，模型在仅从我们这里得到一条信息——天数的情况下，在罗马生成行程做得相当不错。
- en: However, we might want to keep interacting with the bot, so that we can further
    optimize the itinerary, providing more information about our preferences and habits.
    To achieve that, we need to add memory to our bot.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们可能还想继续与机器人交互，以便进一步优化行程，提供更多关于我们偏好和习惯的信息。为了实现这一点，我们需要向我们的机器人添加内存。
- en: Adding memory
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 添加内存
- en: As we’re creating a conversational bot with relatively short messages, in this
    scenario, a `ConversationBufferMemory` could be suitable. To make the configuration
    easier, let’s also initialize a `ConversationChain` to combine the LLM and the
    memory components.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们正在创建一个使用相对简短消息的对话机器人，在这种情况下，`ConversationBufferMemory`可能很合适。为了使配置更简单，让我们还初始化一个`ConversationChain`来结合LLM和内存组件。
- en: 'Let’s first initialize our memory and chain (I’m keeping `verbose = True` so
    that you can see the bot keeping track of previous messages):'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先初始化我们的内存和链（我保持`verbose = True`，这样你可以看到机器人正在跟踪之前的消息）：
- en: '[PRE3]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Great, now let’s have some interactions with our bot:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 太好了，现在让我们与我们的机器人进行一些交互：
- en: '[PRE4]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The following is the output:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是输出：
- en: '[PRE5]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Next, we provide the following input:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们提供以下输入：
- en: '[PRE6]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Here is the corresponding output:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是相应的输出：
- en: '[PRE7]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'As you can see from the chain, it is keeping track of the previous interactions.
    Let’s challenge it and ask something related to the previous context:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，它正在跟踪之前的交互。让我们挑战它，并询问与之前上下文相关的问题：
- en: '[PRE8]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The following is the output that we receive:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们收到的输出：
- en: '[PRE9]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The bot was able to understand that our request was related to its previous
    answer. We can also retrieve the message history with the `memory.load_memory_variables()`
    method (you can see the full output in the GitHub repository). Here is a snippet
    of the output:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 机器人能够理解我们的请求与其之前的回答相关。我们还可以使用`memory.load_memory_variables()`方法检索消息历史（你可以在GitHub仓库中查看完整输出）。以下是输出片段：
- en: '[PRE10]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Rather than running the conversation.run method at every interaction, I’ve
    coded a `while` cycle to make it interactive. The following is a snapshot of the
    whole conversation (you can find it in the book’s GitHub repository):'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 而不是在每次交互时都运行`conversation.run`方法，我编写了一个`while`循环来使其具有交互性。以下是整个对话的快照（你可以在书籍的GitHub仓库中找到它）：
- en: '[PRE11]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The following is a truncated sample from the output (you can find the whole
    output in the book’s GitHub repository):'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是从输出中截取的样本（你可以在书籍的GitHub仓库中找到完整输出）：
- en: '[PRE12]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'As you can see, now the AI assistant is capable of keeping track of the whole
    conversation. In the next section, we are going to add yet another layer of complexity:
    an external knowledge base.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，现在AI助手能够跟踪整个对话。在下一节中，我们将添加另一层复杂性：外部知识库。
- en: Adding non-parametric knowledge
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 添加非参数化知识
- en: Imagine that you also want your GlobeBotter to have access to exclusive documentation
    about itineraries that are not part of its parametric knowledge.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，你希望你的GlobeBotter也能访问关于它行程的独家文档，这些行程不属于其参数化知识。
- en: To do so, we can either embed the documentation in a VectorDB or directly use
    a retriever to do the job. In this case, we will use a vector-store-backed retriever
    using a particular chain, `ConversationalRetrievalChain.` This type of chain leverages
    a retriever over the provided knowledge base that has the chat history, which
    can be passed as a parameter using the desired type of memory previously seen.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 为了做到这一点，我们可以在VectorDB中嵌入文档或直接使用检索器来完成这项工作。在这种情况下，我们将使用一个特定的链`ConversationalRetrievalChain`来支持向量存储的检索器。这种类型的链利用检索器在提供的知识库上，该知识库包含聊天历史，可以通过使用之前看到的所需类型的内存作为参数传递。
- en: With this goal in mind, we will use a sample Italy travel guide PDF downloaded
    from [https://www.minube.net/guides/italy](https://www.minube.net/guides/italy).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 以此目标为前提，我们将使用从[https://www.minube.net/guides/italy](https://www.minube.net/guides/italy)下载的意大利旅行指南PDF样本。
- en: 'The following Python code shows how to initialize all the ingredients we need,
    which are:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 以下Python代码显示了如何初始化我们需要的所有成分，它们是：
- en: '**Document Loader**:Since the document is in PDF format, we will use `PyPDFLoader`.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文档加载器**：由于文档是PDF格式，我们将使用`PyPDFLoader`。'
- en: '**Text splitter**:We will use a `RecursiveCharacterTextSplitter`, which splits
    text by recursively looking at characters to find one that works.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文本分割器**：我们将使用`RecursiveCharacterTextSplitter`，它通过递归查看字符来分割文本，以找到合适的位置。'
- en: '**Vector store**:We will use the `FAISS` VectorDB.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**向量存储**：我们将使用`FAISS` VectorDB。'
- en: '**Memory**:We will use a `ConversationBufferMemory`.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内存**：我们将使用`ConversationBufferMemory`。'
- en: '**LLMs**:We will use the `gpt-3.5-turbo` model for conversations.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LLMs**：我们将使用`gpt-3.5-turbo`模型进行对话。'
- en: '**Embeddings**:We will use the `text-embedding-ada-002`.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**嵌入**：我们将使用`text-embedding-ada-002`。'
- en: 'Let’s take a look at the code:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看代码：
- en: '[PRE13]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Let’s now interact with the chain:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们与链进行交互：
- en: '[PRE14]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The following is the output (I’m reporting a truncated version. You can see
    the whole output in the book’s GitHub repository):'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是输出（我报告的是截断版本。您可以在书籍的GitHub仓库中看到完整的输出）：
- en: '[PRE15]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Note that, by default, the `ConversationalRetrievalChain` uses a prompt template
    called `CONDENSE_QUESTION_PROMPT`, which merges the last user’s query with the
    chat history, so that it results as just one query to the retriever. If you want
    to pass a custom prompt, you can do so using the `condense_question_prompt` parameter
    in the `ConversationalRetrievalChain.from_llm` module.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，默认情况下，`ConversationalRetrievalChain`使用一个名为`CONDENSE_QUESTION_PROMPT`的提示模板，它将最后用户的查询与聊天历史合并，因此结果只有一个查询给检索器。如果您想传递一个自定义提示，您可以使用`ConversationalRetrievalChain.from_llm`模块中的`condense_question_prompt`参数。
- en: Even though the bot was able to provide an answer based on the documentation,
    we still have a limitation. In fact, with such a configuration, our GlobeBotter
    will only look at the provided documentation, but what if we want it to also use
    its parametric knowledge? For example, we might want the bot to be able to understand
    whether it could integrate with the provided documentation or simply answer *freely*.
    To do so, we need to make our GlobeBotter *agentic*, meaning that we want to leverage
    the LLM’s reasoning capabilities to orchestrate and invoke the available tools
    without a fixed order, but rather following the best approach given the user’s
    query.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管机器人能够根据文档提供答案，但我们仍然存在局限性。实际上，在这种配置下，我们的GlobeBotter将只查看提供的文档，但如果我们希望它也能使用其参数化知识怎么办？例如，我们可能希望机器人能够理解它是否能够与提供的文档集成，或者简单地自由回答*。为了做到这一点，我们需要使我们的GlobeBotter具有代理性，这意味着我们希望利用LLM的推理能力来组织和调用可用的工具，而不是遵循固定的顺序，而是根据用户的查询采取最佳方法。
- en: 'To do so, we will use two main components:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 为了做到这一点，我们将使用两个主要组件：
- en: '`create_retriever_tool`: This method creates a custom tool that acts as a retriever
    for an agent. It will need a database to retrieve from, a name, and a short description,
    so that the model can understand when to use it.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`create_retriever_tool`：此方法创建一个作为代理检索器的自定义工具。它需要一个用于检索的数据库、一个名称和一个简短描述，以便模型能够理解何时使用它。'
- en: '`create_conversational_retrieval_agent`: This method initializes a conversational
    agent that is configured to work with retrievers and chat models. It will need
    an LLM, a list of tools (in our case, the retriever), and a memory key to keep
    track of the previous chat history.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`create_conversational_retrieval_agent`：此方法初始化一个配置为与检索器和聊天模型一起工作的对话代理。它需要一个LLM、一个工具列表（在我们的案例中，是检索器）和一个内存键来跟踪之前的聊天历史。'
- en: 'The following code illustrates how to initialize the agent:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码说明了如何初始化代理：
- en: '[PRE16]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Great, now let’s see the thought process of the agent with two different questions
    (I will report only the chain of thoughts and truncate the output, but you can
    find the whole code in the GitHub repo):'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 太好了，现在让我们看看代理在两个不同问题上的思考过程（我将只报告思维链并截断输出，但你可以在 GitHub 仓库中找到完整的代码）：
- en: '[PRE17]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Here is the output:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是输出：
- en: '[PRE18]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Let’s now try with a question not related to the document:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们用一个与文档无关的问题来尝试：
- en: '[PRE19]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The following is the output that we receive:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们收到的输出：
- en: '[PRE20]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: As you can see, when I asked the agent something about Italy, it immediately
    invoked the provided document, while this was not done in the last question.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，当我向代理询问有关意大利的问题时，它立即调用了提供的文档，而在上一个问题中并没有这样做。
- en: The last thing we want to add to our GlobeBotter is the capability to navigate
    the web, since, as travelers, we want to have up-to-date information about the
    country we are traveling to. Let’s implement it with LangChain’s tools.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们最后想要添加到我们的 GlobeBotter 中的是导航网络的能力，因为作为旅行者，我们希望了解我们即将前往的国家最新的信息。让我们使用 LangChain
    的工具来实现它。
- en: Adding external tools
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 添加外部工具
- en: The tool we are going to add here is the Google SerpApi tool, so that our bot
    will be able to navigate the internet.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要添加的工具是 Google SerpApi 工具，这样我们的机器人就能在互联网上导航。
- en: '**Note**'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: SerpApi is a real-time API designed to access Google search results. It simplifies
    the process of data scraping by handling complexities such as managing proxies,
    solving CAPTCHAs, and parsing structured data from search engine results pages.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: SerpApi 是一个实时 API，旨在访问 Google 搜索结果。它通过处理诸如管理代理、解决 CAPTCHA 和从搜索引擎结果页面解析结构化数据等复杂性，简化了数据抓取的过程。
- en: LangChain offers a pre-built tool that wraps SerpApi to make it easier to integrate
    it within your agents. To enable SerpApi, you need to sign in at [https://serpapi.com/users/sign_up](https://serpapi.com/users/sign_up),
    then go to the dashboard under the tab **API key**.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 提供了一个预构建的工具，它封装了 SerpApi，以便更容易将其集成到您的代理中。要启用 SerpApi，您需要登录到 [https://serpapi.com/users/sign_up](https://serpapi.com/users/sign_up)，然后转到“API
    key”选项卡下的仪表板。
- en: Since we don’t want our GlobeBotter to be focused only on the web, we will add
    the SerpApi tool to the previous one, so that the agent will be able to pick the
    most useful tool to answer the question – or use no tool if not necessary.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们不希望我们的 GlobeBotter 只关注网络，因此我们将 SerpApi 工具添加到之前的一个中，这样代理就能选择最有用的工具来回答问题——或者在不必要的情况下不使用任何工具。
- en: 'Let’s initialize our tools and agent (you learned about this and other LangChain
    components in *Chapter 5*):'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们初始化我们的工具和代理（你已经在 *第五章* 中了解了这一点和其他 LangChain 组件）：
- en: '[PRE21]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Great, now let’s test it with three different questions (here, again, the output
    has been truncated):'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 太好了，现在让我们用三个不同的问题来测试它（这里，输出再次被截断）：
- en: “What can I visit in India in 3 days?”
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “在印度三天我能参观什么？”
- en: '[PRE22]'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: In this case, the model doesn’t need external knowledge to answer the question,
    hence it is responding without invoking any tool.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，模型不需要外部知识来回答问题，因此它是在不调用任何工具的情况下进行响应的。
- en: “What is the weather currently in Delhi?”
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “德里现在的天气是什么？”
- en: '[PRE23]'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Note how the agent is invoking the search tool; this is due to the reasoning
    capability of the underlying gpt-3.5-turbo model, which captures the user’s intent
    and dynamically understands which tool to use to accomplish the request.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 注意代理是如何调用搜索工具的；这是由于底层 gpt-3.5-turbo 模型的推理能力，它捕捉用户的意图并动态理解使用哪个工具来完成请求。
- en: “I’m traveling to Italy. Can you give me some suggestions for the main attractions
    to visit?”
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “我要去意大利旅行。你能给我一些建议，去哪些主要景点参观吗？”
- en: '[PRE24]'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Note how the agent is invoking the document retriever to provide the preceding
    output.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 注意代理是如何调用文档检索器来提供前面的输出的。
- en: Overall, our GlobeBotter is now able to provide up-to-date information, as well
    as retrieving specific knowledge from curated documentation. The next step will
    be that of building a front-end. We will do so by building a web app using Streamlit.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，我们的 GlobeBotter 现在能够提供最新信息，以及从精选文档中检索特定知识。下一步将是构建前端。我们将通过使用 Streamlit 构建一个网络应用来实现这一点。
- en: Developing the front-end with Streamlit
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Streamlit 开发前端
- en: Streamlit is a Python library that allows you to create and share web apps.
    It is designed to be easy and fast to use, without requiring any front-end experience
    or knowledge. You can write your app in pure Python, using simple commands to
    add widgets, charts, tables, and other elements.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: Streamlit是一个Python库，允许你创建和分享网络应用。它设计得易于使用且快速，无需任何前端经验或知识。你可以使用纯Python编写你的应用，使用简单的命令添加小部件、图表、表格和其他元素。
- en: In addition to its native capabilities, in July 2023, Streamlit announced an
    initial integration and its future plans with LangChain. At the core of this initial
    integration, there is the ambition of making it easier to build a GUI for conversational
    applications, as well as showing all the steps LangChain’s agents take before
    producing the final response.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 除了其原生功能外，2023年7月，Streamlit宣布了与LangChain的初始集成及其未来计划。在这个初始集成的核心中，有一个目标是使构建对话应用的GUI更容易，同时展示LangChain代理在生成最终响应之前所采取的所有步骤。
- en: To achieve this goal, the main module that Streamlit introduced is the Streamlit
    callback handler. This module provides a class called `StreamlitCallbackHandler`
    that implements the `BaseCallbackHandler` interface from LangChain. This class
    can handle various events that occur during the execution of a LangChain pipeline,
    such as tool start, tool end, tool error, LLM token, agent action, agent finish,
    etc.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这一目标，Streamlit引入的主要模块是Streamlit回调处理程序。该模块提供了一个名为`StreamlitCallbackHandler`的类，该类实现了LangChain的`BaseCallbackHandler`接口。这个类可以处理在LangChain管道执行过程中发生的各种事件，例如工具开始、工具结束、工具错误、LLM令牌、代理动作、代理完成等。
- en: The class can also create and update Streamlit elements, such as containers,
    expanders, text, progress bars, etc., to display the output of the pipeline in
    a user-friendly way. You can use the Streamlit callback handler to create Streamlit
    apps that showcase the capabilities of LangChain and interact with the user through
    natural language. For example, you can create an app that takes a user prompt
    and runs it through an agent that uses different tools and models to generate
    a response. You can use the Streamlit callback handler to show the agent’s thought
    process and the results of each tool in real time.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 该类还可以创建和更新Streamlit元素，如容器、展开器、文本、进度条等，以用户友好的方式显示管道的输出。你可以使用Streamlit回调处理程序创建展示LangChain功能的Streamlit应用，并通过自然语言与用户交互。例如，你可以创建一个应用，接受用户提示并通过使用不同工具和模型的代理生成响应。你可以使用Streamlit回调处理程序实时显示代理的思考过程和每个工具的结果。
- en: To start building your application, you need to create a `.py` file to run in
    your terminal via `streamlit run file.py`. In our case, the file will be named
    `globebotter.py`.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始构建你的应用，你需要创建一个`.py`文件，通过在终端中运行`streamlit run file.py`来运行。在我们的案例中，文件将被命名为`globebotter.py`。
- en: 'The following are the main building blocks of the application:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是应用的主要构建块：
- en: 'Setting the configuration of the webpage:'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置网页的配置：
- en: '[PRE25]'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Initializing the LangChain backbone components we need. The code is the same
    as the one in the previous section, so I will share here only the initialization
    code, without all the preliminary steps:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化我们需要的LangChain骨干组件。代码与上一节相同，所以这里我只分享初始化代码，不包括所有初步步骤：
- en: '[PRE26]'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Setting the input box for the user with a placeholder question:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为用户设置带有占位符问题的输入框：
- en: '[PRE27]'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Setting Streamlit’s session states. Session state is a way to share variables
    between reruns, for each user session. In addition to the ability to store and
    persist state, Streamlit also exposes the ability to manipulate state using callbacks.
    Session state also persists across apps inside a multipage app. You can use the
    session state API to initialize, read, update, and delete variables in the session
    state. In the case of our GlobeBotter, we want two main states: `messages` and
    `memory`:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置Streamlit的会话状态。会话状态是一种在用户会话之间共享变量的方式。除了存储和持久化状态的能力外，Streamlit还公开了使用回调操作状态的能力。会话状态在多页应用内的应用之间也是持久的。你可以使用会话状态API在会话状态中初始化、读取、更新和删除变量。在我们的GlobeBotter案例中，我们想要两个主要状态：`messages`和`memory`：
- en: '[PRE28]'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Making sure to display the whole conversation. To do so, I created a for loop
    that iterates over the list of messages stored in `st.session_state["messages"].`
    For each message, it creates a Streamlit element called `st.chat_message` that
    displays a chat message in a nice format:'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保显示整个对话。为此，我创建了一个for循环，遍历存储在`st.session_state["messages"]`中的消息列表。对于每条消息，它创建一个名为`st.chat_message`的Streamlit元素，以美观的格式显示聊天消息：
- en: '[PRE29]'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Configuring the AI assistant to respond when given a user’s query. In this
    first example, we will keep the whole chain visible and printed to the screen:'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 配置人工智能助手在接收到用户查询时做出响应。在这个第一个例子中，我们将保持整个链在屏幕上可见并打印出来：
- en: '[PRE30]'
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Finally, adding a button to clear the history of the conversation and start
    from scratch:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，添加一个按钮来清除对话历史并从头开始：
- en: '[PRE31]'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The final product looks as follows:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 最终产品看起来如下：
- en: '![A screenshot of a computer  Description automatically generated](img/B21714_06_02.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![计算机截图 自动生成的描述](img/B21714_06_02.png)'
- en: 'Figure 6.2: Front-end of GlobeBotter with Streamlit'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.2：GlobeBotter的Streamlit前端
- en: 'From the expander, we can see that the agent used the `Search` tool (provided
    with the SerpApi). We can also expand `chat_history` or `intermediate_steps` as
    follows:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 从展开器中，我们可以看到代理使用了`Search`工具（由SerpApi提供）。我们还可以按照以下方式展开`chat_history`或`intermediate_steps`：
- en: '![A screenshot of a computer  Description automatically generated](img/B21714_06_03.png)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![计算机截图 自动生成的描述](img/B21714_06_03.png)'
- en: 'Figure 6.3: Example of Streamlit expander'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.3：Streamlit展开器的示例
- en: Of course, we can also decide to only show the output rather than the whole
    chain of thoughts, by specifying in the code to return only `response['output']`.
    You can see the whole code in the book’s GitHub repository.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们也可以选择只显示输出而不是整个思维链，通过在代码中指定只返回`response['output']`。你可以在书籍的GitHub仓库中查看整个代码。
- en: 'Before we wrap up, let’s discuss how you can give your users a streaming experience
    while interacting with your chatbot. You can leverage the `BaseCallbackHandler`
    class to create a custom callback handler in your Streamlit app:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们结束之前，让我们讨论一下如何在用户与聊天机器人交互时提供流式体验。你可以在Streamlit应用中利用`BaseCallbackHandler`类创建一个自定义回调处理器：
- en: '[PRE32]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The `StreamHandler` is designed to capture and display streaming data, such
    as text or other content, in a designated container. Then, you can use it as follows
    in your Streamlit app, making sure to set `streaming=True` while initializing
    your OpenAI LLM.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '`StreamHandler`被设计用来捕获和显示流数据，如文本或其他内容，在指定的容器中。然后，你可以在你的Streamlit应用中使用它，确保在初始化你的OpenAI
    LLM时设置`streaming=True`。'
- en: '[PRE33]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: You can refer to the original code on LangChain’s GitHub repo at [https://github.com/langchain-ai/streamlit-agent/blob/main/streamlit_agent/basic_streaming.py](https://github.com/langchain-ai/streamlit-agent/blob/main/streamlit_agent/basic_streaming.py).
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在LangChain的GitHub仓库中查看原始代码。[https://github.com/langchain-ai/streamlit-agent/blob/main/streamlit_agent/basic_streaming.py](https://github.com/langchain-ai/streamlit-agent/blob/main/streamlit_agent/basic_streaming.py)。
- en: Summary
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we approached the end-to-end implementation of a conversational
    application, leveraging LangChain’s modules and progressively adding layers of
    complexity. We started with a plain vanilla chatbot with no memory, then moved
    on to more complex systems with the ability to keep traces of past interactions.
    We’ve also seen how to add non-parametric knowledge to our application with external
    tools, making it more “agentic” so that it is able to determine which tool to
    use, depending on the user’s query. Finally, we introduced Streamlit as the front-end
    framework to build the web app for our GlobeBotter.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了会话应用的端到端实现，利用LangChain的模块并逐步增加复杂层。我们从没有记忆的普通聊天机器人开始，然后转向更复杂的系统，能够追踪过去的交互。我们还看到了如何使用外部工具将非参数化知识添加到我们的应用中，使其更加“智能”，能够根据用户的查询确定使用哪个工具。最后，我们介绍了Streamlit作为前端框架来构建GlobeBotter的Web应用。
- en: In the next chapter, we will focus on a more specific domain where LLMs add
    value and demonstrate emerging behaviors, that is, recommendation systems.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将关注一个更具体的领域，其中LLMs能够增加价值并展示新兴行为，即推荐系统。
- en: References
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: Example of a context-aware chatbot. [https://github.com/shashankdeshpande/langchain-chatbot/blob/master/pages/2_%E2%AD%90_context_aware_chatbot.py](https://github.com/shashankdeshpande/langchain-chatbot/blob/master/pages/2_%E2%AD%90_context_aware_chatbot.py)
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 上下文感知聊天机器人的示例。[https://github.com/shashankdeshpande/langchain-chatbot/blob/master/pages/2_%E2%AD%90_context_aware_chatbot.py](https://github.com/shashankdeshpande/langchain-chatbot/blob/master/pages/2_%E2%AD%90_context_aware_chatbot.py)
- en: Knowledge base for the AI travel assistant. [https://www.minube.net/guides/italy](https://www.minube.net/guides/italy)
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人工智能旅行助手的知识库。[https://www.minube.net/guides/italy](https://www.minube.net/guides/italy)
- en: LangChain repository. [https://github.com/langchain-ai](https://github.com/langchain-ai)
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LangChain仓库。[https://github.com/langchain-ai](https://github.com/langchain-ai)
- en: Join our community on Discord
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们的Discord社区
- en: 'Join our community’s Discord space for discussions with the author and other
    readers:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 加入我们社区的 Discord 空间，与作者和其他读者进行讨论：
- en: '[https://packt.link/llm](https://packt.link/llm)'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/llm](https://packt.link/llm)'
- en: '![](img/QR_Code214329708533108046.png)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![](img/QR_Code214329708533108046.png)'
