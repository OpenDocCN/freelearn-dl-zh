- en: '3'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Identifying Optimal Use Cases for ChatGPT
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A use case is a description of the possible sequences of interactions between
    the system under discussion and its external actors, related to a particular goal.
  prefs: []
  type: TYPE_NORMAL
- en: '- Alistair Cockburn'
  prefs: []
  type: TYPE_NORMAL
- en: There is a wealth of explanations around writing use cases. I suspect we have
    all created something we call **use cases**. We will first clarify a robust definition
    for a use case to work from the same understanding. Then, we can go into examples
    within use cases to look for opportunities to insert generative AI into the mix,
    while considering where a ChatGPT integration might be challenging or where issues
    might arise. By the end of this chapter, you will be armed with the ability to
    take the research tools from [*Chapter 2*](B21964_02_split_000.xhtml#_idTextAnchor031),
    *Conducting Effective User Research* document use cases in this chapter, and be
    ready to prioritize use cases for a backlog in [*Chapter 4*](B21964_04.xhtml#_idTextAnchor085),
    *Scoring Stories*. Experts in use case development will benefit from learning
    how to apply ChatGPT to the use case process. I encourage all readers to be knowledgeable
    about use case development, as it is not just for designers!
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding use case basics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Aligning **large language models** (**LLMs**) with user goals
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Avoiding ChatGPT limitations, biases, and inappropriate responses
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding use case basics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'These five essential use case components have been consistent over the years:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Primary actor**: Who is the person or type of person who will use this case?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Preconditions**: What has to have happened for this use case to be used?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Triggers**: Why does this use case happen now?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The path**: The steps in the process and the system response to those steps.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Extensions**: Exceptions and variations to the primary path should be considered
    and accounted for in the process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to pick the proper use cases
  prefs: []
  type: TYPE_NORMAL
- en: I suggested Alistair Cockburn’s book in [*Chapter 2*](B21964_02_split_000.xhtml#_idTextAnchor031),
    *Conducting Effective User Research* as the best primer on use cases because he
    explains how to write them effectively. We should also be sensitive when picking
    the proper use cases. It’s possible to write a well-formed use case that does
    not represent significant business value. Cockburn’s book covers the proper construction
    of use cases and provides examples. Consider printing out the one-page summary
    from [*Chapter 1*](B21964_01.xhtml#_idTextAnchor016), *Recognizing the Power of
    Design in ChatGPT*. It has plenty of great suggestions to help write accurate
    use cases.
  prefs: []
  type: TYPE_NORMAL
- en: 'Book: [Writing Effective Use Cases](https://amzn.to/3YnbGSp) ([https://amzn.to/3YnbGSp](https://amzn.to/3YnbGSp))'
  prefs: []
  type: TYPE_NORMAL
- en: 'Book (PDF): [Writing Effective Use Cases](https://www-public.imtbs-tsp.eu/~gibson/Teaching/Teaching-ReadingMaterial/Cockburn00.pdf)
    ([https://www-public.imtbs-tsp.eu/~gibson/Teaching/Teaching-ReadingMaterial/Cockburn00.pdf](https://www-public.imtbs-tsp.eu/~gibson/Teaching/Teaching-ReadingMaterial/Cockburn00.pdf))'
  prefs: []
  type: TYPE_NORMAL
- en: Use case or user stories
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Some people have heard of **user stories**, and the overlap with use cases is
    significant. User stories are typically more general and treated as a narrative.
    As we explained in [*Chapter 2*](B21964_02_split_000.xhtml#_idTextAnchor031),
    *Conducting Effective User Research* we tell an actual story with the storyboard
    cartoon. At the same time, a use case is more descriptive of the interactions.
    Storytelling can set the mood and integrate the context and actor, while the use
    case defines this upfront. Writing a story from a use case is easier because what
    should happen and the order of events is known. Going from a user story to a use
    case is more complex because of the need to address the details of each step.
    The focus here is on the use case approach to provide details to estimate and
    understand the value of the interactions and the engineering effort needed to
    address the problem. It would be easier to ask ChatGPT to create a story from
    a use case than to make the use case from the story.
  prefs: []
  type: TYPE_NORMAL
- en: We can create use cases and use the process to identify steps suitable for ChatGPT.
    We can also learn enough about when not to apply ChatGPT.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s a step-by-step guide:'
  prefs: []
  type: TYPE_NORMAL
- en: Understand how to write compelling use cases.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Identify the use cases and any needed user stories.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Break down the use cases into steps.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Identify places in those steps where ChatGPT can provide support (and where
    it would not be suited).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Work with the development team to explore the value of ChatGPT to solve specific
    steps in the problem. Prioritize the ones with the most value and least cost (more
    on this in the next chapter).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Ignore problems that are not well suited to ChatGPT.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We will use a sample use case to explore how to include ChatGPT in the process.
    First, we can review how ChatGPT might be engaged within the use case.
  prefs: []
  type: TYPE_NORMAL
- en: Establishing a baseline with ChatGPT
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Considering all the activities customers do and even within the company for
    employees, this can add up to many existing use cases. Some will be ripe for improvement
    by integrating a generative solution such as ChatGPT. Conversely, avoid applying
    ChatGPT when it is of limited or no value.
  prefs: []
  type: TYPE_NORMAL
- en: Throughout the book, we cover different ways of understanding what ChatGPT will
    be good at and what it won’t. Because we expect solutions to merge enterprise
    data with one or more generative models (and some specific models, as discussed
    in [*Chapter 6*](B21964_06_split_000.xhtml#_idTextAnchor134), *Gathering Data
    – Content is King*, are better at particular tasks), it is good to understand
    what it can and can’t do.
  prefs: []
  type: TYPE_NORMAL
- en: In this context, there might be a chat interaction, recommendation UI, enterprise
    workflow, or even a backend solution, but ChatGPT might only apply part of the
    problem. ChatGPT was asked what it was good at and provided the results in *Table
    3.1*.
  prefs: []
  type: TYPE_NORMAL
- en: '| **Good At** | **Not** **Good At** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '**Guidance through** **logical processes**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Breaking down complex procedures** **into steps**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Providing explanations** **and examples**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Adapting responses to** **user queries**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Tailoring guidance to** **specific needs**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Structuring and** **explaining workflows**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Assisting with troubleshooting** **and tasks**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Offering** **personalized assistance**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: Real-time interaction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Controlling physical devices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Highly specialized knowledge
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rapidly changing information
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sensitive or controversial topics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Nuanced emotional or interpersonal dynamics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Providing professional advice or judgment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: Table 3.1 – ChatGPT’s opinion of its capabilities
  prefs: []
  type: TYPE_NORMAL
- en: This book covers some of these items from *Table 3.1*. Challenging areas like
    sensitive, emotional, or relationship advice are only briefly addressed. Most
    enterprise solutions will need to handle the problem of specialized knowledge
    by using a model that can be adapted to support enterprise knowledge. We will
    cover this in subsequent chapters. Even ChatGPT fails to explain that more value
    might be gained from applying ChatGPT at a process step, optimized and tuned to
    do one specific task in a sequence. ChatGPT doesn’t have to do everything (as
    we say, don’t *boil the ocean*). That is the beauty of creating a use case to
    break down a process into a series of steps. It is easier to compare step details
    to the capabilities of ChatGPT.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s take an example. Customers commonly deploy patches or firmware updates
    for a variety of products. A mobile phone gets regular updates, and enterprise
    software gets patched, even in the cloud. In the cloud, consumers rarely see this
    as patching is done behind the scenes, typically without an outage for critical
    systems. Someone is working on this problem on our behalf. With personal devices
    such as phones, TVs, and even a toaster, the user manages the process: download
    software updates, schedule it for later (maybe while sleeping), or pick and choose
    when and what update to take. For the enterprise, there might be dozens of patches
    and updates to take and test before deploying them. This is the big brother version
    of updating a phone.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example use case of a simplified enterprise system consisting of
    a step, intent, and system response (processes for patching can be far more complex
    because of customization, integrations, and legal or regional requirements):'
  prefs: []
  type: TYPE_NORMAL
- en: '**Primary actor**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: System administrator, patch manager, or by operations
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Preconditions**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The user is signed into the system
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The software patches are available
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Triggers**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recommended available patch details are emailed to the actor
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following section will expand on this basic patching use case by identifying
    where ChatGPT can be applied. This is brainstorming: find opportunities in the
    use case where gaps exist and identify what ChatGPT can do for customers at each
    step.'
  prefs: []
  type: TYPE_NORMAL
- en: Example use case for a ChatGPT instance – patching software
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This use case is for a traditional graphical user interface. Even in a single
    use case, there might be multiple applications of a generative enhancement to
    adapt the **user experience** (**UX**). We consider the mantra that *the best
    user interface is no user interface*. Though an overarching goal might be to automate
    everything, for this example, we presume a complex scenario where human interaction
    is necessary. But automation of steps along the journey is possible.
  prefs: []
  type: TYPE_NORMAL
- en: We can expand the details of an enterprise patching example. Large enterprises
    frequently manage their software deployments. Even offloading this work to the
    cloud just transitions the problem to the cloud service provider. The problem
    is still the same for those vendors. This software is 100 times more complex than
    our personal updates, containing 1,000 to 10,000 possible patches, with hundreds
    of instances of that software running in various departments and on multiple development,
    test, and staging servers. Knowing precisely what is patched and how that might
    impact the computers becomes essential. It is a complex and time-consuming process.
    This is partially why we see so many security breaches in the news. It is not
    because the software is insecure but because the processes are complex and fraught
    with possible error. In most cases, vendors have already provided patches to fix
    security issues, sometimes years earlier. Companies are reluctant to patch because
    of the complexity and sometimes the risk involved in bringing down a piece of
    software, which means their systems are vulnerable.
  prefs: []
  type: TYPE_NORMAL
- en: Here is a simplified version of this complex process to help us work with this
    use case. Notice how each step in *Table 3.2* resolves to actions or experiences
    that the system needs to address. UI will be designed from this use case, but
    *we are not defining the UI in the use case*. The high-level needs of each step
    are documented. There are better times to determine the exact information, layout,
    and details for patching with the UI design. There is an entire flow and details
    just for the patch detail’s view; the primary use case does not cover this. The
    same would be said for the plan concept introduced in *Step 3*. A plan is a collection
    of patches we can test and deploy simultaneously. A plan would have more than
    just the name. A separate use case can help define the metadata for the plan (who
    has worked on it, dates, contents, state, and deployment details). Review the
    steps in the use case to understand the types of interactions we might need to
    handle at each phase. This use case is about viewing patch recommendations, deciding
    which patches to include in a plan, and then scheduling and deploying those patches.
    Based on our understanding of what ChatGPT is good at, we can think about how
    it might help us in these steps.
  prefs: []
  type: TYPE_NORMAL
- en: The last column of the table identifies opportunities for ChatGPT. For those
    more experienced with use cases, there are extensions to this use case that address
    conditions that are not typical but expected at each step. I have removed and
    placed extensions to this use case in *Table 3.3* to make it easier to read. Know
    that there are many ways of presenting a use case. This is just the one we used
    for convenience.
  prefs: []
  type: TYPE_NORMAL
- en: '| **Step** | **Description** | **System responsibility** | **ChatGPT opportunities**
    |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| **1** | Recommended patches are shown. | Displays the patch recommended for
    the system. | Make better recommendations from existing patches and known bugs.
    |'
  prefs: []
  type: TYPE_TB
- en: '| **2** | The user selects one or many of the recommendations. | Displays details
    about the patch and options available. | Recommend collections of patches that
    work well together. |'
  prefs: []
  type: TYPE_TB
- en: '| **3** | The user reviews and selects recommendations to add to the plan.
    | Patches are added. Completion of the task is communicated. The plan updates.
    |  |'
  prefs: []
  type: TYPE_TB
- en: '| **4** | The user repeats the review process until all patch decisions are
    completed. | Display details, updates, and the number of patches in the plan.
    |  |'
  prefs: []
  type: TYPE_TB
- en: '| **5** | The user starts the plan. | Take the user to the plan. |  |'
  prefs: []
  type: TYPE_TB
- en: '| **6** | The user reviews the plan, checking for conflicts and issues. | Displays
    the plan contents and status. A conflict check is run. | Predict the results of
    the patch plan, and the implications for missing or conflicting patches. |'
  prefs: []
  type: TYPE_TB
- en: '| **7** | The user deploys the plan on a test instance. | The system allows
    the selection of a test instance. |  |'
  prefs: []
  type: TYPE_TB
- en: '| **8** | Run evaluation of test instance. | *(Results and feedback are not
    in scope for* *this example.)* | Generate tests from existing cases. Identify
    gaps in testing. |'
  prefs: []
  type: TYPE_TB
- en: '| **9** | Adjust and evaluate the plan based on test results. | *(Cycle through
    previous steps with a new plan and track the versioning of* *the plan.)* |  |'
  prefs: []
  type: TYPE_TB
- en: '| **10** | Schedule to deploy on the production instance. | Schedule and notify
    the user of success or failure. | Make deployment recommendations. |'
  prefs: []
  type: TYPE_TB
- en: '| **11** |  | *Patches deployed; system available at new* *patch state.* |
    Generate test case. Identify possible issues. |'
  prefs: []
  type: TYPE_TB
- en: '| **12** | Schedule and deploy to other instances. | *Add more instances to
    a plan, such as* *production instances.* | Monitor for abnormalities. |'
  prefs: []
  type: TYPE_TB
- en: Table 3.2 – An example use case for a patching system
  prefs: []
  type: TYPE_NORMAL
- en: The primary use cases have multiple places with opportunities to insert ChatGPT.
    If there is a wealth of data on what patches have been installed and the resulting
    tickets from those versions and releases, a model can be trained to suggest a
    collection of patches that work better together. The LLM can propose a patch plan
    or at least find issues that could result in a conflict or alternative collections
    of patches that resolve a conflict. This model could be used before, during, and
    after the process. This is by no means trivial. It is just an opportunity suited
    to ChatGPT; it is good at providing examples and test cases. After the fact, different
    data from monitoring software performance could be used to train ChatGPT to understand
    or even predict abnormal conditions. Patching, testing, and monitoring can have
    different training models with varying prompts, APIs, and results. In this case,
    uses of the LLM are identified in the table. We break down the steps to a level
    of detail so that it is easier to imagine a LLM solution. It still might be significant
    work to make it happen, but the problem is constrained. It can be evaluated to
    see if there is valuable data that will allow the model to perform successfully.
  prefs: []
  type: TYPE_NORMAL
- en: A case study in [*Chapter 6*](B21964_06_split_000.xhtml#_idTextAnchor134), *Gathering
    Data – Content is King* presents an example of deploying a dozen tuned models
    to perform specific tasks in a life cycle. Each step of the process uses a different
    model. In this case, some patch recommendation steps might not be exposed directly
    to the customer but be used by other models to refine or support suggestions to
    the customer.
  prefs: []
  type: TYPE_NORMAL
- en: Additional sequences that supplement the process or are not the likely path
    are called **extensions** to the use case; some extensions are included in *Table
    3.3*. Usually, the primary flow is the **happy path**, which most people are likely
    to follow to achieve success. Extensions supplement the happy path with other
    necessary functionality. *The happy path is not the only path*. A robust enterprise
    design must consider edge cases, error conditions, slow connectivity and performance
    bottlenecks, accessibility, internationalization, and other issues.
  prefs: []
  type: TYPE_NORMAL
- en: In this case, there are a few extensions to point out. Adding to a plan is standard
    and typical, but without any plans, the first thing that happens (even if automated)
    is a new plan, which would be created like a new folder on a desktop. On a computer,
    the folder is created as `untitled`. A well designed system automatically selects
    that text so the user can immediately type and name it. The use case does not
    describe the behavior at this level. This is good, a product manager can deliver
    the use case, and the designer can pick this up and develop the UX design. Based
    on the main flow and general understanding of ChatGPT capabilities, there are
    places where ChatGPT might be included to offer entire plans or make suggestions
    to resolve conflicts.
  prefs: []
  type: TYPE_NORMAL
- en: '| **Step** | **Description** | **System responsibility** | **ChatGPT opportunities**
    |'
  prefs: []
  type: TYPE_TB
- en: '| 3a | Create and name a new plan. | Create a new plan. Selected patches are
    added to the new plan. Message response for the completion of the task and a link
    to the plan. |  |'
  prefs: []
  type: TYPE_TB
- en: '| 3b | The user selects an existing plan and adds recommendations. | Plan is
    updated and displayed with new details. | Suggest plans that might overlap. |'
  prefs: []
  type: TYPE_TB
- en: '| 6a | The user is notified of a conflict. | Take the user to a conflict resolution
    step. | Offer suggestions to resolve conflict. |'
  prefs: []
  type: TYPE_TB
- en: '| 6a1 | The user saves as a named plan (useful to apply the same plan to other
    instances). | Save a unique named plan. |  |'
  prefs: []
  type: TYPE_TB
- en: '| 10a |  | Alert the user to deprecated patches; the patch cannot be deployed.
    | Offers suggestions. |'
  prefs: []
  type: TYPE_TB
- en: Table 3.3 – Extensions to the patching use case
  prefs: []
  type: TYPE_NORMAL
- en: Suppose data about what patches have been installed in the field and resulting
    trouble tickets from those versions and releases are available. In that case,
    a model can be trained to suggest a collection of patches that will work together.
    The model can recommend a patch plan or suggest an alternative patch collection
    that resolves a conflict. Conflicts are patches that don’t play well with other
    patches. This is by no means trivial. It is just an opportunity that is suited
    to ChatGPT.
  prefs: []
  type: TYPE_NORMAL
- en: Prioritizing use cases based on usage and value – human resource example
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It is critical to understand the importance of every flow. If 10 or 20 flows
    each have five or ten percent of usage, these flows represent almost all usage.
    However, if primary flows represent only a tiny portion of the interactions, this
    is called the **long-tail effect**. If some flows and paths serve few people and
    are infrequently used, there will be a long-tail distribution for these flows.
    This means that any single flow will only have a small impact on the user community.
    When there are a few cases representing most interactions, improvements to these
    flows or tasks have more value than those with little usage. Long-tailed use cases
    will not improve the customer experience as dramatically as the ones with the
    most use. The difference in value between these can be quantified. And if the
    cost of developing one with the most use is the same as the one with the least
    use, the choice is obvious. This will be explained in [*Chapter 4*](B21964_04.xhtml#_idTextAnchor085),
    *Scoring Stories*.
  prefs: []
  type: TYPE_NORMAL
- en: A common distribution (for the statistic geeks, this looks similar to a one-tail
    normal distribution; real-world data doesn’t always look exactly like a normal
    curve) looks something like *Figure 3**.1* by sorting use cases most frequently
    used to least frequent. This dataset is from a human resource (HR) system, so
    it is not a perfectly smooth distribution. In this example, the few top cases
    represent the most usage (like the 80/20 rule). In this case, 80% of the usage
    comes from 20% of the features or capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B21964_03_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.1 – A typical one-sided distribution, a few cases have the most impact
  prefs: []
  type: TYPE_NORMAL
- en: Fewer big-ticket use cases appear in a long-tailed distribution, which extends
    further into the less frequently used use cases, as demonstrated in *Figure 3**.2*.
    It takes more than 40% of the use cases to get to 80% of the usage.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B21964_03_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.2 – An example of a distribution with a long tail – many cases have
    similar usage
  prefs: []
  type: TYPE_NORMAL
- en: Prioritizing based on the 80/20 rule – Amazon shopping
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Features on Amazon.com are something we can explain with no introduction. This
    shopping website has features that represent an 80/20 distribution. Features such
    as searching for a product, adding it to a cart, and checking out represent the
    majority of use. Small features make up the rest, such as creating a wish list,
    registering for an account, or adding a new address. However, if you switch perspectives
    to looking at products, the most popular product would be less than one percent
    of sales. Even popular products based on search traffic, such as the Apple Watch,
    Crocs, AirPods, air fryers, and iPads, might total six million searches, but they
    represent the top of a long tail of product searches. Compared to the volume of
    searches of over 200 million, even the top seller is not even one percent of sales.
    This is a long tail. This article discusses these five search terms out of over
    274,000 keyword searches to make the long-tail problem appear even more impressive.
  prefs: []
  type: TYPE_NORMAL
- en: Article [Top 100 most searched items on Amazon](https://www.semrush.com/blog/most-searched-items-amazon/)
    ([https://www.semrush.com/blog/most-searched-items-amazon/](https://www.semrush.com/blog/most-searched-items-amazon/))
  prefs: []
  type: TYPE_NORMAL
- en: The Amazon example demonstrates that the most value will likely be derived from
    a few features (like the add-to-cart function). Likewise, focusing on content
    (like items to purchase at Amazon) might create a long-tail problem. In either
    case, if AI is added for something on the *right* of the curve, it will provide
    less value than something on the *left*.
  prefs: []
  type: TYPE_NORMAL
- en: Returning to *Figures 3.1 and 3.2,* we can apply the Amazon example to the HR
    data. Notice that the *Absence Balance* item (about vacation time remaining for
    the employee) has almost 350 interactions in *Figure 3**.1*. It would only be
    over 250 in a long tail (*Figure 3**.2*). No one use case stands out in a long
    tail situation. Spending the same effort on this use case in a long-tail environment
    would return a different reward.
  prefs: []
  type: TYPE_NORMAL
- en: It is helpful to know the distribution of use. A more normal distribution means
    value will likely come from improving a few critical use cases, while the long
    tail means the impact will be more challenging without covering more use cases.
  prefs: []
  type: TYPE_NORMAL
- en: But even small cases can be relevant. Signing up customers is a small use case
    by frequency compared to the usage after registration. Still, no one would argue
    that getting signups correct and reducing friction in the process isn’t essential.
    Now that we have covered use cases, we can still consider the impact of a user
    story.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a user story from a use case
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Recall that the concept of use cases and user stories overlap. The form is
    different. Let’s switch back to the patching example. It provides a robust set
    of steps that afford various opportunities for applying ChatGPT. Running ChatGPT
    on the user story from *Table 3.1* produced the story accompanying the use case:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The ChatGPT response to this use case was as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: This generated story from ChatGPT was not edited in any way (grammar errors
    included). I want to use this to make a few points. First, ChatGPT has value in
    our design process. This story is creative and enchanting and could be customized
    further, giving more directions in the prompt to match a specific style and tone.
    Second, it is easy to go from a use case to a user story, even though editing
    the output may be necessary. This could be provided to a cartoon or sketch artist
    to develop the storyboards for an engaging marketing spin. Additional ChatGPT
    refinements could be made to flush out the story beyond the happy path. It could
    be asked to break down the story into eight storyboard cells that would be more
    readily visualized as a storyboard.
  prefs: []
  type: TYPE_NORMAL
- en: It would be best to recognize that it is easier to identify opportunities for
    ChatGPT using the step-by-step approach in the use cases than in this storytelling
    format. The audience for a user story is different. The use case has details that
    the development team needs, but the story is for upper management, other teams,
    and marketing.
  prefs: []
  type: TYPE_NORMAL
- en: Prioritizing ChatGPT opportunities from the use case
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This patching example is useful because there is an actual cost to apply a ChatGPT
    solution at every step, including design and development, and the actual cost
    to run production, stage, and test LLMs. Don’t expect to deploy ChatGPT in all
    these opportunities, so in *Table 3.4*, let’s re-list the steps identified as
    places for ChatGPT support and score each to see which can unlock the most value
    for customers. The team can then spend the time and money on the most valuable
    steps.
  prefs: []
  type: TYPE_NORMAL
- en: Each of these possible stories is scored on three metrics. [*Chapter 4*](B21964_04.xhtml#_idTextAnchor085),
    *Scoring Stories* teaches **User Need Scoring**, the product of the three scores.
    The higher the score, the more value to the customer. In the next chapter, we
    will also factor in the development cost. From this analysis, we have three stories
    with the most value.
  prefs: []
  type: TYPE_NORMAL
- en: '| **Steps Identified for** **ChatGPT Support** | **A** **Customers Impacted**
    **(1** **to 3)** | **B Frequency** **of Need** **(1** **to 3)** | **C Severity**
    **of Issue** **(1** **to 4)** | **User Need Score (****A*B*C)** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| **Step 1: Make better recommendations from existing patches and** **customer
    bugs.** | 2 | 1 | 3 | 6 |'
  prefs: []
  type: TYPE_TB
- en: '| **Step 2: Recommend collections of patches that work** **well together.**
    | 2 | 1 | 3 | 6 |'
  prefs: []
  type: TYPE_TB
- en: '| **Step 6: Predict the results of the patch plan, and the implications for
    missing or** **conflicting patches.** | 2 | 1 | 4 | 8 |'
  prefs: []
  type: TYPE_TB
- en: '| **Step 8: Generate tests from existing cases. Identify gaps** **in testing.**
    | 2 | 1 | 2 | 4 |'
  prefs: []
  type: TYPE_TB
- en: '| **Step 10: Make** **deployment recommendations.** | 2 | 1 | 1 | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| **Step 11: Generate tests from existing cases. Identify gaps** **in testing.**
    | 2 | 3 | 2 | 12 |'
  prefs: []
  type: TYPE_TB
- en: '| **Step 12: Monitor** **for abnormalities.** | 2 | 1 | 4 | 8 |'
  prefs: []
  type: TYPE_TB
- en: Table 3.4 – Opportunities for ChatGPT within the UX (top two items are bold)
  prefs: []
  type: TYPE_NORMAL
- en: Let me break down the scores. All of these stories impact the same number of
    customers. Only some of our customers do patching, so we ranked this a two on
    a three-point scale. Three is the highest and is reserved for tasks that most
    customers do. It is not surprising that patching is done infrequently. Individuals
    update their phones a few times a year; enterprise customers are more hesitant
    to update. Each of these steps is done about the same number of times and typically
    done quarterly, so the frequency of this need is a 1 (again, on a 3-point scale
    where a two would be most of the time, while a three would be all the time). But
    test cases are different. It is an ongoing process, so it scores a 3 on the Frequency
    scale. It is also the one place to catch potential problems before a customer
    encounters them.
  prefs: []
  type: TYPE_NORMAL
- en: The significant differences in the user score come from the severity. Think
    of this as the inverse of bug severity. A severity 1 bug is a big deal in most
    companies. Everyone should agree that this needs to be fixed now, and it should
    be scored the highest, so it is 4 points. A 3 would be a significant problem,
    while a 2 is not so much, and a 1 is the least severe issue (typically a severity
    four bug).
  prefs: []
  type: TYPE_NORMAL
- en: We document the explanations of the scores so multiple people will learn the
    process and be able to score similar problems. Since scores range from 1 to 4
    points, it keeps the explanations and scoring simple. We want people to be able
    to repeat scores, share, and learn a common method. Teams develop more complex
    processes, which can also get in the way. This is discussed in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: The list can be prioritized based on these scores and values. We will explain
    in depth how to score stories and, importantly, how to incorporate engineering’s
    cost into developing these solutions. We can continue our journey knowing we have
    at least three stories (within *Steps 6, 11*, and *12*) with significant user
    value. We will use these same stories in *Chapter 4*, *Scoring Stories* to explain
    scoring in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: So, we started with an easy example. I am an expert in this space, making this
    example easy to explain. Business expertise is critical to solve problems with
    LLMs. If you are not the expert, create a team that balances customer empathy
    with business expertise.
  prefs: []
  type: TYPE_NORMAL
- en: This patching case is a known set of tasks, and we could quickly identify where
    ChatGPT solutions might fit. But what about when it takes more work? You may have
    to explore or do research to determine the best fit. Where do the use cases come
    from? Whose goals are we trying to achieve? Do you know enough to recognize where
    ChatGPT should be considered? Challenging questions. I recommend becoming an expert
    in your product area. The more known about the product or service, the more the
    user’s goals are understood, and the better ChatGPT capabilities are understood,
    the easier it will be to recognize opportunities and solutions. Each new version
    of ChatGPT is different and can cause changes in the plans. As we will explore
    in [*Chapter 6*](B21964_06_split_000.xhtml#_idTextAnchor134), *Gathering Data
    – Content is King*, different models can be used for other tasks. We can’t say
    which model is better; this changes every few months.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s examine how to define those goals. Remember that these are the user’s
    goals, not the organization’s needs.
  prefs: []
  type: TYPE_NORMAL
- en: Aligning LLMs with user goals
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s say we have a customer or role in mind and want to define their goal.
    This book concerns the user’s goals, not marketing, engineering, or sales. It
    is up to product leaders to figure out valid user goals and how valuable the goal
    is to the overall product. Viability is also essential and typically provided
    by engineering. Compelling use cases can come from anywhere; the head of the company
    might have a vision, a customer could complain, the product manager gets an idea
    from a customer, the QA engineer recognizes a shortcut, user researchers uncover
    a critical workaround, or designers imagine a solution to a pain point for customers.
    Be less concerned with who comes up with the solution and more focused on how
    much value it provides. Don’t get hung up on which vendors LLM is needed. As OpenAI
    and the industry evolve, a broad range of models with specific capabilities and
    costs will be available. This fit-to-purpose allows building solutions with a
    suite of LLMs in one product.
  prefs: []
  type: TYPE_NORMAL
- en: Applications of ChatGPT
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There is a world of solutions waiting to be solved. In the space of enterprise
    solutions, there are solutions that ChatGPT can help with. Let’s throw out a collection
    of use cases that can be improved with ChatGPT in the mix. Don’t be shy; ask ChatGPT
    for suggestions specific to the business. Drill down into detail with it. The
    process might not highlight what is most important for the company, but generating
    ideas starts the process. Having an extensive collection of ideas is okay, but
    use the skills provided to prioritize based on value.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you draw on what others have done with ChatGPT, it is essential to understand
    if they have done it *well*. Here are some areas that ChatGPT can handle. There
    are thousands of ideas out there worth exploring. Use this to spur some thinking.
    Rethink these examples into your company’s business and practice. Consider the
    following ideas to help with a brainstorming session:'
  prefs: []
  type: TYPE_NORMAL
- en: Finding critical information in an extensive knowledge base for specific solutions
    for specific versions of products.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Offering suggestions to sales reps on what factors help close customer deals.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Diagnosing service issues, walking customers through the steps to resolve, sending
    repair agents into the field when all else has failed, following up with changes
    to the service appointment, and closing the request when completed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Consider if other modes of interaction, vision-based analysis, monitoring for
    sounds, or sensor data (temperature, pressure, air quality, proximity, light,
    vibration, optical, level, motion, or speed) support a process, a recommendation,
    or a coaching opportunity.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recommending products and solutions based on previous purchase cycles (in the
    loop directly with the customer or as a support angle for a sales rep).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Translating for world languages to broaden support channels.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generating code, autocomplete for tasks, and regression test suite creation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Helping to file human resources (HR), finance, accounting, service, sales, and
    other requests or forms. Expense reports, end-of-month balance sheets, service
    tickets, sales orders, vacation requests, or helping to match candidates to jobs
    (it can’t be worse than the tools out there today).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Validating and ensuring contract conditions are met before completing a transaction
    using blockchain.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Brainstorming with a user to explore and diagnose alternatives to problems.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summarizing, drafting, writing, or editing material.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: HR has many use cases around scheduling interviews, coaching new employees,
    helping to write job descriptions, analyzing exit interviews for reasons for leaving,
    determining the best employee to coach new employees (watch out for bias), and
    detecting bias in those processes. HR is always doing surveys that can be analyzed
    with LLMs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Financials is a hot area – forecasting, market trends, and advice based on spending
    patterns, goals, and tolerance. Some company financial reports, daily stock prices,
    and volatility commentary are already autogenerated.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Many of these could be handled by a 24/7 virtual assistant who supports the
    business and supplements or replaces trivial and simple human-agent interactions.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s pull a random company out of a hat and see the wealth of AI possibilities.
    I picked the 2,000th largest company in the world (so we are inclusive of large
    enterprise companies of many sizes). This search landed on The Gap, an iconic
    retail organization that sells clothes via many brands, such as Old Navy, The
    Gap, Athleta, Banana Republic, and Intermix. It is at the end of the Forbes 2000
    list of global companies. Let me give an example of how to brainstorm with ChatGPT
    by generating a prompt to help brainstorm
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: I have truncated the descriptions, except for the last one, to show how it framed
    the user benefit. Run this exercise for your business and see the results.
  prefs: []
  type: TYPE_NORMAL
- en: 'In-Store Customer Assistance: Implement ChatGPT-powered kiosks or mobile apps….'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Virtual Fitting Rooms: Develop a virtual fitting room(to)receive personalized
    recommendations….'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Returns and Exchanges Assistance: …responses to common return and exchange
    inquiries….'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Personalized Product Recommendations: …analyze customer preferences based on
    past purchases, browsing history, and interactions to generate personalized product
    recommendations….'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Live Chat Support: …provide instant responses to customer inquiries….'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Fashion Advice and Styling Tips: …customers can input their preferences, body
    type, and occasion, receiving personalized styling tips….'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Supply Chain Transparency: …provide real-time updates to customers about (order)
    status….'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Customer Feedback and Surveys: (collecting) customer feedback and conducting
    surveys….'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Multilingual Support: …provide support and assistance to customers in various
    languages….'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'AI-Powered Visual Search: search for products using images, enabling them to
    quickly find similar items or complete looks….'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Customized Loyalty Programs: Utilize ChatGPT to analyze customer data and behavior
    patterns to create customized loyalty programs and incentives tailored to individual
    customers, rewarding them for their engagement and purchases, and fostering brand
    loyalty.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Integrating ChatGPT into these use cases will not only streamline various aspects
    of your business operations and significantly enhance the overall customer experience,
    driving customer satisfaction, retention, and, ultimately, revenue growth.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We could continue. It did a great job exploring opportunities for ChatGPT. These
    examples benefit from what ChatGPT is good at. When good enterprise data is passed
    to an LLM with content and intelligent control via prompting and security, it
    can deliver value at many customer engagement steps. [*Chapter 6*](B21964_06_split_000.xhtml#_idTextAnchor134),
    *Gathering Data – Content is King* explores bringing enterprise data into the
    fold.
  prefs: []
  type: TYPE_NORMAL
- en: When doing competitive research, it might be clear that other companies are
    building similar LLM solutions, and it could be a game of catch-up. For example,
    clothing recommendations will be the norm. A company must have this in the future.
    In any of these deployments for cloth recommenders, there will be failures. Most
    failures will come from not caring and feeding the LLM; some will fail because
    they picked the wrong use case, and a few will fail, likely because LLMs are imperfect.
    Active monitoring, iterative design, and fine-tuning are staples of success and
    will help avoid failure. We will take all of [*Chapter 9*](B21964_09_split_000.xhtml#_idTextAnchor190),
    *Guidelines and Heuristics* to discuss monitoring to ensure an understanding of
    success and future improvements. We will draw on these earlier chapters to refine
    and improve. Stay tuned. I hope we instill the idea that not *every* problem is
    solved with ChatGPT. Focus on the most valuable pieces of a problem that can be
    delivered sooner.
  prefs: []
  type: TYPE_NORMAL
- en: Examples of generative AI outside of chat
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Try to think outside of the box. Great ideas can always come from very different
    fields. We have Velcro® because an engineer noticed the burrs that clung to his
    clothes after a walk with his dog (in 1941), Post-it® notes because of a failed
    attempt by Spencer Silver to create a super-strong adhesive (in 1968), and Super
    Glue® by Dr. Harry Coover, at Eastman Kodak (in 1942), from a failed attempt to
    create a clear plastic. So, it is always good to think outside of the box. I always
    suggest looking at problems in the context of the whole business. Sometimes, we
    get caught solving issues in the weeds when we need to look up and see the entire
    forest. As I mentioned with the patching example, sometimes the solution is to
    remove the UX and automate the whole practice. That is the ultimate simplification.
    This list of innovations that ChatGPT can address grows every day. However, I
    put these out here because they might connect experiences and the company’s needs.
    Innovation can come from anywhere. Could any of these widely varying spaces help
    in a quest for solutions? Let’s see:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Vision analysis of objects for detection, sorting, counting, or analyzing**:
    Are there inventory, shipping, handling, or retail issues? Amazon has already
    implemented stores where customers put stuff in shopping bags in their cart (or
    take it out when they change their mind), the store calculates the cost, and they
    walk out the door. There is no checking out.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Image creation for the visual arts, marketing, or social media**: Although
    this space is much bigger than the example, an artist, with prompting, can generate
    images without licensing issues for media. There might be issues with LLMS training
    on unlicensed material. Something we will discuss later.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Musical composition**: I am impressed by how ChatGPT calls Mathematica to
    create a note-for-note melody. I can’t speak to how catchy the jingles might be…'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**System simulation and testing**: It is very trendy to create virtual simulations
    of processes or building of buildings (we hear the term digital twin), so look
    to see places to use ChatGPT to simulate or test conditions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Prototyping and user interface design**: This was the book we should write,
    but I didn’t think the world was ready for it. Use the models as tools. Someone
    out there will write this book for us.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Drug discovery**: Google it. If drug companies can search for new compounds
    based on research and results, I bet a goldmine is in enterprise data. Mine it.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Finding new solutions to age-old problems**: With the right tools and framework,
    a generative solution can solve problems with unknown answers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We have plenty of uses for ChatGPT, but it will not always be the right solution.
    Here are some places where ChatGPT might not be the best fit.
  prefs: []
  type: TYPE_NORMAL
- en: Avoiding ChatGPT limitations, biases, and inappropriate responses
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A puzzle piece might not fit a puzzle because it is from a different puzzle.
    We love to take a new tool and apply it to every solution. A hammer has a lot
    more uses than just pounding nails, but that doesn’t make it the right tool for
    the job. ChatGPT’s unique ability to predict what to say next will not always
    fit a specific use case perfectly. There are plenty of spaces where there might
    not be a good match. Or, as shown in the enterprise patching example, it’s not
    necessary to apply ChatGPT to every step to get value. Not only should the use
    cases be the most important, but they should also be ones where ChatGPT integration
    makes sense. Here are some areas where it might be challenging to apply ChatGPT
    to a solution and some creative thinking to help if these situations apply.
  prefs: []
  type: TYPE_NORMAL
- en: Lack of real-time information
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Foundational models have cut-off dates for the ingestion of new material. A
    new model might have data only from a year prior or earlier. This problem will
    improve over time; we have seen the ingested material dates as recent as less
    than a year. However, if there is a lag and a customer needs that time-critical
    information, it must provide it. If the company releases a 2.0 widget, new documentation
    can update a custom model with that information at launch. However, if the LLM
    solution depends on keeping third-party details up to date, ingesting up-to-date
    third-party data is also needed. It won’t matter if the third party posts the
    information on their website since the foundational model won’t be that current.
    Since the model updates are limited, Retrieval Augmented Generation (RAG), explained
    in [*Chapter 6*](B21964_06_split_000.xhtml#_idTextAnchor134), *Gathering Data
    – Content is King* can ingest this data and be up to date. Recognize that new
    testing and validation are required with changes to the model.
  prefs: []
  type: TYPE_NORMAL
- en: Complex or specialized topics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Legal and medical advice are the two areas that could cause issues. However,
    many opportunities exist when building enterprise versions of these services.
    They don’t have to be the answer to the legal or medical questions; they can help
    refine the space or look for connections that might be too difficult for a human
    to process (such as possible side effects or interactions for a patient with 15
    different medications). A support tool in the legal space could be to review mountains
    of legal files to highlight information related to specific expertise. Expert
    witnesses have to review depositions to form their conclusions. Still, with a
    ChatGPT tool that can be trained, it can identify important information in hundreds
    of pages of depositions and speed up the process by a factor of 10\. It also comes
    back to the lack of real-time data if it is expected to know everything. Create
    high-quality solutions by carefully monitoring the quality of the results by experts,
    incrementally improving, documenting, and refining success.
  prefs: []
  type: TYPE_NORMAL
- en: Long-form content generation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is common for enterprise use cases to need long-form content, such as writing
    a book. We have knowledge and technical documentation needs, but this is not an
    effective use of ChatGPT. ChatGPT can help edit material, shorten tests, tighten
    language, or even do essential translations, but there are limits. Don’t expect
    to put out long material like this without technical editors. ChatGPT can drift
    away from the topic, introduce unrelated content, and repeat phrasing. It might
    even repeat topics. I have seen good examples where a ten-step guide had two steps
    labeled slightly differently but identical to earlier steps – creating and maintaining
    the organization and hierarchy found in complex and lengthy documents taxes the
    long-term memory limitations of generative AI. Also, facts are not what they used
    to be. Especially with technical documents, we always have additional testers
    run through the processes and tasks in the document to verify that the solutions
    work. ChatGPT might first identify and point the user to the correct pieces of
    well-authored documents. Then, the user can trust the results to be accurate if
    they recognize that the document applies to them. For example, we don’t want to
    show a valid step-by-step solution to the problem in Microsoft Windows when we
    know they are using an Apple Macintosh.
  prefs: []
  type: TYPE_NORMAL
- en: Long-term memory
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A ChatGPT virtual assistant might be good from one comment to the next, but
    not for a long duration. A conversation that spans a week will not likely maintain
    the context or information to continue that conversation. However, some workarounds
    could be developed. Consider if long-term attributes or the conversation could
    be saved and processed to remind the LLM of previous discussions. A collection
    of contextual details could be built up over time. Even a historical list of earlier
    elements of a conversation could be stored. It is exciting to give an LLM the
    appearance of long-term memory. Vendors are working on providing foundational
    models better long-term memory. We have seen this in ChatGPT 4o, for example.
    Imagine a directory service within a company:'
  prefs: []
  type: TYPE_NORMAL
- en: The directory app provides people’s names, phone numbers, email addresses, and
    titles.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Many people have asked the app many times. It can look at search history to
    understand popular people and shortcuts for people’s names (Ben for Benjamin).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a user returns a month later, they don’t want to scroll through the history
    (or maybe the UI doesn’t have this data).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: So, the user asks, “What was *his* phone number again?”
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Once the AI responds with a name, the user responds, “No, it was someone else,”
    and the app returns a short list of other possible names.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By storing people’s history, it looked up and provided that context in the prompt
    (or via other solutions). This recreates the history and presents the appearance
    of long-term memory.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Context about this user and their organization might allow the LLM to provide
    names that were not previously used but are likely answers. “I don’t see that
    we talked about Ben before, but maybe you mean Benjamin Buttons. Here are his
    details…”
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thus, long-term memory could be constructed to provide context to new conversations.
    Each time it is constructed, we can confirm that the user has permission to access
    this information. This is one method to protect sensitive information. Sensitive
    information takes many forms in an enterprise.
  prefs: []
  type: TYPE_NORMAL
- en: Sensitive information
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Understanding what is private and keeping that information confidential is a
    real challenge. Recall that an LLM doesn’t understand what it is saying; it is
    good at predicting. We have seen time and time again stories about chat models
    being forced to spill information that should be sensitive. A workaround is not
    to use that information directly in the model. For example, if the app needs to
    collect credit card information, develop a secure service to pass this information
    between the user and the credit card backend. It doesn’t have to be done within
    the conversational model. Doing so with a GUI element might support building more
    trust with the user. Another place we can build trust and have issues with LLMs
    is with biased thinking.
  prefs: []
  type: TYPE_NORMAL
- en: Biased thinking
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The model is only as good as its training data. If the model has biases toward
    a way of thinking, is harmful to a user group, or contains offensive material,
    it can have unintended consequences on results. This presumably comes from the
    base model. Be cautious of this with proprietary data. It might not be a personal
    or cultural bias, but how a product or a competitor’s products are discussed can
    impact results. If the foundational model has biases, it might take some engineering
    to protect users from these using instructions to the LLM. But no matter how good
    the instructions are, some things are hard to teach, like emotion and empathy.
  prefs: []
  type: TYPE_NORMAL
- en: Emotion and empathy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We discussed the history of **ELIZA**, the original chatbot, in [*Chapter 1*](B21964_01.xhtml#_idTextAnchor016),
    *Recognizing the Power of Design in ChatGPT*; thus, using AI for psychological
    support is at the root of our AI journey. But be careful here. It lacks empathy
    and emotional understanding. There may be ways ChatGPT can be used to support
    the mental health community, but AI is not ready to answer 911 (or 988 mental
    health) calls (these are the emergency phone numbers in the USA). Use guardrails,
    test extensively, and monitor results where humans might be in a sensitive state.
    Even if a conversation with an LLM might be perceived as empathetic, this can
    go wrong quickly. It is only doing what is likely and not based on the nuances
    of empathy or emotion. In some sense, it is unethical for the LLM to sound empathetic.
  prefs: []
  type: TYPE_NORMAL
- en: Ethical and moral guidance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Most enterprise solutions usually do not delve into ethical or moral dilemmas.
    Much of this comes back to the Trolley problem when making a decision that can
    adversely affect two parties. The problem is based on a situation where a runaway
    trolley is about to kill people near the track, or it can be diverted and kill
    other people on a second track. How do you make such a decision?
  prefs: []
  type: TYPE_NORMAL
- en: The Trolly problem
  prefs: []
  type: TYPE_NORMAL
- en: This article describes the moral and ethical dilemmas described by the Trolley
    problem.
  prefs: []
  type: TYPE_NORMAL
- en: 'Wikipedia: [The Trolly Problem](https://www.britannica.com/topic/trolley-problem)
    ([https://www.britannica.com/topic/trolley-problem](https://www.britannica.com/topic/trolley-problem))'
  prefs: []
  type: TYPE_NORMAL
- en: Autonomous cars must consider these decisions, so commercially deployed systems
    already have to handle these hard decisions. ChatGPT is not built to make ethical
    decisions; it will use its predictive model to form its answer. Traditional machine
    learning already has this problem, and LLMs are not immune. Most popular models
    avoid answering ethical questions. Enterprise solutions that need to delve into
    these areas can be impacted by safeguards built into the models. Carefully apply
    best practices to prevent these conditions. Related to ethical and moral issues
    is how to handle critical decisions with significant consequences.
  prefs: []
  type: TYPE_NORMAL
- en: Critical decision making
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We have talked about ethics, morality, security, and empathy. These might come
    into play when making time-critical decisions with profound consequences. Depending
    on business decisions based on the model, and the model has been trained on the
    diverse internet data, will it give the same conclusions that a trusted expert
    would provide? It is essential to monitor this interaction closely, train it on
    company-specific data to avoid biases, and provide guidance and guardrails to
    the recommendation engine. Remember, it is basing its results on patterns it has
    seen. [*Chapter 6*](B21964_06_split_000.xhtml#_idTextAnchor134), *Gathering Data
    – Content is King* covers how ChatGPT works with enterprise data to make the LLM
    respond with business-savvy knowledge. It isn’t going to answer with a human’s
    moral compass and is not in a position to decide on the value of its judgment
    based on the expectations of its human user. Maybe less challenging would be something
    more geeky, like programming.
  prefs: []
  type: TYPE_NORMAL
- en: Programming and debugging
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This is one area that is getting a tremendous amount of visibility. I think
    it’s mostly because geeks love geeky things. Also, getting ChatGPT to do work
    is fantastic. However, if you don’t know what you don’t know, be very careful
    with its responses. Production-level code requires more robustness than what ChatGPT
    can provide. LLMs can write test cases against the code the model wrote. It can
    easily knock out simple scripts and templates in many common languages. And it
    is not just programming. Different models can be used to generate test cases and
    give the human in the loop some support. I suspect this area will mature quickly
    in the next few years. The more it can learn about good patterns and quality code
    examples, the more critical this area will become. Just know and expect it isn’t
    perfect. But these programming languages are sometimes better than world languages.
  prefs: []
  type: TYPE_NORMAL
- en: Translation accuracy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Most models handle translation but are only sometimes successful in technical
    or scientific areas. The training models have traditionally been very English-centric.
    Since they were trained on available web resources and 55% to 60% of the web is
    in English, the sophistication of translations varies considerably based on the
    training available.
  prefs: []
  type: TYPE_NORMAL
- en: There are significant hurdles to overcome for technical and company-specific
    vocabulary. Test and verify how these terms might be handled in other languages
    or used without translation. Test and verify cases of multiple languages being
    used in one interaction. Additionally, brand names are translated into only some
    cultures.
  prefs: []
  type: TYPE_NORMAL
- en: Speaking the user’s language has so much value. We have a UX saying to *bring
    the tool to the user, don’t make the user go to the tool*. Translating languages
    is the same. Customers would appreciate working in their native tongue rather
    than forgoing support or communicating in another language. The quality of the
    language mirrors the training available. Expect better support for Spanish, French,
    and German, while it can be challenged in Russian, Arabic, and Hindi, especially
    with idiomatic dialects, formalities, and technical language. Again, monitor results
    and invest in training technical jargon and unique company vocabulary. Some world
    languages have smaller training sets, grammar, syntax, and phonetics complexities,
    overlaps or confusion with another language, and a limited human feedback loop.
    There is no substitute for a great teacher.
  prefs: []
  type: TYPE_NORMAL
- en: Educational substitution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Human trainers and training or educational material have a long history of success
    (and failure) in various areas. The best class I have ever taken was a three-day
    hands-on class in the 100-degree heat of the desert. We rarely sat down, and even
    with ten years of college, I learned more per hour than in any classroom. Don’t
    expect ChatGPT to have the expertise to train or educate students effectively.
    It doesn’t know how the student reacts and will be challenged to adapt to their
    needs. Hands-on skill training is difficult and even more challenging (but not
    impossible) to analyze and share with an LLM. For example, a training application
    might teach and coach how to change out a faulty sensor on an airplane engine.
    The LLM can coach the user, while cameras can detect the situation and guide the
    user to perform the steps in the correct order, point to the right tool (using
    a laser pointer), and identify the location to apply the tool. Assisted maintenance
    is a vast area, and given the cost of mistakes, investments in this space will
    be significant. So, it is coming, but it will be hard, and accuracy will be critical.
  prefs: []
  type: TYPE_NORMAL
- en: Don’t force-fit a solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Recognize that for every bottleneck to which ChatGPT is applied, ChatGPT might
    offer suggestions on how to avoid or mitigate issues. However, don’t try to force-fit
    ChatGPT into a solution. There seems to be a rich set of opportunities to apply
    ChatGPT in almost any vertical market. Focus on the use cases that provide the
    most value and match the unique capabilities of a generative AI solution.
  prefs: []
  type: TYPE_NORMAL
- en: 'ChatGPT might be used in a space not covered in this book. Try asking it, reviewing
    it, and diving deeper into its response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Developing user stories can sometimes be easy. If requirements are apparent,
    straightforward, and ideally suited to ChatGPT, write those up and get to work.
    We also realize that some things need to be clarified. Use research, discussions
    with internal stakeholders, and your keen mind for problem-solving to find LLM
    opportunities.
  prefs: []
  type: TYPE_NORMAL
- en: Start thinking about the opportunities best suited for a generative solution
    in your business and explain why some problems are unsuitable for ChatGPT.
  prefs: []
  type: TYPE_NORMAL
- en: Hopefully, this chapter will create excitement around introducing our next topic
    for scoring and prioritizing stories. We will jump into that next since we only
    briefly explained User Needs Scoring. This will allow us to prioritize the backlog
    features and use cases we have explored up to this point. It will also be helpful
    to know this when we get a ChatGPT solution up and running and want to test or
    monitor it.
  prefs: []
  type: TYPE_NORMAL
- en: Once we have a solution, we can reuse some of these skills to verify what we
    did and continue to care for and feed the solution for continuous improvement.
    We will then have data and some confidence that we are doing the right things.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '| ![](img/03.png) | The links, book recommendations, and GitHub files in this
    chapter are posted on the reference page.Web Page: [Chapter 3 References](https://uxdforai.com/references#C3)
    ([https://uxdforai.com/references#C3](https://uxdforai.com/references#C3)) |'
  prefs: []
  type: TYPE_TB
