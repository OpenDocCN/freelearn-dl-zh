["```py\n    %run -i \"../util/file_utils.ipynb\"\n    %run -i \"../util/lang_utils.ipynb\"\n    ```", "```py\n    text = \"I have five birds\"\n    doc = small_model(text)\n    ```", "```py\n    for token in doc:\n        if (token.pos_ == \"NOUN\" and token.lemma_ != token.text):\n            print(token.text, \"plural\")\n    ```", "```py\n    birds plural\n    ```", "```py\n    doc = small_model(\"I have five birds.\")\n    print(doc[3].morph.get(\"Number\"))\n    ```", "```py\n    ['Plur']\n    ```", "```py\n    class Noun_number(Enum):\n        SINGULAR = 1\n        PLURAL = 2\n    ```", "```py\n    def get_nouns_number(text, model, method=\"lemma\"):\n        nouns = []\n        doc = model(text)\n        for token in doc:\n            if (token.pos_ == \"NOUN\"):\n                if method == \"lemma\":\n                    if token.lemma_ != token.text:\n                        nouns.append((token.text, \n                            Noun_number.PLURAL))\n                    else:\n                        nouns.append((token.text,\n                            Noun_number.SINGULAR))\n                elif method == \"morph\":\n                    if token.morph.get(\"Number\") == \"Sing\":\n                        nouns.append((token.text,\n                            Noun_number.PLURAL))\n                    else:\n                        nouns.append((token.text,\n                            Noun_number.SINGULAR))\n        return nouns\n    ```", "```py\n    text = \"Three geese crossed the road\"\n    nouns = get_nouns_number(text, small_model, \"morph\")\n    print(nouns)\n    nouns = get_nouns_number(text, small_model)\n    print(nouns)\n    ```", "```py\n    [('geese', <Noun_number.SINGULAR: 1>), ('road', <Noun_number.SINGULAR: 1>)]\n    [('geese', <Noun_number.SINGULAR: 1>), ('road', <Noun_number.SINGULAR: 1>)]\n    ```", "```py\n    !python -m spacy download en_core_web_lg\n    large_model = spacy.load(\"en_core_web_lg\")\n    nouns = get_nouns_number(text, large_model, \"morph\")\n    print(nouns)\n    nouns = get_nouns_number(text, large_model)\n    print(nouns)\n    ```", "```py\n    [('geese', <Noun_number.SINGULAR: 1>), ('road', <Noun_number.SINGULAR: 1>)]\n    [('geese', <Noun_number.PLURAL: 2>), ('road', <Noun_number.SINGULAR: 1>)]\n    ```", "```py\n    from openai import OpenAI\n    client = OpenAI(api_key=OPEN_AI_KEY)\n    prompt=\"\"\"Decide whether each noun in the following text is singular or plural.\n    Return the list in the format of a python tuple: (word, number). Do not provide any additional explanations.\n    Sentence: Three geese crossed the road.\"\"\"\n    response = client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        temperature=0,\n        max_tokens=256,\n        top_p=1.0,\n        frequency_penalty=0,\n        presence_penalty=0,\n        messages=[\n            {\"role\": \"system\", \"content\": \"You are a helpful \n                assistant.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ],\n    )\n    print(response.choices[0].message.content)\n    ```", "```py\n    ('geese', 'plural')\n    ('road', 'singular')\n    ```", "```py\n    from textblob import TextBlob\n    ```", "```py\n    texts = [\"book\", \"goose\", \"pen\", \"point\", \"deer\"]\n    blob_objs = [TextBlob(text) for text in texts]\n    ```", "```py\n    plurals = [blob_obj.words.pluralize()[0] \n        for blob_obj in blob_objs]\n    print(plurals)\n    ```", "```py\n    ['books', 'geese', 'pens', 'points', 'deer']\n    ```", "```py\n    blob_objs = [TextBlob(text) for text in plurals]\n    ```", "```py\n    singulars = [blob_obj.words.singularize()[0] \n        for blob_obj in blob_objs]\n    print(singulars)\n    ```", "```py\n    ['book', 'goose', 'pen', 'point', 'deer']\n    ```", "```py\n    %run -i \"../util/file_utils.ipynb\"\n    %run -i \"../util/lang_utils.ipynb\"\n    ```", "```py\n    sentence = 'I have seldom heard him mention her under any other name.'\n    ```", "```py\n    def print_dependencies(sentence, model):\n        doc = model(sentence)\n        for token in doc:\n            print(token.text, \"\\t\", token.dep_, \"\\t\", \n                spacy.explain(token.dep_))\n    ```", "```py\n    print_dependencies(sentence, small_model)\n    ```", "```py\n    I    nsubj    nominal subject\n    have    aux    auxiliary\n    seldom    advmod    adverbial modifier\n    heard    ROOT    root\n    him    nsubj    nominal subject\n    mention    ccomp    clausal complement\n    her    dobj    direct object\n    under    prep    prepositional modifier\n    any    det    determiner\n    other    amod    adjectival modifier\n    name    pobj    object of preposition\n    .    punct    punctuation\n    ```", "```py\n    def print_ancestors(sentence, model):\n        doc = model(sentence)\n        for token in doc:\n            print(token.text, [t.text for t in token.ancestors])\n    ```", "```py\n    print_ancestors(sentence, small_model)\n    ```", "```py\n    I ['heard']\n    have ['heard']\n    seldom ['heard']\n    heard []\n    him ['mention', 'heard']\n    mention ['heard']\n    her ['mention', 'heard']\n    under ['mention', 'heard']\n    any ['name', 'under', 'mention', 'heard']\n    other ['name', 'under', 'mention', 'heard']\n    name ['under', 'mention', 'heard']\n    . ['heard']\n    ```", "```py\n    def print_children(sentence, model):\n        doc = model(sentence)\n        for token in doc:\n            print(token.text,[t.text for t in token.children])\n    ```", "```py\n    print_children(sentence, small_model)\n    ```", "```py\n    I []\n    have []\n    seldom []\n    heard ['I', 'have', 'seldom', 'mention', '.']\n    him []\n    mention ['him', 'her', 'under']\n    her []\n    under ['name']\n    any []\n    other []\n    name ['any', 'other']\n    . []\n    ```", "```py\n    def print_lefts_and_rights(sentence, model):\n        doc = model(sentence)\n        for token in doc:\n            print(token.text,\n                [t.text for t in token.lefts],\n                [t.text for t in token.rights])\n    ```", "```py\n    print_lefts_and_rights(sentence, small_model)\n    ```", "```py\n    I [] []\n    have [] []\n    seldom [] []\n    heard ['I', 'have', 'seldom'] ['mention', '.']\n    him [] []\n    mention ['him'] ['her', 'under']\n    her [] []\n    under [] ['name']\n    any [] []\n    other [] []\n    name ['any', 'other'] []\n    . [] []\n    ```", "```py\n    def print_subtree(sentence, model):\n        doc = model(sentence)\n        for token in doc:\n            print(token.text, [t.text for t in token.subtree])\n    ```", "```py\n    print_subtree(sentence, small_model)\n    ```", "```py\n    I ['I']\n    have ['have']\n    seldom ['seldom']\n    heard ['I', 'have', 'seldom', 'heard', 'him', 'mention', 'her', 'under', 'any', 'other', 'name', '.']\n    him ['him']\n    mention ['him', 'mention', 'her', 'under', 'any', 'other', 'name']\n    her ['her']\n    under ['under', 'any', 'other', 'name']\n    any ['any']\n    other ['other']\n    name ['any', 'other', 'name']\n    . ['.']\n    ```", "```py\n    %run -i \"../util/file_utils.ipynb\"\n    %run -i \"../util/lang_utils.ipynb\"\n    ```", "```py\n    def print_noun_chunks(text, model):\n        doc = model(text)\n        for noun_chunk in doc.noun_chunks:\n            print(noun_chunk.text)\n    ```", "```py\n    sherlock_holmes_part_of_text = read_text_file(\"../data/sherlock_holmes_1.txt\")\n    print_noun_chunks(sherlock_holmes_part_of_text, small_model)\n    ```", "```py\n    Sherlock Holmes\n    she\n    the_ woman\n    I\n    him\n    her\n    any other name\n    his eyes\n    she\n    the whole\n    …\n    ```", "```py\n    def explore_properties(sentence, model):\n        doc = model(sentence)\n        other_span = \"emotions\"\n        other_doc = model(other_span)\n        for noun_chunk in doc.noun_chunks:\n            print(noun_chunk.text)\n            print(\"Noun chunk start and end\", \"\\t\",\n                noun_chunk.start, \"\\t\", noun_chunk.end)\n            print(\"Noun chunk sentence:\", noun_chunk.sent)\n            print(\"Noun chunk root:\", noun_chunk.root.text)\n            print(f\"Noun chunk similarity to '{other_span}'\",\n                noun_chunk.similarity(other_doc))\n        print(f\"Similarity of the sentence '{sentence}' to \n            '{other_span}':\",\n            doc.similarity(other_doc))\n    ```", "```py\n    sentence = \"All emotions, and that one particularly, were abhorrent to his cold, precise but admirably balanced mind.\"\n    ```", "```py\n    explore_properties(sentence, small_model)\n    ```", "```py\n    All emotions\n    Noun chunk start and end    0    2\n    Noun chunk sentence: All emotions, and that one particularly, were abhorrent to his cold, precise but admirably balanced mind.\n    Noun chunk root: emotions\n    Noun chunk similarity to 'emotions' 0.4026421588260174\n    his cold, precise but admirably balanced mind\n    Noun chunk start and end    11    19\n    Noun chunk sentence: All emotions, and that one particularly, were abhorrent to his cold, precise but admirably balanced mind.\n    Noun chunk root: mind\n    Noun chunk similarity to 'emotions' -0.036891259527462\n    Similarity of the sentence 'All emotions, and that one particularly, were abhorrent to his cold, precise but admirably balanced mind.' to 'emotions': 0.03174900767577446\n    ```", "```py\n    /tmp/ipykernel_1807/2430050149.py:10: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Span.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n      print(f\"Noun chunk similarity to '{other_span}'\", noun_chunk.similarity(other_doc))\n    ```", "```py\n    sentence = \"All emotions, and that one particularly, were abhorrent to his cold, precise but admirably balanced mind.\"\n    explore_properties(sentence, large_model)\n    ```", "```py\n    All emotions\n    Noun chunk start and end    0    2\n    Noun chunk sentence: All emotions, and that one particularly, were abhorrent to his cold, precise but admirably balanced mind.\n    Noun chunk root: emotions\n    Noun chunk similarity to 'emotions' 0.6302678068015664\n    his cold, precise but admirably balanced mind\n    Noun chunk start and end    11    19\n    Noun chunk sentence: All emotions, and that one particularly, were abhorrent to his cold, precise but admirably balanced mind.\n    Noun chunk root: mind\n    Noun chunk similarity to 'emotions' 0.5744456705692561\n    Similarity of the sentence 'All emotions, and that one particularly, were abhorrent to his cold, precise but admirably balanced mind.' to 'emotions': 0.640366414527618\n    ```", "```py\n    %run -i \"../util/file_utils.ipynb\"\n    %run -i \"../util/lang_utils.ipynb\"\n    ```", "```py\n    def get_subject_phrase(doc):\n        for token in doc:\n            if (\"subj\" in token.dep_):\n                subtree = list(token.subtree)\n                start = subtree[0].i\n                end = subtree[-1].i + 1\n                return doc[start:end]\n    ```", "```py\n    def get_object_phrase(doc):\n        for token in doc:\n            if (\"dobj\" in token.dep_):\n                subtree = list(token.subtree)\n                start = subtree[0].i\n                end = subtree[-1].i + 1\n                return doc[start:end]\n    ```", "```py\n    sentences = [\n        \"The big black cat stared at the small dog.\",\n        \"Jane watched her brother in the evenings.\",\n        \"Laura gave Sam a very interesting book.\"\n    ]\n    for sentence in sentences:\n        doc = small_model(sentence)\n        subject_phrase = get_subject_phrase(doc)\n        object_phrase = get_object_phrase(doc)\n        print(sentence)\n        print(\"\\tSubject:\", subject_phrase)\n        print(\"\\tDirect object:\", object_phrase)\n    ```", "```py\n    The big black cat stared at the small dog.\n      Subject: The big black cat\n      Direct object: None\n    Jane watched her brother in the evenings.\n      Subject: Jane\n      Direct object: her brother\n    Laura gave Sam a very interesting book.\n      Subject: Laura\n      Direct object: a very interesting book\n    ```", "```py\n    def get_dative_phrase(doc):\n        for token in doc:\n            if (\"dative\" in token.dep_):\n                subtree = list(token.subtree)\n                start = subtree[0].i\n                end = subtree[-1].i + 1\n                return doc[start:end]\n    ```", "```py\n    def get_phrase(doc, phrase):\n        # phrase is one of \"subj\", \"obj\", \"dative\"\n        for token in doc:\n            if (phrase in token.dep_):\n                subtree = list(token.subtree)\n                start = subtree[0].i\n                end = subtree[-1].i + 1\n                return doc[start:end]\n    ```", "```py\n    sentence = \"Laura gave Sam a very interesting book.\"\n    doc = small_model(sentence)\n    subject_phrase = get_phrase(doc, \"subj\")\n    object_phrase = get_phrase(doc, \"obj\")\n    dative_phrase = get_phrase(doc, \"dative\")\n    print(sentence)\n    print(\"\\tSubject:\", subject_phrase)\n    print(\"\\tDirect object:\", object_phrase)\n    print(\"\\tDative object:\", dative_phrase)\n    ```", "```py\n    Laura gave Sam a very interesting book.\n      Subject: Laura\n      Direct object: a very interesting book\n      Dative object: Sam\n    ```", "```py\n    def get_prepositional_phrase_objs(doc):\n        prep_spans = []\n        for token in doc:\n            if (\"pobj\" in token.dep_):\n                subtree = list(token.subtree)\n                start = subtree[0].i\n                end = subtree[-1].i + 1\n                prep_spans.append(doc[start:end])\n        return prep_spans\n    ```", "```py\n    sentences = [\n        \"The big black cat stared at the small dog.\",\n        \"Jane watched her brother in the evenings.\"\n    ]\n    for sentence in sentences:\n        doc = small_model(sentence)\n        subject_phrase = get_phrase(doc, \"subj\")\n        object_phrase = get_phrase(doc, \"obj\")\n        dative_phrase = get_phrase(doc, \"dative\")\n        prepositional_phrase_objs = \\\n            get_prepositional_phrase_objs(doc)\n        print(sentence)\n        print(\"\\tSubject:\", subject_phrase)\n        print(\"\\tDirect object:\", object_phrase)\n        print(\"\\tPrepositional phrases:\", prepositional_phrase_objs)\n    ```", "```py\n    The big black cat stared at the small dog.\n      Subject: The big black cat\n      Direct object: the small dog\n      Prepositional phrases: [the small dog]\n    Jane watched her brother in the evenings.\n      Subject: Jane\n      Direct object: her brother\n      Prepositional phrases: [the evenings]\n    ```", "```py\n    %run -i \"../util/file_utils.ipynb\"\n    %run -i \"../util/lang_utils.ipynb\"\n    ```", "```py\n    from spacy.matcher import Matcher\n    matcher = Matcher(small_model.vocab)\n    ```", "```py\n    patterns = [\n        [{\"POS\": \"VERB\"}],\n        [{\"POS\": \"AUX\"}, {\"POS\": \"VERB\"}],\n        [{\"POS\": \"AUX\"}, {\"POS\": \"ADJ\"}],\n        [{\"POS\": \"AUX\"}, {\"POS\": \"VERB\"}, {\"POS\": \"ADP\"}]\n    ]\n    matcher.add(\"Verb\", patterns)\n    ```", "```py\n    sherlock_holmes_part_of_text = read_text_file(\"../data/sherlock_holmes_1.txt\")\n    doc = small_model(sherlock_holmes_part_of_text)\n    ```", "```py\n    matches = matcher(doc)\n    for match_id, start, end in matches:\n        string_id = small_model.vocab.strings[match_id]\n        span = doc[start:end]\n        print(match_id, string_id, start, end, span.text)\n    ```", "```py\n    14677086776663181681 Verb 14 15 heard\n    14677086776663181681 Verb 17 18 mention\n    14677086776663181681 Verb 28 29 eclipses\n    14677086776663181681 Verb 31 32 predominates\n    14677086776663181681 Verb 43 44 felt\n    14677086776663181681 Verb 49 50 love\n    14677086776663181681 Verb 63 65 were abhorrent\n    14677086776663181681 Verb 80 81 take\n    14677086776663181681 Verb 88 89 observing\n    14677086776663181681 Verb 94 96 has seen\n    14677086776663181681 Verb 95 96 seen\n    14677086776663181681 Verb 103 105 have placed\n    14677086776663181681 Verb 104 105 placed\n    14677086776663181681 Verb 114 115 spoke\n    14677086776663181681 Verb 120 121 save\n    14677086776663181681 Verb 130 132 were admirable\n    14677086776663181681 Verb 140 141 drawing\n    14677086776663181681 Verb 153 154 trained\n    14677086776663181681 Verb 157 158 admit\n    14677086776663181681 Verb 167 168 adjusted\n    14677086776663181681 Verb 171 172 introduce\n    14677086776663181681 Verb 173 174 distracting\n    14677086776663181681 Verb 178 179 throw\n    14677086776663181681 Verb 228 229 was\n    ```"]