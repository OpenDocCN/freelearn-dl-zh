<html><head></head><body>
		<div><h1 id="_idParaDest-152" class="chapter-number"><a id="_idTextAnchor156" class="calibre6 pcalibre pcalibre1"/>6</h1>
			<h1 id="_idParaDest-153" class="calibre7"><a id="_idTextAnchor157" class="calibre6 pcalibre pcalibre1"/>Topic Modeling</h1>
			<p class="calibre3">In this chapter, we will cover <strong class="bold">topic modeling</strong>, or <a id="_idIndexMarker320" class="calibre6 pcalibre pcalibre1"/>the classification of topics present in a corpus of text. Topic modeling is a very useful technique that can give us an idea about which topics appear in a document set. For example, topic modeling is used for trend discovery on social media. Also, in many cases, it is useful to do topic modeling as part of the preliminary data analysis of a dataset to understand which topics appear in it.</p>
			<p class="calibre3">There are many different algorithms available to do this. All of them try to find similarities between different texts and put them into several clusters. These different clusters indicate different topics.</p>
			<p class="calibre3">You will learn how to create and use topic models via various techniques with the BBC news dataset in this chapter. This dataset has news that falls within the following topics: politics, sport, business, tech, and entertainment. Thus, we know that in each case, we need to have five topic clusters. This is not going to be the case in real-life scenarios, and you will need to estimate the number of topic clusters. A good reference on how to do this is <em class="italic">The Hundred-Page Machine Learning Book</em> by Andriy Burkov (p. 112).</p>
			<p class="calibre3">This chapter contains the following recipes:</p>
			<ul class="calibre15">
				<li class="calibre14">LDA topic modeling with <strong class="source-inline1">gensim</strong></li>
				<li class="calibre14">Community detection clustering with SBERT</li>
				<li class="calibre14">K-Means topic modeling with BERT</li>
				<li class="calibre14">Topic modeling using BERTopic</li>
				<li class="calibre14">Using contextualized topic models</li>
			</ul>
			<h1 id="_idParaDest-154" class="calibre7"><a id="_idTextAnchor158" class="calibre6 pcalibre pcalibre1"/>Technical requirements</h1>
			<p class="calibre3">In this chapter, we will work with the same BBC dataset that we worked with in <a href="B18411_04.xhtml#_idTextAnchor106" class="calibre6 pcalibre pcalibre1"><em class="italic">Chapter 4</em></a>. The dataset is located in the book GitHub repository:</p>
			<p class="calibre3"><a href="https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/data/bbc-text.csv" class="calibre6 pcalibre pcalibre1">https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/data/bbc-text.csv</a></p>
			<p class="calibre3">It is also available through Hugging Face:</p>
			<p class="calibre3"><a href="https://huggingface.co/datasets/SetFit/bbc-news" class="calibre6 pcalibre pcalibre1">https://huggingface.co/datasets/SetFit/bbc-news</a></p>
			<p class="callout-heading">Note</p>
			<p class="callout">This dataset is used in this book with permission from the researchers. The original paper associated with this dataset is as follows:</p>
			<p class="callout">Derek Greene and Pádraig Cunningham. “Practical Solutions to the Problem of Diagonal Dominance in Kernel Document Clustering”, in Proc. 23rd International Conference on Machine Learning (ICML’06), 2006.</p>
			<p class="callout">All rights, including copyright, in the text content of the original articles are owned by the BBC.</p>
			<p class="calibre3">Please make sure to download all the Python notebooks in the <code>util</code> folder on GitHub into the <code>util</code> folder on your computer. The directory structure on your computer should mirror the setup in the GitHub repository. We will be accessing files in this directory in several recipes in this chapter.</p>
			<h1 id="_idParaDest-155" class="calibre7"><a id="_idTextAnchor159" class="calibre6 pcalibre pcalibre1"/>LDA topic modeling with gensim</h1>
			<p class="calibre3"><strong class="bold">Latent Dirichlet Allocation</strong> (<strong class="bold">LDA</strong>) is <a id="_idIndexMarker321" class="calibre6 pcalibre pcalibre1"/>one of the oldest algorithms for topic modeling. It is a statistical generative model that calculates the <a id="_idIndexMarker322" class="calibre6 pcalibre pcalibre1"/>probabilities of different words. In general, LDA is a good choice of model for longer texts.</p>
			<p class="calibre3">We will use one of the <a id="_idIndexMarker323" class="calibre6 pcalibre pcalibre1"/>main topic modeling algorithms, LDA, to create a topic model for the BBC news texts. We know that the BBC news dataset has five topics: tech, politics, business, entertainment, and sport. Thus, we will use five as the expected number of clusters.</p>
			<h2 id="_idParaDest-156" class="calibre5"><a id="_idTextAnchor160" class="calibre6 pcalibre pcalibre1"/>Getting ready</h2>
			<p class="calibre3">We will<a id="_idIndexMarker324" class="calibre6 pcalibre pcalibre1"/> be using the <code>gensim</code> package, which is part of the <a id="_idIndexMarker325" class="calibre6 pcalibre pcalibre1"/>poetry environment. You can also install the <code>requirements.txt</code> file to get the package.</p>
			<p class="calibre3">The dataset is located at <a href="https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/data/bbc-text.csv" class="calibre6 pcalibre pcalibre1">https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/data/bbc-text.csv</a> and should be downloaded to the <code>data</code> folder.</p>
			<p class="calibre3">The notebook is located at <a href="https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter06/6.1_topic_modeling_gensim.ipynb" class="calibre6 pcalibre pcalibre1">https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter06/6.1_topic_modeling_gensim.ipynb</a>.</p>
			<h2 id="_idParaDest-157" class="calibre5"><a id="_idTextAnchor161" class="calibre6 pcalibre pcalibre1"/>How to do it...</h2>
			<p class="calibre3">An LDA model requires the data to be clean. This means that stopwords and other unnecessary tokens need to be removed from the text. This includes digits and punctuation. If this step is skipped, topics that center around stopwords, digits, or punctuation might appear.</p>
			<p class="calibre3">We will load the data, clean it, and preprocess it using the <code>simple_preprocess</code> function, which is available through the <code>gensim</code> package. Then we will create the LDA model. Any topic model requires the engineer to estimate the number of topics in advance. We will use five, as we know that there are five topics present in the data. For more information on how to estimate the number of topics, please see the introductory section of this chapter.</p>
			<p class="calibre3">The steps are as follows:</p>
			<ol class="calibre13">
				<li class="calibre14">Do the necessary imports:<pre class="source-code">
import pandas as pd
import nltk
import re
from nltk.corpus import stopwords
from gensim.utils import simple_preprocess
from gensim.models.ldamodel import LdaModel
import gensim.corpora as corpora
from pprint import pprint
from gensim.corpora import MmCorpus</pre></li>				<li class="calibre14">Load the<a id="_idIndexMarker326" class="calibre6 pcalibre pcalibre1"/> stopwords and the BBC news data, then print the resulting dataframe. Here, we use the standard stopword list from NLTK. As we saw in <a href="B18411_04.xhtml#_idTextAnchor106" class="calibre6 pcalibre pcalibre1"><em class="italic">Chapter 4</em></a>, in the <em class="italic">Clustering sentences using K-Means: unsupervised text classification</em> recipe, the <strong class="source-inline1">said</strong> word is also considered a stopword in this dataset, so we must manually <a id="_idIndexMarker327" class="calibre6 pcalibre pcalibre1"/>add it to the list.<pre class="source-code">
stop_words = stopwords.words('english')
stop_words.append("said")
bbc_df = pd.read_csv("../data/bbc-text.csv")
print(bbc_df)</pre><p class="calibre3">The result will look similar to this:</p></li>			</ol>
			<div><div><img src="img/B18411_06_1.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.1 – The BBC news dataframe output</p>
			<ol class="calibre13">
				<li value="3" class="calibre14">In this step, we will create the <strong class="source-inline1">clean_text</strong> function. This function removes extra whitespace in the first line and digits in the second line from text. It then uses the <strong class="source-inline1">simple_preprocess</strong> function from <strong class="source-inline1">gensim</strong>. The <strong class="source-inline1">simple_preprocess</strong> function splits the text into a list of tokens, lowercases them, and <a id="_idIndexMarker328" class="calibre6 pcalibre pcalibre1"/>removes tokens that are too long or too short. We then remove stopwords <a id="_idIndexMarker329" class="calibre6 pcalibre pcalibre1"/>from the list:<pre class="source-code">
def clean_text(input_string):
    input_string = re.sub(r'[^\w\s]', ' ', input_string)
    input_string = re.sub(r'\d', '', input_string)
    input_list = simple_preprocess(input_string)
    input_list = [word for word in input_list if word not in 
        stop_words]
    return input_list</pre></li>				<li class="calibre14">We will now apply the function to the data. The text column now contains a list of words that are in lowercase and no stopwords:<pre class="source-code">
bbc_df['text'] = bbc_df['text'].apply(lambda x: clean_text(x))
print(bbc_df)</pre><p class="calibre3">The result will look similar to this:</p></li>			</ol>
			<div><div><img src="img/B18411_06_2.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.2 – The processed BBC news output</p>
			<p class="calibre3">Here, we <a id="_idIndexMarker330" class="calibre6 pcalibre pcalibre1"/>will use the <code>gensim.corpora.Dictionary</code> class to create a mapping from a word to its integer ID. This is necessary to then create a bag-of-words representation of the text. Then, using<a id="_idIndexMarker331" class="calibre6 pcalibre pcalibre1"/> this mapping, we create the corpus as a bag of words. To learn more about the bag-of-words concept, please see <a href="B18411_03.xhtml#_idTextAnchor067" class="calibre6 pcalibre pcalibre1"><em class="italic">Chapter 3</em></a>, <em class="italic">Putting Documents into a Bag of Words</em>. In this recipe, instead of using <code>sklean</code>’s <code>CountVectorizer</code> class, we will use the classes provided by the <code>gensim</code> package:</p>
			<pre class="source-code">
texts = bbc_df['text'].values
id_dict = corpora.Dictionary(texts)
corpus = [id_dict.doc2bow(text) for text in texts]</pre>			<ol class="calibre13">
				<li value="5" class="calibre14">In this step, we will initialize and train the LDA model. We will pass in the preprocessed and vectorized data (<strong class="source-inline1">corpus</strong>), the word-to-ID mapping (<strong class="source-inline1">id_dict</strong>), the number of topics, which we initialized to five, the chunk size, and the number of passes. The chunk size determines the number of documents used in each training chunk, and the number of passes specifies the number of passes through the corpus during training. You can experiment with these hyperparameters to see whether they improve the model. The parameters used here, 100 documents per chunk and 20 passes, were chosen experimentally to produce a good model:<pre class="source-code">
num_topics = 5
lda_model = LdaModel(corpus=corpus,
                     id2word=id_dict,
                     num_topics=num_topics,
                     chunksize=100,
                     passes=20)
pprint(lda_model.print_topics())</pre><p class="calibre3">The results will vary. Our output looks like this:</pre></li>			</ol>
			<div><div><img src="img/B18411_06_3.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.3 – Our LDA output</p>
			<h2 id="_idParaDest-158" class="calibre5"><a id="_idTextAnchor162" class="calibre6 pcalibre pcalibre1"/>There’s more...</h2>
			<p class="calibre3">Now let’s save<a id="_idIndexMarker334" class="calibre6 pcalibre pcalibre1"/> the <a id="_idIndexMarker335" class="calibre6 pcalibre pcalibre1"/>model and apply it to novel input:</p>
			<ol class="calibre13">
				<li class="calibre14">Define the <strong class="source-inline1">save_model</strong> function. To save the model, we need the model itself, the path where we want to save it, the vectorizer (<strong class="source-inline1">id_dict</strong>), the path where we want to save the vectorizer, the corpus, and the path where the corpus will be saved. The function will save these three components to their corresponding paths:<pre class="source-code">
def save_model(lda, lda_path, id_dict, dict_path, 
    corpus, corpus_path):
    lda.save(lda_path)
    id_dict.save(dict_path)
    MmCorpus.serialize(corpus_path, corpus)</pre></li>				<li class="calibre14">Save the model, the word-to-ID dictionary, and the vectorized corpus by using the function we just defined:<pre class="source-code">
model_path = "../models/bbc_gensim/lda.model"
dict_path = "../models/bbc_gensim/id2word.dict"
corpus_path = "../models/bbc_gensim/corpus.mm"
save_model(lda_model, model_path, id_dict, dict_path, 
    corpus, corpus_path)</pre></li>				<li class="calibre14">Load the <a id="_idIndexMarker336" class="calibre6 pcalibre pcalibre1"/>saved model:<pre class="source-code">
lda_model = LdaModel.load(model_path)
id_dict = corpora.Dictionary.load(dict_path)</pre></li>				<li class="calibre14">Define a <a id="_idIndexMarker337" class="calibre6 pcalibre pcalibre1"/>new example for testing. This example is on the topic of sports:<pre class="source-code">
new_example = """Manchester United players slumped to the turf
at full-time in Germany on Tuesday in acknowledgement of what their
latest pedestrian first-half display had cost them. The 3-2 loss at
RB Leipzig means United will not be one of the 16 teams in the draw
for the knockout stages of the Champions League. And this is not the
only price for failure. The damage will be felt in the accounts, in
the dealings they have with current and potentially future players
and in the faith the fans have placed in manager Ole Gunnar Solskjaer.
With Paul Pogba's agent angling for a move for his client and ex-United
defender Phil Neville speaking of a "witchhunt" against his former team-mate
Solskjaer, BBC Sport looks at the ramifications and reaction to a big loss for United."""</pre></li>				<li class="calibre14">In this <a id="_idIndexMarker338" class="calibre6 pcalibre pcalibre1"/>step, we <a id="_idIndexMarker339" class="calibre6 pcalibre pcalibre1"/>will preprocess the text using the same <strong class="source-inline1">clean_text</strong> function, then convert it into a bag-of-words vector and run it through the model. The prediction is a list of tuples, where the first element in each tuple is the number of the topic and the second element is the probability that this text belongs to this particular topic. In this example, we can see that topic 1 is the most probable, which is sport, and is the correct identification:<pre class="source-code">
input_list = clean_text(new_example)
bow = id_dict.doc2bow(input_list)
topics = lda_model[bow]
print(topics)</pre><p class="calibre3">The results will vary. Our results look like this:</p><pre class="source-code">[(1, 0.7338447), (2, 0.15261793), (4, 0.1073401)]</pre></li>			</ol>
			<h1 id="_idParaDest-159" class="calibre7"><a id="_idTextAnchor163" class="calibre6 pcalibre pcalibre1"/>Community detection clustering with SBERT</h1>
			<p class="calibre3">In this<a id="_idIndexMarker340" class="calibre6 pcalibre pcalibre1"/> recipe, we will use the community detection<a id="_idIndexMarker341" class="calibre6 pcalibre pcalibre1"/> algorithm<a id="_idIndexMarker342" class="calibre6 pcalibre pcalibre1"/> included with the <strong class="bold">SentenceTransformers</strong> (<strong class="bold">SBERT</strong>) package. SBERT will allow us to easily encode sentences using the BERT model. See the <em class="italic">Using BERT and OpenAI embeddings instead of word embeddings</em> recipe in <a href="B18411_03.xhtml#_idTextAnchor067" class="calibre6 pcalibre pcalibre1"><em class="italic">Chapter 3</em></a> for a more detailed explanation of how to use the sentence transformers.</p>
			<p class="calibre3">This algorithm is frequently used to find <strong class="bold">communities</strong> in social media but can also be used for topic modeling. The advantage of this algorithm is that it is very fast. It works best on shorter texts, such as texts found on social media. It also only discovers the main topics <a id="_idIndexMarker343" class="calibre6 pcalibre pcalibre1"/>in the <a id="_idIndexMarker344" class="calibre6 pcalibre pcalibre1"/>document dataset, as opposed to LDA, which clusters all available text. One use of the community detection algorithm is finding duplicate posts on social media.</p>
			<h2 id="_idParaDest-160" class="calibre5"><a id="_idTextAnchor164" class="calibre6 pcalibre pcalibre1"/>Getting ready</h2>
			<p class="calibre3">We will use the SBERT package in this recipe. It is included in the poetry environment. You can also install it together with other packages by installing the <code>requirements.txt</code> file.</p>
			<p class="calibre3">The notebook is located at <a href="https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter06/6.2_community_detection.ipynb" class="calibre6 pcalibre pcalibre1">https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter06/6.2_community_detection.ipynb</a>.</p>
			<h2 id="_idParaDest-161" class="calibre5"><a id="_idTextAnchor165" class="calibre6 pcalibre pcalibre1"/>How to do it...</h2>
			<p class="calibre3">We will transform the text using the BERT sentence transformers model and then use the community detection clustering algorithm on the resulting embeddings.</p>
			<ol class="calibre13">
				<li class="calibre14">Do the necessary imports. Here, you might need to download the stopwords corpus from NLTK. Please see the <em class="italic">Removing stopwords </em>recipe in <a href="B18411_01.xhtml#_idTextAnchor013" class="calibre6 pcalibre pcalibre1"><em class="italic">Chapter 1</em></a> for detailed instructions on how to do this.<pre class="source-code">
import pandas as pd
import nltk
import re
from nltk.corpus import stopwords
from sentence_transformers import SentenceTransformer, util</pre></li>				<li class="calibre14">Run the <strong class="source-inline1">language </strong><strong class="source-inline1">utilities</strong> file:<pre class="source-code">
%run -i "../util/lang_utils.ipynb"</pre></li>				<li class="calibre14">Load the BBC data and print it:<pre class="source-code">
bbc_df = pd.read_csv("../data/bbc-text.csv")
print(bbc_df)</pre><p class="calibre3">The result will look like <em class="italic">Figure 6</em><em class="italic">.1</em>.</p></li>				<li class="calibre14">Load the<a id="_idIndexMarker345" class="calibre6 pcalibre pcalibre1"/> model and create the embeddings. See the <em class="italic">Using BERT and OpenAI embeddings instead of word embeddings</em> recipe in <a href="B18411_03.xhtml#_idTextAnchor067" class="calibre6 pcalibre pcalibre1"><em class="italic">Chapter 3</em></a> for more information on sentence embeddings. The community detection algorithm requires the embeddings to be in the form of tensors; hence, we must set <strong class="source-inline1">convert_to_tensor</strong> to <strong class="source-inline1">True</strong>:<pre class="source-code">
model = SentenceTransformer('all-MiniLM-L6-v2')
embeddings = model.encode(bbc_df["text"], convert_to_tensor=True)</pre></li>				<li class="calibre14">In this<a id="_idIndexMarker346" class="calibre6 pcalibre pcalibre1"/> step, we will create the clusters. We will specify the threshold for similarity to be <strong class="source-inline1">0.7</strong> on a scale from 0 to 1. This will make sure that the resulting communities are very similar to each other. The minimum community size is 10; that means that a minimum of 10 news articles are required to form a cluster. If we want larger, more general clusters, we should use a larger number for the minimum community size. A more granular clustering should use a smaller number. Any cluster with fewer members will not appear in the output. The result is a list of lists, where each inner list represents a cluster and lists the row IDs of cluster members in the original dataframe:<pre class="source-code">
clusters = util.community_detection(
    embeddings, threshold=0.7, min_community_size=10)
print(clusters)</pre><p class="calibre3">The result will vary and might look like this:</p><pre class="source-code">[[117, 168, 192, 493, 516, 530, 638, 827, 883, 1082, 1154, 1208, 1257, 1359, 1553, 1594, 1650, 1898, 1938, 2059, 2152], [76, 178, 290, 337, 497, 518, 755, 923, 1057, 1105, 1151, 1172, 1242, 1560, 1810, 1813, 1882, 1942, 1981], [150, 281, 376, 503, 758, 900, 1156, 1405, 1633, 1636, 1645, 1940, 1946, 1971], [389, 399, 565, 791, 1014, 1018, 1259, 1288, 1440, 1588, 1824, 1917, 2024], [373, 901, 1004, 1037, 1041, 1323, 1499, 1534, 1580, 1621, 1751, 2178], [42, 959, 1063, 1244, 1292, 1304, 1597, 1915, 2081, 2104, 2128], [186, 193, 767, 787, 1171, 1284, 1625, 1651, 1797, 2148], [134, 388, 682, 1069, 1476, 1680, 2106, 2129, 2186, 2198]]</pre></li>				<li class="calibre14">Here, we <a id="_idIndexMarker347" class="calibre6 pcalibre pcalibre1"/>will define a function that prints the most common words by cluster. We will <a id="_idIndexMarker348" class="calibre6 pcalibre pcalibre1"/>take the clusters created by the community detection algorithm and the original dataframe. For each cluster, we will first select the sentences that represent it and then get the most frequent words by using the <strong class="source-inline1">get_most_frequent_words</strong> function, which we defined in <a href="B18411_04.xhtml#_idTextAnchor106" class="calibre6 pcalibre pcalibre1"><em class="italic">Chapter 4</em></a>, in the <em class="italic">Clustering sentences using K-Means: unsupervised text classification</em> recipe. This function is also located in the <strong class="source-inline1">lang_utils</strong> notebook that we ran in the second step:<pre class="source-code">
def print_words_by_cluster(clusters, input_df):
    for i, cluster in enumerate(clusters):
        print(f"\nCluster {i+1}, {len(cluster)} elements ")
        sentences = input_df.iloc[cluster]["text"]
        all_text = " ".join(sentences)
        freq_words = get_most_frequent_words(all_text)
        print(freq_words)</pre></li>				<li class="calibre14">Now, use the function on the model output (<strong class="source-inline1">truncated</strong>). We can see that there are<a id="_idIndexMarker349" class="calibre6 pcalibre pcalibre1"/> many more specific <a id="_idIndexMarker350" class="calibre6 pcalibre pcalibre1"/>clusters than just the five topics in the original BBC dataset:<pre class="source-code">
Cluster 1, 21 elements
['mr', 'labour', 'brown', 'said', 'blair', 'election', 'minister', 'prime', 'chancellor', 'would', 'party', 'new', 'campaign', 'told', 'government', ...]
Cluster 2, 19 elements
['yukos', 'us', 'said', 'russian', 'oil', 'gazprom', 'court', 'rosneft', 'russia', 'yugansk', 'company', 'bankruptcy', 'auction', 'firm', 'unit', ...]
Cluster 3, 14 elements
['kenteris', 'greek', 'thanou', 'iaaf', 'said', 'athens', 'tests', 'drugs', 'olympics', 'charges', 'also', 'decision', 'test', 'athletics', 'missing', ...]
Cluster 4, 13 elements
['mr', 'tax', 'howard', 'labour', 'would', 'said', 'tory', 'election', 'government', 'taxes', 'blair', 'spending', 'tories', 'party', 'cuts',...]
Cluster 5, 12 elements
['best', 'film', 'aviator', 'director', 'actor', 'foxx', 'swank', 'actress', 'baby', 'million', 'dollar', 'said', 'win', 'eastwood', 'jamie',...]
Cluster 6, 11 elements
['said', 'prices', 'market', 'house', 'uk', 'figures', 'mortgage', 'housing', 'year', 'lending', 'november', 'price', 'december', 'rise', 'rose', ...]
Cluster 7, 10 elements
['lse', 'deutsche', 'boerse', 'bid', 'euronext', 'said', 'exchange', 'london', 'offer', 'stock', 'would', 'also', 'shareholders', 'german', 'market',...]
Cluster 8, 10 elements
['dollar', 'us', 'euro', 'said', 'currency', 'deficit', 'analysts', 'trading', 'yen', 'record', 'exports', 'economic', 'trade', 'markets', 'european',...]</pre></li>			</ol>
			<h1 id="_idParaDest-162" class="calibre7"><a id="_idTextAnchor166" class="calibre6 pcalibre pcalibre1"/>K-Means topic modeling with BERT</h1>
			<p class="calibre3">In <a id="_idIndexMarker351" class="calibre6 pcalibre pcalibre1"/>this recipe, we will use the K-Means algorithm to do unsupervised topic classification, using the BERT embeddings to encode the data. This recipe shares many commonalities with the <em class="italic">Clustering sentences using K-Means – unsupervised text classification</em> recipe in <a href="B18411_04.xhtml#_idTextAnchor106" class="calibre6 pcalibre pcalibre1"><em class="italic">Chapter 4</em></a>.</p>
			<p class="calibre3">The <a id="_idIndexMarker352" class="calibre6 pcalibre pcalibre1"/>K-Means algorithm is <a id="_idIndexMarker353" class="calibre6 pcalibre pcalibre1"/>used to find similar clusters with any kind of data and is an easy way to see trends in the data. It is frequently used while performing preliminary data analysis to quickly check the different types of data that appear in a dataset. We can use it with text data and encode the data using a sentence transformer model.</p>
			<h2 id="_idParaDest-163" class="calibre5"><a id="_idTextAnchor167" class="calibre6 pcalibre pcalibre1"/>Getting ready</h2>
			<p class="calibre3">We will be using the <code>sklearn.cluster.KMeans</code> object to do the unsupervised clustering, as well as using HuggingFace <code>sentence transformers</code>. Both packages are part of the poetry environment.</p>
			<p class="calibre3">The notebook is located at <a href="https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter06/6.3-kmeans_with_bert.ipynb" class="calibre6 pcalibre pcalibre1">https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter06/6.3-kmeans_with_bert.ipynb</a>.</p>
			<h2 id="_idParaDest-164" class="calibre5"><a id="_idTextAnchor168" class="calibre6 pcalibre pcalibre1"/>How to do it...</h2>
			<p class="calibre3">In the recipe, we<a id="_idIndexMarker354" class="calibre6 pcalibre pcalibre1"/> will load the BBC dataset and encode it <a id="_idIndexMarker355" class="calibre6 pcalibre pcalibre1"/>by using the sentence transformers package. We will then use the K-Means clustering algorithm to create five clusters. After that, we will test the model on the test set to see how well it would perform on unseen data:</p>
			<ol class="calibre13">
				<li class="calibre14">Do the necessary imports:<pre class="source-code">
import re
import string
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.cluster import KMeans
from nltk.probability import FreqDist
from nltk.corpus import stopwords
from sentence_transformers import SentenceTransformer</pre></li>				<li class="calibre14">Run the language utilities file. This will allow us to reuse the <strong class="source-inline1">print_most_common_words_by_cluster</strong> function in this recipe:<pre class="source-code">
%run -i "../util/lang_utils.ipynb"</pre></li>				<li class="calibre14">Read and print the data:<pre class="source-code">
bbc_df = pd.read_csv("../data/bbc-text.csv")
print(bbc_df)</pre><p class="calibre3">The result should look like the one in <em class="italic">Figure 6</em><em class="italic">.1</em>.</p></li>				<li class="calibre14">In this step, we will split the data into <strong class="source-inline1">training</strong> and <strong class="source-inline1">testing</strong>. We limit the testing size to 10% of the whole dataset. The length of the training set is 2002 and the length of the test set is 223:<pre class="source-code">
bbc_train, bbc_test = train_test_split(bbc_df, test_size=0.1)
print(len(bbc_train))
print(len(bbc_test))</pre><p class="calibre3">The result will be as follows:</p><pre class="source-code">2002
223</pre></li>				<li class="calibre14">Here, we <a id="_idIndexMarker356" class="calibre6 pcalibre pcalibre1"/>will assign the list of texts to the <strong class="source-inline1">documents</strong> variable. We <a id="_idIndexMarker357" class="calibre6 pcalibre pcalibre1"/>will then read in the <strong class="source-inline1">all-MiniLM-L6-v2</strong> model to use for the sentence embeddings and encode the text data. Next, we will initialize a KMeans model with five clusters, setting the <strong class="source-inline1">n_init</strong> parameter to <strong class="source-inline1">auto</strong>, which determines the number of times the algorithm is run. We will also set the <strong class="source-inline1">init</strong> parameter to <strong class="source-inline1">k-means++</strong>. This parameter ensures faster convergence of the algorithm. We will then train the initialized model:<pre class="source-code">
documents = bbc_train['text'].values
model = SentenceTransformer('all-MiniLM-L6-v2')
encoded_data = model.encode(documents)
km = KMeans(n_clusters=5, n_init='auto', init='k-means++')
km.fit(encoded_data)</pre></li>				<li class="calibre14">Print out the most common words by topic:<pre class="source-code">
print_most_common_words_by_cluster(documents, km, 5)</pre><p class="calibre3">The results will vary; our results look like this:</p><pre class="source-code">0
['said', 'people', 'new', 'also', 'mr', 'technology', 'would', 'one', 'mobile', ...]
1
['said', 'game', 'england', 'first', 'win', 'world', 'last', 'would', 'one', 'two', 'time',...]
2
['said', 'film', 'best', 'music', 'also', 'year', 'us', 'one', 'new', 'awards', 'show',...]
3
['said', 'mr', 'would', 'labour', 'government', 'people', 'blair', 'party', 'election', 'also', 'minister', ...]
4
['said', 'us', 'year', 'mr', 'would', 'also', 'market', 'company', 'new', 'growth', 'firm', 'economy', ...]</pre><p class="calibre3">We can see that the<a id="_idIndexMarker358" class="calibre6 pcalibre pcalibre1"/> mapping of topics is as follows: 0 is tech, 1 is sport, 2 is entertainment, 3 is politics, and 4 is business.</p></li>				<li class="calibre14">We can <a id="_idIndexMarker359" class="calibre6 pcalibre pcalibre1"/>now use the test data to see how well the model performs on unseen data. First, we must create a prediction column in the test dataframe and populate it with the cluster number for each of the test inputs:<pre class="source-code">
bbc_test["prediction"] = bbc_test["text"].apply(
    lambda x: km.predict(model.encode([x]))[0])
print(bbc_test)</pre><p class="calibre3">The results will vary; this is our output:</p></li>			</ol>
			<div><div><img src="img/B18411_06_5.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.4 – The result of running K-Means on the test dataframe</p>
			<ol class="calibre13">
				<li value="8" class="calibre14">Now, we will <a id="_idIndexMarker360" class="calibre6 pcalibre pcalibre1"/>create a mapping between<a id="_idIndexMarker361" class="calibre6 pcalibre pcalibre1"/> the cluster number and the topic name, which we discovered manually by looking at the most frequent words for each cluster. We will then create a column with the predicted topic name for every text in the test set by using the mapping and the <strong class="source-inline1">prediction</strong> column we created in the previous step. Now, we can compare the predictions of the model with the true value of the data. We will use the <strong class="source-inline1">classification_report</strong> function from <strong class="source-inline1">sklearn</strong> to get the corresponding <a id="_idIndexMarker362" class="calibre6 pcalibre pcalibre1"/>statistics. Finally, we will print out the classification report for the predictions:<pre class="source-code">
topic_mapping = {0:"tech", 1:"sport",
    2:"entertainment", 3:"politics", 4:"business"}
bbc_test["pred_category"] = bbc_test["prediction"].apply(
    lambda x: topic_mapping[x])
print(classification_report(bbc_test["category"],
    bbc_test["pred_category"]))</pre><p class="calibre3">The result will be as follows:</p><pre class="source-code">               precision    recall  f1-score   support
     business       0.98      0.96      0.97        55
entertainment       0.95      1.00      0.97        38
     politics       0.97      0.93      0.95        42
        sport       0.98      0.96      0.97        47
         tech       0.93      0.98      0.95        41
     accuracy                           0.96       223
    macro avg       0.96      0.97      0.96       223
 weighted avg       0.96      0.96      0.96       223</pre><p class="calibre3">The <a id="_idIndexMarker363" class="calibre6 pcalibre pcalibre1"/>scores are very high – almost perfect. Most of this speaks to the quality of the sentence embedding model that we used.</p></li>				<li class="calibre14">Define a new example:<pre class="source-code">
new_example = """Manchester United players slumped to the turf
at full-time in Germany on Tuesday in acknowledgement of what their
latest pedestrian first-half display had cost them. The 3-2 loss at
RB Leipzig means United will not be one of the 16 teams in the draw
for the knockout stages of the Champions League. And this is not the
only price for failure. The damage will be felt in the accounts, in
the dealings they have with current and potentially future players
and in the faith the fans have placed in manager Ole Gunnar Solskjaer.
With Paul Pogba's agent angling for a move for his client and ex-United
defender Phil Neville speaking of a "witchhunt" against his former team-mate
Solskjaer, BBC Sport looks at the ramifications and reaction to a big loss for United."""</pre></li>				<li class="calibre14">Print <a id="_idIndexMarker364" class="calibre6 pcalibre pcalibre1"/>the <a id="_idIndexMarker365" class="calibre6 pcalibre pcalibre1"/>prediction for the new example:<pre class="source-code">
predictions = km.predict(model.encode([new_example]))
print(predictions[0])</pre><p class="calibre3">The output will be as follows:</p><pre class="source-code">1</pre></li>			</ol>
			<p class="calibre3">  Cluster number 1 corresponds to sport, which is the correct classification.</p>
			<h1 id="_idParaDest-165" class="calibre7"><a id="_idTextAnchor169" class="calibre6 pcalibre pcalibre1"/>Topic modeling using BERTopic</h1>
			<p class="calibre3">In this recipe, we<a id="_idIndexMarker366" class="calibre6 pcalibre pcalibre1"/> will explore the BERTopic package that provides many different and versatile tools for topic modeling and visualization. It is especially useful if you would like to do different visualizations of the topic clusters created. This topic modeling algorithm uses BERT embeddings to encode the data, hence the “BERT” in the name. You can learn more about the algorithm and its constituent parts at <a href="https://maartengr.github.io/BERTopic/algorithm/algorithm.html" class="calibre6 pcalibre pcalibre1">https://maartengr.github.io/BERTopic/algorithm/algorithm.html</a>.</p>
			<p class="calibre3">The<a id="_idIndexMarker367" class="calibre6 pcalibre pcalibre1"/> BERTopic package, by default, uses the HDBSCAN algorithm to create clusters from the data in an unsupervised fashion. You can learn more about how the HDBSCAN algorithm works at <a href="https://hdbscan.readthedocs.io/en/latest/how_hdbscan_works.html" class="calibre6 pcalibre pcalibre1">https://hdbscan.readthedocs.io/en/latest/how_hdbscan_works.html</a>. However, it is also possible to customize the inner workings of a BERTopic object to use other algorithms. It is also possible to substitute other custom components into its pipeline. In this recipe, we will use the default settings, and you can experiment with other components.</p>
			<p class="calibre3">The resulting topics are of very high quality. There might be several reasons for this. One of them is the result of using BERT embeddings, which we saw in <a href="B18411_04.xhtml#_idTextAnchor106" class="calibre6 pcalibre pcalibre1"><em class="italic">Chapter 4</em></a>, to positively impact the classification results</p>
			<h2 id="_idParaDest-166" class="calibre5"><a id="_idTextAnchor170" class="calibre6 pcalibre pcalibre1"/>Getting ready</h2>
			<p class="calibre3">We will use the BERTopic package to create topic models for the BBC dataset. The package is included in the poetry environment and is also part of the <code>requirements.txt</code> file.</p>
			<p class="calibre3">The notebook is located at <a href="https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter06/6.3-kmeans_with_bert.ipynb" class="calibre6 pcalibre pcalibre1">https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter06/6.3-kmeans_with_bert.ipynb</a>.</p>
			<h2 id="_idParaDest-167" class="calibre5"><a id="_idTextAnchor171" class="calibre6 pcalibre pcalibre1"/>How to do it...</h2>
			<p class="calibre3">In this recipe, we will load the BBC dataset and preprocess it again. The preprocessing step will involve tokenizing the data and removing stopwords. Then we will create the topic model using BERTopic and inspect the results. We will also test the topic model on unseen data and use <code>classification_report</code> to see the accuracy statistics:</p>
			<ol class="calibre13">
				<li class="calibre14">Do the necessary imports:<pre class="source-code">
import pandas as pd
import numpy as np
from bertopic import BERTopic
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report</pre></li>				<li class="calibre14">Run<a id="_idIndexMarker368" class="calibre6 pcalibre pcalibre1"/> the language utilities file:<pre class="source-code">
%run -i "../util/lang_utils.ipynb"</pre></li>				<li class="calibre14">Define and <a id="_idIndexMarker369" class="calibre6 pcalibre pcalibre1"/>amend the stopwords, then read in the BBC data:<pre class="source-code">
stop_words = stopwords.words('english')
stop_words.append("said")
stop_words.append("mr")
bbc_df = pd.read_csv("../data/bbc-text.csv")</pre><p class="calibre3">In this step, we will preprocess the data. We will first tokenize it using the <code>word_tokenize</code> method from NLTK as shown in the <em class="italic">Dividing sentences into words – tokenization</em> recipe in <a href="B18411_01.xhtml#_idTextAnchor013" class="calibre6 pcalibre pcalibre1"><em class="italic">Chapter 1</em></a>. Then remove stopwords and finally put the text back together into a string. We must do the last step because the BERTopic uses a sentence embedding model, and that model requires a string, not a list of words:</p><pre class="source-code">bbc_df["text"] = bbc_df["text"].apply(
    lambda x: word_tokenize(x))
bbc_df["text"] = bbc_df["text"].apply(
    lambda x: [w for w in x if w not in stop_words])
bbc_df["text"] = bbc_df["text"].apply(lambda x: " ".join(x))</pre></li>				<li class="calibre14">Here, we will split the dataset into training and test sets, specifying the size of the test <a id="_idIndexMarker370" class="calibre6 pcalibre pcalibre1"/>set to be 10%. As a result, we will get 2002 datapoints for training and 223 for testing:<pre class="source-code">
bbc_train, bbc_test = train_test_split(bbc_df, test_size=0.1)
print(len(bbc_train))
print(len(bbc_test))</pre><p class="calibre3">The result will be as follows:</p><pre class="source-code">2002
223</pre></li>				<li class="calibre14">Extract the lists of texts from the dataframe:<pre class="source-code">
docs = bbc_train["text"].values</pre></li>				<li class="calibre14">In this <a id="_idIndexMarker371" class="calibre6 pcalibre pcalibre1"/>step, we willinitialize the <strong class="source-inline1">BERTopic</strong> object and then fit it on the documents extracted in <em class="italic">step 6</em>. We will specify the number of topics to be six, one more than the five that we are looking for. This is because a key difference between BERTopic and other topic modeling algorithms is that it has a special <strong class="bold">discard</strong> topic numbered -1. We could also specify a larger number of topics. In that case, they would be narrower than the general five categories of business, politics, entertainment, tech, and sport:<pre class="source-code">
topic_model = BERTopic(nr_topics=6)
topics, probs = topic_model.fit_transform(docs)</pre></li>				<li class="calibre14">Here, we will print out the information about the resulting topic model. Other than the <strong class="source-inline1">discard</strong> topic, the topics align well with the gold labels assigned by human annotators. The function prints out the most representative words for each topic, as well as the most representative documents:<pre class="source-code">
print(topic_model.get_topic_info())</pre><p class="calibre3">The<a id="_idIndexMarker372" class="calibre6 pcalibre pcalibre1"/> results<a id="_idIndexMarker373" class="calibre6 pcalibre pcalibre1"/> will vary; here is an example result:</p><pre class="source-code">   Topic  Count                                 Name  \
0     -1    222             -1_also_company_china_us
1      0    463             0_england_game_win_first
2      1    393      1_would_labour_government_blair
3      2    321             2_film_best_music_awards
4      3    309  3_people_mobile_technology_software
5      4    294             4_us_year_growth_economy
                                      Representation  \
0  [also, company, china, us, would, year, new, p...
1  [england, game, win, first, club, world, playe...
2  [would, labour, government, blair, election, p...
3  [film, best, music, awards, show, year, band, ...
4  [people, mobile, technology, software, digital...
5  [us, year, growth, economy, economic, company,...
                                 Representative_Docs
0  [us retail sales surge december us retail sale...
1  [ireland win eclipses refereeing errors intern...
2  [lib dems unveil election slogan liberal democ...
3  [scissor sisters triumph brits us band scissor...
4  [mobiles media players yet mobiles yet ready a...
5  [consumer spending lifts us growth us economic...</pre></li>				<li class="calibre14">In this step, we <a id="_idIndexMarker374" class="calibre6 pcalibre pcalibre1"/>will print the topics. We can see<a id="_idIndexMarker375" class="calibre6 pcalibre pcalibre1"/> from the words that the zeroth topic is sport, the first topic is politics, the second topic is entertainment, the third topic is tech, and the fourth topic is business.</li>
			</ol>
			<div><div><img src="img/B18411_06_6.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.5 – The topics generated by BERTopic</p>
			<ol class="calibre13">
				<li value="9" class="calibre14">In this <a id="_idIndexMarker376" class="calibre6 pcalibre pcalibre1"/>step, we will generate the topic labels <a id="_idIndexMarker377" class="calibre6 pcalibre pcalibre1"/>using the <strong class="source-inline1">generate_topic_labels</strong> function. We will input the number of words to use for the topic label, the separator (in this case, this is an underscore), and whether to include the topic number. As a result, we will get a list of topic names. We can see from the resulting topics that we could include <em class="italic">would</em> as a stopword:<pre class="source-code">
topic_model.generate_topic_labels(
    nr_words=5, topic_prefix=True, separator='_')</pre><p class="calibre3">The result will be similar to the following:</p><pre class="source-code">['-1_also_company_china_us_would',
 '0_england_game_win_first_club',
 '1_would_labour_government_blair_election',
 '2_film_best_music_awards_show',
 '3_people_mobile_technology_software_digital',
 '4_us_year_growth_economy_economic']</pre></li>				<li class="calibre14">Here, we<a id="_idIndexMarker378" class="calibre6 pcalibre pcalibre1"/> will define the <strong class="source-inline1">get_prediction</strong> function that gives us the topic number for a text input and a corresponding model. The<a id="_idIndexMarker379" class="calibre6 pcalibre pcalibre1"/> function transforms the input text and outputs a tuple of two lists. One is a list of topic numbers and the other is the list of probabilities of assigning each topic. The lists are sorted in the order of the most probable topic, so we can take the first element of the first list as the predicted topic and return it:<pre class="source-code">
def get_prediction(input_text, model):
    pred = model.transform(input_text)
    pred = pred[0][0]
    return pred</pre></li>				<li class="calibre14">In this step, we will define a column for predictions in the test dataframe and then use the function we defined in the previous step to get predictions for each text in the dataframe. We will then create a mapping of topic numbers to gold topic labels that we can use to test the effectiveness of the topic model:<pre class="source-code">
bbc_test["prediction"] = bbc_test["text"].apply(
    lambda x: get_prediction(x, topic_model))
topic_mapping = {0:"sport", 1:"politics",
    2:"entertainment", 3:"tech", 4:"business", -1:"discard"}</pre></li>				<li class="calibre14">Here, we will create a new column in the test dataframe to record the predicted topic name using the mapping we created. We will then filter the test set to only use entries that have not been predicted to be the discard topic -1:<pre class="source-code">
bbc_test["pred_category"] = bbc_test["prediction"].apply(
    lambda x: topic_mapping[x])
test_data = bbc_test.loc[bbc_test['prediction'] != -1]
print(classification_report(test_data["category"],
    test_data["pred_category"]))</pre><p class="calibre3">The<a id="_idIndexMarker380" class="calibre6 pcalibre pcalibre1"/> result <a id="_idIndexMarker381" class="calibre6 pcalibre pcalibre1"/>will be similar to this:</p><pre class="source-code">               precision    recall  f1-score   support
     business       0.95      0.86      0.90        21
entertainment       0.97      1.00      0.98        30
     politics       0.94      1.00      0.97        46
        sport       1.00      1.00      1.00        62
         tech       0.96      0.88      0.92        25
     accuracy                           0.97       184
    macro avg       0.96      0.95      0.95       184
 weighted avg       0.97      0.97      0.97       184</pre><p class="calibre3">The test scores are very high. This is reflective of the encoding model, the BERTopic model, which is also a sentence transformer model, as in the previous recipe.</p></li>				<li class="calibre14">In this step, we will define a new example to test with the model and print it. We will use the <strong class="source-inline1">iloc</strong> function from the <strong class="source-inline1">pandas</strong> package to access the first element of the <strong class="source-inline1">bbc_test</strong> dataframe:<pre class="source-code">
new_input = bbc_test["text"].iloc[0]
print(new_input)
howard dismisses tory tax fears michael howard dismissed fears conservatives plans £4bn tax cuts modest . defended package saying plan tories first budget hoped able go . tories monday highlighted £35bn wasteful spending would stop allow tax cuts reduced borrowing spending key services . ...</pre><p class="calibre3">The<a id="_idIndexMarker382" class="calibre6 pcalibre pcalibre1"/> example<a id="_idIndexMarker383" class="calibre6 pcalibre pcalibre1"/> is about politics, which should be topic 1.</pre></li>				<li class="calibre14">Obtain a prediction from the model and print it:<pre class="source-code">
print(topic_model.transform(new_input))</pre><p class="calibre3">The result will be a correct prediction:</p><pre class="source-code">([1], array([1.]))</pre></li>			</ol>
			<h2 id="_idParaDest-168" class="calibre5"><a id="_idTextAnchor172" class="calibre6 pcalibre pcalibre1"/>There’s more...</h2>
			<p class="calibre3">Now, we can find topics that are similar to a particular word, phrase, or sentence. This way, we could easily find a topic to which a text corresponds within the dataset. We will use a word, a phrase, and a sentence to see how well the model can show the corresponding topics:</p>
			<ol class="calibre13">
				<li class="calibre14">Find topics most similar to the <strong class="source-inline1">sports</strong> word with the corresponding similarity scores. Combine the topic numbers and similarity scores in a list of tuples and print them. The tuples are a combination of the topic number and the similarity score between the text that is passed in and the particular topic:<pre class="source-code">
topics, similarity = topic_model.find_topics("sports", top_n=5)
sim_topics = list(zip(topics, similarity))
print(sim_topics)</pre><p class="calibre3">The most similar topic is topic 0, which is sport:</p><pre class="source-code">[(0, 0.29033981040460977), (3, 0.049293092462828376), (-1, -0.0047265937178774895), (2, -0.02074380026102955), (4, -0.03699168959416969)]</pre></li>				<li class="calibre14">Repeat <a id="_idIndexMarker384" class="calibre6 pcalibre pcalibre1"/>the<a id="_idIndexMarker385" class="calibre6 pcalibre pcalibre1"/> preceding step for the <strong class="source-inline1">business and economics</strong> example phrase:<pre class="source-code">
topics, similarity = topic_model.find_topics(
    "business and economics",
    top_n=5)
sim_topics = list(zip(topics, similarity))
print(sim_topics)</pre><p class="calibre3">Here, the most similar topic is topic 4, which is business:</p><pre class="source-code">[(4, 0.29003573983158404), (-1, 0.26259758927249205), (3, 0.15627005753581313), (1, 0.05491237184012845), (0, 0.010567363445904386)]</pre></li>				<li class="calibre14">Now repeat the same process for the following example sentence: <strong class="source-inline1">"YouTube removed a snippet of code that publicly disclosed whether a channel receives ad payouts, obscuring which creators benefit most from the platform."</strong>. We would expect this to be most similar to the tech topic:<pre class="source-code">
input_text = """YouTube removed a snippet of code that publicly disclosed whether a channel receives ad payouts,
obscuring which creators benefit most from the platform."""
topics, similarity = topic_model.find_topics(
    input_text, top_n=5)
sim_topics = list(zip(topics, similarity))
print(sim_topics)</pre><p class="calibre3">In the output, we can see that the most similar topic is topic 3, which is tech:</p><pre class="source-code">[(3, 0.2540850599909866), (-1, 0.172097560474608), (2, 0.1367798346494483), (4, 0.10243553209139492), (1, 0.06954579004136925)]</pre></li>			</ol>
			<h1 id="_idParaDest-169" class="calibre7"><a id="_idTextAnchor173" class="calibre6 pcalibre pcalibre1"/>Using contextualized topic models</h1>
			<p class="calibre3">In this <a id="_idIndexMarker386" class="calibre6 pcalibre pcalibre1"/>recipe, we will look at another topic model algorithm: contextualized topic models. To produce a more effective topic model, it combines embeddings with a bag-of-words document representation.</p>
			<p class="calibre3">We will show you how to use the trained topic model with input in other languages. This feature is especially useful because we can create a topic model in one language, for example, one that has many resources available, and then apply it on another language that does not have as many resources. To achieve this, we will utilize a multilingual embedding model in order to encode the data.</p>
			<h2 id="_idParaDest-170" class="calibre5"><a id="_idTextAnchor174" class="calibre6 pcalibre pcalibre1"/>Getting ready</h2>
			<p class="calibre3">We will need the <code>contextualized-topic-models</code> package for this recipe. It is part of the poetry environment and the <code>requirements.txt</code> file.</p>
			<p class="calibre3">The notebook is located at <a href="https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter06/6.5-contextualized-tm.ipynb" class="calibre6 pcalibre pcalibre1">https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter06/6.5-contextualized-tm.ipynb</a>.</p>
			<h2 id="_idParaDest-171" class="calibre5"><a id="_idTextAnchor175" class="calibre6 pcalibre pcalibre1"/>How to do it...</h2>
			<p class="calibre3">In this recipe, we will load the data, then <a id="_idIndexMarker387" class="calibre6 pcalibre pcalibre1"/>divide it into sentences, preprocess it, and use the <strong class="bold">gsdmm</strong> model <a id="_idIndexMarker388" class="calibre6 pcalibre pcalibre1"/>to cluster the sentences into topics. If you would like more information about the algorithm, please <a id="_idIndexMarker389" class="calibre6 pcalibre pcalibre1"/>see the package documentation at <a href="https://pypi.org/project/contextualized-topic-models/" class="calibre6 pcalibre pcalibre1">https://pypi.org/project/contextualized-topic-models/</a>.</p>
			<ol class="calibre13">
				<li class="calibre14">Do the necessary imports:<pre class="source-code">
import pandas as pd
from nltk.corpus import stopwords
from contextualized_topic_models.utils.preprocessing import( 
    WhiteSpacePreprocessingStopwords)
from contextualized_topic_models.models.ctm import ZeroShotTM
from contextualized_topic_models.utils.data_preparation import( 
    TopicModelDataPreparation)</pre></li>				<li class="calibre14">Suppress the warnings:<pre class="source-code">
import warnings
warnings.filterwarnings('ignore')
warnings.filterwarnings("ignore", category = DeprecationWarning)
import os
os.environ["TOKENIZERS_PARALLELISM"] = "false"</pre></li>				<li class="calibre14">Create the stopwords list and read in the data:<pre class="source-code">
stop_words = stopwords.words('english')
stop_words.append("said")
bbc_df = pd.read_csv("../data/bbc-text.csv")</pre></li>				<li class="calibre14">In this step, we will create the preprocessor object and use it to preprocess the documents. The <strong class="source-inline1">contextualized-topic-models</strong> package provides different preprocessors that prepare the data to be used in the topic model algorithm. This preprocessor tokenizes the documents, removes the stopwords, and puts them back into a string. It returns the list of preprocessed documents, the list<a id="_idIndexMarker390" class="calibre6 pcalibre pcalibre1"/> of original documents, the dataset vocabulary, and a list of document indices in the original dataframe:<pre class="source-code">
documents = bbc_df["text"]
preprocessor = WhiteSpacePreprocessingStopwords(
    documents, stopwords_list=stop_words)
preprocessed_documents,unpreprocessed_documents,vocab,indices =\
    preprocessor.preprocess()</pre></li>				<li class="calibre14">Here, we will create the <strong class="source-inline1">TopicModelDataPreparation</strong> object. We will pass the embedding model name as the parameter. This is a multilingual model that can encode text in various languages with good results. We will then fit it on the documents. It uses an embedding model to turn the texts into embeddings and also creates a bag-of-words model. The output is a <strong class="source-inline1">CTMDataset</strong> object that represents the training dataset in the format required by the topic model training algorithm:<pre class="source-code">
tp = TopicModelDataPreparation(
    "distiluse-base-multilingual-cased")
training_dataset = tp.fit(
    text_for_contextual=unpreprocessed_documents,
    text_for_bow=preprocessed_documents)</pre></li>				<li class="calibre14">In this step, we will create the topic model using the <strong class="source-inline1">ZeroShotTM</strong> object. The term <strong class="bold">zero shot</strong> means <a id="_idIndexMarker391" class="calibre6 pcalibre pcalibre1"/>that the model has no prior information about the documents. We will input the size of the vocabulary for the bag-of-words model, the size of the embeddings vector, the number of topics (the <strong class="source-inline1">n_components</strong> parameter), and the number of epochs to train the model for. We will use five topics, since the BBC dataset has that many topics. When you apply this algorithm to your data, you will need to experiment with different numbers<a id="_idIndexMarker392" class="calibre6 pcalibre pcalibre1"/> of topics. Finally, we will fit the initialized topic model on the training dataset:<pre class="source-code">
ctm = ZeroShotTM(bow_size=len(tp.vocab),
    contextual_size=512, n_components=5,
    num_epochs=100)
ctm.fit(training_dataset)</pre></li>				<li class="calibre14">Here, we will inspect the topics. We can see that they fit well with the golden labels. Topic 0 is tech, topic 1 is sport, topic 2 is business, topic 3 is entertainment, and topic 4 is politics:<pre class="source-code">
ctm.get_topics()</pre><p class="calibre3">The results will vary; this is the output we get:</p></li>			</ol>
			<div><div><img src="img/B18411_06_7.jpg" alt="" role="presentation" class="calibre4"/>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.6 – The contextualized model output</p>
			<ol class="calibre13">
				<li value="8" class="calibre14">Now, we will initialize a new news piece, this time in Spanish, to see how effective the topic model trained on English-language documents will be on a news article in <a id="_idIndexMarker393" class="calibre6 pcalibre pcalibre1"/>a different language. This particular news piece should fall into the tech topic. We will preprocess it using the <strong class="source-inline1">TopicModelDataPreparation</strong> object. To then use the model on the encoded text, we need to create a dataset object. That is why we have to include the Spanish news piece in a list and then pass it on for data preparation. Finally, we must pass the dataset (that consists of only one element) through the model:<pre class="source-code">
spanish_news_piece = """IBM anuncia el comienzo de la "era de la utilidad cuántica" y anticipa un superordenador en 2033.
La compañía asegura haber alcanzado un sistema de computación que no se puede simular con procedimientos clásicos."""
testing_dataset = tp.transform([spanish_news_piece])</pre></li>				<li class="calibre14">In this step, we will get the topic distribution for the testing dataset we created in the previous step. The result is a list of lists, where each individual list represents the probability that a particular text belongs to that topic. The probabilities have the same indices in individual lists as the topic numbers:<pre class="source-code">
ctm.get_doc_topic_distribution(testing_dataset)</pre><p class="calibre3">In this case, the highest probability is for topic 0, which is indeed tech:</p><pre class="source-code">array([[0.5902461,0.09361929,0.14041995,0.07586181,0.0998529 ]],
      dtype=float32)</pre></li>			</ol>
			<h2 id="_idParaDest-172" class="calibre5"><a id="_idTextAnchor176" class="calibre6 pcalibre pcalibre1"/>See also</h2>
			<p class="calibre3">For more information about contextualized topic models, see <a href="https://contextualized-topic-models.readthedocs.io/en/latest/index.html" class="calibre6 pcalibre pcalibre1">https://contextualized-topic-models.readthedocs.io/en/latest/index.html</a>.</p>
		</div>
	</body></html>