- en: '8'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '8'
- en: Putting Things Away
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 放置物品
- en: 'Imagine that you have to get to Grandma’s house, which, according to legend,
    is *over the hills and through the woods*, and two states away. That would be
    two countries away if you live in Europe. To plan your trip, you can start in
    one of two ways. Ignoring the fact that Google has taken away most map reading
    and navigation skills from today’s youth, you would get out a map and do one of
    the following:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你必须去奶奶家，根据传说，奶奶家在*山丘之上，穿过树林*，距离两个州。如果你住在欧洲，那将是两个国家之外。为了规划你的旅行，你可以从以下两种方式之一开始。忽略谷歌已经从今天的年轻人那里夺走了大部分的地图阅读和导航技能的事实，你会拿出地图并做以下之一：
- en: Start at your house and try to find the roads that are closest to a straight
    line to Grandma’s house
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从你家出发，尝试找到最接近奶奶家直线的道路
- en: Start at Grandma’s house and try to find roads leading to your home
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从奶奶家出发，尝试找到通往你家的道路
- en: From either direction, you will find that the road or path you seek forks, intersects,
    changes, meanders, and may even come to a dead end. Also, all roads are not created
    equally – some are bigger, with higher speed limits, and some are smaller, with
    more stop signs. In the end, you pick your route by the combination of decisions
    that results in the lowest cost. This cost may be in terms of *time* – how long
    to get there. It may be in terms of *distance* – how many miles to cover. Or it
    may be in *monetary* terms – there is a toll road that charges an extra fee.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 从任何方向出发，你会发现你寻求的道路或路径会分叉、交叉、改变、蜿蜒，甚至可能走到死胡同。此外，并非所有道路都同等重要——有些道路更宽，限速更高，而有些道路则更窄，有更多的停车标志。最终，你将通过一系列决策来选择路线，以实现最低的成本。这种成本可能是以*时间*来衡量的——到达那里需要多长时间。它可能是以*距离*来衡量的——需要覆盖多少英里。或者它可能是以*金钱*来衡量的——存在一条收费道路，需要额外收费。
- en: In this chapter, we will be discussing several ways to solve problems involving
    choosing a chain of multiple decisions where there is some metric – such as cost
    – to help us select which combination is somehow the best. There is a lot of information
    here that is widely used in robotics, and we will be expanding our horizons a
    bit beyond our toy-grabbing robot to look at robot path planning and decision-making
    in general. These are critical skills for any robotics practitioner, so they are
    included here. This chapter covers the basics of decision-making processes for
    **artificial intelligence** (**AI**) where the problem can be described in terms
    of either a **classification problem** (determining whether this situation belongs
    to one or more groups of similar situations) or a **regression problem** (fitting
    or approximating a function that can be a curve or a path). Finally, we will be
    applying two approaches to our robot problem – an expert system and random forests.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论几种解决涉及选择一系列决策的问题的方法，其中有一些度量标准——例如成本——可以帮助我们选择哪种组合可能是最好的。这里有很多信息在机器人学中得到了广泛应用，我们将超越我们的玩具抓取机器人，看看机器人的路径规划和一般决策。这些是任何机器人实践者必备的技能，因此它们被包含在这里。本章涵盖了人工智能（**AI**）决策过程的基础，其中问题可以用**分类问题**（确定这种情况是否属于一个或多个类似情况的一组）或**回归问题**（拟合或近似一个可以是曲线或路径的函数）来描述。最后，我们将应用两种方法来解决我们的机器人问题——专家系统和随机森林。
- en: 'This chapter will cover the following topics:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Decision trees and random forests
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 决策树和随机森林
- en: Path planning, grid searches, and the A* (A-star) algorithm
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 路径规划、网格搜索和A*（A星）算法
- en: Dynamic planning with the D* (D-star) technique
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用D*（D星）技术进行动态规划
- en: Expert systems and knowledge bases
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 专家系统和知识库
- en: At first glance, the concepts we will cover in this section – namely, path planning,
    decision trees, random forests, grid searches, and GPS route finders – don’t have
    much in common, other than all being part of computer algorithms used in AI. From
    my point of view, they are all basically the same concept and approach problems
    in the same way.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 初看，我们将在本节中涵盖的概念——即路径规划、决策树、随机森林、网格搜索和GPS路线查找——除了都是人工智能中使用的计算机算法的一部分之外，并没有太多共同之处。从我的观点来看，它们基本上是相同的概念，并以相同的方式处理问题。
- en: Technical requirements
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: The one tool we use for this chapter, you should have already installed from
    earlier chapters – **scikit-learn** ([http://scikit-learn.org/stable/developers/advanced_installation.html](http://scikit-learn.org/stable/developers/advanced_installation.html)).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本章中使用的工具，你应该已经在之前的章节中安装过——**scikit-learn** ([http://scikit-learn.org/stable/developers/advanced_installation.html](http://scikit-learn.org/stable/developers/advanced_installation.html))。
- en: 'Or, if you have the `pip` installer in Python, you can install it using the
    following command:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，如果你有Python的`pip`安装程序，你可以使用以下命令安装它：
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: You’ll find the code for this chapter at [https://github.com/PacktPublishing/Artificial-Intelligence-for-Robotics-2e](https://github.com/PacktPublishing/Artificial-Intelligence-for-Robotics-2e).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[https://github.com/PacktPublishing/Artificial-Intelligence-for-Robotics-2e](https://github.com/PacktPublishing/Artificial-Intelligence-for-Robotics-2e)找到本章的代码。
- en: Task analysis
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 任务分析
- en: Our task in this chapter is one that you may have been waiting for if you have
    been keeping score since [*Chapter 3*](B19846_03.xhtml#_idTextAnchor043), where
    we discussed our storyboards. We need to navigate around the room on our wheels
    and find a path to our destination, whether that is picking up a toy or driving
    to a toybox.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本章的任务可能是如果你从[*第3章*](B19846_03.xhtml#_idTextAnchor043)开始就一直在关注进度，你可能会期待的任务。在第3章中，我们讨论了我们的故事板。我们需要在轮子上在房间里导航，找到通往目的地的路径，无论是捡起玩具还是开车去玩具箱。
- en: To achieve this, we will be using **decision trees**, **classification** (a
    type of **unsupervised learning**), **fishbone diagrams**, which are good for
    troubleshooting, and finally, **path planning**.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这一点，我们将使用**决策树**、**分类**（一种**无监督学习**）、**鱼骨图**，这对于故障排除很有用，最后是**路径规划**。
- en: Introducing decision trees
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍决策树
- en: The concept of a **decision tree** is fairly simple. You are walking down the
    sidewalk and come to a corner. Here, you can go right, turn left, or go straight
    ahead. That is your decision. After making the decision – to turn left – you now
    have different decisions ahead of you than if you turned right. Each decision
    creates paths that lead to other decisions.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**决策树**的概念相当简单。你正在人行道上行走，来到一个拐角。在这里，你可以向右转，左转，或者直行。那是你的决策。做出决策后 – 向左转 – 你现在面临的不同决策比如果向右转要多。每个决策都会创建通往其他决策的路径。'
- en: As we are walking down the sidewalk, we have a goal in mind. We are not just
    wandering around aimlessly; we are trying to get to some goal. One or more combinations
    of decisions will get us to the goal. Let’s say the goal is to get to the grocery
    store to buy bread. There may be four or five paths down sidewalks that will get
    you to the store, but each path may be different in length or may have different
    paths. If one path goes up a hill, that may be harder than taking the level path.
    Another path may have you wait at a traffic light, which costs time. We assign
    a value to each of these attributes and generally want to pick the path with the
    lowest cost, or the highest reward, depending on the problem.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们沿着人行道行走时，我们心中有一个目标。我们并不是漫无目的地闲逛；我们试图达到某个目标。一个或多个决策组合将帮助我们达到目标。假设目标是去杂货店买面包。可能有四到五条人行道可以通往商店，但每条路径可能长度不同或路径不同。如果一条路径要上坡，那可能比走平路更难。另一条路径可能需要你在红绿灯处等待，这会浪费时间。我们为这些属性中的每一个分配一个值，通常我们希望选择成本最低或奖励最高的路径，具体取决于问题。
- en: 'In the following decision tree, we can break down the actions of the robot
    in order to pick up a toy. We start by looking at the toy aspect ratio (the length
    versus width of the bounding box we detected in [*Chapter 4*](B19846_04.xhtml#_idTextAnchor126)).
    We adjust the wrist of the robot arm based on the narrowest part of the toy. Then,
    we try to pick up the toy with that wrist position. If we are successful, we lift
    the toy off the ground and carry it to the toybox. If we fail, we try another
    position. After trying all of the positions, we go on to the next toy and try
    to come back to this toy later, hopefully from a different angle. You can see
    the utility of breaking down our actions this way, and it ends up that decision
    trees are useful for a lot of things, as we will see in this chapter:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的决策树中，我们可以分解机器人捡起玩具的动作。我们首先查看玩具的宽高比（我们在[*第4章*](B19846_04.xhtml#_idTextAnchor126)中检测到的边界框的长度与宽度）。我们根据玩具最窄的部分调整机器人手臂的腕部。然后，我们尝试用那个腕部位置捡起玩具。如果我们成功，我们就把玩具从地上拿起来，拿到玩具箱里。如果我们失败，我们尝试另一个位置。尝试了所有位置后，我们继续到下一个玩具，并试图稍后从这个玩具的角度回来，希望是从不同的角度。你可以看到这样分解我们的动作是有用的，结果证明决策树对很多事情都很有用，正如我们将在本章中看到的：
- en: '![Figure 8.1 – A simple decision tree on how to pick up toys](img/B19846_08_1.jpg)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![图8.1 – 如何捡起玩具的简单决策树](img/B19846_08_1.jpg)'
- en: Figure 8.1 – A simple decision tree on how to pick up toys
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.1 – 如何捡起玩具的简单决策树
- en: The general problem with decision tree-type problems is one of *exponential
    growth*. Let’s consider a chess game, a favorite problem set for AI. We have 20
    choices for an opening move (8 pawns and 2 knights, each with 2 possible moves).
    Each of these 20 moves has 20 possible next moves, and so on. So the first move
    has 20 choices, and the second move has 400 choices. The third move has 197,281
    choices! We soon have a very, very large decision tree as we try to plan ahead.
    We can say that each of these possible decisions is a **branch**, the state we
    are in after making the decision is a **leaf**, and the entire conceptual structure
    is a decision tree.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树类型问题的一般问题在于**指数级增长**。让我们以棋局为例，这是人工智能的一个热门问题集。我们有一个开局的20种选择（8个兵和2个骑士，每种都有2种可能的移动）。这20种移动中的每一种都有20种可能的后续移动，以此类推。所以第一步有20种选择，第二步有400种选择。第三步有197,281种选择！当我们试图提前规划时，很快就会有一个非常大的决策树。我们可以这样说，这些可能的决策是**分支**，做出决策后我们所处的状态是**叶子**，整个概念结构是一个决策树。
- en: Note
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 备注
- en: The secret to working with decision trees is to ruthlessly prune the branches
    so you consider as few decisions as possible.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 与决策树一起工作的秘诀是无情地剪枝，这样你考虑的决策尽可能少。
- en: 'There are two ways to deal with a decision tree (actually, there are three
    – see if you can guess the third before I explain it):'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 处理决策树有两种方法（实际上，有三种——在我解释之前，你能猜到第三种吗）：
- en: The first way is to start at the beginning and work outward towards your goal.
    You may come to a dead end, which means back-tracking or possibly starting over.
    We are going to call this **forward chaining** (chain, as we are making a path
    of links from leaf to leaf in the tree).
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一种方法是从小到大开始，向外工作到你的目标。你可能会走到死胡同，这意味着回溯或可能重新开始。我们将称之为**正向链**（链，因为我们正在树中从叶子到叶子制作一个链接路径）。
- en: The other way is to start with the goal and work up the tree toward the start.
    This is **backward chaining**. The cool thing about backward chaining is that
    there are a lot fewer branches to traverse. You can guess that a major problem
    with backward chaining is you have to know what all the leaves are in advance
    before you can use them. In many problems, such as a grid search or a path planner,
    this is possible. It does not work in chess, with an exponentially massive tree.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另一种方法是先从目标开始，向上工作到树的起点。这是**反向链**。反向链的酷之处在于，要穿越的分支要少得多。你可以猜到反向链的一个主要问题是，你必须提前知道所有叶子，才能使用它们。在许多问题中，例如网格搜索或路径规划器，这是可能的。在棋类游戏中，由于树的大小呈指数级增长，这是不可行的。
- en: The third technique? No one says we can’t do both – we could combine both forward
    and backward chaining and meet somewhere in the middle.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第三种技术？没有人说我们不能两者兼得——我们可以结合正向和反向链，在中间某个地方相遇。
- en: 'The choice of decision tree shapes, chaining techniques, and construction is
    based on the following:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树形状的选择、链技术以及构建是基于以下考虑的：
- en: What data is available?
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可用的数据是什么？
- en: What information is known or unknown? How is the path scored or graded?
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 已知或未知的信息是什么？路径是如何评分或评级的？
- en: There are also different kinds of solutions for path planning using decision
    trees. If you were given unlimited resources, the biggest computer, perfect knowledge
    in advance, and are willing to wait, then you can generate an **optimal path**
    or solution.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 使用决策树进行路径规划也有不同的解决方案。如果你拥有无限资源，最大的计算机，提前获得完美的知识，并且愿意等待，那么你可以生成**最优路径**或解决方案。
- en: One of my lessons learned from years of developing practical AI-based robots
    and unmanned vehicles is that any solution that meets all of the criteria or goals
    is an acceptable and usable solution, and you don’t have to wait and continue
    to compute the perfect or optimal solution. Often then, a *good enough* solution
    is found in 1/10 or even 1/100 the time of an optimal solution, because an optimal
    solution requires an exhaustive search that may have to consider all possible
    paths and combinations.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我从多年开发基于人工智能的实用机器人和无人车辆中学到的一个教训是，任何满足所有标准或目标的解决方案都是可接受和可用的解决方案，你不必等待并继续计算完美或最优的解决方案。通常情况下，一个“足够好”的解决方案可以在最优解决方案的1/10甚至1/100的时间内找到，因为最优解决方案需要穷举搜索，可能需要考虑所有可能的路径和组合。
- en: So, how do we approach making our decision trees work faster, or more efficiently?
    We do what any good gardener would do – start pruning our trees.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们如何着手使我们的决策树运行得更快，或更有效率？我们做任何好的园丁都会做的事情——开始修剪我们的树。
- en: What do we mean by pruning?
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们所说的剪枝是什么意思？
- en: Sometimes in the computer business, we have to make metaphors to help explain
    to people how something works. You may remember the desktop metaphor that Apple,
    and later, Windows, adopted to help explain graphical operating systems. Sometimes,
    we just run those metaphors into the ground, such as the trash can to delete files,
    or *Clippy*, the paper clip assistant.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候在计算机行业中，我们必须使用隐喻来帮助解释事物的工作原理。你可能还记得苹果公司，后来是Windows，采用的桌面隐喻来帮助解释图形操作系统。有时候，我们只是把这些隐喻用滥了，比如垃圾桶用来删除文件，或者*Clippy*，那个纸夹助手。
- en: You may feel that I’ve gone off the metaphorical deep end when I discuss **pruning**
    your decision trees. What’s next, fertilizer and tree spikes? Actually, pruning
    is a critical concept in decision tree-type systems. Each branch in your tree
    can lead to hundreds or thousands of sub-branches. If you can decide early that
    a branch is not useful, you can cut it out and you don’t have to process any of
    the branches or leaves in that branch. The sooner you can discover that a path
    is not getting you to your goal, the quicker you can reduce the time and effort
    involved in creating a solution, which is a real-time system such as a robot,
    a self-driving car, or an autonomous aircraft; this can spell the difference between
    usable and worthless.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 当我讨论**剪枝**你的决策树时，你可能觉得我已经进入了隐喻的深渊。接下来是什么，肥料和树桩？实际上，剪枝是决策树类型系统中一个关键的概念。你树上的每个分支都可能引导成百上千个子分支。如果你能尽早决定一个分支没有用，你可以将其剪掉，你就不必处理该分支或该分支中的任何分支或叶子。你越早发现一条路径无法带你达到目标，你就越快可以减少创建解决方案所需的时间和精力，这对于实时系统来说非常重要，比如机器人、自动驾驶汽车或自主飞机；这可能是可用和毫无价值之间的区别。
- en: Let’s run through a quick example in which we use the pruning method. One great
    use for a decision tree process is **Fault Detection, Isolation, and Recovery**
    (**FDIR**). This is a typical function of a robot. Let’s make a decision tree
    for FDIR in the case of our Tinman robot not moving. What automated steps could
    we take to detect the fault, isolate the problem, and then recover? One technique
    we can use is **root cause analysis**, where we try to figure out our problem
    by systematically listing and then eliminating (pruning) causing factors and seeing
    whether the symptoms match. One way to approach root cause analysis is to use
    a special form of decision tree called a **fishbone diagram**, or **Ishikawa diagram**.
    This diagram is named after its inventor, Professor Kaoru Ishikawa from the University
    of Tokyo. In his 1968 paper, *Guide to Quality Control*, the fishbone diagram
    is named because of its shape, which has a central spine and ribs jutting off
    on either side. I know, the metaphors are getting deep when we have a decision
    *tree* in the shape of a *fish*.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们快速通过一个例子来了解一下我们如何使用剪枝方法。决策树过程的一个很好的用途是**故障检测、隔离和恢复**（**FDIR**）。这是机器人的典型功能。让我们为我们的Tinman机器人无法移动的情况制作一个FDIR的决策树。我们可以采取哪些自动化步骤来检测故障、隔离问题，然后恢复？我们可以使用的一种技术是**根本原因分析**，我们通过系统地列出并消除（剪枝）导致因素，然后看症状是否匹配来试图找出我们的问题。进行根本原因分析的一种方法是通过一种特殊的决策树形式，称为**鱼骨图**，或**石川图**。这张图是以其发明者，东京大学的教授石川馨的名字命名的。在他的1968年论文《质量控制指南》中，鱼骨图因其形状而得名，它有一个中央脊柱和两侧突出的肋骨。我知道，当我们有一个像鱼一样的决策*树*时，这些隐喻变得越来越深。
- en: 'Now, we begin to have a problem. Remember that in a robot, a problem is a symptom,
    not a cause. Our problem is the robot is not moving. What can cause this problem?
    Let’s make a list:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们开始遇到问题。记住，在机器人中，问题是一个症状，而不是原因。我们的问题是机器人无法移动。什么可以导致这个问题？让我们列一个清单：
- en: The drive system
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 驱动系统
- en: The software
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 软件
- en: The communication system
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通信系统
- en: The battery and wiring
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 电池和电线
- en: The sensors
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 传感器
- en: Operator error
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 操作员错误
- en: 'Now, for each of these, we subdivide our branches into smaller branches. What
    parts of the *drive system* can cause the robot to not be able to move? The wheels
    could be stuck. The motors could not be getting power. The gears could be jammed.
    The motor driver could have overheated. Here is my fishbone diagram to illustrate
    the problem of the robot not moving:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，对于每一个分支，我们将它们细分为更小的分支。哪些部分的*驱动系统*可能导致机器人无法移动？轮子可能卡住了。电机可能没有得到电源。齿轮可能卡住了。电机驱动器可能过热了。以下是我的鱼骨图，用以说明机器人无法移动的问题：
- en: '![Figure 8.2 – A fishbone, or Ishikawa, diagram is commonly used for troubleshooting](img/B19846_08_2.jpg)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![图8.2 – 鱼骨图，或石川图，常用于故障排除](img/B19846_08_2.jpg)'
- en: Figure 8.2 – A fishbone, or Ishikawa, diagram is commonly used for troubleshooting
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.2 – 鱼骨图或石川图常用于故障排除
- en: For each of these factors, you can consider what would be the symptoms of that
    problem being the cause. If the gears in the motors are jammed, then the motors
    can’t turn and the wheels can’t turn. If we can check any of these factors off,
    we can prune or eliminate the gears from our diagram or decision tree. We check
    the gears, and the wheels and motors turn by hand, so the gears are not the cause.
    We prune that branch. If we have an automated way of doing testing, we can automatically
    prune branches, which we will be able to do in the later examples in this chapter.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这些因素中的每一个，你可以考虑如果这个问题是原因，那么它的症状会是什么。如果电机中的齿轮卡住了，那么电机无法转动，车轮也无法转动。如果我们能够检查掉这些因素中的任何一个，我们就可以从我们的图或决策树中剪枝或消除齿轮。我们检查了齿轮，用手转动车轮和电机，所以齿轮不是原因。我们剪掉了那个分支。如果我们有一个自动化的测试方法，我们可以自动剪枝分支，我们将在本章后面的例子中做到这一点。
- en: How about the battery? The battery could need charging (dead battery), the battery
    could be disconnected, or a power wire could be loose. We check the battery voltage
    – that is OK, so prune that leaf off the tree. We check the wiring – nothing loose.
    The battery branch gets pruned.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 那电池呢？电池可能需要充电（电池耗尽），电池可能被断开，或者电源线可能松动。我们检查电池电压 – 那是好的，所以从树上剪掉那个叶子。我们检查线路 – 没有松动。电池分支被剪掉了。
- en: And so we go on until we have something that either matches all our symptoms
    or is the last one left. Let’s say the last branch was communications. Now what?
    We ask, “What things in communications would cause us not to move?” Our first
    answer is that motor command messages are not getting through to our robot over
    the network. We check the log and see, indeed, no motor messages are present (`cmd_vel`,
    in our case). There is our problem, but what caused the problem? The network could
    be broken (checked – no, the network is OK), or the IP address could be wrong
    (no, that’s OK). We look to see whether any recent changes were made to the control
    software, and indeed, there were. We revert to the previous version and see the
    robot move. There is our problem and we used a decision tree to find it.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们就这样继续下去，直到我们得到一个要么匹配所有症状，要么是最后一个剩下的东西。假设最后一个分支是通信。现在怎么办？我们问，“通信中的哪些事情会导致我们无法移动？”我们的第一个答案是电机命令消息没有通过网络到达我们的机器人。我们检查日志，确实没有电机消息（在我们的例子中是`cmd_vel`）。这就是我们的问题，但是什么导致了这个问题？网络可能坏了（检查过
    – 没有，网络是好的），或者IP地址可能错了（没有，那没关系）。我们查看是否对控制软件进行了任何最近的变化，确实有。我们恢复到之前的版本，看到机器人移动了。这就是我们的问题，我们使用了决策树来找到它。
- en: So, in this case, we solved our problem almost entirely by pruning branches
    and leaves off our tree until only one path was left, or we arrived at our goal.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在这种情况下，我们几乎完全通过剪枝树上的分支和叶子来解决问题，直到只剩下一条路径，或者我们达到了目标。
- en: How can we prune branches in software? We can look for *dead ends*. Dead ends
    are leaves – parts of the tree that end and have no future branches. When we reach
    a dead end, we can not only prune that leaf but also the parts of the path that
    exclusively lead to that branch. This would be a **backward-chaining** approach
    to pruning, as we start at the end and work backward.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何在软件中剪枝分支？我们可以寻找*死胡同*。死胡同是叶子 – 树的结束部分，没有未来的分支。当我们到达死胡同时，我们不仅可以剪掉那个叶子，还可以剪掉那些唯一导致那个分支的路径部分。这将是一种**反向链**剪枝方法，因为我们从终点开始，向后工作。
- en: We can also see sections of the tree that are unused, or never referenced or
    called. We can remove entire sections in this manner. This is **forward chaining**
    because we are traversing the tree in the forward direction, from the front to
    the back.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以看到树中未使用或从未被引用或调用的部分。我们可以以这种方式删除整个部分。这是**正向链**，因为我们正在正向遍历树，从前面到后面。
- en: Up to this point, we, the humans in the story, have been making these decision
    trees by hand. We have not even discussed how we write a program to allow the
    robot to use trees to make decisions. Wouldn’t it be a lot nicer if the computer
    was doing all the hard work of making the tree, deciding the branches, and labeling
    the nodes instead of us? That is exactly what we will discuss in the next section.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们，故事中的人类，一直是手动制作这些决策树的。我们甚至还没有讨论如何编写一个程序，让机器人能够使用树来做出决策。如果计算机能够代替我们完成所有艰难的树制作、分支决定和节点标记的工作，那岂不是更好？这正是我们将在下一节中讨论的内容。
- en: Creating self-classifying decision trees
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建自我分类的决策树
- en: Let’s consider the problem of classifying toys. We may want to come up with
    a more efficient robot, which sorts toys in some manner instead of just dumping
    them in a box. In an ideal world, out of a population of 20 toys, we would have
    some characteristics that divided the group evenly in half – 10 and 10\. Let’s
    say it is length – half of the toys are under six inches long and half are over.
    Then, it would also be ideal if some other characteristic divided each of those
    groups of 10 in half – into four groups of five.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑一下对玩具进行分类的问题。我们可能想要发明一个更高效的机器人，它以某种方式对玩具进行分类，而不是仅仅将它们扔进一个盒子里。在一个理想的世界里，从20个玩具的群体中，我们会有一些特征将群体均匀地分成两半——10个和10个。让我们假设它是**长度**——一半的玩具长度小于六英寸，另一半的玩具长度大于六英寸。那么，如果另一个特征将这10个组中的每一个都再分成一半——分成四个组，每组五个，那就更理想了。
- en: Let’s say it’s *color* – we have five red toys, five blue toys, five green toys,
    and five yellow toys. You may recognize that we are doing what biologists do in
    classifying new species – we are creating a **taxonomy**. Now, we pick another
    attribute that separates the toys into even smaller groups – it might be what
    kind of toy it is or what size wheels it has. I think you get the picture. Let’s
    look at an example.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们假设它是**颜色**——我们有五种红色玩具，五种蓝色玩具，五种绿色玩具和五种黄色玩具。你可能已经注意到我们在做生物学家在课堂上对新的物种进行分类时所做的事情——我们正在创建一个**分类法**。现在，我们选择另一个属性，将玩具分成更小的组——这可能是玩具的类型或轮子的大小。我想你应该明白了这个道理。让我们来看一个例子。
- en: 'Now, what would be great is if we could list all the toys and all the attributes
    in a table, and let the computer figure out how many groups and what kinds there
    are. We could create a table like this one:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果我们能够将所有玩具和所有属性列在一个表中，并让计算机找出有多少组以及它们是什么类型，那就太好了。我们可以创建一个像这样的表：
- en: '| **Type** | **Length** | **Width** | **Weight** | **Color** | **Number** **of
    wheels** | **Noise** | **Soft** | **Material** | **Eyes** | **Toy Name** |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| **类型** | **长度** | **宽度** | **重量** | **颜色** | **轮子数量** | **噪音** | **软硬** |
    **材料** | **眼睛** | **玩具名称** |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| car | 3 | 1 | 35 | red | 4 | 0 | hard | metal | 0 | hotwheels |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| 汽车 | 3 | 1 | 35 | 红色 | 4 | 0 | 硬 | 金属 | 0 | 热轮车 |'
- en: '| car | 3 | 1 | 35 | orange | 4 | 0 | hard | metal | 0 | hotwheels |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| 汽车 | 3 | 1 | 35 | 橙色 | 4 | 0 | 硬 | 金属 | 0 | 热轮车 |'
- en: '| car | 3 | 1 | 35 | blue | 4 | 0 | hard | metal | 0 | hotwheels |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| 汽车 | 3 | 1 | 35 | 蓝色 | 4 | 0 | 硬 | 金属 | 0 | 热轮车 |'
- en: '| car | 3 | 1 | 35 | blue | 4 | 0 | hard | metal | 0 | hotwheels |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| 汽车 | 3 | 1 | 35 | 蓝色 | 4 | 0 | 硬 | 金属 | 0 | 热轮车 |'
- en: '| car | 3 | 1 | 35 | white | 4 | 0 | hard | metal | 0 | hotwheels |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| 汽车 | 3 | 1 | 35 | 白色 | 4 | 0 | 硬 | 金属 | 0 | 热轮车 |'
- en: '| stuffed | 5 | 5 | 50 | white | 0 | 0 | verysoft | fur | 2 | plush |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| 填充玩具 | 5 | 5 | 50 | 白色 | 0 | 0 | 非常软 | 毛绒 | 2 | 毛绒玩具 |'
- en: '| stuffed | 7 | 5 | 55 | brown | 0 | 0 | verysoft | fur | 3 | plush |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| 填充玩具 | 7 | 5 | 55 | 棕色 | 0 | 0 | 非常软 | 毛绒 | 3 | 毛绒玩具 |'
- en: '| action | 2 | 4 | 80 | gray | 0 | 0 | hard | metal | 0 | slinky |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| 动作 | 2 | 4 | 80 | 灰色 | 0 | 0 | 硬 | 金属 | 0 | 柔软的 |'
- en: '| build | 2 | 2 | 125 | wood | 0 | 0 | hard | wood | 0 | wood block 2x2 |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| 制作 | 2 | 2 | 125 | 木材 | 0 | 0 | 硬 | 木材 | 0 | 2x2积木 |'
- en: '| build | 2 | 2 | 75 | wood | 0 | 0 | hard | wood | 0 | wood block triangle
    |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| 制作 | 2 | 2 | 75 | 木材 | 0 | 0 | 硬 | 木材 | 0 | 木材积木三角形 |'
- en: '| build | 4 | 2 | 250 | wood | 0 | 0 | hard | wood | 0 | wood block 4x2 |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| 制作 | 4 | 2 | 250 | 木材 | 0 | 0 | 硬 | 木材 | 0 | 4x2积木 |'
- en: '| dish | 3 | 3 | 79 | blue | 0 | 0 | hard | ceramic | 0 | teapot |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| 餐具 | 3 | 3 | 79 | 蓝色 | 0 | 0 | 硬 | 陶瓷 | 0 | 茶壶 |'
- en: '| aircraft | 7 | 5 | 65 | white | 4 | 1 | hard | plastic | 0 | space shuttle
    |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| 飞机 | 7 | 5 | 65 | 白色 | 4 | 1 | 硬 | 塑料 | 0 | 太空穿梭机 |'
- en: '| aircraft | 13 | 7 | 500 | green | 8 | 1 | hard | plastic | 0 | Thunderbird
    2 |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| 飞机 | 13 | 7 | 500 | 绿色 | 8 | 1 | 硬 | 塑料 | 0 | 雷鸟2号 |'
- en: '| car | 5 | 1 | 333 | yellow | 6 | 1 | hard | metal | 0 | school bus |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| 汽车 | 5 | 1 | 333 | 黄色 | 6 | 1 | 硬 | 金属 | 0 | 校车 |'
- en: '| music | 12 | 4 | 130 | wood | 0 | 2 | hard | wood | 0 | toy guitar |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| 音乐 | 12 | 4 | 130 | 木材 | 0 | 2 | 硬 | 木材 | 0 | 玩具吉他 |'
- en: '| music | 5 | 2 | 100 | yellow | 0 | 1 | hard | plastic | 0 | playmicrophone
    |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| 音乐 | 5 | 2 | 100 | 黄色 | 0 | 1 | 硬 | 塑料 | 0 | 演唱麦克风 |'
- en: '| music | 4 | 4 | 189 | white | 0 | 2 | hard | wood | 0 | toy drum |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| 音乐 | 4 | 4 | 189 | 白色 | 0 | 2 | 硬 | 木材 | 0 | 玩具鼓 |'
- en: Table 8.1 – A table of attributes for a group of toys used for classification
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 表8.1 – 用于分类的一组玩具的属性表
- en: We now have a problem we have to solve. We will be using a decision tree classifier
    that is provided with the `scikit-learn` Python package called `DecisionTreeClassifier`.
    This program cannot use strings as input data. We will have to convert all of
    our string data into some sort of numeric figure. Fortunately, the `scikit-learn`
    library provides us with a function just for this purpose. It provides several
    encoding functions that convert strings into numbers. The function we will use
    is called `LabelEncoder`. This function takes an array of strings and converts
    it into an enumerated set of integers.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在有一个问题需要解决。我们将使用 `scikit-learn` Python 包中提供的决策树分类器 `DecisionTreeClassifier`。这个程序不能使用字符串作为输入数据。我们必须将所有字符串数据转换成某种数值。幸运的是，`scikit-learn`
    库为我们提供了一个专门为此目的的函数。它提供了几个编码函数，可以将字符串转换为数字。我们将使用的函数称为 `LabelEncoder`。这个函数接受一个字符串数组并将其转换为一系列整数。
- en: We can take our first column, which has the type of toy. My nomenclature is
    *toy = toy car*, *stuffed = stuffed animal*, *aircraft = toy aircraft*, and *music
    = toy musical instrument*. We also have *action* for *action toy*, and *build*
    for *building toy* (that is, blocks, LEGO™, and so on). We’ll have to turn these
    into some sort of numbers.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以取我们的第一列，其中包含玩具的类型。我的命名法是 *toy = toy car*，*stuffed = stuffed animal*，*aircraft
    = toy aircraft*，*music = toy musical instrument*。我们还有 *action* 代表 *action toy*，*build*
    代表 *building toy*（即积木、LEGO™ 等）。我们得把这些转换成某种数字。
- en: '`LabelEncoder` will convert a column in our data table that is populated with
    strings. The `type` column from the data is shown in the following code:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '`LabelEncoder` 将将我们的数据表中填充有字符串的列转换为数值。数据中的 `type` 列如下代码所示：'
- en: '`[''car'' ''car'' ''car'' ''car'' ''car'' ''stuffed'' ''stuffed'' ''action''
    ''build'' ''build'' ''build'' ''dish'' ''aircraft'' ''aircraft'' ''car'' ''music''
    ''``music'' ''music'']`'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '`[''car'' ''car'' ''car'' ''car'' ''car'' ''stuffed'' ''stuffed'' ''action''
    ''build'' ''build'' ''build'' ''dish'' ''aircraft'' ''aircraft'' ''car'' ''music''
    ''music'' ''music'']`'
- en: 'It converts it to the label-encoded toy type:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 它将其转换为标签编码的玩具类型：
- en: '`[3 3 3 3 3 6 6 0 2 2 2 4 1 1 3 5` `5 5]`'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '`[3 3 3 3 3 6 6 0 2 2 2 4 1 1 3 5 5 5]`'
- en: You can see that everywhere where it said `car`, we now have the number `3`.
    You can also see that `6` = `stuffed`, `0` = `action`, and so on. Why the odd
    numbering? The encoder first sorts the strings in alphabetical order.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到，所有提到 `car` 的地方现在都变成了数字 `3`。您还可以看到 `6` 代表 `stuffed`，`0` 代表 `action`，等等。为什么数字这么奇怪？编码器首先按字母顺序对字符串进行排序。
- en: 'We are going to just dive right in from here to create a classification program:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从这里直接开始创建一个分类程序：
- en: 'Here is our decision tree classifier program:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下面是我们的决策树分类器程序：
- en: '[PRE1]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We first import the libraries we will be using. There is an extra library called
    `graphviz` that is useful for drawing pictures of decision trees. You can install
    it with the following:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先导入我们将要使用的库。有一个额外的库称为 `graphviz`，它对于绘制决策树图像很有用。您可以使用以下命令安装它：
- en: '[PRE2]'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: from sklearn import tree
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`from sklearn import tree`'
- en: import numpy as np
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`import numpy as np`'
- en: import pandas as pd
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`import pandas as pd`'
- en: import sklearn.preprocessing as preproc
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`import sklearn.preprocessing as preproc`'
- en: import graphviz
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`import graphviz`'
- en: '[PRE3]'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Our first step is to read in our data. I created my table in Microsoft Excel
    and exported it as a **comma-separated values** (**CSV**) format. This allows
    us to read in the data file directly with the column headers. I print out the
    shape and size of the data file for reference. My version of the file has 18 rows
    and 11 columns. The last column is just a note to myself on the actual name of
    each toy. We will not be using the last column for anything. We are building a
    classifier that will separate the toys by type:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的第一步是读取我们的数据。我在 Microsoft Excel 中创建了我的表格，并将其导出为 **逗号分隔值**（**CSV**）格式。这允许我们直接读取数据文件并带有列标题。我打印出数据文件的大小和形状以供参考。我的文件版本有
    18 行和 11 列。最后一列只是我对每个玩具实际名称的备注。我们不会使用最后一列进行任何操作。我们正在构建一个分类器，该分类器将根据类型对玩具进行分类：
- en: '[PRE4]'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now, we can start building our decision tree classifier. We first build an
    instantiation of the `DecisionTreeClassifer` object. There are two different types
    of **decision tree classification** (**DTC**) algorithms to choose from:'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以开始构建我们的决策树分类器。我们首先创建 `DecisionTreeClassifier` 对象的一个实例。有两种不同的 **决策树分类**（**DTC**）算法可供选择：
- en: '**Gini coefficient**: The Gini coefficient was developed in 1912 by the Italian
    statistician Corrado Gini in his paper, *Variabilita e Mutabilita*. This coefficient,
    or index, measures the amount of inequality in a group of numbers. A zero value
    means all the members of the group are the same.'
  id: totrans-107
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基尼系数**：基尼系数是在1912年由意大利统计学家科拉多·基尼在他的论文《Variabilita e Mutabilita》中提出的。这个系数或指数衡量一组数字中的不平等程度。零值表示组内的所有成员都是相同的。'
- en: '**Entropy method**: Entropy, when we are talking about AI, refers to the amount
    of uncertainty in a set of data. This concept comes from information theory, in
    which it measures the amount of uncertainty in a random variable. The concept
    was introduced by Claude Shannon in the 1940s. To create a decision tree, the
    algorithm tries to decrease entropy (reduce uncertainty) by splitting the group
    at a point where each child node is more homogenous than its parent.'
  id: totrans-108
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**熵方法**：当我们谈论AI时，熵指的是一组数据中的不确定性量。这个概念来自信息理论，其中它衡量随机变量的不确定性量。这个概念是在20世纪40年代由克劳德·香农提出的。为了创建决策树，算法试图通过在某个点上分割组来减少熵（减少不确定性），使得每个子节点比其父节点更同质。'
- en: 'Here, we are going to use the Gini coefficient. If we had a group of toy cars
    that were all the same size and all red, then the Gini coefficient of the group
    would be 0\. If the members of the group are all different, then the Gini coefficient
    is closer to 1\. The Gini coefficient is given by the following equation:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将使用基尼系数。如果我们有一组所有玩具车大小相同且都是红色的玩具车，那么该组的基尼系数将是0。如果组内的成员都不同，那么基尼系数将更接近1。基尼系数由以下方程给出：
- en: G(S) = 1− ∑ i=1 n p i 2
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: G(S) = 1− ∑ i=1 n p i 2
- en: 'We have 4 toy cars out of 18 toys, so the probability of a toy car being in
    a group is *4/18* or 0.222\. The decision tree will continue to subdivide classes
    until the Gini coefficient of the group is 0:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有4辆玩具车，共18个玩具，所以玩具车在组中的概率是*4/18*或0.222。决策树将继续细分类别，直到组的基尼系数为0：
- en: '[PRE5]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We need to separate out the values in our data table. The data in the first
    column, which is called column `0` in Python, are our classification labels. We
    need to pull those out separately, as they are used to separate the toys into
    classes. From our previous work with neural networks, these would be our outputs
    or the label data we have used in other machine learning processes. We will be
    training our classifier to predict the class of the toy based on the attributes
    in the table (size, weight, color, and so on). We use slicing to pull the data
    out of the pandas table. Our pandas data table is called `toyData`. If we want
    the entries in the table, we need to ask for `toyData.values`, which will be returned
    as a 2D array:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要将数据表中的值分离出来。第一列的数据，在Python中称为列`0`，是我们的分类标签。我们需要单独提取这些标签，因为它们用于将玩具分类。从我们之前使用神经网络的工作中，这些将是我们输出或我们在其他机器学习过程中使用的标签数据。我们将训练我们的分类器，根据表中的属性（大小、重量、颜色等）来预测玩具的类别。我们使用切片来从pandas表中提取数据。我们的pandas数据表称为`toyData`。如果我们想要表中的条目，我们需要请求`toyData.values`，这将返回一个二维数组：
- en: '[PRE6]'
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: If you are not familiar with slicing notation in Python, the statement `toyData.values[:,1:10]`
    returns just the columns in our table from 1 to 10 – it leaves column 0 out. We
    actually have 11 columns in our table, but since Python starts numbering them
    at 0, we end up needing 1 to 10\. You will probably guess that the other notation
    just grabs the data in the first column.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你不太熟悉Python中的切片表示法，语句`toyData.values[:,1:10]`返回表中从1到10的列——它省略了列0。实际上，我们的表中确实有11列，但由于Python从0开始编号，我们最终需要1到10。你可能猜到另一种表示法只是抓取第一列的数据。
- en: This is the label encoder that we talked about – it will convert the strings
    in our data into numbers. For example, colors such as *red*, *green*, and *blue*
    will be converted to numbers such as *0*, *1*, and *2*. The first item to be encoded
    is the list of class values that we use to label the data. We use the `LabelEncoder.fit()`
    function to come up with the formula for converting strings to numbers, and then
    the `LabelEncoder.transform()` function to apply it. Note that `fit()` does not
    produce an output.
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这就是我们之前提到的标签编码器——它将把我们的数据中的字符串转换为数字。例如，颜色如*红色*、*绿色*和*蓝色*将被转换为数字如*0*、*1*和*2*。要编码的第一个项目是我们用来标记数据的类别值列表。我们使用`LabelEncoder.fit()`函数来得出将字符串转换为数字的公式，然后使用`LabelEncoder.transform()`函数来应用它。请注意，`fit()`不会产生输出。
- en: 'Finally, we need to make the string text and the list of encoded numbers match
    up. What `LabelEncoder` will do is sort the strings alphabetically and start numbering
    them from *A*, ignoring any duplicates. If we put in `car, car, car, block, stuffed,
    airplane`, we will get `2,2,2,1,3,0` as the encoding, and we will have to know
    that `airplane` = `0`, `block` = `1`, `car` = `2`, and `stuffed` = `3`. We need
    to generate a `airplane, block, car, stuffed`. We duplicate the `LabelEncoder`
    function by using two functions on our list of string-formatted class names:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们需要使字符串文本和编码数字列表相匹配。`LabelEncoder` 会按字母顺序对字符串进行排序，并从 *A* 开始编号，忽略任何重复项。如果我们输入
    `car, car, car, block, stuffed, airplane`，我们将得到 `2,2,2,1,3,0` 作为编码，并且我们需要知道 `airplane`
    = `0`，`block` = `1`，`car` = `2`，和 `stuffed` = `3`。我们需要生成一个 `airplane, block, car,
    stuffed`。我们通过在我们的字符串格式类别名列表上使用两个函数来复制 `LabelEncoder` 函数：
- en: We use the `set()` function to eliminate duplicates
  id: totrans-118
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用 `set()` 函数来消除重复项
- en: We use the `sorted()` function to sort in the correct order
  id: totrans-119
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用 `sorted()` 函数以正确的顺序排序
- en: 'Now, our class name table and the enumerations generated by `LabelEncoder`
    match. We’ll need this later:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们的类别名表和由 `LabelEncoder` 生成的枚举相匹配。我们稍后会用到这个：
- en: '[PRE7]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'To make it easy on ourselves, I created a function to automatically find out
    which columns in our data are composed of strings and to convert those columns
    into numbers. We start by building an empty list to hold our data. We will iterate
    through the columns in our data and look to see whether the first data value is
    a string. If it is, we will convert that whole column into numbers using the label
    encoder object (`lencoder`) we created. The label encoding process has two parts.
    We call `lencoder.fit()` to see how many unique strings we have in our column
    and to create a number for each one. Then, we use `lencoder.transpose` to insert
    those numbers into a list:'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了方便起见，我创建了一个函数来自动找出我们的数据中哪些列由字符串组成，并将这些列转换为数字。我们首先构建一个空列表来存储我们的数据。我们将遍历我们的数据列，查看第一个数据值是否为字符串。如果是，我们将使用我们创建的标签编码器对象（`lencoder`）将整个列转换为数字。标签编码过程有两个部分。我们调用
    `lencoder.fit()` 来查看我们的列中有多少唯一的字符串，并为每个创建一个数字。然后，我们使用 `lencoder.transpose` 将这些数字插入到列表中：
- en: '[PRE8]'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Now, we put all of the data back into the `newData` list, but there is a problem
    – we have turned all our columns into rows! We use the `transpose` function from
    `numpy` to correct this problem. But wait! We don’t have an array anymore, as
    we turned it into a list so we could take it apart and put it back together again
    (you can’t do that with a `numpy` array – believe me, I tried):'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将所有数据放回 `newData` 列表中，但有一个问题——我们已经将所有列转换成了行！我们使用 `numpy` 的 `transpose`
    函数来纠正这个问题。但是等等！我们不再有数组了，因为我们将其转换成了列表，以便将其拆分并重新组合（你无法用 `numpy` 数组这样做——相信我，我试过了）：
- en: '[PRE9]'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Now, all of our preprocessing is done, so we can finally call the real `DecisionTreeClassifer`.
    It takes two arguments:'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，所有的预处理都完成了，所以我们最终可以调用真正的 `DecisionTreeClassifier`。它需要两个参数：
- en: The array of our data values
  id: totrans-127
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们数据值数组
- en: The array of class types that we want the decision tree to divide our groups
    into
  id: totrans-128
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们想要决策树将我们的组划分成类别的类别类型数组
- en: '`DecisionTreeClassifier` will determine what specific data from the table is
    useful for predicting what class one of our toys fits into:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '`DecisionTreeClassifier` 将确定表格中哪些具体数据对预测我们的玩具属于哪个类别是有用的：'
- en: '[PRE10]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'That’s it – one line. But wait – we want to see the results. If we just try
    and print out the decision tree, we get the following:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样——一行。但是等等——我们想看到结果。如果我们只是尝试打印决策树，我们会得到以下内容：
- en: '[PRE11]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: That does not tell us anything; that is a description of the `DecisionTreeClassifier`
    object (it does show us all of the parameters we can set, which is why I put it
    here).
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 这并没有告诉我们任何东西；这是对 `DecisionTreeClassifier` 对象的描述（它确实显示了我们可以设置的参数，这就是为什么我把它放在这里）。
- en: 'So, we use a package called `graphviz`, which is very good at printing decision
    trees. We can even pass our column names and class names into the graph. The final
    two lines output the graph as a `.pdf` file and store it on the hard drive:'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 因此，我们使用一个名为 `graphviz` 的包，它非常擅长打印决策树。我们甚至可以将我们的列名和类别名传递给图形。最后两行将图形输出为 `.pdf`
    文件并存储在硬盘上：
- en: '[PRE12]'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'And here is the result. I will warn you, this is addictive:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是结果。我要提醒你，这可能会上瘾：
- en: "![Figure 8.3 – The output of the decision tree using t\uFEFFhe Gini index method](img/B19846_08_3.jpg)"
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.3 – 使用 Gini 指数方法的决策树输出](img/B19846_08_3.jpg)'
- en: Figure 8.3 – The output of the decision tree using the Gini index method
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.3 – 使用 Gini 指数方法的决策树输出
- en: 'We can quickly check our solution by looking at our input table and seeing
    whether the numbers line up. We should see the following:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过查看我们的输入表并检查数字是否对齐来快速检查我们的解决方案。我们应该看到以下内容：
- en: Five toy cars
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 五辆玩具车
- en: Three building blocks
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 三个积木
- en: One dish
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个盘子
- en: One action toy
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个动作玩具
- en: Two stuffed animals
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 两个填充动物
- en: Three musical instruments
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 三种乐器
- en: Two toy airplanes
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 两个玩具飞机
- en: And that is indeed the case.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 确实如此。
- en: The other number to look at is the Gini index. As shown in *Figure 8**.3*, the
    top-level box shows that the index for the entire group has an overall value of
    `0.8166`, which is close to 1 and shows a high degree of heterogeneity. As we
    progress down the tree, the Gini numbers get smaller and smaller until reaching
    `0` at each of the identified groups, which shows that the items in those groups
    share all of the same attributes.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个需要关注的数字是基尼指数。如图**8**.3所示，顶级框显示整个组的指数整体值为`0.8166`，接近1，表明高度异质性。随着我们向下推进树，基尼指数越来越小，直到在每个识别的组中达到`0`，这表明那些组中的项目具有所有相同的属性。
- en: What does this graph tell us? First of all, we can separate the toy cars by
    only one attribute – *width*. Only the toy cars are less than 1.5 inches wide
    (38 mm). We don’t need to look at color, weight, or anything other than width
    to separate all the toy cars from everything else. We see we have 5 toy cars out
    of our 18 toys, so we have 13 left to classify. Our next division comes in length.
    We have 7 toys less than 4.5 inches long (11 cm) and 5 that are longer. Of the
    group of five, two have eyes and three do not. The toys with eyes are the two
    stuffed animals. If you follow the tree, the branches that lead to the toy music
    instruments are width > 1.5 inches, length > 4.5 inches, and no eyes, and they
    are indeed larger than the other toys in length and width, and don’t have eyes.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 这个图表告诉我们什么？首先，我们可以通过仅一个属性来区分玩具车——*宽度*。只有玩具车的宽度小于1.5英寸（38毫米）。我们不需要看颜色、重量或宽度以外的任何东西来将所有玩具车与其他所有东西分开。我们看到我们有5辆玩具车在我们的18个玩具中，所以我们还有13个需要分类。我们的下一个划分是长度。我们有7个玩具长度小于4.5英寸（11厘米），5个更长。在五个玩具中，有两个有眼睛，三个没有。有眼睛的玩具是两个填充动物。如果你跟随树，通向玩具乐器的分支是宽度>1.5英寸、长度>4.5英寸且没有眼睛，它们在长度和宽度上确实比其他玩具大，并且没有眼睛。
- en: None of the other bits matter in terms of classifying. That means that an attribute
    such as *color* is a poor predictor of what class a toy belongs to – which makes
    sense. Our other useful criteria are the *number of wheels*, the *weight*, and
    the *length*. That data is sufficient to classify all our toys into groups. You
    can see that the Gini index of each leaf node is indeed `0`. I added some additional
    labeling to the graph to make the illustration clearer, as the program uses the
    class number rather than the class name in the graph.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在分类方面，其他任何信息都不重要。这意味着像*颜色*这样的属性是玩具所属类别的糟糕预测因子——这是有道理的。我们其他有用的标准是*轮子数量*、*重量*和*长度*。这些数据足以将所有玩具分类到不同的组中。你可以看到每个叶节点的基尼指数确实是`0`。我在图表中添加了一些额外的标签，以使说明更清晰，因为程序在图表中使用的是类别编号而不是类别名称。
- en: So, that exercise was satisfactory – we were able to create an automatic decision
    tree from our toy data that classified our toys. We can even use that data to
    classify a new toy and predict which class it might belong to. If we found that
    that new toy violated the classification somehow, then we would need to re-rerun
    the classification process and make a new decision table.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，那次练习是令人满意的——我们能够从我们的玩具数据中创建一个自动决策树，将我们的玩具分类。我们甚至可以使用这些数据来分类一个新的玩具，并预测它可能属于哪个类别。如果我们发现那个新玩具在分类上有所违反，那么我们就需要重新运行分类过程并创建一个新的决策表。
- en: There is another type of process for creating decision trees and subdividing
    data into categories. That is called the **entropy model**, or **information gain**.
    Let’s discuss this next.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 创建决策树并将数据细分为类别的另一种类型的过程被称为**熵模型**，或**信息增益**。让我们接下来讨论这个话题。
- en: Understanding entropy
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解熵
- en: '**Entropy** is a measurement of the amount of disorder in the sample of data
    provided. We can also call this process **information gain** since we are measuring
    how much each criterion contributed to our knowledge of which class it belongs
    to.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '**熵**是衡量提供的数据样本中无序程度的度量。我们也可以称这个过程为**信息增益**，因为我们正在衡量每个标准对了解它属于哪个类别的知识贡献了多少。'
- en: 'The formula for entropy is a negative log base 2 function that is still primarily
    looking at the probability of a class belonging to a population, which is just
    the number of individuals belonging to each class divided by the total number
    in the sample:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 熵的公式是一个以2为底的对数函数的负值，它仍然主要关注一个类别属于一个群体的概率，这仅仅是属于每个类别的个体数除以样本总数：
- en: '*Entropy = -p*log2(p) –* *p_i*log2(p_i)*'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '*熵 = -p*log2(p) – p_i*log2(p_i)*'
- en: 'To substitute entropy as our group criteria in our program, we only have to
    change one line:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在我们的程序中将熵作为我们的组标准，我们只需要更改一行：
- en: '[PRE13]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The results are shown in the following diagram:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 结果在以下图表中显示：
- en: "![Figure 8.4 – Output of the decision tree using \uFEFFentropy (information\
    \ gain)](img/B19846_08_4.jpg)"
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![图8.4 – 使用熵（信息增益）的决策树输出](img/B19846_08_4.jpg)'
- en: Figure 8.4 – Output of the decision tree using entropy (information gain)
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.4 – 使用熵（信息增益）的决策树输出
- en: You can note that entropy starts at 2.55 for our whole group, and decreases
    to 0 at the leaf nodes (ends of the branches). We can check that we have seven
    classifications, but you can see that the entropy method selected different criteria
    from the Gini method. For example, the Gini classifier started with `Length`,
    and the entropy classifier started with `Material`. The entropy method also chose
    `Noise` (whether the toy makes a noise or not) and correctly selected that the
    only toys that make a noise were the toy musical instruments and the toy airplanes,
    which have electronic sound boxes that make airplane sounds.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以注意到，熵从我们整个组的2.55开始，并减少到叶节点（分支的末端）的0。我们可以检查我们有七个分类，但你可以看到熵方法选择了与基尼方法不同的标准。例如，基尼分类器从`长度`开始，而熵分类器从`材料`开始。熵方法还选择了`噪音`（玩具是否发出噪音）并正确地选择了只有玩具乐器和玩具飞机发出噪音，这些玩具都有电子音箱发出飞机声音。
- en: 'There is one item that causes some concern, however. There are two blocks that
    show `Material`, dividing the toy’s values in material less than 2.5\. `Material`
    is a discrete value. We can generate a list of materials and run this through
    our `sorted(set(list))` process to get the unique values in sorted order:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有一件事引起了一些关注。有两个显示`材料`的块，将玩具的值分为小于2.5的材料。`材料`是一个离散值。我们可以生成一个材料列表，并通过`sorted(set(list))`过程运行它，以获取排序后的唯一值：
- en: '`[''ceramic'', ''fur'', ''metal'', ''``plastic'', ''wood'']`'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '`[''陶瓷'', ''毛皮'', ''金属'', ''塑料'', ''木材'']`'
- en: So, a `Material` value of 2.5 or less would be either ceramic or fur. Fur and
    ceramic have nothing in common, other than where they are found in the alphabet.
    This is a rather troubling relationship, which is an artifact of how we encoded
    our data as a sequential set of numbers. This implies relationships and grouping
    that don’t really exist. How can we correct this?
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，`材料`值为2.5或更小的是陶瓷或毛皮。毛皮和陶瓷除了在字母表中的位置外没有共同之处。这是一种相当令人不安的关系，这是由于我们将数据编码为一系列数字的顺序集所导致的。这暗示了实际上并不存在的关联和分组。我们如何纠正这个问题？
- en: As a matter of fact, there is a process for handling just this sort of problem.
    This technique is widely used in AI programs and is a *must-have* tool for working
    with classification, either here in the decision tree section or with neural networks.
    This tool has the strange name of **one-hot encoding**.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，有一个处理此类问题的过程。这种技术在AI程序中广泛使用，并且是处理分类的*必备*工具，无论是决策树部分还是神经网络。这个工具有一个奇怪的名称，叫做**独热编码**。
- en: Implementing one-hot encoding
  id: totrans-167
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实现独热编码
- en: The concept for one-hot encoding is pretty simple. Instead of replacing a category
    with an enumeration, we add one column to our data for each possible value and
    set it to be a `1` or `0` based on that value. The name comes from the fact that
    only one column in the set is *hot* or selected.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 独热编码的概念相当简单。我们不是用枚举来替换一个类别，而是为每个可能的值在我们的数据中添加一列，并根据该值将其设置为`1`或`0`。这个名字来源于事实，即在这个集合中只有一个列是*热*或被选中的。
- en: 'We can apply this principle to our example. We can replace the one column,
    `Material`, with five columns for each material type in our database: `ceramic`,
    `fur`, `metal`, `plastic`, and `wood`:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将这个原则应用到我们的例子中。我们可以将数据库中每种材料类型的单列`材料`替换为五个列：`陶瓷`、`毛皮`、`金属`、`塑料`和`木材`：
- en: '| **Material** | **ceramic** | **fur** | **metal** | **plastic** | **wood**
    |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| **材料** | **陶瓷** | **毛皮** | **金属** | **塑料** | **木材** |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| metal | 0 | 0 | 1 | 0 | 0 |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| 金属 | 0 | 0 | 1 | 0 | 0 |'
- en: '| metal | 0 | 0 | 1 | 0 | 0 |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| 金属 | 0 | 0 | 1 | 0 | 0 |'
- en: '| metal | 0 | 0 | 1 | 0 | 0 |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| 金属 | 0 | 0 | 1 | 0 | 0 |'
- en: '| metal | 0 | 0 | 1 | 0 | 0 |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| 金属 | 0 | 0 | 1 | 0 | 0 |'
- en: '| metal | 0 | 0 | 1 | 0 | 0 |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| 金属 | 0 | 0 | 1 | 0 | 0 |'
- en: '| fur | 0 | 1 | 0 | 0 | 0 |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| 毛皮 | 0 | 1 | 0 | 0 | 0 |'
- en: '| fur | 0 | 1 | 0 | 0 | 0 |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| 毛皮 | 0 | 1 | 0 | 0 | 0 |'
- en: '| metal | 0 | 0 | 1 | 0 | 0 |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| 金属 | 0 | 0 | 1 | 0 | 0 |'
- en: '| wood | 0 | 0 | 0 | 0 | 1 |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| 木头 | 0 | 0 | 0 | 0 | 1 |'
- en: '| wood | 0 | 0 | 0 | 0 | 1 |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| 木头 | 0 | 0 | 0 | 0 | 1 |'
- en: '| wood | 0 | 0 | 0 | 0 | 1 |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| 木头 | 0 | 0 | 0 | 0 | 1 |'
- en: '| ceramic | 1 | 0 | 0 | 0 | 0 |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| 陶瓷 | 1 | 0 | 0 | 0 | 0 |'
- en: '| plastic | 0 | 0 | 0 | 1 | 0 |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| 塑料 | 0 | 0 | 0 | 1 | 0 |'
- en: '| plastic | 0 | 0 | 0 | 1 | 0 |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| 塑料 | 0 | 0 | 0 | 1 | 0 |'
- en: '| metal | 0 | 0 | 1 | 0 | 0 |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| 金属 | 0 | 0 | 1 | 0 | 0 |'
- en: '| wood | 0 | 0 | 0 | 0 | 1 |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| 木头 | 0 | 0 | 0 | 0 | 1 |'
- en: '| plastic | 0 | 0 | 0 | 1 | 0 |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| 塑料 | 0 | 0 | 0 | 1 | 0 |'
- en: '| wood | 0 | 0 | 0 | 0 | 1 |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '| 木头 | 0 | 0 | 0 | 0 | 1 |'
- en: Table 8.2 – One-hot encoding data structure for the Material category
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 表 8.2 – 材料类别的单热编码数据结构
- en: This does cause some structural complications to our program. We must insert
    columns for each of our types, which replaces 3 columns with 14 new columns.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 这确实给我们的程序带来了一些结构上的复杂性。我们必须为每种类型插入列，这用 14 个新列替换了 3 个列。
- en: 'I’ve found two functions that we can use to convert text categories into one-hot
    encoded multiple columns:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 我找到了两个函数可以将文本类别转换为单热编码的多列：
- en: One is `OneHotEncoder`, which is part of `scikit-learn`. It is used like `LabelEncoder`
    – in fact, you must use both functions at the same time. You have to convert the
    string data to numeric form with `LabelEncoder` and then apply `OneHotEncoder`
    to convert that to the one-bit-per-value form that we want.
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`OneHotEncoder` 是 `scikit-learn` 的一部分，它使用方式类似于 `LabelEncoder` —— 事实上，你必须同时使用这两个函数。你必须使用
    `LabelEncoder` 将字符串数据转换为数值形式，然后应用 `OneHotEncoder` 将其转换为所需的单比特值形式。'
- en: The simpler way is with a pandas function called `get_dummies()`. The name is
    apparently because we are creating dummy values to replace a string with numbers.
    It does perform the same function. The steps involved are quite a bit simpler
    than using the `OneHotEncoder` process, so that will be the one in our example.
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 简单的方法是使用 pandas 的一个名为 `get_dummies()` 的函数。这个名字显然是因为我们正在创建虚拟值来用数字替换字符串。它确实执行了相同的功能。涉及的步骤比使用
    `OneHotEncoder` 流程简单得多，所以我们将使用示例中的这个方法。
- en: 'Let’s look at the steps we need to follow to implement this:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们需要遵循的步骤来实现这一点：
- en: 'The top header section is the same as before – we have the same imports:'
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 顶部标题部分与之前相同 —— 我们有相同的导入：
- en: '[PRE14]'
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We will begin by reading in our table as before. I added an extra column at
    my end called `Toy Name` so I could keep track of which toy is which. We don’t
    need this column for the decision tree, so we can take it out with the pandas
    `del` function by specifying the name of the column to remove:'
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将像之前一样开始读取表格。我在我的末端添加了一个额外的列，称为 `Toy Name`，这样我就可以跟踪哪个玩具是哪个。我们不需要这个列来进行决策树，所以我们可以使用
    pandas 的 `del` 函数通过指定要删除的列名来移除它：
- en: '[PRE15]'
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Now, we are going to create a list of the columns we are going to remove and
    replace from the pandas `dataTable`. These are the `Color`, `Soft`, and `Material`
    columns. I used the term *Soft* to identify toys that were soft and squished easily
    (as compared to hard plastic or metal) because that is a separate criterion we
    may need for using our robot hand. We generate the dummy values and replace the
    3 columns with 18 new columns. pandas automatically names the columns with a combination
    of the old column name and the value. For example, the single `Color` column is
    replaced by `Color_white`, `Color_blue`, `Color_green`, and so on:'
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将创建一个列表，列出我们将从 pandas `dataTable` 中删除并替换的列。这些是 `Color`、`Soft` 和 `Material`
    列。我使用术语 *Soft* 来标识那些柔软且容易压扁的玩具（与硬塑料或金属相比），因为这是我们可能需要用于我们的机器人手的一个单独标准。我们生成虚拟值，并用
    18 个新列替换这 3 个列。pandas 会自动将列名命名为旧列名和值的组合。例如，单个 `Color` 列被替换为 `Color_white`、`Color_blue`、`Color_green`
    等等：
- en: '[PRE16]'
  id: totrans-201
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'I put a `print` statement here just to check that everything got assembled
    correctly. It is optional. I’ve been really impressed with pandas for data tables
    – there is a lot of capability there to do database-type functions and data analysis:'
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我在这里添加了一个 `print` 语句，只是为了检查所有内容是否正确组装。这是可选的。我对 pandas 在数据表方面的能力印象深刻 —— 它有很多功能可以执行数据库类型的功能和数据分析：
- en: '[PRE17]'
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Now, we are ready to generate our decision tree. We instantiate the object
    and call it `dTree`, setting the classification criteria to Gini. We then extract
    the data values from our `toyData` dataframe, and put the class values in the
    first (0th) column into the `classValues` variable, using array slicing operators:'
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们已经准备好生成我们的决策树。我们实例化对象并命名为 `dTree`，将分类标准设置为 Gini。然后我们从 `toyData` 数据框中提取数据值，并将第一个（0号）列中的类别值放入
    `classValues` 变量中，使用数组切片运算符：
- en: '[PRE18]'
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We still need to convert the class names into an enumerated type using `LabelEncoder`,
    just as we did in the previous two examples. We don’t need to one-hot encode.
    Each class represents an end state for our classification example – the leaves
    on our decision tree. If we were doing a neural network classifier, these would
    be our output neurons. One big difference is that when using a decision tree,
    the computer tells you what the criteria were that it used to classify and segregate
    items. With a neural network, it will do the classification but you have no way
    of knowing what criteria were used:'
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们仍然需要使用 `LabelEncoder` 将类别名称转换为枚举类型，就像我们在前两个例子中所做的那样。我们不需要进行独热编码。每个类别代表我们的分类示例的终端状态——决策树上的叶子。如果我们进行神经网络分类器，这些将是我们的输出神经元。一个很大的不同之处在于，当使用决策树时，计算机会告诉你它用来分类和分离项目的标准。而在神经网络中，它会进行分类，但你无法知道使用了什么标准：
- en: '[PRE19]'
  id: totrans-207
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'As we said, to use the class value names in the final output, we have to eliminate
    any duplicate names and sort them alphabetically. This pair of nested functions
    does that:'
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 正如我们所说的，为了在最终输出中使用类别值名称，我们必须消除任何重复的名称并按字母顺序排序。这对嵌套函数做到了这一点：
- en: '[PRE20]'
  id: totrans-209
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'This is the conclusion of our program. Actually creating the decision tree
    only takes one line of code, now that we have set up all the data. We use the
    same steps as before, and then create the graphic with `graphviz` and save the
    image as a PDF. That was not hard at all – now that we have had all that practice
    setting this up:'
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这就是我们的程序结论。实际上创建决策树只需要一行代码，因为我们已经设置了所有数据。我们使用之前相同的步骤，然后使用 `graphviz` 创建图形并将其保存为PDF。这并不难——现在我们已经有了所有这些设置经验：
- en: '[PRE21]'
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The result is the flowchart shown in the following figure. This output with
    one-hot encoding is a bit easier to read than *Figure 8**.4* because we can see
    the numbers in each category. You’ll note that each leaf (end node) has only one
    category with a count (two stuffed animals and three musical instruments):'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是以下图中所示的流程图。这种使用独热编码的输出比 *图8**.4* 更容易阅读，因为我们可以看到每个类别的数字。你会注意到每个叶子（终端节点）只有一个类别和一个计数（两个填充动物和三个乐器）：
- en: "![Figure 8.5 – The output of the decision tree using one-hot encoding is much\
    \ easier \uFEFF\uFEFF\uFEFFto read](img/B19846_08_5.jpg)"
  id: totrans-213
  prefs: []
  type: TYPE_IMG
  zh: '![图8.5 – 使用独热编码的决策树输出更容易阅读](img/B19846_08_5.jpg)'
- en: Figure 8.5 – The output of the decision tree using one-hot encoding is much
    easier to read
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.5 – 使用独热编码的决策树输出更容易阅读
- en: Since we’ve been able to describe and make all sorts of decision trees, what
    would we have if we used a whole bunch of them? A forest! Let’s explore what this
    might look like.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们已经能够描述和制作各种决策树，如果我们使用一大堆决策树，会发生什么呢？一个森林！让我们探索这可能会是什么样子。
- en: Random forests
  id: totrans-216
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 随机森林
- en: I really wanted to add this section on **random forest classifiers**, but not
    just because the name sounds so cool. While I may have been accused of stretching
    metaphors to the breaking point, this time, the name may have inspired the name
    of this type of decision tree process. We have learned how to make decision trees,
    and we have learned that they have some weak points. It is best if the data really
    belongs to distinct and differentiated groups. They are not very tolerant of noise
    in the data. And they really gets unwieldy if you want to scale them up – you
    can imagine how big a graph would get with 200 classes rather than the 6 or 7
    we were dealing with.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 我真的很想添加关于 **随机森林分类器** 的这一部分，但不仅仅是因为这个名字听起来很酷。虽然我可能被指责过度夸张了隐喻，但这次，这个名字可能启发了这种决策树过程的名称。我们已经学会了如何制作决策树，我们也了解到它们有一些弱点。如果数据确实属于不同的和区分开的组，那就最好不过了。它们对数据中的噪声不太容忍。如果你想要扩展它们，它们会变得非常难以控制——你可以想象一下，如果我们要处理200个类别而不是我们之前处理的6或7个类别，这个图会变得有多大。
- en: 'If you want to take advantage of the simplicity and utility of decision trees
    but want to handle more data, more uncertainty, and more classes, you can use
    a random forest, which, just as the name indicates, is just a whole batch of randomly
    generated decision trees. Let’s step through the process:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要利用决策树的简单性和实用性，但想要处理更多的数据、更多的不确定性和更多的类别，你可以使用随机森林，正如其名称所表明的，它只是一大批随机生成的决策树。让我们一步一步地通过这个过程：
- en: We collect our database of information but, instead of 18 rows in our database,
    we have 10,000 records or 1 million records. We subdivide this data into random
    sets – we generate 100 sets of data each *randomly* chosen from all of our data
    – and we put them in *random* order. We also pull out one set of data to use as
    a test set, just as we did for the neural networks.
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们收集了我们的信息数据库，但我们的数据库中不是18行，而是有10,000条记录或1,000,000条记录。我们将这些数据细分为随机集合——我们生成100个数据集合，每个集合都是随机地从我们所有的数据中选择的——并将它们随机排序。我们还抽取出一组数据作为测试集，就像我们为神经网络所做的那样。
- en: Now, for each set of random data, we make a decision tree using the same process
    we have already learned.
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，对于每一组随机数据，我们使用我们已经学过的相同过程来制作决策树。
- en: Now, we have this collection of 100 classification engines, each generated from
    a different, randomly generated subset of data. We now test our random forest
    by taking data from the test set and running through all 100 of the trees in our
    forest. Each tree will provide an estimate of the classification of the data in
    our test record. If we are still classifying toys, then one of the trees would
    estimate that we are describing a toy car. Another may think it’s a musical instrument.
    We take each estimate and treat it as a vote. Then, the majority rules – the class
    that the majority of the trees selected is the winner. And that is all there is
    to it.
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们有了这100个分类引擎的集合，每个引擎都是从不同的、随机生成的数据子集中生成的。我们现在通过从测试集中取数据并运行我们森林中的所有100棵树来测试我们的随机森林。每一棵树都会为我们测试记录中的数据分类提供一个估计。如果我们仍在分类玩具，那么其中一棵树可能会估计我们正在描述一辆玩具车。另一棵可能认为它是一件乐器。我们接受每个估计并将其视为一票。然后，多数决定——多数树选择的类别就是赢家。这就是全部。
- en: The setup and program are just the same as what we did before, but you can’t
    draw a decision tree from a random forest, or just create a tree as an end in
    itself because that is not what a random forest does – if you just need a decision
    tree, you know how to do that. What you can do is to use a random forest like
    a neural network, as either a classification engine (to what class does this data
    belong?) or a regression engine that approximates a non-linear curve.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 设置和程序与之前所做的完全相同，但你不能从随机森林中绘制决策树，或者仅仅创建一个树作为最终目标，因为那不是随机森林的作用——如果你只需要决策树，你知道如何做。你可以做的是像神经网络一样使用随机森林，作为分类引擎（这些数据属于哪个类别？）或近似非线性曲线的回归引擎。
- en: At this point, you can conclude with me that decision trees are really useful
    for a lot of things. But did you know you can navigate with them? The next section
    covers path planning for robots – using a different type of decision tree.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，你可以和我一起得出结论，决策树在许多事情上都非常有用。但你是否知道你可以用它们来导航？下一节将介绍机器人的路径规划——使用不同类型的决策树。
- en: Introducing robot path planning
  id: totrans-224
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍机器人路径规划
- en: In this section, we will be applying decision tree techniques to perform robot
    navigation. Some people like to refer to these as **graph-based solutions**, but
    any sort of navigation problem ends up being a decision tree. Consider as you
    drive your car, can you divide your navigation problems into a set of decisions
    – turn right, turn left, or go straight?
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将应用决策树技术来执行机器人导航。有些人喜欢将这些称为**基于图的解决方案**，但任何类型的导航问题最终都会变成一个决策树。考虑一下当你开车时，你是否可以将你的导航问题分解成一系列决策——向右转，向左转，还是直行？
- en: We are going to take what we have learned so far and press on to a problem related
    to classification, and that is **grid searching** and **path finding**. We will
    be learning about the famous and widely used **A*** (pronounced **A-star**) algorithm.
    This will start with grid navigation methods, topological path finding, such as
    GPS route finding, and finally, expert systems. You will see that these are all
    versions and variations on the topic of decision trees that we have already learned.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将把到目前为止所学的内容应用到与分类相关的问题上，那就是**网格搜索**和**路径查找**。我们将学习著名的、广泛使用的**A**（发音为**A-star**）算法。这将从网格导航方法开始，如拓扑路径查找，例如GPS路线查找，最后是专家系统。你会看到这些都是我们已经学习过的决策树主题的版本和变体。
- en: Some problems and datasets, particularly in robotics, lend themselves to a grid-based
    solution as a simplification of the navigation problem. It makes a lot of sense
    that, if we were trying to plot a path around a house or through a field for a
    robot, we would divide the ground into some sort of checkerboard grid and use
    that to plot coordinates that the robot can drive to. We could use latitude and
    longitude, or we could pick some reference point as zero – such as our starting
    position – and measure off some rectangular grid relative to the robot. The grid
    serves the same purpose in chess, limiting the number of positions under consideration
    for potential future movement and limiting and delineating our possible paths
    through the space.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 一些问题和数据集，尤其是在机器人领域，适合使用基于网格的解决方案，作为简化导航问题的方法。如果我们试图为机器人规划绕房子或穿过田野的路径，将地面划分为某种棋盘格网格，并使用它来绘制机器人可以驾驶到的坐标，这是非常有意义的。我们可以使用纬度和经度，或者我们可以选择某个参考点作为零点——比如我们的起始位置——并相对于机器人测量一些矩形网格。网格在棋盘游戏中也起到相同的作用，限制考虑的潜在未来移动的位置数量，并限制和划定了我们在空间中的可能路径。
- en: While this section deals with gridded path finding, regardless of whether maps
    are involved or not, there are robot navigation paradigms that don’t use maps
    and even some that don’t use grids, or use grids with uneven spacing. I’ve designed
    robot navigation systems with multiple-layer maps where some layers were mutable
    – changeable – and some were not. This is a rich and fertile ground for imagination
    and experimentation, and I recommend further research if you find this topic interesting.
    For now, let’s start with a description of the coordinate system we’ll be using.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然本节讨论的是网格路径查找，无论是否涉及地图，都有一些机器人导航范例不使用地图，甚至有些不使用网格，或者使用间距不均匀的网格。我设计过具有多层地图的机器人导航系统，其中一些层是可变的——可更改的——而另一些则不是。这是一个充满想象力和实验的肥沃土壤，如果你对这个主题感兴趣，我建议进行进一步的研究。现在，让我们先描述我们将要使用的坐标系。
- en: Understanding the coordinate system
  id: totrans-229
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解坐标系
- en: Let’s get back to the topic at hand. We have a robot and room that is roughly
    rectangular, and within that rectangle are also some roughly rectangular obstacles
    in the form of furniture, chairs, bookcases, a fireplace, and so on. It is a simple
    concept to consider that we mark off a grid to represent this space and create
    an array of numbers that matches the physical room with a virtual room. We set
    our grid spacing at 1 cm – each grid square is 1 cm x 1 cm, giving us a grid with
    580 x 490 squares or 284,200 squares. We represent each square by an unsigned
    integer in a 2D array in the robot’s memory.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回到手头的主题。我们有一个大致呈矩形的机器人和房间，在这个矩形内部也有一些大致呈矩形的障碍物，如家具、椅子、书架、壁炉等。考虑我们用网格来表示这个空间，并创建一个与物理房间相对应的虚拟房间的数字数组，这是一个简单的概念。我们将网格间距设置为1厘米——每个网格方格是1厘米
    x 1厘米，给我们一个580 x 490个方格的网格，或284,200个方格。我们在机器人的记忆中用二维数组中的无符号整数来表示每个方格。
- en: Now, we are going to need some other data. We have a starting location and a
    goal location, specified as grid coordinates. We’ll put `0,0` for the grid in
    the nearest and leftmost corner of the room so that all our directions and angles
    will be positive. In the way I’ve drawn the room map for you in *Figure 8**.6*,
    that corner will always be the lower-left corner of our map. In standard *right-hand
    rule* notation, left turns are positive angles and right turns are negative. The
    *x* direction is horizontal and the *y* direction is vertical on the page. For
    the robot, the *x* axis is out the right side and the *y* axis is the direction
    of motion.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们需要一些其他数据。我们有一个起点和一个目标点，指定为网格坐标。我们将把网格的`0,0`放在房间最近和最左边的角落，这样我们的所有方向和角度都将为正。在我为你绘制的房间地图*图8.6*中，那个角落将始终是地图的左下角。在标准的*右手定则*表示法中，左转是正角度，右转是负角度。*x*方向是水平方向，*y*方向是垂直方向。对于机器人来说，*x*轴是右侧，*y*轴是运动方向。
- en: 'You may think it odd that I’m giving these details, but setting up the proper
    coordinate system is the first step in doing grid searches and path planning.
    We are using Cartesian coordinates indoors. We would use different rules outdoors
    with latitude and longitude. There, we might want to use *north-east-down* (north
    is positive, south is negative, east is positive, west is negative, the *z* axis
    is down, and the *x* axis is aligned on the robot with the direction of travel):'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会觉得我提供这些细节很奇怪，但设置正确的坐标系是进行网格搜索和路径规划的第一步。我们在室内使用笛卡尔坐标系。在户外，我们会使用不同的规则，使用纬度和经度。在那里，我们可能希望使用*北东下*（北是正的，南是负的，东是正的，西是负的，*z*轴向下，*x*轴与机器人的行驶方向对齐）：
- en: '![Figure 8.6 – Coordinate frames for Earth navigation and indoor navigation](img/B19846_08_6.jpg)'
  id: totrans-233
  prefs: []
  type: TYPE_IMG
  zh: '![图8.6 – 地球导航和室内导航的坐标系](img/B19846_08_6.jpg)'
- en: Figure 8.6 – Coordinate frames for Earth navigation and indoor navigation
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.6 – 地球导航和室内导航的坐标系
- en: We will be looking at this room map in more detail later.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在稍后更详细地查看这个房间地图。
- en: So, we have our grid and a coordinate system that we agree upon, or at least
    agree that we both understand. We also have a starting location and an ending
    location. Our objective is to determine the best path for the robot from the start
    to the finish point. And in between, we have to plan a path around any obstacles
    that may be in the way.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们有一个网格和一个我们同意的坐标系，或者至少我们同意我们都理解。我们还有一个起点和一个终点。我们的目标是确定机器人从起点到终点的最佳路径。在中间，我们必须规划一条绕过可能挡道的任何障碍物的路径。
- en: Next, we have to talk about knowledge.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们必须谈谈知识。
- en: Developing a map based on our knowledge
  id: totrans-238
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于我们的知识开发地图
- en: 'There are basically two kinds of grid search and path finding routines:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上有两种类型的网格搜索和路径查找程序：
- en: '**A priori knowledge**, where you know where everything is on the map'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**先验知识**，你知道地图上的一切'
- en: '**A posteriori knowledge**, where you don’t know where the obstacles are'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**事后知识**，你不知道障碍物在哪里'
- en: We will start in the easier position where we can do our path planning with
    perfect knowledge of the layout of the room – we have a map.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从更容易的位置开始，在那里我们可以利用对房间布局的完美知识来进行路径规划——我们有一张地图。
- en: 'We really have three goals we are trying to achieve simultaneously with path
    planning:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 我们实际上有三个目标，我们试图在路径规划中同时实现：
- en: Reach our goal
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 达到我们的目标
- en: Avoid obstacles
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 避开障碍物
- en: Take the shortest path
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择最短路径
- en: We can talk about how we might go about this. We can start with our pencil at
    the start point and draw an imaginary line from our start to the goal. If there
    are no obstacles in the way, we are done. But wait – our pencil is a tiny line
    on paper. Our robot is somewhat chubbier – it has a significant width as it drives
    around. How do we judge whether the robot is going down some narrow passage that
    it won’t fit into? We need to modify our map!
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以谈谈我们可能如何进行。我们可以从起点开始，用铅笔画一条从起点到目标的想象中的线。如果没有障碍物挡道，我们就完成了。但是等等——我们的铅笔在纸上只是一条细线。我们的机器人则相对较胖——它在行驶过程中有一个显著的宽度。我们如何判断机器人是否正在通过一条它无法进入的狭窄通道？我们需要修改我们的地图！
- en: 'We have our grid, or a piece of paper that represents the grid. We can draw
    on that grid the outlines of all the obstacles, to scale. We have two chairs,
    two tables, a fireplace, two ottomans, and four bookcases. We color in all the
    obstacles in the darkest black we can. Now, we get a lighter colored pencil –
    say a blue color – and draw an outline around all of the furniture that is half
    the width of the robot. Our robot is 32 cm wide, so half of that is 16 cm, a nice
    even number. Our grid is 1 cm per square, so we make a 16-square border around
    everything. It looks like this:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有自己的网格，或者是一张代表网格的纸张。我们可以在网格上绘制所有障碍物的轮廓，并按比例绘制。我们有两张椅子、两张桌子、一个壁炉、两个脚凳和四个书架。我们用最深的黑色将所有障碍物都涂上颜色。现在，我们拿一支浅色的铅笔——比如说蓝色——围绕所有机器人宽度一半的家具画一个轮廓。我们的机器人宽度是32厘米，所以一半是16厘米，这是一个很好的偶数。我们的网格是每平方厘米1厘米，所以我们围绕所有东西画一个16平方单位的边界。它看起来像这样：
- en: '![Figure 8.7 – Adding safety boundaries to obstacles helps prevent collisions](img/B19846_08_7.jpg)'
  id: totrans-249
  prefs: []
  type: TYPE_IMG
  zh: '![图8.7 – 为障碍物添加安全边界有助于防止碰撞](img/B19846_08_7.jpg)'
- en: Figure 8.7 – Adding safety boundaries to obstacles helps prevent collisions
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.7 – 为障碍物添加安全边界有助于防止碰撞
- en: So, now our map has two colors – obstacles and a *keep-out* border. We are going
    to keep the center of the robot out of the keep-out zone, and then we will not
    hit anything. This should make sense. As for judging passages and doorways, if
    the keep-out zones touch on either side (so if there are no white squares left
    in the middle), then the robot is too big to pass. You can see this around the
    ottoman in the upper-left corner of the illustration.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，现在我们的地图有两种颜色——障碍物和*禁止*边界。我们将保持机器人的中心不在禁止区域内，这样我们就不会撞到任何东西。这应该是有意义的。至于判断通道和门，如果禁止区域在两侧接触（也就是说，中间没有剩下的白色方格），那么机器人太大，无法通过。你可以在插图右上角的脚凳周围看到这一点。
- en: We look at our line now. We need a way to write a computer algorithm that determines
    the white squares that the robot can pass through that gets us from the start
    point to the finish point.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看这条线。我们需要一种方法来编写一个计算机算法，该算法确定机器人可以穿过的白色方格，从而从起点到达终点。
- en: 'Since we have the goal in Cartesian coordinates and we have our start spot,
    we can express the distance in a straight line from the start to the finish. If
    the start point is `x1, y1` and the finish point is `x2, y2`, then the distance
    is the square root of the sums of the difference between the points:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们有了目标在笛卡尔坐标系中的位置，并且我们有我们的起点，我们可以用一条直线从起点到终点的距离来表示。如果起点是`x1, y1`，终点是`x2, y2`，那么距离是两点之间差值的平方和的平方根：
- en: '*distance = sqrt(x2-x1)^2 + (**y2-y1)^2)*'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: '*距离 = sqrt((x2-x1)^2 + (y2-y1)^2)*'
- en: One approach for developing a path planning algorithm is to use a **wavefront
    method**. We know where the start is. We go out in every direction to the eight
    squares adjacent to the start point. If any of those hit an obstacle or keep-out
    zone, we throw it out as a possible path. We keep track of how we got to each
    square, which, in my illustration (*Figure 8**.8*), is indicated by the arrows.
    We use the information on how we got to the square because we don’t yet know where
    we are going next. Now, we take all the new squares and do the same thing again
    – grabbing one square, seeing which of its eight neighbors is a legal move, and
    then putting an arrow (or a pointer to the location of the previous square) in
    it to keep track of how we got there. We continue to do this until we get to our
    goal. We keep a record of the order of the squares we examined and follow the
    arrows backward to our starting point.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 开发路径规划算法的一种方法是用**波前法**。我们知道起点在哪里。我们向八个相邻的方格方向延伸。如果其中任何一个遇到障碍物或禁止区域，我们就将其排除在可能的路径之外。我们记录我们如何到达每个方格，在我的插图（*图8.8*）中，这由箭头表示。我们使用我们如何到达方格的信息，因为我们还不知道我们接下来要去哪里。现在，我们拿所有新的方格并再次做同样的事情——选择一个方格，看看它的八个邻居中哪个是合法的移动，然后在其中放一个箭头（或指向前一个方格位置的指针）以记录我们是如何到达那里的。我们继续这样做，直到我们到达目标。我们记录我们检查方格的顺序，并跟随箭头向后到达我们的起点。
- en: 'If more than one square has a path leading to the current square, then we take
    the closest one, which is to say the shortest path. We follow these predecessors
    all the way back to the starting point, and that is our path:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 如果有多个方格都有通往当前方格的路径，那么我们选择最近的那个，也就是说，最短的路径。我们跟随这些前驱者一直回到起点，这就是我们的路径：
- en: '![Figure 8.8 – The wavefront approach to path planning has very little math
    involved. Each figure is a step in the process, starting at the upper left and
    going across, then down](img/B19846_08_8.jpg)'
  id: totrans-257
  prefs: []
  type: TYPE_IMG
  zh: '![图8.8 – 波前法路径规划涉及很少的数学计算。每个图都是过程的一个步骤，从左上角开始，横向移动，然后向下](img/B19846_08_8.jpg)'
- en: Figure 8.8 – The wavefront approach to path planning has very little math involved.
    Each figure is a step in the process, starting at the upper left and going across,
    then down
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.8 – 波前法路径规划涉及很少的数学计算。每个图都是过程的一个步骤，从左上角开始，横向移动，然后向下
- en: You will notice in this example that I allowed the robot to make diagonal turns
    to get from one square to another. I could have also specified that only right-angle
    turns are allowed, but that is not very efficient and is hard on the robot’s drive
    system. Only allowing right-angle turns simplifies the processing somewhat, since
    you only have to consider four neighbors around a square instead of eight.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 你会注意到在这个例子中，我允许机器人进行对角转向以从一个方格移动到另一个方格。我也可以指定只允许直角转向，但这不是很高效，而且对机器人的驱动系统来说很困难。只允许直角转向在某种程度上简化了处理，因为您只需要考虑一个方格周围的四个邻居，而不是八个。
- en: 'Another approach for developing a path planning algorithm that would look promising
    is the **Greedy Best-First** approach. Instead of keeping a record and checking
    all of the grid points as we did in the wavefront method, we just keep the single
    best path square out of the eight we just tested. The measure we use to decide
    which square to keep is the one that is closest to our straight-line path. Another
    way of saying this is to say it’s the square that is closest to the goal. We remove
    squares that are blocked by obstacles, of course. The net result is we are considering
    a lot (really a lot!) fewer squares than the wavefront method of path planning:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种开发看起来有希望路径规划算法的方法是**贪婪最佳优先**方法。与我们在波前方法中记录并检查所有网格点不同，我们只需保留我们刚刚测试的八个方格中的最佳路径方格。我们用来决定保留哪个方格的度量标准是离我们的直线路径最近的那个。另一种说法是，它是离目标最近的那个方格。我们当然会移除被障碍物阻挡的方格。最终结果是，我们考虑的方格比波前法路径规划少得多：
- en: '![Figure 8.9 – The aptly named “Greedy Best-First” algorithm is fast, but can
    get stuck](img/B19846_08_9.jpg)'
  id: totrans-261
  prefs: []
  type: TYPE_IMG
  zh: '![图8.9 – 被恰当地命名为“贪婪最佳优先”的算法速度快，但可能会陷入困境](img/B19846_08_9.jpg)'
- en: Figure 8.9 – The aptly named “Greedy Best-First” algorithm is fast, but can
    get stuck
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.9 – 被恰当地命名为“贪婪最佳优先”的算法速度快，但可能会陷入困境
- en: Does the greedy technique work for all cases? Not really.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 贪婪技术适用于所有情况吗？实际上并不适用。
- en: 'Why not? That seems a simple algorithm, and we are only considering legal moves.
    The problem is it can’t deal with a **local minima**. What is a local minima?
    It is a place on the map where the robot would have to go backward to find a good
    path. The easiest type of minima to visualize is a U-shaped area where the robot
    can get in but not back out. The Greedy Best-First algorithm is also not trying
    to find the shortest path, just a valid path:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么不呢？这似乎是一个简单的算法，我们只考虑合法的移动。问题是它无法处理**局部最小值**。什么是局部最小值？它是在地图上机器人必须后退才能找到好路径的地方。最容易可视化的最小值类型是U形区域，机器人可以进入但不能退出。贪婪最佳优先算法也不是试图找到最短路径，而只是找到一个有效路径：
- en: '![Figure 8.10 – A “local minima” can occur when no straight path exists, and
    the robot will have to back up or reverse direction](img/B19846_08_10.jpg)'
  id: totrans-265
  prefs: []
  type: TYPE_IMG
  zh: '![图8.10 – 当不存在直线路径时，可能会出现“局部最小值”，机器人将不得不后退或改变方向](img/B19846_08_10.jpg)'
- en: Figure 8.10 – A “local minima” can occur when no straight path exists, and the
    robot will have to back up or reverse direction
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.10 – 当不存在直线路径时，可能会出现“局部最小值”，机器人将不得不后退或改变方向
- en: If we want to find the shortest path, we need to do some more math.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们要找到最短路径，我们需要做一些额外的数学计算。
- en: A more systematic and mathematical way to approach finding the shortest path
    around obstacles for a grid search problem is the **A* algorithm**, first developed
    for Shakey the Robot.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 一种更系统和数学的方法来处理网格搜索问题中绕过障碍物找到最短路径是**A*算法**，最初是为Shakey机器人开发的。
- en: Introducing the A* algorithm
  id: totrans-269
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍A*算法
- en: Honestly, you can’t really write a book about robotics without mentioning the
    A* algorithm. A* has its origins with *Shakey the Robot* at Stanford University
    back in 1968\. This was one of the first map-navigating robots. Nils Nilsson and
    his team were trying to find a method to navigate Shakey around the hallways at
    Stanford and started trying different algorithms. The first was called *A1*, the
    second *A2*, and so forth. After several iterations, the team decided that a combination
    of techniques worked best. In computer science, A* means the letter A followed
    by anything else, and thus the A-star was named.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 实话实说，如果不提及A*算法，你真的无法写出一本关于机器人的书。A*算法的起源可以追溯到1968年斯坦福大学的*Shakey机器人*。这是最早的地图导航机器人之一。Nils
    Nilsson和他的团队试图找到一种方法来让Shakey在斯坦福的大厅中导航，并开始尝试不同的算法。第一个算法被称为*A1*，第二个*A2*，以此类推。经过多次迭代，团队决定技术组合的效果最好。在计算机科学中，A*表示字母A后面跟着任何其他字符，因此A-star就这样命名了。
- en: 'The concept of the A-star process is very much like what we have already been
    doing with our other path planners. Like the wavefront planner, we start by considering
    the neighbors around our starting location. We will compute an estimate for each
    square based on two factors: the distance from the starting location and the distance
    in a straight line to the goal. We are going to use these factors to find the
    path with the lowest cumulative cost. We calculate that cost by adding up the
    value for each grid square that is part of the path. The formula is as follows:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: A*过程的概念与我们之前使用其他路径规划器所做的是非常相似的。像波前规划器一样，我们首先考虑起点的邻居。我们将根据两个因素计算每个方块的一个估计值：从起点到该方块的距离和到目标的直线距离。我们将使用这些因素来找到累积成本最低的路径。我们通过将路径中每个网格方块的价值相加来计算这个成本。公式如下：
- en: '*F(n) = g(n) +* *h(n)*'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: '*F(n) = g(n) +* *h(n)*'
- en: Here, *F(n)* refers to the contribution of this square to the path cost, *g(n)*
    represents the distance from this square from the start position along the path
    chosen (that is, the sum of the path cost), and *h(n)* is the straight line distance
    from this square to the goal, which is a heuristic or estimate of the distance
    remaining to the goal. Since we don’t know what other obstacles we have to go
    around later, we use this guess as a measuring stick to compare paths.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*F(n)*指的是这个方块对路径成本的贡献，*g(n)*代表从该方块到起点沿所选路径的距离（即路径成本的总和），而*h(n)*是从该方块到目标的直线距离，这是一个启发式或对剩余距离的估计。由于我们不知道之后我们还要绕过哪些障碍，我们使用这个猜测作为比较路径的衡量标准。
- en: 'This value represents the cost or contribution of this square if it were a
    part of the final path. We will select the square to be part of the path that
    has the lowest combined cost. As with the wavefront planner, we keep track of
    the predecessor square or the square that was traversed before this one to reconstruct
    our path:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 这个值代表如果这个方块是最终路径的一部分，它的成本或贡献是多少。我们将选择成本最低的方块作为路径的一部分。与波前规划器一样，我们跟踪前驱方块或在这个方块之前走过的方块，以重建我们的路径：
- en: '![Figure 8.11 – The A-star computation uses the distance to start (G) and the
    distance to the goal (H)](img/B19846_08_11.jpg)'
  id: totrans-275
  prefs: []
  type: TYPE_IMG
  zh: '![图8.11 – A*计算使用从起点（G）到目标（H）的距离](img/B19846_08_11.jpg)'
- en: Figure 8.11 – The A-star computation uses the distance to start (G) and the
    distance to the goal (H)
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.11 – A*计算使用从起点（G）到目标（H）的距离
- en: The preceding diagram illustrates the A* algorithm. Each square is evaluated
    based on the sum of the distance along a path back to the start (*G*), and an
    estimate of the remaining distance to the goal (*H*). The yellow squares represent
    the path selected so far.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 上述图示说明了A*算法。每个方块都是基于从起点沿路径的距离（*G*）和到目标的剩余距离的估计（*H*）来评估的。黄色方块代表迄今为止选定的路径。
- en: 'Let’s illustrate how the A* algorithm works:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过实例说明A*算法是如何工作的：
- en: 'We keep a set of all the grid squares on the map we have computed values for.
    We’ll call this `exploredMap`. Our map grid square object looks like this:'
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们保留一个集合，包含我们在地图上计算值的所有网格方块。我们将这个称为`exploredMap`。我们的地图网格方块对象看起来是这样的：
- en: '[PRE22]'
  id: totrans-280
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Now, we will fill in our map with zeros to initialize everything. We will define
    the `mapGridSquare` function later in the code – it creates our data structures:'
  id: totrans-281
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将地图填充为零以初始化一切。我们将在代码中稍后定义`mapGridSquare`函数——它创建我们的数据结构：
- en: '[PRE23]'
  id: totrans-282
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The next section creates all of the obstacles on the map. We put the location
    of which grid squares to *fill-in* or make impassable:'
  id: totrans-283
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一个部分将在地图上创建所有障碍。我们将放置要*填充*或使其不可通行的网格方块的位置：
- en: '[PRE24]'
  id: totrans-284
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Now, we declare our starting and ending positions:'
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们声明我们的起始和结束位置：
- en: '[PRE25]'
  id: totrans-286
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'In this section, we are creating our data structures to keep track of all of
    the computations we make. The `G` value is the computed distance from the start,
    and the `H` value is the estimated distance to the goal. `F` is just the sum of
    these two. We also create a function to compute these values:'
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在本节中，我们正在创建我们的数据结构来跟踪我们做出的所有计算。`G` 值是从起点计算出的距离，`H` 值是到目标的估计距离。`F` 只是这两个值的总和。我们还创建了一个函数来计算这些值：
- en: '[PRE26]'
  id: totrans-288
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'We need a function to trace the path from the goal back to the start once we’ve
    completed the map computations. This function is called `reconstructPath`:'
  id: totrans-289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦完成地图计算，我们需要一个函数来追踪从目标到起点的路径。这个函数被称为 `reconstructPath`：
- en: '[PRE27]'
  id: totrans-290
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'We create a `findMin` function to locate the grid block that we have explored
    with the lowest `F` score:'
  id: totrans-291
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们创建了一个 `findMin` 函数来定位我们探索过的网格块中具有最低 `F` 分数的那个：
- en: '[PRE28]'
  id: totrans-292
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Then, we create the `navigation` function itself:'
  id: totrans-293
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们创建 `navigation` 函数本身：
- en: '[PRE29]'
  id: totrans-294
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The `neighbors` function returns all the neighbors of the current square that
    are not marked as obstacles:'
  id: totrans-295
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`neighbors` 函数返回当前方块所有未标记为障碍物的相邻方块：'
- en: '[PRE30]'
  id: totrans-296
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'We only compute each grid square once:'
  id: totrans-297
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们只计算每个网格方块一次：
- en: '[PRE31]'
  id: totrans-298
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Now, we look for the square that has the lowest `G` value – that is, the one
    closest to the start:'
  id: totrans-299
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们寻找具有最低 `G` 值的方块——即离起点最近的那个：
- en: '[PRE32]'
  id: totrans-300
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: So, in this section, we’ve covered the A* approach to finding the shortest path
    on a map, given that we know where all of the obstacles are in advance. But what
    if we don’t? Another method we can use is the D* algorithm.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在本节中，我们介绍了在已知所有障碍物位置的情况下，在地图上找到最短路径的 A* 方法。但如果我们不知道呢？我们可以使用的另一种方法是 D* 算法。
- en: Introducing the D* (D-star or dynamic A*) algorithm
  id: totrans-302
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍 D*（D-星或动态 A*）算法
- en: Earlier in the chapter, I talked about *a priori* knowledge. The A-star algorithm,
    for all its usefulness, requires that obstacles in the entire map be known in
    advance. What do we do if we are planning a movement into an unknown space, where
    we will create the map as we go along? If we have a robot with sensors, such as
    sonar or lidar, then the robot will be detecting and identifying obstacles as
    it goes. So, it must continually replan its route based on increasing information.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的前面部分，我谈到了 *先验* 知识。尽管 A* 算法非常有用，但它要求在地图上预先知道所有障碍物。如果我们计划进入一个未知空间，我们将边走边创建地图，我们该怎么办？如果我们有一个带有传感器（如声纳或激光雷达）的机器人，那么机器人将在移动过程中检测和识别障碍物。因此，它必须根据不断增多的信息不断重新规划其路线。
- en: The A* process is only run one time to plan a route for a robot before it begins
    to move. **D***, a dynamic replanning process, is constantly updating the robot’s
    path as new information becomes available.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: A* 过程只运行一次，在机器人开始移动之前为机器人规划路线。**D***，一个动态重新规划过程，会随着新信息的出现不断更新机器人的路径。
- en: 'The D* algorithm allows for replanning by adding some additional information
    to each grid square. You will remember that in A*, we had the `G` value (distance
    to the start along the path), and the `H` value (straight-line distance to the
    goal). D-star adds a tag to the square that can have several possible values:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: D* 算法通过向每个网格方块添加一些附加信息来允许重新规划。你可能会记得，在 A* 中，我们有 `G` 值（路径上到起点的距离）和 `H` 值（到目标的直线距离）。D-star
    在方块上添加了一个可以具有几个可能值的标签：
- en: The square’s tag could be `NEW` for a new square that had never been explored
    before.
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 方块的标签可能是 `NEW`，表示一个以前从未被探索过的新方块。
- en: It could be `OPEN` for tags that have been evaluated and are being considered
    as part of the path.
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它可能是 `OPEN`，表示已评估并作为路径一部分考虑的标签。
- en: '`CLOSED` is for squares that have been dropped from consideration.'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CLOSED` 是指已被从考虑中删除的方块。'
- en: The next two tags are `RAISED` and `LOWERED`. The `RAISED` flag is set if a
    sensor reading or additional information caused the cost of that square to increase,
    and `LOWERED` is the opposite. For `LOWERED` squares, we need to propagate the
    new path cost to the neighbors of the now lower-cost square, so that they can
    be re-evaluated. This may cause tags to change on the neighboring squares. `RAISED`
    squares have increased cost, and so may be dropped from the path, and `LOWERED`
    squares have reduced cost and may be added into the path.
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 下两个标签是 `RAISED` 和 `LOWERED`。如果传感器的读数或附加信息导致该方块的代价增加，则设置 `RAISED` 标志，而 `LOWERED`
    则相反。对于 `LOWERED` 方块，我们需要将新的路径代价传播到现在代价较低的方块相邻的方块，以便它们可以重新评估。这可能会导致相邻方块上的标签发生变化。`RAISED`
    方块的代价增加，因此可能从路径中删除，而 `LOWERED` 方块的代价减少，可能被添加到路径中。
- en: Note
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Keep in mind that changes in cost values ripple through the D* evaluation of
    paths like a wave as the path is backtracked all the way to the start when the
    values change.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，当路径回溯到起点时，成本值的变化会在 D* 的路径评估中像波浪一样传播。
- en: Another major difference between D* and A* is that D* starts at the goal and
    works backward toward the start. This allows D* to know the exact cost to the
    target – it is using the actual path distance to the goal from the current position
    and not a heuristic or estimate of the distance to go, as A* did.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: D* 和 A* 之间的另一个主要区别在于，D* 从目标开始，逆向工作到起点。这使得 D* 能够知道到达目标的确切成本——它使用从当前位置到目标的实际路径距离，而不是像
    A* 那样使用启发式或距离估计。
- en: This is a good time to remind you that all these grid-searching techniques we
    just covered are still variations of decision trees. We are going from leaf to
    leaf – which we have been calling grid squares, but they are still leaves of a
    decision tree. We set some criteria for choosing which of several paths to take,
    which make branching paths. We are working toward some goal or endpoint in each
    case. I bring this up because, in the next section, we will combine decision trees
    and the type of path planning we learned from the A* and D* algorithms to find
    a path through streets with a GPS.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 这是个提醒你的时候，我们刚刚覆盖的所有这些网格搜索技术仍然是决策树的变体。我们是从叶子到叶子——我们称之为网格方块，但它们仍然是决策树的叶子。我们设定了一些标准来选择走哪条路径，这形成了分支路径。我们在每种情况下都朝着某个目标或终点工作。我提这一点是因为，在下一节中，我们将结合决策树和从
    A* 和 D* 算法中学到的路径规划类型，以使用 GPS 在街道上找到一条路径。
- en: GPS path finding
  id: totrans-314
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GPS 路径查找
- en: I wanted to have the opportunity (since we have come this far) to talk just
    for a little bit about **topological path planners**. This is an alternative method
    to the grid-based techniques we used in the preceding sections. There are types
    of problems and types of navigation where a grid-based approach is not appropriate
    or would require astronomical amounts of detailed data that may not be available
    or practical in a small robot.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 我想有机会（既然我们已经走到这一步）简单谈谈**拓扑路径规划器**。这是前几节中使用的基于网格技术的替代方法。有些问题和导航类型不适合基于网格的方法，或者可能需要天文数字般的大量详细数据，而这些数据可能在小机器人中不可用或不实用。
- en: As an example, I wanted to talk about how your GPS in your car finds a route
    along streets to reach your destination. You must have wondered about how that
    box has enough information in its tiny brain to provide turn-by-turn directions
    from one place to another. You may have imagined, if you stopped to think about
    it, that the GPS was using the same map you were viewing on the LCD screen to
    determine where you need to go. You would also think that some sort of grid-based
    search took place, such as the A* algorithm we discussed in such detail. And you
    would be wrong.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我想谈谈你的汽车中的 GPS 如何在街道上找到一条路线到达目的地。你一定想知道那个小盒子在其微小的“大脑”中如何拥有足够的信息来提供从一地到另一地的逐个转弯指示。如果你停下来思考，你可能想象
    GPS 正在使用你在 LCD 屏幕上查看的同一张地图来确定你需要去哪里。你也会认为发生了一种基于网格的搜索，就像我们之前详细讨论的 A* 算法一样。但你会错的。
- en: The data that the GPS uses to plan a route does not look like a map at all.
    Instead, it is a **topological network** that shows how streets are interconnected.
    In format, it looks more like a database of vectors (which have a direction and
    a magnitude, or distance), rather than an *X, Y* gridded raster map made up of
    pixels. The database format also takes up a lot less room in the GPS internal
    storage. The streets are divided by **nodes** or points where roads intersect
    or change. Each node shows which streets are connected. The nodes are connected
    by **links**, which allow you to traverse the data from node to node. The links
    represent the roads and have a length, along with cost data about the quality
    of the road. The cost data is used to compute the desirability of the route. A
    limited access highway with a high-speed limit would have a low cost, and a small
    side street or dirt road with a lot of stop signs would have a high cost since
    that link is both less desirable and slower.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: GPS 用于规划路线的数据看起来根本不像地图。相反，它是一个 **拓扑网络**，显示了街道是如何相互连接的。在格式上，它看起来更像是一个矢量数据库（具有方向和大小或距离），而不是由像素组成的
    *X, Y* 网格栅格地图。数据库格式在 GPS 内部存储中也占用更少的空间。街道被 **节点** 或道路交叉或改变的地方分隔。每个节点显示哪些街道是相连的。节点通过
    **链接** 相连，允许您从节点到节点遍历数据。链接代表道路，并具有长度，以及关于道路质量的成本数据。成本数据用于计算路线的吸引力。限速高速公路的成本会很低，而有很多停车标志的小巷或土路成本会很高，因为该链接既不太受欢迎，速度也较慢。
- en: The technique that most GPS path planners use is called **Dijkstra’s algorithm**,
    after Edsger W. Dijkstra, from the Netherlands. He wanted to find the shortest
    path from Rotterdam to Groningen, back in 1956\. His graph-based solution has
    withstood the test of time and is very commonly used for GPS routing. It’s not
    of any help to us for our robot, so you can research this on your own.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数 GPS 路径规划器使用的算法被称为 **迪杰斯特拉算法**（Dijkstra’s algorithm），以荷兰的埃德加·W·迪杰斯特拉（Edsger
    W. Dijkstra）的名字命名。他在 1956 年想要找到从鹿特丹到格罗宁根的最短路径。他的基于图的解决方案经受住了时间的考验，并且非常普遍地用于 GPS
    路由。对我们这个机器人来说，这并没有任何帮助，所以你可以自己研究一下。
- en: 'We use the same procedures with the GPS road network database as we would when
    working the A-star process on a grid map. We evaluate each node, and progress
    outward from our start node, choosing the path that takes us closest in the direction
    of our destination:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用与在网格图上执行 A* 过程相同的程序来处理 GPS 路网数据库。我们评估每个节点，并从起始节点向外扩展，选择最接近目的地方向的路径：
- en: '![Figure 8.12 – A road-based network can be represented as a series of nodes
    (circles) and links (lines)](img/B19846_08_12.jpg)'
  id: totrans-320
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.12 – 基于道路的网络可以表示为一系列节点（圆圈）和链接（线条）](img/B19846_08_12.jpg)'
- en: Figure 8.12 – A road-based network can be represented as a series of nodes (circles)
    and links (lines)
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.12 – 基于道路的网络可以表示为一系列节点（圆圈）和链接（线条）
- en: Many GPS systems also simultaneously try to backward-chain from the endpoint
    – the goal or destination – and try to meet somewhere in the middle. An amazing
    amount of work has gone into making our current crop of GPS systems small, lightweight,
    and reliable. Of course, they are dependent on up-to-date information in the database.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 许多 GPS 系统也会同时尝试从终点——目标或目的地——反向链，并试图在中间某处相遇。为了使我们的 GPS 系统小巧、轻便和可靠，投入了惊人的工作量。当然，它们依赖于数据库中的最新信息。
- en: Summary
  id: totrans-323
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Well, this has been a very busy chapter. We covered the uses of decision trees
    for a variety of applications. The basic decision tree has leaves (nodes) and
    links, or branches, that each represent a decision or a change in a path. We learned
    about fishbone diagrams and root cause analysis, a special type of decision tree.
    We showed a method using `scikit-learn` to have the computer build a classification
    decision tree for us and create a usable graph. We discussed the concept of random
    forests, which are just an evolved form of using groups of decision trees to perform
    prediction or regression. Then, we got into graph search algorithms and path planners,
    spending some time on the A* (or A-star) algorithm, which is widely used for making
    routes and paths. For times when we do not have a map created in advance, the
    D* (or dynamic A-star) process can use dynamic replanning to continually adjust
    the robot’s path to reach its goal. Finally, we introduced topological graph path
    planning and discussed how GPS systems find a route for you to the coffee shop.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 嗯，这已经是一个非常繁忙的章节了。我们讨论了决策树在多种应用中的用途。基本决策树有叶子（节点）和链接，或分支，每个都代表一个决策或路径上的变化。我们学习了鱼骨图和根本原因分析，这是一种特殊的决策树。我们展示了使用`scikit-learn`的方法，让计算机为我们构建一个分类决策树并创建一个可用的图。我们讨论了随机森林的概念，它只是使用决策树组进行预测或回归的演变形式。然后，我们探讨了图搜索算法和路径规划器，花了一些时间讨论A*（或A-star）算法，该算法广泛用于制作路线和路径。当我们没有预先创建地图时，D*（或动态A-star）过程可以使用动态重新规划来不断调整机器人的路径以到达目标。最后，我们介绍了拓扑图路径规划，并讨论了GPS系统是如何为你找到去咖啡店的路线的。
- en: In our next chapter, we’ll be talking about giving your robot an artificial
    personality, by simulating emotions using a Monte Carlo model.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们接下来的章节中，我们将讨论通过使用蒙特卡洛模型模拟情绪来给你的机器人赋予人工个性。
- en: Questions
  id: totrans-326
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: What are the three ways to traverse a decision tree?
  id: totrans-327
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有哪三种方法可以遍历决策树？
- en: In the fishbone diagram example, how does one go about pruning the branches
    of the decision tree?
  id: totrans-328
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在鱼骨图示例中，如何对决策树的分支进行剪枝？
- en: What is the role of the Gini evaluator in creating a classification?
  id: totrans-329
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Gini评估器在创建分类中扮演什么角色？
- en: In the toy classifier example using Gini indexing, which attributes of the toy
    were not used by the decision tree? Why not?
  id: totrans-330
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在使用基尼指数的玩具分类器示例中，玩具的哪些属性没有被决策树使用？为什么没有使用？
- en: Which color for the toys was used as a criterion by one of the classification
    techniques we tried?
  id: totrans-331
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们尝试的某个分类技术中，哪种颜色被用作玩具的标准？
- en: Give an example of label encoding and one-hot encoding for menu items at a restaurant.
  id: totrans-332
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请举一个在餐厅菜单项中进行标签编码和独热编码的例子。
- en: In the A* algorithm, discuss the different ways that `G()` and `H()` are computed.
  id: totrans-333
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在A*算法中，讨论`G()`和`H()`的不同计算方式。
- en: In the A* algorithm, why is `H()` considered a heuristic and `G()` is not? Also,
    in the D* algorithm, heuristics are not used. Why not?
  id: totrans-334
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在A*算法中，为什么`H()`被认为是启发式，而`G()`不是？此外，在D*算法中，没有使用启发式。为什么？
- en: In the D* algorithm, why is there a `RAISED` and `LOWERED` tag and not just
    a `CHANGED` flag?
  id: totrans-335
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在D*算法中，为什么有`RAISED`和`LOWERED`标签，而不是仅仅一个`CHANGED`标志？
- en: Further reading
  id: totrans-336
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: '*Introduction to the A** *Algorithm*: [https://www.redblobgames.com/pathfinding/a-star/introduction.html](https://www.redblobgames.com/pathfinding/a-star/introduction.html)'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*A算法简介*：[https://www.redblobgames.com/pathfinding/a-star/introduction.html](https://www.redblobgames.com/pathfinding/a-star/introduction.html)'
- en: '*Introduction to AI Robotics* by Robin R. Murphy, MIT Press, 2000'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*人工智能机器人导论*，罗宾·R·墨菲著，麻省理工学院出版社，2000年'
- en: '*How Decision Tree Algorithm* *Works*: [https://dataaspirant.com/2017/01/30/how-decision-tree-algorithm-works/](https://dataaspirant.com/2017/01/30/how-decision-tree-algorithm-works/)'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*决策树算法是如何工作的*：[https://dataaspirant.com/2017/01/30/how-decision-tree-algorithm-works/](https://dataaspirant.com/2017/01/30/how-decision-tree-algorithm-works/)'
- en: '*Game Programming* *Heuristics*: [http://theory.stanford.edu/~amitp/GameProgramming/Heuristics.html](http://theory.stanford.edu/~amitp/GameProgramming/Heuristics.html)'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*游戏编程* *启发式方法*：[http://theory.stanford.edu/~amitp/GameProgramming/Heuristics.html](http://theory.stanford.edu/~amitp/GameProgramming/Heuristics.html)'
- en: '*D*Lite Algorithm Blog (Project Fast Replanning)* by Sven Koening: [http://idm-lab.org/project-a.html](http://idm-lab.org/project-a.html)'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*D*Lite算法博客（快速重新规划项目）*，斯文·科宁：[http://idm-lab.org/project-a.html](http://idm-lab.org/project-a.html)'
- en: '*Graph-Based Path Planning for Mobile Robots*, Dissertation by David Wooden,
    School of Electrical and Computer Engineering, Georgia Institute of Technology,
    December 2006'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*移动机器人的基于图的路径规划*，大卫·伍德南的论文，乔治亚理工学院电子与计算机工程系，2006年12月'
- en: '*The Focused D* Algorithm for Real-Time Replanning* by Anthony Stentz: [https://robotics.caltech.edu/~jwb/courses/ME132/handouts/Dstar_ijcai95.pdf](https://robotics.caltech.edu/~jwb/courses/ME132/handouts/Dstar_ijcai95.pdf)'
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*《实时重规划中的聚焦D算法》* 由安东尼·斯坦茨撰写：[https://robotics.caltech.edu/~jwb/courses/ME132/handouts/Dstar_ijcai95.pdf](https://robotics.caltech.edu/~jwb/courses/ME132/handouts/Dstar_ijcai95.pdf)'
