- en: 3\. Topic Modeling and Theme Extraction
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3. 主题建模和主题提取
- en: Overview
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 概述
- en: This chapter describes the use of Topic Modeling to understand common themes
    in a document set by analyzing documents using Amazon Comprehend. You will learn
    the fundamentals of the algorithm used for Topic Modeling, **Latent Dirichlet
    Allocation** (**LDA**). Learning LDA will allow you to apply Topic Modeling to
    a multitude of unique business cases. You will then perform Topic Modeling on
    two documents with a known topic structure. By the end of this chapter, you will
    be able to extract and analyze common themes through Topic Modeling with Amazon
    Comprehend and describe the basics of Topic Modeling analysis. You will also be
    able to perform Topic Modeling on a set of documents and analyze the results.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章描述了使用Amazon Comprehend分析文档来理解文档集中共同主题的使用。你将学习用于主题建模的算法的基本原理，**潜在狄利克雷分配**（**LDA**）。学习LDA将使你能够将主题建模应用于各种独特的业务案例。然后，你将对具有已知主题结构的两个文档执行主题建模。到本章结束时，你将能够通过Amazon
    Comprehend进行主题建模来提取和分析共同主题，并描述主题建模分析的基本原理。你还将能够对一组文档执行主题建模并分析结果。
- en: Introduction
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简介
- en: Topic Modeling is an important capability for business systems to make sense
    of unstructured information, ranging from support tickets to customer feedback
    and complaints, to business documents. Topic Modeling helps process automation
    to route customer feedback and mail; it enables a business to categorize and then
    effectively respond to social media posts, reviews, and other user-generated content
    from the various channels. It enables businesses to respond faster to critical
    items by understanding the topics and themes on incoming omnichannel interactions
    as well as responding most effectively by routing the materials to the most appropriate
    teams. Another two areas where Topic Modeling helps are knowledge management and
    brand monitoring.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 主题建模是企业系统理解非结构化信息的重要能力，范围从支持票到客户反馈和投诉，再到商业文件。主题建模有助于自动化处理客户反馈和邮件；它使企业能够对来自各种渠道的社会媒体帖子、评论和其他用户生成内容进行分类，并有效地响应。它使企业能够通过理解传入的多渠道交互中的主题和主题，以及通过将材料路由到最合适的团队来最有效地响应关键事项。主题建模帮助的两个其他领域是知识管理和品牌监控。
- en: Topic Modeling with Latent Dirichlet Allocation (LDA)
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用潜在狄利克雷分配（LDA）进行主题建模
- en: The subjects or **common themes** of a set of documents can be determined with
    Amazon Comprehend. For example, you have a movie review website with two message
    boards, and you want to determine which message board is discussing two newly
    released movies (one about sport and the other about a political topic). You can
    provide the message board text data to Amazon Comprehend to discover the most
    prominent topics discussed on each message board.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 一组文档的主题或**常见主题**可以使用Amazon Comprehend来确定。例如，你有一个电影评论网站，有两个论坛，你想要确定哪个论坛正在讨论两部新上映的电影（一部关于体育，另一部关于政治话题）。你可以提供论坛的文本数据给Amazon
    Comprehend，以发现每个论坛上讨论的最突出主题。
- en: The machine learning algorithm that Amazon Comprehend uses to perform Topic
    Modeling is called **Latent Dirichlet Allocation** (**LDA**). LDA is a learning-based
    model that's used to determine the most important topics in a collection of documents.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Comprehend用于执行主题建模的机器学习算法称为**潜在狄利克雷分配**（**LDA**）。LDA是一个基于学习的模型，用于确定文档集合中最重要的主题。
- en: How LDA works is that it considers every document to be a combination of topics,
    and each word in the document is associated with one of these topics.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: LDA的工作原理是，它将每个文档视为主题的组合，文档中的每个单词都与这些主题之一相关联。
- en: For example, if the first paragraph of a document consists of words such as
    **eat**, **chicken**, **restaurant**, and **cook**, then you conclude that the
    topic can be generalized to **Food**. Similarly, if the second paragraph of a
    document contains words such as **ticket**, **train**, **kilometer**, and **vacation**,
    then you can conclude that the topic is **Travel**.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果一份文档的第一段包含诸如**吃**、**鸡肉**、**餐厅**和**烹饪**等词语，那么你可以得出结论，该主题可以概括为**食物**。同样，如果文档的第二段包含诸如**票**、**火车**、**公里**和**假期**等词语，那么你可以得出结论，该主题是**旅行**。
- en: Basic LDA Example
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基本LDA示例
- en: LDA has lots of math behind it—concepts such as **Expectation Maximization**,
    Gibs sampling, priors, and a probability distribution over a "bag of words". If
    you want to understand the mathematical underpinnings, a good start is the Amazon
    documentation on SageMaker ([https://docs.aws.amazon.com/sagemaker/latest/dg/lda-how-it-works.html](https://docs.aws.amazon.com/sagemaker/latest/dg/lda-how-it-works.html)).
    Let's look at LDA more pragmatically and understand it empirically through an
    example.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: LDA 后面有很多数学原理——例如 **期望最大化**、吉布斯抽样、先验和“词袋”上的概率分布。如果你想了解数学基础，可以从 Amazon 的 SageMaker
    文档（[https://docs.aws.amazon.com/sagemaker/latest/dg/lda-how-it-works.html](https://docs.aws.amazon.com/sagemaker/latest/dg/lda-how-it-works.html)）开始。让我们更实际地看看
    LDA，并通过一个例子来实证地理解它。
- en: Say you have one document with six sentences, and you want to infer two common
    topics.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你有一篇包含六个句子的文档，你想推断出两个共同的主题。
- en: 'The sentences are as follows:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 句子如下：
- en: They loved each other greatly.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 他们彼此深爱着。
- en: Most people experience love without noticing that there is anything remarkable
    about it.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大多数人体验爱情时并没有意识到它有什么特别之处。
- en: It was partly the war; the revolution did the rest.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部分原因是战争；其余的是革命所造成的。
- en: The war was an artificial break in life, as if life could be put off for a time.
    What nonsense!
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 战争是生活中的一种人为的断裂，好像生活可以被推迟一段时间。多么荒谬！
- en: I said life, but I mean life as you see it in a great picture, transformed by
    genius, creatively enriched.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我说的是生活，但我指的是你在伟大画作中看到的生活，被天才所改变，创造性地丰富。
- en: Only now have people decided to experience it not in books and pictures, but
    in themselves, not as an abstraction, but in practice.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 只有现在人们才决定在自身中体验它，而不是在书籍和图片中，不是作为一种抽象，而是在实践中。
- en: 'When you feed these sentences into an LDA algorithm, specifying the number
    of topics as two, it will discover the following:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 当你将这些句子输入到 LDA 算法中，指定主题数量为两个时，它将发现以下内容：
- en: '**Sentence-Topics**'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**句子-主题**'
- en: 'Sentence 1: Topic 0'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 句子 1：主题 0
- en: 'Sentence 2: Topic 0'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 句子 2：主题 0
- en: 'Sentence 3: Topic 1'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 句子 3：主题 1
- en: 'Sentence 4: Topic 1'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 句子 4：主题 1
- en: 'Sentence 5: Topic 0'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 句子 5：主题 0
- en: 'Sentence 6: Topic 0'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 句子 6：主题 0
- en: '**Topic terms**'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**主题术语**'
- en: 'Topic 0: life 12%, people 8%, experience 8%, love 5%, and so forth'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 主题 0：生活 12%，人们 8%，体验 8%，爱情 5%，等等
- en: 'Topic 1: 62% revolution, 23% war, and the rest 15%'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 主题 1：62% 革命，23% 战争，其余 15%
- en: Of course, knowing that the sentences are from the book *Dr. Zhivago* by the
    famous Russian author *Boris Pasternak*, the topics war and life/love seem reasonable.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，知道这些句子来自著名俄罗斯作家鲍里斯·帕斯捷尔纳克所著的《日瓦戈医生》一书，主题战争和生命/爱情似乎是有道理的。
- en: While this example is a simplistic depiction of a complex algorithm, it gives
    you an idea. As discussed in this chapter, in various business situations, an
    indication of what a document or an e-mail or a social media post is about is
    very valuable for downstream systems—and the ability to perform that classification
    automatically is priceless.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这个例子是对一个复杂算法的简单描述，但它给你一个想法。正如本章所讨论的，在各种商业场景中，一个文档或电子邮件或社交媒体帖子所涉及内容的指示对于下游系统来说非常有价值——能够自动执行这种分类的能力是无价的。
- en: Why Use LDA?
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么使用 LDA？
- en: LDA is useful when you want to group a set of documents based on common topics,
    without thinking about the documents themselves. LDA can create subjects from
    inferring the general topics by analyzing the words in the documents. This is
    usually utilized in suggestion frameworks, report arrangement, and record synopsis.
    In conclusion, LDA has many uses. For example, you have 30,000 user emails and
    want to determine the most common topics to provide group-specific recommended
    content based on the most prevalent topics. Manually reading, or even outsourcing
    the manual reading, of 30,000 emails would take an excessive investment in terms
    of time and money, and the accuracy would be difficult to confirm. However, Amazon
    Comprehend can seamlessly provide the most common topics in 30,000 emails in a
    few steps with incredible accuracy. First, convert the emails to text files, upload
    them to an S3 bucket, and then imitate a Topic Modeling job with Amazon Comprehend.
    The output is two CSV files with the corresponding topics and terms.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 当你想根据共同的主题对一组文档进行分组，而不考虑文档本身时，LDA 非常有用。LDA 可以通过分析文档中的单词来推断一般主题，从而创建主题。这通常用于建议框架、报告安排和记录摘要。总之，LDA
    有很多用途。例如，你有 30,000 用户的电子邮件，并想确定最常见的主题，以便根据最普遍的主题提供针对特定群体的推荐内容。手动阅读，或者外包手动阅读，30,000
    封电子邮件将需要大量的时间和金钱投入，而且准确性难以确认。然而，Amazon Comprehend 可以在几个步骤内无缝地以惊人的准确性提供 30,000
    封电子邮件中最常见的主题。首先，将电子邮件转换为文本文件，上传到 S3 桶中，然后使用 Amazon Comprehend 模拟一个主题建模作业。输出是包含相应主题和术语的两个
    CSV 文件。
- en: Amazon Comprehend—Topic Modeling Guidelines
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Amazon Comprehend—主题建模指南
- en: 'The most accurate results are obtained if you provide Comprehend with the largest
    possible corpus. More specifically:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你向 Comprehend 提供尽可能大的语料库，可以获得最准确的结果。更具体地说：
- en: You should use no fewer than 1,000 records in every subject.
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个主题中应使用不少于 1,000 条记录。
- en: Each document ought to be something like three sentences in length.
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个文档应该像三句话那么长。
- en: If a document comprises, for the most part, numeric information, you should
    expel it from the corpus.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果一个文档大部分是数字信息，你应该将其从语料库中排除。
- en: 'Currently, Topic Modeling is limited to two document languages: **English**
    and **Spanish**.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，主题建模仅限于两种文档语言：**英语**和**西班牙语**。
- en: A Topic Modeling job allows two format types for input data (refer to the following
    *Figure 3.1*). This allows users to process both collections of large documents
    (for example, newspaper articles or scientific journals), and short documents
    (for example, tweets or social media posts).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 主题建模作业允许两种输入数据格式类型（参见图 3.1）。这使用户能够处理大型文档集合（例如，报纸文章或科学期刊），以及短文档（例如，推文或社交媒体帖子）。
- en: '**Input Format Options:**'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**输入格式选项：**'
- en: '![Figure 3.1: AWS Comprehend—Topic Modeling input format options'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.1：AWS Comprehend—主题建模输入格式选项](img/B16061_03_01.jpg)'
- en: '](img/B16061_03_01.jpg)'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16061_03_01.jpg](img/B16061_03_01.jpg)'
- en: 'Figure 3.1: AWS Comprehend—Topic Modeling input format options'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.1：AWS Comprehend—主题建模输入格式选项
- en: '**Output Format Options:**'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**输出格式选项：**'
- en: '![Figure 3.2: AWS Comprehend—Topic Modeling output files description'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.2：AWS Comprehend—主题建模输出文件描述](img/B16061_03_02.jpg)'
- en: '](img/B16061_03_02.jpg)'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16061_03_02.jpg](img/B16061_03_02.jpg)'
- en: 'Figure 3.2: AWS Comprehend—Topic Modeling output files description'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.2：AWS Comprehend—主题建模输出文件描述
- en: 'After Amazon Comprehend processes your document collection, the modeling outputs
    two CSV files: `topic-terms.csv` (see *Figure 3.2*) and `doc-topics.csv`.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Amazon Comprehend 处理完你的文档集合后，建模输出两个 CSV 文件：`topic-terms.csv`（参见图 3.2）和 `doc-topics.csv`。
- en: 'The `topic-terms.csv` file provides a list of topics in the document collection
    with the terms, respective topics, and their weights. For example, if you gave
    Amazon Comprehend two hypothetical documents, **learning to garden** and **investment
    strategies**, it might return the following to describe the two topics in the
    collection:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '`topic-terms.csv` 文件提供了文档集合中主题的列表，包括术语、相应的主题及其权重。例如，如果你向 Amazon Comprehend
    提供了两篇假设文档，**学习园艺**和**投资策略**，它可能会返回以下内容来描述集合中的两个主题：'
- en: '![Figure 3.3: Sample Topic Modeling output (topic-terms.csv) for two documents''
    input'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.3：两个文档输入的示例主题建模输出（topic-terms.csv）](img/B16061_03_03.jpg)'
- en: '](img/B16061_03_03.jpg)'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16061_03_03.jpg](img/B16061_03_03.jpg)'
- en: 'Figure 3.3: Sample Topic Modeling output (topic-terms.csv) for two documents''
    input'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.3：两个文档输入的示例主题建模输出（topic-terms.csv）
- en: 'The `doc-topics.csv` file provides a list of the documents provided for the
    Topic Modeling job, and the respective topics and their proportions in each document.
    Given two hypothetical documents, `learning_to_garden.txt` and `investment_strategies.txt,`
    you can expect the following output:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.4: Sample Topic Modeling output (doc-topics.csv) for two documents''
    input'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16061_03_04.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 3.4: Sample Topic Modeling output (doc-topics.csv) for two documents''
    input'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 3.01: Using Amazon Comprehend to Perform Topic Modeling on Two Documents
    with Known Topics'
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this exercise, we will use two documents (**Romeo and Juliet** and **War
    of the Worlds**) to better understand LDA. We will use Amazon Comprehend to discover
    the main topics in the two documents. Before proceeding to the exercise, just
    look at an overview of the data pipeline architecture. The text files are stored
    in S3, and then we direct Comprehend to look for the files in the input bucket.
    Comprehend analyzes the documents and puts the results back in S3 in the output
    bucket:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.5: Data pipeline architecture overview'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16061_03_05.jpg)'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 3.5: Data pipeline architecture overview'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: 'Complete the Topic Modeling of a known topic structure:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: 'First, you need to get to the S3 console. Please refer to *Chapter 1*, *An
    Introduction to AWS*, for account setup instructions. Go to [https://aws.amazon.com/](https://aws.amazon.com/)
    and click `My Account` followed by `AWS Management Console`. Click `Services`,
    and then search or select `S3` in a new browser tab. You will see the S3 console
    as shown in the following screenshot:![Figure 3.6: Amazon S3 console'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16061_03_06.jpg)'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.6: Amazon S3 console'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We need an input and output S3 bucket. Let''s create both. Now, click the `Create
    bucket` button to create a bucket:![Figure 3.7: Creating a bucket'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16061_03_07.jpg)'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.7: Creating a bucket'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'For the bucket name, enter a unique name that describes the function. Here,
    the name `aws-ml-input-for-topic-modeling` is used. Click the `Create` button:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The bucket names in AWS have to be unique. So, you might get an error saying,
    "Bucket name already exists." One easy way to get a unique name is to append the
    bucket name with today's date (plus time, if required); say, YYYYMMDDHHMM. While
    writing this chapter, we created a bucket, `aws-ml-input-for-topic-modeling-20200301`.
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Clicking `Create` in the following window uses all the default settings for
    properties and permissions, while clicking `Next` allows you to adjust these settings
    according to your needs.
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.8: Creating a bucket name input'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16061_03_08.jpg)'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.8: Creating a bucket name input'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Click `Next`, then `Next` again to go to `Configure options`, click `Next`
    once more to go to `Set permissions`, and finally click on `Create Bucket` in
    the `Review` tab:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now, click the bucket and then the `Create folder` button to create a folder:![Figure
    3.9: Creating a folder in S3 for Topic modeling input'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，点击桶，然后点击`创建文件夹`按钮来创建一个文件夹：![图3.9：在S3中为主题建模输入创建文件夹
- en: '](img/B16061_03_09.jpg)'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16061_03_09.jpg)'
- en: 'Figure 3.9: Creating a folder in S3 for Topic modeling input'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.9：在S3中为主题建模输入创建文件夹
- en: 'Now, type in `known_structure` as the folder name, and then click the `Save`
    button:![Figure 3.10: Saving the known_structure folder name'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，将文件夹名称输入为`known_structure`，然后点击`保存`按钮：![图3.10：保存`known_structure`文件夹名称
- en: '](img/B16061_03_10.jpg)'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16061_03_10.jpg)'
- en: 'Figure 3.10: Saving the known_structure folder name'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.10：保存`known_structure`文件夹名称
- en: 'After clicking the `Save` button, your folder will be generated. Now, click
    the `known_structure` folder:![Figure 3.11: The input bucket screen'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击`保存`按钮后，你的文件夹将被生成。现在，点击`known_structure`文件夹：![图3.11：输入桶屏幕
- en: '](img/B16061_03_11.jpg)'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16061_03_11.jpg)'
- en: 'Figure 3.11: The input bucket screen'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.11：输入桶屏幕
- en: 'Now, click the `Upload` button:![Figure 3.12: The Upload button'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，点击`上传`按钮：![图3.12：上传按钮
- en: '](img/B16061_03_12.jpg)'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16061_03_12.jpg)'
- en: 'Figure 3.12: The Upload button'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.12：上传按钮
- en: 'Now, you will be prompted to add files to the folder. Click `Add files`, or
    drag the files onto the screen:![Figure 3.13: The Add files button'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，你将被提示向文件夹中添加文件。点击`添加文件`，或将文件拖放到屏幕上：![图3.13：添加文件按钮
- en: '](img/B16061_03_13.jpg)'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16061_03_13.jpg)'
- en: 'Figure 3.13: The Add files button'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.13：添加文件按钮
- en: The files for this chapter are located in the `Chapter03` folder in the GitHub
    repository at [https://packt.live/3eba6rM](https://packt.live/3eba6rM). As we
    mentioned in *Chapter 1*, *An Introduction to AWS*, you should have downloaded
    the GitHub files to a local subdirectory.
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 本章的文件位于GitHub仓库的`Chapter03`文件夹中，网址为[https://packt.live/3eba6rM](https://packt.live/3eba6rM)。正如我们在*第一章*，*AWS简介*中提到的，你应该已经将GitHub文件下载到本地子目录中。
- en: 'By way of an example, we have downloaded the files to the `Documents/aws-book/The-Applied-AI-and-Natural-Language-Processing-with-AWS`
    directory. Navigate to `Upload` and select the following two text files from your
    local disk. As you may have guessed, the files for this exercise are located in
    the `Exercise3.01` subdirectory:'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过一个例子，我们已经将文件下载到`Documents/aws-book/The-Applied-AI-and-Natural-Language-Processing-with-AWS`目录。导航到`上传`，从你的本地磁盘选择以下两个文本文件。正如你可能猜到的，这个练习的文件位于`Exercise3.01`子目录中：
- en: 'Once the files have been selected, click on the `Open` button to upload the
    files:'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 文件选择完毕后，点击`打开`按钮上传文件：
- en: '![Figure 3.14: Selecting files to upload from the local directory'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图3.14：从本地目录选择要上传的文件'
- en: '](img/B16061_03_14.jpg)'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16061_03_14.jpg)'
- en: 'Figure 3.14: Selecting files to upload from the local directory'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.14：从本地目录选择要上传的文件
- en: 'The following figure shows the uploading of text files:'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下面的图显示了文本文件的上传过程：
- en: '![Figure 3.15: Uploading for the two known_structure text files'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图3.15：上传两个`known_structure`文本文件'
- en: '](img/B16061_03_15.jpg)'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16061_03_15.jpg)'
- en: 'Figure 3.15: Uploading for the two known_structure text files'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.15：上传两个`known_structure`文本文件
- en: 'Click `Next` in the `Set permissions` and `Set Properties` tabs. Select `Upload`
    in the `Review` tab:![Figure 3.16: Amazon S3 upload files'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`设置权限`和`设置属性`选项卡中点击`下一步`。在`审查`选项卡中选择`上传`：![图3.16：Amazon S3上传文件
- en: '](img/B16061_03_16.jpg)'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16061_03_16.jpg)'
- en: 'Figure 3.16: Amazon S3 upload files'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.16：Amazon S3上传文件
- en: 'Navigate to the `Amazon S3` home screen:![Figure 3.17: Amazon S3'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到`Amazon S3`主屏幕：![图3.17：Amazon S3
- en: '](img/B16061_03_17.jpg)'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16061_03_17.jpg)'
- en: 'Figure 3.17: Amazon S3'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.17：Amazon S3
- en: 'Next, create an output S3 bucket. Use the same S3 bucket creation process.
    To do so, click the `Create bucket` button:![Figure 3.18: Creating a bucket'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，创建一个输出S3桶。使用相同的S3桶创建过程。为此，点击`创建桶`按钮：![图3.18：创建桶
- en: '](img/B16061_03_18.jpg)'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16061_03_18.jpg)'
- en: 'Figure 3.18: Creating a bucket'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.18：创建桶
- en: 'Now, name the bucket and then click the `Create` button:![Figure 3.19: Creating
    bucket output for Topic Modeling'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，命名桶，然后点击`创建`按钮：![图3.19：为主题建模创建桶输出
- en: '](img/B16061_03_19.jpg)'
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16061_03_19.jpg)'
- en: 'Figure 3.19: Creating bucket output for Topic Modeling'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.19：为主题建模创建桶输出
- en: Click `Next` under `Configure Options`, `Next` under `Set permissions`, and
    `Create Bucket` in the `Review` window.
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`配置选项`下点击`下一步`，在`设置权限`下点击`下一步`，在`审查`窗口中点击`创建桶`。
- en: Now you have two buckets, one for input with two text files, and an empty output
    bucket. Let's now proceed to Amazon Comprehend.
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，你有了两个桶，一个用于输入，包含两个文本文件，另一个输出桶为空。现在让我们继续使用Amazon Comprehend。
- en: 'Navigate to Amazon Comprehend: [https://console.aws.amazon.com/comprehend/](https://console.aws.amazon.com/comprehend/).
    If you are presented with the following screen, click `Launch Amazon Comprehend`:![Figure
    3.20: The Amazon Comprehend home screen'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到Amazon Comprehend：[https://console.aws.amazon.com/comprehend/](https://console.aws.amazon.com/comprehend/).
    如果您看到以下屏幕，请点击`启动Amazon Comprehend`：![图3.20：Amazon Comprehend主页
- en: '](img/B16061_03_20.jpg)'
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16061_03_20.jpg)'
- en: 'Figure 3.20: The Amazon Comprehend home screen'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.20：Amazon Comprehend主页
- en: 'Now, click the first `Analysis jobs` option in the left-hand side toolbar (**not**
    the one under Amazon Comprehend Medical):![Figure 3.21: The Amazon Comprehend
    organization screen'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，在左侧工具栏中点击第一个`分析作业`选项（**不是**Amazon Comprehend Medical下的那个）：![图3.21：Amazon
    Comprehend组织屏幕
- en: '](img/B16061_03_21.jpg)'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16061_03_21.jpg)'
- en: 'Figure 3.21: The Amazon Comprehend organization screen'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.21：Amazon Comprehend组织屏幕
- en: 'Now, click the `Create job` button:![Figure 3.22: The Amazon Comprehend Create
    job button'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，点击`创建作业`按钮：![图3.22：Amazon Comprehend创建作业按钮
- en: '](img/B16061_03_22.jpg)'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16061_03_22.jpg)'
- en: 'Figure 3.22: The Amazon Comprehend Create job button'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.22：Amazon Comprehend创建作业按钮
- en: 'Enter `known_structure_topic_modeling_job` in the `Name` field:![Figure 3.23:
    Name of the Topic Modeling job'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`名称`字段中输入`known_structure_topic_modeling_job`：![图3.23：主题建模作业名称
- en: '](img/B16061_03_23.jpg)'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16061_03_23.jpg)'
- en: 'Figure 3.23: Name of the Topic Modeling job'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.23：主题建模作业名称
- en: 'Select `Topic Modeling` in the `Analysis type` drop-down box:![Figure 3.24:
    Selecting analysis type (Topic Modeling)'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`分析类型`下拉框中选择`主题建模`：![图3.24：选择分析类型（主题建模）
- en: '](img/B16061_03_24.jpg)'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16061_03_24.jpg)'
- en: 'Figure 3.24: Selecting analysis type (Topic Modeling)'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.24：选择分析类型（主题建模）
- en: 'Now, scroll down to the `Input data` tab and then click `Browse S3`:![Figure
    3.25: Clicking Search to locate the Topic Modeling input data source'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，滚动到`输入数据`选项卡，然后点击`浏览S3`：![图3.25：点击搜索以定位主题建模输入数据源
- en: '](img/B16061_03_25.jpg)'
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16061_03_25.jpg)'
- en: 'Figure 3.25: Clicking Search to locate the Topic Modeling input data source'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.25：点击搜索以定位主题建模输入数据源
- en: 'The list of S3 buckets will be displayed:![Figure 3.26: Selecting the input
    bucket'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将显示S3存储桶列表：![图3.26：选择输入存储桶
- en: '](img/B16061_03_26.jpg)'
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16061_03_26.jpg)'
- en: 'Figure 3.26: Selecting the input bucket'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.26：选择输入存储桶
- en: 'Select the input bucket (in my case, it is `aws-ml-input-for-topic-modeling-20200301`)
    and click on the bucket. Then, the folder will be displayed:![Figure 3.27: Selecting
    the input folder'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择输入存储桶（在我的情况下，它是`aws-ml-input-for-topic-modeling-20200301`），然后点击存储桶。然后，文件夹将显示：![图3.27：选择输入文件夹
- en: '](img/B16061_03_27.jpg)'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16061_03_27.jpg)'
- en: 'Figure 3.27: Selecting the input folder'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.27：选择输入文件夹
- en: 'Click the radio button next to `known_structure` and then click the `Choose`
    button, which will direct you to the following screen:![Figure 3.28: The Input
    data section with the S3 location filled in'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击`known_structure`旁边的单选按钮，然后点击`Choose`按钮，这将带您到以下屏幕：![图3.28：输入数据部分，已填写S3位置
- en: '](img/B16061_03_28.jpg)'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16061_03_28.jpg)'
- en: 'Figure 3.28: The Input data section with the S3 location filled in'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.28：输入数据部分，已填写S3位置
- en: 'Now, from the drop-down menu, select `One document per file`:![Figure 3.29:
    Selecting One document per file'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，从下拉菜单中选择`每个文件一个文档`：![图3.29：选择每个文件一个文档
- en: '](img/B16061_03_29.jpg)'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16061_03_29.jpg)'
- en: 'Figure 3.29: Selecting One document per file'
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.29：选择每个文件一个文档
- en: 'Now, enter `2` for the `Number of Topics` you need to have:![Figure 3.30: Entering
    2 for the number of topics to perform Topic Modeling'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，为所需的`主题数量`输入`2`：![图3.30：输入2以执行主题建模
- en: '](img/B16061_03_30.jpg)'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16061_03_30.jpg)'
- en: 'Figure 3.30: Entering 2 for the number of topics to perform Topic Modeling'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.30：输入2以执行主题建模
- en: 'Next, click `Browse S3` in the `Output data` tab:![Figure 3.31: Output data
    tab and the Browse S3 button for the Topic Modeling S3 output location'
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，在`输出数据`选项卡中点击`浏览S3`：![图3.31：输出数据选项卡和用于主题建模S3输出位置的浏览S3按钮
- en: '](img/B16061_03_31.jpg)'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16061_03_31.jpg)'
- en: 'Figure 3.31: Output data tab and the Browse S3 button for the Topic Modeling
    S3 output location'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.31：输出数据选项卡和用于主题建模S3输出位置的浏览S3按钮
- en: 'Select the output bucket (in our case, it is `aws-ml-output-for-topic-modeling-20200301)`
    and then click `Choose`:![Figure 3.32: Selecting the output S3 bucket'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择输出存储桶（在我们的情况下，它是`aws-ml-output-for-topic-modeling-20200301`），然后点击`Choose`：![图3.32：选择输出S3存储桶
- en: '](img/B16061_03_32.jpg)'
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16061_03_32.jpg)'
- en: 'Figure 3.32: Selecting the output S3 bucket'
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.32：选择输出S3存储桶
- en: 'Make sure that the `Output data` tab looks similar to the following screenshot:![Figure
    3.33: Output data tab with the output bucket name'
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保输出数据标签页看起来与以下截图类似：![图3.33：带有输出存储桶名称的输出数据标签页
- en: '](img/B16061_03_33.jpg)'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16061_03_33.jpg)'
- en: 'Figure 3.33: Output data tab with the output bucket name'
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.33：带有输出存储桶名称的输出数据标签页
- en: 'Scroll down to the `Access permissions` tab, and then select the option `Create
    an IAM role`:![Figure 3.34: Selecting Create an IAM role and providing permission
    to'
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 滚动到“访问权限”标签页，然后选择“创建IAM角色”选项：![图3.34：选择创建IAM角色并提供访问权限
- en: Input and Output S3 buckets
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输入和输出S3存储桶
- en: '](img/B16061_03_34.jpg)'
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16061_03_34.jpg)'
- en: 'Figure 3.34: Selecting Create an IAM role and providing permission to Input
    and Output S3 buckets'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.34：选择创建IAM角色并为输入和输出S3存储桶提供权限
- en: 'Check to make sure that `Input and Output S3 buckets` is listed under `Permissions
    to access`:'
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 确认“输入和输出S3存储桶”列在“访问权限”下：
- en: 'Enter `myTopicModelingRole` in the `Name suffix` field and then click the `Create
    job` button:![Figure 3.35: Clicking the Create job button'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在“名称后缀”字段中输入`myTopicModelingRole`，然后点击“创建作业”按钮：![图3.35：点击创建作业按钮
- en: '](img/B16061_03_35.jpg)'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16061_03_35.jpg)'
- en: 'Figure 3.35: Clicking the Create job button'
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.35：点击创建作业按钮
- en: 'Creating the job may take a few minutes and you might see a message "Propagating
    IAM role, please remain on the page." Once the creation is complete, you will
    be redirected to the Comprehend home screen as follows:![Figure 3.36: The Comprehend
    home screen'
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建作业可能需要几分钟，您可能会看到消息“传播IAM角色，请留在页面上。”一旦创建完成，您将被重定向到Comprehend主屏幕，如下所示：![图3.36：Comprehend主屏幕
- en: '](img/B16061_03_36.jpg)'
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16061_03_36.jpg)'
- en: 'Figure 3.36: The Comprehend home screen'
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.36：Comprehend主屏幕
- en: Note
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: Bear in mind that clicking `Create job` starts the job as well. There is no
    separate "start a job" button. Also, if you want to redo the job, you will have
    to use the `Copy` button.
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请记住，点击“创建作业”也会启动作业。没有单独的“启动作业”按钮。此外，如果您想重新做作业，您将不得不使用“复制”按钮。
- en: 'While the job is being processed, the status displayed will be `In Progress`:![Figure
    3.37: In progress status displayed'
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在作业处理过程中，显示的状态将是“进行中”：![图3.37：显示进行中状态
- en: '](img/B16061_03_37.jpg)'
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16061_03_37.jpg)'
- en: 'Figure 3.37: In progress status displayed'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.37：显示进行中状态
- en: 'On our account, it took around 4 minutes to complete the job. When the status
    changes to `Completed`, click the Topic Modeling job name:![Figure 3.38: Completed
    status displayed'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在我们的账户上，完成这项工作大约需要4分钟。当状态变为“完成”时，点击主题建模作业名称：![图3.38：显示完成状态
- en: '](img/B16061_03_38.jpg)'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16061_03_38.jpg)'
- en: 'Figure 3.38: Completed status displayed'
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.38：显示完成状态
- en: 'Now, scroll down to the `Output` section:![Figure 3.39: Topic Modeling output
    display home screen'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，滚动到“输出”部分：![图3.39：主题建模输出显示主屏幕
- en: '](img/B16061_03_39.jpg)'
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16061_03_39.jpg)'
- en: 'Figure 3.39: Topic Modeling output display home screen'
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.39：主题建模输出显示主屏幕
- en: 'Click the hyperlink under `Data location`:![Figure 3.40: Topic Modeling data
    output hyperlinked location'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击“数据位置”下的超链接：![图3.40：主题建模数据输出超链接位置
- en: '](img/B16061_03_40.jpg)'
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16061_03_40.jpg)'
- en: 'Figure 3.40: Topic Modeling data output hyperlinked location'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.40：主题建模数据输出超链接位置
- en: 'This will take you directly to the S3 bucket:'
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将直接带您到S3存储桶：
- en: '![Figure 3.41: Topic Modeling output file in S3'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图3.41：S3中的主题建模输出文件'
- en: '](img/B16061_03_41.jpg)'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16061_03_41.jpg)'
- en: 'Figure 3.41: Topic Modeling output file in S3'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.41：S3中的主题建模输出文件
- en: 'Click `Download` and save the file in your local disk. Usually, the `Downloads`
    folder is an ideal location:![Figure 3.42: Topic Modeling downloading the output
    file to the local disk'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击“下载”并将文件保存在您的本地磁盘上。通常，“下载”文件夹是一个理想的位置：![图3.42：将主题建模输出文件下载到本地磁盘
- en: '](img/B16061_03_42.jpg)'
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16061_03_42.jpg)'
- en: 'Figure 3.42: Topic Modeling downloading the output file to the local disk'
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.42：将主题建模输出文件下载到本地磁盘
- en: 'Extract `output.tar.gz` and usually, it will show up in a directory output:![Figure
    3.43: Output files from Topic Modeling'
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解压`output.tar.gz`，通常它将出现在output目录中：![图3.43：主题建模的输出文件
- en: '](img/B16061_03_43.jpg)'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16061_03_43.jpg)'
- en: 'Figure 3.43: Output files from Topic Modeling'
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.43：主题建模的输出文件
- en: 'Now examine the two files: `topic-terms.xlsx` and `doc-topics.xlsx`:'
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在检查两个文件：`topic-terms.xlsx`和`doc-topics.xlsx`：
- en: Note
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: Your `topic-terms.csv` and `doc-topics.csv` results should be the same as the
    following results. If your results are NOT the same, use the output files for
    the remainder of the chapter, which are located at *Chapter03/Exercise3.01/topic-terms.csv*
    [https://packt.live/3iHlH5y](https://packt.live/3iHlH5y) and *Chapter03/Exercise3.01/doc-topics.csv*
    [https://packt.live/2ZMTaTw](https://packt.live/2ZMTaTw).
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你的 `topic-terms.csv` 和 `doc-topics.csv` 结果应与以下结果相同。如果你的结果不同，请使用本章剩余部分提供的输出文件，这些文件位于
    *Chapter03/Exercise3.01/topic-terms.csv* [https://packt.live/3iHlH5y](https://packt.live/3iHlH5y)
    和 *Chapter03/Exercise3.01/doc-topics.csv* [https://packt.live/2ZMTaTw](https://packt.live/2ZMTaTw)。
- en: 'The following is the output generated. As we had indicated that we want to
    have topics, Comprehend has segregated the relevant words into two groups/topics
    as well as the weights. It doesn''t know what the topics are, but has inferred
    the similarity of the words to one of the two topics:'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下为生成的输出。正如我们之前所指示的，我们希望有主题，Comprehend 已经将相关词汇分成了两个组/主题以及权重。它不知道这些主题是什么，但已经推断出词汇与两个主题中的一个的相似性：
- en: '![Figure 3.44: topic-terms.csv result'
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 3.44：topic-terms.csv 结果'
- en: '](img/B16061_03_44.jpg)'
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16061_03_44.jpg)'
- en: 'Figure 3.44: topic-terms.csv result'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.44：topic-terms.csv 结果
- en: 'The `doc-topics.csv` shows the affinity of the documents to the topics. In
    this case, it is very deterministic, but if we have more topics, the proportion
    will show the strength of the topics in each of the documents:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '`doc-topics.csv` 显示文档与主题的亲和力。在这种情况下，它是非常确定的，但如果我们有更多主题，比例将显示每个文档中主题的强度：'
- en: '![Figure 3.45: doc-topics.csv results'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.45：doc-topics.csv 结果'
- en: '](img/B16061_03_45.jpg)'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16061_03_45.jpg)'
- en: 'Figure 3.45: doc-topics.csv results'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.45：doc-topics.csv 结果
- en: In this exercise, we used Amazon Comprehend to infer topics embedded in a set
    of documents. While this is easier to do with two documents; Amazon Comprehend
    is very effective when we have hundreds of documents with multiple documents and
    we want to perform process automation.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们使用了 Amazon Comprehend 来推断一组文档中嵌入的主题。虽然对于两个文档来说这更容易做到；当有数百个文档，且我们想要进行流程自动化时，Amazon
    Comprehend 非常有效。
- en: 'Exercise 3.02: Performing Known Structure Analysis Programmatically'
  id: totrans-207
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 3.02：以编程方式执行已知结构分析
- en: While it is easy to look at one or two outputs, when we want to scale and analyze
    hundreds of documents with different topics, we need to use Comprehend programmatically.
    That is what we will do in this exercise.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们查看一个或两个输出时，很容易；当我们想要扩展并分析具有不同主题的数百个文档时，我们需要使用 Comprehend 进行编程。这正是我们将在这个练习中做的。
- en: 'In this exercise, we will programmatically upload the CSV files (`doc-topics.csv`
    and `Topic-terms.csv`) to S3, merge the CSV files on the Topic column, and print
    the output to the console. The following are the steps for performing known structure
    analysis:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将以编程方式上传 CSV 文件（`doc-topics.csv` 和 `Topic-terms.csv`），在 S3 上合并主题列的
    CSV 文件，并将输出打印到控制台。以下是执行已知结构分析的步骤：
- en: Note
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'For this step, you will be using Jupyter Notebook. You may either follow along
    with the exercise and type in the code or obtain it from the source code folder,
    `local_csv_to_s3_for_analysis.ipynb`, and paste it into the editor. The source
    code is available on GitHub in the following repository: [https://packt.live/2BOqjWT](https://packt.live/2BOqjWT).
    As explained in *Chapter 1*, *An Introduction to AWS*, you should have downloaded
    the repository to your local disk.'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这一步，你将使用 Jupyter Notebook。你可以跟随练习并输入代码，或者从源代码文件夹 `local_csv_to_s3_for_analysis.ipynb`
    中获取它，并将其粘贴到编辑器中。源代码可在以下 GitHub 仓库中找到：[https://packt.live/2BOqjWT](https://packt.live/2BOqjWT)。正如
    *第 1 章* 中所解释的，*AWS 简介*，你应该已经将仓库下载到本地磁盘。
- en: 'First, we will import `boto3` using the following command:'
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们将使用以下命令导入 `boto3`：
- en: '[PRE0]'
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Next, we will import `pandas` using the following command:'
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将使用以下命令导入 `pandas`：
- en: '[PRE1]'
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now, we will create the S3 client object using the following command:'
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将使用以下命令创建 S3 客户端对象：
- en: '[PRE2]'
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Next, we will create a variable with a unique bucket name. Here, the selected
    bucket name is `known-tm-analysis`, but you will need to create a unique name:'
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将创建一个具有唯一存储桶名称的变量。在这里，选定的存储桶名称是 `known-tm-analysis`，但你需要创建一个唯一的名称：
- en: '[PRE3]'
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Next, create a new bucket:'
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，创建一个新的存储桶：
- en: '[PRE4]'
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Create a list of the CSV filenames to import:'
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建要导入的 CSV 文件名列表：
- en: '[PRE5]'
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Note
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: Ensure that the two CSV files (highlighted) in the aforementioned step are stored
    in the same location where you're running the Jupyter Notebook code. An alternative
    is to specify the exact path as it exists on your local system.
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 确保上述步骤中提到的两个CSV文件（突出显示）存储在与您运行Jupyter Notebook代码相同的同一位置。另一种选择是指定在您的本地系统上存在的确切路径。
- en: 'Now, iterate on each file to upload to S3 using the following line of code:'
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用以下代码行迭代每个文件以上传到S3：
- en: '[PRE6]'
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Note
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: Do not execute *steps 7* and *8* yet. We will show the code for the entire `for`
    block in *step 9*.
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 还不要执行*步骤7*和*步骤8*。我们将在*步骤9*中展示整个`for`块的代码。
- en: 'Next, check whether the filename is `doc-topics.csv`: and get the `doc-topics.csv`
    file object and assign it to the `obj` variable.'
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，检查文件名是否为`doc-topics.csv`：并获取`doc-topics.csv`文件对象，将其分配给`obj`变量。
- en: '[PRE7]'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Next, read the `csv` object and assign it to the `doc_topics` variable. You
    can see the entire code block, including steps *7* and *8* below:'
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，读取`csv`对象并将其分配给`doc_topics`变量。您可以看到包括以下*步骤7*和*步骤8*在内的整个代码块：
- en: '[PRE8]'
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Now, merge the files on the Topic column to obtain the most common terms per
    document using the following command:'
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用以下命令将主题列上的文件合并，以获取每份文档中最常见的术语：
- en: '[PRE9]'
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Next, execute the notebook cells using the *Shift* + *Enter* keys:'
  id: totrans-236
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，使用*Shift* + *Enter*键执行笔记本单元格：
- en: 'The console output is a merged DataFrame that provides the docnames with their
    respective terms and the term''s weights (refer to the following):![Figure 3.46:
    Output from the s3.create_bucket call'
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 控制台输出是一个合并的DataFrame，它提供了具有相应术语的docnames以及术语的权重（参见图以下）：![图3.46：s3.create_bucket调用的输出
- en: '](img/B16061_03_46.jpg)'
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16061_03_46.jpg)'
- en: 'Figure 3.46: Output from the s3.create_bucket call'
  id: totrans-239
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.46：s3.create_bucket调用的输出
- en: '![Figure 3.47: known_structure Topic Modeling merged results'
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图3.47：已知的结构主题建模合并结果'
- en: '](img/B16061_03_47.jpg)'
  id: totrans-241
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16061_03_47.jpg)'
- en: 'Figure 3.47: known_structure Topic Modeling merged results'
  id: totrans-242
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.47：已知的结构主题建模合并结果
- en: 'To verify the CSV files, navigate to S3 (reload the page if the new bucket
    does not appear), and the new bucket will have been created in S3\. Click on the
    bucket to verify a successful import:![Figure 3.48: known-tm-analysis S3 bucket'
  id: totrans-243
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了验证CSV文件，导航到S3（如果新存储桶没有出现，请重新加载页面），新的存储桶已在S3中创建。点击存储桶以验证成功导入：![图3.48：已知的tm-analysis
    S3存储桶
- en: '](img/B16061_03_48.jpg)'
  id: totrans-244
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16061_03_48.jpg)'
- en: 'Figure 3.48: known-tm-analysis S3 bucket'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.48：已知的tm-analysis S3存储桶
- en: 'There will be two CSV files in the bucket – `doc-topics.csv` and `topic-terms.csv`:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 存储桶中将有两个CSV文件 - `doc-topics.csv`和`topic-terms.csv`：
- en: '![Figure 3.49: Topic Modeling results uploaded to S3'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.49：上传到S3的主题建模结果'
- en: '](img/B16061_03_49.jpg)'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16061_03_49.jpg)'
- en: 'Figure 3.49: Topic Modeling results uploaded to S3'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.49：上传到S3的主题建模结果
- en: In this exercise, we learned how to use Comprehend programmatically. We programmatically
    uploaded two CSV files to S3, merged them on a column, and printed the output
    to the console.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们学习了如何使用Comprehend进行编程。我们编程上传了两个CSV文件到S3，在列上合并它们，并将输出打印到控制台。
- en: 'Activity 3.01: Performing Topic Modeling on a Set of Documents with Unknown
    Topics'
  id: totrans-251
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动3.01：对一组未知主题的文档执行主题建模
- en: In this activity, we will perform Topic Modeling on a set of documents with
    unknown topics. Suppose your employer wants you to build a data pipeline to analyze
    negative movie reviews that are in individual text files with a unique ID filename.
    Thus, you need to perform Topic Modeling to determine which files represent the
    respective topics. Overall, negative reviews represent a loss to the company,
    so they are prioritizing negative reviews over positive reviews. The company's
    end goal is to incorporate the data into a feedback chatbot application. To ensure
    that this happens correctly, you need a file that contains negative comments.
    The expected outcome for this activity will be the Topic Modeling results from
    the negative movie review files.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个活动中，我们将对一组未知主题的文档执行主题建模。假设您的雇主希望您构建一个数据管道来分析存储在具有唯一ID文件名的单个文本文件中的负面电影评论。因此，您需要执行主题建模以确定哪些文件代表相应的主题。总的来说，负面评论对公司来说是一种损失，所以他们优先考虑负面评论而不是正面评论。公司的最终目标是将这些数据整合到反馈聊天机器人应用程序中。为了确保这一点，您需要一个包含负面评论的文件。这个活动的预期结果将是负面电影评论文件的主题建模结果。
- en: '**Performing Topic Modeling:**'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: '**执行主题建模：**'
- en: 'Navigate to the following link (or to your local directory where you have downloaded
    the GitHub files) to obtain the text data file that contains negative review comments:
    [https://packt.live/38Nw4jT](https://packt.live/38Nw4jT).'
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到以下链接（或您已下载GitHub文件的本地目录）以获取包含负面评论的文本数据文件：[https://packt.live/38Nw4jT](https://packt.live/38Nw4jT)。
- en: Create a bucket for Topic Modeling with a unique name.
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用唯一名称为主题建模创建一个存储桶。
- en: Create a folder for Topic Modeling.
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为主题建模创建一个文件夹。
- en: Import the dependencies of the Python library, such as `os` and `boto3`.
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入Python库的依赖项，例如`os`和`boto3`。
- en: Mention your unique bucket name.
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提及您的唯一存储桶名称。
- en: Gather all of the working directories of the local path and make them into text files.
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 收集所有本地路径的工作目录并将它们转换为文本文件。
- en: Create a list for all of the text files.
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为所有文本文件创建一个列表。
- en: Iterate the files and upload them to S3.
  id: totrans-261
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 遍历文件并将它们上传到S3。
- en: Create a job in Organization using Amazon Comprehend.
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用Amazon Comprehend在组织中创建一个作业。
- en: As per requirements, choose the input data. This may be **My document** or **Example
    document**.
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据要求选择输入数据。这可能是指**我的文档**或**示例文档**。
- en: Choose the file from the data source.
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从数据源中选择文件。
- en: Apply the input format.
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 应用输入格式。
- en: Provide the number of topics to perform the modeling.
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提供要执行建模的主题数量。
- en: Choose an IAM role and create a job.
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择一个IAM角色并创建一个作业。
- en: Download the output file and extract the file.
  id: totrans-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载输出文件并提取文件。
- en: The generated output will include the two CSV files.
  id: totrans-269
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成的输出将包括两个CSV文件。
- en: '**Analysis of Unknown Topics:**'
  id: totrans-270
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**未知主题分析：**'
- en: Import dependences of the Python library, such as `boto3` and `pandas`.
  id: totrans-271
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入Python库的依赖项，例如`boto3`和`pandas`。
- en: Create an S3 client.
  id: totrans-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个S3客户端。
- en: Create a new bucket with a unique name.
  id: totrans-273
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用唯一名称创建一个新的存储桶。
- en: Create a list of CSV filenames to import.
  id: totrans-274
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个CSV文件名列表以导入。
- en: Check the filename and assign it to the **obj** variable.
  id: totrans-275
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查文件名并将其分配给**obj**变量。
- en: Read the **obj** variable.
  id: totrans-276
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 读取**obj**变量。
- en: Merge the files on the Topic column.
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 合并主题列上的文件。
- en: Print the merged files to the console.
  id: totrans-278
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将合并的文件打印到控制台。
- en: This is a long activity. Yet, you were able to manage 1,000 files, upload them
    to S3, perform Topic Modeling using Amazon Comprehend, and then merge the results
    into a table that had more than 40,000 rows. In real-world situations, you will
    be handling thousands of documents, not just one or two. That is the reason we
    did this activity using Jupyter Notebook and Python.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个漫长的活动。然而，你能够管理1,000个文件，将它们上传到S3，使用Amazon Comprehend进行主题建模，然后将结果合并到一个包含超过40,000行的表中。在现实世界的情况下，你将处理数千份文档，而不仅仅是几份。这就是我们为什么使用Jupyter
    Notebook和Python来完成这个活动的原因。
- en: However, this is only the first step in a multi-step automation process — an
    important and essential step of inferencing on the unstructured documents. While
    Comprehend analyzed the documents and gave us a list of topics, it is still our
    job to figure out what to do with them.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这只是一个多步骤自动化过程的第一步——对非结构化文档进行推理的重要且基本步骤。虽然Comprehend分析了文档并给出了主题列表，但确定如何处理这些主题仍然是我们的工作。
- en: Note
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity can be found on page 291.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 该活动的解决方案可以在第291页找到。
- en: Summary
  id: totrans-283
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we learned about analyzing Topic Modeling results from AWS
    Comprehend. You are now able to incorporate S3 to store data and use it to perform
    analysis. Also, we learned how to analyze documents where we know the topics before
    performing Topic Modeling, as well as documents where the topic is unknown. We
    know that the latter requires additional analysis to determine the relevant topics.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了如何分析AWS Comprehend的主题建模结果。你现在能够将S3用于存储数据并用于分析。我们还学习了如何在执行主题建模之前分析已知主题的文档以及主题未知文档的方法。我们知道后者需要额外的分析来确定相关主题。
- en: We did not build the downstream systems that analyze the topic lists and then
    route the document appropriately. For example, you might have a mapping of the
    topics to a SharePoint folder for knowledge management or a workflow to route
    the files via email to appropriate persons depending on the topics detected. While
    the broader topic of **Robotic Process Automation** (**RPA**) is beyond the scope
    of this book, you have learned how to use Amazon Comprehend to implement the Topic
    and Theme detection steps for process automation.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 我们没有构建分析主题列表并适当路由文档的下游系统。例如，你可能有一个将主题映射到用于知识管理的SharePoint文件夹的映射，或者一个根据检测到的主题通过电子邮件将文件路由到适当人员的流程。虽然更广泛的**机器人流程自动化**（RPA）主题超出了本书的范围，但你已经学会了如何使用Amazon
    Comprehend来实现流程自动化的主题和主题检测步骤。
- en: Another application of what you learned in this chapter is document clustering
    for knowledge management. In this case, we would restrict the number of topics
    to 10 and then segregate the documents based on their major topics. For example,
    if these documents were news articles, this process would divide the articles
    into 10 subjects, which are easier to handle in downstream systems such as a new
    recommendation engine.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 本章所学知识的另一个应用是用于知识管理的文档聚类。在这种情况下，我们将主题数量限制为10个，然后根据主要主题对文档进行分类。例如，如果这些文档是新闻文章，这个过程将文章分为10个主题，这有助于在下游系统（如新的推荐引擎）中处理。
- en: As you can see, Topic Modeling can be applied in a variety of applications and
    systems. Now you have the skills required to perform Topic Modeling using Amazon
    Comprehend.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，主题建模可以应用于各种应用和系统。现在你已经拥有了使用Amazon Comprehend进行主题建模所需的技能。
- en: In the next chapter, we will dive into the concept of chatbots and their use
    of natural language processing.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将深入探讨聊天机器人的概念及其在自然语言处理中的应用。
