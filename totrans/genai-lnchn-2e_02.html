<html><head></head><body>
<div aria-label="1" epub:type="pagebreak" id="page1-3" role="doc-pagebreak"/>
<div id="_idContainer021">
<h1 class="chapterNumber"><a id="_idTextAnchor001"/><span class="koboSpan" id="kobo.1.1">1</span></h1>
<h1 class="chapterTitle" id="_idParaDest-15"><a id="_idTextAnchor002"/><span class="koboSpan" id="kobo.2.1">The Rise of Generative AI: From Language Models to Agents</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.3.1">The gap between experimental and production-ready agents is stark. </span><span class="koboSpan" id="kobo.3.2">According to LangChain’s State of Agents report, performance quality is the #1 concern among 51% of companies using agents, yet only 39.8% have implemented proper evaluation systems. </span><span class="koboSpan" id="kobo.3.3">Our book bridges this gap on two fronts: first, by demonstrating how LangChain and LangSmith provide robust testing and observability solutions; second, by showing how LangGraph’s state management enables complex, reliable multi-agent systems. </span><span class="koboSpan" id="kobo.3.4">You’ll find production-tested code patterns that leverage each tool’s strengths for enterprise-scale implementation and extend basic RAG into robust knowledge systems.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.4.1">LangChain accelerates time-to-market with readily available building blocks, unified vendor APIs, and detailed tutorials. </span><span class="koboSpan" id="kobo.4.2">Furthermore, LangChain and LangSmith debugging and tracing functionalities simplify the analysis of complex agent behavior. </span><span class="koboSpan" id="kobo.4.3">Finally, LangGraph has excelled in executing its philosophy behind agentic AI – it allows a developer to give a </span><strong class="keyWord"><span class="koboSpan" id="kobo.5.1">large language model</span></strong><span class="koboSpan" id="kobo.6.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.7.1">LLM</span></strong><span class="koboSpan" id="kobo.8.1">) partial</span><a id="_idIndexMarker000"/><span class="koboSpan" id="kobo.9.1"> control flow over the workflow (and to manage the level of how much control an LLM should have), while still making agentic workflows reliable and well-performant.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.10.1">In this chapter, we’ll explore how LLMs have evolved into the foundation for agentic AI systems and how frameworks like LangChain and LangGraph transform these models into production-ready applications. </span><span class="koboSpan" id="kobo.10.2">We’ll also examine the modern LLM landscape, understand the limitations of raw LLMs, and introduce the core concepts of agentic applications that form the basis for the hands-on development we’ll tackle throughout this book.</span></p>
<div aria-label="2" epub:type="pagebreak" id="page2-3" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.11.1">In a nutshell, the following topics will be covered in this book:</span></p>
<ul>
<li class="b lletList"><span class="koboSpan" id="kobo.12.1">The modern LLM landscape</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.13.1">From models to agentic applications</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.14.1">Introducing LangChain</span><a id="_idTextAnchor003"/></li>
</ul>
<h1 class="heading-1" id="_idParaDest-16"><a id="_idTextAnchor004"/><span class="koboSpan" id="kobo.15.1">The modern LLM landscape</span></h1>
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.16.1">Artificial intelligence</span></strong><span class="koboSpan" id="kobo.17.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.18.1">AI</span></strong><span class="koboSpan" id="kobo.19.1">) has</span><a id="_idIndexMarker001"/><span class="koboSpan" id="kobo.20.1"> long been a subject of fascination </span><a id="_idIndexMarker002"/><span class="koboSpan" id="kobo.21.1">and research, but recent advancements in generative AI have propelled it into mainstream adoption. </span><span class="koboSpan" id="kobo.21.2">Unlike traditional AI systems that classify data or make predictions, generative AI can create new content—text, images, code, and more—by leveraging vast amounts of training data.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.22.1">The generative AI revolution was catalyzed by the 2017 introduction of the transformer architecture, which enabled models to process text with unprecedented understanding of context and relationships. </span><span class="koboSpan" id="kobo.22.2">As researchers scaled these models from millions to billions of parameters, they discovered something remarkable: larger models didn’t just perform incrementally better—they exhibited entirely new emergent capabilities like few-shot learning, complex reasoning, and creative generation that weren’t explicitly programmed. </span><span class="koboSpan" id="kobo.22.3">Eventually, the release of ChatGPT in 2022 marked a turning point, demonstrating these capabilities to the public and sparking widespread adoption.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.23.1">The landscape shifted again with the open-source revolution led by models like Llama and Mistral, democratizing access to powerful AI beyond the major tech companies. </span><span class="koboSpan" id="kobo.23.2">However, these advanced capabilities came with significant limitations—models couldn’t reliably use tools, reason through complex problems, or maintain context across interactions. </span><span class="koboSpan" id="kobo.23.3">This gap between raw model power and practical utility created the need for specialized frameworks like LangChain that transform these models from impressive text generators into functional, production-ready agents capable of solving real-world problems.</span></p>
<div>
<div class="note" id="_idContainer012">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.24.1">Key terminologies</span></strong></p>
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.25.1">Tools</span></strong><span class="koboSpan" id="kobo.26.1">: External</span><a id="_idIndexMarker003"/><span class="koboSpan" id="kobo.27.1"> utilities or functions that AI models can use to interact with the world. </span><span class="koboSpan" id="kobo.27.2">Tools allow agents to perform actions like searching the web, calculating values, or accessing databases to overcome LLMs’ inherent limitations.</span></p>
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.28.1">Memory</span></strong><span class="koboSpan" id="kobo.29.1">: Systems that</span><a id="_idIndexMarker004"/><span class="koboSpan" id="kobo.30.1"> allow AI applications to store and retrieve information across interactions. </span><span class="koboSpan" id="kobo.30.2">Memory enables contextual awareness in conversations and complex workflows by tracking previous inputs, outputs, and important information.</span></p>
</div>
</div>
<div>
<div class="note" id="_idContainer013">
<div aria-label="3" epub:type="pagebreak" id="page3-3" role="doc-pagebreak"/>
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.31.1">Reinforcement learning from human feedback </span></strong><span class="koboSpan" id="kobo.32.1">(</span><strong class="keyWord"><span class="koboSpan" id="kobo.33.1">RLHF</span></strong><span class="koboSpan" id="kobo.34.1">): A training technique where AI models learn from direct </span><a id="_idIndexMarker005"/><span class="koboSpan" id="kobo.35.1">human feedback, optimizing their performance to align with human preferences. </span><span class="koboSpan" id="kobo.35.2">RLHF helps create models that are more helpful, safe, and aligned with human values.</span></p>
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.36.1">Agents</span></strong><span class="koboSpan" id="kobo.37.1">: AI systems</span><a id="_idIndexMarker006"/><span class="koboSpan" id="kobo.38.1"> that can perceive their environment, make decisions, and take actions to accomplish goals. </span><span class="koboSpan" id="kobo.38.2">In LangChain, agents use LLMs to interpret tasks, choose appropriate tools, and execute multi-step processes with minimal human intervention.</span></p>
</div>
</div>
<table class="No-Table-Style _idGenTablePara-1" id="table001-2">
<colgroup>
<col/>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><strong class="keyWord"><a id="_idTextAnchor005"/><span class="koboSpan" id="kobo.39.1">Yea</span></strong><strong class="keyWord"><span class="koboSpan" id="kobo.40.1">r</span></strong></p>
</td>
<td class="No-Table-Style">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.41.1">Development</span></strong></p>
</td>
<td class="No-Table-Style">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.42.1">Key Features</span></strong></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.43.1">1990s</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.44.1">IBM Alignment Models</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.45.1">Statistical machine translation</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.46.1">2000s</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.47.1">Web-scale datasets</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.48.1">Large-scale statistical models</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.49.1">2009</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.50.1">Statistical models dominate</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.51.1">Large-scale text ingestion</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.52.1">2012</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.53.1">Deep learning gains traction</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.54.1">Neural networks outperform statistical models</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.55.1">2016</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.56.1">Neural Machine Translation (NMT)</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.57.1">Seq2seq deep LSTMs replace statistical methods</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.58.1">2017</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.59.1">Transformer architecture</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.60.1">Self-attention revolutionizes NLP</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.61.1">2018</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.62.1">BERT and GPT-1</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.63.1">Transformer-based language understanding and generation</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.64.1">2019</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.65.1">GPT-2</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.66.1">Large-scale text generation, public awareness increases</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.67.1">2020</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.68.1">GPT-3</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.69.1">API-based access, state-of-the-art performance</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.70.1">2022</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.71.1">ChatGPT</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.72.1">Mainstream adoption of LLMs</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.73.1">2023</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.74.1">Large Multimodal Models (LMMs)</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.75.1">AI models process text, images, and audio</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<div aria-label="4" epub:type="pagebreak" id="page4-3" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.76.1">2024</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.77.1">OpenAI o1</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.78.1">Stronger reasoning capabilities</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.79.1">2025</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.80.1">DeepSeek R1</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.81.1">Open-weight, large-scale AI model</span></p>
</td>
</tr>
</tbody>
</table>
<p class="packt_figref"><a id="_idTextAnchor006"/><span class="koboSpan" id="kobo.82.1">Table 1.1: A timeline of major developments in language models</span><a id="_idTextAnchor007"/></p>
<p class="normal"><span class="koboSpan" id="kobo.83.1">The field of LLMs </span><a id="_idIndexMarker007"/><span class="koboSpan" id="kobo.84.1">is rapidly evolving, with multiple models competing in terms of performance, capabilities, and accessibility. </span><span class="koboSpan" id="kobo.84.2">Each provider brings distinct advantages, from OpenAI’s advanced general-purpose AI to Mistral’s open-weight, high-efficiency models. </span><span class="koboSpan" id="kobo.84.3">Understanding the differences between these models helps practitioners make informed decisions when integrating LLMs into their applications.</span><a id="_idTextAnchor008"/></p>
<h2 class="heading-2" id="_idParaDest-17"><a id="_idTextAnchor009"/><span class="koboSpan" id="kobo.85.1">Model comparison</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.86.1">The following</span><a id="_idIndexMarker008"/><span class="koboSpan" id="kobo.87.1"> points outline key factors to consider when comparing different LLMs, focusing on their accessibility, size, capabilities, and specialization:</span></p>
<ul>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.88.1">Open-source vs. </span><span class="koboSpan" id="kobo.88.2">closed-source models</span></strong><span class="koboSpan" id="kobo.89.1">: Open-source models like Mistral and LLaMA provide transparency and the ability to run locally, while closed-source models like GPT-4 and Claude are accessible through APIs. </span><span class="koboSpan" id="kobo.89.2">Open-source LLMs can be downloaded and modified, enabling developers and researchers to investigate and build upon their architectures, though specific usage terms may apply.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.90.1">Size and capabilities</span></strong><span class="koboSpan" id="kobo.91.1">: Larger models generally offer better performance but require more computational resources. </span><span class="koboSpan" id="kobo.91.2">This makes smaller models great for use on devices with limited computing power or memory, and can be significantly cheaper to use. </span><strong class="keyWord"><span class="koboSpan" id="kobo.92.1">Small language models</span></strong><span class="koboSpan" id="kobo.93.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.94.1">SLMs</span></strong><span class="koboSpan" id="kobo.95.1">) have</span><a id="_idIndexMarker009"/><span class="koboSpan" id="kobo.96.1"> a relatively small number of parameters, typically using millions to a few billion parameters, as opposed to LLMs, which can have hundreds of billions or even trillions of parameters.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.97.1">Specialized models</span></strong><span class="koboSpan" id="kobo.98.1">: Some LLMs are optimized for specific tasks, such as code generation (for example, Codex) or mathematical reasoning (e.g., Minerva).</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.99.1">The increase in the scale of language models has been a major driving force behind their impressive performance gains. </span><span class="koboSpan" id="kobo.99.2">However, recently there has been a shift in architecture and training methods that has led to better parameter efficiency in terms of performance.</span></p>
<div>
<div class="note" id="_idContainer014">
<div aria-label="5" epub:type="pagebreak" id="page5-3" role="doc-pagebreak"/>
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.100.1">Model scaling laws</span></strong></p>
<p class="normal"><span class="koboSpan" id="kobo.101.1">Empirically derived scaling laws predict the performance of LLMs based on the given training budget, dataset size, and the number of parameters. </span><span class="koboSpan" id="kobo.101.2">If true, this means that highly powerful systems will be concentrated in the hands of Big Tech, however, we have seen a significant shift over recent months.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.102.1">The </span><strong class="keyWord"><span class="koboSpan" id="kobo.103.1">KM scaling law</span></strong><span class="koboSpan" id="kobo.104.1">, proposed </span><a id="_idIndexMarker010"/><span class="koboSpan" id="kobo.105.1">by Kaplan et al., derived through empirical </span><a id="_idIndexMarker011"/><span class="koboSpan" id="kobo.106.1">analysis and fitting of model performance with varied data sizes, model sizes, and training compute, presents power-law relationships, indicating a strong codependence between model performance and factors such as model size, dataset size, and training compute.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.107.1">The </span><strong class="keyWord"><span class="koboSpan" id="kobo.108.1">Chinchilla scaling law</span></strong><span class="koboSpan" id="kobo.109.1">, proposed </span><a id="_idIndexMarker012"/><span class="koboSpan" id="kobo.110.1">by the Google DeepMind team, involved</span><a id="_idIndexMarker013"/><span class="koboSpan" id="kobo.111.1"> experiments with a wider range of model sizes and data sizes. </span><span class="koboSpan" id="kobo.111.2">It suggests an optimal allocation of compute budget to model size and data size, which can be determined by optimizing a specific loss function under a constraint.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.112.1">However, future progress may depend more on model architecture, data cleansing, and model algorithmic innovation rather than sheer size. </span><span class="koboSpan" id="kobo.112.2">For example, models such as phi, first presented in </span><em class="italic"><span class="koboSpan" id="kobo.113.1">Textbooks Are All You Need</span></em><span class="koboSpan" id="kobo.114.1"> (2023, Gunasekar et al.), with about 1 billion parameters, showed that models can – despite a smaller scale – achieve high accuracy on evaluation benchmarks. </span><span class="koboSpan" id="kobo.114.2">The authors suggest that improving data quality can dramatically change the shape of scaling laws.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.115.1">Further, there is a body of work on simplified model architectures, which have substantially fewer parameters and only modestly drop accuracy (for example, </span><em class="italic"><span class="koboSpan" id="kobo.116.1">One Wide Feedforward is All You Need</span></em><span class="koboSpan" id="kobo.117.1">, Pessoa Pires et al., 2023). </span><span class="koboSpan" id="kobo.117.2">Additionally, techniques such as fine-tuning, quantization, distillation, and prompting techniques can enable smaller models to leverage the capabilities of large foundations without replicating their costs. </span><span class="koboSpan" id="kobo.117.3">To compensate for model limitations, tools like search engines and calculators have been incorporated into agents, and multi-step reasoning strategies, plugins, and extensions may be increasingly used to expand capabilities.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.118.1">The future could see the co-existence of massive, general models with smaller and more accessible models that provide faster and cheaper training, maintenance, and inference.</span></p>
</div>
</div>
<div aria-label="6" epub:type="pagebreak" id="page6-3" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.119.1">Let’s now </span><a id="_idIndexMarker014"/><span class="koboSpan" id="kobo.120.1">discuss a comparative overview of various LLMs, highlighting their key characteristics and differentiating factors. </span><span class="koboSpan" id="kobo.120.2">We’ll delve into aspects such as open-source vs. </span><span class="koboSpan" id="kobo.120.3">closed-source models, model size and capabilities, and specialized models. </span><span class="koboSpan" id="kobo.120.4">By understanding these distinctions, you can select the most suitable LLM for your specific needs and applications.</span></p>
<h2 class="heading-2" id="_idParaDest-18"><a id="_idTextAnchor010"/><span class="koboSpan" id="kobo.121.1">LLM provider landscape</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.122.1">You can</span><a id="_idIndexMarker015"/><span class="koboSpan" id="kobo.123.1"> access LLMs from major providers like OpenAI, Google, and Anthropic, along with a growing number of others, through their websites or APIs. </span><span class="koboSpan" id="kobo.123.2">As the demand for LLMs grows, numerous providers have entered the space, each offering models with unique capabilities and trade-offs. </span><span class="koboSpan" id="kobo.123.3">Developers need to understand the various access options available for integrating these powerful models into their applications. </span><span class="koboSpan" id="kobo.123.4">The choice of provider will significantly impact development experience, performance characteristics, and operational costs.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.124.1">The table below</span><a id="_idIndexMarker016"/><span class="koboSpan" id="kobo.125.1"> provides a comparative overview of leading LLM providers and examples of the models they offer:</span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table002">
<colgroup>
<col/>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.126.1">Provider</span></strong></p>
</td>
<td class="No-Table-Style">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.127.1">Notable models</span></strong></p>
</td>
<td class="No-Table-Style">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.128.1">Key features and strengths</span></strong></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.129.1">OpenAI</span></strong></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.130.1">GPT-4o, GPT-4.5; o1; o3-mini</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.131.1">Strong general performance, proprietary models, advanced reasoning; multimodal reasoning across text, audio, vision, and video in real time</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.132.1">Anthropic</span></strong></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.133.1">Claude 3.7 Sonnet; Claude 3.5 Haiku</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.134.1">Toggle between real-time responses and extended “thinking” phases; outperforms OpenAI’s o1 in coding benchmarks</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.135.1">Google</span></strong></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.136.1">Gemini 2.5, 2.0 (flash and pro), Gemini 1.5</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.137.1">Low latency and costs, large context window (up to 2M tokens), multimodal inputs and outputs, reasoning capabilities</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.138.1">Cohere</span></strong></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.139.1">Command R, Command R Plus</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.140.1">Retrieval-augmented generation, enterprise AI solutions</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.141.1">Mistral AI</span></strong></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.142.1">Mistral Large; Mistral 7B</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.143.1">Open weights, efficient inference, multilingual support</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.144.1">AWS</span></strong></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.145.1">Titan</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.146.1">Enterprise-scale AI models, optimized for the AWS cloud</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<div aria-label="7" epub:type="pagebreak" id="page7-2" role="doc-pagebreak"/>
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.147.1">DeepSeek</span></strong></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.148.1">R1</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.149.1">Maths-first: solves Olympiad-level problems; cost-effective, optimized for multilingual and programming tasks</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.150.1">Together AI</span></strong></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.151.1">Infrastructure for running open models</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.152.1">Competitive pricing; growing marketplace of models</span></p>
</td>
</tr>
</tbody>
</table>
<p class="packt_figref"><span class="koboSpan" id="kobo.153.1">Table 1.2: Comparative overview of major LLM providers and their flagship models for LangChain implementation</span></p>
<p class="normal"><span class="koboSpan" id="kobo.154.1">Other organizations develop LLMs but do not necessarily provide them through </span><strong class="keyWord"><span class="koboSpan" id="kobo.155.1">application programming interfaces</span></strong><span class="koboSpan" id="kobo.156.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.157.1">APIs</span></strong><span class="koboSpan" id="kobo.158.1">) to </span><a id="_idIndexMarker017"/><span class="koboSpan" id="kobo.159.1">developers. </span><span class="koboSpan" id="kobo.159.2">For example, Meta AI develops the very influential Llama model series, which has strong reasoning, code-generation capabilities, and is released under an open-source license.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.160.1">There is a whole</span><a id="_idIndexMarker018"/><span class="koboSpan" id="kobo.161.1"> zoo of open-source models that you can access through Hugging Face or through other providers. </span><span class="koboSpan" id="kobo.161.2">You can even download these open-source models, fine-tune them, or fully train them. </span><span class="koboSpan" id="kobo.161.3">We’ll try this out practically starting in </span><a href="E_Chapter_2.xhtml#_idTextAnchor044"><em class="italic"><span class="koboSpan" id="kobo.162.1">Chapter 2</span></em></a><span class="koboSpan" id="kobo.163.1">.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.164.1">Once you’ve selected an appropriate model, the next crucial step is understanding how to control its behavior to suit your specific application needs. </span><span class="koboSpan" id="kobo.164.2">While accessing a model gives you computational capability, it’s the choice of generation parameters that transforms raw model power into tailored output for different use cases within your applications</span><a id="_idTextAnchor011"/><span class="koboSpan" id="kobo.165.1">.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.166.1">Now that we’ve covered the LLM provider landscape, let’s discuss another critical aspect of LLM implementation: licensing considerations. </span><span class="koboSpan" id="kobo.166.2">The licensing terms of different models significantly impact how you can use them in your applications.</span></p>
<h2 class="heading-2" id="_idParaDest-19"><a id="_idTextAnchor012"/><span class="koboSpan" id="kobo.167.1">Licensing</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.168.1">LLMs are </span><a id="_idIndexMarker019"/><span class="koboSpan" id="kobo.169.1">available under different licensing models that impact how they can be used in practice. </span><span class="koboSpan" id="kobo.169.2">Open-source models like</span><a id="_idIndexMarker020"/><span class="koboSpan" id="kobo.170.1"> Mixtral and BERT can</span><a id="_idIndexMarker021"/><span class="koboSpan" id="kobo.171.1"> be freely used, modified, and integrated into applications. </span><span class="koboSpan" id="kobo.171.2">These models allow developers to run them locally, investigate their behavior, and build upon them for both research and commercial purposes.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.172.1">In contrast, proprietary models like</span><a id="_idIndexMarker022"/><span class="koboSpan" id="kobo.173.1"> GPT-4 and</span><a id="_idIndexMarker023"/><span class="koboSpan" id="kobo.174.1"> Claude are accessible only through APIs, with their internal workings kept private. </span><span class="koboSpan" id="kobo.174.2">While this ensures consistent performance and regular updates, it means depending on external services and typically incurring usage costs.</span></p>
<div aria-label="8" epub:type="pagebreak" id="page8-2" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.175.1">Some models like Llama 2 take</span><a id="_idIndexMarker024"/><span class="koboSpan" id="kobo.176.1"> a middle ground, offering permissive licenses for both research and commercial use while maintaining certain usage conditions. </span><span class="koboSpan" id="kobo.176.2">For detailed information about specific model licenses and their implications, refer to the documentation of each model or consult the model </span><a id="_idIndexMarker025"/><span class="koboSpan" id="kobo.177.1">openness framework: </span><a href="https://isitopen.ai/"><span class="url"><span class="koboSpan" id="kobo.178.1">https://isitopen.ai/</span></span></a><span class="koboSpan" id="kobo.179.1">.</span></p>
<div>
<div class="note" id="_idContainer015">
<p class="normal"><span class="koboSpan" id="kobo.180.1">The </span><strong class="keyWord"><span class="koboSpan" id="kobo.181.1">model openness framework </span></strong><span class="koboSpan" id="kobo.182.1">(</span><strong class="keyWord"><span class="koboSpan" id="kobo.183.1">MOF</span></strong><span class="koboSpan" id="kobo.184.1">) evaluates</span><a id="_idIndexMarker026"/><span class="koboSpan" id="kobo.185.1"> language models based on criteria such as access to model architecture details, training methodology and hyperparameters, data sourcing and processing information, documentation around development decisions, ability to evaluate model workings, biases, and limitations, code modularity, published model card, availability of servable model, option to run locally, source code availability, and redistribution rights.</span></p>
</div>
</div>
<p class="normal"><span class="koboSpan" id="kobo.186.1">In general, open-source licenses promote wide adoption, collaboration, and innovation around the models, benefiting both research and commercial development. </span><span class="koboSpan" id="kobo.186.2">Proprietary licenses typically give companies exclusive control but may limit academic research progress. </span><span class="koboSpan" id="kobo.186.3">Non-commercial licenses often restrict commercial use while enabling research.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.187.1">By making </span><a id="_idIndexMarker027"/><span class="koboSpan" id="kobo.188.1">knowledge and knowledge work more accessible and adaptable, generative AI models have the potential to level the playing field and create new opportunities for people from all walks of life.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.189.1">The evolution of AI has brought us to a pivotal moment where AI systems can not only process information but also take autonomous action. </span><span class="koboSpan" id="kobo.189.2">The next section explores the transformation from basic language models to more complex, and finally, fully agentic app</span><a id="_idTextAnchor013"/><span class="koboSpan" id="kobo.190.1">lications.</span></p>
<div>
<div class="note" id="_idContainer016">
<p class="normal"><span class="koboSpan" id="kobo.191.1">The information provided about AI model licensing is for educational purposes only and does not constitute legal advice. </span><span class="koboSpan" id="kobo.191.2">Licensing terms vary significantly and evolve rapidly. </span><span class="koboSpan" id="kobo.191.3">Organizations should consult qualified legal counsel regarding specific licensing decisions for their AI implementations.</span></p>
</div>
</div>
<h1 class="heading-1" id="_idParaDest-20"><a id="_idTextAnchor014"/><span class="koboSpan" id="kobo.192.1">From models to agentic applications</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.193.1">As discussed so far, LLMs have been demonstrating remarkable fluency in natural language processing. </span><span class="koboSpan" id="kobo.193.2">However, as impressive as they are, they remain fundamentally </span><em class="italic"><span class="koboSpan" id="kobo.194.1">reactive</span></em><span class="koboSpan" id="kobo.195.1"> rather than </span><em class="italic"><span class="koboSpan" id="kobo.196.1">proactive</span></em><span class="koboSpan" id="kobo.197.1">. </span><span class="koboSpan" id="kobo.197.2">They lack the ability to take independent actions, interact meaningfully with external systems, or autonomously achieve complex objectives.</span></p>
<div aria-label="9" epub:type="pagebreak" id="page9-1" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.198.1">To unlock the next phase of AI capabilities, we need to move beyond passive text generation and toward </span><strong class="keyWord"><span class="koboSpan" id="kobo.199.1">agentic AI</span></strong><span class="koboSpan" id="kobo.200.1">—systems</span><a id="_idIndexMarker028"/><span class="koboSpan" id="kobo.201.1"> that can plan, reason, and take action to accomplish tasks with minimal human intervention. </span><span class="koboSpan" id="kobo.201.2">Before exploring the potential of agentic AI, it’s important to first understand the core limitations of LLMs that necessitate this</span><a id="_idTextAnchor015"/><span class="koboSpan" id="kobo.202.1"> evolution.</span></p>
<h2 class="heading-2" id="_idParaDest-21"><a id="_idTextAnchor016"/><span class="koboSpan" id="kobo.203.1">Limitations of traditional LLMs</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.204.1">Despite their</span><a id="_idIndexMarker029"/><span class="koboSpan" id="kobo.205.1"> advanced language capabilities, LLMs have inherent constraints that limit their effectiveness in real-world a</span><a id="_idTextAnchor017"/><span class="koboSpan" id="kobo.206.1">pplications:</span></p>
<div aria-label="10" epub:type="pagebreak" id="page10-1" role="doc-pagebreak"/>
<ol>
<li class="numberedList" value="1"><strong class="keyWord"><span class="koboSpan" id="kobo.207.1">Lack of true understanding</span></strong><span class="koboSpan" id="kobo.208.1">: LLMs generate human-like text by predicting the next most likely word based on statistical patterns in training data. </span><span class="koboSpan" id="kobo.208.2">However, they do not understand meaning in the way humans do. </span><span class="koboSpan" id="kobo.208.3">This leads to hallucinations—confidently stating false information as fact—and generating plausible but incorrect, misleading, or nonsensical outputs. </span><span class="koboSpan" id="kobo.208.4">As Bender et al. </span><span class="koboSpan" id="kobo.208.5">(2021) describe, LLMs function as “stochastic parrots”—repeating patterns without genuine c</span><a id="_idTextAnchor018"/><span class="koboSpan" id="kobo.209.1">omprehension.</span></li>
<li class="numberedList"><strong class="keyWord"><span class="koboSpan" id="kobo.210.1">Struggles with complex reasoning and problem-solving</span></strong><span class="koboSpan" id="kobo.211.1">: While LLMs excel at retrieving and reformatting knowledge, they struggle with multi-step reasoning, logical puzzles, and mathematical problem-solving. </span><span class="koboSpan" id="kobo.211.2">They often fail to break down problems into</span><a id="_idIndexMarker030"/><span class="koboSpan" id="kobo.212.1"> sub-tasks or synthesize information across different contexts. </span><span class="koboSpan" id="kobo.212.2">Without explicit prompting techniques like chain-of-thought reasoning, their ability to deduce or infer remai</span><a id="_idTextAnchor019"/><span class="koboSpan" id="kobo.213.1">ns unreliable.</span></li>
<li class="numberedList"><strong class="keyWord"><span class="koboSpan" id="kobo.214.1">Outdated knowledge and limited external access</span></strong><span class="koboSpan" id="kobo.215.1">: LLMs are trained on static datasets and do not have real-time access to current events, dynamic databases, or live information sources. </span><span class="koboSpan" id="kobo.215.2">This makes them unsuitable for tasks requiring up-to-date knowledge, such as financial analysis, breaking news summaries, or scientific research requiring the la</span><a id="_idTextAnchor020"/><span class="koboSpan" id="kobo.216.1">test findings.</span></li>
<li class="numberedList"><strong class="keyWord"><span class="koboSpan" id="kobo.217.1">No native tool use or action-taking abilities</span></strong><span class="koboSpan" id="kobo.218.1">: LLMs operate in isolation—they cannot interact with APIs, retrieve live data, execute code, or modify external systems. </span><span class="koboSpan" id="kobo.218.2">This lack of tool integration makes them less effective in scenarios that require real-world actions, such as conducting web searches, automating workflows, or controlling sof</span><a id="_idTextAnchor021"/><span class="koboSpan" id="kobo.219.1">tware systems.</span></li>
<li class="numberedList"><strong class="keyWord"><span class="koboSpan" id="kobo.220.1">Bias, ethical concerns, and reliability issues: </span></strong><span class="koboSpan" id="kobo.221.1">Because LLMs learn from large datasets that may contain biases, they can unintentionally reinforce ideological, social, or cultural biases. </span><span class="koboSpan" id="kobo.221.2">Importantly, even with open-source models, accessing and auditing the complete training data to identify and mitigate these biases remains challenging for most practitioners. </span><span class="koboSpan" id="kobo.221.3">Additionally, they can generate misleading or harmful information without understanding the ethical implications of their outputs.</span></li>
<li class="numberedList"><strong class="keyWord"><span class="koboSpan" id="kobo.222.1">Computational costs and efficiency challenges</span></strong><span class="koboSpan" id="kobo.223.1">: Deploying and running LLMs at scale requires </span><strong class="keyWord"><span class="koboSpan" id="kobo.224.1">significant </span></strong><span class="koboSpan" id="kobo.225.1">computational resources, making them costly and energy-intensive. </span><span class="koboSpan" id="kobo.225.2">Larger models can also introduce latency, slowing response times in real-time applications.</span></li>
</ol>
<p class="normal"><span class="koboSpan" id="kobo.226.1">To overcome these limitations, AI systems must evolve from passive text generators into active agents that can plan, reason, and interact with their environment. </span><span class="koboSpan" id="kobo.226.2">This is where agentic AI comes in—integrating LLMs with tool use, decision-making mechanisms, and autonomous execution capabilities to enhance their functionality.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.227.1">While frameworks like LangChain provide comprehensive solutions to LLM limitations, understanding fundamental prompt engineering techniques remains valuable. </span><span class="koboSpan" id="kobo.227.2">Approaches like few-shot learning, chain-of-thought, and structured prompting can significantly enhance model performance for specific tasks. </span><a href="E_Chapter_3.xhtml#_idTextAnchor107"><em class="italic"><span class="koboSpan" id="kobo.228.1">Chapter 3</span></em></a><span class="koboSpan" id="kobo.229.1"> will cover these techniques in detail, showing how LangChain helps standardize and optimize prompting patterns while minimizing the need for custom prompt engineering in every application.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.230.1">The next section explores how agentic AI extends the capabilities of traditional LLMs and unlocks new possibilities for automation, problem-solving, and intelligent dec</span><a id="_idTextAnchor022"/><span class="koboSpan" id="kobo.231.1">ision-making.</span></p>
<h2 class="heading-2" id="_idParaDest-22"><a id="_idTextAnchor023"/><span class="koboSpan" id="kobo.232.1">Understanding LLM applications</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.233.1">LLM applications</span><a id="_idIndexMarker031"/><span class="koboSpan" id="kobo.234.1"> represent the bridge between raw model capability and practical business value. </span><span class="koboSpan" id="kobo.234.2">While LLMs possess impressive language processing abilities, they require thoughtful integration to deliver real-world solutions. </span><span class="koboSpan" id="kobo.234.3">These applications broadly fall into two categories: complex integrated applications and autonomous agents.</span></p>
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.235.1">Complex integrated applications</span></strong><span class="koboSpan" id="kobo.236.1"> enhance</span><a id="_idIndexMarker032"/><span class="koboSpan" id="kobo.237.1"> human workflows</span><a id="_idIndexMarker033"/><span class="koboSpan" id="kobo.238.1"> by integrating LLMs into existing processes, including:</span></p>
<ul>
<li class="b lletList"><span class="koboSpan" id="kobo.239.1">Decision support systems that provide analysis and recommendations</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.240.1">Content generation pipelines with human review</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.241.1">Interactive tools that augment human capabilities</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.242.1">Workflow automation with human oversight</span></li>
</ul>
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.243.1">Autonomous agents</span></strong><span class="koboSpan" id="kobo.244.1"> operate</span><a id="_idIndexMarker034"/><span class="koboSpan" id="kobo.245.1"> with minimal human intervention, further augmenting workflows through LLM integration. </span><span class="koboSpan" id="kobo.245.2">Examples include:</span></p>
<ul>
<li class="b lletList"><span class="koboSpan" id="kobo.246.1">Task automation agents that execute defined workflows</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.247.1">Information gathering and analysis systems</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.248.1">Multi-agent systems for complex task coordination</span></li>
</ul>
<div aria-label="11" epub:type="pagebreak" id="page11" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.249.1">LangChain provides frameworks for both integrated applications and autonomous agents, offering flexible components that support various architectural choices. </span><span class="koboSpan" id="kobo.249.2">This book will explore both approaches, demonstrating how to build reliable, production-ready systems that match your specific requirements.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.250.1">Autonomous systems of agents are potentially very powerful, and it’s therefore worthwhile exploring</span><a id="_idTextAnchor024"/><span class="koboSpan" id="kobo.251.1"> them a bit more.</span></p>
<h2 class="heading-2" id="_idParaDest-23"><a id="_idTextAnchor025"/><span class="koboSpan" id="kobo.252.1">Understanding AI agents</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.253.1">It is sometimes joked that</span><a id="_idIndexMarker035"/><span class="koboSpan" id="kobo.254.1"> AI is just a fancy word for ML, or AI is ML in a suit, as illustrated in this image; however, there’s more to it, as we’ll see.</span></p>
<figure class="mediaobject">
<span class="koboSpan" id="kobo.255.1"><img alt="Figure 1.1: ML in a suit. Generated by a model on replicate.com, Diffusers Stable Diffusion v2.1" src="../Images/B32363_01_01.png"/></span>
</figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.256.1">Figure 1.1: ML in a suit. </span><span class="koboSpan" id="kobo.256.2">Generated by a model on replicate.com, Diffusers Stable Diffusion v2.1</span></p>
<p class="normal"><span class="koboSpan" id="kobo.257.1">An AI agent represents </span><a id="_idIndexMarker036"/><span class="koboSpan" id="kobo.258.1">the bridge between raw cognitive capability and practical action. </span><span class="koboSpan" id="kobo.258.2">While an LLM possesses vast knowledge and processing ability, it remains fundamentally reactive without agency. </span><span class="koboSpan" id="kobo.258.3">AI agents transform this passive capability into active utility through structured workflows that parse requirements, analyze options, and execute actions.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.259.1">Agentic AI enables autonomous systems to make decisions and act independently, with minimal human intervention. </span><span class="koboSpan" id="kobo.259.2">Unlike deterministic systems that follow fixed rules, agentic AI relies on patterns and likelihoods to make informed choices. </span><span class="koboSpan" id="kobo.259.3">It functions through a network of autonomous software components called agents, which learn from user behavior and large datasets to improve over time.</span></p>
<div aria-label="12" epub:type="pagebreak" id="page12" role="doc-pagebreak"/>
<p class="normal"><em class="italic"><span class="koboSpan" id="kobo.260.1">Agency</span></em><span class="koboSpan" id="kobo.261.1"> in AI refers to a system’s ability to act independently to achieve goals. </span><span class="koboSpan" id="kobo.261.2">True agency means an AI system can perceive its environment, make decisions, act, and adapt over time by learning from interactions and feedback. </span><span class="koboSpan" id="kobo.261.3">The distinction between raw AI and agents parallels the difference between knowledge and expertise. </span><span class="koboSpan" id="kobo.261.4">Consider a brilliant researcher who understands complex theories but struggles with practical application. </span><span class="koboSpan" id="kobo.261.5">An agent system adds the crucial element of purposeful action, turning abstract capability into concrete results.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.262.1">In the context of LLMs, agentic AI involves developing systems that act autonomously, understand context, adapt to new information, and collaborate with humans to solve complex challenges. </span><span class="koboSpan" id="kobo.262.2">These AI agents leverage LLMs to process information, generate responses, and execute tasks based on defined objectives.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.263.1">Particularly, AI agents extend the capabilities of LLMs by integrating memory, tool use, and decision-making frameworks. </span><span class="koboSpan" id="kobo.263.2">These agents can:</span></p>
<ul>
<li class="b lletList"><span class="koboSpan" id="kobo.264.1">Retain and recall information across interactions.</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.265.1">Utilize external tools, APIs, and databases.</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.266.1">Plan and execute multi-step workflows.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.267.1">The value</span><a id="_idIndexMarker037"/><span class="koboSpan" id="kobo.268.1"> of agency lies in reducing the need for constant human oversight. </span><span class="koboSpan" id="kobo.268.2">Instead of manually prompting an LLM for every request, an agent can proactively execute tasks, react to new data, and integrate with real-world applications.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.269.1">AI agents are systems designed to act on behalf of users, leveraging LLMs alongside external tools, memory, and decision-making frameworks. </span><span class="koboSpan" id="kobo.269.2">The hope behind AI agents is that they can automate complex workflows, reducing human effort while increasing efficiency and accuracy. </span><span class="koboSpan" id="kobo.269.3">By allowing systems to act autonomously, agents promise to unlock new levels of automation in AI-driven applications. </span><span class="koboSpan" id="kobo.269.4">But are the hopes justified?</span></p>
<p class="normal"><span class="koboSpan" id="kobo.270.1">Despite their potential, AI </span><a id="_idIndexMarker038"/><span class="koboSpan" id="kobo.271.1">agents face significant challenges:</span></p>
<ul>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.272.1">Reliability</span></strong><span class="koboSpan" id="kobo.273.1">: Ensuring agents make correct, context-aware decisions without supervision is difficult.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.274.1">Generalization</span></strong><span class="koboSpan" id="kobo.275.1">: Many agents work well in narrow domains but struggle with open-ended, multi-domain tasks.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.276.1">Lack of trust</span></strong><span class="koboSpan" id="kobo.277.1">: Users must trust that agents will act responsibly, avoid unintended actions, and respect privacy constraints.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.278.1">Coordination complexity</span></strong><span class="koboSpan" id="kobo.279.1">: Multi-agent systems often suffer from inefficiencies and miscommunication when executing tasks collaboratively.</span></li>
</ul>
<div aria-label="13" epub:type="pagebreak" id="page13" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.280.1">Production-ready agent systems must address not just theoretical challenges but practical implementation hurdles like:</span></p>
<ul>
<li class="b lletList"><span class="koboSpan" id="kobo.281.1">Rate limitations and API quotas</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.282.1">Token context overflow errors</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.283.1">Hallucination management</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.284.1">Cost optimization</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.285.1">LangChain and LangSmith provide robust solutions for these challenges, which we’ll explore in depth in </span><a href="E_Chapter_8.xhtml#_idTextAnchor390"><em class="italic"><span class="koboSpan" id="kobo.286.1">Chapter 8</span></em></a><span class="koboSpan" id="kobo.287.1"> and </span><a href="E_Chapter_9.xhtml#_idTextAnchor448"><em class="italic"><span class="koboSpan" id="kobo.288.1">Chapter 9</span></em></a><span class="koboSpan" id="kobo.289.1">. </span><span class="koboSpan" id="kobo.289.2">These chapters will cover how to build reliable, observable AI systems that can operate at an enterprise scale.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.290.1">When developing </span><a id="_idIndexMarker039"/><span class="koboSpan" id="kobo.291.1">agent-based systems, therefore, several key factors require careful consideration:</span></p>
<ul>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.292.1">Value generation</span></strong><span class="koboSpan" id="kobo.293.1">: Agents must provide a clear utility that outweighs their costs in terms of setup, maintenance, and necessary human oversight. </span><span class="koboSpan" id="kobo.293.2">This often means starting with well-defined, high-value tasks where automation can demonstrably improve outcomes.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.294.1">Trust and safety</span></strong><span class="koboSpan" id="kobo.295.1">: As agents take on more responsibility, establishing and maintaining user trust becomes crucial. </span><span class="koboSpan" id="kobo.295.2">This encompasses both technical reliability and transparent operation that allows users to understand and predict agent behavior.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.296.1">Standardization</span></strong><span class="koboSpan" id="kobo.297.1">: As the agent ecosystem grows, standardized interfaces and protocols become essential for interoperability. </span><span class="koboSpan" id="kobo.297.2">This parallels the development of web standards that enabled the growth of internet applications.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.298.1">While </span><a id="_idIndexMarker040"/><span class="koboSpan" id="kobo.299.1">early AI systems focused on pattern matching and predefined templates, modern AI agents demonstrate emergent capabilities such as reasoning, problem-solving, and long-term planning. </span><span class="koboSpan" id="kobo.299.2">Today’s AI agents integrate LLMs with interactive environments, enabling them to function autonomously in complex domains.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.300.1">The development of agent-based AI is a natural progression from statistical models to deep learning and now to reasoning-based systems. </span><span class="koboSpan" id="kobo.300.2">Modern AI agents leverage multimodal capabilities, reinforcement learning, and memory-augmented architectures to adapt to diverse tasks. </span><span class="koboSpan" id="kobo.300.3">This evolution marks a shift from predictive models to truly autonomous systems capable of dynamic decision-making.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.301.1">Looking ahead, AI agents will continue to refine their ability to reason, plan, and act within structured and unstructured environments. </span><span class="koboSpan" id="kobo.301.2">The rise of open-weight models, combined with advances in agent-based AI, will likely drive the next wave of innovations in AI, expanding its applications across science, engineering, and everyday life.</span></p>
<div aria-label="14" epub:type="pagebreak" id="page14" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.302.1">With frameworks like LangChain, developers can build complex and agentic structured systems that overcome the limitations of raw LLMs. </span><span class="koboSpan" id="kobo.302.2">It offers built-in solutions for memory management, tool integration, and multi-step reasoning that align with the ecosystem model presented here. </span><span class="koboSpan" id="kobo.302.3">In the next section we will explore how LangChain facilitates the development of production-ready AI agents.</span></p>
<h1 class="heading-1" id="_idParaDest-24"><a id="_idTextAnchor026"/><span class="koboSpan" id="kobo.303.1">Introducing LangChain</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.304.1">LangChain</span><a id="_idIndexMarker041"/><span class="koboSpan" id="kobo.305.1"> exists as both an open-source framework and a venture-backed company. </span><span class="koboSpan" id="kobo.305.2">The framework, introduced in 2022 by Harrison Chase, streamlines the development of LLM-powered applications with support for multiple programming languages including Python, JavaScript/TypeScript, Go, Rust, and Ruby.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.306.1">The company behind the framework, LangChain, Inc., is based in San Francisco and has secured significant venture funding through multiple rounds, including a Series A in February 2024. </span><span class="koboSpan" id="kobo.306.2">With 11-50 employees, the company maintains and expands the framework while offering enterprise solutions for LLM application development.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.307.1">While the core framework remains open source, the company provides additional enterprise features and support for commercial users. </span><span class="koboSpan" id="kobo.307.2">Both share the same mission: accelerating LLM application </span><a id="_idIndexMarker042"/><span class="koboSpan" id="kobo.308.1">development by providing robust tools and infrastructure.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.309.1">Modern LLMs are undeniably powerful, but their practical utility in production applications is constrained by several inherent limitations. </span><span class="koboSpan" id="kobo.309.2">Understanding these challenges is essential for appreciating why frameworks like LangChain have become indispensable </span><a id="_idTextAnchor027"/><span class="koboSpan" id="kobo.310.1">tools for AI developers.</span></p>
<h2 class="heading-2" id="_idParaDest-25"><a id="_idTextAnchor028"/><span class="koboSpan" id="kobo.311.1">Challenges with raw LLMs</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.312.1">Despite </span><a id="_idIndexMarker043"/><span class="koboSpan" id="kobo.313.1">their impressive capabilities, LLMs face fundamental constraints that create significant hurdles for developers building real-world applications:</span></p>
<div aria-label="15" epub:type="pagebreak" id="page15" role="doc-pagebreak"/>
<ol>
<li class="numberedList" value="1"><strong class="keyWord"><span class="koboSpan" id="kobo.314.1">Context window limitations</span></strong><span class="koboSpan" id="kobo.315.1">: LLMs process text as tokens (subword units), not complete words. </span><span class="koboSpan" id="kobo.315.2">For example, “LangChain” might be processed as two tokens: “Lang” and “Chain.” </span><span class="koboSpan" id="kobo.315.3">Every LLM has a fixed context window—the maximum number of tokens it can process at once—typically ranging from 2,000 to 128,000 tokens. </span><span class="koboSpan" id="kobo.315.4">This creates several practical challenges:

      </span><ol>
<li class="alphabeticList level-2" value="1"><strong class="keyWord"><span class="koboSpan" id="kobo.316.1">Document processing</span></strong><span class="koboSpan" id="kobo.317.1">: Long documents must be chunked effectively to fit within context limits</span></li>
<li class="alphabeticList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.318.1">Conversation history</span></strong><span class="koboSpan" id="kobo.319.1">: Maintaining information across extended conversations requires careful memory management</span></li>
<li class="alphabeticList level-2"><strong class="keyWord"><span class="koboSpan" id="kobo.320.1">Cost management</span></strong><span class="koboSpan" id="kobo.321.1">: Most providers charge based on token count, making efficient token use a business imperative</span></li>
</ol></li>
</ol>
<p class="normal-one"><span class="koboSpan" id="kobo.322.1">These constraints directly impact application architecture, making techniques like RAG (which we’ll explore in </span><a href="E_Chapter_4.xhtml#_idTextAnchor152"><em class="italic"><span class="koboSpan" id="kobo.323.1">Chapter 4</span></em></a><span class="koboSpan" id="kobo.324.1">) essential for production systems.</span></p>
<ol>
<li class="numberedList" value="2"><strong class="keyWord"><span class="koboSpan" id="kobo.325.1">Limited tool orchestration</span></strong><span class="koboSpan" id="kobo.326.1">: While many modern LLMs offer native tool-calling capabilities, they lack the infrastructure to discover appropriate tools, execute complex workflows, and manage tool interactions across multiple turns. </span><span class="koboSpan" id="kobo.326.2">Without this orchestration layer, developers must build custom solutions for each integration.</span></li>
<li class="numberedList"><strong class="keyWord"><span class="koboSpan" id="kobo.327.1">Task coordination challenges</span></strong><span class="koboSpan" id="kobo.328.1">: Managing multi-step workflows with LLMs requires structured control mechanisms. </span><span class="koboSpan" id="kobo.328.2">Without them, complex processes involving sequential reasoning or decision-making become difficult to implement reliably.</span></li>
</ol>
<p class="normal"><span class="koboSpan" id="kobo.329.1">Tools in this context refer to functional capabilities that extend an LLM’s reach: web browsers for searching the internet, calculators for precise mathematics, coding environments for executing programs, or APIs for accessing external services and databases. </span><span class="koboSpan" id="kobo.329.2">Without these tools, LLMs remain confined to operating within their training knowledge, unable to perform real-world actions or access current information.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.330.1">These fundamental</span><a id="_idIndexMarker044"/><span class="koboSpan" id="kobo.331.1"> limitations create three key challenges for developers working with raw LLM APIs, as demonstrated in the following table.</span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table003">
<colgroup>
<col/>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.332.1">Challenge</span></strong></p>
</td>
<td class="No-Table-Style">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.333.1">Description</span></strong></p>
</td>
<td class="No-Table-Style">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.334.1">Impact</span></strong></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.335.1">Reliability</span></strong></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.336.1">Detecting hallucinations and validating outputs</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.337.1">Inconsistent results that may require human verification</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.338.1">Resource Management</span></strong></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.339.1">Handling context windows and rate limits</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.340.1">Implementation complexity and potential cost overruns</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.341.1">Integration Complexity</span></strong></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.342.1">Building connections to external tools and data sources</span></p>
</td>
<td class="No-Table-Style">
<p class="normal"><span class="koboSpan" id="kobo.343.1">Extended development time and maintenance burden</span></p>
</td>
</tr>
</tbody>
</table>
<p class="packt_figref"><span class="koboSpan" id="kobo.344.1">Table 1.3: Three key developer challenges</span></p>
<p class="normal"><span class="koboSpan" id="kobo.345.1">LangChain addresses these challenges by providing a structured framework with tested solutions, simplifying AI application development and enabling more sophisticated use cases.</span></p>
<div aria-label="16" epub:type="pagebreak" id="page16" role="doc-pagebreak"/>
<h2 class="heading-2" id="_idParaDest-26"><a id="_idTextAnchor029"/><span class="koboSpan" id="kobo.346.1">How LangChain enables agent development</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.347.1">LangChain </span><a id="_idIndexMarker045"/><span class="koboSpan" id="kobo.348.1">provides the foundational infrastructure for building sophisticated AI applications through its modular architecture and composable patterns. </span><span class="koboSpan" id="kobo.348.2">With the evolution to version 0.3, LangChain has refined its approach to creating intelligent systems:</span></p>
<ul>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.349.1">Composable workflows</span></strong><span class="koboSpan" id="kobo.350.1">: The </span><strong class="keyWord"><span class="koboSpan" id="kobo.351.1">LangChain Expression Language</span></strong><span class="koboSpan" id="kobo.352.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.353.1">LCEL</span></strong><span class="koboSpan" id="kobo.354.1">) allows developers</span><a id="_idIndexMarker046"/><span class="koboSpan" id="kobo.355.1"> to break down complex tasks into modular components that can be assembled and reconfigured. </span><span class="koboSpan" id="kobo.355.2">This composability enables systematic reasoning through the orchestration of multiple processing steps.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.356.1">Integration ecosystem</span></strong><span class="koboSpan" id="kobo.357.1">: LangChain offers battle-tested abstract interfaces for all generative AI components (LLMs, embeddings, vector databases, document loaders, search engines). </span><span class="koboSpan" id="kobo.357.2">This lets you build applications that can easily switch between providers without rewriting core logic.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.358.1">Unified model access</span></strong><span class="koboSpan" id="kobo.359.1">: The framework provides consistent interfaces to diverse language and embedding models, allowing seamless switching between providers while maintaining application logic.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.360.1">While earlier versions of LangChain handled memory management directly, version 0.3 takes a more specialized approach to application development:</span></p>
<ul>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.361.1">Memory and state management</span></strong><span class="koboSpan" id="kobo.362.1">: For applications requiring persistent context across interactions, LangGraph now serves as the recommended solution. </span><span class="koboSpan" id="kobo.362.2">LangGraph maintains conversation history and application state with purpose-built persistence mechanisms.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.363.1">Agent architecture</span></strong><span class="koboSpan" id="kobo.364.1">: Though LangChain contains agent implementations, LangGraph has become the preferred framework for building sophisticated agents. </span><span class="koboSpan" id="kobo.364.2">It provides:

      </span><ul>
<li class="bulletList level-2"><span class="koboSpan" id="kobo.365.1">Graph-based workflow definition for complex decision paths</span></li>
<li class="bulletList level-2"><span class="koboSpan" id="kobo.366.1">Persistent state management across multiple interactions</span></li>
<li class="bulletList level-2"><span class="koboSpan" id="kobo.367.1">Streaming support for real-time feedback during processing</span></li>
<li class="bulletList level-2"><span class="koboSpan" id="kobo.368.1">Human-in-the-loop capabilities for validation and corrections</span></li>
</ul></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.369.1">Together, LangChain </span><a id="_idIndexMarker047"/><span class="koboSpan" id="kobo.370.1">and its companion projects like LangGraph and LangSmith form a comprehensive ecosystem that transforms LLMs from simple text generators into systems capable of sophisticated real-world tasks, combining strong abstractions with practical implementation patterns optimized for production us</span><a id="_idTextAnchor030"/><span class="koboSpan" id="kobo.371.1">e.</span></p>
<div aria-label="17" epub:type="pagebreak" id="page17" role="doc-pagebreak"/>
<h2 class="heading-2" id="_idParaDest-27"><a id="_idTextAnchor031"/><span class="koboSpan" id="kobo.372.1">Exploring the LangChain architecture</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.373.1">LangChain’s </span><a id="_idIndexMarker048"/><span class="koboSpan" id="kobo.374.1">philosophy centers on composability and modularity. </span><span class="koboSpan" id="kobo.374.2">Rather than treating LLMs as standalone services, LangChain views them as components that can be combined with other tools and services to create more capable systems. </span><span class="koboSpan" id="kobo.374.3">This approach is built on several principl</span><a id="_idTextAnchor032"/><span class="koboSpan" id="kobo.375.1">es:</span></p>
<ul>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.376.1">Modular architecture</span></strong><span class="koboSpan" id="kobo.377.1">: Every component is designed to be reusable and interchangeable, allowing developers to integrate LLMs seamlessly into various applications. </span><span class="koboSpan" id="kobo.377.2">This modularity extends beyond LLMs to include numerous building blocks for developing complex generative AI applicatio</span><a id="_idTextAnchor033"/><span class="koboSpan" id="kobo.378.1">ns.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.379.1">Support for agentic workflows</span></strong><span class="koboSpan" id="kobo.380.1">: LangChain offers best-in-class APIs that allow you to develop sophisticated agents quickly. </span><span class="koboSpan" id="kobo.380.2">These agents can make decisions, use tools, and solve problems with minimal development overhe</span><a id="_idTextAnchor034"/><span class="koboSpan" id="kobo.381.1">ad.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.382.1">Production readiness</span></strong><span class="koboSpan" id="kobo.383.1">: The framework provides built-in capabilities for tracing, evaluation, and deployment of generative AI applications, including robust building blocks for managing memory and persistence across interactio</span><a id="_idTextAnchor035"/><span class="koboSpan" id="kobo.384.1">ns.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.385.1">Broad vendor ecosystem</span></strong><span class="koboSpan" id="kobo.386.1">: LangChain offers battle-tested abstract interfaces for all generative AI components (LLMs, embeddings, vector databases, document loaders, search engines, etc.). </span><span class="koboSpan" id="kobo.386.2">Vendors develop their own integrations that comply with these interfaces, allowing you to build applications on top of any third-party provider and easily switch between them.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.387.1">It’s worth noting that </span><a id="_idIndexMarker049"/><span class="koboSpan" id="kobo.388.1">there’ve been major changes since LangChain version 0.1 when the first edition of this book was written. </span><span class="koboSpan" id="kobo.388.2">While early versions attempted to handle everything, LangChain version 0.3 focuses on excelling at specific functions with companion projects handling specialized needs. </span><span class="koboSpan" id="kobo.388.3">LangChain manages model integration and workflows, while LangGraph handles stateful agents and LangSmith provides observability.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.389.1">LangChain’s memory management, too, has gone through major changes. </span><span class="koboSpan" id="kobo.389.2">Memory mechanisms within the base LangChain library have been deprecated in favor of LangGraph for persistence, and while agents are present, LangGraph is the recommended approach for their creation in version 0.3. </span><span class="koboSpan" id="kobo.389.3">However, models and tools continue to be fundamental to LangChain’s functionality. </span><span class="koboSpan" id="kobo.389.4">In </span><a href="E_Chapter_3.xhtml#_idTextAnchor107"><em class="italic"><span class="koboSpan" id="kobo.390.1">Chapter 3</span></em></a><span class="koboSpan" id="kobo.391.1">, we’ll explore LangChain and LangGraph’s memory mechanisms.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.392.1">To translate model design principles into practical tools, LangChain has developed a comprehensive ecosystem of libraries, services, and applications. </span><span class="koboSpan" id="kobo.392.2">This ecosystem provides developers with everything they need to build, deploy, and maintain sophisticated AI applications. </span><span class="koboSpan" id="kobo.392.3">Let’s examine the components that make up this thriving environment and how they’ve gained adoption across the industry.</span></p>
<div aria-label="18" epub:type="pagebreak" id="page18" role="doc-pagebreak"/>
<h3 class="heading-3" id="_idParaDest-28"><a id="_idTextAnchor036"/><span class="koboSpan" id="kobo.393.1">Ecosystem</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.394.1">LangChain </span><a id="_idIndexMarker050"/><span class="koboSpan" id="kobo.395.1">has achieved impressive ecosystem metrics, demonstrating strong market adoption with over 20 million monthly downloads and powering more than 100,000 applications. </span><span class="koboSpan" id="kobo.395.2">Its open-source community is thriving, evidenced by 100,000+ GitHub stars and contributions from over 4,000 developers. </span><span class="koboSpan" id="kobo.395.3">This scale of adoption positions LangChain as a leading framework in the AI application development space, particularly for building reasoning-focused LLM applications. </span><span class="koboSpan" id="kobo.395.4">The framework’s modular architecture (with components like LangGraph for agent workflows and LangSmith for monitoring) has clearly resonated with developers building production AI systems across various industries.</span></p>
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.396.1">Core libraries</span></strong></p>
<ul>
<li class="b lletList"><span class="koboSpan" id="kobo.397.1">LangChain (Python): Reusable components for building LLM applications</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.398.1">LangChain.js: JavaScript/TypeScript implementation of the framework</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.399.1">LangGraph (Python): Tools for building LLM agents as orchestrated graphs</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.400.1">LangGraph.js: JavaScript implementation for agent workflows</span></li>
</ul>
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.401.1">Platform services</span></strong></p>
<ul>
<li class="b lletList"><span class="koboSpan" id="kobo.402.1">LangSmith: Platform for debugging, testing, evaluating, and monitoring LLM applications</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.403.1">LangGraph: Infrastructure for deploying and scaling LangGraph agents</span></li>
</ul>
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.404.1">Applications and extensions</span></strong></p>
<ul>
<li class="b lletList"><span class="koboSpan" id="kobo.405.1">ChatLangChain: Documentation assistant for answering questions about the framework</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.406.1">Open Canvas: Document and chat-based UX for writing code/markdown (TypeScript)</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.407.1">OpenGPTs: Open source implementation of OpenAI’s GPTs API</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.408.1">Email assistant: AI tool for email management (Python)</span></li>
<li class="b lletList"><span class="koboSpan" id="kobo.409.1">Social media agent: Agent for content curation and scheduling (TypeScript)</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.410.1">The </span><a id="_idIndexMarker051"/><span class="koboSpan" id="kobo.411.1">ecosystem provides a complete solution for building reasoning-focused AI applications: from core building blocks to deployment platforms to reference implementations. </span><span class="koboSpan" id="kobo.411.2">This architecture allows developers to use components independently or stack them for fuller and more complete solutions.</span></p>
<div aria-label="19" epub:type="pagebreak" id="page19" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.412.1">From customer testimonials and company partnerships, LangChain is being adopted by enterprises like Rakuten, Elastic, Ally, and Adyen. </span><span class="koboSpan" id="kobo.412.2">Organizations report using LangChain and LangSmith to identify optimal approaches for LLM implementation, improve developer productivity, and accelerate development workflows.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.413.1">LangChain also offers a full stack for AI application development:</span></p>
<ul>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.414.1">Build</span></strong><span class="koboSpan" id="kobo.415.1">: with the composable framework</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.416.1">Run</span></strong><span class="koboSpan" id="kobo.417.1">: deploy with LangGraph Platform</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.418.1">Manage</span></strong><span class="koboSpan" id="kobo.419.1">: debug, test, and monitor with LangSmith</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.420.1">Based on our experience </span><a id="_idIndexMarker052"/><span class="koboSpan" id="kobo.421.1">building with LangChain, here are some of its benefits we’ve found especially helpful:</span></p>
<ul>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.422.1">Accelerated development cycles</span></strong><span class="koboSpan" id="kobo.423.1">: LangChain dramatically speeds up time-to-market with ready-made building blocks and unified APIs, eliminating weeks of integration work.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.424.1">Superior observability</span></strong><span class="koboSpan" id="kobo.425.1">: The combination of LangChain and LangSmith provides unparalleled visibility into complex agent behavior, making trade-offs between cost, latency, and quality more transparent.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.426.1">Controlled agency balance</span></strong><span class="koboSpan" id="kobo.427.1">: LangGraph’s approach to agentic AI is particularly powerful—allowing developers to give LLMs partial control flow over workflows while maintaining reliability and performance.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.428.1">Production-ready patterns</span></strong><span class="koboSpan" id="kobo.429.1">: Our implementation experience has proven that LangChain’s architecture delivers enterprise-grade solutions that effectively reduce hallucinations and improve system reliability.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.430.1">Future-proof flexibility</span></strong><span class="koboSpan" id="kobo.431.1">: The framework’s vendor-agnostic design creates applications </span><a id="_idIndexMarker053"/><span class="koboSpan" id="kobo.432.1">that can adapt as the LLM landscape evolves, preventing technological lock-in.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.433.1">These advantages stem directly from LangChain’s architectural decisions, which prioritize modularity, observability, and deployment flexibility for real-world applications.</span></p>
<h3 class="heading-3" id="_idParaDest-29"><a id="_idTextAnchor037"/><span class="koboSpan" id="kobo.434.1">Modular design and dependency management</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.435.1">LangChain </span><a id="_idIndexMarker054"/><span class="koboSpan" id="kobo.436.1">evolves rapidly, with approximately 10-40 pull requests merged daily. </span><span class="koboSpan" id="kobo.436.2">This fast-paced development, combined with the framework’s extensive integration ecosystem, presents unique challenges. </span><span class="koboSpan" id="kobo.436.3">Different integrations often require specific third-party Python packages, which can lead to dependency conflicts.</span></p>
<div aria-label="20" epub:type="pagebreak" id="page20" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.437.1">LangChain’s package architecture evolved as a direct response to scaling challenges. </span><span class="koboSpan" id="kobo.437.2">As the framework rapidly expanded to support hundreds of integrations, the original monolithic structure became unsustainable—forcing users to install unnecessary dependencies, creating maintenance bottlenecks, and hindering contribution accessibility. </span><span class="koboSpan" id="kobo.437.3">By dividing into specialized packages with lazy loading of dependencies, LangChain elegantly solved these issues while preserving a cohesive ecosystem. </span><span class="koboSpan" id="kobo.437.4">This architecture allows developers to import only what they need, reduces version conflicts, enables independent release cycles for stable versus experimental features, and dramatically simplifies the contribution path for community developers working on specific integrations.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.438.1">The LangChain codebase follows a well-organized structure that separates concerns while maintaining a cohesive ecosystem:</span></p>
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.439.1">Core structure</span></strong></p>
<ul>
<li class="b lletList"><code class="inlineCode"><span class="koboSpan" id="kobo.440.1">docs/</span></code><span class="koboSpan" id="kobo.441.1">: Documentation </span><a id="_idIndexMarker055"/><span class="koboSpan" id="kobo.442.1">resources for developers</span></li>
<li class="b lletList"><code class="inlineCode"><span class="koboSpan" id="kobo.443.1">libs/</span></code><span class="koboSpan" id="kobo.444.1">: Contains all library packages in the monorepo</span></li>
</ul>
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.445.1">Library organization</span></strong></p>
<ul>
<li class="b lletList"><code class="inlineCode"><span class="koboSpan" id="kobo.446.1">langchain-core/</span></code><span class="koboSpan" id="kobo.447.1">: Foundational </span><a id="_idIndexMarker056"/><span class="koboSpan" id="kobo.448.1">abstractions and interfaces that define the framework</span></li>
<li class="b lletList"><code class="inlineCode"><span class="koboSpan" id="kobo.449.1">langchain/</span></code><span class="koboSpan" id="kobo.450.1">: The main implementation library with core components:</span></li>
<li class="b lletList"><code class="inlineCode"><span class="koboSpan" id="kobo.451.1">vectorstores/</span></code><span class="koboSpan" id="kobo.452.1">: Integrations </span><a id="_idIndexMarker057"/><span class="koboSpan" id="kobo.453.1">with vector databases (Pinecone, Chroma, etc.)</span></li>
<li class="b lletList"><code class="inlineCode"><span class="koboSpan" id="kobo.454.1">chains/</span></code><span class="koboSpan" id="kobo.455.1">: Pre-built chain implementations for common workflows</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.456.1">Other component directories for retrievers, embeddings, etc.</span></p>
<div aria-label="21" epub:type="pagebreak" id="page21" role="doc-pagebreak"/>
<ul>
<li class="b lletList"><code class="inlineCode"><span class="koboSpan" id="kobo.457.1">langchain-experimental/</span></code><span class="koboSpan" id="kobo.458.1">: Cutting-edge</span><a id="_idIndexMarker058"/><span class="koboSpan" id="kobo.459.1"> features still under development</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.460.1">langchain-community</span></strong><span class="koboSpan" id="kobo.461.1">: Houses </span><a id="_idIndexMarker059"/><span class="koboSpan" id="kobo.462.1">third-party integrations maintained by the LangChain community. </span><span class="koboSpan" id="kobo.462.2">This includes most integrations for components like LLMs, vector stores, and retrievers. </span><span class="koboSpan" id="kobo.462.3">Dependencies are optional to maintain a lightweight package.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.463.1">Partner packages</span></strong><span class="koboSpan" id="kobo.464.1">: Popular </span><a id="_idIndexMarker060"/><span class="koboSpan" id="kobo.465.1">integrations </span><a id="_idIndexMarker061"/><span class="koboSpan" id="kobo.466.1">are separated into dedicated packages (e.g., </span><strong class="keyWord"><span class="koboSpan" id="kobo.467.1">langchain-openai</span></strong><span class="koboSpan" id="kobo.468.1">, </span><strong class="keyWord"><span class="koboSpan" id="kobo.469.1">langchain-anthropic</span></strong><span class="koboSpan" id="kobo.470.1">) to enhance independent support. </span><span class="koboSpan" id="kobo.470.2">These packages reside outside the</span><a id="_idIndexMarker062"/><span class="koboSpan" id="kobo.471.1"> LangChain repository but within the GitHub “langchain-ai” organization (see </span><a href="https://github.com/langchain-ai"><span class="url"><span class="koboSpan" id="kobo.472.1">github.com/orgs/langchain-ai</span></span></a><span class="koboSpan" id="kobo.473.1">). </span><span class="koboSpan" id="kobo.473.2">A full list is available at</span><a href="https://python.langchain.com/docs/integrations/providers/"> <span class="url"><span class="koboSpan" id="kobo.474.1">python.langchain.com/v0.3/docs/integrations/platforms/</span></span></a><span class="koboSpan" id="kobo.475.1">.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.476.1">External partner packages</span></strong><span class="koboSpan" id="kobo.477.1">: Some </span><a id="_idIndexMarker063"/><span class="koboSpan" id="kobo.478.1">partners maintain their integration packages independently. </span><span class="koboSpan" id="kobo.478.2">For example, several packages from the Google organization (</span><a href="https://github.com/orgs/googleapis/repositories?q=langchain"><span class="url"><span class="koboSpan" id="kobo.479.1">github.com/orgs/googleapis/repositories?q=langchain</span></span></a><span class="koboSpan" id="kobo.480.1">), such as the </span><code class="inlineCode"><span class="koboSpan" id="kobo.481.1">langchain-google-cloud-sql-mssql</span></code><span class="koboSpan" id="kobo.482.1"> package, are developed and maintained outside the LangChain ecosystem.</span></li>
</ul>
<figure class="mediaobject">
<span class="koboSpan" id="kobo.483.1"><img alt="Figure 1.2: Integration ecosystem map" src="../Images/B32363_01_02.png"/></span>
</figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.484.1">Figure 1.2: Integration ecosystem map</span></p>
<div>
<div class="note" id="_idContainer019">
<p class="normal"><span class="koboSpan" id="kobo.485.1">For full details on the dozens of available modules and packages, refer to the comprehensive LangChain API reference: </span><a href="https://api.python.langchain.com/"><span class="url"><span class="koboSpan" id="kobo.486.1">https://api.python.langchain.com/</span></span></a><span class="koboSpan" id="kobo.487.1">. </span><span class="koboSpan" id="kobo.487.2">There are also hundreds of code examples demonstrating real-world use cases: </span><a href="https://python.langchain.com/v0.1/docs/use_cases/"><span class="url"><span class="koboSpan" id="kobo.488.1">https://python.langchain.com/v0.1/docs/use_cases/</span></span></a><span class="koboSpan" id="kobo.489.1">.</span></p>
</div>
</div>
<h3 class="heading-3" id="_idParaDest-30"><a id="_idTextAnchor038"/><span class="koboSpan" id="kobo.490.1">LangGraph, LangSmith, and companion tools</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.491.1">LangChain’s core functionality is extended by the following companion projects:</span></p>
<ul>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.492.1">LangGraph</span></strong><span class="koboSpan" id="kobo.493.1">: An </span><a id="_idIndexMarker064"/><span class="koboSpan" id="kobo.494.1">orchestration framework for building stateful, multi-actor applications with LLMs. </span><span class="koboSpan" id="kobo.494.2">While it integrates smoothly with LangChain, it can also be used independently. </span><span class="koboSpan" id="kobo.494.3">LangGraph facilitates complex applications with cyclic data flows and supports streaming and human-in-the-loop interactions. </span><span class="koboSpan" id="kobo.494.4">We’ll talk about LangGraph in more detail in </span><a href="E_Chapter_3.xhtml#_idTextAnchor107"><em class="italic"><span class="koboSpan" id="kobo.495.1">Chapter 3</span></em></a><span class="koboSpan" id="kobo.496.1">.</span></li>
<li class="b lletList"><strong class="keyWord"><span class="koboSpan" id="kobo.497.1">LangSmith</span></strong><span class="koboSpan" id="kobo.498.1">: A </span><a id="_idIndexMarker065"/><span class="koboSpan" id="kobo.499.1">platform that complements LangChain by providing robust debugging, testing, and monitoring capabilities. </span><span class="koboSpan" id="kobo.499.2">Developers can inspect, monitor, and evaluate their applications, ensuring continuous optimization and confident deployment.</span></li>
</ul>
<div aria-label="22" epub:type="pagebreak" id="page22" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.500.1">These extensions, along with the core framework, provide a comprehensive ecosystem for developing, managing, and visualizing LLM applications, each with unique capabilities that enhance functionality and user experience.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.501.1">LangChain also has an extensive array of tool integrations, which we’ll discuss in detail in </span><a href="E_Chapter_5.xhtml#_idTextAnchor231"><em class="italic"><span class="koboSpan" id="kobo.502.1">Chapter 5</span></em></a><span class="koboSpan" id="kobo.503.1">. </span><span class="koboSpan" id="kobo.503.2">New integrations are added regularly, expanding the framework’s capabilities across domains.</span></p>
<h3 class="heading-3" id="_idParaDest-31"><a id="_idTextAnchor039"/><span class="koboSpan" id="kobo.504.1">Third-party applications and visual tools</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.505.1">Many third-party applications </span><a id="_idIndexMarker066"/><span class="koboSpan" id="kobo.506.1">have been built on top of or around LangChain. </span><span class="koboSpan" id="kobo.506.2">For example, LangFlow and Flowise introduce visual interfaces for LLM development, with </span><a id="_idIndexMarker067"/><span class="koboSpan" id="kobo.507.1">UIs that allow for the drag-and-drop assembly of LangChain components into executable workflows. </span><span class="koboSpan" id="kobo.507.2">This visual approach enables rapid prototyping and experimentation, lowering the barrier to entry for complex pipeline creation, as illustrated in the following screenshot of Flowise:</span></p>
<figure class="mediaobject">
<span class="koboSpan" id="kobo.508.1"><img alt="Figure 1.3: Flowise UI with an agent that uses an LLM, a calculator, and a search tool (Source: https://github.com/FlowiseAI/Flowise)" src="../Images/B32363_01_03.png"/></span>
</figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.509.1">Figure 1.3: Flowise UI with an agent that uses an LLM, a calculator, and a search tool (Source: https://github.com/FlowiseAI/Flowise)</span></p>
<div aria-label="23" epub:type="pagebreak" id="page23" role="doc-pagebreak"/>
<p class="normal"><span class="koboSpan" id="kobo.510.1">In the UI above, you </span><a id="_idIndexMarker068"/><span class="koboSpan" id="kobo.511.1">can see an agent connected to a search</span><a id="_idIndexMarker069"/><span class="koboSpan" id="kobo.512.1"> interface (Serp API), an LLM, and a calculator. </span><span class="koboSpan" id="kobo.512.2">LangChain and similar tools can be deployed locally using libraries like Chainlit, or on various cloud platforms, including Google Cloud.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.513.1">In summary, LangChain simplifies the development of LLM applications through its modular design, extensive integrations, and supportive ecosystem. </span><span class="koboSpan" id="kobo.513.2">This makes it an invaluable tool for developers looking to build sophisticated AI systems without reinventing </span><a id="_idTextAnchor040"/><span class="koboSpan" id="kobo.514.1">fundamental components.</span></p>
<h1 class="heading-1" id="_idParaDest-32"><a id="_idTextAnchor041"/><span class="koboSpan" id="kobo.515.1">Summary</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.516.1">This chapter introduced the modern LLM landscape and positioned LangChain as a powerful framework for building production-ready AI applications. </span><span class="koboSpan" id="kobo.516.2">We explored the limitations of raw LLMs and then showed how these frameworks transform models into reliable, agentic systems capable of solving complex real-world problems. </span><span class="koboSpan" id="kobo.516.3">We also examined the LangChain ecosystem’s architecture, including its modular components, package structure, and companion projects that support the complete development lifecycle. </span><span class="koboSpan" id="kobo.516.4">By understanding the relationship between LLMs and the frameworks that extend them, you’re now equipped to build applications that go beyond simple text generation.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.517.1">In the next chapter, we’ll set up our development environment and take our first steps with LangChain, translating the conceptual understanding from this chapter into working code. </span><span class="koboSpan" id="kobo.517.2">You’ll learn how to connect to various LLM providers, create your first chains, and begin implementing the patterns that form the foundation of enterprise</span><a id="_idTextAnchor042"/><span class="koboSpan" id="kobo.518.1">-grade AI applications.</span></p>
<h1 class="heading-1" id="_idParaDest-33"><a id="_idTextAnchor043"/><span class="koboSpan" id="kobo.519.1">Questions</span></h1>
<div aria-label="24" epub:type="pagebreak" id="page24" role="doc-pagebreak"/>
<ol>
<li class="numberedList" value="1"><span class="koboSpan" id="kobo.520.1">What are the three primary limitations of raw LLMs that impact production applications, and how does LangChain address each one?</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.521.1">Compare and contrast open-source and closed-source LLMs in terms of deployment options, cost considerations, and use cases. </span><span class="koboSpan" id="kobo.521.2">When might you choose each type?</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.522.1">What is the difference between a LangChain chain and a LangGraph agent? </span><span class="koboSpan" id="kobo.522.2">When would you choose one over the other?</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.523.1">Explain how LangChain’s modular architecture supports the rapid development of AI applications. </span><span class="koboSpan" id="kobo.523.2">Provide an example of how this modularity might benefit an enterprise use case.</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.524.1">What are the key components of the LangChain ecosystem, and how do they work together to support the development lifecycle from building to deployment to monitoring?</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.525.1">How does agentic AI differ from traditional LLM applications? </span><span class="koboSpan" id="kobo.525.2">Describe a business scenario where an agent would provide significant advantages over a simple chain.</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.526.1">What factors should you consider when selecting an LLM provider for a production application? </span><span class="koboSpan" id="kobo.526.2">Name at least three considerations beyond just model performance.</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.527.1">How does LangChain help address common challenges like hallucinations, context limitations, and tool integration that affect all LLM applications?</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.528.1">Explain how the LangChain package structure (</span><code class="inlineCode"><span class="koboSpan" id="kobo.529.1">langchain-core</span></code><span class="koboSpan" id="kobo.530.1">, </span><code class="inlineCode"><span class="koboSpan" id="kobo.531.1">langchain</span></code><span class="koboSpan" id="kobo.532.1">, </span><code class="inlineCode"><span class="koboSpan" id="kobo.533.1">langchain-community</span></code><span class="koboSpan" id="kobo.534.1">) affects dependency management and integration options in your applications.</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.535.1">What role does LangSmith play in the development lifecycle of production LangChain applications?</span></li>
</ol>
</div>
</body></html>