<html><head></head><body>
<div><h1 class="chapterNumber">8</h1>
<h1 class="chapterTitle" id="_idParaDest-105">Unleashing Creativity Visually with ChatGPT</h1>
<p class="normal">In this chapter, we focus on the visual capabilities of ChatGPT, ranging from the traditional image generation with DALL-E to the more complex design and formatting activities embedded in the model.</p>
<p class="normal">Visual capabilities in ChatGPT have been improving dramatically over the past months as we are now entering the era of multimodality. In fact, ChatGPT can now not only generate images from natural language descriptions but also reason about multimodal data and solve complex queries. This multimodal thinking brings ChatGPT closer to the way our brains process the reality around them, which is mainly made of visual input.</p>
<p class="normal">Throughout this chapter, we will cover the following topics:</p>
<ul>
<li class="bulletList">Prompt design to generate stunning illustrations with DALL-E</li>
<li class="bulletList">Leveraging ChatGPT as a designer assistant</li>
<li class="bulletList">Exploring advanced plugins within the GPT store</li>
</ul>
<p class="normal">By the end of this chapter, you will be able to get the most out of ChatGPT by incorporating visual input and output within your conversations.</p>
<h1 class="heading-1" id="_idParaDest-106">What is multimodality?</h1>
<p class="normal">In <em class="italic">Chapter 1</em>, while covering<a id="_idIndexMarker393"/> the latest trends and innovations, we introduced multimodality as a feature typical of large multimodal models (a subset of large foundation models), which consists of processing and generating different types of data, such as text, images, audio, and video.</p>
<div><p class="normal"><strong class="keyWord">Definition</strong></p>
<p class="normal"><strong class="keyWord">Large language models</strong> (<strong class="keyWord">LLMs</strong>) and <strong class="keyWord">large multimodal models</strong> (<strong class="keyWord">LMMs</strong>) are both<a id="_idIndexMarker394"/> part of the realm of generative <a id="_idIndexMarker395"/>AI and feature a Transformer architecture.</p>
<p class="normal">LLMs are trained on extensive textual data, enabling them to understand and generate human-like text. They are utilized in applications such as content creation, language translation, and customer service agents.</p>
<p class="normal">On the other hand, LMMs expand upon LLMs by processing and integrating multiple data types, including text, images, audio, and video. This allows them to generate images from textual descriptions, analyze videos with textual context, and create content that combines various data forms.</p>
</div>
<p class="normal">The added value of LMMs is that they can comprehensively reason about a heterogeneous surrounding environment, processing the latent semantics of circumstances rather than having siloed reasoning on each “reality asset” type. I’m aware this might sound too abstract, so let me give you an example.</p>
<p class="normal">Imagine you are sitting in a room, and you are aware of everything happening around you. You hear voices, see objects, and read a nice book. All these senses are different types of input coming to your brain. But your brain doesn’t separate them; it processes everything together, allowing you to understand your environment as a whole. For example, you might relate something you are reading in the book – let’s say, a nice landscape – to what you can see from your room’s window.</p>
<p class="normal">Now, think of an LMM as being like a person in this room. Instead of just understanding words (like reading a book), it can also “see” pictures (images), “hear” sounds (voices), and make correlations among them. All this information flows in at the same time, and the model combines it to make sense of the entire environment, just like how your brain blends everything together to help you understand what’s happening.</p>
<p class="normal">So, just like you can sit in a room and perceive it as a whole experience, an LMM can process different types of data all at once, whether it’s a picture, a piece of text, or an audio clip. It doesn’t treat these inputs <a id="_idIndexMarker396"/>separately but instead understands the full context of everything combined.</p>
<p class="normal">In the following sections, we are going to cover both monomodal and multimodal models in the context of visual creativity.</p>
<h1 class="heading-1" id="_idParaDest-107">Prompt design to generate stunning illustrations with DALL-E</h1>
<p class="normal">In the previous chapters, we learned how well-written prompts are key when it comes to generating<a id="_idIndexMarker397"/> relevant results. This holds as much for generated text as for generated images. Henceforth, when we leverage models like DALL-E 3 (the latest version of the base model DALL-E), which receives natural language instructions as input and generates images as output, writing a well-designed prompt is paramount.</p>
<div><p class="normal"><strong class="keyWord">Note</strong></p>
<p class="normal">At the time of writing this book (October 2024), DALL-E 3 is integrated into the ChatGPT application. This implies that:</p>
<ul>
<li class="bulletList">You can seamlessly interact with ChatGPT before creating the image so that you can come up with more creative ideas (we will see this scenario in the next section).</li>
<li class="bulletList">DALL-E 3 itself is built on top of ChatGPT, meaning that the latter, when prompted with an idea, will automatically generate in its backend a more refined prompt to obtain the best result when invoking DALL-E 3.</li>
</ul>
</div>
<p class="normal">Designing prompts for DALL-E 3 is a creative process that involves carefully crafting descriptions to produce visually stunning and contextually appropriate images. Let’s explore some key techniques for designing prompts that yield the best results, from setting up a subject to adjusting technical details like aspect ratios.</p>
<h2 class="heading-2" id="_idParaDest-108">Defining the subject and setting</h2>
<p class="normal">The subject is the core <a id="_idIndexMarker398"/>of any prompt. It’s the central object or concept that you want DALL-E 3 to visualize. The more specific and clear you are with your subject, the better DALL-E will be able to interpret and create an accurate image. For example, instead of just saying “a dog,” specify “a golden retriever puppy playing in a garden.” Adding elements such as the <em class="italic">setting</em> can further refine the image, like “playing in a garden filled with tulips during spring.”</p>
<p class="normal"><strong class="screenText">Example prompt</strong>: “A golden retriever puppy playing in a tulip-filled garden during springtime.”</p>
<p class="normal">This tells DALL-E not just what the subject is (the puppy) but where it exists (the garden) and in what conditions (springtime), providing a clearer context for the generated image.</p>
<p class="normal">Let’s try it in DALL-E 3 embedded in ChatGPT:</p>
<figure class="mediaobject"><img alt="" src="img/B31559_08_01.png"/></figure>
<p class="packt_figref">Figure 8.1: Example of DALL-E 3 generating an image within ChatGPT</p>
<p class="normal">The quality of the <a id="_idIndexMarker399"/>picture is already very high; however, we might want to be more specific about how the final product should look.</p>
<h2 class="heading-2" id="_idParaDest-109">Setting the mood with color and lighting</h2>
<p class="normal">Once the subject<a id="_idIndexMarker400"/> and setting are in place, the next step is to shape the mood and atmosphere of the image by controlling the <strong class="screenText">color palette</strong> and <strong class="screenText">lighting conditions</strong>. The tone of the image can change dramatically based on whether the scene is bright and vibrant or muted and calm. Colors can evoke specific emotions, while lighting conditions like soft sunlight, harsh midday light, or moody shadows can affect the overall feel of the image.</p>
<p class="normal"><strong class="screenText">Example prompt</strong>: “A golden retriever puppy playing in a tulip-filled garden during springtime, under soft morning sunlight with pastel-colored flowers.”</p>
<figure class="mediaobject"><img alt="A screenshot of a computer screen  Description automatically generated" src="img/B31559_08_02.png"/></figure>
<p class="packt_figref">Figure 8.2: Example of DALL-E 3 incorporating further details as requested</p>
<p class="normal">Here, the <a id="_idIndexMarker401"/>mention of “soft morning sunlight” creates a warm, serene mood, while “pastel-colored flowers” adds a specific color palette that enhances the atmosphere.</p>
<h2 class="heading-2" id="_idParaDest-110">Introducing camera angles and materials</h2>
<p class="normal">Incorporating <a id="_idIndexMarker402"/>technical aspects, such as the <strong class="screenText">camera perspective</strong> or the <strong class="screenText">materials</strong> used, can take your prompt from simple to sophisticated. By adding these details, you instruct DALL-E on how to render the image in a way that feels more intentional or artistic. You can specify the type of shot—whether it’s a close-up, a wide-angle view, or even a macro shot for intricate details.</p>
<p class="normal">Additionally, mentioning the material or texture, such as “canvas,” “metallic surfaces,” or “wood,” gives DALL-E instructions on how to render specific details.</p>
<p class="normal"><strong class="screenText">Example prompt</strong>: “A golden retriever puppy playing in a tulip-filled garden during springtime, shot in a close-up angle with soft focus, highlighting the texture of the flowers and fur.”</p>
<figure class="mediaobject"><img alt="A puppy in a garden of tulips  Description automatically generated" src="img/B31559_08_03.png"/></figure>
<p class="packt_figref">Figure 8.3: Example of DALL-E 3 incorporating further details as requested</p>
<p class="normal">This tells DALL-E to <a id="_idIndexMarker403"/>focus on the close-up details, enhancing texture and creating an intimate shot.</p>
<h2 class="heading-2" id="_idParaDest-111">Infusing artistic influence</h2>
<p class="normal">Another technique <a id="_idIndexMarker404"/>to improve prompt engineering is to borrow from established art styles or specific artists. By referencing a <strong class="screenText">particular artist </strong>or <strong class="screenText">art movement</strong>, you can imbue the image with distinct characteristics, such as the brush strokes of Van Gogh or the abstract shapes of Picasso. Alternatively, you can direct DALL-E to follow a broader artistic movement, like Impressionism, Surrealism, or Photorealism, depending on the style you want.</p>
<p class="normal"><strong class="screenText">Example prompt</strong>: “A golden retriever puppy playing in a tulip-filled garden during springtime, painted in an impressionist style. The scene features soft, dappled sunlight filtering through the flowers, with blurred and vibrant tulip petals.”</p>
<figure class="mediaobject"><img alt="" src="img/B31559_08_04.png"/></figure>
<p class="packt_figref">Figure 8.4: Example of DALL-E 3 incorporating further details as requested</p>
<p class="normal">This will guide <a id="_idIndexMarker405"/>DALL-E to emulate the Impressionist style, with its focus on light, color, and the soft blending of shapes, creating a dreamlike quality to the image.</p>
<h2 class="heading-2" id="_idParaDest-112">Setting the cultural and historical context</h2>
<p class="normal">Adding a <strong class="screenText">cultural</strong> or <strong class="screenText">historical context</strong> to your prompt can deepen the meaning and influence the<a id="_idIndexMarker406"/> final image. Whether you’re creating something with a historical theme, like “medieval Europe,” or a futuristic vibe with “sci-fi city,” including these elements helps the AI model understand the time period, architecture, and style of the setting.</p>
<p class="normal"><strong class="screenText">Example prompt:</strong> “A golden retriever puppy playing in a tulip-filled garden in 18th-century Europe, surrounded by ornate stone fountains and baroque architecture.”</p>
<figure class="mediaobject"><img alt="A screenshot of a phone  Description automatically generated" src="img/B31559_08_05.png"/></figure>
<p class="packt_figref">Figure 8.5: Example of DALL-E 3 incorporating further details as requested</p>
<p class="normal">This establishes <a id="_idIndexMarker407"/>not only a time period but also cultural references like Baroque architecture, giving DALL-E specific visual cues for style and detail.</p>
<h2 class="heading-2" id="_idParaDest-113">Choosing a medium and form</h2>
<p class="normal">Another powerful<a id="_idIndexMarker408"/> technique in prompt engineering is specifying the <strong class="screenText">medium</strong> in which the image is “created.” This could be anything from photography, painting, or even sculpture. Each medium has its own set of textures, forms, and visual rules, which DALL-E can emulate. Similarly, describing the <strong class="screenText">form </strong>or <strong class="screenText">shape</strong> of objects can guide the composition further.</p>
<p class="normal"><strong class="screenText">Example prompt</strong>: “A golden retriever puppy playing in a tulip-filled garden during springtime, captured as a digital painting with soft brushstrokes and vibrant color contrasts.”</p>
<figure class="mediaobject"><img alt="A dog in a garden of tulips  Description automatically generated" src="img/B31559_08_06.png"/></figure>
<p class="packt_figref">Figure 8.6: Example of DALL-E 3 incorporating further details as requested</p>
<p class="normal">Here, the choice <a id="_idIndexMarker409"/>of medium—digital painting—gives DALL-E instructions on how to construct the image, ensuring that it reflects the textures and techniques commonly associated with digital art.</p>
<h2 class="heading-2" id="_idParaDest-114">Adding style, techniques, and aspect ratio</h2>
<p class="normal">Lastly, the finishing <a id="_idIndexMarker410"/>touches for a well-crafted prompt <a id="_idIndexMarker411"/>often<a id="_idIndexMarker412"/> come from including details about the <strong class="screenText">style</strong>, <strong class="screenText">technique</strong>, or <strong class="screenText">aspect ratio</strong>. Whether you want the image to look like an oil painting, be rendered in photorealistic detail, or even match a specific image format like widescreen or square, these choices finalize the aesthetic direction.</p>
<p class="normal">For instance, you can instruct DALL-E to follow a particular photographic style like “black-and-white portrait photography” or request an image with a cinematic aspect ratio like “16:9” to create a widescreen landscape.</p>
<p class="normal"><strong class="screenText">Example prompt</strong>: “A golden retriever puppy playing in a tulip-filled garden during springtime, captured as a digital painting with vibrant colors, set in a widescreen 16:9 aspect ratio, resembling a panoramic landscape.”</p>
<figure class="mediaobject"><img alt="A dog running on a path in a garden  Description automatically generated" src="img/B31559_08_07.png"/></figure>
<p class="packt_figref">Figure 8.7: Example of DALL-E 3 incorporating further details as requested</p>
<p class="normal">This final <a id="_idIndexMarker413"/>touch <a id="_idIndexMarker414"/>provides <a id="_idIndexMarker415"/>DALL-E with precise instructions on how to frame and style the image.</p>
<h2 class="heading-2" id="_idParaDest-115">Combining techniques for maximum impact</h2>
<p class="normal">While each of the <a id="_idIndexMarker416"/>techniques described above can be used individually, the real power of prompt engineering comes when you combine multiple elements to produce a rich, layered description.</p>
<p class="normal"><strong class="screenText">Comprehensive example prompt</strong>: “A golden retriever puppy playing in a tulip-filled garden during springtime, shot in a close-up angle with soft focus. The image is painted in an impressionist style, featuring soft sunlight and pastel-colored flowers. The scene has loose brushstrokes, blending the puppy’s fur with the delicate tulips in a dreamy, warm atmosphere. The painting is rendered digitally in a 16:9 aspect ratio, capturing the gentle play of light and color with a soft, blurred effect reminiscent of classic impressionist art.”</p>
<figure class="mediaobject"><img alt="A puppy in a field of tulips  Description automatically generated" src="img/B31559_08_08.png"/></figure>
<p class="packt_figref">Figure 8.8: Example of DALL-E 3 incorporating further details as requested</p>
<p class="normal">By combining the<a id="_idIndexMarker417"/> subject, setting, mood, artistic influence, and technical details, this prompt gives DALL-E detailed instructions that will likely result in a highly accurate, visually appealing image.</p>
<p class="normal">Prompt engineering for DALL-E 3 is a nuanced process that requires a balance of creativity and precision. By thoughtfully combining elements such as the subject, setting, mood, style, and technical parameters, you can generate highly customized and visually compelling images.</p>
<p class="normal">However, the native integration of DALL-E 3 into ChatGPT brings much more to the table of possibilities. In fact, the true value of the integration relies on the multimodal capabilities offered by this service, and <a id="_idIndexMarker418"/>we will cover this in the upcoming section.</p>
<h1 class="heading-1" id="_idParaDest-116">Leveraging ChatGPT as a designer assistant</h1>
<p class="normal">With the advent of GPT-4 Vision and the following GPT-4o, we witnessed a huge acceleration in the field of <a id="_idIndexMarker419"/>multimodality, since these models are capable of processing both images and natural language. However, they were only able to produce text (including code, of course) as output. With the integration of DALL-E 3 into the ChatGPT experience, we now have an AI system that is capable of interacting with us with images and text (and, for the sake of completeness, also with audio) both in input and output.</p>
<p class="normal">Let’s see some concrete applications of that.</p>
<h2 class="heading-2" id="_idParaDest-117">Fashion assistant</h2>
<p class="normal">Let’s say that we<a id="_idIndexMarker420"/> work in the world of fashion, and we are asked to produce blog content around the latest trends as well as come up with new fashion ideas. We recently attended a fashion event and took some pictures as possible inspiration. Let’s see how ChatGPT can assist us in that:</p>
<ol>
<li class="numberedList" value="1">First of all, let’s ask the model to generate a short blog post about the provided outfit:</li>
</ol>
<figure class="mediaobject"><img alt="" src="img/B31559_08_09.png"/></figure>
<p class="packt_figref">Figure 8.9: Example of ChatGPT understanding an image and generating an article based on it</p>
<ol>
<li class="numberedList" value="2">Let’s now<a id="_idIndexMarker421"/> ask a more specific question about the fabric of the skirt:</li>
</ol>
<figure class="mediaobject"><img alt="A screenshot of a chat  Description automatically generated" src="img/B31559_08_10.png"/></figure>
<p class="packt_figref">Figure 8.10: Example of ChatGPT analyzing the fabric of the skirt in the image</p>
<ol>
<li class="numberedList" value="3">Now we want our <a id="_idIndexMarker422"/>model to generate an illustration to reproduce the outfit with an oil painting style:</li>
</ol>
<figure class="mediaobject"><img alt="" src="img/B31559_08_11.png"/></figure>
<p class="packt_figref">Figure 8.11: Example of DALL-E 3 generating an illustration based on a provided image</p>
<ol>
<li class="numberedList" value="4">Ask for some adjustments:</li>
</ol>
<figure class="mediaobject"><img alt="A person wearing a dress  Description automatically generated" src="img/B31559_08_12.png"/></figure>
<p class="packt_figref">Figure 8.12: Example of DALL-E 3 refining the image as per request</p>
<ol>
<li class="numberedList" value="5">Now let’s <a id="_idIndexMarker423"/>extend the outfit with some accessories:</li>
</ol>
<figure class="mediaobject"><img alt="A close-up of a person's handbag  Description automatically generated" src="img/B31559_08_13.png"/></figure>
<p class="packt_figref">Figure 8.13: Example of DALL-E 3 adding details to the image</p>
<ol>
<li class="numberedList" value="6">Finally, let’s generate <a id="_idIndexMarker424"/>a brand-new outfit:</li>
</ol>
<figure class="mediaobject"><img alt="" src="img/B31559_08_14.png"/></figure>
<p class="packt_figref">Figure 8.14: Example of DALL-E 3 generating a brand-new outfit</p>
<p class="normal">The quality of the picture and the text comprehension capabilities of the model have been increasingly improving over the last months, and you can now appreciate the multimodal collaboration<a id="_idIndexMarker425"/> between GPT-4o and DALL-E 3 within the same user interface.</p>
<p class="normal">Note that, similarly to other tasks explored in previous chapters, the above example can be an iterative process, where we ask ChatGPT to further refine the result according to our requirements.</p>
<h2 class="heading-2" id="_idParaDest-118">UX designer</h2>
<p class="normal">In <em class="italic">Chapter 5</em>, we explored<a id="_idIndexMarker426"/> how we can leverage ChatGPT to generate, optimize, and debug code. This can be, of course, paired with more sophisticated assistance when it comes to the<strong class="keyWord"> user-experience</strong> (<strong class="keyWord">UX</strong>) design of a website that we would like to build. For example, even before generating the code, we might want to ask ChatGPT how to organize the UX, which color palette to use, the overall style of the components, and so on.</p>
<p class="normal">Let’s say that we want to develop our portfolio landing page and engage ChatGPT in a brainstorming session:</p>
<ol>
<li class="numberedList" value="1">I will first ask ChatGPT to suggest some design styles for my tech portfolio (truncated output):</li>
</ol>
<figure class="mediaobject"><img alt="" src="img/B31559_08_15.png"/></figure>
<p class="packt_figref">Figure 8.15: Example of ChatGPT suggesting different styles for my website</p>
<ol>
<li class="numberedList" value="2">Let’s go for a <a id="_idIndexMarker427"/>minimalist and sleek design. Now I want some inspiration for the color palette (output truncated):</li>
</ol>
<figure class="mediaobject"><img alt="" src="img/B31559_08_16.png"/></figure>
<p class="packt_figref">Figure 8.16: Example of ChatGPT suggesting different palettes for a minimalist UX</p>
<ol>
<li class="numberedList" value="3">Let’s go <a id="_idIndexMarker428"/>with option 1, and let’s ask the model to suggest some further UX features I should embed in my portfolio (truncated output):</li>
</ol>
<figure class="mediaobject"><img alt="" src="img/B31559_08_17.png"/></figure>
<p class="packt_figref">Figure 8.17: Example of ChatGPT suggesting features to incorporate in the UX</p>
<ol>
<li class="numberedList" value="4">Now I would<a id="_idIndexMarker429"/> love to see a draft of my website. As we have learned, we can ask the model to generate the code to build it; however, before that, we might want to have a visual representation so that we can have an idea of the final product we are aiming for. Let’s see whether the embedded DALL-E 3 model is capable of doing so:</li>
</ol>
<figure class="mediaobject"><img alt="" src="img/B31559_08_18.png"/></figure>
<p class="packt_figref">Figure 8.18: Example of a visual draft of how our UX might look</p>
<p class="normal">Well, as you might have noticed, the image model still struggles when it comes to generating text. However, it still managed to produce a design that is in line with my preferences – a minimal, classic<a id="_idIndexMarker430"/> palette with a touch of blue and provided with additional UX features.</p>
<p class="normal">In the next paragraph, we will see some further examples of the UX design capabilities of ChatGPT, especially when we incorporate them into existing web designer platforms like Wix or Canva.</p>
<h2 class="heading-2" id="_idParaDest-119">Style transfer</h2>
<p class="normal">The last example I <a id="_idIndexMarker431"/>want to show you is how you can transfer the style of one illustration to another. This might be useful if you are developing a set of illustrations with a consistent style, and then you get really impressed by a visual you would like to include in your list. However, this visual doesn’t match the style you have been consistently applying to all the illustrations. If this is the case, you can provide ChatGPT with an example of your style and the illustration you want to apply it to and ask for a style transfer.</p>
<p class="normal">Let’s see this in practice. Imagine we are working with illustrations in a sketchy style like the following:</p>
<figure class="mediaobject"><img alt="" src="img/B31559_08_19.png"/></figure>
<p class="packt_figref">Figure 8.19: Example of a sketchy style illustration</p>
<p class="normal">Then you find a <a id="_idIndexMarker432"/>very nice illustration you would love to include in your set:</p>
<figure class="mediaobject"><img alt="A boat in the ocean  Description automatically generated" src="img/B31559_08_20.png"/></figure>
<p class="packt_figref">Figure 8.20: Example of an illustration you would like to have in a different style</p>
<p class="normal">Let’s see what happens if we ask ChatGPT to transfer the style:</p>
<figure class="mediaobject"><img alt="A screenshot of a ship  Description automatically generated" src="img/B31559_08_21.png"/></figure>
<p class="packt_figref">Figure 8.21: Example of style transfer with DALL-E 3</p>
<p class="normal">Nice! As you can<a id="_idIndexMarker433"/> see, the new illustration is perfectly in line with the sketchy style I’m applying to my illustration set.</p>
<p class="normal">The cool thing about style transfer is that you can apply it even if you don’t have a reference picture. For example, let’s say you want to apply to your illustration the style of Expressionism.</p>
<p class="normal">Let’s ask ChatGPT to transfer this style to the boat illustration, without providing the above reference image:</p>
<figure class="mediaobject"><img alt="A screenshot of a computer screen  Description automatically generated" src="img/B31559_08_22.png"/></figure>
<p class="packt_figref">Figure 8.22: Example of style transfer with DALL-E 3</p>
<p class="normal">Now, all of these visual assistants can be useful as a standalone chatbot; however, it would be far more seamless to have them integrated with the software that we typically use for previous activities, like Photoshop for image editing or Canva for visuals.</p>
<p class="normal">Another way you can achieve this further integration is by leveraging plugins and building your own GPTs from the GPT store. We will cover GPTs in the next chapter, so I won’t dive deeply into what they are and how to create your own GPT from scratch; however, in the next section, I will show <a id="_idIndexMarker434"/>you some pre-built and publicly available GPTs that offer exactly this type of seamless integration with third-party services and that can boost your visual creativity.</p>
<h1 class="heading-1" id="_idParaDest-120">Exploring advanced plugins within the GPT store</h1>
<p class="normal">In January 2024, OpenAI<a id="_idIndexMarker435"/> introduced the GPTs, which can be defined as specialized and customized versions of ChatGPT. Users can create their own GPT by specifying a system message, a set of actions, the tone, and other features that we are going to cover. Once you create your GPT, you can make it public via the GPT store, a nice marketplace that is available to all users with ChatGPT Plus.</p>
<p class="normal">You can access the store at <a href="https://chatgpt.com/gpts">https://chatgpt.com/gpts</a> and, from there, navigate through many GPTs developed both by consumers and companies. In this section, we are going to cover some interesting GPTs developed by companies working in the visual design field and integrating generative <a id="_idIndexMarker436"/>AI via plugins (in GPT jargon, these plugins are called “actions.” We will cover this topic in the next chapter.).</p>
<h2 class="heading-2" id="_idParaDest-121">Canva</h2>
<p class="normal"><strong class="keyWord">Canva</strong> is a graphic design platform that was launched in Australia in 2013. It aims to democratize design, making<a id="_idIndexMarker437"/> it accessible to everyone, regardless<a id="_idIndexMarker438"/> of their skill level. Canva offers a wide array of tools and templates for creating everything from social media graphics and presentations to posters, promotional items, and even websites.</p>
<p class="normal">One of Canva’s key features is its intuitive drag-and-drop interface, which allows users to easily customize their designs. Whether you’re using a computer or a mobile device, Canva provides a seamless experience through its web and mobile apps. Additionally, Canva includes robust photo and video editing capabilities, making it a comprehensive tool for all your design needs.</p>
<figure class="mediaobject"><img alt="" src="img/B31559_08_23.png"/></figure>
<p class="packt_figref">Figure 8.23: Canva plugin</p>
<p class="normal">Let’s <a id="_idIndexMarker439"/>test <a id="_idIndexMarker440"/>it:</p>
<figure class="mediaobject"><img alt="A screenshot of a social media post  Description automatically generated" src="img/B31559_08_24.png"/></figure>
<p class="packt_figref">Figure 8.24: Example of ChatGPT leveraging the Canva plugin</p>
<p class="normal">You can also <a id="_idIndexMarker441"/>expand the <strong class="keyWord">Talked to chatgpt-plugin.canva.com</strong> tab <a id="_idIndexMarker442"/>to see the configuration of the API call (as we will see in the next chapter, GPT actions are REST API calls at their core).</p>
<figure class="mediaobject"><img alt="A screenshot of a computer  Description automatically generated" src="img/B31559_08_25.png"/></figure>
<p class="packt_figref">Figure 8.25: Details of the Canva plugin’s API call</p>
<p class="normal">What the Canva GPT does is retrieve some options from Canva’s templates for you, according to your request in natural language. Plus, it will add a caption to make it relevant to your topic. Once <a id="_idIndexMarker443"/>you have identified one proposal that <a id="_idIndexMarker444"/>matches your needs, you can click on it and keep editing directly in Canva:</p>
<figure class="mediaobject"><img alt="A screenshot of a computer  Description automatically generated" src="img/B31559_08_26.png"/></figure>
<p class="packt_figref">Figure 8.26: Example of the Canva plugin’s output</p>
<p class="normal">The Canva GPT is a <a id="_idIndexMarker445"/>very useful tool to start drafting your visual in <a id="_idIndexMarker446"/>natural language, and its seamless integration with the Canva platform allows you to keep the flow without losing ideas across different platforms.</p>
<h2 class="heading-2" id="_idParaDest-122">Wix</h2>
<p class="normal"><strong class="keyWord">Wix</strong> is a leading<a id="_idIndexMarker447"/> cloud-based web development <a id="_idIndexMarker448"/>platform that empowers users to create stunning, professional websites with ease. Founded in 2006, Wix has revolutionized the way people build and manage their online presence. With its intuitive drag-and-drop interface, users can design websites without needing any coding skills.</p>
<p class="normal">Wix offers a wide range of customizable templates and advanced features, including e-commerce capabilities, SEO tools, and integrated marketing solutions. Whether you’re a small business owner, artist, blogger, or entrepreneur, Wix provides the tools you need to bring your vision to life and reach your audience effectively.</p>
<figure class="mediaobject"><img alt="A screenshot of a website builder  Description automatically generated" src="img/B31559_08_27.png"/></figure>
<p class="packt_figref">Figure 8.27: Wix plugin</p>
<p class="normal">Leveraging the conversational model behind ChatGPT, Wix allows customers to co-design their website with ChatGPT while creating the backend directly in Wix. Once the conversation and co-creation is over, the user can directly jump to the final website and keep editing it in Wix.</p>
<p class="normal">Let’s say, for example, that we want to design a portfolio to show our work:</p>
<figure class="mediaobject"><img alt="A screenshot of a chat  Description automatically generated" src="img/B31559_08_28.png"/></figure>
<p class="packt_figref">Figure 8.28: Example of an interaction with the Wix plugin</p>
<p class="normal">Since these very first interactions, I’ve set the stage for a co-design session with my GPT, which is, in this case, customized<a id="_idIndexMarker449"/> in such a way that it will also keep <a id="_idIndexMarker450"/>asking me useful questions to build the final product. Among the names suggested, I think I’ll go with Coded Creations.</p>
<figure class="mediaobject"><img alt="A screenshot of a chat  Description automatically generated" src="img/B31559_08_29.png"/></figure>
<p class="packt_figref">Figure 8.29: Example of the Wix plugin generating a website</p>
<p class="normal">Once it had gathered some further information, the GPT generated my website on Wix and provided me with the link. Also, in this case, you can expand the <strong class="keyWord">Talked to wix.com</strong> tab to see the configuration of the call (as we will see in the next chapter, GPT actions are REST API calls at their core).</p>
<figure class="mediaobject"><img alt="A screenshot of a computer  Description automatically generated" src="img/B31559_08_30.png"/></figure>
<p class="packt_figref">Figure 8.30: Details of the Wix plugin’s API call</p>
<p class="normal">Let’s have<a id="_idIndexMarker451"/> a look at<a id="_idIndexMarker452"/> the result:</p>
<figure class="mediaobject"><img alt="A screenshot of a computer  Description automatically generated" src="img/B31559_08_31.png"/></figure>
<p class="packt_figref">Figure 8.31: Example of the Wix plugin’s final output</p>
<p class="normal">And that’s it! Now you can keep working on this design or ask the AI embedded in Wix to regenerate it with some slight modifications. Alternatively, you can modify it directly via ChatGPT as follows:</p>
<figure class="mediaobject"><img alt="A screenshot of a computer  Description automatically generated" src="img/B31559_08_32.png"/></figure>
<p class="packt_figref">Figure 8.32: Example of the Wix plugin adjusting the API call as per the user’s request</p>
<p class="normal">As you can see<a id="_idIndexMarker453"/> from <a id="_idIndexMarker454"/>the API call reference, the <strong class="keyWord">lookAndFeel</strong> field has changed to what we asked for. Let’s have a look at the result:</p>
<figure class="mediaobject"><img alt="A screenshot of a website  Description automatically generated" src="img/B31559_08_33.png"/></figure>
<p class="packt_figref">Figure 8.33: Example of the Wix plugin’s adjusted output</p>
<p class="normal">And that’s it! In just<a id="_idIndexMarker455"/> a few interactions, we created and <a id="_idIndexMarker456"/>modified the first draft of our landing page. Again, you will always have the possibility to further customize, but starting from something other than a blank page is often way more productive.</p>
<h2 class="heading-2" id="_idParaDest-123">Veed.io</h2>
<p class="normal"><strong class="keyWord">Veed.io</strong> is an innovative <a id="_idIndexMarker457"/>online video editing platform<a id="_idIndexMarker458"/> that empowers creators of all skill levels to produce professional-quality videos. Founded in 2017 and headquartered in London, England, Veed.io has quickly made a name for itself in the digital content creation space. The platform aims to simplify the video editing process with an array of user-friendly tools and features. From automatic subtitles and text-to-video capabilities to screen recording and background noise removal, Veed.io provides the resources needed to bring creative visions to life. With its focus on accessibility and ease of use, Veed.io is transforming the way videos are made, making high-quality production achievable for everyone.</p>
<figure class="mediaobject"><img alt="A screenshot of a video chat  Description automatically generated" src="img/B31559_08_34.png"/></figure>
<p class="packt_figref">Figure 8.34: The Veed.io plugin</p>
<p class="normal">Let’s <a id="_idIndexMarker459"/>test <a id="_idIndexMarker460"/>it:</p>
<figure class="mediaobject"><img alt="A screenshot of a chat  Description automatically generated" src="img/B31559_08_35.png"/></figure>
<p class="packt_figref">Figure 8.35: Example of the Veed.io plugin asking for further details to proceed with the API call</p>
<p class="normal">As you can see, the<a id="_idIndexMarker461"/> GPT asked me for further details to<a id="_idIndexMarker462"/> make sure it can complete the task. Once provided with the required information, the GPT goes ahead and generates the final video:</p>
<figure class="mediaobject"><img alt="A screenshot of a video project  Description automatically generated" src="img/B31559_08_36.png"/></figure>
<p class="packt_figref">Figure 8.36: Example of the Veed.io plugin generating the final output</p>
<p class="normal">Let’s inspect <a id="_idIndexMarker463"/>the <a id="_idIndexMarker464"/>API call:</p>
<figure class="mediaobject"><img alt="A screenshot of a message  Description automatically generated" src="img/B31559_08_37.png"/></figure>
<p class="packt_figref">Figure 8.37: Details of the Veed.io plugin’s API call</p>
<p class="normal">Let’s see <a id="_idIndexMarker465"/>the <a id="_idIndexMarker466"/>result:</p>
<figure class="mediaobject"><img alt="A screenshot of a computer  Description automatically generated" src="img/B31559_08_38.png"/></figure>
<p class="packt_figref">Figure 8.38: Example of the Veed.io plugin’s output</p>
<p class="normal">Once you click <a id="_idIndexMarker467"/>on the link, you will be directed to the<a id="_idIndexMarker468"/> editing page of your new video. The voice-over is the female avatar we indicated to our GPT, and you can see that the video already includes many different scenes and visual effects.</p>
<p class="normal">Those were just three examples out of the numerous visual GPTs that you can find in the marketplace. Many companies are publishing their own GPTs to allow seamless integration with their platform, and they are worth exploring!</p>
<h1 class="heading-1" id="_idParaDest-124">Summary</h1>
<p class="normal">Leveraging ChatGPT as a visual assistant can boost your productivity while keeping your creativity spark.</p>
<p class="normal">By mastering prompt design, you can generate stunning, tailor-made illustrations that cater to your exact needs. Whether you’re working on branding, content creation, or artistic projects, ChatGPT acts as a reliable designer assistant, simplifying complex tasks while enabling high-quality output.</p>
<p class="normal">Furthermore, exploring advanced plugins within the GPT store elevates the experience, offering specialized tools for an even broader range of creative possibilities. In fact, the real value of ChatGPT design and its visual capabilities (and of its capabilities in general) is unleashed when we can integrate them into our own tools and processes, unlocking a seamless productivity flow. As demonstrated in this chapter, this can be achieved through GPTs’ actions and, more broadly, with GPTs – a topic we will cover in more detail in the next chapter.</p>
<h1 class="heading-1" id="_idParaDest-125">References</h1>
<ul>
<li class="bulletList">The Role of Likes: How Online Feedback Impacts Users' Mental Health: <a href="https://arxiv.org/abs/2312.11914">https://arxiv.org/abs/2312.11914</a></li>
<li class="bulletList">Towards Facilitating Empathic Conversations in Online Mental Health Support: A Reinforcement Learning Approach: <a href="https://arxiv.org/abs/2101.07714">https://arxiv.org/abs/2101.07714</a></li>
<li class="bulletList">The Second Machine Age: Work, Progress, and Prosperity in a Time of Brilliant Technologies: <a href="https://psycnet.apa.org/record/2014-07087-000">https://psycnet.apa.org/record/2014-07087-000</a></li>
<li class="bulletList">The Impact of Technostress on Role Stress and Productivity: <a href="https://www.tandfonline.com/doi/abs/10.2753/MIS0742-1222240109">https://www.tandfonline.com/doi/abs/10.2753/MIS0742-1222240109</a></li>
<li class="bulletList">The Big Debate about the Future of Work, explained: <a href="https://www.youtube.com/watch?v=TUmyygCMMGA">https://www.youtube.com/watch?v=TUmyygCMMGA</a></li>
</ul>
</div>
</body></html>