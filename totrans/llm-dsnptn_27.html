<html><head></head><body><div><div><div><h1 id="_idParaDest-307" class="chapter-number"><a id="_idTextAnchor378"/>27</h1>
			<h1 id="_idParaDest-308"><a id="_idTextAnchor379"/>Graph-Based RAG</h1>
			<p>In this chapter, we’ll learn how to leverage graph-structured knowledge in RAG for LLMs. You’ll learn about graph-based knowledge representation and how to design RAG architectures that can utilize this structured information.</p>
			<p>A graph-based knowledge representation structures information as nodes and edges in a graph, where nodes represent concepts or facts and edges capture their relationships. When used with RAG, this approach enables richer information retrieval by leveraging both the individual pieces of information and their interconnections, allowing for more contextual and relationship-aware responses.</p>
			<p>We’ll cover graph embedding techniques for retrieval, query expansion using graph structures, and methods for integrating graph information into LLM generation. You’ll also explore various applications and use cases of graph RAG in LLMs.</p>
			<p>By the end of this chapter, you’ll be able to implement advanced RAG systems that can leverage the rich relationships in graph-structured data.</p>
			<p> In this chapter, we’ll be covering the following topics:</p>
			<ul>
				<li>Introduction to graph-based knowledge representation for LLMs</li>
				<li>Designing graph RAG architectures for LLMs</li>
				<li>Graph embedding techniques for LLM retrieval</li>
				<li>Query expansion using graph structures in LLMs</li>
				<li>Integrating graph information into LLM generation</li>
				<li>Applications and use cases of graph RAG in LLMs</li>
				<li>Challenges and future directions in graph-based RAG</li>
			</ul>
			<h1 id="_idParaDest-309"><a id="_idTextAnchor380"/>Introduction to graph-based knowledge representation for LLMs</h1>
			<p>Graph-based knowledge representation<a id="_idIndexMarker1234"/> allows complex relationships to be encoded between concepts and facts, which can significantly enhance the contextual understanding of LLMs. In a graph, nodes represent entities, and edges represent relationships between them.</p>
			<div><div><img src="img/B31249_27_01.jpg" alt="Figure 27.1 – Graph-based knowledge representation for LLMs" width="1567" height="569"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 27.1 – Graph-based knowledge representation for LLMs</p>
			<p>The following are the key<a id="_idIndexMarker1235"/> benefits of graph-based knowledge<a id="_idIndexMarker1236"/> for LLMs:</p>
			<ul>
				<li>Captures complex relationships</li>
				<li>Enables multi-hop reasoning</li>
				<li>Provides structured context for generation</li>
				<li>Facilitates domain-specific knowledge integration</li>
			</ul>
			<p>Let’s start by implementing a simple graph structure:</p>
			<pre class="source-code">
from typing import Dict, List, Tuple
class KnowledgeGraph:
    def __init__(self):
        self.nodes: Dict[str, Dict] = {}
        self.edges: Dict[str, List[Tuple[str, str]]] = {}
    def add_node(self, node_id: str, properties: Dict):
        self.nodes[node_id] = properties
    def add_edge(self, source: str, target: str, relation: str):
        if source not in self.edges:
            self.edges[source] = []
        self.edges[source].append((target, relation))<a id="_idTextAnchor381"/>
    def get_neighbors(
        self, node_id: str) -&gt; List[Tuple[str, str]
    ]:
        return self.edges.get(node_id, [])
# Example usage
kg = KnowledgeGraph()
kg.add_node("Paris", {"type": "City", "country": "France"})
kg.add_node("France", {"type": "Country", "continent": "Europe"})
kg.add_edge("Paris", "France", "capital_of")
print(kg.get_neighbors("Paris"))</pre>			<p>This code implements a foundational <code>KnowledgeGraph</code> class in Python, allowing knowledge to be represented as a network of interconnected entities. The class uses dictionaries to store nodes and <a id="_idIndexMarker1237"/>edges, where nodes are identified by unique IDs and hold associated properties, and edges define relationships between nodes through source, target, and relation labels. The <code>add_node</code> method populates the <code>nodes</code> dictionary, while <code>add_edge</code> establishes connections within the <code>edges</code> dictionary. The <code>get_neighbors</code> method allows nodes directly connected to a given node to be retrieved, along with the corresponding relationship types.</p>
			<p>This example demonstrates how to create a graph, add nodes representing <code>Paris</code> and <code>France</code>, define the <code>capital_of</code> relationship between them, and then query the graph to find neighbors of <code>Paris</code>. This structure provides a basis for encoding complex relationships and facilitating knowledge-aware applications.</p>
			<p>Next, we’ll discuss how to design graph RAG architecture.</p>
			<h1 id="_idParaDest-310"><a id="_idTextAnchor382"/>Designing graph RAG architectures for LLMs</h1>
			<p>To design a graph RAG system, we <a id="_idIndexMarker1238"/>need to integrate our knowledge graph with the retrieval and generation components:</p>
			<pre class="source-code">
import networkx as nx
from sentence_transformers import SentenceTransformer
import torch
class GraphRAG:
    def __init__(self, kg: KnowledgeGraph, model_name: str):
        self.kg = kg
        self.model = SentenceTransformer(model_name)
        self.graph = self.build_networkx_graph()
        self.node_embeddings = self.compute_node_embeddings()
    def build_networkx_graph(self):
        G = nx.DiGraph()
        for node_id, properties in self.kg.nodes.items():
            G.add_node(node_id, properties)
        for source, edges in self.kg.edges.items():
            for target, relation in edges:
                G.add_edge(source, target, relation=relation)
        return G
    def compute_node_embeddings(self):
        embeddings = {}
        for node_id, properties in self.kg.nodes.items():
            text = f"{node_id} {' '.join(properties.values())}"
            embedding = self.model.encode(text)
            embeddings[node_id] = embedding
        return embeddings
    def retrieve(self, query: str, k: int = 5) -&gt; List[str]:
        query_embedding = self.model.encode(query)
        similarities = {
            node_id: torch.cosine_similarity(
                torch.tensor(query_embedding),
                torch.tensor(emb), dim=0
            )
            for node_id, emb in self.node_embeddings.items()}
        return sorted(
            similarities, key=similarities.get, reverse=True
        )[:k]
# Example usage
kg = KnowledgeGraph()
# Add more nodes and edges to the knowledge graph
graph_rag = GraphRAG(kg, "all-MiniLM-L6-v2")
retrieved_nodes = graph_rag.retrieve("What is the capital of France?")
print("Retrieved nodes:", retrieved_nodes)</pre>			<p>In the preceding code, we used the NetworkX Python package. The NetworkX package is designed for creating, manipulating, and studying the structure, dynamics, and functions of complex networks. It provides<a id="_idIndexMarker1239"/> tools for working with graphs, which are collections of nodes (vertices) and edges (connections between nodes), and offers a wide range of algorithms for analyzing network properties, making it invaluable for fields such as social network analysis, biology, and infrastructure studies.</p>
			<p>This code defines a <code>GraphRAG</code> class that combines a <code>KnowledgeGraph</code> object with a Sentence Transformer model to enable context-aware information retrieval. The class initializes with a <code>KnowledgeGraph</code> object and a Sentence Transformer model name, which it uses to build a <code>networkx</code> graph representation of the knowledge graph and compute embeddings for each node based on its ID and properties. The <code>build_networkx_graph</code> method converts the custom <code>KnowledgeGraph</code> object into a <code>networkx</code> directed graph, preserving node properties and edge relationships. The <code>compute_node_embeddings</code> method generates embeddings for each node by concatenating its ID and properties into a text string and encoding it using the Sentence Transformer model.</p>
			<p>The <code>retrieve</code> method takes a query, encodes it using the same Sentence Transformer, calculates the cosine similarity between the query embedding and each node embedding, and returns the top <em class="italic">k</em> most similar node IDs. This architecture leverages graph structure and semantic embeddings to retrieve relevant knowledge based on query context, bridging the <a id="_idIndexMarker1240"/>gap between symbolic knowledge representation and neural information retrieval.</p>
			<p>Now, let’s explore more advanced techniques for representing our graph data to further enhance the performance of our LLM retrieval system. Specifically, we’ll delve into graph embedding techniques for LLM retrieval.</p>
			<h1 id="_idParaDest-311"><a id="_idTextAnchor383"/>Graph embedding techniques for LLM retrieval</h1>
			<p>Graph embedding techniques aim to represent the nodes of a graph in a low-dimensional vector space, capturing<a id="_idIndexMarker1241"/> the graph’s structural properties and relationships. Several methods exist, each with its own approach – for<a id="_idIndexMarker1242"/> instance, <strong class="bold">Node2Vec</strong> explores neighborhoods through biased random walks, balancing <a id="_idIndexMarker1243"/>breadth-first and depth-first exploration. <strong class="bold">DeepWalk</strong> is another random-walk-based approach but performs walks uniformly. <strong class="bold">Graph convolutional networks</strong> (<strong class="bold">GCNs</strong>) aggregate information from a node’s neighbors <a id="_idIndexMarker1244"/>using convolutional operations, learning node embeddings based on the graph’s structure and node features. <strong class="bold">Graph attention networks</strong> (<strong class="bold">GATs</strong>) extend<a id="_idIndexMarker1245"/> GCNs by incorporating an attention mechanism to weigh the importance of different neighbors when aggregating information. <strong class="bold">Translating Embeddings for Knowledge Graphs</strong> (<strong class="bold">TransE</strong>) is <a id="_idIndexMarker1246"/>specifically designed for knowledge graphs, representing entities and relations as vectors such that if (<em class="italic">h</em>, <em class="italic">r</em>, <em class="italic">t</em>) holds (head, relation, tail), then <em class="italic">h + r ≈ </em><em class="italic">t</em>.</p>
			<p>Let’s focus on <strong class="bold">Node2Vec</strong> as an <a id="_idIndexMarker1247"/>example. Node2Vec aims to create embeddings that preserve network neighborhoods. It achieves this by employing biased random walks that <a id="_idIndexMarker1248"/>balance <strong class="bold">breadth-first search</strong> (<strong class="bold">BFS</strong>) and <strong class="bold">depth-first search</strong> (<strong class="bold">DFS</strong>). BFS prioritizes<a id="_idIndexMarker1249"/> exploring immediate neighbors and capturing local structural information, while DFS explores distant nodes, thereby capturing higher-order dependencies and community structures. The bias is controlled by two parameters, <em class="italic">p</em> (return parameter) and <em class="italic">q</em> (in-out parameter), which influence the likelihood of revisiting the previous node or exploring distant nodes, respectively. By learning embeddings that reflect these biased random walks, Node2Vec <a id="_idIndexMarker1250"/>captures both local and global network structures, allowing for effective node classification, link prediction, and community detection:</p>
			<pre class="source-code">
from node2vec import Node2Vec
class AdvancedGraphRAG(GraphRAG):
    def __init__(self, kg: KnowledgeGraph, model_name: str):
        super().__init__(kg, model_name)
        self.node2vec_embeddings = self.compute_node2vec_embeddings()
    def compute_node2vec_embeddings(self):
        node2vec = Node2Vec(
            self.graph, dimensions=64, walk_length=30,
            num_walks=200, workers=4
        )
        model = node2vec.fit(window=10, min_count=1)
        return {node: model.wv[node]
            for node in self.graph.nodes()
        }
    def retrieve(self, query: str, k: int = 5) -&gt; List[str]:
        query_embedding = self.model.encode(query)
        combined_similarities = {}
        for node_id in self.graph.nodes():
            text_sim = torch.cosine_similarity(
                torch.tensor(query_embedding),
                torch.tensor(self.node_embeddings[node_id]),
                dim=0
            )
            graph_sim = torch.cosine_similarity(
                torch.tensor(query_embedding),
                torch.tensor(self.node2vec_embeddings[node_id]),
                dim=0
            )
            combined_similarities[node_id] = \
                0.5 * text_sim + 0.5 * graph_sim
        return sorted(
            combined_similarities,
            key=combined_similarities.get,
            reverse=True
        )[:k]
# Example usage
advanced_graph_rag = AdvancedGraphRAG(kg, "all-MiniLM-L6-v2")
retrieved_nodes = advanced_graph_rag.retrieve("What is the capital of France?")
print("Retrieved nodes:", retrieved_nodes)</pre>			<p>This code builds upon the <code>GraphRAG</code> class by incorporating <code>Node2Vec</code> embeddings for enhanced retrieval performance. It introduces an <code>AdvancedGraphRAG</code> class that inherits from <code>GraphRAG</code> and computes <code>Node2Vec</code> embeddings during initialization. The <code>compute_node2vec_embeddings</code> method utilizes the <code>node2vec</code> library to generate these embeddings, creating a <code>Node2Vec</code> object with specified dimensions, walk length, number of walks, and worker threads; it then trains the Node2Vec model by using random walks on the graph structure and extracts the learned node embeddings. The <code>retrieve</code> method is overridden to combine both the original text-based embeddings and the <code>Node2Vec</code> embeddings for similarity calculation. For each node, it computes the cosine similarity between the query embedding and both the text-based embedding and the <code>Node2Vec</code> embedding, then averages these two similarity scores with equal weights<a id="_idIndexMarker1251"/> to produce a combined similarity score. Finally, it returns the top <em class="italic">k</em> nodes with the highest combined similarity scores, leveraging both semantic and structural information for more effective retrieval.</p>
			<p>Now, let’s explore how we can further improve retrieval by leveraging the graph structure to refine our queries. In the next section, we’ll implement a simple yet effective technique to broaden the scope of our search.</p>
			<h1 id="_idParaDest-312"><a id="_idTextAnchor384"/>Query expansion using graph structures in LLMs</h1>
			<p>We can leverage graph<a id="_idIndexMarker1252"/> structures to expand queries <a id="_idIndexMarker1253"/>and improve retrieval. Let’s implement a simple query expansion technique:</p>
			<pre class="source-code">
import random
class QueryExpansionGraphRAG(AdvancedGraphRAG):
    def expand_query(
        self, query: str, num_expansions: int = 2
    ) -&gt; List[str]:
        initial_nodes = super().retrieve(query, k=3)
        expanded_queries = [query]
        for node in initial_nodes:
            neighbors = list(self.graph.neighbors(node))
            if neighbors:
                random_neighbor = random.choice(neighbors)
                expanded_query = (
                    f"{query}"
                    f"{self.graph.nodes[random_neighbor].
                        get('type', '')}"
                    f"{random_neighbor}"
                )
                expanded_queries.append(expanded_query)
                if len(expanded_queries) &gt;= num_expansions + 1:
                    break
        return expanded_queries
    def retrieve(self, query: str, k: int = 5) -&gt; List[str]:
        expanded_queries = self.expand_query(query)
        all_retrieved = []
        for q in expanded_queries:
            all_retrieved.extend(super().retrieve(q, k))
        return list(dict.fromkeys(all_retrieved))[:k]
# Example usage
query_expansion_rag = QueryExpansionGraphRAG(kg, "all-MiniLM-L6-v2")
retrieved_nodes = query_expansion_rag.retrieve("What is the capital of France?")
print("Retrieved nodes:", retrieved_nodes)</pre>			<p>This code implements query expansion within a graph-based RAG system to enhance retrieval performance. The <code>QueryExpansionGraphRAG</code> class inherits from <code>AdvancedGraphRAG</code> and introduces an <code>expand_query</code> method that takes a query and the desired number of expansions as input. First, this method retrieves the top three most relevant nodes based on the initial query using the base class’s <code>retrieve</code> method. It then iterates through <a id="_idIndexMarker1254"/>these initial nodes, selecting a random neighbor for each and constructing an expanded query by appending the neighbor’s type (if available) and the neighbor’s ID to the original query. The <code>retrieve</code> method is overridden<a id="_idIndexMarker1255"/> to first expand the input query using the <code>expand_query</code> method. It then retrieves results for each expanded query using the base class’s <code>retrieve</code> method, concatenates the results, removes duplicates while preserving order, and returns the top <em class="italic">k</em> unique nodes. This approach leverages the graph structure to explore related concepts and broaden the search scope, potentially capturing more relevant information than a direct query alone.</p>
			<p>Query expansion is particularly useful when the initial query is too narrow or underspecified, resulting in low recall. In graph-based retrieval settings, this often occurs when the query does not explicitly mention related entities or concepts that are semantically or structurally linked in the graph. By incorporating neighboring nodes into the query formulation, the system can uncover relevant content that would otherwise be overlooked, making query expansion especially beneficial in exploratory search scenarios or domains with sparse or highly interconnected data.</p>
			<p>Now that we’ve explored techniques to enhance retrieval, let’s shift our focus to improving the generation phase. We’ll now delve into the process of integrating graph information into LLM generation, examining how we can incorporate graph knowledge directly into the generation process to create more informed and coherent responses.Integrating graph information into LLM generation</p>
			<p>To integrate graph information<a id="_idIndexMarker1256"/> into LLM generation, we<a id="_idIndexMarker1257"/> can create a prompt that incorporates<a id="_idIndexMarker1258"/> the retrieved graph context:</p>
			<pre class="source-code">
from transformers import AutoModelForCausalLM, AutoTokenizer
class GenerativeGraphRAG(QueryExpansionGraphRAG):
    def __init__(
        self, kg: KnowledgeGraph, retriever_model: 
        str, generator_model: str
    ):
        super().__init__(kg, retriever_model)
        self.generator = \
            AutoModelForCausalLM.from_pretrained(generator_model)
        self.generator_tokenizer = \
            AutoTokenizer.from_pretrained(generator_model)
    def generate_response(
        self, query: str, max_length: int = 100
    ) -&gt; str:
        retrieved_nodes = self.retrieve(query)
        context = self.build_graph_context(retrieved_nodes)
        prompt = f"Graph Context:\n{context}\n\nQuestion: {query}\nAnswer:"
        inputs = self.generator_tokenizer(
            prompt, return_tensors="pt"
        )
        outputs = self.generator.generate(
            inputs, max_length=max_length
        )
        return self.generator_tokenizer.decode(
            outputs[0], skip_special_tokens=True
        )
    def build_graph_context(self, nodes: List[str]) -&gt; str:
        context = []
        for node in nodes:
            context.append(f"Node: {node}")
            context.append(f"Properties: {self.graph.nodes[node]}")
            for neighbor, edge_data in self.graph[node].items():
                context.append(
                    f"  Related to {neighbor} by 
                    {edge_data['relation']}")
        return "\n".join(context)
# Example usage
generative_graph_rag = GenerativeGraphRAG(
    kg, "all-MiniLM-L6-v2", "gpt2-medium"
)
response = generative_graph_rag.generate_response("What is the capital of France?")
print("Generated response:", response)</pre>			<p>This code integrates an LLM for response generation within the graph-based RAG framework. The <code>GenerativeGraphRAG</code> class inherits from <code>QueryExpansionGraphRAG</code> and initializes with <code>KnowledgeGraph</code>, a retriever model name, and a generator <a id="_idIndexMarker1259"/>model name. It loads a pre-trained causal language model and its corresponding tokenizer using <code>transformers</code>. The <code>generate_response</code> method orchestrates the entire process: first, it<a id="_idIndexMarker1260"/> retrieves relevant nodes from the knowledge graph using the <code>retrieve</code> method inherited from the parent class. Then, it constructs a context string by calling <code>build_graph_context</code>, which formats the retrieved nodes, their properties, and their relationships to other nodes <a id="_idIndexMarker1261"/>into a readable text. This context is then incorporated into a prompt alongside the original query, which is fed into the pre-trained language model. The language model generates a response based on the prompt, and the generated tokens are decoded back <a id="_idIndexMarker1262"/>into a human-readable string, effectively leveraging the graph structure to inform the language model’s response generation. The <code>build_graph_context</code> method formats retrieved graph information into the <a id="_idIndexMarker1263"/>prompt, including node IDs, properties, and relationships to neighbors, providing a structured representation of the relevant knowledge to the LLM.</p>
			<p>Now that we’ve explored how to integrate graph information into the generation process, let’s consider the broader applications and potential uses of this approach.</p>
			<h1 id="_idParaDest-313"><a id="_idTextAnchor385"/>Applications and use cases of graph RAG in LLMs</h1>
			<p>Graph-based RAG can <a id="_idIndexMarker1264"/>be particularly<a id="_idIndexMarker1265"/> effective in various applications:</p>
			<ul>
				<li>Question-answering over knowledge graphs</li>
				<li>Personalized recommendation systems</li>
				<li>Scientific literature analysis</li>
				<li>Drug discovery and biomedical research</li>
				<li>Social network analysis</li>
			</ul>
			<p>Here’s an example of <a id="_idIndexMarker1266"/>how graph RAG could be used for a recommendation <a id="_idIndexMarker1267"/>system:</p>
			<pre class="source-code">
class RecommendationGraphRAG(GenerativeGraphRAG):
    def get_recommendations(
        self, user_id: str, num_recommendations: int = 5
    ) -&gt; List[str]:
        user_node = self.retrieve(f"User {user_id}", k=1)[0]
        user_interests = self.graph.nodes[user_node].
            get('interests', [])
        potential_recommendations = set()
        for interest in user_interests:
            related_items = self.retrieve(interest, k=3)
            potential_recommendations.update(related_items)
        recommendations = list(
            potential_recommendations - set(user_interests)
        )[:num_recommendations]
        return recommendations
    def explain_recommendation(
        self, user_id: str, item_id: str
    ) -&gt; str:
        query = f"Why would User {user_id} be interested in {item_id}?"
        return self.generate_response(query)
# Example usage
recommendation_rag = RecommendationGraphRAG(
    kg, "all-MiniLM-L6-v2", "gpt2-medium"
)
user_id = "12345"
recommendations = recommendation_rag.get_recommendations(user_id)
print(f"Recommendations for User {user_id}:", recommendations)
for item in recommendations[:2]:
    explanation = recommendation_rag.explain_recommendation(user_id,
        item)
    print(f"Explanation for recommending {item}:", explanation)</pre>			<p>This example <a id="_idIndexMarker1268"/>demonstrates how graph RAG can be used to generate personalized <a id="_idIndexMarker1269"/>recommendations and explain those recommendations using the graph structure.</p>
			<h1 id="_idParaDest-314"><a id="_idTextAnchor386"/>Challenges and future directions in graph-based RAG</h1>
			<p>Let’s consider some key <a id="_idIndexMarker1270"/>challenges and future research directions in graph-based RAG:</p>
			<ul>
				<li>Scalability to very large graphs</li>
				<li>Handling dynamic and evolving graph structures</li>
				<li>Incorporating uncertainty and probabilistic relationships</li>
				<li>Improving the interpretability of graph-based retrievals and generations</li>
				<li>Developing more sophisticated graph-aware language models</li>
			</ul>
			<p>These are fascinating and complex research topics. In this chapter, we’ll focus on the scalability aspect of graph-based RAG. You are encouraged to read the research paper titled <em class="italic">Graph Retrieval-Augmented Generation: A Survey</em> at <a href="https://arxiv.org/abs/2408.08921">https://arxiv.org/abs/2408.08921</a> for more information on other challenges and research directions.</p>
			<p>Real-world knowledge graphs can contain millions or even billions of nodes and edges. Querying and traversing such massive graphs can be computationally expensive, especially when incorporated into a real-time RAG pipeline. Furthermore, providing a huge subgraph as context to the LLM can exceed its context window limit and dilute the relevant information with <a id="_idIndexMarker1271"/>noise.</p>
			<p>Several factors contribute to this scalability bottleneck:</p>
			<ul>
				<li><strong class="bold">Graph traversal complexity</strong>: Finding relevant nodes and their connections within a large graph can be time consuming. Standard <a id="_idIndexMarker1272"/>graph algorithms such as BFS or DFS can become inefficient as the graph grows.</li>
				<li><strong class="bold">Embedding storage and retrieval</strong>: Storing and retrieving node embeddings for a massive graph requires significant memory and computational resources. Computing similarity scores between the query embedding and all node embeddings becomes a bottleneck.</li>
				<li><strong class="bold">Context window limitations</strong>: LLMs have a limited context window, meaning they can only process a fixed amount of text at a time. A large graph context can easily exceed this limit, forcing truncation and potentially resulting in the loss of important information.</li>
				<li><strong class="bold">Noise in context</strong>: Including too much irrelevant information from the graph as context can confuse the LLM and degrade the quality of the generated response.</li>
			</ul>
			<p>To address these scalability challenges, several strategies can be employed. One such strategy, which we will<a id="_idIndexMarker1273"/> implement, is <strong class="bold">subgraph sampling</strong>. This involves extracting a smaller, more manageable subgraph from the overall knowledge graph that is most relevant to the user’s query. This reduces the computational cost of graph traversal and embedding retrieval, while also ensuring that the LLM receives a focused and informative context. Other techniques for improving scalability include the following:</p>
			<ul>
				<li><strong class="bold">Graph databases</strong>: Using specialized graph databases such as Neo4j or Amazon Neptune can significantly improve query performance and scalability compared to general-purpose databases</li>
				<li><strong class="bold">Approximate nearest neighbor (ANN) search</strong>: Using ANN algorithms for embedding retrieval can significantly speed up the search process by sacrificing some accuracy</li>
				<li><strong class="bold">Knowledge graph summarization</strong>: Condensing the knowledge graph into a smaller, more manageable representation while preserving its essential information</li>
				<li><strong class="bold">Hardware acceleration</strong>: Utilizing GPUs or specialized hardware accelerators can speed up graph computations and embedding operations</li>
				<li><strong class="bold">Context distillation</strong>: Techniques such as selective context injection or hierarchical retrieval <a id="_idIndexMarker1274"/>can filter and prioritize the most relevant information for the LLM</li>
			</ul>
			<p>Now, let’s proceed with implementing subgraph sampling to see how it helps address scalability concerns:</p>
			<pre class="source-code">
import networkx as nx
class ScalableGraphRAG(GenerativeGraphRAG):
    def __init__(
        self, kg: KnowledgeGraph, retriever_model: str,
        generator_model: str, max_subgraph_size: int = 1000
    ):
        super().__init__(kg, retriever_model, generator_model)
        self.max_subgraph_size = max_subgraph_size
    def retrieve(self, query: str, k: int = 5) -&gt; List[str]:
        initial_nodes = super().retrieve(query, k=k)
        subgraph = self.sample_subgraph(initial_nodes)
        return self.rank_nodes_in_subgraph(subgraph, query)[:k]
    def sample_subgraph(self, seed_nodes: List[str]) -&gt; nx.Graph:
        subgraph = nx.Graph()
        frontier = set(seed_nodes)
        while len(subgraph) &lt; self.max_subgraph_size and frontier:
            node = frontier.pop()
            if node not in subgraph:
                subgraph.add_node(node, self.graph.nodes[node])
                neighbors = list(self.graph.neighbors(node))
                for neighbor in neighbors:
                    if len(subgraph) &lt; self.max_subgraph_size:
                        subgraph.add_edge(
                            node, neighbor,
                            self.graph[node][neighbor]
                        )
                        frontier.add(neighbor)
                    else:
                        break
        return subgraph
    def rank_nodes_in_subgraph(
        self, subgraph: nx.Graph, query: str
    ) -&gt; List[str]:
        query_embedding = self.model.encode(query)
        node_scores = {}
        for node in subgraph.nodes():
            node_embedding = self.node_embeddings[node]
            score = torch.cosine_similarity(
                torch.tensor(query_embedding),
                torch.tensor(node_embedding), dim=0
            )
            node_scores[node] = score
        return sorted(node_scores, key=node_scores.get, reverse=True)
# Example usage
scalable_graph_rag = ScalableGraphRAG(
    kg, "all-MiniLM-L6-v2", "gpt2-medium"
)
retrieved_nodes = scalable_graph_rag.retrieve("What is the capital of France?")
print("Retrieved nodes:", retrieved_nodes)</pre>			<p>This code introduces a <code>ScalableGraphRAG</code> class, which is designed to address the scalability challenges of graph-based RAG systems by implementing a subgraph sampling technique. Inheriting from <code>GenerativeGraphRAG</code>, it incorporates a <code>max_subgraph_size</code> parameter to limit the size of the extracted subgraph.</p>
			<p>The overridden retrieve method first identifies an initial set of relevant nodes using the base class’s retrieval mechanism. It then calls the <code>sample_subgraph</code> method to construct a subgraph centered around these initial nodes, limiting its growth to the specified <code>max_subgraph_size</code>.</p>
			<p>The <code>sample_subgraph</code> method performs a breadth-first expansion from the seed nodes, adding nodes and edges to the subgraph until the size limit is reached, prioritizing nodes closer to the seed.</p>
			<p>Subgraph sampling can be<a id="_idIndexMarker1275"/> tuned by adjusting the <code>max_subgraph_size</code> parameter so that it balances context richness and computational efficiency. A smaller size results in faster processing but potentially misses crucial contextual information, while a larger size captures more context but increases computational cost. Additionally, the algorithm’s node selection criteria during subgraph expansion can be tuned – for example, prioritizing nodes with higher semantic similarity to the query or nodes with stronger connectivity to the seed nodes. Experimenting with these parameters is useful for optimizing the RAG system’s performance for specific applications and graph structures.</p>
			<p>Finally, the <code>rank_nodes_in_subgraph</code> method calculates the relevance of each node within the subgraph to the query by computing the cosine similarity between the query embedding and the node’s pre-computed embedding. Then, it returns a ranked list of nodes based on their similarity scores, ensuring that only the most relevant nodes within the sampled subgraph <a id="_idTextAnchor387"/>are considered for context augmentation.</p>
			<h1 id="_idParaDest-315"><a id="_idTextAnchor388"/>Summary</h1>
			<p>Graph-based RAG extends the capabilities of traditional RAG systems by leveraging the rich structure of knowledge graphs. By implementing the techniques and approaches discussed in this chapter, you can create more sophisticated LLM systems capable of reasoning over complex relationships and generating more contextually appropriate responses. In the next chapter, we will explore advanced RAG patterns for LLMs. This will build upon the graph-based techniques we’ve discussed here so that you can create even more powerful and flexible RAG systems.</p>
		</div>
	</div></div></body></html>