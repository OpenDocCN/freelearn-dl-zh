- en: '5'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '5'
- en: Extracting Faces
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提取人脸
- en: In this chapter, we will start our hands-on activities with the code. To begin
    with, we’ll cover the process of extracting faces.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将从代码入手开始我们的动手实践。首先，我们将介绍提取人脸的过程。
- en: Extracting faces is a series of steps in a process that involves many different
    stages, but it’s the first discrete stage in creating a deepfake. This chapter
    will first talk about how to run the face extraction script, then we will go hands-on
    with the code, explaining what each part does.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 提取人脸是涉及许多不同阶段的过程中的一系列步骤，但它是创建deepfake的第一个离散阶段。本章将首先讨论如何运行人脸提取脚本，然后我们将动手编写代码，解释每个部分的作用。
- en: 'In this chapter, we will cover the following key sections:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下关键部分：
- en: Getting image files from a video
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从视频中获取图像文件
- en: Running extract on frame images
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在帧图像上运行提取操作
- en: Getting hands-on with the code
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与代码动手实践
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: To proceed, we recommend that you download the code from the GitHub repo at
    [https://github.com/PacktPublishing/Exploring-Deepfakes](https://github.com/PacktPublishing/Exploring-Deepfakes)
    and follow the instructions in the `readme.md` file to install Anaconda and to
    create a virtual environment with all required libraries to run the scripts. The
    repo will also contain any errata or updates that have happened since the book
    was published, so please check there for any updates.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 为了继续，我们建议您从GitHub仓库[https://github.com/PacktPublishing/Exploring-Deepfakes](https://github.com/PacktPublishing/Exploring-Deepfakes)下载代码，并按照`readme.md`文件中的说明安装Anaconda，创建一个包含所有必需库的虚拟环境以运行脚本。该仓库还将包含自本书出版以来发生的任何勘误或更新，因此请检查那里以获取任何更新。
- en: Getting image files from a video
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从视频中获取图像文件
- en: Videos are not designed for frame-by-frame access and can cause problems when
    processed out of order. Accessing a video file is a complicated process and not
    good for a beginner-level chapter like this. For this reason, the first task is
    to convert any videos that you want to extract from into individual frames. The
    best way to do this is to use **FFmpeg**. If you followed the installation instructions
    in the *Technical requirements* section, you will have FFmpeg installed and ready
    to use.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 视频不是为逐帧访问而设计的，如果处理顺序错误可能会导致问题。访问视频文件是一个复杂的过程，不适合像本章这样的入门级章节。因此，第一个任务是转换您想要提取的任何视频，将其转换为单独的帧。最好的方法是使用**FFmpeg**。如果您遵循了*技术要求*部分中的安装说明，您将已安装并准备好使用FFmpeg。
- en: Let’s begin the process.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始这个过程。
- en: Tip
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 小贴士
- en: When you see code or command examples such as those present here with text inside
    of curly brackets, you should replace that text with the information that is explained
    in the brackets. For example, if it says `cd {Folder with video}` and the video
    is in the `c:\Videos\` folder, then you should enter `cd c:\Videos`.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 当您看到代码或命令示例，例如这里用花括号括起来的文本时，您应该用括号中解释的信息替换该文本。例如，如果它说`cd {包含视频的文件夹}`，并且视频在`c:\Videos\`文件夹中，那么您应该输入`cd
    c:\Videos`。
- en: 'Place the video into a folder, then open an Anaconda prompt and enter the following
    commands:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 将视频放入一个文件夹中，然后打开Anaconda提示符并输入以下命令：
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This will fill the `frames` folder with numbered images containing the exported
    frames.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这将填充`frames`文件夹，其中包含带有编号的导出帧的图像。
- en: There are a lot of options you can control with FFmpeg, from the resolution
    of the output image to the number of frames to be skipped. These features are
    beyond the scope of this book but have been covered extensively elsewhere. We
    advise searching for a guide to ffmpeg’s command line options if you’re going
    to do much more than the basics.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用FFmpeg控制许多选项，从输出图像的分辨率到要跳过的帧数。这些功能超出了本书的范围，但已在其他地方广泛介绍。如果您打算进行比基础操作更多的操作，我们建议您搜索FFmpeg命令行选项的指南。
- en: Running extract on frame images
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在帧图像上运行提取操作
- en: 'To run the extract process on a video, you can run the extract program from
    the cloned `git` repository folder. To do this, simply run the following in an
    Anaconda prompt:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 要在视频上运行提取过程，您可以从克隆的`git`仓库文件夹中运行提取程序。为此，只需在Anaconda提示符中运行以下命令：
- en: '[PRE1]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This will run the face extraction process on each of the images in the folder
    and put the extracted images into the `face_images` folder, which (by default)
    will be inside the folder of frame images. This folder will contain three types
    of files for each face detected, along with a file containing all alignments.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这将在文件夹中的每个图像上运行面部提取过程，并将提取的图像放入`face_images`文件夹中，默认情况下，该文件夹位于帧图像文件夹内。该文件夹将包含每个检测到的面部的三种类型文件，以及包含所有对齐的文件。
- en: face_alignments.json
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: face_alignments.json
- en: There will just be one of these files. It is a JSON-formatted file containing
    the landmark positions and warp matrix for every face found in the images. This
    file is human-readable like any JSON file and can be read or edited (though it’s
    probably not something that you’d do manually).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 将只有一个这样的文件。这是一个包含在图像中找到的每个面部地标和变形矩阵的JSON格式文件。这个文件像任何JSON文件一样可读，可以读取或编辑（尽管这可能不是你手动操作的事情）。
- en: face_landmarks_{filename}_{face number}.png
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: face_landmarks_{filename}_{face number}.png
- en: This is a copy of the original image with a bounding box drawn around the face
    and five **landmark** points written out. Landmarks are common points on the face.
    We’ll cover the usage of these landmark points later, but the ones we’re most
    interested in are the eyes, nose, and corners of the mouth.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这是对原始图像的副本，在面部周围画了一个边界框，并写出了五个**地标**点。地标是面部上的常见点。我们将在后面介绍这些地标点的用法，但我们最感兴趣的是眼睛、鼻子和嘴巴的角落。
- en: '![Figure 5.1 – Example of face_landmarks_bryan_0.png](img/B17535_05_001.jpg)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![图5.1 – face_landmarks_bryan_0.png示例](img/B17535_05_001.jpg)'
- en: Figure 5.1 – Example of face_landmarks_bryan_0.png
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.1 – face_landmarks_bryan_0.png示例
- en: Author’s note
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 作者注记
- en: All of the images of people used for practical demonstration in this section
    are of the authors.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 本节中用于实际演示的所有人物图像均为作者本人。
- en: face_bbox_{filename}_{face number}.png
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: face_bbox_{filename}_{face number}.png
- en: This image represents the original **bounding box** (the smallest box that surrounds
    the detected face) found in the original image. It will be in the full original
    size and angle of the face found in the image.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这张图像代表在原始图像中找到的原始**边界框**（围绕检测到的面部最小的框）。它将以图像中找到的面部的完整原始大小和角度显示。
- en: '![Figure 5.2 – Example of face_bbox_bryan_0.png](img/B17535_05_002.jpg)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![图5.2 – face_bbox_bryan_0.png示例](img/B17535_05_002.jpg)'
- en: Figure 5.2 – Example of face_bbox_bryan_0.png
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.2 – face_bbox_bryan_0.png示例
- en: face_aligned_{filename}_{face number}.png
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: face_aligned_{filename}_{face number}.png
- en: This image will be a smaller size (the default is 256x256) image of the face.
    This is an **aligned** face image, where the face has been lined up according
    to the landmarks. This image should generally have the face centered in the image
    and lined up vertically. If the face in the bounding box image was crooked or
    angled in the box, it should be straightened in the aligned image. There may also
    be a black cutout where the edge of the original frame cuts off the data.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这张图像将是面部的一个较小尺寸（默认为256x256）图像。这是一个**对齐**的面部图像，其中面部已根据地标对齐。这张图像通常应将面部置于图像中心并垂直对齐。如果边界框图像中的面部在框内歪斜或倾斜，则应在对齐图像中将其拉直。还可能有一个黑色裁剪区域，其中原始框架的边缘切断了数据。
- en: This image is the most important image and is the one that will be used for
    training the model. It is critical for quality training that the aligned face
    is a good-quality image. This is the data that you’ll want to clean to get a successful
    deepfake.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这是最重要的图像，也是用于训练模型的图像。确保对齐的面部是高质量图像对于高质量训练至关重要。这是你想要清理以获得成功深度伪造的数据。
- en: '![Figure 5.3 – Example of face_aligned_bryan_0.png](img/B17535_05_003.jpg)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![图5.3 – face_aligned_bryan_0.png示例](img/B17535_05_003.jpg)'
- en: Figure 5.3 – Example of face_aligned_bryan_0.png
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.3 – face_aligned_bryan_0.png示例
- en: face_mask_{filename}_{face number}.png
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: face_mask_{filename}_{face number}.png
- en: This image matches the size of the aligned image. In fact, it matches the aligned
    image in the crop, rotation, and size. The mask is an AI-predicted outline of
    the face that will be used later to ensure that the face is trained properly and
    help swap the final face back onto the image.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这张图像与对齐图像的大小相匹配。实际上，它在裁剪、旋转和尺寸上与对齐图像相匹配。面具是AI预测的面部轮廓，稍后将用于确保面部被正确训练，并帮助将最终的面部换回到图像中。
- en: '![Figure 5.4 – Example of face_mask_bryan_0.png](img/B17535_05_004.jpg)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![图5.4 – face_mask_bryan_0.png示例](img/B17535_05_004.jpg)'
- en: Figure 5.4 – Example of face_mask_bryan_0.png
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.4 – face_mask_bryan_0.png示例
- en: The mask should line up with the aligned face perfectly, showing where the face
    and edges are. You can see how the mask overlays onto the face in *Figure 5**.5*.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 遮罩应该与对齐的人脸完美对齐，显示人脸和边缘的位置。您可以在*图5.5*中看到遮罩是如何覆盖在人脸上的。
- en: '![Figure 5.5 – Example of mask overlayed on aligned face](img/B17535_05_005.jpg)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![图5.5 – 遮罩覆盖在对齐人脸上的示例](img/B17535_05_005.jpg)'
- en: Figure 5.5 – Example of mask overlayed on aligned face
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.5 – 遮罩覆盖在对齐人脸上的示例
- en: So, now that you know how to run the face detector and all of its output, let’s
    get into the hands-on section and determine exactly what it’s doing.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，现在您已经知道了如何运行人脸检测器及其所有输出，让我们进入实践部分，确定它到底在做什么。
- en: Getting hands-on with the code
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 与代码实践
- en: 'Now it’s time to get into the code. We’ll go over exactly what `C5-face_detection.py`
    does and why each option was chosen. There are five main parts to the code: initialization,
    image preparation, face detection, face landmarking/aligning, and masking.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候进入代码部分了。我们将详细说明`C5-face_detection.py`文件的功能以及为什么选择每个选项。代码主要分为五个部分：初始化、图像准备、人脸检测、人脸标记/对齐和遮罩。
- en: Initialization
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 初始化
- en: Let’s begin.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧。
- en: Author’s note
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 作者注
- en: Formatting for easy reading in a book requires modifying the spacing in the
    samples. Python, however, is whitespace sensitive and uses spacing as a part of
    the language syntax. This means that copying code from this book will almost definitely
    contain the wrong spacing. For this reason, we highly recommend pulling the code
    from the Git repository for the book at [https://github.com/PacktPublishing/Exploring-Deepfakes](https://github.com/PacktPublishing/Exploring-Deepfakes)
    if you plan on running it.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 为了便于在书中阅读，需要对示例中的间距进行修改。然而，Python对空白字符敏感，并将空白字符作为语言语法的一部分使用。这意味着从本书中复制代码几乎肯定会包含错误的间距。因此，我们强烈建议您从本书的Git仓库[https://github.com/PacktPublishing/Exploring-Deepfakes](https://github.com/PacktPublishing/Exploring-Deepfakes)中获取代码，如果您打算运行它的话。
- en: 'First, we import all required libraries:'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们导入所有必需的库：
- en: '[PRE2]'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: In this section, we’re importing all the important libraries and functions that
    we will use. These are all used in the code and will be explained when they’re
    used, but it’s a good idea to get familiar with the imports for any project since
    it lets you understand the functions being used and where they came from.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们导入我们将使用的重要库和函数。这些都在代码中使用，将在使用时进行解释，但熟悉任何项目的导入是一个好主意，因为它让您了解正在使用的函数及其来源。
- en: Many of these imports are from the Python standard library, and if you’re interested
    in reading more about them, you can find their documentation online. We’ll be
    explaining those that aren’t part of the standard library as we come to them,
    including where you can find documentation on them.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 许多这些导入来自Python标准库，如果您想了解更多关于它们的信息，您可以在网上找到它们的文档。我们将在我们遇到它们时解释那些不是标准库的部分，包括如何找到它们的文档。
- en: 'Next, let’s skip to the end of the code for a moment, where we’ll look at argument
    parsing:'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，让我们暂时跳到代码的末尾，看看参数解析：
- en: '[PRE3]'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: In this section, we define the options available in the script. It lets you
    change many options without needing to modify the code at all. Most of these will
    be fine with the defaults, but the argument parser included in the Python standard
    libraries gives us an easy-to-use method to make those changes at runtime. The
    documents and guides for the argument parser are part of the standard library,
    so we’ll skip over the basics, except to state that we use `parser.add_argument`
    for each argument that we want, and all the arguments get put into the `opt` variable.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们定义了脚本中可用的选项。它允许您在不修改代码的情况下更改许多选项。大多数选项使用默认值即可，但Python标准库中的参数解析器为我们提供了一个易于使用的运行时更改这些选项的方法。参数解析器的文档和指南是标准库的一部分，所以我们将跳过基础知识，除了说明我们使用`parser.add_argument`为每个我们想要的参数添加，所有参数都放入`opt`变量中。
- en: One special thing we’re doing here is to change the `export_path` variable after
    it is defined, replacing the `$path` string in the variable to put the output
    folder into the input folder. If the user overrides the default, there will be
    nothing to replace (or the user could use `$path` to specify a different subfolder
    in the input folder if desired).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里做的一件特别的事情是在定义后更改`export_path`变量，将变量中的`$path`字符串替换为将输出文件夹放入输入文件夹。如果用户覆盖了默认值，则不需要替换（或者用户可以使用`$path`来指定输入文件夹中的不同子文件夹，如果需要的话）。
- en: Note
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Python norms require that this section is at the end of the file to work. However,
    it’s very important to at least look at this section so that you know what it
    is doing before we go through the rest of the code.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: Python规范要求此部分位于文件末尾才能正常工作。然而，在浏览其余代码之前，至少查看此部分非常重要，以便了解它在做什么。
- en: 'Next, we return to the following code:'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们返回以下代码：
- en: '[PRE4]'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This section begins with the main function we’re using to do all the actual
    work.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 本节从我们用于执行所有实际工作的主函数开始。
- en: 'The first thing we do is make sure the output folder exists:'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先确保输出文件夹存在：
- en: '[PRE5]'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This creates the output folder if it doesn’t already exist.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如果不存在，这将创建输出文件夹。
- en: 'Then we enable **graphics processing unit** (**GPU**) acceleration if it’s
    available:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，如果可用，我们启用**图形处理单元**（**GPU**）加速：
- en: '[PRE6]'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: In this part, we begin with the `PyTorch` for CUDA availability and save the
    device variable for later use.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在这部分，我们从检查CUDA可用性的`PyTorch`开始，并将设备变量保存以供以后使用。
- en: 'Next, we’ll initialize the face detector and aligner:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将初始化人脸检测器和对齐器：
- en: '[PRE7]'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This code defines the face detector and aligner that we’ll be using; it specifies
    what devices we’re going to use and tells the aligner to use a model trained for
    `2D` face landmarks. These classes come from the `face_alignment` library available
    at [https://github.com/1adrianb/face-alignment](https://github.com/1adrianb/face-alignment).
    Both the detector and the aligner are AI models that have been trained for their
    specific uses. The detector finds any faces in a given image, returning their
    position through the use of a bounding box. The aligner takes those detected faces
    and finds landmarks that we can use to align the face to a known position.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码定义了我们将要使用的检测器和对齐器；它指定我们将使用哪些设备，并告诉对齐器使用为`2D`人脸特征点训练的模型。这些类来自[https://github.com/1adrianb/face-alignment](https://github.com/1adrianb/face-alignment)提供的`face_alignment`库。检测器和对齐器都是针对特定用途训练的AI模型。检测器在给定图像中找到任何人脸，并通过使用边界框返回它们的位置。对齐器接收这些检测到的人脸并找到我们可以用来将人脸对齐到已知位置的标记点。
- en: 'Next, we define our masker and prepare it. We load the pre-trained weights
    and set it to use CUDA if NVIDIA support is enabled:'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们定义我们的掩码器并准备它。我们加载预训练的权重，并设置它使用CUDA（如果启用了NVIDIA支持）：
- en: '[PRE8]'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: We use the `desired_segments` variable to define which of the masker segments
    we want to use. In our current masker, this gives us the face itself and discards
    background, hair, and clothing so that our model will only need to learn the information
    that we want to swap.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`desired_segments`变量来定义我们想要使用哪些掩码器段。在我们的当前掩码器中，这给我们提供了人脸本身，并丢弃背景、头发和衣服，以便我们的模型只需要学习我们想要交换的信息。
- en: 'Lastly, we get a list of files in the input folder:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们获取输入文件夹中的文件列表：
- en: '[PRE9]'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This code first prepares an empty dictionary to store the alignment data. This
    dictionary will store all the data that we want to store and save with the face
    data we’ll use to convert with later.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码首先准备一个空字典来存储对齐数据。这个字典将存储我们想要存储和与我们将要使用的面部数据一起保存的所有数据。
- en: Next, it will get a list of all files in the folder. This assumes that each
    file is an image that we want to import any faces from. If there are any non-image
    files, it will fail, so it’s important to keep extra files out of the folder.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，它将获取文件夹中所有文件的列表。这假设每个文件是我们想要从中导入人脸的图像。如果有任何非图像文件，它将失败，因此重要的是将额外文件保持在文件夹外。
- en: Next, files in the directory are listed and checked to ensure they’re files
    before being stored in a list.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，列出目录中的文件并检查它们是否为文件，在将它们存储在列表中之前。
- en: Image preparation
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图像准备
- en: The image preparation is the next step.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 图像准备是下一步。
- en: 'This loads the images and gets them ready to be processed by the rest of the
    tools:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这加载图像并使它们准备好由其他工具处理：
- en: '[PRE10]'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This is the start of a loop that will go over every file in the directory to
    process them. The `tqdm` library creates a nice readable status bar, including
    predictions for how long the process will take. This one line is enough to get
    the basics, but there are a lot more features that it can provide. You can see
    the full documentation at [https://github.com/tqdm/tqdm#documentation](https://github.com/tqdm/tqdm#documentation).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个循环的开始，它将遍历目录中的每个文件以处理它们。`tqdm`库创建了一个易于阅读的状态栏，包括预测处理过程将花费多长时间。这一行足以了解基础知识，但它还能提供更多功能。您可以在[https://github.com/tqdm/tqdm#documentation](https://github.com/tqdm/tqdm#documentation)查看完整文档。
- en: 'Next, we load the image and convert it to RGB color order:'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们加载图像并将其转换为RGB颜色顺序：
- en: '[PRE11]'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: OpenCV is a library of tools for operating on images. You can find documentation
    for it at [https://docs.opencv.org/](https://docs.opencv.org/). In this code,
    we use it to open images and handle various image tasks, which we’ll explain as
    they come up.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV是一个用于操作图像的工具库。您可以在[https://docs.opencv.org/](https://docs.opencv.org/)找到它的文档。在这段代码中，我们使用它来打开图像并处理各种图像任务，我们将随着任务的展开进行解释。
- en: OpenCV loads the images in a **blue, green, red** (**BGR**) color order, which
    is unusual, so we must convert it to **red, green, blue** (**RGB**) color order
    for later processing since the other libraries expect the files in that color
    order. If we don’t convert it, all the colors will be off, and many tools will
    provide the wrong results.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV以**蓝、绿、红**（**BGR**）的顺序加载图像，这是不寻常的，因此我们必须将其转换为**红、绿、蓝**（**RGB**）的顺序，以便后续处理，因为其他库期望文件以该颜色顺序。如果我们不转换，所有颜色都会错位，许多工具将提供错误的结果。
- en: Then we get the image’s shape; this will give us the height and width of the
    image, as well as the number of color channels (this will be three since we loaded
    them as color images).
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们获取图像的形状；这将给我们图像的高度和宽度，以及颜色通道的数量（由于我们以彩色图像加载，这将会有三个）。
- en: 'Next, we need to check whether we need to resize the image:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们需要检查是否需要调整图像的大小：
- en: '[PRE12]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: When you’re running images through AI models, the image’s dimensions can drastically
    change the amount of memory used. This can cause an error if it exceeds the memory
    available for AI to use. In this code, we’re getting a maximum size from the options,
    then finding what adjustment we need to make to resize the image down to the maximum
    size and keep track of that change so that the results from the face detector
    can be restored to work on the original image. This process allows us to use a
    smaller image for the face detection AI while still using the face from the full-sized
    image, giving us the best resolution and details.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 当您通过AI模型运行图像时，图像的尺寸可以极大地改变使用的内存量。如果它超过了AI可用的内存，这可能会导致错误。在这段代码中，我们正在从选项中获取最大尺寸，然后找到我们需要调整以将图像调整到最大尺寸并跟踪该变化，以便可以将面部检测器的结果恢复到在原始图像上工作。这个过程允许我们使用较小的图像进行面部检测AI，同时仍然使用全尺寸图像中的面部，从而提供最佳分辨率和细节。
- en: Face detection
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 面部检测
- en: Now it’s time to detect the faces within the image. This process goes through
    each image to detect any faces.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候检测图像中的面部了。这个过程会遍历每一张图像以检测任何面部。
- en: 'First, we check the resized image for any faces:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们检查调整大小后的图像中是否有任何面部：
- en: '[PRE13]'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This runs the face detector to find any faces in the image. The library makes
    this a very easy process. We send the resized image through and get back a list
    of all the faces found as well as their bounding boxes. These boxes are all relative
    to the smaller, resized image to ensure we have enough memory to handle it.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 这运行面部检测器以在图像中找到任何面部。该库使这个过程变得非常简单。我们发送调整大小后的图像，并返回一个包含找到的所有面部及其边界框的列表。这些框都是相对于较小的调整大小后的图像的，以确保我们有足够的内存来处理它。
- en: 'Next, we’ll iterate over each face:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将遍历每个面部：
- en: '[PRE14]'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: As input into the loop we use the built-in Python function `enumerate`, which
    gives us a count of each of the faces as it finds them. We use this number later
    to identify the face by number.Then, we break out the bounding box size and divide
    it by the adjustment size. This restores the face bounding box that was detected
    to match the original image instead of the smaller resized image. We store the
    adjusted face detection in variables that we round to integers so we can keep
    it lined up with the individual pixels.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 作为循环的输入，我们使用内置的Python函数`enumerate`，它为我们提供了找到的每个面部的计数。我们使用这个数字来稍后通过编号识别面部。然后，我们提取边界框的大小并将其除以调整大小。这会将检测到的面部边界框恢复到与原始图像匹配，而不是较小的调整大小后的图像。我们将调整后的面部检测存储在变量中，并将它们四舍五入到整数，以便我们可以将其与单个像素对齐。
- en: Next, the confidence level of the face detection AI is used to skip any faces
    that fall below the confidence level, which is set up in the options.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，使用面部检测AI的置信度水平跳过任何低于置信度水平的面部，该置信度水平已在选项中设置。
- en: Tip
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 小贴士
- en: The confidence level from the face detection AI varies from `0` (no face) to
    `1` (absolute certainty of a face). Most AI uses the range of `0` to `1` since
    it’s easier for AI to work with a known range. If you are doing AI work and get
    results you don’t expect, you might want to check whether it’s been restricted
    down to the range of `0` to `1`.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 面部检测AI的置信度从`0`（无面部）到`1`（绝对确定有面部）。大多数AI使用`0`到`1`的范围，因为对于AI来说，处理已知范围更容易。如果您在进行AI工作时得到您不期望的结果，您可能想要检查它是否已被限制在`0`到`1`的范围内。
- en: 'Next, we make sure the face is big enough to use:'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们确保面部足够大以便使用：
- en: '[PRE15]'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: This code finds the face height and width, then uses that to find the overall
    size of the face, and compares it against a minimum face size, skipping any faces
    that are too small. It uses the original size of the frame to filter out faces
    that aren’t the main focus more easily. This is set low but can be useful if you
    have lots of faces in a single image, such as in a crowd scene.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码找到面部的高度和宽度，然后使用这些信息来找到整个面部的大小，并将其与最小面部大小进行比较，跳过任何太小的人脸。它使用原始帧的大小来更容易地过滤掉不是主要焦点的面部。这个值设置得比较低，但如果在单张图像中有许多面部，例如在人群场景中，这可能很有用。
- en: 'Next, we write out the bounding box as an image:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将边界框作为图像输出：
- en: '[PRE16]'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: This code creates an image containing just the parts of the image that fit inside
    the face bounding box of the face and saves it as a `.png` file into the output
    folder. This lets you see the face that is detected; however, it’s not actually
    needed for any future step, so it can be removed if you don’t want to save this
    data.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码创建一个只包含图像中适合面部边界框的部分的图像，并将其保存为输出文件夹中的`.png`文件。这可以让您看到检测到的面部；然而，这实际上对于任何后续步骤都不是必需的，因此如果您不想保存这些数据，可以将其删除。
- en: Face landmarking/aligning
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 面部关键点定位/对齐
- en: The next step is to detect landmarks of the face and align them to a known position.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是检测面部关键点并将它们对齐到已知位置。
- en: 'First, we will get alignments:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们将获取对齐：
- en: '[PRE17]'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Here, we use the same library we used for face detection, passing the full image
    and the adjusted bounding boxes in order to get landmarks for the face. The library
    returns 68 landmark positions, which are based on specific points on the face.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用与面部检测相同的库，传递完整的图像和调整后的边界框，以获取面部关键点。该库返回68个关键点位置，这些位置基于面部上的特定点。
- en: 'Next, we draw a box:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们画一个框：
- en: '[PRE18]'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Here, we generate a new copy of the original image in BGR color format so we
    can draw onto the image without damaging our original copy. We then use OpenCV
    to draw a rectangle for the detected face. Its `thickness` is set to `10` pixels
    and drawn in black.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们以BGR颜色格式生成原始图像的新副本，这样我们就可以在不损坏原始副本的情况下在图像上绘制。然后我们使用OpenCV绘制一个检测到的面部的矩形。其`厚度`设置为`10`像素，用黑色绘制。
- en: 'Next, we create the landmarks we’re going to use for alignment:'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们创建用于对齐的关键点：
- en: '[PRE19]'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: In this code, we split the 68 landmarks down to just 5\. We use the average
    of the landmarks around each eye to find the average eye position, and then get
    the tip of the nose and the corners of the mouth and save them into a new array.
    This reduced set of landmarks helps to keep alignment consistent since the 68
    landmarks contain a lot of noisy edge points.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在此代码中，我们将68个关键点拆分到只有5个。我们使用每个眼睛周围的关键点的平均值来找到平均眼睛位置，然后获取鼻尖和嘴角的拐角，并将它们保存到一个新的数组中。这个减少的关键点集有助于保持对齐的一致性，因为68个关键点包含大量的噪声边缘点。
- en: 'Next, we will draw the landmarks onto the image:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将绘制关键点到图像上：
- en: '[PRE20]'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Here, we define a set of colors, then use those to draw individual dots for
    each landmark position. We save them as a `.png` image file in the output folder.
    These images are for demonstration and debugging purposes and aren’t ever used
    later, so you can remove them (and this save call) if you don’t need those debug
    images.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们定义一组颜色，然后使用这些颜色为每个关键点位置绘制单独的点。我们将它们保存为输出文件夹中的`.png`图像文件。这些图像用于演示和调试目的，并且以后从未使用过，因此如果您不需要这些调试图像，可以删除它们（以及这个保存调用）。
- en: 'Next, we define the mean face:'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们定义平均面部：
- en: '[PRE21]'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Here, we define another array; this is based on the average face locations of
    the different landmarks. We use this in the next part to align the image. These
    numbers are based on where we want the face to be but could be any numbers that
    can be reliably detected on the face.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们定义另一个数组；这是基于不同关键点的平均面部位置。我们在下一部分中使用它来对齐图像。这些数字基于我们希望面部所在的位置，但可以是任何可以在面部可靠检测到的数字。
- en: 'Next, we generate the transformation matrix to align the face:'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们生成用于对齐面部的转换矩阵：
- en: '[PRE22]'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: This is a bit complicated to understand, so we’ll go into depth here. We use
    an algorithm to align two point sets created by Shinji Umeyama as implemented
    in the `SciKit-Image` library. This takes two sets of points, one a known set
    (in this case, `MEAN_FACE`, which we defined earlier) and the other an unknown
    set (in this case, the five landmark points from the detected face saved in `limited_landmarks`),
    and aligns them. Next, we multiply the landmarks by the size that we want the
    image to end up being and add a border around the face so that it is centered
    with some extra space around the edges.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 这部分内容有点复杂，所以我们将在这里深入探讨。我们使用Shinji Umeyama创建的两个点集对齐算法，该算法在`SciKit-Image`库中实现。这个过程需要两组点，一组是已知集（在本例中为`MEAN_FACE`，我们之前定义过）和另一组未知集（在本例中为`limited_landmarks`中保存的五个标记点），并将它们对齐。接下来，我们将标记点乘以我们想要图像最终大小的尺寸，并在人脸周围添加边框，以便人脸居中，边缘周围有额外空间。
- en: The `umeyama` algorithm creates a matrix that we save as `warp_matrix`, which
    encodes the translations necessary to create an aligned face.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '`umeyama`算法创建一个矩阵，我们将其保存为`warp_matrix`，该矩阵编码了创建对齐人脸所需的平移。'
- en: 'Next, we add the landmarks and `warp_matrix` to the list of alignment data:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将标记点和`warp_matrix`添加到对齐数据列表中：
- en: '[PRE23]'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Finally, we create and write the aligned face image:'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们创建并写入对齐的人脸图像：
- en: '[PRE24]'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Here, the code creates a new copy of the original image and then uses the `warpAffine`
    function from the OpenCV library to apply the `warp_matrix` that was generated
    by the `umeyama` algorithm. The matrix includes all the information – translation
    (moving the image side to side or up and down), scaling (resizing to fit), and
    rotation – to align the face with the pre-defined landmarks. Finally, it saves
    that newly aligned image as a file.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，代码创建原始图像的新副本，然后使用OpenCV库中的`warpAffine`函数应用由`umeyama`算法生成的`warp_matrix`。该矩阵包括所有信息——平移（将图像左右或上下移动）、缩放（调整大小以适应）和旋转——以将人脸与预定义的标记点对齐。最后，它将新对齐的图像保存为文件。
- en: Tip
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 小贴士
- en: While OpenCV does all image processes in BGR color order, it’s fine to do any
    tasks that don’t depend on the color order, such as this `cv2.warpAffine()` step
    here. If you do ignore the color order, you must be careful since it can get easy
    to forget which color order you are using, leading to complicated bugs where the
    colors are all wrong. In this case, since the next step will be to write the image
    out as a file using `cv2.imwrite()`, we are fine using the BGR color order image.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然OpenCV在BGR颜色顺序中处理所有图像过程，但对于不依赖于颜色顺序的任务，例如这里的`cv2.warpAffine()`步骤，是可以的。如果你忽略颜色顺序，你必须小心，因为很容易忘记你正在使用哪种颜色顺序，这可能导致颜色完全错误的复杂错误。在这种情况下，由于下一步将是使用`cv2.imwrite()`将图像写入文件，我们可以使用BGR颜色顺序的图像。
- en: 'Next, we save the data we’ll need to later reconstruct the image:'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们保存稍后用于重建图像所需的数据：
- en: '[PRE25]'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: We save the landmarks and the warp matrix into a dictionary, which we’ll later
    save as a JSON file. This information is important to save for later processing
    steps, so we must make sure to save it.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将标记点和变换矩阵保存到字典中，稍后我们将将其保存为JSON文件。这些信息对于后续处理步骤非常重要，因此我们必须确保保存它。
- en: 'Next, we’re going to create a mask image:'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将创建一个遮罩图像：
- en: '[PRE26]'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: The masker is another AI that has specific requirements for the image that it
    is given. To meet these requirements, we must first process the face image in
    certain ways. The first is that the masker AI expects images that are 512x512
    pixels. Since our aligned faces can be different sizes, we need to make a copy
    of the image that is in the expected 512x512 size.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 遮罩器是另一个对所提供图像有特定要求的AI。为了满足这些要求，我们首先必须以某种方式处理人脸图像。首先，遮罩器AI期望图像大小为512x512像素。由于我们的对齐人脸可能大小不同，我们需要创建一个图像副本，使其大小符合预期的512x512像素。
- en: We then convert it to a `PyTorch` Tensor instead of a `Numpy` array and then
    `unsqueeze` the tensor. This adds an additional dimension since the masker works
    on an array containing one or more images; even though we’re only feeding it one,
    we still need to give it that extra dimension containing our single image to match
    the shape expected.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将其转换为`PyTorch`张量而不是`Numpy`数组，然后对张量进行`unsqueeze`操作。这添加了一个额外的维度，因为遮罩器在包含一个或多个图像的数组上工作；尽管我们只提供给它一个，我们仍然需要提供包含我们的单个图像的额外维度，以匹配预期的形状。
- en: Next, the masker expects the channels to be in a different order than we have
    them. To do this, we `permute` the array into the correct order. Also, traditionally
    images are stored in the range of `0`-`255`, which allows for `256` variations
    of each separate color, but the masker expects the image colors to be a float
    in the range of 0-1\. We divide the range by `255` to get into the expected range.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，masker期望通道的顺序与我们不同。为此，我们将数组`permute`到正确的顺序。此外，传统上图像存储在`0`-`255`的范围内，这允许每个单独的颜色有`256`种变化，但masker期望图像颜色为0-1范围内的浮点数。我们通过`255`来除以范围，以获得预期的范围。
- en: Next, if NVIDIA support is enabled, we convert the image into a CUDA variable,
    which converts it into a format that can be used by the GPU as well as handle
    being moved to the GPU.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，如果启用了NVIDIA支持，我们将图像转换为CUDA变量，这将其转换为GPU也可以使用的格式，并处理将其移动到GPU。
- en: Finally, we run the masker AI on the image that we’ve prepared, saving the mask
    output to a new variable. The masker outputs multiple arrays of information, but
    only the first array is useful to us now, so we save only that one and discard
    all the others.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们在准备好的图像上运行masker AI，并将掩码输出保存到新的变量中。masker输出多个信息数组，但现在对我们有用的只有第一个数组，所以我们只保存这一个，并丢弃所有其他数组。
- en: 'Next, we process the masker output and save it to an image file:'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们处理masker输出并将其保存到图像文件中：
- en: '[PRE27]'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Now that the result has been returned from the masker, we still need to process
    it to get something useful. First, we use `softmax` to convert the result from
    absolute to relative values. This lets us look at the mask as an array of likelihoods
    that each pixel belongs to a particular class instead of the raw values from the
    model.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 现在masker的结果已经返回，我们仍然需要对其进行处理以获得有用的信息。首先，我们使用`softmax`将结果从绝对值转换为相对值。这使得我们可以将掩码视为一个数组，其中每个像素属于特定类别的可能性，而不是模型中的原始值。
- en: Next, we use `interpolate`, which is a `Pytorch` method, to resize the data
    back to the original face image size. We have to do this because, like the input,
    the output of the masker model is 512x512\. We use `bicubic` because it gives
    the smoothest results, but other options could be chosen instead.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们使用`interpolate`，这是一个`Pytorch`方法，将数据调整回原始人脸图像大小。我们必须这样做，因为像输入一样，masker模型的输出是512x512。我们使用`bicubic`因为它给出了最平滑的结果，但也可以选择其他选项。
- en: Next, we use `sum` and `where` to `255` or `0`. We also use `desired_segments`
    to remove the segments that aren’t useful to us. We’re using `.7` as a threshold
    here, so if we’re 70% sure that a given pixel should be in the mask, we keep it,
    but if it’s below that 70% cutoff, we throw that pixel out.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们使用`sum`和`where`将值设置为`255`或`0`。我们还使用`desired_segments`来移除对我们无用的片段。在这里，我们使用`.7`作为阈值，所以如果我们有70%的把握认为某个像素应该包含在掩码中，我们就保留它，但如果低于那个70%的截止值，我们就将该像素丢弃。
- en: Next, we move the data back to the CPU (if it was already on the CPU, then nothing
    changes) and convert it to a `Numpy` array.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将数据移回CPU（如果它已经在CPU上，则没有任何变化）并将其转换为`Numpy`数组。
- en: Finally, we save the mask image as a `.png` file so we can use it later.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将掩码图像保存为`.png`文件，以便以后使用。
- en: 'The last step of the entire extract process is to write the alignment data
    as a file:'
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 整个提取过程的最后一步是将对齐数据写入文件：
- en: '[PRE28]'
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Once each image is processed, the last step of the file is to save the file
    containing all the landmark data for later use. Here we use the `json_tricks`
    library, which has some useful functionality for writing out `Numpy` arrays as
    a JSON file. The library handles everything for writing and reading back the JSON
    file as `Numpy` arrays, so we can simply pass the full `dictionary` of arrays
    without manually converting them to lists or other default Python types for the
    Python standard library JSON to handle. For full documentation on this, please
    visit their documentation page at [https://json-tricks.readthedocs.io/en/latest/](https://json-tricks.readthedocs.io/en/latest/).
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦每个图像都经过处理，文件的最后一步是保存包含所有地标数据的文件，以供以后使用。在这里，我们使用`json_tricks`库，该库有一些将`Numpy`数组写入JSON文件的有用功能。该库处理写入和读取JSON文件作为`Numpy`数组的一切，因此我们可以简单地传递完整的`dictionary`数组，而无需手动将它们转换为列表或其他Python标准库JSON可以处理的其他默认Python类型。有关完整文档，请访问他们的文档页面[https://json-tricks.readthedocs.io/en/latest/](https://json-tricks.readthedocs.io/en/latest/)。
- en: At this point, we’ve extracted all the faces from a folder full of images. We’ve
    run them through multiple AI to get the data we need and formatted all that data
    for later use. This data is now ready for training, which will be covered in the
    next chapter.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经从一个充满图像的文件夹中提取了所有面部。我们运行了多个AI来获取所需的数据，并将所有这些数据格式化以供以后使用。这些数据现在已准备好进行训练，这将在下一章中介绍。
- en: Summary
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Extraction is the first step of the training process. In this chapter, we examined
    the data that we will need in later steps as well as the process of extracting
    the required training data from the source images. We went hands-on with the process,
    using multiple AIs to detect and landmark faces and generate a mask, as well as
    the necessary steps to process and save that data.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 提取是训练过程的第一步。在本章中，我们检查了后续步骤中需要的数据以及从源图像中提取所需训练数据的过程。我们亲自动手处理这个过程，使用多个AI来检测和标记面部并生成掩码，以及处理和保存这些数据的必要步骤。
- en: The `C5-face_detection.py` file can process a directory of images. So, we covered
    how to convert a video into a directory of images and how to process that directory
    through the script. The script creates all the files you need for training and
    some interesting debug images that let you visualize each of the processes the
    detector uses to process the images. We then looked at the entire process, line
    by line, so that we knew exactly what was going on inside that script, learning
    not just what was being output, but exactly how that output was created.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '`C5-face_detection.py` 文件可以处理一个图像目录。因此，我们介绍了如何将视频转换为图像目录以及如何通过脚本处理该目录。该脚本创建了你需要的所有训练文件，以及一些有趣的调试图像，这些图像让你可以可视化检测器处理图像时使用的每个过程。然后我们逐行检查整个过程，以便我们确切地知道脚本内部发生了什么，不仅学习了输出内容，而且确切地了解了输出是如何产生的。'
- en: 'After finishing the detection process, you can go through data cleaning, as
    talked about in [*Chapter 3*](B17535_03.xhtml#_idTextAnchor054), *Mastering Data*,
    to make sure your data is ready for the subject of the next chapter: training.'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成检测过程后，你可以进行数据清理，如第[*3章*](B17535_03.xhtml#_idTextAnchor054)中所述的*掌握数据*，以确保你的数据为下一章的主题：训练做好准备。
- en: Exercises
  id: totrans-167
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 练习
- en: We used pre-existing libraries for face detection, landmarking, and aligning
    landmarks. There are other libraries that offer similar functionality. Not all
    libraries work the same way, and implementing the differences is an extremely
    useful exercise. Try replacing the `face_alignment` library with another library
    for detecting faces, such as [https://github.com/timesler/facenet-pytorch](https://github.com/timesler/facenet-pytorch)
    or [https://github.com/serengil/deepface](https://github.com/serengil/deepface).
    Open source has lots of useful libraries but learning the differences and when
    to use one over another can be difficult, and converting between them can be a
    useful practice.
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用了现有的库来进行面部检测、地标标记和地标对齐。还有其他提供类似功能的库。并非所有库的工作方式都相同，实现这些差异是一项极其有用的练习。尝试用其他检测面部库替换
    `face_alignment` 库，例如 [https://github.com/timesler/facenet-pytorch](https://github.com/timesler/facenet-pytorch)
    或 [https://github.com/serengil/deepface](https://github.com/serengil/deepface)。开源有很多有用的库，但学习它们之间的差异以及何时使用一个而不是另一个可能很困难，而在这之间进行转换可能是一种有用的实践。
- en: 'We used `2D` landmarks for alignment in this chapter, but there may be a need
    for `3D` landmarks instead. Try replacing the following:'
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在本章中，我们使用了 `2D` 地标进行对齐，但可能需要 `3D` 地标。尝试替换以下内容：
- en: '[PRE29]'
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'with:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 'with:'
- en: '[PRE30]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: and adjust the rest of the process accordingly. You will also need to modify
    `MEAN_FACE` to account for the third dimension.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 并相应地调整其余过程。你还需要修改 `MEAN_FACE` 以考虑第三维。
- en: What other problems do `3D` landmarks include? What do you gain by using them?
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '`3D` 地标还包含哪些问题？使用它们你能得到什么好处？'
- en: 'In deepfakes, we’re most interested in faces, so this process uses techniques
    specific to faces. Imagine what you’d need to do to extract images of different
    objects. Watches, hats, or sunglasses, for example. The repo at [https://github.com/ultralytics/yolov5](https://github.com/ultralytics/yolov5)
    has a pre-trained model that can detect hundreds of different objects. Try extracting
    a different object instead of faces. Think in particular about how to do an alignment:
    can you utilize edge detection or color patterns to find points to which you can
    align?'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在深度伪造中，我们最感兴趣的是人脸，因此这个过程使用专门针对人脸的技术。想象一下你需要做些什么来提取不同物体的图像。例如，手表、帽子或太阳镜。在[https://github.com/ultralytics/yolov5](https://github.com/ultralytics/yolov5)的仓库中有一个预训练的模型，可以检测数百种不同的物体。尝试提取人脸以外的不同物体。特别思考如何进行对齐：你能利用边缘检测或颜色模式来找到可以对其对齐的点吗？
- en: Umeyama’s method treats every point that it aligns with equal importance, but
    what happens if you try to align with all 68 landmarks instead of just the `5`?
    What about 2 points? Can you find a better method? A faster method? A more accurate
    one? Try modifying the script to output all 68 landmark points in the `face_landmarks`
    `.png` file so you can visualize the process.
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Umeyama的方法将与其对齐的每个点视为同等重要，但如果你尝试与所有68个地标点对齐而不是仅仅的`5`个点，会发生什么？如果是2个点呢？你能找到一个更好的方法吗？一个更快的方法？一个更准确的方法吗？尝试修改脚本以输出`face_landmarks`
    `.png`文件中的所有68个地标点，这样你可以可视化这个过程。
- en: EBSCOhost - printed on 11/27/2023 6:20 AM via . All use subject to [https://www.ebsco.com/terms-of-use](https://www.ebsco.com/terms-of-use)
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: EBSCOhost - 2023年11月27日早上6:20打印。所有使用均受[https://www.ebsco.com/terms-of-use](https://www.ebsco.com/terms-of-use)条款约束。
