- en: '7'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '7'
- en: Enhancing the GenAISys with DeepSeek
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用DeepSeek增强GenAISys
- en: 'The *DeepSeek-V3 Technical Report* arrived in December 2024, followed a month
    later by the **DeepSeek-R1** paper and a full set of open source resources. The
    release sent a shockwave through the AI community: download counts on Hugging
    Face exploded, DeepSeek apps topped store charts, and new API providers sprang
    up overnight. Governments debated moratoriums while the major generative AI players—OpenAI,
    X (with Grok 3), and others—stepped on the gas. Within weeks, we saw o3 versions
    improve OpenAI models, a clear signal that the AI race had entered a new phase.
    At the same time, real-world AI production teams watched these dizzying innovations
    pile up, disrupting existing AI systems. Teams that spent months adapting their
    systems to one generative AI model found themselves caught in a gray area between
    systems that work but could still be improved.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '*DeepSeek-V3技术报告*于2024年12月发布，一个月后，**DeepSeek-R1**论文和一套完整的开源资源紧随其后。这一发布在AI社区中引起了轩然大波：Hugging
    Face上的下载量激增，DeepSeek应用在商店排行榜上名列前茅，新的API提供商一夜之间涌现。政府在辩论暂停令的同时，主要的生成式AI玩家——OpenAI、X（带有Grok
    3）和其他人——加快了步伐。在几周内，我们看到了o3版本改进了OpenAI模型，这是一个明确的信号，表明AI竞赛已经进入了一个新的阶段。与此同时，现实世界的AI生产团队目睹了这些令人眼花缭乱的创新堆积起来，破坏了现有的AI系统。那些花费数月时间调整其系统以适应一个生成式AI模型的团队发现自己陷入了系统工作但仍有改进空间的灰色地带。'
- en: So, what should we do? Should we upgrade a stable GenAISys to follow the latest
    trend in an accelerating AI market with the cost and risks entailed? Or should
    we ignore the latest models if our system is stable? If we ignore evolutions,
    our system may become obsolete. If we keep following the trends, our system will
    become unstable!
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们应该怎么做？我们应该以成本和风险为代价，将稳定的GenAISys升级以跟随加速的AI市场的最新趋势吗？或者，如果我们的系统稳定，我们应该忽略最新的模型吗？如果我们忽略进化，我们的系统可能会过时。如果我们继续跟随趋势，我们的系统可能会变得不稳定！
- en: This chapter shows how to strike a workable balance. Instead of rewriting entire
    environments for every model upgrade or new functionality, we introduce a **handler-selection
    mechanism** that routes user requests to the right tool at the right time. A **handler
    registry** stores every AI function we develop; the selection layer inspects each
    incoming message and triggers the appropriate handler. With this design, the GenAISys
    can evolve indefinitely without destabilizing the stack. We will begin the chapter
    by defining how a balanced approach can be found between model evolutions and
    real-world usage, illustrated through a product design and production use case.
    Next comes a concise look at DeepSeek-V3, DeepSeek-R1, and the distilled Llama
    model we’ll implement. Then, we’ll install **DeepSeek-R1-Distill-Llama-8B** locally
    with Hugging Face, wrap it in a reusable function, and then plug it into our GenAISys.
    At that point, we will develop the flexible, scalable environment of the handler-selection
    mechanism to allow us to activate the models and tasks we need for each project.
    By the end of the chapter, you will be able to have full control over the GenAISys
    and be ready for whatever the AI market throws at you.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章展示了如何找到一个可行的平衡点。我们不是为每个模型升级或新功能重写整个环境，而是引入了一个**处理器选择机制**，该机制将用户请求路由到正确的时间的正确工具。一个**处理器注册表**存储了我们开发的每个AI功能；选择层检查每个传入的消息并触发适当的处理器。这种设计使得GenAISys可以无限期地进化而不会破坏堆栈。我们将从定义如何在模型演化和实际使用之间找到一个平衡方法开始本章，通过产品设计和生产用例进行说明。接下来，我们将简要介绍DeepSeek-V3、DeepSeek-R1以及我们将要实施的精炼Llama模型。然后，我们将使用Hugging
    Face本地安装**DeepSeek-R1-Distill-Llama-8B**，将其封装在一个可重用的函数中，并将其插入到我们的GenAISys中。到那时，我们将开发灵活、可扩展的处理器选择机制环境，以便我们可以激活每个项目所需的模型和任务。到本章结束时，你将能够完全控制GenAISys，并准备好应对AI市场带来的任何挑战。
- en: 'This chapter covers the following topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖了以下主题：
- en: The balance between AI acceleration and usage
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人工智能加速与使用的平衡
- en: An overview of DeepSeek-V3, R1, and distillation models
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DeepSeek-V3、R1和蒸馏模型的概述
- en: Installing DeepSeek-R1-Distill-Llama-8B locally
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本地安装DeepSeek-R1-Distill-Llama-8B
- en: Creating a function to run DeepSeek-R1-Distill-Llama-8B
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个运行DeepSeek-R1-Distill-Llama-8B的函数
- en: Deploying DeepSeek-R1-Distill-Llama-8B in the GenAISys
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在GenAISys中部署DeepSeek-R1-Distill-Llama-8B
- en: Building a handler registry for all the AI functions
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为所有AI功能构建处理器注册表
- en: Building a handler-selection mechanism to select the handlers
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建处理器选择机制以选择处理器
- en: Upgrading the AI functions to be handler-compatible
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 升级AI功能以兼容处理器
- en: Running product design and production examples
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行产品设计和生产示例
- en: Let’s start by defining the balance between relentless AI evolution and day-to-day
    business usage.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从定义不懈的AI进化与日常业务使用之间的平衡开始。
- en: Balancing model evolution with project needs
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 平衡模型进化与项目需求
- en: Before racing to adopt every new model, we must anchor our decisions on project
    needs. So far, our GenAISys has served mostly marketing functions for an online
    travel agency. Now, imagine that the agency has grown large enough to fund a line
    of branded merchandise—custom travel bags, booklets, and other goodies. To manage
    this new venture, the company hires a **product designer and production manager**
    (**PDPM**). The PDPM studies customer feedback and designs personalized kits but
    quickly sees that AI could boost both creativity and throughput.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在急于采用每个新模型之前，我们必须根据项目需求来做出决策。到目前为止，我们的GenAISys主要服务于在线旅行社的营销功能。现在，想象一下，这家旅行社已经发展壮大，足以资助一系列品牌商品——定制旅行包、手册和其他好东西。为了管理这项新业务，公司雇佣了一位**产品设计师和生产经理**（**PDPM**）。PDPM研究客户反馈并设计个性化套装，但很快发现AI可以提升创造力和效率。
- en: The examples in this chapter thus focus on product design and production workflows.
    Our goal is not to force DeepSeek (or any other model) into every task but to
    choose the model that best fits the need. To do that, we’ll extend the GenAISys
    with a handler-selection mechanism that responds to user choices in the IPython
    interface and to keywords in each message. Depending on the situation, the operations
    team can configure the system to route requests to GPT-4o, DeepSeek, or any future
    model.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的示例因此专注于产品设计和生产工作流程。我们的目标不是将DeepSeek（或任何其他模型）强加到每个任务上，而是选择最适合需求的模型。为此，我们将通过一个处理程序选择机制扩展GenAISys，该机制响应IPython界面中的用户选择和每条消息中的关键词。根据具体情况，操作团队可以配置系统将请求路由到GPT-4o、DeepSeek或任何未来的模型。
- en: Before wiring DeepSeek into our GenAISys, let’s review the DeepSeek model family.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在将DeepSeek集成到我们的GenAISys之前，让我们回顾一下DeepSeek模型家族。
- en: 'DeepSeek-V3, DeepSeek-V1, and R1-Distill-Llama: Overview'
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: DeepSeek-V3, DeepSeek-V1, 和 R1-Distill-Llama：概述
- en: DeepSeek’s journey began with DeepSeek-V3, advanced to DeepSeek-R1—a reasoning-focused
    upgrade—and then branched into distilled variants built on Qwen and Llama architectures,
    as shown in *Figure 7.1*. V3 was responsible for putting the model on the map,
    and it was R1 that brought in robust reasoning.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: DeepSeek的旅程始于DeepSeek-V3，发展到DeepSeek-R1——一个以推理为重点的升级，然后分支到基于Qwen和Llama架构的蒸馏变体，如图*图7.1*所示。V3负责将模型推向市场，而R1则带来了强大的推理能力。
- en: '![Figure 7.1: DeepSeek development cycle](img/B32304_07_1.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![图7.1：DeepSeek开发周期](img/B32304_07_1.png)'
- en: 'Figure 7.1: DeepSeek development cycle'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.1：DeepSeek开发周期
- en: According to DeepSeek-AI et al. (2024), V3 delivered striking efficiency gains.
    Its full training budget was only 2.788 million H800 GPU-hours (≈ USD 5.6 million
    at USD 2 per GPU-hour)—remarkably low for a modern frontier model. Even on a per-token
    basis, the cost is lean, needing just 180 K GPU-hours per trillion tokens. The
    cost is, therefore, very economical compared to what is typically reported for
    large-scale models.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 根据DeepSeek-AI等人（2024）的研究，V3实现了显著的效率提升。其完整训练预算仅为2.788百万H800 GPU小时（≈每GPU小时2美元的5.6百万美元）——对于一个现代前沿模型来说，这个成本非常低。即使是按每个token计算，成本也很低，只需180
    K GPU小时就能处理万亿个tokens。因此，与通常报道的大规模模型相比，成本非常经济。
- en: When we examine the list of authors of the DeepSeek-V3 Technical Report (2024)
    on arXiv, [https://arxiv.org/abs/2412.19437](https://arxiv.org/abs/2412.19437),
    we first notice that more than 150 specialists wrote the paper! In itself, this
    factor alone proves the efficiency of open source approaches that involve collective
    efforts to produce efficiency-driven architectures by opening ideas to every person
    willing to contribute. The list of *Contributions and Acknowledgements* in *Appendix
    A* is a tribute to open source developments.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们查看arXiv上DeepSeek-V3技术报告（2024）的作者名单[https://arxiv.org/abs/2412.19437](https://arxiv.org/abs/2412.19437)时，我们首先注意到超过150位专家撰写了这篇论文！仅此一点，就证明了开源方法的有效性，这些方法涉及集体努力，通过向愿意贡献的每个人开放思想来产生效率驱动的架构。《附录A》中的*贡献和致谢*名单是对开源发展的致敬。
- en: '![Figure 7.2: DeepSeek-R1 is derived from DeepSeek-V3](img/B32304_07_2.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![图7.2：DeepSeek-R1源自DeepSeek-V3](img/B32304_07_2.png)'
- en: 'Figure 7.2: DeepSeek-R1 is derived from DeepSeek-V3'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.2：DeepSeek-R1源自DeepSeek-V3
- en: DeepSeek-R1 grew straight out of DeepSeek-V3\. The team wanted V3’s punch, but
    with feather-weight inference, so they wired the model to activate only a minimal
    subset of experts during inference, as shown in *Figure 7.2*. Furthermore, training
    stayed just as lean. R1 jumped directly into reinforcement learning with no supervised
    fine-tuning. The reasoning was high but faced limitations for classic NLP tasks.
    Rule-based rewards were introduced to avoid the neural network’s training cycles.
    The training prompts were structured with neat `<think> … <answer>` tags, avoiding
    the smuggling of biases into the model’s final answer. Moreover, the reinforcement
    learning process began with *cold-start* data containing **chain of thought**
    (**CoT**) examples focusing on reasoning. This approach reduced training time
    and costs.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: DeepSeek-R1 直接从 DeepSeek-V3 发展而来。团队希望拥有 V3 的冲击力，但又要实现轻量级的推理，因此他们在推理时仅激活了专家的最小子集，如图
    *图 7.2* 所示。此外，训练过程也保持了简洁。R1 直接进入强化学习，没有进行监督微调。推理能力很高，但面对经典 NLP 任务的限制。引入基于规则的奖励以避免神经网络训练周期。训练提示以整洁的
    `<think> … <answer>` 标签结构化，避免将偏见带入模型的最终答案。此外，强化学习过程从包含 **思维链**（**CoT**）示例的 *冷启动*
    数据开始，这些示例专注于推理。这种方法减少了训练时间和成本。
- en: DeepSeek evolved to R1 by refining MoE strategies and integrating multi-token
    prediction, significantly enhancing both accuracy and efficiency. Finally, DeepSeek-R1
    was used to enhance DeepSeek-V3 with reasoning features. DeepSeek-R1 was also
    distilled into smaller models such as Llama and Qwen. The technique used was knowledge
    distillation, where a smaller “student” model (in this chapter, Llama) learns
    from a “teacher” model (in this chapter, DeepSeek-R1). This approach is effective
    in that it teaches the student model to achieve performance similar to that of
    the teacher while being more efficient and suitable for deployment on resource-constrained
    devices, which will be the case in this chapter, as you’ll see.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: DeepSeek 通过优化 MoE 策略和集成多令牌预测，演变为 R1，显著提高了准确性和效率。最终，DeepSeek-R1 被用于增强 DeepSeek-V3
    的推理功能。DeepSeek-R1 还被蒸馏成更小的模型，如 Llama 和 Qwen。所使用的技术是知识蒸馏，其中较小的“学生”模型（在本章中为 Llama）从“教师”模型（在本章中为
    DeepSeek-R1）学习。这种方法有效，因为它教会学生模型达到与教师模型相似的性能，同时更高效且适合部署在资源受限的设备上，正如您在本章中将会看到的。
- en: Let’s install and run DeepSeek-R1-Distill-Llama-8B and plug it into our GenAISys.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们安装并运行 DeepSeek-R1-Distill-Llama-8B 并将其连接到我们的 GenAISys。
- en: Getting started with DeepSeek-R1-Distill-Llama-8B
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开始使用 DeepSeek-R1-Distill-Llama-8B
- en: In this section, we will implement DeepSeek-RAI-Distill-Llama-8B, a distilled
    version of DeepSeek-R1, as shown in *Figure 7.3*. We will install Hugging Face’s
    open-source `Transformers` library, an open framework for using and fine-tuning
    pre-trained transformer models.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将实现 DeepSeek-RAI-Distill-Llama-8B，这是 DeepSeek-R1 的精简版本，如图 *图 7.3* 所示。我们将安装
    Hugging Face 的开源 `Transformers` 库，这是一个用于使用和微调预训练 Transformer 模型的开放框架。
- en: '![Figure 7.3: Installing DeepSeek-RAI-Distill-Llama-8B, a distilled version
    of DeepSeek-R1](img/B32304_07_3.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.3：安装 DeepSeek-RAI-Distill-Llama-8B，DeepSeek-R1 的精简版本](img/B32304_07_3.png)'
- en: 'Figure 7.3: Installing DeepSeek-RAI-Distill-Llama-8B, a distilled version of
    DeepSeek-R1'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.3：安装 DeepSeek-RAI-Distill-Llama-8B，DeepSeek-R1 的精简版本
- en: 'We will be using the DeepSeek-RAI-Distill-Llama-8B documented by Hugging Face:
    [https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B).
    Hugging Face also provides recommendations for this model: [https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B#usage-recommendations](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B#usage-recommendations).'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 Hugging Face 记录的 DeepSeek-RAI-Distill-Llama-8B：[https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B)。Hugging
    Face 还为此模型提供了推荐：[https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B#usage-recommendations](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B#usage-recommendations)。
- en: 'The version we will download is an open source distilled version of DeepSeek-R1
    provided by Unsloth, an LLM accelerator, on Hugging Face: [https://unsloth.ai/](https://unsloth.ai/).
    We will thus not use a DeepSeek API but only a locally installed open source version
    that does not interact with the web, leveraging Hugging Face’s SOC 2 Type 2 certification
    that complies with privacy and security constraints: [https://huggingface.co/docs/inference-endpoints/en/security](https://huggingface.co/docs/inference-endpoints/en/security).'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将下载的版本是由 LLM 加速器 Unsloth 提供的 DeepSeek-R1 的开源蒸馏版本，在 Hugging Face 上：[https://unsloth.ai/](https://unsloth.ai/)。因此，我们将不使用
    DeepSeek API，而只使用本地安装的开源版本，该版本不与网络交互，利用 Hugging Face 的 SOC 2 Type 2 认证，符合隐私和安全约束：[https://huggingface.co/docs/inference-endpoints/en/security](https://huggingface.co/docs/inference-endpoints/en/security)。
- en: To install deepseek-ai/DeepSeek-R1-Distill-Llama-8B locally on a recent machine,
    it is recommended to have about 20 GB of RAM. A bit less is possible, but it is
    best to avoid the risk. About 20 GB of disk space is also recommended.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在本地机器上安装 deepseek-ai/DeepSeek-R1-Distill-Llama-8B，建议拥有大约 20 GB 的 RAM。稍微少一点也是可能的，但最好避免风险。也建议大约
    20 GB 的磁盘空间。
- en: To install DeepSeek-R1-Distill-Llama-8B on Google Colab, it is recommended to
    use Google Colab Pro to obtain GPU memory and power. For this section, the Hugging
    Face model is downloaded on Google Drive, which is mounted through Google Colab.
    The disk space required will exceed the free version of Google Drive, and a minimal
    subscription to Google Drive may be required. Check the costs before installing
    on Google Colab.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Google Colab 上安装 DeepSeek-R1-Distill-Llama-8B，建议使用 Google Colab Pro 以获得 GPU
    内存和动力。在本节中，Hugging Face 模型是在 Google Drive 上下载的，并通过 Google Colab 挂载。所需的磁盘空间将超过
    Google Drive 的免费版本，可能需要 Google Drive 的最小订阅。在 Google Colab 上安装之前请检查费用。
- en: 'Open `Getting_started_with_DeepSeek_R1_Distill_Llama_8B.ipynb` within the Chapter07
    directory on GitHub ([https://github.com/Denis2054/Building-Business-Ready-Generative-AI-Systems/tree/main](https://github.com/Denis2054/Building-Business-Ready-Generative-AI-Systems/tree/main)).
    We will follow the standard procedure of the Hugging Face framework:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在 GitHub 的 Chapter07 目录中打开 `Getting_started_with_DeepSeek_R1_Distill_Llama_8B.ipynb`
    ([https://github.com/Denis2054/Building-Business-Ready-Generative-AI-Systems/tree/main](https://github.com/Denis2054/Building-Business-Ready-Generative-AI-Systems/tree/main))。我们将遵循
    Hugging Face 框架的标准程序：
- en: 'Run the notebook once to install DeepSeek-R1-Distill-Llama-8B locally:'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行一次笔记本以在本地安装 DeepSeek-R1-Distill-Llama-8B：
- en: '[PRE0]'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Run the notebook with no installation and interact with the model:'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无需安装即可运行笔记本并与模型交互：
- en: '[PRE1]'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: With the model in place, we can wrap it in a handler and plug it into our GenAISys
    in the next section.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 模型就位后，我们可以在下一节中将它包装在处理器中，并将其插入我们的 GenAISys。
- en: Setting up the DeepSeek Hugging Face environment
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置 DeepSeek Hugging Face 环境
- en: We’ll begin by installing DeepSeek-R1-Distill-Llama-8B (locally or in Colab)
    and then run a quick inference to confirm everything works.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先安装 DeepSeek-R1-Distill-Llama-8B（本地或 Colab），然后运行快速推理以确认一切正常工作。
- en: 'We will first install DeepSeek in the first session:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在第一个会话中首先安装 DeepSeek：
- en: '[PRE2]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The GPU needs to be activated, so let’s check it:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 需要激活 GPU，让我们检查一下：
- en: '[PRE3]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'If we are installing Google Colab, we can mount Google Drive:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们在安装 Google Colab，我们可以挂载 Google Drive：
- en: '[PRE4]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We now set the cache directory in Google Drive and set the corresponding environment
    variables:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在设置 Google Drive 中的缓存目录并设置相应的环境变量：
- en: '[PRE5]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We can now install the Hugging Face `Transformers` library:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以安装 Hugging Face 的 `Transformers` 库：
- en: '[PRE6]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: With that, we are ready to download the model.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，我们就准备好下载模型了。
- en: Downloading DeepSeek
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下载 DeepSeek
- en: 'Let’s now download the model from `unsloth/DeepSeek-R1-Distill-Llama-8B` within
    the Hugging Face framework with the tokenizer and the model:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们在 Hugging Face 框架内从 `unsloth/DeepSeek-R1-Distill-Llama-8B` 下载模型，包括分词器和模型：
- en: '[PRE7]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The download time will be displayed and also depends on your internet connection
    and Hugging Face’s download speed. Once installed, verify that everything is installed
    in your local directory. In this case, it is as follows:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 下载时间将显示，并取决于您的互联网连接和 Hugging Face 的下载速度。安装完成后，请验证本地目录中是否已安装所有内容。在这种情况下，如下所示：
- en: '[PRE8]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The output should show the files downloaded:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 输出应显示下载的文件：
- en: '[PRE9]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Now, let’s run a DeepSeek session.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们运行一个 DeepSeek 会话。
- en: Running a DeepSeek-R1-Distill-Llama-8B session
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 运行 DeepSeek-R1-Distill-Llama-8B 会话
- en: 'To make sure the model is correctly installed and also to avoid overwriting
    the installation when starting a new session, go back to the top of the notebook
    and set the following:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保模型正确安装，并避免在启动新会话时覆盖安装，请回到笔记本的顶部并设置以下内容：
- en: '[PRE10]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We will now load the `DeepSeek-R1-Distill-Llama-8B` tokenizer and model locally:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将本地加载 `DeepSeek-R1-Distill-Llama-8B` 分词器和模型：
- en: '[PRE11]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The time it took to load the model is displayed and will depend on the configuration
    of your machine:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 加载模型所需的时间将显示，并取决于你的机器配置：
- en: '[PRE12]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'We can have a look at the configuration of the Llama model:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以查看 Llama 模型的配置：
- en: '[PRE13]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The output shows interesting information. The `LlamaConfig` readout confirms
    we are running a compact, well-scoped model:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示了有趣的信息。`LlamaConfig` 的读取确认我们正在运行一个紧凑、范围明确的模型：
- en: '[PRE14]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The distilled Llama model has 32 transformer layers and 32 attention heads
    per layer, totaling 1,024 attention heads. Also, it contains 8 billion parameters.
    By contrast, its teacher model, **DeepSeek-R1**, is an MoE giant with **61 layers**
    and a massive **671 billion parameters**, of which about **37 billion** are active
    on each forward pass. Let’s now run an example with a prompt for a production
    issue:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 精炼的 Llama 模型有 32 个 transformer 层和每层 32 个注意力头，总共 1,024 个注意力头。此外，它包含 80 亿个参数。相比之下，其教师模型
    **DeepSeek-R1** 是一个 MoE 巨型，有 **61 层** 和庞大的 **6710 亿参数**，其中大约 **370 亿** 在每次前向传递时是活跃的。现在让我们用一个针对生产问题的提示来运行一个示例：
- en: '[PRE15]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We first insert time measurement and tokenize the input using the GPU:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先插入时间测量，并使用 GPU 对输入进行分词：
- en: '[PRE16]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Then, we run the generation:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们运行生成：
- en: '[PRE17]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The goal of our parameters is to limit the repetitions and remain focused:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们参数的目标是限制重复并保持专注：
- en: '`max_new_tokens=1200`: To limit the number of output tokens'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_new_tokens=1200`: 限制输出标记的数量'
- en: '`repetition_penalty=1.5`: To limit the repetitions (can be higher)'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`repetition_penalty=1.5`: 限制重复（可以更高）'
- en: '`no_repeat_ngram_size=3`: To prevent repeating n-grams of a particular size'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`no_repeat_ngram_size=3`: 防止重复特定大小的 n-gram'
- en: '`temperature=0.6`: To reduce randomness and stay focused'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`temperature=0.6`: 减少随机性并保持专注'
- en: '`top_p=0.9`: Allows nucleus sampling for diversity'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`top_p=0.9`: 允许核采样以增加多样性'
- en: '`top_k=50`: Limits token selection to `top_k` to make the next token choice'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`top_k=50`: 将标记选择限制为 `top_k` 以进行下一个标记选择'
- en: 'This set of tokens tends to limit repetitions while allowing diversity. We
    can now decode the generated text with the tokenizer:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这组标记倾向于限制重复，同时允许多样性。现在我们可以使用分词器解码生成的文本：
- en: '[PRE18]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The output shows the overall time it took the model to think and respond:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示了模型思考和响应所花费的总时间：
- en: '[PRE19]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Let’s wrap `generated_text` and display it:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将 `generated_text` 包装并显示：
- en: '[PRE20]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The output provides ideas as requested. It displays DeepSeek-R1’s thinking
    abilities:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 输出提供了所需的想法。它显示了 DeepSeek-R1 的思考能力：
- en: '[PRE21]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Integrating DeepSeek-R1-Distill-Llama-8B
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 集成 DeepSeek-R1-Distill-Llama-8B
- en: 'In this section, we will add DeepSeek-R1-Distill-Llama-8B to our GenAISys in
    a few steps. Open `GenAISys_DeepSeek.ipynb`. You can decide to run the notebook
    with DeepSeek in the first cell, which will require a GPU:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将通过几个步骤将 DeepSeek-R1-Distill-Llama-8B 添加到我们的 GenAISys 中。打开 `GenAISys_DeepSeek.ipynb`。你可以决定在第一个单元中运行笔记本，这将需要
    GPU：
- en: '[PRE22]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'You can also decide not to run DeepSeek in this notebook, in which case, you
    will not need a GPU and can change the runtime to CPU. If you decide on this option,
    OpenAI’s API will take over, confirming that no GPU is required:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以选择不在本笔记本中运行 DeepSeek，在这种情况下，你不需要 GPU，可以将运行时更改为 CPU。如果你选择此选项，OpenAI 的 API
    将接管，确认不需要 GPU：
- en: '[PRE23]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Now, go to the *Setting up the DeepSeek Hugging Face environment* subsection
    of the notebook. We will simply transfer the following cells from `Getting_started_with_DeepSeek_R1_Distill_Llama_8B.ipynb`
    to this subsection. The following code will only be activated if `deepseek=True`:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，转到笔记本的 *设置 DeepSeek Hugging Face 环境* 子节。我们将简单地从 `Getting_started_with_DeepSeek_R1_Distill_Llama_8B.ipynb`
    将以下单元格转移到这个子节。以下代码仅在 `deepseek=True` 时激活：
- en: 'GPU activation check: `!nvidia-smi`'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPU 激活检查：`!nvidia-smi`
- en: 'Setting the local cache of the model: `…os.environ[''TRANSFORMERS_CACHE'']
    =cache_dir…`'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置模型的本地缓存：`…os.environ['TRANSFORMERS_CACHE'] =cache_dir…`
- en: 'Installing the Hugging Face library: `!pip install transformers==4.48.3`'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装 Hugging Face 库：`!pip install transformers==4.48.3`
- en: 'Loading the tokenizer and the model:'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加载分词器和模型：
- en: '[PRE24]'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The installation is now complete. The calls to the DeepSeek model will be made
    in the *AI Functions* section if `DeepSeek==True` with the parameters described
    in the *Running a DeepSeek-R1-Distill-Llama-8B session* section:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 安装现在已完成。如果`DeepSeek==True`，则DeepSeek模型的调用将在*AI函数*部分进行，参数在*运行DeepSeek-R1-Distill-Llama-8B会话*部分中描述：
- en: '[PRE25]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: With DeepSeek functioning, we’re ready to build the handler selection mechanism,
    which will route every user request to GPT-4o, DeepSeek, or any future model—without
    touching the rest of the stack.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在DeepSeek运行的情况下，我们已准备好构建处理器选择机制，该机制将把每个用户请求路由到GPT-4o、DeepSeek或任何未来的模型——而不触及堆栈的其余部分。
- en: Implementing the handler selection mechanism as an orchestrator of the GenAISys
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将处理器选择机制作为GenAISys的编排器实现
- en: The PDPM at the online travel agency is experiencing increased demands, requiring
    the agency to design and produce large quantities of merchandise kits, including
    travel bags, booklets, and pens. The PDPM wants to be directly involved in the
    GenAISys development to explore how it can significantly boost productivity.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在在线旅行社中，PDPM正面临日益增长的需求，要求旅行社设计和生产大量商品套装，包括旅行包、手册和笔。PDPM希望直接参与GenAISys的开发，以探索它如何显著提高生产力。
- en: 'Given the growing complexity and variety of AI tasks in the system, the GenAISys
    development team has decided to organize these tasks using handlers, as illustrated
    in *Figure 7.4*:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 由于系统中AI任务的复杂性和多样性不断增加，GenAISys开发团队已决定使用处理器来组织这些任务，如图*7.4*所示：
- en: '![Figure 7.4: GenAISys data flow and component interaction](img/B32304_07_4.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![图7.4：GenAISys数据流和组件交互](img/B32304_07_4.png)'
- en: 'Figure 7.4: GenAISys data flow and component interaction'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.4：GenAISys数据流和组件交互
- en: We’ll, therefore, define, implement, and then invite the PDPM to run the enhanced
    GenAISys to evaluate functions aimed at improving productivity in merchandise
    design and production.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们将定义、实现该处理器选择机制，然后邀请PDPM运行增强版的GenAISys，以评估旨在提高商品设计和生产效率的函数。
- en: '*Figure 7.4* describes the behavior of the handler pipeline we are going to
    implement:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '*图7.4*描述了我们将要实施的处理器管道的行为：'
- en: The **IPython interface** serves as the entry and exit point for user interactions,
    capturing user input, formatting it, and displaying responses returned by the
    handler mechanism.
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**IPython界面**作为用户交互的入口和出口点，捕获用户输入，对其进行格式化，并显示处理器机制返回的响应。'
- en: The **handler mechanism** interprets user inputs, directing data among the IPython
    interface, the handler registry, and the AI functions. It ensures tasks triggered
    by user messages execute smoothly.
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**处理器机制**解释用户输入，在IPython界面、处理器注册表和AI函数之间引导数据。它确保由用户消息触发的任务能够顺利执行。'
- en: The **handler registry** maintains a list of all available handlers and their
    corresponding functions. It supports system modularity and scalability by clarifying
    handler registration and retrieval.
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**处理器注册表**维护所有可用处理器及其对应函数的列表。它通过明确处理器注册和检索来支持系统模块化和可扩展性。'
- en: '**AI functions** perform core tasks such as natural language understanding
    and data analysis, executing instructions received from the handler mechanism,
    and returning outputs to the IPython Interface.'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**AI函数**执行核心任务，如自然语言理解和数据分析，执行从处理器机制接收的指令，并将输出返回到IPython界面。'
- en: In this setup, a user provides input through the IPython interface. This input
    is routed into a handler selection mechanism, which then evaluates the available
    handlers registered alongside specific conditions. Each entry in the registry
    is a (condition, handler) pair responsible for different operations such as reasoning,
    image generation, or data analysis. Once a matching condition is found, the corresponding
    AI function is activated. After processing, it returns the results to the interface.
    This structured pipeline—from user input through to the AI-generated response—is
    handled gracefully, with each handler clearly defined for readability and efficiency.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在此设置中，用户通过IPython界面提供输入。此输入被路由到处理器选择机制，该机制随后评估注册的可用处理器以及特定条件。注册表中的每个条目都是一个（条件，处理器）对，负责不同的操作，如推理、图像生成或数据分析。一旦找到匹配的条件，相应的AI函数就会被激活。处理完毕后，它将结果返回到界面。这个结构化的管道——从用户输入到AI生成的响应——被优雅地处理，每个处理器都明确定义以提高可读性和效率。
- en: Before coding, let’s clearly define what we mean by a “handler” in the GenAISys.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在编码之前，让我们明确定义在GenAISys中我们所说的“处理器”是什么。
- en: What is a handler?
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是处理器？
- en: A handler is essentially a specialized function responsible for addressing specific
    tasks or types of requests. Each handler is registered alongside a condition,
    typically a small function or lambda expression. When evaluated as `True`, this
    condition indicates that the associated handler should be invoked. This design
    neatly decouples the logic for deciding *which* handler should run from *how*
    the handler executes its task.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 处理器本质上是一个专门的功能，用于处理特定的任务或请求类型。每个处理器都与一个条件注册在一起，通常是一个小的函数或lambda表达式。当评估为`True`时，这个条件表明应该调用相关的处理器。这种设计巧妙地将决定“哪个”处理器应该运行的逻辑与处理器执行其任务的逻辑分离。
- en: In our context, handlers are the orchestrator’s building blocks—conditional
    functions designed to process specific input types. When a user provides input,
    the handler selection mechanism evaluates it against the handler registry, which
    consists of pairs of conditions and handlers. Upon finding a match, the corresponding
    handler is triggered, invoking specialized functions such as `handle_generation`,
    `handle_analysis`, or `handle_pinecone_rag`. These handlers execute sophisticated
    reasoning, data retrieval, or content generation tasks, providing precise and
    targeted outputs.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的上下文中，处理器是协调器的构建块——设计用于处理特定输入类型的条件函数。当用户提供输入时，处理器选择机制将其与处理器注册表进行比较，该注册表由条件和处理器成对组成。一旦找到匹配项，相应的处理器就会被触发，调用专门的函数，如`handle_generation`、`handle_analysis`或`handle_pinecone_rag`。这些处理器执行复杂的推理、数据检索或内容生成任务，提供精确和有针对性的输出。
- en: But why exactly is a handler better for our GenAISys than a traditional list
    of `if…then` conditions?
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 但为什么处理器（handler）比传统的`if…then`条件列表更适合我们的GenAISys呢？
- en: Why is a handler better than a traditional if...then list?
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么处理器比传统的if...then列表更好？
- en: 'Using handlers improves maintainability and readability. Instead of scattering
    multiple `if...then` checks across the code, each handler is self-contained: it
    has its condition and a separate function that carries out the required action.
    This structure makes it easier to add, remove, or modify handlers without risking
    unintended interactions in a chain of lengthy conditionals. Additionally, since
    it separates the logic of “which handler do we need?” from “how does that handler
    actually work?” we’re left with a more modular design that makes scaling seamless.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 使用处理器可以提高可维护性和可读性。而不是在代码中分散多个`if...then`检查，每个处理器都是自包含的：它有自己的条件和执行所需操作的单独函数。这种结构使得在不冒险在长条件链中产生意外交互的情况下添加、删除或修改处理器变得更容易。此外，由于它将“我们需要哪个处理器？”的逻辑与“该处理器实际上是如何工作的？”的逻辑分开，我们得到了一个更模块化的设计，这使得扩展变得无缝。
- en: We will first go through the modifications to our IPython interface.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先介绍我们对IPython界面的修改。
- en: 1\. IPython interface
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1. IPython界面
- en: We’ll start by reviewing the primary updates to our IPython interface, which
    remains the main interaction point, as shown in *Figure 7.5*. From a user perspective,
    the introduction of handlers doesn’t alter the interface significantly, but some
    underlying code adjustments are necessary.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先回顾一下我们对IPython界面的主要更新，它仍然是主要的交互点，如*图7.5*所示。从用户的角度来看，引入处理器并没有显著改变界面，但需要对一些底层代码进行调整。
- en: '![Figure 7.5: The IPython interface processes the user input and displays the
    output](img/B32304_07_5.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![图7.5：IPython界面处理用户输入并显示输出](img/B32304_07_5.png)'
- en: 'Figure 7.5: The IPython interface processes the user input and displays the
    output'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.5：IPython界面处理用户输入并显示输出
- en: 'The IPython interface calls `chat_with_gpt` as before:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: IPython界面像以前一样调用`chat_with_gpt`：
- en: '[PRE26]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Now, however, we can explicitly select either an OpenAI or a DeepSeek model
    with the following:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，然而，我们可以明确选择OpenAI或DeepSeek模型，如下所示：
- en: '[PRE27]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'To add the model to the `chat_with_gpt` call, we first add a drop-down model
    selector to the interface:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 要将模型添加到`chat_with_gpt`调用中，我们首先在界面中添加一个下拉模型选择器：
- en: '[PRE28]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The model selector is added to the `VBox` instances in the interface:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 模型选择器被添加到界面中的`VBox`实例中：
- en: '[PRE29]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The user can now choose their preferred model directly from the interface,
    as shown here:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 用户现在可以直接从界面中选择他们偏好的模型，如图所示：
- en: '![Figure 7.6: Selecting a model](img/B32304_07_6.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![图7.6：选择模型](img/B32304_07_6.png)'
- en: 'Figure 7.6: Selecting a model'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.6：选择模型
- en: '![A magnifying glass on a black background  AI-generated content may be incorrect.](img/1.png)**Quick
    tip**: Need to see a high-resolution version of this image? Open this book in
    the next-gen Packt Reader or view it in the PDF/ePub copy.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '![黑色背景上的放大镜  AI生成的内容可能不正确。](img/1.png)**快速提示**：需要查看此图像的高分辨率版本？在下一代Packt Reader中打开此书或在其PDF/ePub副本中查看。'
- en: '![](img/2.png)**The next-gen Packt Reader** is included for free with the purchase
    of this book. Scan the QR code OR go to [packtpub.com/unlock](http://packtpub.com/unlock),
    then use the search bar to find this book by name. Double-check the edition shown
    to make sure you get the right one.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/2.png)**新一代Packt Reader**随本书免费赠送。扫描二维码或访问[packtpub.com/unlock](http://packtpub.com/unlock)，然后使用搜索栏通过名称查找本书。请仔细核对显示的版本，以确保您获得正确的版本。'
- en: '![A qr code on a white background  AI-generated content may be incorrect.](img/Unlock_Code2.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![白色背景上的二维码  AI生成的内容可能不正确。](img/Unlock_Code2.png)'
- en: An additional feature has been added to manage file displays.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 已添加一个额外的功能来管理文件显示。
- en: File management
  id: totrans-151
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 文件管理
- en: 'There are many ways to design file management. We will introduce a function
    here that can be expanded during a project’s implementation phase as needed. Our
    file management code has three functions:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 设计文件管理的方式有很多。在这里，我们将介绍一个可以在项目实施阶段根据需要扩展的功能。我们的文件管理代码有三个函数：
- en: Manage user-triggered file deletion
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理用户触发的文件删除
- en: Delete `c_image.png` when the checkbox is unchecked
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当复选框取消选中时删除`c_image.png`
- en: Use existence checks to prevent errors during deletion
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用存在性检查来防止删除时的错误
- en: We will build the code to handle user interactions directly by observing changes
    in the checkbox widget of our interface within the Jupyter Notebook environment.
    The code will then delete a specific image file (`c_image.png`) when the user
    unchecks the checkbox named `files_checkbox`. This ensures that files are removed
    cleanly when they are no longer needed, preventing clutter and saving storage
    space.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在Jupyter Notebook环境中直接通过观察界面复选框小部件的变化来构建处理用户交互的代码。当用户取消选中名为`files_checkbox`的复选框时，该代码将删除特定的图像文件（`c_image.png`）。这确保了当文件不再需要时，文件会被干净地移除，防止杂乱并节省存储空间。
- en: 'We first define the function:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先定义函数：
- en: '[PRE30]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The event handler function defines a callback function named `on_files_checkbox_change`
    that will execute when the state of `files_checkbox` changes. `change` is provided
    by the observer, which contains information about the change event, including
    the following:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 事件处理函数定义了一个名为`on_files_checkbox_change`的回调函数，当`files_checkbox`的状态发生变化时将执行。`change`由观察者提供，其中包含有关更改事件的信息，包括以下内容：
- en: '`old`: The previous state of the checkbox'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`old`: 复选框的先前状态'
- en: '`new`: The new state of the checkbox'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`new`: 复选框的新状态'
- en: '[PRE31]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The code verifies whether the checkbox was previously checked (`True`) and
    has now been unchecked (`False`). This guarantees that the file deletion only
    occurs when the user explicitly unchecks the checkbox, preventing accidental file
    removal. We now remove the file:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 代码验证复选框之前是否被选中（`True`）并且现在已被取消选中（`False`）。这保证了文件删除仅在用户明确取消选中复选框时发生，防止意外删除文件。我们现在删除文件：
- en: '[PRE32]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'We also need to add an observer to inform the `on_files_checkbox_change` function
    when there is a file status change:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要添加一个观察者，以便在文件状态发生变化时通知`on_files_checkbox_change`函数：
- en: '[PRE33]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: The `files_checkbox.observe()` function links the `on_files_checkbox_change`
    function to the `files_checkbox` widget. `names='value'` specifies that the function
    should be triggered when the value of the checkbox changes (i.e., when it is checked
    or unchecked).
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '`files_checkbox.observe()`函数将`on_files_checkbox_change`函数链接到`files_checkbox`小部件。`names=''value''`指定当复选框的值发生变化时（即，当它被选中或取消选中时）应触发该函数。'
- en: We will now move on to the next part of the pipeline and implement the handler
    selection mechanism.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将进入管道的下一部分，并实现处理程序选择机制。
- en: 2\. Handler selection mechanism
  id: totrans-169
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2. 处理程序选择机制
- en: 'The handler selection mechanismdynamically selects and executes the appropriate
    handler based on predefined conditions. It iterates through available handlers,
    evaluating conditions until it finds a match, ensuring efficient and structured
    processing of the user input. The handler selection mechanism is in the `chat_with_gpt`
    function we built in the previous chapters. However, it now contains an orchestration
    task, as shown in *Figure 7.7*:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 处理器选择机制根据预定义的条件动态选择并执行适当的处理程序。它遍历可用的处理程序，评估条件直到找到匹配项，确保对用户输入进行高效和结构化的处理。处理器选择机制在我们在前几章中构建的`chat_with_gpt`函数中。然而，现在它包含了一个协调任务，如*图7.7*所示：
- en: '`chat_with_gpt` remains a pivotal function within the GenAISys and now contains
    the handler mechanism'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`chat_with_gpt`在GenAISys中仍然是一个关键功能，并且现在包含处理器机制'
- en: It checks conditions sequentially to decide which handler to invoke
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它按顺序检查条件以决定调用哪个处理器
- en: It falls back to a memory-based handler if no conditions match
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果没有条件匹配，它将回退到基于内存的处理程序
- en: It ensures robustness with error handling for an uninterrupted user experience
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它确保了通过错误处理来保证用户体验的连续性
- en: '![Figure 7.7: The orchestration role of the handler mechanism](img/B32304_07_7.png)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![图7.7：处理器机制的协调角色](img/B32304_07_7.png)'
- en: 'Figure 7.7: The orchestration role of the handler mechanism'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.7：处理器机制的协调角色
- en: In the broader GenAISys workflow, the handler mechanism acts as an orchestrator.
    It processes user inputs and identifies which AI functions to activate. When the
    IPython interface captures user messages, the handler mechanism evaluates these
    inputs to determine the appropriate handler from the handler registry. If no specific
    handler matches, it defaults to a memory-based response, which is then returned
    to the IPython interface.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在更广泛的GenAISys工作流程中，处理器机制充当协调者。它处理用户输入并识别要激活的AI功能。当IPython界面捕获用户消息时，处理器机制评估这些输入以确定从处理器注册表中适当的处理器。如果没有特定的处理器匹配，它默认使用基于内存的响应，然后将其返回到IPython界面。
- en: 'The `chat_with_gpt` function encapsulates this logic. It iterates through a
    predefined list of handlers, each paired with a corresponding condition function.
    When a condition evaluates to true, the associated handler is executed. If none
    match, the fallback memory-based handler ensures a seamless response:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '`chat_with_gpt`函数封装了这个逻辑。它遍历一个预定义的处理程序列表，每个处理程序都与相应的条件函数配对。当条件评估为真时，将执行相关的处理程序。如果没有匹配项，回退的基于内存的处理程序确保了无缝的响应：'
- en: '[PRE34]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Let’s go through the parameters of the function:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看函数的参数：
- en: '`messages`: The conversation history between the user and the AI'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`messages`: 用户和AI之间的对话历史'
- en: '`user_message`: The latest message from the user'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`user_message`: 用户最新的消息'
- en: '`files_status`: Tracks the status of any files involved in the conversation'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`files_status`: 跟踪涉及对话的任何文件的状态'
- en: '`active_instruct`: Any instruction or mode that might influence how responses
    are generated'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`active_instruct`: 可能影响响应生成的任何指令或模式'
- en: '`models`: Specifies the active AI model in use'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`models`: 指定正在使用的活动AI模型'
- en: The function uses `global memory_enabled` to access a global variable that determines
    whether memory should be applied to store/remember the full dialogue of a user.
    In this chapter, `global memory_enabled=True`.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数使用`global memory_enabled`来访问一个全局变量，该变量确定是否应该应用内存来存储/记住用户的完整对话。在本章中，`global
    memory_enabled=True`。
- en: 'The function attempts to execute the appropriate handler based on the provided
    conditions:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 函数尝试根据提供的条件执行适当的处理程序：
- en: '[PRE35]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'As you can see, `for condition, handler in handlers` iterates over a list called
    `handlers`, where each item is a tuple containing the following items:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，`for condition, handler in handlers`遍历一个名为`handlers`的列表，其中每个项目都是一个包含以下内容的元组：
- en: A condition functionto check whether a handler should be used
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个条件函数，用于检查是否应该使用处理程序
- en: A handler function to execute whether the condition is satisfied
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个处理器函数，无论条件是否满足都要执行
- en: A generic `if` condition, `(...)`, toevaluate the condition function with the
    provided parameters
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个通用的`if`条件`(...)`, 用于使用提供的参数评估条件函数
- en: The code returns the output of the corresponding handler if the condition is
    met, immediately exiting the function
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果条件满足，代码将返回相应处理程序的输出，并立即退出函数
- en: 'Let’s now add a fallback if no handlers match the input conditions:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们添加一个回退，如果没有任何处理器匹配输入条件：
- en: '[PRE36]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '`handle_with_memory` is called as a default handler that does the following:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '`handle_with_memory`作为默认处理器被调用，执行以下操作：'
- en: Uses the full conversation history (`messages`)
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用完整的对话历史（`messages`）
- en: Considers memory if `memory_enabled` is true, which is the case in this chapter
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果 `memory_enabled` 为 true，则考虑内存，在本章中就是这种情况
- en: Returns the response directly if executed
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果执行，则直接返回响应
- en: 'Finally, let’s add an exception to catch return errors:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们添加一个异常来捕获返回错误：
- en: '[PRE37]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: With the handler selection mechanism defined, we can now proceed to build the
    handler registry that stores these handlers.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在定义了处理器选择机制之后，我们现在可以继续构建存储这些处理器的处理器注册表。
- en: 3\. Handler registry
  id: totrans-203
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3. 处理器注册表
- en: 'The **handler registry** is a structured collection of condition-handler pairs,
    where each condition is a lambda function that evaluates user messages and instructions
    to determine whether specific criteria are met. When a condition is satisfied,
    the corresponding handler is triggered and executed immediately, as illustrated:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '**处理器注册表**是一个结构化的条件-处理器对集合，其中每个条件都是一个 lambda 函数，它评估用户消息和指令以确定是否满足特定标准。当条件满足时，相应的处理器立即被触发并执行，如图所示：'
- en: '![Figure 7.8: Creating the handler registry](img/B32304_07_8.png)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.8：创建处理器注册表](img/B32304_07_8.png)'
- en: 'Figure 7.8: Creating the handler registry'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.8：创建处理器注册表
- en: All lambda functions have four parameters (`msg`, `instruct`, `mem`, and `models`).
    This ensures that the number of arguments matches when `chat_with_gpt()` calls
    a handler.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 所有 lambda 函数都有四个参数（`msg`、`instruct`、`mem` 和 `models`）。这确保了当 `chat_with_gpt()`
    调用一个处理器时，参数的数量匹配。
- en: 'The handler registry has three main features:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 处理器注册表有三个主要功能：
- en: Is orchestrated by the handler mechanism and can be unlimited
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由处理器机制编排，可以无限扩展
- en: Routes inputs based on keywords, instructions, or model selection
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据关键词、指令或模型选择路由输入
- en: Guarantees a fallback response if no conditions match
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果没有条件匹配，则保证有回退响应
- en: 'We will design our handler registry with the following structure of four key
    properties:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将按照以下四个关键属性的结构设计我们的处理器注册表：
- en: '**Handler registration**: Creates a list of handlers, each with a condition
    function and a corresponding handler function'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**处理器注册**：创建一个处理器列表，每个处理器都有一个条件函数和一个相应的处理器函数'
- en: '**Specific handler conditions**: Sequentially checks whether an input meets
    any of the specific conditions'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特定处理器条件**：依次检查输入是否满足任何特定条件'
- en: '**Fallback handler**: Adds a default memory-based handler if none of the conditions
    match'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**回退处理器**：如果没有条件匹配，则添加一个默认的基于内存的处理器'
- en: '**Execution**: When a condition is satisfied, the corresponding handler is
    executed immediately'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**执行**：当条件满足时，相应的处理器立即执行'
- en: The role of `**kwargs` in the code provides a flexible way to interact with
    the AI functions. `**kwargs` is short for *keyword arguments* and is used in Python
    functions to allow passing a variable number of arguments to a function. In the
    context of our handler registry code, `**kwargs` plays a crucial role by allowing
    handlers to accept additional, optional parameters without explicitly defining
    them in the function. It makes the handlers extensible for future updates or new
    parameters without requiring modifications to existing function signatures.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 代码中 `**kwargs` 的作用提供了一个灵活的方式与 AI 函数交互。`**kwargs` 是 *关键字参数* 的缩写，用于 Python 函数中，允许向函数传递可变数量的参数。在我们的处理器注册表代码中，`**kwargs`
    通过允许处理器接受额外的、可选的参数，而不需要在函数中显式定义它们，发挥着至关重要的作用。这使得处理器易于扩展，以便于未来的更新或添加新参数，而无需修改现有的函数签名。
- en: We will now begin to build the handler registry with the Pinecone/RAG handler.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将开始构建带有 Pinecone/RAG 处理器的处理器注册表。
- en: Pinecone/RAG handler
  id: totrans-219
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Pinecone/RAG 处理器
- en: 'The Pinecone/RAG handler manages the **retrieval-augmented generation** (**RAG**)
    functions previously defined. It activates when detecting the `Pinecone` or `RAG`
    keyword within the user message:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: Pinecone/RAG 处理器管理之前定义的 **检索增强生成**（**RAG**）功能。它在检测到用户消息中包含 `Pinecone` 或 `RAG`
    关键词时激活：
- en: '[PRE38]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: This handler checks whether the user message contains “Pinecone” or “RAG,” in
    which case `lambda:` returns `True`; otherwise, it returns `False`. We will now
    create the reasoning handler.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 此处理器检查用户消息是否包含“Pinecone”或“RAG”，如果是，则 `lambda:` 返回 `True`；否则，返回 `False`。我们现在将创建推理处理器。
- en: Reasoning handler
  id: totrans-223
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 推理处理器
- en: 'We have already built the reasoning function, but now we need a handler. The
    keywords that trigger the handler are `Use reasoning`, `customer`, and `activities`.
    Any additional text in the message provides context for the reasoning process.
    The handler uses `all()` to ensure all keywords are included in the message:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经构建了推理函数，但现在我们需要一个处理程序。触发处理程序的关键字是 `Use reasoning`、`customer` 和 `activities`。消息中的任何附加文本都为推理过程提供上下文。处理程序使用
    `all()` 确保所有关键字都包含在消息中：
- en: '[PRE39]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Let’s move on and create the analysis handler.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续创建分析处理程序。
- en: Analysis handler
  id: totrans-227
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分析处理程序
- en: 'The analysis handler has been used for memory analysis up to now and is triggered
    by the `Analysis` instruction:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 分析处理程序到目前为止已被用于内存分析，并由 `Analysis` 指令触发：
- en: '[PRE40]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Time to create the generation handler.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 是时候创建生成处理程序了。
- en: Generation handler
  id: totrans-231
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成处理程序
- en: 'The generation handler takes memory analysis to another level by asking the
    generative AI model to generate an engaging text for a customer based on a memory
    analysis of the text. The `Generation` instruction triggers the generation handler:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 生成处理程序通过要求生成式 AI 模型根据文本的内存分析为顾客生成吸引人的文本，将内存分析提升到了另一个层次。`Generation` 指令触发生成处理程序：
- en: '[PRE41]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Let’s now build the image creation handler.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来构建图像创建处理程序。
- en: Image handler
  id: totrans-235
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图像处理程序
- en: 'The image creation handler is triggered by the `Create` and `image` keywords
    in the user message:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 图像创建处理程序由用户消息中的 `Create` 和 `image` 关键字触发：
- en: '[PRE42]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: We will now create the freestyle handler for when there is no keyword or instructions.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将创建用于没有关键字或指令的情况的自由处理程序。
- en: Fallback memory handler
  id: totrans-239
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 回退内存处理程序
- en: 'This handler is a general-purpose handler when there is no instruction or keyword
    to trigger a specific function. Let’s append the fallback memory handler accordingly:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 当没有指令或关键字触发特定功能时，此处理程序是一个通用处理程序。让我们相应地附加回退内存处理程序：
- en: '[PRE43]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Note that we have replaced `user_memory` with `memory_enabled` to generalize
    memory management.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们已经将 `user_memory` 替换为 `memory_enabled` 以实现内存管理的通用化。
- en: You can add as many handlers and AI functions as you wish to the handler registry.
    You can scale your GenAISys as much as you need to. You can also modify the keywords
    by replacing them with explicit instructions, as we did for the `Analysis` and
    `generation` functions. The handlers will then call all the AI functions you need.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以将任意数量的处理程序和 AI 函数添加到处理程序注册表中。您可以根据需要扩展 GenAISys。您还可以通过替换显式指令来修改关键字，就像我们对
    `Analysis` 和 `generation` 函数所做的那样。然后，处理程序将调用您需要的所有 AI 函数。
- en: Let’s now go through the new organization of the AI functions.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们现在来了解 AI 函数的新组织结构。
- en: 4\. AI functions
  id: totrans-245
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4. AI 函数
- en: We will now run the AI functions that are activated by the handler registry.
    The functions build on those from earlier chapters but are now managed by the
    handler-selection mechanism introduced in this chapter. Additionally, the examples
    used in this section are based on typical prompts related to product design and
    production scenarios. Keep in mind that, due to the stochastic (probabilistic)
    nature of generative AI models, outputs can vary each time we run these tasks.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将运行由处理程序注册表激活的 AI 函数。这些函数基于早期章节中的函数，但现在由本章中引入的处理程序选择机制管理。此外，本节中使用的示例基于与产品设计和生产场景相关的典型提示。请记住，由于生成式
    AI 模型的随机（概率）性质，每次运行这些任务时输出都可能有所不同。
- en: '![Figure 7.9: AI functions call by the handler selection mechanism and registry](img/B32304_07_9.png)'
  id: totrans-247
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.9：处理程序选择机制和注册表调用的 AI 函数](img/B32304_07_9.png)'
- en: 'Figure 7.9: AI functions call by the handler selection mechanism and registry'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.9：处理程序选择机制和注册表调用的 AI 函数
- en: We’ll now execute all AI functions currently available in our GenAISys, incorporating
    DeepSeek model calls where applicable. Let’s begin with the RAG functions.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将执行 GenAISys 中目前所有可用的 AI 函数，并在适用的情况下调用 DeepSeek 模型。让我们从 RAG 函数开始。
- en: Functions such as speech synthesis, file management, dialogue history, and summary
    generation remain unchanged from previous chapters.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 诸如语音合成、文件管理、对话历史和摘要生成等功能与上一章保持不变。
- en: RAG
  id: totrans-251
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RAG
- en: 'This RAG function can run with OpenAI or DeepSeek with the `Pinecone` keyword
    in the user message. The RAG function’s name has changed, but its process remains
    unchanged for the query:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 此 RAG 函数可以在用户消息中使用 `Pinecone` 关键字与 OpenAI 或 DeepSeek 运行。RAG 函数的名称已更改，但其查询过程保持不变：
- en: '[PRE44]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'However, the function now contains a DeepSeek distilled R1 call. The function
    first defaults to OpenAI if no model is provided or if DeepSeek is deactivated:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，该函数现在包含了一个DeepSeek蒸馏R1调用。如果没有提供模型或DeepSeek被禁用时，该函数默认使用OpenAI：
- en: '[PRE45]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'If DeepSeek is activated, it will be called if chosen in the IPython interface
    for this task:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 如果激活了DeepSeek，它将在IPython界面中为此任务选择时被调用：
- en: '[PRE46]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: We will first run a sentiment analysis.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先进行情感分析。
- en: Sentiment analysis (genaisys)
  id: totrans-259
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 情感分析（genaisys）
- en: 'An example user input by the PDPM is the following:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: PDPM的以下示例用户输入：
- en: '[PRE47]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'The output with OpenAI selected (default) and `Agent` checked will be as follows:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 选择OpenAI（默认）和勾选`Agent`的输出将如下所示：
- en: '[PRE48]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'On the other hand, the output with DeepSeek selected (default) and `Agent`
    checked will be as follows:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，选择DeepSeek（默认）和勾选`Agent`的输出将如下所示：
- en: '[PRE49]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: The sentiment score and explanation score are acceptable in both cases. Imagine
    receiving thousands of such customer feedback messages—the GenAISys filters the
    low scores and provides these outputs automatically, storing them in the customer
    database.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 在两种情况下，情感分数和解释分数都是可以接受的。想象一下接收数千条这样的客户反馈消息——GenAISys会过滤掉低分，并自动提供这些输出，并将它们存储在客户数据库中。
- en: Now, the PDPM checks semantic analysis.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，PDPM检查语义分析。
- en: Semantic analysis (genaisys)
  id: totrans-268
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 语义分析（genaisys）
- en: 'Consider another example input by the PDPM:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑PDPM的另一个示例输入：
- en: '[PRE50]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: This RAG function can run with OpenAI or DeepSeek with a “Pinecone” keyword
    in the user message.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 此RAG函数可以与OpenAI或DeepSeek一起运行，只要用户消息中包含“Pinecone”关键字。
- en: 'OpenAI’s output is acceptable and clearly outlines the semantic relationships
    within the message:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI的输出是可以接受的，并且清楚地概述了消息中的语义关系：
- en: '[PRE51]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'DeepSeek’s output is relevant as well:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: DeepSeek的输出同样相关：
- en: '[PRE52]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: DeepSeek’s answer is longer and more complex. However, what would a team prefer?
    A shorter answer like OpenAI’s response or a longer one with more explanations?
    The decision can be reached through workshops and meetings.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: DeepSeek的回答更长且更复杂。然而，团队会偏好哪种？像OpenAI那样简短的回答，还是带有更多解释的长回答？这个决定可以通过研讨会和会议达成。
- en: Data retrieval (data01)
  id: totrans-277
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据检索（data01）
- en: 'Both OpenAI and DeepSeek can be used for data retrieval. The user input for
    a product designer could be as follows:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI和DeepSeek都可以用于数据检索。产品设计师的用户输入可能如下所示：
- en: '[PRE53]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'The output is satisfactory:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 输出令人满意：
- en: '[PRE54]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: We thus have a flexible RAG system in our GenAISys that can run with the models
    we wish. However, we still have to evaluate the models for each set of tasks we
    want to perform.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在我们的GenAISys中，我们有一个灵活的RAG系统，可以使用我们想要的模型运行。然而，我们仍然必须评估我们想要执行的每一组任务的模型。
- en: Chain of thought
  id: totrans-283
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 思维链
- en: 'The CoT function operates with **Files** checked and defaults to **OpenAI**
    as the model provider. Its implementation remains consistent as it is built and
    run in the previous chapter. The key difference is that it is now integrated into
    the handler selection mechanism, which activates based on specific keywords in
    the input:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: CoT函数在勾选**Files**并默认使用**OpenAI**作为模型提供者时运行。其实现保持一致，因为它是在上一章中构建和运行的。主要区别在于它现在集成到处理程序选择机制中，该机制基于输入中的特定关键字激活：
- en: '[PRE55]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Consider anexample user input from the PDPM:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑PDPM的另一个示例用户输入：
- en: '[PRE56]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'The output seems acceptable:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 输出看起来是可以接受的：
- en: '[PRE57]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: Let’s now see how memory analysis will run with both model sources (OpenAI and
    DeepSeek).
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看内存分析如何使用这两种模型源（OpenAI和DeepSeek）运行。
- en: Analysis (memory)
  id: totrans-291
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分析（记忆）
- en: 'Both OpenAI and DeepSeek models handle memory-based customer profiles using
    neuroscientific-style categorizations. The function has been adapted to the handler
    selection process and contains a DeepSeek call:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI和DeepSeek模型都使用神经科学风格的分类处理基于记忆的客户档案。该函数已适应处理程序选择过程，并包含一个DeepSeek调用：
- en: '[PRE58]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'An example user input using the `Analysis` option in the `Reasoning` list could
    be:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`Reasoning`列表中的`Analysis`选项的示例用户输入可以是：
- en: '[PRE59]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'OpenAI’s output contains a useful segment highlighting the emotional dimension
    related to the customer’s wish for a personalized souvenir, which could help the
    product designer with their merchandise kit production endeavor:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI的输出包含一个有用的段落，突出了与客户对个性化纪念品愿望相关的情感维度，这可能有助于产品设计师在商品套装生产方面的努力：
- en: '[PRE60]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'DeepSeek’s output, however, goes off track. It first finds the right task to
    do:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，DeepSeek的输出却偏离了轨道。它首先找到正确的任务去做：
- en: '[PRE61]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'But it then gets lost and seems to struggle with formatting and coherence,
    introducing irregular spacing and even foreign characters:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 但随后它似乎迷失了方向，在格式和连贯性上遇到了困难，引入了不规则的间距甚至外文字符：
- en: '[PRE62]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: DeepSeek can certainly do better, but improving this result would require additional
    iterations of prompt refinement or selecting a more robust DeepSeek variant or
    API. Investing time in refining prompts carries some risk, as even then, the outcome
    may not meet your expectations. Whether to refine the prompt, switch to a DeepSeek
    API, explore another DeepSeek variant, or default to OpenAI should ultimately
    be decided collaboratively within the team and based on your project’s needs.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: DeepSeek当然可以做得更好，但改善这个结果需要额外的提示改进迭代，或者选择更健壮的DeepSeek变体或API。在提示改进上投入时间存在一些风险，因为即使如此，结果可能也不会达到你的期望。是否改进提示、切换到DeepSeek
    API、探索另一个DeepSeek变体，还是默认使用OpenAI，最终应在团队内部协作决定，并基于你的项目需求。
- en: Let’s now move on to running the generation function.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们继续运行生成函数。
- en: Generation
  id: totrans-304
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成
- en: 'The generation function (select `Generation` in the `Reasoning` list), active
    by default with **OpenAI**, **Agent**, and **Files** checked, supports the creation
    of engaging, memory-based customer messages:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 生成函数（在`推理`列表中选择`生成`），默认激活，**OpenAI**、**Agent**和**文件**被勾选，支持创建引人入胜、基于记忆的客户消息：
- en: '[PRE63]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Let’s consider a general user input as an example:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以一个通用用户输入为例：
- en: '[PRE64]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'OpenAI’s output is an appealing customer-facing message, blending nostalgia
    and merchandising suggestions, accompanied by an appropriate custom T-shirt image:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI的输出是一个吸引顾客的消息，融合了怀旧和商品建议，并附有合适的定制T恤图像：
- en: '[PRE65]'
  id: totrans-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: '![Figure 7.10: A personal image for a customer](img/B32304_07_10.png)'
  id: totrans-311
  prefs: []
  type: TYPE_IMG
  zh: '![图7.10：客户的个人图像](img/B32304_07_10.png)'
- en: 'Figure 7.10: A personal image for a customer'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.10：客户的个人图像
- en: Let’s now create an image.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们创建一个图像。
- en: Creating an image
  id: totrans-314
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建图像
- en: 'This functionality utilizes DALL-E to generate images, with the **Files** box
    checked. The function does not change beyond being adapted to the handler-selection
    mechanism, which activates this feature with the `Create` and `image` keywords
    in the user input:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 此功能利用DALL-E生成图像，并勾选了**文件**框。该函数在适配处理程序选择机制之外没有变化，该机制通过用户输入中的`Create`和`image`关键字激活此功能：
- en: '[PRE66]'
  id: totrans-316
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'The product designer could use it to ideate merchandising kits:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 产品设计师可以利用它来构思商品套装：
- en: '[PRE67]'
  id: totrans-318
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'The output is a cool T-shirt that the production team could use and adapt for
    production:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 输出是一个酷炫的T恤，生产团队可以使用并适应生产：
- en: '![Figure 7.11: Custom T-shirt design](img/B32304_07_11.png)'
  id: totrans-320
  prefs: []
  type: TYPE_IMG
  zh: '![图7.11：定制T恤设计](img/B32304_07_11.png)'
- en: 'Figure 7.11: Custom T-shirt design'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.11：定制T恤设计
- en: We will now create freestyle prompts that are not triggered by any keywords
    or instructions.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将创建一些自由风格的提示，这些提示不会被任何关键字或指令触发。
- en: Fallback handler (memory-based)
  id: totrans-323
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 回退处理程序（基于内存）
- en: 'This general-purpose handler activates when no specific instruction or keyword
    matches the input. `handle_with_memory` runs with OpenAI and DeepSeek, depending
    on the model selected. The memory of a user dialogue is set with a global variable,
    `memory_enabled`, that is initialized at the beginning:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 当没有特定指令或关键字与输入匹配时，此通用处理程序会被激活。`handle_with_memory`根据所选模型，与OpenAI和DeepSeek一起运行。用户对话的内存通过全局变量`memory_enabled`设置，该变量在开始时初始化：
- en: '[PRE68]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'The function will return a message and stop if `memory_enabled` is set to `False`:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`memory_enabled`设置为`False`，则函数将返回消息并停止：
- en: '[PRE69]'
  id: totrans-327
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'It will process the past messages of a user from the conversation history:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 它将处理用户从对话历史中的过去消息：
- en: '[PRE70]'
  id: totrans-329
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'Then, the models are selected with OpenAI being the default model provider
    if no other model is selected in the IPython interface:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在IPython界面中没有选择其他模型的情况下，默认模型提供者是OpenAI：
- en: '[PRE71]'
  id: totrans-331
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'The response message is stored and returned:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 响应消息将被存储并返回：
- en: '[PRE72]'
  id: totrans-333
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'An example input by the PDPM could be the following:'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: PDPM的一个示例输入可能是以下内容：
- en: '[PRE73]'
  id: totrans-335
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'OpenAI’s answer is both acceptable and productive. Take your time to read the
    prompt and the response, which shows the transition of generative AI from NLP
    general tasks to zero-shot domain-specific tasks:'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI的回答既可接受又富有成效。花点时间阅读提示和响应，这显示了生成式AI从NLP通用任务到零样本特定领域任务的转变：
- en: '[PRE74]'
  id: totrans-337
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'DeepSeek’s answer does not provide the same quality, although it contains some
    interesting points:'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管DeepSeek的回答包含一些有趣的观点，但它的质量并不相同：
- en: '[PRE75]'
  id: totrans-339
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'Obtaining a better result would require further prompt design and output analysis
    cycles, evaluating DeepSeek models that are not distilled, such as DeepSeek-V3
    or DeepSeek-R1\. DeepSeek can surely do better, as demonstrated by using DeepSeek-R1
    on [https://chat.deepseek.com/](https://chat.deepseek.com/), which produced the
    following output:'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 要获得更好的结果，需要进一步的提示设计和输出分析循环，评估未蒸馏的DeepSeek模型，如DeepSeek-V3或DeepSeek-R1。DeepSeek确实可以做得更好，正如使用DeepSeek-R1在[https://chat.deepseek.com/](https://chat.deepseek.com/)上所展示的，它产生了以下输出：
- en: '[PRE76]'
  id: totrans-341
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: Read the prompts and outputs in this section carefully. For security and privacy
    reasons, we are using only a locally installed, distilled Hugging Face open source
    version of DeepSeek-R1\. However, you could use the online version of DeepSeek
    for certain tasks, such as the production example in this section, if you have
    the necessary permissions, just as you would with ChatGPT or any other online
    platform. Depending on your project’s specifications, you could also explore US-based
    DeepSeek APIs or alternative deployment approaches.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 仔细阅读本节中的提示和输出。出于安全和隐私原因，我们仅使用本地安装的、蒸馏的Hugging Face开源版本的DeepSeek-R1。然而，如果您有必要的权限，您可以使用DeepSeek的在线版本执行某些任务，例如本节中的生产示例，就像您使用ChatGPT或任何其他在线平台一样。根据您项目的具体要求，您还可以探索基于美国的DeepSeek
    API或替代部署方法。
- en: In any case, both OpenAI and DeepSeek are capable of delivering effective production
    solutions when correctly prompted and when the most appropriate model version
    is selected. Generative AI has clearly entered a new phase!
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 无论如何，OpenAI和DeepSeek都能够在正确提示和选择最合适的模型版本时提供有效的生产解决方案。生成式AI显然已经进入了一个新的阶段！
- en: Summary
  id: totrans-344
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'In this chapter, we moved further along our journey into generative AI systems.
    First, we took the time to digest the arrival of DeepSeek-R1, a powerful open
    source reasoning model known for innovative efficiency improvements in training.
    This development immediately raised a critical question for project managers:
    should we constantly follow real-time trends or prioritize maintaining a stable
    system?'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们进一步深入到生成式AI系统的探索之旅。首先，我们花时间消化了DeepSeek-R1的问世，这是一个以训练中创新效率提升而闻名的强大开源推理模型。这一发展立即为项目经理们提出了一个关键问题：我们应该不断追随实时趋势，还是优先考虑维护一个稳定的系统？
- en: To address this challenge, we developed a balanced solution by building a handler
    selection mechanism. This mechanism processes user messages, triggers handlers
    within a handler registry, and then activates the appropriate AI functions. To
    ensure flexibility and adaptability, we updated our IPython interface, allowing
    users to easily select between OpenAI and DeepSeek models before initiating a
    task.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 为了应对这一挑战，我们通过构建一个处理程序选择机制来开发了一个平衡的解决方案。该机制处理用户消息，在处理程序注册表中触发处理程序，然后激活适当的AI功能。为了确保灵活性和适应性，我们更新了我们的IPython接口，使用户在启动任务之前能够轻松地在OpenAI和DeepSeek模型之间进行选择。
- en: This design allows the GenAISys administrator to introduce new experimental
    models or any other function(non-AI, ML, or DL) while maintaining access to proven
    results. For instance, when analyzing user comments, administrators can run tasks
    using the reliable OpenAI model while simultaneously evaluating the DeepSeek model.
    Administrators can also disable specific models when necessary, providing a practical
    balance between stability and innovation, which is crucial in today’s fast-paced
    AI environment.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 这种设计允许GenAISys管理员在保持对已验证结果访问的同时，引入新的实验模型或任何其他功能（非AI、ML或DL）。例如，在分析用户评论时，管理员可以使用可靠的OpenAI模型同时评估DeepSeek模型。管理员还可以在必要时禁用特定模型，在稳定性和创新之间提供实际平衡，这在当今快速发展的AI环境中至关重要。
- en: To achieve this balance practically, we began by installing and running DeepSeek-R1-Distill-Llama-8B
    in an independent notebook, demonstrating its capabilities through production-related
    examples. We then integrated this distilled model into our GenAISys, creating
    a need for enhanced flexibility and scalability.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在实际上实现这种平衡，我们首先在一个独立的笔记本中安装并运行了DeepSeek-R1-Distill-Llama-8B，通过生产相关示例展示了其能力。然后，我们将这个蒸馏模型集成到我们的GenAISys中，这需要增强灵活性和可扩展性。
- en: The introduction of the handler selection mechanism and the structured handler
    registry ensures that our system can scale effectively and indefinitely. Each
    handler follows a unified, modular format, enabling easy management, activation,
    or deactivation by administrators. We demonstrated these handlers through a series
    of practical prompts related to product design and production.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 引入处理器选择机制和结构化处理器注册表确保我们的系统可以有效地无限扩展。每个处理器都遵循统一的、模块化的格式，使得管理员可以轻松地进行管理、激活或停用。我们通过一系列与产品设计和生产相关的实际提示展示了这些处理器。
- en: We are now positioned to expand and scale our GenAISys, adding new features
    within this adaptable framework. In the next chapter, we’ll continue this journey
    by connecting our GenAISys to the broader external world.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在处于扩展和扩展 GenAISys 的位置，在这个可适应的框架内添加新功能。在下一章中，我们将继续这一旅程，通过将 GenAISys 连接到更广泛的外部世界。
- en: Questions
  id: totrans-351
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: DeepSeek-V3 was trained with zero-shot examples. (True or False)
  id: totrans-352
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: DeepSeek-V3 使用零样本示例进行训练。（对或错）
- en: DeepSeek-R1 is a reasoning model. (True or False)
  id: totrans-353
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: DeepSeek-R1 是一个推理模型。（对或错）
- en: DeepSeek-R1 was first trained with RL-only. (True or False)
  id: totrans-354
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: DeepSeek-R1 首次仅使用强化学习进行训练。（对或错）
- en: DeepSeek-R1-Distill-Llama-8B is the teacher of DeepSeek-R1\. (True or False)
  id: totrans-355
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: DeepSeek-R1-Distill-Llama-8B 是 DeepSeek-R1 的教师。（对或错）
- en: DeepSeek-V3 was enhanced with DeepSeek-R1, which was derived from DeepSeek.
    (True or False)
  id: totrans-356
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: DeepSeek-V3 通过 DeepSeek 衍生的 DeepSeek-R1 进行增强。（对或错）
- en: A handler registry that contains a list of handlers for all the AI functions
    is scalable. (True or False)
  id: totrans-357
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 包含所有 AI 功能处理器的处理器注册表是可扩展的。（对或错）
- en: A handler selection mechanism that processes user messages makes the GenAISys
    highly flexible. (True or False)
  id: totrans-358
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个处理用户消息的处理器选择机制使 GenAISys 非常灵活。（对或错）
- en: Generative AI models such as OpenAI and DeepSeek reasoning models solve a wide
    range of problems with no additional training. (True or False)
  id: totrans-359
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如 OpenAI 和 DeepSeek 推理模型之类的生成式 AI 模型无需额外训练即可解决广泛的问题。（对或错）
- en: A GenAISys with a solid architecture is sufficiently flexible to be expanded
    in terms of models and tasks to perform. (True or False)
  id: totrans-360
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个具有坚实架构的 GenAISys 在模型和执行任务方面足够灵活，可以扩展。（对或错）
- en: References
  id: totrans-361
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '*DeepSeek-V3 Technical Report*. [https://arxiv.org/abs/2412.19437](https://arxiv.org/abs/2412.19437)'
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*DeepSeek-V3 技术报告*。[https://arxiv.org/abs/2412.19437](https://arxiv.org/abs/2412.19437)'
- en: 'Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N.,
    Kaiser, Ł., & Polosukhin, I. (2017). *Attention Is All You Need*. Advances in
    Neural Information Processing Systems, 30, 5998–6008\. Available at: [https://arxiv.org/abs/1706.03762](https://arxiv.org/abs/1706.03762)'
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N.,
    Kaiser, Ł., & Polosukhin, I. (2017). *Attention Is All You Need*. Advances in
    Neural Information Processing Systems, 30, 5998–6008\. 可在：[https://arxiv.org/abs/1706.03762](https://arxiv.org/abs/1706.03762)
- en: 'DeepSeekAI, Daya Guo, Dejian Yang, et al: [https://arxiv.org/abs/2501.12948](https://arxiv.org/abs/2501.12948)'
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DeepSeekAI，郭大亚，杨德建等：[https://arxiv.org/abs/2501.12948](https://arxiv.org/abs/2501.12948)
- en: 'Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.-A., Lacroix,
    T., Rozière, B., Goyal, N., Hambro, E., Azhar, F., Rodriguez, A., Joulin, A.,
    Grave, E., & Lample, G. (2023). *LLaMA: Open and Efficient Foundation Language
    Models*. [https://arxiv.org/abs/2302.13971](https://arxiv.org/abs/2302.13971))'
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.-A., Lacroix,
    T., Rozière, B., Goyal, N., Hambro, E., Azhar, F., Rodriguez, A., Joulin, A.,
    Grave, E., & Lample, G. (2023). *LLaMA: 开放且高效的基座语言模型*. [https://arxiv.org/abs/2302.13971](https://arxiv.org/abs/2302.13971)'
- en: Grattafiori, A., Dubey, A., Jauhri, A., Pandey, A., Kadian, A., Al-Dahle, A.,
    Letman, A., Mathur, A., Schelten, A., Vaughan, et al. (2024). *The Llama 3 Herd
    of Models*. [https://arxiv.org/abs/2407.21783](https://arxiv.org/abs/2407.21783)
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Grattafiori, A., Dubey, A., Jauhri, A., Pandey, A., Kadian, A., Al-Dahle, A.,
    Letman, A., Mathur, A., Schelten, A., Vaughan, 等等. (2024). *Llama 3 模型群*. [https://arxiv.org/abs/2407.21783](https://arxiv.org/abs/2407.21783)
- en: 'Hugging Face:'
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Hugging Face:'
- en: '[https://huggingface.co/docs/transformers/index](https://huggingface.co/docs/transformers/index)'
  id: totrans-368
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://huggingface.co/docs/transformers/index](https://huggingface.co/docs/transformers/index)'
- en: '[https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B)'
  id: totrans-369
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B)'
- en: '[https://huggingface.co/docs/inference-endpoints/en/security](https://huggingface.co/docs/inference-endpoints/en/security)'
  id: totrans-370
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://huggingface.co/docs/inference-endpoints/en/security](https://huggingface.co/docs/inference-endpoints/en/security)'
- en: 'Unsloth AI: [https://unsloth.ai/](https://unsloth.ai/)'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Unsloth AI：[https://unsloth.ai/](https://unsloth.ai/)
- en: Further reading
  id: totrans-372
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'Frantar, E., Ashkboos, S., Hoefler, T., & Alistarh, D. (2023). *GPTQ: Accurate
    Post-Training Quantization for Generative Pre-trained Transformers* [https://arxiv.org/abs/2210.01774](https://arxiv.org/abs/2210.01774))'
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Frantar, E., Ashkboos, S., Hoefler, T., & Alistarh, D. (2023). *GPTQ: Accurate
    Post-Training Quantization for Generative Pre-trained Transformers* [https://arxiv.org/abs/2210.01774](https://arxiv.org/abs/2210.01774))'
- en: 'NVIDIA’s data center GPUs: [https://www.nvidia.com/en-us/data-center/](https://www.nvidia.com/en-us/data-center/)'
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NVIDIA的数据中心GPU：[https://www.nvidia.com/en-us/data-center/](https://www.nvidia.com/en-us/data-center/)
- en: '|'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Unlock this book’s exclusive benefits now
  id: totrans-376
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 现在解锁这本书的独家优惠
- en: Scan this QR code or go to [packtpub.com/unlock](http://packtpub.com/unlock),
    then search for this book by name. | ![A qr code on a white background  AI-generated
    content may be incorrect.](img/Unlock.png) |
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 扫描此二维码或访问[packtpub.com/unlock](http://packtpub.com/unlock)，然后通过书名搜索这本书。 | ![白色背景上的二维码
    AI生成的内容可能不正确。](img/Unlock.png) |
- en: '| *Note: Keep your purchase invoice ready before you start.* |'
  id: totrans-378
  prefs: []
  type: TYPE_TB
  zh: '| *注意：开始之前请准备好您的购买发票。* |'
