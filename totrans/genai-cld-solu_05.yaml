- en: '5'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '5'
- en: 'Effective Prompt Engineering Techniques: Unlocking Wisdom Through AI'
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高效提示工程技巧：通过人工智能开启智慧
- en: Prompt engineering emerged as a standout profession in 2023, captivating the
    tech industry with its profound impact on AI interactions and applications. But
    what sparked this surge in popularity? The answer lies in the nuanced and intricate
    nature of the discipline. Understanding the essentials of prompt engineering is
    crucial; it’s not just about communicating with the model; it’s about crafting
    prompts that guide the AI to understand the context and nuances of the task at
    hand. In the previous chapter, we learned about how we can add relevant context
    through RAG by searching through vector DB. Finally, a prompt needs to be crafted
    and sent to the LLMs. This leads to more accurate and relevant responses, turning
    a simple interaction into a robust tool for a variety of cloud-based applications.
    Whether it’s automating customer support, generating content, or analyzing data,
    the ability to fine-tune prompts is a game-changer, ensuring that the AI’s capabilities
    are fully leveraged in a controlled and purposeful manner.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 提示工程在2023年成为了一个突出的职业，以其对人工智能交互和应用的深远影响吸引了科技行业的关注。但是什么引发了这种流行趋势的激增？答案在于该学科的微妙和复杂本质。理解提示工程的要点至关重要；这不仅仅是与模型进行交流；这是关于构建引导AI理解任务背景和细微之处的提示。在前一章中，我们学习了如何通过RAG通过搜索向量数据库添加相关上下文。最后，需要精心制作并发送提示到LLMs。这导致更准确和相关的响应，将简单的交互转变为适用于各种云应用平台的强大工具。无论是自动化客户支持、生成内容还是分析数据，调整提示的能力都是一个变革者，确保AI的能力在受控和有目的的方式中得到充分利用。
- en: This chapter delves into the techniques for effective prompt engineering, offering
    strategies to refine interactions for optimal outcomes. This goes hand in hand
    with the ethical dimensions of prompt engineering, a topic of paramount importance
    in today’s tech landscape. It addresses the responsibility of developers to ensure
    that AI interactions are not only efficient and goal-oriented but also ethically
    sound and bias-free. Finally, the integration of prompt engineering with cloud
    solutions opens up a new realm of possibilities. It allows for scalable, efficient,
    and flexible AI solutions that can be seamlessly integrated into existing cloud
    infrastructure, revolutionizing how businesses and individuals interact with AI.
    In essence, this chapter is not just an instructional guide but is a cornerstone
    for building responsible and effective cloud-based GenAI applications.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章深入探讨了高效提示工程的技术，提供了优化交互以获得最佳结果的策略。这与提示工程的伦理维度密切相关，在当今技术环境中这是一个至关重要的主题。它讨论了开发者确保人工智能交互不仅高效且目标导向，而且符合伦理且无偏见的责任。最后，提示工程与云解决方案的集成开辟了一个新的可能性领域。它允许实现可扩展、高效和灵活的人工智能解决方案，可以无缝集成到现有的云基础设施中，彻底改变企业和个人与人工智能互动的方式。本质上，本章不仅是一本指导手册，而且是构建负责任和有效云基通用人工智能应用的基石。
- en: 'In this chapter, we will talk about the following:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论以下内容：
- en: The essentials of prompt engineering with ChatGPT
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用ChatGPT的提示工程要点
- en: What is prompt engineering?
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是提示工程？
- en: Techniques for effective prompt engineering
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高效提示工程的技术
- en: The ethical dimensions of prompt engineering
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提示工程的伦理维度
- en: '![Figure 5.1 – Comic depiction of Prompt Engineer](img/chapter_5-joke.jpg)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![图5.1 – 提示工程师的漫画描绘](img/chapter_5-joke.jpg)'
- en: Figure 5.1 – Comic depiction of Prompt Engineer
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.1 – 提示工程师的漫画描绘
- en: The essentials of prompt engineering
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提示工程要点
- en: Before discussing prompt engineering, it is important to first understand the
    foundational components of a prompt. In this section, we’ll delve into the key
    components of a prompt, such as ChatGPT prompts, completions, and tokens. Additionally,
    grasping what tokens are is pivotal to understanding the model’s constraints and
    managing costs.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在讨论提示工程之前，首先理解提示的基础组件非常重要。在本节中，我们将深入研究提示的关键组件，例如ChatGPT提示、补全和令牌。此外，理解令牌是什么对于理解模型的限制和管理成本至关重要。
- en: ChatGPT prompts and completions
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ChatGPT提示和补全
- en: A prompt is an input provided to LLMs, whereas completions refer to the output
    of LLMs. The structure and content of a prompt can vary based on the type of LLM
    (e.g., the text or image generation model), specific use cases, and the desired
    output of the language model.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 提示是提供给 LLM 的输入，而完成则指的是 LLM 的输出。提示的结构和内容可以根据 LLM 的类型（例如，文本或图像生成模型）、具体用例以及语言模型期望的输出而有所不同。
- en: Completions refer to the response generated by ChatGPT prompts; basically, it
    is an answer to your questions. Check out the following example to understand
    the difference between prompts and completions when we prompt ChatGPT with, “What
    is the capital of India?”
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 完成指的是 ChatGPT 提示生成的响应；基本上，它是对你问题的回答。查看以下示例，了解当我们向 ChatGPT 提出问题时，提示和完成之间的区别：“印度的首都是什么？”
- en: '![Figure 5.2 – An image showing a sample LLM prompt and completion](img/B21443_05_2.jpg)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.2 – 展示样本 LLM 提示和完成的图像](img/B21443_05_2.jpg)'
- en: Figure 5.2 – An image showing a sample LLM prompt and completion
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.2 – 展示样本 LLM 提示和完成的图像
- en: Based on the use case, we can leverage one of the two ChatGPT API calls, named
    **Completions** or **ChatCompletions**, to interact with the model. However, OpenAI
    recommends using the ChatCompletions API in the majority of scenarios.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 根据用例，我们可以利用两个 ChatGPT API 调用中的一个，名为 **Completions** 或 **ChatCompletions**，来与模型交互。然而，OpenAI
    建议在大多数情况下使用 ChatCompletions API。
- en: Completions API
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Completions API
- en: The Completions API is designed to generate creative, free-form text. You provide
    a prompt, and the API generates text that continues from it. This is often used
    for tasks where you want the model to answer a question or generate creative text,
    such as for writing an article or a poem.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: Completions API 是为了生成创意的自由文本。你提供提示，API 会生成从它继续的文字。这通常用于你希望模型回答问题或生成创意文本的任务，例如撰写文章或诗歌。
- en: ChatCompletions API
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ChatCompletions API
- en: The ChatCompletions API is designed for multi-turn conversations. You send a
    series of messages instead of a single prompt, and the model generates a message
    as a response. The messages sent to the model include a role (which can be a **system**,
    **user**, or **assistant**) and the content of the message. The system role is
    used to set the behavior of the assistant, the user role is used to instruct the
    assistant, and the model’s responses are under the assistant role.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: ChatCompletions API 是为多轮对话设计的。你发送一系列消息而不是单个提示，模型会生成一条消息作为响应。发送给模型的消息包括一个角色（可以是
    **system**、**user** 或 **assistant**）和消息的内容。系统角色用于设置助手的行为了，用户角色用于指导助手，而模型的响应则属于助手角色。
- en: 'The following is an example of a sample ChatCompletions API call:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个样本 ChatCompletions API 调用的示例：
- en: '[PRE0]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The main difference between the Completions API and ChatCompletions API is that
    the Completions API is designed for single-turn tasks, while the ChatCompletions
    API is designed to handle multiple turns in a conversation, making it more suitable
    for building conversational agents. However, the ChatCompletions API format can
    be modified to behave as a Completions API by using a single user message.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: Completions API 与 ChatCompletions API 之间的主要区别在于，Completions API 是为单轮任务设计的，而
    ChatCompletions API 是为了处理对话中的多轮对话，这使得它更适合构建对话代理。然而，通过使用单个用户消息，ChatCompletions
    API 格式可以被修改为表现得像 Completions API。
- en: Important note
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: The CompletionsAPI, launched in June 2020, initially offered a freeform text
    interface for Open AI’s language models. However, experience has shown that structured
    prompts often yield better outcomes. The chat-based approach, especially through
    the ChatCompletions API, excels in addressing a wide array of needs, offering
    enhanced flexibility and specificity and reducing prompt injection risks. Its
    design supports multi-turn conversations and a variety of tasks, enabling developers
    to create advanced conversational experiences. Hence, Open AI announced that they
    would be deprecating some of the older models using Completions API and, in moving
    forward, they would be investing in the ChatCompletions API to optimize their
    efforts to use compute capacity. While the Completions API will remain accessible,
    it shall be labeled as “legacy” in the Open AI developer documentation.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 2020 年 6 月推出的 CompletionsAPI，最初为 Open AI 的语言模型提供了一个自由文本界面。然而，经验表明，结构化提示往往会产生更好的结果。基于聊天的方法，尤其是通过
    ChatCompletions API，在满足广泛需求方面表现出色，提供了更高的灵活性和具体性，并降低了提示注入风险。其设计支持多轮对话和各种任务，使开发者能够创建高级的对话体验。因此，Open
    AI 宣布他们将弃用一些使用 Completions API 的较旧模型，并且在未来，他们将投资于 ChatCompletions API 以优化其计算能力的使用。虽然
    Completions API 仍将可用，但在 Open AI 开发者文档中将被标记为“遗留”。
- en: Tokens
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 标记
- en: Understanding the concepts of tokens is essential, as it helps us better comprehend
    the restrictions, such as model limitations, and the aspect of cost management
    when utilizing ChatGPT.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 理解标记的概念至关重要，因为它有助于我们更好地理解在使用 ChatGPT 时遇到的限制，例如模型限制和成本管理方面的问题。
- en: A ChatGPT token is a unit of text that ChatGPT’s language model uses to understand
    and generate language. In ChatGPT, a token is a sequence of characters that the
    model uses to generate new sequences of tokens and form a coherent response to
    a given prompt. The models use tokens to represent words, phrases, and other language
    elements. The tokens are not cut where the word starts or ends but can consist
    of trailing spaces, sub words and punctuations, too.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT 的标记是 ChatGPT 语言模型用来理解和生成语言的文本单位。在 ChatGPT 中，一个标记是模型用来生成新的标记序列并形成对给定提示的连贯响应的字符序列。模型使用标记来表示单词、短语和其他语言元素。标记不会在单词的开始或结束处被截断，也可以由尾随空格、子词和标点符号组成。
- en: As stated on the OpenAI website, tokens can be thought of as pieces of words.
    Before the API processes the prompts, the input is broken down into tokens.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 如 OpenAI 网站所述，标记可以被视为单词的片段。在 API 处理提示之前，输入被分解成标记。
- en: 'To understand tokens in terms of lengths, the following is used as a rule of
    thumb:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 为了从长度上理解标记，以下是一个经验法则：
- en: 1 token ~= 4 chars in English
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 标记 ~= 4 个英文字符
- en: 1 token ~= ¾ words
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 标记 ~= ¾ 个单词
- en: 100 tokens ~= 75 words
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 100 标记 ~= 75 个单词
- en: 1–2 sentences ~= 30 tokens
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1–2 句 ~= 30 标记
- en: 1 paragraph ~= 100 tokens
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 段 ~= 100 标记
- en: 1,500 words ~= 2048 tokens
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1,500 字 ~= 2048 标记
- en: 1 US page (8 ½” x 11”) ~= 450 tokens (assuming ~1800 characters per page)
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 美国页（8 ½” x 11”） ~= 450 标记（假设每页约 1800 个字符）
- en: 'For example, this famous quote from Thomas Edison (“Genius is one percent inspiration
    and ninety-nine percent perspiration.”) has **14** tokens:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，托马斯·爱迪生（Thomas Edison）的这句著名引言（“天才是一分灵感，百分之九十九是汗水。”）有 **14** 个标记：
- en: '![Figure 5.3 – Tokenization of sentence](img/B21443_05_3.jpg)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.3 – 句子分词](img/B21443_05_3.jpg)'
- en: Figure 5.3 – Tokenization of sentence
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.3 – 句子分词
- en: We used the OpenAI **Tokenizer** tool to calculate the tokens; the tool can
    be found at [https://platform.openai.com/tokenizer](https://platform.openai.com/tokenizer).
    An alternative way to tokenize text (programmatically) is to use the **Tiktoken
    library** on Github; this can be found at [https://github.com/openai/tiktoken](https://github.com/openai/tiktoken).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了 OpenAI 的 **Tokenizer** 工具来计算标记；该工具可以在 [https://platform.openai.com/tokenizer](https://platform.openai.com/tokenizer)
    找到。另一种对文本进行标记（程序化）的方法是使用 Github 上的 **Tiktoken 库**；这可以在 [https://github.com/openai/tiktoken](https://github.com/openai/tiktoken)
    找到。
- en: Token limits in ChatGPT models
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ChatGPT 模型的标记限制
- en: Depending on the model, the token limits on the model will vary. As of Feb 2024,
    the token limit for the family of GPT-4 models ranges from 8,192 to 128,000 tokens.
    This means the sum of prompt and completion tokens for an API call cannot exceed
    32,768 tokens for the GPT-4-32K model. If the prompt is 30,000 tokens, the response
    cannot be more than 2,768 tokens. The GPT4-Turbo 128K is the most recent model
    as of Feb 2024, with 128,000 tokens, which is close to 300 pages of text in a
    single prompt and completion. This is a massive context prompt compared to its
    predecessor models.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 根据模型的不同，模型的令牌限制会有所变化。截至2024年2月，GPT-4模型系列的令牌限制范围从8,192到128,000个令牌。这意味着API调用中提示和完成令牌的总和不能超过GPT-4-32K模型的32,768个令牌。如果提示为30,000个令牌，则响应不能超过2,768个令牌。GPT4-Turbo
    128K是截至2024年2月最新的模型，拥有128,000个令牌，这相当于单个提示和完成中的近300页文本。与前辈模型相比，这是一个巨大的上下文提示。
- en: Though this can be a technical limitation, there are creative ways to address
    the problem of limitation, such as using chunking and condensing your prompts.
    We discussed chunking strategies in [*Chapter 4*](B21443_04.xhtml#_idTextAnchor070),
    which can help you address token limitations.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这可能是一个技术限制，但有一些创造性的方法可以解决限制问题，例如使用分块和压缩提示。我们在[*第4章*](B21443_04.xhtml#_idTextAnchor070)中讨论了分块策略，这可以帮助你解决令牌限制问题。
- en: 'The following figure shows various models and token limits:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 下图显示了各种模型和令牌限制：
- en: '| **Model** | **Token Limit** |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| **模型** | **令牌限制** |'
- en: '| --- | --- |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| GPT-3.5-turbo | 4,096 |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| GPT-3.5-turbo | 4,096 |'
- en: '| GPT-3.5-turbo-16k | 16,384 |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| GPT-3.5-turbo-16k | 16,384 |'
- en: '| GPT-3.5-turbo-0613 | 4,096 |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| GPT-3.5-turbo-0613 | 4,096 |'
- en: '| GPT-3.5-turbo-16k-0613 | 16,384 |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| GPT-3.5-turbo-16k-0613 | 16,384 |'
- en: '| GPT-4 | 8,192 |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4 | 8,192 |'
- en: '| GPT-4-0613 | 32,768 |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4-0613 | 32,768 |'
- en: '| GPT-4-32K | 32,768 |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4-32K | 32,768 |'
- en: '| GPT-4-32-0613 | 32,768 |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4-32-0613 | 32,768 |'
- en: '| GPT-4-Turbo 128K | 128,000 |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4-Turbo 128K | 128,000 |'
- en: Figure 5.4 – Models and associated Token Limits
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.4 – 模型和相关的令牌限制
- en: For the latest updates on model limits for newer versions of models, please
    check the OpenAI website.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 关于模型最新版本的模型限制的最新更新，请检查OpenAI网站。
- en: Tokens and cost considerations
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 令牌和成本考虑
- en: The cost of using ChatGPT or similar models via an API is often tied to the
    number of tokens processed, encompassing both the input prompts and the model’s
    generated responses.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 通过API使用ChatGPT或类似模型的成本通常与处理的令牌数量相关，包括输入提示和模型生成的响应。
- en: In terms of pricing, providers typically have a per-token charge, leading to
    a direct correlation between conversation length and cost; the more tokens processed,
    the higher the cost. The latest cost updates can be found on the OpenAI website.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在定价方面，提供商通常按每个令牌收费，导致对话长度与成本直接相关；处理的令牌越多，成本越高。最新的成本更新可以在OpenAI网站上找到。
- en: From an optimization perspective, understanding this cost-token relationship
    can guide more efficient API usage. For instance, creating more succinct prompts
    and configuring the model for brief yet effective responses can help control token
    count and, consequently, manage expenses.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 从优化的角度来看，理解这种成本-令牌关系可以指导更有效的API使用。例如，创建更简洁的提示并配置模型以提供简短而有效的响应可以帮助控制令牌数量，从而管理费用。
- en: We hope you now have a good understanding of the key components of a prompt.
    Now, you are ready to learn about prompt engineering. In the next section, we
    will explore the details of prompt engineering and effective strategies, enabling
    you to maximize the potential of your prompt contents through the one-shot and
    few-shot learning approaches.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望你现在已经很好地理解了提示的关键组件。现在，你准备好学习提示工程了。在下一节中，我们将探讨提示工程的细节和有效策略，通过单次学习和少量学习的方法，使你能够最大限度地发挥提示内容潜力。
- en: What is prompt engineering?
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是提示工程？
- en: Prompt engineering is the art of crafting or designing prompts to unlock desired
    outcomes from large language models or AI systems. The concept of prompt engineering
    revolves around the fundamental idea that the quality of your response is intricately
    tied to the quality of the question you pose. By strategically engineering prompts,
    one can influence the generated outputs and improve the overall performance and
    usefulness of the system. In this section, we will learn about the necessary elements
    of effective prompt design, prompt engineering techniques, best practices, bonus
    tips, and tricks.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 提示工程是制作或设计提示以从大型语言模型或AI系统中解锁所需结果的艺术。提示工程的概念围绕着这样一个基本理念：你得到的回答质量与提出的问题质量紧密相连。通过策略性地设计提示，可以影响生成的输出并提高系统的整体性能和实用性。在本节中，我们将学习有效提示设计所需的要素、提示工程技术、最佳实践、额外技巧和窍门。
- en: Elements of a good prompt design
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 良好提示设计的要素
- en: Designing a good prompt is important because it significantly influences the
    output of a language model such as GPT. The prompt provides the initial context,
    sets the task, guides the style and structure of the response, reduces ambiguities
    and hallucinations, and supports the optimization of resources, thereby reducing
    costs and energy use. In this section, let’s understand the elements of good prompt
    design.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 设计一个好的提示非常重要，因为它会显著影响GPT等语言模型的输出。提示提供了初始上下文，设定了任务，指导了回答的风格和结构，减少了歧义和幻觉，并支持资源的优化，从而降低成本和能源消耗。在本节中，让我们了解良好提示设计的要素。
- en: 'The foundational elements of a good prompt include instructions, questions,
    input data, and examples:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 良好提示的基础要素包括指令、问题、输入数据和示例：
- en: '**Instructions**: The instructions in a prompt refer to the specific guidelines
    or directions given to a language model within the input text to guide the kind
    of response it should produce.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**指令**：提示中的指令指的是在输入文本中给出的具体指南或方向，以指导语言模型应产生的回答类型。'
- en: '**Questions**: Questions in a prompt refer to queries or interrogative statements
    that are included in the input text. The purpose of these questions is to instruct
    the language model to provide a response or an answer to the query. In order to
    obtain the results, either the question or instruction is mandatory.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**问题**：提示中的问题指的是包含在输入文本中的查询或疑问句。这些问题的目的是指示语言模型提供对查询的响应或答案。为了获得结果，问题或指令是必须的。'
- en: '**Input data**: The purpose of input data is to provide any additional supporting
    context when prompting the LLM. It could be used to provide new information the
    model has not previously been trained on for more personalized experiences.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输入数据**：输入数据的目的是在提示LLM时提供任何额外的支持上下文。它可以用来提供模型之前未训练过的新信息，以实现更个性化的体验。'
- en: '**Examples**: The purpose of examples in a prompt is to provide specific instances
    or scenarios that illustrate the desired behavior or response from ChatGPT. You
    can input a prompt that includes one or more examples, typically in the form of
    input-output pairs.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**示例**：提示中示例的目的是提供具体实例或场景，以说明ChatGPT期望的行为或响应。你可以输入包含一个或多个示例的提示，通常以输入-输出对的形式。'
- en: 'The following table shows how to build effective prompts using the aforementioned
    prompt elements:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 下表展示了如何使用上述提示元素构建有效的提示：
- en: '| **Sample** **Prompt Formula** | **Example** |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| **样本** **提示公式** | **示例** |'
- en: '| --- | --- |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Questions + Instructions | How should I create a healthy meal plan for a
    week?Include a variety of nutrients and food groups, and explain the benefits
    of each meal choice. |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| 问题 + 指令 | 我应该如何创建一个为期一周的健康餐单？包括各种营养和食物组，并解释每个餐点的益处。 |'
- en: '| Instructions + Input Data | Provide a punchy title in less than 5 words for
    the paragraph below.{Jake finally took his brand-new Tesla for a spin on the coastal
    highway, the smooth hum of the electric motor filling the air as the scenic ocean
    views passed by.} |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| 指令 + 输入数据 | 为以下段落提供一个不超过5个字的醒目标题：{杰克终于驾驶他全新的特斯拉在沿海公路上试驾，随着风景如画的海洋景观一闪而过，电动汽车的平稳嗡嗡声充满了空气。}
    |'
- en: '| Examples + Question | I enjoy movies such as Star Wars, Matrix, and Transformers.What
    other movies would you recommend? |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| 示例 + 问题 | 我喜欢像星球大战、黑客帝国和变形金刚这样的电影。你还会推荐其他哪些电影？ |'
- en: Figure 5.5 – Sample Prompt formula consisting of prompt elements with examples
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.5 – 由示例组成的样本提示公式，包含提示元素
- en: Prompt parameters
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提示参数
- en: 'ChatGPT prompt parameters are variables that you can set in the API calls.
    They allow users to influence the model’s output, customizing the behavior of
    the model to better fit specific applications or contexts. The following table
    shows some of the most important parameters of a ChatGPT API call:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT提示参数是在API调用中可以设置的变量。它们允许用户影响模型输出，定制模型的行为以更好地适应特定的应用或上下文。以下表格显示了ChatGPT
    API调用的一些最重要的参数：
- en: '| **Parameter** | **Description** | **Effect** **and Usage** |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| **参数** | **描述** | **效果和用法** |'
- en: '| --- | --- | --- |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Model | Determines the model to be used in the API. Larger models have higher
    costs and latency. | Select based on the task complexity, cost considerations,
    and acceptable latency. Always try to use the latest model version. |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | 确定在API中使用的模型。较大的模型具有更高的成本和延迟。 | 根据任务复杂度、成本考虑和可接受的延迟进行选择。始终尝试使用最新版本的模型。
    |'
- en: '| Temperature | Controls the randomness of the model’s responses. It can be
    set between 0 (more focused responses) and 2 (more diverse responses). | Lower
    values yield more deterministic responses, which is ideal for more formal or exact
    responses, such as in legal use cases. Higher values may result in more creative
    output but can also lead to hallucinations. |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| 温度 | 控制模型响应的随机性。它可以设置为0（更集中的响应）到2（更多样化的响应）。 | 较低的值会产生更确定性的响应，这对于更正式或精确的响应，如法律用例，是理想的。较高的值可能导致更具创造性的输出，但也可能导致幻觉。
    |'
- en: '| Top_P (Nucleus Sampling) | Sets a cumulative probability threshold for the
    model’s responses. A value of 0.1 implies only the top 10% of probable tokens
    are considered. | Lower values yield more predictable and focused responses. OpenAI
    recommends using either Temperature or Top_p, not both. |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| Top_P（核采样） | 设置模型响应的累积概率阈值。0.1的值意味着只有最可能的10%的令牌被考虑。 | 较低的值会产生更可预测和集中的响应。OpenAI建议使用Temperature或Top_p中的一个，而不是两者都使用。
    |'
- en: '| Max Tokens | Sets the maximum length of the generated response. This is useful
    for controlling the length of output and the cost. | Lower values lead to shorter
    responses, reduced latency, and potentially lower costs, while higher values allow
    for longer, more detailed responses. |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| 最大令牌数 | 设置生成响应的最大长度。这对于控制输出长度和成本很有用。 | 较低的值会导致较短的响应，降低延迟，并可能降低成本，而较高的值允许生成更长、更详细的响应。
    |'
- en: Figure 5.6 – Essential Prompt Parameters
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.6 – 有效的提示参数
- en: In this section, only the top parameters for building an effective prompt are
    highlighted. For a full list of parameters, refer to the OpenAI API reference
    ([https://platform.openai.com/docs/api-reference](https://platform.openai.com/docs/api-reference)).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，仅突出显示构建有效提示所需的最重要参数。有关参数的完整列表，请参阅OpenAI API参考（[https://platform.openai.com/docs/api-reference](https://platform.openai.com/docs/api-reference)）。
- en: ChatGPT roles
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ChatGPT角色
- en: System message
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 系统消息
- en: This is the part where you design your metaprompts. Metaprompts help to set
    the initial context, theme, and behavior of the ChatGPT API to guide the model’s
    interactions with the user, thus setting roles or response styles for the assistant.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 这是您设计元提示的部分。元提示有助于设定初始上下文、主题和行为，以引导ChatGPT API与用户的交互，从而为助手设定角色或响应风格。
- en: Metaprompts are structured instructions or guidelines that dictate how the system
    should interpret and respond to user requests. These metaprompts are designed
    to ensure that the system’s outputs adhere to specific policies, ethical guidelines,
    or operational rules. They’re essentially “prompts about how to handle prompts,”
    guiding the system in generating responses, handling data, or interacting with
    users in a way that aligns with predefined standards.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 元提示是有结构的指令或指南，它规定了系统应该如何解释和响应用户请求。这些元提示旨在确保系统的输出符合特定的政策、道德指南或操作规则。它们本质上是对“如何处理提示”的提示，指导系统在生成响应、处理数据或与用户交互时符合预定义的标准。
- en: 'The following table is a metaprompt framework that you can follow to design
    the ChatGPT system message:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 以下表格是一个元提示框架，您可以遵循它来设计ChatGPT系统消息：
- en: '| **Elements of** **a Metaprompt** | **Description** |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| **元提示的** **要素** | **描述** |'
- en: '| --- | --- |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Task and Audience | Explain the intended audience for the application and
    expectations from the model. |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| 任务和受众 | 解释应用的目标受众和模型期望。 |'
- en: '| Helper Tools | Clarify how the model should address user queries and whether
    there are external tools, such as plugins, APIs, or code, that the model might
    need to consider utilizing. |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| 辅助工具 | 明确模型应如何处理用户查询，以及是否存在模型可能需要考虑利用的外部工具，例如插件、API 或代码。|'
- en: '| Scope of the Task | Clarify on how the model should respond if a question
    is out of scope, and set those guard rails. |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| 任务范围 | 明确模型在遇到超出范围的问题时应如何响应，并设置这些防护措施。|'
- en: '| Posture and Tone | Setting postures and tones, such as professional, friendly,
    respectful, and motivational, help improve user experiences with chat application.
    |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| 姿态和语气 | 设置专业、友好、尊重和激励等姿态和语气，有助于改善用户在使用聊天应用时的体验。|'
- en: '| Format of Responses | Based on the requirements of the application, you can
    set the output format to be of a certain format. It could be a table of contents,
    a certain programming language, JSON, or XML. |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| 响应格式 | 根据应用程序的要求，您可以设置输出格式为特定的格式。这可能是一个目录、某种编程语言、JSON 或 XML。|'
- en: '| Few-Shot Examples | Outline the challenging scenarios where the prompts are
    unclear or complex, providing the model with more insight into how to handle such
    situations. |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| 少样本示例 | 概述提示不明确或复杂的有挑战性的场景，为模型提供更多关于如何处理此类情况的见解。|'
- en: '| Chain-of-Thought Reasoning | Demonstrate the reasoning process to guide the
    model in taking the necessary steps to produce the desired results. |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| 思维链推理 | 展示推理过程，以引导模型采取必要的步骤来产生期望的结果。|'
- en: '| Guardrails to Address Specific Harm | Establish clear boundaries to address
    and prevent any potential harm that has been recognized and deemed important for
    the given scenario.For example, if jailbreaking attempts are detected, you must
    have clear guardrails to address those jailbreaking attempts in the system message.
    We will learn more about jailbreaking in [*Chapter 8*](B21443_08.xhtml#_idTextAnchor163).
    |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| 针对特定危害的防护措施 | 建立明确的边界，以应对和预防已识别并认为对特定场景重要的一切潜在危害。例如，如果检测到越狱尝试，您必须在系统消息中明确防护措施来应对这些越狱尝试。我们将在[*第
    8 章*](B21443_08.xhtml#_idTextAnchor163)中了解更多关于越狱的内容。|'
- en: Figure 5.7 – Elements of a Metaprompt
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.7 – 元提示的元素
- en: User
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 用户
- en: The messages from the user serve as prompts or remarks that the assistant is
    expected to react to or engage with. what is it establishes the anticipated scope
    of queries that may come from the user.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 用户的消息作为提示或评论，是助手预期会做出反应或参与的内容。这确立了可能来自用户的查询的预期范围。
- en: Assistant
  id: totrans-110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 助手
- en: While not mandatory, assistant messages can be included to illustrate the preferred
    conduct or response patterns of the chatbot.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然不是强制性的，但助手消息可以包含在内，以说明聊天机器人的首选行为或响应模式。
- en: 'Now let’s look at an example; if you are developing an application for a fitness
    AI assistant, a very well-rounded system message might look as follows:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们来看一个例子；如果您正在开发一个健身人工智能助手的程序，一个全面系统的系统消息可能看起来如下所示：
- en: '[PRE1]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The following link provides great examples of “Act As” prompts for you to leverage
    in your system message: *Awesome ChatGPT* *Prompts* ([https://github.com/f/awesome-chatgpt-prompts/](https://github.com/f/awesome-chatgpt-prompts/)).'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 以下链接提供了许多“扮演”提示的示例，供您在系统消息中利用：*Awesome ChatGPT* *Prompts* ([https://github.com/f/awesome-chatgpt-prompts/](https://github.com/f/awesome-chatgpt-prompts/))。
- en: Techniques for effective prompt engineering
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 有效的提示工程技巧
- en: In the past two years, a wide array of prompt-engineering techniques have been
    developed. This section focuses on the essential ones, offering key strategies
    that you might find indispensable for daily interactions with ChatGPT and other
    LLM-based applications.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去两年中，已经开发了许多提示工程技巧。本节重点介绍其中的一些基本技巧，提供了一些您可能认为对于与 ChatGPT 和其他基于 LLM 的应用程序的日常交互不可或缺的关键策略。
- en: N-shot prompting
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: N-shot 提示
- en: N-shot prompting is a term used in the context of training large language models,
    particularly for **zero-shot** or **few-shot** learning tasks. It is also called
    in-context learning and refers to the technique of providing the model with example
    prompts along with corresponding responses during training to steer the model’s
    behavior to provide more accurate responses.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: N-shot 提示是在训练大型语言模型的背景下使用的术语，特别是用于**零样本**或**少样本**学习任务。它也被称为情境学习，指的是在训练过程中向模型提供示例提示及其相应响应的技术，以引导模型的行为，提供更准确的响应。
- en: The “N” in “N-shot” refers to the number of example prompts provided to the
    model. For instance, in a one-shot learning scenario, only one example prompt
    and its response are given to the model. In an N-shot learning scenario, multiple
    example prompts and responses are provided.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: “N”在“N样本”中指的是提供给模型的示例提示的数量。例如，在一样本学习场景中，只向模型提供了一个示例提示及其响应。在N样本学习场景中，提供了多个示例提示及其响应。
- en: 'While ChatGPT works great with zero-shot prompting, it may sometimes be useful
    to provide examples for a more accurate response. Let’s see some examples of zero-shot
    and few-shot prompting:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然ChatGPT在零样本提示下表现良好，但有时提供示例可能有助于获得更准确的响应。让我们看看零样本和少样本提示的示例：
- en: '| **Techniques** | **Prompt Example** |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| **技术** | **提示示例** |'
- en: '| --- | --- |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| **Zero-shot prompting**: No additional examples are provided in line with
    the prompt. | System message: You are an AI assistant who determines the sentiment
    of the customer review provided.(No examples responses provided in the form of
    assistant response, hence it is called zero-shot prompting.) |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| **零样本提示**：与提示一起提供，没有额外的示例。 | 系统消息：您是一位AI助手，负责确定客户评价的情感。（没有以助手回应的形式提供示例，因此称为零样本提示。）
    |'
- en: '| **Few-Shot Prompting**: A few examples are provided in line with the prompt.
    | System message: You are an AI assistant who determines the sentiment of the
    customer review provided.Example 1:User: The product is miserable.Assistant: NegativeExample
    2:User: This shirt is made from very good material.Assistant: Positive |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| **少样本提示**：在提示中提供了一些示例。 | 系统消息：您是一位AI助手，负责确定客户评价的情感。示例 1：用户：这个产品很糟糕。助手：负面示例
    2：用户：这件衬衫是由非常好的材料制成的。助手：正面 |'
- en: Figure 5.8 – N-shot prompting examples
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.8 – N样本提示示例
- en: Chain-of-thought (CoT) prompting
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 思维链（CoT）提示
- en: 'Chain-of-thought prompting refers to a sequence of intermediate reasoning steps,
    significantly boosting the capability of large language models to tackle complex
    reasoning tasks. By presenting a few chain-of-thought demonstrations as examples
    in the prompts, the models proficiently handle intricate reasoning tasks:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 思维链提示指的是一系列中间推理步骤，显著提升了大型语言模型处理复杂推理任务的能力。通过在提示中提供几个思维链演示作为示例，模型能够熟练地处理复杂的推理任务：
- en: '![Figure 5.9 – Chain-of-Thought Prompting Examples](img/B21443_05_4.jpg)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.9 – 思维链提示示例](img/B21443_05_4.jpg)'
- en: Figure 5.9 – Chain-of-Thought Prompting Examples
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.9 – 思维链提示示例
- en: Figure sourced from [https://arxiv.org/pdf/2201.11903.pdf](https://arxiv.org/pdf/2201.11903.pdf).
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 图来源于 [https://arxiv.org/pdf/2201.11903.pdf](https://arxiv.org/pdf/2201.11903.pdf)。
- en: Program-aided language (PAL) models
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 程序辅助语言（PAL）模型
- en: '**Program-aided language** (**PAL**) models, also called **program-of-thought
    prompting** (**PoT**), is a technique that incorporates additional task-specific
    instructions, pseudo-code, rules, or programs alongside the free-form text to
    guide the behavior of a language model:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '**程序辅助语言**（**PAL**）模型，也称为**思维程序提示**（**PoT**），是一种将额外的任务特定指令、伪代码、规则或程序与自由文本结合的技术，以指导语言模型的行为：'
- en: '![Figure 5.10 – Program-aided language prompting examples](img/B21443_05_5.jpg)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.10 – 程序辅助语言提示示例](img/B21443_05_5.jpg)'
- en: Figure 5.10 – Program-aided language prompting examples
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.10 – 程序辅助语言提示示例
- en: Figure sourced from [https://arxiv.org/abs/2211.10435](https://arxiv.org/abs/2211.10435).
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 图来源于 [https://arxiv.org/abs/2211.10435](https://arxiv.org/abs/2211.10435)。
- en: 'In this section, although we have not explored all prompt engineering techniques
    (only the most important ones), we want to convey to our readers that there are
    numerous variants of these techniques, as illustrated in the following figure
    from the research paper *A Systematic Survey of prompt engineering in Large Language
    Models: Techniques and Applications* ([https://arxiv.org/pdf/2402.07927.pdf](https://arxiv.org/pdf/2402.07927.pdf)).
    This paper provides an extensive inventory of prompt engineering strategies across
    various application areas, showcasing the evolution and breadth of this field
    over the last four years:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，尽管我们没有探索所有提示工程技术（只探索了其中最重要的），但我们想向读者传达，这些技术有众多变体，如下文所示的研究论文《大型语言模型中提示工程的系统调查：技术和应用》中的图所示（[https://arxiv.org/pdf/2402.07927.pdf](https://arxiv.org/pdf/2402.07927.pdf)）。这篇论文提供了跨各种应用领域的提示工程策略的详尽清单，展示了过去四年该领域的演变和广度：
- en: '![Figure 5.11 – Taxonomy of prompt engineering techniques across multiple application
    domains](img/B21443_05_6.jpg)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.11 – 涉及多个应用领域的提示工程技术分类](img/B21443_05_6.jpg)'
- en: Figure 5.11 – Taxonomy of prompt engineering techniques across multiple application
    domains
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.11 – 涉及多个应用领域的提示工程技术分类
- en: Prompt engineering best practices
  id: totrans-139
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提示工程最佳实践
- en: 'In the following list, we outline additional best practices to optimize and
    enhance your experience with prompt creation:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下列表中，我们概述了额外的最佳实践，以优化和增强你使用提示创建的体验：
- en: '**Clarity and precision for accurate responses**: Ensure that prompts are clear,
    concise, and specific, avoiding ambiguity or multiple interpretations:'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**清晰和精确以获得准确响应**：确保提示清晰、简洁、具体，避免含糊不清或多种解释：'
- en: '| **Bad Prompt** | **Good Prompt** |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| **差的提示** | **好的提示** |'
- en: '| --- | --- |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Tell me about World War 1 | How did World War 1 start, and who won it? |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| 告诉我关于第一次世界大战的事情 | 第一次世界大战是如何开始的，谁赢得了它？ |'
- en: 'Figure 5.12 – Best practice: clarity and precision'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.12 – 最佳实践：清晰和精确
- en: '**Descriptive**: Be descriptive so that ChatGPT can understand your intent:'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**描述性**：要描述性，以便 ChatGPT 能够理解你的意图：'
- en: '| **Bad Prompt** | **Good Prompt** |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| **差的提示** | **好的提示** |'
- en: '| --- | --- |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Write a poem about India. | Write a poem about India focusing on its cultural
    diversity, deciduous cuisine, beautiful wildlife, nature, technology innovation,
    and film industry. |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| 写一首关于印度的诗。 | 写一首关于印度的诗，侧重于其文化多样性、落叶美食、美丽的野生动物、自然、技术创新和电影产业。 |'
- en: 'Figure 5.13 – Best practice: be descriptive'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.13 – 最佳实践：描述性
- en: '**Format the output**: Mention the format of the output, which can be bullet
    points, paragraphs, sentences, tables, and languages, such as XML, HTML, and JSON.
    Use examples to articulate the desired output.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**格式化输出**：说明输出格式，可以是项目符号、段落、句子、表格和语言，如 XML、HTML 和 JSON。使用示例来阐述期望的输出。'
- en: '**Adjust the Temperature and Top_p parameters for creativity**: As indicated
    in the parameters section, modifying the **Temperatures** and **Top_p** can significantly
    influence the variability of the model’s output. In scenarios that call for creativity
    and imagination, raising the temperature proves beneficial. On the other hand,
    when dealing with legal applications that demand a reduction in hallucinations,
    a lower temperature becomes advantageous.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**调整温度和 Top_p 参数以增加创造力**：如参数部分所示，修改**温度**和**Top_p**可以显著影响模型输出的可变性。在需要创造力和想象力的场景中，提高温度是有益的。另一方面，在处理需要减少幻觉的法律应用时，降低温度是有利的。'
- en: '**Use syntax as separators in prompts**: In this example, for a more effective
    output, use “”” or ### to separate instruction and input data:'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**在提示中使用语法作为分隔符**：在此示例中，为了获得更有效的输出，使用“””或###来分隔指令和输入数据：'
- en: 'Example:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: Convert the text below to Spanish
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 将以下文本翻译成西班牙语
- en: 'Text: “””'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 文本：“””
- en: '{text input here}'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '{在此处输入文本}'
- en: “””
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: “””
- en: '**Order of the prompt elements matter**: It has been found, in certain instances,
    that giving an instruction before an example can improve the quality of your outputs.
    Additionally, the order of examples can affect the output of prompts.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提示元素的顺序很重要**：在某些情况下，发现在示例之前给出指令可以提高输出的质量。此外，示例的顺序也会影响提示的输出。'
- en: '**Use guiding words**: This helps steer the model toward a specific structure,
    such as the text highlighted in the following:'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用引导词**：这有助于将模型引导到特定的结构，如下所示：'
- en: 'Example:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: Create a basic Python function that
  id: totrans-162
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建一个基本的 Python 函数，
- en: 1\. Requests the user to enter a temperature in Celsius
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1. 请求用户输入摄氏温度
- en: 2\. Converts the Celsius temperature to Fahrenheit
  id: totrans-164
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2. 将摄氏温度转换为华氏温度
- en: 'def ctf():'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 'def ctf():'
- en: '**Instead of saying what not to provide, give alternative recommendations**:
    Provide an alternative path if ChatGPT is unable to perform a task, such as in
    the following highlighted message:'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**而不是说不要提供什么，给出替代建议**：如果 ChatGPT 无法执行任务，提供替代路径，如下所示的高亮消息：'
- en: 'Example:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：
- en: 'System Message: You are an AI nutrition consultant that provides nutrition
    consultation based on health and wellness goals of the customer Please note that
    any questions or inquiries beyond the scope of nutrition consultation will NOT
    be answered and instead will receive the response: “Sorry! This question falls
    outside my domain of expertise!”'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 系统消息：您是一位基于客户健康和福祉目标的 AI 营养顾问，请注意，任何超出营养咨询范围的问题或询问将不会回答，而是收到以下响应：“抱歉！这个问题超出了我的专业领域！”
- en: 'Customer: How do I invest in 401K?'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 客户：我如何投资401K？
- en: 'Nutrition AI Assistant: “Sorry! This question falls outside my domain of expertise!”'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 营养AI助手： “抱歉！这个问题超出了我的专业领域！”
- en: '**Provide example-based prompts**: This helps the language model learn from
    specific instances and patterns. Start with a zero-shot, then a few-shot, and
    if neither of them works, then fine-tune the model.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提供基于实例的提示**： 这有助于语言模型从具体的实例和模式中学习。从零样本开始，然后是几个样本，如果它们都不起作用，那么就微调模型。'
- en: '**Ask ChatGPT to provide citations/sources**: When asking ChatGPT to provide
    information, you can ask it to answer only using reliable sources and to cite
    the sources:'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**要求ChatGPT提供引用/来源**： 当要求ChatGPT提供信息时，您可以要求它只使用可靠的来源，并引用这些来源：'
- en: '| **Prompts** | **ChatGPT Completion** |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| **提示** | **ChatGPT完成** |'
- en: '| --- | --- |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| When was the steam engine invented?Answer using only reliable sources and
    cite the sources | The steam engine was invented during the late 17th century.
    The first practical steam engine is credited to Thomas Savery, an English military
    engineer and inventor, who patented his design in 1698\. Savery’s steam engine
    was primarily used for pumping water out of mines.Source: Encyclopædia Britannica.
    (2021, September 2). Thomas Savery. In Encyclopædia Britannica. [https://www.britannica.com/biography/Thomas-Savery](https://www.britannica.com/biography/Thomas-Savery).
    |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| 何时发明了蒸汽机？请仅使用可靠的来源并引用来源 | 蒸汽机是在17世纪末发明的。第一台实用的蒸汽机归功于托马斯·萨弗里，他是英国军事工程师和发明家，他在1698年获得了他的设计的专利。萨弗里的蒸汽机主要用于从矿井中抽水。来源：大英百科全书。（2021年9月2日）。托马斯·萨弗里。在大英百科全书。[https://www.britannica.com/biography/Thomas-Savery](https://www.britannica.com/biography/Thomas-Savery)
    |'
- en: 'Figure 5.14 – Best practice: provide citations'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.14 – 最佳实践：提供引用
- en: '**Break down a complex task into simpler tasks**: See the following example:'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**将复杂任务分解为更简单的任务**： 请参阅以下示例：'
- en: '| **Bad Prompt** | **Effective Prompt** |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| **差的提示** | **有效的提示** |'
- en: '| Provide a summary of the following and provide key points from the summary
    | Provide a summary of the following text: [Insert long text here]Summarize the
    key points from the following passage: [Insert long text here] |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| 提供以下内容的总结并提供关键点 | 提供以下文本的总结：[在此处插入长文本]总结以下段落的关键点：[在此处插入长文本] |'
- en: 'Figure 5.15 – Best practice: break down a complex task'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.15 – 最佳实践：分解复杂任务
- en: Bonus tips and tricks
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 额外技巧和窍门
- en: 'The following list provides some helpful bonus tips and tricks:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列表提供了一些有用的额外技巧和窍门：
- en: '`<begin>`, `<end>`, and `<|endofprompt|>`, that determine the beginning and
    end of prompts can help separate the different elements of a prompt. This can
    help generate high-quality output.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<begin>`，`<end>`，和`<|endofprompt|>`，这些可以确定提示的开始和结束，有助于区分提示的不同元素。这有助于生成高质量的输出。'
- en: '**Use of languages**: Though ChatGPT performs best with English, it can be
    used to generate responses in several other languages.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用语言**： 虽然ChatGPT在英语上表现最佳，但它可以用来生成多种其他语言的响应。'
- en: '**Obtaining the most accurate, up-to-date information**: This can be achieved
    by using the grounding process with a **retrieval augmented generation** (**RAG**)
    architecture and plugins, as discussed in [*Chapter 4*](B21443_04.xhtml#_idTextAnchor070)
    already. This helps in addressing the knowledge cutoff limitation of LLMs.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**获取最准确、最新的信息**： 这可以通过使用带有**检索增强生成**（**RAG**）架构和插件的grounding过程来实现，正如在[*第4章*](B21443_04.xhtml#_idTextAnchor070)中已经讨论的那样。这有助于解决LLMs的知识截止限制。'
- en: Ethical guidelines for prompt engineering
  id: totrans-186
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提示工程伦理准则
- en: Prompt engineering is a critical stage where AI behavior is molded, and incorporating
    ethics at this level helps ensure that AI language models are developed and deployed
    responsibly. It promotes fairness, transparency, and user trust while avoiding
    potential risks and negative societal impact.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 提示工程是一个关键阶段，AI的行为在这里被塑造，在这个层面上融入伦理有助于确保AI语言模型被负责任地开发和部署。它促进了公平、透明和用户信任，同时避免了潜在的风险和负面影响。
- en: 'While [*Chapter 4*](B21443_04.xhtml#_idTextAnchor070) delved further into constructing
    ethical generative AI solutions, in this section, our focus will be on briefly
    discussing the integration of ethical approaches at the prompt engineering level:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然[*第4章*](B21443_04.xhtml#_idTextAnchor070)进一步探讨了构建道德生成式AI解决方案，但本节的重点将简要讨论在提示工程级别整合道德方法：
- en: '**Diverse and** **representative data**'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多样化和** **代表性数据**'
- en: When fine-tuning the model with few-shot examples, use training data that represent
    diverse perspectives and demographics.
  id: totrans-190
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在使用少量示例微调模型时，使用代表不同观点和人口统计数据的训练数据。
- en: If the AI language model is intended for healthcare, the training data should
    cover medical cases from different demographics and regions.
  id: totrans-191
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果AI语言模型旨在用于医疗保健，训练数据应涵盖来自不同人口统计和地区的医疗案例。
- en: For instance, if a user poses a question to the LLM, such as, “Can you describe
    some global traditional festivals?” the response should offer a comprehensive
    view that encompasses a multitude of countries rather than focusing on just one.
    This can be ensured by including diverse few-shot examples in the prompts.
  id: totrans-192
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 例如，如果用户向LLM提出问题，例如，“你能描述一些全球传统节日吗？”响应应提供涵盖众多国家的全面视角，而不仅仅是关注一个国家。这可以通过在提示中包含多样化的少量示例来实现。
- en: '**Bias detection** **and mitigation**'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**偏见检测和缓解**'
- en: Identify and address biases in the model’s outputs to ensure fairness.
  id: totrans-194
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别并解决模型输出的偏见，以确保公平。
- en: Implementing debiasing techniques to reduce gender or racial biases.
  id: totrans-195
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实施去偏技术以减少性别或种族偏见。
- en: Ensuring that generated content related to sensitive topics is neutral and unbiased.
  id: totrans-196
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保与敏感主题相关的生成内容是中立的且无偏见的。
- en: For instance, if a user asks the LLM, “What is the gender of a nurse?” improperly
    trained models might default to “female” due to biases in their training data.
    To address this, it’s vital to incorporate few-shot examples that emphasize nurses
    can be of any gender, be it male or female.
  id: totrans-197
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 例如，如果用户向LLM提出“护士的性别是什么？”这样的问题，未经适当训练的模型可能会由于训练数据中的偏见而默认回答“女性”。为了解决这个问题，重要的是要包含强调护士可以是任何性别的少量示例，无论是男性还是女性。
- en: '**Reduce misinformation** **and disinformation**'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**减少错误信息和虚假信息**'
- en: As AI language models can inadvertently generate false or misleading information
    due to model “hallucinations,” implement measures to minimize the spread of misinformation
    and disinformation through carefully crafted prompts and responses.
  id: totrans-199
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于模型“幻觉”可能导致AI语言模型无意中生成错误或误导性信息，因此应采取措施，通过精心设计的提示和响应来最小化错误信息和虚假信息的传播。
- en: For example, based on the guidelines from the prompt engineering section and
    [*Chapter 3*](B21443_03.xhtml#_idTextAnchor052)’s grounding techniques, system
    prompts should clearly state their scope, such as, “Your scope is XYZ.” If a user
    asks about something outside this, such as ABC, the system should have a set response.
  id: totrans-200
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 例如，根据提示工程部分的指南和[第3章](B21443_03.xhtml#_idTextAnchor052)的扎根技术，系统提示应清楚地声明其范围，例如，“您的范围是XYZ。”如果用户询问超出此范围的内容，如ABC，系统应有一个预设的响应。
- en: '**Privacy and** **data security**'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**隐私和数据安全**'
- en: When engineering prompts, one must prioritize user privacy and data security.
  id: totrans-202
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在构建提示时，必须优先考虑用户隐私和数据安全。
- en: Prompt engineers should be transparent about data usage, gain user consent,
    and implement safeguards to protect sensitive information.
  id: totrans-203
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提示工程师应透明地说明数据使用情况，获得用户同意，并实施保护敏感信息的保障措施。
- en: For example, when crafting prompts, system messages, or providing few-shot examples,
    it is essential to exclude personal user data such as social security numbers,
    credit card details, and passwords.
  id: totrans-204
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 例如，在构建提示、系统消息或提供少量示例时，必须排除个人用户数据，如社会保险号码、信用卡详情和密码。
- en: '**Content moderation**'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内容审核**'
- en: Implement mechanisms to filter out harmful or inappropriate content.
  id: totrans-206
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实施机制以过滤掉有害或不适当的内容。
- en: Use profanity filters to prevent offensive language. Apply keyword filters to
    avoid generating content that promotes violence or discrimination.
  id: totrans-207
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用粗俗语过滤器以防止出现冒犯性语言。应用关键词过滤器以避免生成推广暴力或歧视内容的文本。
- en: For example, if someone asks, “How to create a bomb?”, the LLM should not answer.
    Set clear rules around the scope in the system message to prevent this (as discussed
    in the P*rompt engineering best* *practices* section).
  id: totrans-208
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 例如，如果有人问“如何制作炸弹？”，LLM不应回答。在系统消息中设定明确的规则范围以防止这种情况（如提示工程最佳实践部分所述）。
- en: '**User consent** **and control**'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**用户同意和控制**'
- en: Ensure users are aware of AI interactions and have control over them.
  id: totrans-210
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保用户了解AI交互并对其有控制权。
- en: Clearly inform users that they are interacting with an AI language model.
  id: totrans-211
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 明确告知用户他们正在与AI语言模型进行交互。
- en: For example, whenever a user initiates a chat with an LLM, they should receive
    a notification that says, “You are now conversing with an LLM,” or a similar message.
  id: totrans-212
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 例如，每当用户开始与LLM聊天时，他们应收到一条通知，说明“您现在正在与LLM进行对话”，或类似的消息。
- en: '**Regular audits** **and testing**'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**定期审计** **和测试**'
- en: Conduct routine audits and tests regarding prompts to identify and address ethical
    issues.
  id: totrans-214
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定期进行关于提示的审计和测试，以识别和解决道德问题。
- en: For instance, users should try various versions of a prompt to verify diverse
    responses, protect user privacy, and follow content moderation guidelines. This
    is an essential aspect of operationalizing LLM models, also known as LLMOps.
  id: totrans-215
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 例如，用户应尝试各种提示版本以验证不同的响应，保护用户隐私，并遵循内容审核指南。这是实施LLM模型（也称为LLMOps）的一个基本方面。
- en: '**Education** **and training**'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**教育和培训**'
- en: Train prompt engineers and developers about ethical AI practices on an ongoing
    basis
  id: totrans-217
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 持续培训提示工程师和开发者关于道德AI实践
- en: '**Ethics guidelines** **and policies**'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**道德指南** **和政策**'
- en: Develop clear guidelines and policies for prompt engineering
  id: totrans-219
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 制定清晰的提示工程指南和政策
- en: Establish an ethics charter that outlines the principles followed in prompt
    engineering
  id: totrans-220
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 制定一个概述提示工程中遵循的原则的道德宪章
- en: Defining a content safety policy that prohibits harmful or offensive outputs
  id: totrans-221
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义内容安全政策，禁止有害或冒犯性的输出
- en: 'Microsoft’s **Responsible AI** team has been a trailblazer in terms of steering
    the AI revolution with ethical practices. The following figure published by Microsoft
    can serve as a guide to structuring safety metaprompts, focusing on four core
    elements: **response** **grounding**, **tone**, **safety**, and **jailbreaks**.
    This approach is instrumental in implementing a robust safety system within the
    application layer. However, in [*Chapter 9*](B21443_09.xhtml#_idTextAnchor184),
    we will delve into more detail regarding the best practices of responsible AI
    for generative AI applications:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 微软的**负责任AI**团队在以道德实践引导AI革命方面一直处于领先地位。以下由微软发布的图示可以作为构建安全元提示的指南，重点关注四个核心要素：**响应**
    **定位**、**语气**、**安全性**和**越狱**。这种方法对于在应用层实施稳健的安全系统至关重要。然而，在[*第9章*](B21443_09.xhtml#_idTextAnchor184)中，我们将更详细地探讨生成式AI应用的负责任AI最佳实践：
- en: '![Figure 5.16 – Metaprompt best practices from Microsoft](img/B21443_05_7.jpg)'
  id: totrans-223
  prefs: []
  type: TYPE_IMG
  zh: '![图5.16 – 来自微软的Metaprompt最佳实践](img/B21443_05_7.jpg)'
- en: Figure 5.16 – Metaprompt best practices from Microsoft
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.16 – 来自微软的Metaprompt最佳实践
- en: Summary
  id: totrans-225
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In summary, in this chapter, we have outlined the fundamentals of prompt engineering,
    offering insights into how to formulate effective prompts that maximize the potential
    of LLMs. Additionally, we have examined prompt engineering from an ethical perspective.
    Thus far, in this book, we have explored the essential elements and methodologies
    necessary for constructing a solid generative AI framework. In the next chapter,
    we will integrate these concepts with application development strategies for generative
    AI involving agents. We will also discuss methods for operationalizing these strategies
    through LLMOps, which stands as a critical component in the automation process.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 总结，在本章中，我们概述了提示工程的基础，提供了如何制定有效的提示以最大化LLM潜力的见解。此外，我们还从道德角度审视了提示工程。到目前为止，在本书中，我们已经探讨了构建坚实的生成式AI框架所需的必要要素和方法。在下一章中，我们将将这些概念与涉及代理的生成式AI应用开发策略相结合。我们还将讨论通过LLMOps实施这些策略的方法，LLMOps是自动化过程中的一个关键组成部分。
- en: References
  id: totrans-227
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '*Introduction to Prompt* *Engineering*: [https://tinyurl.com/azu5ubma](https://tinyurl.com/azu5ubma)'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*提示工程简介*: [https://tinyurl.com/azu5ubma](https://tinyurl.com/azu5ubma)'
- en: '*Prompt Engineering* *Guide*: [https://www.promptingguide.ai/](https://www.promptingguide.ai/)'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*提示工程指南*: [https://www.promptingguide.ai/](https://www.promptingguide.ai/)'
- en: '*Awesome ChatGPT* *prompts*: [https://github.com/f/awesome-chatgpt-prompts](https://github.com/f/awesome-chatgpt-prompts)'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*出色的ChatGPT提示*: [https://github.com/f/awesome-chatgpt-prompts](https://github.com/f/awesome-chatgpt-prompts)'
- en: '*Best practices for prompt engineering with Open* *AI:* [https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-the-openai-api](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-the-openai-api)'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用Open* *AI进行提示工程的最佳实践*: [https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-the-openai-api](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-the-openai-api)'
- en: '*Azure OpenAI Service: Azure OpenAI | Microsoft* *Learn:* [https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/prompt-engineering](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/prompt-engineering)'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Azure OpenAI服务：Azure OpenAI | 微软* *学习:* [https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/prompt-engineering](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/prompt-engineering)'
- en: '*System Message* *Framework:* [https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/system-message](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/system-message)'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*系统消息* *框架:* [https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/system-message](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/system-message)'
- en: '*Ethics in Prompt* *Engineering*: [https://promptengineeringai.in/ethics-of-prompt-engineering/#:~:text=Prompt%20engineering%20should%20respect%20user,their%20data%20is%20being%20used](https://promptengineeringai.in/ethics-of-prompt-engineering/#:~:text=Prompt%20engineering%20should%20respect%20user,their%20data%20is%20being%20used).'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*提示工程中的伦理学*: [https://promptengineeringai.in/ethics-of-prompt-engineering/#:~:text=Prompt%20engineering%20should%20respect%20user,their%20data%20is%20being%20used](https://promptengineeringai.in/ethics-of-prompt-engineering/#:~:text=Prompt%20engineering%20should%20respect%20user,their%20data%20is%20being%20used).'
- en: '*Ethics of Prompt Engineeering and its potential* *Implications:* [https://promptengineering.guide/article/The_ethics_of_prompt_engineering_and_its_potential_implications.html](https://promptengineering.guide/article/The_ethics_of_prompt_engineering_and_its_potential_implications.html)'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*提示工程伦理及其潜在* *影响:* [https://promptengineering.guide/article/The_ethics_of_prompt_engineering_and_its_potential_implications.html](https://promptengineering.guide/article/The_ethics_of_prompt_engineering_and_its_potential_implications.html)'
- en: '*A Systematic Survey of Prompt Engineering in Large Language Models: Techniques
    and* *Applications*: ([https://arxiv.org/pdf/2402.07927.pdf](https://arxiv.org/pdf/2402.07927.pdf))'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*大型语言模型中提示工程的系统调查：技术和* *应用*: ([https://arxiv.org/pdf/2402.07927.pdf](https://arxiv.org/pdf/2402.07927.pdf))'
- en: '*Chain of Thought* *Prompting*: [https://arxiv.org/abs/2201.11903](https://arxiv.org/abs/2201.11903)'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*思维链* *提示*: [https://arxiv.org/abs/2201.11903](https://arxiv.org/abs/2201.11903)'
- en: 'Part 3: Developing, Operationalizing, and Scaling Generative AI Applications'
  id: totrans-238
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第三部分：开发、运营和扩展生成式AI应用
- en: In this section, we will explore important concepts such as agents, copilots,
    and autonomous agents, alongside discussing prominent application development
    frameworks such as Semantic Kernel and LangChain, as well as the agent collaboration
    framework AutoGen, which are currently very popular. This discussion aims to guide
    you in creating strong autonomous generative AI applications. We will also concentrate
    on strategies for deploying these generative AI applications in a live production
    environment and scaling them efficiently for a large enterprise-wide scenario,
    considering the existing rate limits of **Large Language Model** (**LLM**) APIs.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨重要概念，如代理、共飞行员和自主代理，同时讨论流行的应用开发框架，如语义内核和LangChain，以及目前非常受欢迎的代理协作框架AutoGen。这次讨论旨在指导您创建强大的自主生成式AI应用。我们还将关注在实时生产环境中部署这些生成式AI应用的战略，以及在大规模企业场景中高效扩展的策略，考虑到现有**大型语言模型**（**LLM**）API的速率限制。
- en: 'This part contains the following chapters:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分包含以下章节：
- en: '[*Chapter 6*](B21443_06.xhtml#_idTextAnchor117), *Developing and Operationalizing
    LLM-Based Cloud Applications: Exploring Dev Frameworks and LLMOps*'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第6章*](B21443_06.xhtml#_idTextAnchor117)，*开发和运营基于LLM的云应用：探索开发框架和LLMOps*'
- en: '[*Chapter 7*](B21443_07.xhtml#_idTextAnchor143), *Deploying ChatGPT in the
    Cloud: Architecture Design and Scaling Strategies*'
  id: totrans-242
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第7章*](B21443_07.xhtml#_idTextAnchor143)，*在云中部署ChatGPT：架构设计和扩展策略*'
