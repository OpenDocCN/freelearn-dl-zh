<html><head></head><body>
  <div><h1 class="chapter-number" id="_idParaDest-59">
    <a id="_idTextAnchor064">
    </a>
    
     3
    
   </h1>
   <h1 id="_idParaDest-60">
    <a id="_idTextAnchor065">
    </a>
    
     Essential Components of Intelligent Agents
    
   </h1>
   <p>
    
     In this chapter, we’ll dive into the essential components that make up the core of intelligent agents.
    
    
     Just as the human body has a skeleton that provides structure and support, intelligent agents have certain fundamental elements that allow them to adapt, act independently, and pursue goals in
    
    
     
      complex environments.
     
    
   </p>
   <p>
    
     We’ll look at the important pieces that bring agents to life – how they represent and store knowledge, the reasoning processes that guide their decision-making, the algorithms that help them learn and grow, and the mechanisms for choosing the right actions to take.
    
    
     You’ll also see how the exciting field of generative AI can supercharge these components, giving agents more powerful abilities to understand their surroundings, learn from experiences, and interact meaningfully with the world
    
    
     
      around them.
     
    
   </p>
   <p>
    
     In this chapter, we’re going to cover the following
    
    
     
      main topics:
     
    
   </p>
   <ul>
    <li>
     
      Knowledge representation in
     
     
      
       intelligent agents
      
     
    </li>
    <li>
     
      Reasoning in
     
     
      
       intelligent agents
      
     
    </li>
    <li>
     
      Learning mechanisms for
     
     
      
       adaptive agents
      
     
    </li>
    <li>
     
      Decision-making and planning in
     
     
      
       agentic systems
      
     
    </li>
    <li>
     
      Enhancing agent capabilities with
     
     
      
       generative AI
      
     
    </li>
   </ul>
   <p>
    
     By the end of this chapter, you’ll understand knowledge representation methods in intelligent agents, reasoning and learning mechanisms, decision-making, and planning techniques, as well as having explored a generative AI-powered enhanced
    
    
     
      agent example.
     
    
   </p>
   <h1 id="_idParaDest-61">
    <a id="_idTextAnchor066">
    </a>
    
     Technical requirements
    
   </h1>
   <p>
    
     You can find the code files for this chapter on GitHub
    
    
     
      at
     
    
    <a href="https://github.com/PacktPublishing/Building-Agentic-AI-Systems">
     
      
       https://github.com/PacktPublishing/Building-Agentic-AI-Systems
      
     
    </a>
    
     
      .
     
    
   </p>
   <h1 id="_idParaDest-62">
    <a id="_idTextAnchor067">
    </a>
    
     Knowledge representation in intelligent agents
    
   </h1>
   <p>
    
     The ability to store and manipulate information is fundamental for any intelligent agent.
    
    
     Knowledge representation provides the mechanisms for encoding an agent’s understanding of its environment into
    
    <a id="_idIndexMarker167">
    </a>
    
     formats amenable to reasoning and decision-making processes.
    
    
     It is the most basic way to enable an intelligent agent to build a model of
    
    
     
      its surroundings.
     
    
   </p>
   <p>
    
     Knowledge representation can be formally defined as the method of structuring and organizing data in such a way that an agent can effectively utilize that information for tasks such as drawing inferences, solving problems, and determining a course of action.
    
    
     There are several well-established approaches to knowledge representation, each with its own strengths and ideal applications, which we will
    
    
     
      discuss next.
     
    
   </p>
   <h2 id="_idParaDest-63">
    <a id="_idTextAnchor068">
    </a>
    
     Semantic networks
    
   </h2>
   <p>
    
     Semantic networks provide one of the
    
    <a id="_idIndexMarker168">
    </a>
    
     most intuitive and flexible approaches for representing knowledge within intelligent agents.
    
    
     At their core, semantic networks are graph-based structures
    
    <a id="_idIndexMarker169">
    </a>
    
     composed of nodes that represent concepts, entities, events, or states in the world.
    
    
     These nodes are connected by labeled edges that explicitly define the semantic relationships between the
    
    
     
      represented concepts.
     
    
   </p>
   <p>
    
     The simplicity yet expressiveness of semantic networks allows them to naturally capture the rich, diverse relationships and interconnections that exist in our complex world.
    
    
     For example, a node representing the concept of “
    
    <em class="italic">
     
      dog
     
    </em>
    
     ” could be connected to the “
    
    <em class="italic">
     
      animal
     
    </em>
    
     ” node via an “
    
    <em class="italic">
     
      is-a
     
    </em>
    
     ” relation edge, indicating that dogs are a type of animal.
    
    
     That same “
    
    <em class="italic">
     
      dog
     
    </em>
    
     ” node may also be connected to nodes for “
    
    <em class="italic">
     
      mammal
     
    </em>
    
     ,” “
    
    <em class="italic">
     
      domesticated
     
    </em>
    
     ,” “
    
    <em class="italic">
     
      canine
     
    </em>
    
     ,” and “
    
    <em class="italic">
     
      pet
     
    </em>
    
     ” via other typed
    
    
     
      relationship links:
     
    
   </p>
   <div><div><img alt="img" role="presentation" src="img/B31483_03_01.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 3.1 – Semantic network representing “Dog” relationships
    
   </p>
   <p>
    
     Unlike strict logic or rigid database schemas, semantic networks provide a flexible knowledge representation where any concept can be associated with any other concept through an appropriate
    
    <a id="_idIndexMarker170">
    </a>
    
     semantic relation.
    
    
     This flexibility enables semantic networks to represent incredibly nuanced domains in an intuitive graphical form.
    
    
     As a real-world example, a medical semantic
    
    <a id="_idIndexMarker171">
    </a>
    
     network could model diseases, symptoms, treatments, and anatomical concepts with relation types such as “
    
    <em class="italic">
     
      causes
     
    </em>
    
     ,” “
    
    <em class="italic">
     
      is-diagnosed-by
     
    </em>
    
     ,” “
    
    <em class="italic">
     
      interacts-with
     
    </em>
    
     ,” and
    
    
     
      so on:
     
    
   </p>
   <div><div><img alt="img" role="presentation" src="img/B31483_03_02.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 3.2 – Semantic network representing “Disease” relationships
    
   </p>
   <p>
    
     Semantic networks gain much of their power from their ability to perform generalization through the inheritance of properties along relationship paths.
    
    
     If the network specifies that dogs are a subclass of animals and that animals breathe air, then an agent can semantically infer that dogs also breathe air through inheritance.
    
    
     Algorithms can traverse the graph, chaining sequences of relations together to derive new facts and conclusions from the represented knowledge.
    
    
     For instance, in a semantic network for family relations, one could infer that a person’s spouse’s parents are also
    
    
     
      their in-laws.
     
    
   </p>
   <p>
    
     Additionally, semantic networks integrate naturally with other symbolic reasoning techniques.
    
    
     Their graph-based
    
    <a id="_idIndexMarker172">
    </a>
    
     structure maps well to deductive methods such as
    
    <strong class="bold">
     
      first-order logic
     
    </strong>
    
     , where nodes become constants or predicates and edges become relations that can
    
    <a id="_idIndexMarker173">
    </a>
    
     participate in logical proofs and inference rules.
    
    
     An intelligent tutoring system could use this combined representational power for logic-based explanations and teach students new concepts
    
    <a id="_idIndexMarker174">
    </a>
    
     based on their semantic
    
    
     
      knowledge graphs.
     
    
   </p>
   <p>
    
     Semantic networks provide a robust yet intuitive mechanism for intelligent agents to build rich, expressive models of their environment.
    
    
     Their inherent support for capturing interconnected concepts and deriving new knowledge through relation composition and inheritance makes them an extremely powerful knowledge representation formalism across many
    
    
     
      real-world domains.
     
    
   </p>
   <h2 id="_idParaDest-64">
    <a id="_idTextAnchor069">
    </a>
    
     Frames
    
   </h2>
   <p>
    
     The frame knowledge representation
    
    <a id="_idIndexMarker175">
    </a>
    
     paradigm provides a structured way for intelligent agents to model concepts and their associated attributes.
    
    
     In this formalism, knowledge about objects, situations, or events is stored in
    
    <a id="_idIndexMarker176">
    </a>
    
     data structures
    
    
     
      called
     
    
    
     <strong class="bold">
      
       frames
      
     </strong>
    
    
     
      .
     
    
   </p>
   <p>
    
     Each frame consists of a collection of attribute-value pairs that describe the properties and characteristics of the concept being represented.
    
    
     For example, a frame for the concept “
    
    <em class="italic">
     
      Car
     
    </em>
    
     ” may contain attributes such as “
    
    <em class="italic">
     
      make
     
    </em>
    
     ,” “
    
    <em class="italic">
     
      model
     
    </em>
    
     ,” “
    
    <em class="italic">
     
      year
     
    </em>
    
     ,” “
    
    <em class="italic">
     
      color
     
    </em>
    
     ,” “
    
    <em class="italic">
     
      fuel type
     
    </em>
    
     ,” and so on with corresponding values providing specifics for a particular
    
    
     
      car instance.
     
    
   </p>
   <p>
    
     Frames are organized hierarchically, allowing for the inheritance of attributes from higher-level, more general frames down to their specialized sub-frames.
    
    
     The “
    
    <em class="italic">
     
      Car
     
    </em>
    
     ” frame could inherit properties from a parent “
    
    <em class="italic">
     
      Vehicle
     
    </em>
    
     ” frame while adding new attributes unique to cars.
    
    
     This hierarchical taxonomy facilitates efficient knowledge storage by avoiding redundant attribute definitions across
    
    
     
      related concepts.
     
    
   </p>
   <p>
    
     A key advantage of frames is their flexibility to represent procedural knowledge alongside factual information.
    
    
     In addition to simple attribute-value slots, frames can contain procedures that supply attribute values dynamically or model operations relevant to the represented concept.
    
    
     For instance, the “
    
    <em class="italic">
     
      Car
     
    </em>
    
     ” frame could have methods for calculating fuel efficiency or querying service records.
    
    
     The following figure illustrates the concept of frames with our
    
    
     
      vehicle example:
     
    
   </p>
   <div><div><img alt="img" role="presentation" src="img/B31483_03_03.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 3.3 – Frames representing “Vehicle” and “Car” relationships
    
   </p>
   <p>
    
     Frames provide an intuitive model for representation that mirrors how humans conceptualize knowledge
    
    <a id="_idIndexMarker177">
    </a>
    
     about the world.
    
    
     Their hierarchical nature aligns with how people form conceptual abstractions and
    
    <a id="_idIndexMarker178">
    </a>
    
     categorize ideas based on shared attributes
    
    
     
      and relations.
     
    
   </p>
   <p>
    
     In real-world applications, frame representations are widely used in areas such as
    
    
     
      the following:
     
    
   </p>
   <ul>
    <li>
     <strong class="bold">
      
       Natural language processing
      
     </strong>
     
      : Linguistic frames model semantic concepts, roles, and relations extracted from
     
     
      
       text data
      
     
    </li>
    <li>
     <strong class="bold">
      
       Expert systems
      
     </strong>
     
      : Frames capture domain expertise and rules for knowledge-based
     
     
      
       reasoning engines
      
     
    </li>
    <li>
     <strong class="bold">
      
       Object-oriented programming
      
     </strong>
     
      : Classes in OOP languages are essentially frame-like structures encapsulating attributes
     
     
      
       and methods
      
     
    </li>
    <li>
     <strong class="bold">
      
       Computer vision
      
     </strong>
     
      : Object detection systems use frame hierarchies to identify and describe visual entities based on attributes such as shape, color, texture, and
     
     
      
       so on
      
     
    </li>
    <li>
     <strong class="bold">
      
       Robotics
      
     </strong>
     
      : Frames enable robots to represent objects/environments along with associated actions, motion models,
     
     
      
       and constraints
      
     
    </li>
   </ul>
   <p>
    
     The frame knowledge representation
    
    <a id="_idIndexMarker179">
    </a>
    
     formalism offers an efficient, structured, and human-compatible way for intelligent agents to capture rich conceptual information suitable for
    
    <a id="_idIndexMarker180">
    </a>
    
     knowledge-based reasoning
    
    
     
      and decision-making.
     
    
   </p>
   <h2 id="_idParaDest-65">
    <a id="_idTextAnchor070">
    </a>
    
     Logic-based representations
    
   </h2>
   <p>
    
     While semantic networks and frames offer visually intuitive ways to represent knowledge, the logic-based approach takes a more formal, mathematical route.
    
    
     Logic-based knowledge representation employs the machinery of symbolic logic to encode facts, rules, and axioms about
    
    
     
      a
     
    
    
     <a id="_idIndexMarker181">
     </a>
    
    
     
      domain.
     
    
   </p>
   <p>
    
     In this paradigm, statements
    
    <a id="_idIndexMarker182">
    </a>
    
     representing knowledge are translated into well-formed formulae in formal logical
    
    <a id="_idIndexMarker183">
    </a>
    
     languages such as
    
    <strong class="bold">
     
      propositional logic
     
    </strong>
    
     ,
    
    <strong class="bold">
     
      first-order logic
     
    </strong>
    
     , or
    
    <strong class="bold">
     
      specialized modal/temporal logics
     
    </strong>
    
     .
    
    
     See this,
    
    
     
      for
     
    
    
     <a id="_idIndexMarker184">
     </a>
    
    
     
      example:
     
    
   </p>
   <ul>
    <li>
     
      “
     
     <em class="italic">
      
       All humans are mortal
      
     </em>
     
      ” can be represented as
     
     <em class="italic">
      
       ∀
      
     </em>
     <em class="italic">
      
       x (Human(x) → Mortal(x))
      
     </em>
     
      in
     
     
      
       first-order logic
      
     
    </li>
    <li>
     
      “
     
     <em class="italic">
      
       It is raining or it is sunny
      
     </em>
     
      ” can be expressed as
     
     <em class="italic">
      
       Rain
      
     </em>
     <em class="italic">
      
       ∨
      
     </em>
     <em class="italic">
      
       Sunny
      
     </em>
     
      in
     
     
      
       propositional logic
      
     
    </li>
    <li>
     
      “
     
     <em class="italic">
      
       Eventually, the system will stabilize
      
     </em>
     
      ” can be modeled as
     
     <em class="italic">
      
       ◇
      
     </em>
     <em class="italic">
      
       Stable
      
     </em>
     
      in
     
     
      
       temporal logic
      
     
    </li>
   </ul>
   <p>
    
     
      Here:
     
    
   </p>
   <ul>
    <li>
     <strong class="bold">
      
       ∀
      
     </strong>
     <strong class="bold">
      
       x
      
     </strong>
     
      : Universal quantifier meaning “
     
     <em class="italic">
      
       for
      
     </em>
     
      <em class="italic">
       
        all x
       
      </em>
     
     
      
       .”
      
     
     <p class="list-inset">
      <strong class="bold">
       
        Example
       
      </strong>
      
       :
      
      <em class="italic">
       
        ∀
       
      </em>
      <em class="italic">
       
        x (Human(x) → Mortal(x))
       
      </em>
      
       .
      
      
       Translation:
      
      <em class="italic">
       
        For all x, if x is a human, then x
       
      </em>
      
       <em class="italic">
        
         is mortal
        
       </em>
      
      
       
        .
       
      
     </p>
    </li>
    <li>
     <strong class="bold">
      
       ∨
      
     </strong>
     
      : Logical disjunction
     
     
      
       meaning “
      
     
     
      <em class="italic">
       
        or
       
      </em>
     
     
      
       .”
      
     
     <p class="list-inset">
      <strong class="bold">
       
        Example
       
      </strong>
      
       :
      
      <em class="italic">
       
        Rain
       
      </em>
      <em class="italic">
       
        ∨
       
      </em>
      <em class="italic">
       
        Sunny
       
      </em>
      
       .
      
      
       Translation:
      
      <em class="italic">
       
        It is either raining
       
      </em>
      
       <em class="italic">
        
         or sunny
        
       </em>
      
      
       
        .
       
      
     </p>
    </li>
    <li>
     <strong class="bold">
      
       ◇
      
     </strong>
     
      : Diamond operator in temporal logic
     
     
      
       meaning “
      
     
     
      <em class="italic">
       
        eventually
       
      </em>
     
     
      
       .”
      
     
     <p class="list-inset">
      <strong class="bold">
       
        Example
       
      </strong>
      
       :
      
      <em class="italic">
       
        ◇
       
      </em>
      <em class="italic">
       
        Stable
       
      </em>
      
       .
      
      
       Translation:
      
      <em class="italic">
       
        Eventually, the system
       
      </em>
      
       <em class="italic">
        
         will stabilize
        
       </em>
      
      
       
        .
       
      
     </p>
    </li>
   </ul>
   <p>
    
     These logical formulae act as the building blocks for constructing a comprehensive knowledge base using strict logical deductive systems with clearly defined axioms, inference rules, and formal
    
    <a id="_idIndexMarker185">
    </a>
    
     semantics.
    
    
     An inference engine can then derive new facts and conclusions from the existing knowledge by applying the rules of
    
    
     
      logical reasoning.
     
    
   </p>
   <p>
    
     A key advantage of logic-based representations is their formal rigor and associated strong theoretical properties.
    
    
     Systems built on logical foundations can provide guarantees around soundness (only deriving logically valid conclusions) and completeness (deriving all possible valid conclusions).
    
    
     This mathematical grounding makes logic attractive for knowledge representation in safety-critical domains.
    
    
     Logic-based representations find widespread use in many real-world applications, such
    
    
     
      as these:
     
    
   </p>
   <ul>
    <li>
     <strong class="bold">
      
       Expert systems
      
     </strong>
     
      : Rule-based expert system engines are essentially theorem provers operating over a logical knowledge
     
     <a id="_idIndexMarker186">
     </a>
     
      base encoding
     
     
      
       domain expertise
      
     
    </li>
    <li>
     <strong class="bold">
      
       Database systems
      
     </strong>
     
      : Relational databases use relational algebra/calculus – subsets of first-order logic – as the
     
     
      
       mathematical foundations
      
     
    </li>
    <li>
     <strong class="bold">
      
       Automated reasoning
      
     </strong>
     
      : From software verification to robot planning, logic provides the representational underpinnings for automated
     
     
      
       reasoning systems
      
     
    </li>
    <li>
     <strong class="bold">
      
       Legal/regulatory domains
      
     </strong>
     
      : Laws, policies, and regulations can be precisely represented as logical rules amenable to
     
     
      
       formal analysis
      
     
    </li>
    <li>
     <strong class="bold">
      
       Semantic web
      
     </strong>
     
      : Description logics such as OWL (Web Ontology Language) form the knowledge representation backbone of ontologies and the
     
     
      
       Semantic Web
      
     
    </li>
   </ul>
   <p>
    
     While logic-based representations aren’t as intuitive as semantic networks or frames, their mathematical rigor and ability to support sound, automated reasoning make them invaluable in applications where formal verification, consistency, and completeness guarantees
    
    
     
      are essential.
     
    
   </p>
   <p>
    
     Having explored the foundational structures of knowledge representation, which form the basis of an agent’s
    
    <a id="_idIndexMarker187">
    </a>
    
     knowledge base, we now turn to examine how intelligent agents harness these representations to perform reasoning tasks, draw inferences, and solve
    
    
     
      complex problems.
     
    
   </p>
   <h1 id="_idParaDest-66">
    <a id="_idTextAnchor071">
    </a>
    
     Reasoning in intelligent agents
    
   </h1>
   <p>
    
     By employing the language of logic, intelligent agents can build robust knowledge bases, enabling sophisticated querying, deductive inference, and reasoning that are not possible with less expressive
    
    <a id="_idIndexMarker188">
    </a>
    
     representational formalisms.
    
    
     Once an intelligent agent has a robust way to represent its knowledge, reasoning mechanisms allow it to intelligently manipulate and make use of that information.
    
    
     Reasoning capabilities
    
    <a id="_idIndexMarker189">
    </a>
    
     enable agents to derive new insights, draw logical conclusions, explain observations, and ultimately make informed decisions to achieve
    
    
     
      their goals.
     
    
   </p>
   <p>
    
     Reasoning in intelligent agents is rarely a singular, monolithic process.
    
    
     Sophisticated agent architectures tend to employ a multi-faceted reasoning approach that combines different reasoning styles and data-driven, analytical, and learned components.
    
    
     For instance, a question-answering system could use semantic parsing to map questions to logical forms, apply deductive reasoning over a logical knowledge base, and then invoke a neural sequence-to-sequence model to render the final answer fluently.
    
    
     There are several fundamental reasoning paradigms, namely, deductive, inductive, and
    
    
     
      abductive reasoning.
     
    
   </p>
   <h2 id="_idParaDest-67">
    <a id="_idTextAnchor072">
    </a>
    
     Deductive reasoning
    
   </h2>
   <p>
    <strong class="bold">
     
      Deductive reasoning
     
    </strong>
    
     is a fundamental form
    
    <a id="_idIndexMarker190">
    </a>
    
     of logical reasoning that follows a top-down approach.
    
    
     In deductive reasoning, an
    
    <a id="_idIndexMarker191">
    </a>
    
     intelligent agent starts with general premises or rules about a domain and applies them to derive specific, logically inescapable conclusions.
    
    
     The classic example illustrating deductive reasoning is the following
    
    
     
      popular syllogism:
     
    
   </p>
   <p>
    <em class="italic">
     
      “All men
     
    </em>
    
     <em class="italic">
      
       are mortal.
      
     </em>
    
   </p>
   <p>
    <em class="italic">
     
      Socrates is
     
    </em>
    
     <em class="italic">
      
       a man.
      
     </em>
    
   </p>
   <p>
    <em class="italic">
     
      Therefore, Socrates
     
    </em>
    
     <em class="italic">
      
       is mortal.”
      
     </em>
    
   </p>
   <p>
    
     If the initial premises (“
    
    <em class="italic">
     
      All men are mortal
     
    </em>
    
     ” and “
    
    <em class="italic">
     
      Socrates is a man
     
    </em>
    
     ”) are true, then the conclusion “
    
    <em class="italic">
     
      Socrates is mortal
     
    </em>
    
     ” follows inescapably from applying the rules of deductive logic.
    
    
     Deduction
    
    <a id="_idIndexMarker192">
    </a>
    
     provides a way to reach irrefutable conclusions as long as the original premises and
    
    <a id="_idIndexMarker193">
    </a>
    
     rules are correct and factual.
    
    
     The following figure illustrates deductive reasoning with
    
    
     
      the example:
     
    
   </p>
   <div><div><img alt="img" role="presentation" src="img/B31483_03_04.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 3.4 – Deductive reasoning – from general premises to specific conclusions
    
   </p>
   <p>
    
     Deductive reasoning finds application across many
    
    <a id="_idIndexMarker194">
    </a>
    
     domains, such
    
    
     
      as these:
     
    
   </p>
   <ul>
    <li>
     <strong class="bold">
      
       Mathematics/geometry
      
     </strong>
     
      : Formal mathematical proofs are quintessential examples of deductive reasoning, deriving specific theorems from general axioms and previously
     
     
      
       proven statements
      
     
    </li>
    <li>
     <strong class="bold">
      
       Law
      
     </strong>
     
      : Legal reasoning applies codified laws and precedents to derive judgments about particular cases
     
     
      
       through deduction
      
     
    </li>
    <li>
     <strong class="bold">
      
       Software verification
      
     </strong>
     
      : Formal verification techniques use deductive reasoning over logical specifications to prove correctness properties of
     
     
      
       hardware/software systems
      
     
    </li>
    <li>
     <strong class="bold">
      
       Network routing
      
     </strong>
     
      : Routing protocols determine optimal paths by deductively applying rules/constraints
     
     <a id="_idIndexMarker195">
     </a>
     
      about network topology, bandwidth, and
     
     
      
       so on
      
     
    </li>
   </ul>
   <p>
    
     Deductive reasoning is particularly powerful when combined with other forms of reasoning such as abduction or induction.
    
    
     For example, a medical diagnosis system could do
    
    
     
      the following:
     
    
   </p>
   <ul>
    <li>
     <strong class="bold">
      
       Abduce
      
     </strong>
     
      possible disease hypotheses from symptoms (inference to the
     
     
      
       best explanation)
      
     
    </li>
    <li>
     <strong class="bold">
      
       Deduce
      
     </strong>
     
      expected findings for each hypothesis using rules about
     
     
      
       disease models
      
     
    </li>
    <li>
     <strong class="bold">
      
       Compare
      
     </strong>
     
      deduced findings to actual patient data to
     
     
      
       confirm/reject hypotheses
      
     
    </li>
   </ul>
   <p>
    
     While deduction alone cannot
    
    <a id="_idIndexMarker196">
    </a>
    
     acquire entirely new knowledge, it is indispensable for intelligent agents to logically expand their knowledge, enforcing consistency and enabling rational decision-making.
    
    
     Deductive reasoning provides the rigor to ensure the trustworthiness of an
    
    
     
      agent’s conclusions.
     
    
   </p>
   <h2 id="_idParaDest-68">
    <a id="_idTextAnchor073">
    </a>
    
     Inductive reasoning
    
   </h2>
   <p>
    
     In contrast to the top-down
    
    <a id="_idIndexMarker197">
    </a>
    
     approach of deductive reasoning, inductive reasoning follows a bottom-up methodology.
    
    
     Inductive reasoning involves
    
    <a id="_idIndexMarker198">
    </a>
    
     making generalizations or deriving probable conclusions from a set of specific observations or data points.
    
    
     The following is
    
    
     
      an example:
     
    
   </p>
   <p>
    <em class="italic">
     
      “The Sun has risen every day for the past
     
    </em>
    
     <em class="italic">
      
       million days.
      
     </em>
    
   </p>
   <p>
    <em class="italic">
     
      Therefore, the sun will likely rise
     
    </em>
    
     <em class="italic">
      
       again tomorrow.”
      
     </em>
    
   </p>
   <p>
    
     Based on the repeated instances of the sun rising, an inductive reasoning process allows an intelligent agent to hypothesize or induce that the sun will continue rising in the future.
    
    
     However, unlike deduction,
    
    <strong class="bold">
     
      inductive conclusions
     
    </strong>
    
     are not logically guaranteed to be true – they merely suggest a likely
    
    <em class="italic">
     
      possibility
     
    </em>
    
     based on the observed evidence.
    
    
     The following figure illustrates the concept with
    
    
     
      the example:
     
    
   </p>
   <div><div><img alt="img" role="presentation" src="img/B31483_03_05.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 3.5 – Inductive reasoning – from specific observations to general conclusions
    
   </p>
   <p>
    
     Inductive reasoning has
    
    <a id="_idIndexMarker199">
    </a>
    
     immense applicability in the following real-world domains where data-driven learning and theory formation
    
    
     
      are crucial:
     
    
   </p>
   <ul>
    <li>
     <strong class="bold">
      
       Scientific method
      
     </strong>
     
      : The process of formulating scientific laws/theories relies heavily on inductively generalizing from experimental observations
     
     
      
       and data
      
     
    </li>
    <li>
     <strong class="bold">
      
       Machine learning
      
     </strong>
     
      : ML algorithms
     
     <a id="_idIndexMarker200">
     </a>
     
      essentially perform inductive reasoning, inferring general models from training data that can make predictions on
     
     
      
       new instances
      
     
    </li>
    <li>
     <strong class="bold">
      
       Pattern recognition
      
     </strong>
     
      : Computer vision, signal
     
     <a id="_idIndexMarker201">
     </a>
     
      processing, and other pattern recognition tasks use inductive techniques to classify inputs based on detected
     
     
      
       statistical regularities
      
     
    </li>
    <li>
     <strong class="bold">
      
       Data mining
      
     </strong>
     
      : Approaches such as association rule mining inductively identify frequently occurring patterns, correlations, or relationships in
     
     
      
       large datasets
      
     
    </li>
    <li>
     <strong class="bold">
      
       Natural language acquisition
      
     </strong>
     
      : Children learn grammar rules and language models through inductive generalization from the linguistic inputs
     
     
      
       they receive
      
     
    </li>
   </ul>
   <p>
    
     While powerful, purely inductive reasoning has limitations since conclusions can be incorrect if the observed instances are an imperfect sample not representative of the entire space.
    
    
     As such, it is often combined with other reasoning approaches such as abduction (inference to the best explanation) and deduction (validating hypotheses) in intelligent agent architectures.
    
    
     Despite not guaranteeing truth, inductive reasoning’s ability to extract knowledge, recognize patterns, and formulate theories from specific data makes it indispensable for intelligent agents operating in noisy, uncertain environments where knowledge is
    
    <a id="_idIndexMarker202">
    </a>
    
     not fully
    
    
     
      available upfront.
     
    
   </p>
   <h2 id="_idParaDest-69">
    <a id="_idTextAnchor074">
    </a>
    
     Abductive reasoning
    
   </h2>
   <p>
    
     Abductive reasoning is a form of
    
    <a id="_idIndexMarker203">
    </a>
    
     reasoning that works backward – attempting to find the most plausible explanations or premises that could account for a given set of observations or data.
    
    
     It is often described as
    
    <em class="italic">
     
      inference to the best explanation
     
    </em>
    
     .
    
    
     Unlike deductive reasoning, which starts with general rules and arrives at guaranteed specific conclusions, abduction begins with observed effects or phenomena and hypothesizes
    
    <a id="_idIndexMarker204">
    </a>
    
     the most likely underlying causes based on current knowledge.
    
    
     An example of abductive
    
    
     
      reasoning is:
     
    
   </p>
   <p>
    <em class="italic">
     
      “The lawn
     
    </em>
    
     <em class="italic">
      
       is wet.
      
     </em>
    
   </p>
   <p>
    <em class="italic">
     
      A plausible explanation: It rained
     
    </em>
    
     <em class="italic">
      
       last night.”
      
     </em>
    
   </p>
   <p>
    
     Here, the observed effect is a wet lawn.
    
    
     Abductive reasoning allows an intelligent agent to rationally deduce or infer that the most likely explanation, based on past experience, is that it rained the previous night, even though that was not directly observed.
    
    
     The following figure illustrates this concept of
    
    
     
      backward reasoning:
     
    
   </p>
   <div><div><img alt="img" role="presentation" src="img/B31483_03_06.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 3.6 – Abductive reasoning – inference to the best explanation
    
   </p>
   <p>
    
     Abductive reasoning is extremely useful in diagnostic domains and applications where root cause analysis is critical, such
    
    
     
      as these:
     
    
   </p>
   <ul>
    <li>
     <strong class="bold">
      
       Medical diagnosis
      
     </strong>
     
      : Given a set of symptoms, physicians abduce and investigate the most probable
     
     <a id="_idIndexMarker205">
     </a>
     
      diseases or conditions that could explain
     
     
      
       those symptoms
      
     
    </li>
    <li>
     <strong class="bold">
      
       Fault detection
      
     </strong>
     
      : Monitoring systems in
     
     <a id="_idIndexMarker206">
     </a>
     
      manufacturing use abduction to isolate the most likely faults or failures that led to
     
     
      
       observed anomalies
      
     
    </li>
    <li>
     <strong class="bold">
      
       Forensics/criminal investigation
      
     </strong>
     
      : From crime scene evidence, detectives abduce possible scenarios and suspect profiles to determine
     
     
      
       what transpired
      
     
    </li>
    <li>
     <strong class="bold">
      
       AI planning
      
     </strong>
     
      : For agents to achieve desired goals, they must abduce sequences of viable actions by reasoning backward from
     
     
      
       those goals
      
     
    </li>
    <li>
     <strong class="bold">
      
       Scientific discovery
      
     </strong>
     
      : New
     
     <a id="_idIndexMarker207">
     </a>
     
      scientific theories are often initially inferred by finding explanatory hypotheses for currently unexplained observations
     
     
      
       or phenomena
      
     
    </li>
   </ul>
   <p>
    
     A key advantage of abductive reasoning is its ability to generate new plausible premises that deductive or inductive methods cannot produce solely from existing knowledge and data.
    
    
     It facilitates thinking outside the box and exploring novel possible explanations.
    
    
     However, abduction does not guarantee correct explanations – there may be multiple possible hypotheses consistent with the observations.
    
    
     This is why abductive reasoning is commonly used in tandem with deductive reasoning to validate the consistency and plausibility of the explanatory
    
    
     
      hypotheses formed.
     
    
   </p>
   <p>
    
     Points to remember here are that implementing abductive reasoning in agentic systems is challenging due to its computational complexity, as generating and evaluating multiple hypotheses can be resource-intensive.
    
    
     It also deals with uncertainty and incomplete data, making it difficult to determine the most plausible explanations.
    
    
     Proper knowledge representation is crucial but difficult to maintain, and evaluating hypotheses often requires subjective criteria.
    
    
     Integrating abductive reasoning with other reasoning modes can lead
    
    <a id="_idIndexMarker208">
    </a>
    
     to conflicts, and scalability becomes an issue as the domain grows.
    
    
     Additionally, handling dynamic environments and ensuring explainability for users may add further complexity to the process.
    
    
     However, by applying abductive reasoning, intelligent agents can exhibit deeper understanding, creativity in postulating tentative explanations, and an increased ability to operate effectively in uncertain environments with partial observability and information.
    
    
     Through robust knowledge representation formalisms and multi-faceted reasoning capabilities, intelligent agents gain the power to build rich models of their environment, draw insights, explain observations, and ultimately make well-informed decisions about how to interact with the world.
    
    
     These capabilities
    
    <a id="_idIndexMarker209">
    </a>
    
     form the bedrock for more advanced
    
    
     
      agent functionality.
     
    
   </p>
   <h1 id="_idParaDest-70">
    <a id="_idTextAnchor075">
    </a>
    
     Learning mechanisms for adaptive agents
    
   </h1>
   <p>
    
     Learning mechanisms are key to enabling intelligent agents to adapt to changes in their environment or to improve over time.
    
    
     The ability to learn allows agents to continuously refine their knowledge and behavior
    
    <a id="_idIndexMarker210">
    </a>
    
     based on new experiences and data.
    
    
     There are numerous approaches to learning, each with its own strengths
    
    
     
      and applications:
     
    
   </p>
   <ul>
    <li>
     <strong class="bold">
      
       Supervised learning
      
     </strong>
     
      : This learning paradigm involves training an agent on a dataset where the inputs are paired with corresponding labeled outputs or target values.
     
     
      The aim is for
     
     <a id="_idIndexMarker211">
     </a>
     
      the agent to learn a mapping function that accurately predicts outputs for new
     
     <a id="_idIndexMarker212">
     </a>
     
      unseen inputs.
     
     
      Supervised learning is widely used for classification and regression tasks across domains such
     
     
      
       as these:
      
     
     <ul>
      <li>
       
        Image classification (for example, identifying objects and digits
       
       
        
         in images)
        
       
      </li>
      <li>
       
        Spam detection (classifying emails as spam or
       
       
        
         not spam)
        
       
      </li>
      <li>
       
        Machine translation (learning to map text in one language
       
       
        
         to another)
        
       
      </li>
      <li>
       
        Medical diagnosis (mapping patient symptoms/tests to
       
       
        
         disease labels
        
       
      </li>
     </ul>
    </li>
    <li>
     <strong class="bold">
      
       Unsupervised learning
      
     </strong>
     
      : Here, the agent is
     
     <a id="_idIndexMarker213">
     </a>
     
      trained on unlabeled data without any associated target
     
     <a id="_idIndexMarker214">
     </a>
     
      outputs.
     
     
      The goal is to discover inherent patterns, correlations, or groupings within the data itself in an unsupervised manner.
     
     
      Key applications include
     
     
      
       the following:
      
     
     <ul>
      <li>
       
        Customer segmentation (grouping customers based on
       
       
        
         purchasing behavior)
        
       
      </li>
      <li>
       
        Anomaly detection (identifying
       
       <a id="_idIndexMarker215">
       </a>
       
        unusual data points that differ from
       
       
        
         the norm)
        
       
      </li>
      <li>
       
        Topic modeling (extracting topics/themes from collections
       
       
        
         of documents)
        
       
      </li>
      <li>
       
        Dimensionality
       
       <a id="_idIndexMarker216">
       </a>
       
        reduction (finding lower-dimensional representations of
       
       
        
         high-dimensional data)
        
       
      </li>
     </ul>
    </li>
    <li>
     <strong class="bold">
      
       Reinforcement learning
      
     </strong>
     
      : This learning approach is inspired by how humans and animals learn – through
     
     <a id="_idIndexMarker217">
     </a>
     
      trial and error using feedback from the environment in the form of rewards or punishments.
     
     
      An RL agent learns optimal behaviors/policies by trying
     
     <a id="_idIndexMarker218">
     </a>
     
      out different actions and updating its strategy based on the observed rewards.
     
     
      RL has seen great success in
     
     <a id="_idIndexMarker219">
     </a>
     
      domains such as
     
     
      
       the following:
      
     
     <ul>
      <li>
       
        Game playing (learning to master games such as chess, Go, and
       
       
        
         video games)
        
       
      </li>
      <li>
       
        Robotics (learning control policies for robot navigation
       
       
        
         and manipulation)
        
       
      </li>
      <li>
       
        Supply chain optimization (finding policies to
       
       
        
         maximize efficiency)
        
       
      </li>
      <li>
       
        Traffic signal control (learning timing policies to improve
       
       
        
         traffic flow)
        
       
      </li>
     </ul>
    </li>
    <li>
     <strong class="bold">
      
       Transfer learning
      
     </strong>
     
      : This technique focuses on transferring knowledge learned in one setting to facilitate learning
     
     <a id="_idIndexMarker220">
     </a>
     
      in a different but related setting.
     
     
      By leveraging previously learned patterns
     
     <a id="_idIndexMarker221">
     </a>
     
      and representations, transfer learning can significantly accelerate training speed and sample efficiency for new tasks.
     
     
      Applications span areas such as
     
     
      
       the following:
      
     
     <ul>
      <li>
       
        Natural language processing (transferring language models
       
       
        
         across domains)
        
       
      </li>
      <li>
       
        Computer vision (using pre-trained models as initialization for new
       
       
        
         vision tasks)
        
       
      </li>
      <li>
       
        Recommendation systems (transferring user/product embeddings
       
       
        
         across platforms)
        
       
      </li>
     </ul>
    </li>
   </ul>
   <p>
    
     These learning mechanisms, often
    
    <a id="_idIndexMarker222">
    </a>
    
     used in hybrid combinations, equip intelligent agents with the ability to continuously expand their knowledge, refine their behaviors, and grow their problem-solving
    
    <a id="_idIndexMarker223">
    </a>
    
     capabilities – the key hallmarks of intelligence.
    
    
     As learning algorithms advance, agents will only become more adaptable and robust when facing
    
    
     
      new challenges.
     
    
   </p>
   <p>
    
     Having explored the learning mechanisms that enable adaptive agents to acquire knowledge and skills, we
    
    <a id="_idIndexMarker224">
    </a>
    
     now turn our attention to how these agents leverage this learning to make decisions and plan their actions in
    
    
     
      complex environments.
     
    
   </p>
   <h1 id="_idParaDest-71">
    <a id="_idTextAnchor076">
    </a>
    
     Decision-making and planning in agentic systems
    
   </h1>
   <p>
    
     Decision-making and planning are critical capabilities for intelligent agents to achieve their goals effectively in complex environments.
    
    
     Agents need to analyze various possible scenarios, evaluate outcomes, and select the action(s) that will lead to the most desirable outcome based on their
    
    <a id="_idIndexMarker225">
    </a>
    
     preferences and constraints.
    
    
     Although utility
    
    <a id="_idIndexMarker226">
    </a>
    
     functions (tools) and planning will be discussed in detail in later chapters, we will discuss these key components involved in agent decision-making at a high level in the
    
    
     
      following sections.
     
    
   </p>
   <h2 id="_idParaDest-72">
    <a id="_idTextAnchor077">
    </a>
    
     Utility function
    
   </h2>
   <p>
    
     A utility function quantifies an agent’s
    
    <a id="_idIndexMarker227">
    </a>
    
     preferences by mapping outcomes to utility values, enabling the agent to compare and choose actions that maximize expected utility.
    
    
     Utility functions play a central role in decision-making for intelligent agents by providing a quantitative way to represent and reason about preferences over different outcomes or states of
    
    
     
      the world.
     
    
   </p>
   <p>
    
     A utility function  maps any given state or outcome  to a real-numbered utility value , reflecting the desirability or preference for that state according to the agent’s goals, rewards, and penalties.
    
    
     Formally, this is mathematically
    
    
     
      expressed as:
     
    
   </p>
   <p>
    
     This expression may look a
    
    <a id="_idIndexMarker228">
    </a>
    
     little intimidating at first, but the concept is really straightforward.
    
    
     Let us use some example Python code to explain
    
    
     
      this further:
     
    
   </p>
   <pre class="source-code">
1 def travel_utility_function(travel_option):
2    price_utility = (1000 - travel_option['price']) * 0.05
3    comfort_utility = travel_option['comfort_rating'] * 10
4    conv_utility = travel_option['convenience_score'] * 15
5
6    total_utility = price_utility + \
7                    comfort_utility + \
8                    convenience_utility
9
10    return total_utility</pre>
   <p>
    
     To explain this utility function, let us go back to our travel booking example.
    
    
     The given Python utility function evaluates travel options based on price, convenience, and comfort.
    
    
     Lines 2,3, and 4 of the function assign a real numbered utility for price, comfort, and convenience respectively.
    
    
     The numbers 0.05, 10, and 15 are completely arbitrary but are in the order of magnitude of importance of each of the three factors in a person’s travel decision-making.
    
    
     For example, in line 2, we assign the price utility to a number; note that we subtract the price from an arbitrary value of
    
    <strong class="source-inline">
     
      1000
     
    </strong>
    
     , since the lower the price the better, which means a lower price contributes to more utility.
    
    
     Thus, the price utility number would be higher if the price is lower, that is, an inverse relationship.
    
    
     Similarly, the comfort and convenience utilities are assigned respective utility scores.
    
    
     The comfort and convenience scores are often user provided.
    
    
     For example, travel review websites such as Tripadvisor allow users to post detailed reviews about their travel experience via
    
    
     
      star ratings.
     
    
   </p>
   <p>
    
     Applying our utility function
    
    <a id="_idIndexMarker229">
    </a>
    
     to a few travel options will give us a clear picture of how this function works.
    
    
     Let us apply the utility function to two travel options a
    
    <em class="italic">
     
      Budget Airline
     
    </em>
    
     vs
    
    
     <em class="italic">
      
       Road Trip
      
     </em>
    
    
     
      .
     
    
   </p>
   <p>
    
     A sample input to the utility function is
    
    
     
      as follows:
     
    
   </p>
   <pre class="source-code">
1 [{
2     'name': 'Budget Airline',
3     'price': 300,
4     'comfort_rating': 3,
5     'convenience_score': 2
6 },
7 {
8     'name': 'Road Trip',
9     'price': 150,
10    'comfort_rating': 4,
11    'convenience_score': 3
12 }]</pre>
   <p>
    
     Here’s the output of the
    
    
     
      utility function:
     
    
   </p>
   <pre class="console">
1 Budget Airline – Utility: 95.00
2 Road Trip – Utility: 127.50</pre>
   <p>
    
     The output clearly shows that the road trip option scores a higher utility score due to higher convenience, comfort, and lower price compared to the budget airline.
    
    
     The full code is available in the
    
    <strong class="source-inline">
     
      Chapter_03.ipynb
     
    </strong>
    
     Python notebook in our
    
    
     
      GitHub repository.
     
    
   </p>
   <p>
    
     Utility functions encode an agent’s preferences by mapping states or outcomes to utility values, allowing any two states to be ranked or compared based on their assigned utilities.
    
    
     Higher utility values correspond to more preferred states or outcomes.
    
    
     This enables rational agents to select actions that maximize their expected utility, which is calculated as the probability-weighted sum of utilities over all possible outcome states resulting from those actions.
    
    
     By quantifying preferences in this way, utility functions provide a systematic mechanism for agents to make rational decisions in pursuit of the most desirable outcomes
    
    <a id="_idIndexMarker230">
    </a>
    
     according to the specified utility measure.
    
    
     Utility functions can take many mathematical forms depending on the domain, such as
    
    
     
      the following:
     
    
   </p>
   <ul>
    <li>
     
      Simple scoring functions that apply weights to quantify preferences
     
     
      
       between attributes
      
     
    </li>
    <li>
     
      Constraint satisfaction functions that are maximized when all hard constraints
     
     
      
       are met
      
     
    </li>
    <li>
     
      Economic utility functions modeling pricing, profits, costs, and
     
     
      
       so on
      
     
    </li>
    <li>
     
      Multiplicative functions modeling preferences between outcomes with independent
     
     
      
       utility impacts
      
     
    </li>
   </ul>
   <p>
    
     More sophisticated utility functions can model uncertainty, risk preferences, multi-attribute tradeoffs, changing preferences over time, and dependencies between attributes.
    
    
     In the case of
    
    <strong class="bold">
     
      multi-attribute tradeoffs
     
    </strong>
    
     , an agent must weigh different attributes (for example, cost, quality, time, or
    
    <a id="_idIndexMarker231">
    </a>
    
     safety) when making decisions.
    
    
     These attributes often conflict, and an agent must find a balance between them, such as choosing between a faster but more expensive option versus a slower, cheaper one.
    
    
     The challenge here lies in quantifying how much an agent values each attribute relative to others, and how changes in one attribute influence the
    
    
     
      overall utility.
     
    
   </p>
   <p>
    
     Defining an accurate quantitative utility function that captures all of an agent’s preferences is often a major challenge because preferences are often complex and context-dependent.
    
    
     Agents may have different attitudes toward risk (for example, risk-averse or risk-seeking), and preferences may change based on the situation or over time.
    
    
     Additionally, dependencies between attributes – such as how the increase in one attribute (e.g., speed) may negatively affect another (for example, cost) – can complicate the modeling process.
    
    
     Moreover, the uncertainty in predicting outcomes or preferences under changing conditions further complicates the task of creating a utility function that fully reflects the agent’s decision-making process.
    
    
     Techniques such as preference elicitation, inverse reinforcement learning, and learning from human feedback are used in
    
    
     
      such cases.
     
    
   </p>
   <h2 id="_idParaDest-73">
    <a id="_idTextAnchor078">
    </a>
    
     Planning algorithms
    
   </h2>
   <p>
    
     Planning algorithms are algorithms that derive sequences of actions for an agent to take in order to achieve its goals from a given initial state.
    
    
     Some of the most common planning approaches include
    
    <strong class="bold">
     
      graph-based planning
     
    </strong>
    
     ,
    
    <strong class="bold">
     
      heuristic search
     
    </strong>
    
     ,
    
    <strong class="bold">
     
      Monte Carlo tree search
     
    </strong>
    
     (
    
    <strong class="bold">
     
      MCTS
     
    </strong>
    
     ),
    
    <strong class="bold">
     
      hierarchical planning
     
    </strong>
    
     , and
    
    <strong class="bold">
     
      constraint satisfaction
     
    </strong>
    
     .
    
    
     Let’s discuss each of these
    
    <a id="_idIndexMarker232">
    </a>
    
     planning algorithms in the
    
    
     
      following sections.
     
    
   </p>
   <h3>
    
     Graph-based planning
    
   </h3>
   <p>
    
     Graph-based planning represents a
    
    <a id="_idIndexMarker233">
    </a>
    
     planning problem as a graph, where the nodes correspond to possible states or configurations, and the edges represent actions or transitions that can be taken to move between states.
    
    
     A fundamental concept within graph-based planning algorithms is the
    
    <strong class="bold">
     
      state-space graph
     
    </strong>
    
     , which is a
    
    <a id="_idIndexMarker234">
    </a>
    
     graph representation where nodes represent all possible states in the problem domain.
    
    
     In such a representation, the edges represent the actions or transitions between
    
    <a id="_idIndexMarker235">
    </a>
    
     the states.
    
    
     This graph representation effectively maps out the entire “space” of possible situations and how they connect with each other
    
    
     
      via edges.
     
    
   </p>
   <p>
    
     An
    
    <strong class="bold">
     
      edge cost
     
    </strong>
    
     is a property of
    
    <a id="_idIndexMarker236">
    </a>
    
     an edge in a weighted graph.
    
    
     Each edge can have an associated cost (or weight) that represents some measure of the “expense” of taking that action or making that transition.
    
    
     Costs could represent factors such as distance, time, energy consumption, financial cost, or any other relevant metric appropriate for the
    
    
     
      use case.
     
    
   </p>
   <p>
    
     Using state-space graphs, edges, and edge costs, there are two broad categories of graph-based
    
    
     
      planning algorithms:
     
    
   </p>
   <ul>
    <li>
     <strong class="bold">
      
       Graph search
      
     </strong>
     
      : In graph search, the planning process involves searching this graph data structure to find a path from the initial state to one of the goal states.
     
     
      The path defines the
     
     <a id="_idIndexMarker237">
     </a>
     
      sequence of actions for the agent to execute to transition between states and reach the goal.
     
     
      Some of the most common algorithms under this category are
     
     <strong class="bold">
      
       depth-first search
      
     </strong>
     
      (
     
     <strong class="bold">
      
       DFS
      
     </strong>
     
      ),
     
     <strong class="bold">
      
       breadth-first search
      
     </strong>
     
      (
     
     <strong class="bold">
      
       BFS
      
     </strong>
     
      ), and
     
     
      
       Dijkstra’s algorithm.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Optimal path finding
      
     </strong>
     
      : This is a specific type of graph search that aims to find not just any path, but the best path
     
     <a id="_idIndexMarker238">
     </a>
     
      according to some criteria (usually minimizing total edge cost).
     
     
      Two of the algorithms in this category are the Bellman-Ford algorithm and the
     
     
      
       A* search.
      
     
    </li>
   </ul>
   <p>
    
     The downsides of using graph-based planning algorithms include fixing the state representation (state space) upfront, and the potential for exponential growth in the number of states to
    
    <a id="_idIndexMarker239">
    </a>
    
     represent and store as problems get
    
    
     
      more complex.
     
    
   </p>
   <p>
    
     Graph-based planning techniques find numerous real-world applications across domains, where finding optimal sequences of actions to achieve goals is crucial.
    
    
     These applications include
    
    <a id="_idIndexMarker240">
    </a>
    
     navigation and route planning, such as GPS systems using graph representations of road networks to find optimal routes minimizing travel time or distance.
    
    
     Logistics and supply chain applications involve planning optimal sequences of operations for manufacturing products or finding least-cost shipping routes and delivery schedules.
    
    
     AI planning employs graph-based methods for game AI move sequencing in chess, video games, and real-time strategy games, as well as for task planning in
    
    
     
      AI assistants.
     
    
   </p>
   <h3>
    
     Heuristic search
    
   </h3>
   <p>
    
     Heuristic search techniques are widely used when finding optimal solutions through exhaustive search is computationally intractable due to the exponential growth of the search space.
    
    
     By using heuristic
    
    <a id="_idIndexMarker241">
    </a>
    
     functions to guide the search toward
    
    <a id="_idIndexMarker242">
    </a>
    
     promising areas, these methods can find reasonably good approximate solutions
    
    
     
      much faster.
     
    
   </p>
   <p>
    
     Heuristic search techniques find widespread use in route planning and navigation applications.
    
    
     When finding truly optimal routes is computationally too expensive, heuristics such as estimating the straight-line distance to the destination can effectively guide the search toward reasonably short driving routes.
    
    
     AI agents in video games also commonly employ heuristic pathfinding algorithms to navigate virtual
    
    
     
      environments efficiently.
     
    
   </p>
   <p>
    
     The key benefit of heuristic search is the ability to trade off optimality for computational efficiency, making larger problem instances solvable within limited time/memory constraints by finding
    
    <a id="_idIndexMarker243">
    </a>
    
     approximate solutions.
    
    
     Heuristic design
    
    <a id="_idIndexMarker244">
    </a>
    
     remains a critical challenge tailored to each
    
    
     
      application domain.
     
    
   </p>
   <h3>
    
     Monte Carlo tree search
    
   </h3>
   <p>
    
     The core idea behind MCTS is to iteratively build an asymmetric search tree by running many random simulations (playouts) from the current state.
    
    
     An asymmetric tree means that the tree is not balanced
    
    <a id="_idIndexMarker245">
    </a>
    
     or uniform in its structure.
    
    
     The results of these simulations are used to guide the growth of the most promising branches in
    
    <a id="_idIndexMarker246">
    </a>
    
     the tree at
    
    
     
      each iteration.
     
    
   </p>
   <p>
    
     MCTS has seen widespread adoption across various real-world applications involving sequential decision-making under uncertainty.
    
    
     This algorithm has particular benefits in AI agents in situations that are likely to encounter uncertainties, and contain large state spaces, that is, a large number of possible outcomes.
    
    
     MCTS is found to produce reasonable results even with limited
    
    
     
      computational resources.
     
    
   </p>
   <p>
    
     The key advantages of MCTS are anytime behavior, the ability to handle large action spaces, and reasoning about long-term outcomes through simulations.
    
    
     However, its efficiency depends on having an effective simulation model and designing good exploration strategies tailored to the domain.
    
    
     Some of the common drawbacks of this algorithm include the
    
    <a id="_idIndexMarker247">
    </a>
    
     computational intensity required for simulations of complex problems and the difficult-to-tune tree policy that helps with outcome selection
    
    
     
      during simulations.
     
    
   </p>
   <h3>
    
     Hierarchical planning
    
   </h3>
   <p>
    
     Hierarchical planning approaches breaking down complex problems into hierarchies of higher-level tasks or goals, and
    
    <a id="_idIndexMarker248">
    </a>
    
     subtasks or subgoals that achieve those higher-level objectives.
    
    
     This hierarchical decomposition allows reasoning about
    
    <a id="_idIndexMarker249">
    </a>
    
     problems more abstractly and reusing solutions to
    
    
     
      common subproblems.
     
    
   </p>
   <p>
    
     The core advantages of hierarchical approaches include computational efficiency via reusing subplan solutions, knowledge representation at multiple abstraction levels, and increased scalability to handle highly complex problems through hierarchical reasoning, though not always optimally.
    
    
     This structure also aligns well with how humans conceptualize and tackle complex tasks.
    
    
     The core advantages of hierarchical approaches include
    
    
     
      the following:
     
    
   </p>
   <ul>
    <li>
     
      Computational efficiency by reusing subplan solutions and avoiding reasoning about all
     
     
      
       details simultaneously
      
     
    </li>
    <li>
     
      Knowledge representation at multiple levels
     
     
      
       of abstraction
      
     
    </li>
    <li>
     
      Increased scalability to handle very
     
     
      
       complex problems
      
     
    </li>
   </ul>
   <p>
    
     While not always optimal, hierarchical plans can provide good approximations for large problems where optimal
    
    <a id="_idIndexMarker250">
    </a>
    
     solutions may be computationally
    
    <a id="_idIndexMarker251">
    </a>
    
     unmanageable.
    
    
     The structure also maps well to how humans tend to conceptualize and tackle
    
    
     
      complex tasks.
     
    
   </p>
   <h3>
    
     Constraint satisfaction
    
   </h3>
   <p>
    <strong class="bold">
     
      Constraint satisfaction problems
     
    </strong>
    
     (
    
    <strong class="bold">
     
      CSPs
     
    </strong>
    
     ) involve
    
    <a id="_idIndexMarker252">
    </a>
    
     formulating the problem as a set of constraints that must be satisfied, and then using constraint propagation techniques to eliminate inconsistent
    
    <a id="_idIndexMarker253">
    </a>
    
     possibilities from the search space.
    
    
     CSPs represent a powerful framework in AI for solving a wide variety of complex problems.
    
    
     At their core, CSPs involve defining a problem in terms of variables that need to be assigned values, under a set of constraints that restrict the possible combinations of these values.
    
    
     This approach allows for a natural representation of many real-world problems, from scheduling and resource allocation to puzzle-solving and
    
    
     
      configuration tasks.
     
    
   </p>
   <p>
    
     The beauty of CSPs lies in their ability to separate the problem representation from the solving method.
    
    
     Once a problem is formulated as a CSP, a variety of general-purpose algorithms can be applied to find a solution.
    
    
     This separation allows researchers and practitioners to focus on accurately modeling the problem without worrying about the intricacies and complexities of the
    
    
     
      solving algorithm.
     
    
   </p>
   <p>
    
     Intelligent agents require flexible
    
    <a id="_idIndexMarker254">
    </a>
    
     decision-making capabilities that can weigh constraints, handle uncertainty, learn from experience, and scale to complex real-world problems in pursuit of their goals.
    
    
     Advances in planning, search, reasoning, and learning algorithms continue enhancing these crucial
    
    
     
      cognitive abilities.
     
    
   </p>
   <p>
    
     Having examined the foundational aspects of intelligent agents – from knowledge representation and reasoning to learning mechanisms and decision-making processes – we now turn our
    
    <a id="_idIndexMarker255">
    </a>
    
     attention to a cutting-edge development that promises to significantly expand these capabilities: the integration of generative AI into
    
    
     
      agent systems.
     
    
   </p>
   <h1 id="_idParaDest-74">
    <a id="_idTextAnchor079">
    </a>
    
     Enhancing agent capabilities with generative AI
    
   </h1>
   <p>
    
     Generative AI is transforming the development of intelligent agents by enhancing learning efficiency, improving their understanding of environments, and enabling more complex interactions through generative
    
    <a id="_idIndexMarker256">
    </a>
    
     models.
    
    
     Some of the major developments in ushering generative AI in the space of
    
    <a id="_idIndexMarker257">
    </a>
    
     intelligent agents are
    
    
     
      as follows:
     
    
   </p>
   <ul>
    <li>
     <strong class="bold">
      
       Data augmentation
      
     </strong>
     
      : Creating synthetic training data with generative models supplements datasets, improving the robustness and efficiency of machine learning agents.
     
     
      For example, self-driving car agents can use generated scene images to learn better object detection and
     
     
      
       navigation policies.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Understanding of context
      
     </strong>
     
      : Generative AI constructs simulations modeling real-world complexities in fine detail, aiding agents in contextual understanding for informed decisions.
     
     
      For example, virtual assistants such as chatbots can use generative AI to simulate conversations in diverse contexts, helping them better understand user intent and provide more accurate, context-aware responses before interacting with
     
     
      
       real users.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Natural language processing
      
     </strong>
     
      : Generative language models ease human-agent interaction by improving understanding and generation capabilities.
     
     
      Virtual assistants such as Alexa and chatbots leverage generative NLP for
     
     
      
       natural conversations.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Creative problem solving
      
     </strong>
     
      : By generating diverse possible solutions, generative AI allows agents to explore creative ideas and evaluate their feasibility.
     
     
      This could allow AI architects to creatively design innovative building layouts while adhering to
     
     
      
       structural constraints.
      
     
    </li>
   </ul>
   <p>
    
     The deep integration of generative AI with knowledge representation, learning mechanisms, and decision-making processes yields highly responsive and adaptive intelligent agents capable of operating effectively in dynamic, complex environments.
    
    
     Some examples of how this synergistic
    
    <a id="_idIndexMarker258">
    </a>
    
     combination can enable advanced capabilities are
    
    
     
      as follows:
     
    
   </p>
   <ul>
    <li>
     <strong class="bold">
      
       Learning
      
     </strong>
     
      : Agents can gather data from various sources such as sensors, human interactions, or simulations to
     
     <a id="_idIndexMarker259">
     </a>
     
      build models based on their operating environment through machine learning techniques such as
     
     
      
       reinforcement learning
      
     
    </li>
    <li>
     <strong class="bold">
      
       Knowledge representation
      
     </strong>
     
      : The learned environmental data is structured into usable representations such as semantic networks, logical rules, or probabilistic graphical models to capture relationships, constraints,
     
     
      
       and uncertainties
      
     
    </li>
    <li>
     <strong class="bold">
      
       Decision processes
      
     </strong>
     
      : Based on the represented knowledge, agents use planning and decision-making algorithms (for example, Markov decision processes and MCTS) to derive sequences of actions aiming to achieve their
     
     
      
       objectives optimally
      
     
    </li>
    <li>
     <strong class="bold">
      
       Generative models
      
     </strong>
     
      : Provide
     
     <a id="_idIndexMarker260">
     </a>
     
      contextual simulations to enhance agents’ understanding through generated scenarios accounting for complexities such as noisy sensor data, stochastic
     
     <a id="_idIndexMarker261">
     </a>
     
      dynamics, or extraneous factors absent from
     
     
      
       training data
      
     
    </li>
    <li>
     <strong class="bold">
      
       Feedback loops
      
     </strong>
     
      : Allow continuous adaptation by feeding real-world interaction outcomes back into the learning mechanisms to refine the agent’s knowledge and decision models based
     
     
      
       on experience
      
     
    </li>
   </ul>
   <h2 id="_idParaDest-75">
    <a id="_idTextAnchor080">
    </a>
    
     Start building agentic AI
    
   </h2>
   <p>
    
     We have learned quite
    
    <a id="_idIndexMarker262">
    </a>
    
     a lot about the characteristics of intelligent agents, how they are built, how they work with different algorithms, and their essential components.
    
    
     It is now time for a gentle introduction to the world of agentic AI and to start building applications using
    
    
     
      different frameworks.
     
    
   </p>
   <p>
    
     In subsequent chapters of this book, we will make extensive use of several open source frameworks.
    
    
     The most popular framework for building agentic and multi-agent AI systems is LangChain’s LangGraph framework, although some of the other noteworthy frameworks (as of this writing) include AutoGen, CrewAI, and MetaGPT.
    
    
     This is not an exhaustive list of open source frameworks; these are only the most popular frameworks that allow you to build agentic and multi-agent systems with LLMs.
    
    
     Note that although some of these frameworks support different programming languages, we will primarily use Python programming language for our purposes.
    
    
     For consistency, we will use LangGraph and OpenAI
    
    <a id="_idIndexMarker263">
    </a>
    
     GPT models throughout the book; however; there are a number of other LLMs that can be used with agentic
    
    
     
      AI frameworks.
     
    
   </p>
   <p class="callout-heading">
    
     Important note
    
   </p>
   <p class="callout">
    
     Although the code samples are created specifically with OpenAI GPT models, you can use any model of your choice that is supported by LangGraph.
    
    
     LangGraph also works with LLMs offered via several cloud providers
    
    <a id="_idIndexMarker264">
    </a>
    
     such as
    
    <strong class="bold">
     
      Amazon Web Services
     
    </strong>
    
     (
    
    <strong class="bold">
     
      AWS
     
    </strong>
    
     ),
    
    <strong class="bold">
     
      Microsoft Azure
     
    </strong>
    
     , and
    
    <strong class="bold">
     
      Google Cloud Platform
     
    </strong>
    
     (
    
    <strong class="bold">
     
      GCP
     
    </strong>
    
     ).
    
    
     Using AI models or cloud
    
    <a id="_idIndexMarker265">
    </a>
    
     platforms may incur some costs.
    
    
     Refer to the respective
    
    <a id="_idIndexMarker266">
    </a>
    
     AI model documentation for
    
    
     
      more details.
     
    
   </p>
   <p>
    
     Now that we have the overview of frameworks and LLMs out of the way, let’s start with building our basic travel agent booking.
    
    
     At this stage, we only want the model to respond back with greetings and any follow-up questions.
    
    
     For example, if we ask the agent to “
    
    <em class="italic">
     
      Book a flight for me
     
    </em>
    
     ”, then we want the model to respond back with a follow-up question about travel cities, dates, and so on.
    
    
     For the following code, we will directly use OpenAI’s Python SDK to build this functionality and use its function calling feature, that is the LLM model’s ability to call a function on the user’s behalf.
    
    
     Here’s the
    
    
     
      code snippet:
     
    
   </p>
   <pre class="source-code">
1 import openai from OpenAI
2
3 def book_flight(passenger_name: str,
4                 from_city: str,
5                 to_city: str,
6                 travel_date: str) -&gt; str:
7     return "A flight has been booked"
8
9 tools = [{ "type":"function",
10           "function":{ "name": "book_flight", … }}]
11
12 def travel_agent(user_message: str, messages: list) -&gt; str:
13    messages.append({"role": "user", "content": user_message})
14    try:
15       response = openai.chat.completions.create(
16                    model="gpt-4-turbo",
17                    messages=messages,
18                    tools=tools)
19       if response.choices[0].message.content:
20           return response.choices[0].message.content
21       elif response.choices[0].message.tool_calls:
22           [ … ]
23           confirmation = book_flight(…)
24           [ … ]
25           response = openai.chat.completions.create(
26                          model="gpt-4-turbo",
27                          messages=messages)
28           return response.choices[0].message.content</pre>
   <p>
    
     Let us break down what is happening in this code snippet.
    
    
     We first define a
    
    <strong class="source-inline">
     
      book_flight
     
    </strong>
    
     function in line 3 – at the moment, this function just returns a message that says that the flight booking is complete.
    
    
     The
    
    <strong class="source-inline">
     
      travel_agent
     
    </strong>
    
     function in line 12 is where we call the LLM, in this case, OpenAI’s
    
    <strong class="source-inline">
     
      gpt-4-turbo
     
    </strong>
    
     model.
    
    
     We call the LLM’s API using the OpenAI SDK in line 15, which is where we pass in the user’s message, the model’s name, and a set of tools.
    
    
     Note that we are using our
    
    <strong class="source-inline">
     
      book_flight
     
    </strong>
    
     function as a
    
    <em class="italic">
     
      tool
     
    </em>
    
     for our intelligent agent and the API takes
    
    <strong class="source-inline">
     
      tools
     
    </strong>
    
     as
    
    
     
      a parameter.
     
    
   </p>
   <p>
    
     We will discuss tools in
    
    <a id="_idIndexMarker267">
    </a>
    
     greater detail in the subsequent chapters, but for now, it is sufficient to understand that
    
    <em class="italic">
     
      tools
     
    </em>
    
     are a mechanism by which your intelligent agent can interact with the external world (or external systems) to complete a task.
    
    
     In this case, the task is booking a flight ticket.
    
    
     The LLM is smart enough to indicate to us when to call the
    
    <strong class="source-inline">
     
      book_flight
     
    </strong>
    
     tool function when it has all the details from the passenger.
    
    
     In a more complete solution as we will see in future chapters, functions such as
    
    <strong class="source-inline">
     
      book_flight
     
    </strong>
    
     will be used to interact with external systems, such as calling APIs to complete the flight booking and so on.
    
    
     Here’s how a possible conversation using this
    
    
     
      code looks:
     
    
   </p>
   <div><div><img alt="img" role="presentation" src="img/B31483_03_07.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 3.7 – A sample conversation with the AI agent
    
   </p>
   <p>
    
     A few things to note here: after the first user message, our agent doesn’t directly call the
    
    <strong class="source-inline">
     
      book_flight
     
    </strong>
    
     function because it doesn’t have all the parameter values to call the function successfully.
    
    
     In a typical heuristics-based approach, you could use string parsing to find out whether the user has provided their name, travel cities, and date of travel.
    
    
     But such logic can be overly complicated and error-prone.
    
    
     This is where the beauty of an intelligent agent comes in.
    
    
     The LLM has better language understanding capabilities and can know when to call the
    
    <strong class="source-inline">
     
      book_flight
     
    </strong>
    
     function during the conversation, and if the required values are not provided
    
    <a id="_idIndexMarker268">
    </a>
    
     by the user, it can prompt them to provide these values, that is, their name, travel cities, and date of travel.
    
    
     It can also accurately extract these values from the user’s response, which allows us to call the
    
    <strong class="source-inline">
     
      book_flight
     
    </strong>
    
     function.
    
    
     For the full code of the intelligent agent, refer to the
    
    <strong class="source-inline">
     
      Chapter_03.ipynb
     
    </strong>
    
     Python notebook in the
    
    
     
      GitHub repository.
     
    
   </p>
   <h1 id="_idParaDest-76">
    <a id="_idTextAnchor081">
    </a>
    
     Summary
    
   </h1>
   <p>
    
     In this chapter, we discussed several aspects and key components of intelligent agents.
    
    
     We started with the understanding and importance of various knowledge representation mechanisms such as semantic networks, frames, and logic-based representations.
    
    
     We also learned about various reasoning techniques such as deductive, inductive, and abductive reasoning to understand how intelligent agents may use these techniques for decision-making to accomplish tasks.
    
    
     We briefly looked at some of the learning mechanisms that intelligent agents may use to adapt themselves to various use cases and explored agent decision-making via utility functions and various planning algorithms.
    
    
     Finally, we wrapped up this chapter with an introduction to intelligent agents with generative AI using an LLM and discussed a simple intelligent agent that is capable of gathering information from user queries for our travel booking
    
    
     
      agent example.
     
    
   </p>
   <p>
    
     In the next chapter, we will dive deeper into the advanced intelligent agent concepts such as reflection and introspection.
    
    
     We will learn how reflection and introspection influence an intelligent agent’s decision-making capabilities.
    
    
     Before we conclude this chapter, take a moment and try to answer the questions listed in the
    
    
     
      subsequent sections.
     
    
   </p>
   <h1 id="_idParaDest-77">
    <a id="_idTextAnchor082">
    </a>
    
     Questions
    
   </h1>
   <ol>
    <li>
     
      What are the three main types of knowledge representation discussed in
     
     
      
       the chapter?
      
     
    </li>
    <li>
     
      How does inductive reasoning differ from
     
     
      
       deductive reasoning?
      
     
    </li>
    <li>
     
      What is the purpose of a utility function in
     
     
      
       agent decision-making?
      
     
    </li>
    <li>
     
      How does generative AI enhance the capabilities of
     
     
      
       intelligent agents?
      
     
    </li>
    <li>
     
      What is the role of “tools” in AI frameworks such as the one demonstrated in the travel
     
     
      
       agent example?
      
     
    </li>
   </ol>
   <h1 id="_idParaDest-78">
    <a id="_idTextAnchor083">
    </a>
    
     Answers
    
   </h1>
   <ol>
    <li value="1">
     
      The three main types of knowledge representation discussed are semantic networks, frames, and
     
     
      
       logic-based representations.
      
     
    </li>
    <li>
     
      Inductive reasoning follows a bottom-up approach, making generalizations from specific observations, while deductive reasoning follows a top-down approach, deriving specific conclusions from
     
     
      
       general premises.
      
     
    </li>
    <li>
     
      A utility function quantifies an agent’s preferences by mapping outcomes to utility values, enabling the agent to compare and choose actions that maximize
     
     
      
       expected utility.
      
     
    </li>
    <li>
     
      Generative AI enhances agent capabilities through data augmentation, improved context understanding, better natural language processing, and enabling
     
     
      
       creative problem-solving.
      
     
    </li>
    <li>
     
      Tools in AI frameworks allow agents to interact with external systems or perform specific functions, such as booking a flight in the travel agent example, enhancing the agent’s ability to complete
     
     
      
       complex tasks.
      
     
    </li>
   </ol>
   <h1 id="_idParaDest-79">
    <a id="_idTextAnchor084">
    </a>
    
     Join our communities on Discord and Reddit
    
   </h1>
   <p>
    
     Have questions about the book or want to contribute to discussions on Generative AI and LLMs?
    
    
     Join our Discord server at
    
    <a href="https://packt.link/I1tSU">
     
      https://packt.link/I1tSU
     
    </a>
    
     and our Reddit channel at
    
    <a href="https://packt.link/ugMW0">
     
      https://packt.link/ugMW0
     
    </a>
    
     to connect, share, and collaborate with
    
    
     
      like-minded enthusiasts.
     
    
   </p>
   <div><div><img alt="img" role="presentation" src="img/B31483_Discord_QR_new.jpg"/>
     
    </div>
   </div>
   <p>
   </p>
   <div><div><img alt="img" role="presentation" src="img/qrcode_Reddit_Channel.jpg"/>
     
    </div>
   </div>
  </div>
 

  <div><h1 id="_idParaDest-80" lang="en-US" xml:lang="en-US">
    <a id="_idTextAnchor085">
    </a>
    
     Part 2: Designing and Implementing Generative AI-Based Agents
    
   </h1>
   <p>
    
     This part equips you with practical techniques and approaches for designing and implementing generative AI-based agentic systems, enabling you to create adaptive, self-aware, and collaborative
    
    
     
      intelligent agents.
     
    
   </p>
   <p>
    
     This part contains the
    
    
     
      following chapters:
     
    
   </p>
   <ul>
    <li>
     <a href="B31483_04.xhtml#_idTextAnchor086">
      <em class="italic">
       
        Chapter 4
       
      </em>
     </a>
     
      ,
     
     <em class="italic">
      
       Reflection and Introspection in Agents
      
     </em>
    </li>
    <li>
     <a href="B31483_05.xhtml#_idTextAnchor114">
      <em class="italic">
       
        Chapter 5
       
      </em>
     </a>
     
      ,
     
     <em class="italic">
      
       Enabling Tool Use and Planning in Agents
      
     </em>
    </li>
    <li>
     <a href="B31483_06.xhtml#_idTextAnchor138">
      <em class="italic">
       
        Chapter 6
       
      </em>
     </a>
     
      ,
     
     <em class="italic">
      
       Exploring the Coordinator, Worker, and Delegator Approach
      
     </em>
    </li>
    <li>
     <a href="B31483_07.xhtml#_idTextAnchor159">
      <em class="italic">
       
        Chapter 7
       
      </em>
     </a>
     
      ,
     
     <em class="italic">
      
       Effective Agentic System Design Techniques
      
     </em>
    </li>
   </ul>
  </div>
  <div><div></div>
  </div>
  <div><div></div>
  </div>
 </body></html>