<html><head></head><body>
<div><h1 class="chapterNumber">8</h1>
<h1 class="chapterTitle" id="_idParaDest-111">Using LLMs with Structured Data</h1>
<p class="normal">In this chapter, we are going to cover yet <a id="_idIndexMarker573"/>another great capability of <strong class="keyWord">large language models</strong> (<strong class="keyWord">LLMs</strong>): the ability to handle structured, tabular data. We will see how, thanks to plugins and an agentic approach, we can use LLMs as a natural language interface between us and our structured data, reducing the gap between the business user and the structured information.</p>
<p class="normal">During this chapter, we will cover the following topics:</p>
<ul>
<li class="bulletList">Introduction to the main structured data systems</li>
<li class="bulletList">Using tools and plugins to connect LLMs to tabular data</li>
<li class="bulletList">Building a database copilot with LangChain</li>
</ul>
<p class="normal">By the end of this chapter, you will be able to build your own natural language interface for your data estate and be able to combine unstructured with structured sources.</p>
<h1 class="heading-1" id="_idParaDest-112">Technical requirements</h1>
<p class="normal">To complete the tasks in this chapter, you will need the following:</p>
<ul>
<li class="bulletList">A Hugging Face account and user access token.</li>
<li class="bulletList">An OpenAI account and user access token.</li>
<li class="bulletList">Python 3.7.1 or later version.</li>
<li class="bulletList">Python packages: Make sure to have the following Python packages installed: <code class="inlineCode">langchain</code>, <code class="inlineCode">python-dotenv</code>, <code class="inlineCode">huggingface_hub</code>, <code class="inlineCode">streamlit</code>, and <code class="inlineCode">sqlite3</code>. Those can be easily installed via <code class="inlineCode">pip install</code> in your terminal.</li>
</ul>
<p class="normal">You can find all the code and examples in the book’s GitHub repository at <a href="Chapter_08.xhtml">https://github.com/PacktPublishing/Building-LLM-Powered-Applications</a>.</p>
<h1 class="heading-1" id="_idParaDest-113">What is structured data?</h1>
<p class="normal">In previous chapters, we focused on how LLMs can handle textual data. In fact, those models are, as the name suggests, “language” models, meaning<a id="_idIndexMarker574"/> that they have been trained and are able to handle unstructured text data.</p>
<p class="normal">Nevertheless, unstructured data only refers to a portion of the overall data realm that applications can handle. Generally, data can be categorized into three types, which are as follows:</p>
<ul>
<li class="bulletList"><strong class="keyWord">Unstructured data</strong>: This refers to <a id="_idIndexMarker575"/>data that doesn’t have a specific or predefined format. It lacks a consistent structure, making it challenging to organize and analyze using traditional databases. Examples of unstructured data include:<ul>
<li class="bulletList level-2">Text documents: Emails, social media posts, articles, and reports.</li>
<li class="bulletList level-2">Multimedia: Images, videos, audio recordings.</li>
<li class="bulletList level-2">Natural language text: Chat logs, transcriptions of spoken conversations.</li>
<li class="bulletList level-2">Binary data: Files without a specific data format, such as proprietary file formats.</li>
</ul>
</li>
</ul>
<div><p class="normal"><strong class="keyWord">Note</strong></p>
<p class="normal">When it comes to storing unstructured data, NoSQL databases play a crucial role, due to their flexible schema-less design, which allows them to handle various data types like text, images, and videos efficiently. The term “NoSQL” originally stood for “non-SQL” or “not only SQL” to emphasize that these databases don’t rely solely on the<a id="_idIndexMarker576"/> traditional <strong class="keyWord">Structured Query Language</strong> (<strong class="keyWord">SQL</strong>) to manage and query data. NoSQL databases emerged as a response to the limitations of relational databases, particularly their rigid schema requirements and difficulties in scaling horizontally.</p>
<p class="normal">An example of a NoSQL database is MongoDB, a<a id="_idIndexMarker577"/> document-oriented NoSQL database, which stores data in JSON-like documents, making it highly effective for managing diverse unstructured content; similarly, Cassandra, with its wide-column store model, excels at handling large volumes of data across many commodity servers, providing high availability without compromising performance. This flexibility enables NoSQL databases to adapt to the volume, variety, and velocity of unstructured data, accommodating rapid changes and scaling easily. Traditional relational databases, with their rigid schema requirements, struggle to manage such diversity and volume efficiently.</p>
</div>
<ul>
<li class="bulletList"><strong class="keyWord">Structured data</strong>: This type of data is organized and formatted with a clear structure, typically into rows and <a id="_idIndexMarker578"/>columns. It follows a fixed schema, making it easy to store, retrieve, and analyze using relational databases. Examples of structured data include:<ul>
<li class="bulletList level-2">Relational databases: Data <a id="_idIndexMarker579"/>stored in tables with predefined columns and data types.</li>
<li class="bulletList level-2">Spreadsheets: Data organized in rows and columns in software like Microsoft Excel.</li>
<li class="bulletList level-2">Sensor data: Recorded measurements like temperature, pressure, and time in a structured format.</li>
<li class="bulletList level-2">Financial data: Transaction records, balance sheets, and income statements.</li>
</ul>
</li>
<li class="bulletList"><strong class="keyWord">Semi-structured data</strong>: This falls between the two categories. While it doesn’t adhere to a rigid structure like <a id="_idIndexMarker580"/>structured data, it has some level of organization and may contain tags or other markers that provide context. Examples of semi-structured data include:<ul>
<li class="bulletList level-2"><strong class="keyWord">eXtensible Markup Language</strong> (<strong class="keyWord">XML</strong>) files: They use tags to structure data, but the specific tags and their <a id="_idIndexMarker581"/>arrangement can vary.</li>
<li class="bulletList level-2"><strong class="keyWord">JavaScript Object Notation</strong> (<strong class="keyWord">JSON</strong>): This is used for data interchange and allows for nested structures<a id="_idIndexMarker582"/> and key-value pairs.</li>
<li class="bulletList level-2">NoSQL databases: Storing data in a format that doesn’t require a fixed schema, allowing for flexibility.</li>
</ul>
</li>
</ul>
<p class="normal">In summary, unstructured data lacks a defined format, structured data follows a strict format, and semi-structured data has some level of structure but is more flexible than structured data. The distinction between these types of data is important as it impacts how they are stored, processed, and analyzed in various applications.</p>
<p class="normal">However, regardless of its nature, querying structured data involves using a query language or methods specific to that database technology. For example, for SQL databases, SQL is used to interact with relational databases. Henceforth, to extract data from tables, you need to know this specific language.</p>
<p class="normal">But what if we want to ask questions in natural language to our structured data? What if our application could provide us not only with a sterile numeric answer but rather with a conversational answer, which also gives us context about the number? This is exactly what we will try to achieve in the next <a id="_idIndexMarker583"/>sections with our LLM-powered applications. More specifically, we are going build something that we’ve already defined in <em class="chapterRef">Chapter 2</em>: a <strong class="keyWord">copilot</strong>. Since we<a id="_idIndexMarker584"/> are going to mount our copilot to a relational database, we will <a id="_idIndexMarker585"/>name our application <strong class="keyWord">DBCopilot</strong>. First, let’s look at what relational databases are.</p>
<h1 class="heading-1" id="_idParaDest-114">Getting started with relational databases</h1>
<p class="normal">The concept of relational databases was first proposed by E.F. Codd, an IBM researcher, in 1970. He defined the rules and principles of the relational model, which aimed to provide a simple and consistent way of <a id="_idIndexMarker586"/>accessing and manipulating data. He also introduced SQL, which became the standard language for querying and manipulating relational databases. Relational databases have become widely used in various domains<a id="_idIndexMarker587"/> and applications, such as e-commerce, inventory <a id="_idIndexMarker588"/>management, payroll, <strong class="keyWord">customer relationship management</strong> (<strong class="keyWord">CRM</strong>), and <strong class="keyWord">business intelligence</strong> (<strong class="keyWord">BI</strong>).</p>
<p class="normal">In this section, we are going to cover the main aspects of a relational database. Then, we will start working with the sample database we will use in our DBCopilot, the Chinook database. We will inspect this database and explore how to connect to remote tables using Python.</p>
<h2 class="heading-2" id="_idParaDest-115">Introduction to relational databases</h2>
<p class="normal">A relational database is a type of database <a id="_idIndexMarker589"/>that stores and organizes data in structured tables with rows and columns. Each row represents a record, and each column represents a field or attribute. The relationships between tables are established through keys, primarily the primary key and foreign key. This allows for efficient querying and manipulation of data using SQL. These databases are commonly used for various applications like websites and business management systems, due to their ability to manage structured data effectively.</p>
<p class="normal">To have a better understanding of relational databases, let’s consider an example of a database of a library. We’ll have two tables: one for books and another for authors. The relationship between them will be established using primary and foreign keys.</p>
<div><p class="normal"><strong class="keyWord">Definition</strong></p>
<p class="normal">A primary key is like the unique<a id="_idIndexMarker590"/> fingerprint of each record in a table. It’s a special column that holds a value that’s distinct for each row in that table. Think of it as the “identity” of a record. Having a primary key is important because it guarantees that no two records in the same table will share the same key. This uniqueness makes it easy to locate, modify, and manage individual records in the table.</p>
<p class="normal">A foreign key is a bridge between <a id="_idIndexMarker591"/>two tables. It’s a column in one table that references the primary key column in another table. This reference creates a link between the data in the two tables, establishing a relationship. The purpose of the foreign key is to maintain data consistency and integrity across related tables. It ensures that if a change is made in the primary key table, the related data in the other table remains accurate. By using foreign keys, you can retrieve information from multiple tables that are connected, enabling you to understand how different pieces of data are related to each other.</p>
</div>
<p class="normal">Let’s take a closer look at our <a id="_idIndexMarker592"/>example, as shown in the following image:</p>
<figure class="mediaobject"><img alt="A screenshot of a computer  Description automatically generated" src="img/B21714_08_01.png"/></figure>
<p class="packt_figref">Figure 8.1: An example of the relationship between two tables in a database</p>
<p class="normal">In this example, the Authors table contains information about authors, including their ID, name, and birth year. The Books table includes details about books, including the book’s ID, title, and a foreign key called AuthorID, which references the corresponding author in the Authors table (with AuthorID as the primary key). This way, you can use SQL queries to retrieve information like finding all books written by a specific author or the birth year of an author based on the book they wrote. The relational structure allows for efficient management <a id="_idIndexMarker593"/>and retrieval of data in a structured manner.</p>
<p class="normal">Some of the main database systems in the market include:</p>
<ul>
<li class="bulletList"><strong class="keyWord">SQL databases</strong>: These are <strong class="keyWord">relational database management systems</strong> (<strong class="keyWord">RDBMS</strong>) that use SQL for data <a id="_idIndexMarker594"/>manipulation and querying. Examples include MySQL, PostgreSQL, and Microsoft SQL Server.</li>
<li class="bulletList"><strong class="keyWord">Oracle Database</strong>: A widely-used<a id="_idIndexMarker595"/> RDBMS that offers advanced features and scalability for large-scale applications.</li>
<li class="bulletList"><strong class="keyWord">SQLite:</strong> A self-contained, serverless, and<a id="_idIndexMarker596"/> zero-configuration SQL database engine commonly used in embedded systems and mobile applications.</li>
<li class="bulletList"><strong class="keyWord">IBM Db2</strong>: A family of data management <a id="_idIndexMarker597"/>products, including relational database servers, developed by IBM.</li>
<li class="bulletList"><strong class="keyWord">Amazon Web Services (AWS) RDS</strong>: A managed relational database service offered by Amazon, providing options for<a id="_idIndexMarker598"/> various databases like MySQL, PostgreSQL, SQL Server, and more.</li>
<li class="bulletList"><strong class="keyWord">Google Cloud SQL</strong>: A managed database<a id="_idIndexMarker599"/> service by Google Cloud Platform, supporting MySQL, PostgreSQL, and SQL Server.</li>
<li class="bulletList"><strong class="keyWord">Redis</strong>: An open-source, in-memory<a id="_idIndexMarker600"/> data structure store that can be used as a database, cache, and message broker.</li>
</ul>
<p class="normal">In this chapter, we are going to use SQLite database, which also offers a seamless integration with Python. But before we do that, let’s understand the database we’ll be using.</p>
<h2 class="heading-2" id="_idParaDest-116">Overview of the Chinook database</h2>
<p class="normal">The Chinook database is a sample <a id="_idIndexMarker601"/>database that can be used for learning and practicing SQL. It is based on a fictional digital media store and contains<a id="_idIndexMarker602"/> data about artists, albums, tracks, customers, invoices, and more. The Chinook database is available for various database management systems, such as SQL Server, Oracle, MySQL, PostgreSQL, SQLite, and DB2.</p>
<p class="normal">Here are some features of this<a id="_idIndexMarker603"/> database:</p>
<ul>
<li class="bulletList">It uses real data from an iTunes library, which makes it more realistic and interesting.</li>
<li class="bulletList">It has a clear and simple data model, which makes it easy to understand and query.</li>
<li class="bulletList">It covers more features of SQL, such as subqueries, joins, views, and triggers.</li>
<li class="bulletList">It is compatible with <a id="_idIndexMarker604"/>multiple database servers, which makes it more versatile and portable.</li>
</ul>
<p class="normal">You can find the configuration instructions at <a href="https://database.guide/2-sample-databases-sqlite/">https://database.guide/2-sample-databases-sqlite/</a>.</p>
<p class="normal">You can see an illustration of the relationship among the database’s tables here:</p>
<figure class="mediaobject"><img alt="A screenshot of a computer  Description automatically generated" src="img/B21714_08_02.png"/></figure>
<p class="packt_figref">Figure 8.2: Diagram of Chinook Database (source: <a href="https://github.com/arjunchndr/Analyzing-Chinook-Database-using-SQL-and-Python">https://github.com/arjunchndr/Analyzing-Chinook-Database-using-SQL-and-Python</a>)</p>
<p class="normal">As you can see, there are 11 tables, all related<a id="_idIndexMarker605"/> to each other with primary and foreign keys. In the upcoming paragraph, we will see how LLMs will be able to navigate among those tables, capturing their relationships and gathering relevant information. But before jumping to LLMs, let’s first inspect the Chinook database a bit more by setting up the connection with Python.</p>
<h2 class="heading-2" id="_idParaDest-117">How to work with relational databases in Python</h2>
<p class="normal">To work with relational databases in Python, you need to use a library that can connect to the database and execute <a id="_idIndexMarker606"/>SQL queries. Some of these<a id="_idIndexMarker607"/> libraries are as follows:</p>
<ul>
<li class="bulletList"><code class="inlineCode">SQLAlchemy</code>: This is an open-source SQL toolkit and <strong class="keyWord">object-relational mapper</strong> (<strong class="keyWord">ORM</strong>) for Python. It allows<a id="_idIndexMarker608"/> you to create, read, update, and delete data from relational databases using Python objects and methods. It supports many database engines, such as SQLite, MySQL, PostgreSQL, and Oracle.</li>
<li class="bulletList"><code class="inlineCode">Psycopg</code>: This is a popular database connector for PostgreSQL. It enables you to execute SQL queries and access PostgreSQL features from Python. It is fast, reliable, and thread-safe.</li>
<li class="bulletList"><code class="inlineCode">MySQLdb</code>: This is a database connector for MySQL. It allows you to interact with MySQL databases from Python using the DB-API 2.0 specification. It is one of the oldest and most widely used Python libraries for MySQL, but its development is mostly frozen.</li>
<li class="bulletList"><code class="inlineCode">cx_Oracle</code>: This is a database connector for Oracle Database. It enables you to connect to Oracle databases and use SQL and PL/SQL features from Python. It supports advanced features such<a id="_idIndexMarker609"/> as object types, <strong class="keyWord">Large Objects</strong> (<strong class="keyWord">LOBs</strong>), and arrays.</li>
<li class="bulletList"><code class="inlineCode">sqlite3</code>: This is a database connector for SQLite3, a widely used, lightweight, serverless, self-contained, and open-source relational database management system. You can use sqlite3 to create, query, update, and delete data from <code class="inlineCode">SQLite</code> databases in your Python programs</li>
</ul>
<p class="normal">Since we are going to work with SQLite, we will use the <code class="inlineCode">sqlite3</code> module, which you will need to install via <code class="inlineCode">pip install sqlite3</code>. Some of the features of sqlite3 are as follows:</p>
<ul>
<li class="bulletList">It follows the DB-API 2.0 specification, which defines a standard interface for Python database access modules.</li>
<li class="bulletList">It supports transactions, which allow you to execute multiple SQL statements as a single unit of work and roll back in case of errors.</li>
<li class="bulletList">It allows you to use Python objects as parameters and results for SQL queries, using various adapters and converters.</li>
<li class="bulletList">It supports user-defined functions, aggregates, collations, and authorizers, which enable you to extend the functionality of SQLite with Python code.</li>
<li class="bulletList">It has a built-in row factory, which returns query results as named tuples or dictionaries instead of plain tuples.</li>
</ul>
<p class="normal">Let’s see an example of this<a id="_idIndexMarker610"/> connection using our Chinook database:</p>
<ol>
<li class="numberedList" value="1">The database can be downloaded locally from <a href="https://www.sqlitetutorial.net/wp-content/uploads/2018/03/chinook.zip">https://www.sqlitetutorial.net/wp-content/uploads/2018/03/chinook.zip</a>. You will only need to unzip the <code class="inlineCode">chinook.db</code> file and it will be<a id="_idIndexMarker611"/> ready to be consumed. In the following code, we are initializing a connection (<code class="inlineCode">conn</code>) to our <code class="inlineCode">chinook.db</code>, which will be used to interact with the database. Then, we will save our tables in a pandas object with the <code class="inlineCode">read_sql</code> module, which allows you to run SQL queries against your database:
        <pre class="programlisting code-one"><code class="hljs-code">import sqlite3
import pandas as pd
## creating a connection
database = 'chinook.db'
conn = sqlite3.connect(database)
## importing tables
tables = pd.read_sql("""SELECT name, type
                        FROM sqlite_master
                         WHERE type IN ("table", "view");""", conn)
</code></pre>
</li>
</ol>
<p class="normal-one">Here is the output that we can see:</p>
<figure class="mediaobject"><img alt="A screenshot of a black screen  Description automatically generated" src="img/B21714_08_03.png"/></figure>
<p class="packt_figref">Figure 8.3: A list of tables within the Chinook database</p>
<div><p class="normal"><strong class="keyWord">Note</strong></p>
<p class="normal">Column names might be slightly different as the online database is updated over time. To get up-to-date columns’ naming conventions, you can run the following command:</p>
<pre class="programlisting code"><code class="hljs-code">pd.read_sql("PRAGMA table_info(customers);", conn)
print(customer_columns)
</code></pre>
</div>
<ol>
<li class="numberedList" value="2">We can also inspect the<a id="_idIndexMarker612"/> single table to gather <a id="_idIndexMarker613"/>some relevant data. For example, let’s say we want to see the top five countries per album sales:
        <pre class="programlisting code-one"><code class="hljs-code">pd.read_sql("""
SELECT c.country AS Country, SUM(i.total) AS Sales
FROM customer c
JOIN invoice i ON c.customer_id = i.customer_id
GROUP BY Country
ORDER BY Sales DESC
LIMIT 5;
""", conn)
</code></pre>
</li>
</ol>
<p class="normal-one">Here is the corresponding output:</p>
<figure class="mediaobject"><img alt="A screenshot of a cellphone  Description automatically generated" src="img/B21714_08_04.png"/></figure>
<p class="packt_figref">Figure 8.4: Top 5 countries with highest sales</p>
<ol>
<li class="numberedList" value="3">Finally, we can also use the <code class="inlineCode">matplotlib</code> Python library to create useful diagrams about the database’s statistics. In the following Python snippet, we are going to run an<a id="_idIndexMarker614"/> SQL query to extract <a id="_idIndexMarker615"/>the number of tracks grouped by genre, and then plot the result using <code class="inlineCode">matplotlib</code> as follows:
        <pre class="programlisting code-one"><code class="hljs-code">import matplotlib.pyplot as plt
# Define the SQL query
sql = """
SELECT g.Name AS Genre, COUNT(t.track_id) AS Tracks
FROM genre g
JOIN track t ON g.genre_id = t.genre_id
GROUP BY Genre
ORDER BY Tracks DESC;
"""
# Read the data into a dataframe
data = pd.read_sql(sql, conn)
# Plot the data as a bar chart
plt.bar(data.Genre, data.Tracks)
plt.title("Number of Tracks by Genre")
plt.xlabel("Genre")
plt.ylabel("Tracks")
plt.xticks(rotation=90)
plt.show()
</code></pre>
</li>
</ol>
<p class="normal-one">We’ll see the following output:</p>
<figure class="mediaobject"><img alt="A graph of tracks with blue bars  Description automatically generated" src="img/B21714_08_05.png"/></figure>
<p class="packt_figref">Figure 8.5: Number of tracks by genre</p>
<p class="normal">As you can see, in order to gather <a id="_idIndexMarker616"/>relevant information from our database, we used the syntax of SQL. Our goal is to gather information by simply asking in natural language, and we are going to do so starting in the next section.</p>
<h1 class="heading-1" id="_idParaDest-118">Implementing the DBCopilot with LangChain</h1>
<p class="normal">In this section, we are going to cover the<a id="_idIndexMarker617"/> architecture and implementation steps behind a DBCopilot application, a natural language interface to chat with<a id="_idIndexMarker618"/> database-structured data. In the upcoming sections, we will explore how to achieve that by leveraging a powerful LangChain component called SQL Agent.</p>
<h2 class="heading-2" id="_idParaDest-119">LangChain agents and SQL Agent</h2>
<p class="normal">In <em class="chapterRef">Chapter 4</em>, we introduced the concept of <a id="_idIndexMarker619"/>LangChain agents, defining them as entities<a id="_idIndexMarker620"/> that drive decision making within LLM-powered applications.</p>
<p class="normal">Agents have access to a suite of tools and can decide which tool to call based on the user input and the context. Agents are dynamic and adaptive, meaning that they can change or adjust their actions based on the situation or the goal.</p>
<p class="normal">In this chapter, we will see agents in action, using the following LangChain components:</p>
<ul>
<li class="bulletList"><code class="inlineCode">create_sql_agent</code>: An agent designed to interact with relational databases</li>
<li class="bulletList"><code class="inlineCode">SQLDatabaseToolkit</code>: A toolkit to provide the agent with the required non-parametric knowledge</li>
<li class="bulletList"><code class="inlineCode">OpenAI</code>: An LLM to act as the reasoning engine behind the agent, as well as the generative engine to produce conversational results</li>
</ul>
<p class="normal">Let’s start with our implementation by following these steps:</p>
<ol>
<li class="numberedList" value="1">We’ll first initialize all the components and establish the connection to the Chinook database, using the <code class="inlineCode">SQLDatabase</code> LangChain component (which uses <code class="inlineCode">SQLAlchemy</code> under the hood and is used to connect to our database):
        <pre class="programlisting code-one"><code class="hljs-code">from langchain.agents import create_sql_agent
from langchain.llms import OpenAI
from langchain.chat_models import ChatOpenAI
from langchain.agents.agent_toolkits import SQLDatabaseToolkit
from langchain.sql_database import SQLDatabase
from langchain.llms.openai import OpenAI
from langchain.agents import AgentExecutor
from langchain.agents.agent_types import AgentType
from langchain.chat_models import ChatOpenAI
llm = OpenAI()
db = SQLDatabase.from_uri('sqlite:///chinook.db')
toolkit = SQLDatabaseToolkit(db=db, llm=llm)
agent_executor = create_sql_agent(
    llm=llm,
    toolkit=toolkit,
    verbose=True,
    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
)
</code></pre>
</li>
<li class="numberedList">Before running the <a id="_idIndexMarker621"/>agent, let’s first inspect its available tools:
        <pre class="programlisting code-one"><code class="hljs-code">[tool.name for tool in toolkit.get_tools()]
</code></pre>
</li>
</ol>
<p class="normal-one">Here is the output:</p>
<pre class="programlisting con-one"><code class="hljs-con">['sql_db_query', 'sql_db_schema', 'sql_db_list_tables', 'sql_db_query_checker']
</code></pre>
<p class="normal-one">Those tools have the following capabilities:</p>
<ul>
<li class="bulletList level-2"><code class="inlineCode">sql_db_query</code>: This takes as<a id="_idIndexMarker622"/> input a detailed and correct SQL query, and it outputs a result from the database. If the query is not correct, an error message will be returned.</li>
<li class="bulletList level-2"><code class="inlineCode">sql_db_schema</code>: This takes as input a comma-separated list of tables, and it outputs the schema and sample rows for those tables.</li>
<li class="bulletList level-2"><code class="inlineCode">sql_db_list_tables</code>: This takes as input an empty string, and it outputs a comma-separated list of tables in the database.</li>
<li class="bulletList level-2"><code class="inlineCode">sql_db_query_checker</code>: This tool double-checks whether the query is correct before executing it.</li>
</ul>
<ol>
<li class="numberedList" value="3">Let’s now execute our agent with a simple query to describe the <code class="inlineCode">playlisttrack</code> table:
        <pre class="programlisting code-one"><code class="hljs-code">agent_executor.run("Describe the playlisttrack table")
</code></pre>
</li>
</ol>
<p class="normal-one">The following output is then obtained (the output is truncated – you can find the full output in the book’s GitHub repository):</p>
<pre class="programlisting con-one"><code class="hljs-con">&gt; Entering new AgentExecutor chain...
Action: sql_db_list_tables
Action Input:
Observation: album, artist, customer, employee, genre, invoice, invoice_line, media_type, playlist, playlist_track, track
Thought: The table I need is playlist_track
Action: sql_db_schema
Action Input: playlist_track
Observation:
CREATE TABLE playlist_track (
[...]
&gt; Finished chain.
'The playlist_track table contains the playlist_id and track_id columns. It has a primary key of playlist_id and track_id. There is also a foreign key reference to the track and playlist tables. Sample rows include (1, 3402), (1, 3389), and (1, 3390).'
</code></pre>
<p class="normal">As you can see, with a simple question in natural language, our agent was able to understand its semantics, translate it into an SQL query, extract the relevant information, and use it as context to <a id="_idIndexMarker623"/>generate the response.</p>
<p class="normal">But how was it able to do all of<a id="_idIndexMarker624"/> that? Under the hood, the SQL agent comes with a default prompt template, which makes it tailored to this type of activity. Let’s see the default template of the LangChain component:</p>
<pre class="programlisting code"><code class="hljs-code">print(agent_executor.agent.llm_chain.prompt.template)
</code></pre>
<p class="normal">Here is the output obtained:</p>
<pre class="programlisting con"><code class="hljs-con">You are an agent designed to interact with a SQL database.
Given an input question, create a syntactically correct sqlite query to run, then look at the results of the query and return the answer.
Unless the user specifies a specific number of examples they wish to obtain, always limit your query to at most 10 results.
You can order the results by a relevant column to return the most interesting examples in the database.
Never query for all the columns from a specific table, only ask for the relevant columns given the question.
You have access to tools for interacting with the database.
Only use the below tools. Only use the information returned by the below tools to construct your final answer.
You MUST double check your query before executing it. If you get an error while executing a query, rewrite the query and try again.
DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.
If the question does not seem related to the database, just return "I don't know" as the answer.
sql_db_query: Input to this tool is a detailed and correct SQL query, output is a result from the database. If the query is not correct, an error message will be returned. If an error is returned, rewrite the query, check the query, and try again. If you encounter an issue with Unknown column 'xxxx' in 'field list', using sql_db_schema to query the correct table fields.
sql_db_schema: Input to this tool is a comma-separated list of tables, output is the schema and sample rows for those tables. 
Be sure that the tables actually exist by calling sql_db_list_tables first! Example Input: 'table1, table2, table3'
sql_db_list_tables: Input is an empty string, output is a comma separated list of tables in the database.
sql_db_query_checker: Use this tool to double check if your query is correct before executing it. Always use this tool before executing a query with sql_db_query!
Use the following format:
Question: the input question you must answer
Thought: you should always think about what to do
Action: the action to take, should be one of [sql_db_query, sql_db_schema, sql_db_list_tables, sql_db_query_checker]
Action Input: the input to the action
...
Question: {input}
Thought: I should look at the tables in the database to see what I can query.  Then I should query the schema of the most relevant tables.
{agent_scratchpad}
</code></pre>
<p class="normal">Thanks to this prompt template, the agent is able to use the proper tools and generate a SQL query, without modifying the underlying <a id="_idIndexMarker625"/>database (you can see the explicit rule not to run any <strong class="keyWord">data manipulation language</strong> (<strong class="keyWord">DML</strong>) statements).</p>
<div><p class="normal"><strong class="keyWord">Definition</strong></p>
<p class="normal">DML is a class of SQL statements that are used to query, edit, add, and delete row-level data from database tables or views. The main DML statements are as follows:</p>
<ul>
<li class="bulletList"><code class="inlineCode">SELECT</code>: This is used to retrieve data from one or more tables or views based on specified criteria.</li>
<li class="bulletList"><code class="inlineCode">INSERT</code>: This is used to insert new data records or rows into a table.</li>
<li class="bulletList"><code class="inlineCode">UPDATE</code>: This is used to modify the values of existing data records or rows in a table.</li>
<li class="bulletList"><code class="inlineCode">DELETE</code>: This is used to remove one or more data records or rows from a table.</li>
<li class="bulletList"><code class="inlineCode">MERGE</code>: This is used to combine the data from two tables into one based on a common column.</li>
<li class="bulletList">DML statements are used to store, modify, retrieve, delete, and update data in a database.</li>
</ul>
</div>
<p class="normal">We can also see how the agent is<a id="_idIndexMarker626"/> able to correlate more than one table <a id="_idIndexMarker627"/>within the database:</p>
<pre class="programlisting code"><code class="hljs-code">agent_executor.run('what is the total number of tracks and the average length of tracks by genre?')
</code></pre>
<p class="normal">From the first lines of the chain, you can see that <code class="inlineCode">Action Input</code> invokes two tables – track and genre:</p>
<pre class="programlisting code"><code class="hljs-code">&gt; Entering new AgentExecutor chain...
Action: sql_db_list_tables
Action Input:
Observation: album, artist, customer, employee, genre, invoice, invoice_line, media_type, playlist, playlist_track, track
Thought: I should look at the schema of the track and genre tables.
Action: sql_db_schema
Action Input: track, genre
[…]
</code></pre>
<p class="normal">The following is the output:</p>
<pre class="programlisting con"><code class="hljs-con">'The top 10 genres by track count and average track length are Rock (1297 tracks with an average length of 283910.04 ms), Latin (579 tracks with an average length of 232859.26 ms), Metal (374 tracks with an average length of 309749.44 ms), Alternative &amp; Punk (332 tracks with an average length of 234353.85 ms), Jazz (130 tracks with an average length of 291755.38 ms), TV Shows (93 tracks with an average length of 2145041.02 ms), Blues (81 tracks with an average length of 270359.78 ms), Classical (74 tracks with an average length of 293867.57 ms), Drama (64 tracks with an average length of 2575283.78 ms), and R&amp;B/Soul (61 tracks with an average length of 220066.85 ms).'
</code></pre>
<p class="normal">Now, the question is as follows: are we sure that we are getting the proper result? A nice way to double-check this<a id="_idIndexMarker628"/> would be to print the SQL query that the agent ran against the <a id="_idIndexMarker629"/>database. To do so, we can modify the default prompt to ask the agent to explicitly show us the reasoning behind its result.</p>
<h2 class="heading-2" id="_idParaDest-120">Prompt engineering</h2>
<p class="normal">As we saw in the previous chapter, pre-built LangChain agents and chains come with default prompts, which make it easier to<a id="_idIndexMarker630"/> tailor them toward their goals. Nevertheless, we can customize that prompt and pass it as a parameter to our component. For example, let’s say that we want our SQL agent to print the SQL query it used to return the result.</p>
<p class="normal">First of all, we have to understand which kind of prompt chunks the SQL Agent is able to take as parameters. To do so, we can simply inspect the objects running <code class="inlineCode">create_sql_agent</code>.</p>
<figure class="mediaobject"><img alt="" role="presentation" src="img/B21714_08_06.png"/></figure>
<p class="packt_figref">Figure 8.6: A screenshot of the description of the SQL agent</p>
<p class="normal">The Agent takes a prompt prefix and a format instruction, which are merged and constitute the default prompt we<a id="_idIndexMarker631"/> inspected in the previous section. To make our agent more self-explanatory, we will create two variables, <code class="inlineCode">prefix</code> and <code class="inlineCode">format_instructions</code>, which will be passed as parameters and that slightly modify the default prompt as follows (you can find the whole prompts in the GitHub repository at <a href="Chapter_08.xhtml">https://github.com/PacktPublishing/Building-LLM-Powered-Applications</a><a href="https://github.com/PacktPublishing/Building-Large-Language-Model-Applications"/>:</p>
<ul>
<li class="bulletList">We have the <code class="inlineCode">prompt_prefix</code>, which is already configured as follows:
        <pre class="programlisting code-one"><code class="hljs-code">prefix: 'str' = 'You are an agent designed to interact with a SQL database.\nGiven an input question, create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer.\nUnless the user specifies a specific number of examples they wish to obtain, always limit your query to at most {top_k} results.\nYou can order the results by a relevant column to return the most interesting examples in the database.\nNever query for all the columns from a specific table, only ask for the relevant columns given the question.\nYou have access to tools for interacting with the database.\nOnly use the below tools. Only use the information returned by the below tools to construct your final answer.\nYou MUST double check your query before executing it. If you get an error while executing a query, rewrite the query and try again.\n\nDO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\n\nIf the question does not seem related to the database, just return "I don\'t know" as the answer.\n',
</code></pre>
</li>
</ul>
<p class="normal-one">To this, we will add the following line of instruction:</p>
<pre class="programlisting code-one"><code class="hljs-code">As part of your final answer, ALWAYS include an explanation of how to got to the final answer, including the SQL query you run. Include the explanation and the SQL query in the section that starts with "Explanation:".
</code></pre>
<ul>
<li class="bulletList">In <code class="inlineCode">prompt_format_instructions</code>, we<a id="_idIndexMarker632"/> will add the following example of explanation using few-shot learning, which we covered in <em class="chapterRef">Chapter 1</em>:
        <pre class="programlisting code-one"><code class="hljs-code">Explanation:
&lt;===Beginning of an Example of Explanation:
I joined the invoices and customers tables on the customer_id column, which is the common key between them. This will allowed me to access the Total and Country columns from both tables. Then I grouped the records by the country column and calculate the sum of the Total column for each country, ordered them in descending order and limited the SELECT to the top 5.
```sql
SELECT c.country AS Country, SUM(i.total) AS Sales
FROM customer c
JOIN invoice i ON c.customer_id = i.customer_id
GROUP BY Country
ORDER BY Sales DESC
LIMIT 5;
```sql
===&gt;End of an Example of Explanation
</code></pre>
</li>
</ul>
<p class="normal">Now, let’s pass those prompt chunks as parameters to our agent and print the result (I will omit the whole chain here, but you can see it in the GitHub repository):</p>
<pre class="programlisting code"><code class="hljs-code">agent_executor = create_sql_agent(
    prefix=prompt_prefix,
    format_instructions = prompt_format_instructions,
    llm=llm,
    toolkit=toolkit,
    verbose=True,
    top_k=10
)
result = agent_executor.run("What are the top 5 best-selling albums and their artists?")
print(result)
</code></pre>
<p class="normal">Here is the obtained<a id="_idIndexMarker633"/> output:</p>
<pre class="programlisting con"><code class="hljs-con">The top 5 best-selling albums and their artists are 'A Matter of Life and Death' by Iron Maiden, 'BBC Sessions [Disc 1] [live]' by Led Zeppelin, 'MK III The Final Concerts [Disc 1]' by Deep Purple, 'Garage Inc. (Disc 1)' by Metallica and 'Achtung Baby' by U2.
Explanation: I joined the album and invoice tables on the album_id column and joined the album and artist tables on the artist_id column. This allowed me to access the title and artist columns from the album table and the total column from the invoice table. Then I grouped the records by the artist column and calculated the sum of the Total column for each artist, ordered them in descending order and limited the SELECT to the top 5.
```sql
SELECT al.title AS Album, ar.name AS Artist, SUM(i.total) AS Sales
FROM album al
JOIN invoice i ON al.album_id = i.invoice_id
JOIN artist ar ON al.artist_id = ar.artist_id
GROUP BY ar.name
ORDER BY Sales
</code></pre>
<p class="normal">Now, in our result, we have a clear explanation of the thought process as well as the printed query our agent made for us. This is key if we want to double-check the correctness of the reasoning procedure happening in the backend of our agent.</p>
<p class="normal">This is already extremely useful, but we want to bring it to the next level: we want our DBCopilot to also be able to generate graphs and save results in our local file system. To achieve this goal, we need to add tools to our agent, and we are going to do so in the next section.</p>
<h2 class="heading-2" id="_idParaDest-121">Adding further tools</h2>
<p class="normal">In order to make our DBCopilot more versatile, there are two further capabilities we need to add:</p>
<ul>
<li class="bulletList"><strong class="keyWord">PythonREPLTool</strong>: This tool allows you to interact with the Python programming language using natural language. You can use this tool to write, run, and debug Python code <a id="_idIndexMarker634"/>without having to use a script file or an IDE. You can also use this tool to access and manipulate various Python modules, libraries, and data structures.<strong class="keyWord"> We will need this tool to produce the matplotlib graphs from the SQL query’s results.</strong></li>
</ul>
<div><p class="normal"><strong class="keyWord">Definition</strong></p>
<p class="normal">REPL is an acronym for read-eval-print loop, which is <a id="_idIndexMarker635"/>a term that describes an interactive shell or environment that allows you to execute code and see the results immediately. REPL is a common feature of many programming languages, such as Python, Ruby, and Lisp.</p>
<p class="normal">In the context of LangChain, REPL is a feature that allows you to interact with LangChain agents and tools using natural language. You can use REPL in LangChain to test, debug, or experiment with different agents and tools without having to write and run a script file. You can also use REPL in LangChain to access and manipulate various data sources, such as databases, APIs, and web pages.</p>
</div>
<ul>
<li class="bulletList"><strong class="keyWord">FileManagementToolkit</strong>: This is a set of tools, or toolkit, that allows you to interact with the file system of your computer or device using natural language. You can use this toolkit to<a id="_idIndexMarker636"/> perform various operations on files and directories, such as creating, deleting, renaming, copying, moving, searching, reading, and writing. You can also use this toolkit to access and manipulate the metadata and attributes of files and directories, such as name, size, type, date, and permissions.</li>
</ul>
<p class="normal-one">We will need this toolkit to save the graphs generated by our agent in our working directory.</p>
<p class="normal">Now, let’s see how we can add these<a id="_idIndexMarker637"/> tools to our DBCopilot:</p>
<ol>
<li class="numberedList" value="1">First, we define the list of tools for our agent:
        <pre class="programlisting code-one"><code class="hljs-code">from  langchain_experimental.tools.python.tool import PythonREPLTool
from  langchain_experimental.python import PythonREPL
from langchain.agents.agent_toolkits import FileManagementToolkit
working_directory  = os.getcwd()
tools = FileManagementToolkit(
    root_dir=str(working_directory),
    selected_tools=["read_file", "write_file", "list_directory"],).get_tools()
tools.append(
    PythonREPLTool())
tools.extend(SQLDatabaseToolkit(db=db, llm=llm).get_tools())
</code></pre>
</li>
<li class="numberedList">In order to leverage that heterogeneous set of tools – SQL Database, Python REPL, and File System (<a href="https://python.langchain.com/v0.1/docs/integrations/tools/filesystem/">https://python.langchain.com/v0.1/docs/integrations/tools/filesystem/</a>) – we cannot work anymore with the SQL Database-specific agent, since its default configurations are meant to only accept SQL-related contents. Henceforth, we need to set up an agnostic agent that is able to use all of the tools that we provide it with. For this purpose, we are going to use the <code class="inlineCode">STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION</code> agent type, which is able to use a multi-tool input.</li>
</ol>
<p class="normal-one">Let’s first start with initializing the agent and asking it to produce a bar chart and save it in the current working directory for the top five countries for sales (note that, for this purpose, I’ve used a chat model as best suited for the type of agent in use):</p>
<pre class="programlisting code-one"><code class="hljs-code">from langchain.chat_models import ChatOpenAI
from langchain.agents import initialize_agent, Tool
from langchain.agents import AgentType
model = ChatOpenAI()
agent = initialize_agent(
    tools, model, agent= AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION, verbose=True
)
agent.run("generate a matplotlib bar chart of the top 5 countries for sales from the chinook database. Save the output in the current working directory as figure.png")
</code></pre>
<p class="normal-one">We then receive the following output, showing how, in this case, the agent was also able to dynamically orchestrate the available tools to generate the final answer (I will report here<a id="_idIndexMarker638"/> just the main actions of the chain – you can see the whole code in the GitHub repository of the book):</p>
<pre class="programlisting con-one"><code class="hljs-con">&gt; Entering new AgentExecutor chain...
Action:
```
{
  "action": "sql_db_query",
  "action_input": "SELECT billing_country as Country, SUM(total) as Sales FROM invoices GROUP BY billing_country ORDER BY Sales DESC LIMIT 5"
}
```
[…]
Observation: [('USA', 10405.889999999912), ('Canada', 5489.549999999994), ('Brazil', 4058.999999999997), ('France', 3972.869999999995), ('Germany', 3441.2399999999925)]
[…]
We have successfully retrieved the top 5 countries for sales. We can now use matplotlib to create a bar chart.
Action:
```
{
  "action": "Python_REPL",
  "action_input": "import matplotlib.pyplot as plt\nsales_data = [('USA', 10405.89), ('Canada', 5489.55), ('Brazil', 4059.0), ('France', 3972.87), ('Germany', 3441.24)]\n\nx = [item[0] for item in sales_data]\ny = [item[1] for item in sales_data]\nplt.bar(x, y)\nplt.xlabel('Country')\nplt.ylabel('Sales')\nplt.title('Top 5 Countries for Sales')\nplt.show()"
}
```
[…]
&gt; Finished chain.
'Here is the bar chart of the top 5 countries for sales from the Chinook database. It has been saved as figure.png in the current working directory. '
</code></pre>
<p class="normal-one">The following is the generated chart of the top five countries by sales, as requested:</p>
<figure class="mediaobject"><img alt="A graph of blue bars  Description automatically generated" src="img/B21714_08_07.png"/></figure>
<p class="packt_figref">Figure 8.7: Bar chart of top five countries by sales</p>
<p class="normal">Great! The agent was able to first invoke<a id="_idIndexMarker639"/> the SQL tool to retrieve the relevant information, then it used the Python tool to generate the <code class="inlineCode">matplotlib</code> bar chart. Then, it used the file system tool to save the result as PNG.</p>
<p class="normal">Also, in this case, we can modify the prompt of the agent. For example, we might want the agent to provide an explanation not <a id="_idIndexMarker640"/>only of the SQL query but also of the Python code. To do so, we need to define the <code class="inlineCode">prompt_prefix</code> and <code class="inlineCode">prompt_format_instructions</code> variables to be passed as <code class="inlineCode">kgwargs</code> to the agent as follows:</p>
<pre class="programlisting code"><code class="hljs-code">prompt_prefix = """ Your prefix here
"""
prompt_format_instructions= """
Your instructions here.
"""
agent = initialize_agent(tools, model, agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION, verbose = True,
                         agent_kwargs={
                            'prefix':prompt_prefix,
                            'format_instructions': prompt_format_instructions })
</code></pre>
<p class="normal">Thanks to LangChain’s tools components, we were able to extend our DBCopilot capabilities and make it more versatile, depending upon the user’s query.</p>
<p class="normal">With the same logic, we can tailor our agents to any domain, adding or removing tools so that we can control its perimeter of actions. Plus, thanks to the prompt customization, we can always refine the agent’s backend logic to make it more customized.</p>
<h1 class="heading-1" id="_idParaDest-122">Developing the front-end with Streamlit</h1>
<p class="normal">Now that we have seen the logic<a id="_idIndexMarker641"/> behind an LLM-powered DBCopilot, it is time to give a GUI to our application. To do so, we <a id="_idIndexMarker642"/>will once again leverage Streamlit. As always, you can find the whole Python code in the GitHub book repository at <a href="Chapter_08.xhtml">https://github.com/PacktPublishing/Building-LLM-Powered-Applications</a>.</p>
<p class="normal">As per the previous sections, you need to create a <code class="inlineCode">.py</code> file to run in your terminal via <code class="inlineCode">streamlit run file.py</code>. In our case, the file will be named <code class="inlineCode">dbcopilot.py</code>.</p>
<p class="normal">Here are the main steps to set up the frontend:</p>
<ol>
<li class="numberedList" value="1">Configure the application web page:
        <pre class="programlisting code-one"><code class="hljs-code">import streamlit as st
st.set_page_config(page_title="DBCopilot", page_icon="<img alt="" role="presentation" src="img/Icon.png"/>")
st.header('<img alt="" role="presentation" src="img/Icon.png"/> Welcome to DBCopilot, your copilot for structured databases.')
</code></pre>
</li>
<li class="numberedList">Import the credentials<a id="_idIndexMarker643"/> and establish the connection with the Chinook database:
        <pre class="programlisting code-one"><code class="hljs-code">load_dotenv()
#os.environ["HUGGINGFACEHUB_API_TOKEN"]
openai_api_key = os.environ['OPENAI_API_KEY']
db = SQLDatabase.from_uri('sqlite:///chinook.db')
</code></pre>
</li>
<li class="numberedList">Initialize the LLM and<a id="_idIndexMarker644"/> the toolkit:
        <pre class="programlisting code-one"><code class="hljs-code">llm = OpenAI()
toolkit = SQLDatabaseToolkit(db=db, llm=llm)
</code></pre>
</li>
<li class="numberedList">Initialize the Agent using the prompt variables defined in the previous sections:
        <pre class="programlisting code-one"><code class="hljs-code">agent_executor = create_sql_agent(
    prefix=prompt_prefix,
    format_instructions = prompt_format_instructions,
    llm=llm,
    toolkit=toolkit,
    verbose=True,
    top_k=10
)
</code></pre>
</li>
<li class="numberedList">Define Streamlit’s session states to make it conversational and memory aware:
        <pre class="programlisting code-one"><code class="hljs-code">if "messages" not in st.session_state or st.sidebar.button("Clear message history"):
    st.session_state["messages"] = [{"role": "assistant", "content": "How can I help you?"}]
for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])
</code></pre>
</li>
<li class="numberedList">Finally, define the logic of the application whenever a user makes a query:
        <pre class="programlisting code-one"><code class="hljs-code">if user_query:
    st.session_state.messages.append({"role": "user", "content": user_query})
    st.chat_message("user").write(user_query)
    with st.chat_message("assistant"):
        st_cb = StreamlitCallbackHandler(st.container())
        response = agent_executor.run(user_query, callbacks = [st_cb], handle_parsing_errors=True)
        st.session_state.messages.append({"role": "assistant", "content": response})
        st.write(response)
</code></pre>
</li>
</ol>
<p class="normal">You can run<a id="_idIndexMarker645"/> your application<a id="_idIndexMarker646"/> in the terminal with the <code class="inlineCode">streamlit run copilot.py</code> command. The final web page looks as follows:</p>
<figure class="mediaobject"><img alt="A screenshot of a computer  Description automatically generated" src="img/B21714_08_08.png"/></figure>
<p class="packt_figref">Figure 8.8: Screenshot of the front-end of DBCopilot</p>
<p class="normal">Thanks to<a id="_idIndexMarker647"/> the <code class="inlineCode">StreamlitCallbackHandler</code> module, we<a id="_idIndexMarker648"/> can also expand each action the agent took, for example:</p>
<figure class="mediaobject"><img alt="A screenshot of a computer  Description automatically generated" src="img/B21714_08_09.png"/></figure>
<p class="packt_figref">Figure 8.9: Illustration of the agent’s actions during the chain</p>
<p class="normal">With just a few lines of code, we<a id="_idIndexMarker649"/> were able to set up a simple<a id="_idIndexMarker650"/> front-end for our DBCopilot with a conversational user interface.</p>
<h1 class="heading-1" id="_idParaDest-123">Summary</h1>
<p class="normal">In this chapter, we saw how LLMs are not only capable of interacting with textual and unstructured data, but also with structured and numeric data. This is made possible because of two main elements: the natural capabilities of LLMs and, more generally, LFMs for understanding a problem’s statement, planning a resolution, and acting as reasoning engines, as well as a set of tools that extend LLMs’ capabilities with domain-specific skills.</p>
<p class="normal">In this case, we mainly relied upon LangChain’s SQL Database toolkit, which connects the Agent to an SQL database with a curated prompt. Furthermore, we extended the Agent’s capabilities even further, making it able to generate matplotlib graphs, with the Python REPL tool, and save the output to our local file system with the File Management tool.</p>
<p class="normal">In the next chapter, we are going to delve even deeper into the analytical capabilities of LLMs. More specifically, we are going to cover their capabilities of working with code.</p>
<h1 class="heading-1" id="_idParaDest-124">References</h1>
<ul>
<li class="bulletList">Chinook Database: <a href="https://github.com/lerocha/chinook-database/tree/master/ChinookDatabase/DataSources">https://github.com/lerocha/chinook-database/tree/master/ChinookDatabase/DataSources</a></li>
<li class="bulletList">LangChain File system tool: <a href="https://python.langchain.com/docs/integrations/tools/filesystem">https://python.langchain.com/docs/integrations/tools/filesystem</a></li>
<li class="bulletList">LangChain Python REPL tool: <a href="https://python.langchain.com/docs/integrations/toolkits/python">https://python.langchain.com/docs/integrations/toolkits/python</a></li>
</ul>
<h1 class="heading-1">Join our community on Discord</h1>
<p class="normal">Join our community’s Discord space for discussions with the author and other readers:</p>
<p class="normal"><a href="https://packt.link/llm ">https://packt.link/llm</a></p>
<p class="normal"><img alt="" role="presentation" src="img/QR_Code214329708533108046.png"/></p>
</div>
</body></html>