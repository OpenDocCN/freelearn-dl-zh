- en: '2'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Building the Generative AI Controller
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A **generative AI system** (**GenAISys**)’s controller requires two key components:
    a **conversational agent** and an **orchestrator**. The conversational agent—powered
    by a generative AI model—interacts with human users and system processes. The
    orchestrator, on the other hand, is a set of generative AI and non-AI functions,
    such as managing user roles, content generation, activating machine learning algorithms,
    and running classical queries. We need both to build a functional GenAISys.'
  prefs: []
  type: TYPE_NORMAL
- en: If we examine this architecture closely, we’ll see that software orchestrators
    and user interfaces date back to the first computers. Any operating system, with
    even basic functionality, has orchestrators that trigger disk space alerts, memory
    usage, and hundreds of other functions. Today’s user interfaces are intuitive
    and have event-driven functionality, but at a high level, the underlying architecture
    of a GenAISys still echoes decades of software design principles. So, what sets
    a classical software controller apart from a GenAISys controller?
  prefs: []
  type: TYPE_NORMAL
- en: 'We can sum up the difference in one word: *adaptability*. In a classical software
    controller, a sequence of tasks is more or less hardcoded. But in a GenAISys,
    the user interface is a conversational AI agent that is flexible, and the generative
    AI model behind it is pre-trained to respond to a wide range of requests with
    no additional coding. Furthermore, the orchestrator isn’t locked into static flows
    either; it can modify the tasks it triggers based on the user (human or system)
    prompts.'
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we’ll take a hands-on approach to building a custom GenAISys
    based on the architecture of a GenAISys defined in the previous chapter. We’ll
    begin by defining the structure of our AI controller in Python, breaking it into
    two parts—the conversational agent and the orchestrator—and exploring how the
    two interact. Then, we’ll build the conversational agent using GPT-4o. We’ll automate
    the contextual awareness and memory retention features from [*Chapter 1*](Chapter_1.xhtml#_idTextAnchor021).
    Our system will support both short-term and long-term memory, as well as multi-user
    and cross-session capabilities—pushing it beyond what standard copilots typically
    offer.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we will build the structure of an AI controller to interpret user input
    and trigger a response scenario. The response will be a sentiment analysis or
    a semantic (hard science) analysis, depending on the context of what the AI controller
    will analyze and manage. Our custom GenAISys will lay the groundwork for domain-specific
    RAG, something a standard ChatGPT-grade system can’t offer when you’re working
    with large volumes of data, especially in cases of daily dataset updates, such
    as the daily sales of a product or service. By the end of this chapter, you’ll
    know how to build the foundations of a GenAISys AI controller that we will enhance
    throughout the book.
  prefs: []
  type: TYPE_NORMAL
- en: 'To sum up, this chapter covers the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Architecture of the AI controller
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Architecture of an AI conversational agent and its workflow
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing the storage of short- and long-term memory sessions in code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Architecture of an AI orchestrator and the intent functionality
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a GenAI scenario library containing instruction scenarios
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Processing an input with vector search to orchestrate instructions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Processing an input with a GPT-4o analysis to orchestrate instructions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Selecting and executing tasks based on the input with the multipurpose orchestrator
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s begin by defining the architecture of the AI controller.
  prefs: []
  type: TYPE_NORMAL
- en: Architecture of the AI controller
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We’ll continue to implement the architecture of GenAISys as we’ve defined in
    *Figure 1.1* from [*Chapter 1*](Chapter_1.xhtml#_idTextAnchor021). *Figure 2.1*,
    on the other hand, takes us further into the underlying functions of a GenAISys.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.1: Defining the functions to build](img/B32304_02_1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.1: Defining the functions to build'
  prefs: []
  type: TYPE_NORMAL
- en: We established in the previous chapter that human roles are essential, and the
    preceding figure acknowledges that fact. We are the core of a GenAISys, no matter
    how advanced the building blocks (models or frameworks) are. Our first task is
    designing using our human creativity to find effective ways to implement a GenAISys
    controller. GenAISys needs human creativity, judgment, and technical decision-making.
    Under the hood of seamless copilots such as ChatGPT, Gemini, and Microsoft Copilot
    lie intricate layers of AI and non-AI logic. If we want to build our own ChatGPT-like
    system, we humans need to do the heavy lifting!
  prefs: []
  type: TYPE_NORMAL
- en: 'We will build two separate programs:'
  prefs: []
  type: TYPE_NORMAL
- en: A **conversational agent** implemented with GPT-4o, which supports both short-
    and long-term memory. This will help us enforce contextual awareness across multiple
    exchanges. It aligns with function **F3** in *Figure 2.1*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An **AI controller orchestrator** that will also use GPT-4o to analyze the user
    input, search a library of instructions, augment the input with the appropriate
    instructions, and run the function(s) in the instructions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In this chapter, we’ll focus on two scenarios: sentiment analysis and semantic
    (hard science) analysis, which correspond to functions **F1** and **F2** in our
    architecture. Functions **F4** and **F5** will be added in [*Chapter 3*](Chapter_3.xhtml#_idTextAnchor085).'
  prefs: []
  type: TYPE_NORMAL
- en: Although these examples are built for OpenAI’s API, the logic is model-agnostic.
    Once you understand how it works, you can adapt the code to use any LLM—such as
    Meta’s Llama, xAI’s Grok, Google’s Gemini, or Cohere.
  prefs: []
  type: TYPE_NORMAL
- en: Once we’ve built the conversational agent and controller orchestrator programs
    separately, we will merge them into a unified intelligence AI controller, as shown
    in *Figure 2.2*.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.2: Next steps—integrating the AI controller functions through a
    Pinecone vector store](img/B32304_02_2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.2: Next steps—integrating the AI controller functions through a Pinecone
    vector store'
  prefs: []
  type: TYPE_NORMAL
- en: For now, we need to focus on building each component individually so we can
    fully understand their behavior. Once that foundation is in place, in [*Chapter
    3*](Chapter_3.xhtml#_idTextAnchor085), we will merge them through a Pinecone vector
    store. Let’s now dive straight down into code and begin developing the conversational
    agent.
  prefs: []
  type: TYPE_NORMAL
- en: Conversational AI agent
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Our two primary goals for this section are to build a conversational AI agent
    with the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Short-term memory retention** for a full ChatGPT-like conversational loop.
    The user and agent can have as many exchanges as they wish; there is no limit
    to the number of interactions between them.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Long-term memory retention** across multiple users and sessions. We’ll store
    in-memory sessions and persist them to a memory storage (in this case, a text
    file). This will enable multi-user contextual awareness for users such as John,
    Myriam, and Bob. Our conversational agent will move beyond classic one-to-one
    ChatGPT-style dialogues toward a custom GenAISys capable of handling multi-session,
    multi-user interactions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To get started, open `Conversational_AI_Agent.ipynb` in this chapter’s GitHub
    directory ([https://github.com/Denis2054/Building-Business-Ready-Generative-AI-Systems/tree/main](https://github.com/Denis2054/Building-Business-Ready-Generative-AI-Systems/tree/main)).
    This notebook will guide you through the environment setup.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up the environment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We’ll reuse the setup process from the previous chapter. If you need a refresher,
    feel free to revisit that section. Start by installing OpenAI and downloading
    the required files:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'We’ll also need to download two additional functions to build our conversational
    agent:'
  prefs: []
  type: TYPE_NORMAL
- en: '`download("commons","conversational_agent.py")`: This contains the functions
    to manage a full-turn conversation loop and memorize the dialogue.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`download("commons", "processing_conversations.py")`: This contains tools to
    load, display, and cleanse past conversations to increase the memory span of the
    conversational agent across several sessions and users. This custom multisession,
    multi-user feature goes beyond the scope of standard ChatGPT-like copilots.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s now move on to implementing the functions in `conversational_agent.py`,
    which we’ll call throughout our sessions with the conversational AI agent.
  prefs: []
  type: TYPE_NORMAL
- en: Conversational AI agent workflow
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The conversation AI agent contains two main parts:'
  prefs: []
  type: TYPE_NORMAL
- en: Starting the initial conversation to initiate a dialogue with the AI agent
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running the full-turn conversation loop to continue as many in-memory exchanges
    as a user wishes with the AI agent. At the end of each session, the dialog is
    saved so it can be resumed later—by the same user or another.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Starting the initial conversation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The initial conversation marks the entry point for a new session. It’s handled
    by the AI controller and illustrated in *Figure 2.3*.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.3: The initial conversation controller](img/B32304_02_3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.3: The initial conversation controller'
  prefs: []
  type: TYPE_NORMAL
- en: We will go through each step of the initial conversation with the generative
    AI model to understand in detail how a small-scale ChatGPT-like conversational
    agent works. The 10-step process begins with *Start*.
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Starting the conversation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The program begins at this entry point through the `run_conversational_agent`
    function in `openai_api.py`, which will be called in the notebook by `conversational_agent`
    and its parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The parameters the conversational agent will process in this case are the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`uinput`: Contains the input (user or system), for example, `Where is Hawaii?`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mrole`: Defines the role of the message. It can be `user` or `system`. You
    can also assign other roles that the API will interpret, such as defining the
    AI’s persona, for example, `You are a geology expert`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mcontent`: Is what we expect the system to be, for example, `You are a geology
    expert`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`user_role`: Defines the role of the user, for example, `user`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`user_name`: The name of the user, for example, `John`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 2–3\. Initializing API variables and the messages object
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '`messages_obj` is initialized with the parameters of the conversation described
    in the previous step, *Starting the conversation*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '`messages_obj` is focusing on the memory of the system. This object will be
    appended as long as the session lasts with the exchanges with the GPT-4o model.
    It will be used to log conversations between sessions. The first message contains
    the role and content for setting up the agent’s context.'
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Printing a welcome message
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The system is now ready to interact with users. The agent first displays a
    welcome message and explains how to exit the system once the conversation is over:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 5\. Handling the initial user input
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The user’s initial input is added to `messages_obj` to provide the agent with
    memory and provide the direction the agent is expected to follow. The initial
    user input will be sent from the conversational agent:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 6\. Cleansing the initial conversation log
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '`messages_obj` holds the conversation’s history in a structured format. For
    certain operations within our application, such as generating a simplified display,
    creating a consolidated log entry, or preparing input for a text-based function,
    we need to convert this structured log into a single, continuous string. This
    makes sure that the data is in the correct format for these specific tasks and
    helps resolve any potential punctuation or formatting quirks that might arise
    when combining the different message parts:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The cleansing function cleans the conversation and returns a string:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 7\. Making the initial API call
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The cleansed conversation string is sent to the API for processing. The API
    provides a response based on the last input and the conversation history. The
    system now has a memory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 8\. Appending the initial API response
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The assistant’s response from the API is processed and appended to `messages_obj`.
    We are continuing to increase the system’s memory and, thus, its contextual awareness:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 9\. Displaying the initial assistant’s response
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The system’s response is displayed for the user to analyze and decide whether
    to continue or exit the session:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 10\. Starting the conversation loop
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The system now enters the conversation loop, where multiple dialogue turns
    can take place until the user decides to exit the session:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: We are now ready to begin a full-turn conversation loop.
  prefs: []
  type: TYPE_NORMAL
- en: The full-turn conversation loop
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The initial conversation is now initialized. We will enter the full-turn conversation
    loop starting from *step 11* onward, as illustrated in *Figure 2.4*.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.4: The conversation loop starting from step 11](img/B32304_02_4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.4: The conversation loop starting from step 11'
  prefs: []
  type: TYPE_NORMAL
- en: 11\. Prompting for the user input
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The conversation continues the initial dialogue and is memorized through the
    `messages` object. The user prompt triggers a full-turn conversation loop. The
    first step is to enter the user’s name. This custom takes us beyond the standard
    ChatGPT-like conversational agents that are limited to one user per session. We
    are initializing a multi-user conversation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 12\. Checking the Exit condition
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'If `q` or `quit` is entered, the session is ended:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 13\. Appending the user input to the messages object
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The system is now equipped with a memory of a full-turn conversation loop.
    It uses the generic API format we defined. The user’s input is appended to `messages_obj`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 14\. Cleansing the conversation log (loop)
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The updated `messages_obj` is cleansed to make sure it complies with the API
    calls, as in *step 6*, *Cleansing the initial conversation log*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 15\. Making the API call in the conversation loop
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In this full-turn conversation loop, the whole conversation is sent to the
    API. The API will thus return a response based on the context of the whole conversation
    and the new input:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 16\. Appending the API response in the conversation loop
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The API’s response is appended to `messages_obj` at each conversation turn:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 17\. Displaying the assistant’s response
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The API response is displayed at each conversation turn in the loop:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 18\. Exiting and saving the conversation log
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'When a user exits the loop, the conversation is saved. This feature will replicate
    a ChatGPT-like platform that can save dialogue between two sessions with the same
    user. However, as we will see in our implementation of a conversational agent
    in the *Running the conversational agent* section, our program will be able to
    save a multi-user session in a conversation between team members:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 19\. End
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The conversational agent terminates the session after memorizing the conversation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: We have explored the conversational agent’s functionality.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s move on to the AI conversational agent program that represents an
    AI controller.
  prefs: []
  type: TYPE_NORMAL
- en: Running the conversational AI agent
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The main program, `Conversational_AI_Agent.ipynb`, calls the necessary functions
    from `conversational_agent.py` to handle AI interactions. We will be running a
    conversation through three user sessions with this scenario:'
  prefs: []
  type: TYPE_NORMAL
- en: John begins with a short-term memory session with the conversational AI agent.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: John’s conversation will be saved in a log file when the session is over.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Myriam resumes the session using that same log file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Myriam’s conversation will be saved in the same log file as John’s when the
    session is over.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Bob will pick up where John and Myriam left off.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Bob’s conversation will be saved in the same log file as John’s and Myriam’s
    when the session is over.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'All three users interact in successive sessions. In [*Chapter 3*](Chapter_3.xhtml#_idTextAnchor085),
    we’ll go further by grouping users through a Pinecone vector store so that multiple
    users can participate together in a session in real time. For the moment, let’s
    walk through this multi-user setup step by step and see how the conversational
    AI agent handles these sessions. Let’s begin with the first step: John’s short-term
    memory session.'
  prefs: []
  type: TYPE_NORMAL
- en: Short-term memory session
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The session begins with the parameters described in *step 1*, *Starting the
    conversation*, of the conversational agent:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'We are also adding the name of the user like in a ChatGPT-like session:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: This simple addition—`user_name`—is what takes our GenAISys beyond standard
    ChatGPT-like platforms. It allows us to associate memory with specific users and
    expand into multi-user conversations within a single system.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will now import the first function, the OpenAI API functionality, to make
    a request to OpenAI’s API, as described in [*Chapter 1*](Chapter_1.xhtml#_idTextAnchor021):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The program now imports the second function, the conversational agent, and
    runs it as described earlier in this section:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s go through each step of the dialog implemented with our two functions.
    The agent first welcomes us:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'John, the first user, asks for a geological explanation about Hawaii:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'The agent provides a satisfactory answer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'John now asks about surfing “there”:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Thanks to the memory we built into the agent, it now has contextual awareness
    through memory retention. The agent correctly responds about surfing in Hawaii:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'John now asks about the best places to stay without mentioning Hawaii:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'The agent answers correctly using contextual awareness:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'John then quits the session:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'The agent exits the conversation and saves the dialogue in a conversation log:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: The short-term session ends, but thanks to memory retention via `conversation_log.txt`,
    we can easily pick up from where John left off. We can thus continue the dialogue
    immediately or at a later time, leveraging memory retention through the `conversation_log.txt`
    file that was automatically generated.
  prefs: []
  type: TYPE_NORMAL
- en: Long-term memory session
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The short-term session is saved. We have three options:'
  prefs: []
  type: TYPE_NORMAL
- en: Stop the program now. In this case, `conversation_log.txt` will only contain
    John’s session, which can be continued or not.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Decide to initialize a separate `conversation_log.txt` for the next user, Myriam.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Continue with a multi-user session by loading John’s conversation into Myriam’s
    initial dialog context.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The program in this chapter chooses to continue a multi-session, multi-user
    scenario.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first step to continue the conversation with John is to load and display
    the conversation log using the function in `processing_conversations.py` that
    we downloaded in the *Setting up the environment* section. We now import and run
    the function that we need to load and display the conversation log:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'The function is a standard `IPython` process using HTML functionality that
    reads and displays the conversation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'The output displays each participant in the conversation, beginning with the
    system’s information, followed by John’s request, and then the GPT-4o assistant’s
    response at each turn:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Before adding the conversation to the context of the next input, we will clean
    and prepare it. To achieve this, we successively import `cleanse_conversation_log`
    and import `initialize_uinput` from `processing_conversations.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we will call the two Python functions that we defined to cleanse and
    then prepare the new input:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'The `cleanse` function removes punctuation and potentially problematic characters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we initialize the new input:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'The output confirms that the conversation log has been cleansed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, the output confirms that `nuinput` contains the conversation log for
    continuation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: Continuing the previous session
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'We can now continue the conversation that John began with `nuinput` as the
    memory retention variable for contextual awareness. We will add the context, `nuinput`,
    to Myriam’s request using the message variables as before:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'The message call contains two key features:'
  prefs: []
  type: TYPE_NORMAL
- en: '`ninput = nuinput+ [user input]`, which shows that the AI controller now has
    a long-term memory that goes beyond a single session'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`user_name = "Myriam"`, which shows the multi-user feature, proving that our
    custom small-scale ChatGPT-like AI controller has more flexibility than a standard
    copilot'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The overall process is the same as with John. Myriam asks a question:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'The agent responds:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Myriam quits:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'The agent confirms that the conversation has ended and is saved to the conversation
    log:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: The AI controller now has a log of John’s session and Myriam’s continuation
    of the session. The controller can take this further and add yet another user
    to the conversation.
  prefs: []
  type: TYPE_NORMAL
- en: Continuing the long-term multi-user memory
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Let’s add Bob to the mix to continue the conversation. First, display the conversation
    log again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'You’ll see entries for both John and Myriam:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'The log is then cleansed and prepared for the next turn of the conversation
    as previously. `nuinput` now contains John and Myriam’s sessions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'Bob is focused on the geological mission, not leisure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'The AI agent provides an accurate response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Bob then quits the session:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'The agent exits the conversation and saves it in the conversation log:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: With these three scenarios, we have implemented a conversational agent managed
    by the AI controller in a multi-user full-turn conversational loop. Let’s examine
    the next steps for this conversational agent.
  prefs: []
  type: TYPE_NORMAL
- en: Next steps
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: At this point, we have the basic structure of a conversational agent. We need
    to integrate it into an AI controller orchestrator. Let’s sum up the work we did
    for the conversational agent before beginning to build the AI controller orchestrator.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.5: The cycle of a conversational agent loop](img/B32304_02_5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.5: The cycle of a conversational agent loop'
  prefs: []
  type: TYPE_NORMAL
- en: 'As illustrated in the preceding figure, the AI conversation agent does the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: The agent processes the input (system or human user).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The agent responds.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The memory retention function is activated.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The conversation is added to the following input as context.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The user can quit.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: However, the entry/exit point is incomplete. We can enter and exit the conversation
    but cannot call functions to orchestrate tasks such as activating sentiment analysis
    and semantic analysis. To complete the architecture of the AI controller, we need
    to begin building the AI controller orchestrator.
  prefs: []
  type: TYPE_NORMAL
- en: AI controller orchestrator
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we will build the first component of our AI controller orchestrator:
    the ability to select the right task to perform. We develop this component as
    a standalone component that we will integrate starting from [*Chapter 3*](Chapter_3.xhtml#_idTextAnchor085),
    where we will bridge the conversational agent with the AI controller orchestrator
    through a Pinecone vector store.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 2.6* illustrates the workflow of the AI controller orchestrator we’ll
    be developing:'
  prefs: []
  type: TYPE_NORMAL
- en: '**C1\. AI controller entry point input** triggers the process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**C2\. Analyzes input,** which could be a system or human user prompt.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**C3\. Embeds user input** through GPT-4o’s native functionality.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**C4\. Embeds task scenario** **repository** through GPT-4o’s native functionality.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**C5\. Selects a** **scenario** to execute a task that best matches the input.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**C6\. Executes the scenario** selected by the AI controller orchestrator.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 2.6: Workflow of the AI controller orchestrator](img/B32304_02_6.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.6: Workflow of the AI controller orchestrator'
  prefs: []
  type: TYPE_NORMAL
- en: We’ll develop this first component of the AI controller orchestrator with OpenAI’s
    GPT-4o API and Python. Additionally, since the idea is to leverage the full power
    of the generative AI model to perform several tasks requested by the AI controller
    orchestrator, we will thus avoid overloading the orchestrator with additional
    libraries to focus on the architecture of the GenAISys.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this notebook, GPT-4o will perform three key functions in the program, as
    shown in *Figure 2.7*:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Embedding**: GPT-4o systematically embeds all the data it receives through
    a prompt. The input is embedded before going through the layers of the model.
    In [*Chapter 3*](Chapter_3.xhtml#_idTextAnchor085), we will take this further
    by embedding and upserting reusable data such as instruction scenarios into a
    Pinecone vector store.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Similarity search**: GPT-4o can perform a similarity search with reliable
    results. GPT-4o doesn’t have a deterministic fixed cosine similarity function.
    It learns to understand relationships through its complex neural network, mimicking
    similarity judgments in a much more nuanced, less deterministic way.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Task execution**: Once a scenario is chosen, GPT-4o can execute a number
    of standard tasks, such as sentiment and semantic analysis.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 2.7: Triggering tasks with similarity searches in a list of instructions](img/B32304_02_7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.7: Triggering tasks with similarity searches in a list of instructions'
  prefs: []
  type: TYPE_NORMAL
- en: We have defined the workflow of the orchestrator and the generative AI model’s
    usage. However, we must examine how a model identifies the task it is expected
    to perform.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the intent functionality
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'No matter how powerful a generative AI model such as GPT-4o is, it cannot guess
    what a user wants without a prompt that explicitly expresses *intent*. We cannot
    just say, “The Grand Canyon is a great place to visit in Arizona” and expect the
    model to guess that we want a sentiment analysis done on our statement. We have
    to explicitly formulate our intent by entering: “Provide a sentiment analysis
    of the following text: The Grand Canyon is a great place to visit in Arizona.”'
  prefs: []
  type: TYPE_NORMAL
- en: To resolve the issue of intent for an AI controller, we have to find a framework
    for it to orchestrate its tasks. A good place to start is to study the **Text-to-Text
    Transfer Transformer** (**T5**), which is a text-to-text model (Raffel et al.,
    2020). A T5 model uses *task tags* or *task-specific prefixes* to provide the
    intent of a prompt to the transformer model. A task tag contains instructions
    such as summarization, translation, and classification. The model will detect
    the tag and know what to do, as shown in *Figure 2.8*.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.8: T5 with task tags](img/B32304_02_8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.8: T5 with task tags'
  prefs: []
  type: TYPE_NORMAL
- en: 'Training a T5 model involves *explicitly* adding a task tag when creating an
    input and then providing the response. However, OpenAI GPT models learn which
    task to perform by analyzing billions of sequences of language, not explicit structures,
    that contain instructions and responses. A generative AI model using GPT-like
    architectures will thus learn which task to perform *implicitly* through the context
    of the prompt. For example, a well-parsed prompt such as “Provide a sentiment
    analysis of the following text: The Grand Canyon is a great place to visit in
    Arizona.” contains enough context for GPT-4o to infer the desired operation—without
    requiring an explicit tag.'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s illustrate how a GPT model works by running T5-style examples with GPT-4o’s
    implicit analysis of which task needs to be performed.
  prefs: []
  type: TYPE_NORMAL
- en: From T5 to GPT models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we’ll write a program to show how GPT-4o interprets instructions—a
    capability we’ll leverage in our orchestrator. The aim is to demonstrate that,
    although GPT-style models infer intent implicitly, they still need clear instructions.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll begin by opening `T52GPT.ipynb` in the `Chapter02` directory on GitHub.
    Set up the environment exactly as in the *Setting up the environment* subsection
    of the *Conversational AI agent* section, installing only the OpenAI environment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: No additional installations are required. Let’s now begin with a CoLA task.
  prefs: []
  type: TYPE_NORMAL
- en: Corpus of Linguistic Acceptability (CoLA)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The **Corpus of Linguistic Acceptability** (**CoLA**) is a public dataset of
    short English sentences, each tagged as acceptable (grammatical) or unacceptable
    (ungrammatical). By testing GPT-4o on these examples, we can show that advanced
    generative models can tackle new tasks purely by understanding language, without
    any task-specific fine-tuning. This means that we can apply advanced generative
    AI models to a wide range of tasks we didn’t train them for.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s first submit the following input to the GPT-4o model to see whether it
    is acceptable without an explicit task tag:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'We will provide minimal information to the system:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'We’ll also make an OpenAI API call with the function we have been using throughout
    this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'The output shows that even one of the most powerful generative AI models doesn’t
    have a clue about what to do without a task tag:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let’s write an instruction with a task tag and the same message:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'The input now contains an indication of what is expected of the generative
    AI model. The output is now accurate:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: Let’s now perform a translation task.
  prefs: []
  type: TYPE_NORMAL
- en: Translation task
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The task begins with a task tag that is expressed in natural language:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'The output we get is accurate:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: Let’s now perform a **Semantic Textual Similarity Benchmark** (**STSB**) task.
  prefs: []
  type: TYPE_NORMAL
- en: Semantic Textual Similarity Benchmark (STSB)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'STSB-style scoring is an important feature for a GenAISys AI controller, which
    depends on similarity searches to pick the right instruction scenarios, documents,
    and other resources. The orchestrator will rely on this very capability. In the
    test that follows, we submit two sentences to the model and ask it to judge their
    semantic similarity:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'The output we get is accurate:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: This function will prove to be very useful when we’re searching for data that
    matches the input in a dataset. Let’s now run a summarization task.
  prefs: []
  type: TYPE_NORMAL
- en: Summarization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In the following input, GPT-4o can detect the summarization instruction tag
    and also interpret the maximum length of the response required:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is once again accurate:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: The takeaway of this exploration is that no matter which generative AI model
    we implement, it requires task tags to react as we expect. Next, we’ll use this
    insight to implement semantic textual similarity in our orchestrator for processing
    task tags.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing the orchestrator for instruction selection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we will begin building the orchestrator for two instructions
    based on task tags, as shown in *Figure 2.9*: sentiment analysis to determine
    the sentiment of a sentence and semantic analysis to analyze the facts in a sentence.'
  prefs: []
  type: TYPE_NORMAL
- en: We will make the system more complex by asking the generative AI model to find
    the best task tag scenario (sentiment or semantic analysis) based on the input.
    In other words, the task tag will not be part of the input. We will use GPT-4o’s
    semantic textual similarity features to choose the right task tag itself.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.9: Running tasks with implicit task tags](img/B32304_02_9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.9: Running tasks with implicit task tags'
  prefs: []
  type: TYPE_NORMAL
- en: Eventually, our orchestrator will support any task (see **3\. Any Task required**
    in *Figure 2.9*), not just sentiment or semantic analysis.
  prefs: []
  type: TYPE_NORMAL
- en: 'Setting up the environment is the same as earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: No additional installations are required for the orchestrator. We will begin
    by implementing an instruction scenario selection.
  prefs: []
  type: TYPE_NORMAL
- en: Selecting a scenario
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The core of an AI controller is to decide what to do when it receives an input
    (system or human user). The selection of a task opens a world of possible methods
    that we will explore throughout the book. However, we can classify them into two
    categories:'
  prefs: []
  type: TYPE_NORMAL
- en: Using an explicit task tag to trigger an instruction. This tag can be a context
    in a generative AI model and expressed freely in various ways in a prompt.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The prompt has no task instruction but instead a repository of scenarios from
    which the AI controller will make decisions based on semantic textual similarity.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Here, we’ll explore the second, more proactive approach. We’ll test two prompts
    with no instructions, no task tag, and no clue as to what is expected of the generative
    AI model. Although we will implement other, more explicit approaches later with
    task tags, a GenAISys AI controller orchestrator must be able to be proactive
    in certain situations.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first prompt is an opinion on a movie, implying that a sentiment analysis
    might interest the user:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The second prompt is a fact, implying that a semantic analysis might interest
    the user:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: To provide the AI controller with decision-making capabilities, we will need
    a repository of instruction scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: Defining task/instruction scenarios
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Scenarios are sets of instructions that live in a repository within a GenAISys.
    While ChatGPT-like models are trained to process many instructions natively, domain-specific
    use cases need custom scenarios (we’ll dive into these starting from [*Chapter
    5*](Chapter_5.xhtml#_idTextAnchor140)). For example, a GenAISys could receive
    a message such as `Customer order #9283444 is late`. The message could be about
    a production delay or a delivery delay. By examining the sender’s username and
    group (production or delivery department), the AI controller can determine the
    context and, selecting a scenario, take an appropriate decision.'
  prefs: []
  type: TYPE_NORMAL
- en: In this notebook, the scenarios are stored in memory. In [*Chapter 3*](Chapter_3.xhtml#_idTextAnchor085),
    we will organize the storage and retrieval of these instruction sets in Pinecone
    vector stores.
  prefs: []
  type: TYPE_NORMAL
- en: 'In both cases, we begin by creating a repository of structured scenarios (market,
    sentiment, and semantic analysis):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: 'We will also add a dictionary of the same scenarios, containing simple definitions
    of the scenarios:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'We now extract the strings from the dictionary and store them in a list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: At this point, our AI controller has everything it needs to recognize intent—matching
    any incoming prompt to the best-fitting scenario.
  prefs: []
  type: TYPE_NORMAL
- en: Performing intent recognition and scenario selection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We first define the parameters of the conversational AI agent just as we did
    in the *Conversational AI agent* section:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: The orchestrator’s job is to find the best task for any given input, making
    the AI controller flexible and adaptive. In some cases, the orchestrator may decide
    not to apply a scenario and just follow the user’s input. In the following example,
    however, the orchestrator will select a scenario and apply it.
  prefs: []
  type: TYPE_NORMAL
- en: 'We now adjust the input to take the orchestrator’s request into account:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'GPT-4o will now perform a text semantic similarity search as we ran in the
    *Semantic Textual Similarity Benchmark (STSB)* section. In this case, it doesn’t
    just perform a plain text comparison, but matches one text (the user input) against
    a list of texts (our scenario descriptions):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: 'Our user input is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, the scenario is chosen:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: 'The scenario number is then chosen, stored with the instructions that go with
    it, and displayed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: 'For our *Gladiator II* example, the orchestrator correctly picks the sentiment
    analysis scenario:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: This autonomous task-selection capability—letting GenAISys choose the right
    analysis without explicit tags—will prove invaluable in real-world deployments
    (see [*Chapter 5*](Chapter_5.xhtml#_idTextAnchor140)). The program now runs the
    scenarios with the generative AI agent.
  prefs: []
  type: TYPE_NORMAL
- en: Running scenarios with the generative AI agent
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that the AI controller has identified the correct `scenario_number`, it’s
    time to execute the selected task. In this notebook, we’ll walk through that process
    step by step. We first print the input:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: 'Using the `scenario_number` value, we access the scenario description from
    our `instructions_as_strings` list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: The orchestrator is now ready to run a sentiment analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Sentiment analysis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We append the description of the scenario to the original user prompt and send
    the combined request to GPT-4o:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: 'For our *Gladiator II* example, the response might look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: The response shows that the orchestrator found a scenario that matches the input
    and produces an acceptable output. Now, let’s go back, change the prompt, and
    see whether the orchestrator finds the right scenario.
  prefs: []
  type: TYPE_NORMAL
- en: Semantic analysis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The goal now is to verify, without changing a single line of code, whether the
    orchestrator can access another scenario. The orchestrator will rely on GPT-4o’s
    native ability to perform semantic text similarity searches.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will now activate prompt 2:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: 'This input clearly calls for a semantic analysis rather than sentiment analysis.
    We then reuse the exact same code as our sentiment analysis search:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: 'The output shows that the right scenario was found:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: 'The task response is displayed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: 'The output shows that the orchestrator produces a coherent semantic analysis:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: This demonstrates that in some cases, the orchestrator will be able to find
    the right scenarios without task tags. This will prove useful when we tackle more
    complex workflows, such as advanced production and support.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The first takeaway from this chapter is the central role of humans in a GenAISys.
    Human design drove the creation of both our conversational agent and orchestrator.
    We started developing these two complex components with simply an OpenAI API and
    Python, yet we *humans* designed the initial levels of the AI controller that
    powers our custom GenAISys. The basic GenAISys rule will always apply: no human
    roles, no GenAISys. We design AI systems, implement them, maintain them, and evolve
    them based on ongoing feedback.'
  prefs: []
  type: TYPE_NORMAL
- en: The second takeaway is how our conversational AI agent goes beyond a small-scale
    ChatGPT-like structure. We not only built short-term context and memory retention
    for a full-turn dialogue, but we also added long-term memory across multiple users
    and multiple topics. Our dialogue included three users (John, Myriam, and Bob)
    and two topics (geology and surfing). As we progress through the book, we will
    expand the scope of these multi-user, multi-topic sessions to use cases where
    team cooperation is essential.
  prefs: []
  type: TYPE_NORMAL
- en: The third takeaway concerns our AI controller orchestrator. We gave the orchestrator
    a small scenario dataset containing custom instructions that we can expand for
    a domain-specific use case, and then leveraged GPT-4o to both select the appropriate
    scenario and execute the task itself.
  prefs: []
  type: TYPE_NORMAL
- en: At this point, we have a conversational agent and a nascent AI controller orchestrator.
    When we assemble our AI controller, they will together form a unique multi-user,
    multi-domain customized GenAISys. To build our multi-user, multi-domain GenAISys
    AI controller, we will now build a Pinecone vector store in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A ChatGPT-like GenAISys only needs a generative AI model such as GPT-4o. (True
    or False)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A ChatGPT-like GenAISys doesn’t require an AI controller. (True or False)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Human roles are critical when building and running GenAISys. (True or False)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Generally, not always, a generative AI model such as GPT-4o contains a task
    tag in one form or the other. (True or False)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Sometimes, not always, a generative model can find the most probable task to
    perform without a task tag. (True or False)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Semantic text similarity cannot be natively performed by GPT-4o. (True or False)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A full-turn generative AI conversation loop with an OpenAI API AI requires coding.
    (True or False)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Long-term memory AI conversation sessions are never necessary. (True or False)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Summarizing a text can only be done in English by GPT-4o. (True or False)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: An AI controller orchestrator is sentient. (True or False)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou,
    Y., Li, W., & Liu, P. J. (2020). *Exploring the Limits of Transfer Learning with
    a Unified Text-to-Text Transformer.* [https://arxiv.org/abs/1910.10683](https://arxiv.org/abs/1910.10683)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ren, J., Sun, Y., Du, H., Yuan, W., Wang, C., Wang, X., Zhou, Y., Zhu, Z.,
    Wang, F., & Cui, S. (2024). *Generative Semantic Communication: Architectures,
    Technologies, and Applications.* [https://doi.org/10.48550/arXiv.2412.08642](https://doi.org/10.48550/arXiv.2412.08642
    )'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Koziolek, H., Gruener, S., & Ashiwal, V. (2023). *ChatGPT for PLC/DCS Control
    Logic Generation.* [https://doi.org/10.48550/arXiv.2305.15809](https://doi.org/10.48550/arXiv.2305.15809)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Subscribe for a Free eBook
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: New frameworks, evolving architectures, research drops, production breakdowns—*AI_Distilled*
    filters the noise into a weekly briefing for engineers and researchers working
    hands-on with LLMs and GenAI systems. Subscribe now and receive a free eBook,
    along with weekly insights that help you stay focused and informed.
  prefs: []
  type: TYPE_NORMAL
- en: Subscribe at [https://packt.link/TRO5B](https://packt.link/TRO5B) or scan the
    QR code below.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Newsletter_QR_Code.png)'
  prefs: []
  type: TYPE_IMG
