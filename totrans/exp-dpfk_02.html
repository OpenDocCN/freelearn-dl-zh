<html><head></head><body>
		<div id="_idContainer014">
			<h1 id="_idParaDest-36" class="chapter-number"><a id="_idTextAnchor035"/>2</h1>
			<h1 id="_idParaDest-37"><a id="_idTextAnchor036"/>Examining Deepfake Ethics and Dangers</h1>
			<p>Deepfakes have a reputation for being extremely dangerous and of questionable ethics. While any technology can be abused, it is the usage itself that is unethical, not the technology itself. This applies to deepfakes as well. As long as the usage is ethical, deepfakes can be an ethical technology. However, there are still potential threats from deepfakes. The technology is available publicly – anyone can make a deepfake, even those with unethical intentions. The best way to limit the danger of deepfakes may well be to make sure that everyone knows about them, effectively inoculating the public against trusting a video just because they have <span class="No-Break">watched it.</span></p>
			<p>In this chapter, we will cover the ethics and dangers of deepfakes. We will examine the ethics of deepfake’s origins, create some guidelines to follow in creating ethical deepfakes, discuss the dangers of deepfakes, and cover some of the defenses <span class="No-Break">against deepfakes.</span></p>
			<p>We’ll cover the following topics in <span class="No-Break">this chapter:</span></p>
			<ul>
				<li>The unethical origin <span class="No-Break">of deepfakes</span></li>
				<li>Being an <span class="No-Break">ethical deepfaker</span></li>
				<li>The dangers <span class="No-Break">of deepfakes</span></li>
				<li>Preventing damage <span class="No-Break">from deepfakes</span></li>
			</ul>
			<h1 id="_idParaDest-38"><a id="_idTextAnchor037"/>The unethical origin of deepfakes</h1>
			<p>Deepfakes began with an unfortunately unethical beginning. The first public deepfakes were created <a id="_idIndexMarker049"/>by a Reddit user by the name of /u/Deepfakes. These first videos showing off Deepfake’s capabilities involved putting (usually) female actors into pornographic scenes. This non-consensual pornography was radically different from previous fakes in that they were more realistic, easier to create, and full video, capable of poses and expressions that the target actor had never performed in any <span class="No-Break">recorded media.</span></p>
			<p>Non-consensual pornographic deepfakes are not victimless events. This usage is extremely damaging as it harms the actors in profound ways. With non-consensual deepfakes being made, celebrities are losing control of their image and reputation. Unfortunately, there is no way to completely avoid the threat from deepfakes as even after proving a video isn’t actually of them, the deepfake will still be spread and objectify the actor. Some of the people being deepfaked in pornographic films against their will aren’t even celebrities and aren’t equipped or ready to deal with the attention and infamy of <span class="No-Break">the situation.</span></p>
			<p class="callout-heading">Author’s note</p>
			<p class="callout">While we believe our stance is clear, we want to once again reiterate that the authors do not condone or participate in non-consensual pornographic deepfakes. We believe that the practice is horrible and causes serious harm to <span class="No-Break">its victims.</span></p>
			<p>Putting women’s faces into pornographic videos that they did not participate in or consent to is <a id="_idIndexMarker050"/>obviously a highly unethical use of any technology. Unfortunately, this is still the most well-known use of deepfake technology. However, this is slowly changing, with deepfakes becoming more recognized for their flexibility <span class="No-Break">and innovation.</span></p>
			<h1 id="_idParaDest-39"><a id="_idTextAnchor038"/>Being an ethical deepfaker</h1>
			<p>Deepfakes have many potential uses, both ethical and unethical. Knowing what is ethical or not is <a id="_idIndexMarker051"/>sometimes difficult to figure out. For example, are all pornographic deepfakes unethical? What if everyone involved consents? This can be difficult to answer sometimes, and there is a lot of ambiguity, but there are some guidelines that you can follow and some tests you can run to try to ensure your usage is on the right side of the <span class="No-Break">ethical questions.</span></p>
			<h2 id="_idParaDest-40"><a id="_idTextAnchor039"/>Consent</h2>
			<p>Probably <a id="_idIndexMarker052"/>the most important ethical concern is one of consent. Consent is quite simple: is everyone involved willing to participate? This is most obviously an issue when it comes to pornographic deepfakes – if not everyone is a consenting participant, then it’s <span class="No-Break">unquestionably unethical.</span></p>
			<p>However, this becomes less obvious when the video is satirical or an actor is put into a role that they didn’t originally perform. Very few deepfake creators can get explicit permission from an actor, and even if the actors were all okay with the usage, contacting the actors to get permission would <span class="No-Break">be difficult.</span></p>
			<p>Some deepfakes, such as the Jennifer Lawrence-Buscemi one by birbfakes, have received lots of attention (and in the case of Steve Buscemi, even a response) without direct permission from the people involved. These uses were likely ethical despite the lack of consent, as they were done in parody and without violating other ethical concerns. This <a id="_idIndexMarker053"/>can be a difficult balance to keep, but consent needs to be considered, even if <span class="No-Break">it’s hypothetical.</span></p>
			<p>Even if an actor or actress has passed away, it doesn’t mean that you don’t need permission from their estate or family. Disney had permission from Carrie Fisher and her family to use CGI techniques to replicate her character in Rogue One and other Star <span class="No-Break">Wars productions.</span></p>
			<p>One important note is that while you should get permission (if possible) from the person you’re swapping in, you should also consider the person you’re swapping onto. While the harm there is less obvious, it’s still a potentially <span class="No-Break">harmful action.</span></p>
			<h2 id="_idParaDest-41"><a id="_idTextAnchor040"/>Respect</h2>
			<p>It’s important to remember that the people you’re swapping to and from are real people who <a id="_idIndexMarker054"/>have emotions and have worked to be where they are. You should show respect to the people <span class="No-Break">you’re swapping.</span></p>
			<p>In the case of pornography, this is again a point that is violated. Actors have to make an active decision in every role they look at as to whether they’re comfortable with the content. This includes whether they’re comfortable with nudity or sexuality in their roles. Even though they may have done some similar scenes in the past, they may change their mind if the work, context, or even opinions change. When a person who has chosen not to be in sexual roles gets deepfaked into pornographic scenes, their decisions are dismissed and violated. Actors who have participated in sexual scenes in the past were able to make that decision in the context of the work; that does not mean that they aren’t harmed when put into other scenes in different contexts or put into scenes that perhaps they would no longer choose to <span class="No-Break">participate in.</span></p>
			<p>In the case of deepfake Tom Cruise by Chris Ume, and similar works, they stay on the positive side of this rule by showing nothing outrageous or disrespectful. The things that deepfake Tom Cruise does are not outside the realm of what Tom Cruise himself might do. The key <a id="_idIndexMarker055"/>thing to consider is that the fakes do not harm his reputation or demean his character and simply provide a glimpse of how the deepfakers believe Tom Cruise would act in <span class="No-Break">those situations.</span></p>
			<h2 id="_idParaDest-42"><a id="_idTextAnchor041"/>Deception</h2>
			<p>While the previous guidelines were all about the people being swapped, this one is actually about <a id="_idIndexMarker056"/>the audience. Creating deepfakes while being obvious and deliberate about them being deepfakes means that potential dangers are reduced and helps to keep them on the side of <span class="No-Break">ethical usage.</span></p>
			<p>This doesn’t mean that your work can’t be used unethically. For example, if it’s taken out of context and shared on social media, it could spread far and wide without the warning that it’s a deepfake. To combat this, the warning that it’s a deepfake may need to be more than a disclaimer at the beginning or description. Try to think of how it could be misused and present the warning in a way that matches <span class="No-Break">the risk.</span></p>
			<p>If the risk of it being misused is low, then no explicit warning may be needed, instead simply allowing the absurdity of the situation or the innocuous nature of the deepfake to disarm the risk. This, for example, is the case with the large number of videos that have the actor Nicolas Cage swapped into them. It’s easy to see that Cage wasn’t the original actor (especially when a deepfake swapped Nicolas Cage onto Amy Adams in <em class="italic">Man of Steel</em>) and, even when it’s not, the danger is low of any real <span class="No-Break">damage ensuing.</span></p>
			<p>Another clear example is when your deepfake is used where special effects or visual effects are commonplace. If you’re bringing a deceased actor into a movie where visual effects would be expected, there is little reason to explicitly label the content as a deepfake. The context alone is sufficient to make it clear that you cannot trust everything you see. The famous story of the radio drama of H.G. Wells’s <em class="italic">War of the Worlds</em> causing panic in the street is unlikely to happen with a deepfake bringing an actor back to life for a movie they <span class="No-Break">couldn’t film.</span></p>
			<p>Now that we know how we can judge the ethics of a deepfake, how about we put this <span class="No-Break">into practice.</span></p>
			<h2 id="_idParaDest-43"><a id="_idTextAnchor042"/>Putting it into practice</h2>
			<p>In this section, we’ll look at several deepfakes and evaluate them using the metrics that we <span class="No-Break">proposed above.</span></p>
			<h3>Deep Tom Cruise</h3>
			<p><strong class="bold">Deep Tom Cruise</strong> is a project by Metaphysic, a company that creates deepfakes for VFX and movies. They <a id="_idIndexMarker057"/>made several videos that deepfaked Tom Cruise in various situations and environments. They posted these videos on TikTok <span class="No-Break">at </span><a href="https://www.tiktok.com/@deeptomcruise"><span class="No-Break">https://www.tiktok.com/@deeptomcruise</span></a><span class="No-Break">:</span></p>
			<ul>
				<li><strong class="bold">Consent</strong>: For consent, we look at whether they had permission from those involved. Deep Tom Cruise did not get permission from Mr. Cruise. However, Cruise is a public figure so getting explicit permission may have been impossible. They did get permission (and participation) from Miles Fisher who was the impersonator whose performance they deepfaked into <span class="No-Break">Tom Cruise.</span></li>
				<li><strong class="bold">Respect</strong>: Mr. Cruise was never shown doing anything inappropriate or even the significantly out of character. The videos respected Cruise’s reputation and personality. However, they did show Cruise doing things in his personal life that he wouldn’t normally share, such as playing golf or having lunch, but these were not hurtful in <span class="No-Break">any way.</span></li>
				<li><strong class="bold">Deception</strong>: It was always very clear that Deep Tom Cruise was not a genuine account of Mr. Cruise. Even the name of the account itself disclosed that it was a deepfake. This was accompanied by interviews and news stories detailing that it was a deepfake, as well as how it <span class="No-Break">was done.</span></li>
				<li><strong class="bold">Analysis</strong>: While they did not get explicit permission from Mr. Cruise, they did not do anything to harm his reputation and clearly disclosed that it was a deepfake. On the whole, this is an ethical use of deepfakes, but it would have been better if they had gotten Cruise’s explicit permission before creating the project. Presumably, if Cruise were to object to the project, they would remove it from public view and minimize the damage, as leaving it up with an objection from Cruise would tip it over into <span class="No-Break">unethical usage.</span></li>
			</ul>
			<h3>Dalí Lives</h3>
			<p><strong class="bold">Dalí Lives</strong> is an art project that shows an interactive deepfake of Salvador Dalí at the Dalí museum. This project’s stated goals are to let visitors virtually “meet” and learn about the artist <a id="_idIndexMarker058"/>directly from Dalí himself. You can see information about the exhibit <span class="No-Break">at </span><a href="https://thedali.org/exhibit/dali-lives/"><span class="No-Break">https://thedali.org/exhibit/dali-lives/</span></a><span class="No-Break">:</span></p>
			<ul>
				<li><strong class="bold">Consent</strong>: Salvador Dalí is deceased and has no children or surviving immediate family. Consent is next to impossible in <span class="No-Break">this situation.</span></li>
				<li><strong class="bold">Respect</strong>: It’s hard to imagine a more respectful usage than Dalí Lives. The museum worked hard to create a representation of Dalí so that people who visit the museum can interact with and see Dalí. The museum hosts many of his paintings and other artistic pieces and Dalí Lives fits into that <span class="No-Break">environment perfectly.</span></li>
				<li><strong class="bold">Deception</strong>: The museum is very clear that Dalí Lives is an art piece and not the genuine article. The project is set up in many locations around the museum along with placards explaining that the Dalí represented is not the actual person, but a project to let people interact with the representation. They also include a “making of” video showing the <span class="No-Break">deepfake process.</span></li>
				<li><strong class="bold">Analysis</strong>: This is pretty unquestionably an ethical use of deepfake technology. It’s hard to imagine a more ethical usage than enabling visitors to a museum to interact with a famous historical figure who is no <span class="No-Break">longer alive.</span></li>
			</ul>
			<p>While they lack consent, it’s not hard to imagine that Dalí would have eagerly granted it if he were able. He loved the absurd and macabre. The idea that he could interact with guests from beyond the grave seems perfectly in line with <span class="No-Break">his sensibilities.</span></p>
			<p>In addition, the project is respectful of Dalí, showing him in an environment that he fits perfectly into – a museum that has many of his <span class="No-Break">own projects.</span></p>
			<p>Finally, there is no deception. Nobody who visits believes that they are truly interacting with Dalí and so this path is <span class="No-Break">also clear.</span></p>
			<p>While there are <a id="_idIndexMarker059"/>ways to approach deepfakes ethically, what dangers do <span class="No-Break">deepfakes present?</span></p>
			<h1 id="_idParaDest-44"><a id="_idTextAnchor043"/>The dangers of deepfakes</h1>
			<p>The dangers of deepfakes go beyond just fooling some people. If others act on what they see in deepfakes, there are huge dangers to reputation, politics, and even economics. Imagine if a <a id="_idIndexMarker060"/>large number of people were convinced by a deepfake of a declaration of war. There could be pandemonium and huge amounts of damage to international reputation before the truth was revealed. This very nearly happened recently: a deepfake of President Zelenskyy of Ukraine was spread online telling the Ukranian people to lay down arms during the <span class="No-Break">Russian invasion.</span></p>
			<h2 id="_idParaDest-45"><a id="_idTextAnchor044"/>Reputation</h2>
			<p>In some ways, danger to reputation sounds like the most trivial of potential dangers from deepfakes. However, reputation can be incredibly important for all kinds of things. Imagine if a person <a id="_idIndexMarker061"/>were to lose their job over a deepfake insulting their boss, or another person getting arrested when a deepfake falsely confessing to a crime is sent to the police. These effects can compound and seriously impair a person’s future due to actions that they have no <span class="No-Break">control over.</span></p>
			<p>Wide-spread reputation damage is already incredibly easy in the internet age. People getting “canceled” for actions that they genuinely took can cause long-term harm to a person’s future. Even if the damage is only temporary or limited, having the threat of actions you didn’t actually do causing similar harm is a <span class="No-Break">scary proposition.</span></p>
			<h2 id="_idParaDest-46"><a id="_idTextAnchor045"/>Politics</h2>
			<p>The dangers of deepfakes in politics are much the same as the dangers to reputation but magnified by the <a id="_idIndexMarker062"/>public policy effects that can come from reputation damage. A politician, in many ways, relies on their reputation in order to get elected. Few would be willing to elect someone that they believed to be dishonest or disreputable (which is not the same as actually <em class="italic">being</em> dishonest <span class="No-Break">or disreputable).</span></p>
			<p>If a political group were to be targeted by a deepfake smear campaign, there are many who would believe the results even if they were revealed to be a fabrication. This is the unfortunate nature of human psychology where we are far more likely to believe something that confirms our already-held beliefs than something that disproves them. Once an opinion is made of a candidate in the minds of the public, there is little that can be done to reverse that opinion, especially bringing a reputation back from <span class="No-Break">severe damage.</span></p>
			<p>Deepfakes have, unfortunately, already been used in politics and have done varying amounts of damage. There are relatively innocuous uses such as Trey Parker and Matt Stone parodying then-President Donald Trump with Sassy Justice. Parody videos such as those are unlikely to <a id="_idIndexMarker063"/>do real harm as our society is already used to humor being used against politicians as a technique to criticize or entertain. In fact, many politicians actively participate in shows that parody them. One example is when Barrack Obama invited Keegan Michael Key to be his “anger translator” at the 2015 White House Correspondents’ dinner – a role that originated in parodies on Comedy Central’s <em class="italic">Key &amp; </em><span class="No-Break"><em class="italic">Peele</em></span><span class="No-Break">.</span></p>
			<p>However, we’ve already seen significant damage done to candidates over doctored videos. One video that spread among social networks in early 2019 was of Nancy Pelosi where the video had been slowed down to imply that she was inebriated or unfit as a politician. In Iraq, multiple female candidates withdrew from elections after pornographic videos claiming to be them were released publicly, harming <span class="No-Break">their reputations.</span></p>
			<h2 id="_idParaDest-47"><a id="_idTextAnchor046"/>Avoiding consequences by claiming manipulation</h2>
			<p>While it’s easy to see the damage that a deepfake can cause, it’s also possible for deepfakes <a id="_idIndexMarker064"/>to create issues where there is no deepfake. Now that deepfakes and manipulated media have entered the public perception, it’s possible that genuine videos showing inappropriate behavior will be labeled as deepfakes <span class="No-Break">and ignored.</span></p>
			<p>This is unlikely to be a serious threat for minor faux pas or inappropriate activities as it’s always been possible to diminish or dismiss videos (or even photos or voice recordings) that show a person doing things that are controversial. For more major situations such as videos of crimes or serious offenses, it’s unlikely that the police or courts will long be confused or dissuaded by claims <span class="No-Break">of deepfakes.</span></p>
			<p>However, there are a range of potential scandals that may have no other way of defense beyond convincing people that the video is fake. In those situations, it’s possible that <a id="_idIndexMarker065"/>the person involved may claim that the video is a manipulation as a defense against <span class="No-Break">the controversy.</span></p>
			<p>While it’s good to know the potential dangers, arguably, it’s more important to know how to defend yourself from <span class="No-Break">the dangers.</span></p>
			<h1 id="_idParaDest-48"><a id="_idTextAnchor047"/>Preventing damage from deepfakes</h1>
			<p>There is no foolproof way to make yourself immune to deepfakes or their effects, but there are activities and actions you can take in order to reduce the dangers. In this section, we’ll examine methods that you can use to prevent as much damage <span class="No-Break">as possible.</span></p>
			<h2 id="_idParaDest-49"><a id="_idTextAnchor048"/>Starving the model of data</h2>
			<p>While deepfakes have been done with a minimum of data, the result is not seamless or high quality. This <a id="_idIndexMarker066"/>means that if you can simply prevent the deepfaker from getting enough data, you can prevent a deepfake from being of sufficient quality to <span class="No-Break">fool anyone.</span></p>
			<p>If you’re trying to protect a famous person, this tactic is much harder, since every movie, TV show, interview, or even photoshoot that is available is a source of training data for a model. In fact, it’s almost inevitable that enough data is available to target any famous person as the public nature of their job means that a lot of training data will be <span class="No-Break">publicly available.</span></p>
			<p>As a private individual, however, it is easier to control your media presence. By avoiding publicly available videos or images, you can prevent a deepfaker from getting enough content to create a convincing result. To do this, you can’t allow publicly posted images or videos of yourself. This is harder with social media that allows your friends to tag you, allowing a deepfaker to potentially find media that you don’t control <span class="No-Break">being posted.</span></p>
			<h2 id="_idParaDest-50"><a id="_idTextAnchor049"/>Authenticating any genuine media</h2>
			<p>There are services that now offer authentication of media. This lets users embed a verifiable <a id="_idIndexMarker067"/>watermark or metadata that allows the media to be proven to be genuine. Unfortunately, most sites and services remove metadata and recompress both images and videos, causing some types of watermarks to be removed. This means that even if you authenticate all genuine media, there will be nearly identical versions without the <span class="No-Break">authentication embedded.</span></p>
			<p>Authenticating media is an interesting solution to the problem of deepfakes, but may not be feasible: even if everyone starts supporting authenticated media, users will need to be trained to verify the authenticity, and that won’t be possible until all major sites support media authentication. This leads to a chicken and egg problem, where media sites won’t support authentication in the media until the public demands it and the public won’t be aware of it until it’s supported by all <span class="No-Break">major sites.</span></p>
			<p>Despite the failings of authenticated media, it might be a good idea to get a head-start on authenticating your media so that you’ll be ready in the future when authenticated media <span class="No-Break">is expected.</span></p>
			<h2 id="_idParaDest-51"><a id="_idTextAnchor050"/>Deepfake detection</h2>
			<p>Another solution that relies heavily on large-scale support is <strong class="bold">deepfake detection</strong>. The idea behind deepfake detection is that a site would run any hosted videos through an algorithm or process <a id="_idIndexMarker068"/>to identify any deepfakes and either mark them as <a id="_idIndexMarker069"/>fake or block them from the site. In this situation, any site that had a perfect deepfake detector and a policy of flagging them would be safe from damage due <span class="No-Break">to deepfakes.</span></p>
			<p>Unfortunately, the solution is not that easy. First, deepfake detection requires dedication to detecting and flagging any deepfakes. Companies have paid lip service to detection, but ultimately, deepfake detection is not in use by any major services at this time. There are few economic incentives right now for companies to provide a thorough deepfake detection solution, but it’s very possible that legal changes or public demand for deepfake detection could change the policy of companies so that they provide <span class="No-Break">this detection.</span></p>
			<p class="callout-heading">A disclaimer on detection</p>
			<p class="callout">At the time of writing this book, the authors are not aware of any social media or video content services that run deepfake detection on all hosted videos; however, it’s possible that services are using detection to tag videos that the authors are not <span class="No-Break">aware of.</span></p>
			<p>Even if sites started dedicating themselves to detecting deepfakes, it’s unlikely that they’d block them outright. There are legitimate uses of deepfakes and it’s far more likely that sites would prefer to tag them (either publicly or internally) and monitor them than block these videos entirely. This would limit the effectiveness of any mitigations to the most flagrant violations, allowing lesser viewed or less offensive deepfakes to remain on <span class="No-Break">the platform.</span></p>
			<p>Another problem is in the accuracy of deepfake detection. There is no perfect way to identify and prevent deepfakes at this time. There have been many attempts to identify and flag deepfakes with many different solutions, ranging from purely technical to a mix of automatic and <a id="_idIndexMarker070"/>manual reviews. These methods can catch some but not all deepfakes right now. Even if they caught all the current deepfakes, the technology is moving and advancing – some developers will simply use deepfake detection as a way to improve their deepfakes to be undetectable again. This will lead to the same type of cat-and-mouse game that malware detectors have gone through. It’s possible that deepfake producers may find new ways to fool detectors, even if just for a <span class="No-Break">short time.</span></p>
			<p>Finally, even if you have a perfect method for the detection of deepfakes, that would be of limited value in the long term. Even if one site started blocking deepfakes, there are a lot of other services that a deepfake could be posted on. Even if every major site blocked deepfakes entirely, there would be sites that would pop up specifically to deceive people with deepfakes. A total block of deepfakes online is impossible without complete control of the <span class="No-Break">entire internet.</span></p>
			<h2 id="_idParaDest-52"><a id="_idTextAnchor051"/>Public relations</h2>
			<p>If you have <a id="_idIndexMarker071"/>the money and the need, there have always been companies focused on helping to manage your reputation. They can be surprisingly effective and may be able to actively prevent deepfakes from being posted in the <span class="No-Break">first place.</span></p>
			<p>Public relations companies will have contacts with major companies such as Facebook and Youtube. They’ll be able to get inappropriate or rule-violating images or videos removed much faster than attempting to do it manually. They’ll also have legal departments and tools that may be able to get deepfake videos removed from <span class="No-Break">other sources.</span></p>
			<p>Even if a video can’t be removed (or after it’s already begun to spread), a public relations company could handle the fallout from the video, getting ahead of it, convincing news agencies to ignore the video, or pushing for stories about the video <span class="No-Break">being manipulated.</span></p>
			<p>The big issue is that public relations companies are not cheap and are selective about who they <a id="_idIndexMarker072"/>are willing to work with. Unless you are famous or have a very valuable reputation to maintain, it may be hard or prohibitively expensive to get a public relations company to work <span class="No-Break">with you.</span></p>
			<h2 id="_idParaDest-53"><a id="_idTextAnchor052"/>Public awareness</h2>
			<p>One other way to defend against deepfakes is to raise public awareness of deepfakes. Both the threats <a id="_idIndexMarker073"/>and potential, once publicly known, may encourage additional scrutiny of videos and images. This has the advantage of working even with new technologies or techniques but relies on public awareness and a willingness to <span class="No-Break">question content.</span></p>
			<h1 id="_idParaDest-54"><a id="_idTextAnchor053"/>Summary</h1>
			<p>The ethics and dangers of deepfakes are probably the most publicized aspects of them. However, they’re things that all deepfake creators should consider, as it’s easy to operate unethically if you don’t consider these questions. Even those who aren’t creating deepfakes may need to think about how to prevent damage from deepfakes or other <span class="No-Break">manipulated media.</span></p>
			<p>As a creator, you must consider the ethics of the content you’re creating. Making sure that you evaluate such things as consent, the personal experience, and the labeling of a deepfake is a good way to clear ethical hurdles and make <span class="No-Break">low-risk deepfakes.</span></p>
			<p>Even as non-creators, people should be wary of the threats of deepfakes. The technology is “out of the bag” and cannot be erased. Even if the technology were to be banned immediately, state-level actors would still be able to wield it in potentially dangerous ways and could ignore any laws or restrictions placed on its use. Everything from reputation damage to political manipulation, to those who claim genuine videos are deepfakes to avoid repercussions are new threats that we can only mitigate through critical thinking and not through ignoring the <span class="No-Break">subject entirely.</span></p>
			<p class="callout-heading">Author’s note</p>
			<p class="callout">The authors of this book are also developers of the open source deepfake software Faceswap. We have considered these same questions and the ethics of publicizing deepfakes. We consider the damage to be already done, and removing access to the technology now would not prevent any future abuses. We believe that the best way forward is to ensure that the public is aware of the threat so that critical thinking can be applied to any videos to consider whether they appear manipulated or out of <span class="No-Break">the norm.</span></p>
			<p>The dangers of deepfakes do have limits, and there are ways that they can be defended against. Right now, deepfakes require large amounts of data, and those who don’t live in the public eye might be able to starve a deepfake creator of the content that they need in order to make a deepfake. For those who can’t just remove all content, they can advocate for deepfake detection, media watermarking, or using public relations firms to help avoid damage from <span class="No-Break">manipulated media.</span></p>
			<p>In the next chapter, we’ll get into the importance of data, how you can get enough data, and how you can make the most of the data you do have in order to get the best quality <span class="No-Break">deepfakes possible.</span></p>
		</div>
		<div>
			<div id="_idContainer015" class="IMG---Figure">
			</div>
		</div>
	<div style="width:100%; margin-top:20px; "><div style="text-align:left; padding:10px" aria-hidden="true"><span style="font-size: 0.75em">EBSCOhost - printed on 11/27/2023 6:20 AM via . All use subject to <a target="_blank" href="https://www.ebsco.com/terms-of-use">https://www.ebsco.com/terms-of-use</a></span></div></div>
</body></html>