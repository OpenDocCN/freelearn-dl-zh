["```py\nimport vertexai\nfrom google.cloud import aiplatform\nfrom vertexai.generative_models import GenerativeModel, Part\n#Authenticate with Google Colab\nfrom google.colab import auth as google_auth\ngoogle_auth.authenticate_user()\n# GCP Parameters\nPROJECT = \"your-GCP-project\" #@param {type:\"string\"}\nLOCATION = \"us-central1\" #@param {type:\"string\"}\n#Init Vertex AI Platform\naiplatform.init(project=PROJECT, location=LOCATION)\ndef generate(prompt):\n  model = GenerativeModel(\"gemini-pro\")\n  response = model.generate_content(\n    [prompt],\n    generation_config={\n        \"max_output_tokens\": 2048,\n        \"temperature\": 0.1,\n        \"top_p\": 0,\n        \"top_k\": 5,\n    },\n    safety_settings={\n          generative_models.HarmCategory.HARM_CATEGORY_HATE_SPEECH: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n          generative_models.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n          generative_models.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n          generative_models.HarmCategory.HARM_CATEGORY_HARASSMENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n    },\n    stream=False,\n  )\n  return response\nresult = generate(\"Tell me a joke about cars\")\nprint(result) \n```", "```py\ndef generate(prompt):\n  model = GenerativeModel(\"gemini-pro\")\n  response = model.generate_content(\n    [prompt],\n    generation_config={\n        \"max_output_tokens\": 2048,\n        \"temperature\": 0.1,\n        \"top_p\": 1\n    },\n    safety_settings={\n        generative_models.HarmCategory.HARM_CATEGORY_HATE_SPEECH: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n        generative_models.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n        generative_models.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n        generative_models.HarmCategory.HARM_CATEGORY_HARASSMENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n    },\n    stream=False,\n  )\n  return response \n```", "```py\nsafety_settings={\n    generative_models.HarmCategory.HARM_CATEGORY_HATE_SPEECH: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n    generative_models.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n    generative_models.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n    generative_models.HarmCategory.HARM_CATEGORY_HARASSMENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n} \n```", "```py\ncandidates {\n  content {\n    role: \"model\"\n    parts {\n      text: \"What do you call a car that\\'s always breaking down?\\n\\nA lemon-aid stand!\"\n    }\n  }\n  finish_reason: STOP\n  safety_ratings {\n    category: HARM_CATEGORY_HATE_SPEECH\n    probability: NEGLIGIBLE\n  }\n  safety_ratings {\n    category: HARM_CATEGORY_DANGEROUS_CONTENT\n    probability: NEGLIGIBLE\n  }\n  safety_ratings {\n    category: HARM_CATEGORY_HARASSMENT\n    probability: NEGLIGIBLE\n  }\n  safety_ratings {\n    category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n    probability: NEGLIGIBLE\n  }\n}\nusage_metadata {\n  prompt_token_count: 6\n  candidates_token_count: 20\n  total_token_count: 26\n} \n```", "```py\nsafety_ratings {\n    category: HARM_CATEGORY_HATE_SPEECH\n    probability: NEGLIGIBLE\n  }\n  safety_ratings {\n    category: HARM_CATEGORY_DANGEROUS_CONTENT\n    probability: NEGLIGIBLE\n  }\n  safety_ratings {\n    category: HARM_CATEGORY_HARASSMENT\n    probability: NEGLIGIBLE\n  }\n  safety_ratings {\n    category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n    probability: NEGLIGIBLE\n  } \n```", "```py\nsafety_settings={\n    generative_models.HarmCategory.HARM_CATEGORY_HATE_SPEECH: generative_models.HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n    generative_models.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: generative_models.HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n    generative_models.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: generative_models.HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n    generative_models.HarmCategory.HARM_CATEGORY_HARASSMENT: generative_models.HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n} \n```", "```py\ncandidates {\n  content {\n    role: \"model\"\n  }\n  finish_reason: SAFETY\n  safety_ratings {\n    category: HARM_CATEGORY_HATE_SPEECH\n    probability: NEGLIGIBLE\n  }\n  safety_ratings {\n    category: HARM_CATEGORY_DANGEROUS_CONTENT\n    probability: LOW\n    blocked: true\n  }\n  safety_ratings {\n    category: HARM_CATEGORY_HARASSMENT\n    probability: NEGLIGIBLE\n  }\n  safety_ratings {\n    category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n    probability: NEGLIGIBLE\n  }\n}\nusage_metadata {\n  prompt_token_count: 10\n  total_token_count: 10\n} \n```", "```py\nimport vertexai\nfrom google.cloud import aiplatform\nfrom vertexai.language_models import TextGenerationModel\nfrom google.colab import auth as google_auth\ngoogle_auth.authenticate_user()\n# GCP Parameters\nPROJECT = \"your-GCP-project\" #@param {type:\"string\"}\nLOCATION = \"us-central1\" #@param {type:\"string\"}\n#Init Vertex AI Platform\naiplatform.init(project=PROJECT, location=LOCATION)\ndef generate(prompt):\n  model = TextGenerationModel.from_pretrained(\"text-bison\")\n  parameters = {\n    \"candidate_count\": 2,\n    \"max_output_tokens\": 1024,\n    \"temperature\": 0.9,\n    \"top_p\": 1\n    }\n  response = model.predict(\n    prompt,\n    **parameters\n    )\n  return response\nresult = generate(\"Tell me a joke about cars\")\nfor candidate in result.candidates:\n  print(f\"Response Candidate: {candidate}\\n\\n\") \n```", "```py\ndef generate(prompt):\n  model = TextGenerationModel.from_pretrained(\"text-bison\")\n  parameters = {\n    \"candidate_count\": 2,\n    \"max_output_tokens\": 1024,\n    \"temperature\": 0.5,\n    \"top_p\": 1\n    }\n  response = model.predict(\n    prompt,\n    **parameters\n    )\n  return response \n```", "```py\nresult = generate(\"Tell me a joke about cars\")\nfor candidate in result.candidates:\n  print(f\"Response Candidate: {candidate}\\n\\n\") \n```", "```py\nResponse Candidate:  Why did the car get a parking ticket?\nBecause it was parked illegally.\nResponse Candidate:  Why did the car get a speeding ticket?\nBecause it was going too fast! \n```", "```py\nPrompt: Tell me a joke about cars\nResult:\nWhy don't cars like to go to the beach?\nBecause they just want to dune it. \n```", "```py\nPrompt:\nExpand the following text in two paragraphs:\nWhy don't cars like to go to the beach?\nBecause they just want to dune it.\nResult: \nCars, unlike humans and other creatures, harbor an aversion to the sandy shores of the beach. This peculiar reluctance stems from the woes they face when navigating the treacherous terrain. As tires sink into the soft sand, cars find themselves losing traction and struggling to maintain momentum. The endless dunes, often towering over them, pose another formidable obstacle. Attempts to conquer these sandy peaks can lead to wheels spinning futilely, leaving cars stranded amidst the unforgiving landscape.\nTherefore, while the beach beckons with its allure of sun, sand, and surf, cars prefer to remain on paved roads, where they can glide effortlessly without the fear of getting bogged down. Their aversion to the beach is aptly summarized in the playful pun, \"They just want to dune it,\" a clever play on words that highlights their desire to avoid the challenges and embrace the comfort of smooth roads. \n```", "```py\ndef generate(prompt):\n  model = TextGenerationModel.from_pretrained(\"text-bison\")\n  parameters = {\n    \"candidate_count\": 2,\n    \"max_output_tokens\": 1024,\n    \"temperature\": 0.9,\n    \"top_p\": 1\n  }\n  response = model.predict(\n    prompt,\n    **parameters\n  )\n  return response \n```", "```py\nresult = generate(\"Tell me a joke about cars\")\nfor candidate in result.candidates:\n  print(f\"Response Candidate: {candidate}\\n\\n\") \n```", "```py\nResponse Candidate:  What does a car with road rage suffer from?\nAnswer: A road rash.\nResponse Candidate:  What did one car say to the other car as it drove past? We should race and I bet I will win.\nWhat did the other car say? Don't be silly there is no way you can beat a Volkswagen! \n```", "```py\nresult = generate(f\"Modify this joke to be a sonnet with no more than 2 verses: {result.candidates[0].text} \")\nfor candidate in result.candidates:\n  print(f\"Response Candidate: {candidate}\\n\\n\") \n```", "```py\nResponse Candidate:  A chariot of fire, its engine's beat,\nA symphony of power, fierce and wild,\nWith burning wheels, it danced upon the street,\nA tempest unleashed, untamed and beguiled.\nIts metal frame, a vessel of desire,\nA rebel's heart that yearned for freedom's call,\nThrough winding roads, it sparked electric fire,\nA fearless spirit, soaring high and tall.\nResponse Candidate:  A car of wrath with engine's fiery might,\nIts metal frame roars to the storm within,\nIts wheels devour the roads in ravenous fight,\nAn elemental fury none can win.\nIts tires are scorching marks upon the ground,\nAs it dances wildly under fate's harsh glance,\nWith bruised fenders and paintwork battle-bound,\nThis rage-filled vessel knows no calm expanse. \n```", "```py\n{\n  \"timestamp\":,\n  \"user_input\":, \n  \"context\": ,\n  \"pre_prosessing_prompt_template\": ,\n  \"model\": ,\n  \"result_payload\":\n  \"post_prosessing_prompt_template\":\n} \n```"]