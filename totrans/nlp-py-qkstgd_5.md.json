["```py\nfrom pathlib import Path\nimport pandas as pd\nimport gzip\nfrom urllib.request import urlretrieve\nfrom tqdm import tqdm\nimport os\nimport numpy as np\n\nclass TqdmUpTo(tqdm):\n    def update_to(self, b=1, bsize=1, tsize=None):\n        if tsize is not None: self.total = tsize\n        self.update(b * bsize - self.n)\n```", "```py\ndef get_data(url, filename):\n    \"\"\"\n    Download data if the filename does not exist already\n    Uses Tqdm to show download progress\n    \"\"\"\n    if not os.path.exists(filename):\n\n        dirname = os.path.dirname(filename)\n        if not os.path.exists(dirname):\n            os.makedirs(dirname)\n\n        with TqdmUpTo(unit='B', unit_scale=True, miniters=1, desc=url.split('/')[-1]) as t:\n            urlretrieve(url, filename, reporthook=t.update_to)\n```", "```py\ndata_url = 'http://files.fast.ai/data/aclImdb.tgz'\nget_data(data_url, 'data/imdb.tgz')\n```", "```py\ndata_path = Path(os.getcwd())/'data'/'imdb'/'aclImdb'\nassert data_path.exists()\nfor pathroute in os.walk(data_path):\n    next_path = pathroute[1]\n    for stop in next_path:\n        print(stop)\n```", "```py\nTest\n |- all\n |- neg\n |- pos\n\n Train\n |- all\n |- neg\n |- pos\n |- unsup\n```", "```py\ntrain_path = data_path/'train'\ntest_path = data_path/'test'\n\ndef read_data(dir_path):\n    \"\"\"read data into pandas dataframe\"\"\"\n\n    def load_dir_reviews(reviews_path):\n        files_list = list(reviews_path.iterdir())\n        reviews = []\n        for filename in files_list:\n            f = open(filename, 'r', encoding='utf-8')\n            reviews.append(f.read())\n        return pd.DataFrame({'text':reviews})\n\n    pos_path = dir_path/'pos'\n    neg_path = dir_path/'neg'\n\n    pos_reviews, neg_reviews = load_dir_reviews(pos_path), load_dir_reviews(neg_path)\n\n    pos_reviews['label'] = 1\n    neg_reviews['label'] = 0\n\n    merged = pd.concat([pos_reviews, neg_reviews])\n    merged.reset_index(inplace=True)\n\n    return merged\n```", "```py\ntrain = read_data(train_path)\ntest = read_data(test_path)\n\nX_train, y_train = train['text'], train['label']\nX_test, y_test = test['text'], test['label']\n```", "```py\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n```", "```py\nfrom sklearn.linear_model import LogisticRegression as LR\nlr_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf',LR())])\n```", "```py\nlr_clf.fit(X=X_train, y=y_train) # note that .fit function calls are inplace, and the Pipeline is not re-assigned\n```", "```py\nlr_predicted = lr_clf.predict(X_test)\n```", "```py\nlr_acc = sum(lr_predicted == y_test)/len(lr_predicted)\nlr_acc # 0.88316\n```", "```py\ndef imdb_acc(pipeline_clf):\n    predictions = pipeline_clf.predict(X_test)\n    assert len(y_test) == len(predictions)\n    return sum(predictions == y_test)/len(y_test), predictions\n```", "```py\nlr_clf = Pipeline([('vect', CountVectorizer(stop_words='english')), ('tfidf', TfidfTransformer()), ('clf',LR())])\nlr_clf.fit(X=X_train, y=y_train)\nlr_acc, lr_predictions = imdb_acc(lr_clf)\nlr_acc # 0.879\n```", "```py\nlr_clf = Pipeline([('vect', CountVectorizer(stop_words='english', ngram_range=(1,3))), ('tfidf', TfidfTransformer()), ('clf',LR())])\nlr_clf.fit(X=X_train, y=y_train)\nlr_acc, lr_predictions = imdb_acc(lr_clf)\nlr_acc # 0.86596\n```", "```py\nfrom sklearn.naive_bayes import MultinomialNB as MNB\nmnb_clf = Pipeline([('vect', CountVectorizer()), ('clf',MNB())])\n```", "```py\nmnb_clf.fit(X=X_train, y=y_train)\nmnb_acc, mnb_predictions = imdb_acc(mnb_clf)\nmnb_acc # 0.81356\n```", "```py\nmnb_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf',MNB())])\nmnb_clf.fit(X=X_train, y=y_train)\nmnb_acc, mnb_predictions = imdb_acc(mnb_clf)\nmnb_acc # 0.82956\n```", "```py\nmnb_clf = Pipeline([('vect', CountVectorizer(stop_words='english')), ('tfidf', TfidfTransformer()), ('clf',MNB())])\nmnb_clf.fit(X=X_train, y=y_train)\nmnb_acc, mnb_predictions = imdb_acc(mnb_clf)\nmnb_acc # 0.82992 \n```", "```py\nmnb_clf = Pipeline([('vect', CountVectorizer(stop_words='english', ngram_range=(1,3))), ('tfidf', TfidfTransformer()), ('clf',MNB())])\nmnb_clf.fit(X=X_train, y=y_train)\nmnb_acc, mnb_predictions = imdb_acc(mnb_clf)\nmnb_acc # 0.8572\n```", "```py\nmnb_clf = Pipeline([('vect', CountVectorizer(stop_words='english', ngram_range=(1,3))), ('tfidf', TfidfTransformer()), ('clf',MNB(fit_prior=False))])\nmnb_clf.fit(X=X_train, y=y_train)\nmnb_acc, mnb_predictions = imdb_acc(mnb_clf)\nmnb_acc # 0.8572\n```", "```py\nfrom sklearn.svm import SVC\nsvc_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf',SVC())])\nsvc_clf.fit(X=X_train, y=y_train)\nsvc_acc, svc_predictions = imdb_acc(svc_clf)\nprint(svc_acc) # 0.6562\n```", "```py\nfrom sklearn.tree import DecisionTreeClassifier as DTC\ndtc_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf',DTC())])\ndtc_clf.fit(X=X_train, y=y_train)\ndtc_acc, dtc_predictions = imdb_acc(dtc_clf)\ndtc_acc # 0.7028\n```", "```py\nfrom sklearn.ensemble import RandomForestClassifier as RFC\nrfc_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf',RFC())])\nrfc_clf.fit(X=X_train, y=y_train)\nrfc_acc, rfc_predictions = imdb_acc(rfc_clf)\nrfc_acc # 0.7226\n```", "```py\nfrom sklearn.ensemble import ExtraTreesClassifier as XTC\nxtc_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf',XTC())])\nxtc_clf.fit(X=X_train, y=y_train)\nxtc_acc, xtc_predictions = imdb_acc(xtc_clf)\nxtc_acc # 0.75024\n```", "```py\nfrom sklearn.model_selection import RandomizedSearchCV\nparam_grid = dict(clf__C=[50, 75, 85, 100], \n                  vect__stop_words=['english', None],\n                  vect__ngram_range = [(1, 1), (1, 3)],\n                  vect__lowercase = [True, False],\n                 )\n```", "```py\nrandom_search = RandomizedSearchCV(lr_clf, param_distributions=param_grid, n_iter=5, scoring='accuracy', n_jobs=-1, cv=3)\nrandom_search.fit(X_train, y_train)\nprint(f'Calculated cross-validation accuracy: {random_search.best_score_}')\n```", "```py\nbest_random_clf = random_search.best_estimator*_* best_random_clf.fit(X_train, y_train)\nimdb_acc(best_random_clf) # 0.90096\n```", "```py\nprint(best_random_clf.steps)\n\n[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n          dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n          lowercase=True, max_df=1.0, max_features=None, min_df=1,\n          ngram_range=(1, 3), preprocessor=None, stop_words=None,\n          strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n          tokenizer=None, vocabulary=None)),\n ('tfidf',\n  TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)),\n ('clf',\n  LogisticRegression(C=75, class_weight=None, dual=False, fit_intercept=True,\n            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n            penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n            verbose=0, warm_start=False))]\n```", "```py\nfrom sklearn.model_selection import GridSearchCV\nparam_grid = dict(clf__C=[85, 100, 125, 150])\ngrid_search = GridSearchCV(lr_clf, param_grid=param_grid, scoring='accuracy', n_jobs=-1, cv=3)\ngrid_search.fit(X_train, y_train)\ngrid_search.best_estimator_.steps\n```", "```py\n[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n          dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n          lowercase=True, max_df=1.0, max_features=None, min_df=1,\n          ngram_range=(1, 3), preprocessor=None, stop_words=None,\n          strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n          tokenizer=None, vocabulary=None)),\n ('tfidf',\n  TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)),\n ('clf',\n  LogisticRegression(C=150, class_weight=None, dual=False, fit_intercept=True,\n            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n            penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n            verbose=0, warm_start=False))]\n```", "```py\nprint(f'Calculated cross-validation accuracy: {grid_search.best_score_} while random_search was {random_search.best_score_}')\n\n> Calculated cross-validation accuracy: 0.87684 while random_search was 0.87648\n\nbest_grid_clf = grid_search.best_estimator_\nbest_grid_clf.fit(X_train, y_train)\n\nimdb_acc(best_grid_clf) \n> (0.90208, array([1, 1, 1, ..., 0, 0, 1], dtype=int64))\n```", "```py\nfrom sklearn.ensemble import VotingClassifier\nvoting_clf = VotingClassifier(estimators=[('xtc', xtc_clf), ('rfc', rfc_clf)], voting='hard', n_jobs=-1)\nvoting_clf.fit(X_train, y_train)\nhard_voting_acc, _ = imdb_acc(voting_clf)\nhard_voting_acc # 0.71092\n```", "```py\nvoting_clf = VotingClassifier(estimators=[('lr', lr_clf), ('mnb', mnb_clf)], voting='soft', n_jobs=-1)\nvoting_clf.fit(X_train, y_train)\nsoft_voting_acc, _ = imdb_acc(voting_clf)\nsoft_voting_acc # 0.88216\n```", "```py\nweighted_voting_clf = VotingClassifier(estimators=[('lr', lr_clf), ('lr2', lr_clf),('rf', xtc_clf), ('mnb2', mnb_clf),('mnb', mnb_clf)], voting='soft', n_jobs=-1)\nweighted_voting_clf.fit(X_train, y_train)\n```", "```py\n\nweighted_voting_acc, _ = imdb_acc(weighted_voting_clf)\nweighted_voting_acc # 0.88092\n```", "```py\n1111111100 = 80% accuracy\n 1111111100 = 80% accuracy\n 1011111100 = 70% accuracy\n```", "```py\n1111111100 = 80% accuracy\n```", "```py\n1111111100 = 80% accuracy\n 0111011101 = 70% accuracy\n 1000101111 = 60% accuracy\n```", "```py\n1111111101 = 90% accuracy\n```", "```py\n\n np.corrcoef(mnb_predictions, lr_predictions)[0][1] # this is too high a correlation at 0.8442355164021454\n\ncorr_voting_clf = VotingClassifier(estimators=[('lr', lr_clf), ('mnb', mnb_clf)], voting='soft', n_jobs=-1)\ncorr_voting_clf.fit(X_train, y_train)\ncorr_acc, _ = imdb_acc(corr_voting_clf)\n print(corr_acc) # 0.88216 \n```", "```py\nnp.corrcoef(dtc_predictions,xtc_predictions )[0][1] # this is looks like a low correlation # 0.3272698219282598\n\nlow_corr_voting_clf = VotingClassifier(estimators=[('dtc', dtc_clf), ('xtc', xtc_clf)], voting='soft', n_jobs=-1)\nlow_corr_voting_clf.fit(X_train, y_train)\nlow_corr_acc, _ = imdb_acc(low_corr_voting_clf)\n print(low_corr_acc) # 0.70564\n```"]