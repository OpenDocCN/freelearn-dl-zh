- en: '5'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Integration Pattern: Batch Metadata Extraction'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will explore a metadata extraction use case, which serves
    as an excellent entry point to understand the capabilities of **Generative Artificial
    Intelligence** (**GenAI**). This topic is particularly relevant across industries
    and thought-provoking.
  prefs: []
  type: TYPE_NORMAL
- en: To illustrate this use case, let us consider a scenario where we work with a
    financial services company that requires the extraction of data from a 10-K report.
    These reports, filed annually with the **Securities and Exchange Commission**
    (**SEC**) by publicly traded companies, provide a comprehensive overview of their
    financial performance, operations, and significant events. They are extensive
    documents that are over 100 pages long and contain a wealth of information, structured
    across different sections across different data modalities (tables, text, etc.).
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, our objective is to identify the specific dataset and critical
    data points that need to be extracted from this vast repository of information.
    This process requires a systematic approach to pinpoint the desired data points
    with precision.
  prefs: []
  type: TYPE_NORMAL
- en: Once the relevant data points have been identified, we will determine the appropriate
    storage location for this extracted data. This could involve a centralized database
    accessible to authorized individuals within the organization, or a cloud-based
    repository that facilitates seamless access and collaboration across teams and
    locations.
  prefs: []
  type: TYPE_NORMAL
- en: Regardless of the chosen storage solution, GenAI will play a pivotal role throughout
    this endeavor. With its ability to understand and process natural language, GenAI
    will prove invaluable in navigating the intricate structure of financial reports,
    extracting the essential data points with remarkable efficiency and accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will cover the following main topics in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Use case definition**: We will describe an example scenario of extracting
    metadata from a 10-K report for a financial services company, explaining the structure
    and importance of these reports.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Architecture**: We will outline a cloud-based, serverless architecture using
    Google Cloud services to process 10-K reports, including storage, messaging, processing,
    and database components.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Entry point**: We will explain how the batch processing pipeline is triggered,
    using Google Cloud Storage and Cloud Functions to initiate the content extraction
    process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Prompt pre-processing**: We will detail the creation of an initial prompt
    for the AI model, leveraging SEC guidance to identify key data points for extraction
    from 10-K reports.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Inference**: We will discuss the submission of the prompt to Gemini Pro 1.5
    via Vertex AI, showcasing how the model processes and extracts information from
    the 10-K report.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Result post processing**: We will cover parsing the JSON output from the
    **large language model** (**LLM**) and the strategies to ingest the extracted
    data into databases, considering both relational and document database options.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Result presentation**: We will consider how to present the extracted data,
    including the use of business intelligence tools, data visualization platforms,
    and custom applications.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Code sample**: We will provide a practical implementation of the metadata
    extraction process, including setup, prompt creation, inference, and result handling.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use case definition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Extracting metadata from 10-K reports holds significant value for financial
    services companies and other stakeholders. These reports, mandated by the SEC,
    are a treasure trove of information that can provide valuable insights into a
    company’s financial health, operational performance, and strategic direction.
    However, the sheer volume, complexity of these documents, and lack of consistency
    across the way companies build their reports can make it challenging to manually
    extract and analyze the relevant data points.
  prefs: []
  type: TYPE_NORMAL
- en: Typical 10-K reports follow a standardized structure, comprising multiple sections
    that cover various aspects of a company’s operations. These sections may include
    a business overview, risk factors, management’s discussion and analysis, financial
    statements, and disclosures about corporate governance, among others. While the
    structure is consistent across companies, the specific data points and their presentation
    can vary, making it difficult to establish a one-size-fits-all approach to data
    extraction.
  prefs: []
  type: TYPE_NORMAL
- en: 'The 10-K includes five distinct sections:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Business**: This section provides an overview of the company’s main operations,
    including its products and services, key markets, competitive landscape, and other
    relevant details about its business model and operations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Risk factors**: In this section, the company outlines and discusses any,
    and all, risks it faces. This includes operational, financial, legal, regulatory,
    and industry-specific risks that could potentially impact its performance or future
    prospects.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Selected financial data**: This section presents specific financial information
    about the company over the last five years, typically including key metrics such
    as revenue, net income, earnings per share, and other relevant financial data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Management’s Discussion and Analysis** (**MD&A**): The fourth section offers
    senior management’s explanation and analysis of the company’s financial results,
    including a detailed discussion of the factors that influenced its performance,
    future strategies, and potential opportunities and challenges.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Financial statements and supplementary data**: The final section furnishes
    the audited financial statements, including the income statement, balance sheets,
    statement of cash flows, and accompanying notes and disclosures. This section
    provides a comprehensive and detailed picture of the company’s financial position
    and performance during the reporting period.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The biggest challenge to these documents is that specific data points and their
    presentation can vary, making it very difficult to establish a one-size-fits-all
    approach to data extraction. However, by leveraging GenAI’s natural language processing
    capabilities, financial services companies can efficiently navigate this structured
    format and extract relevant data points from each section, tailoring their approach
    to the unique characteristics of each company’s report.
  prefs: []
  type: TYPE_NORMAL
- en: The availability of structured metadata extracted from these documents opens
    up opportunities for financial services companies. For example, they can conduct
    an in-depth analysis of a company’s financial performance, benchmarking it against
    industry peers or historical trends. This analysis can inform investment decisions,
    risk assessments, and strategic planning efforts.
  prefs: []
  type: TYPE_NORMAL
- en: Another opportunity would be to leverage the extracted metadata to develop predictive
    models and identify patterns that may not be immediately apparent from manual
    analysis. These models can help anticipate potential risks, identify emerging
    trends, and uncover new investment opportunities.
  prefs: []
  type: TYPE_NORMAL
- en: Thinking further, the extracted metadata can be integrated into existing data
    repositories or business intelligence platforms, enabling seamless access and
    collaboration among various teams within the organization. This integration can
    foster cross-functional collaboration, enabling different departments, such as
    investment banking, asset management, and risk management, to leverage the same
    data for their respective analyses and decision-making processes.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to financial services companies, the extracted metadata can also
    be valuable for regulatory bodies, academic researchers, and other stakeholders
    interested in studying corporate performance, industry trends, and the overall
    health of the financial markets.
  prefs: []
  type: TYPE_NORMAL
- en: By leveraging the power of GenAI to extract metadata from 10-K reports, financial
    services companies can unlock a wealth of insights, streamline their analysis
    processes, and make more informed decisions that drive business growth and mitigate
    risks.
  prefs: []
  type: TYPE_NORMAL
- en: Architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Though the scope of this book is not to provide a deep dive into the intricacies
    of a LLM processing architecture, we will briefly discuss what a cloud-based architecture
    for our metadata extraction use case might look like. For this example, we will
    leverage the capabilities of Google Cloud, as it offers a native AI platform called
    Vertex AI that allows us to seamlessly integrate leading models, including Google’s
    Gemini and third-party models such as Anthropic’s Claude, in an enterprise-compliant
    manner.
  prefs: []
  type: TYPE_NORMAL
- en: The approach we’ll adopt for this use case is to leverage a batch-optimized
    architecture, which is suitable for processing large volumes of data in an efficient
    and scalable manner. This kind of architecture aligns with cloud-native principles
    and is a serverless architecture that leverages various Google Cloud services.
  prefs: []
  type: TYPE_NORMAL
- en: This architecture will consist of an object store (Google Cloud Storage) to
    store the 10-K reports, a messaging queue (Google Cloud Pub/Sub) to coordinate
    the data flow, a processing component (Google Cloud Functions) to execute the
    LLM-based metadata extraction tasks, an LLM model (such as Google Gemini hosted
    on Vertex-AI) to perform the actual extraction, and a database (Google Big-Query)
    to store the extracted metadata.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s a more detailed breakdown of how this architecture will function:'
  prefs: []
  type: TYPE_NORMAL
- en: The 10-K reports are stored in Google Cloud Storage, a highly scalable and durable
    object store.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A Cloud Function is triggered periodically (for example, daily or weekly) to
    initiate the metadata extraction process.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A Cloud Function will read a list of 10-K reports from Cloud Storage and publish
    messages to a Pub/Sub topic, effectively creating a queue of reports to be processed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Another Cloud Function, subscribed to the Pub/Sub topic, is triggered for each
    message tied to a given report in the queue.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This second Cloud Function invokes the LLM model (for example, Google Gemini)
    hosted on Vertex-AI, passing the 10-K report content as input.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The LLM model processes the report, leveraging its natural language understanding
    capabilities to extract the relevant metadata.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The extracted metadata is then stored in a structured format (for example, BigQuery)
    for further analysis and consumption.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This serverless architecture provides several benefits, including automatic
    scaling, cost-efficiency (pay-per-use pricing), and seamless integration with
    other Google Cloud services.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B22175_05_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.1: GenAI document data extraction pipeline'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram showcases the architecture that will be leveraged in
    this example, following our GenAI integration framework discussed in *Chapter
    3*, *Designing Patterns for Interacting with Generative AI*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B22175_05_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.2: The Application Integration Framework'
  prefs: []
  type: TYPE_NORMAL
- en: Entry point
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The entry point for our batch processing pipeline will be an object created
    in **Google Cloud Storage** (**GCS**), which will then trigger a Google Cloud
    Function to start the processing pipeline. This setup allows us to seamlessly
    integrate with existing workflows, where the 10-K reports are uploaded to a designated
    GCS bucket. By leveraging the event-driven nature of Cloud Functions, our system
    can automatically get into action as soon as a new report lands in the storage
    bucket.
  prefs: []
  type: TYPE_NORMAL
- en: Once triggered, the Cloud Function will initiate the content extraction process.
    For this step, we’ve decided to employ the powerful capabilities of Google’s Gemini
    Pro 1.5, a state-of-the-art GenAI multimodal model that supports processing PDF
    documents directly. Gemini Pro 1.5 will analyze the uploaded 10-K report, intelligently
    extracting not only the textual content but also the relevant data points we’re
    interested in, such as financial figures, company overviews, and key performance
    indicators.
  prefs: []
  type: TYPE_NORMAL
- en: By leveraging Gemini Pro 1.5’s advanced natural language processing and document
    understanding capabilities, we can obtain a comprehensive transcript of the report’s
    content. This transcript will serve as the foundation for further analysis and
    processing steps in our pipeline. Additionally, the extracted data points will
    be structured and organized in a format of our choosing (JSON, Markup, etc.),
    defined in the prompt, allowing us to seamlessly integrate them into our downstream
    systems to generate insightful summaries, visualizations, and other valuable outputs.
  prefs: []
  type: TYPE_NORMAL
- en: Prompt pre-processing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As a first step, we will start elaborating a prompt to extract the essential
    data points required to comprehensively understand a 10-K document. To guide our
    efforts, we will leverage a valuable resource provided by the SEC itself – a document
    titled *How to Read a 10k*, which is available on the SEC website ([https://www.sec.gov/files/reada10k.pdf](https://www.sec.gov/files/reada10k.pdf)).
  prefs: []
  type: TYPE_NORMAL
- en: This SEC-provided document serves as a very useful roadmap, outlining the critical
    sections and information that investors and analysts should focus on when delving
    into a company’s 10-K filing. By carefully studying this resource, we can identify
    the key data points that are most relevant and insightful, ensuring that our GenAI
    system extracts the information that truly matters.
  prefs: []
  type: TYPE_NORMAL
- en: To kickstart our data extraction process, we will create a simple yet effective
    prompt for our GenAI model. This initial prompt will serve as a starting point,
    instructing the model to identify and extract the specific data points outlined
    in the *How to Read a 10k* document. While this initial prompt may be concise,
    it will lay the foundation for more sophisticated prompts and fine-tuning techniques
    as our project progresses. The goal is to iteratively refine our prompts, leveraging
    the power of GenAI to extract the most crucial information accurately and efficiently
    from these complex financial documents.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is example output from the previous prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have a template of what to look for in the actual 10-K, we can
    create a prompt to extract those data points:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Note that the template has very specific instructions on what to do as well
    as what *not* to do. This is a best practice for prompting LLMs, as these models
    require such specific instructions in order to effectively give you precise information.
    A good analogy is to guide them as if they are a first-year student, offering
    clear instructions and providing as much context as possible.
  prefs: []
  type: TYPE_NORMAL
- en: Inference
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For the inference, we are going to submit our prompt to Gemini Pro 1.5 available
    through Vertex-AI.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Vertex AI Gemini API is tailored for developers and enterprises seeking
    to incorporate Gemini models into scaled deployments. This enterprise-grade offering
    provides a robust set of features designed to meet the demands of modern, high-performance
    applications. With the Vertex AI Gemini API, you can benefit from enhanced enterprise
    security measures, ensuring that your data and models are protected with industry-leading
    safeguards. Additionally, it offers data residency options, allowing you to comply
    with regional data storage and processing regulations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Note that there are configurations available to play with in the API. You can
    check the specific call in the code provided in the GitHub repository of the book.
  prefs: []
  type: TYPE_NORMAL
- en: Result post-processing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once the LLM has processed the 10-K reports, it will return the results in a
    structured JSON format. This JSON document will contain the extracted data points,
    organized in a hierarchical manner that aligns with the structure of the 10-K
    report itself. To effectively utilize these results, we will need to parse the
    JSON document and extract the relevant information.
  prefs: []
  type: TYPE_NORMAL
- en: The next step in our pipeline is to ingest the parsed data into a database for
    efficient storage and retrieval. The specific ingestion strategy will depend on
    the type of database we choose to employ. For example, if we opt for a relational
    database, we will need to map the extracted data points to appropriate table structures,
    ensuring proper normalization and adherence to data integrity principles.
  prefs: []
  type: TYPE_NORMAL
- en: Alternatively, if we decide to use a document database, the ingestion process
    will be more straightforward, as these databases are designed to store hierarchical
    data structures, such as JSON documents, natively. In this case, we can directly
    ingest the parsed JSON results, leveraging the database’s ability to efficiently
    store and query complex data structures.
  prefs: []
  type: TYPE_NORMAL
- en: Regardless of the database type chosen, it is crucial to design an ingestion
    strategy that ensures data consistency, scalability, and performance. This may
    involve implementing strategies such as bulk ingestion, indexing, and partitioning
    to optimize the database’s performance and ensure efficient retrieval of the extracted
    data points.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to storing the extracted data points, we can also consider generating
    embeddings for the various sections of the 10-K reports. Embeddings are vector
    representations of text that capture semantic meaning, enabling efficient similarity
    searches and retrieval. By generating embeddings for the report sections, we can
    integrate our dataset with a vector search pipeline, allowing users to perform
    advanced queries based on semantic similarity.
  prefs: []
  type: TYPE_NORMAL
- en: For a deep dive into embeddings generation and vector search integration, we
    will cover the **Retrieval Augmented Generation** (**RAG**) example in a dedicated
    chapter. This chapter will provide detailed insights into the process of generating
    embeddings, constructing vector databases, and implementing efficient vector search
    algorithms, enabling you to create powerful search and retrieval capabilities
    for your GenAI applications.
  prefs: []
  type: TYPE_NORMAL
- en: Result presentation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When it comes to presenting the results obtained from processing the 10-K reports,
    it’s important to consider the fact that these results are ingested into a database.
    This means that the considerations you’ll need to make are similar to those you
    would have when developing an experience that leverages data available in a database.
  prefs: []
  type: TYPE_NORMAL
- en: One of the primary considerations is the need for a tool or platform that can
    effectively aggregate and analyze data stored in a database. This could be a **business
    intelligence** (**BI**) tool, a data visualization platform, or even a custom-built
    application tailored to your specific needs. The chosen tool should provide robust
    querying capabilities, enabling you to extract and combine data from various tables
    or collections within the database.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, the presentation layer should offer a range of visualization options,
    such as charts, graphs, and dashboards, to effectively communicate the insights
    derived from the data. These visualizations should be interactive, allowing users
    to explore the data from different perspectives, filter and sort the results,
    and drill down into specific areas of interest.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, the presentation layer should be designed with scalability and
    performance in mind. As the volume of data grows over time, the ability to handle
    large datasets and provide responsive user experiences becomes crucial. This may
    involve implementing techniques such as caching, indexing, and optimizing database
    queries to ensure efficient data retrieval and rendering.
  prefs: []
  type: TYPE_NORMAL
- en: On the GitHub directory for this chapter, you will find the complete code and
    an analysis of how all the layers described in this chapter fit together.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we explored metadata extraction from financial documents, specifically
    10-K reports filed by publicly traded companies. We walked through the experience
    of working with a financial services firm that needs to extract key data points
    from these massive 10-K annual reports, leveraging the data extraction capabilities
    of LLMs.
  prefs: []
  type: TYPE_NORMAL
- en: We defined the use case, and we leveraged the power of GenAI to navigate through
    the structured sections of a 10-K, pinpointing and extracting the most relevant
    information nuggets, following the guidance provided by a best practices document.
    We walked through the process, starting by crafting an effective prompt to guide
    the AI model. This involved studying an SEC resource that outlines the critical
    sections and data points that investors should focus on. Armed with this knowledge,
    we can iteratively refine our prompts to ensure accurate and efficient extraction.
  prefs: []
  type: TYPE_NORMAL
- en: Then, we proposed a cloud-native, serverless architecture on Google Cloud to
    handle the batch processing of these documents. This scalable setup can leverage
    various services like Cloud Storage, Pub/Sub, and Cloud Functions, allowing us
    to seamlessly integrate the AI model and store the extracted data.
  prefs: []
  type: TYPE_NORMAL
- en: The chapter also touched on post-processing steps, such as ingesting the extracted
    data into a database (relational or document-based), potentially generating embeddings
    for vector similarity searches, and presenting the results through BI tools or
    custom applications with interactive visualizations.
  prefs: []
  type: TYPE_NORMAL
- en: In summary, this chapter offered you a practical blueprint to utilize GenAI
    to enhance the extraction and analysis of critical information from complex financial
    documents. It demonstrated how you can leverage this technology to make more informed
    decisions and uncover valuable insights, thereby optimizing your operational efficiency
    and strategic capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will examine a summarization use case. This example
    will illustrate another instance of what a batch processing use case could look
    like.
  prefs: []
  type: TYPE_NORMAL
- en: Join our community on Discord
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join our community’s Discord space for discussions with the authors and other
    readers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/genpat](Chapter_05.xhtml)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code134841911667913109.png)'
  prefs: []
  type: TYPE_IMG
