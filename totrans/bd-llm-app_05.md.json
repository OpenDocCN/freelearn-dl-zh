["```py\nfrom langchain.llms import OpenAI\nllm = OpenAI(openai_api_key=\"your-api-key\")\nprint(llm('tell me a joke')) \n```", "```py\nQ: What did one plate say to the other plate?\nA: Dinner's on me! \n```", "```py\nSentence: {sentence}\nTranslation in {language}: \n```", "```py\nfrom langchain import PromptTemplate\ntemplate = \"\"\"Sentence: {sentence}\nTranslation in {language}:\"\"\"\nprompt = PromptTemplate(template=template, input_variables=[\"sentence\", \"language\"])\nprint(prompt.format(sentence = \"the cat is on the table\", language = \"spanish\")) \n```", "```py\nSentence: the cat is on the table\nTranslation in spanish: \n```", "```py\n    {\"prompt\": \"<prompt text>\", \"completion\": \"<ideal generated text>\"} \n    ```", "```py\nfrom langchain.document_loaders.csv_loader import CSVLoader\nloader = CSVLoader(file_path='sample.csv')\ndata = loader.load()\nprint(data) \n```", "```py\n[Document(page_content='Name: John\\nAge: 25\\nCity: New York', metadata={'source': 'sample.csv', 'row': 0}), Document(page_content='Name: Emily\\nAge: 28\\nCity: Los Angeles', metadata={'source': 'sample.csv', 'row': 1}), Document(page_content='Name: Michael\\nAge: 22\\nCity: Chicago', metadata={'source': 'sample.csv', 'row': 2})] \n```", "```py\nwith open('mountain.txt') as f:\n    mountain = f.read()\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\ntext_splitter = RecursiveCharacterTextSplitter(\n    chunk_size = 100, #number of characters for each chunk\n    chunk_overlap  = 20,#number of characters overlapping between a preceding and following chunk\n    length_function = len #function used to measure the number of characters\n)\ntexts = text_splitter.create_documents([mountain])\nprint(texts[0])\nprint(texts[1])\nprint(texts[2]) \n```", "```py\npage_content=\"Amidst the serene landscape, towering mountains stand as majestic guardians of nature's beauty.\" metadata={}\npage_content='The crisp mountain air carries whispers of tranquility, while the rustling leaves compose a' metadata={} \n```", "```py\nfrom langchain.embeddings import OpenAIEmbeddings\nfrom dotenv import load_dotenv\nload_dotenv()\nos.environ[\"OPENAI_API_KEY\"]\nembeddings_model = OpenAIEmbeddings(model ='text-embedding-ada-002' )\nembeddings = embeddings_model.embed_documents(\n    [\n        \"Good morning!\",\n        \"Oh, hello!\",\n        \"I want to report an accident\",\n        \"Sorry to hear that. May I ask your name?\",\n        \"Sure, Mario Rossi.\"\n    ]\n)\nprint(\"Embed documents:\")\nprint(f\"Number of vector: {len(embeddings)}; Dimension of each vector: {len(embeddings[0])}\")\nembedded_query = embeddings_model.embed_query(\"What was the name mentioned in the conversation?\")\nprint(\"Embed query:\")\nprint(f\"Dimension of the vector: {len(embedded_query)}\")\nprint(f\"Sample of the first 5 elements of the vector: {embedded_query[:5]}\") \n```", "```py\nEmbed documents:\nNumber of vector: 5; Dimension of each vector: 1536\nEmbed query:\nDimension of the vector: 1536\nSample of the first 5 elements of the vector: [0.00538721214979887, -0.0005941778072156012, 0.03892524912953377, -0.002979141427204013, -0.008912666700780392] \n```", "```py\nfrom langchain.document_loaders import TextLoader\nfrom langchain.embeddings.openai import OpenAIEmbeddings\nfrom langchain.text_splitter import CharacterTextSplitter\nfrom langchain.vectorstores import FAISS\nfrom dotenv import load_dotenv\nload_dotenv()\nos.environ[\"OPENAI_API_KEY\"]\n# Load the document, split it into chunks, embed each chunk and load it into the vector store.\nraw_documents = TextLoader('dialogue.txt').load()\ntext_splitter = CharacterTextSplitter(chunk_size=50, chunk_overlap=0, separator = \"\\n\",)\ndocuments = text_splitter.split_documents(raw_documents)\ndb = FAISS.from_documents(documents, OpenAIEmbeddings()) \n```", "```py\nquery = \"What is the reason for calling?\"\ndocs = db.similarity_search(query)\nprint(docs[0].page_content) \n```", "```py\nI want to report an accident \n```", "```py\nfrom langchain.chains import RetrievalQA\nfrom langchain.llms import OpenAI\nretriever = db.as_retriever()\nqa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", retriever=retriever)\nquery = \"What was the reason of the call?\"\nqa.run(query) \n```", "```py\n' The reason for the call was to report an accident.' \n```", "```py\nfrom langchain.memory import ConversationSummaryMemory, ChatMessageHistory\nfrom langchain.llms import OpenAI\nmemory = ConversationSummaryMemory(llm=OpenAI(temperature=0))\nmemory.save_context({\"input\": \"hi, I'm looking for some ideas to write an essay in AI\"}, {\"output\": \"hello, what about writing on LLMs?\"})\nmemory.load_memory_variables({}) \n```", "```py\n{'history': '\\nThe human asked for ideas to write an essay in AI and the AI suggested writing on LLMs.'} \n```", "```py\nfrom langchain import PromptTemplate\ntemplate = \"\"\"Sentence: {sentence}\nTranslation in {language}:\"\"\"\nprompt = PromptTemplate(template=template, input_variables=[\"sentence\", \"language\"]) \n```", "```py\nfrom langchain import OpenAI, LLMChain\nllm = OpenAI(temperature=0)\nllm_chain = LLMChain(prompt=prompt, llm=llm)\nllm_chain.predict(sentence=\"the cat is on the table\", language=\"spanish\") \n```", "```py\n' El gato está en la mesa.' \n```", "```py\nitinerary_template = \"\"\"You are a vacation itinerary assistant. \\\nYou help customers finding the best destinations and itinerary. \\\nYou help customer screating an optimized itinerary based on their preferences.\nHere is a question:\n{input}\"\"\"\nrestaurant_template = \"\"\"You are a restaurant booking assistant. \\\nYou check with customers number of guests and food preferences. \\\nYou pay attention whether there are special conditions to take into account.\nHere is a question:\n{input}\"\"\" \n```", "```py\nprint(chain.run(\"I'm planning a trip from Milan to Venice by car. What can I visit in between?\")) \n```", "```py\n> Entering new MultiPromptChain chain...\nitinerary: {'input': \"I'm planning a trip from Milan to Venice by car. What attractions can I visit in between?\"}\n> Finished chain.\nAnswer:\nThere are many attractions that you can visit while traveling from Milan to Venice by car. Some of the most popular attractions include Lake Como, Verona, the Dolomites, and the picturesque towns of Bergamo and Brescia. You can also visit the stunning UNESCO World Heritage Sites in Mantua and Ferrara. Additionally, you can explore some of the local wineries and sample some of the wines of the region. \n```", "```py\nprint(chain.run(\"I want to book a table for tonight\")) \n```", "```py\n> Entering new MultiPromptChain chain...\nrestaurant: {'input': 'I want to book a table for tonight'}\n> Finished chain.\n. How many people are in your party?\nHi there! How many people are in your party for tonight's reservation? \n```", "```py\nfrom langchain.llms import OpenAI\nfrom langchain.chains import LLMChain\nfrom langchain.prompts import PromptTemplate\nllm = OpenAI(temperature=.7)\ntemplate = \"\"\"You are a comedian. Generate a joke on the following {topic}\nJoke:\"\"\"\nprompt_template = PromptTemplate(input_variables=[\"topic\"], template=template)\njoke_chain = LLMChain(llm=llm, prompt=prompt_template)\ntemplate = \"\"\"You are translator. Given a text input, translate it to {language}\nTranslation:\"\"\"\n.prompt_template = PromptTemplate(input_variables=[\"language\"], template=template)\ntranslator_chain = LLMChain(llm=llm, prompt=prompt_template) \n```", "```py\n# This is the overall chain where we run these two chains in sequence.\nfrom langchain.chains import SimpleSequentialChain\noverall_chain = SimpleSequentialChain(chains=[joke_chain, translator_chain], verbose=True)\ntranslated_joke = overall_chain.run(\"Cats and Dogs\") \n```", "```py\n> Entering new SimpleSequentialChain chain...\nWhy did the cat cross the road? To prove to the dog that it could be done!\n ¿Por qué cruzó el gato la carretera? ¡Para demostrarle al perro que se podía hacer!\n> Finished chain. \n```", "```py\nfrom langchain.chains import TransformChain, LLMChain, SimpleSequentialChain\nfrom langchain.llms import OpenAI\nfrom langchain.prompts import PromptTemplate\ntransform_chain = TransformChain(\n    input_variables=[\"text\"], output_variables=[\"output_text\"], transform=rename_cat\n)\ntemplate = \"\"\"Summarize this text:\n{output_text}\nSummary:\"\"\"\nprompt = PromptTemplate(input_variables=[\"output_text\"], template=template)\nllm_chain = LLMChain(llm=OpenAI(), prompt=prompt)\nsequential_chain = SimpleSequentialChain(chains=[transform_chain, llm_chain])\nsequential_chain.run(cats_and_dogs) \n```", "```py\n\" Silvester the Cat and a dog lived together but did not get along. Silvester the Cat played a prank on the dog which made him angry. When their owner found them fighting, she scolded them and made them apologize. After that, they became friends and learned to respect each other's differences and appreciate each other's strengths.\" \n```", "```py\nfrom langchain import SerpAPIWrapper\nfrom langchain.agents import AgentType, initialize_agent\nfrom langchain.llms import OpenAI\nfrom langchain.tools import BaseTool, StructuredTool, Tool, tool\nimport os\nfrom dotenv import load_dotenv\nload_dotenv()\nos.environ[\"SERPAPI_API_KEY\"]\nsearch = SerpAPIWrapper()\ntools = [Tool.from_function(\n        func=search.run,\n        name=\"Search\",\n        description=\"useful for when you need to answer questions about current events\"\n    )]\nagent = initialize_agent(tools, llm = OpenAI(), agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\nagent.run(\"When was Avatar 2 released?\") \n```", "```py\n> Entering new AgentExecutor chain...\n I need to find out when Avatar 2 was released.\nAction: Search\nAction Input: \"Avatar 2 release date\"\nObservation: December 16, 2022\nThought: I now know the final answer.\nFinal Answer: Avatar 2 was released on December 16, 2022.\n> Finished chain.\n'Avatar 2 was released on December 16, 2022.' \n```", "```py\nimport os\nfrom dotenv import load_dotenv\nload_dotenv()\nos.environ[\"HUGGINGFACEHUB_API_TOKEN\"] \n```", "```py\nfrom dotenv import load_dotenv\nfrom pathlib import Path\ndotenv_path = Path('path/to/.env')\nload_dotenv(dotenv_path=dotenv_path) \n```", "```py\nfrom langchain import HuggingFaceHub\nrepo_id = \"tiiuae/falcon-7b-instruct\" \nllm = HuggingFaceHub(\n    repo_id=repo_id, model_kwargs={\"temperature\": 0.5, \"max_length\": 1000}\n)\nprint(llm(\"what was the first disney movie?\")) \n```", "```py\nThe first Disney movie was 'Snow White and the Seven Dwarfs' \n```"]