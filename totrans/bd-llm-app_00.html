<html><head></head><body>
<div><h1 class="mainHeading" id="_idParaDest-4">Preface</h1>
<p class="normal">With this book, we embark upon an exploration of <strong class="keyWord">large language models</strong> (<strong class="keyWord">LLMs</strong>) and the transformative paradigm they represent within the realm of <strong class="keyWord">artificial intelligence</strong> (<strong class="keyWord">AI</strong>). This comprehensive guide helps you delve into the fundamental concepts, from solid theoretical foundations of these cutting-edge technologies to practical applications that LLMs offer, ultimately converging on the ethical and responsible considerations while using generative AI solutions. This book aims to provide you with a firm understanding of how the emerging LLMs in the market can impact individuals, large enterprises, and society. It focuses on how to build powerful applications powered by LLMs, leveraging new AI orchestrators such as LangChain and uncovering new trends in modern application development.</p>
<p class="normal">By the end of this book, you will be able to navigate the rapidly evolving ecosystem of generative AI solutions more easily; plus, you will have the tools to get the most out of LLMs in both your daily tasks and your businesses. Let’s get started!</p>
<h1 class="heading-1" id="_idParaDest-5">Who this book is for</h1>
<p class="normal">The book is designed to mainly appeal to a technical audience with some basic Python code foundations. However, the theoretical chapters and the hands-on exercises are based on generative AI foundations and industry-led use cases, which might be of interest to non-technical audiences as well.</p>
<p class="normal">Overall, the book caters to individuals interested in gaining a comprehensive understanding of the transformative power of LLMs and define, enabling them to navigate the rapidly evolving AI landscape with confidence and foresight. All kinds of readers are welcome, but readers who can benefit the most from this book include:</p>
<ul>
<li class="bulletList"><strong class="keyWord">Software developers and engineers</strong>: This book provides practical guidance for developers looking to build applications leveraging LLMs. It covers integrating LLMs into app backends, APIs, architectures, and so on.</li>
<li class="bulletList"><strong class="keyWord">Data scientists</strong>: For data scientists interested in deploying LLMs for real-world usage, this book shows how to take models from research to production. It covers model serving, monitoring, and optimization.</li>
<li class="bulletList"><strong class="keyWord">AI/ML engineers</strong>: Engineers focused on AI/ML applications can leverage this book to understand how to architect and deploy LLMs as part of intelligent systems and agents.</li>
<li class="bulletList"><strong class="keyWord">Technical founders/CTOs</strong>: Startup founders and CTOs can use this book to evaluate if and how LLMs could be used within their apps and products. It provides a technical overview alongside business considerations.</li>
<li class="bulletList"><strong class="keyWord">Students</strong>: Graduate students and advanced undergraduates studying AI, ML, <strong class="keyWord">natural language processing</strong> (<strong class="keyWord">NLP</strong>), or computer science can learn how LLMs are applied in practice from this book.</li>
<li class="bulletList"><strong class="keyWord">LLM researchers</strong>: Researchers working on novel LLM architectures, training techniques, and so on will gain insight into real-world model usage and the associated challenges.</li>
</ul>
<h1 class="heading-1" id="_idParaDest-6">What this book covers</h1>
<p class="normal"><em class="chapterRef">Chapter 1</em>, <em class="italic">Introduction to Large Language Models</em>, provides an introduction to and deep dive into LLMs, a powerful set of deep learning neural networks in the domain of generative AI. It introduces the concept of LLMs, their differentiators from classical machine learning models, and the relevant jargon. It also discusses the architecture of the most popular LLMs, moving on to explore how LLMs are trained and consumed and compare base LLMs with fine-tuned LLMs. By the end of this chapter, you will have the foundations of what LLMs are and their positioning in the landscape of AI, creating the basis for the subsequent chapters.</p>
<p class="normal"><em class="chapterRef">Chapter 2</em>, <em class="italic">LLMs for AI-Powered Applications</em>, explores how LLMs are revolutionizing the world of software development, leading to a new era of AI-powered applications. By the end of this chapter, you will have a clearer picture of how LLMs can be embedded in different application scenarios, with the help of new AI orchestrator frameworks that are currently available in the AI development market.</p>
<p class="normal"><em class="chapterRef">Chapter 3</em>, <em class="italic">Choosing an LLM for Your Application</em>, highlights how different LLMs may have different architectures, sizes, training data, capabilities, and limitations. Choosing the right LLM for your application is not a trivial decision as it can significantly impact the performance, quality, and cost of your solution. In this chapter, we will navigate the process of choosing the right LLM for your application. We will discuss the most promising LLMs in the market, the main criteria and tools to use when comparing LLMs, and the various trade-offs between size and performance. By the end of this chapter, you should have a clear understanding of how to choose the right LLM for your application and how to use it effectively and responsibly.</p>
<p class="normal"><em class="chapterRef">Chapter 4</em>, <em class="italic">Prompt Engineering</em>, explains how prompt engineering is a crucial activity while designing LLM-powered applications since prompts have a massive impact on the performance of LLMs. In fact, there are several techniques that can be implemented to not only to refine your LLM’s responses but also reduce risks associated with hallucination and biases. In this chapter, we will cover the emerging techniques in the field of prompt engineering, from basic approaches up to advanced frameworks. By the end of this chapter, you will have the foundations to build functional and solid prompts for your LLM-powered applications, which will also be relevant in the upcoming chapters.</p>
<p class="normal"><em class="chapterRef">Chapter 5</em>, <em class="italic">Embedding LLMs within Your Applications</em>, discusses a new set of components introduced into the landscape of software development with the advent of developing applications with LLMs. To make it easier to orchestrate LLMs and their related components in an application flow, several AI frameworks have emerged, of which LangChain is one of the most widely used. In this chapter, we will take a deep dive into LangChain and how to use it, and learn how to call open-source LLM APIs into code via Hugging Face Hub and manage prompt engineering. By the end of this chapter, you will have the technical foundations to start developing your LLM-powered applications using LangChain and open-source Hugging Face models.</p>
<p class="normal"><em class="chapterRef">Chapter 6</em>, <em class="italic">Building Conversational Applications</em>, allows us to embark on the hands-on section of this book with your first concrete implementation of LLM-powered applications. Throughout this chapter, we will cover a step-by-step implementation of a conversational application, using LangChain and its components. We will configure the schema of a simple chatbot, adding a memory component, non-parametric knowledge, and tools to make the chatbot “agentic.” By the end of this chapter, you will be able to set up your own conversational application project with just a few lines of code.</p>
<p class="normal"><em class="chapterRef">Chapter 7</em>, <em class="italic">Search and Recommendation Engines with LLMs</em>, explores how LLMs can enhance recommendation systems, using both embeddings and generative models. We will discuss the definition and evolution of recommendation systems, learn how generative AI is impacting this field of research, and understand how to build recommendation systems with LangChain. By the end of this chapter, you will be able to create your own recommendation application and leverage state-of-the-art LLMs using LangChain as the framework.</p>
<p class="normal"><em class="chapterRef">Chapter 8</em>, <em class="italic">Using LLMs with Structured Data</em>, covers a great capability of LLMs: the ability to handle structured, tabular data. We will see how, with plug-ins and an agentic approach, we can use LLMs as a natural language interface between us and our structured data, reducing the gap between the business user and the structured information. To demonstrate this, we will build a database copilot with LangChain. By the end of this chapter, you will be able to build your own natural language interface for your data estate, combining unstructured with structured sources.</p>
<p class="normal"><em class="chapterRef">Chapter 9</em>, <em class="italic">Working with Code</em>, covers another great capability of LLMs: working with programming languages. In the previous chapter, we’ve already seen a glimpse of this capability, when we asked our LLM to generate SQL queries against a SQL Database. In this chapter, we are going to examine in which other ways LLMs can be used with code, from “simple” code understanding and generation to the building of applications that behave as if they were an algorithm. By the end of this chapter, you will be able to build LLM-powered applications for your coding projects, as well as build LLM-powered applications with natural language interfaces to work with code.</p>
<p class="normal"><em class="chapterRef">Chapter 10</em>, <em class="italic">Building Multimodal Applications with LLMs</em>, goes beyond LLMs, introducing the concept of multi-modality while building agents. We will see the logic behind the combination of foundation models in different AI domains – language, images, audio – into one single agent that can adapt to a variety of tasks. You will learn how to build a multi-modal agent with single-modal LLMs using LangChain. By the end of this chapter, you will be able to build your own multi-modal agent, providing it with the tools and LLMs needed to perform various AI tasks.</p>
<p class="normal"><em class="chapterRef">Chapter 11</em>, <em class="italic">Fine-Tuning Large Language Models</em>, covers the technical details of fine-tuning LLMs, from the theory behind it to hands-on implementation with Python and Hugging Face. We will delve into how you can prepare your data to fine-tune a base model on your data, as well as discuss hosting strategies for your fine-tuned model. By the end of this chapter, you will be able to fine-tune an LLM on your own data so that you can build domain-specific applications powered by that LLM.</p>
<p class="normal"><em class="chapterRef">Chapter 12</em>, <em class="italic">Responsible AI</em>, introduces the fundamentals of the discipline behind the mitigation of the potential harms of LLMs – and AI models in general – that is, responsible AI. This is important because LLMs open the doors to a new set of risks and biases to be taken into account while developing LLM-powered applications. </p>
<p class="normal">We will then move on to the risks associated with LLMs and how to prevent or, at the very least, mitigate them using proper techniques. By the end of this chapter, you will have a deeper understanding of how to prevent LLMs from making your application potentially harmful.</p>
<p class="normal"><em class="chapterRef">Chapter 13</em>, <em class="italic">Emerging Trends and Innovations</em>, explores the latest advancements and future trends in the field of generative AI.</p>
<h1 class="heading-1" id="_idParaDest-7">To get the most out of this book</h1>
<p class="normal">This book aims to provide a solid theoretical foundation of what LLMs are, their architecture, and why they are revolutionizing the field of AI. It adopts a hands-on approach, providing you with a step-by-step guide to implementing LLMs-powered apps for specific tasks and using powerful frameworks like LangChain. Furthermore, each example will showcase the usage of a different LLM, so that you can appreciate their differentiators and when to use the proper model for a given task.</p>
<p class="normal">Overall, the book combines theoretical concepts with practical applications, making it an ideal resource for anyone who wants to gain a solid foundation in LLMs and their applications in NLP. The following pre-requisites will help you to get the most out of this book:</p>
<ul>
<li class="bulletList">A basic understanding of the math behind neural networks (linear algebra, neurons and parameters, and loss functions)</li>
<li class="bulletList">A basic understanding of ML concepts, such as training and test sets, evaluation metrics, and NLP</li>
<li class="bulletList">A basic understanding of Python</li>
</ul>
<h2 class="heading-2" id="_idParaDest-8">Download the example code files</h2>
<p class="normal">The code bundle for the book is hosted on GitHub at <a href="https://github.com/PacktPublishing/Building-LLM-Powered-Applications">https://github.com/PacktPublishing/Building-LLM-Powered-Applications</a>. We also have other code bundles from our rich catalog of books and videos available at <a href="https://github.com/PacktPublishing/">https://github.com/PacktPublishing/</a>. Check them out!</p>
<h2 class="heading-2" id="_idParaDest-9">Download the color images</h2>
<p class="normal">We also provide a PDF file that has color images of the screenshots/diagrams used in this book. You can download it here: <a href="https://packt.link/gbp/9781835462317">https://packt.link/gbp/9781835462317</a>.</p>
<h2 class="heading-2" id="_idParaDest-10">Conventions used</h2>
<p class="normal">There are a number of text conventions used throughout this book.</p>
<p class="normal"><code class="inlineCode">CodeInText:</code> Indicates code words in text, database table names, folder names, filenames, file extensions, pathnames, dummy URLs, user input, and Twitter handles. For example: “I set the two variables <code class="inlineCode">system_message</code> and <code class="inlineCode">instructions</code>.”</p>
<p class="normal">A block of code is set as follows:</p>
<pre class="programlisting code"><code class="hljs-code">[default]
$pip install openai == 0.28
import os
import openai
openai.api_key = os.environment.get('OPENAI_API_KEY')
response = openai.ChatCompletion.create(
    model="gpt-35-turbo", # engine = "deployment_name".
    messages=[
        {"role": "system", "content": system_message},
        {"role": "user", "content": instructions},
    ]
)
</code></pre>
<p class="normal">Any command-line input or output is written as follows:</p>
<pre class="programlisting con"><code class="hljs-con">{'text': "Terrible movie. Nuff Said.[…]
 'label': 0}
</code></pre>
<p class="normal"><strong class="keyWord">Bold:</strong> Indicates a new term, an important word, or words that you see on the screen. For instance, words in menus or dialog boxes appear in the text like this. For example: “[…] he found that repeating the main instruction at the end of the prompt can help the model to overcome its inner <strong class="keyWord">recency bias</strong>.”</p>
<div><p class="normal">Warnings or important notes appear like this.</p>
</div>
<div><p class="normal">Tips and tricks appear like this.</p>
</div>
<h1 class="heading-1" id="_idParaDest-11">Get in touch</h1>
<p class="normal">Feedback from our readers is always welcome.</p>
<p class="normal"><strong class="keyWord">General feedback</strong>: Email <code class="inlineCode">feedback@packtpub.com</code> and mention the book’s title in the subject of your message. If you have questions about any aspect of this book, please email us at <code class="inlineCode">questions@packtpub.com</code>.</p>
<p class="normal"><strong class="keyWord">Errata</strong>: Although we have taken every care to ensure the accuracy of our content, mistakes do happen. If you have found a mistake in this book, we would be grateful if you reported this to us. Please visit <a href="http://www.packtpub.com/submit-errata">http://www.packtpub.com/submit-errata</a>, click <strong class="keyWord">Submit Errata</strong>, and fill in the form.</p>
<p class="normal"><strong class="keyWord">Piracy</strong>: If you come across any illegal copies of our works in any form on the internet, we would be grateful if you would provide us with the location address or website name. Please contact us at <code class="inlineCode">copyright@packtpub.com</code> with a link to the material.</p>
<p class="normal"><strong class="keyWord">If you are interested in becoming an author</strong>: If there is a topic that you have expertise in and you are interested in either writing or contributing to a book, please visit <a href="http://authors.packtpub.com">http://authors.packtpub.com</a>.</p>
</div>
<div><p class="eop"/>
<h1 class="heading-1" id="_idParaDest-12">Share your thoughts</h1>
<p class="normal">Once you’ve read <em class="italic">Building LLM Powered Application</em>, we’d love to hear your thoughts! Please <a href="https://packt.link/r/1835462316">click here to go straight to the Amazon review page</a> for this book and share your feedback.</p>
<p class="normal">Your review is important to us and the tech community and will help us make sure we’re delivering excellent quality content.</p>
</div>
<div><p class="eop"/>
<h1 class="heading-1" id="_idParaDest-13">Download a free PDF copy of this book</h1>
<p class="normal">Thanks for purchasing this book!</p>
<p class="normal">Do you like to read on the go but are unable to carry your print books everywhere?</p>
<p class="normal">Is your eBook purchase not compatible with the device of your choice?</p>
<p class="normal">Don’t worry, now with every Packt book you get a DRM-free PDF version of that book at no cost.</p>
<p class="normal">Read anywhere, any place, on any device. Search, copy, and paste code from your favorite technical books directly into your application.</p>
<p class="normal">The perks don’t stop there, you can get exclusive access to discounts, newsletters, and great free content in your inbox daily.</p>
<p class="normal">Follow these simple steps to get the benefits:</p>
<ol>
<li class="numberedList" value="1">Scan the QR code or visit the link below:</li>
</ol>
<figure class="mediaobject"><img alt="" role="presentation" src="img/B21714_Free_PDF_QR.png"/></figure>
<p class="packt_figref"><a href="https://packt.link/free-ebook/9781835462317 ">https://packt.link/free-ebook/9781835462317</a></p>
<ol>
<li class="numberedList" value="2">Submit your proof of purchase.</li>
<li class="numberedList">That’s it! We’ll send your free PDF and other benefits to your email directly.</li>
</ol>
</div>
</body></html>