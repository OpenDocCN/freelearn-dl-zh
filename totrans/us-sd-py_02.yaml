- en: '2'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Setting Up the Environment for Stable Diffusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Welcome to [*Chapter 2*](B21263_02.xhtml#_idTextAnchor037). In this chapter,
    we will be focusing on setting up the environment to run Stable Diffusion. We
    will cover all the necessary steps and aspects to ensure a seamless experience
    while working with Stable Diffusion models. Our primary goal is to help you understand
    the importance of each component and how they contribute to the overall process.
  prefs: []
  type: TYPE_NORMAL
- en: 'The contents of this chapter are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to the hardware requirements to run Stable Diffusion
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Detailed steps to install the required software dependencies: CUDA from NVIDIA,
    Python, a Python virtual environment (optional but recommended), and PyTorch'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Alternative options for users without a GPU, such as Google Colab and Apple
    MacBook with silicon CPU (M series)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Troubleshooting common issues during the setup process
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tips and best practices for maintaining a stable environment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will begin by providing an overview of Stable Diffusion, its significance,
    and its applications in various fields. This will help you gain a better understanding
    of the core concept and its importance.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will dive into the step-by-step installation process for each dependency,
    including CUDA, Python, and PyTorch. We will also discuss the benefits of using
    a Python virtual environment and guide you through setting one up.
  prefs: []
  type: TYPE_NORMAL
- en: For those who do not have access to a machine with a GPU, we will explore alternative
    options such as Google Colab. We will provide a comprehensive guide to using these
    services and discuss the trade-offs associated with them.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we will address common issues that may arise during the setup process
    and provide troubleshooting tips. Additionally, we will share best practices for
    maintaining a stable environment to ensure a smooth experience while working with
    Stable Diffusion models.
  prefs: []
  type: TYPE_NORMAL
- en: By the end of this chapter, you will have a solid foundation for setting up
    and maintaining an environment tailored for Stable Diffusion, allowing you to
    focus on building and experimenting with your models efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: Hardware requirements to run Stable Diffusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section will discuss the hardware requirements of running a Stable Diffusion
    model. This book will cover **Stable Diffusion v1.5** and the **Stable Diffusion
    XL** (**SDXL**) version. These two are also the most used models at the time of
    writing this book.
  prefs: []
  type: TYPE_NORMAL
- en: Stable Diffusion v1.5, released in October 2022, is considered a general-purpose
    model, and can be used interchangeably with v1.4\. On the other hand, SDXL, which
    was released in July 2023, is known for its ability to handle higher resolutions
    more effectively compared to Stable Diffusion v1.5\. It can generate images with
    larger dimensions without compromising on quality.
  prefs: []
  type: TYPE_NORMAL
- en: 'Essentially, Stable Diffusion is a set of models that includes the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Tokenizer**: This tokenizes a text prompt into a sequence of tokens.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Text Encoder**: The Stable Diffusion text encoder is a special Transformer
    language model – specifically, the text encoder of a CLIP model. In SDXL, a larger-size
    OpenCLIP [6] text encoder is also used to encode the tokens into text embeddings.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Variational Autoencoder** (**VAE**): This encodes images into a latent space
    and decodes them back into images.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**UNet**: This is where the denoising process happens. The UNet structure is
    employed to comprehend the steps involved in the noising/denoising cycle. It accepts
    certain elements such as noise, time step data, and a conditioning signal (for
    instance, a representation of a text description), and forecasts noise residuals
    that can be utilized in the denoising process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The components of Stable Diffusion provide neural network weight data, except
    for the tokenizer. While the CPU can handle the training and inference in theory,
    a physical machine with a GPU or parallel computing device can provide the best
    experience to learn and run Stable Diffusion models.
  prefs: []
  type: TYPE_NORMAL
- en: GPU
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In theory, Stable Diffusion models can run on both GPU and CPU. In reality,
    PyTorch-based models work best on an NVIDIA GPU with CUDA.
  prefs: []
  type: TYPE_NORMAL
- en: Stable Diffusion requires a GPU with at least 4 GB VRAM. From my own experience,
    a GPU with 4 GB VRAM can only enable you to generate 512x512 images but it may
    take a long time to generate them. A GPU with at least 8 GB VRAM grants a relatively
    pleasant learning and usage experience. The larger the VRAM size, the better.
  prefs: []
  type: TYPE_NORMAL
- en: The code of this book is tested on NVIDIA RTX 3070Ti with 8 GB VRAM and RTX
    3090 with 24 GB VRAM.
  prefs: []
  type: TYPE_NORMAL
- en: System memory
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There will be a lot of data transferred between GPU and CPU, and some Stable
    Diffusion models will easily take up to 6 GB RAM. Please prepare at least 16 GB
    of system RAM; 32 GB RAM will be good – the more, the better, especially for multiple
    models.
  prefs: []
  type: TYPE_NORMAL
- en: Storage
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Do prepare a large drive. By default, the Hugging Face package will download
    model data to a cache folder located in the system drive. If you only have 256
    GB or 512 GB storage, you will find it quickly running out. Preparing a 1 TB NVME
    SSD is recommended, although 2 TB or more will be even better.
  prefs: []
  type: TYPE_NORMAL
- en: Software requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now we have the hardware prepared, Stable Diffusion requires additional software
    to support its execution and provide better control using Python. This section
    will provide you with the steps to prepare the software environment.
  prefs: []
  type: TYPE_NORMAL
- en: CUDA installation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you are using Microsoft Windows, please install Microsoft **Visual Studio**
    (**VS**) [5] first. VS will install all other dependent packages and binary files
    for CUDA. You can simply choose the latest Community version of VS for free.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, go to the NVIDIA CUDA download page [1] to get the CUDA installation file.
    The following screenshot shows an example of selecting CUDA for Windows 11:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.1: Selecting the CUDA installation download file for Windows](img/B21263_02_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.1: Selecting the CUDA installation download file for Windows'
  prefs: []
  type: TYPE_NORMAL
- en: Download the CUDA installation file, then double-click this file to install
    CUDA like any other Windows application.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are using a Linux operating system, installing CUDA for Linux is slightly
    different. You can execute the Bash script provided by NVIDIA to automate the
    installation. Here are the detailed steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'It is better to uninstall all NVIDIA drivers first to ensure minimum errors,
    so if you have NVIDIA’s driver already installed, use the following command to
    uninstall it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then, reboot your system:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Install GCC. **GNU Compiler Collection** (**GCC**) is a set of compilers for
    various programming languages such as C, C++, Objective-C, Fortran, Ada, and others.
    It is an open source project developed by the GNU Project and is widely used for
    compiling and building software on Unix-like operating systems, including Linux.
    Without GCC being installed, we will get errors during the CUDA installation.
    Install it with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Select the right CUDA version for your system on the CUDA download page [2].
    The following screenshot shows an example of selecting CUDA for Ubuntu 22.04:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 2.2: Selecting the CUDA installation download file for Linux](img/B21263_02_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.2: Selecting the CUDA installation download file for Linux'
  prefs: []
  type: TYPE_NORMAL
- en: 'After your selection, the page will show you the command scripts that handle
    the entire installation process. Here is one example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The script may have been updated by the time you read this book. To avoid errors
    and potential installation failures, I would suggest opening the page and using
    the script that reflects your selection.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Python for Windows, Linux, and macOS
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will first install Python for Windows.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Python for Windows
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You can visit [https://www.python.org/](https://www.python.org/) and download
    Python 3.9 or Python 3.10 to install it.
  prefs: []
  type: TYPE_NORMAL
- en: After years of manually downloading and clicking through the installation process,
    I found that using a package manager is quite useful to automate the installation.
    With a package manager, you write a script once, save it, and then the next time
    you need to install the software, all you have to do is run the same script in
    a terminal window. One of the best package managers for Windows is Chocolatey
    ([https://chocolatey.org/](https://chocolatey.org/)).
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you have Chocolatey installed, use the following command to install Python
    3.10.6:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a Python virtual environment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: We will move on to the steps to install Python for Linux.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Python for Linux
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let’s now install Python for Linux (Ubuntu). Follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Install the required packages:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Install `pip`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a Python virtual environment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Installing Python for macOS
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'If you are using a Mac with the silicon chip inside (with Apple Mx CPU), there
    is a high chance you have Python installed already. You can test whether you have
    Python installed on your Mac with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'If your machine doesn’t have a Python interpreter yet, you can install it with
    one simple command using Homebrew [7] like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Keep in mind that Python versions are regularly updated, usually on an annual
    basis. You can change the version number to install a specific Python version.
    For example, you can change `python3.10` to `python3.11`.
  prefs: []
  type: TYPE_NORMAL
- en: Installing PyTorch
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The Hugging Face Diffusers package relies on the PyTorch package, so we will
    need to have the PyTorch package installed. Go to the PyTorch **Get Started**
    page ([https://pytorch.org/get-started/locally/](https://pytorch.org/get-started/locally/))
    and select the appropriate PyTorch version for your system. The following is a
    screenshot of PyTorch for Windows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.3: Installing PyTorch](img/B21263_02_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.3: Installing PyTorch'
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, use the dynamically generated command to install PyTorch:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: In addition to CUDA 11.7, there is also CUDA 11.8\. The choice of version will
    depend on the CUDA version installed on your machine.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can use the following command to find out your CUDA version:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'You can also use this command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Your machine’s CUDA version may be higher than the listed versions of 11.7 or
    11.8, such as 12.1\. Often, a specific version is required by a certain model
    or package. For Stable Diffusion, just install the newest version.
  prefs: []
  type: TYPE_NORMAL
- en: If you are using a Mac, select the **Mac** option to install PyTorch for macOS.
  prefs: []
  type: TYPE_NORMAL
- en: If you are using a Python virtual environment, make sure to install PyTorch
    within the activated virtual environment. Otherwise, you may encounter issues
    where PyTorch is not installed correctly if you accidentally install it outside
    the virtual environment and then run your Python code within the virtual environment.
  prefs: []
  type: TYPE_NORMAL
- en: Running a Stable Diffusion pipeline
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that you have installed all the dependencies, it is time to run a Stable
    Diffusion pipeline to test whether the environment is correctly set up. You can
    use any Python editing tool, such as VS Code or Jupyter Notebook, to edit and
    execute Python code. Follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Install the packages for Hugging Face Diffusers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Start a Stable Diffusion pipeline:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: If you are using a Mac, change `cuda` to `mps`. Even though macOS is supported
    and can generate images using the Diffusers package, its performance is relatively
    slow. As a comparison, an NVIDIA RTX 3090 can achieve about 20 iterations per
    second to generate one 512x512 image using Stable Diffusion V1.5, whereas an M3
    Max CPU can only reach around 5 iterations per second with the default settings.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Generate an image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: If you see an image of an astronaut riding a horse, you have all the environments
    set up correctly in your physical machine.
  prefs: []
  type: TYPE_NORMAL
- en: Using Google Colaboratory
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Google Colaboratory** (or **Google Colab**) is an online computing service
    provided by Google. In essence, Google Colab is an online Jupyter notebook with
    GPU/CUDA capability.'
  prefs: []
  type: TYPE_NORMAL
- en: Its free notebook can provide CUDA computing with 15 GB VRAM equivalent to an
    NVIDIA RTX 3050 or RTX 3060\. The performance is decent if you don’t have a discrete
    GPU at hand.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at the advantages and disadvantages of using Google Colab:'
  prefs: []
  type: TYPE_NORMAL
- en: '`pip` and downloading of resources are fast'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Disadvantages**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is a disk limitation for each notebook
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: You don't have full control of the backend server; terminal access requires
    a Colab Pro subscription
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The performance is not guaranteed so you may experience slow GPU inference during
    peak time and could be disconnected for long-time computing
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The Colab notebook compute environment will be reset every time you restart
    the notebook; in other words, you will need to reinstall all the packages and
    download the model files every time you start the notebook
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Google Colab to run a Stable Diffusion pipeline
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here are the detailed steps to start using Google Colab:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a new instance from [https://colab.research.google.com/](https://colab.research.google.com/).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Click **Runtime** | **Change runtime type** and select **T4 GPU**, as shown
    in *Figure 2**.4*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 2.4: Selecting GPU in the Google Colab notebook](img/B21263_02_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.4: Selecting GPU in the Google Colab notebook'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new cell and use the following command to check whether the GPU and
    CUDA are working:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Install the packages for Hugging Face Diffusers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Start a Stable Diffusion pipeline:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Generate an image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In a few seconds, you should be able to see the result as shown in *Figure
    2**.5*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.5: Running a Stable Diffusion pipeline in Google Colab](img/B21263_02_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.5: Running a Stable Diffusion pipeline in Google Colab'
  prefs: []
  type: TYPE_NORMAL
- en: If you see an image generated as in *Figure 2**.5*, you have successfully set
    up the Diffusers package to run the Stable Diffusion model in Google Colab.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Some say that the most challenging part of starting to train a machine learning
    model is not the math or its internal logic. Often, the biggest hurdle is setting
    up a proper working environment to run the model. It's not uncommon to see engineers
    and professors spend an entire weekend trying to install CUDA on their lab machines.
    This can be due to missing dependencies, skipped steps, or version incompatibilities.
  prefs: []
  type: TYPE_NORMAL
- en: I dedicated an entire chapter to covering the installation process, hoping that
    these detailed steps would help you avoid common pitfalls. By following these
    steps, you’ll be able to delve into the Stable Diffusion model and start image
    generation with minimum obstacles.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, the software and packages you installed will also work for Transformer-based
    large language models.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will start using Stable Diffusion to generate images.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*CUDA Installation Guide for Microsoft* *Windows*: [https://docs.nvidia.com/cuda/cuda-installation-guide-microsoft-windows/index.html](https://docs.nvidia.com/cuda/cuda-installation-guide-microsoft-windows/index.html)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*NVIDIA CUDA* *Downloads*: [https://developer.nvidia.com/cuda-downloads](https://developer.nvidia.com/cuda-downloads)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Google* *Colab*: [https://colab.research.google.com/](https://colab.research.google.com/)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Hugging Face Diffusers* *Installation*: [https://huggingface.co/docs/diffusers/installation](https://huggingface.co/docs/diffusers/installation)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Visual Studio Community* *Download*: [https://visualstudio.microsoft.com/vs/community/](https://visualstudio.microsoft.com/vs/community/)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*OpenCLIP GitHub* *repository*: [https://github.com/mlfoundations/open_clip](https://github.com/mlfoundations/open_clip)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Homebrew*: [https://brew.sh/](https://brew.sh/)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
