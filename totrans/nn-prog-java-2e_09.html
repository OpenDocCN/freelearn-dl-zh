<html><head></head><body><div><div><div><div><div><h1 class="title"><a id="ch09" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Chapter 9. Optimizing and Adapting Neural Networks</h1></div></div></div><p class="calibre11">In this chapter, the reader will be presented with techniques that help to optimize neural networks, in order to get the best performance. Tasks such as input selection, dataset separation and filtering, choosing the number of hidden neurons, and cross-validation strategies are examples of what can be adjusted to improve a neural network's performance. Furthermore, this chapter focuses on methods for adapting neural networks to real-time data. Two implementations of these techniques are presented here. Application problems will be selected for exercises. This chapter deals with the following topics:</p><div><ul class="itemizedlist"><li class="listitem">Input selection</li><li class="listitem">Dimensionality reduction</li><li class="listitem">Data filtering</li><li class="listitem">Structure selection</li><li class="listitem">Pruning</li><li class="listitem">Validation strategies</li><li class="listitem">Cross-validation</li><li class="listitem">Online retraining</li><li class="listitem">Stochastic online learning</li><li class="listitem">Adaptive neural networks</li><li class="listitem">Adaptive resonance theory</li></ul></div><div><div><div><div><h1 class="title2"><a id="ch09lvl1sec54" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Common issues in neural network implementations</h1></div></div></div><p class="calibre11">When developing <a id="id514" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>a neural network application, it is quite common to face problems regarding how accurate the results are. The source of these problems can be various:</p><div><ul class="itemizedlist"><li class="listitem">Bad input selection</li><li class="listitem">Noisy data</li><li class="listitem">Too big a dataset</li><li class="listitem">Unsuitable structure</li><li class="listitem">Inadequate number of hidden neurons</li><li class="listitem">Inadequate learning rate</li><li class="listitem">Insufficient stop condition</li><li class="listitem">Bad dataset segmentation</li><li class="listitem">Bad validation strategy</li></ul></div><p class="calibre11">The design of a neural network application sometimes requires a lot of patience and the use of trial and error methods. There is no methodology stating specifically which number of hidden units and/or architecture should be used, but there are recommendations on how to choose these parameters properly. Another issue programmers may face is a long training time, which often causes the neural network to not learn the data. No matter how long the training runs, the neural network won't converge.</p><div><div><h3 class="title4"><a id="tip34" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Tip</h3><p class="calibre17">Designing a neural network requires the programmer or designer to test and redesign the neural structure as many times as needed, until an acceptable result is obtained.</p></div></div><p class="calibre11">On the other hand, the neural network solution designer may wish to improve the results. Because a neural network can learn until the learning algorithm reaches the stop condition, the number of epochs or the mean squared error, the results are not accurate enough or not generalized. This will require a redesign of the neural structure, or a new dataset selection.</p></div></div></div>



  
<div><div><div><div><div><h1 class="title2"><a id="ch09lvl1sec55" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Input selection</h1></div></div></div><p class="calibre11">One of the key<a id="id515" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> tasks in designing a neural network application is to select appropriate inputs. For the unsupervised case, one wishes to use only relevant variables on which the neural network will find the patterns. And for the supervised case, there is a need to map the outputs to the inputs, so one needs to choose only the input variables which somewhat have influence on the output.</p><div><div><div><div><h2 class="title5"><a id="ch09lvl2sec110" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Data correlation</h2></div></div></div><p class="calibre11">One strategy<a id="id516" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> that helps in selecting good inputs in the supervised <a id="id517" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>case is the correlation between data series, which is implemented in <a class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2" href="ch05.xhtml" title="Chapter 5. Forecasting Weather">Chapter 5</a>, <em class="calibre16">Forecasting Weather</em>. A correlation between data series is a measure of how one data sequence reacts or influences the other. Suppose we have one dataset containing a number of data series, from which we choose one to be an output. Now we need to select the inputs from the remaining variables.</p><p class="calibre11">The correlation takes values from <em class="calibre16">-1</em> to 1, where values near to <em class="calibre16">+1</em> indicate a positive correlation, values near -1 indicate a negative correlation, and values near <em class="calibre16">0</em> indicate no correlation at all.</p><p class="calibre11">As an example, let's see three charts of two variables <em class="calibre16">X</em> and <em class="calibre16">Y</em>:</p><div><img src="img/B5964_09_01.jpg" alt="Data correlation" class="calibre205"/></div><p class="calibre11">In the first chart, to the left, visually one can see that as one variable decreases, the other increases its value (corr. -0.8). The middle chart shows the case when the two variables vary in the same direction, therefore positive correlation (corr. +0.7). The third chart, to the right, shows a case where there is no correlation between the variables (corr. <em class="calibre16">-0.1</em>).</p><p class="calibre11">There is no threshold rule as to which correlation should be taken into account as a limit; it depends on the application. While absolute correlation values greater than 0.5 may be suitable for one application, in others, values near 0.2 may add a significant contribution.</p></div><div><div><div><div><h2 class="title5"><a id="ch09lvl2sec111" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Transforming data</h2></div></div></div><p class="calibre11">Linear <a id="id518" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>correlation is very good in detecting behaviors between<a id="id519" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> data series when they are presumably linear. However, if two data series form a parable when plotted together, linear correlation won't be able to identify any relation. That's why sometimes we need to transform data into a view that exhibits a linear correlation.</p><p class="calibre11">Data transformation depends on the problem that is being faced. It consists of inserting an additional data series with processed data from one or more data series. One example is an equation (possibly nonlinear) that includes one or more parameters. Some behaviors are more <a id="id520" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>detectable under a transformed view of the<a id="id521" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> data.</p><div><div><h3 class="title6"><a id="tip35" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Tip</h3><p class="calibre17">Data transformation also involves a bit of knowledge about the problem. However, by seeing the scatter plot of two data series, it becomes easier to choose which transformation to apply.</p></div></div></div><div><div><div><div><h2 class="title5"><a id="ch09lvl2sec112" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Dimensionality reduction</h2></div></div></div><p class="calibre11">Another interesting<a id="id522" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> point is regarding removing<a id="id523" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> redundant data. Sometimes this is desired when there is a lot of available data in both unsupervised and supervised learning. As an example, let's see a chart of two variables:</p><div><img src="img/B5964_09_02.jpg" alt="Dimensionality reduction" class="calibre206"/></div><p class="calibre11">It can be seen that both X and <em class="calibre16">Y</em> variables share the same shape, so this can be interpreted as a redundancy, as both variables are carrying almost the same information due the high positive correlation. Thus, one can consider a technique called <strong class="calibre12">Principal Component Analysis</strong> (<strong class="calibre12">PCA</strong>) which<a id="id524" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> gives a good approach for dealing with these cases.</p><p class="calibre11">The result of PCA will be a new variable summarizing the previous two (or more). Basically, the original data series are subtracted by the mean and then multiplied by the transposed eigenvectors of the covariance matrix:</p><div><img src="img/B05964_09_02_01.jpg" alt="Dimensionality reduction" class="calibre207"/></div><p class="calibre11">Here, <em class="calibre16">SXY</em> is the covariance between the variables <em class="calibre16">X</em> and <em class="calibre16">Y</em>.</p><p class="calibre11">The derived new data will be then:</p><div><img src="img/B05964_09_02_02.jpg" alt="Dimensionality reduction" class="calibre208"/></div><p class="calibre11">Let's see now what a new variable would look like in a chart, compared to the original ones:</p><div><img src="img/B5964_09_03.jpg" alt="Dimensionality reduction" class="calibre209"/></div><p class="calibre11">In our <a id="id525" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>framework, we are going to add the class <code class="literal">PCA</code> that <a id="id526" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>will perform this transformation and preprocessing before applying the data into a neural network:</p><div><pre class="programlisting">public class PCA {
    
  DataSet originalDS;
  int numberOfDimensions;
  DataSet reducedDS;
    
  DataNormalization normalization = new DataNormalization(DataNormalization.NormalizationTypes.ZSCORE);
    
  public PCA(DataSet ds,int dimensions){
    this.originalDS=ds;
    this.numberOfDimensions=dimensions;
  }
    
  public DataSet reduceDS(){
    //matrix algebra to calculate transformed data in lower dimension
    …
  }

  public DataSet reduceDS(int numberOfDimensions){
    this.numberOfDimensions = numberOfDimensions;
    return reduceDS;
  }

}</pre></div></div><div><div><div><div><h2 class="title5"><a id="ch09lvl2sec113" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Data filtering</h2></div></div></div><p class="calibre11">Noisy data<a id="id527" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> and bad data are also sources of problems in <a id="id528" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>neural network applications; that's why we need to filter data. One of the common data filtering techniques can be performed by excluding the records that exceed the usual range. For example, temperature values are between -40 and 40, so a value such as 50 would be considered an outlier and could be taken out.</p><p class="calibre11">The 3-sigma rule is a good and effective measure for filtering. It consists in filtering the values that are beyond three times the standard deviation from the mean:</p><div><img src="img/B05964_09_03_01.jpg" alt="Data filtering" class="calibre210"/></div><p class="calibre11">Let's add a class to deal with data filtering:</p><div><pre class="programlisting">public abstract class DataFiltering {
    
  DataSet originalDS;
  DataSet filteredDS;

}

public class ThreeSigmaRule extends DataFiltering {
    
  double thresholdDistance = 3.0;

  public ThreeSigmaRule(DataSet ds,double threshold){
    this.originalDS=ds;
    this.thresholdDistance=threshold;
  }
    
  public DataSet filterDS(){
    //matrix algebra to calculate the distance of each point in each column
    …
  }

}</pre></div><p class="calibre11">These classes can be called in <code class="literal">DataSet</code> by the following methods, which are then called elsewhere <a id="id529" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>for<a id="id530" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> filtering and reducing dimensionality:</p><div><pre class="programlisting">public DataSet applyPCA(int dimensions){
  PCA pca = new PCA(this,dimensions);
  return pca.reduceDS();
}
    
public DataSet filter3Sigma(double threshold){
  ThreeSigmaRule df = new ThreeSigmaRule(this,threshold);
  return df.filterDS();
}</pre></div></div><div><div><div><div><h2 class="title5"><a id="ch09lvl2sec114" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Cross-validation</h2></div></div></div><p class="calibre11">Among a <a id="id531" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>number of strategies for validating a neural network, one <a id="id532" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>very important one is cross-validation. This strategy ensures that all data has been presented to the neural network as training and test data. The dataset is partitioned into <em class="calibre16">K</em> groups, of which one is separated for testing while the others are for training:</p><div><img src="img/B5964_09_04.jpg" alt="Cross-validation" class="calibre211"/></div><p class="calibre11">In our code, let's create a class called <code class="literal">CrossValidation</code> to manage cross-validation:</p><div><pre class="programlisting">public class CrossValidation {
  NeuralDataSet dataSet;
  int numberOfFolds;
    
  public LearningAlgorithm la;
    
  double[] errorsMSE;
    
  public CrossValidation(LearningAlgorithm _la,NeuralDataSet _nds,int _folds){
    this.dataSet=_nds;
    this.la=_la;
    this.numberOfFolds=_folds;
    this.errorsMSE=new double[_folds];
  }
    
  public void performValidation() throws NeuralException{
    //shuffle the dataset
    NeuralDataSet shuffledDataSet = dataSet.shuffle();
    int subSize = shuffledDataSet.numberOfRecords/numberOfFolds;
    NeuralDataSet[] foldedDS = new NeuralDataSet[numberOfFolds];
    for(int i=0;i&lt;numberOfFolds;i++){
            foldedDS[i]=shuffledDataSet.subDataSet(i*subSize,(i+1)*subSize-1);
    }
    //run the training
    for(int i=0;i&lt;numberOfFolds;i++){
      NeuralDataSet test = foldedDS[i];
      NeuralDataSet training = foldedDS[i==0?1:0];
      for(int k=1;k&lt;numberOfFolds;k++){
        if((i&gt;0)&amp;&amp;(k!=i)){
          training.append(foldedDS[k]);
        }
        else if(k&gt;1) training.append(foldedDS[k]);
      }
      la.setTrainingDataSet(training);
      la.setTestingDataSet(test);
      la.train();
      errorsMSE[i]=la.getMinOverallError();
    }
  }
}</pre></div></div><div><div><div><div><h2 class="title5"><a id="ch09lvl2sec115" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Structure selection</h2></div></div></div><p class="calibre11">To choose an <a id="id533" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>adequate structure for a neural network is also a <a id="id534" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>very important step. However, this is often done empirically, since there is no rule on how many hidden units a neural network should have. The only measure of how many units are adequate is the neural network performance. One assumes that if the general error is low enough, then the structure is suitable. Nevertheless, there might be a smaller structure that could yield the same result.</p><p class="calibre11">In this context, there are basically two methodologies: constructive and pruning. The constructive consists in starting with only the input and output layers, then adding new neurons at a hidden layer, until a good result can be obtained. The destructive approach, also known as pruning, works on a bigger structure on which the neurons having few contributions to the output are taken out.</p><p class="calibre11">The constructive <a id="id535" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>approach is depicted in the following <a id="id536" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>figure:</p><div><img src="img/B5964_09_05.jpg" alt="Structure selection" class="calibre212"/></div><p class="calibre11">Pruning is the way back: when given a high number of neurons, one wishes to <em class="calibre16">prune</em> those whose sensitivity is very low, that is, whose contribution to the error is minimal:</p><div><img src="img/B5964_09_06.jpg" alt="Structure selection" class="calibre213"/></div><p class="calibre11">To implement pruning, we`ve added the following properties in the class <code class="literal">NeuralNet</code>:</p><div><pre class="programlisting">public class NeuralNet{
//…
  public Boolean pruning;
  public double senstitityThreshold;
}</pre></div><p class="calibre11">A method called <code class="literal">removeNeuron</code> in the class <code class="literal">NeuralLayer</code>, which actually sets all the connections<a id="id537" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> of the neuron to zero, disables weight updating <a id="id538" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>and fires only zero at the neuron`s output. This method is called if the property pruning of the <code class="literal">NeuralNet</code> object is set to true. The sensitivity calculation is according to the chain rule, as shown in <a class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2" href="ch03.xhtml" title="Chapter 3. Perceptrons and Supervised Learning">Chapter 3</a>, <em class="calibre16">Perceptrons and Supervised Learning</em> and implemented in the <code class="literal">calcNewWeigth</code> method:</p><div><pre class="programlisting">@Override
public Double calcNewWeight(int layer,int input,int neuron){
  Double deltaWeight=calcDeltaWeight(layer,input,neuron);
  if(this.neuralNet.pruning){
    if(deltaWeight&lt;this.neuralNet.sensitivityThreshold)
      neuralNet.getHiddenLayer(layer).remove(neuron);
  }
  return newWeights.get(layer).get(neuron).get(input)+deltaWeight;
}</pre></div></div></div></div>



  
<div><div><div><div><div><h1 class="title2"><a id="ch09lvl1sec56" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Online retraining</h1></div></div></div><p class="calibre11">During the learning process, it is important to design how the training should be performed. Two<a id="id539" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> basic approaches are batch and incremental learning.</p><p class="calibre11">In batch learning, all the<a id="id540" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> records are fed to the network, so it can evaluate the error and then update the weights:</p><div><img src="img/B5964_09_07.jpg" alt="Online retraining" class="calibre214"/></div><p class="calibre11">In <a id="id541" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>incremental learning, the update is performed after each record has been sent to the network:</p><div><img src="img/B5964_09_08.jpg" alt="Online retraining" class="calibre215"/></div><p class="calibre11">Both approaches work well and have advantages and disadvantages. While batch learning can used for a less frequent, though more directed, weight update, incremental learning provides a method for fine-tuned weight adjustment. In that context, it is possible to design a mode of learning that enables the network to learn continually.</p><div><div><h3 class="title4"><a id="tip36" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Tip</h3><p class="calibre17">As a suggested exercise, the reader may pick one of the datasets available in the code and design a training using part of the records, and then train using another part in both modes, online and batch. See the <code class="literal">IncrementalLearning.java</code> file for details.</p></div></div><div><div><div><div><h2 class="title5"><a id="ch09lvl2sec116" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Stochastic online learning</h2></div></div></div><p class="calibre11">Offline learning<a id="id542" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> means that the neural network learns while not in <em class="calibre16">operation</em>. Every neural network application is supposed to <a id="id543" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>work in an environment, and in order to be at production, it should be properly trained. Offline training is suitable for putting the network into operation, since its outputs may be varied over large ranges of values, which would certainly compromise the system, if it is in operation. But when it comes to online learning, there are restrictions. While in offline learning, it's possible to use cross-validation and bootstrapping to predict errors, in online learning, this can't be done since there's no "training dataset" anymore. However, one would need online training when some improvement in the neural network's performance is desired.</p><p class="calibre11">A stochastic method is used when online learning is performed. This algorithm to improve neural network training is composed of two main features: random choice of samples for training and variation of learning rate in runtime (online). This training method has been used when noise is found in the objective function. It helps to escape the local minimum (one of the best solutions) and to reach the global minimum (the best solution):</p><p class="calibre11">The pseudo-algorithm is<a id="id544" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> displayed below (source: <a class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2" href="ftp://ftp.sas.com/pub/neural/FAQ2.html#A_styles">ftp://ftp.sas.com/pub/neural/FAQ2.html#A_styles</a>):</p><div><pre class="programlisting">Initialize the weights.
   Initialize the learning rate.
   Repeat the following steps:
      Randomly select one (or possibly more) case(s)
         from the population.
      Update the weights by subtracting the gradient
         times the learning rate.
      Reduce the learning rate according to an
         appropriate schedule.</pre></div></div><div><div><div><div><h2 class="title5"><a id="ch09lvl2sec117" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Implementation</h2></div></div></div><p class="calibre11">The Java project <a id="id545" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>has created the class <code class="literal">BackpropagtionOnline</code> inside the <code class="literal">learn</code> package. The differences between this algorithm and classic Backpropagation was programmed by changing the <code class="literal">train()</code> method, by adding two new methods: <code class="literal">generateIndexRandomList()</code> and <code class="literal">reduceLearningRate()</code>. The first one generates a random list of indexes to be used in the training step and the second one executes the learning rate online variation according to the following heuristic:</p><div><pre class="programlisting">private double reduceLearningRate(NeuralNet n, double percentage) {
    double newLearningRate = n.getLearningRate() * 
                    ((100.0 - percentage) / 100.0);
    
    if(newLearningRate &lt; 0.1) {
      newLearningRate = 1.0;
    }
    
    return newLearningRate;
  }</pre></div><p class="calibre11">This method <a id="id546" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>will be called at the end of the <code class="literal">train()</code> method.</p></div><div><div><div><div><h2 class="title5"><a id="ch09lvl2sec118" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Application</h2></div></div></div><p class="calibre11">It has used <a id="id547" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>data from previous chapters to test this new way to train neural nets. The same neural net topology defined in each chapter (<a class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2" href="ch05.xhtml" title="Chapter 5. Forecasting Weather">Chapter 5</a>, <em class="calibre16">Forecasting Weather</em> and <a class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2" href="ch08.xhtml" title="Chapter 8. Text Recognition">Chapter 8</a>, <em class="calibre16">Text Recognition</em>) has been used to train the nets of this chapter. The first one is the weather forecasting problem and the second one is the OCR. The following table shows the comparison of results:</p><div><img src="img/B5964_09_08_01.jpg" alt="Application" class="calibre216"/></div><p class="calibre11">In addition, charts of the MSE evolution have been plotted and are shown here:</p><div><img src="img/B5964_09_09.jpg" alt="Application" class="calibre217"/></div><div><img src="img/B5964_09_10.jpg" alt="Application" class="calibre218"/></div><p class="calibre11">The curve <a id="id548" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>showed in the first chart (Weather Forecast) has a saw shape, because of the variation of learning rate. Besides, it's very similar to the curve, as shown in <a class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2" href="ch05.xhtml" title="Chapter 5. Forecasting Weather">Chapter 5</a>, <em class="calibre16">Forecasting Weather</em> On the other hand, the second chart (OCR) shows that the training process was faster and stops near the 900th epoch because it reached a very small MSE error.</p><p class="calibre11">Other experiments were made: training neural nets with a backpropagation algorithm, and considering the learning rate found by the online approach. The MSE values reduced in both problems:</p><div><img src="img/B5964_09_11.jpg" alt="Application" class="calibre219"/></div><p class="calibre11">Another<a id="id549" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> important observation consists in the fact that training process demonstrated by the training terminated almost in the 3,000th epoch. Therefore, it's faster and better than the training process seen in <a class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2" href="ch08.xhtml" title="Chapter 8. Text Recognition">Chapter 8</a>, <em class="calibre16">Text Recognition</em> using the same algorithm.</p></div></div></div>



  
<div><div><div><div><div><h1 class="title2"><a id="ch09lvl1sec57" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Adaptive neural networks</h1></div></div></div><p class="calibre11">Analogous <a id="id550" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>to human learning, neural networks may also work in order not to forget previous knowledge. Using the traditional approaches for neural learning, this is nearly impossible, due to the fact that every training implies replacing all the connections already made by new ones, thereby <em class="calibre16">forgetting</em> the previous knowledge. Thus a need arises to make the neural networks adapt to new knowledge by incrementing instead of replacing their current knowledge. To address that issue, we are going to explore one method called <strong class="calibre12">adaptive resonance theory</strong> (<strong class="calibre12">ART</strong>).</p><div><div><div><div><h2 class="title5"><a id="ch09lvl2sec119" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Adaptive resonance theory</h2></div></div></div><p class="calibre11">The <a id="id551" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>question that drove the<a id="id552" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> development of this theory was: <em class="calibre16">How can an adaptive system remain plastic to a significant input and yet keep stability for irrelevant inputs?</em> In other words: <em class="calibre16">How can it retain previously learned information while learning new information?</em>
</p><p class="calibre11">We've seen that competitive learning in unsupervised learning deals with pattern recognition, whereby similar inputs yield similar outputs or fire the same neurons. In an ART topology, the resonance comes in when the information is being retrieved from the network, by providing a feedback from the competitive layer and the input layer. So, while the network receives data to learn, there is an oscillation resulting from the feedback between the competitive and input layers. This oscillation stabilizes when the pattern is<a id="id553" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> fully developed<a id="id554" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> inside the neural network. This resonance then reinforces the stored pattern.</p></div><div><div><div><div><h2 class="title5"><a id="ch09lvl2sec120" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Implementation</h2></div></div></div><p class="calibre11">A new class <a id="id555" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>called <code class="literal">ART</code> has created into the some package, inheriting from <code class="literal">CompetitiveLearning</code>. Besides other small contributions, its great change is the vigilance test:</p><div><pre class="programlisting">public class ART extends CompetitiveLearning{
  
  private boolean vigilanceTest(int row_i) {
    double v1 = 0.0;
    double v2 = 0.0;
    
    for (int i = 0; i &lt; neuralNet.getNumberOfInputs(); i++) {
      double weightIn  = neuralNet.getOutputLayer().getWeight(i);
      double trainPattern = trainingDataSet.getIthInput(row_i)[i];
      
      v1 = v1 + (weightIn * trainPattern);
      
      v2 = v2 + (trainPattern * trainPattern);
    }
    
    double vigilanceValue = v1 / v2;
    
    if(vigilanceValue &gt; neuralNet.getMatchRate()){
      return true;
    } else {
      return false;
    }
    
  }

}</pre></div><p class="calibre11">The training method is shown below. It's possible to notice that, firstly, global variables and the neural net are initialized; after that, the number of training sets and the training patterns are stored; then the training process begins. The first step of this process is to calculate the index of the winner neuron; the second is make attribution of the neural net output. The next step consists of verifying whether the neural net has learned or not, whether it has<a id="id556" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/> learned that weights are fixed; if not, another training sample is presented to the net:</p><div><pre class="programlisting">epoch=0;
int k=0;
forward();
//...
currentRecord=0;
forward(currentRecord);
while(!stopCriteria()){
 //...
  boolean isMatched = this.vigilanceTest(currentRecord);
  if ( isMatched ) {
  applyNewWeights();
} </pre></div></div></div></div>



  
<div><div><div><div><div><h1 class="title2"><a id="ch09lvl1sec58" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Summary</h1></div></div></div><p class="calibre11">In this chapter, we've seen a few topics that make a neural network work better, either by improving its accuracy or by extending its knowledge. These techniques help a lot in designing solutions with artificial neural networks. The reader is welcome to apply this framework in any desired task that neural networks can be used on, in order to explore the enhanced power that these structures can have. Even simple details such as selecting input data may influence the entire learning process, as well as filtering bad data or eliminating redundant variables. We demonstrated two implementations, two strategies that help to improve the performance of a neural network: stochastic online learning and adaptive resonance theory. These methodologies enable the network to extend its knowledge and therefore adapt to new, changing environments.</p></div></div>



  </body></html>