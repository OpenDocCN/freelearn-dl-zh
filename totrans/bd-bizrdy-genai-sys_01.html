<html><head></head><body>
  <div class="Basic-Text-Frame" id="_idContainer056">
    <h1 class="chapterNumber"><a id="_idTextAnchor021"/>1</h1>
    <h1 class="chapterTitle" id="_idParaDest-21"><a id="_idTextAnchor022"/>Defining a Business-Ready Generative AI System</h1>
    <p class="normal">Implementing a <strong class="keyWord">generative AI system</strong> (<strong class="keyWord">GenAISys</strong>) in an organization doesn’t stop at simply integrating a standalone model such as GPT, Grok, Llama, or Gemini via an API. While this is often a starting point, we often mistake it as the finish line. The rising demand for AI, as it expands across all domains, calls for the implementation of advanced AI systems that go beyond simply integrating a prebuilt model.</p>
    <p class="normal">A business-ready GenAISys should provide ChatGPT-grade functionality in an organization, but also go well beyond it. Its <a id="_idIndexMarker000"/>capabilities and features must include <strong class="keyWord">natural language understanding</strong> (<strong class="keyWord">NLU</strong>), contextual awareness through memory retention across dialogues in a chat session, and agentic functions such as autonomous image, audio, and document analysis and generation. Think of a generative AI model as an entity with a wide range of functions, including AI agents as agentic co-workers.</p>
    <p class="normal">We will begin the chapter by defining what a business-ready GenAISys is. From there, we’ll focus on the central role of a generative AI model, such as GPT-4o, that can both orchestrate and execute tasks. Building on that, we will lay the groundwork for contextual awareness and memory retention, discussing <a id="_idIndexMarker001"/>four types of generative AI memory: memoryless, short-term, long-term, and multiple sessions. We will also define a new approach to <strong class="keyWord">retrieval-augmented generation</strong> (<strong class="keyWord">RAG</strong>) that introduces an additional dimension to data retrieval: instruction and agentic reasoning scenarios. Adding instructions stored in a vector store takes RAG to another level by retrieving instructions that we can add to a prompt. In parallel, we will examine a critical component of a GenAISys: human roles. We will see how, throughout its life cycle, an AI system requires human expertise. Additionally, we will define several levels of implementation to adapt the scope and scale of a GenAISys, not only to business requirements but also to available budgets and resources.</p>
    <p class="normal">Finally, we’ll illustrate how contextual awareness and memory retention can be implemented using OpenAI’s LLM and multimodal API. A GenAISys cannot work without solid memory retention functionality—without memory, there’s no context, and without context, there’s no sustainable generation. Throughout this book, we will create modules for memoryless, short-term, long-term, and multisession types depending on the task at hand. By the end of this chapter, you will have acquired a clear conceptual framework for what makes an AI system business-ready and practical experience in building the first bricks of an AI controller.</p>
    <p class="normal">In a nutshell, this chapter covers the following topics:</p>
    <ul>
      <li class="bulletList">Components of a business-ready GenAISys</li>
      <li class="bulletList">AI controllers and agentic functionality (model-agnostic)</li>
      <li class="bulletList">Hybrid human roles and collaboration with AI</li>
      <li class="bulletList">Business opportunities and scope</li>
      <li class="bulletList">Contextual awareness through memory retention</li>
    </ul>
    <p class="normal">Let’s begin by defining what a business-ready GenAISys is.</p>
    <h1 class="heading-1" id="_idParaDest-22"><a id="_idTextAnchor023"/>Components of a business-ready GenAISys</h1>
    <p class="normal">A business-ready GenAISys is a modular orchestrator that seamlessly integrates standard AI models with <a id="_idIndexMarker002"/>multifunctional frameworks to deliver hybrid intelligence. By combining generative AI with agentic functionality, RAG, <strong class="keyWord">machine learning</strong> (<strong class="keyWord">ML</strong>), web <a id="_idIndexMarker003"/>search, non-AI operations, and multiple-session memory systems, we are able to deliver scalable and adaptive solutions for diverse and complex tasks. Take ChatGPT, for example; people use the name “ChatGPT” interchangeably for the generative AI model as well as for the application itself. However, behind the chat interface, tools such as ChatGPT and Gemini are part of larger systems—online copilots—that are fully integrated and managed by intelligent AI controllers to provide a smooth user experience.</p>
    <p class="normal">It was Tomczak (2024) who took us from thinking of generative AI models as a collective entity to considering complex GenAISys architectures. His paper uses the term “GenAISys” to describe these more complex platforms. Our approach in this book will be to expand the horizon of a GenAISys to include advanced AI controller functionality and human roles in a business-ready ecosystem. There is no single silver-bullet architecture for a GenAISys. However, in this section, we’ll define the main components necessary to attain ChatGPT-level functionality. These include a generative AI model, memory retention functions, modular RAG, and multifunctional capabilities. How each component contributes to the GenAISys framework is illustrated in <em class="italic">Figure 1.1</em>:</p>
    <figure class="mediaobject"><img alt="Figure 1.1: GenAISys, the AI controller, and human roles" src="../Images/B32304_01_1.png"/></figure>
    <p class="packt_figref">Figure 1.1: GenAISys, the AI controller, and human roles</p>
    <p class="normal">Let’s now define <a id="_idIndexMarker004"/>the architecture of the AI controllers and human roles that make up a GenAISys.</p>
    <h2 class="heading-2" id="_idParaDest-23"><a id="_idTextAnchor024"/>AI controllers</h2>
    <p class="normal">At the heart of a business-ready GenAISys is an <strong class="keyWord">AI controller</strong> that activates custom ChatGPT-level features <a id="_idIndexMarker005"/>based on the context of the input. Unlike traditional pipelines with predetermined task sequences, the AI controller operates without a fixed order, dynamically adapting tasks—such as web search, image analysis, and text generation—based on the specific context of each input. This agentic context-driven approach enables the AI controller to <a id="_idIndexMarker006"/>orchestrate various components seamlessly, ensuring effective and coherent performance of the generative AI model.</p>
    <p class="normal">A lot of work is required to achieve effective results with a custom ChatGPT-grade AI controller. However, the payoff is a new class of AI systems that can withstand real-world pressure and produce tangible business results. A solid AI controller ecosystem can support use cases across multiple domains: customer support automation, sales lead generation, production optimization (services and manufacturing), healthcare response support, supply chain optimization, and any other domain the market will take you! A GenAISys, thus, requires an AI controller to orchestrate multiple pipelines, such as contextual awareness to understand the intent of the prompt and memory retention to support continuity across sessions. </p>
    <p class="normal">The GenAISys must also define human roles, which determine which functions and data can be accessed. Before we move on to human roles, however, let’s first break down the key components that power the AI controller. As shown in <em class="italic">Figure 1.1</em>, the generative AI model, memory, modular <a id="_idIndexMarker007"/>RAG, and multifunctional capabilities each play vital roles in enabling flexible, context-driven orchestration. Let’s explore how these elements work together to build a business-ready GenAISys. We will first define the role of the generative AI model.</p>
    <h3 class="heading-3" id="_idParaDest-24"><a id="_idTextAnchor025"/>Model-agnostic approach to generative AI</h3>
    <p class="normal">When we build a sustainable GenAISys, we need model <em class="italic">interchangeability</em>—the flexibility to swap <a id="_idIndexMarker008"/>out the underlying model as needed. A generative AI model should serve as a component within the system, not as the <a id="_idIndexMarker009"/>core that the system is <a id="_idIndexMarker010"/>built around. That way, if our model is deprecated or requires updating, or we simply find a better-performing one, we can simply replace it with another that better fits our project.</p>
    <p class="normal">As such, the generative AI model can be OpenAI’s GPT, Google’s Gemini, Meta’s Llama, xAI’s Grok, or any Hugging Face model, as long as it supports the required tasks. Ideally, we should choose a multipurpose, multimodal model that encompasses text, vision, and reasoning abilities. Bommasani et al. (2021) provide a comprehensive analysis of such foundation models, whose scope reaches beyond LLMs.</p>
    <p class="normal">A generative AI model has two main functions, as shown in <em class="italic">Figure 1.2</em>:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Orchestrates</strong> by determining which tasks need to be triggered based on the input. This input <a id="_idIndexMarker011"/>can be a user prompt or a system request <a id="_idIndexMarker012"/>from another function in the pipeline. The orchestration function agent can trigger web search, document parsing, image generation, RAG, ML functions, non-AI functions, and any other function integrated into the GenAISys.</li>
      <li class="bulletList"><strong class="keyWord">Executes</strong> the tasks <a id="_idIndexMarker013"/>requested by the orchestration <a id="_idIndexMarker014"/>layer or executes a task directly based on the input. For example, a simple query such as requesting the capital of the US will not necessarily require complex functionality. However, a request for document analysis might require several functions (chunking, embedding, storing, and retrieving).</li>
    </ul>
    <figure class="mediaobject"><img alt="Figure 1.2: A generative AI model to orchestrate or execute tasks" src="../Images/B32304_01_2.png"/></figure>
    <p class="packt_figref">Figure 1.2: A generative AI model to orchestrate or execute tasks</p>
    <p class="normal">Notice that <em class="italic">Figure 1.2</em> has a unique feature. There are no arrows directing the input, orchestration, and execution components. Unlike traditional hardcoded linear pipelines, a flexible GenAISys has its components unordered. We build the components and then let automated scenarios selected by the orchestration function order the tasks dynamically.</p>
    <p class="normal">This flexibility <a id="_idIndexMarker015"/>ensures the system’s <a id="_idIndexMarker016"/>adaptability to a wide range of tasks. We will <a id="_idIndexMarker017"/>not be able to build a system that solves every task, but we can build one that satisfies a wide range of tasks within a company. Here are two example workflows that illustrate how a GenAISys can dynamically sequence tasks based on the roles involved:</p>
    <ul>
      <li class="bulletList">Human roles can be configured so that, in some cases, the user input executes a simple API call to provide a straightforward response, such as requesting the capital of a country. In this case, the generative AI model executes a request directly.</li>
      <li class="bulletList">System roles can be configured dynamically to orchestrate a set of instructions, such as searching the web first and then summarizing the web page. In this case, the system goes through an orchestration process to produce an output.</li>
    </ul>
    <p class="normal">The possibilities are unlimited; however, all the scenarios will rely on the memory to ensure consistent, context-aware behavior. Let’s look at memory next.</p>
    <h3 class="heading-3" id="_idParaDest-25"><a id="_idTextAnchor026"/>Building the memory of a GenAISys</h3>
    <p class="normal">Advanced <a id="_idIndexMarker018"/>generative AI models such as OpenAI’s GPT, Meta’s Llama, xAI’s Grok, Google’s Gemini, and many Hugging Face variants are <em class="italic">context-driven</em> regardless of their specific version or performance level. You will choose the model based on your project, but the basic rule remains simple:</p>
    <p class="center">No-context =&gt; No meaningful generation</p>
    <p class="normal">When we use ChatGPT or any other copilot, we have nothing to worry about as contextual memory is handled for us. We just start a dialogue, and things run smoothly as we adapt our prompt to the level of responses we are obtaining. However, when we develop a system with a generative AI API <a id="_idIndexMarker019"/>from scratch, we have to explicitly build contextual awareness and memory retention.</p>
    <p class="normal">Four approaches stand out among the wide range of possible memory retention strategies with an API:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Stateless and memoryless session</strong>: A request is sent to the API, and a response is returned <a id="_idIndexMarker020"/>with no memory retention functionality.</li>
      <li class="bulletList"><strong class="keyWord">Short-term memory session</strong>: The <a id="_idIndexMarker021"/>exchanges between the requests and responses are stored in memory during the session but not beyond.</li>
      <li class="bulletList"><strong class="keyWord">Long-term memory of multiple sessions</strong>: The exchanges between the requests and <a id="_idIndexMarker022"/>responses are stored in memory and memorized even after the session ends.</li>
      <li class="bulletList"><strong class="keyWord">Long-term memory of multiple cross-topic sessions</strong>: This feature links the long-term <a id="_idIndexMarker023"/>memory of multiple sessions to other sessions. Each session is assigned a role: a system or multiple users. This feature is not standard in platforms such as ChatGPT but is essential for workflow management within organizations.</li>
    </ul>
    <p class="normal"><em class="italic">Figure 1.3</em> sums up these four memory architectures. We’ll demonstrate each configuration in Python using GPT-4o in the upcoming section, <em class="italic">Contextual awareness and memory retention</em>.</p>
    <figure class="mediaobject"><img alt="Figure 1.3: Four different GenAISys memory configurations" src="../Images/B32304_01_3.png"/></figure>
    <p class="packt_figref">Figure 1.3: Four different GenAISys memory configurations</p>
    <p class="normal">These four <a id="_idIndexMarker024"/>memory types serve as a starting point that can be expanded as necessary when developing a GenAISys. However, practical implementations often require additional functionality, including the following:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Human roles</strong> to define users or groups of users that can access session history or sets of sessions on multiple topics. This will take us beyond ChatGPT-level platforms. We will introduce this aspect in <a href="Chapter_2.xhtml#_idTextAnchor055"><em class="italic">Chapter 2</em></a>, <em class="italic">Building the Generative AI Controller</em>.</li>
      <li class="bulletList"><strong class="keyWord">Storage strategies </strong>to define what we need to store and what we need to discard. We will introduce storage strategies and take this concept further with a Pinecone vector store in <a href="Chapter_3.xhtml#_idTextAnchor085"><em class="italic">Chapter 3</em></a>, <em class="italic">Integrating Dynamic RAG into the GenAISys</em>.</li>
    </ul>
    <p class="normal">There are native distinctions between two key categories of memorization in generative models:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Semantic memory</strong>, which <a id="_idIndexMarker025"/>contains facts such as hard science</li>
      <li class="bulletList"><strong class="keyWord">Episodic memory</strong>, which contains <a id="_idIndexMarker026"/>personal timestamped memories such as personal events in time and business meetings</li>
    </ul>
    <p class="normal">We can see that building a GenAISys’s memory requires careful design and deliberate development to implement ChatGPT-grade memory and additional memory configurations, such as long-term, cross-topic sessions. The ultimate goal, however, of this advanced memory system is to enhance the model’s contextual awareness. While generative AI models such as GPT-4o have inbuilt contextual awareness, to expand the scope of a context-driven system such as the GenAISys we’re building, we need to integrate advanced RAG functionality.</p>
    <h3 class="heading-3" id="_idParaDest-26"><a id="_idTextAnchor027"/>RAG as an agentic multifunction co-orchestrator</h3>
    <p class="normal">In this section, we explain <a id="_idIndexMarker027"/>the motivations for using RAG for <a id="_idIndexMarker028"/>three core functions within a GenAISys:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Knowledge retrieval: </strong>Retrieving targeted, nuanced information</li>
      <li class="bulletList"><strong class="keyWord">Context window optimization: </strong>Engineering optimized prompts</li>
      <li class="bulletList"><strong class="keyWord">Agentic orchestration of multifunctional capabilities</strong>: Triggering functions dynamically</li>
    </ul>
    <p class="normal">Let’s begin with knowledge retrieval.</p>
    <h4 class="heading-4">1. Knowledge retrieval</h4>
    <p class="normal">Generative AI models excel when it comes to revealing parametric knowledge that they have learned, which is <a id="_idIndexMarker029"/>embedded in their weights. This knowledge is learned during training and embedded in models such as GPT, Llama, Grok, and Gemini. However, that knowledge stops at the cutoff date when no additional data is fed to the model. At that point, to update or supplement it, we have two options:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Implicit knowledge</strong>: Fine-tune the model so that more trained knowledge is added to its weights (parametric). This process can be challenging if you are working with dynamic data that changes daily, such as weather forecasts, newsfeeds, or social media messages. It also comes with costs and risks if the fine-tuning process doesn’t work that well for your data.</li>
      <li class="bulletList"><strong class="keyWord">Explicit knowledge</strong>: Store the data in files or embed data in vector stores. The knowledge will then be structured, accessible, traceable, and updated. We can then retrieve the information with advanced queries.</li>
    </ul>
    <p class="normal">It’s important to note here that static implicit knowledge cannot scale effectively without dynamic explicit knowledge. More on that in the upcoming chapters.</p>
    <h4 class="heading-4">2. Context window optimization</h4>
    <p class="normal">Generative AI <a id="_idIndexMarker030"/>models are expanding the boundaries of context windows. For example, at the time of writing, the following are the supported context lengths:</p>
    <ul>
      <li class="bulletList">Llama 4 Scout: 10 million tokens</li>
      <li class="bulletList">Gemini 2.0 Pro Experimental: 2 million tokens</li>
      <li class="bulletList">Claude 3.7 Sonnet: 200,000 tokens</li>
      <li class="bulletList">GPT-4o: 128,000 tokens</li>
    </ul>
    <p class="normal">While impressive, these large context windows can be expensive in terms of token costs and compute. Furthermore, the main issue is that their precision diminishes when the context becomes too large. Also, we don’t need the largest context window but only the one that best fits our project. This can justify implementing RAG if necessary to optimize a project.</p>
    <p class="normal">The chunking process of RAG splits large content into more nuanced groups of tokens. When we embed these chunks, they become vectors that can be stored and efficiently retrieved from vector stores. This approach ensures we use only the most relevant context per task, minimizing <a id="_idIndexMarker031"/>token usage and maximizing response quality. Thus, we can rely on generative AI capabilities for parametric implicit knowledge and RAG for large volumes of explicit non-parametric data in vector stores. We can take RAG further and use the method as an orchestrator.</p>
    <h4 class="heading-4">3. Agentic orchestrator of multifunctional capabilities</h4>
    <p class="normal">The AI controller bridges with RAG through the generative AI model. RAG is used to augment the <a id="_idIndexMarker032"/>model’s input with a flexible range of instructions. Now, using RAG to retrieve instructions might seem counterintuitive at first—but think about it. If we store instructions as vectors and retrieve the best set for a task, we get a fast, adaptable way to enable agentic functionality, generate effective results, and avoid the need to fine-tune the model every time we change our instruction strategies for how we want it to behave.</p>
    <p class="normal">These instructions act as optimized prompts, tailored to the task at hand. In this sense, RAG becomes part of the orchestration layer of the AI system. A vector store such as Pinecone can store and return this functional information, as illustrated in <em class="italic">Figure 1.4</em>:</p>
    <figure class="mediaobject"><img alt="Figure 1.4: RAG orchestration functionality" src="../Images/B32304_01_4.png"/></figure>
    <p class="packt_figref">Figure 1.4: RAG orchestration functionality</p>
    <p class="normal">The orchestration of these scenarios is performed through the following:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Scenario retrieval</strong>: The AI controller will receive structure instructions (scenarios) from a vector database, such as Pinecone, adapted to the user’s query</li>
      <li class="bulletList"><strong class="keyWord">Dynamic task activation</strong>: Each scenario specifies a series of tasks, such as web search, ML algorithms, standard SQL queries, or any function we need</li>
    </ul>
    <p class="normal">Adding <a id="_idIndexMarker033"/>classical functions and ML functionality to the GenAISys enhances its capabilities dramatically. The modular architecture of a GenAISys makes this multifunctional approach effective, as in the following use cases:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Web search</strong> to perform real-time searches to augment inputs</li>
      <li class="bulletList"><strong class="keyWord">Document analysis</strong> to process documents and populate the vector store</li>
      <li class="bulletList"><strong class="keyWord">Document search </strong>to retrieve parts of the processed documents from the vector store</li>
      <li class="bulletList"><strong class="keyWord">ML</strong> such <a id="_idIndexMarker034"/>as <strong class="keyWord">K-means clustering</strong> (<strong class="keyWord">KMC</strong>) to group data <a id="_idIndexMarker035"/>and <strong class="keyWord">k-nearest neighbors</strong> (<strong class="keyWord">KNN</strong>) for similarity searches</li>
      <li class="bulletList"><strong class="keyWord">SQL queries</strong> to execute rule-based retrieval on structured datasets</li>
      <li class="bulletList">Any other function required for your project or workflow</li>
    </ul>
    <p class="normal">RAG remains a critical component of a GenAISys, which we will build into our GenAISys in <a href="Chapter_3.xhtml#_idTextAnchor085"><em class="italic">Chapter 3</em></a>, <em class="italic">Integrating Dynamic RAG into the GenAISys</em>. In <a href="Chapter_3.xhtml#_idTextAnchor085"><em class="italic">Chapter 3</em></a><em class="italic">, Integrating Dynamic RAG into the GenAISys</em>, we will also enhance the system with multifunctional features.</p>
    <p class="normal">We’ll now move on to the human roles, which form the backbone of any GenAISys.</p>
    <h2 class="heading-2" id="_idParaDest-27"><a id="_idTextAnchor028"/>Human roles</h2>
    <p class="normal">Contrary to popular belief, the successful deployment and operation of a GenAISys—such as the ChatGPT platform—relies heavily on human involvement throughout its entire life cycle. While these <a id="_idIndexMarker036"/>tools may seem to handle complex <a id="_idIndexMarker037"/>tasks effortlessly, behind the scenes are multiple layers of human expertise, oversight, and coordination that make their smooth operation possible.</p>
    <p class="normal">Software professionals must first design the architecture, process massive datasets, and fine-tune the system on million-dollar servers equipped with cutting-edge compute resources. After deployment, large teams are required to monitor, validate, and interpret system outputs—continuously adapting them in response to errors, emerging technologies, and regulatory changes. On top of that, when it comes to deploying these systems within organizations—whether inside corporate intranets, public-facing websites, research environments, or learning management systems—it takes cross-functional coordination efforts across multiple domains.</p>
    <p class="normal">These tasks require high levels of expertise and qualified teams. Humans are, therefore, not just irreplaceable; they are critical! They are architects, supervisors, curators, and guardians of the AI systems they create and maintain.</p>
    <h3 class="heading-3" id="_idParaDest-28"><a id="_idTextAnchor029"/>GenAISys implementation and governance teams</h3>
    <p class="normal">Implementing a GenAISys requires technical skills and teamwork to gain the support of end users. It’s a <a id="_idIndexMarker038"/>collaborative challenge between AI controller design, user roles, and expectations. To anyone who thinks that deploying a real-world AI <a id="_idIndexMarker039"/>system is just about getting access to a model—such as the latest GPT, Llama, or Gemini—a close look at the resources required will reveal the true challenges. A massive number of human resources might be involved in the development, deployment, and maintenance of an AI system. Of course, not every organization will need all of these roles, but we must recognize the range of skills involved, such as the following:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Project manager</strong> (<strong class="keyWord">PM</strong>)</li>
      <li class="bulletList">Product <a id="_idIndexMarker040"/>manager</li>
      <li class="bulletList">Program manager</li>
      <li class="bulletList"><strong class="keyWord">ML engineer</strong> (<strong class="keyWord">MLE</strong>)/data <a id="_idIndexMarker041"/>scientist</li>
      <li class="bulletList">Software <a id="_idIndexMarker042"/>developer/<strong class="keyWord">backend engineer</strong> (<strong class="keyWord">BE</strong>)</li>
      <li class="bulletList"><strong class="keyWord">Cloud engineer</strong> (<strong class="keyWord">CE</strong>)</li>
      <li class="bulletList"><strong class="keyWord">Data engineer</strong> (<strong class="keyWord">DE</strong>) and <a id="_idIndexMarker043"/>privacy <a id="_idIndexMarker044"/>manager</li>
      <li class="bulletList">UI/UX designer</li>
      <li class="bulletList">Compliance and regulatory officer</li>
      <li class="bulletList">Legal counsel</li>
      <li class="bulletList"><strong class="keyWord">Security engineer </strong>(<strong class="keyWord">SE</strong>) and <a id="_idIndexMarker045"/>security officer</li>
      <li class="bulletList">Subject-matter experts for each domain-specific deployment</li>
      <li class="bulletList"><strong class="keyWord">Quality assurance engineer</strong> (<strong class="keyWord">QAE</strong>) and <a id="_idIndexMarker046"/>tester</li>
      <li class="bulletList">Technical documentation writer</li>
      <li class="bulletList">System maintenance and support technician</li>
      <li class="bulletList">User support</li>
      <li class="bulletList">Trainer</li>
    </ul>
    <p class="normal">These are just examples—just enough to show how many different roles are involved in building and operating a full-scale GenAISys. <em class="italic">Figure 1.5</em> shows that designing and implementing a GenAISys is a continual process, where human resources are needed at every stage.</p>
    <figure class="mediaobject"><img alt="Figure 1.5: A GenAISys life cycle" src="../Images/B32304_01_5.png"/></figure>
    <p class="packt_figref">Figure 1.5: A GenAISys life cycle</p>
    <p class="normal">We can <a id="_idIndexMarker047"/>see that a GenAISys life cycle is a never-ending process:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Business requirements </strong>will continually evolve with market constraints</li>
      <li class="bulletList"><strong class="keyWord">GenAISys </strong>design will have to adapt with each business shift</li>
      <li class="bulletList"><strong class="keyWord">AI controller </strong>specifications must adapt to technological progress</li>
      <li class="bulletList"><strong class="keyWord">Implementation</strong> must adapt to ever-changing business specifications</li>
      <li class="bulletList"><strong class="keyWord">User feedback</strong> will drive continual improvement</li>
    </ul>
    <p class="normal">Real-world <a id="_idIndexMarker048"/>AI relies heavily on human abilities—the kind of contextual and technical understanding that AI alone cannot replicate. AI can automate a wide range of tasks effectively. But it’s humans who bring the deep insight needed to align those systems with real business goals.</p>
    <p class="normal">Let’s take this further and look at a RACI heatmap to show why humans are a critical component of a GenAISys.</p>
    <h3 class="heading-3" id="_idParaDest-29"><a id="_idTextAnchor030"/>GenAISys RACI</h3>
    <p class="normal">Organizing a GenAISys project requires human resources that go far beyond what AI automation <a id="_idIndexMarker049"/>alone can provide. <strong class="keyWord">RACI</strong> is a responsibility assignment matrix <a id="_idIndexMarker050"/>that helps define roles and responsibilities for each task <a id="_idIndexMarker051"/>or decision by identifying who is <strong class="keyWord">Responsible</strong>, <strong class="keyWord">Accountable</strong>, <strong class="keyWord">Consulted</strong>, and <strong class="keyWord">Informed</strong>. RACI is ideal for managing the complexity of building a GenAISys. It adds structure to the growing list of human roles required during the system’s life cycle and provides a pragmatic framework for coordinating their involvement.</p>
    <p class="normal">As in any complex project, teams working on a GenAISys need to collaborate across disciplines, and RACI helps define who does what. Each letter in RACI stands for a specific type of role:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">R (Responsible): </strong>The person(s) who works actively on the task. They are responsible for the proper completion of the work. For example, an MLE may be responsible for processing datasets with ML algorithms.</li>
      <li class="bulletList"><strong class="keyWord">A (Accountable): </strong>The person(s) answerable for the success or failure of a task. They oversee the task that somebody else is responsible for carrying out. For example, the <strong class="keyWord">product owner</strong> (<strong class="keyWord">PO</strong>) will have to make sure that the MLE’s task is done on time and in compliance with the specifications. If not, the PO will be accountable for the failure.</li>
      <li class="bulletList"><strong class="keyWord">C (Consulted)</strong>: The person(s) providing input, advice, and feedback to help the others in a team. They are not responsible for executing the work. For example, a subject-matter expert in retail may help the MLE understand the goal of an ML algorithm.</li>
      <li class="bulletList"><strong class="keyWord">I (Informed)</strong>: The person(s) kept in the loop about the progress or outcome of a task. They don’t <a id="_idIndexMarker052"/>participate in the task but want to be simply informed or need to make decisions. For example, a <strong class="keyWord">data privacy officer</strong> (<strong class="keyWord">DPO</strong>) would like to be informed about a system’s security functionality.</li>
    </ul>
    <p class="normal">A RACI <a id="_idIndexMarker053"/>heatmap typically contains legends for each human role in a project. Let’s build a heatmap with the following roles:</p>
    <ul>
      <li class="bulletList">The<strong class="keyWord"> MLE</strong> develops and integrates AI models</li>
      <li class="bulletList">The<strong class="keyWord"> DE</strong> designs data management pipelines</li>
      <li class="bulletList">The<strong class="keyWord"> BE</strong> builds API interactions</li>
      <li class="bulletList">The<strong class="keyWord"> frontend engineer </strong>(<strong class="keyWord">FE</strong>) develops end user features</li>
      <li class="bulletList">The<strong class="keyWord"> UI/UX designer</strong> designs user interfaces</li>
      <li class="bulletList">The<strong class="keyWord"> CE/DevOps engineer </strong>manages cloud infrastructure</li>
      <li class="bulletList">The<strong class="keyWord"> prompt engineer</strong> (<strong class="keyWord">PE</strong>) designs optimal prompts</li>
      <li class="bulletList">The<strong class="keyWord"> SE</strong> handles secure data and access</li>
      <li class="bulletList">The<strong class="keyWord"> DPO</strong> manages data governance and regulation compliance</li>
      <li class="bulletList">The<strong class="keyWord"> legal/compliance officer</strong> (<strong class="keyWord">LC</strong>) reviews the legal scope of a project</li>
      <li class="bulletList">The<strong class="keyWord"> QAE</strong> tests the GenAISys</li>
      <li class="bulletList">The<strong class="keyWord"> PO</strong> defines <a id="_idIndexMarker054"/>the scope and scale of a product</li>
      <li class="bulletList">The<strong class="keyWord"> PM</strong> coordinates resources and timelines</li>
      <li class="bulletList">The<strong class="keyWord"> technical writer</strong> (<strong class="keyWord">TW</strong>) produces documentation</li>
      <li class="bulletList">The<strong class="keyWord"> vendor manager</strong> (<strong class="keyWord">VM</strong>) communicates with external vendors and service providers</li>
    </ul>
    <p class="normal">Not every GenAISys project will include all of these roles, but depending on the scope and scale of <a id="_idIndexMarker055"/>the project, many of them will be critical. Now, let’s list <a id="_idIndexMarker056"/>the key responsibilities of the roles defined above in a typical generative AI project:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Model</strong>: AI model development</li>
      <li class="bulletList"><strong class="keyWord">Controller</strong>: Orchestration of APIs and multimodal components</li>
      <li class="bulletList"><strong class="keyWord">Pipelines</strong>: Data processing and integration workflows</li>
      <li class="bulletList"><strong class="keyWord">UI/UX</strong>: User interface and experience design</li>
      <li class="bulletList"><strong class="keyWord">Security</strong>: Data protection and access control</li>
      <li class="bulletList"><strong class="keyWord">DevOps</strong>: Infrastructure, scaling, and monitoring</li>
      <li class="bulletList"><strong class="keyWord">Prompts</strong>: Designing and optimizing model interactions</li>
      <li class="bulletList"><strong class="keyWord">QA</strong>: Testing and quality assurance</li>
    </ul>
    <p class="normal">We’ve defined the roles and the tasks. Now, we can show how they can be mapped to a real-world scenario. <em class="italic">Figure 1.6</em> illustrates an example RACI heatmap for a GenAISys.</p>
    <figure class="mediaobject"><img alt="Figure 1.6: Example of a RACI heatmap" src="../Images/B32304_01_6.png"/></figure>
    <p class="packt_figref">Figure 1.6: Example of a RACI heatmap</p>
    <p class="normal">For example, in this <a id="_idIndexMarker057"/>heatmap, the MLE has the following responsibilities:</p>
    <ul>
      <li class="bulletList">(<strong class="keyWord">R</strong>)esponsible and (<strong class="keyWord">A</strong>)ccountable for the model, which could be GPT-4o.</li>
      <li class="bulletList">(<strong class="keyWord">R</strong>)esponsible and (<strong class="keyWord">A</strong>)ccountable for the prompts for the model</li>
      <li class="bulletList">(<strong class="keyWord">C</strong>)onsulted as an expert for the controller, the pipeline, and testing (QA)</li>
      <li class="bulletList">(<strong class="keyWord">I</strong>)nformed about the UI/UX, security, and DevOps</li>
    </ul>
    <p class="normal">We can <a id="_idIndexMarker058"/>sum it up with one simple rule for a GenAISys:</p>
    <p class="center">No humans -&gt; no system!</p>
    <p class="normal">We can see that <em class="italic">we</em> are necessary during the whole life cycle of a GenAISys, from design to maintenance and support, including continual evolutions to keep up with user feedback. Humans have been and will be here for a long time! Next, let’s explore the business opportunities that a GenAISys can unlock.</p>
    <h1 class="heading-1" id="_idParaDest-30"><a id="_idTextAnchor031"/>Business opportunities and scope</h1>
    <p class="normal">More often than not, we will not have access to the incredible billion-dollar resources of OpenAI, Meta, xAI, or Microsoft Azure to build ChatGPT-like platforms. The previous section showed <a id="_idIndexMarker059"/>that beneath a ChatGPT-like, seemingly simple, seamless interface, there is a complex layer of expensive infrastructure, rare talent, and continuous improvement and evolution that absorb resources only large corporations can afford. Therefore, a smarter path from the start is to determine which project category we are in and leverage the power of existing modules and libraries to build our GenAISys. Whatever the use case, such as marketing, finance, production, or support, we need to find the right scope and scale to implement a realistic GenAISys.</p>
    <p class="normal">The first step of any GenAISys is to define the project’s goal (opportunity), including its scope and scale, as we mentioned. During this step, you will assess the risks, such as costs, confidentiality, and resource availability (risk management).</p>
    <p class="normal">We can <a id="_idIndexMarker060"/>classify GenAISys projects into three main business implementation types depending on our resources, our objectives, the complexity of our use case, and our budget. These are illustrated in <em class="italic">Figure 1.7</em>:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Hybrid approach</strong>: Leveraging existing AI platforms</li>
      <li class="bulletList"><strong class="keyWord">Small scope and scale</strong>: A focused GenAISys</li>
      <li class="bulletList"><strong class="keyWord">Full-scale generative multi-agent AI system</strong>: A complete ChatGPT-level generative AI platform</li>
    </ul>
    <figure class="mediaobject"><img alt="Figure 1.7: The three main GenAISys business implementations" src="../Images/B32304_01_7.png"/></figure>
    <p class="packt_figref">Figure 1.7: The three main GenAISys business implementations</p>
    <p class="normal">Let’s begin with a hybrid approach, a practical way to deliver business results without overbuilding.</p>
    <h2 class="heading-2" id="_idParaDest-31"><a id="_idTextAnchor032"/>Hybrid approach</h2>
    <p class="normal">A hybrid <a id="_idIndexMarker061"/>framework enables you <a id="_idIndexMarker062"/>to minimize development costs and time by combining ready-to-use SaaS platforms with custom-built components developed only when necessary, such as web search and data cleansing. This way, you can leverage the power of generative AI without developing everything from scratch. Let’s go through the key characteristics and a few example use cases.</p>
    <h3 class="heading-3" id="_idParaDest-32"><a id="_idTextAnchor033"/>Key characteristics</h3>
    <ul>
      <li class="bulletList">Relying on <a id="_idIndexMarker063"/>proven web services such as OpenAI’s GPT API, AWS, Google AI, or Microsoft Azure. These platforms provide the core generative functionality.</li>
      <li class="bulletList">Customizing your project by integrating domain-specific vector stores and your organization’s proprietary datasets.</li>
      <li class="bulletList">Focusing development on targeted functionality, such as customer support automation or marketing campaign generation.</li>
    </ul>
    <h3 class="heading-3" id="_idParaDest-33"><a id="_idTextAnchor034"/>Use case examples</h3>
    <ul>
      <li class="bulletList">Implementing a <a id="_idIndexMarker064"/>domain-specific vector store to handle legal, medical, or product-related customer queries</li>
      <li class="bulletList">Building customer support on a social media platform with real-time capabilities</li>
    </ul>
    <p class="normal">This category offers the ability to do more with less—in terms of both cost and development effort. A hybrid system can be a standalone GenAISys or a subsystem within a larger generative AI platform where full-scale development isn’t necessary. Let’s now look at how a small-scope, small-scale GenAISys can take us even further.</p>
    <h2 class="heading-2" id="_idParaDest-34"><a id="_idTextAnchor035"/>Small scope and scale</h2>
    <p class="normal">A small-scale GenAISys might include an intelligent, GenAI-driven AI controller connected to a vector <a id="_idIndexMarker065"/>store. This setup allows <a id="_idIndexMarker066"/>the system to retrieve data, trigger instructions, and call additional functionality such as web search or ML—without needing full-scale infrastructure.</p>
    <h3 class="heading-3" id="_idParaDest-35"><a id="_idTextAnchor036"/>Key characteristics</h3>
    <ul>
      <li class="bulletList">A clearly <a id="_idIndexMarker067"/>defined profitable system designed to achieve reasonable objectives with optimal development time and cost</li>
      <li class="bulletList">The AI controller orchestrates instruction scenarios that, in turn, trigger RAG, web search, image analysis, and additional custom tasks that fit your needs</li>
      <li class="bulletList">The focus is on high-priority, productive features</li>
    </ul>
    <h3 class="heading-3" id="_idParaDest-36"><a id="_idTextAnchor037"/>Use case examples</h3>
    <ul>
      <li class="bulletList">A GenAISys for <a id="_idIndexMarker068"/>document retrieval and summarization for any type of document with nuanced analysis through chunked and embedded content</li>
      <li class="bulletList">Augmenting a model such as GPT or Llama with real-time web search to bypass its data cutoff date—ideal for applications such as weather forecasting or news monitoring <a id="_idIndexMarker069"/>that don’t need continual fine-tuning</li>
    </ul>
    <p class="normal">This category takes us a step beyond the hybrid approach, while still staying realistic and manageable for small to mid-sized businesses or even individual departments within large organizations.</p>
    <h2 class="heading-2" id="_idParaDest-37"><a id="_idTextAnchor038"/>Full-scale GenAISys</h2>
    <p class="normal">If you’re <a id="_idIndexMarker070"/>working in a team of experts <a id="_idIndexMarker071"/>within an organization that has a large budget and advanced infrastructure, this category is for you. Your team can build a full-scale GenAISys that begins to approach the capabilities of ChatGPT-grade platforms.</p>
    <h3 class="heading-3" id="_idParaDest-38"><a id="_idTextAnchor039"/>Key characteristics</h3>
    <ul>
      <li class="bulletList">A full-blown <a id="_idIndexMarker072"/>AI controller that manages and orchestrates complex automated workflows, including RAG, instruction scenarios, multimodal functionality, and real-time data</li>
      <li class="bulletList">Requires significant computing resources and highly skilled development teams</li>
    </ul>
    <div class="note">
      <p class="normal"> Think of the GenAISys we’re building in this book as an alpha version—a template that can be cloned, configured, and deployed anywhere in the organization as often as needed.</p>
    </div>
    <h3 class="heading-3" id="_idParaDest-39"><a id="_idTextAnchor040"/>Use case examples</h3>
    <ul>
      <li class="bulletList">GenAISys is <a id="_idIndexMarker073"/>already present in healthcare to assist with patient diagnosis and disease prevention. The Institut Curie in Paris, for example, has a very advanced AI research team: <a href="https://institut-curie.org/"><span class="url">https://institut-curie.org/</span></a>.</li>
      <li class="bulletList">Many large organizations have begun implementing GenAISys for fraud detection, weather predictions, and legal expertise.</li>
    </ul>
    <p class="normal">You can join one of these large organizations that have the resources to build a sustainable GenAISys, whether it be on a cloud platform, local servers, or both.</p>
    <p class="normal">The three categories—hybrid, small scale, and full scale—offer distinct paths for building a GenAISys, depending on your organization’s goals, budget, and technical capabilities. In this book, we’ll explore the critical components that make up a GenAISys. By the end, you’ll be equipped to contribute to any of these categories and offer realistic, technically grounded recommendations for the projects you work on.</p>
    <p class="normal">Let’s now lift the hood and begin building contextual awareness and memory retention in code.</p>
    <h1 class="heading-1" id="_idParaDest-40"><a id="_idTextAnchor041"/>Contextual awareness and memory retention</h1>
    <p class="normal">In this section, we’ll begin implementing simulations of contextual awareness and memory retention <a id="_idIndexMarker074"/>in Python to illustrate the concepts introduced in the <em class="italic">Building the memory of a GenAISys</em> section. The goal is to demonstrate practical ways to manage context and memory—two features that are becoming increasingly critical as generative AI platforms evolve.</p>
    <p class="normal">Open the <code class="inlineCode">Contextual_Awareness_and_Memory_Retention.ipynb</code> file located in the <code class="inlineCode">chapter01</code> folder of the GitHub repository (<a href="https://github.com/Denis2054/Building-Business-Ready-Generative-AI-Systems/tree/main"><span class="url">https://github.com/Denis2054/Building-Business-Ready-Generative-AI-Systems/tree/main</span></a>). You’ll see that the notebook is divided into five main sections:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Setting up the environment</strong>, building reusable functions, and storing them in the <code class="inlineCode">commons</code> directory of the repository, so we can reuse them when necessary throughout the book</li>
      <li class="bulletList"><strong class="keyWord">Stateless and memoryless session</strong> with semantic and episodic memory</li>
      <li class="bulletList"><strong class="keyWord">Short-term memory session</strong> for context awareness during a session</li>
      <li class="bulletList"><strong class="keyWord">Long-term memory across multiple sessions</strong> for context retention across different sessions</li>
      <li class="bulletList"><strong class="keyWord">Long-term memory of multiple cross-topic sessions</strong>, expanding long-term memory over formerly separate sessions</li>
    </ul>
    <p class="normal">The goal is to illustrate each type of memory in an explicit process. These examples are intentionally kept manual for now, but they will be automated and managed by the AI controller we will begin to build in the next chapter.</p>
    <div class="note">
      <p class="normal"> Due to the probabilistic nature of generative models, you may observe different outputs for the same prompt across runs. Make sure to run the entire notebook in a single session, as memory retention in this notebook is explicit in different cells. In <a href="Chapter_2.xhtml#_idTextAnchor055"><em class="italic">Chapter 2</em></a>, this functionality will become persistent and fully managed by the AI controller</p>
    </div>
    <p class="normal">The first step is to install the environment.</p>
    <h2 class="heading-2" id="_idParaDest-41"><a id="_idTextAnchor042"/>Setting up the environment</h2>
    <p class="normal">We will <a id="_idIndexMarker075"/>need a <code class="inlineCode">commons</code> directory for our GenAISys project. This directory will contain the main modules and libraries needed across all notebooks in this book’s GitHub repository. The motivation is to focus on designing the system for maintenance and support. As such, by grouping the main modules and libraries in one directory, we can zero in on a resource that requires our attention instead of repeating the setup steps in every notebook. Furthermore, this section will serve as a reference point for all the notebooks in this book’s GitHub repository. We’ll only describe the downloading of each resource once and then reuse them throughout the book to build our educational GenAISys.</p>
    <p class="normal">Thus, we can download the notebook resources from the <code class="inlineCode">commons</code> directory and install the requirements.</p>
    <p class="normal">The first <a id="_idIndexMarker076"/>step is to download <code class="inlineCode">grequests.py</code>, a utility script we will use throughout the book. It contains a function to download the files we need directly from GitHub:</p>
    <pre class="programlisting code"><code class="hljs-code">!curl -L https://raw.githubusercontent.com/Denis2054/Building-Business-Ready-Generative-AI-Systems/master/commons/grequests.py --output grequests.py
</code></pre>
    <div class="packt_tip">
      <p class="normal"><img alt="" src="../Images/3-PPMUMLAP0325.png"/><strong class="keyWord">Quick tip</strong>: Enhance your coding experience with the <strong class="keyWord">AI Code Explainer</strong> and <strong class="keyWord">Quick Copy</strong> features. Open this book in the next-gen Packt Reader. Click the <strong class="keyWord">Copy</strong> button</p>
      <p class="normal">(<strong class="keyWord">1</strong>) to quickly copy code into your coding environment, or click the <strong class="keyWord">Explain</strong> button</p>
      <p class="normal">(<strong class="keyWord">2</strong>) to get the AI assistant to explain a block of code to you.</p>
      <p class="normal"><img alt="A white background with a black text  AI-generated content may be incorrect." src="../Images/image_%282%29.png"/></p>
      <p class="normal"><img alt="" src="../Images/4.png"/><strong class="keyWord">The next-gen Packt Reader </strong>is included for free with the purchase of this book. Scan the QR code OR visit <a href="http://packtpub.com/unlock"><span class="url">packtpub.com/unlock</span></a>, then use the search bar to find this book by name. Double-check the edition shown to make sure you get the right one.</p>
      <p class="normal"><img alt="A qr code on a white background  AI-generated content may be incorrect." src="../Images/Unlock_Code1.png"/></p>
    </div>
    <p class="normal">The goal of this script is to download a file from any directory of the repository by calling the <code class="inlineCode">download</code> function from <code class="inlineCode">grequests</code>:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import sys</span>
<span class="hljs-keyword">import subprocess </span>
<span class="hljs-keyword">from</span> grequests <span class="hljs-keyword">import</span> download
download([directory],[file])
</code></pre>
    <p class="normal">This function uses a <code class="inlineCode">curl</code> command to download files from a specified directory and filename. It also includes basic error handling in case of command execution failures.</p>
    <p class="normal">The code begins by importing <code class="inlineCode">subprocess</code> to handle paths and commands. The <code class="inlineCode">download</code> function contains two parameters:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">def</span> <span class="hljs-title">download</span>(<span class="code-highlight"><strong class="hljs-params-slc">directory</strong></span><span class="hljs-params">, </span><span class="code-highlight"><strong class="hljs-params-slc">filename</strong></span>):
</code></pre>
    <ul>
      <li class="bulletList"><code class="inlineCode">directory</code>: The subdirectory of the GitHub repository where the file is stored</li>
      <li class="bulletList"><code class="inlineCode">filename</code>: The name of the file to download</li>
    </ul>
    <p class="normal">The base URL for the GitHub repository is then defined, pointing to the raw files we will need:</p>
    <pre class="programlisting code"><code class="hljs-code">base_url = <span class="hljs-string">'https://raw.githubusercontent.com/Denis2054/Building-Business-Ready-Generative-AI-Systems/main/'</span>
</code></pre>
    <p class="normal">We now need to define the file’s full URL with the <code class="inlineCode">directory</code> and <code class="inlineCode">filename</code> parameters:</p>
    <pre class="programlisting code"><code class="hljs-code">file_url = <span class="hljs-string">f"</span><span class="hljs-subst">{base_url}{directory}</span><span class="hljs-string">/</span><span class="hljs-subst">{filename}</span><span class="hljs-string">"</span>
</code></pre>
    <p class="normal">The function now defines the <code class="inlineCode">curl</code> command:</p>
    <pre class="programlisting code"><code class="hljs-code">curl_command = <span class="hljs-string">f'curl -o </span><span class="hljs-subst">{filename}</span><span class="hljs-string"> </span><span class="hljs-subst">{file_url}</span><span class="hljs-string">'</span>
</code></pre>
    <p class="normal">Finally, the <code class="inlineCode">download</code> command is executed:</p>
    <pre class="programlisting code"><code class="hljs-code">subprocess.run(curl_command, check=<span class="hljs-literal">True</span>, shell=<span class="hljs-literal">True</span>)
</code></pre>
    <ul>
      <li class="bulletList"><code class="inlineCode">check=True</code> activates an exception if the <code class="inlineCode">curl</code> command fails</li>
      <li class="bulletList"><code class="inlineCode">shell=True</code> runs the command through the shell</li>
    </ul>
    <p class="normal">The <code class="inlineCode">try-except</code> block <a id="_idIndexMarker077"/>is used to handle errors:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">try</span>:
    <span class="hljs-comment"># Prepare the curl command with the Authorization header</span>
    curl_command = <span class="hljs-string">f'curl -o </span><span class="hljs-subst">{filename}</span><span class="hljs-string"> </span><span class="hljs-subst">{file_url}</span><span class="hljs-string">'</span>
    <span class="hljs-comment"># Execute the curl command</span>
    subprocess.run(curl_command, check=<span class="hljs-literal">True</span>, shell=<span class="hljs-literal">True</span>)
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f"Downloaded '</span><span class="hljs-subst">{filename}</span><span class="hljs-string">' successfully."</span>)
<span class="hljs-keyword">except</span> subprocess.CalledProcessError:
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f"Failed to download '</span><span class="hljs-subst">{filename}</span><span class="hljs-string">'. Check the URL and your internet connection"</span>)
</code></pre>
    <p class="normal">We now have a standalone download script that we’ll use throughout the book. Let’s go ahead and download the resources we need for this program.</p>
    <h3 class="heading-3" id="_idParaDest-42"><a id="_idTextAnchor043"/>Downloading OpenAI resources</h3>
    <p class="normal">We need <a id="_idIndexMarker078"/>three resources for this notebook:</p>
    <ul>
      <li class="bulletList"><code class="inlineCode">requirements01.py</code> to install the precise OpenAI version we want</li>
      <li class="bulletList"><code class="inlineCode">openai_setup.py</code> to initialize the OpenAI API key</li>
      <li class="bulletList"><code class="inlineCode">openai_api_py</code> contains a reusable function for calling the GPT-4o model, so you don’t need to rewrite the same code across multiple cells or notebooks</li>
    </ul>
    <div class="note">
      <p class="normal"> We will be reusing the same functions throughout the book for standard OpenAI API calls. You can come back to this section any time you want to revisit the installation process. Other scenarios will be added to the <code class="inlineCode">commons</code> directory when necessary.</p>
    </div>
    <p class="normal">We can download these files with the <code class="inlineCode">download()</code> function:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> grequests <span class="hljs-keyword">import</span> download
download(<span class="hljs-string">"commons"</span>,<span class="hljs-string">"requirements01.py"</span>)
download(<span class="hljs-string">"commons"</span>,<span class="hljs-string">"</span><span class="hljs-string">openai_setup.py"</span>)
download(<span class="hljs-string">"commons"</span>,<span class="hljs-string">"openai_api.py"</span>)
</code></pre>
    <p class="normal">The first <a id="_idIndexMarker079"/>resource is <code class="inlineCode">requirements01.py</code>.</p>
    <h4 class="heading-4">Installing OpenAI</h4>
    <p class="normal"><code class="inlineCode">requirements01.py</code> makes sure that a specific version of the OpenAI library is installed to avoid conflicts <a id="_idIndexMarker080"/>with other installed libraries. The code thus uninstalls existing versions, force-installs the specified version requested, and verifies the result. The function executes the installation with error handling:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">def</span> <span class="hljs-title">run_command</span>(<span class="hljs-params">command</span>):
    <span class="hljs-keyword">try</span>:
        subprocess.check_call(command)
    <span class="hljs-keyword">except</span> subprocess.CalledProcessError <span class="hljs-keyword">as</span> e:
        <span class="hljs-built_in">print</span>(<span class="hljs-string">f"Command failed: </span><span class="hljs-subst">{</span><span class="hljs-string">' '</span><span class="hljs-subst">.join(command)}</span><span class="hljs-string">\nError: </span><span class="hljs-subst">{e}</span><span class="hljs-string">"</span>)
        sys.exit(<span class="hljs-number">1</span>)
</code></pre>
    <p class="normal">The first step for the function is to uninstall the current OpenAI library, if there is one:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-built_in">print</span>(<span class="hljs-string">"Installing 'openai' version 1.57.1..."</span>)
run_command([sys.executable, <span class="hljs-string">"-m"</span>, <span class="hljs-string">"pip"</span>, <span class="hljs-string">"install"</span>, <span class="hljs-string">"--force-reinstall"</span>, <span class="hljs-string">"openai==1.57.1"</span>])
</code></pre>
    <p class="normal">The function then installs a specific version of OpenAI:</p>
    <pre class="programlisting code"><code class="hljs-code">run_command(
    [
        sys.executable, <span class="hljs-string">"-m"</span>, <span class="hljs-string">"pip"</span>, <span class="hljs-string">"install"</span>, 
        <span class="code-highlight"><strong class="hljs-string-slc">"--force-reinstall"</strong><strong class="hljs-slc">, </strong><strong class="hljs-string-slc">"openai==1.57.1"</strong></span>
    ]
)
</code></pre>
    <p class="normal">Finally, the function verifies that OpenAI is properly installed:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">try</span>:
    <span class="hljs-keyword">import</span> openai
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f"'openai' version </span><span class="hljs-subst">{openai.__version__}</span><span class="hljs-string"> is installed."</span>)
<span class="hljs-keyword">except</span> ImportError:
    <span class="hljs-built_in">print</span>(<span class="hljs-string">"Failed to import the 'openai' library after installation."</span>)
    sys.exit(<span class="hljs-number">1</span>)
</code></pre>
    <p class="normal">The output <a id="_idIndexMarker081"/>at the end of the function should be as follows:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-string">'openai'</span> version <span class="hljs-number">1.57.1</span> <span class="hljs-keyword">is</span> installed.
</code></pre>
    <p class="normal">We can now initialize the OpenAI API key.</p>
    <h4 class="heading-4">OpenAI API key initialization</h4>
    <p class="normal">There are <a id="_idIndexMarker082"/>two methods to initialize the OpenAI <a id="_idIndexMarker083"/>API key in the notebook:</p>
    <ol>
      <li class="numberedList" value="1"><strong class="keyWord">Using Google Colab secrets</strong>: Click on the key icon in the left pane in Google Colab, as shown in <em class="italic">Figure 1.8</em>, then click on <strong class="screenText">Add new secret</strong> and add your key with the name of the key variable you will use in the notebook:</li>
    </ol>
    <figure class="mediaobject"><img alt="Figure 1.8: Add a new Google secret key" src="../Images/B32304_01_8.png"/></figure>
    <p class="packt_figref">Figure 1.8: Add a new Google secret key</p>
    <p class="normal">Then, we can use Google’s function to initialize the key by calling it in our <code class="inlineCode">openai_setup</code> function in <code class="inlineCode">openai_setup.py</code>:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># Import libraries</span>
<span class="hljs-keyword">import</span> openai
<span class="hljs-keyword">import</span> os
<span class="hljs-keyword">from</span> google.colab <span class="hljs-keyword">import</span> userdata
<span class="hljs-comment"># Function to initialize the OpenAI API key</span>
<span class="hljs-keyword">def</span> <span class="hljs-title">initialize_openai_api</span>():
<span class="hljs-comment"># Function to initialize the OpenAI API key</span>
<span class="hljs-keyword">def</span> <span class="hljs-title">initialize_openai_api</span>():
    <span class="hljs-comment"># Access the secret by its name</span>
    API_KEY = userdata.get(<span class="hljs-string">'API_KEY'</span>)
   
    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> API_KEY:
        <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">"API_KEY is not set in userdata!"</span>)
   
    <span class="hljs-comment"># Set the API key in the environment and OpenAI</span>
    os.environ[<span class="hljs-string">'OPENAI_API_KEY'</span>] = API_KEY
    openai.api_key = os.getenv(<span class="hljs-string">"</span><span class="hljs-string">OPENAI_API_KEY"</span>)
    <span class="hljs-built_in">print</span>(<span class="hljs-string">"OpenAI API key initialized successfully."</span>)
</code></pre>
    <p class="normal">This method is activated if <code class="inlineCode">google_secrets</code> is set to <code class="inlineCode">True</code>:</p>
    <pre class="programlisting code"><code class="hljs-code">google_secrets=<span class="hljs-literal">True</span>
<span class="hljs-keyword">if</span> google_secrets==<span class="hljs-literal">True</span>:
    <span class="hljs-keyword">import</span> openai_setup
    openai_setup.initialize_openai_api()
</code></pre>
    <ul>
      <li class="bulletList"><strong class="keyWord">Custom secure method</strong>: You can also choose a custom method or enter the key in the <a id="_idIndexMarker084"/>code by setting <code class="inlineCode">google_secrets</code> to <code class="inlineCode">False</code>, uncommenting the following code, and entering your API key directly, or any method of your choice:
        <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">if</span> google_secrets==<span class="hljs-literal">False</span>: <span class="hljs-comment"># Uncomment the code and choose any method you wish to initialize the API_KEY</span>
    <span class="hljs-keyword">import</span> os
    <span class="hljs-comment">#API_KEY=[YOUR API_KEY]</span>
    <span class="hljs-comment">#os.environ['OPENAI_API_KEY'] = API_KEY</span>
    <span class="hljs-comment">#openai.api_key = os.getenv("OPENAI_API_KEY")</span>
    <span class="hljs-comment">#print("OpenAI API key initialized successfully.")</span>
</code></pre>
      </li>
    </ul>
    <p class="normal">In both cases, the code will create an environment variable:</p>
    <pre class="programlisting code"><code class="hljs-code">os.environ[<span class="hljs-string">'OPENAI_API_KEY'</span>] = API_KEY
openai.api_key = os.getenv(<span class="hljs-string">"OPENAI_API_KEY"</span>)
</code></pre>
    <p class="normal">The OpenAI API key is initialized. We will now import a custom OpenAI API call.</p>
    <h4 class="heading-4">OpenAI API call</h4>
    <p class="normal">The goal <a id="_idIndexMarker085"/>next is to create an OpenAI API call function in <code class="inlineCode">openai_api.py</code> that <a id="_idIndexMarker086"/>we can import in two lines:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment">#Import the function from the custom OpenAI API file</span>
<span class="hljs-keyword">import</span> openai_api
<span class="hljs-keyword">from</span> openai_api <span class="hljs-keyword">import</span> make_openai_api_call
</code></pre>
    <p class="normal">The function is thus built to receive four variables when making the call and display them seamlessly:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># API function call</span>
response = openai_api.make_openai_api_call(
    uinput,mrole,mcontent,user_role)
<span class="hljs-built_in">print</span>(response)
</code></pre>
    <p class="normal">The parameters in this function are the following:</p>
    <ul>
      <li class="bulletList"><code class="inlineCode">input</code>: Contains the input (user or system), for example, <code class="inlineCode">Where is Hawaii?</code></li>
      <li class="bulletList"><code class="inlineCode">mrole</code>: Defines the system’s role, for example, <code class="inlineCode">You are a geology expert.</code> or simply <code class="inlineCode">System.</code></li>
      <li class="bulletList"><code class="inlineCode">mcontent</code>: Is what we expect the system to be, for example, <code class="inlineCode">You are a geology expert.</code></li>
      <li class="bulletList"><code class="inlineCode">user_role</code>: Defines the role of the user, for example, <code class="inlineCode">user</code></li>
    </ul>
    <p class="normal">The first <a id="_idIndexMarker087"/>part of the code in the function defines the model we will be using in this <a id="_idIndexMarker088"/>notebook and creates a message object for the API call with the parameters we sent:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">def</span> <span class="hljs-title">make_openai_api_call</span>(<span class="hljs-built_in">input</span><span class="hljs-params">, mrole,mcontent,user_role</span>):
    <span class="hljs-comment"># Define parameters</span>
    gmodel = <span class="hljs-string">"gpt-4o"</span>
    <span class="hljs-comment"># Create the messages object</span>
    messages_obj = [
        {
            <span class="hljs-string">"role"</span>: mrole,
            <span class="hljs-string">"content"</span>: mcontent
        },
        {
            <span class="hljs-string">"role"</span>: user_role,
            <span class="hljs-string">"content"</span>: <span class="hljs-built_in">input</span>
        }
    ]
</code></pre>
    <p class="normal">We then define the API call parameters in a dictionary for this notebook:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># Define all parameters in a dictionary named params:</span>
    params = {
        <span class="code-highlight"><strong class="hljs-string-slc">"temperature"</strong></span>: <span class="hljs-number">0</span>,
        <span class="code-highlight"><strong class="hljs-string-slc">"max_tokens"</strong></span>: <span class="hljs-number">256</span>,
        <span class="code-highlight"><strong class="hljs-string-slc">"top_p"</strong></span>: <span class="hljs-number">1</span>,
        <span class="code-highlight"><strong class="hljs-string-slc">"frequency_penalty"</strong></span>: <span class="hljs-number">0</span>,
        <span class="code-highlight"><strong class="hljs-string-slc">"presence_penalty"</strong></span>: <span class="hljs-number">0</span>
    }
</code></pre>
    <p class="normal">The dictionary parameters are the following:</p>
    <ul>
      <li class="bulletList"><code class="inlineCode">temperature</code>: Controls the randomness of a response. <code class="inlineCode">0</code> will produce deterministic responses. Higher values<strong class="keyWord"> </strong>(e.g., <code class="inlineCode">0.7</code>) will produce more creative responses.</li>
      <li class="bulletList"><code class="inlineCode">max_tokens</code>: Limits the maximum number of tokens of a response.</li>
      <li class="bulletList"><code class="inlineCode">top_p</code>: Produces nucleus sampling. It controls the diversity of a response by sampling from the top tokens with a cumulative probability of 1.</li>
      <li class="bulletList"><code class="inlineCode">frequency_penalty</code>: Reduces the repetition of tokens to avoid redundancies. <code class="inlineCode">0</code> will apply no penalty, and <code class="inlineCode">2</code> a strong penalty. In this case, <code class="inlineCode">0</code> is sufficient because of the high performance of the OpenAI model.</li>
      <li class="bulletList"><code class="inlineCode">presence_penalty</code>: Encourages new content by penalizing existing content to avoid redundancies. It applies to the same values as for the frequency penalty. In this case, due to the high performance of the OpenAI model, it doesn’t require this control.</li>
    </ul>
    <p class="normal">We then <a id="_idIndexMarker089"/>initialize the OpenAI client to create an instance for the API calls:</p>
    <pre class="programlisting code"><code class="hljs-code">    client = OpenAI()
</code></pre>
    <p class="normal">Finally, we make <a id="_idIndexMarker090"/>the API call by sending the model, the message object, and the unpacked parameters:</p>
    <pre class="programlisting code"><code class="hljs-code">    <span class="hljs-comment"># Make the API call</span>
    response = client.chat.completions.create(
        model=gmodel,
        messages=messages_obj,
        **params  <span class="hljs-comment"># Unpack the parameters dictionary</span>
    )
</code></pre>
    <p class="normal">The function ends by returning the content of the API’s response that we need:</p>
    <pre class="programlisting code"><code class="hljs-code">    <span class="hljs-comment">#Return the response</span>
    <span class="hljs-keyword">return</span> response.choices[<span class="hljs-number">0</span>].message.content
</code></pre>
    <p class="normal">This function will help us focus on the GenAISys architecture without having to overload the notebook with repetitive libraries and functions.</p>
    <p class="normal">In the notebook, we have the following:</p>
    <ul>
      <li class="bulletList">The program provides the input, roles, and message content to the function</li>
      <li class="bulletList"><code class="inlineCode">messages_obj</code> contains the conversation history</li>
      <li class="bulletList">The parameters for the API’s behavior are defined in the <code class="inlineCode">params</code> dictionary</li>
      <li class="bulletList">An API call is made to the OpenAI model using the OpenAI client</li>
      <li class="bulletList">The function returns only the AI’s response content</li>
    </ul>
    <div class="note">
      <p class="normal"> A GenAISys will contain many components—including a generative model. You can choose the one that fits your project. In this book, the models are used for educational purposes only, not as endorsements or recommendations.</p>
    </div>
    <p class="normal">Let’s now build and run a stateless and memoryless session.</p>
    <h2 class="heading-2" id="_idParaDest-43"><a id="_idTextAnchor044"/>1. Stateless and memoryless session</h2>
    <p class="normal">A stateless and memoryless session is useful if we only want a single and temporary exchange with <a id="_idIndexMarker091"/>no stored information between requests. The examples in this section are both stateless and memoryless:</p>
    <ul>
      <li class="bulletList"><em class="italic">Stateless</em> indicates <a id="_idIndexMarker092"/>that each request will be processed independently</li>
      <li class="bulletList"><em class="italic">Memoryless</em> means that <a id="_idIndexMarker093"/>there is no mechanism to remember past exchanges</li>
    </ul>
    <p class="normal">Let’s begin with a semantic query.</p>
    <h3 class="heading-3" id="_idParaDest-44"><a id="_idTextAnchor045"/>Semantic query</h3>
    <p class="normal">This request <a id="_idIndexMarker094"/>expects a purely semantic, factual response:</p>
    <pre class="programlisting code"><code class="hljs-code">uinput = <span class="hljs-string">"Hawai is on a geological volcano system. Explain:"</span>
mrole = <span class="hljs-string">"system"</span>
mcontent = <span class="hljs-string">"You are an expert in geology."</span>
user_role = <span class="hljs-string">"user"</span>
</code></pre>
    <p class="normal">Now, we call the OpenAI API function:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># Function call</span>
response = openai_api.make_openai_api_call(
    uinput,mrole,mcontent,user_role)
<span class="hljs-built_in">print</span>(response)
</code></pre>
    <p class="normal">As you can see, the response is purely semantic:</p>
    <pre class="programlisting con"><code class="hljs-con">Hawaii is located on a volcanic hotspot in the central Pacific Ocean, which is responsible for the formation of the Hawaiian Islands. This hotspot is a region where magma from deep within the Earth's mantle rises to the surface, creating volcanic activity…
</code></pre>
    <p class="normal">The next query is episodic.</p>
    <h3 class="heading-3" id="_idParaDest-45"><a id="_idTextAnchor046"/>Episodic query with a semantic undertone</h3>
    <p class="normal">The query in this example is episodic and draws on personal experience. However, there is a semantic <a id="_idIndexMarker095"/>undertone because of the description of Hawaii. Here’s the message, which is rather poetic:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># API message</span>
uinput = <span class="hljs-string">"I vividly remember my family's move to Hawaii in the 1970s, how they embraced the warmth of its gentle breezes, the joy of finding a steady job, and the serene beauty that surrounded them. Sum this up in one nice sentence from a personal perspective:"</span>
mrole = <span class="hljs-string">"system"</span>
mcontent = <span class="hljs-string">"You are an expert in geology."</span>
user_role = <span class="hljs-string">"user"</span>
</code></pre>
    <div class="note">
      <p class="normal"><code class="inlineCode">mcontent</code> is reused <a id="_idIndexMarker096"/>from the semantic query example (“You are an expert in geology”), but in this case, it doesn’t significantly influence the response. Since the user input is highly personal and narrative-driven, the system prompt plays a minimal role. </p>
    </div>
    <p class="normal">We could insert external information before the function call if necessary. For example, we could add some information from another source, such as a text message received that day from a family member:</p>
    <pre class="programlisting code"><code class="hljs-code">text_message=<span class="hljs-string">'I agree, we had a wonderful time there.'</span>
uninput=text_message+uinput
text_message=<span class="hljs-string">"Hi, I agree, we had a wonderful time there."</span>
</code></pre>
    <p class="normal">Now, we call the function:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># Call the function</span>
response = openai_api.make_openai_api_call(
    uinput,mrole,mcontent,user_role)
<span class="hljs-built_in">print</span>(response)
</code></pre>
    <p class="normal">We see that the response is mostly episodic with some semantic information:</p>
    <pre class="programlisting con"><code class="hljs-con">Moving to Hawaii in the 1970s was a transformative experience for my family, as they found joy in the island's gentle breezes, the security of steady employment, and the serene beauty that enveloped their new home.
</code></pre>
    <h3 class="heading-3" id="_idParaDest-46"><a id="_idTextAnchor047"/>Stateless and memoryless verification</h3>
    <p class="normal">We added <a id="_idIndexMarker097"/>no memory retention functionality earlier, making the dialogue stateless. Let’s check:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># API message</span>
uinput = <span class="hljs-string">"What question did I just ask you?"</span>
mrole = <span class="hljs-string">"system"</span>
mcontent = <span class="hljs-string">"You already have this information"</span>
user_role = <span class="hljs-string">"user"</span>
</code></pre>
    <p class="normal">When we <a id="_idIndexMarker098"/>call the function, our dialogue will be forgotten:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># API function call</span>
response = openai_api.make_openai_api_call(
    uinput,mrole,mcontent,user_role
)
<span class="hljs-built_in">print</span>(response)
</code></pre>
    <p class="normal">The output confirms that the session is memoryless:</p>
    <pre class="programlisting con"><code class="hljs-con">I'm sorry, but I can't recall previous interactions or questions. Could you please repeat your question?
</code></pre>
    <p class="normal">The API call is stateless because the OpenAI API does not retain memory between requests. If we were using ChatGPT directly, the exchanges would be memorized within that session. This has a critical impact on implementation. It means we have to build our own memory mechanisms to give GenAISys stateful behavior. Let’s start with the first layer: short-term memory.</p>
    <h2 class="heading-2" id="_idParaDest-47"><a id="_idTextAnchor048"/>2. Short-term memory session</h2>
    <p class="normal">The <a id="_idIndexMarker099"/>goal of this section <a id="_idIndexMarker100"/>is to emulate a short-term memory session using a two-step process:</p>
    <ol>
      <li class="numberedList" value="1">First, we initiate a session that goes from user input to a response:</li>
    </ol>
    <p class="center">User input =&gt; Generative model API call =&gt; Response</p>
    <p class="normal">To achieve this first step, we run the session up to the response:</p>
    <pre class="programlisting code"><code class="hljs-code">uinput = <span class="hljs-string">"Hawai is on a geological volcano system. Explain:"</span>
mrole = <span class="hljs-string">"system"</span>
mcontent = <span class="hljs-string">"You are an expert in geology."</span>
user_role = <span class="hljs-string">"user"</span>
response = openai_api.make_openai_api_call(
    uinput,mrole,mcontent,user_role)
<span class="hljs-built_in">print</span>(response)
</code></pre>
    <p class="normal">The response’s output is stored in <code class="inlineCode">response</code>:</p>
    <pre class="programlisting con"><code class="hljs-con">"Hawaii is part of a volcanic system known as a hotspot, which is a region of the Earth's mantle where heat rises as a thermal plume from deep within the Earth. This hotspot is responsible for the formation of the Hawaiian Islands. Here's how the process works:…"
</code></pre>
    <ol>
      <li class="numberedList" value="2">The next <a id="_idIndexMarker101"/>step is to feed the previous interaction into <a id="_idIndexMarker102"/>the next prompt, along with a follow-up question:<ul>
          <li class="bulletList">Explain the situation: <code class="inlineCode">The current dialog session is:</code></li>
          <li class="bulletList">Add the user’s initial input: <code class="inlineCode">Hawai is on a geological volcano system. Explain:</code></li>
          <li class="bulletList">Add the response we obtained in the previous call</li>
          <li class="bulletList">Add the user’s new input: <code class="inlineCode">Sum up your previous response in a short sentence in a maximum of 20 words.</code></li>
        </ul>
      </li>
    </ol>
    <p class="normal">The goal here is to compress the session log. We won’t always need to compress dialogues, but in longer sessions, large context windows can pile up quickly. This technique helps keep the token count low, which matters for both cost and performance. In this particular case, we’re only managing one response, so we could keep the entire interaction in memory if we wanted to. Still, this example introduces a useful habit for scaling up.</p>
    <p class="normal">Once the prompt is assembled:</p>
    <ul>
      <li class="bulletList">Call the API function</li>
      <li class="bulletList">Display the response</li>
    </ul>
    <p class="normal">The scenario is illustrated in the code:</p>
    <pre class="programlisting code"><code class="hljs-code">ninput = <span class="hljs-string">"Sum up your previous response in a short sentence in a maximum of 20 words."</span>
uinput = (
    <span class="hljs-string">"The current dialog session is: "</span> +
    uinput +
    response +
    ninput
)
response = openai_api.make_openai_api_call(
    uinput, mrole, mcontent, user_role
)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"</span><span class="hljs-string">New response:"</span>, <span class="hljs-string">"\n\n"</span>, uinput, <span class="hljs-string">"\n"</span>, response)
</code></pre>
    <p class="normal">The output provides a nice, short summary of the dialogue:</p>
    <pre class="programlisting con"><code class="hljs-con">New response: Hawaii's islands form from volcanic activity over a stationary hotspot beneath the moving Pacific Plate.
</code></pre>
    <p class="normal">This <a id="_idIndexMarker103"/>functionality <a id="_idIndexMarker104"/>wasn’t strictly necessary here, but it sets us up for the longer dialogues we’ll encounter later in the book. Next, let’s build a long-term simulation of multiple sessions.</p>
    <div class="note">
      <p class="normal"> Keep in mind: Since the session is still in-memory only, the conversation would be lost if the notebook disconnects. Nothing is stored on disk or in a database yet.</p>
    </div>
    <h2 class="heading-2" id="_idParaDest-48"><a id="_idTextAnchor049"/>3. Long-term memory of multiple sessions</h2>
    <p class="normal">In this section, we’re simulating long-term memory by continuing a conversation from an earlier <a id="_idIndexMarker105"/>session. The difference here is that we’re not just <em class="italic">remembering</em> a dialogue from a single session—we’re <em class="italic">reusing</em> content from a past session to extend <a id="_idIndexMarker106"/>the conversation. At this point, the term “session” takes on a broader meaning. In a traditional copilot scenario, one user interacts with one model in one self-contained session. Here, we’re blending sessions and supporting multiple sub-sessions. Multiple users can interact with the model in a shared environment, effectively creating a single global session with branching memory threads. Think of the model as a guest in an ongoing Zoom or Teams meeting. You can ask the AI guest to participate or stay quiet—and when it joins, it may need a recap.</p>
    <p class="normal">To avoid repeating the first steps of the past conversation, we’re reusing the content from the short-term memory session we just ran. Let’s assume the previous session is over, but we still want to continue from where we left off:</p>
    <pre class="programlisting code"><code class="hljs-code">session01=response
<span class="hljs-built_in">print</span>(session01)
</code></pre>
    <p class="normal">The output contains the final response from our short-term memory session:</p>
    <pre class="programlisting con"><code class="hljs-con">Hawaii's islands form from volcanic activity over a stationary hotspot beneath the moving Pacific Plate.
</code></pre>
    <p class="normal">The <a id="_idIndexMarker107"/>process in <a id="_idIndexMarker108"/>this section will build on the previous session, similar to how you’d revisit a conversation with an online copilot after some time away:</p>
    <p class="center">Save previous session =&gt; Load previous session =&gt; Add it to the new session’s scenario</p>
    <p class="normal">Let’s first test whether the API remembers anything on its own:</p>
    <pre class="programlisting code"><code class="hljs-code">uinput=<span class="hljs-string">"Is it safe to go there on vacation"</span>
response = openai_api.make_openai_api_call(
    uinput,mrole,mcontent,user_role
)
<span class="hljs-built_in">print</span>(response)
</code></pre>
    <p class="normal">The output shows that it forgot the conversation we were in:</p>
    <pre class="programlisting con"><code class="hljs-con">I'm sorry, but I need more information to provide a helpful response. Could you specify the location you're considering for your vacation? …
</code></pre>
    <p class="normal">The API forgot the previous call because stateless APIs don’t retain past dialogue. It’s up to us to decide what to include in the prompt. We have a few choices:</p>
    <ul>
      <li class="bulletList">Do we want to remember everything with a large consumption of tokens?</li>
      <li class="bulletList">Do we want to summarize parts or all of the previous conversations?</li>
    </ul>
    <p class="normal">In a real GenAISys, when an input triggers a request, the AI controller decides which is the best strategy to apply to a task. The code now associates the previous session’s context and memory with a new request:</p>
    <pre class="programlisting code"><code class="hljs-code">ninput = <span class="hljs-string">"Let's continue our dialog."</span>
uinput=ninput + session01 + <span class="hljs-string">"Would it be safe to go there on vacation?"</span>
response = openai_api.make_openai_api_call(
    uinput,mrole,mcontent,user_role
)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Dialog:"</span>, uinput,<span class="hljs-string">"\n"</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Response:"</span>, response)
</code></pre>
    <p class="normal">The response <a id="_idIndexMarker109"/>shows that the system now remembers the past <a id="_idIndexMarker110"/>session and has enough information to provide an acceptable output:</p>
    <pre class="programlisting con"><code class="hljs-con">Response: Hawaii is generally considered a safe destination for vacation, despite its volcanic activity. The Hawaiian Islands are formed by a hotspot beneath the Pacific Plate, which creates volcanoes as the plate moves over it. While volcanic activity is a natural and ongoing process in Hawaii, it is closely monitored by the United States Geological Survey (USGS) and other agencies…
</code></pre>
    <p class="normal">Let’s now build a long-term simulation of multiple sessions across different topics.</p>
    <h2 class="heading-2" id="_idParaDest-49"><a id="_idTextAnchor050"/>4. Long-term memory of multiple cross-topic sessions</h2>
    <p class="normal">This <a id="_idIndexMarker111"/>section illustrates how to merge two separate sessions into one. This isn’t <a id="_idIndexMarker112"/>something standard ChatGPT-like platforms offer. Typically, when we start a new topic, the copilot only remembers what’s happened in the current session. But in a corporate environment, we may need more flexibility—especially when multiple users are collaborating. In such cases, the AI controller can be configured to allow groups of users to view and merge sessions generated by others in the same group.</p>
    <p class="normal">Let’s say we want to sum up two separate conversations—one about Hawaii’s volcanic systems, and another about organizing a geological field trip to Arizona. We begin by saving the previous long-term memory session:</p>
    <pre class="programlisting code"><code class="hljs-code">session02=uinput + response
<span class="hljs-built_in">print</span>(session02)
</code></pre>
    <p class="normal">Then we can start a separate multi-user sub-session from another location, Arizona:</p>
    <pre class="programlisting code"><code class="hljs-code">ninput =<span class="hljs-string">"</span><span class="hljs-string">I would like to organize a geological visit in Arizona."</span>
uinput=ninput+<span class="hljs-string">"Where should I start?"</span>
response = openai_api.make_openai_api_call(
    uinput,mrole,mcontent,user_role
)
<span class="hljs-comment">#print("Dialog:", uinput,"\n")</span>
</code></pre>
    <p class="normal">We now expect a response on Arizona, leaving Hawaii out:</p>
    <pre class="programlisting con"><code class="hljs-con">Response: Organizing a geological visit in Arizona is a fantastic idea, as the state is rich in diverse geological features. Here's a step-by-step guide to help you plan your trip:…
</code></pre>
    <p class="normal">The <a id="_idIndexMarker113"/>response is acceptable. Now, let’s <a id="_idIndexMarker114"/>simulate long-term memory across multiple topics by combining both sessions and prompting the system to summarize them:</p>
    <pre class="programlisting code"><code class="hljs-code">session02=response
ninput=<span class="hljs-string">"Sum up this dialog in a short paragraph:"</span>
uinput=ninput+ session01 + session02
response = openai_api.make_openai_api_call(
    uinput,mrole,mcontent,user_role
)
<span class="hljs-comment">#print("Dialog:", uinput,"\n")#optional</span>
<span class="hljs-built_in">print</span>(<span class="hljs-string">"Response:"</span>, response)
</code></pre>
    <p class="normal">The system’s output shows that the long-term memory of the system is effective. We see that the first part is about Hawaii:</p>
    <pre class="programlisting con"><code class="hljs-con">Response: The dialog begins by explaining the formation of Hawaii's volcanic islands as the Pacific Plate moves over a stationary hotspot, leading to active volcanoes like Kilauea….
</code></pre>
    <p class="normal">Then the response continues to the part about Arizona:</p>
    <pre class="programlisting con"><code class="hljs-con">It then transitions to planning a geological visit to Arizona, emphasizing the state's diverse geological features. The guide recommends researching key sites such as the Grand Canyon…
</code></pre>
    <p class="normal">We’ve now covered the core memory modes of GenAISys—from stateless and short-term memory to multi-user, multi-topic long-term memory. Let’s now summarize the chapter’s journey and move to the next level!</p>
    <h1 class="heading-1" id="_idParaDest-50"><a id="_idTextAnchor051"/>Summary</h1>
    <p class="normal">A business-ready GenAISys offers functionality on par with ChatGPT-like platforms. It brings together generative AI models, agentic features, RAG, memory retention, and a range of ML and non-AI functions—all coordinated by an AI controller. Unlike traditional pipelines, the controller doesn’t follow a fixed sequence of steps. Instead, it orchestrates tasks dynamically, adapting to the context.</p>
    <p class="normal">A GenAISys typically runs on a model such as GPT-4o—or whichever model best fits your use case. But as we’ve seen, just having access to an API isn’t enough. Contextual awareness and memory retention are essential. While ChatGPT-like tools offer these features by default, we have to build them ourselves when creating custom systems.</p>
    <p class="normal">We explored four types of memory: memoryless, short-term, long-term, and cross-topic. We also distinguished semantic memory (facts) from episodic memory (personal, time-stamped information). Context awareness depends heavily on memory—but context windows have limits. Even if we increase the window size, models can still miss the nuance in complex tasks. That’s where advanced RAG comes in—breaking down content into smaller chunks, embedding them, and storing them in vector stores such as Pinecone. This expands what the system can “remember” and use for reasoning.</p>
    <p class="normal">We also saw that no matter how advanced GenAISys becomes, it can’t function without human expertise. From design to deployment, maintenance, and iteration, people remain critical throughout the system’s life cycle. We then outlined three real-world implementation models based on available resources and goals: hybrid systems that leverage existing AI platforms, small-scale systems for targeted business needs, and full-scale systems built for ChatGPT-grade performance.</p>
    <p class="normal">Finally, we got hands-on—building a series of memory simulation modules in Python using GPT-4o. These examples laid the groundwork for what comes next: the AI controller that will manage memory, context, and orchestration across your GenAISys. We are now ready to build a GenAISys AI controller!</p>
    <h1 class="heading-1" id="_idParaDest-51"><a id="_idTextAnchor052"/>Questions</h1>
    <ol>
      <li class="numberedList" value="1">Is an API generative AI model such as GPT an AI controller? (Yes or No) </li>
      <li class="numberedList">Does a memoryless session remember the last exchange(s)? (Yes or No) </li>
      <li class="numberedList">Is RAG used to optimize context windows? (Yes or No)</li>
      <li class="numberedList">Are human roles important for the entire life cycle of a GenAISys? (Yes or No) </li>
      <li class="numberedList">Can an AI controller run tasks dynamically? (Yes or No) </li>
      <li class="numberedList">Is a small-scale GenAISys built with a limited number of key features? (Yes or No) </li>
      <li class="numberedList">Does a full-scale ChatGPT-like system require huge resources? (Yes or No) </li>
      <li class="numberedList">Is long-term memory necessary across multiple sessions? (Yes or No) </li>
      <li class="numberedList">Do vector stores such as Pinecone support knowledge and AI controller functions? (Yes or No) </li>
      <li class="numberedList">Can a GenAISys function without contextual awareness? (Yes or No) </li>
    </ol>
    <h1 class="heading-1" id="_idParaDest-52"><a id="_idTextAnchor053"/>References</h1>
    <ul>
      <li class="bulletList">Tomczak, J. M. (2024). <em class="italic">Generative AI Systems: A Systems-based Perspective on Generative AI.</em> <a href="https://arxiv.org/pdf/2407.11001"><span class="url">https://arxiv.org/pdf/2407.11001</span></a><a href="https://arxiv.org/pdf/2407.11001 "/></li>
      <li class="bulletList">Zewe, A. (2023, November 9). <em class="italic">Explained: Generative AI.</em> MIT News. Retrieved from <a href="https://news.mit.edu/2023/explained-generative-ai-1109"><span class="url">https://news.mit.edu/2023/explained-generative-ai-1109</span></a><a href="https://news.mit.edu/2023/explained-generative-ai-1109 "/></li>
      <li class="bulletList">OpenAI models: <a href="https://platform.openai.com/docs/models"><span class="url">https://platform.openai.com/docs/models</span></a><a href="https://platform.openai.com/docs/models "/></li>
      <li class="bulletList">Bommasani, R., Hudson, D. A., Adeli, E., Altman, R., Arora, S., von Arx, S., ... &amp; Liang, P. (2021). <em class="italic">On the Opportunities and Risks of Foundation Models.</em> arXiv preprint arXiv:2108.07258. Retrieved from <a href="https://arxiv.org/abs/2108.07258"><span class="url">https://arxiv.org/abs/2108.07258</span></a><a href="https://arxiv.org/abs/2108.07258 "/></li>
    </ul>
    <h1 class="heading-1" id="_idParaDest-53"><a id="_idTextAnchor054"/>Further reading</h1>
    <ul>
      <li class="bulletList">Feuerriegel, S., Hartmann, J., Janiesch, C., &amp; Zschech, P. (2023). <em class="italic">Generative AI. Business &amp; Information Systems Engineering</em>. <a href="https://doi.org/10.1007/s12599-023-00834-7 "><span class="url">https://doi.org/10.1007/s12599-023-00834-7</span></a></li>
      <li class="bulletList">Eloundou et al. (2023). <em class="italic">GPTs are GPTs: An Early Look at the Labor Market Impact Potential of Large Language Models.</em> <a href="https://arxiv.org/abs/2303.10130"><span class="url">https://arxiv.org/abs/2303.10130</span></a>
        <div class="unlock">
          <table class="table-container" id="table001-1">
            <tbody>
              <tr>
                <td class="table-cell">
                  <h4 class="heading-4">Unlock this book’s exclusive benefits now</h4>
                  <p class="normal">Scan this QR code or go to <a href="http://packtpub.com/unlock"><span class="url">packtpub.com/unlock</span></a>, then search for this book by name.</p>
                </td>
                <td class="table-cell" rowspan="2">
                  <figure class="mediaobject"><img alt="A qr code on a white background  AI-generated content may be incorrect." src="../Images/Unlock.png"/></figure>
                </td>
              </tr>
              <tr>
                <td class="table-cell">
                  <p class="normal"><em class="italic">Note: Keep your purchase invoice ready before you start.</em></p>
                </td>
              </tr>
            </tbody>
          </table>
        </div>
      </li>
    </ul>
  </div>
</body></html>