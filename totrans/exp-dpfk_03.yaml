- en: '3'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '3'
- en: Acquiring and Processing Data
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据获取和处理
- en: Data is the most important part of any AI task, and deepfakes are no exception.
    The quality of a swap is limited by the input data, and selecting that data is
    the most important task of a deepfake creator. While there are ways to automate
    parts of data gathering, the process is still largely manual.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 数据是任何AI任务最重要的部分，深度伪造也不例外。交换的质量受到输入数据的质量限制，选择数据是深度伪造制作者最重要的任务。虽然有一些方法可以自动化数据收集的部分，但这个过程仍然主要是手动的。
- en: In this chapter, we will cover the importance of data, what makes quality data,
    how to get your data, and how to improve poor data. These are skills that are
    critical for a deepfake creator and must be developed. This chapter will explain
    the basics of these skills, but they must be practiced for full understanding
    and use.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论数据的重要性、什么因素使数据质量好、如何获取数据以及如何改进差数据。这些技能对于深度伪造制作者至关重要，必须加以培养。本章将解释这些技能的基本原理，但它们必须通过实践来完全理解和应用。
- en: Upscaling
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 上采样
- en: 'We will cover the following sections:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将涵盖以下部分：
- en: Why data is important
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么数据很重要
- en: Understanding the value of variety
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解多样性的价值
- en: Sourcing data
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据来源
- en: Improving your data
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提升你的数据
- en: Upscaling
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 上采样
- en: Why data is important
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么数据很重要
- en: Neural networks work by taking data that is known and processing it in order
    to train the deepfake AI (see [*Chapter 1*](B17535_01.xhtml#_idTextAnchor015),
    *Surveying Deepfakes*, for an explanation of the whole process). We call this
    set of data, simply enough, a **dataset**. To create a dataset, the data has to
    be processed and prepared for the neural network so that it has something to train
    with. In the case of deepfakes, we use faces, which need to be detected, aligned,
    and cleaned in order to create an effective dataset.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络通过处理已知数据来训练深度伪造AI（见[*第1章*](B17535_01.xhtml#_idTextAnchor015)，*调查深度伪造*，了解整个过程）。我们简单地将这组数据称为**数据集**。为了创建数据集，数据必须经过处理和准备，以便神经网络有东西可以训练。在深度伪造的情况下，我们使用人脸，需要检测、对齐和清理，以创建一个有效的数据集。
- en: Without a properly formatted and prepared dataset, the neural network simply
    cannot be trained. There is another potential problem when it comes to generative
    networks like deepfakes – a poor quality dataset leads to poor swaps. Unfortunately,
    it’s hard to know at the beginning whether a dataset will produce a good swap
    or not. This is a skill that takes time to learn, and your first few deepfakes
    are unlikely to turn out well as you learn the importance of data.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 没有格式正确且准备好的数据集，神经网络就无法进行训练。对于像深度伪造这样的生成网络，还存在另一个潜在问题——质量差的数据集会导致交换效果差。不幸的是，在开始时很难知道数据集是否会生成好的交换效果。这是一种需要时间来学习的技能，而且在你学习数据的重要性时，你最初的几个深度伪造作品可能不会很好。
- en: Time spent cleaning and managing data is time very well spent. While the largest
    time sink in a deepfake is the time spent training, that time requires no input
    from the creator – however, if your data is flawed, that time will be entirely
    wasted. To this end, most deepfakers spend a good deal of time cleaning and testing
    their data before they commit to a long training session.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 花在清理和管理数据上的时间是值得的。虽然深度伪造中最大的时间消耗是训练时间，但那段时间不需要创作者的输入——然而，如果你的数据有缺陷，那么这段时间将完全浪费。因此，大多数深度伪造制作者在投入长时间训练之前，会花大量时间清理和测试他们的数据。
- en: You may think that **resolution** (the number of pixels in an image) is important
    in your dataset, but it’s really not that important. There are very few high-resolution
    deepfakes available. A video may be 4k, 8k, or even higher, but the face swapped
    will be limited by the AI model, the capabilities of the computer it’s trained
    on, and the time available to spend training. 512x512 pixels is a very high resolution
    in the world of deepfakes, and higher resolutions are reserved for the most dedicated
    and skilled deepfakers.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能认为**分辨率**（图像中的像素数量）在你的数据集中很重要，但实际上并不是那么重要。可用的超高分辨率深度伪造非常少。视频可能是4k、8k甚至更高，但人脸交换将受到AI模型、训练计算机的能力以及可用于训练的时间的限制。在深度伪造的世界里，512x512像素是一个非常高的分辨率，而更高的分辨率则留给最专注和技艺高超的深度伪造制作者。
- en: 'That doesn’t mean you can’t get good results with lower resolutions. One clear
    way to think of the difference is that **fidelity** is not the same as resolution.
    Fidelity measures how little information is lost from its original, that is how
    realistic or lifelike an image is. Think of a small thumbnail picture of a realistic
    painting, such as the image of the Mona Lisa shown in *Figure 3**.1*: it is *highfidelity*
    but *low-resolution*. The opposite in this example would be a drawing by a 5-year-old
    (or in this case, one of the authors) of the Mona Lisa using an advanced drawing
    pad on a computer. That image is *high-resolution* but *low-fidelity*. As you
    train, your deepfake AI will increase its fidelity but the resolution will stay
    the same.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这并不意味着你不能用较低的分辨率获得好的结果。一种清晰的方式来思考这种差异是**保真度**并不等同于分辨率。保真度衡量的是从原始信息中丢失了多少信息，即图像的逼真程度或真实感。想象一下一幅小缩略图，如*图3.1*中展示的蒙娜丽莎的画像，它是一个逼真的图像，但分辨率低。在这个例子中，相反的是一位5岁孩子（或在这种情况下，作者之一）使用电脑上的高级绘图板绘制的蒙娜丽莎画像。这幅图像分辨率高，但保真度低。随着你的训练，你的深度伪造AI将提高其保真度，但分辨率将保持不变。
- en: "![Figure 3.1 – “The Mona Lisa” by Leonardo DaVinci,\uFEFF a high-fidelity but\
    \ low-resolution image (UL); “A Mona Lisa” by Bryan Lyon, a high-resolution but\
    \ low-fidelity image (LR)](img/B17535_03_001.jpg)"
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![图3.1 – 列奥纳多·达·芬奇的“蒙娜丽莎”，高保真但低分辨率图像（UL）；布莱恩·莱昂的“蒙娜丽莎”，高分辨率但低保真度图像（LR）](img/B17535_03_001.jpg)'
- en: Figure 3.1 – “The Mona Lisa” by Leonardo DaVinci, a high-fidelity but low-resolution
    image (UL); “A Mona Lisa” by Bryan Lyon, a high-resolution but low-fidelity image
    (LR)
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.1 – 列奥纳多·达·芬奇的“蒙娜丽莎”，高保真但低分辨率图像（UL）；布莱恩·莱昂的“蒙娜丽莎”，高分辨率但低保真度图像（LR）
- en: Data is very important to your deepfakes, and variety is the most effective
    way to ensure good data.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 数据对你的深度伪造非常重要，而多样性是确保良好数据的最有效方式。
- en: Understanding the value of variety
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解多样性的价值
- en: Variety is the single most defining trait of a good dataset. The best datasets
    will all have a large variety of poses, expressions, and lighting situations,
    while the worst results will come from data lacking variety in one or more of
    these categories. Some of the areas of variety we’ll cover in this section include
    pose, expression, and lighting.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 多样性是良好数据集的最具定义性的特征。最好的数据集都将拥有大量不同的姿势、表情和照明情况，而最差的结果将来自在这些类别中缺乏多样性的数据。在本节中，我们将涵盖的一些多样性领域包括姿势、表情和照明。
- en: Pose
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 姿势
- en: Pose is a simple category to both see and understand. Pose is simply the direction
    and placement of the face in the image. When it comes to deepfakes, only the pose
    of the face itself matters – the rest of the body’s pose is ignored. Pose in deepfakes
    is important so that the AI can learn all the angles and directions of the face.
    Without sufficient pose data, the AI will struggle to match the direction of the
    face and you’ll end up with poor results.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 姿势是一个简单且易于观察和理解的类别。姿势简单来说就是图像中面部方向和位置。在深度伪造中，只有面部本身的姿势很重要——身体其他部位的姿势被忽略。在深度伪造中，姿势很重要，这样AI才能学习到面部所有角度和方向。如果没有足够的姿势数据，AI将难以匹配面部方向，最终导致结果不佳。
- en: '![Figure 3.2 – Examples of different poses](img/B17535_03_002.jpg)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![图3.2 – 不同姿势的示例](img/B17535_03_002.jpg)'
- en: Figure 3.2 – Examples of different poses
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.2 – 不同姿势的示例
- en: One quick way to get the full range of poses is to simply move the head while
    being filmed. By looking around up, down, and from side to side (along with mixtures
    of these), you give the AI all the directions that it needs. Don’t forget to get
    distant shots with a high **focal length** to zoom into the face, as well as close-ups
    with a neutral focal length. A high focal length “zoom” on a distant face causes
    the “flattening” (the effect is properly called **lens compression**) of the depth
    of the face and is often used for dramatic effect in movies, so you need to match
    the variance in your data as well. Even something such as lens distortion matters
    and can affect the image enough that getting a variety of examples can help get
    quality data.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 一个快速获得完整姿势范围的方法是在被拍摄时简单地移动头部。通过向上、向下和从侧面四处张望（以及这些动作的组合），你为AI提供了它所需的所有方向。别忘了用高**焦距**的远摄镜头来放大面部，以及用中性焦距的特写镜头。远摄镜头对远处的面部进行“扁平化”（这种效果正确地称为**镜头压缩**），常在电影中用于戏剧效果，因此你需要匹配你数据中的这种变化。甚至像镜头畸变这样的因素也很重要，它足以影响图像，因此获取各种示例可以帮助获得高质量的数据。
- en: Expression
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 表情
- en: Expression is another aspect that is easy to understand – it’s the shape the
    face makes during training. Unfortunately, it’s very hard to ensure that you have
    met the full range without missing important data. Think about how expressive
    a face may be – happy, sad, angry, awake, surprised, and so much more – and think
    about how easy it may be to miss an important subset of those expressions in your
    data.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 表情是另一个容易理解的方面——它是训练期间脸部形成的形状。不幸的是，很难确保你涵盖了全部范围而没有遗漏重要数据。想想一个脸部的表现力可能有多大——快乐、悲伤、愤怒、清醒、惊讶等等——然后想想在数据中错过这些表情的重要子集可能有多容易。
- en: There is no easy way to ensure that you have all the variety that you need,
    but the more the better. You don’t want to just sit someone down and film their
    face for an hour, as you are unlikely to get all the expressions you really want.
    To really get a good variety of expressions, you need to make sure that you get
    data from different days, in different environments, and with different emotional
    stimuli. An actor may give you drastically different “sad” expressions in different
    contexts or times, and that variety is important for the AI to really understand
    how to recreate those same expressions.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 没有简单的方法可以确保你拥有所有需要的多样性，但越多越好。你不想只是让人坐下来，面对镜头拍一个小时，因为你不太可能得到你真正想要的全部表情。要真正获得丰富的表情多样性，你需要确保从不同日期、不同环境和不同情绪刺激中获取数据。一个演员在不同的情境或时间可能会给出截然不同的“悲伤”表情，这种多样性对于人工智能真正理解如何重现这些相同的表情非常重要。
- en: '![Figure 3.3 – Examples of different expressions](img/B17535_03_003.jpg)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.3 – 不同表情的示例](img/B17535_03_003.jpg)'
- en: Figure 3.3 – Examples of different expressions
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.3 – 不同表情的示例
- en: The key here is to get as many different expressions as you can. You can’t get
    all your data at once; if you do, your data will be extremely limited. If you
    have an excellent actor as your target face, you might be able to get away with
    having them match the expressions that you’re swapping to, but you’ll probably
    want to get a much more varied dataset to ensure you’re getting the right data
    in the right contexts.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的关键是尽可能多地获取不同的表情。你不可能一次性获取所有数据；如果你这么做，你的数据将会极其有限。如果你有一个优秀的演员作为目标面孔，你可能能够让他们匹配你正在交换的表情，但你可能想要获取一个更加多样化的数据集，以确保你在正确的情境中获取正确的数据。
- en: Lighting
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 照明
- en: Lighting may sound easy and/or trivial but ask any photographer or videographer
    about it and they’ll be able to talk forever. Lighting a photo or video shoot
    is complicated even when you’re not dealing with AI, but when deepfakes are involved,
    it becomes an enormous issue. It’s simply impossible to get a complete variety
    of lighting, but there are some keys to consider.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 照明可能听起来简单且/或微不足道，但问问任何摄影师或视频制作人员，他们可以永远谈论这个话题。即使不涉及人工智能，照明照片或视频拍摄也是复杂的，但当涉及到深度伪造时，它成为一个巨大的问题。完全获得各种照明是不可能的，但有一些关键点需要考虑。
- en: “Good” lighting
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: “良好的”照明
- en: Most Hollywood films are examples of expert light management with entire teams
    dedicated to even the simplest setups. However, there are a few good ground rules
    for basic lighting for deepfakes.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数好莱坞电影都是专业照明管理的例子，整个团队致力于最简单的设置。然而，对于深度伪造的基本照明有一些很好的基本规则。
- en: Clear lighting cannot come from a single direction. This leads to deep shadows
    in the eyes, next to the nose, and often on one whole side of the face. Even direct
    face-first lighting will lead to shadows at the edges (not to mention probably
    lead to expression changes as the actor squints). Instead, you need to have good
    **ambient**-style lighting – that is, lighting coming evenly from all directions.
    Offices with large fluorescent lights will probably be a good example of this
    lighting (although the color of the light will leave something to be desired).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 明亮的照明不能来自单一方向。这会导致眼睛、鼻子旁边以及经常是整个脸部一侧出现深阴影。即使是直接面向镜头的照明也会在边缘产生阴影（更不用说演员眯眼时可能会改变表情）。相反，你需要有良好的**环境**式照明——也就是说，从所有方向均匀照射的照明。拥有大型荧光灯的办公室可能是这种照明的良好例子（尽管灯光的颜色可能不尽如人意）。
- en: Shadows
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 阴影
- en: However, ambient lighting is not the only style of lighting that deepfakes require.
    You need some shadow in the dataset or the AI will never learn how to recreate
    anything but a fully lit face. For this lighting, you can use a normal overhead
    light or lamp. This will enable the AI to pick up some of those deeper shadows
    that really help to bring a face’s depth into perspective.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，环境光线并不是深度伪造所需的唯一照明风格。数据集中需要一些阴影，否则AI将永远无法学会如何重现除了完全照亮的面部之外的其他任何东西。对于这种照明，你可以使用普通的顶灯或灯具。这将使AI能够捕捉到那些真正有助于将面部深度展现出来的较深阴影。
- en: The best way to get shadow variety is in scenes where the lighting or subject
    is moving, giving you lots of varied shadows that the AI can learn.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 获取阴影多样性的最佳方式是在照明或主题移动的场景中，这样你就能获得大量的变化阴影，AI可以从中学习。
- en: Outdoors
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 户外
- en: Finally, you are going to want to get some outdoor images. The Sun is particularly
    unique among all other light sources. There is nothing that quite matches the
    natural effect of a burning ball of plasma millions of miles away from the subject
    – and believe it or not, the distance really does matter, as it leads to basically
    parallel light rays. Because of this, no matter how much “in-studio” filming you
    do, it’s very important to get at least some of your data outdoors. The Sun’s
    light is truly impossible to reproduce, and getting data that was filmed outdoors
    is indispensable to fill out the lighting data for the AI.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，你将想要获取一些户外图像。太阳在所有其他光源中特别独特。没有任何东西能够完全匹配来自数百万英里之外的燃烧等离子体的自然效果——信不信由你，距离确实很重要，因为它会导致基本上平行的光线。正因为如此，无论你在摄影棚内拍摄多少，获取至少一些户外数据都非常重要。太阳的光线是无法复制的，获取户外拍摄的数据对于补充AI的照明数据是必不可少的。
- en: Bringing this variety together
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将这种多样性结合起来
- en: It’s important to think about all the aspects of variety separately, but you
    actually also need to consider them together as well. You should get data that
    mix and match all three aspects in order to ensure that you get the best results.
    For example, all your different lighting scenarios should have a variety of expressions
    and poses. Only with varied data can the AI learn to create a truly convincing
    deepfake.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到多样性的所有方面是很重要的，但实际上你还需要考虑它们一起。你应该获取混合匹配所有三个方面的数据，以确保你获得最佳结果。例如，你所有的不同照明场景都应该有各种各样的表情和姿势。只有通过多样化的数据，AI才能学会创建一个真正令人信服的深度伪造。
- en: Having good variety is critical, but how do you actually get the data you need?
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 良好的多样性至关重要，但你怎么能实际获取所需的数据呢？
- en: Sourcing data
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据来源
- en: If you’re working on a deepfake, then you probably already know who you’re going
    to be swapping. Hopefully, you’re lucky and are working on a deepfake that covers
    two people who you have access to so you can film them or gather data from them
    without too much trouble. Unfortunately, not everyone is so lucky, and most of
    the time, one or both of your subjects will be unavailable for custom data (this
    is probably why you’re working on a deepfake in the first place, after all).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在制作深度伪造，那么你可能已经知道你要替换成谁了。希望你是幸运的，正在制作一个可以轻松拍摄或收集数据的深度伪造，涉及两个人，这样你就可以在没有太多麻烦的情况下进行拍摄。不幸的是，并不是每个人都很幸运，大多数时候，你的一个或两个主题可能无法获取定制数据（这也许是你一开始制作深度伪造的原因）。
- en: These two situations require very different approaches to getting data, and
    sometimes, even if you have good access to your subjects, you will need to get
    some of your data from another source.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这两种情况需要非常不同的数据获取方法，有时，即使你能够很好地接触到你的主题，你也可能需要从另一个来源获取一些数据。
- en: Filming your own data
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 拍摄自己的数据
- en: Filming your own sources is a dream position for any deepfaker. The ability
    to build the perfect dataset by putting an actor in front of a camera is liberating,
    but also a wasted opportunity if you don’t know how to capture all that you need.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 拍摄自己的数据源是任何深度伪造者的梦想位置。能够通过将演员置于摄像机前构建完美的数据集是一种解放，但如果你不知道如何捕捉所有需要的内容，这也会是一个浪费的机会。
- en: Author’s note
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 作者注记
- en: This book’s scope is unable to even begin to approach the extensive vocabulary
    and techniques that photography and filming involve. If you’re planning on doing
    much actual filming of your own data, it is highly recommended that you read some
    photography or filmography books, watch some tutorials, and talk to experts in
    that field before you get on set so that you can get the most out of the time.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这本书的范围甚至无法触及摄影和电影所涉及的广泛词汇和技术。如果你计划大量拍摄自己的数据，强烈建议你在上片场之前阅读一些摄影或电影制作书籍，观看一些教程，并与该领域的专家交谈，以便充分利用时间。
- en: Telling the **gaffer** (the person in charge of lighting on a set) to go against
    all their training and deliberately give you bad lighting can be scary if you’re
    not an expert. Telling an actor to make a “sadder” face or to make extreme expressions
    can be equally awkward. When filming for a deepfake, you need to make it clear
    to the crew that you do need their regular skills, but that you also need to go
    beyond the norm into the weird, esoteric, and uncomfortable.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 让**电工**（负责片场照明的负责人）违背他们的所有训练，故意给你提供糟糕的照明，如果你不是专家，可能会感到害怕。告诉演员做出“更悲伤”的表情或做出极端的表情可能会同样尴尬。在拍摄深度伪造时，你需要清楚地告诉剧组，你确实需要他们的常规技能，但你还需要超越常规，进入奇怪、神秘和不舒服的领域。
- en: While you may be tempted to ensure that the data is always done in close with
    the actor’s face filling the frame, don’t be afraid to let the face be smaller
    or farther from the camera; it’s rarely the resolution of the face in the data
    that hurts the results.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然你可能想确保数据总是近距离拍摄，演员的脸填满整个画面，但不要害怕让脸更小或离摄像机更远；通常不是数据中脸部分辨率的问题会损害结果。
- en: You need to consider all aspects of a deepfake when you’re filming. Even when
    filming the video to be swapped, it is important to consider the limitations of
    the deepfake technology. Angled faces, such as profiles, are especially difficult
    to swap without an uncanny effect. Because of this, you will want to minimize
    the number of faces looking far from the axis of the camera. They don’t have to
    be directly facing the camera, especially if you get a lot of angles in the training
    data, but there comes a a point when things things are just too angular for the
    AI to provide a good result.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 当你拍摄深度伪造时，需要考虑所有方面。即使是在拍摄要替换的视频时，也要考虑深度伪造技术的局限性。例如，侧面这样的角度面部在没有产生不自然效果的情况下特别难以替换。正因为如此，你将希望尽量减少远离摄像机轴线面部数量的最大化。它们不必直接面对摄像机，特别是如果你在训练数据中得到很多角度，但总会有一个点，事情变得过于角度化，以至于AI无法提供良好的结果。
- en: One important detail is that your deepfakes will improve with practice as you
    develop your skills. For this reason, it is highly recommended that you not rely
    on your first deepfake to be perfect, and if you have an important project coming
    up that requires deepfakes, you may want to create a couple of practice deepfakes
    first so that you can get the necessary practice with the data to ensure that
    while filming your important deepfake you have the experience necessary to get
    quality data.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 一个重要的细节是，随着你技能的发展，你的深度伪造会随着实践而提高。因此，强烈建议你不要依赖你的第一个深度伪造是完美的，如果你有一个即将到来的重要项目需要深度伪造，你可能想要先创建几个练习深度伪造，这样你就可以在拍摄重要的深度伪造时获得必要的经验，以确保你能够获得高质量的数据。
- en: Getting data from historical sources
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从历史资料中获取数据
- en: Sometimes, you cannot film your subjects – for example, if the actor has passed
    away or you’re deepfaking a younger version of an actor. In these cases, you don’t
    have the luxury of making your own data to meet your situation. That means you
    must rely on older sources for all your training data.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，你无法拍摄你的主题——例如，如果演员已经去世，或者你正在伪造一个年轻版本的演员。在这些情况下，你无法享受制作自己的数据来满足你情况的优势。这意味着你必须依赖更早的资料来获取所有训练数据。
- en: Hopefully, your subject is recent, and videos and photos of them exist. Some
    subjects cannot be deepfaked due to the sheer lack of original content around
    them – Albert Einstein, for example, will never have a traditional deepfake made
    simply because there isn’t the necessary training data. Your best bet at that
    point is to use an impersonator to some degree. This is the technique that the
    Dalí Museum used to bring Dalí back – impersonators and some limited video interviews
    of the artist.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 希望你的主题是最近的，并且有他们的视频和照片。由于周围缺乏原始内容，一些主题无法进行深度伪造——例如，阿尔伯特·爱因斯坦将永远不会制作传统的深度伪造，仅仅是因为没有必要的训练数据。在这种情况下，你最好的选择是使用一定程度的模仿者。这就是达利博物馆用来让达利复活的技术——模仿者和一些有限的艺术家视频访谈。
- en: If you’re lucky enough that data exists for your subject, you can use any data
    available, and you do not need to restrict yourself based on age or resolution
    (see the discussion about the difference between resolution and fidelity in the
    *Why data is important* section). Instead, focus more on getting variety. It can
    be a challenge knowing where to stop but, generally, time spent gathering and
    managing your data is well rewarded. It’s unlikely that time spent on data will
    be wasted in the long run.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你足够幸运，你的主题有数据，你可以使用任何可用的数据，并且你不需要根据年龄或分辨率进行限制（参见*为什么数据很重要*部分关于分辨率和保真度的讨论）。相反，更多地关注获得多样性。知道在哪里停止可能是一个挑战，但通常，花在收集和管理数据上的时间是值得的。从长远来看，花在数据上的时间不太可能浪费。
- en: Movies, interviews, and even random photos of people can be used for deepfake
    training data. You don’t want to rely too much on any one of these, as they are
    all very limited in domain. A horror movie is unlikely to have many smiles and
    random photos that you can find will be unlikely to have anything besides smiles.
    Finding the balance between the different categories in order to find the variety
    necessary to train is one of the skills that you will simply have to learn.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 电影、访谈甚至人们的随机照片都可以用作深度伪造训练数据。你不希望过度依赖其中任何一个，因为它们在领域上都非常有限。恐怖电影不太可能有很多人笑，你找到的随机照片很可能除了微笑之外什么都没有。在寻找不同类别之间的平衡，以便找到训练所需的多样性，是你必须学会的一项技能。
- en: Especially when dealing with historical data, you’ll often find that it is not
    as high-quality as you want, so how can you get the most out of your limited data?
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 尤其是处理历史数据时，你经常会发现它们的质量并不像你希望的那样高，那么你如何从有限的数据中获得最大价值？
- en: Improving your data
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提升你的数据
- en: There are no silver bullets to magically make your data better, but there are
    some ways that you can tweak your data to improve the training of the AI.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 没有银弹可以神奇地让你的数据变得更好，但有一些方法你可以调整你的数据来改善AI的训练。
- en: Linear color
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 线性色彩
- en: When you’re filming you may film in **logarithmic scale** (**log**) color, where
    the scale represents an exponential change. This is great for storing a large
    color range while filming but does not work well for training a deepfake. To get
    the best results from your training, you’ll want to convert your video into a
    **linear** color space (where a change of some number is consistently represented).
    It doesn’t really matter which one, but all your data and converted videos should
    be the same. Since most content is **Rec.709**, we recommend that you use that
    unless you have a good reason to pick a different color space.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 当你拍摄时，你可能会在对数尺度（**log**）色彩下拍摄，其中尺度代表指数变化。这对于在拍摄时存储大量色彩范围非常出色，但并不适合训练深度伪造。为了从你的训练中获得最佳结果，你希望将你的视频转换为**线性**色彩空间（其中某些数字的变化是一致表示的）。这实际上并不重要，但所有你的数据和转换后的视频应该是相同的。由于大多数内容是**Rec.709**，除非你有充分的理由选择不同的色彩空间，否则我们建议你使用它。
- en: Author’s note
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 作者注记
- en: Color science is a very robust field, and a full examination is outside the
    scope of this book. However, a basic understanding can help. **Rec.709** is one
    of many so-called **color spaces**, which are how a computer or TV represents
    colors. There are many different color spaces, including **SRGB** and **Adobe
    RGB** (among others), which can show different colors or represent them in different
    ways. The important thing when it comes to deepfakes is that you must keep all
    your data in the same color space when training and converting.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 色彩科学是一个非常稳健的领域，全面考察超出了本书的范围。然而，基本理解可以帮助。**Rec.709**是许多所谓的**色彩空间**之一，这是计算机或电视表示色彩的方式。有许多不同的色彩空间，包括**SRGB**和**Adobe
    RGB**（以及其他），它们可以显示不同的颜色或以不同的方式表示它们。在深度伪造方面，重要的是在训练和转换时必须保持所有数据在同一个色彩空间。
- en: '**High-dynamic range** (**HDR**) content is also problematic – at least when
    it comes to commercially-released content. Consumer HDR technologies throw out
    a lot of data to fit the color data into the frame. This means that something
    that looks dark in one scene could actually be stored as brighter than something
    that looks bright in another scene. Even when mapped back to a linear range, it
    tends to be highly variable, which causes great difficulty for AI to generalize,
    often leading to the failure of the deepfake model. The best way to deal with
    this is to avoid giving HDR content to the AI model. This can be complicated since
    sometimes the highest quality data you can get is HDR. In that situation, it’s
    useful to know that data of a lower resolution but a consistent color space will
    lead to better results than a higher resolution but inconsistent color.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '**高动态范围**（**HDR**）内容也存在问题——至少在商业发布的内容中是这样。消费者HDR技术为了将颜色数据放入帧中，会丢弃大量数据。这意味着在一个场景中看起来较暗的东西实际上可能存储得比另一个场景中看起来较亮的东西还要亮。即使映射回线性范围，它也往往变化很大，这对AI进行泛化造成了极大的困难，通常会导致深度伪造模型的失败。处理这个问题的最好方法是避免向AI模型提供HDR内容。这可能会很复杂，因为有时你能获得的最高质量数据就是HDR。在这种情况下，了解较低分辨率但颜色空间一致的数据将比高分辨率但颜色不一致的数据产生更好的结果是有用的。'
- en: Professional cameras recording in RAW will not have the same problem as **HDR**
    since they keep the exact data coming from the sensor and the complete color data
    remains available.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 使用RAW格式记录的专业相机不会像**HDR**那样有问题，因为它们保留了来自传感器的确切数据，并且完整的颜色数据仍然可用。
- en: Color science is complicated and sometimes non-intuitive. It’s not necessary
    to become an expert in all the details, but it’s useful to know when the color
    space might be causing a problem.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 颜色科学很复杂，有时也不直观。成为所有细节的专家并不必要，但了解颜色空间可能引起问题时很有用。
- en: Data matching
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据匹配
- en: Sometimes, you’re extremely limited with the data that you have access to for
    one of your subjects. In that case, it can be very hard to get a good swap. One
    way to help get the results you need is to match your data as close as possible
    for at least part of your training. Have the subject that you have access to match
    the data for the other subject as closely as possible. It’s important to match
    the poses, expressions, and lighting all in a single image. This doesn’t have
    to be for your final conversion and shouldn’t be the only data you use, but having
    closely matching data can sometimes help the AI find the details to swap the two.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，你可能会在某个主题上对可访问的数据极为有限。在这种情况下，获得一个好的交换可能非常困难。帮助获得所需结果的一种方法是将你的数据尽可能匹配，至少在训练的部分。确保你能够访问的主题与另一个主题的数据尽可能匹配。在单个图像中匹配姿势、表情和照明非常重要。这不必是最终的转换，也不应该是你使用的唯一数据，但拥有匹配的数据有时可以帮助AI找到交换两个主题的细节。
- en: When doing data matching, you’ll want to train for a very short time on just
    the subset of your data which matches. Both your subject datasets should be cleaned
    to a single short segment and training should be limited to no more than 100 **epochs**
    (an epoch is one full cycle of training the AI model on all the data). Once you’re
    done training with that subset, you’ll want to train with the full data. You may
    want to repeat this process a couple of times with different subsets of your data.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行数据匹配时，你将希望仅对与你的数据匹配的子集进行非常短时间的训练。你的主题数据集都应该被清理到单个短段，训练应限制在不超过100个**周期**（一个周期是AI模型在所有数据上完成一次完整训练）。一旦你用那个子集完成训练，你将希望用完整的数据进行训练。你可能希望用你数据的不同子集重复这个过程几次。
- en: Upscaling
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 放大
- en: One major current trend in AI is in **upscaling** content. This is a great use
    for AI, which can fill in missing data from its training, especially **temporally
    aware upscalers**, which can find missing data by tracking an object across multiple
    frames to get more detail. Unfortunately, when used as training data for generative
    AI such as deepfakes, the AI upscaled data is problematic and prone to training
    failures. Even a very good upscaling AI has glitches and artifacts. The artifacts
    might be difficult for the eye to see, but the deepfake AI searches for patterns
    and will often get tripped up by artifacts, causing the training to fail.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 目前AI的一个主要趋势是在**提升**内容。这是一个AI的绝佳用途，它可以填补其训练中的缺失数据，特别是**时间感知提升器**，可以通过跟踪物体跨越多个帧来找到缺失数据以获得更多细节。不幸的是，当用作生成AI（如deepfakes）的训练数据时，提升的AI数据是有问题的，并且容易导致训练失败。即使是非常好的提升AI也有故障和伪影。这些伪影可能对肉眼难以察觉，但deepfake
    AI会寻找模式，并且经常会被伪影绊倒，导致训练失败。
- en: Generally, the best way to deal with upscaling is to not upscale your training
    data but instead to upscale the output. This is even better in many ways since
    it can replace missing face data and improve the resolution of the output at the
    same time. The reason that chaining AIs in that direction doesn’t cause failures
    is that, unlike deepfakes, upscalers are not trained on the data generated.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，处理提升的最佳方式不是提升训练数据，而是提升输出。这在很多方面都更好，因为它可以同时替换缺失的面部数据并提高输出的分辨率。之所以链式AI不会导致失败，是因为与deepfakes不同，提升器不是在生成数据上训练的。
- en: That said, there are a lot of techniques that are completely safe for upscaling
    your training data. More traditional or temporal solutions that don’t involve
    AI can be used to upscale without leading to failure to train. Upscaling with
    **bicubic** or **Lanczos** filtering is also perfectly acceptable.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，有很多技术可以安全地用于提升您的训练数据。更多传统或时间相关的解决方案，不涉及AI的，也可以用于提升而不会导致训练失败。使用**双三次**或**Lanczos**滤波进行提升也是完全可以接受的。
- en: Cleaning up noise or adjusting colors is also fine and a valid way to maximize
    your data quality, especially if the extract was unable to find faces in some
    of the data.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 清理噪声或调整颜色也是可以的，并且是提高数据质量的有效方式，特别是如果提取程序无法在部分数据中找到面部时。
- en: Summary
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Data is critical for deepfakes, as with all AI. Getting the best data is a skill
    that you have to learn over time. It’s something that you will get better at as
    you become more experienced with deepfakes. That being said, some tasks can be
    learned without heavy investment in the process. Cleaning and organizing your
    data is important – time spent on this can save you time later since your AIs
    will be less likely to fail.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 数据对于deepfakes至关重要，就像所有AI一样。获取最佳数据是一项你必须随着时间的推移来学习的技能。随着你对deepfakes越来越有经验，你将在这方面做得越来越好。尽管如此，一些任务可以在不大量投资于过程的情况下学习。清理和组织你的数据很重要——花在这上面的时间可以节省你以后的时间，因为你的AI不太可能失败。
- en: Filming your own data is sometimes necessary and can get you the best results,
    as this will give you enough control to fill in missing data or match limited
    historical data. When you have nothing but historical data, you’re more limited
    and may need to do further work to improve the data you have. Upscaling and filtering
    are possible, but you must be careful, as some techniques can add artifacts that
    interfere with training.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 录制自己的数据有时是必要的，并且可以给你带来最佳结果，因为这将给你足够的控制来填补缺失的数据或匹配有限的历史数据。当你只有历史数据时，你的选择更有限，可能需要进一步工作来改进你拥有的数据。提升和滤波是可能的，但你必须小心，因为一些技术可能会添加干扰训练的伪影。
- en: In the end, data is the most important part of training a deepfake and therefore
    is the most important job of a deepfaker. You must spend time and effort learning
    the skill of data management if you are going to excel at creating deepfakes.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，数据是训练deepfake最重要的部分，因此也是deepfaker最重要的工作。如果你想在创建deepfakes方面表现出色，你必须花时间和精力学习数据管理的技能。
- en: In the next chapter, we will be walking you through using Faceswap – a freely
    available open source deepfake software – so that you can generate your own deepfakes.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将向您介绍如何使用Faceswap – 一款免费开源的deepfake软件 – 以便您可以生成自己的deepfakes。
- en: EBSCOhost - printed on 11/27/2023 6:20 AM via . All use subject to [https://www.ebsco.com/terms-of-use](https://www.ebsco.com/terms-of-use)
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: EBSCOhost - 2023年11月27日 6:20 AM 打印。所有使用均受[https://www.ebsco.com/terms-of-use](https://www.ebsco.com/terms-of-use)条款约束。
