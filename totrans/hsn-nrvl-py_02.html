<html><head></head><body>
        

                            
                    <h1 class="header-title">Overview of Neuroevolution Methods</h1>
                
            
            
                
<p class="p1">The concept of <strong>artificial neural networks</strong> (<strong>ANN</strong>) was inspired by the structure of the human brain. There was a strong belief that, if we were able to imitate this intricate structure in a very similar way, we would be able to create artificial intelligence. We are still on the road to achieving this. Although we can implement Narrow AI agents, we are still far from creating a Generic AI agent.</p>
<p class="p1">This chapter introduces you to the concept of ANNs and the two methods that we can use to train them (the gradient descent with error backpropagation and neuroevolution) so that they learn how to approximate the objective function. However, we will mainly focus on discussing the neuroevolution-based family of algorithms. You will learn about the implementation of the evolutionary process that's inspired by natural evolution and become familiar with the most popular neuroevolution algorithms: NEAT, HyperNEAT, and ES-HyperNEAT. We will also discuss the methods of optimization that we can use to search for final solutions and make a comparison between objective-based search and Novelty Search algorithms. By the end of this chapter, you will have a complete understanding of the internals of neuroevolution algorithms and be ready to apply this knowledge in practice.</p>
<p class="p1">In this chapter, we will cover the following topics:</p>
<ul class="ul1">
<li class="li1">Evolutionary algorithms and neuroevolution-based methods</li>
<li class="li1">NEAT algorithm overview</li>
<li class="li1">Hypercube-based NEAT</li>
<li class="li1">Evolvable-Substrate HyperNEAT</li>
<li class="li1">Novelty Search optimization method</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Evolutionary algorithms and neuroevolution-based methods</h1>
                
            
            
                
<p>The term artificial neural networks stands for a graph of nodes connected by links where each of the links has a particular weight. The neural node defines a kind of threshold operator that allows the signal to pass only after a specific activation function has been applied. It remotely resembles the way in which neurons in the brain are organized. Typically, the ANN training process consists of selecting the appropriate weight values for all the links within the network. Thus, ANN can approximate any function and can be considered as a universal approximator, which is established by the Universal Approximation Theorem.</p>
<p>For more information on the proof of the Universal Approximation Theorem, take a look at the following papers:</p>
<ul>
<li>Cybenko, G. (1989)<em> Approximations by Superpositions of Sigmoidal Functions,</em> Mathematics of Control, Signals, and Systems, 2(4), 303–314. </li>
<li>Leshno, Moshe; Lin, Vladimir Ya.; Pinkus, Allan; Schocken, Shimon (January 1993). <em>Multilayer feedforward networks with a nonpolynomial activation function can approximate any function</em>. Neural Networks. 6 (6): 861–867. doi:10.1016/S0893-6080(05)80131-5. (<a href="https://www.sciencedirect.com/science/article/abs/pii/S0893608005801315?via%3Dihub">https://www.sciencedirect.com/science/article/abs/pii/S0893608005801315?via%3Dihub</a>)</li>
<li>Kurt Hornik (1991) <em>Approximation Capabilities of Multilayer Feedforward Networks</em>, Neural Networks, 4(2), 251–257. doi:10.1016/0893-6080(91)90009-T (<a href="https://www.sciencedirect.com/science/article/abs/pii/089360809190009T?via%3Dihub">https://www.sciencedirect.com/science/article/abs/pii/089360809190009T?via%3Dihub</a>)</li>
<li>Hanin, B. (2018). <em>Approximating Continuous Functions by ReLU Nets of Minimal Width</em>. arXiv preprint arXiv:1710.11278. (<a href="https://arxiv.org/abs/1710.11278">https://arxiv.org/abs/1710.11278</a>)</li>
</ul>
<p>Over the past 70 years, many ANN training methods have been proposed. However, the most popular technique that gained fame in this decade was proposed by Jeffrey Hinton. It is based on the backpropagation of prediction error through the network, with various optimization techniques built around the gradient descent of the loss function with respect to connection weights between the network nodes. It demonstrates the outstanding performance of training deep neural networks for tasks related mainly to pattern recognition. However, despite its inherent powers, it has significant drawbacks. One of these drawbacks is that a vast amount of training samples are required to learn something useful from a specific dataset. Another significant disadvantage is the fixed network architecture that's created manually by the experimenter, which results in inefficient use of computational resources. This is due to a significant amount of network nodes not participating in the inference process. Also, backpropagation-based methods have problems with transferring the acquired knowledge to other similar domains.</p>
<p>Alongside backpropagation methods, there are very promising evolutionary algorithms that can address the aforementioned problems. These bio-inspired techniques draw inspiration from Darwin's theory of evolution and use natural evolution abstractions to create artificial neural networks. The basic idea behind neuroevolution is to produce the ANNs by using stochastic, population-based search methods. It is possible to evolve optimal architectures of neural networks, which accurately address the specific tasks using the evolutionary process. As a result, compact and energy-efficient networks with moderate computing power requirements can be created. The evolutionary process is executed by applying genetic operators (<em>mutation</em>, <em>crossover</em>) to the population of chromosomes (genetically encoded representations of ANNs/solutions) over many generations. The central belief is that since this is in biological systems, subsequent generations will be suited to withstand the generational pressure that's expressed by the objective function, that is, they will become better approximators of the objective function.</p>
<p>Next, we will discuss the basic concepts of genetic algorithms. You will need to have a moderate level of understanding of genetic algorithms.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Genetic operators</h1>
                
            
            
                
<p>Genetic operators are at the very heart of every evolutionary algorithm, and the performance of any neuroevolutionary algorithm depends on them. There are two major genetic operators: mutation and crossover (recombination).</p>
<p>In this chapter, you will learn about the basics of genetic algorithms and how they differ from conventional algorithms, which use error backpropagation-based methods for training the ANN.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Mutation operator</h1>
                
            
            
                
<p>The <em>mutation</em> operator serves the essential role of preserving the genetic diversity of the population during evolution and prevents stalling in the local minima when the chromosomes of organisms in a population become too similar. This mutation alters one or more genes in the chromosome, according to the mutation probability defined by the experimenter. By introducing random changes to the solver's chromosome, mutation allows the evolutionary process to explore new areas in the search space of possible solutions and find better and better solutions over generations.</p>
<p>The following diagram shows the common types of mutation operators:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-737 image-border" src="img/1a5c1fb7-54b2-4d24-8878-807d27020f44.png" style="width:20.92em;height:18.75em;"/></p>
<p>Types of mutation operators</p>
<p>The exact type of mutation operator depends on the kind of genetic encoding that's used by a specific genetic algorithm. Among the various mutation types we come across, we can distinguish the following:</p>
<ul>
<li><strong>Bit inversion</strong>: The randomly selected bit, which is inverted (<em>binary encoding</em>).</li>
<li><strong>Order change</strong>: Two genes are randomly selected and their position is flipped in the genome (<em>permutation encoding</em>).</li>
<li><strong>Value change</strong>: A small value is added to the expressed gene at a random position (<em>value encoding</em>).</li>
<li><strong>Gene expression change</strong>: A random gene is selected and added/removed from the genotype (<em>structural encoding</em>).</li>
</ul>
<p>Genotypes can be encoded using genetic encoding schemes with fixed and variable chromosomal lengths. The first three mutations can be applied to both types of encoding schemes. The last mutation can only be expressed in genotypes that have been encoded using a variable-length encoding.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Crossover operator</h1>
                
            
            
                
<p>The <em>crossover</em> (recombination) operator allows us to stochastically generate new generations (solutions) from existing populations by recombining genetic information from two parents to generate offspring. Thus, the portions of good solutions from parent organisms can be combined and can potentially lead to better offspring. Typically, after a crossover, the produced offspring are mutated before being added to the population of the next generation.</p>
<p>The following diagram shows the various crossover operators:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-738 image-border" src="img/d7d251a0-ed00-4a83-b961-b912bb4b40c7.png" style="width:23.25em;height:19.83em;"/></p>
<p>Types of crossover operators</p>
<p>The different types of crossover operators also depend on the genetic encoding that's used by particular algorithms, but the following are the most common:</p>
<ul>
<li><strong>Single-point crossover</strong>: The random crossover point is selected, the genome part from the beginning to the crossover point is copied to the offspring from one parent, and the rest are copied from another parent.</li>
<li><strong>Two-point crossover</strong>: The two crossover points are chosen randomly, the part of the genome from the beginning to the first point is copied from the first parent, the part between the first and second crossover point is copied from the second parent, and the rest are copied from the first parent.</li>
<li><strong>Uniform crossover</strong>: The genes are copied from the first or second parent randomly.</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Genome encoding schemes</h1>
                
            
            
                
<p>One of the most crucial choices when designing the neuroevolution algorithm is to determine the genetic representation of the neural network, which can be evolved in the following ways</p>
<ul>
<li>Standard mutation (see the preceding <em>Mutation operator</em> subsection)</li>
<li>Combination operators (see the preceding <em>Crossover operator</em> subsection)</li>
</ul>
<p>At the moment, two major schemes for genome encoding exist: direct and indirect. Let's consider each schema in more detail.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Direct genome encoding</h1>
                
            
            
                
<p>Direct genome encoding attempts were used in neuroevolution methods to create ANNs that were related to neural networks with a fixed topology; that is, the network topology was determined solely by the experimenter. Here, genetic encoding (<em>genotype</em>) is implemented as a vector of real numbers, representing the strength (<em>weights</em>) of the connections between the network nodes.</p>
<p>The evolutionary operators modify the values of the weights vector with the mutation operator and combine the vectors of the parent organisms with the recombination (crossover) operator to produce offspring. While allowing evolutionary operators to be applied with ease, the described encoding method has some significant drawbacks. One of its main drawbacks is that the network topology is determined by the experimenter from the very beginning and fixed through all the generations during the execution of the algorithm. This approach contradicts the natural evolutionary process, in which not only the properties but also the physical structure of the organisms change during the evolutionary process. This allows us to explore the broadest possible search space and find optimal solutions.</p>
<p>The following diagram shows the evolutionary process:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-739 image-border" src="img/6a987ef3-6b60-49af-9a0b-38ce6b5b1eda.png" style="width:15.50em;height:11.42em;"/></p>
<p>The evolutionary process</p>
<p>To address the drawbacks of the fixed topology methods, Kenneth O. Stanley proposed the <strong>NeuroEvolution of Augmenting Topologies</strong> (<strong>NEAT</strong>) method. The primary idea behind this algorithm is that the evolutionary operators are applied not only to the vector with the weights of all the connections but also to the topology of the created neural network. Thus, through generating the populations of the organisms, various topologies with a variety of connection weights are tested. We will discuss the particulars of the NEAT algorithm later in this chapter.</p>
<p>The NEAT algorithm demonstrates outstanding performance in a variety of tasks – from traditional reinforcement learning to the control of sophisticated non-player characters in computer games – and has become one of the most popular neuroevolution algorithms ever. However, it belongs to the family of direct encoding algorithms, which limits its use to evolving only modest-sized ANNs, where parameter space is limited to a maximum of thousands of connections. This is because each connection is directly encoded in the genotype, and with a large number of encoded connections, the computational requirements increase significantly. This makes it impossible to use the algorithm to evolve large neural networks.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Indirect genome encoding</h1>
                
            
            
                
<p>To overcome size issues with direct encoding, Kenneth O. Stanley proposed an <em>indirect</em> encoding method, which is inspired by how the phenotype is encoded by the genome in the DNA. It is based on the fact that the physical world is built around geometry and regularities (structural patterns), where natural symmetries are found everywhere. Thus, the encoding size of any physical process can be significantly reduced through the reuse of a specific set of encoding blocks for the same structure that repeats many times. The proposed method, called <strong>Hypercube-based NeuroEvolution of Augmenting Topologies</strong> (<strong>HyperNEAT</strong>), is designed to build large-scale neural networks by exploiting geometrical regularities. HyperNEAT employs a connective <strong>Compositional Pattern Producing Network</strong> (<strong>CPPN</strong>) to represent node connections as a function of Cartesian space. We will discuss HyperNEAT in more detail later in this chapter.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Coevolution</h1>
                
            
            
                
<p>In nature, populations of different species often simultaneously evolve in mutual interaction with each other. This type of inter-species relationship is called <strong>coevolution</strong>. Coevolution is a powerful tool of natural evolution, and it is no surprise that it attracted the attention of the neuroevolution community. There are three main types of coevolution: </p>
<ul>
<li><strong>Mutualism</strong>, which is when two or more species coexist and mutually benefit from each other.</li>
<li><strong>Competitive coevolution</strong>:
<ul>
<li><strong>Predation</strong>, which is when one organism kills another and consumes its resources.</li>
<li><strong>Parasitism</strong>, which is when one organism exploits the resources of another but does not kill it.</li>
</ul>
</li>
<li><strong>Commensalism</strong>, which is when the members of one species gain benefits without causing harm or gaining benefits from other species.</li>
</ul>
<p>The preceding coevolution strategies were explored by researchers and their pros and cons were revealed. In this book, we will introduce a neuroevolution algorithm that employs the commensalistic principle to maintain two coevolving populations: the population of candidate solutions and the population of candidate objective functions. We will discuss the <strong>Solution and Fitness Evolution</strong> (<strong>SAFE</strong>) algorithm later in <a href="048be1ce-8b6a-48c7-9d13-cb34c8482eb4.xhtml" target="_blank"/><a href="048be1ce-8b6a-48c7-9d13-cb34c8482eb4.xhtml" target="_blank"/><a href="048be1ce-8b6a-48c7-9d13-cb34c8482eb4.xhtml" target="_blank">Chapter 9</a>, <em>Co-Evolution and the SAFE Method</em>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Modularity and hierarchy</h1>
                
            
            
                
<p>Another crucial aspect of how natural cognitive systems are organized is modularity and hierarchy. While studying the human brain, neuroscientists have found that it is not a monolithic system with a uniform structure, but rather a complex hierarchy of modular structures. Also, due to the speed limitations of signal propagation in the biological tissues, the structure of the brain enforces the principle of locality when related tasks are processed by geometrically adjacent structures in the brain. This aspect of natural systems did not escape the attention of researchers of neuroevolution and they are implemented in many evolutionary algorithms. We will discuss how modular ANNs can be created using a neuroevolution-based algorithm in <a href="9f3dce4d-2cc7-4307-a704-bfcfe4ad56b4.xhtml" target="_blank">Chapter 8</a>, <em>ES-HyperNEAT and the Retina Problems</em>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">NEAT algorithm overview</h1>
                
            
            
                
<p class="p1">The method of NEAT for evolving complex ANNs was designed to reduce the dimensionality of the parameter search space through the gradual elaboration of the ANN's structure during evolution. The evolutionary process starts with a population of small, simple genomes (seeds) and gradually increases their complexity over generations.</p>
<p class="p1">The seed genomes have a very simple topology: only input, output, and bias neurons are expressed. No hidden nodes are introduced into the seed from the beginning to guarantee that the search for a solution starts in the lowest-dimensional parameter space (connection weights) possible. With each new generation, additional genes are introduced, expanding the solution search space by presenting a new dimension that previously did not exist. Thus, evolution begins by searching in a small space that can be easily optimized and adds new dimensions when necessary. With this approach, complex phenotypes (solutions) can be discovered gradually, step by step, which is much more efficient than launching the search directly in the vast space of the final solutions. Natural evolution utilizes a similar strategy by occasionally adding new genes that make phenotypes more complex. In biology, this process of incremental elaboration is called <strong>complexification</strong>.</p>
<p class="p1">The primary goal of the NEAT method is to minimize the complexity of the genome structure – not only the final product, but of all the intermediate generations of the organisms as well. Thus, the evolution of the network topology results in a significant performance advantage by reducing the overall solutions for the search space. For example, the high-dimensional space of the final solution is only encountered at the end of the evolutionary process. Another essential feature of the algorithm is that each structure that's introduced to the genome is the subject of subsequent fitness evaluations in the future generations. Also, only useful structures will survive during the evolutionary process. In other words, the structural complexity of the genome is always goal-justified.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">NEAT encoding scheme</h1>
                
            
            
                
<p class="p1">The genetic encoding scheme of NEAT is designed to allow easy matching between corresponding genes during the mating process when a crossover operator is applied to the two parent genomes. The NEAT genome is a linear representation of the connectivity pattern of the encoded neural network, as shown in the following NEAT genome scheme:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-740 image-border" src="img/79b7b32f-0c4e-4871-9773-006c9c4ff857.png" style="width:34.25em;height:25.75em;"/></p>
<p>The NEAT genome scheme</p>
<p class="p1">Each genome is represented as a list of connection genes that encode connections between the nodes of the neural network. Also, there are node genes that encode information about network nodes, such as the node identifier, node type, and type of activation function. The connection gene encodes the following connection parameters of the network link:</p>
<ul class="ul1">
<li class="li1">The identifier of the input network node</li>
<li class="li1">The identifier of the output network node</li>
<li class="li1">The strength (weight) of the connection</li>
<li class="li1">A bit, which indicates whether the connection is enabled (expressed) or not</li>
<li class="li1">An innovation number, which allows matching genes during recombination</li>
</ul>
<p>The bottom part of the preceding diagram represents a scheme of the same genome in the form of a directed graph.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Structural mutations</h1>
                
            
            
                
<p class="p1">The mutation operator that's specific to NEAT can change a connection's strength (weight) and the network's structure. There are two main types of structural mutations:</p>
<ul class="ul1">
<li class="li1">Adding a new connection between nodes</li>
<li class="li1">Adding a new node to the network</li>
</ul>
<p class="p1">The following diagram shows the structural mutations of the NEAT algorithm:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-741 image-border" src="img/0db168be-5731-4f21-804b-b16860e4f654.png" style="width:36.08em;height:30.17em;"/></p>
<p>The structural mutations of the NEAT algorithm</p>
<p>When the mutation operator is applied to the NEAT genome, the newly added gene (connection gene or node gene) is assigned with an increasingly incremented innovation number. During the evolutionary process, the genomes of organisms within the population gradually get larger and genomes of varying sizes are produced. This process results in different connection genes being in the same positions within a genome, making the matching process between same-origin genes extremely complicated.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Crossover with an innovation number</h1>
                
            
            
                
<p class="p1">There is a piece of unexploited information in the evolutionary process that tells us exactly which genes to match between the genomes of any organism in the topologically diverse population. This is where each gene tells us which ancestor that gene was derived from. The connection genes with the same historical origin represent the same structure, despite possibly having different connection weight values. The historical origins of genes in the NEAT algorithm are represented by incrementally assigned innovation numbers, which allow us to track the chronology of structural mutations.</p>
<p class="p1">At the same time, during the crossover, the offspring inherit the innovation numbers of genes from parent genomes. Thus, the innovation number of specific genes never change, allowing similar genes from different genomes to be matched during the crossover. The innovation numbers of matched genes are the same. If the innovation numbers do not match, the gene belongs to the <em>disjoint</em> or <em>excess</em> part of the genome, depending on whether its innovation number lies inside of, or outside of, the range of other parent innovation numbers. The disjoint or excess genes represent structures that are not present in the genome of the other parent and require special handling during the crossover phase. Thus, the offspring inherits genes that have the same innovation number. These are randomly chosen from one of the parents. The offspring always inherit the disjoint or excess genes from the parent with the highest fitness. This feature allows a NEAT algorithm to efficiently perform gene recombination using linear genome encoding, without the need for complex topological analysis.</p>
<p class="p1">The following diagram shows the crossover (recombination) in the NEAT algorithm:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-742 image-border" src="img/3e0a3210-228f-46c1-a3f7-3d4baeff1635.png" style="width:37.42em;height:33.67em;"/></p>
<p>Crossover (recombination) in the NEAT algorithm</p>
<p>The preceding diagram shows an example of a crossover between two parents using the NEAT algorithm. The genomes of both parents are aligned using the innovation numbers (the number at the top of the connection gene cell). After that, the offspring is produced by randomly choosing connection genes from either of parents when the innovation numbers are the same: the genes with innovation numbers from one to five. Finally, the disjoint and excess genes are added from either of the parents unconditionally and ordered by innovation number.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Speciation</h1>
                
            
            
                
<p class="p1">In the evolutionary process, organisms can create diverse topologies through generations, but they fail to produce and maintain topological innovations of their own. The smaller network structures optimize faster than larger ones, which artificially reduces the chances of survival of a descendant genome after adding a new node or connection to it. Thus, the freshly augmented topologies experience negative evolutionary pressure due to the temporary decrease of fitness of the organisms within the population. At the same time, novel topologies can introduce innovations that lead to a winning solution in the long run. To address the temporal drop of fitness, the concept of speciation was introduced in the NEAT algorithm. The speciation limits the range of organisms that can mate by introducing narrow niches where only organisms that belong to the same niche compete with each other during the crossover, instead of competing with all the organisms in the population. Speciation is implemented by dividing the population so that organisms with a similar topology belong to the same species.</p>
<p>Let's refer to the following speciation algorithm:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-743 image-border" src="img/d5150acd-027d-4972-b813-c4137022868f.png" style="width:37.92em;height:19.50em;"/></p>
<p>The speciation algorithm</p>
<p class="p1">The NEAT method permits the creation of complex ANNs that are capable of solving a variety of control optimization problems, as well as other unsupervised learning problems. Due to the introduced specifics of ANN topology augmentation through complexification and speciation, the solutions tend to optimize the performance of training and inference. The resulting ANN topology grows to match the problem that needs to be solved, without any excess layers of hidden units being introduced by the conventional methods of ANN's topology design for backpropagation-based training.</p>
<p>More details about the NEAT algorithm can be found in the original paper: <a href="http://nn.cs.utexas.edu/downloads/papers/stanley.phd04.pdf">http://nn.cs.utexas.edu/downloads/papers/stanley.phd04.pdf</a>.<a href="http://nn.cs.utexas.edu/downloads/papers/stanley.phd04.pdf"/></p>


            

            
        
    

        

                            
                    <h1 class="header-title">Hypercube-based NEAT</h1>
                
            
            
                
<p>Intelligence is a product of the brain, and the human brain as a structure is itself a product of natural evolution. Such an intricate structure has evolved over millions of years, under pressure from harsh environments, and while competing with other living beings for survival. As a result, an extremely complex structure has evolved, with many layers, modules, and trillions of connections between neurons. The structure of the human brain is our guiding star and is aiding our efforts in creating artificial intelligence systems. However, how can we address all the complexity of the human brain with our imperfect instruments?</p>
<p>By studying the human brain, neuroscientists have found that its spatial structure plays an essential role in all perceiving and cognitive tasks – from vision to abstract thinking. Many intricate geometric structures have been found, such as the grid cells that help us with inertial navigation, and the cortical columns that are connected to the eye's retina to process visual stimuli. It has been demonstrated that the structure of the brain allows us to effectively respond to the patterns in signals that are received from the sensorium by using designated neural structures that are activated by specific patterns in the inputs. This feature of the brain allows it to use an extremely efficient way of representing and processing the entire diversity of the input data that's obtained from the environment. Our brains have evolved to be effective pattern recognition and pattern processing engines that actively reuse specific neural modules to process particular patterns, thus dramatically reducing the number of different neural structures required. This only became possible due to the complex modular hierarchy and the spatial integration of its various parts.</p>
<p>As we mentioned previously, the biological brain incorporates complex hierarchical and spatially-aware data processing routines. This has inspired the researchers of neuroevolution to introduce similar data processing methods in the field of artificial neural networks. When designing such systems, it is necessary to address the following problems:</p>
<ul>
<li>The vast number of input features and training parameters that require large-scale ANNs</li>
<li>The effective representation of natural geometrical regularities and symmetries that are observed in the physical world</li>
<li>The effective processing of input data through the introduction of the locality principle, that is, when spatially/semantically adjacent data structures are processed by the modules of interconnected neural units, which occupy the same compact area of the entire network structure</li>
</ul>
<p>In this section, you learned about the<strong> Hypercube-based NeuroEvolution of Augmenting Topologies</strong> (<strong>HyperNEAT</strong>) method, which was proposed by Kenneth O. Stanley to solve various problems by exploiting geometrical regularities. In the next section, we will look at <strong>Compositional Pattern Producing Networks</strong> (<strong>CPPNs</strong>).</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Compositional Pattern Producing Networks</h1>
                
            
            
                
<p>HyperNEAT extends the original NEAT algorithm by introducing a new type of indirect genome encoding scheme called CPPNs. This type of encoding makes it possible to represent the connectivity patterns of a phenotype's ANN as a function of its geometry.</p>
<p>HyperNEAT stores the connectivity pattern of the phenotype neural network as a four-dimensional hypercube, where each point encodes the connection between two nodes (that is, the coordinates of the source and target neurons) and the connective CPPN paints various patterns within it. In other words, CPPN computes the four-dimensional function, which is defined as follows: </p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/0bff394f-591a-4f1f-a0ee-5ad0267c4329.png" style="width:15.67em;height:1.67em;"/></p>
<p>Here, the source node is at (<em>x<sub>1</sub></em>, <em>y<sub>1</sub></em>) and the target node is at (<em>x<sub>2</sub></em>, <em>y<sub>2</sub></em>). At this stage, CPPN returns a weight for every connection between every node in the phenotype network, which is represented as a grid. By convention, the connection between the two nodes is not expressed if the magnitude of the connection weight that's computed by CPPN is less than a minimum threshold (<em>w<sub>min</sub></em>). That way, the connectivity pattern that's produced by CPPN can represent any network topology. The connectivity pattern can be used to encode large-scale ANNs by discovering regularities in the training data and can reuse the same set of genes to encode repetitions. By convention, the connectivity pattern that's produced by CPPN is called the <strong>substrate</strong>.</p>
<p>The following diagram shows the interpretation of the Hypercube-based Geometric Connectivity Pattern:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-744 image-border" src="img/4823fb2d-40e2-4eb0-b06b-a49250416730.png" style="width:37.58em;height:18.33em;"/></p>
<p>Hypercube-based Geometric Connectivity Pattern interpretation</p>
<p>Unlike traditional ANN architectures, CPPN employs a set of various activation functions for its hidden nodes to explore a variety of geometrical regularities. For example, the trigonometric sine can be used to represent repetitions, while Gaussian can be used to enforce locality at a specific part of the network (that is, symmetry along the coordinate axis). Thus, the CPPN encoding scheme can represent patterns with different geometrical regularities such as symmetry, repetition, repetition with regularities, and so on in a compact manner.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Substrate configuration</h1>
                
            
            
                
<p>The layout of the network nodes in the substrate that CPPN connects to can take various forms, which are best suited to different kinds of problems. It is the responsibility of the experimenter to select the appropriate layout to achieve optimal performance. For example, the output nodes that control a radial entity such as a six-leg crawler may be best laid out with radial geometry so that a connectivity pattern can be expressed with polar coordinates.</p>
<p>The following diagram shows some examples of substrate layout configurations:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-745 image-border" src="img/bd6be905-d416-463e-98b2-9f26beb88416.png" style="width:35.17em;height:11.58em;"/></p>
<p>Examples of substrate layout configurations</p>
<p>There are several common types of substrate layout that are typically used with HyperNEAT (see the preceding diagram), some of which are as follows:</p>
<ul>
<li><strong>Two-dimensional grid</strong>: A regular grid of network nodes in a two-dimensional Cartesian space centered at (0, 0)</li>
<li><strong>Three-dimensional grid</strong>: A regular grid of network nodes in a three-dimensional Cartesian space centered at (0, 0, 0)</li>
<li><strong>State-Space Sandwich</strong>: Two 2D planar grids with source and target nodes in which one layer can send connections in the direction of the other one</li>
<li><strong>Circular</strong>: The regular radial structure, which is suited to define regularities in radial geometry-based polar coordinates</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Evolving connective CPPNs and the HyperNEAT algorithm</h1>
                
            
            
                
<p>The method is called <strong>HyperNEAT</strong> because it uses a modified NEAT to evolve CPPNs that represent spatial patterns in the hyperspace. Each expressed point of the pattern, which is bounded by a hypercube, represents a connection between two nodes in the lower-dimensional graph (substrate). Thus, the dimensionality of the hyperspace is twice as big as the dimensionality of the underlying lower-dimensional graph. Later in <a href="9f3dce4d-2cc7-4307-a704-bfcfe4ad56b4.xhtml" target="_blank">Chapter 8</a>, <em>ES-HyperNEAT and the Retina Problem</em>, we will look at some examples that use two-dimensional connectivity patterns.</p>
<p>The HyperNEAT algorithm can be seen in the following diagram:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-746 image-border" src="img/35641a49-7e0d-4127-999d-623852a4f8e8.png" style="width:44.92em;height:20.33em;"/></p>
<p>The general form of the HyperNEAT algorithm</p>
<p>Any connection gene or node gene that's added to the connective CPPN during its evolution leads to the discovery of a new global dimension of variation in the connectivity patterns across the phenotype substrate (novel traits). Each modification that's made to the CPPN genome represents a new way that an entire connectivity pattern can vary. Also, previously evolved connective CPPNs can be queried to produce connectivity patterns for the substrate at a higher resolution than what was used for its training. This allows us to produce a working solution to the same problem at any resolution, potentially without an upper limit. Thus, the aforementioned properties have made HyperNEAT a powerful instrument in evolving large-scale bio-inspired artificial neural networks.</p>
<p>For more information on the HyperNEAT method, you can refer to the following link: <a href="https://eplex.cs.ucf.edu/papers/stanley_alife09.pdf">https://eplex.cs.ucf.edu/papers/stanley_alife09.pdf</a>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Evolvable-Substrate HyperNEAT</h1>
                
            
            
                
<p>The HyperNEAT method exposes the fact that geometrical regularities of the natural world can be adequately represented by artificial neural networks with nodes placed at specific spatial locations. That way, the neuroevolution gains significant benefits and it allows large-scale ANNs to be trained for high dimensional problems, which was impossible with the ordinary NEAT algorithm. At the same time, the HyperNEAT approach is inspired by the structure of a natural brain, which still lacks the plasticity of the natural evolution process. While allowing the evolutionary process to elaborate on a variety of connectivity patterns between network nodes, the HyperNEAT approach exposes a hard limitation on where the network nodes are placed. The experimenter must define the layout of the network nodes from the very beginning, and any incorrect assumption that's made by the researcher will lower the performance of the evolutionary process.</p>
<p>By placing the network node at a specific location in the substrate, the experimenter creates an unintentional constraint on the pattern of weights that are produced by the CPPN. This restriction then interferes with the CPPN when it attempts to encode the geometrical regularities of the natural world into the topography of solution-producing ANN (phenotype). Here, the connectivity pattern produced by CPPN must perfectly align with the layout of the substrate that is defined by the experimenter; connections only are possible between given network nodes. Such limitation leads to unnecessary approximation errors, which spoil the outcome. It may be more effective for the CPPN to elaborate connectivity patterns over nodes that have been placed at slightly different locations.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Information patterns in the hypercube</h1>
                
            
            
                
<p>Why should such limitations on the location of nodes be imposed in the first place? Wouldn't it be nice if the implicit clues that had been drawn from the connectivity patterns became the guidelines of where to place the next node to represent the natural regularities of the physical world better? </p>
<p class="p1">The areas with uniform connection weights encode a small amount of information and hence have little functional value. At the same time, the areas with vast gradients of weight values are extremely information-intensive. Such areas can benefit from additional network nodes being placed to represent a much finer encoding of the natural process. As you may recall from our discussion of the HyperNEAT algorithm, it is possible to represent the connection between two nodes in the substrate as a point in a four-dimensional hypercube. Thus, the main feature of the proposed ES-HyperNEAT algorithm is to express more hyper-points in the areas of the hypercube, where the high variation of connection weights are detected. At the same time, the fewer hyper-points are placed in the areas with a lower variation of connection weights.</p>
<p class="p1">The placement of nodes and the exposed connections between them can be dictated by the variation in the weights of connections that are produced by the evolving CPPN for a given region of a substrate. In other words, there is no need for additional information to decide on the next node placement in the substrate, other than what we are already receiving from the CPPN that encodes the connectivity patterns of the network. Information density becomes the main guiding principle for the algorithm to determine the topography of the substrate.</p>
<p class="p1">Node placement in the phenotype ANN signifies where the information is encoded in the connectivity patterns that are created by the CPPN.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Quadtree as an effective information extractor</h1>
                
            
            
                
<p>To represent hyper-points that are encoding connection weights within the hypercube, the ES-HyperNEAT algorithm employs a <em>quadtree</em>. A quadtree is a tree data structure in which each internal node has exactly four children nodes. This data structure was selected due to its inherent properties, allowing it to represent two-dimensional areas at different levels of granularity. With a quadtree, it is possible to organize an effective search through the two-dimensional space by splitting any area of interest into four subareas, and each of them becomes a leaf of the tree, with root (parent) node representing the original (decomposed) region.</p>
<p>Using the quadtree-based information extraction method, the ES-HyperNEAT approach iteratively looks for new connections between nodes in the two-dimensional space of the substrate ANN, starting from the input and output nodes that have been predefined by the experimenter. This method is much more computationally effective than searching directly in the four-dimensional hypercube space. </p>
<p>The following diagram shows an example of extracting information using quadtree data structures:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-747 image-border" src="img/6f64241b-221e-403a-806a-41c94354d8af.png" style="width:33.67em;height:43.67em;"/></p>
<p>Quadtree information extraction example</p>
<p>The quadtree-based search algorithm operates in two main stages:</p>
<ol>
<li><strong>Division and initialization</strong>: At this stage, the quadtree is created by recursively subdividing the initial substrate space occupying the area from (-1, -1) to (1, 1). The subdivision stops when the desired tree depth is reached. This implicitly determines how many subspaces fit into the initial space of the substrate (initialization resolution). After that, for every quadtree node with the center at <img class="fm-editor-equation" src="img/81ca5f1c-7d61-4d46-9d54-0f9a1671bf80.png" style="width:2.50em;height:1.33em;"/>, the CPPN is queried with <img class="fm-editor-equation" src="img/b192864b-1e82-4114-8c13-2d7cd7fe6310.png" style="width:5.75em;height:1.42em;"/> arguments to find connection weights. When connection weights for <img class="fm-editor-equation" src="img/eb93f7bf-1498-4e2d-8d1a-b63f2b397304.png" style="width:0.58em;height:1.00em;"/> leaf nodes of a particular quadtree node <img class="fm-editor-equation" src="img/70e29e27-edfd-4fca-b88f-a0a9e0012f3f.png" style="width:0.67em;height:1.00em;"/> are found, the variance of this node can be calculated by the following formula:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/a4e2dc7c-beee-49c5-af45-0886c166b8f3.png" style="width:11.33em;height:4.33em;"/></p>
<p style="padding-left: 60px">Here <img class="fm-editor-equation" src="img/06860371-dbc5-4efc-9a50-b958b744c471.png" style="width:1.00em;height:1.08em;"/> is the mean connection weight among <img class="fm-editor-equation" src="img/531eab51-4128-4d34-a8ac-d128a4699802.png" style="width:0.67em;height:1.08em;"/> leaf nodes and <img class="fm-editor-equation" src="img/ddba058a-ccaa-4c47-adbd-25886edeb8ae.png" style="width:1.50em;height:1.17em;"/> is a connection weight to a specific leaf node. The calculated variance value is a heuristic indicator of the presence of information in the specific substrate area. If this value is higher than the particular division threshold (defining desired information density), then the division stage can be repeated for the corresponding square of the substrate. This way, the desired information density can be enforced by the algorithm. Take a look at the top part of the preceding diagram for a visual insight into how division and initialization are done using the quadtree data structures.<br/></p>
<ol start="2">
<li><strong>Pruning and extraction</strong>: To guarantee that more connections (and nodes in the substrate) become expressed in the regions with high information density (high weights variance), the pruning and extraction procedure is executed over the quadtree that was generated during the previous stage. The quadtree traverses depth-first until the variance of the current node is smaller than a variance threshold <img class="fm-editor-equation" src="img/9213a181-6ab8-46bf-9a55-4d1be8b0ba88.png" style="width:1.25em;height:1.50em;"/> or until the node has no children (the zero variance). For every qualified node, the connection is expressed between its center <img class="fm-editor-equation" src="img/7d06e8bd-2222-4af3-ab99-45da675f2121.png" style="width:2.75em;height:1.42em;"/> and each parent node is already defined, either by the experimenter or found at the previous run of these two stages (that is, from hidden nodes that have already been created by ES-HyperNEAT method). Refer to the bottom part of the preceding diagram for a visual insight into how the pruning and extraction phase works.</li>
</ol>


            

            
        
    

        

                            
                    <h1 class="header-title">ES-HyperNEAT algorithm</h1>
                
            
            
                
<p>The ES-HyperNEAT algorithm starts with user-defined input nodes and elaborates on exploring connections from them and sending them to the newly expressed hidden nodes. The expression of outgoing connectivity patterns and hidden nodes placement within the substrate space is done using the quadtree information extraction method, which we described previously. The information extraction process is iteratively applied until the desired level of information expression density is achieved, or until no more information can be discovered in the hypercube. After that, the resulting network is connected to the user-defined output nodes by expressing the incoming connectivity patterns to the outputs. We use quadtree information extraction for this as well. Only those hidden nodes are kept in the final network, which has a path to both the input and output nodes.</p>
<p>Now, we have defined a multitude of nodes and connections within the substrate of the phenotype ANN. It can be beneficial to remove some nodes from the network by introducing an additional band pruning processing stage. At this stage, we keep only the points within a specific band and remove points on the edge of the band. By making bands broader or narrower, the CPPN can manage the density of the encoded information. For more details about band pruning, please refer to the <em>ES-HyperNEAT paper</em> (<a href="https://eplex.cs.ucf.edu/papers/risi_alife12.pdf">https://eplex.cs.ucf.edu/papers/risi_alife12.pdf</a>).</p>
<p>Take a look at the following ES-HyperNEAT algorithm:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-748 image-border" src="img/6f194296-5fae-4524-a44c-4fffe328680e.png" style="width:42.25em;height:49.25em;"/></p>
<p>The ES-HyperNEAT algorithm</p>
<p>The ES-HyperNEAT algorithm takes all the advantages of the NEAT and HyperNEAT methods and introduces even more powerful new features, including the following: </p>
<ul>
<li>Automatic placement of the hidden nodes within the substrate to precisely match the connectivity patterns that are expressed by evolved CPPNs.</li>
<li>Allows us to produce modular phenotype ANNs much more easily due to its inherent capabilities to start the evolutionary search with a bias toward locality (by the specific design of the initial CPPN architectures).</li>
<li>With ES-HyperNEAT, it is possible to elaborate on the existing phenotype ANN structure by increasing the number of nodes and connections in the substrate during evolution. This is the opposite of HyperNEAT, where the number of substrate nodes is predefined.</li>
</ul>
<p>The ES-HyperNEAT algorithm allows us to use the original HyperNEAT architecture without altering the genetic structure of the NEAT part. It allows us to address problems that are hard to solve with the HyperNEAT algorithm due to difficulties with creating an appropriate substrate configuration in advance.</p>
<p>More details about the ES-HyperNEAT algorithm and the motivations behind it can be found at <a href="https://eplex.cs.ucf.edu/papers/risi_alife12.pdf">h</a><a href="https://eplex.cs.ucf.edu/papers/risi_alife12.pdf">ttps://eplex.cs.ucf.edu/papers/risi_alife12.pdf</a>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Novelty Search optimization method</h1>
                
            
            
                
<p class="p1">Most of the machine learning methods, including evolutionary algorithms, base their training on the optimization of the objective function. The main focus underlying the methods of optimization of the objective function is that the best way to improve the performance of a solver is to reward them for getting closer to the goal. In most evolutionary algorithms, the closeness to the goal is measured by the fitness of the solver. The measure of an organism's performance is defined by the fitness function, which is a metaphor for evolutionary pressure on the organism to adapt to its environment. According to that paradigm, the fittest organism is better adapted to its environment and best suited to find a solution.</p>
<div><div><div><p>While direct fitness function optimization methods work well in many simple cases, for more complex tasks, it often falls victim to the local optima trap. Convergence to the local optima means that no local step in the search space provides any improvements during the fitness function optimization process. The traditional genetic algorithms use mutation and island mechanisms to escape from such local optima. However, as we will find out by doing experiments later in this book, it may not always help with deceptive problems, or it can take too long to find a successful solution.</p>
<p class="column">Many real-world problems have such deceptive fitness function landscapes that cannot be solved by an optimization process that is based solely on measuring how close the current solution is to the goal. As an example, we can consider the task of navigating through an unknown city with an irregular street pattern. In such a task, heading toward the destination often means traveling along deceptive roads that move you further away, only to bring you to the destination after several twists. But if you decide to start with roads that have been aligned in direction to the destination, it often leads you to a dead end, while the destination is just behind the wall but unreachable.</p>
</div>
</div>
</div>


            

            
        
    

        

                            
                    <h1 class="header-title">Novelty Search and natural evolution</h1>
                
            
            
                
<p class="p1">By looking at how natural selection works in the physical world, we can see that the enabling force behind evolutionary diversity is a search for novelty. In other words, any evolving species gains immediate evolutionary advantages over its rivals by finding new behavior patterns. This allows them to exploit the environment more efficiently. The natural evolution has no defined goals, and it broadens the solution search space by rewarding the exploration and exploitation of novel behaviors. This novelty can be considered as a proxy for many hidden creative forces in the natural world, which allows evolution to elaborate on even more complex behaviors and biological structures.</p>
<p class="p1">Taking inspiration from the natural evolution, <em>Joel Lehman</em> proposed a new method of search optimization for an artificial evolutionary process called <strong>Novelty Search</strong>. With this method, no particular fitness function is defined or used for solution search; instead, the novelty of each found solution is directly rewarded during the neuroevolution process. Thus, the novelty of the solutions that are found guide the neuroevolution toward the final goal. Such an approach gives us a chance to exploit the creative forces of evolution independent of the adaptive pressure to fit the solution into a particular niche.</p>
<p class="p1">The effectiveness of a Novelty Search can be demonstrated with the <em>maze navigation</em> experiment, where an objective-based search finds the solution for the simple maze in many more steps (generations) than a Novelty Search. Furthermore, for the hard maze with deceptive configuration, the objective-based search fails to find any solution at all. We will discuss maze navigation experiments later in <a href="22365f85-3003-4b67-8e1e-cc89fa5e259b.xhtml" target="_blank">Chapter 5</a>, <em>Autonomous Maze Navigation</em>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Novelty metric</h1>
                
            
            
                
<p class="p1">The Novelty Search method employs a novelty metric for tracking the uniqueness of the behavior of each new individual. That is, the novelty metric is a measure of how far the new organism is from the rest of the population in the behavior space. An effective novelty metric implementation should allow us to compute sparseness at any point of the behavior space. Any area with a denser cluster of visited points is less novel and produces less evolutionary rewards.</p>
<p class="p1">The most straightforward measure of sparseness at a point is an average distance to the k-nearest neighbors of that point in the behavior space. When this distance is high, the point of interest is in the sparse area. At the same time, the denser areas are marked by lower values of distance. Thus, sparseness <img class="fm-editor-equation" src="img/98e5abd5-4d97-40fa-94bf-a17c4b8f18e7.png" style="width:0.58em;height:0.92em;"/> at the point <img class="fm-editor-equation" src="img/61d4f9eb-a296-4600-91c6-cd1617a1a894.png" style="width:0.83em;height:0.83em;"/> is given by the following formula:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/f16535a8-dde3-463e-9c03-05103fddcc13.png" style="width:14.58em;height:4.42em;"/></p>
<p class="p1">Here, <img class="fm-editor-equation" src="img/6efa9269-ed7d-4d38-bda1-f5d646dd229a.png" style="width:1.17em;height:1.00em;"/> is the i-th nearest neighbor of  <img class="fm-editor-equation" src="img/bfabb96e-2cfd-4ce2-8d58-feb46d60152a.png" style="width:0.83em;height:0.83em;"/>, as calculated by the distance metric  <img class="fm-editor-equation" src="img/66e6b90d-f6ea-4705-b8d1-97bf89a965f4.png" style="width:4.75em;height:1.25em;"/>. The distance metric is a domain-specific measure of the behavioral difference between the two individuals.</p>
<p class="p1">The candidate individuals from sparse areas receive higher novelty scores. When this score exceeds some minimum threshold <img class="fm-editor-equation" src="img/092df855-c373-4f67-b897-1150f7effe54.png" style="width:2.25em;height:1.00em;"/>, the individual at that location is added to the archive of best performers that characterize the distribution of prior solutions in the behavior space. The current generation of the population, combined with the archive, defines where the search has already been and where it is now. Thus, by maximizing the novelty metric, the gradient of search is directed toward new behavior, without any explicit objective. However, Novelty Search is still driven by meaningful information because exploring new behaviors requires comprehensive exploitation of the search domain.</p>
<p>The following image shows the Novelty Search algorithm:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-749 image-border" src="img/112dc5f7-ef90-4a8a-bb28-aeecab886517.png" style="width:42.58em;height:31.25em;"/></p>
<p>The Novelty Search algorithm</p>
<p class="p1">The Novelty Search optimization method allows evolution to search for solutions in any deceptive space and find optimal solutions. With this method, it is possible to implement divergent evolution when the population is forced not to converge in a particular niche solution (local optima) and have to explore the whole solution space. It seems like a very effective search optimization method, despite its counterintuitive approach, which completely ignores the explicit objective during the search. Moreover, it can find the final solution in most cases even faster than a traditional objective-based search that's measuring fitness as a distance from the final solution.</p>
<p>For more details, you can refer to the following link: <a href="http://joellehman.com/lehman-dissertation.pdf">http://joellehman.com/lehman-dissertation.pdf</a>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Summary</h1>
                
            
            
                
<p class="p1">In this chapter, we began by discussing the different methods that are used to train artificial neural networks. We considered how traditional gradient descent-based methods differ from neuroevolution-based ones. Then, we presented one of the most popular neuroevolution algorithms (NEAT) and the two ways we can extend it (HyperNEAT and ES-HyperNEAT). Finally, we described the search optimization method (Novelty Search), which can find solutions to a variety of deceptive problems that cannot be solved by conventional objective-based search methods. Now, you are ready to put this knowledge into practice after setting up the necessary environment, which we will discuss in the next chapter.</p>
<p>In the next chapter, we will cover the libraries that are available so that we can experiment with neuroevolution in Python. We will also demonstrate how to set up a working environment and what tools are available to manage dependencies in the Python ecosystem.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Further reading</h1>
                
            
            
                
<p class="p1">For a deeper understanding of the topics that we discussed in this chapter, take a look at the following links:</p>
<ul class="ul1">
<li class="li1"><strong>NEAT</strong>: <a href="http://nn.cs.utexas.edu/downloads/papers/stanley.phd04.pdf">http://nn.cs.utexas.edu/downloads/papers/stanley.phd04.pdf</a></li>
<li class="li1"><strong>HyperNEAT</strong>: <a href="https://eplex.cs.ucf.edu/papers/stanley_alife09.pdf">https://eplex.cs.ucf.edu/papers/stanley_alife09.pdf</a></li>
<li class="li1"><strong>ES-HyperNEAT</strong>: <a href="https://eplex.cs.ucf.edu/papers/risi_alife12.pdf">https://eplex.cs.ucf.edu/papers/risi_alife12.pdf</a></li>
<li class="li1"><strong>Novelty Search</strong>: <a href="http://joellehman.com/lehman-dissertation.pdf">http://joellehman.com/lehman-dissertation.pdf</a></li>
</ul>


            

            
        
    </body></html>