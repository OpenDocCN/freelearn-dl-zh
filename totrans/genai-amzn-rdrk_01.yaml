- en: '1'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '1'
- en: Exploring Amazon Bedrock
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索亚马逊Bedrock
- en: People across the globe have been amazed by the potential of generative AI,
    and industries across the globe are looking to innovate in their organizations
    and solve business use cases through generative AI.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 全球各地的人们都对生成式AI的潜力感到惊讶，全球各地的行业都在寻求通过生成式AI在组织中进行创新和解决业务用例。
- en: This chapter will introduce you to a powerful generative AI service known as
    **Amazon Bedrock**. We’ll begin by providing an overview of the generative AI
    landscape. Then, we’ll examine the challenges industries face with generative
    AI and how Amazon Bedrock addresses those challenges effectively. After, we’ll
    explore the various **foundation models** (**FMs**) that are currently offered
    by Amazon Bedrock and help you assess which model is suitable for specific scenarios.
    Additionally, we’ll cover some of Amazon’s additional generative AI capabilities
    beyond FMs. By the end of this chapter, you will have a solid understanding of
    Amazon Bedrock’s generative AI offerings, model selection criteria, and the broader
    generative AI capabilities available from Amazon.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将向您介绍一个名为**亚马逊Bedrock**的强大生成式AI服务。我们将首先提供一个生成式AI领域的概述。然后，我们将探讨行业在生成式AI方面面临的挑战以及亚马逊Bedrock如何有效地解决这些挑战。接下来，我们将探索亚马逊Bedrock目前提供的各种**基础模型**（**FMs**），并帮助您评估哪种模型适用于特定场景。此外，我们还将介绍亚马逊在基础模型之外的一些附加生成式AI功能。到本章结束时，您将对亚马逊Bedrock的生成式AI服务、模型选择标准以及亚马逊提供的更广泛的生成式AI功能有一个扎实的理解。
- en: 'The following topics will be covered in the chapter:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Understanding the generative AI landscape
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解生成式AI领域
- en: What are FMs?
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是FMs？
- en: What is Amazon Bedrock?
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是亚马逊Bedrock？
- en: FMs in Amazon Bedrock
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 亚马逊Bedrock中的FMs
- en: Evaluating and selecting the right FM
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估和选择合适的FM
- en: Generative AI capabilities of Amazon
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 亚马逊的生成式AI功能
- en: Generative AI use cases with Amazon Bedrock
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用亚马逊Bedrock的生成式AI用例
- en: Understanding the generative AI landscape
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解生成式AI领域
- en: Since the advent of ChatGPT, organizations across the globe have explored a
    plethora of use cases that generative AI can solve for them. They have built several
    innovation teams and teams of data scientists to build and explore various use
    cases, including summarizing long documents, extracting information from documents,
    and performing sentiment analysis to gauge satisfaction or discontent toward a
    product or service. If you have been working in the **machine learning** (**ML**)
    or **natural language processing** (**NLP**) field, you may be familiar with how
    a language model works – by understanding the relationship between the words in
    documents. The main objective of these **language models** is to predict the next
    probable word in a sentence.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 自ChatGPT问世以来，全球各地的组织都在探索大量生成式AI可以为他们解决的问题。他们建立了多个创新团队和数据科学家团队来构建和探索各种用例，包括总结长文档、从文档中提取信息以及执行情感分析以衡量对产品或服务的满意或不满意程度。如果您在**机器学习**（**ML**）或**自然语言处理**（**NLP**）领域工作，您可能熟悉语言模型的工作方式——通过理解文档中单词之间的关系。这些**语言模型**的主要目标是预测句子中的下一个可能的单词。
- en: 'If you look at the sentence *John loves to eat*, a natural language model is
    trying to predict what the next word or token in the sequence will be. Here, the
    next probable word seems to be *ice-cream*, with a 9.4% chance, as shown in *Figure
    1**.1*:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你观察句子 *John loves to eat*，一个自然语言模型正在尝试预测序列中的下一个单词或标记。在这里，下一个可能的单词似乎是 *ice-cream*，概率为9.4%，如*图1.1*所示：
- en: '![Figure 1.1 – Sentence sequencing prediction](img/B22045_01_01.jpg)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![图1.1 – 句子序列预测](img/B22045_01_01.jpg)'
- en: Figure 1.1 – Sentence sequencing prediction
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.1 – 句子序列预测
- en: Language models can do this by converting every word into a numerical vector,
    also known as **embeddings**. Similar words will be closer in the vector space,
    while dissimilar words will be positioned spatially distant from each other. For
    instance, the word *phone* will be far apart from the word *eat* since the semantic
    meanings of these words are different.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 语言模型可以通过将每个单词转换为数值向量，也称为**嵌入**，来实现这一点。在向量空间中，相似的单词会彼此靠近，而不相似的单词在空间上会彼此远离。例如，单词
    *phone* 会与单词 *eat* 相距甚远，因为这两个单词的语义意义不同。
- en: Early NLP techniques such as **bag-of-words models** with **Term Frequency -
    Inverse Document Frequency** (**TF-IDF**) scoring and **n-gram** analysis had
    some limitations for language modeling tasks. TF-IDF, which determines word importance
    based on frequency, does not account for semantic context within sentences. N-grams,
    representing adjacent words or characters, do not generalize well for out-of-vocabulary
    terms. What was needed to advance language modeling was a method of representing
    words in a way that captures semantic meaning and relationships between words.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 早期的自然语言处理技术，如**词袋模型**和**词频-逆文档频率**（**TF-IDF**）评分以及**n-gram**分析，在语言建模任务中存在一些局限性。基于频率确定单词重要性的TF-IDF没有考虑句子中的语义上下文。表示相邻单词或字符的n-gram对于词汇表外的术语泛化效果不佳。为了推进语言建模，需要一种以捕捉单词的语义意义和单词之间关系的方式来表示单词。
- en: In neural networks, a word embedding model known as **Word2Vec** was able to
    learn associations from a large corpus of text. However, the Word2Vec model struggled
    to perform well with out-of-vocabulary words. Since the 2010s, researchers have
    been experimenting with more advanced sequence modeling techniques to address
    this limitation, such as **recurrent neural networks** (**RNNs**) and **long short-term
    memory** (**LSTM**) networks. These models have memory cells that allow them to
    consider the context of previous words in a sentence when predicting the next
    word. RNNs and LSTMs can capture longer-range dependencies compared to models
    such as Word2Vec. While powerful for modeling word sequences, RNNs and LSTM are
    also more computationally and memory intensive, which means they can hold limited
    context depending on how much data is being fed to the model. Therefore, these
    models are unable to perform well when a whole document with several pages is
    provided.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在神经网络中，一种名为**Word2Vec**的词嵌入模型能够从大量文本语料库中学习关联。然而，Word2Vec模型在处理词汇表外的单词时表现不佳。自2010年代以来，研究人员一直在尝试更先进的序列建模技术来解决这一局限性，例如**循环神经网络**（**RNNs**）和**长短期记忆**（**LSTM**）网络。这些模型具有记忆单元，允许它们在预测下一个单词时考虑句子中先前单词的上下文。与Word2Vec等模型相比，RNNs和LSTMs可以捕捉更长的依赖关系。虽然这些模型在建模词序列方面非常强大，但它们在计算和内存消耗上更高，这意味着它们根据模型接收到的数据量可以保持有限的范围。因此，当提供包含多页文档时，这些模型无法很好地表现。
- en: In 2017, researchers at Google and the University of Toronto published a paper
    called *Attention Is All You Need* ([https://arxiv.org/abs/1706.03762](https://arxiv.org/abs/1706.03762)).
    This paper introduced the **transformer architecture**, which is based on a self-attention
    mechanism rather than recurrent or convolutional layers used in previous models.
    This **self-attention mechanism** allows the model to learn contextual relationships
    between all words (or a set of tokens) in the input simultaneously. It does this
    by calculating the importance of each word concerning other words in the sequence.
    This attention is applied to derive contextual representations for downstream
    tasks such as language modeling or machine translation. One major benefit of the
    transformer architecture is its ability to perform parallel computation with a
    long sequence of words. This enabled transformers to be effectively applied to
    much longer texts and documents compared to previous recurrent models.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在2017年，谷歌和多伦多大学的学者们发表了一篇名为 *Attention Is All You Need* ([https://arxiv.org/abs/1706.03762](https://arxiv.org/abs/1706.03762))
    的论文。这篇论文介绍了 **transformer架构**，它基于自注意力机制，而不是之前模型中使用的循环或卷积层。这种**自注意力机制**允许模型同时学习输入中所有单词（或一组标记）之间的上下文关系。它是通过计算每个单词相对于序列中其他单词的重要性来实现的。这种注意力被应用于推导出用于下游任务（如语言建模或机器翻译）的上下文表示。transformer架构的一个主要优点是它能够对长序列的单词进行并行计算。这使得transformer能够比之前的循环模型更有效地应用于更长的文本和文档。
- en: Language models based on the transformer architecture exhibit **state-of-the-art**
    (**SOTA**) and near-human-level performance. Since the advent of transformer architecture,
    various models have been developed. This breakthrough paved the way for modern
    **large language models** (**LLMs**), including **Bidirectional Encoder Representations
    from Transformers** (**BERT**), **Generative Pre-Training language model** (**GPT**),
    **Text-To-Text Transfer Transformer** (**T5**), **BLOOM**, and **Anthropic Claude**.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 基于Transformer架构的语言模型展现出**最先进**（**SOTA**）和接近人类水平的性能。自从Transformer架构出现以来，已经开发了各种模型。这一突破为现代**大型语言模型**（**LLMs**），包括**双向编码器表示的Transformer**（**BERT**）、**生成式预训练语言模型**（**GPT**）、**文本到文本迁移Transformer**（**T5**）、**BLOOM**和**Anthropic
    Claude**铺平了道路。
- en: Now, let’s dive into some LLMs that a powering a substantial change in the generative
    AI domain.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们深入了解一些正在推动生成式AI领域发生重大变化的LLMs。
- en: What are FMs?
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是FM？
- en: Most of the generative AI models today are powered by the transformer-based
    architecture. In general, these generative AI models, also widely known as FMs,
    employ transformers due to their ability to process text one token at a time or
    entire sequences of text at once using self-attention. FMs are trained on massive
    amounts of data with millions or billions of parameters, allowing them to understand
    relationships between words in context to predict subsequent sequences. While
    models based on the transformer architecture currently dominate the field, not
    all FMs rely on this architecture. Some models are built using alternative techniques,
    such as **generative adversarial networks** (**GANs**) or **variational autoencoders**.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 目前大多数生成式AI模型都由基于Transformer的架构驱动。一般来说，这些生成式AI模型，也广泛被称为FM，使用Transformer是因为它们能够一次处理一个或整个序列的文本，使用自注意力。FM在数百万或数十亿参数的大量数据上训练，使它们能够理解上下文中词语之间的关系，以预测后续序列。虽然基于Transformer架构的模型目前在领域内占据主导地位，但并非所有FM都依赖于这种架构。一些模型使用替代技术构建，例如**生成对抗网络**（**GANs**）或**变分自编码器**。
- en: GANs utilize two neural networks pitted against each other in competition. The
    first network is known as the **generator** and is tasked with generating synthetic
    samples that mimic real data. For example, the generator could produce new images,
    texts, or audio clips. The second network is called the **discriminator**. Its
    role is to analyze examples, both real and synthetic, to classify which ones are
    genuine and which have been artificially generated.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: GANs利用两个相互竞争的神经网络。第一个网络被称为**生成器**，其任务是生成模仿真实数据的合成样本。例如，生成器可以生成新的图像、文本或音频剪辑。第二个网络被称为**判别器**。其作用是分析示例，包括真实和合成的，以分类哪些是真实的，哪些是人工生成的。
- en: Through this adversarial process, the generator learns to produce increasingly
    convincing fakes that can fool the discriminator. Meanwhile, the discriminator
    becomes better at detecting subtle anomalies that reveal the synthetic samples.
    Their competing goals drive both networks to continuously improve. An example
    of a GAN can be found at [https://thispersondoesnotexist.com/](https://thispersondoesnotexist.com/).
    By refreshing the page endlessly, users are presented with an endless stream of
    novel human faces. However, none are real – all are synthetic portraits created
    solely by a GAN trained on vast databases of real human images. The site offers
    a glimpse into how GANs can synthesize highly realistic outputs across many domains.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这种对抗过程，生成器学会产生越来越令人信服的伪造品，可以欺骗判别器。同时，判别器在检测揭示合成样本的微妙异常方面变得更好。它们的竞争目标推动两个网络不断改进。一个GAN的例子可以在[https://thispersondoesnotexist.com/](https://thispersondoesnotexist.com/)找到。通过不断刷新页面，用户会看到一系列新颖的人类面孔。然而，它们都不是真实的——所有这些都是由一个在大量真实人类图像数据库上训练的GAN生成的合成肖像。该网站展示了GAN如何在许多领域合成高度逼真的输出。
- en: '**Variational autoencoders** are simpler-to-train generative AI algorithms
    that also utilize two neural networks – an **encoder** and a **decoder**. Encoders
    learn the patterns in the data by mapping it into lower-dimensional latent space,
    while decoders use these patterns from the latent space and generate realistic
    samples.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**变分自编码器**是更易于训练的生成式AI算法，它也利用两个神经网络——一个**编码器**和一个**解码器**。编码器通过将其映射到低维潜在空间来学习数据中的模式，而解码器使用这些潜在空间中的模式来生成逼真的样本。'
- en: While these FMs (transformer, GAN, or variational autoencoders-based) are trained
    on massive datasets, this makes them different from other traditional ML models,
    such as logistic regression, **support vector machines** (**SVM**), decision trees,
    and others. The term *foundation models* was coined by researchers at Stanford
    University at Human-Centered Artificial Intelligence to differentiate them from
    other ML models. The traditional ML models are trained on the labeled data and
    are only capable of performing narrowly defined tasks. For example, there will
    be one model for text generation, another model for summarization, and so on.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这些FMs（基于Transformer、GAN或变分自编码器）是在大量数据集上训练的，这使得它们与其他传统机器学习模型（如逻辑回归、**支持向量机**（SVM）、决策树等）不同。斯坦福大学人类中心化人工智能研究团队提出了“基础模型”这一术语，以区分它们与其他机器学习模型。传统的机器学习模型是在标记数据上训练的，并且只能执行狭窄定义的任务。例如，将有一个用于文本生成的模型，另一个用于摘要的模型，等等。
- en: 'In contrast, FMs learn patterns in language by analyzing the relationships
    between words and sentences while training on a massive dataset containing millions
    or billions of parameters. Due to their enormous pre-training datasets, FMs tend
    to generalize well and understand contextual meaning, which allows them to solve
    various use cases, such as text generation, summarization, entity extraction,
    image generation, and others. Their pre-training enables them to serve as a highly
    adaptable starting point for many different applications. *Figure 1**.2* highlights
    some of the differences between traditional ML models and FMs:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 与之相反，FMs（基础模型）通过在包含数百万或数十亿参数的巨大数据集上进行训练，通过分析单词和句子之间的关系来学习语言中的模式。由于它们拥有庞大的预训练数据集，FMs往往能够很好地泛化并理解上下文意义，这使得它们能够解决各种用例，例如文本生成、摘要、实体提取、图像生成等。它们的预训练使它们能够作为许多不同应用的极高适应性起点。*图1.2*突出了传统机器学习模型和FMs之间的一些差异：
- en: '![Figure 1.2 – Traditional ML models versus FMs](img/B22045_01_02.jpg)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![图1.2 – 传统机器学习模型与FMs](img/B22045_01_02.jpg)'
- en: Figure 1.2 – Traditional ML models versus FMs
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.2 – 传统机器学习模型与FMs
- en: 'Despite the range of FMs available, organizations face several challenges when
    adopting these models at scale:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管有各种FMs可用，但组织在采用这些模型进行大规模部署时面临几个挑战：
- en: '**No single model solution**: There is no single model that’s optimized for
    all tasks and models are constantly improving with new advances in technology.
    To address multiple use cases, organizations may need to assemble several models
    that work with each other. This can take significant time and resources.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**没有单一模型解决方案**：没有单一模型是针对所有任务进行优化的，而且随着新技术的进步，模型也在不断改进。为了应对多个用例，组织可能需要组装几个相互协作的模型。这可能会耗费大量时间和资源。'
- en: '**Security concerns**: Security and privacy pose a major concern as organizations
    want to protect their data and valuable intellectual property, and they also want
    control over how their data is shared and used by these models.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全问题**：安全和隐私是主要关注点，因为组织希望保护他们的数据和宝贵的知识产权，他们还希望控制这些模型如何共享和使用他们的数据。'
- en: '**Time and resource management**: For applications such as document summarization
    and virtual assistants, specific model configuration is needed. This includes
    defining tasks, granting access to internal data sources, and developing APIs
    for the model to take action. This requires a multi-step process and complex coding.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**时间和资源管理**：对于文档摘要和虚拟助手等应用，需要特定的模型配置。这包括定义任务、授权访问内部数据源，以及为模型开发执行操作的API。这需要一个多步骤的过程和复杂的编码。'
- en: '**Lack of seamless integration**: Being able to seamlessly integrate into existing
    applications is important to avoid managing large computational infrastructures
    or incurring high costs. Organizations want models to work behind the scenes without
    any heavy lifting or expense.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**缺乏无缝集成**：能够无缝集成到现有应用中非常重要，以避免管理大型计算基础设施或承担高昂的成本。组织希望模型在幕后工作，无需任何重负载或费用。'
- en: Addressing these technical, operational, security, and privacy challenges is
    key for organizations to successfully adopt and deploy FMs at an enterprise scale.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这些技术、运营、安全和隐私挑战是组织成功采用和部署FMs的企业规模的关键。
- en: These are the very problems that Amazon Bedrock is designed to solve.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这些正是亚马逊Bedrock旨在解决的问题。
- en: What is Amazon Bedrock?
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是亚马逊Bedrock？
- en: Amazon Bedrock is a fully managed service that offers various choices of high-performing
    FMs via a single API. *Fully managed* implies that users do not have to worry
    about creating, deploying, and operating the backend infrastructure as it has
    been taken care of by Amazon. So, from within your application or code, you can
    invoke the model on Bedrock with a single API containing your prompt. One of the
    key advantages of Amazon Bedrock is it provides a wide choice of leading FMs from
    Amazon and top AI companies such as Anthropic, AI21 Labs, Cohere, Meta, Stability
    AI, and Mistral.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Bedrock 是一项完全托管的服务，通过单个 API 提供各种高性能 FM 的选择。*完全托管*意味着用户无需担心创建、部署和运营后端基础设施，因为这一切都由
    Amazon 负责。因此，您可以在应用程序或代码内部使用单个 API 调用 Bedrock 上的模型，该 API 包含您的提示。Amazon Bedrock
    的一个关键优势是它提供了来自 Amazon 和顶级 AI 公司（如 Anthropic、AI21 Labs、Cohere、Meta、Stability AI
    和 Mistral）的广泛选择。
- en: Once you’ve defined your use case, the next step is to choose an FM. Amazon
    Bedrock provides a playground experience (a web interface for rapid experimentation)
    where you can experiment with different models and prompts. Additionally, there
    are certain techniques and suitability criteria you need to employ to choose the
    best-fit model for your use case. We will learn how to evaluate LLMs in the upcoming
    sections.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你定义了你的用例，下一步就是选择一个 FM。Amazon Bedrock 提供了一个沙盒体验（一个用于快速实验的 Web 界面），你可以在这里尝试不同的模型和提示。此外，还有一些技术和适用性标准你需要采用，以选择最适合你用例的模型。我们将在接下来的章节中学习如何评估
    LLM。
- en: 'Once you have evaluated and identified the FM for your use case, the focus
    turns to enhancing its predictive capabilities. Amazon Bedrock provides the following
    key capabilities for refining model performance:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你评估并确定了适用于你的用例的 FM，重点就转向增强其预测能力。Amazon Bedrock 提供以下关键能力来优化模型性能：
- en: '`Tell me the recipe for chocolate cake` or can be detailed prompts with multiple
    examples, depending on the use case that you are trying to solve. With its playground
    experience, Amazon Bedrock lets you effectively design and formulate prompts through
    rapid experimentation. We will discuss some of these techniques and practical
    aspects of prompt engineering in [*Chapter 3*](B22045_03.xhtml#_idTextAnchor053).'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`告诉我巧克力蛋糕的做法` 或可以详细提示，包含多个示例，具体取决于你试图解决的问题的使用场景。凭借其沙盒体验，Amazon Bedrock 允许你通过快速实验有效地设计和制定提示。我们将讨论这些技术以及提示工程的一些实际方面，详见
    [*第3章*](B22045_03.xhtml#_idTextAnchor053)。'
- en: '**Easy fine-tuning**: Amazon Bedrock allows you to easily customize FMs with
    your dataset. This process is called **fine-tuning** the model and involves training
    the model further with your domain dataset, improving the accuracy for domain-specific
    tasks. Fine-tuning can be done directly from the Amazon Bedrock console or through
    APIs, and by providing your datasets in an Amazon **Simple Storage Service** (**Amazon
    S3**) bucket. We will discuss fine-tuning Amazon Bedrock FMs in detail in [*Chapter
    4*](B22045_04.xhtml#_idTextAnchor073).'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**易于微调**：Amazon Bedrock 允许你使用你的数据集轻松定制 FM。这个过程称为**微调**模型，涉及使用你的领域数据集进一步训练模型，以提高特定领域任务的准确性。微调可以直接从
    Amazon Bedrock 控制台或通过 API 进行，并通过提供你的数据集在 Amazon **简单存储服务**（**Amazon S3**）存储桶中完成。我们将在
    [*第4章*](B22045_04.xhtml#_idTextAnchor073) 中详细讨论微调 Amazon Bedrock FM。'
- en: '**Native support for RAG**: **Retrieval augmented generation** (**RAG**) is
    a powerful technique to fetch data from outside the language model, such as from
    internal knowledge bases or external sources, to provide accurate responses to
    domain-specific use cases. This technique is useful when large documents are needed
    that are beyond the context provided by the model. Amazon Bedrock provides native
    support for RAG, so you can connect your data source for retrieval augmentation.
    We will discuss RAG in greater detail in [*Chapter 5*](B22045_05.xhtml#_idTextAnchor090).'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**原生支持 RAG**：**检索增强生成**（**RAG**）是一种强大的技术，可以从语言模型外部获取数据，例如从内部知识库或外部来源，以提供针对特定领域用例的准确响应。当需要超出模型提供的上下文的大型文档时，这种技术非常有用。Amazon
    Bedrock 提供原生支持 RAG，因此您可以连接您的数据源以进行检索增强。我们将在 [*第5章*](B22045_05.xhtml#_idTextAnchor090)
    中更详细地讨论 RAG。'
- en: Furthermore, there are additional capabilities provided by Amazon Bedrock, such
    as the ability to build intelligent **Agents** to orchestrate and carry out multiple
    tasks on your behalf. Agents can call various internal and external data sources,
    connect to applications, and run complex tasks in multiple steps. We will dive
    deep into building intelligent Agents in [*Chapter 10*](B22045_10.xhtml#_idTextAnchor192).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，亚马逊Bedrock还提供了额外的功能，例如构建智能**代理**来代表您协调和执行多项任务的能力。代理可以调用各种内部和外部数据源，连接到应用程序，并在多个步骤中运行复杂任务。我们将在[*第10章*](B22045_10.xhtml#_idTextAnchor192)中深入探讨构建智能代理。
- en: Security, privacy, and observability are some of the key capabilities of Amazon
    Bedrock. The data that you provide when you invoke FMs, including prompts and
    context, isn’t used to retain any of the FMs. In addition, all the AWS security
    and governance capabilities, including data encryption, IAM authentication and
    permission policies, VPC configuration, and others, apply to Amazon Bedrock. Hence,
    you can encrypt your data at rest and in transit. You can tell Amazon Bedrock
    to use **Virtual Private Cloud** (**VPC**) so that the traffic between AWS-hosted
    system components does not flow through the internet. Also, via **Identity and
    Access Management** (**IAM**), you can provide access to certain resources or
    users. Furthermore, metrics, logs, and API calls are pushed to AWS CloudWatch
    and AWS CloudTrail, so you can have visibility and monitor the usage of Amazon
    Bedrock models. In *Part 3* of the book, we will cover model evaluation, monitoring,
    security, privacy, and ensuring safe and responsible AI practices.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '安全性、隐私性和可观察性是亚马逊Bedrock的一些关键功能。您在调用FM时提供的数据，包括提示和上下文，不会用于保留任何FM。此外，所有AWS安全性和治理功能，包括数据加密、IAM身份验证和权限策略、VPC配置等，都适用于亚马逊Bedrock。因此，您可以在静态和传输中加密您的数据。您可以告诉亚马逊Bedrock使用**虚拟私有云**（**VPC**），这样AWS托管系统组件之间的流量就不会通过互联网。此外，通过**身份和访问管理**（**IAM**），您可以提供对某些资源或用户的访问权限。此外，指标、日志和API调用被推送到AWS
    CloudWatch和AWS CloudTrail，这样您就可以了解并监控亚马逊Bedrock模型的用法。本书的*第3部分*将涵盖模型评估、监控、安全、隐私以及确保安全和负责任的AI实践。 '
- en: For now, let’s look at the different FMs offered by Amazon Bedrock.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，让我们看看亚马逊Bedrock提供的不同FM。
- en: FMs in Amazon Bedrock
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 亚马逊Bedrock中的FM
- en: 'With Amazon Bedrock, you have access to six FMs from Amazon and leading AI
    companies – that is, AI21, Anthropic, Command, Stability AI, and Meta – as depicted
    in *Figure 1**.3*. Amazon Bedrock might add access to more FMs in the future:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 通过亚马逊Bedrock，您可以使用亚马逊和领先AI公司（即AI21、Anthropic、Command、Stability AI和Meta）提供的六种FM，如图*图1**.3*所示。亚马逊Bedrock可能会在未来添加更多FM的访问权限：
- en: '![Figure 1.3 – FMs available on Amazon Bedrock](img/B22045_01_03.jpg)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![图1.3 – 亚马逊Bedrock上可用的FM](img/B22045_01_03.jpg)'
- en: Figure 1.3 – FMs available on Amazon Bedrock
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.3 – 亚马逊Bedrock上可用的FM
- en: Now, let’s discuss each of these models in detail.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们详细讨论这些模型中的每一个。
- en: Amazon Titan FMs
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 亚马逊泰坦FM
- en: The **Amazon Titan FMs** represent a suite of powerful, multipurpose models
    developed by AWS through extensive pretraining on vast datasets, endowing them
    with broad applicability across diverse domains. This FM supports use cases such
    as generating texts, question-answering, summarization, RAG, personalization,
    image generation, and more. A simple example would be generating an article/blog
    or writing an email.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**亚马逊泰坦FM**代表一套由AWS通过在大量数据集上进行广泛预训练开发的强大、多用途模型，赋予它们在多个领域广泛适用的能力。此FM支持生成文本、问答、摘要、RAG、个性化、图像生成等多种用例。一个简单的例子就是生成文章/博客或撰写电子邮件。'
- en: 'Three types of Amazon Titan models are currently available on Amazon Bedrock:
    *Titan Text Generation*, *Titan Image Generator*, and *Titan Embeddings*.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 目前在亚马逊Bedrock上可用的亚马逊泰坦模型有三种：*泰坦文本生成*、*泰坦图像生成*和*泰坦嵌入*。
- en: Titan Text Generation
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 泰坦文本生成
- en: '**Titan Text Generation** is an LLM that’s designed for use cases such as generating
    texts, summarization, and more. Let’s assume that John has to write an email to
    the customer support team of his telephone operator, asking them to fix the billing
    issue he has been facing. We can provide a prompt to the Titan Text Generation
    model. The response will be generated alongside the subject, as shown in *Figure
    1**.4*:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**泰坦文本生成**是一个为生成文本、摘要等用例设计的LLM。假设约翰需要给他的电话运营商的客户支持团队写一封电子邮件，要求他们修复他一直面临的开账问题。我们可以向泰坦文本生成模型提供提示。响应将与主题一起生成，如图*图1**.4*所示：'
- en: '![Figure 1.4 – Response generated by the Titan Text G1- Express model](img/B22045_01_04.jpg)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.4 – Titan Text G1-Express 模型生成的响应](img/B22045_01_04.jpg)'
- en: Figure 1.4 – Response generated by the Titan Text G1- Express model
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.4 – Titan Text G1-Express 模型生成的响应
- en: At the time of writing, Titan Text Generation is available in three different
    flavors – *Titan Text G1 Lite,* *Titan Text G1 Express* and *Titan Text G1 Premier*.
    The main difference is that Lite is a more cost-effective and smaller model and
    supports up to *4,000* tokens, Express is a larger model that supports up to *8,000*
    tokens and is designed for complex use cases, and Premier is most advanced model
    by Titan that supports up to 32k tokens and is designed to provide exceptional
    performance.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，Titan 文本生成器提供三种不同的版本 – *Titan Text G1 Lite*、*Titan Text G1 Express* 和
    *Titan Text G1 Premier*。主要区别在于 Lite 是一个更经济实惠且规模较小的模型，支持高达 *4,000* 个标记，Express
    是一个更大的模型，支持高达 *8,000* 个标记，专为复杂用例设计，而 Premier 是 Titan 最先进的模型，支持高达 32k 个标记，旨在提供卓越的性能。
- en: Titan Image Generator
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Titan 图像生成器
- en: '`Generate an image of a Bunny skiing in the Swiss Alps`. Once the images have
    been generated, we can create variations of a single image, or even edit the image,
    as demonstrated in *Figure 1**.5*:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '`生成一张瑞士阿尔卑斯山滑雪兔子的图像`。一旦生成图像，我们就可以创建单个图像的变体，甚至编辑图像，如 *图 1.5* 所示：'
- en: '![Figure 1.5 – Titan Image Generator and its configurations](img/B22045_01_05.jpg)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.5 – Titan 图像生成器和其配置](img/B22045_01_05.jpg)'
- en: Figure 1.5 – Titan Image Generator and its configurations
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.5 – Titan 图像生成器和其配置
- en: In [*Chapter 9*](B22045_09.xhtml#_idTextAnchor171), we will learn more about
    how image generation works and dive into various use cases.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [*第 9 章*](B22045_09.xhtml#_idTextAnchor171) 中，我们将学习更多关于图像生成的工作原理，并深入了解各种用例。
- en: Titan Embeddings
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Titan Embeddings
- en: The main function of the **Titan Embeddings** model is to convert texts (or
    images) into numeric vectors. These vectors represent words mathematically so
    that similar words have similar vectors. You can store these embeddings in vector
    databases such as **OpenSearch**, **Aurora pgvector**, **Amazon Kendra**, or **Pinecone**,
    and these databases will be used to compare the relationship between the texts.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '**Titan Embeddings** 模型的主要功能是将文本（或图像）转换为数值向量。这些向量以数学方式表示单词，使得相似的单词具有相似的向量。您可以将这些嵌入存储在如
    **OpenSearch**、**Aurora pgvector**、**Amazon Kendra** 或 **Pinecone** 等向量数据库中，这些数据库将用于比较文本之间的关系。'
- en: At the time of writing, the Titan Embeddings model is available in two variations
    – **Titan Text Embeddings** and **Titan Multimodal Embeddings**. The main difference
    is Titan Text Embeddings converts texts into embeddings, which makes the model
    a suitable fit for use cases such as RAG and clustering, while Titan Multimodal
    Embeddings can convert a combination of texts and images into embeddings, which
    makes it apt for use cases such as searching within images and providing recommendations.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，Titan 嵌入模型提供两种变体 – **Titan Text Embeddings** 和 **Titan Multimodal Embeddings**。主要区别在于
    Titan Text Embeddings 将文本转换为嵌入，这使得模型非常适合用于 RAG 和聚类等用例，而 Titan Multimodal Embeddings
    可以将文本和图像的组合转换为嵌入，这使得它在图像搜索和提供推荐等用例中非常适用。
- en: While Titan Text Embeddings supports up to *8,000* tokens and over 25 languages,
    Titan Multimodal Embeddings can support up to *128* tokens with a maximum image
    size of 25 MB. Here, English is the only supported language.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 Titan Text Embeddings 支持高达 *8,000* 个标记和超过 25 种语言，但 Titan Multimodal Embeddings
    可以支持高达 *128* 个标记，最大图像大小为 25 MB。在这里，英语是唯一支持的语言。
- en: In the next chapter, we will learn how to invoke these models and their input
    configuration parameters. For now, let’s learn about some other FMs provided by
    Amazon Bedrock.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习如何调用这些模型及其输入配置参数。现在，让我们了解 Amazon Bedrock 提供的一些其他 FM。
- en: AI21 Labs – Jurassic-2
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AI21 Labs – Jurassic-2
- en: AI21 Labs has built several FMs and task-specific models. However, at the time
    of writing, Amazon Bedrock provides access to *Jamba-Instruct*, *Jurassic 2 –
    Ultra* and *Jurassic 2 –* *Mid* FMs.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: AI21 Labs 已构建了多个 FM 和特定任务的模型。然而，在撰写本文时，Amazon Bedrock 提供了对 *Jamba-Instruct*、*Jurassic
    2 – Ultra* 和 *Jurassic 2 – Mid* FM 的访问。
- en: '**Jamba-Instruct** supports only English, whereas **Jurassic-2** models support
    multiple languages and use cases such as advanced text generation, comprehension,
    open book Q&A, summarization and others.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '**Jamba-Instruct** 只支持英语，而 **Jurassic-2** 模型支持多种语言和用例，如高级文本生成、理解、开放式书籍问答、摘要等。'
- en: Jamba-Instruct supports context token length of 256K, whereas, **Jurassic-2
    Ultra** and **Jurassic-2 Mid** both support a context token length of 8,192.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: Jamba-Instruct 支持上下文标记长度为 256K，而 **Jurassic-2 Ultra** 和 **Jurassic-2 Mid** 都支持上下文标记长度为
    8,192。
- en: 'An example would be the prompt `Give me pointers on how I should grow vegetables
    at home`. The output is depicted in *Figure 1**.6*:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，提示“给我一些在家种植蔬菜的建议”。输出结果如图 *1.6* 所示：
- en: '![Figure 1.6 – Prompting the Jurassic-2 model](img/B22045_01_06.jpg)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.6 – 激活 Jurassic-2 模型](img/B22045_01_06.jpg)'
- en: Figure 1.6 – Prompting the Jurassic-2 model
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.6 – 激活 Jurassic-2 模型
- en: Anthropic Claude
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Anthropic Claude
- en: Anthropic focuses on safe and responsible AI and provides a group of Claude
    models. These models support use cases such as Q&A, removing **personally identifiable
    information** (**PII**), content generation, roleplay dialogues, and more. One
    major benefit of using Anthropic Claude is its ability to process longer sequences
    of text as prompts. With a maximum context window of *200,000* tokens to date,
    Claude can understand and respond to much more extensive prompts. This larger
    context allows Claude to engage in deeper discussions, understand longer narratives
    or documents, and generate more coherent multi-paragraph responses.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: Anthropic 致力于安全负责任的 AI，并提供一系列 Claude 模型。这些模型支持问答、移除 **个人身份信息**（**PII**）、内容生成、角色扮演对话等多种用例。使用
    Anthropic Claude 的一大好处是它能够处理更长的文本序列作为提示。截至目前，Claude 的最大上下文窗口为 *200,000* 个标记，它可以理解和回应更广泛的提示。这种更大的上下文允许
    Claude 进行更深入的讨论，理解更长的叙述或文档，并生成更连贯的多段回应。
- en: 'Amazon Bedrock currently offers access to five versions of Anthropic’s Claude
    language model:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Bedrock 目前提供访问 Anthropic Claude 语言模型五个版本的权限：
- en: '**Anthropic Claude 3.5 Sonnet**: This sets new industry standards for superior
    intelligence, outperforming its predecessors and other top AI models in various
    benchmarks. Claude 3.5 Sonnet excels in areas like visual processing, content
    generation, customer support, data analysis, and coding. Remarkably, it achieves
    this enhanced performance while being 80% more cost-effective than previous Anthropic
    models, making it an attractive choice for businesses seeking advanced AI capabilities
    at a lower price point. The following link highlights the benchmarks and comparison
    with other models on different tasks: https://aws.amazon.com/blogs/aws/anthropics-claude-3-5-sonnet-model-now-available-in-amazon-bedrock-the-most-intelligent-claude-model-yet/.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Anthropic Claude 3.5 Sonnet**：这设定了行业新的智能标准，在各种基准测试中优于其前辈和其他顶级 AI 模型。Claude
    3.5 Sonnet 在视觉处理、内容生成、客户支持、数据分析、编码等领域表现出色。令人印象深刻的是，它在保持比之前 Anthropic 模型 80% 更高效成本的同时，实现了这种增强的性能，使其成为寻求在较低价格点获得先进
    AI 功能企业的理想选择。以下链接突出了基准测试以及与其他模型在不同任务上的比较：https://aws.amazon.com/blogs/aws/anthropics-claude-3-5-sonnet-model-now-available-in-amazon-bedrock-the-most-intelligent-claude-model-yet/'
- en: '**Anthropic Claude 3**: This has three model variants – *Claude 3 Opus*, *Claude
    3 Sonnet*, and *Claude 3 Haiku*. They are the recent and most advanced family
    of Anthropic models available on Amazon Bedrock. All these models have multimodal
    capabilities and can perceive and analyze images (jpeg, png), as well as other
    file types, such as .csv, .doc, .docx, .html, .md, .pdf, .txt, .xls, .xlsx, .gif,
    and text input, with a 200K context window:'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Anthropic Claude 3**：该模型有三个变体 – *Claude 3 Opus*、*Claude 3 Sonnet* 和 *Claude
    3 Haiku*。它们是 Amazon Bedrock 上最近和最先进的 Anthropic 模型系列。所有这些模型都具有多模态功能，可以感知和分析图像（jpeg、png），以及其他文件类型，如
    .csv、.doc、.docx、.html、.md、.pdf、.txt、.xls、.xlsx、.gif 以及文本输入，上下文窗口为 200K：'
- en: '**Claude 3 Opus**: This is Anthropic’s most capable model to date, with 175
    billion parameters. Opus has advanced few-shot learning capabilities, allowing
    it to quickly adapt to a wide variety of tasks using just a few examples.'
  id: totrans-84
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Claude 3 Opus**：这是 Anthropic 到目前为止最强大的模型，拥有 1750 亿个参数。Opus 具有先进的少样本学习能力，只需少量示例即可快速适应各种任务。'
- en: '**Claude 3 Sonnet**: A 60-billion-parameter multimodal AI model, Sonnet has
    strong few-shot learning abilities. Its parameter-efficient architecture allows
    it to handle complex inputs such as long documents while being more computationally
    efficient than Opus.'
  id: totrans-85
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Claude 3 Sonnet**：一个拥有 600 亿个参数的多模态 AI 模型，Sonnet 具有强大的少样本学习能力。其参数高效的架构允许它处理复杂输入，如长文档，同时比
    Opus 更具计算效率。'
- en: '**Claude 3 Haiku**: At 7 billion parameters, Haiku is Anthropic’s most compact
    and lightweight model. It is optimized for efficiency, providing high performance
    for its size. Its low computational requirements make it very fast to run inference.'
  id: totrans-86
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Claude 3 Haiku**：在70亿参数下，Haiku是Anthropic最紧凑和轻量级的模型。它针对效率进行了优化，提供了与其大小相匹配的高性能。其低计算需求使其推理非常快速。'
- en: '**Anthropic Claude 2.1** **and** **Claude 2**: They are also advanced additions
    to Anthropic’s Claude family. They provide performant reasoning capabilities and
    high accuracy with lower hallucination rates. They perform well on use cases such
    as dialogue, creative writing, information, roleplay, summarization, and others.
    In terms of context length, Claude 2.1 supports up to *200,000* tokens and Claude
    2 supports up to *100,000* tokens.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Anthropic Claude 2.1** **和** **Claude 2**：它们也是Anthropic Claude家族的先进补充。它们提供了高性能的推理能力和高精度，同时幻觉率较低。它们在对话、创意写作、信息、角色扮演、摘要等用例上表现良好。在上下文长度方面，Claude
    2.1支持高达*200,000*个标记，而Claude 2支持高达*100,000*个标记。'
- en: '**Anthropic Claude 1.3**: This is an earlier release with capabilities typical
    of LLMs at that time. It demonstrated strong performance on tasks involving factual
    responses, summarization, and basic question-answering. In terms of context length,
    Claude 1.3 supports up to *100,000* tokens.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Anthropic Claude 1.3**：这是一个较早的版本，具有当时LLM的典型功能。它在涉及事实回应、摘要和基本问答的任务上表现出色。在上下文长度方面，Claude
    1.3支持高达*100,000*个标记。'
- en: '**Anthropic Claude Instant 1.2**: This offers a faster and more cost-effective
    option compared to other Claude models. The latency of the Claude Instant model
    is greatly reduced at the cost of impacted performance. However, Claude Instant
    still demonstrates strong language skills for many common NLP applications that
    do not require the highest levels of reasoning or nuanced responses, and when
    speed or cost is a higher priority than absolute highest performance. In terms
    of context length, Claude Instant 1.2 supports up to *100,000* tokens.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Anthropic Claude Instant 1.2**：与其它Claude模型相比，这提供了一个更快、更经济的选项。Claude Instant模型的延迟大大降低，但性能受到影响。然而，Claude
    Instant仍然在许多常见的NLP应用中表现出强大的语言技能，这些应用不需要最高水平的推理或细微的回应，并且当速度或成本比绝对最高性能更重要时。在上下文长度方面，Claude
    Instant 1.2支持高达*100,000*个标记。'
- en: We will walk through some examples of leveraging Anthropic Claude with Bedrock
    in the next chapter.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一章中通过一些示例来展示如何利用Anthropic Claude与Bedrock结合使用。
- en: Cohere
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Cohere
- en: 'Amazon Bedrock offers multiple models from Cohere: *Command*, *Command R+*,
    *Command R*, *Command Light* models, *Embed English,* and *Embed Multilingual*.
    **Cohere Command****,** trained with 52 billion parameters**,** is an LLM useful
    for more complex language understanding. **Command Light**, with 6 billion parameters,
    is cost-effective and faster, making it a good option for those who need a lighter
    model for their applications. **Command R+**, trained on 104 billiion parameters,
    is the most powerful model by Cohere, at the time of writing this book, and is
    designed for tasks with context window size of 128K tokens. **Command R**, trained
    on 35 billion parameters, is also designed for tasks with longer context window
    of 128K tokens.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Bedrock提供了来自Cohere的多个模型：*Command*、*Command R+*、*Command R*、*Command Light*模型、*Embed
    English*和*Embed Multilingual*。**Cohere Command**，经过520亿参数训练，是一个适用于更复杂语言理解的LLM。**Command
    Light**，具有60亿参数，既经济又快速，对于那些需要为应用提供更轻量级模型的用户来说是一个好选择。**Command R+**，在1040亿参数上训练，是Cohere在撰写本书时的最强大模型，并设计用于具有128K标记上下文窗口大小的任务。**Command
    R**，在350亿参数上训练，也是为具有128K标记上下文窗口大小的任务设计的。
- en: Cohere Embed provides a set of models that have been trained to generate high-quality
    embeddings, which we already know are representations of text documents in a numerical
    format in vector space. Cohere offers **Embed English**, which has only been trained
    on English text, as well as **Embed Multilingual**, which can handle multiple
    (more than 100) languages. Embed models support a maximum token length of 512\.
    These embedding models open a wide range of downstream applications, such as semantic
    search to find related documents, RAG, text clustering, classification, and more.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: Cohere Embed提供了一系列经过训练以生成高质量嵌入的模型，这些嵌入我们已经知道是文本文档在向量空间中的数值格式表示。Cohere提供**Embed
    English**，它仅针对英语文本进行训练，以及**Embed Multilingual**，可以处理多种（超过100种）语言。嵌入模型支持的最大标记长度为512。这些嵌入模型为下游应用开辟了广泛的应用范围，例如语义搜索以查找相关文档、RAG、文本聚类、分类等。
- en: 'Take note of the following figure, which highlights a text generation example
    for summarizing a conversation using the Cohere Command model within Amazon Bedrock’s
    text playground:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 注意以下图示，它突出了在Amazon Bedrock文本游乐场中使用Cohere Command模型对对话进行摘要的文本生成示例：
- en: '![Figure 1.7 – Cohere Command text generation example in Amazon Bedrock’s text
    playground](img/B22045_01_07.jpg)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![图1.7 – 在Amazon Bedrock文本游乐场中的Cohere Command文本生成示例](img/B22045_01_07.jpg)'
- en: Figure 1.7 – Cohere Command text generation example in Amazon Bedrock’s text
    playground
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.7 – 在Amazon Bedrock文本游乐场中的Cohere Command文本生成示例
- en: Meta Llama 2 and Llama 3
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Meta Llama 2和Llama 3
- en: Meta offers several pre-trained LLMs under their **Llama 2** and **Llama 3**
    series for chatbot applications. Their base Llama2 model is pre-trained on over
    2 trillion tokens of publicly available online data sources, at which point it’s
    fine-tuned with over 1 million examples of human annotation.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: Meta在其**Llama 2**和**Llama 3**系列下提供了几个预训练的LLM，用于聊天机器人应用。其基础Llama2模型在超过2000万亿个公开在线数据源上进行预训练，此时它通过超过100万个人类标注示例进行微调。
- en: 'Four variants of Llama2 have been made available through Amazon Bedrock: **Llama
    2 Chat 13B**, **Llama 2 Chat 70B**, **Llama 2 13B**, and **Llama 2 70B**. The
    13B model contains 13 billion parameters and its training process took 368,640
    GPU hours to complete. One of the key advantages of the Llama 13B model is its
    ability to process input sequences of arbitrary length, making it well-suited
    for tasks that require long documents or web pages to be analyzed. The larger
    70B model variant contains 70 billion parameters and its training process took
    1,720,320 GPU hours to complete. The 70B model can be used for multitask learning,
    implying it is well suited for performing multiple tasks simultaneously, such
    as image classification, speech recognition, and NLP. It has been shown to achieve
    improved performance on several tasks compared to 13B models, likely due to its
    relatively larger size and higher computational resources.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 通过Amazon Bedrock，已经提供了四种Llama2变体：**Llama 2 Chat 13B**、**Llama 2 Chat 70B**、**Llama
    2 13B**和**Llama 2 70B**。13B模型包含130亿参数，其训练过程耗时368,640个GPU小时。Llama 13B模型的一个关键优势是能够处理任意长度的输入序列，这使得它非常适合需要分析长文档或网页的任务。更大的70B模型变体包含700亿参数，其训练过程耗时1,720,320个GPU小时。70B模型可用于多任务学习，这意味着它非常适合同时执行多个任务，如图像分类、语音识别和NLP。与13B模型相比，它在多个任务上表现出改进的性能，这可能是由于其相对较大的规模和更高的计算资源。
- en: Along with Llama2, Meta Llama 3 variants are also available on Amazon Bedrock,
    namely **Llama 3 8B Instruct** and **Llama 3 70B Instruct**. The Llama 3 8B Instruct
    model is optimized for scenarios with limited computational resources, making
    it well-suited for edge devices and applications. It demonstrates strong performance
    in tasks such as text summarization, text classification, language translation,
    and sentiment analysis. The Llama 3 70B Instruct model is tailored for content
    creation, conversational AI systems, language understanding applications, and
    enterprise solutions. It excels in areas such as accurate text summarization,
    nuanced text classification, sophisticated sentiment analysis and reasoning, language
    modeling, dialogue systems, code generation, and following complex instructions.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 除了Llama2之外，Meta的Llama 3系列变体也已在Amazon Bedrock上提供，具体包括**Llama 3 8B Instruct**和**Llama
    3 70B Instruct**。Llama 3 8B Instruct模型针对计算资源有限的场景进行了优化，非常适合边缘设备和应用。它在文本摘要、文本分类、语言翻译和情感分析等任务中表现出色。Llama
    3 70B Instruct模型针对内容创作、对话式人工智能系统、语言理解和企业解决方案进行了定制。它在精确文本摘要、细微文本分类、复杂的情感分析和推理、语言建模、对话系统、代码生成和遵循复杂指令等领域表现出色。
- en: For developers looking to utilize these models, Meta has created an open source
    GitHub repository called *llama-recipes* ([https://github.com/facebookresearch/llama-recipes/tree/main](https://github.com/facebookresearch/llama-recipes/tree/main))
    that includes demo code and examples of integrating the Llama2 models into chatbots
    and virtual assistants. This provides a starting point for researchers and practitioners
    to experiment with Llama2 and adapt it for their own conversational AI applications.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 对于希望利用这些模型的开发者，Meta创建了一个名为*llama-recipes*的开源GitHub仓库（[https://github.com/facebookresearch/llama-recipes/tree/main](https://github.com/facebookresearch/llama-recipes/tree/main)），其中包含将Llama2模型集成到聊天机器人和虚拟助手中的示例代码和示例。这为研究人员和实践者提供了一个起点，以便他们可以尝试Llama2并将其适应自己的对话式人工智能应用。
- en: '*Figure 1**.8* demonstrates an entity extraction example using the Meta Llama
    2 Chat 13 B model in Amazon Bedrock’s text playground:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 1**.8* 展示了在 Amazon Bedrock 文本游乐场中使用 Meta Llama 2 Chat 13 B 模型进行实体提取的示例：'
- en: '![Figure 1.8 – Entity extraction with the Llama 2 Chat 13B model in Amazon
    Bedrock’s text playground](img/B22045_01_08.jpg)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.8 – 在 Amazon Bedrock 文本游乐场中使用 Llama 2 Chat 13B 模型进行实体提取](img/B22045_01_08.jpg)'
- en: Figure 1.8 – Entity extraction with the Llama 2 Chat 13B model in Amazon Bedrock’s
    text playground
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.8 – 在 Amazon Bedrock 文本游乐场中使用 Llama 2 Chat 13B 模型进行实体提取
- en: Mistral AI
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Mistral AI
- en: '**Mistral AI** focuses on building compute-efficient, trustworthy, and powerful
    AI models. These are currently available in four variants on Amazon Bedrock –
    *Mistral 7B Instruct*, *Mixtral 8X7B Instruct*, *Mistral Large*, and *Mistral
    Small*:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '**Mistral AI** 致力于构建计算高效、值得信赖且强大的 AI 模型。这些模型目前在 Amazon Bedrock 上提供四种变体 – *Mistral
    7B Instruct*、*Mixtral 8X7B Instruct*、*Mistral Large* 和 *Mistral Small*：'
- en: '**Mistral 7B instruct**: This is a 7-billion-parameter dense transformer language
    model designed for instructional tasks. It offers a compelling balance of performance
    and efficiency, delivering robust capabilities suitable for a wide range of use
    cases despite its relatively compact size. Mistral 7B instruct supports processing
    English natural language and code inputs, with an extended 32,000 token context
    window capacity. While more limited than larger models, Mistral 7B instruct provides
    high-quality language understanding, generation, and task execution tailored for
    instructional applications at a lower computational cost.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Mistral 7B 指令**：这是一个为教学任务设计的 70 亿参数稠密 Transformer 语言模型。它提供了性能和效率之间的诱人平衡，尽管其相对紧凑的尺寸，但仍然提供了适用于广泛用例的强大功能。Mistral
    7B 指令支持处理英语自然语言和代码输入，具有扩展的 32,000 令牌上下文窗口容量。尽管比大型模型更有限，但 Mistral 7B 指令提供了针对教学应用的高质量语言理解、生成和任务执行，同时降低了计算成本。'
- en: '**Mixtral 8X7B**: This is a 7-billion-parameter sparse Mixture-of-Experts language
    model that employs a highly parameter-efficient architecture. Despite its relatively
    compact total size, it utilizes 12 billion active parameters for any given input,
    enabling stronger language understanding and generation capabilities compared
    to similarly-sized dense models such as Mistral 7B. This sparse model supports
    processing inputs across multiple natural languages, as well as coding languages,
    catering to a wide range of multilingual and programming use cases. Additionally,
    Mixtral 8X7B maintains an extended context window of 32,000 tokens, allowing it
    to effectively model long-range dependencies within lengthy inputs.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Mixtral 8X7B**：这是一个 70 亿参数稀疏混合专家语言模型，采用高度参数高效的架构。尽管其总体尺寸相对紧凑，但它为任何给定输入利用了
    120 亿个活跃参数，与类似规模的稠密模型（如 Mistral 7B）相比，提供了更强的语言理解和生成能力。这种稀疏模型支持处理多种自然语言以及编码语言，满足广泛的跨语言和编程用例。此外，Mixtral
    8X7B 保持扩展的上下文窗口为 32,000 令牌，使其能够有效地在长输入中建模长距离依赖关系。'
- en: '**Mistral Large**: This is capable of complex reasoning, analysis, text generation,
    and code generation and excels at handling intricate multilingual tasks across
    English, French, Italian, German, and Spanish. Mistral Large supports a maximum
    context window of 32,000 tokens, enabling it to process long-form inputs while
    delivering SOTA performance on language understanding, content creation, and coding
    applications demanding sophisticated multilingual capabilities.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Mistral 大型**：它能够进行复杂推理、分析、文本生成和代码生成，并在处理英语、法语、意大利语、德语和西班牙语的复杂多语言任务方面表现出色。Mistral
    大型支持最大上下文窗口为 32,000 令牌，使其能够处理长文本输入，同时在语言理解、内容创作和需要高级多语言能力的编码应用上提供最先进的性能。'
- en: '**Mistral Small**: This is an advanced language model designed for efficiency
    and affordability. It excels in handling high-volume, low-latency language tasks
    swiftly and cost-effectively. With its specialized capabilities, Mistral Small
    seamlessly tackles coding challenges and operates fluently across multiple languages,
    including English, French, German, Spanish, and Italian. Mistral Small supports
    a maximum context window of 32,000 tokens.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Mistral 小型**：这是一个为效率和成本效益而设计的先进语言模型。它擅长快速且经济高效地处理高容量、低延迟的语言任务。凭借其专业能力，Mistral
    小型无缝地解决编码挑战，并在包括英语、法语、德语、西班牙语和意大利语在内的多种语言中流畅运行。Mistral 小型支持最大上下文窗口为 32,000 令牌。'
- en: '*Figure 1**.9* illustrates the usage of the Mistral Large model with a reasoning
    scenario within Amazon Bedrock’s text playground:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 1.9* 展示了在 Amazon Bedrock 文本沙盒中使用 Mistral Large 模型的推理场景：'
- en: '![Figure 1.9 – Mistral Large in Amazon Bedrock’s text playground](img/B22045_01_09.jpg)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.9 – Amazon Bedrock 文本沙盒中的 Mistral Large](img/B22045_01_09.jpg)'
- en: Figure 1.9 – Mistral Large in Amazon Bedrock’s text playground
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.9 – Amazon Bedrock 文本沙盒中的 Mistral Large
- en: Stability AI – Stable Diffusion
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Stability AI – 稳定扩散
- en: Stable Diffusion was developed by Stability AI to generate highly realistic
    images using diffusion models trained on large datasets. The core technique behind
    Stable Diffusion is called **latent diffusion**, which involves using a forward
    diffusion process to add noise to data over time, and a reverse diffusion process
    to gradually remove noise and reconstruct the original data. In the case of image
    generation, this allows the model to generate new images conditioned on text or
    image prompts provided by the user.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 稳定扩散是由 Stability AI 开发的，用于使用在大数据集上训练的扩散模型生成高度逼真图像。稳定扩散背后的核心技术称为**潜在扩散**，它涉及使用正向扩散过程在数据上逐渐添加噪声，以及反向扩散过程逐渐去除噪声并重建原始数据。在图像生成的案例中，这允许模型根据用户提供的文本或图像提示生成新的图像。
- en: Amazon Bedrock provides **SDXL 0.8** and **SDXL1.0** Stable Diffusion models
    from Stability AI. The Stable Diffusion model aims to generate highly realistic
    images based on the text or image that’s provided as a prompt. SDXL 1.0 is particularly
    impressive due to its large model sizes. Its base model contains over *3.5 billion*
    parameters, while its ensemble pipeline uses two models totaling *6.6 billion*
    parameters. By aggregating results from multiple models, the ensemble approach
    generates even higher-quality images.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Bedrock 提供了 Stability AI 的 **SDXL 0.8** 和 **SDXL 1.0** 稳定扩散模型。稳定扩散模型旨在根据提供的文本或图像提示生成高度逼真的图像。SDXL
    1.0 特别引人注目，因为其模型规模庞大。其基础模型包含超过 *3.5 亿* 个参数，而其集成管道使用两个模型，总参数量达到 *6.6 亿*。通过聚合多个模型的结果，集成方法可以生成更高品质的图像。
- en: Through Amazon Bedrock, developers can leverage Stable Diffusion for a variety
    of image generation tasks. This includes generating images from text descriptions
    (text-to-image), generating new images based on existing images (image-to-image),
    as well as filling in missing areas (inpainting) or extending existing images
    (outpainting). We will look at these in detail in [*Chapter 9*](B22045_09.xhtml#_idTextAnchor171)*.*
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 通过 Amazon Bedrock，开发者可以利用稳定扩散进行各种图像生成任务。这包括从文本描述生成图像（文本到图像）、基于现有图像生成新图像（图像到图像），以及填充缺失区域（修复）或扩展现有图像（扩展）。我们将在[*第
    9 章*](B22045_09.xhtml#_idTextAnchor171)中详细探讨这些内容。
- en: 'Let’s run through a simple example of the Stable Diffusion model in Amazon
    Bedrock’s text playground by using this prompt: `a dog wearing sunglasses, riding
    a bike` `on mars`.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过以下提示在 Amazon Bedrock 文本沙盒中运行一个简单的稳定扩散模型示例：`a dog wearing sunglasses, riding
    a bike on mars`。
- en: '![Figure 1.10 – Image generation with the Stable Diffusion model](img/B22045_01_10.jpg)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.10 – 使用稳定扩散模型生成图像](img/B22045_01_10.jpg)'
- en: Figure 1.10 – Image generation with the Stable Diffusion model
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.10 – 使用稳定扩散模型生成图像
- en: The ability to automatically create visual content has many applications across
    industries such as advertising, media and entertainment, and gaming. In [*Chapter
    9*](B22045_09.xhtml#_idTextAnchor171), we will explore how Stable Diffusion works
    under the hood. We will also discuss best practices and architecture patterns
    for leveraging image generation models in your applications.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 自动创建视觉内容的能力在广告、媒体和娱乐以及游戏等众多行业中都有广泛应用。在[*第 9 章*](B22045_09.xhtml#_idTextAnchor171)中，我们将探讨稳定扩散在底层的工作原理。我们还将讨论在您的应用程序中利用图像生成模型的最佳实践和架构模式。
- en: Evaluating and selecting the right FM
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估和选择合适的 FM
- en: Now that we’ve understood the different types of FMs available in Amazon Bedrock,
    how do we determine which one is best suited for our specific project needs? This
    section will help you learn how to evaluate the model fit for your use case.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了在 Amazon Bedrock 中可用的不同类型的 FM，我们如何确定哪一个最适合我们的特定项目需求？本节将帮助您学习如何评估模型与您的用例的匹配度。
- en: The first step is to clearly define the problem you’re trying to solve or the
    use case you want to build. Get as specific as possible about the inputs, outputs,
    tasks involved, and any other requirements. With a well-defined use case in hand,
    you can research which models have demonstrated capabilities relevant to your
    needs. Narrowing the options upfront based on capabilities will streamline the
    evaluation process.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是明确界定你试图解决的问题或你想要构建的用例。尽可能具体地描述输入、输出、涉及的任务以及其他任何要求。有了明确定义的用例，你可以研究哪些模型已经证明了与你的需求相关的功能。根据功能在最初就缩小选项范围将简化评估过程。
- en: Once you’ve identified some potential candidate models, the next step is to
    examine their performance across standardized benchmarks and use cases. Amazon
    Bedrock provides a capability to evaluate FMs, also called **model evaluation
    jobs**. With model evaluation jobs, users have the option to use either automatic
    model evaluation or evaluation through the human workforce. We will cover Amazon
    Bedrock’s model evaluation in more detail in the upcoming chapters.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你确定了一些潜在的候选模型，下一步就是检查它们在标准化基准和用例中的表现。Amazon Bedrock提供了一种评估FM的能力，也称为**模型评估作业**。通过模型评估作业，用户可以选择使用自动模型评估或通过人工劳动力进行评估。我们将在接下来的章节中更详细地介绍Amazon
    Bedrock的模型评估。
- en: 'In addition, several leaderboards and benchmarks exist today that can help
    with this evaluation, such as the following:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，目前存在几个排行榜和基准，可以帮助进行这种评估，例如以下这些：
- en: Stanford Helm leaderboard for LLMs
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 斯坦福 Helm 排行榜（针对大型语言模型）
- en: HuggingFace’s open leaderboard
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: HuggingFace的开源排行榜
- en: GLUE ([https://gluebenchmark.com/](https://gluebenchmark.com/))
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GLUE ([https://gluebenchmark.com/](https://gluebenchmark.com/))
- en: SuperGLUE ([https://super.gluebenchmark.com/](https://super.gluebenchmark.com/))
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SuperGLUE ([https://super.gluebenchmark.com/](https://super.gluebenchmark.com/))
- en: MMLU ([https://paperswithcode.com/sota/multi-task-language-understanding-on-mmlu](https://paperswithcode.com/sota/multi-task-language-understanding-on-mmlu))
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MMLU ([https://paperswithcode.com/sota/multi-task-language-understanding-on-mmlu](https://paperswithcode.com/sota/multi-task-language-understanding-on-mmlu))
- en: BIG-bench ([https://github.com/google/BIG-bench](https://github.com/google/BIG-bench))
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: BIG-bench ([https://github.com/google/BIG-bench](https://github.com/google/BIG-bench))
- en: Reviewing where each model ranks on tasks related to your use case provides
    an objective measure of its abilities.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 检查每个模型在你相关用例的任务中的排名，可以提供一个对其能力的客观衡量。
- en: Apart from benchmark performance, inspecting each model’s cost per query, processing
    latency, training parameters if fine-tuning is needed, and any other non-functional
    requirements need to be considered. The right model needs to not only achieve
    your technical objectives but also fit within your cost and timeline constraints.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 除了基准性能外，还需要检查每个模型的每查询成本、处理延迟、是否需要微调的训练参数以及任何其他非功能性需求。正确的模型不仅需要实现你的技术目标，还需要符合你的成本和时间限制。
- en: No evaluation is complete without hands-on testing. Take advantage of Amazon
    Bedrock’s text playground or **Amazon Partyrock** to try out candidates on sample
    prompts, text generation tasks, or other example interactions representing your
    intended use case. More details regarding Amazon Bedrock’s text playground and
    Amazon Partyrock will be covered in the next chapter. This mechanism of model
    evaluation allows for a more qualitative assessment of things such as generated
    language quality, ability to maintain context, interpretability of responses,
    and the overall *feel* of interacting with each model.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 没有实际操作测试的评估是不完整的。利用Amazon Bedrock的文本游乐场或**Amazon Partyrock**来尝试在样本提示、文本生成任务或其他代表你预期用例的示例交互中测试候选者。有关Amazon
    Bedrock的文本游乐场和Amazon Partyrock的更多详细信息将在下一章中介绍。这种模型评估机制允许对生成语言质量、保持上下文的能力、响应的可解释性以及与每个模型交互的整体*感觉*等进行更定性的评估。
- en: By thoroughly researching capabilities, performance, and requirements, as well
    as testing multiple options, you’ll be well-equipped to select the right FM that
    provides the best overall fit and solution for your project needs. The right choice
    will help ensure your project’s success.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 通过彻底研究能力、性能和需求，以及测试多个选项，你将能够为选择最适合你项目需求的FM做好准备。正确的选择将有助于确保项目的成功。
- en: Generative AI capabilities of Amazon
  id: totrans-137
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 亚马逊的生成式AI能力
- en: This book is primarily focused on Amazon Bedrock, but we wanted to highlight
    a few other generative AI capabilities offered by Amazon that are being used in
    enterprises for accelerating developer productivity, innovating faster, and solving
    their use cases with ease.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 本书主要关注Amazon Bedrock，但我们想突出亚马逊提供的其他一些生成式AI功能，这些功能正在企业中被用于加速开发者生产力、更快地进行创新以及轻松解决他们的用例。
- en: Amazon SageMaker
  id: totrans-139
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Amazon SageMaker
- en: '**Amazon SageMaker** is Amazon’s fully managed ML platform for building, training,
    and deploying ML models at scale. One of the most powerful features of SageMaker
    is SageMaker Jumpstart, which provides a catalog of pre-trained open source FMs
    that are ready to be deployed and used.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '**Amazon SageMaker** 是亚马逊的全托管机器学习平台，用于大规模构建、训练和部署机器学习模型。SageMaker最强大的功能之一是SageMaker
    Jumpstart，它提供了一系列预训练的开源FM，这些FM已经准备好部署和使用。'
- en: Some examples of FMs available in SageMaker Jumpstart include FLAN-T5 XL, a
    fine-tuned XL version of the T5 transformer model optimized for natural language
    understanding. Additional models, such as Meta Llama2, AI21 Jurassic-2 Ultra,
    and Stable Diffusion models, are also available in SageMaker Jumpstart.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker Jumpstart中可用的FM示例包括FLAN-T5 XL，这是T5转换器模型的微调XL版本，针对自然语言理解进行了优化。此外，Meta
    Llama2、AI21 Jurassic-2 Ultra和Stable Diffusion模型等额外模型也可在SageMaker Jumpstart中找到。
- en: In addition to deploying these pre-trained FMs directly, SageMaker Jumpstart
    provides tools for customizing and fine-tuning select models for specific use
    cases. For instance, users can perform prompt engineering to better control model
    responses by adjusting text prompts. Some models also support reasoning augmentation
    to improve the common-sense reasoning ability of LLMs through question-answering
    tasks. Fine-tuning capabilities allow you to adapt the language models to domain-specific
    datasets.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 除了直接部署这些预训练的FM之外，SageMaker Jumpstart还提供了用于针对特定用例定制和微调选定模型的工具。例如，用户可以通过调整文本提示来执行提示工程，以更好地控制模型响应。一些模型还支持通过问答任务增强推理能力，以改善LLM的常识推理能力。微调功能允许您将语言模型适应特定领域的数据集。
- en: 'This enables engineers and researchers to leverage the power of these generative
    AI models directly from Jumpstart so that they can build novel applications without
    requiring deep expertise in model training. The SageMaker platform handles all
    the heavy lifting of deploying, scaling, and managing ML models. When you open
    SageMaker Jumpstart within SageMaker Studio UI, you will see models offered by
    different model providers. This can be seen in *Figure 1**.11*:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得工程师和研究人员可以直接从Jumpstart利用这些生成式AI模型的力量，从而无需深入的专业知识即可构建新颖的应用程序。SageMaker平台处理了部署、扩展和管理ML模型的所有繁重工作。当您在SageMaker
    Studio UI中打开SageMaker Jumpstart时，您将看到不同模型提供商提供的模型。这可以在*图1.11*中看到：
- en: '![Figure 1.11 – SageMaker Jumpstart](img/B22045_01_11.jpg)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![图1.11 – SageMaker Jumpstart](img/B22045_01_11.jpg)'
- en: Figure 1.11 – SageMaker Jumpstart
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.11 – SageMaker Jumpstart
- en: 'You can choose the model you would like to work with based on your use case
    and deploy it directly to a SageMaker endpoint, or you can fine-tune the model
    with a custom dataset. *Figure 1**.12* shows several open source models offered
    by HuggingFace, on SageMaker Jumpstart, exemplifying the simplicity in SageMaker
    to search for models of your choice suited to a particular task using the search
    bar or **Filters** options:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以根据您的用例选择要工作的模型，并将其直接部署到SageMaker端点，或者您可以使用自定义数据集对模型进行微调。*图1.12*显示了HuggingFace在SageMaker
    Jumpstart上提供的几个开源模型，展示了在SageMaker中通过搜索栏或**过滤器**选项搜索适合特定任务的模型选择的简单性：
- en: '![Figure 1.12 – SageMaker Jumpstart HuggingFace models](img/B22045_01_12.jpg)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![图1.12 – SageMaker Jumpstart HuggingFace模型](img/B22045_01_12.jpg)'
- en: Figure 1.12 – SageMaker Jumpstart HuggingFace models
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.12 – SageMaker Jumpstart HuggingFace模型
- en: Amazon Q
  id: totrans-149
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Amazon Q
- en: '**Amazon Q** is a Generative AI-powered assistant that is built on top of Amazon
    Bedrock, and has been designed to enhance productivity and accelerate decision-making
    across various domains. It can assist users in a multitude of tasks, ranging from
    software development to data analysis and decision making.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '**Amazon Q** 是一个基于Amazon Bedrock构建的生成式AI助手，旨在提高各个领域的生产力和加速决策制定。它可以帮助用户在从软件开发到数据分析再到决策制定的众多任务中。'
- en: Here is an overview of key offerings available with Amazon Q.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是Amazon Q的关键功能概述。
- en: Amazon Q for Business
  id: totrans-152
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Amazon Q for Business
- en: '**Amazon Q for Business** is an enterprise-grade, generative AI-powered assistant
    designed to streamline operations and enhance productivity within organizations.
    With this tool you can access and interact with the company repositories of data
    if you have required permissions, simplifying tasks and accelerating problem-solving
    processes. Here are some key features of Amazon Q for Business:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '**Amazon Q for Business**是一个企业级、由生成式AI驱动的助手，旨在简化组织内的运营并提高生产力。如果您有必要的权限，可以使用此工具访问和交互公司的数据存储库，简化任务并加速问题解决过程。以下是Amazon
    Q for Business的一些关键特性：'
- en: '**Comprehensive Data Integration**: Amazon Q for Business seamlessly connects
    to over 40 popular enterprise data sources, including Amazon S3, Microsoft 365,
    and Salesforce. It ensures secure access to content based on existing user permissions
    and credentials, leveraging single sign-on for a seamless experience.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**全面的数据集成**：Amazon Q for Business可以无缝连接到40多个流行的企业数据源，包括Amazon S3、Microsoft
    365和Salesforce。它确保基于现有的用户权限和凭证安全访问内容，利用单点登录提供无缝体验。'
- en: '**Intelligent Query Handling**: You can ask questions in natural language,
    and Amazon Q for Business will search across all connected data sources, summarize
    relevant information logically, analyze trends, and engage in interactive dialogue.
    This empowers users to obtain accurate and comprehensive answers, eliminating
    the need for time-consuming manual data searches.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**智能查询处理**：您可以用自然语言提问，Amazon Q for Business将跨所有连接的数据源进行搜索，逻辑地总结相关信息，分析趋势，并参与交互式对话。这使用户能够获得准确和全面的答案，消除了耗时的人工数据搜索需求。'
- en: '**Customizable and Secure**: Organizations can tailor Amazon Q for Business
    to their specific needs by configuring administrative guardrails, document enrichment,
    and relevance tuning. This ensures that responses align with company guidelines
    while maintaining robust security and access controls.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可定制和安全的**：组织可以通过配置管理护栏、文档丰富化和相关性调整来定制Amazon Q for Business以满足其特定需求。这确保了响应与公司指南保持一致，同时保持强大的安全和访问控制。'
- en: '**Task Automation**: Amazon Q for Business allows users to streamline routine
    tasks, such as employee onboarding requests or expense reporting, through simple,
    natural language prompts. Additionally, users can create and share task automation
    applications, further enhancing efficiency and productivity.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**任务自动化**：Amazon Q for Business 允许用户通过简单的自然语言提示来简化日常任务，例如员工入职请求或费用报告。此外，用户可以创建和共享任务自动化应用程序，进一步提高效率和生产力。'
- en: You can set up Amazon Q for Business Application in a few clicks as shown in
    *Figure 1**.13*.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以像*图1.13*所示的那样，只需几步即可设置Amazon Q for Business应用程序。
- en: '![Figure 1.13 – Setting up Amazon Q for Business](img/B22045_01_13.jpg)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![图1.13 – 设置Amazon Q for Business](img/B22045_01_13.jpg)'
- en: Figure 1.13 – Setting up Amazon Q for Business
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.13 – 设置Amazon Q for Business
- en: 'For more details on setting up Amazon Q for Business Application, you can check
    the link: [https://docs.aws.amazon.com/amazonq/latest/qbusiness-ug/getting-started.html](https://docs.aws.amazon.com/amazonq/latest/qbusiness-ug/getting-started.html)'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 想要了解更多关于设置Amazon Q for Business应用程序的详细信息，您可以查看以下链接：[https://docs.aws.amazon.com/amazonq/latest/qbusiness-ug/getting-started.html](https://docs.aws.amazon.com/amazonq/latest/qbusiness-ug/getting-started.html)
- en: '![Figure 1.14 – Customize web experience for Amazon Q for Business](img/B22045_01_14.jpg)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![图1.14 – 自定义Amazon Q for Business的网页体验](img/B22045_01_14.jpg)'
- en: Figure 1.14 – Customize web experience for Amazon Q for Business
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.14 – 自定义Amazon Q for Business的网页体验
- en: Once the application is set up, users can customize the web experience for the
    Q business application as shown in *Figure 1**.14*
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦设置好应用，用户就可以像*图1.14*所示的那样自定义Q商业应用的网页体验。
- en: Let us now look at another offering Amazon Q for QuickSight.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看一下Amazon Q for QuickSight的另一个产品。
- en: Amazon Q for QuickSight
  id: totrans-166
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Amazon Q for QuickSight
- en: '**Amazon Q for QuickSight** is built for business users and analysts to unlock
    insights from their data more efficiently. It leverages the capabilities of Generative
    AI to streamline the process of data analysis and visualization. Here are some
    key features of Amazon Q for QuickSight :'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '**Amazon Q for QuickSight**是为商业用户和分析人员设计的，旨在更有效地从数据中提取洞察。它利用生成式AI的能力来简化数据分析可视化的流程。以下是Amazon
    Q for QuickSight的一些关键特性：'
- en: '**Intuitive Storytelling**: With Amazon Q for QuickSight, business users can
    create visually compelling narratives from their data by using simple, natural
    language prompts. These stories can include visuals, images, and text, making
    it easier to communicate insights and align stakeholders.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**直观的故事讲述**：使用 Amazon Q for QuickSight，业务用户可以通过使用简单的自然语言提示从他们的数据中创建引人注目的叙事。这些故事可以包括视觉元素、图像和文本，使传达洞察和协调利益相关者更容易。'
- en: '**Executive Summaries**: Amazon Q for QuickSight can automatically generate
    executive summaries that highlight the most important trends and statistics from
    your dashboards. This feature saves time by providing a quick snapshot of key
    insights, eliminating the need to browse through multiple visuals.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**执行摘要**：Amazon Q for QuickSight 可以自动生成执行摘要，突出显示来自您的仪表板的最重要趋势和统计数据。此功能通过提供关键洞察的快速快照来节省时间，消除了浏览多个视觉元素的需求。'
- en: '**Natural Language Q&A**: Business users can confidently answer questions about
    their data using natural language queries. Amazon Q can understand vague or general
    questions, provide alternative perspectives, and offer context through narrative
    summaries.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自然语言问答**：业务用户可以使用自然语言查询自信地回答有关其数据的问题。Amazon Q 可以理解模糊或一般性的问题，提供不同的观点，并通过叙事摘要提供上下文。'
- en: '**Accelerated Dashboard Building**: Analysts can significantly reduce the time
    required to build dashboards by describing the desired visualizations using natural
    language. Amazon Q can interpret these prompts and generate the corresponding
    visuals in seconds.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**加速仪表板构建**：分析师可以通过使用自然语言描述所需的可视化来显著减少构建仪表板所需的时间。Amazon Q 可以解释这些提示并在几秒钟内生成相应的视觉元素。'
- en: Amazon Q for Developer
  id: totrans-172
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Amazon Q for Developer
- en: '**Amazon Q for Developer** streamlines the software development lifecycle on
    AWS. Here are some key features of Amazon Q for Developers:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '**Amazon Q for Developer** 简化了 AWS 上的软件开发生命周期。以下是 Amazon Q for Developers 的一些关键功能：'
- en: '**Intuitive Development Assistance**: Within IDEs, Amazon Q can provide real-time
    code suggestions, generate new code snippets, and offer guidance on software development
    best practices. This accelerates the coding process and enhances productivity.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**直观的开发辅助**：在 IDE 中，Amazon Q 可以提供实时代码建议，生成新的代码片段，并提供软件开发最佳实践的指导。这加速了编码过程并提高了生产力。'
- en: '**Code Transformation**: Amazon Q can help you upgrade and modernize your legacy
    codebases by automatically transforming and optimizing your code to the latest
    language versions and frameworks. This capability ensures your applications remain
    up-to-date and secure.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**代码转换**：Amazon Q 可以通过自动转换和优化您的代码到最新的语言版本和框架，帮助您升级和现代化您的遗留代码库。此功能确保您的应用程序保持最新和安全。'
- en: '**Troubleshooting and Maintenance**: Amazon Q can assist you in diagnosing
    and resolving errors, bugs, and issues within your AWS applications. It can also
    help you understand and manage your AWS resources more efficiently, minimizing
    the need to navigate through complex consoles.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**故障排除和维护**：Amazon Q 可以帮助您诊断和解决 AWS 应用程序中的错误、bug 和问题。它还可以帮助您更有效地理解和管理工作负载，最小化在复杂控制台中导航的需求。'
- en: '**Cost Optimization**: By analyzing your AWS cost data, Amazon Q can provide
    valuable insights into your cloud spending patterns, helping you identify cost-saving
    opportunities and optimize your cloud infrastructure for better cost efficiency.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**成本优化**：通过分析您的 AWS 成本数据，Amazon Q 可以提供有关您的云支出模式的宝贵见解，帮助您识别节省成本的机会，并优化您的云基础设施以实现更好的成本效率。'
- en: '*Figure 1**.15* and *Figure 1**.16* illustrate an example of Amazon Q Developer
    for aiding in productivity gains for software engineers or developers.'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 1**.15* 和 *图 1**.16* 展示了 Amazon Q Developer 的一个示例，用于帮助软件工程师或开发者提高生产力。'
- en: '![Figure 1.15 – Amazon Q Developer](img/B22045_01_15.jpg)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.15 – Amazon Q Developer](img/B22045_01_15.jpg)'
- en: Figure 1.15 – Amazon Q Developer
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.15 – Amazon Q Developer
- en: '![Figure 1.16 – Amazon Q Developer Lambda function](img/B22045_01_16.jpg)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.16 – Amazon Q Developer Lambda 函数](img/B22045_01_16.jpg)'
- en: Figure 1.16 – Amazon Q Developer Lambda function
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.16 – Amazon Q Developer Lambda 函数
- en: With Amazon Q, developers can streamline their workflows, from planning and
    development to testing, deployment, and maintenance, ultimately enabling them
    to deliver high-quality applications faster and with greater confidence.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Amazon Q，开发者可以简化他们的工作流程，从规划和发展到测试、部署和维护，最终使他们能够更快、更有信心地交付高质量的应用程序。
- en: Generative AI use cases with Amazon Bedrock
  id: totrans-184
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Amazon Bedrock 上的生成式 AI 用例
- en: 'Since the advent of generative AI, numerous organizations have benefited from
    the potential applications of this transformative technology in achieving their
    business objectives. Many of these organizations, which include Accenture, Adidas,
    Intuit, and Salesforce, have successfully developed prototypes and even have deployed
    production-ready generative AI systems using Amazon Bedrock. Across various industries,
    we have seen numerous compelling use cases for generative AI with Amazon Bedrock.
    Let’s learn more about some of these industries in detail:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 自从生成 AI 的出现以来，众多组织已经从这种变革性技术的潜在应用中受益，以实现其商业目标。这些组织包括埃森哲、阿迪达斯、Intuit 和 Salesforce，它们已经成功开发了原型，甚至已经使用
    Amazon Bedrock 部署了生产就绪的生成 AI 系统。在各个行业中，我们已经看到了许多令人信服的 Amazon Bedrock 生成 AI 用例。让我们更详细地了解一些这些行业：
- en: '**Finance**: In the financial services sector, organizations have been working
    on use cases such as classifying and categorizing huge corpus of legal documents,
    developing systems to select optimal funding and investment plans for customers,
    providing insights and simplified summaries and Q&As of complex financial documents,
    as well as detecting fraudulent activities such as forged signatures and tampered
    invoices. Additionally, organizations are utilizing Amazon Bedrock to understand
    market trends and customer behavior, aiding in informed decision-making processes.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**金融**: 在金融服务领域，组织一直在研究诸如对大量法律文件进行分类和分类、为客户选择最佳融资和投资计划、提供复杂金融文件的见解和简化摘要以及问答，以及检测伪造签名和篡改发票等欺诈活动等用例。此外，组织正在利用
    Amazon Bedrock 来理解市场趋势和客户行为，帮助进行明智的决策过程。'
- en: '**Healthcare**: The healthcare industry has witnessed significant investment
    in developing generative AI applications with Amazon Bedrock. At the time of writing,
    AWS HealthScribe has been announced, which is powered by Amazon Bedrock ([https://aws.amazon.com/healthscribe/](https://aws.amazon.com/healthscribe/)).
    These applications address a wide range of use cases, such as automating medical
    claims and adjudication processes, extracting valuable insights from health documents
    and medical research papers, and generating summaries of patient-doctor interactions.
    By leveraging Amazon Bedrock, healthcare providers are aiming to enhance patient
    care and drive innovation in the field.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**医疗保健**: 医疗保健行业在开发 Amazon Bedrock 的生成 AI 应用方面投入了大量资金。在撰写本文时，已宣布 AWS HealthScribe，它由
    Amazon Bedrock 驱动（[https://aws.amazon.com/healthscribe/](https://aws.amazon.com/healthscribe/)）。这些应用涵盖了广泛的使用案例，例如自动化医疗索赔和裁决流程，从健康文件和医学研究论文中提取有价值的见解，以及生成患者-医生互动的摘要。通过利用
    Amazon Bedrock，医疗保健提供者旨在提升患者护理并推动该领域的创新。'
- en: '**Media and entertainment**: In the media and entertainment industry, organizations
    are actively exploring the diverse applications with Amazon Bedrock. These include
    generating narratives and storylines in sports and broadcasting, creating captions,
    images, and animations for storytelling, as well as providing personalized recommendations
    for TV shows, movies, and other forms of entertainment. By harnessing the capabilities
    of generative AI with Amazon Bedrock, media and entertainment companies aim to
    enhance the user experience, create engaging content, and stay ahead of the competition.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**媒体和娱乐**: 在媒体和娱乐行业，组织正在积极探索 Amazon Bedrock 的多样化应用。这包括在体育和广播中生成叙事和剧情，为故事讲述创建字幕、图像和动画，以及为电视节目、电影和其他形式的娱乐提供个性化推荐。通过利用
    Amazon Bedrock 生成 AI 的能力，媒体和娱乐公司旨在提升用户体验，创造引人入胜的内容，并保持竞争优势。'
- en: These are just a few examples of the numerous use cases that various industries
    are working on. In later chapters, we will understand architectural patterns in
    building industry-specific use cases through Amazon Bedrock.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是众多行业中正在研究的众多用例中的几个例子。在后续章节中，我们将了解通过 Amazon Bedrock 构建行业特定用例的架构模式。
- en: Summary
  id: totrans-190
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'In this chapter, we explored the various facets of the generative AI landscape:
    from understanding language models and the development of various NLP techniques
    to the invention of current SOTA transformer models. Then, we covered industrial
    challenges in building generative AI applications at scale and how Amazon Bedrock
    is seamlessly tackling those challenges.'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了生成式AI领域的各个方面：从理解语言模型和开发各种自然语言处理（NLP）技术到当前最先进的（SOTA）Transformer模型的发明。然后，我们讨论了在规模上构建生成式AI应用时遇到的工业挑战，以及亚马逊Bedrock如何无缝地解决这些挑战。
- en: Furthermore, we explored various FMs offered by Amazon Bedrock and provided
    insights into how you can take advantage of various frameworks and tools to evaluate
    and select the right FM for your use case. We also looked at alternative generative
    AI capabilities offered by Amazon, including Amazon SageMaker and Amazon Q. We
    concluded this chapter by uncovering a few generative AI use cases with Amazon
    Bedrock in financial services, healthcare, and media and entertainment.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们探讨了亚马逊Bedrock提供的各种功能模块（FMs），并提供了如何利用各种框架和工具来评估和选择适合您用例的正确FMs的见解。我们还研究了亚马逊提供的其他生成式AI能力，包括亚马逊SageMaker和亚马逊Q。我们通过揭示亚马逊Bedrock在金融服务、医疗保健和媒体娱乐领域的几个生成式AI用例来结束本章。
- en: In the next chapter, we will discover several techniques to access Amazon Bedrock
    and dive into various APIs via serverless services. Furthermore, we will learn
    about a hands-on approach toward invoking Bedrock FMs that can be integrated into
    enterprise-grade applications.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将发现几种访问亚马逊Bedrock的技术，并通过无服务器服务深入了解各种API。此外，我们将学习一种实际的方法来调用Bedrock FMs，这些FM可以集成到企业级应用中。
