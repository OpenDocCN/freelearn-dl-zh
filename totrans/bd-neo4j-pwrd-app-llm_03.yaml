- en: '3'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Building a Foundational Understanding of Knowledge Graph for Intelligent Applications
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we looked at what RAG is and at a few simple examples
    of how we can implement RAG flow, along with LLMs. In this chapter, we will take
    a look at what knowledge graphs are and how graphs can make **Retrieval-Augmented
    Generation** (**RAG**) more effective. We will explore how to model knowledge
    graphs and how Neo4j can be used for this purpose. We will look at how data modeling
    with the Neo4j data persistence approach can help build more powerful knowledge
    graphs. We will also look at data store persistence approaches, from **Relational
    Database Management Systems** (**RDBMSs**) to Neo4j knowledge graphs, to get a
    better understanding of data using various data models.
  prefs: []
  type: TYPE_NORMAL
- en: We will embark on an exciting journey to understand how the fusion of RAG models
    and Neo4j’s robust graph database capabilities enables the creation of intelligent
    applications that leverage structured knowledge bases for enhanced performance
    and results.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we are going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the importance of graph data modeling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Combining the power of RAG and Neo4j knowledge graphs with GraphRAG
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enhancing knowledge graph
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before we dive into the practical aspects of building a knowledge graph for
    RAG integration with Neo4j, it is essential to set up the necessary tools and
    environments. Here are the technical requirements for this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Neo4j database**: You can use Neo4j Desktop for a local setup or Neo4j Aura
    for a cloud-based solution. Download Neo4j Desktop from the Neo4j download center:
    [https://neo4j.com/download/](https://neo4j.com/download/). For Neo4j Aura, visit
    Neo4j Aura: [https://neo4j.com/product/neo4j-graph-database/](https://neo4j.com/product/neo4j-graph-database/).
    Neo4j offers two primary cloud-based services – AuraDB and AuraDS:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**AuraDB** is a fully managed graph database service tailored for developers
    building intelligent applications. It supports flexible schemas, native storage
    of relationships, and efficient querying with the Cypher language. AuraDB offers
    a free tier, enabling users to explore graph data without incurring costs. Learn
    more about AuraDB at [https://neo4j.com/product/auradb/](https://neo4j.com/product/auradb/).'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**AuraDS** is a fully managed Neo4j Graph Data Science instance that can be
    used to build data science applications. You can learn more about it at [https://neo4j.com/docs/aura/graph-analytics/](https://neo4j.com/docs/aura/graph-analytics/).'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**DB Browser for SQLite**: This tool is used to query SQLite databases easily
    [https://sqlitebrowser.org/](https://sqlitebrowser.org/).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cypher query language**: Before starting with this chapter, you will need
    to familiarize yourself with Cypher, Neo4j’s query language. Neo4j provides excellent
    Cypher tutorials. If you are unfamiliar with Cypher, Neo4j provides excellent
    tutorials and fundamental courses on GraphAcademy ([https://graphacademy.neo4j.com/](https://graphacademy.neo4j.com/))
    to help you get started. You can also read this book to learn about Cypher in
    detail: Graph Data Processing with Cypher ([https://www.packtpub.com/en-us/product/graph-data-processing-with-cypher-9781804611074](https://www.packtpub.com/en-us/product/graph-data-processing-with-cypher-9781804611074)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Python environment**: Python 3.8 or higher is recommended. Ensure you have
    it installed. You can download it from the official Python website [https://www.python.org/downloads/](https://www.python.org/downloads/).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Neo4j Python Driver**: This allows you to interact with your Neo4j database
    from Python. Install it using `pip`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**GitHub repository**: All the code and resources for this chapter are available
    in the following GitHub repository: [https://github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs](https://github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs).
    Navigate to the `ch3` folder for the specific content related to this chapter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ensure you have all these tools and libraries installed and configured before
    proceeding. This setup will enable you to follow along with the examples and exercises
    seamlessly.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the importance of graph data modeling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we go ahead with looking at how **GraphRAG flow** works with Neo4j, let
    us take a step back and understand how we can model knowledge graphs. We will
    take some simple data and try to look at how we model that data in RDBMSs and
    graphs. We will also see how this modeling differs depending on how we see that
    data.
  prefs: []
  type: TYPE_NORMAL
- en: Graphs force us to think in different ways and see the data from different perspectives
    depending on what we are trying to solve. While this might seem like a problem,
    it is actually opens a lot of doors. For a long time, we have been taught to think
    of the RDBMS storage approach in terms of **Entity-Relationship** (**ER**) diagrams.
    This approach was good for representing/persisting data when there were limitations
    in the technology, and storage costs were very high. With technologies evolving
    and hardware becoming cheaper, new avenues have opened and new approaches to model
    data are possible. Graphs are well suited to take advantage of this.
  prefs: []
  type: TYPE_NORMAL
- en: To think about new ways of modeling data, we might have to unlearn some of the
    ways we are used to representing data using ER diagrams. While this seems simple,
    in reality, it might be a bit difficult. The learning and unlearning process is
    similar to in the neural plasticity prism goggles experiment, depicted in the
    following figure.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.1 — Neural plasticity prism goggles experiment](img/B31107_03_1.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.1 — Neural plasticity prism goggles experiment
  prefs: []
  type: TYPE_NORMAL
- en: The experiment involves wearing prism goggles to perform a simple task. It takes
    some time for the mind to adjust to the shift in vision to perform the task correctly.
    When the participant takes off the goggles, it takes some time to be able to perform
    the same task again. It is the same with data modeling. We might have to unlearn
    a few of the approaches we used to rely on before we can build a better graph
    data model. You can read more about this experiment at [https://sfa.cems.umn.edu/neural-plasticity-prism-goggle-experiment](https://sfa.cems.umn.edu/neural-plasticity-prism-goggle-experiment).
  prefs: []
  type: TYPE_NORMAL
- en: We will take a look at how we consume data in real life to understand whether
    there are any other approaches that can help us in building a good graph data
    model.
  prefs: []
  type: TYPE_NORMAL
- en: For example, let us consider a library or a bookstore to understand how our
    data or information consumption drives how the books are laid out. In a library,
    the books are laid out by category and last name of the author. This is similar
    to how we leverage indexes to find data. But there may be other sections at the
    entrance of the library that highlight new releases and popular books. This is
    done to make sure people can find these quickly. Trying to model these aspects
    in an RDBMS is difficult. But the graph database approach in Neo4j makes it quite
    easy to do this by leveraging multiple labels. This enables graph databases to
    help us build a data model that helps with the easy and efficient consumption
    of data. With graphs, we might have to try and change our thought process and
    try a few different data modeling approaches. Our initial approaches may not be
    completely correct, but we need to keep adjusting the data models to get to an
    acceptable data model that works for us. With RDBMSs and other technologies, the
    data model is rigid, and not getting it right can have a huge impact. This is
    where Neo4j stands out. Its optional flexible schema approach helps us get started
    with a data model that might not be optimal in the beginning, but we can tune
    it incrementally without needing to start from scratch.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will take some small, simple data and look at data modeling with an RDBMS
    and graph. The data we will be trying to model looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'A person with the following required details:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Five rentals the person has lived at, in the following format:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: While this seems simple, it is enough for us to understand the nuances of how
    this data can be represented in an RDBMS and graph.
  prefs: []
  type: TYPE_NORMAL
- en: 'These are the questions we would like to answer using this data:'
  prefs: []
  type: TYPE_NORMAL
- en: What is the latest address the person named *John Doe* is living at?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is the first address the person named *John Doe* lived at?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is the third address the person named *John Doe* lived at?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s take a look at how this data can be modeled in an RDBMS.
  prefs: []
  type: TYPE_NORMAL
- en: RDBMS data modeling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we will take a look at the RDBMS data modeling aspects of
    the sample data we defined previously. The following figure represents the data
    model as an ER diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.2 — ER diagram](img/B31107_03_2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.2 — ER diagram
  prefs: []
  type: TYPE_NORMAL
- en: There are three tables in this data model. The `Person` table contains the person
    details. The `Address` table contains the address details. The `Person_Address`
    table contains the rental details along with references to the `Person` and `Address`
    tables. We use this join table to represent the rental details, to avoid duplicating
    the data of `Person` or `Address` entities. We need to be extra sure of the details
    when we are building these data models, as changing them can be quite time-consuming,
    depending on how much we are changing. If we are splitting a table into multiple
    tables, then the data migration can be quite a task.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can use this tutorial to create the SQLite database: [https://datacarpentry.org/sql-socialsci/02-db-browser.html](https://datacarpentry.org/sql-socialsci/02-db-browser.html).
    We will use that SQLite database to load the data and validate queries to answer
    the questions we defined before.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following SQL script creates the tables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The next SQL script inserts the data into the tables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Once we load the data, it will look like this.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.3 — Data stored in an RDBMS](img/B31107_03_3.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.3 — Data stored in an RDBMS
  prefs: []
  type: TYPE_NORMAL
- en: 'We will now see how we can query data from the RDBMS:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Query 1 – Get the latest address**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let’s take a look at the following SQL query to answer the first question:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: From the query, we can see that we are relying on the end column value to be
    null to determine which is the latest address. This is the logic to determine
    what the last address is in the SQL query.
  prefs: []
  type: TYPE_NORMAL
- en: '**Query 2****– Get the first address**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We will take a look at the SQL query to answer the second question:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: From the query, we can see that we are relying on the search-sort-filter pattern
    to get to the data we want, with the logic in the SQL query.
  prefs: []
  type: TYPE_NORMAL
- en: '**Query 3 – Get the third address**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We will take a look at SQL query to answer the third question:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Again, in this query also we can see that we are relying on the pattern *Search-Sort-Filter*
    to get to the data we wanted.
  prefs: []
  type: TYPE_NORMAL
- en: We will now look at how this data can be modeled with graphs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Graph data modeling: basic approach'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For illustration purposes, we will use the most common and simplest way to model
    this data in a graph.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.4 — Basic graph data model](img/B31107_03_4.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.4 — Basic graph data model
  prefs: []
  type: TYPE_NORMAL
- en: 'This aligns with how we normally express the information in English:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Person** *lives at* **Address**'
  prefs: []
  type: TYPE_NORMAL
- en: In this sentence, the **nouns** are represented as **nodes**, and the **verb**
    is represented as a **relationship**. This data model approach is pretty simple
    and almost resembles the ER diagram of the RDBMS data model. The only difference
    here is that the join table that represents the rental is modeled as a relationship.
    The advantage of this type of data persistence is that it reduces the index lookup
    cost. In RDBMSs, the biggest cost in terms of data retrieval is the join table’s
    index lookup cost. As the data size increases, that lookup cost keeps on increasing.
    We can reduce that cost with this approach.
  prefs: []
  type: TYPE_NORMAL
- en: '**Note**'
  prefs: []
  type: TYPE_NORMAL
- en: You can use this tutorial to create the Neo4j database if you are using Neo4j
  prefs: []
  type: TYPE_NORMAL
- en: 'Desktop: [https://neo4j.com/docs/desktop-manual/current/operations/create-dbms/](https://neo4j.com/docs/desktop-manual/current/operations/create-dbms/).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Alternatively, you can use this tutorial to create a database in the cloud:
    [https://neo4j.com/docs/aura/auradb/getting-started/create-database/](https://neo4j.com/docs/aura/auradb/getting-started/create-database/).
    There is a free option available. This would be optimal for those who may not
    or do not want to install Neo4j Desktop locally. Neo4j Aura is a fully managed
    graph-database-as-a-service solution.'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at the following graph queries to understand this.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following Cypher script sets up the indexes for faster data load and retrieval.
    This can be thought of as a schema:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: This Cypher script creates two unique constraints to make sure we don’t have
    duplicate **Person** and **Address** nodes. We also added an index to speed up
    the person lookup using the name.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the schema is set up, we can use this Cypher script to load the data into
    Neo4j:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Once we load the data, it looks like this in the graph.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.5 — Representation of Person Rentals using graph data modeling,
    basic approach](img/B31107_03_5.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.5 — Representation of Person Rentals using graph data modeling, basic
    approach
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we will create the Cypher queries analogous to the retrievals we performed  with
    the RDBMS queries in the previous section:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Query 1 – Get the latest address**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following Cypher query gets us the latest address:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'If we look at this query, it is much simpler than the SQL query we saw earlier.
    Still, the result depends on how we mark the last address, by not having the `end`
    property set on the relationship. So, the logic to know what the last address
    is still part of the query, like in the SQL query. We can see that we are checking
    the values in the relationship and trying to use indexes, as shown in the following
    code, on the join table:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Just avoiding these indexes itself can get us better performance.
  prefs: []
  type: TYPE_NORMAL
- en: '**Query 2 – Get the first address**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This Cypher fetches us the first address:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: From the query, we can see that we are relying on the search-sort-filter pattern
    to get to the data we want, similar to the SQL query. The logic to determine what
    the first address is part of the Cypher query.
  prefs: []
  type: TYPE_NORMAL
- en: '**Query 3 – Get the third address**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This Cypher gets us the third address:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Similar to the previous query, we had to rely on search-sort-filter to get to
    the data we wanted. The logic to determine what the third address is part of the
    Cypher query.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will dive into a more nuanced approach to graph data modeling.
  prefs: []
  type: TYPE_NORMAL
- en: 'Graph data modeling: advanced approach'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will look at this data differently and build a data model. This model is
    influenced by how we consume the data.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.6 — Representation of Person Rentals using graph data modeling,
    consumption approach](img/B31107_03_6.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.6 — Representation of Person Rentals using graph data modeling, consumption
    approach
  prefs: []
  type: TYPE_NORMAL
- en: At first look, this looks closer to the RDBMS ER diagram. We have **Person**,
    **Address**, and **Rental** nodes. That’s where the similarity ends. We can see
    that **Person** is connected to the **Rental** node via a **FIRST** or **LATEST**
    relationship. **Rental** may have a **NEXT** relationship to another **Rental**
    node. The **Rental** node is connected to an **Address**, too. The model might
    look a bit complex. Once we load the data and see how it is connected, it makes
    more sense.
  prefs: []
  type: TYPE_NORMAL
- en: 'This Cypher script sets up the indexes for faster data load and retrieval:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: We can see the indexes are the same as in the previous model. We have not added
    any indexes or constraints to the **Rental** node.
  prefs: []
  type: TYPE_NORMAL
- en: 'This Cypher script loads the data into Neo4j:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Once the data is loaded, it will look like this in the graph (*Figure 3.7*).
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.7 — Representation of Person Rentals with a Rental sequence graph](img/B31107_03_7.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.7 — Representation of Person Rentals with a Rental sequence graph
  prefs: []
  type: TYPE_NORMAL
- en: 'We can see that the data stored in the graph is way different from before.
    **Person** is connected to only the first and last rentals. Each of those rentals
    from first to last is connected via a **NEXT** relationship:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Query 1 – Get the latest address**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This Cypher query gets us the latest address:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: We can see that this query is very different from the previous graph and SQL
    queries. In the previous graph model, the Cypher query was similar to the SQL
    query in determining what the last address is. Here, the query looks similar to
    a sentence in English (*Person’s latest address*).
  prefs: []
  type: TYPE_NORMAL
- en: While the query looks simpler and easier to understand for most people, is it
    worth representing the data in this way? In this scenario, we will use more storage
    to be able to represent data in an elaborate manner. Let’s profile the queries
    from the initial graph data model to this data model and see whether there is
    any advantage.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.8 — Basic graph model versus advanced graph model – query 1 profiles](img/B31107_03_8.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.8 — Basic graph model versus advanced graph model – query 1 profiles
  prefs: []
  type: TYPE_NORMAL
- en: From the **query profiles**, we can see the initial graph data model took 18
    **db hits** (accesses) and 312 bytes of memory to perform the operation. The current
    graph data model took 12 db hits and 312 bytes of memory to perform the operation.
    We can see the new data model is able to perform this query more optimally. As
    the data grows, the previous graph data model will take more time to perform the
    operation and the db hits will grow linearly with the number of relationships
    the person has. With the current data model, it would stay relatively constant.
  prefs: []
  type: TYPE_NORMAL
- en: Now let us look at query 2.
  prefs: []
  type: TYPE_NORMAL
- en: '**Query 2 – Get the first address**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This Cypher query gets us to the first address:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: We can see that this query looks exactly like the previous one, except for the
    relationship we are traversing. We are not using the *search-sort-filter* pattern
    anymore here. This is the biggest advantage of this data model. This model also
    makes it easy for us to use a graph as a structure to retrieve the data. Also,
    it means the logic to determine what data we are looking at is not coded into
    the query in the form of some property comparisons. Let us compare the query profiles
    to see whether this gives us any advantage.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.9 — Basic graph model versus advanced graph model – query 2 profiles](img/B31107_03_9.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.9 — Basic graph model versus advanced graph model – query 2 profiles
  prefs: []
  type: TYPE_NORMAL
- en: We can see the query execution plan for the initial graph data model is larger
    and more complex than the current data model. With the initial graph data model,
    it took 19 db hits and 1,020 bytes of memory to perform the operation. With the
    current data model, the plan is almost similar to query 1\. It took 12 db hits
    and 312 bytes of memory. We can see that the ordering is causing us to use more
    memory and will consume more CPU cycles. As **Person** is connected to more addresses,
    the initial graph data model will take more memory and db hits as performance
    will slowly degrade. With the current data model, the performance will remain
    relatively constant.
  prefs: []
  type: TYPE_NORMAL
- en: '**Query 3 – Get the third address**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This Cypher query gets us the third address:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: We can see from the query that the way it is written is to traverse to the first
    rental and skip the next rental to get to the third rental. This is how we normally
    look at data and it feels natural to express the query this way to retrieve the
    data. Again, we are not relying on the *search-sort-filter* pattern. Let us compare
    the query profiles to see whether this gives us any advantage.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.10 — Basic graph model versus advanced graph model – query 3 profiles](img/B31107_03_10.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.10 — Basic graph model versus advanced graph model – query 3 profiles
  prefs: []
  type: TYPE_NORMAL
- en: We can see from these profiles that the current data model query profile is
    a bit more involved than the previous queries. The initial graph data model took
    19 db hits and 1,028 bytes to perform the operation. The current graph data model
    took 16 db hits and 336 bytes to perform the operation.
  prefs: []
  type: TYPE_NORMAL
- en: '**Note**'
  prefs: []
  type: TYPE_NORMAL
- en: '**Query profiling** is the best way to understand how the query works.  If
    we are not happy with the query performance, profiling helps us understand which
    areas of the query execution we want to improve or change for better performance.
    You can read more about this at [https://neo4j.com/docs/cypher-manual/current/planning-and-tuning/](https://neo4j.com/docs/cypher-manual/current/planning-and-tuning/).'
  prefs: []
  type: TYPE_NORMAL
- en: From analyzing the queries and data models, we can see that taking a fresher
    look at how the data models are defined can have a huge impact in terms of performance
    and cost to perform the same operations.
  prefs: []
  type: TYPE_NORMAL
- en: Another advantage of the current data model is that if we do want to track how
    the rentals are working from an address perspective, we can add just another relationship,
    say, **NEXT_RENTAL**, between the rentals for the same address. This would give
    us a different perspective of the same data. Trying to represent the data like
    this in an RDBMS or other data persistence layers would be difficult. This is
    where Neo4j with its flexibility to be able to persist relationships to avoid
    the join index cost and optional schema is better suited to build knowledge graphs.
  prefs: []
  type: TYPE_NORMAL
- en: A good graph data model makes the **retriever in RAG flow** more effective.
    It makes retrieving relevant data faster and easier, as we have explored here.
  prefs: []
  type: TYPE_NORMAL
- en: We will take a look at how we can use knowledge graphs as part of RAG flow next.
  prefs: []
  type: TYPE_NORMAL
- en: Combining the power of RAG and Neo4j knowledge graphs with GraphRAG
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we looked at the **retriever**, which is the heart
    of RAG flows. The retriever leverages data stores to retrieve relevant information
    to provide to LLMs to get the best response to our question. Retrievers can work
    with various data stores as needed. The data store capabilities can greatly determine
    how useful, quick, and effective the information retrieved is. This is where graphs
    play a great role. That’s how **GraphRAG** came into being.
  prefs: []
  type: TYPE_NORMAL
- en: '**Note**'
  prefs: []
  type: TYPE_NORMAL
- en: 'You can read more about GraphRAG and how it is effective at [https://www.microsoft.com/en-us/research/blog/graphrag-unlocking-llm-discovery-on-narrative-private-data/](https://www.microsoft.com/en-us/research/blog/graphrag-unlocking-llm-discovery-on-narrative-private-data/)
    and [https://microsoft.github.io/graphrag/](https://microsoft.github.io/graphrag/).
    For a comprehensive understanding of GraphRAG, you can refer to Microsoft’s research
    paper titled *From Local to Global: A Graph RAG Approach to Query-Focused Summarization*
    ([https://arxiv.org/abs/2404.16130](https://arxiv.org/abs/2404.16130)). Additionally,
    Microsoft has made the GraphRAG project available on GitHub ([https://github.com/microsoft/graphrag](https://github.com/microsoft/graphrag)),
    providing resources and tools for implementing this approach.'
  prefs: []
  type: TYPE_NORMAL
- en: The Neo4j graph database excels at persisting the data as a property graph with
    nodes and relationships. This makes it easy to store and retrieve data in an intuitive
    manner and serves the data stores for RAG retrievers. This approach allows for
    more accurate, contextually aware, and reliable AI-driven applications.
  prefs: []
  type: TYPE_NORMAL
- en: We will now build a GraphRAG flow that combines the power of RAG and knowledge
    graphs for improved LLM responses.
  prefs: []
  type: TYPE_NORMAL
- en: 'GraphRAG: enhancing RAG models with Neo4j'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous chapter, we discussed the flow of information in a chat application
    with a RAG model (refer to *Figure 3.5*).
  prefs: []
  type: TYPE_NORMAL
- en: Now we will see how this workflow can be augmented to generate improved responses
    for the chat application. *Figure 3.11* shows the workflow of GraphRAG, where
    a user’s prompt is processed through an LLM API, retrieving relevant information
    from Neo4j, and then combined with the prompt before being sent to an LLM API.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.11 — Workflow of GraphRAG](img/B31107_03_11.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.11 — Workflow of GraphRAG
  prefs: []
  type: TYPE_NORMAL
- en: The LLM API generates a response using both the prompt and the relevant information
    from the Neo4j knowledge graph, providing the user with accurate and contextually
    enriched results. By combining the capabilities of Neo4j and RAG models, GraphRAG
    enhances relevance with more domain context.
  prefs: []
  type: TYPE_NORMAL
- en: Let us build a simple graph to showcase this GraphRAG flow.
  prefs: []
  type: TYPE_NORMAL
- en: Building a knowledge graph for RAG integration
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For this example, we will use limited data for demonstration purposes to build
    the graph, focusing on movies and their plots.
  prefs: []
  type: TYPE_NORMAL
- en: 'Python code example: Setting up a knowledge graph in Neo4j'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'By following along with the provided code example, you will learn how to set
    up a Neo4j database, define nodes and relationships, and perform basic queries
    using Cypher:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Set up the Neo4j database**: Before running the code, ensure you have access
    to a Neo4j database. You can use either of the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Neo4j Desktop**: Install and run it locally (download Neo4j Desktop: [https://neo4j.com/download/](https://neo4j.com/download/))'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Neo4j AuraDB**: This is a cloud-hosted option (learn more about AuraDB at
    [https://neo4j.com/product/auradb/](https://neo4j.com/product/auradb/))'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Start your database instance and note the connection credentials (e.g., URI,
    username, and password).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Install the necessary Python libraries**: You will need the following Python
    libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Neo4j Python Driver**: To interact with the database'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Pandas**: For handling data structures and analysis'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Install these libraries using the following command:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '**Connect to the database and set up the knowledge graph**: Once your Neo4j
    database is running and the required Python libraries are installed, you can use
    the following Python script to set up a simple knowledge graph. In this example,
    we will create a graph for IMDb movies and their plots, with nodes representing
    movies and plots and relationships indicating which plot belongs to which movie.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Note**'
  prefs: []
  type: TYPE_NORMAL
- en: We will not be using any external dataset, rather, we will be using a hardcoded
    data set to showcase the graph model and the GraphRAG flow. We will be exploring
    full-fledged data loading and the GraphRAG flow in *Chapters 4* and *5*. This
    example is to showcase the GraphRAG flow aspects only.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will first build a simple graph. We will be using this simple graph to showcase
    where and how Neo4j fits in the GraphRAG flow:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the `GraphDatabase` library and define Neo4j connectivity and credentials:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let us create a few nodes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The next step is to create relationships:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'If we visualize the data that we created, it would look as shown in *Figure
    3.12*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![Figure 3.12 — Sample graph showing movies and plots](img/B31107_03_12.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.12 — Sample graph showing movies and plots
  prefs: []
  type: TYPE_NORMAL
- en: '5\. We will now retrieve the data using a Cypher query:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '6\. If we run this, we can see the output as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: You can find the complete code at [https://github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/blob/main/ch3/imdb_kg.py](https://github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/blob/main/ch3/imdb_kg.py).
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have built the basic graph, let us use it in the GraphRAG flow.
  prefs: []
  type: TYPE_NORMAL
- en: Integrating RAG with your Neo4j knowledge graph
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To integrate RAG models with Neo4j, you need to configure the models to query
    the graph database. This typically involves setting up an API or a middleware
    layer that facilitates communication between the RAG models and Neo4j.
  prefs: []
  type: TYPE_NORMAL
- en: 'An example integration workflow is provided here:'
  prefs: []
  type: TYPE_NORMAL
- en: '**User input:** The user provides a prompt. In the following code example,
    the prompt is predefined in the script as an example (`"The Matrix"`). Users can
    modify this to test other movies or prompts:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**Query generation**: The prompt is processed, and a Cypher query is generated
    to retrieve relevant information from Neo4j. For example, the query might fetch
    the plot of the movie mentioned in the prompt:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**Data retrieval**: The Cypher query is executed, and the relevant data (e.g.,
    the plot of *The Matrix*) is fetched from the knowledge graph:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**RAG model processing**: The retrieved data is combined with the original
    prompt and passed to the RAG model for further processing, allowing the model
    to generate a richer and context-aware response:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**Response generation**: The RAG model generates a response using the enriched
    prompt (e.g., “The plot of *The Matrix* is: ‘A computer hacker learns from mysterious
    rebels about the true nature of his reality and his role in the war against its
    controllers.’”):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The following is a sample output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'The full version of the code in this chapter is placed at: [https://github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/blob/main/ch3/neo4j_rag.py](https://github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/blob/main/ch3/neo4j_rag.py).'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: With an understanding of how to build and query a basic knowledge graph, as
    well as how to integrate RAG models with Neo4j, you are now equipped with the
    foundational skills needed to create intelligent, context-aware applications.
    Next, we will take a look at a few approaches to enhance knowledge graphs. We
    will just be introducing these concepts here and will be exploring them in more
    detail upcoming chapters for building intelligent applications.
  prefs: []
  type: TYPE_NORMAL
- en: Enhancing knowledge graphs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We looked at building a graph and GraphRAG flow in the previous section. What
    we have looked at is a simple graph. There are a few approaches we can follow
    to make knowledge graphs more effective. Let us take a look at these approaches.
    We will be using these approaches to enhance our knowledge graphs in the upcoming
    chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Ontology development**: An ontology can define the structure and the content
    of the graph. By having the ontology persisted in the graph, we might be able
    to explain the data and its connectivity in a more intuitive way. This ensures
    that the graph follows best practices and aligns with your domain-specific needs.
    Ontologies also help in maintaining uniformity across different datasets and in
    extending the graph over time. In [*Chapter 5*](Chapter_05.xhtml#_idTextAnchor038),
    we would be enhancing the simple movie knowledge graph we created in this chapter   If
    you want to learn more about ontologies, you can take a look at [https://neo4j.com/blog/ontologies-in-neo4j-semantics-and-knowledge-graphs/](https://neo4j.com/blog/ontologies-in-neo4j-semantics-and-knowledge-graphs/).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Graph Data Science (GDS)**: While data loaded as a graph can be effective
    as a knowledge graph, there are a few other approaches that can make this graph
    much more effective. For example, we can perform some link prediction or perform
    community detection to create additional relationships between nodes that are
    inferred based on the existing data in the graph. This can help us enhance the
    intelligence stored in the graph to give us better answers when querying. We will
    be leveraging the KNN similarity and community detection algorithms in [*Chapter
    10*](Chapter_10.xhtml#_idTextAnchor066) to enhance the graph to get more intelligence.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We have looked at a few approaches to enhance knowledge graphs. Let us now summarize
    our understanding of the concepts we have looked at.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we explored the foundational aspects of building a knowledge
    graph for RAG integration using Neo4j. We began by understanding the importance
    of Neo4j knowledge graphs and their role in GraphRAG. We also set up a Neo4j database,
    created nodes and relationships, and performed queries to retrieve relevant information.
  prefs: []
  type: TYPE_NORMAL
- en: 'We also covered the integration workflow of RAG models with Neo4j. You are
    now ready to move on to *Part 2*, *Integrating Haystack with Neo4j: A Practical
    Guide to Building AI-Powered Search*. In the next part, we will build on the foundation
    laid in this chapter and explore how to integrate Haystack with Neo4j to create
    powerful, AI-driven search capabilities. This next step will naturally extend
    your knowledge and skills, enabling you to develop sophisticated search applications
    that leverage the strengths of both Haystack and Neo4j.'
  prefs: []
  type: TYPE_NORMAL
