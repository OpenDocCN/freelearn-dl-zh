- en: '6'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Using Stable Diffusion Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When we start using Stable Diffusion models, we will immediately encounter different
    kinds of model files and will need to know how to convert a model file to the
    desired format.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we are going to get more familiar with Stable Diffusion model
    files, covering how to load models from the Hugging Face repository using model
    IDs. We’ll also provide sample code to load `safetensors` and `.ckpt` model files
    shared by the open source community.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Loading the Diffusers model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Loading model checkpoints from safetensors and ckpt files
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using CKPT and safetensors files with Diffusers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Model safety checker
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Converting checkpoint model files to the Diffusers format
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Stable Diffusion XL
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of this chapter, you will have learned about the Stable Diffusion
    model file types and how to convert and load model files to a format that can
    be loaded with Diffusers.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before you start, make sure you have the `safetensors` package installed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The `safetensors` Python package offers a simple and efficient way to access,
    store, and share tensors securely.
  prefs: []
  type: TYPE_NORMAL
- en: Loading the Diffusers model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Instead of downloading model files manually, the Hugging Face Diffusers package
    provides a convenient way to access open source model files from a string-type
    model ID like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: When the preceding code is executed, if Diffusers can’t find the model files
    that are denoted by the model ID, the package will automatically reach out to
    the Hugging Face repository to download the model files and store them in a cache
    folder for next time.
  prefs: []
  type: TYPE_NORMAL
- en: 'By default, the cache files will be stored in the following places:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Windows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`C:\Users\user_name\.cache\huggingface\hub`'
  prefs: []
  type: TYPE_NORMAL
- en: 'Linux:'
  prefs: []
  type: TYPE_NORMAL
- en: '`\``home\user_name\.cache\huggingface\hub`'
  prefs: []
  type: TYPE_NORMAL
- en: Using the default cache path is fine in the beginning, however, if your system
    driver is less than 512 GB, you will soon find those model files are eating up
    storage space. To avoid running out of storage, we may need to plan the model
    storage in advance. Diffusers provides a parameter for us to specify a custom
    path for storing the cached weight files.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the preceding sample code with one more parameter, `cache_dir`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: By specifying this `cache_dir` parameter, all auto-downloaded model and configuration
    files will be stored in the new location instead of eating up the system disk
    drive.
  prefs: []
  type: TYPE_NORMAL
- en: You might also notice that the sample code specifies a `torch_dtytpe` parameter
    to tell Diffusers to use `torch.float16`. By default, PyTorch uses `torch.float32`
    for matrix multiplications. For model inference, or in other words, at the stage
    of using Stable Diffusion to generate images, we can use the `float16` type to
    not only increase the speed by about 100% but also save GPU memory with almost
    unnoticeable difference.
  prefs: []
  type: TYPE_NORMAL
- en: Usually, using models from Hugging Face is easy and safe. Hugging Face implements
    a safety checker to ensure the uploaded model files do not contain any malicious
    code that may harm your computer.
  prefs: []
  type: TYPE_NORMAL
- en: Nevertheless, we can still use manually downloaded model files with Diffusers.
    Next, we are going to load various model files from the local disk.
  prefs: []
  type: TYPE_NORMAL
- en: Loading model checkpoints from safetensors and ckpt files
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The complete model files are also called **checkpoint** data. If you read an
    article or document talking about downloading a checkpoint, they are talking about
    a Stable Diffusion model file.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are many types of checkpoints, such as `.ckpt` files, `safetensors` files,
    and `diffusers` files:'
  prefs: []
  type: TYPE_NORMAL
- en: '`.ckpt` is the most basic file format and is compatible with most Stable Diffusion
    models. However, they are also the most vulnerable to malicious attacks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`safetensors` is a newer file format that is designed to be more secure than
    `.ckpt` files. The `safetensors` format is better in terms of security, speed,
    and usability compared with `.ckpt`. Safetensors has several features to prevent
    code execution:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Restricted data types**: Only specific data types, such as integers and tensors,
    are allowed to be stored. This eliminates the possibility of including code within
    the saved data.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Hashing**: Each chunk of data is hashed, and the hash is stored alongside
    the data. Any modification to the data would change the hash, making it instantly
    detectable.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Isolation**: Data is stored in an isolated environment, preventing interaction
    with other programs, and protecting your system from potential exploits.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Diffusers files are the latest file format specifically crafted for seamless
    integration with the `Diffusers` library. This format boasts top-notch security
    features and ensures compatibility with all Stable Diffusion models. Unlike traditional
    compression into a single file, the Diffusers format takes the form of a folder
    that encompasses both weights and configuration files. Moreover, the model files
    contained within these folders adhere to the `safetensors` format.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When we use the Diffusers auto download function, Diffusers will store the files
    in the Diffusers format.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we are going to load up a Stable Diffusion model in `ckpt` or `safetensors`
    format.
  prefs: []
  type: TYPE_NORMAL
- en: Using ckpt and safetensors files with Diffusers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Diffusers community is actively enhancing the functionality. At the time
    of writing, we can easily load `.ckpt` or `safetensors` checkpoint files using
    the `Diffusers` package.
  prefs: []
  type: TYPE_NORMAL
- en: The following code can be used to load and use a `safetensors` or `.ckpt` checkpoint
    file.
  prefs: []
  type: TYPE_NORMAL
- en: 'Load the `safetensors` model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Load the `.ckpt` model with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: You are not reading the wrong code; we can load both `safetensors` and `.ckpt`
    model files with the same function – `from_single_file`. Next, let’s take a look
    at the safety checker.
  prefs: []
  type: TYPE_NORMAL
- en: Turning off the model safety checker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: By default, the Diffusers pipeline will check the output result with a safety
    checker model to ensure the generated result does not include any NSFW, violent,
    or unsafe content. In certain cases, the safety checker may trigger false alarms
    and produce empty images (completely black images). There are several GitHub issue
    discussions about the safety checker [11]. In the test stage, we can temporarily
    turn off the safety checker.
  prefs: []
  type: TYPE_NORMAL
- en: 'To turn off the safety checker when loading the model using the model ID, run
    the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that the parameter to turn off the safety checker is different when we
    are loading the model from a `safetensors` or `.ckpt` file. Instead of using `safety_checker`,
    we should use `load_safety_checker` as shown in the following sample code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: You should be able to use `load_safety_checker = False` in the `from_pretrained`
    function to disable the safety checker.
  prefs: []
  type: TYPE_NORMAL
- en: The safety checker is an open source machine learning model from CompVis – Computer
    Vision and Learning LMU Munich ([https://github.com/CompVis](https://github.com/CompVis)),
    built based on CLIP [9][10], called **Stable Diffusion Safety** **Checker** [3].
  prefs: []
  type: TYPE_NORMAL
- en: While we can load a model in a single file, in some cases, we will need to convert
    a `.ckpt` or `safetensors` model file to the Diffusers folder structure. Next,
    let’s see how we can convert model files to the Diffusers format.
  prefs: []
  type: TYPE_NORMAL
- en: Converting the checkpoint model file to the Diffusers format
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Loading checkpoint model data from a `.ckpt` or `safetensors` file is slow compared
    with the Diffusers format because every time we load a `.ckpt` or `safetensors`
    file, Diffusers will unpack and convert the file to the Diffusers format. To save
    the conversion every time we load a model file, we may consider converting checkpoint
    files to the Diffusers format.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use the following code to convert a `.ckpt` file to the Diffusers format:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'To convert a `safetensors` file to the Diffusers format, simply change the
    `from_safetensors` parameter to `True` as shown in the following sample code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'If you have tried asking a search engine to find a solution to do the conversion,
    from some corners of the internet, you may see a solution that uses a script called
    `convert_original_stable_diffusion_to_diffusers.py`. The script is located in
    the Diffusers GitHub repository: [https://github.com/huggingface/diffusers/tree/main/scripts](https://github.com/huggingface/diffusers/tree/main/scripts).
    The script works well. If you look at the code of the script, the script uses
    the same code presented previously.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To use the converted model file, simply use the `from_pretrained` function
    to load the `local` folder (instead of the model ID) this time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: You should see a cute puppy image generated by the preceding code. Next, let’s
    load Stable Diffusion XL models.
  prefs: []
  type: TYPE_NORMAL
- en: Using Stable Diffusion XL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Stable Diffusion XL** (**SDXL**) is a model from Stability AI. Slightly different
    compared to previous models, SDXL is designed to be a two-stage model. We will
    need the base model to generate an image and can leverage a second, refiner model
    to refine an image, as shown in *Figure 6**.1*. The refiner model is optional:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.1: SDXL, a two-model pipeline](img/B21263_06_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.1: SDXL, a two-model pipeline'
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 6**.1* shows that to generate images of the best quality from the SDXL
    model, we will need to use the base model to generate a raw image, output as a
    128x128 latent, and then use the refiner model to enhance it.'
  prefs: []
  type: TYPE_NORMAL
- en: Before trying out the SDXL model, please ensure you have at least 15 GB of VRAM,
    otherwise, you may see a `CUDA out of memory` error right before the refiner model
    outputs the image. You can also use the optimization methods from [*Chapter* *5*](B21263_05.xhtml#_idTextAnchor097),to
    build a custom pipeline to move the model out of VRAM whenever possible.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the steps to load up an SDXL model:'
  prefs: []
  type: TYPE_NORMAL
- en: Download the base model `safetensors` file [6]. You don’t need to download all
    files from the model repository. At the time of writing this, the checkpoint name
    is `sd_xl_base_1.0.safetensors`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Download the refiner model `safetensors` file [7]. We can also let the Diffusers
    pipeline download the `safetensors` file for us by providing the model ID.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Next, we will initialize the base and refiner models from the `safetensors`
    files:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Or, we can initialize the base and refiner models using model ID:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s generate the base image in latent space (the 4x128x128 middle layer latent):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE57]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE58]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE60]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE61]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE63]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE64]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE65]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE66]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note that at the end of the preceding code, we moved `base_pipe` out of VRAM
    by using `base_pipe.to("cpu")` and `torch.cuda.empty_cache()`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Load the refiner model to VRAM and use the base image in latent space to generate
    the final image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE68]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE69]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE70]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE71]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE72]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE73]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE74]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE75]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE76]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE77]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE78]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE79]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The result will be similar to the one shown in *Figure 6**.2*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 6.2: Image generated by SDXL – a cat in a spacesuit](img/B21263_06_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.2: Image generated by SDXL – a cat in a spacesuit'
  prefs: []
  type: TYPE_NORMAL
- en: The detail and quality are way better than the one rendered by Stable Diffusion
    1.5\. While this model is relatively new at the time of writing, in the near future,
    more mixed checkpoint models and Low-Rank Adapters (LoRAs) will be available.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter mainly focused on the usage of the Stable Diffusion model. We can
    utilize a model from Hugging Face by using its model ID. Additionally, widely
    distributed open source models are available on community websites such as CIVITAI
    [4], where you can download numerous model resources. These model files are typically
    in the `.ckpt` or `safetensors` file format.
  prefs: []
  type: TYPE_NORMAL
- en: The chapter covered the distinction between these model files and using checkpoint
    model files directly from the `Diffusers` package. Furthermore, it offered a solution
    to convert standalone model checkpoint files to the Diffusers format for faster
    model loading.
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, this chapter also covered how to load and use SDXL’s two-model pipelines.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Hugging Face Load safetensors: [https://huggingface.co/docs/diffusers/using-diffusers/using_safetensors](https://huggingface.co/docs/diffusers/using-diffusers/using_safetensors)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'pickle — Python object serialization: [https://docs.python.org/3/library/pickle.html](https://docs.python.org/3/library/pickle.html)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Stable Diffusion Safety Checker: [https://huggingface.co/CompVis/stable-diffusion-safety-checker](https://huggingface.co/CompVis/stable-diffusion-safety-checker'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: )
  prefs: []
  type: TYPE_NORMAL
- en: 'civitai: [https://www.civitai.com](https://www.civitai.com'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: )
  prefs: []
  type: TYPE_NORMAL
- en: 'stability.ai: [https://stability.ai/](https://stability.ai/)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'stable-diffusion-xl-base-1.0: [https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0](https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: )
  prefs: []
  type: TYPE_NORMAL
- en: 'stable-diffusion-xl-refiner-1.0: [https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-1.0](https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-1.0'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: )
  prefs: []
  type: TYPE_NORMAL
- en: 'safetensors GitHub repository: [https://github.com/huggingface/safetensors](https://github.com/huggingface/safetensors)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Alec Radford et al, Learning Transferable Visual Models From Natural Language
    Supervision: [https://arxiv.org/abs/2103.00020](https://arxiv.org/abs/2103.00020)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'OpenAI CLIP GitHub repository: [https://github.com/openai/CLIP](https://github.com/openai/CLIP)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Issues with safety checker: [https://github.com/huggingface/diffusers/issues/845](https://github.com/huggingface/diffusers/issues/845),
    [https://github.com/huggingface/diffusers/issues/3422](https://github.com/huggingface/diffusers/issues/3422)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Part 2 – Improving Diffusers with Custom Features
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In Part 1, we explored the fundamental concepts and techniques behind diffusers,
    setting the stage for their application in various domains. Now, it’s time to
    take our understanding to the next level by delving into advanced customization
    options that can significantly enhance the capabilities of these powerful models.
  prefs: []
  type: TYPE_NORMAL
- en: The chapters in this section are designed to equip you with the knowledge and
    skills necessary to optimize and extend your diffusers, unlocking new possibilities
    for creative expression and problem-solving. From refining performance and managing
    VRAM usage to leveraging community-driven resources and exploring innovative techniques
    such as textual inversion, we’ll cover a range of topics that will help you push
    the boundaries of what’s possible with diffusers.
  prefs: []
  type: TYPE_NORMAL
- en: Through the following chapters, you’ll learn how to overcome limitations, tap
    into the collective wisdom of the community, and unlock new features that will
    elevate your work with diffusers. Whether you’re seeking to improve efficiency,
    explore new artistic avenues, or simply stay at the forefront of innovation, the
    custom features and techniques presented in this part of the book will provide
    you with the tools and inspiration you need to succeed.
  prefs: []
  type: TYPE_NORMAL
- en: 'This part contains the following chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 7*](B21263_07.xhtml#_idTextAnchor136)*, Optimizing Performance and
    VRAM Usage*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 8*](B21263_08.xhtml#_idTextAnchor153)*, Using Community-Shared LoRAs*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 9*](B21263_09.xhtml#_idTextAnchor178)*, Using Textual Inversion*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 10*](B21263_10.xhtml#_idTextAnchor197)*, Unlocking 77 Token Limitations
    and Enabling Prompt Weighting*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 11*](B21263_11.xhtml#_idTextAnchor214)*, Image Restore and Super-Resolution*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 12*](B21263_12.xhtml#_idTextAnchor240)*, Scheduled Prompt Parsing*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
