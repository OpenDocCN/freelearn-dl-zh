- en: '2'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '2'
- en: RAG Embedding Vector Stores with Deep Lake and OpenAI
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Deep Lake和OpenAI构建RAG嵌入向量存储
- en: 'There will come a point in the execution of your project where complexity is
    unavoidable when implementing RAG-driven generative AI. Embeddings transform bulky
    structured or unstructured texts into compact, high-dimensional vectors that capture
    their semantic essence, enabling faster and more efficient information retrieval.
    However, we will inevitably be faced with a storage issue as the creation and
    storage of document embeddings become necessary when managing increasingly large
    datasets. You could ask the question at this point, why not use keywords instead
    of embeddings? And the answer is simple: although embeddings require more storage
    space, they capture the deeper semantic meanings of texts, with more nuanced and
    context-aware retrieval compared to the rigid and often-matched keywords. This
    results in better, more pertinent retrievals. Hence, our option is to turn to
    vector stores in which embeddings are organized and rapidly accessible.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在执行你的项目过程中，将不可避免地遇到在实现由RAG驱动的生成式AI时复杂性增加的情况。嵌入将庞大的结构化或非结构化文本转换为紧凑的高维向量，这些向量捕捉了它们的语义本质，从而实现了更快、更高效的信息检索。然而，随着管理越来越大的数据集时文档嵌入的创建和存储变得必要，我们不可避免地会面临存储问题。此时，你可能会问，为什么不使用关键词而不是嵌入呢？答案是简单的：虽然嵌入需要更多的存储空间，但它们捕捉了文本的更深层次的语义含义，与僵化且经常匹配的关键词相比，具有更细腻和上下文感知的检索。这导致了更好的、更相关的检索结果。因此，我们的选择是转向向量存储，其中嵌入被组织和快速访问。
- en: We will begin this chapter by exploring how to go from raw data to an Activeloop
    Deep Lake vector store via loading OpenAI embedding models. This requires installing
    and implementing several cross-platform packages, which leads us to the architecture
    of such systems. We will organize our RAG pipeline into separate components because
    breaking down the RAG pipeline into independent parts will enable several teams
    to work on a project simultaneously. We will then set the blueprint for a RAG-driven
    generative AI pipeline. Finally, we will build a three-component RAG pipeline
    from scratch in Python with Activeloop Deep Lake, OpenAI, and custom-built functions.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先通过加载OpenAI嵌入模型，从原始数据探索如何进入Activeloop Deep Lake向量存储。这需要安装和实现几个跨平台包，这使我们了解了这些系统的架构。我们将把我们的RAG管道组织成独立的组件，因为将RAG管道分解成独立的部分将使多个团队能够同时在一个项目上工作。然后，我们将为RAG驱动的生成式AI管道制定蓝图。最后，我们将使用Activeloop
    Deep Lake、OpenAI和自定义构建的函数从头开始构建一个三组件的RAG管道。
- en: This coding journey will take us into the depths of cross-platform environment
    issues with packages and dependencies. We will also face the challenges of chunking
    data, embedding vectors, and loading them on vector stores. We will augment the
    input of a GPT-4o model with retrieval queries and produce solid outputs. By the
    end of this chapter, you will fully understand how to leverage the power of embedded
    documents in vector stores for generative AI.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 这段编码之旅将带我们深入到跨平台环境问题，包括包和依赖项。我们还将面临数据分块、嵌入向量和在向量存储上加载它们的挑战。我们将通过检索查询增强GPT-4o模型的输入，并产生可靠的输出。到本章结束时，你将完全理解如何利用向量存储中嵌入文档的力量为生成式AI提供支持。
- en: 'To sum up, this chapter covers the following topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，本章涵盖了以下主题：
- en: Introducing document embeddings and vector stores
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍文档嵌入和向量存储
- en: How to break a RAG pipeline into independent components
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何将RAG管道分解成独立组件
- en: Building a RAG pipeline from raw data to Activeloop Deep Lake
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从原始数据构建RAG管道到Activeloop Deep Lake
- en: Facing the environmental challenge of cross-platform packages and libraries
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 面对跨平台包和库的环境挑战
- en: Leveraging the power of LLMs to embed data with an OpenAI embedding model
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用LLM的强大功能，使用OpenAI嵌入模型嵌入数据
- en: Querying an Activeloop Deep Lake vector store to augment user inputs
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查询Activeloop Deep Lake向量存储以增强用户输入
- en: Generative solid augmented outputs with OpenAI GPT-4o
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用OpenAI GPT-4o生成可靠的增强输出
- en: Let’s begin by learning how to go from raw data to a vector store.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从学习如何将原始数据转换为向量存储开始。
- en: From raw data to embeddings in vector stores
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从原始数据到向量存储中的嵌入
- en: Embeddings convert any form of data (text, images, or audio) into real numbers.
    Thus, a document is converted into a vector. These mathematical representations
    of documents allow us to calculate the distances between documents and retrieve
    similar data.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入将任何形式的数据（文本、图像或音频）转换为实数。因此，文档被转换为向量。这些文档的数学表示允许我们计算文档之间的距离并检索相似的数据。
- en: 'The raw data (books, articles, blogs, pictures, or songs) is first collected
    and cleaned to remove noise. The prepared data is then fed into a model such as
    OpenAI `text-embedding-3-small`, which will embed the data. Activeloop Deep Lake,
    for example, which we will implement in this chapter, will break a text down into
    pre-defined chunks defined by a certain number of characters. The size of a chunk
    could be 1,000 characters, for instance. We can let the system optimize these
    chunks, as we will implement them in the *Optimizing chunking* section of the
    next chapter. These chunks of text make it easier to process large amounts of
    data and provide more detailed embeddings of a document, as shown here:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 原始数据（书籍、文章、博客、图片或歌曲）首先被收集和清理以去除噪声。准备好的数据随后被输入到如OpenAI `text-embedding-3-small`这样的模型中，该模型将嵌入数据。例如，Activeloop
    Deep Lake，我们将在本章中实现，将文本分解为预定义的块，这些块由一定数量的字符定义。一个块的大小可以是1,000个字符，例如。我们可以让系统优化这些块，正如我们将在下一章的*优化块分割*部分中实现的那样。这些文本块使得处理大量数据变得更容易，并为文档提供更详细的嵌入，如图所示：
- en: '![A diagram of a number and embedding  Description automatically generated
    with medium confidence](img/B31169_02_01.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![一个数字和嵌入的图  描述由中等置信度自动生成](img/B31169_02_01.png)'
- en: 'Figure 2.1: Excerpt of an Activeloop vector store dataset record'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.1：Activeloop向量存储数据集记录的摘录
- en: 'Transparency has been the holy grail in AI since the beginning of parametric
    models, in which the information is buried in learned parameters that produce
    black box systems. RAG is a game changer, as shown in *Figure 2.1*, because the
    content is fully traceable:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 透明度自从参数模型开始以来一直是人工智能的圣杯，在这些模型中，信息被隐藏在产生黑盒系统的学习参数中。RAG是一个变革者，如图*2.1*所示，因为内容是完全可追溯的：
- en: 'Left side (Text): In RAG frameworks, every piece of generated content is traceable
    back to its source data, ensuring the output’s transparency. The OpenAI generative
    model will respond, taking the augmented input into account.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 左侧（文本）：在RAG框架中，每一条生成的内容都可以追溯到其源数据，确保输出的透明度。OpenAI的生成模型将做出响应，考虑到增强输入。
- en: 'Right side (Embeddings): Data embeddings are directly visible and linked to
    the text, contrasting with parametric models where data origins are encoded within
    model parameters.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 右侧（嵌入）：数据嵌入直接可见并与文本相关联，与参数模型形成对比，在参数模型中数据来源被编码在模型参数中。
- en: Once we have our text and embeddings, the next step is to store them efficiently
    for quick retrieval. This is where *vector stores* come into play. A vector store
    is a specialized database designed to handle high-dimensional data like embeddings.
    We can create datasets on serverless platforms such as Activeloop, as shown in
    *Figure 2.2*. We can create and access them in code through an API, as we will
    do in the *Building a RAG pipeline* section of this chapter.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了文本和嵌入，下一步就是高效地存储它们以便快速检索。这正是*向量存储*发挥作用的地方。向量存储是一种专门为处理高维数据（如嵌入）而设计的数据库。我们可以在如Activeloop这样的无服务器平台上创建数据集，如图*2.2*所示。我们可以通过API在代码中创建和访问它们，正如我们在本章的*构建RAG管道*部分中所做的那样。
- en: '![A screenshot of a computer  Description automatically generated](img/B31169_02_02.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![计算机屏幕截图  描述由中等置信度自动生成](img/B31169_02_02.png)'
- en: 'Figure 2.2: Managing datasets with vector stores'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.2：使用向量存储管理数据集
- en: Another feature of vector stores is their ability to retrieve data with optimized
    methods. Vector stores are built with powerful indexing methods, which we will
    discuss in the next chapter. This retrieving capacity allows a RAG model to quickly
    find and retrieve the most relevant embeddings during the generation phase, augment
    user inputs, and increase the model’s ability to produce high-quality output.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 向量存储的另一个特点是它们能够使用优化方法检索数据。向量存储是通过强大的索引方法构建的，我们将在下一章中讨论。这种检索能力允许RAG模型在生成阶段快速找到并检索最相关的嵌入，增强用户输入，并提高模型生成高质量输出的能力。
- en: We will now see how to organize a RAG pipeline that goes from data collection,
    processing, and retrieval to augmented-input generation.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将看到如何组织一个RAG管道，该管道从数据收集、处理和检索到增强输入生成。
- en: Organizing RAG in a pipeline
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在管道中组织RAG
- en: 'A RAG pipeline will typically collect data and prepare it by cleaning it, for
    example, chunking the documents, embedding them, and storing them in a vector
    store dataset. The vector dataset is then queried to augment the user input of
    a generative AI model to produce an output. However, it is highly recommended
    not to run this sequence of RAG in one single program when it comes to using a
    vector store. We should at least separate the process into three components:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: RAG 管道通常会收集数据并通过清理等方式准备它，例如，将文档分块、嵌入并存储在向量存储数据集中。然后查询这个向量数据集来增强生成式 AI 模型的用户输入以产生输出。然而，当使用向量存储时，强烈建议不要在一个单独的程序中运行这个
    RAG 序列。我们至少应该将这个过程分为三个组件：
- en: Data collection and preparation
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据收集和准备
- en: Data embedding and loading into the dataset of a vector store
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据嵌入并将它们加载到向量存储的数据集中
- en: Querying the vectorized dataset to augment the input of a generative AI model
    to produce a response
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查询向量化数据集以增强生成式 AI 模型的输入以产生响应
- en: 'Let’s go through the main reasons for this component approach:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看采用这种组件方法的主要原因：
- en: '**Specialization**, which will allow each member of a team to do what they
    are best at, either collecting and cleaning data, running embedding models, managing
    vector stores, or tweaking generative AI models.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**专业化**，将允许团队中的每个成员都做他们最擅长的事情，无论是收集和清理数据、运行嵌入模型、管理向量存储还是调整生成式 AI 模型。'
- en: '**Scalability**, making it easier to upgrade separate components as the technology
    evolves and scale the different components with specialized methods. Storing raw
    data, for example, can be scaled on a different server than the cloud platform,
    where the embedded vectors are stored in a vectorized dataset.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可扩展性**，使得在技术发展和不同组件的扩展上使用专门的方法变得更加容易。例如，存储原始数据可以在存储嵌入向量的不同服务器上进行扩展，而不是在云平台上。'
- en: '**Parallel development**, which allows each team to advance at their pace without
    waiting for others. Improvements can be made continually on one component without
    disrupting the processes of the other components.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**并行开发**，允许每个团队根据自己的节奏前进，无需等待他人。可以在不影响其他组件流程的情况下，对单个组件进行持续改进。'
- en: '**Maintenance** is component-independent. One team can work on one component
    without affecting the other parts of the system. For example, if the RAG pipeline
    is in production, users can continue querying and running generative AI through
    the vector store while a team fixes the data collection component.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**维护**是组件独立的。一个团队可以专注于一个组件，而不会影响系统的其他部分。例如，如果 RAG 管道正在生产中，用户可以通过向量存储继续查询和运行生成式
    AI，同时一个团队修复数据收集组件。'
- en: '**Security** concerns and privacy are minimized because each team can work
    separately with specific authorization, access, and roles for each component.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全性**和隐私问题最小化，因为每个团队都可以分别使用特定的授权、访问和角色来处理每个组件。'
- en: As we can see, in real-life production environments or large-scale projects,
    it is rare for a single program or team to manage end-to-end processes. We are
    now ready to draw the blueprint of the RAG pipeline that we will build in Python
    in this chapter.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，在现实生活中的生产环境或大型项目中，单个程序或团队管理端到端流程的情况很少见。我们现在已经准备好绘制我们将在此章中用 Python 构建的
    RAG 管道的蓝图。
- en: A RAG-driven generative AI pipeline
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 由 RAG 驱动的生成式 AI 管道
- en: 'Let’s dive into what a real-life RAG pipeline looks like. Imagine we’re a team
    that has to deliver a whole system in just a few weeks. Right off the bat, we’re
    bombarded with questions like:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入了解一个真实的 RAG 管道是什么样子。想象一下，我们是一个必须在几周内交付整个系统的团队。一开始，我们就被各种问题淹没，比如：
- en: Who’s going to gather and clean up all the data?
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 谁将收集并清理所有数据？
- en: Who’s going to handle setting up OpenAI’s embedding model?
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 谁将负责设置 OpenAI 的嵌入模型？
- en: Who’s writing the code to get those embeddings up and running and managing the
    vector store?
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 谁将编写代码来启动那些嵌入并管理向量存储？
- en: Who’s going to take care of implementing GPT-4 and managing what it spits out?
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 谁将负责实施 GPT-4 并管理其输出的内容？
- en: Within a few minutes, everyone starts looking pretty worried. The whole thing
    feels overwhelming—like, seriously, who would even think about tackling all that
    alone?
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 几分钟内，每个人都开始显得有些担忧。整个事情感觉压倒性——真的，谁会想到独自应对所有这些？
- en: 'So here’s what we do. We split into three groups, each of us taking on different
    parts of the pipeline, as shown in *Figure 2.3*:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们这样做。我们分成三个小组，每个人都承担管道的不同部分，如图 *图 2.3* 所示：
- en: '![A diagram of a pipeline  Description automatically generated](img/B31169_02_03.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![管道图  自动生成的描述](img/B31169_02_03.png)'
- en: 'Figure 2.3: RAG pipeline components'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.3：RAG管道组件
- en: 'Each of the three groups has one component to implement:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 三个小组中的每一个都需要实现一个组件：
- en: '**Data Collection and Prep (D1 and D2)**: One team takes on collecting the
    data and cleaning it.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据收集和准备（D1和D2）**：一个团队负责收集数据并进行清理。'
- en: '**Data Embedding and Storage (D2 and D3)**: Another team works on getting the
    data through OpenAI’s embedding model and stores these vectors in an Activeloop
    Deep Lake dataset.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据嵌入和存储（D2和D3）**：另一个团队负责通过OpenAI的嵌入模型获取数据，并将这些向量存储在Activeloop Deep Lake数据集中。'
- en: '**Augmented Generation (D4, G1-G4, and E1)**: The last team handles the big
    job of generating content based on user input and retrieval queries. They use
    GPT-4 for this, and even though it sounds like a lot, it’s actually a bit easier
    because they aren’t waiting on anyone else—they just need the computer to do its
    calculations and evaluate the output.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**增强生成（D4，G1-G4和E1）**：最后一个团队负责根据用户输入和检索查询生成内容。他们使用GPT-4来完成这项工作，尽管听起来工作量很大，但实际上要容易一些，因为他们不需要等待其他人——他们只需要计算机进行计算和评估输出。'
- en: Suddenly, the project doesn’t seem so scary. Everyone has their part to focus
    on, and we can all work without being distracted by the other teams. This way,
    we can all move faster and get the job done without the hold-ups that usually
    slow things down.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 突然间，这个项目看起来不再那么可怕。每个人都有自己的部分要关注，我们都可以专注于自己的工作，而不会被其他团队分心。这样，我们都可以更快地工作，避免通常会使事情变慢的延误。
- en: The organization of the project, represented in *Figure 2.3*, is a variant of
    the RAG ecosystem’s framework represented in *Figure 1.3* of *Chapter 1*, *Why
    Retrieval Augmented Generation?*
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 项目组织，如图2.3所示，是第一章“为什么是检索增强生成？”中图1.3所示的RAG生态系统框架的一个变体。
- en: We can now begin building a RAG pipeline.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以开始构建一个RAG管道。
- en: Building a RAG pipeline
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建RAG管道
- en: 'We will now build a RAG pipeline by implementing the pipeline described in
    the previous section and illustrated in *Figure 2.3*. We will implement three
    components assuming that three teams (`Team #1`, `Team #2`, and `Team #3`) work
    in parallel to implement the pipeline:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '我们现在将通过实现上一节中描述并在图2.3中展示的管道来构建一个RAG管道。我们假设有三个团队（`Team #1`、`Team #2`和`Team #3`）并行工作以实现管道，将实现三个组件：'
- en: 'Data collection and preparation by `Team #1`'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '由`Team #1`进行的数据收集和准备'
- en: 'Data embedding and storage by `Team #2`'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '数据嵌入和存储由`Team #2`完成'
- en: 'Augmented generation by `Team #3`'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '增强生成由`Team #3`完成'
- en: The first step is to set up the environment for these components.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是为这些组件设置环境。
- en: Setting up the environment
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置环境
- en: Let’s face it here and now. Installing cross-platform, cross-library packages
    with their dependencies can be quite challenging! It is important to take this
    complexity into account and be prepared to get the environment running correctly.
    Each package has dependencies that may have conflicting versions. Even if we adapt
    the versions, an application may not run as expected anymore. So, take your time
    to install the right versions of the packages and dependencies.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们直面现实。安装跨平台、跨库的包及其依赖项可能相当具有挑战性！考虑到这种复杂性并准备好正确运行环境是很重要的。每个包都有可能存在冲突版本的依赖项。即使我们调整了版本，应用程序也可能不再按预期运行。因此，请花时间安装正确的包和依赖项版本。
- en: We will only describe the environment once in this section for all three components
    and refer to this section when necessary.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本节中只描述一次环境，适用于所有三个组件，并在必要时引用此部分。
- en: The installation packages and libraries
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 安装包和库
- en: 'To build the RAG pipeline in this section, we will need packages and need to
    freeze the package versions to prevent dependency conflicts and issues with the
    functions of the libraries, such as:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 要在本节中构建RAG管道，我们需要包并需要冻结包版本以防止依赖项冲突和库函数的问题，例如：
- en: Possible conflicts between the versions of the dependencies.
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 依赖项版本之间可能存在的冲突。
- en: Possible conflicts when one of the libraries needs to be updated for an application
    to run. For example, in August 2024, installing `Deep Lake` required `Pillow`
    version 10.x.x and Google Colab’s version was 9.x.x. Thus, it was necessary to
    uninstall `Pillow` and reinstall it with a recent version before installing `Deep
    Lake`. Google Colab will no doubt update Pillow. Many cases such as this occur
    in a fast-moving market.
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当其中一个库需要更新以使应用程序运行时可能出现的冲突。例如，在 2024 年 8 月，安装 `Deep Lake` 需要 `Pillow` 版本 10.x.x，而
    Google Colab 的版本是 9.x.x。因此，在安装 `Deep Lake` 之前，有必要卸载 `Pillow` 并使用较新版本重新安装它。毫无疑问，Google
    Colab 将更新 Pillow。在快速发展的市场中，这种情况经常发生。
- en: Possible deprecations if the versions remain frozen for too long.
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果版本冻结时间过长，可能出现的问题。
- en: Possible issues if the versions are frozen for too long and bugs are not corrected
    by upgrades.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果版本冻结时间过长且未通过升级修复错误，可能出现的问题。
- en: Thus, if we freeze the versions, an application may remain stable for some time
    but encounter issues. But if we upgrade the versions too quickly, some of the
    other libraries may not work anymore. There is no silver bullet! It’s a continual
    quality control process.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果我们冻结版本，应用程序可能会在一段时间内保持稳定，但会遇到问题。但如果我们升级版本太快，一些其他库可能就不再工作了。没有万能的解决方案！这是一个持续的质量控制过程。
- en: For our program, in this section, we will freeze the versions. Let’s now go
    through the installation steps to create the environment for our pipeline.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的程序，在本节中，我们将冻结版本。现在，让我们通过安装步骤来创建管道的环境。
- en: The components involved in the installation process
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 安装过程中的相关组件
- en: Let’s begin by describing the components that are installed in the *Installing
    the environment* section of each notebook. The components are not necessarily
    installed in all notebooks; this section serves as an inventory of the packages.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先描述在每个笔记本的 *安装环境* 部分中安装的组件。这些组件不一定在所有笔记本中安装；本节作为包的清单。
- en: 'In the first pipeline section, *1\. Data collection and preparation*, we will
    only need to install Beautiful Soup and Requests:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一个管道部分，*1. 数据收集和准备*，我们只需要安装 Beautiful Soup 和 Requests：
- en: '[PRE0]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This explains why this component of the pipeline should remain separate. It’s
    a straightforward job for a developer who enjoys creating interfaces to interact
    with the web. It’s also a perfect fit for a junior developer who wants to get
    involved in data collection and analysis.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这解释了为什么这个管道组件应该保持独立。对于喜欢创建与网络交互界面的开发者来说，这是一项简单的工作。这也非常适合想要参与数据收集和分析的初级开发者。
- en: The two other pipeline components we will build in this section, *2\. Data embedding
    and storage* and *3\. Augmented generation*, will require more attention as well
    as the installation of `requirements01.txt`, as explained in the previous section.
    For now, let’s continue with the installation step by step.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将构建的两个其他管道组件，*2. 数据嵌入和存储* 和 *3. 增强生成*，也需要更多的关注以及安装 `requirements01.txt`，如前节所述。现在，让我们继续逐步进行安装。
- en: Mounting a drive
  id: totrans-79
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 挂载驱动器
- en: 'In this scenario, the program mounts Google Drive in Google Colab to safely
    read the OpenAI API key to access OpenAI models and the Activeloop API token for
    authentication to access Activeloop Deep Lake datasets:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，程序在 Google Colab 中挂载 Google Drive，以安全地读取 OpenAI API 密钥以访问 OpenAI 模型，以及
    Activeloop API 令牌以进行认证以访问 Activeloop Deep Lake 数据集：
- en: '[PRE1]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: You can choose to store your keys and tokens elsewhere. Just make sure they
    are in a safe location.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以选择在其他地方存储您的密钥和令牌。只需确保它们在一个安全的位置。
- en: Creating a subprocess to download files from GitHub
  id: totrans-83
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 创建子进程以从 GitHub 下载文件
- en: 'The goal here is to write a function to download the `grequests.py` file from
    GitHub. This program contains a function to download files using `curl`, with
    the option to add a private token if necessary:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的目标是编写一个函数，从 GitHub 下载 `grequests.py` 文件。这个程序包含一个使用 `curl` 下载文件的函数，如果需要，可以添加一个私有令牌：
- en: '[PRE2]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The `grequests.py` file contains a function that can, if necessary, accept
    a private token or any other security system that requires credentials when retrieving
    data with `curl` commands:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '`grequests.py` 文件包含一个函数，如果需要，可以接受一个私有令牌或任何其他在用 `curl` 命令检索数据时需要凭证的安全系统：'
- en: '[PRE3]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Installing requirements
  id: totrans-88
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 安装需求
- en: 'Now, we will install the requirements for this section when working with Activeloop
    Deep Lake and OpenAI. We will only need:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，当与 Activeloop Deep Lake 和 OpenAI 一起工作时，我们将安装本节的依赖项。我们只需要：
- en: '[PRE4]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: As of August 2024, Google Colab’s version of Pillow conflicts with `deeplake`'s
    package. However, the `deeplake` installation package deals with this automatically.
    All you have to do is restart the session and run it again, which is why `pip
    install deeplake==3.9.18` is the first line of each notebook it is installed in.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 截至2024年8月，Google Colab的Pillow版本与`deeplake`包冲突。然而，`deeplake`安装包会自动处理这个问题。您只需重新启动会话并再次运行即可，这就是为什么`pip
    install deeplake==3.9.18`是安装在每个notebook中的第一行。
- en: 'After installing the requirements, we must run a line of code for Activeloop
    to activate a public DNS server:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 安装完要求后，我们必须运行一行代码以激活Activeloop的公共DNS服务器：
- en: '[PRE5]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Authentication process
  id: totrans-94
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 认证过程
- en: 'You will need to sign up to OpenAI to obtain an API key: [https://openai.com/](https://openai.com/).
    Make sure to check the pricing policy before using the key. First, let’s activate
    OpenAI’s API key:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要在OpenAI上注册以获取API密钥：[https://openai.com/](https://openai.com/)。在使用密钥之前，请确保检查定价政策。首先，让我们激活OpenAI的API密钥：
- en: '[PRE6]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Then, we activate Activeloop’s API token for Deep Lake:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们激活Deep Lake的Activeloop API令牌：
- en: '[PRE7]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'You will need to sign up on Activeloop to obtain an API token: [https://www.activeloop.ai/](https://www.activeloop.ai/).
    Again, make sure to check the pricing policy before using the Activeloop token.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要在Activeloop上注册以获取API令牌：[https://www.activeloop.ai/](https://www.activeloop.ai/)。再次提醒，在使用Activeloop令牌之前，请确保检查定价政策。
- en: 'Once the environment is installed, you can hide the *Installing the environment*
    cells we just ran to focus on the content of the pipeline components, as shown
    in *Figure 2.4*:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 环境安装完成后，您可以隐藏我们刚刚运行的**安装环境**单元格，以便专注于管道组件的内容，如图*图2.4*所示：
- en: '![A white background with black text  Description automatically generated](img/B31169_02_04.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![白色背景，黑色文字  自动生成的描述](img/B31169_02_04.png)'
- en: 'Figure 2:4: Hiding the installation cells'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 图2:4：隐藏安装单元格
- en: 'The installation cells will then be hidden but can still be run, as shown in
    *Figure 2.5*:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 隐藏安装单元格后，它们仍然可以运行，如图*图2.5*所示：
- en: '![A screenshot of a computer  Description automatically generated](img/B31169_02_05.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![计算机的屏幕截图  自动生成的描述](img/B31169_02_05.png)'
- en: 'Figure 2.5: Running hidden cells'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.5：运行隐藏单元格
- en: We can now focus on the pipeline components for each pipeline component. Let’s
    begin with data collection and preparation.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以专注于每个管道组件的管道组件。让我们从数据收集和准备开始。
- en: 1\. Data collection and preparation
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1. 数据收集和准备
- en: 'Data collection and preparation is the first pipeline component, as described
    earlier in this chapter. `Team #1` will only focus on their component, as shown
    in *Figure 2.6*:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '数据收集和准备是第一个管道组件，如本章前面所述。**Team #1**将只关注他们的组件，如图*图2.6*所示：'
- en: '![A diagram of a pipeline component  Description automatically generated](img/B31169_02_06.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![管道组件的示意图  自动生成的描述](img/B31169_02_06.png)'
- en: 'Figure 2.6: Pipeline component #1: Data collection and preparation'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.6：管道组件#1：数据收集和准备
- en: 'Let’s jump in and lend a hand to `Team #1`. Our work is clearly defined, so
    we can enjoy the time taken to implement the component. We will retrieve and process
    10 Wikipedia articles that provide a comprehensive view of various aspects of
    space exploration:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '让我们加入并帮助**Team #1**。我们的工作定义清晰，因此我们可以享受实现组件所花费的时间。我们将检索并处理10篇维基百科文章，这些文章提供了对太空探索各个方面的全面视角：'
- en: '**Space exploration**: Overview of the history, technologies, missions, and
    plans involved in the exploration of space ([https://en.wikipedia.org/wiki/Space_exploration](https://en.wikipedia.org/wiki/Space_exploration))'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**太空探索**：关于太空探索的历史、技术、任务和计划的概述（[https://en.wikipedia.org/wiki/Space_exploration](https://en.wikipedia.org/wiki/Space_exploration)）'
- en: '**Apollo program**: Details about the NASA program that landed the first humans
    on the Moon and its significant missions ([https://en.wikipedia.org/wiki/Apollo_program](https://en.wikipedia.org/wiki/Apollo_program))'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**阿波罗计划**：关于将人类首次送上月球并执行其重大任务的NASA计划的信息（[https://en.wikipedia.org/wiki/Apollo_program](https://en.wikipedia.org/wiki/Apollo_program)）'
- en: '**Hubble Space Telescope**: Information on one of the most significant telescopes
    ever built, which has been crucial in many astronomical discoveries ([https://en.wikipedia.org/wiki/Hubble_Space_Telescope](https://en.wikipedia.org/wiki/Hubble_Space_Telescope))'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**哈勃太空望远镜**：关于有史以来最显著的望远镜之一的信息，它在许多天文学发现中发挥了关键作用（[https://en.wikipedia.org/wiki/Hubble_Space_Telescope](https://en.wikipedia.org/wiki/Hubble_Space_Telescope)）'
- en: '**Mars rover**: Insight into the rovers that have been sent to Mars to study
    its surface and environment ([https://en.wikipedia.org/wiki/Mars_rover](https://en.wikipedia.org/wiki/Mars_rover))'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**火星漫游车**：深入了解被送往火星以研究其表面和环境的漫游车（[https://en.wikipedia.org/wiki/Mars_rover](https://en.wikipedia.org/wiki/Mars_rover)）'
- en: '**International Space Station (ISS)**: Details about the ISS, its construction,
    international collaboration, and its role in space research ([https://en.wikipedia.org/wiki/International_Space_Station](https://en.wikipedia.org/wiki/International_Space_Station))'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**国际空间站（ISS）**：关于ISS的详细信息，其建设、国际合作及其在空间研究中的作用（[https://en.wikipedia.org/wiki/International_Space_Station](https://en.wikipedia.org/wiki/International_Space_Station)）'
- en: '**SpaceX**: Covers the history, achievements, and goals of SpaceX, one of the
    most influential private spaceflight companies ([https://en.wikipedia.org/wiki/SpaceX](https://en.wikipedia.org/wiki/SpaceX))'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**SpaceX**：涵盖了SpaceX的历史、成就和目标，这是最有影响力的私营太空飞行公司之一（[https://en.wikipedia.org/wiki/SpaceX](https://en.wikipedia.org/wiki/SpaceX)）'
- en: '**Juno (spacecraft)**: Information about the NASA space probe that orbits and
    studies Jupiter, its structure, and moons ([https://en.wikipedia.org/wiki/Juno_(spacecraft))](https://en.wikipedia.org/wiki/Juno_(spacecraft))'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**朱诺号（航天器）**：关于环绕并研究木星、其结构和卫星的NASA太空探测器的信息（[https://en.wikipedia.org/wiki/Juno_(spacecraft))](https://en.wikipedia.org/wiki/Juno_(spacecraft)）'
- en: '**Voyager program**: Details on the Voyager missions, including their contributions
    to our understanding of the outer solar system and interstellar space ([https://en.wikipedia.org/wiki/Voyager_program](https://en.wikipedia.org/wiki/Voyager_program))'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**旅行者计划**：关于旅行者任务，包括它们对我们理解外太阳系和星际空间的贡献（[https://en.wikipedia.org/wiki/Voyager_program](https://en.wikipedia.org/wiki/Voyager_program)）'
- en: '**Galileo (spacecraft)**: Overview of the mission that studied Jupiter and
    its moons, providing valuable data on the gas giant and its system ([https://en.wikipedia.org/wiki/Galileo_(spacecraft)](https://en.wikipedia.org/wiki/Galileo_(spacecraft)))'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**伽利略号（航天器）**：概述了研究木星及其卫星的任务，提供了关于这颗气态巨行星及其系统的宝贵数据（[https://en.wikipedia.org/wiki/Galileo_(spacecraft)](https://en.wikipedia.org/wiki/Galileo_(spacecraft)）'
- en: '**Kepler space telescope**: Information about the space telescope designed
    to discover Earth-size planets orbiting other stars ([https://en.wikipedia.org/wiki/Kepler_Space_Telescope](https://en.wikipedia.org/wiki/Kepler_Space_Telescope))'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**开普勒太空望远镜**：关于设计用于发现绕其他恒星运行的地球大小行星的太空望远镜的信息（[https://en.wikipedia.org/wiki/Kepler_Space_Telescope](https://en.wikipedia.org/wiki/Kepler_Space_Telescope)）'
- en: These articles cover a wide range of topics in space exploration, from historical
    programs to modern technological advances and missions.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 这些文章涵盖了太空探索的广泛主题，从历史计划到现代技术进步和任务。
- en: Now, open `1-Data_collection_preparation.ipynb` in the GitHub repository. We
    will first collect the data.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在GitHub仓库中打开`1-Data_collection_preparation.ipynb`。我们首先收集数据。
- en: Collecting the data
  id: totrans-124
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 收集数据
- en: 'We just need `import requests` for the HTTP requests, `from bs4 import BeautifulSoup`
    for HTML parsing, and `import re`, the regular expressions module:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只需要`import requests`进行HTTP请求，`from bs4 import BeautifulSoup`进行HTML解析，以及`import
    re`，正则表达式模块：
- en: '[PRE8]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We then select the URLs we need:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 我们然后选择所需的URL：
- en: '[PRE9]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This list is in code. However, it could be stored in a database, a file, or
    any other format, such as JSON. We can now prepare the data.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 这个列表在代码中。然而，它也可以存储在数据库中，文件中，或任何其他格式，例如JSON。我们现在可以准备数据。
- en: Preparing the data
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 准备数据
- en: 'First, we write a cleaning function. This function removes numerical references
    such as [1] [2] from a given text string, using regular expressions, and returns
    the cleaned text:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们编写一个清理函数。此函数使用正则表达式从给定的文本字符串中删除数字引用，如[1] [2]，并返回清理后的文本：
- en: '[PRE10]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Then, we write a classical fetch and clean function, which will return a nice
    and clean text by extracting the content we need from the documents:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们编写一个经典的获取和清理函数，该函数将通过从文档中提取所需内容来返回一个整洁的文本：
- en: '[PRE11]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Finally, we write the content in `llm.txt` file for the team working on the
    data embedding and storage functions:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将内容写入`llm.txt`文件，供数据嵌入和存储功能的小组使用：
- en: '[PRE12]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The output confirms that the text has been written:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 输出确认文本已被写入：
- en: '[PRE13]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The program can be modified to save the data in other formats and locations,
    as required for a project’s specific needs. The file can then be verified before
    we move on to the next batch of data to retrieve and process:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 程序可以根据项目特定需求修改以保存数据到其他格式和位置：
- en: '[PRE14]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The output shows the first lines of the document that will be processed:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示了将要处理的文档的第一行：
- en: '[PRE15]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: This component can be managed by a team that enjoys searching for documents
    on the web or within a company’s data environment. The team will gain experience
    in identifying the best documents for a project, which is the foundation of any
    RAG framework.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 这个组件可以由一个喜欢在网络上或公司数据环境中搜索文档的团队管理。该团队将在识别项目最佳文档方面获得经验，这是任何RAG框架的基础。
- en: '`Team #2` can now work on the data to embed the documents and store them.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '`Team #2`现在可以处理数据以嵌入文档并将它们存储起来。'
- en: 2\. Data embedding and storage
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2. 数据嵌入和存储
- en: '`Team #2`''s job is to focus on the second component of the pipeline. They
    will receive batches of prepared data to work on. They don’t have to worry about
    retrieving data. `Team #1` has their back with their data collection and preparation
    component.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '`Team #2`的任务是专注于管道的第二组件。他们将接收准备好的数据批次以进行处理。他们不必担心检索数据。`Team #1`在数据收集和准备组件方面支持他们。'
- en: '![A diagram of a pipeline component  Description automatically generated](img/B31169_02_07.png)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![管道组件的图示  自动生成的描述](img/B31169_02_07.png)'
- en: 'Figure 2.7: Pipeline component #2: Data embedding and storage'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.7：管道组件#2：数据嵌入和存储
- en: 'Let’s now jump in and help `Team #2` to get the job done. Open `2-Embeddings_vector_store.ipynb`
    in the GitHub Repository. We will embed and store the data provided by `Team #1`
    and retrieve a batch of documents to work on.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '让我们现在跳进去帮助`Team #2`完成任务。在GitHub仓库中打开`2-Embeddings_vector_store.ipynb`。我们将嵌入并存储`Team
    #1`提供的数据，并检索一批文档进行处理。'
- en: Retrieving a batch of prepared documents
  id: totrans-150
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 检索一批准备好的文档
- en: 'First, we download a batch of documents available on a server and provided
    by `Team #1`, which is the first of a continual stream of incoming documents.
    In this case, we assume it’s the space exploration file:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '首先，我们下载由`Team #1`提供并存储在服务器上的一批文档，这是持续流入文档的第一批。在这种情况下，我们假设它是太空探索文件：'
- en: '[PRE16]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Note that `source_text = "llm.txt"` will be used by the function that will
    add the data to our vector store. We then briefly check the document just to be
    sure, knowing that `Team #1` has already verified the information:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '注意，`source_text = "llm.txt"` 将由将数据添加到我们的向量存储库的函数使用。然后我们简要检查文档，以确保`Team #1`已经验证了信息：'
- en: '[PRE17]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The output is satisfactory, as shown in the following excerpt:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 输出令人满意，如下所示：
- en: '[PRE18]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: We will now chunk the data. We will determine a chunk size defined by the number
    of characters. In this case, it is `CHUNK_SIZE = 1000`, but we can select chunk
    sizes using different strategies. *Chapter 7*, *Building Scalable Knowledge-Graph-based
    RAG with Wikipedia API and LlamaIndex*, will take chunk size optimization further
    with automated seamless chunking.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将数据分块。我们将根据字符数确定块大小。在这种情况下，它是 `CHUNK_SIZE = 1000`，但我们可以使用不同的策略选择块大小。*第7章*，*使用Wikipedia
    API和LlamaIndex构建可扩展的基于知识图谱的RAG*，将进一步优化块大小，实现自动无缝分块。
- en: 'Chunking is necessary to optimize data processing: selecting portions of text,
    embedding, and loading the data. It also makes the embedded dataset easier to
    query. The following code chunks a document to complete the preparation process:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 分块是优化数据处理所必需的：选择文本部分、嵌入和加载数据。它还使嵌入的数据集更容易查询。以下代码将文档分块以完成准备过程：
- en: '[PRE19]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: We are now ready to create a vector store to vectorize data or add data to an
    existing one.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已准备好创建一个向量存储库以向量化数据或向现有的存储库中添加数据。
- en: Verifying if the vector store exists and creating it if not
  id: totrans-161
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 验证向量存储是否存在并在不存在时创建它
- en: 'First, we need to define the path of our Activeloop vector store path, whether
    our dataset exists or not:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要定义我们的Activeloop向量存储路径，无论我们的数据集是否存在：
- en: '[PRE20]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Make sure to replace `` `hub://denis76/space_exploration_v1` `` with your organization
    and dataset name.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 确保将 `` `hub://denis76/space_exploration_v1` `` 替换为您的组织和数据集名称。
- en: 'Then, we write a function to attempt to load the vector store or automatically
    create one if it doesn’t exist:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们编写一个函数来尝试加载向量存储库或自动创建一个如果它不存在的话：
- en: '[PRE21]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The output confirms that the vector store has been created:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 输出确认向量存储已创建：
- en: '[PRE22]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: We now need to create an embedding function.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在需要创建一个嵌入函数。
- en: The embedding function
  id: totrans-170
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 嵌入函数
- en: The embedding function will transform the chunks of data we created into vectors
    to enable vector-based search. In this program, we will use `"text-embedding-3-small"`
    to embed the documents.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入函数将把创建的数据块转换为向量，以实现基于向量的搜索。在这个程序中，我们将使用`"text-embedding-3-small"`来嵌入文档。
- en: 'OpenAI has other embedding models that you can use: [https://platform.openai.com/docs/models/embeddings](https://platform.openai.com/docs/models/embeddings).
    *Chapter 6*, *Scaling RAG Bank Customer Data with Pinecone*, provides alternative
    code for embedding models in the *Embedding* section. In any case, it is recommended
    to evaluate embedding models before choosing one in production. Examine the characteristics
    of each embedding model, as described by OpenAI, focusing on their length and
    capacities. `text-embedding-3-small` was chosen in this case because it stands
    out as a robust choice for efficiency and speed:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI还有其他可以使用的嵌入模型：[https://platform.openai.com/docs/models/embeddings](https://platform.openai.com/docs/models/embeddings)。第6章*使用Pinecone扩展RAG银行客户数据*在*嵌入*部分提供了嵌入模型的替代代码。无论如何，建议在选择生产中的嵌入模型之前对其进行评估。检查OpenAI描述的每个嵌入模型的特点，重点关注它们的长度和能力。在这种情况下，选择`text-embedding-3-small`是因为它作为一个高效且快速的稳健选择而突出：
- en: '[PRE23]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The `text-embedding-3-small` text embedding model from OpenAI typically uses
    embeddings with a restricted number of dimensions, to balance obtaining enough
    detail in the embeddings with large computational workloads and storage space.
    Make sure to check the model page and pricing information before running the code:
    [https://platform.openai.com/docs/guides/embeddings/embedding-models](https://platform.openai.com/docs/guides/embeddings/embedding-models).'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI的`text-embedding-3-small`文本嵌入模型通常使用具有限制性维度的嵌入，以平衡在嵌入中获得足够细节与大型计算工作负载和存储空间之间的平衡。在运行代码之前，请确保检查模型页面和定价信息：[https://platform.openai.com/docs/guides/embeddings/embedding-models](https://platform.openai.com/docs/guides/embeddings/embedding-models)。
- en: We are now all set to begin populating the vector store.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好开始填充向量存储。
- en: Adding data to the vector store
  id: totrans-176
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 向向量存储添加数据
- en: 'We set the adding data flag to `True`:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将添加数据的标志设置为`True`：
- en: '[PRE24]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The source text, `source_text = "llm.txt"`, has been embedded and stored. A
    summary of the dataset’s structure is displayed, showing that the dataset was
    loaded:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 源文本`source_text = "llm.txt"`已被嵌入并存储。数据集结构的摘要显示，数据集已被加载：
- en: '[PRE25]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Observe that the dataset contains four tensors:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 观察到数据集包含四个张量：
- en: '`embedding`: Each chunk of data is embedded in a vector'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`embedding`：每个数据块都嵌入到一个向量中'
- en: '`id`: The ID is a string of characters and is unique'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`id`：ID是一串字符，且是唯一的'
- en: '`metadata`: The metadata contains the source of the data—in this case, the
    `llm.txt` file.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`metadata`：元数据包含数据的来源——在本例中，是`llm.txt`文件。'
- en: '`text`: The content of a chunk of text in the dataset'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text`：数据集中文本块的内容'
- en: 'This dataset structure can vary from one project to another, as we will see
    in *Chapter 4*, *Multimodal Modular RAG for Drone Technology*. We can also visualize
    how the dataset is organized at any time to verify the structure. The following
    code will display the summary that was just displayed:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 这种数据集结构可能因项目而异，正如我们将在第4章*多模态模块化RAG用于无人机技术*中看到的。我们还可以在任何时候可视化数据集的组织结构以验证其结构。以下代码将显示刚刚显示的摘要：
- en: '[PRE26]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: We can also visualize vector store information if we wish.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们愿意，我们还可以可视化向量存储信息。
- en: Vector store information
  id: totrans-189
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 向量存储信息
- en: 'Activeloop’s API reference provides us with all the information we need to
    manage our datasets: [https://docs.deeplake.ai/en/latest/](https://docs.deeplake.ai/en/latest/).
    We can visualize our datasets once we sign in at [https://app.activeloop.ai/datasets/mydatasets/](https://app.activeloop.ai/datasets/mydatasets/).'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: Activeloop的API参考为我们提供了管理数据集所需的所有信息：[https://docs.deeplake.ai/en/latest/](https://docs.deeplake.ai/en/latest/)。在[https://app.activeloop.ai/datasets/mydatasets/](https://app.activeloop.ai/datasets/mydatasets/)登录后，我们可以可视化我们的数据集。
- en: 'We can also load our dataset in one line of code:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以用一行代码加载我们的数据集：
- en: '[PRE27]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The output provides a path to visualize our datasets and query and explore
    them online:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 输出提供了一个路径，可以可视化我们的数据集，并在线查询和探索它们：
- en: '[PRE28]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'You can also access your dataset directly on Activeloop by signing in and going
    to your datasets. You will find online dataset exploration tools to query your
    dataset and more, as shown here:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以通过登录Activeloop并进入您的数据集来直接访问您的数据集。您将找到在线数据集探索工具来查询您的数据集等，如下所示：
- en: '![A screenshot of a web page  Description automatically generated](img/B31169_02_08.png)'
  id: totrans-196
  prefs: []
  type: TYPE_IMG
  zh: '![网页截图  自动生成的描述](img/B31169_02_08.png)'
- en: 'Figure 2.8: Querying and exploring a Deep Lake dataset online.'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.8：在线查询和探索Deep Lake数据集。
- en: 'Among the many functions available, we can display the estimated size of a
    dataset:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多可用功能中，我们可以显示数据集的估计大小：
- en: '[PRE29]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Once we have obtained the size, we can convert it into megabytes and gigabytes:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们获得了大小，我们可以将其转换为兆字节和千兆字节：
- en: '[PRE30]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The output shows the size of the dataset in megabytes and gigabytes:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示了数据集的大小（以兆字节和千兆字节为单位）：
- en: '[PRE31]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '`Team #2`''s pipeline component for data embedding and storage seems to be
    working. Let’s now explore augmented generation.'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '`团队#2`的数据嵌入和存储管道组件似乎正在正常工作。现在让我们探索增强生成。'
- en: 3\. Augmented input generation
  id: totrans-205
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3. 增强输入生成
- en: 'Augmented generation is the third pipeline component. We will use the data
    we retrieved to augment the user input. This component processes the user input,
    queries the vector store, augments the input, and calls `gpt-4-turbo`, as shown
    in *Figure 2.9*:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 增强生成是第三个管道组件。我们将使用我们检索到的数据来增强用户输入。该组件处理用户输入，查询向量存储，增强输入，并调用`gpt-4-turbo`，如图*图2.9*所示：
- en: '![A diagram of a pipeline  Description automatically generated](img/B31169_02_09.png)'
  id: totrans-207
  prefs: []
  type: TYPE_IMG
  zh: '![管道的示意图  自动生成的描述](img/B31169_02_09.png)'
- en: 'Figure 2.9: Pipeline component #3: Augmented input generation'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.9：管道组件#3：增强输入生成
- en: '*Figure 2.9* shows that pipeline component #3 fully deserves its **Retrieval
    Augmented Generation** (**RAG**) name. However, it would be impossible to run
    this component without the work put in by `Team #1` and `Team #2` to provide the
    necessary information to generate augmented input content.'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '*图2.9*显示，管道组件#3完全配得上其**检索增强生成**（**RAG**）的名称。然而，如果没有`团队#1`和`团队#2`的工作，提供生成增强输入内容所需的信息，将无法运行此组件。'
- en: 'Let’s jump in and see how `Team #3` does the job. Open `3-Augmented_Generation.ipynb`
    in the GitHub repository. The *Installing the environment* section of the notebook
    is described in the *Setting up the environment* section of this chapter. We select
    the vector store (replace the vector store path with your vector store):'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们跳进去看看`团队#3`是如何完成工作的。在GitHub仓库中打开`3-Augmented_Generation.ipynb`。笔记本的*安装环境*部分在本章的*设置环境*部分有描述。我们选择向量存储（将向量存储路径替换为您的向量存储）：
- en: '[PRE32]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Then, we load the dataset:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们加载数据集：
- en: '[PRE33]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'We print a confirmation message that the vector store exists. At this point
    stage, `Team #2` previously ensured that everything was working well, so we can
    just move ahead rapidly:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 我们打印一条确认消息，表明向量存储存在。在这个阶段，`团队#2`之前确保了一切工作正常，因此我们可以快速前进：
- en: '[PRE34]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The output confirms that the dataset exists and is loaded:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 输出确认数据集存在并已加载：
- en: '[PRE35]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'We assume that pipeline `component #2`, as built in the *Data embedding and
    storage* section, has created and populated the `vector_store` and has verified
    that it can be queried. Let’s now process the user input.'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设管道组件`#2`，如在第*数据嵌入和存储*部分所述构建，已经创建并填充了`vector_store`，并已验证它可以被查询。现在让我们处理用户输入。
- en: Input and query retrieval
  id: totrans-219
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 输入和查询检索
- en: 'We will need the embedding function to embed the user input:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要嵌入函数来嵌入用户输入：
- en: '[PRE36]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Note that we are using the same embedding model as the data embedding and storage
    component to ensure full compatibility between the input and the vector dataset:
    `text-embedding-ada-002`.'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们使用与数据嵌入和存储组件相同的嵌入模型，以确保输入和向量数据集之间的完全兼容性：`text-embedding-ada-002`。
- en: We can now either use an interactive prompt for an input or process user inputs
    in batches. In this case, we process a user input that has already been entered
    that could be fetched from a user interface, for example.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以使用交互式提示输入或批量处理用户输入。在这种情况下，我们处理一个已经输入的用户输入，例如可以从用户界面获取。
- en: 'We first ask the user for an input or define one:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先要求用户输入或定义一个：
- en: '[PRE37]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'We then plug the prompt into the search query and store the output in `search_results`:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们将提示插入到搜索查询中，并将输出存储在`search_results`中：
- en: '[PRE38]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'The user prompt and search results stored in `search_results` are formatted
    to be displayed. First, let’s print the user prompt:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 存储在`search_results`中的用户提示和搜索结果被格式化以供显示。首先，让我们打印用户提示：
- en: '[PRE39]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'We can also wrap the retrieved text to obtain a formatted output:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以将检索到的文本包装起来以获得格式化的输出：
- en: '[PRE40]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'However, let’s only select one of the top results and print it:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们只选择最上面的一个结果并打印它：
- en: '[PRE41]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'The following output shows that we have a reasonably good match:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 以下输出显示我们有一个相当好的匹配：
- en: '[PRE42]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: We are ready to augment the input with the additional information we have retrieved.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 我们准备好使用我们检索到的附加信息来增强输入。
- en: Augmented input
  id: totrans-237
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 增强输入
- en: 'The program adds the top retrieved text to the user input:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 程序将检索到的最上面的文本添加到用户输入中：
- en: '[PRE43]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'The output displays the augmented input:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示了增强输入：
- en: '[PRE44]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '`gpt-4o` can now process the augmented input and generate content:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: '`gpt-4o` 现在可以处理增强输入并生成内容：'
- en: '[PRE45]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Note that we are timing the process. We now write the generative AI call, adding
    roles to the message we create for the model:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们正在计时这个过程。我们现在编写生成式 AI 调用，为创建的消息添加角色：
- en: '[PRE46]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'The generative model is called with the augmented input; the response time
    is calculated and displayed along with the output:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 生成模型使用增强输入被调用；计算并显示响应时间以及输出：
- en: '[PRE47]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Note that the raw output is displayed with the response time:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，原始输出会显示响应时间：
- en: '[PRE48]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Let’s format the output with `textwrap` and print the result. `print_formatted_response(response)`
    first checks if the response returned contains Markdown features. If so, it will
    format the response; if not, it will perform a standard output text wrap:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用 `textwrap` 格式化输出并打印结果。`print_formatted_response(response)` 首先检查返回的响应是否包含
    Markdown 功能。如果是这样，它将格式化响应；如果不是，它将执行标准输出文本换行：
- en: '[PRE49]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'The output is satisfactory:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 输出令人满意：
- en: '[PRE50]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: Let’s introduce an evaluation metric to measure the quality of the output.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们引入一个评估指标来衡量输出的质量。
- en: Evaluating the output with cosine similarity
  id: totrans-255
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用余弦相似度评估输出
- en: 'In this section, we will implement cosine similarity to measure the similarity
    between user input and the generative AI model’s output. We will also measure
    the augmented user input with the generative AI model’s output. Let’s first define
    a cosine similarity function:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将实现余弦相似度来衡量用户输入和生成式 AI 模型输出之间的相似度。我们还将衡量增强用户输入与生成式 AI 模型输出之间的相似度。让我们首先定义一个余弦相似度函数：
- en: '[PRE51]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Then, let’s calculate a score that measures the similarity between the user
    prompt and GPT-4’s response:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，让我们计算一个分数来衡量用户提示和 GPT-4 的响应之间的相似度：
- en: '[PRE52]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'The score is low, although the output seemed acceptable for a human:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管输出对于人类来说似乎是可以接受的，但分数很低：
- en: '[PRE53]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: It seems that either we missed something or need to use another metric.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来我们可能遗漏了某些内容或需要使用另一个指标。
- en: 'Let’s try to calculate the similarity between the augmented input and GPT-4’s
    response:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试计算增强输入和 GPT-4 的响应之间的相似度：
- en: '[PRE54]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'The score seems better:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 分数似乎更好：
- en: '[PRE55]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: Can we use another method? Cosine similarity, when using **Term Frequency-Inverse
    Document Frequency** (**TF-IDF**), relies heavily on exact vocabulary overlap
    and takes into account important language features, such as semantic meanings,
    synonyms, or contextual usage. As such, this method may produce lower similarity
    scores for texts that are conceptually similar but differ in word choice.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用另一种方法吗？当使用 **词频-逆文档频率**（**TF-IDF**）时，余弦相似度高度依赖于精确的词汇重叠，并考虑重要的语言特征，如语义含义、同义词或上下文用法。因此，这种方法可能会为概念上相似但词汇选择不同的文本产生较低的相似度分数。
- en: In contrast, using Sentence Transformers to calculate similarity involves embeddings
    that capture deeper semantic relationships between words and phrases. This approach
    is more effective in recognizing the contextual and conceptual similarity between
    texts. Let’s try this approach.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，使用 Sentence Transformers 计算相似度涉及捕捉单词和短语之间更深层次语义关系的嵌入。这种方法在识别文本之间的上下文和概念相似性方面更有效。让我们尝试这种方法。
- en: 'First, let’s install `sentence-transformers`:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们安装 `sentence-transformers`：
- en: '[PRE56]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: Be careful installing this library at the end of the session, since it may induce
    potential conflicts with the RAG pipeline’s requirements. Depending on a project’s
    needs, this code could be yet another separate pipeline component.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 在会话结束时安装此库要小心，因为它可能会与 RAG 管道的要求产生潜在冲突。根据项目的需求，这段代码可能又是另一个独立的管道组件。
- en: As of August 2024, using a Hugging Face token is optional. If Hugging Face requires
    a token, sign up to Hugging Face to obtain an API token, check the conditions,
    and set up the key as instructed.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 截至 2024 年 8 月，使用 Hugging Face 令牌是可选的。如果 Hugging Face 需要令牌，请注册 Hugging Face 获取
    API 令牌，检查条件，并按照说明设置密钥。
- en: 'We will now use a MiniLM architecture to perform the task with `all-MiniLM-L6-v2`.
    This model is available through the Hugging Face Model Hub we are using. It’s
    part of the `sentence-transformers` library, which is an extension of the Hugging
    Face Transformers library. We are using this architecture because it offers a
    compact and efficient model, with a strong performance in generating meaningful
    sentence embeddings quickly. Let’s now implement it with the following function:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将使用MiniLM架构使用`all-MiniLM-L6-v2`执行任务。此模型可通过我们使用的Hugging Face模型库获得。它是`sentence-transformers`库的一部分，该库是Hugging
    Face Transformers库的扩展。我们使用此架构是因为它提供了一个紧凑且高效的模型，在快速生成有意义的句子嵌入方面表现出色。现在让我们使用以下函数实现它：
- en: '[PRE57]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'We can now call the function to calculate the similarity between the augmented
    user input and GPT-4’s response:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以调用函数来计算增强用户输入与GPT-4响应之间的相似度：
- en: '[PRE58]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'The output shows that the Sentence Transformer captures semantic similarities
    between the texts more effectively, resulting in a high cosine similarity score:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示，Sentence Transformer在捕捉文本之间的语义相似性方面更为有效，从而产生了高余弦相似度分数：
- en: '[PRE59]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: The choice of metrics depends on the specific requirements of each project phase.
    *Chapter 3*, *Building Index-Based RAG with LlamaIndex, Deep Lake, and OpenAI*,
    will provide advanced metrics when we implement index-based RAG. At this stage,
    however, the RAG pipeline’s three components have been successfully built. Let’s
    summarize our journey and move to the next level!
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 指标的选择取决于每个项目阶段的具体要求。*第3章*，*使用LlamaIndex、Deep Lake和OpenAI构建基于索引的RAG*，将在我们实施基于索引的RAG时提供高级指标。然而，在这个阶段，RAG管道的三个组件已经成功构建。让我们总结我们的旅程，迈向下一个层次！
- en: Summary
  id: totrans-280
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we tackled the complexities of using RAG-driven generative
    AI, focusing on the essential role of document embeddings when handling large
    datasets. We saw how to go from raw texts to embeddings and store them in vector
    stores. Vector stores such as Activeloop, unlike parametric generative AI models,
    provide API tools and visual interfaces that allow us to see embedded text at
    any moment.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们解决了使用RAG驱动的生成式AI的复杂性，重点关注处理大数据集时文档嵌入的基本作用。我们看到了如何从原始文本到嵌入并将它们存储在向量存储中的方法。与参数化生成式AI模型不同，向量存储（如Activeloop）提供了API工具和可视化界面，使我们能够随时查看嵌入的文本。
- en: A RAG pipeline detailed the organizational process of integrating OpenAI embeddings
    into Activeloop Deep Lake vector stores. The RAG pipeline was broken down into
    distinct components that can vary from one project to another. This separation
    allows multiple teams to work simultaneously without dependency, accelerating
    development and facilitating specialized focus on individual aspects, such as
    data collection, embedding processing, and query generation for the augmented
    generation AI process.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 一个RAG管道详细说明了将OpenAI嵌入集成到Activeloop Deep Lake向量存储中的组织过程。RAG管道被分解为不同的组件，这些组件可能因项目而异。这种分离允许多个团队同时工作而无需依赖，加速开发并促进对个别方面的专业关注，例如数据收集、嵌入处理和增强生成式AI过程中的查询生成。
- en: We then built a three-component RAG pipeline, beginning by highlighting the
    necessity of specific cross-platform packages and careful system architecture
    planning. The resources involved were Python functions built from scratch, Activeloop
    Deep Lake to organize and store the embeddings in a dataset in a vector store,
    an OpenAI embedding model, and OpenAI’s GPT-4o generative AI model. The program
    guided us through building a three-part RAG pipeline using Python, with practical
    steps that involved setting up the environment, handling dependencies, and addressing
    implementation challenges like data chunking and vector store integration.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 我们随后构建了一个三组件的RAG管道，首先强调了特定跨平台包的必要性以及仔细的系统架构规划。涉及到的资源包括从头开始构建的Python函数，Activeloop
    Deep Lake用于在向量存储中组织和存储数据集的嵌入，OpenAI嵌入模型，以及OpenAI的GPT-4o生成式AI模型。程序引导我们使用Python构建一个三部分的RAG管道，涉及实际步骤，包括设置环境、处理依赖项以及解决实现挑战，如数据分块和向量存储集成。
- en: This journey provided a robust understanding of embedding documents in vector
    stores and leveraging them for enhanced generative AI outputs, preparing us to
    apply these insights to real-world AI applications in well-organized processes
    and teams within an organization. Vector stores enhance the retrieval of documents
    that require precision in information retrieval. Indexing takes RAG further and
    increases the speed and relevance of retrievals. The next chapter will take us
    a step further by introducing advanced indexing methods to retrieve and augment
    inputs.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 这段旅程为我们提供了对在向量存储中嵌入文档以及利用它们来增强生成式 AI 输出的稳健理解，使我们能够将这些见解应用于组织内有序流程和团队中的实际 AI
    应用。向量存储增强了需要精确信息检索的文档检索。索引将 RAG 推进一步，并提高了检索的速度和相关性。下一章将引入更高级的索引方法，以检索和增强输入。
- en: Questions
  id: totrans-285
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: 'Answer the following questions with *Yes* or *No*:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 用 *Yes* 或 *No* 回答以下问题：
- en: Do embeddings convert text into high-dimensional vectors for faster retrieval
    in RAG?
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 嵌入是否将文本转换为高维向量，以在 RAG 中实现更快的检索？
- en: Are keyword searches more effective than embeddings in retrieving detailed semantic
    content?
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 关键词搜索在检索详细语义内容方面是否比嵌入更有效？
- en: Is it recommended to separate RAG pipelines into independent components?
  id: totrans-289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 是否建议将 RAG 管道分离成独立的组件？
- en: Does the RAG pipeline consist of only two main components?
  id: totrans-290
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: RAG 管道是否仅由两个主要组件组成？
- en: Can Activeloop Deep Lake handle both embedding and vector storage?
  id: totrans-291
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Activeloop Deep Lake 是否可以同时处理嵌入和向量存储？
- en: Is the text-embedding-3-small model from OpenAI used to generate embeddings
    in this chapter?
  id: totrans-292
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: OpenAI 的 text-embedding-3-small 模型是否用于本章生成嵌入？
- en: Are data embeddings visible and directly traceable in an RAG-driven system?
  id: totrans-293
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据嵌入在 RAG 驱动的系统中是否可见且可直接追踪？
- en: Can a RAG pipeline run smoothly without splitting into separate components?
  id: totrans-294
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: RAG 管道是否可以在不拆分成单独组件的情况下顺利运行？
- en: Is chunking large texts into smaller parts necessary for embedding and storage?
  id: totrans-295
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将大文本分成更小的部分对嵌入和存储是否必要？
- en: Are cosine similarity metrics used to evaluate the relevance of retrieved information?
  id: totrans-296
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 是否使用余弦相似度指标来评估检索信息的相关性？
- en: References
  id: totrans-297
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'OpenAI Ada documentation for embeddings: [https://platform.openai.com/docs/guides/embeddings/embedding-models](https://platform.openai.com/docs/guides/embeddings/embedding-models)'
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI Ada 嵌入文档指南：[https://platform.openai.com/docs/guides/embeddings/embedding-models](https://platform.openai.com/docs/guides/embeddings/embedding-models)
- en: 'OpenAI GPT documentation for content generation: [https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4)'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI GPT 内容生成文档：[https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4)
- en: 'Activeloop API documentation: [https://docs.deeplake.ai/en/latest/](https://docs.deeplake.ai/en/latest/)'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Activeloop API 文档：[https://docs.deeplake.ai/en/latest/](https://docs.deeplake.ai/en/latest/)
- en: 'MiniLM model reference: [https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MiniLM 模型参考：[https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)
- en: Further reading
  id: totrans-302
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'OpenAI’s documentation on embeddings: [https://platform.openai.com/docs/guides/embeddings](https://platform.openai.com/docs/guides/embeddings)'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI 关于嵌入的文档：[https://platform.openai.com/docs/guides/embeddings](https://platform.openai.com/docs/guides/embeddings)
- en: 'Activeloop documentation: [https://docs.activeloop.ai/](https://docs.activeloop.ai/)'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Activeloop 文档：[https://docs.activeloop.ai/](https://docs.activeloop.ai/)
- en: Join our community on Discord
  id: totrans-305
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们的 Discord 社区
- en: 'Join our community’s Discord space for discussions with the author and other
    readers:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 加入我们的社区 Discord 空间，与作者和其他读者进行讨论：
- en: '[https://www.packt.link/rag](https://www.packt.link/rag)'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.packt.link/rag](https://www.packt.link/rag)'
- en: '![](img/QR_Code50409000288080484.png)'
  id: totrans-308
  prefs: []
  type: TYPE_IMG
  zh: '![](img/QR_Code50409000288080484.png)'
