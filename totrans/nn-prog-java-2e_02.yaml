- en: Chapter 2. Getting Neural Networks to Learn
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that you have been introduced to neural networks, it is time to learn about
    their learning process. In this chapter, we''re going to explore the concepts
    involved with neural network learning, along with their implementation in Java.
    We will make a review on the foundations and inspirations for the neural learning
    process that will guide us in implementation of learning algorithms in Java to
    be applied on our neural network code. In summary, these are the concepts addressed
    in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Learning ability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How learning helps
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learning paradigms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Supervised
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unsupervised
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The learning process
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Optimization foundations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The cost function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Error measurement
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learning algorithms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Delta rule
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hebbian rule
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adaline/perceptron
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training, test, and validation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dataset splitting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Overfitting and overtraining
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generalization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learning ability in neural networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What is really amazing in neural networks is their capacity to learn from the
    environment, just like brain-gifted beings are able to do so. We, as humans, experience
    the learning process through observations and repetitions, until some task, or
    concept is completely mastered. From the physiological point of view, the learning
    process in the human brain is a reconfiguration of the neural connections between
    the nodes (neurons), which results in a new thinking structure.
  prefs: []
  type: TYPE_NORMAL
- en: While the connectionist nature of neural networks distributes the learning process
    all over the entire structure, this feature makes this structure flexible enough
    to learn a wide variety of knowledge. As opposed to ordinary digital computers
    that can execute only tasks they are programmed to do, neural systems are able
    to improve and perform new activities according to some satisfaction criteria.
    In other words, neural networks don't need to be programmed; they learn the program
    by themselves.
  prefs: []
  type: TYPE_NORMAL
- en: How learning helps solving problems
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Considering that every task to solve may have a huge number of theoretically
    possible solutions, the learning process seeks to find an optimal solution that
    can produce a satisfying result. The use of structures such as **artificial neural
    networks** (**ANN**) is encouraged due to their ability to acquire knowledge of
    any type, strictly by receiving input stimuli, that is, data relevant to the task/problem.
    At first, the ANN will produce a random result and an error, and based on this
    error, the ANN parameters are adjusted.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We can then think of the ANN parameters (weights) as the components of a solution.
    Let's imagine that each weight corresponds to a dimension and one single solution
    represents a single point in the solution hyperspace. For each single solution,
    there is an error measure informing how far that solution is from the satisfaction
    criteria. The learning algorithm then iteratively seeks a solution closer to the
    satisfaction criteria.
  prefs: []
  type: TYPE_NORMAL
- en: Learning paradigms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are basically two types of learning for neural networks, namely supervised,
    and unsupervised. The learning in the human mind, for example, also works in this
    way. We are able to build knowledge from observations without any target (unsupervised)
    or we can have a teacher who shows us the right pattern to follow (supervised).
    The difference between these two paradigms relies mainly on the relevancy of a
    target pattern, and varies from problem to problem.
  prefs: []
  type: TYPE_NORMAL
- en: Supervised learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This learning type deals with pairs of *xs* (independent values), and *ys*
    (dependent values) with the objective to map them in a function . Here the Y data
    is the *supervisor*, the target desired outputs, and the X are the source independent
    data that jointly generate the Y data. It is analogous to a teacher who is teaching
    somebody a certain task to be performed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Supervised learning](img/B05964_02_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: One particular feature of this learning paradigm is that there is a direct error
    reference which is just the comparison between the target and the current actual
    result. The network parameters are fed into a cost function which quantifies the
    mismatch between desired and actual outputs.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A cost function is just a measurement to be minimized in an optimization problem.
    That means one seeks to find the parameters that drive the cost function to the
    lowest possible value.
  prefs: []
  type: TYPE_NORMAL
- en: The cost function will be covered in detail later in this chapter
  prefs: []
  type: TYPE_NORMAL
- en: The supervised learning is suitable for tasks having a defined pattern to be
    reproduced. Some examples include classification of images, speech recognition,
    function approximation, and forecasting. Note that the neural network should be
    provided a previous knowledge of both input independent values (X) and the output
    dependent values (Y). The presence of a dependent output value is a necessary
    condition for the learning to be supervised.
  prefs: []
  type: TYPE_NORMAL
- en: Unsupervised learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In unsupervised learning, we deal only with data without any labeling or classification.
    Instead, one tries to make an inference and extract knowledge by taking into account
    only the independent data X:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Unsupervised learning](img/B05964_02_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: This is analogous to self-learning, when someone takes into account his/her
    own experience and a set of supporting criteria. In unsupervised learning, we
    don't have a defined desired pattern; instead, we use the provided data to infer
    a dependent output Y without any supervision.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In unsupervised learning, the closer the independent data is, more similar the
    generated output should be, and this should be considered in the cost function,
    as opposed to the supervised paradigm.
  prefs: []
  type: TYPE_NORMAL
- en: Examples of tasks that unsupervised learning can be applied to are clustering,
    data compression, statistical modeling, and language modeling. This learning paradigm
    will be covered in more detail in [Chapter 4](ch04.xhtml "Chapter 4. Self-Organizing
    Maps"), *Self-Organizing Maps*.
  prefs: []
  type: TYPE_NORMAL
- en: The learning process
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we have theoretically defined the learning process and how it is carried
    out. But in practice, we must dive a little bit deeper into the mathematical logic,
    in order to implement the learning algorithm itself. For simplicity, in this chapter,
    we are basically covering the supervised learning case; however, we will present
    here a rule for updating weights in unsupervised learning. A learning algorithm
    is a procedure that drives the learning process of neural networks, and it is
    strongly determined by the neural network architecture. From the mathematical
    point of view, one wishes to find the optimal weights W that can drive the cost
    function C(X, Y) to the lowest possible value. However, sometimes the learning
    process cannot find a good set of weights capable of meeting the acceptance criteria,
    but a stop condition must be set to prevent the neural network from learning forever
    and thereby causing the Java program to freeze.
  prefs: []
  type: TYPE_NORMAL
- en: 'In general, this process is carried out in the fashion presented in the following
    flowchart:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The learning process](img/B05964_02_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The cost function finding the way down to the optimum
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now let''s find out in detail what role the cost function plays. Let''s think
    of cost function as a two-variable function whose shape is represented by a hypersurface.
    For simplicity, let''s consider for now only two weights (two-dimensional space
    plus height representing cost function). Suppose our cost function has the following
    shape:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The cost function finding the way down to the optimum](img/B05964_02_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Visually, we can see that there is an optimum, by which the cost function roughly
    approaches zero. But how can we make this programmatically? The answer lies in
    the mathematical optimization, whereby the cost function is defined as an optimization
    problem:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The cost function finding the way down to the optimum](img/B05964_02_04_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: By recalling the optimization Fermat's theorems, the optimal solution lies in
    a place where the surface slope should be zero at all dimensions, that is, the
    partial derivative should be zero, and it should be convex (for the minimum case).
    Considering that one starts with an arbitrary solution W, the search for the optimum
    should take into account the direction to which the surface height is going down.
    This is the so-called gradient method.
  prefs: []
  type: TYPE_NORMAL
- en: Learning in progress - weight update
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'According to the cost function used, an update rule will dictate how the weights,
    the neural flexible parameters, should be changed, so the cost function will have
    a lower value at the new weights:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Learning in progress - weight update](img/B05964_02_04_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Here, k refers to the kth iteration and *W(k)* refers to the neural weights
    at the kth iteration, and subsequently *k+1* refers to the next iteration.
  prefs: []
  type: TYPE_NORMAL
- en: The weight update operation can be performed in online or batch mode. Online
    here implies that the weights are updated after every single record from the dataset.
    Batch update means that first all the records from the dataset are presented to
    the neural network before it starts updating its weights. This will be explored
    in detail in the code at the end of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Calculating the cost function
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When a neural network learns, it receives data from an environment and adapts
    its weights according to the objective. This data is referred to as the training
    dataset and has several samples. The idea behind the word training lies in the
    process of adapting the neural weights, as if they were *training* to give the
    desired response in the neural network. While the neural network is still learning,
    there is an error between the target outputs (Y) and the neural outputs (), in
    the supervised case:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Calculating the cost function](img/B05964_02_04_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Some literature about neural networks identifies the target variable with the
    letter T, and the neural output as Y, while in this book we are going to the denote
    it as Y and, to not confuse the reader, since it was presented initially as Y.
  prefs: []
  type: TYPE_NORMAL
- en: 'Well, given that the training dataset has multiple values, there will be N
    values of errors for each single record. So, how to get an overall error? One
    intuitive approach is to get an average of all errors, but this is misleading.
    The error vector can take on both positive and negative values, therefore an average
    of all error values is very likely to be closer to zero, regardless of how big
    the error measurements may be. Using the absolute value to generate an average
    seems to be a smarter approach, but this function has a discontinuity at the origin,
    what is awkward in calculating its derivative:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Calculating the cost function](img/B05964_02_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'So, the reasonable option we have is to use the average of a quadratic sum
    of the error, also known as **mean squared error (MSE)**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Calculating the cost function](img/B05964_02_05_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: General error and overall error
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We need to clarify one thing before going further. The neural network being
    a multiple output structure, we have to deal with the multiple output case, when
    instead of an error vector, we will have an error matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '![General error and overall error](img/B05964_02_05_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Well, in such cases, there may be a huge number of errors to work with, whether
    regarding one specific output, a specific record, or the whole dataset. To facilitate
    understanding, let's call the specific-to-record error the general error, by which
    all output errors are given one scalar for the general output error; and the error
    referring to the whole data as overall error.
  prefs: []
  type: TYPE_NORMAL
- en: 'The general error for single output network is a mere difference between target
    and output, but in the multiple output case, it needs be composed of each output
    error. As we saw, the squared error is a suitable approach to summarize error
    measures, therefore the general error can be calculated using the square of each
    output error:'
  prefs: []
  type: TYPE_NORMAL
- en: '![General error and overall error](img/B05964_02_05_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: As for the overall error, it actually considers the general error but for all
    records in the dataset. Since the dataset can be huge, it is better to calculate
    the overall error using the MSE of the quadratic general errors.
  prefs: []
  type: TYPE_NORMAL
- en: Can the neural network learn forever? When is it good to stop?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As the learning process is run, the neural network must give results closer
    and closer to the expectation, until finally it reaches the acceptation criteria
    or one limitation in learning iterations, that we''ll call epochs. The learning
    process is then considered to be finished when one of these conditions is met:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Satisfaction criterion**: minimum overall error or minimum weight distance,
    according to the learning paradigm'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Maximum number of epochs**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Examples of learning algorithms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's now merge the theoretical content presented so far together into simple
    examples of learning algorithms. In this chapter, we are going to explore a couple
    of learning algorithms in single layer neural networks; multiple layers will be
    covered in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: In the Java code, we will create one new superclass `LearningAlgorithm` in a
    new package `edu.packt.neural.learn`. Another useful package called `edu.packt.neural.data`
    will be created to handle datasets that will be processed by the neural network,
    namely the classes `NeuralInputData`, and `NeuralOutputData`, both referenced
    by the `NeuralDataSet` class. We recommend the reader takes a glance at the code
    documentation to understand how these classes are organized, to save text space
    here.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `LearningAlgorithm` class has the following attributes and methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The `neuralNet` object is a reference to the neural network that will be trained
    by this learning algorithm. The `enums` define the learning mode and learning
    paradigm. The learning executing parameters are defined (MaxEpochs, MinOverallError,
    LearningRate), and the datasets that will be taken into account during the learning
    process.
  prefs: []
  type: TYPE_NORMAL
- en: The method `train( )` should be overridden by each learning algorithm implementation.
    All the training process will occur in this method. The methods `forward( )` and
    `forward(int k)` process the neural network with all input data and with the kth
    input data record, respectively. And finally, the method `calcNewWeight( )` will
    perform the weight update for the weight connecting an input to a neuron in a
    specific layer. A variation in the `calcNewWeight( )` method allows providing
    a specific error to be taken in the update operation.
  prefs: []
  type: TYPE_NORMAL
- en: The delta rule
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This algorithm updates the weights according to the cost function. Following
    the gradient approach, one wants to know which weights can drive the cost function
    to a lower value. Note that we can find the direction by computing the partial
    derivative of the cost function to each of the weights. To help in understanding,
    let''s consider one simple approach with only one neuron, one weight, and one
    bias, and therefore one input. The output will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The delta rule](img/B05964_02_05_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, g is the activation function, X is the vector containing x values, and
    Y is the output vector generated by the neural network. The general error for
    the kth sample is quite simple:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The delta rule](img/B05964_02_05_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'However, it is possible to define this error as square error, N-degree error,
    or MSE. But, for simplicity, let''s consider the simple error difference for the
    general error. Now the overall error, that will be the cost function, should be
    computed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The delta rule](img/B05964_02_05_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The weight and bias are updated according to the delta rule, that considers
    the partial derivatives ![The delta rule](img/B05964_02_05_07.jpg) with respect
    to the weight and the bias, respectively. For the batch training mode, X and E
    are vectors:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The delta rule](img/B05964_02_05_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'If the training mode is online, we don''t need to perform dot product:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The delta rule](img/B05964_02_05_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The learning rate
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Note in the preceding equations the presence of the term α that indicates the
    learning rate. It plays an important role in weight update, because it can drive
    faster or slower to the minimum cost value. Let''s see a cost error surface in
    relation to two weights:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The learning rate](img/B05964_02_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Implementing the delta rule
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will implement the delta rule in a class called `DeltaRule`, that will extend
    the `LearningAlgorithm` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The errors discussed in the error measurement section (general and overall errors)
    are implemented in the `DeltaRule` class, because the delta rule learning algorithm
    considers these errors during the training. They are arrays because there will
    be a general error for each dataset record, and there will be an overall error
    for each output. An attribute `overallGeneralError` takes on the cost function
    result, or namely the overall error for all outputs and records. A matrix called
    error, stores the errors for each output record combination.
  prefs: []
  type: TYPE_NORMAL
- en: This class also allows multiple ways of calculating the overall and general
    errors. The attributes `generalErrorMeasurement` and `overallErrorMeasurement`
    can take on one of the input values for simple error, square error calculation,
    Nth degree error (cubic, quadruple, and so on), or the MSE. The default will be
    simple error for the general error and MSE for the overall.
  prefs: []
  type: TYPE_NORMAL
- en: 'Two important attributes are worth noting in this code: `currentRecord` refers
    to the index of the record being fed into the neural network during training,
    and the `newWeights` cubic matrix is a collection of all new values of weights
    that will be updated in the neural network. The `currentRecord` attribute is useful
    in the online training, and the `newWeights` matrix helps the neural network to
    keep all of its original weights until all new weights calculation is finished,
    preventing new weights to be updated during the forward processing stage, what
    could compromise the training quality significantly.'
  prefs: []
  type: TYPE_NORMAL
- en: The core of the delta rule learning - train and calcNewWeight methods
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To save space, we will not detail here the implementation of the forward methods.
    As described in the previous section, forward means that neural dataset records
    should be fed into the neural network and then the error values are calculated:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: We note that in the `train( )` method, there is a loop with a condition to continue
    training. This means that while the training will stop when this condition no
    longer holds true. The condition checks the `epoch` number and the overall error.
    When the `epoch` number reaches the maximum or the error reaches the minimum,
    the training is finished. However, there are some cases in which the overall error
    fails to meet the minimum requirement, and the neural network needs to stop training.
  prefs: []
  type: TYPE_NORMAL
- en: 'The new weight is calculated using the `calcNewWeight( )` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Note that in the weight update, there a call to the derivative of the activation
    function of the given neuron. This is needed to meet the delta rule. In the activation
    function interface, we've added this method `derivative( )` to be overridden in
    each of the implementing classes.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Note: For the batch mode the call to the `derivativeBatch( )`, that receives
    and returns an array of values, instead of a single scalar.'
  prefs: []
  type: TYPE_NORMAL
- en: In the `train( )` method, we've seen that new weights are stored in the `newWeights`
    attribute, to not influence the current learning process, and are only applied
    after the training iteration has finished.
  prefs: []
  type: TYPE_NORMAL
- en: Another learning algorithm - Hebbian learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the 1940s, the neuropsychologist Donald Hebb postulated that the connections
    between neurons that activate or fire simultaneously, or using his words, repeatedly
    or persistently, should be increased. This is one approach of unsupervised learning,
    since no target output is specified for Hebbian learning:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Another learning algorithm - Hebbian learning](img/B05964_02_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'In summary, the weight update rule for Hebbian learning takes into account
    only the input and outputs of the neuron. Given a neuron j whose connection to
    neuron i (weight ij) is to be updated, the update is given by the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Another learning algorithm - Hebbian learning](img/B05964_02_07_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Here, α is a learning rate, oj is the output of the neuron j, and oi is the
    output of the neuron i, also the input i for the neuron j. For the batch training
    case, oi and oj will be vectors, and we'll need to perform a dot product.
  prefs: []
  type: TYPE_NORMAL
- en: Since we don't include error measurement in Hebbian learning, a stop condition
    can be determined by the maximum number of epochs or the increase in the overall
    average of neural outputs. Given N records, we compute the expectancy or average
    of all outputs produced by the neural network. When this average increases over
    a certain level, it is time to stop the training, to prevent the neural outputs
    from blowing up.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll develop a new class for Hebbian learning, also inheriting from `LearningAlgorithm`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'All parameters except for the absent error measures and the new measures of
    mean are identical to the `DeltaRule` class. The methods are quite similar, except
    for the `calcNewWeight( )`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Adaline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Adaline is an architecture standing for Adaptive Linear Neuron, developed by
    Bernard Widrow and Ted Hoff, based on the McCulloch, and Pitts neuron. It has
    only one layer of neurons and can be trained similarly to the delta rule. The
    main difference lies in the fact that the update rule is given by the error between
    the weighted sum of inputs and biases and the target output, instead of updating
    based on the neuron output after the activation function. This may be desirable
    when one wants to perform continuous learning for classification problems, which
    tend to use discrete values instead of continuous.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following figure illustrates how Adaline learns:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Adaline](img/B05964_02_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'So the weights are updated by the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Adaline](img/B05964_02_08_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'In order to implement Adaline, we create a class called **Adaline** with the
    following overridden `weight calcNewWeight`. To save space, we''re presenting
    only the online case:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Note the method `getOutputBeforeActivation( )`; we mentioned in the last chapter
    that this property would be useful in the future.
  prefs: []
  type: TYPE_NORMAL
- en: Time to see the learning in practice!
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s work on a very simple yet illustrative example. Suppose you want a single
    neuron neural network to learn how to fit a simple linear function such as the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '| ![Time to see the learning in practice!](img/B05964_02_09_01.jpg) | ![Time
    to see the learning in practice!](img/B05964_02_09.jpg) |'
  prefs: []
  type: TYPE_TB
- en: This is quite easy even for those who have little math background, so guess
    what? It is a nice start for our simplest neural network to prove its learning
    ability!
  prefs: []
  type: TYPE_NORMAL
- en: Teaching the neural network – the training dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We;re going to structure the dataset for the neural network to learn using
    the following code, which you can find in the main method of the file `NeuralNetDeltaRuleTest`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The `funcTest` function is defined as the function we mentioned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that we''re using the class `NeuralDataSet` to structure all this data
    in such a way that they will be fed into the neural network the right way. Now
    let''s link this dataset to the neural network. Remember that this network has
    a single neuron in the output. Let''s use a nonlinear activation function such
    as hyperbolic tangent at the output with a coefficient `0.85`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s now instantiate the `DeltaRule` object and link it to the neural network
    created. Then we''ll set the learning parameters such as learning rate, minimum
    overall error, and maximum number of epochs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let''s see the first neural output of the untrained neural network, after
    calling the method `forward( )` of the `deltaRule` object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '![Teaching the neural network – the training dataset](img/B05964_02_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Plotting a chart, we find that the output generated by the neural network is
    a little bit different:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Teaching the neural network – the training dataset](img/B05964_02_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'We will start training the neural network in the online mode. We''ve set the
    `printTraining` attribute as true, so we will receive in the screen an update.
    The following piece of code will produce the subsequent screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '![Teaching the neural network – the training dataset](img/B05964_02_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The training begins and the overall error information is updated after every
    weight update. Note the error is decreasing:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Teaching the neural network – the training dataset](img/B05964_02_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'After five epochs, the error reaches the minimum; now let''s see the neural
    outputs and the plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '| ![Teaching the neural network – the training dataset](img/B05964_02_14.jpg)
    | ![Teaching the neural network – the training dataset](img/B05964_02_15.jpg)
    |'
  prefs: []
  type: TYPE_TB
- en: 'Quite amazing, isn''t it? The target and the neural output are practically
    the same. Now let''s take a look at the final `weight` and `bias`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Amazing, it learned! Or, did it really? A further step – testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Well, we might ask now: so the neural network has already learned from the
    data; how can we attest it has effectively learned? Just like in exams students
    are subjected to, we need to check the network response after training. But wait!
    Do you think it is likely a teacher would put in an exam the same questions he/she
    has presented in class? There is no sense in evaluating somebody''s learning with
    examples that are already known, or a suspecting teacher would conclude the student
    might have memorized the content, instead of having learned it.'
  prefs: []
  type: TYPE_NORMAL
- en: Okay, let's now explain this part. What we are talking about here is testing.
    The learning process we have covered is called training. After training a neural
    network, we should test whether it has really learnt. For testing, we must present
    to the neural network another fraction of data from the same environment it has
    learnt from. This is necessary because, just like the student, the neural network
    could respond properly to only the data points it has been exposed to; this is
    called overtraining. To check whether the neural network has not passed on overtraining,
    we must check its response to other data points.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following figure illustrates the overtraining problem. Imagine that our
    network is designed to approximate some function f(x) whose definition is unknown.
    The neural network was fed with some data from that function and produced the
    result shown on the left in the following figure. But when expanding to a wider
    domain, for example, adding a testing dataset, we note the neural response does
    not follow the data (on the right in the figure):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Amazing, it learned! Or, did it really? A further step – testing](img/B05964_02_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'In this case, we see that the neural network failed to learn the whole environment
    (the function *f(x)*). This happens because of a number of reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: The neural network didn't receive enough information from the environment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The data from the environment is nondeterministic
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The training and testing datasets are poorly defined
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The neural network has learnt so much on the training data, it has *forgotten*
    about the testing data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Throughout this book, we are going to cover the process to prevent this and
    other issues that may arise during training.
  prefs: []
  type: TYPE_NORMAL
- en: Overfitting and overtraining
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In our previous example, the neural network seemed to have learned amazingly
    well. However, there is a risk of overfitting and overtraining. The difference
    between these two concepts is very subtle. An overfitting occurs when the neural
    network memorizes the problem''s behavior, so that it can provide good values
    only on training points, therefore losing a generalization capacity. Overtraining,
    which can be a cause for overfitting, occurs when the training error becomes much
    smaller than the testing error, or actually, the testing error starts to increase
    as the neural network continues (over)training:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Overfitting and overtraining](img/B05964_02_17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: One of ways to prevent overtraining and overfitting is checking the testing
    error when the training goes on. When the testing error starts to increase, it
    is time to stop. This will be covered more in detail in the next chapters.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s see if there is the case in our example. Let''s now add some more
    data and test it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '| ![Overfitting and overtraining](img/B05964_02_18.jpg) | ![Overfitting and
    overtraining](img/B05964_02_19.jpg) |'
  prefs: []
  type: TYPE_TB
- en: As can be seen, the neural network presents a generalization capacity in this
    case. In spite of the simplicity of this example, we can still see the learning
    skill of the neural network.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter presented the reader with the whole learning process of which neural
    networks are capable. We presented the very basic foundations of learning, inspired
    by human learning itself. To illustrate this process in practice, we have implemented
    two learning algorithms in Java, and applied them in two examples. With this,
    the reader can have a basic but useful understanding on how neural networks learn
    and even how one can systematically describe the process of learning. This will
    be the foundation for the next chapters, which will present more complex examples.
  prefs: []
  type: TYPE_NORMAL
