["```py\n!pip install llama-index-vector-stores-deeplake==0.1.6 \n```", "```py\n!pip install deeplake==3.9.8 \n```", "```py\n!pip install llama-index==0.10.64 \n```", "```py\nfrom llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Document\nfrom llama_index.vector_stores.deeplake import DeepLakeVectorStore \n```", "```py\n!mkdir data \n```", "```py\nimport requests\nfrom bs4 import BeautifulSoup\nimport re\nimport os\nurls = [\n    \"https://github.com/VisDrone/VisDrone-Dataset\",\n    \"https://paperswithcode.com/dataset/visdrone\",\n    \"https://openaccess.thecvf.com/content_ECCVW_2018/papers/11133/Zhu_VisDrone-DET2018_The_Vision_Meets_Drone_Object_Detection_in_Image_Challenge_ECCVW_2018_paper.pdf\",\n    \"https://github.com/VisDrone/VisDrone2018-MOT-toolkit\",\n    \"https://en.wikipedia.org/wiki/Object_detection\",\n    \"https://en.wikipedia.org/wiki/Computer_vision\",…\n] \n```", "```py\ndef clean_text(content):\n    # Remove references and unwanted characters\n    content = re.sub(r'\\[\\d+\\]', '', content)   # Remove references\n    content = re.sub(r'[^\\w\\s\\.]', '', content)  # Remove punctuation (except periods)\n    return content\ndef fetch_and_clean(url):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()  # Raise exception for bad responses (e.g., 404)\n        soup = BeautifulSoup(response.content, 'html.parser')\n        # Prioritize \"mw-parser-output\" but fall back to \"content\" class if not found\n        content = soup.find('div', {'class': 'mw-parser-output'}) or soup.find('div', {'id': 'content'})\n        if content is None:\n            return None\n        # Remove specific sections, including nested ones\n        for section_title in ['References', 'Bibliography', 'External links', 'See also', 'Notes']:\n            section = content.find('span', id=section_title)\n            while section:\n                for sib in section.parent.find_next_siblings():\n                    sib.decompose()\n                section.parent.decompose()\n                section = content.find('span', id=section_title)\n        # Extract and clean text\n        text = content.get_text(separator=' ', strip=True)\n        text = clean_text(text)\n        return text\n    except requests.exceptions.RequestException as e:\n        print(f\"Error fetching content from {url}: {e}\")\n        return None  # Return None on error \n```", "```py\n# Directory to store the output files\noutput_dir = './data/'\nos.makedirs(output_dir, exist_ok=True)\n# Processing each URL and writing its content to a separate file\nfor url in urls:\n    article_name = url.split('/')[-1].replace('.html',\")  # Handle .html extension\n    filename = os.path.join(output_dir, article_name + '.txt')  # Create a filename for the article\n    clean_article_text = fetch_and_clean(url)\n    with open(filename, 'w', encoding='utf-8') as file:\n        file.write(clean_article_text)\nprint(f\"Content(ones that were possible) written to files in the '{output_dir}' directory.\") \n```", "```py\nWARNING:bs4.dammit:Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\nContent(ones that were possible) written to files in the './data/' directory. \n```", "```py\n# load documents\ndocuments = SimpleDirectoryReader(\"./data/\").load_data() \n```", "```py\ndocuments[0] \n```", "```py\n'/content/data/1804.06985.txt', 'file_name': '1804.06985.txt', 'file_type': 'text/plain', 'file_size': 3698, 'creation_date': '2024-05-27', 'last_modified_date': '2024-05-27'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='High Energy Physics  Theory arXiv1804.06985 hepth Submitted on 19 Apr 2018 Title A Near Horizon Extreme Binary Black Hole Geometry Authors Jacob Ciafre  Maria J. Rodriguez View a PDF of the paper titled A Near Horizon Extreme Binary Black Hole Geometry by Jacob Ciafre and Maria J. Rodriguez View PDF Abstract A new solution of fourdimensional vacuum General Relativity is presented… \n```", "```py\nfrom llama_index.core import StorageContext\nvector_store_path = \"hub://denis76/drone_v2\"\ndataset_path = \"hub://denis76/drone_v2\" \n```", "```py\nvector_store_path = \"hub://[YOUR VECTOR STORE/ \n```", "```py\n# overwrite=True will overwrite dataset, False will append it\nvector_store = DeepLakeVectorStore(dataset_path=dataset_path, overwrite=True)\nstorage_context = StorageContext.from_defaults(vector_store=vector_store)\n# Create an index over the documents\nindex = VectorStoreIndex.from_documents(documents, storage_context=storage_context)\n) \n```", "```py\nYour Deep Lake dataset has been successfully created!\nUploading data to deeplake dataset.\n100%|██████████| 41/41 [00:02<00:00, 18.15it/s] \n```", "```py\nDataset(path='hub://denis76/drone_v2', tensors=['text', 'metadata', 'embedding', 'id']) \n```", "```py\nimport deeplake\nds = deeplake.load(dataset_path)  # Load the dataset \n```", "```py\n/\nThis dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/denis76/drone_v2\nhub://denis76/drone_v2 loaded successfully.\nThis dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/denis76/drone_v1\nhub://denis76/drone_v2 loaded successfully. \n```", "```py\nimport json\nimport pandas as pd\nimport numpy as np\n# Assuming 'ds' is your loaded Deep Lake dataset\n# Create a dictionary to hold the data\ndata = {}\n# Iterate through the tensors in the dataset\nfor tensor_name in ds.tensors:\n    tensor_data = ds[tensor_name].numpy()\n    # Check if the tensor is multi-dimensional\n    if tensor_data.ndim > 1:\n        # Flatten multi-dimensional tensors\n        data[tensor_name] = [np.array(e).flatten().tolist() for e in tensor_data]\n    else:\n        # Convert 1D tensors directly to lists and decode text\n        if tensor_name == \"text\":\n            data[tensor_name] = [t.tobytes().decode('utf-8') if t else \"\" for t in tensor_data]\n        else:\n            data[tensor_name] = tensor_data.tolist()\n# Create a Pandas DataFrame from the dictionary\ndf = pd.DataFrame(data) \n```", "```py\n# Function to display a selected record\ndef display_record(record_number):\n    record = df.iloc[record_number]\n    display_data = {\n        \"ID\": record[\"id\"] if \"id\" in record else \"N/A\",\n        \"Metadata\": record[\"metadata\"] if \"metadata\" in record else \"N/A\",\n        \"Text\": record[\"text\"] if \"text\" in record else \"N/A\",\n        \"Embedding\": record[\"embedding\"] if \"embedding\" in record else \"N/A\"\n    } \n```", "```py\n# Function call to display a record\nrec = 0  # Replace with the desired record number\ndisplay_record(rec) \n```", "```py\nID:\n['a89cdb8c-3a85-42ff-9d5f-98f93f414df6'] \n```", "```py\n['High Energy Physics  Theory arXiv1804.06985 hepth Submitted on 19 Apr 2018 Title A Near Horizon Extreme Binary Black Hole Geometry Authors Jacob Ciafre  Maria J. Rodriguez View a PDF of the paper titled A Near Horizon Extreme Binary… \n```", "```py\n[-0.0009671939187683165, 0.010151553899049759, -0.010979819111526012, -0.003061748342588544, -0.00865076668560505, 0.02144993655383587, -0.01412297785282135, -0.02674516849219799, -0.008693241514265537, -0.03383851423859596, 0.011404570192098618, 0.015956487506628036, -0.013691147789359093, 0.008856062777340412,…] \n```", "```py\nuser_input=\"How do drones identify vehicles?\" \n```", "```py\n#similarity_top_k\nk=3\n#temperature\ntemp=0.1\n#num_output\nmt=1024 \n```", "```py\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sentence_transformers import SentenceTransformer\nmodel = SentenceTransformer('all-MiniLM-L6-v2')\ndef calculate_cosine_similarity_with_embeddings(text1, text2):\n    embeddings1 = model.encode(text1)\n    embeddings2 = model.encode(text2)\n    similarity = cosine_similarity([embeddings1], [embeddings2])\n    return similarity[0][0] \n```", "```py\nfrom llama_index.core import VectorStoreIndex\nvector_store_index = VectorStoreIndex.from_documents(documents) \n```", "```py\nprint(type(vector_store_index)) \n```", "```py\n<class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> \n```", "```py\nvector_query_engine = vector_store_index.as_query_engine(similarity_top_k=k, temperature=temp, num_output=mt) \n```", "```py\nimport pandas as pd\nimport textwrap\ndef index_query(input_query):\n    response = vector_query_engine.query(input_query)\n    # Optional: Print a formatted view of the response (remove if you don't need it in the output)\n    print(textwrap.fill(str(response), 100))\n    node_data = []\n    for node_with_score in response.source_nodes:\n        node = node_with_score.node\n        node_info = {\n            'Node ID': node.id_,\n            'Score': node_with_score.score,\n            'Text': node.text\n        }\n        node_data.append(node_info)\n    df = pd.DataFrame(node_data)\n    # Instead of printing, return the DataFrame and the response object\n    return df, response, \n```", "```py\nimport time\n#start the timer\nstart_time = time.time()\ndf, response = index_query(user_input)\n# Stop the timer\nend_time = time.time()\n# Calculate and print the execution time\nelapsed_time = end_time - start_time\nprint(f\"Query execution time: {elapsed_time:.4f} seconds\")\nprint(df.to_markdown(index=False, numalign=\"left\", stralign=\"left\"))  # Display the DataFrame using markdown \n```", "```py\nDrones can automatically identify vehicles across different cameras with different viewpoints and hardware specifications using reidentification methods. \n```", "```py\nQuery execution time: 0.8831 seconds \n```", "```py\nnodeid=response.source_nodes[0].node_id\nnodeid \n```", "```py\n4befdb13-305d-42db-a616-5d9932c17ac8 \n```", "```py\nresponse.source_nodes[0].get_text() \n```", "```py\n['These activities can be carried out with different approaches that include photogrammetry SfM thermography multispectral images 3D field scanning NDVI maps etc. Agriculture forestry and environmental studies edit Main article Agricultural drone As global demand for food production grows exponentially resources are depleted farmland is… \n```", "```py\nfor node_with_score in response.source_nodes:\n    node = node_with_score.node  # Extract the Node object from NodeWithScore\n    chunk_size = len(node.text)\n    print(f\"Node ID: {node.id_}, Chunk Size: {chunk_size} characters\") \n```", "```py\nNode ID: 83a135c6-dddd-402e-9423-d282e6524160, Chunk Size: 4417 characters\nNode ID: 7b7b55fe-0354-45bc-98da-0a715ceaaab0, Chunk Size: 1806 characters\nNode ID: 18528a16-ce77-46a9-bbc6-5e8f05418d95, Chunk Size: 3258 characters \n```", "```py\nimport numpy as np\ndef info_metrics(response):\n  # Calculate the performance (handling None scores)\n  scores = [node.score for node in response.source_nodes if node.score is not None]\n  if scores:  # Check if there are any valid scores\n      weights = np.exp(scores) / np.sum(np.exp(scores))\n      perf = np.average(scores, weights=weights) / elapsed_time\n  else:\n      perf = 0  # Or some other default value if all scores are None \n```", "```py\nperf = np.average(scores, weights=weights) / elapsed_time \n```", "```py\ninfo_metrics(response) \n```", "```py\nAverage score: 0.8374\nQuery execution time: 1.3266 seconds\nPerformance metric: 0.6312 \n```", "```py\nfrom llama_index.core import TreeIndex\ntree_index = TreeIndex.from_documents(documents) \n```", "```py\nprint(type(tree_index)) \n```", "```py\n<class 'llama_index.core.indices.tree.base.TreeIndex'> \n```", "```py\ntree_query_engine = tree_index.as_query_engine(similarity_top_k=k, temperature=temp, num_output=mt) \n```", "```py\nimport time\nimport textwrap\n# Start the timer\nstart_time = time.time()\nresponse = tree_query_engine.query(user_input)\n# Stop the timer\nend_time = time.time()\n# Calculate and print the execution time\nelapsed_time = end_time - start_time\nprint(f\"Query execution time: {elapsed_time:.4f} seconds\")\nprint(textwrap.fill(str(response), 100)) \n```", "```py\nQuery execution time: 4.3360 seconds\nDrones identify vehicles using computer vision technology related to object detection. This\ntechnology involves detecting instances of semantic objects of a certain class, such as vehicles, in\ndigital images and videos. Drones can be equipped with object detection algorithms, such as YOLOv3\nmodels trained on datasets like COCO, to detect vehicles in real-time by analyzing the visual data\ncaptured by the drone's cameras. \n```", "```py\nsimilarity_score = calculate_cosine_similarity_with_embeddings(user_input, str(response))\nprint(f\"Cosine Similarity Score: {similarity_score:.3f}\")\nprint(f\"Query execution time: {elapsed_time:.4f} seconds\")\nperformance=similarity_score/elapsed_time\nprint(f\"Performance metric: {performance:.4f}\") \n```", "```py\nCosine Similarity Score: 0.731\nQuery execution time: 4.3360 seconds\nPerformance metric: 0.1686 \n```", "```py\nfrom llama_index.core import ListIndex\nlist_index = ListIndex.from_documents(documents) \n```", "```py\nprint(type(list_index)) \n```", "```py\n<class 'llama_index.core.indices.list.base.SummaryIndex'> \n```", "```py\nlist_query_engine = list_index.as_query_engine(similarity_top_k=k, temperature=temp, num_output=mt) \n```", "```py\n#start the timer\nstart_time = time.time()\nresponse = list_query_engine.query(user_input)\n# Stop the timer\nend_time = time.time()\n# Calculate and print the execution time\nelapsed_time = end_time - start_time\nprint(f\"Query execution time: {elapsed_time:.4f} seconds\")\nprint(textwrap.fill(str(response), 100)) \n```", "```py\nQuery execution time: 16.3123 seconds\nDrones can identify vehicles through computer vision systems that process image data captured by\ncameras mounted on the drones. These systems use techniques like object recognition and detection to\nanalyze the images and identify specific objects, such as vehicles, based on predefined models or\nfeatures. By processing the visual data in real-time, drones can effectively identify vehicles in\ntheir surroundings. \n```", "```py\nsimilarity_score = calculate_cosine_similarity_with_embeddings(user_input, str(response))\nprint(f\"Cosine Similarity Score: {similarity_score:.3f}\")\nprint(f\"Query execution time: {elapsed_time:.4f} seconds\")\nperformance=similarity_score/elapsed_time\nprint(f\"Performance metric: {performance:.4f}\") \n```", "```py\nCosine Similarity Score: 0.775\nQuery execution time: 16.3123 seconds\nPerformance metric: 0.0475 \n```", "```py\nfrom llama_index.core import KeywordTableIndex\nkeyword_index = KeywordTableIndex.from_documents(documents) \n```", "```py\n# Extract data for DataFrame\ndata = []\nfor keyword, doc_ids in keyword_index.index_struct.table.items():\n    for doc_id in doc_ids:\n        data.append({\"Keyword\": keyword, \"Document ID\": doc_id})\n# Create the DataFrame\ndf = pd.DataFrame(data)\ndf \n```", "```py\nkeyword_query_engine = keyword_index.as_query_engine(similarity_top_k=k, temperature=temp, num_output=mt) \n```", "```py\nimport time\n# Start the timer\nstart_time = time.time()\n# Execute the query (using .query() method)\nresponse = keyword_query_engine.query(user_input)\n# Stop the timer\nend_time = time.time()\n# Calculate and print the execution time\nelapsed_time = end_time - start_time\nprint(f\"Query execution time: {elapsed_time:.4f} seconds\")\nprint(textwrap.fill(str(response), 100)) \n```", "```py\nQuery execution time: 2.4282 seconds\nDrones can identify vehicles through various means such as visual recognition using onboard cameras, sensors, and image processing algorithms. They can also utilize technologies like artificial intelligence and machine learning to analyze and classify vehicles based on their shapes, sizes, and movement patterns. Additionally, drones can be equipped with specialized software for object detection and tracking to identify vehicles accurately. \n```", "```py\nsimilarity_score = calculate_cosine_similarity_with_embeddings(user_input, str(response))\nprint(f\"Cosine Similarity Score: {similarity_score:.3f}\")\nprint(f\"Query execution time: {elapsed_time:.4f} seconds\")\nperformance=similarity_score/elapsed_time\nprint(f\"Performance metric: {performance:.4f}\") \n```", "```py\nCosine Similarity Score: 0.801\nQuery execution time: 2.4282 seconds\nPerformance metric: 0.3299 \n```"]