["```py\nimport numpy as np\nimport gensim\nprint(f\"Gensim version: {gensim.__version__}\")\n\nfrom tqdm import tqdm\nclass TqdmUpTo(tqdm):\n    def update_to(self, b=1, bsize=1, tsize=None):\n        if tsize is not None: self.total = tsize\n        self.update(b * bsize - self.n)\n\ndef get_data(url, filename):\n    \"\"\"\n    Download data if the filename does not exist already\n    Uses Tqdm to show download progress\n    \"\"\"\n    import os\n    from urllib.request import urlretrieve\n\n    if not os.path.exists(filename):\n\n        dirname = os.path.dirname(filename)\n        if not os.path.exists(dirname):\n            os.makedirs(dirname)\n\n        with TqdmUpTo(unit='B', unit_scale=True, miniters=1, desc=url.split('/')[-1]) as t:\n            urlretrieve(url, filename, reporthook=t.update_to)\n    else:\n        print(\"File already exists, please remove if you wish to download again\")\n\nembedding_url = 'http://nlp.stanford.edu/data/glove.6B.zip'\nget_data(embedding_url, 'data/glove.6B.zip')\n```", "```py\n# !unzip data/glove.6B.zip \n# !mv -v glove.6B.300d.txt data/glove.6B.300d.txt \n# !mv -v glove.6B.200d.txt data/glove.6B.200d.txt \n# !mv -v glove.6B.100d.txt data/glove.6B.100d.txt \n# !mv -v glove.6B.50d.txt data/glove.6B.50d.txt \n\nfrom gensim.scripts.glove2word2vec import glove2word2vec\nglove_input_file = 'data/glove.6B.300d.txt'\nword2vec_output_file = 'data/glove.6B.300d.txt.word2vec'\nimport os\nif not os.path.exists(word2vec_output_file):\n    glove2word2vec(glove_input_file, word2vec_output_file)\n```", "```py\n%%time\nfrom gensim.models import KeyedVectors\nfilename = word2vec_output_file\nembed = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)\n```", "```py\nassert embed['awesome'] is not None\n```", "```py\ncuisine_refs = [\"mexican\", \"thai\", \"british\", \"american\", \"italian\"]\nsample_sentence = \"Iâ€™m looking for a cheap Indian or Chinese place in Indiranagar\"\n```", "```py\ntokens = sample_sentence.split()\ntokens = [x.lower().strip() for x in tokens] \nthreshold = 18.3\nfound = []\nfor term in tokens:\n    if term in embed.vocab:\n        scores = []\n        for C in cuisine_refs:\n            scores.append(np.dot(embed[C], embed[term].T))\n            # hint replace above above np.dot with: \n            # scores.append(embed.cosine_similarities(<vector1>, <vector_all_others>))\n        mean_score = np.mean(scores)\n        print(f\"{term}: {mean_score}\")\n        if mean_score > threshold:\n            found.append(term)\nprint(found)\n```", "```py\nlooking: 7.448504447937012\nfor: 10.627421379089355\na: 11.809560775756836\ncheap: 7.09670877456665\nindian: 18.64516258239746\nor: 9.692893981933594\nchinese: 19.09498405456543\nplace: 7.651237487792969\nin: 10.085711479187012\n['indian', 'chinese']\n```", "```py\ndef sum_vecs(embed,text):\n\n    tokens = text.split(' ')\n    vec = np.zeros(embed.vector_size)\n\n    for idx, term in enumerate(tokens):\n        if term in embed.vocab:\n            vec = vec + embed[term]\n    return vec\n\nsentence_vector = sum_vecs(embed, sample_sentence)\nprint(sentence_vector.shape)\n>> (300,)\n```", "```py\ndata={\n  \"greet\": {\n    \"examples\" : [\"hello\",\"hey you\",\"howdy\",\"hello\",\"hi\",\"hey there\",\"hey ho\", \"ssup?\"],\n    \"centroid\" : None\n  },\n  \"inform\": {\n    \"examples\" : [\n        \"i'd like something asian\",\n        \"maybe korean\",\n        \"what swedish options do i have\",\n        \"what italian options do i have\",\n        \"i want korean food\",\n        \"i want vegetarian food\",\n        \"i would like chinese food\",\n        \"what japanese options do i have\",\n        \"vietnamese please\",\n        \"i want some chicken\",\n        \"maybe thai\",\n        \"i'd like something vegetarian\",\n        \"show me British restaurants\",\n        \"show me a cool malay spot\",\n        \"where can I get some spicy food\"\n    ],\n    \"centroid\" : None\n  },\n  \"deny\": {\n    \"examples\" : [\n      \"no thanks\"\n      \"any other places ?\",\n      \"something else\",\n      \"naah\",\n      \"not that one\",\n      \"i do not like that\",\n      \"something else\",\n      \"please nooo\"\n      \"show other options?\"\n    ],\n    \"centroid\" : None\n  },\n    \"affirm\":{\n        \"examples\":[\n            \"yeah\",\n            \"that works\",\n            \"good, thanks\",\n            \"this works\",\n            \"sounds good\",\n            \"thanks, this is perfect\",\n            \"just what I wanted\"\n        ],\n        \"centroid\": None\n    }\n\n}\n```", "```py\ndef get_centroid(embed,examples):\n     C = np.zeros((len(examples),embed.vector_size))\n     for idx, text in enumerate(examples):\n         C[idx,:] = sum_vecs(embed,text)\n\n     centroid = np.mean(C,axis=0)\n     assert centroid.shape[0] == embed.vector_size\n     return centroid\n```", "```py\nfor label in data.keys():\n    data[label][\"centroid\"] = get_centroid(embed,data[label][\"examples\"])\n```", "```py\ndef get_intent(embed,data, text):\n    intents = list(data.keys())\n    vec = sum_vecs(embed,text)\n    scores = np.array([ np.linalg.norm(vec-data[label][\"centroid\"]) for label in intents])\n    return intents[np.argmin(scores)]\n```", "```py\nfor text in [\"hey \",\"i am looking for chinese food\",\"not for me\", \"ok, this is good\"]:\n    print(f\"text : '{text}', predicted_label : '{get_intent(embed, data, text)}'\")\n```", "```py\ntext : 'hey ', predicted_label : 'greet'\ntext : 'i am looking for chinese food', predicted_label : 'inform'\ntext : 'not for me', predicted_label : 'deny'\ntext : 'ok, this is good', predicted_label : 'affirm'\n```", "```py\ntemplates = {\n        \"utter_greet\": [\"hey there!\", \"Hey! How you doin'? \"],\n        \"utter_options\": [\"ok, let me check some more\"],\n        \"utter_goodbye\": [\"Great, I'll go now. Bye bye\", \"bye bye\", \"Goodbye!\"],\n        \"utter_default\": [\"Sorry, I didn't quite follow\"],\n        \"utter_confirm\": [\"Got it\", \"Gotcha\", \"Your order is confirmed now\"]\n    }\n```", "```py\nresponse_map = {\n    \"greet\": \"utter_greet\",\n    \"affirm\": \"utter_goodbye\",\n    \"deny\": \"utter_options\",\n    \"inform\": \"utter_confirm\",\n    \"default\": \"utter_default\",\n}\n```", "```py\nimport random\ndef get_bot_response(bot_response_map, bot_templates, intent):\n    if intent not in list(response_map):\n        intent = \"default\"\n    select_template = bot_response_map[intent]\n    templates = bot_templates[select_template]\n    return random.choice(templates)\n```", "```py\nuser_intent = get_intent(embed, data, \"i want indian food\")\nget_bot_response(response_map, templates, user_intent)\n```", "```py\nfor text in [\"hey\",\"i am looking for italian food\",\"not for me\", \"ok, this is good\"]:\n    user_intent = get_intent(embed, data, text)\n    bot_reply = get_bot_response(response_map, templates, user_intent)\n    print(f\"text : '{text}', intent: {user_intent}, bot: {bot_reply}\")\n```", "```py\ntext : 'hey', intent: greet, bot: Hey! How you doin'? \ntext : 'i am looking for italian food', intent: inform, bot: Gotcha\ntext : 'not for me', intent: deny, bot: ok, let me check some more\ntext : 'ok, this is good', intent: affirm, bot: Goodbye!\n```"]