- en: '9'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Creating End-to-End spaCy Workflows with Weasel
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will explore how to create end-to-end NLP workflows using
    spaCy and its companion tool, **Weasel** . Originally a part of spaCy, Weasel
    has now become a standalone library, meaning you can also use it for other projects
    that are not created with spaCy.
  prefs: []
  type: TYPE_NORMAL
- en: '**Data Version Control** ( **DVC** ) has an ecosystem of solutions for data/model
    versioning and experiment tracking, enhancing collaboration and experiment management.
    By integrating Weasel with DVC, we ensure our projects are efficiently versioned
    and tracked, improving organization and reliability.'
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will start by cloning and running a project template with
    Weasel, following the best software engineering practices to ensure a reproducible
    and well-structured workflow. We will then adapt this template for a different
    use case and, finally, we will explore how to use DVC to track and manage trained
    models, enabling efficient collaboration. This approach will allow us to create
    robust NLP pipelines, ready for production and teamwork.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’re going to cover these main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Cloning and running a project template with Weasel
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Modifying a project template for a different use case
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Managing models with the DVC Studio model registry
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will be using the spaCy, Weasel, and DVC libraries. The
    chapter code can be found at [https://github.com/PacktPublishing/Mastering-spaCy-Second-Edition](https://github.com/PacktPublishing/Mastering-spaCy-Second-Edition)
    .
  prefs: []
  type: TYPE_NORMAL
- en: Cloning and running a project template with Weasel
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The **spacy weasel clone** command clones a project template from a Git repository.
    It uses spaCy’s project template repo ( [https://github.com/explosion/projects](https://github.com/explosion/projects)
    ) by default, but you can provide any other repo you have access to (public or
    private) using the **--** **repo** option.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will use the **categorization of emotions in Reddit posts**
    (also referred to as **text classification** ) project as our project template.
    Let’s go ahead and clone the project:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'This command creates a **textcat_goemotions** folder in the current directory.
    The **project.yml** file defines everything related to the project. This includes
    assets and custom commands. The main sections of the **project.yml** files are
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**title** : You guessed right, this defines the title of the project.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**description** : An optional project description.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**vars** : A dictionary of variables for paths, URLs, and scripts, which can
    be overridden via the CLI.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**env** : A dictionary mapping variables to environment names, allowing project
    scripts to use values such as **${env.name}** from environment variables.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**directories** : A list of directories to be created within the project, automatically
    generated by spaCy if they don’t exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**assets** : A list of assets to be fetched, each defined by a URL or local
    path, a destination within the project, and an optional checksum for verification.
    You can also specify a Git repository with **repo** , **branch** , and **path**
    to download assets directly from Git.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**commands** : A command specifies how to run the project steps. It usually
    specifies how to run a Python script. Each command is specified with **script**
    , **deps** , and **outputs** . **deps** define the files the command depends on,
    and **outputs** define the files the command produces. This lets spaCy determine
    when to re-run a command if a dependency changed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**workflows** : Workflows define a list of commands that should be executed
    in order.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now that we have cloned the template, the next step is to fetch the assets.
    The **spacy weasel assets** command downloads all the assets defined in the **assets**
    section of **project.yml** . Let’s download the assets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'This project has four assets: a file with the categories to train and three
    files with data, one for training, one for development, and one for testing. The
    data is in **.tsv** format, so we need to convert it into **.spacy** binary format.
    The **scripts/convert_corpus.py** script does that. The **project.yml** file has
    a command named **preprocess** that we can use to run this script. Let’s see how
    this command is defined:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The command specifies the assets in the **deps** keys (because we need them
    to run the code) and the outputs the code generates. To run this command, we can
    use **spacy project run** and the name of the command, like this: **spacy project
    run preprocess** . This command creates **train.spacy** , **dev.spacy** , and
    **test.spacy** inside the **/** **corpus** folder.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The **all** workflow calls the **preprocess** , **train** , **evaluate** ,
    and **package** commands in order. This is useful so we don’t have to call each
    command manually. Let’s try running this workflow:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '*Figure 9* *.1* displays the command outputs. Weasel verified that **deps**
    of the **preprocess** command didn’t change, so it skipped this step.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.1 – Outputs after running the all workflow](img/B22441_09_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.1 – Outputs after running the all workflow
  prefs: []
  type: TYPE_NORMAL
- en: The **visualize** command uses **Streamlit** and **spacy-streamlit** to serve
    a web app to interact with the model. We can run this command with **weasel run
    visualize** . *Figure 9* *.2* shows the web app interface. We will learn how to
    use spaCy with Streamlit in [*Chapter 11*](B22441_11.xhtml#_idTextAnchor143) .
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.2 – Streamlit interface to interact with the model](img/B22441_09_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.2 – Streamlit interface to interact with the model
  prefs: []
  type: TYPE_NORMAL
- en: With all that, we have successfully used the project template to recreate this
    text classification pipeline. What if we have another dataset and need to execute
    these same project steps? We can simply reuse the template and adapt it to our
    needs. Let’s learn how to do it in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Modifying a project template for a different use case
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To reuse the project template for a different use case, the first thing we’ll
    do is clone the project, specifying a different **dest** folder. Let’s do that:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'This will create a **textcat_github_issues** folder. The new use case uses
    annotated data from **Prodigy** and we should predict whether a GitHub issue title
    is about documentation or not. The original project is available here: [https://github.com/explosion/projects/tree/v3/tutorials/textcat_docs_issues](https://github.com/explosion/projects/tree/v3/tutorials/textcat_docs_issues)
    . The goal of this section is to learn how to reuse a project template, so we
    will modify the **textcat_goemotions** project to this domain.'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we should update **title** , **description** , and **vars** with the
    information for this new GitHub issues project. The assets of the GitHub issues
    are in the **.jsonl** format, so we will need to modify the command to convert
    the data to **.spacy** format. We have three files: **train.jsonl** , **dev.jsonl**
    , and **eval.jsonl** . Let’s first modify the assets key of **project.yml** to
    point to these files:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can download the assets using the **assets** command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s see a snippet of the training data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'This format is different from **textcat_goemotions** , so we will need to create
    a different **convert_corpus.py** script. We will use **srsly** (a package that
    bundles some of the best Python serialization libraries) to read the **.jsonl**
    data and **typer** (a library for building CLI applications) to specify the arguments
    of the script. Let’s write the script to do that:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we import the libraries and define the variables for the directories:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To run the script, we should specify the directory to read the assets, the
    directory to save the corpus, and the language of the model we’ll use to create
    the **Doc** objects. With **typer** , we can do this by creating a function with
    these arguments:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The script should convert all the **train.jsonl** , **dev.json** , and **eval.jsonl**
    files, so we will need to loop through each file in **assets_dir** , and if it’s
    a **.jsonl** file, we will create a **DocBin** object:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'For each **jsonl_file** , we will build the **Doc** object, set the **cats**
    parameter, and add it to the **DocBin** object. Finally, we save this **DocBin**
    object to disk:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The last step is to tie this script with Typer. We do that with **typer.run(main)**
    :'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we can save this new **convert_corpus.py** script and run the following
    command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '*Figure 9* *.3* shows the output of this command.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 9.3 – Weasel output after running the preprocess command](img/B22441_09_3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.3 – Weasel output after running the preprocess command
  prefs: []
  type: TYPE_NORMAL
- en: 'Weasel is saying that we’re missing an **assets/train.tsv** dependency. That’s
    because we didn’t update **deps** and **outputs** of the **preprocess** command
    to work with this new use case. Let’s do it now:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Now you can save these changes and try running the **preprocess** command again.
    The script creates the **.spacy** files in the **/corpus** directory. Alright,
    let’s also update the dependencies of the **evaluate** command and run the **all**
    workflow to train, evaluate, and create a package for this GitHub issues project:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '*Figure 9* *.4* displays the evaluation results for this pipeline.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 9.4 – Evaluation results](img/B22441_09_4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.4 – Evaluation results
  prefs: []
  type: TYPE_NORMAL
- en: 'Could we get better results using BERT? Let’s change this in the **vars** section
    of **project.yml** :'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'I had trouble running the training with the batch configuration defined on
    the **configs/bert.cfg** file, so let’s change it to **spacy.batch_by_padded.v1**
    :'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can run the workflow again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '*Figure 9* *.5* displays the evaluation results of this model, which performs
    better than the first one.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.5 – Results using BERT](img/B22441_09_5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.5 – Results using BERT
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have the trained models, we can use Weasel to upload them to remote
    storage. Let’s do that in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Uploading and downloading project outputs to remote storage
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You can use the **spacy project push** command to store project outputs in remote
    storage, enabling you to share pipeline packages, collaborate with your team,
    or cache results to avoid redundant tasks. The **spacy project pull** command
    retrieves any missing outputs from remote storage. Remotes are specified in the
    **remotes** section of **project.yml** . To configure the remote storage, you
    can list one or more destinations in the **remotes** section of the **project.yml**
    file, mapping a string name to the storage URL. spaCy uses **cloudpathlib** to
    communicate with remote storage, allowing the use of any protocol supported by
    **cloudpathlib** , including S3, Google Cloud Storage, Azure Blob Storage, and
    the local filesystem.
  prefs: []
  type: TYPE_NORMAL
- en: The **push** command uploads all files or directories listed in **outputs**
    section of commands to remote storage. Outputs are archived and compressed before
    upload. Weasel uses a hash of the command string and dependencies and a hash of
    the file contents. This means **push** should never overwrite a file in your remote
    storage. If all hashes match, the contents are the same and nothing happens. If
    the contents differ, the new version of the file is uploaded.
  prefs: []
  type: TYPE_NORMAL
- en: The **pull** command downloads all files or directories listed as outputs for
    commands unless they are already present locally. When searching for files in
    the remote storage, **pull** will consider not only the output path but also the
    command string and dependency hashes.
  prefs: []
  type: TYPE_NORMAL
- en: We’ve trained two models for the GitHub issues use case. If we were in a production
    setting, we would need to manage these trained models. The straightforward use
    case would be to change between them in production. DVC is a library that helps
    us connect to versioned data sources and code with pipelines, track experiments,
    and register models. Weasel was inspired by DVC and we can use the **spacy weasel
    dvc** command to auto-generate a DVC configuration file. With this file, we can
    manage the spaCy project like any other DVC project. In the next section, we will
    use the DVC Studio model registry to catalog our **Machine Learning** ( **ML**
    ) models and manage them in production.
  prefs: []
  type: TYPE_NORMAL
- en: Managing models with the DVC model registry
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: DVC is an open source command-line tool that helps us develop reproducible ML
    projects. Weasel itself was inspired by DVC ( [https://x.com/honnibal/status/1316792615996592133](https://x.com/honnibal/status/1316792615996592133)
    ). It comes with tools to version data and models, track experiments, compare
    data, and share experiments. In this section, we’re going to use the model registry
    in **DVC Studio** , a web application that enables teams to run and track experiments
    and manage the model life cycle.
  prefs: []
  type: TYPE_NORMAL
- en: Under the hood, DVC Studio uses a command line called **Git Tag Ops** ( **GTO**
    ) for model registry actions. To work with DVC, it’s useful to learn more about
    **GitOps** . Let’s do this in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: What is GitOps?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**GitOps** is a set of practices that emphasizes the use of the Git version
    control system as the source of truth for declarative infrastructure and applications.
    It draws ideas from DevOps and infrastructure as code practices. The *GitOps WG*
    ( [https://opengitops.dev/](https://opengitops.dev/) ) defines four GitOps principles
    (v1.0.0):'
  prefs: []
  type: TYPE_NORMAL
- en: '**Declarative** : In a GitOps-managed system, the desired state must be defined
    declaratively'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Versioned and immutable** : The desired state is stored in a way that enforces
    immutability and versioning and retains a complete version history'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Pulled automatically** : Software agents automatically pull the desired state
    declarations from the source'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Continuously reconciled** : Software agents constantly monitor the system
    and work to align it with the desired state'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let’s delve deeper into each principle in the following list:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Principle 1 – declarative** : In practical terms, this means that all the
    configurations and settings for your infrastructure and applications are described
    in a declarative format, such as YAML or JSON files. Rather than writing scripts
    that perform a series of steps to reach the desired state, you define what the
    final state should look like. This is also the principle of **Weasel** for the
    **project.yml** file – it ensures that we have no hidden defaults. The configuration
    files serve as a blueprint for how your system should be configured.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Principle 2 – versioned and immutable** : This principle emphasizes that
    all configuration files (the declarative descriptions) should be stored in a Git
    repository. Git naturally supports versioning, allowing you to track changes over
    time. Immutability means that once a particular state is defined and committed,
    it shouldn’t be altered. If changes are necessary, a new version should be created.
    This practice ensures that you have a complete history of every change made to
    your configurations, making it easier to understand the evolution of your code
    and infrastructure and roll back to previous states if necessary. For example,
    if a new configuration breaks your application, you can quickly revert to the
    last known good configuration using Git’s version history.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Principle 3 – pulled automatically** : In a GitOps setup, when a new commit
    is detected, the GitOps agent should automatically pull the updated configuration
    files and apply the changes to the infrastructure or applications. This automation
    ensures that any updates made in the Git repository are promptly reflected in
    the actual running environment without manual intervention.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Principle 4 – continuously reconciled** : The GitOps agents should continuously
    compare the actual state of your infrastructure and applications with the desired
    state defined in your Git repository. If there is a discrepancy between the two,
    the agents will try to reconcile them by making the necessary adjustments to bring
    the actual state in line with the desired state. This continuous reconciliation
    ensures that your system is always aligned with the configurations in Git. This
    principle ensures consistency and reliability, preventing drift between what is
    declared in Git and what is actually running in your environment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s move on to DVC, addressing common data science and ML challenges next.
  prefs: []
  type: TYPE_NORMAL
- en: How DVC addresses common data science and ML challenges
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Data science and ML projects often face challenges that can be effectively
    addressed using DVC and GitOps principles. Here are some common challenges and
    how these tools and principles can help solve them:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Difficult sharing and collaboration** : Sharing datasets, models, and experiments
    among team members can be complicated, especially when dealing with large files
    or multiple versions, leading to duplicated work and errors. With DVC, we can
    use remote storage to track datasets and models just like we track code with Git.
    This allows team members to pull and push assets to make sure everyone is working
    with the same state.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Pipelines not reliable or not reproducible** : We usually start our project
    experiments in a Jupyter notebook. This is completely fine for data analysis and
    prototypes, but when the project grows (as we hope so), structure and automation
    become beneficial. Some requirements for structured pipelines include units of
    code as **.py** modules and managing configuration in dedicated files (to track
    parameters, file paths, etc.). DVC (and Weasel) perfectly creates a structure
    for us to create these reusable pipelines.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Model metrics tracking** : Keeping a history of model performance metrics
    is crucial for understanding the evolution and effectiveness of models over time.
    DVC allows the storing and versioning of performance metrics along with models,
    facilitating the comparison of different versions and the analysis of improvements.
    With GitOps, these metrics can be integrated into CI/CD pipelines, ensuring that
    new model versions are always validated against previous versions before deployment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'By addressing these challenges with DVC and GitOps principles, data science
    and ML teams can achieve more reliable, reproducible, and scalable workflows.
    The benefits of implementing GitOps principles include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Increased developer and operational productivity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enhanced developer experience
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Improved stability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Consistency and standardization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DVC integrates seamlessly with GitOps practices, so by using the tool, we get
    all these benefits. Now that we know what GitOps is and the challenges it addresses,
    let’s go ahead and convert our Weasel project to DVC and add our models to the
    model registry so we can share them.
  prefs: []
  type: TYPE_NORMAL
- en: From Weasel to DVC
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The first step is to install DVC. DVC is a Python library, so we can carry
    out the installation using **pip** or **conda** :'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, inside the project directory, we can run **dvc init** to initialize a
    DVC project. There has to be a Git repository initialized in this directory. Let’s
    initialize the project:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The **dvc init** command creates three files: **.dvc/config** , **.dvc/.gitignore**
    , and **.dvcignore** . DVC provides access to external storage locations, allowing
    us to manage and share our data and ML models. It supports cloud providers such
    as Amazon S3, Microsoft Azure Blob Storage, and Google Cloud Storage, and self-hosted/on-premises
    options such as SSH and HDFS. In this chapter, we will use Google Drive as remote
    storage. For that, we need the folder ID of the Google Drive folder. The **dvc
    remote add** command adds the remote configuration to the **.dvc/config** file.
    Let’s do it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: The **gdrive_acknowledge_abuse** flag allows the download of files flagged as
    potentially abusive, such as containing malware or personal information, but only
    by the file’s owner when this parameter is enabled. Now, when we run **dvc pull**
    or **dvc push** to store or retrieve model artifacts using Google Drive as the
    remote storage, the browser will open a new window for authentication.
  prefs: []
  type: TYPE_NORMAL
- en: Once DVC is configured, the **spacy project dvc** command auto-generates a **dvc.yaml**
    file from your **project.yml** . This lets you manage your spaCy project as a
    DVC repository, using the workflow defined in **project.yml** . In this chapter,
    we’re just going to use the model registry functionality, so let’s go ahead and
    see how to do that in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a command to add the model to the model registry
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To add the model to the model registry, we need to install the **DVCLive**
    Python package. DVCLive is a Python library for logging ML metrics and other metadata:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s install it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, let’s revisit our **project.yml** Weasel file. We have the **all** workflow
    defined there with these commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: What we’ll do is create three new commands, one to track the model with DVC,
    one to push the model to the remote storage, and one to add the model to the model
    registry.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To push the model to the remote storage, first we need to track it with DVC.
    We do this with **dvc add** . Let’s create the command inside **project.yml**
    :'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, let’s run this command with Weasel:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: You should remove the **packages** folder from the root **.gitignore** file
    created by Weasel to add the model package to DVC (DVC will create a new **.gitignore**
    file inside the **model** folder).
  prefs: []
  type: TYPE_NORMAL
- en: The **dvc add** command creates a **.dvc** file for the artifact, and this artifact
    is then tracked with Git.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we can create the command to add this model to Google Drive:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can also run it with Weasel:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The command will open the browser so we can authenticate with Google Drive.
    Now we are finally ready to create the command that adds the model to the DVC
    Studio model registry. To do that, we will create a new Python script. Let’s do
    it:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we import the libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we create a **main()** function with the context manager block for the
    DVCLive logger and use the **log_artifact()** method to add the model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, we add **typer.run(main)** to handle the command-line arguments:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can save this script as **scripts/add_model_registry.py** . Now, we can
    create the command to run this script:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We should now commit the **dvc.yaml** file that was created:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now you should go to [https://studio.iterative.ai/](https://studio.iterative.ai/)
    , connect with GitHub/GitLab/Bitbucket and import your Git repo. After doing that,
    you can click on the **Models** menu and see the model there. *Figure 9* *.6*
    shows this interface.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 9.6 – DVC Studio Models](img/B22441_09_6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.6 – DVC Studio Models
  prefs: []
  type: TYPE_NORMAL
- en: The next step is to register the model. Click on the model’s name to see the
    options displayed in *Figure 9* *.7* .
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 9.7 – DVC Studio model options](img/B22441_09_7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.7 – DVC Studio model options
  prefs: []
  type: TYPE_NORMAL
- en: Now, click on the blue **Register first version** button to choose a specific
    commit in our model development history and attach a version to it to make it
    easier to keep track of it. *Figure 9* *.8* shows the register model popup.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 9.8 – The DVC Studio register model options](img/B22441_09_8.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.8 – The DVC Studio register model options
  prefs: []
  type: TYPE_NORMAL
- en: The model is now registered, and we can download it or assign it to life cycle
    stages. *Figure 9* *.9* shows those options.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.9 – Ways to access the model with DVC Studio](img/B22441_09_9.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.9 – Ways to access the model with DVC Studio
  prefs: []
  type: TYPE_NORMAL
- en: 'When the model is assigned to a stage, it can automatically trigger actions
    in your CI/CD workflows, such as deploying the model to a new environment. You
    can learn more about that in the DVC documentation: [https://dvc.org/doc/start/model-registry/model-cicd](https://dvc.org/doc/start/model-registry/model-cicd)
    .'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned how to manage spaCy projects with Weasel. First,
    you cloned a project template from spaCy’s repository and ran it on your machine.
    Then, you used this same project structure to train a model for a dataset. After
    that, you saw how GitOps can address some data science and ML challenges and used
    DVC to register the model we’ve trained to share it with teammates or add a deploy
    setting to it. The goal of this chapter was to teach you how to manage NLP projects
    in a production setting.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will explore how to train a model for coreference resolution.
    This will involve understanding what coreference resolution is, why it is important
    in NLP, and how to implement it using spaCy.
  prefs: []
  type: TYPE_NORMAL
