["```py\n        pip install neo4j \n        ```", "```py\n        pip install pandas \n        ```", "```py\n    CREATE CONSTRAINT unique_person_name IF NOT EXISTS\n    FOR (p:Person)\n    REQUIRE p.person_name IS UNIQUE; \n    ```", "```py\nCREATE CONSTRAINT unique_person_id IF NOT EXISTS\nFOR (p:Person)\nREQUIRE p.person_id IS UNIQUE; \n```", "```py\n    CREATE INDEX person_name_index IF NOT EXISTS\n    FOR (p:Person)\n    ON (p.person_name); \n    ```", "```py\n    CREATE INDEX movie_title_index IF NOT EXISTS\n    FOR (m:Movie)\n    ON (m.title); \n    ```", "```py\n    CREATE INDEX acted_in_role_index IF NOT EXISTS\n    FOR ()-[r:ACTED_IN]-()\n    ON (r.role); \n    ```", "```py\n    # Load the CSV file\n    df = pd.read_csv('./raw_data/credits.csv')\n    # Function to extract relevant cast information\n    def extract_cast(cast_str):\n        cast_list = ast.literal_eval(cast_str)\n        return [\n            {\n                'actor_id': c['id'],\n                'name': c['name'],\n                'character': c['character'],\n                'cast_id': c['cast_id']\n            }\n            for c in cast_list\n        ]\n    # Function to extract relevant crew information\n    def extract_crew(crew_str):\n        crew_list = ast.literal_eval(crew_str)\n        relevant_jobs = ['Director', 'Producer']\n        return [\n            {\n                'crew_id': c['id'],\n                'name': c['name'],\n                'job': c['job']\n            }\n            for c in crew_list if c['job'] in relevant_jobs\n        ]\n    # Apply the extraction functions to each row\n    df['cast'] = df['cast'].apply(extract_cast)\n    df['crew'] = df['crew'].apply(extract_crew)\n    # Explode the lists into separate rows\n    df_cast = df.explode('cast').dropna(subset=['cast'])\n    df_crew = df.explode('crew').dropna(subset=['crew'])\n    # Normalize the exploded data\n    df_cast_normalized = pd.json_normalize(df_cast['cast'])\n    df_crew_normalized = pd.json_normalize(df_crew['crew'])\n    # Reset index to avoid duplicate indices\n    df_cast_normalized = df_cast_normalized.reset_index(drop=True)\n    df_crew_normalized = df_crew_normalized.reset_index(drop=True)\n    # Drop duplicate rows if any\n    df_cast_normalized = df_cast_normalized.drop_duplicates()\n    df_crew_normalized = df_crew_normalized.drop_duplicates()\n    # Add the movie ID back to the normalized DataFrames\n    df_cast_normalized['tmdbId'] = df_cast.reset_index(drop=True)['id']\n    df_crew_normalized['tmdbId'] = df_crew.reset_index(drop=True)['id']\n    # Save the normalized data with the updated column names\n    df_cast_normalized.to_csv(\n        os.path.join(output_dir, 'normalized_cast.csv'),\n        index=False\n    )\n    df_crew_normalized.to_csv(\n        os.path.join(output_dir, 'normalized_crew.csv'),\n        index=False\n    )\n    # Display a sample of the output for verification\n    print(\"Sample of normalized cast data:\")\n    print(df_cast_normalized.head())\n    print(\"Sample of normalized crew data:\")\n    print(df_crew_normalized.head()) \n    ```", "```py\n    # Load the CSV file\n    df = pd.read_csv('./raw_data/keywords.csv')  # Update the path as necessary\n    # Function to extract and normalize keywords\n    def normalize_keywords(keyword_str):\n        if pd.isna(keyword_str) or not isinstance(keyword_str, str):  # Check if the value is NaN or not a string\n            return []\n        # Convert the stringified JSON object into a list of dictionaries\n        keyword_list = ast.literal_eval(keyword_str)\n        # Extract the 'name' of each keyword and return them as a list\n        return [kw['name'] for kw in keyword_list]\n    # Apply the normalization function to the 'keywords' column\n    df['keywords'] = df['keywords'].apply(normalize_keywords)\n    # Combine all keywords for each tmdbId into a single row\n    df_keywords_aggregated = df.groupby('id', as_index=False).agg({\n        'keywords': lambda x: ', '.join(sum(x, []))\n    })\n    # Rename the 'id' column to 'tmdbId'\n    df_keywords_aggregated.rename(\n        columns={'id': 'tmdbId'}, inplace=True\n    )\n    # Save the aggregated DataFrame to a new CSV file\n    df_keywords_aggregated.to_csv(\n        os.path.join(output_dir, 'normalized_keywords.csv'),\n        index=False\n    )\n    # Display the first few rows of the aggregated DataFrame for verification\n    print(df_keywords_aggregated.head()) \n    ```", "```py\n        import pandas as pd\n        import ast\n        # Load the CSV file\n        df = pd.read_csv('./raw_data/movies_metadata.csv')  # Update the path as necessary \n        ```", "```py\n        # Function to extract and normalize genres\n        def extract_genres(genres_str):\n            if pd.isna(genres_str) or not isinstance(\n                genres_str, str\n            ):\n                return []\n            genres_list = ast.literal_eval(genres_str)\n            return [\n                {'genre_id': int(g['id']), 'genre_name': g['name']}\n                for g in genres_list\n            ]\n        # Function to extract and normalize production companies\n        def extract_production_companies(companies_str):\n            if pd.isna(companies_str) or not isinstance(\n                companies_str, str\n            ):\n                return []\n            companies_list = ast.literal_eval(companies_str)\n            if isinstance(companies_list, list):\n                return [\n                    {'company_id': int(c['id']),\n                        'company_name': c['name']\n                    }\n                    for c in companies_list\n                ]\n            return [] \n        ```", "```py\n        df['genres'] = df['genres'].apply(extract_genres)\n        df['production_companies'] = \\\n            df['production_companies'].apply(\n                extract_production_companies\n            )\n        df['production_countries'] = \\\n            df['production_countries'].apply(\n                extract_production_countries\n            )\n        df['spoken_languages'] = df['spoken_languages'].apply(\n            extract_spoken_languages\n        )\n        # Explode lists into rows\n        df_genres = df.explode('genres').dropna(subset=['genres'])\n        df_companies = df.explode('production_companies').dropna(\n            subset=['production_companies']\n        )\n        df_countries = df.explode('production_countries').dropna(\n            subset=['production_countries']\n        )\n        df_languages = df.explode('spoken_languages').dropna(\n            subset=['spoken_languages']\n        ) \n        ```", "```py\n        df_genres_normalized = pd.json_normalize(df_genres['genres'])\n        # Reset index to avoid duplicate indices\n        df_genres_normalized = \\\n            df_genres_normalized.reset_index(drop=True)\n        # Add the movie ID back to the normalized DataFrames as 'tmdbId'\n        df_genres_normalized['tmdbId'] = df_genres.reset_index(\n            drop=True\n        )['id']\n        # Ensure that 'company_id' and similar fields are treated as integers\n        df_genres_normalized['genre_id'] = \\\n            df_genres_normalized['genre_id'].astype(int)\n        # Save the normalized data with the updated column names\n        df_genres_normalized.to_csv(\n            os.path.join(output_dir, 'normalized_genres.csv'),\n            index=False\n        ) \n        ```", "```py\n        # For the movies, including \"Belongs to Collection\" within the same CSV\n        # Extract only the \"name\" from \"belongs_to_collection\" and include additional fields\n        def extract_collection_name(collection_str):\n            if isinstance(collection_str, str):\n                try:\n                    collection_dict = \\\n                        ast.literal_eval(collection_str)\n                    if isinstance(collection_dict, dict):\n                        return collection_dict.get('name', \"None\")\n                except (ValueError, SyntaxError):  # Handle cases where string parsing fails\n                    return \"None\"\n            return \"None\"\n        df_movies = df[\n            [\n                'id', 'original_title', 'adult', 'budget', 'imdb_id',\n                'original_language', 'revenue', 'tagline', 'title',\n                'release_date', 'runtime', 'overview',\n                'belongs_to_collection'\n            ]\n        ].copy()\n        df_movies['belongs_to_collection'] = \\\n            df_movies['belongs_to_collection'].apply(\n                extract_collection_name\n            )\n        df_movies['adult'] = df_movies['adult'].apply(\n            lambda x: 1 if x == 'TRUE' else 0\n        )  # Convert 'adult' to integer\n        # Rename 'id' to 'tmdbId'\n        df_movies.rename(columns={'id': 'tmdbId'}, inplace=True)  # Rename 'id' to 'tmdbId'\n        # Save the movies to a separate CSV, including the extracted fields\n        df_movies.to_csv(\n            './normalized_data/normalized_movies.csv', index=False\n        ) \n        ```", "```py\nNEO4J_URI=neo4j+s://<your-instance-id>.databases.neo4j.io\nNEO4J_USERNAME=neo4j\nNEO4J_PASSWORD=<your-generated-password>\nAURA_INSTANCEID=<your-instance-id>\nAURA_INSTANCENAME=<your-instance-name> \n```", "```py\n\"CREATE CONSTRAINT unique_tmdb_id IF NOT EXISTS FOR (m:Movie) REQUIRE m.tmdbId IS UNIQUE;\",\n\"CREATE CONSTRAINT unique_movie_id IF NOT EXISTS FOR (m:Movie) REQUIRE m.movieId IS UNIQUE;\",\n\"CREATE CONSTRAINT unique_prod_id IF NOT EXISTS FOR (p:ProductionCompany) REQUIRE p.company_id IS UNIQUE;\",\n\"CREATE CONSTRAINT unique_genre_id IF NOT EXISTS FOR (g:Genre) REQUIRE g.genre_id IS UNIQUE;\",\n\"CREATE CONSTRAINT unique_lang_id IF NOT EXISTS FOR (l:SpokenLanguage) REQUIRE l.language_code IS UNIQUE;\",\n\"CREATE CONSTRAINT unique_country_id IF NOT EXISTS FOR (c:Country) REQUIRE c.country_code IS UNIQUE;\",\n\"CREATE INDEX actor_id IF NOT EXISTS FOR (p:Person) ON (p.actor_id);\",\n\"CREATE INDEX crew_id IF NOT EXISTS FOR (p:Person) ON (p.crew_id);\",\n\"CREATE INDEX movieId IF NOT EXISTS FOR (m:Movie) ON (m.movieId);\",\n\"CREATE INDEX user_id IF NOT EXISTS FOR (p:Person) ON (p.user_id);\" \n```", "```py\ngraph.load_movies('https://storage.googleapis.com/movies-packt/normalized_movies.csv', movie_limit) \n```", "```py\n pip install neo4j \n```", "```py\npython graph_build.py \n```", "```py\nMATCH (m:Movie)-[:HAS_GENRE]->(g:Genre)\nRETURN m.title, g.genre_name\nLIMIT 10; \n```", "```py\n    MATCH (a:Actor {name: 'Tom Hanks'})-[:ACTED_IN*1..3]-(m:Movie)\n    RETURN DISTINCT m.title; \n    ```", "```py\n        MATCH path = (a:Actor)-[:ACTED_IN]->(m:Movie)\n        RETURN path; \n        ```", "```py\n    MATCH (a:Actor {name: \"Tom Hanks\"})-[:ACTED_IN]->(m1:Movie)<-[:DIRECTED_BY]-(d:Director) MATCH (a)-[:ACTED_IN]->(m2:Movie)<-[:DIRECTED_BY]-(d)\n    WHERE m1 <> m2\n    RETURN a.name AS actor, d.name AS director, collect(DISTINCT m1.title) + collect(DISTINCT m2.title) AS movies \n    ```", "```py\n        CALL {\n          MATCH (m:Movie)-[:HAS_GENRE]->(g:Genre {name: 'Action'})\n          RETURN m\n        }\n        MATCH (m)-[:DIRECTED_BY]->(d:Director)\n        RETURN d.name, COUNT(m) AS action_movies_directed; \n        ```", "```py\n    LOAD CSV WITH HEADERS FROM $csvFile AS row\n    CALL (row) {\n      MATCH (m:Movie {movieId: toInteger(row.movieId)})\n      WITH m, row\n      MERGE (p:Person {user_id: toInteger(row.userId)})\n      ON CREATE SET p.role = 'user'\n      MERGE (p)-[r:RATED]->(m)\n      ON CREATE SET r.rating = toFloat(row.rating), r.timestamp = toInteger(row.timestamp)\n    } IN TRANSACTIONS OF 50000 ROWS; \n    ```", "```py\n    MATCH (m:Movie)\n    WHERE m.revenue > 100000000\n    CALL {\n      WITH m\n      MATCH (m)-[:HAS_GENRE]->(g:Genre)\n      RETURN g.name AS genre\n    }\n    RETURN m.title, genre; \n    ```"]