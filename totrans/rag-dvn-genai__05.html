<html><head></head><body>
  <div id="_idContainer064" class="Basic-Text-Frame">
    <h1 class="chapterNumber"><span class="koboSpan" id="kobo.1.1">5</span></h1>
    <h1 id="_idParaDest-125" class="chapterTitle"><span class="koboSpan" id="kobo.2.1">Boosting RAG Performance with Expert Human Feedback</span></h1>
    <p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.3.1">Human feedback</span></strong><span class="koboSpan" id="kobo.4.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.5.1">HF</span></strong><span class="koboSpan" id="kobo.6.1">) is not just useful for generative AI—it’s essential, especially when it comes to models using RAG. </span><span class="koboSpan" id="kobo.6.2">A generative AI model uses information from datasets with various documents during training. </span><span class="koboSpan" id="kobo.6.3">The data that trained the AI model is set in stone in the model’s parameters; we can’t change it unless we train it again. </span><span class="koboSpan" id="kobo.6.4">However, in the world of retrieval-based text and multimodal datasets, there is information we can see and tweak. </span><span class="koboSpan" id="kobo.6.5">That is where HF comes in. </span><span class="koboSpan" id="kobo.6.6">By providing feedback on what the AI model pulls from its datasets, HF can directly influence the quality of its future responses. </span><span class="koboSpan" id="kobo.6.7">Engaging with this process makes humans an active player in the RAG’s development. </span><span class="koboSpan" id="kobo.6.8">It adds a new dimension to AI projects: adaptive RAG.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.7.1">We have explored and implemented naïve, advanced, and modular RAG so far. </span><span class="koboSpan" id="kobo.7.2">Now, we will add adaptive RAG to our generative AI toolbox. </span><span class="koboSpan" id="kobo.7.3">We know that even the best generative AI system with the best metrics cannot convince a dissatisfied user that it is helpful if it isn’t. </span><span class="koboSpan" id="kobo.7.4">We will introduce adaptive RAG with an HF loop. </span><span class="koboSpan" id="kobo.7.5">The system thus becomes adaptive because the documents used for retrieval are updated. </span><span class="koboSpan" id="kobo.7.6">Integrating HF in RAG leads to a pragmatic hybrid approach because it involves humans in an otherwise automated generative process. </span><span class="koboSpan" id="kobo.7.7">We will thus leverage HF, which we will use to build a hybrid adaptive RAG program in Python from scratch, going through the key steps of building a RAG-driven generative AI system from the ground up. </span><span class="koboSpan" id="kobo.7.8">By the end of this chapter, you will have a theoretical understanding of the adaptive RAG framework and practical experience in building an AI model based on HF.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.8.1">This chapter covers the following topics:</span></p>
    <ul>
      <li class="bulletList"><span class="koboSpan" id="kobo.9.1">Defining the adaptive RAG ecosystem</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.10.1">Applying adaptive RAG to augmented retrieval queries</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.11.1">Automating augmented generative AI inputs with HF</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.12.1">Automating end-user feedback rankings to trigger expert HF</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.13.1">Creating an automated feedback system for a human expert</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.14.1">Integrating HF with adaptive RAG for GPT-4o</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.15.1">Let’s begin by defining adaptive RAG.</span></p>
    <h1 id="_idParaDest-126" class="heading-1"><span class="koboSpan" id="kobo.16.1">Adaptive RAG</span></h1>
    <p class="normal"><span class="koboSpan" id="kobo.17.1">No, RAG cannot solve all our problems and challenges. </span><span class="koboSpan" id="kobo.17.2">RAG, just like any generative model, can also </span><a id="_idIndexMarker307"/><span class="koboSpan" id="kobo.18.1">produce irrelevant and incorrect output! </span><span class="koboSpan" id="kobo.18.2">RAG might be a useful option, however, because we feed pertinent documents to the generative AI model that inform its responses. </span><span class="koboSpan" id="kobo.18.3">Nonetheless, the quality of RAG outputs depends on the accuracy and relevance of the underlying data, which calls for verification! </span><span class="koboSpan" id="kobo.18.4">That’s where adaptive RAG comes in. </span><span class="koboSpan" id="kobo.18.5">Adaptive RAG introduces human, real-life, pragmatic feedback that will improve a RAG-driven generative AI ecosystem.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.19.1">The core information in a generative AI model is parametric (stored as weights). </span><span class="koboSpan" id="kobo.19.2">But in the context of RAG, this data can be visualized and controlled, as we saw in </span><em class="chapterRef"><span class="koboSpan" id="kobo.20.1">Chapter 2</span></em><span class="koboSpan" id="kobo.21.1">, </span><em class="italic"><span class="koboSpan" id="kobo.22.1">RAG Embedding Vector Stores with Deep Lake and OpenAI</span></em><span class="koboSpan" id="kobo.23.1">. </span><span class="koboSpan" id="kobo.23.2">Despite this, challenges remain; for example, the end-user might write fuzzy queries, or the RAG data retrieval might be faulty. </span><span class="koboSpan" id="kobo.23.3">An HF process is, therefore, highly recommended to ensure the system’s reliability.</span></p>
    <p class="normal"><em class="italic"><span class="koboSpan" id="kobo.24.1">Figure 1.3</span></em><span class="koboSpan" id="kobo.25.1"> from </span><em class="chapterRef"><span class="koboSpan" id="kobo.26.1">Chapter 1</span></em><span class="koboSpan" id="kobo.27.1">, </span><em class="italic"><span class="koboSpan" id="kobo.28.1">Why Retrieval Augmented Generation?</span></em><span class="koboSpan" id="kobo.29.1">, represents the complete RAG framework and ecosystem. </span><span class="koboSpan" id="kobo.29.2">Let’s zoom in on the adaptive RAG ecosystem and focus on the key processes that come into play, as shown in the following figure:</span></p>
    <figure class="mediaobject"><span class="koboSpan" id="kobo.30.1"><img src="../Images/B31169_05_01.png" alt="A diagram of a process  Description automatically generated"/></span></figure>
    <p class="packt_figref"><span class="koboSpan" id="kobo.31.1">Figure 5.1: A variant of an adaptive RAG ecosystem</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.32.1">The variant </span><a id="_idIndexMarker308"/><span class="koboSpan" id="kobo.33.1">of an adaptive RAG ecosystem in this chapter includes the following components, as shown in </span><em class="italic"><span class="koboSpan" id="kobo.34.1">Figure 5.1</span></em><span class="koboSpan" id="kobo.35.1">, for the retriever:</span></p>
    <ul>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.36.1">D1</span></strong><span class="koboSpan" id="kobo.37.1">: </span><strong class="keyWord"><span class="koboSpan" id="kobo.38.1">Collect and process</span></strong><span class="koboSpan" id="kobo.39.1"> Wikipedia articles on LLMs by fetching and cleaning the data</span></li>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.40.1">D4</span></strong><span class="koboSpan" id="kobo.41.1">: </span><strong class="keyWord"><span class="koboSpan" id="kobo.42.1">Retrieval query</span></strong><span class="koboSpan" id="kobo.43.1"> to query the retrieval dataset</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.44.1">The generator’s components are:</span></p>
    <ul>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.45.1">G1</span></strong><span class="koboSpan" id="kobo.46.1">: </span><strong class="keyWord"><span class="koboSpan" id="kobo.47.1">Input </span></strong><span class="koboSpan" id="kobo.48.1">entered by an end-user</span></li>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.49.1">G2</span></strong><span class="koboSpan" id="kobo.50.1">: </span><strong class="keyWord"><span class="koboSpan" id="kobo.51.1">Augmented input with HF </span></strong><span class="koboSpan" id="kobo.52.1">that will augment the user’s initial input and </span><strong class="keyWord"><span class="koboSpan" id="kobo.53.1">prompt engineering </span></strong><span class="koboSpan" id="kobo.54.1">to configure the GPT-4o model’s prompt</span></li>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.55.1">G4</span></strong><span class="koboSpan" id="kobo.56.1">: </span><strong class="keyWord"><span class="koboSpan" id="kobo.57.1">Generation and output </span></strong><span class="koboSpan" id="kobo.58.1">to run the generative AI model and obtain a response</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.59.1">The evaluator’s components are:</span></p>
    <ul>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.60.1">E1</span></strong><span class="koboSpan" id="kobo.61.1">: </span><strong class="keyWord"><span class="koboSpan" id="kobo.62.1">Metrics</span></strong><span class="koboSpan" id="kobo.63.1"> to apply a cosine similarity measurement</span></li>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.64.1">E2</span></strong><span class="koboSpan" id="kobo.65.1">: </span><strong class="keyWord"><span class="koboSpan" id="kobo.66.1">Human feedback</span></strong><span class="koboSpan" id="kobo.67.1"> to obtain and process the ultimate measurement of a system through end-user and expert feedback</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.68.1">In this chapter, we will illustrate adaptive RAG by building a hybrid adaptive RAG program in Python on Google Colab. </span><span class="koboSpan" id="kobo.68.2">We will build this program from scratch to acquire a clear understanding of an adaptive process, which may vary depending on a project’s goals, but the underlying principles remain the same. </span><span class="koboSpan" id="kobo.68.3">Through this hands-on experience, you will learn </span><a id="_idIndexMarker309"/><span class="koboSpan" id="kobo.69.1">how to develop and customize a RAG system when a ready-to-use one fails to meet the users’ expectations. </span><span class="koboSpan" id="kobo.69.2">This is important because human users can be dissatisfied with a response no matter what the performance metrics show. </span><span class="koboSpan" id="kobo.69.3">We will also explore the incorporation of human user rankings to gather expert feedback on our RAG-driven generative AI system. </span><span class="koboSpan" id="kobo.69.4">Finally, we will implement an automated ranking system that will decide how to augment the user input for the generative model, offering practical insights into how a RAG-driven system can be successfully implemented in a company.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.70.1">We will develop a proof of concept for a hypothetical company called </span><em class="italic"><span class="koboSpan" id="kobo.71.1">Company C</span></em><span class="koboSpan" id="kobo.72.1">. </span><span class="koboSpan" id="kobo.72.2">This company would like to deploy a conversational agent that explains what AI is. </span><span class="koboSpan" id="kobo.72.3">The goal is for the employees of this company to understand the basic terms, concepts, and applications of AI. </span><span class="koboSpan" id="kobo.72.4">The ML engineer in charge of this RAG-driven generative AI example would like future users to acquire a better knowledge of AI while implementing other AI projects across the sales, production, and delivery domains.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.73.1">Company C currently faces serious issues with customer support. </span><span class="koboSpan" id="kobo.73.2">With a growing number of products and services, their product line of smartphones of the C-phone series has been experiencing technical problems with too many customer requests. </span><span class="koboSpan" id="kobo.73.3">The IT department would like to set up a conversational agent for these customers. </span><span class="koboSpan" id="kobo.73.4">However, the teams are not convinced. </span><span class="koboSpan" id="kobo.73.5">The IT department has thus decided to first set up a conversational agent to explain what an LLM is and how it can be helpful in the C-phone series customer support service.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.74.1">The program will be hybrid and adaptive to fulfill the needs of Company C:</span></p>
    <ul>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.75.1">Hybrid</span></strong><span class="koboSpan" id="kobo.76.1">: Real-life scenarios go beyond theoretical frameworks and configurations. </span><span class="koboSpan" id="kobo.76.2">The system is hybrid because we are integrating HF within the retrieval process that can be processed in real time. </span><span class="koboSpan" id="kobo.76.3">However, we will not parse the content of the documents with a keyword alone. </span><span class="koboSpan" id="kobo.76.4">We will label the documents (which are Wikipedia URLs in this case), which can be done automatically, controlled, and improved </span><em class="italic"><span class="koboSpan" id="kobo.77.1">by a human</span></em><span class="koboSpan" id="kobo.78.1">, if necessary. </span><span class="koboSpan" id="kobo.78.2">As we show in this chapter, some documents will be replaced by human-expert feedback and relabeled. </span><span class="koboSpan" id="kobo.78.3">The program will automatically retrieve human-expert feedback documents and raw retrieved documents to form a hybrid (human-machine) </span><em class="italic"><span class="koboSpan" id="kobo.79.1">dynamic</span></em><span class="koboSpan" id="kobo.80.1"> RAG system.</span></li>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.81.1">Adaptive</span></strong><span class="koboSpan" id="kobo.82.1">: We will introduce human user ranking, expert feedback, and automated document re-ranking. </span><span class="koboSpan" id="kobo.82.2">This HF loop takes us deep into modular RAG and adaptive RAG. </span><span class="koboSpan" id="kobo.82.3">Adaptive RAG leverages the flexibility of a RAG system to adapt its responses to the queries. </span><span class="koboSpan" id="kobo.82.4">In this case, we want HF to be triggered to improve the quality of the output.</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.83.1">Real-life projects will inevitably require an ML engineer to go beyond the boundaries of pre-determined categories. </span><span class="koboSpan" id="kobo.83.2">Pragmatism and necessity encourage creative and innovative solutions. </span><span class="koboSpan" id="kobo.83.3">For example, for the hybrid, dynamic, and adaptive aspects of the system, ML engineers </span><a id="_idIndexMarker310"/><span class="koboSpan" id="kobo.84.1">could imagine any process that works with any type of algorithm: classical software functions, ML clustering algorithms, or any function that works. </span><span class="koboSpan" id="kobo.84.2">In real-life AI, what works, works!</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.85.1">It’s time to build a proof of concept to show Company C’s management how hybrid adaptive RAG-driven generative AI can successfully help their teams by:</span></p>
    <ul>
      <li class="bulletList"><span class="koboSpan" id="kobo.86.1">Proving that AI can work with a proof of concept before scaling and investing in a project</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.87.1">Showing that an AI system can be customized for a specific project</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.88.1">Developing solid ground-up skills to face any AI challenge</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.89.1">Building the company’s data governance and control of AI systems</span></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.90.1">Laying solid grounds to scale the system by solving the problems that will come up during the proof of concept</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.91.1">Let’s go to our keyboards!</span></p>
    <h1 id="_idParaDest-127" class="heading-1"><span class="koboSpan" id="kobo.92.1">Building hybrid adaptive RAG in Python</span></h1>
    <p class="normal"><span class="koboSpan" id="kobo.93.1">Let’s now </span><a id="_idIndexMarker311"/><span class="koboSpan" id="kobo.94.1">start building the proof of concept </span><a id="_idIndexMarker312"/><span class="koboSpan" id="kobo.95.1">of a hybrid adaptive RAG-driven generative AI configuration. </span><span class="koboSpan" id="kobo.95.2">Open </span><code class="inlineCode"><span class="koboSpan" id="kobo.96.1">Adaptive_RAG.ipynb</span></code><span class="koboSpan" id="kobo.97.1"> on GitHub. </span><span class="koboSpan" id="kobo.97.2">We will focus on HF and, as such, will not use an existing framework. </span><span class="koboSpan" id="kobo.97.3">We will build our own pipeline and introduce HF.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.98.1">As established earlier, the program is divided into three separate parts: the </span><strong class="keyWord"><span class="koboSpan" id="kobo.99.1">retriever</span></strong><span class="koboSpan" id="kobo.100.1">, </span><strong class="keyWord"><span class="koboSpan" id="kobo.101.1">generator</span></strong><span class="koboSpan" id="kobo.102.1">, and </span><strong class="keyWord"><span class="koboSpan" id="kobo.103.1">evaluator</span></strong><span class="koboSpan" id="kobo.104.1"> functions, which can be separate agents in a real-life project’s pipeline. </span><span class="koboSpan" id="kobo.104.2">Try to separate these functions from the start because, in a project, several teams might be working in parallel on separate aspects of the RAG framework.</span></p>
    <div class="note">
      <p class="normal"><span class="koboSpan" id="kobo.105.1">The titles of each of the following sections correspond exactly to the names of each section in the program on GitHub. </span><span class="koboSpan" id="kobo.105.2">The retriever functionality comes first.</span></p>
    </div>
    <h2 id="_idParaDest-128" class="heading-2"><span class="koboSpan" id="kobo.106.1">1. </span><span class="koboSpan" id="kobo.106.2">Retriever</span></h2>
    <p class="normal"><span class="koboSpan" id="kobo.107.1">We will first outline the initial steps required to set up the environment for a RAG-driven generative </span><a id="_idIndexMarker313"/><span class="koboSpan" id="kobo.108.1">AI model. </span><span class="koboSpan" id="kobo.108.2">This process begins with the installation of </span><a id="_idIndexMarker314"/><span class="koboSpan" id="kobo.109.1">essential software components and libraries that facilitate the retrieval and processing of data. </span><span class="koboSpan" id="kobo.109.2">We specifically cover the downloading of crucial files and the installation of packages needed for effective data retrieval and web scraping.</span></p>
    <h3 id="_idParaDest-129" class="heading-3"><span class="koboSpan" id="kobo.110.1">1.1. </span><span class="koboSpan" id="kobo.110.2">Installing the retriever’s environment</span></h3>
    <p class="normal"><span class="koboSpan" id="kobo.111.1">Let’s begin by downloading </span><code class="inlineCode"><span class="koboSpan" id="kobo.112.1">grequests.py</span></code><span class="koboSpan" id="kobo.113.1"> from the </span><code class="inlineCode"><span class="koboSpan" id="kobo.114.1">commons</span></code><span class="koboSpan" id="kobo.115.1"> directory of the GitHub repository. </span><span class="koboSpan" id="kobo.115.2">This </span><a id="_idIndexMarker315"/><span class="koboSpan" id="kobo.116.1">repository contains resources that can be common to several programs in the repository, thus avoiding redundancy.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.117.1">The download is standard and built around the request:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.118.1">url = </span><span class="hljs-string"><span class="koboSpan" id="kobo.119.1">"https://raw.githubusercontent.com/Denis2054/RAG-Driven-Generative-AI/main/commons/grequests.py"</span></span><span class="koboSpan" id="kobo.120.1">
output_file = </span><span class="hljs-string"><span class="koboSpan" id="kobo.121.1">"grequests.py"</span></span>
</code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.122.1">We will only need two packages for the retriever since we are building a RAG-driven generative AI model from scratch. </span><span class="koboSpan" id="kobo.122.2">We will install:</span></p>
    <ul>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.123.1">requests</span></code><span class="koboSpan" id="kobo.124.1">, the HTTP library to retrieve Wikipedia documents:
        </span><pre class="programlisting code-one"><code class="hljs-code"><span class="koboSpan" id="kobo.125.1">!pip install requests==</span><span class="hljs-number"><span class="koboSpan" id="kobo.126.1">2.32.3</span></span>
</code></pre>
      </li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.127.1">beautifulsoup4</span></code><span class="koboSpan" id="kobo.128.1">, to scrape information from web pages:
        </span><pre class="programlisting code-one"><code class="hljs-code"><span class="koboSpan" id="kobo.129.1">!pip install beautifulsoup4==</span><span class="hljs-number"><span class="koboSpan" id="kobo.130.1">4.12.3</span></span>
</code></pre>
      </li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.131.1">We now need a dataset.</span></p>
    <h3 id="_idParaDest-130" class="heading-3"><span class="koboSpan" id="kobo.132.1">1.2.1. </span><span class="koboSpan" id="kobo.132.2">Preparing the dataset</span></h3>
    <p class="normal"><span class="koboSpan" id="kobo.133.1">For this proof of concept, we will retrieve Wikipedia documents by scraping them through </span><a id="_idIndexMarker316"/><span class="koboSpan" id="kobo.134.1">their URLs. </span><span class="koboSpan" id="kobo.134.2">The dataset will contain automated or human-crafted labels for each document, which is the first step toward indexing the documents of a dataset:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.135.1">import</span></span><span class="koboSpan" id="kobo.136.1"> requests
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.137.1">from</span></span><span class="koboSpan" id="kobo.138.1"> bs4 </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.139.1">import</span></span><span class="koboSpan" id="kobo.140.1"> BeautifulSoup
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.141.1">import</span></span><span class="koboSpan" id="kobo.142.1"> re
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.143.1"># URLs of the Wikipedia articles mapped to keywords</span></span><span class="koboSpan" id="kobo.144.1">
urls = {
    </span><span class="hljs-string"><span class="koboSpan" id="kobo.145.1">"prompt engineering"</span></span><span class="koboSpan" id="kobo.146.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.147.1">"https://en.wikipedia.org/wiki/Prompt_engineering"</span></span><span class="koboSpan" id="kobo.148.1">,
    </span><span class="hljs-string"><span class="koboSpan" id="kobo.149.1">"artificial intelligence"</span></span><span class="koboSpan" id="kobo.150.1">:</span><span class="hljs-string"><span class="koboSpan" id="kobo.151.1">"https://en.wikipedia.org/wiki/Artificial_intelligence"</span></span><span class="koboSpan" id="kobo.152.1">,
    </span><span class="hljs-string"><span class="koboSpan" id="kobo.153.1">"llm"</span></span><span class="koboSpan" id="kobo.154.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.155.1">"https://en.wikipedia.org/wiki/Large_language_model"</span></span><span class="koboSpan" id="kobo.156.1">,
    </span><span class="hljs-string"><span class="koboSpan" id="kobo.157.1">"llms"</span></span><span class="koboSpan" id="kobo.158.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.159.1">"https://en.wikipedia.org/wiki/Large_language_model"</span></span><span class="koboSpan" id="kobo.160.1">
}
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.161.1">One or more labels precede each URL. </span><span class="koboSpan" id="kobo.161.2">This approach might be sufficient for a relatively small dataset.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.162.1">For specific projects, including a proof of concept, this approach can provide a solid first step to go from naïve RAG (content search with keywords) to searching a dataset with indexes (the labels in this case). </span><span class="koboSpan" id="kobo.162.2">We now have to process the data.</span></p>
    <h3 id="_idParaDest-131" class="heading-3"><span class="koboSpan" id="kobo.163.1">1.2.2. </span><span class="koboSpan" id="kobo.163.2">Processing the data</span></h3>
    <p class="normal"><span class="koboSpan" id="kobo.164.1">We first </span><a id="_idIndexMarker317"/><span class="koboSpan" id="kobo.165.1">apply a standard scraping and text-cleaning function to the document that will be retrieved:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.166.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.167.1">fetch_and_clean</span></span><span class="koboSpan" id="kobo.168.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.169.1">url</span></span><span class="koboSpan" id="kobo.170.1">):
    </span><span class="hljs-comment"><span class="koboSpan" id="kobo.171.1"># Fetch the content of the URL</span></span><span class="koboSpan" id="kobo.172.1">
    response = requests.get(url)
    soup = BeautifulSoup(response.content, </span><span class="hljs-string"><span class="koboSpan" id="kobo.173.1">'html.parser'</span></span><span class="koboSpan" id="kobo.174.1">)
    </span><span class="hljs-comment"><span class="koboSpan" id="kobo.175.1"># Find the main content of the article, ignoring side boxes and headers</span></span><span class="koboSpan" id="kobo.176.1">
    content = soup.find(</span><span class="hljs-string"><span class="koboSpan" id="kobo.177.1">'div'</span></span><span class="koboSpan" id="kobo.178.1">, {</span><span class="hljs-string"><span class="koboSpan" id="kobo.179.1">'class'</span></span><span class="koboSpan" id="kobo.180.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.181.1">'mw-parser-output'</span></span><span class="koboSpan" id="kobo.182.1">})
    </span><span class="hljs-comment"><span class="koboSpan" id="kobo.183.1"># Remove less relevant sections such as "See also", "References", etc.</span></span>
    <span class="hljs-keyword"><span class="koboSpan" id="kobo.184.1">for</span></span><span class="koboSpan" id="kobo.185.1"> section_title </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.186.1">in</span></span><span class="koboSpan" id="kobo.187.1"> [</span><span class="hljs-string"><span class="koboSpan" id="kobo.188.1">'References'</span></span><span class="koboSpan" id="kobo.189.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.190.1">'Bibliography'</span></span><span class="koboSpan" id="kobo.191.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.192.1">'External links'</span></span><span class="koboSpan" id="kobo.193.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.194.1">'See also'</span></span><span class="koboSpan" id="kobo.195.1">]:
        section = content.find(</span><span class="hljs-string"><span class="koboSpan" id="kobo.196.1">'span'</span></span><span class="koboSpan" id="kobo.197.1">, {</span><span class="hljs-string"><span class="koboSpan" id="kobo.198.1">'id'</span></span><span class="koboSpan" id="kobo.199.1">: section_title})
        </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.200.1">if</span></span><span class="koboSpan" id="kobo.201.1"> section:
            </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.202.1">for</span></span><span class="koboSpan" id="kobo.203.1"> sib </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.204.1">in</span></span><span class="koboSpan" id="kobo.205.1"> section.parent.find_next_siblings():
                sib.decompose()
            section.parent.decompose()
    </span><span class="hljs-comment"><span class="koboSpan" id="kobo.206.1"># Focus on extracting and cleaning text from paragraph tags only</span></span><span class="koboSpan" id="kobo.207.1">
    paragraphs = content.find_all(</span><span class="hljs-string"><span class="koboSpan" id="kobo.208.1">'p'</span></span><span class="koboSpan" id="kobo.209.1">)
    cleaned_text = </span><span class="hljs-string"><span class="koboSpan" id="kobo.210.1">' '</span></span><span class="koboSpan" id="kobo.211.1">.join(paragraph.get_text(separator=</span><span class="hljs-string"><span class="koboSpan" id="kobo.212.1">' '</span></span><span class="koboSpan" id="kobo.213.1">, strip=</span><span class="hljs-literal"><span class="koboSpan" id="kobo.214.1">True</span></span><span class="koboSpan" id="kobo.215.1">) </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.216.1">for</span></span><span class="koboSpan" id="kobo.217.1"> paragraph </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.218.1">in</span></span><span class="koboSpan" id="kobo.219.1"> paragraphs)
    cleaned_text = re.sub(</span><span class="hljs-string"><span class="koboSpan" id="kobo.220.1">r'\[\d+\]'</span></span><span class="koboSpan" id="kobo.221.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.222.1">''</span></span><span class="koboSpan" id="kobo.223.1">, cleaned_text)  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.224.1"># Remove citation markers like [1], [2], etc.</span></span>
    <span class="hljs-keyword"><span class="koboSpan" id="kobo.225.1">return</span></span><span class="koboSpan" id="kobo.226.1"> cleaned_text
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.227.1">The code fetches the document’s content based on its URL, which is, in turn, based on its label. </span><span class="koboSpan" id="kobo.227.2">This straightforward approach may satisfy a project’s needs depending on its goals. </span><span class="koboSpan" id="kobo.227.3">An ML </span><a id="_idIndexMarker318"/><span class="koboSpan" id="kobo.228.1">engineer or developer must always be careful not to overload a system with costly and unprofitable functions. </span><span class="koboSpan" id="kobo.228.2">Moreover, labeling website URLs can guide a retriever pipeline to the correct locations to process data, regardless of the techniques (load balancing, API call optimization, etc.) applied. </span><span class="koboSpan" id="kobo.228.3">In the end, each project or sub-project will require one or several techniques, depending on its specific needs.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.229.1">Once the fetching and cleaning function is ready, we can implement the retrieval process for the user’s input.</span></p>
    <h3 id="_idParaDest-132" class="heading-3"><span class="koboSpan" id="kobo.230.1">1.3. </span><span class="koboSpan" id="kobo.230.2">Retrieval process for user input</span></h3>
    <p class="normal"><span class="koboSpan" id="kobo.231.1">The first </span><a id="_idIndexMarker319"/><span class="koboSpan" id="kobo.232.1">step here involves identifying a keyword within the user’s input. </span><span class="koboSpan" id="kobo.232.2">The function </span><code class="inlineCode"><span class="koboSpan" id="kobo.233.1">process_query</span></code><span class="koboSpan" id="kobo.234.1"> takes two parameters: </span><code class="inlineCode"><span class="koboSpan" id="kobo.235.1">user_input</span></code><span class="koboSpan" id="kobo.236.1"> and </span><code class="inlineCode"><span class="koboSpan" id="kobo.237.1">num_words</span></code><span class="koboSpan" id="kobo.238.1">. </span><span class="koboSpan" id="kobo.238.2">The number of words to retrieve is restricted by factors like the input limitations of the model, cost considerations, and overall system performance:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.239.1">import</span></span><span class="koboSpan" id="kobo.240.1"> textwrap
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.241.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.242.1">process_query</span></span><span class="koboSpan" id="kobo.243.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.244.1">user_input, num_words</span></span><span class="koboSpan" id="kobo.245.1">):
    user_input = user_input.lower()
    </span><span class="hljs-comment"><span class="koboSpan" id="kobo.246.1"># Check for any of the specified keywords in the input</span></span><span class="koboSpan" id="kobo.247.1">
    matched_keyword = </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.248.1">next</span></span><span class="koboSpan" id="kobo.249.1">((keyword </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.250.1">for</span></span><span class="koboSpan" id="kobo.251.1"> keyword </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.252.1">in</span></span><span class="koboSpan" id="kobo.253.1"> urls </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.254.1">if</span></span><span class="koboSpan" id="kobo.255.1"> keyword </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.256.1">in</span></span><span class="koboSpan" id="kobo.257.1"> user_input), </span><span class="hljs-literal"><span class="koboSpan" id="kobo.258.1">None</span></span><span class="koboSpan" id="kobo.259.1">)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.260.1">Upon finding </span><a id="_idIndexMarker320"/><span class="koboSpan" id="kobo.261.1">a match between a keyword in the user input and the keywords associated with URLs, the following functions for fetching and cleaning the data are triggered:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.262.1">if</span></span><span class="koboSpan" id="kobo.263.1"> matched_keyword:
    </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.264.1">print</span></span><span class="koboSpan" id="kobo.265.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.266.1">f"Fetching data from: </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.267.1">{urls[matched_keyword]}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.268.1">"</span></span><span class="koboSpan" id="kobo.269.1">)
    cleaned_text = fetch_and_clean(urls[matched_keyword])
   
    </span><span class="hljs-comment"><span class="koboSpan" id="kobo.270.1"># Limit the display to the specified number of words from the cleaned text</span></span><span class="koboSpan" id="kobo.271.1">
    words = cleaned_text.split()  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.272.1"># Split the text into words</span></span><span class="koboSpan" id="kobo.273.1">
    first_n_words = </span><span class="hljs-string"><span class="koboSpan" id="kobo.274.1">' '</span></span><span class="koboSpan" id="kobo.275.1">.join(words[:num_words])  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.276.1"># Join the first n words into a single string</span></span>
</code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.277.1">The </span><code class="inlineCode"><span class="koboSpan" id="kobo.278.1">num_words</span></code><span class="koboSpan" id="kobo.279.1"> parameter helps in chunking the text. </span><span class="koboSpan" id="kobo.279.2">While this basic approach may work for use cases with a manageable volume of data, it’s recommended to embed the data into vectors for more complex scenarios.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.280.1">The cleaned and truncated text is then formatted for display:</span></p>
    <pre class="programlisting code"><code class="hljs-code">    <span class="hljs-comment"><span class="koboSpan" id="kobo.281.1"># Wrap the first n words to 80 characters wide for display</span></span><span class="koboSpan" id="kobo.282.1">
    wrapped_text = textwrap.fill(first_n_words, width=</span><span class="hljs-number"><span class="koboSpan" id="kobo.283.1">80</span></span><span class="koboSpan" id="kobo.284.1">)
    </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.285.1">print</span></span><span class="koboSpan" id="kobo.286.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.287.1">"\nFirst {} words of the cleaned text:"</span></span><span class="koboSpan" id="kobo.288.1">.</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.289.1">format</span></span><span class="koboSpan" id="kobo.290.1">(num_words))
    </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.291.1">print</span></span><span class="koboSpan" id="kobo.292.1">(wrapped_text)  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.293.1"># Print the first n words as a well-formatted paragraph</span></span>
    <span class="hljs-comment"><span class="koboSpan" id="kobo.294.1"># Use the exact same first_n_words for the GPT-4 prompt to ensure consistency</span></span><span class="koboSpan" id="kobo.295.1">
    prompt = </span><span class="hljs-string"><span class="koboSpan" id="kobo.296.1">f"Summarize the following information about </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.297.1">{matched_keyword}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.298.1">:\n</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.299.1">{first_n_words}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.300.1">"</span></span><span class="koboSpan" id="kobo.301.1">
    wrapped_prompt = textwrap.fill(prompt, width=</span><span class="hljs-number"><span class="koboSpan" id="kobo.302.1">80</span></span><span class="koboSpan" id="kobo.303.1">)  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.304.1"># Wrap prompt text</span></span>
    <span class="hljs-built_in"><span class="koboSpan" id="kobo.305.1">print</span></span><span class="koboSpan" id="kobo.306.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.307.1">"\nPrompt for Generator:"</span></span><span class="koboSpan" id="kobo.308.1">, wrapped_prompt)
    </span><span class="hljs-comment"><span class="koboSpan" id="kobo.309.1"># Return the specified number of words</span></span>
    <span class="hljs-keyword"><span class="koboSpan" id="kobo.310.1">return</span></span><span class="koboSpan" id="kobo.311.1"> first_n_words
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.312.1">else</span></span><span class="koboSpan" id="kobo.313.1">:
    </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.314.1">print</span></span><span class="koboSpan" id="kobo.315.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.316.1">"No relevant keywords found. </span><span class="koboSpan" id="kobo.316.2">Please enter a query related to 'LLM', 'LLMs', or 'Prompt Engineering'."</span></span><span class="koboSpan" id="kobo.317.1">)
    </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.318.1">return</span></span> <span class="hljs-literal"><span class="koboSpan" id="kobo.319.1">None</span></span>
</code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.320.1">Note that the </span><a id="_idIndexMarker321"/><span class="koboSpan" id="kobo.321.1">function ultimately returns the first </span><code class="inlineCode"><span class="koboSpan" id="kobo.322.1">n</span></code><span class="koboSpan" id="kobo.323.1"> words, providing a concise and relevant snippet of information based on the user’s query. </span><span class="koboSpan" id="kobo.323.2">This design allows the system to manage data retrieval efficiently while also maintaining user engagement.</span></p>
    <h2 id="_idParaDest-133" class="heading-2"><span class="koboSpan" id="kobo.324.1">2. </span><span class="koboSpan" id="kobo.324.2">Generator</span></h2>
    <p class="normal"><span class="koboSpan" id="kobo.325.1">The generator </span><a id="_idIndexMarker322"/><span class="koboSpan" id="kobo.326.1">ecosystem contains several components, several </span><a id="_idIndexMarker323"/><span class="koboSpan" id="kobo.327.1">of which overlap with the retriever functions and user interfaces in the RAG-driven generative AI frameworks:</span></p>
    <ul>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.328.1">2.1. </span><span class="koboSpan" id="kobo.328.2">Adaptive RAG selection based on human rankings</span></strong><span class="koboSpan" id="kobo.329.1">: This will be based on the ratings of a user panel over time. </span><span class="koboSpan" id="kobo.329.2">In a real-life pipeline, this functionality could be a separate program.</span></li>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.330.1">2.2. </span><span class="koboSpan" id="kobo.330.2">Input</span></strong><span class="koboSpan" id="kobo.331.1">: In a real-life </span><a id="_idIndexMarker324"/><span class="koboSpan" id="kobo.332.1">project, a </span><strong class="keyWord"><span class="koboSpan" id="kobo.333.1">user interface</span></strong><span class="koboSpan" id="kobo.334.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.335.1">UI</span></strong><span class="koboSpan" id="kobo.336.1">) will manage the input. </span><span class="koboSpan" id="kobo.336.2">This interface and the associated process should be carefully designed in collaboration with the users, ideally in a workshop setting where their needs and preferences can be fully understood.</span></li>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.337.1">2.3. </span><span class="koboSpan" id="kobo.337.2">Mean ranking simulation scenario</span></strong><span class="koboSpan" id="kobo.338.1">: Calculating the mean value of the user evaluation scores and functionality.</span></li>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.339.1">2.4. </span><span class="koboSpan" id="kobo.339.2">Checking the input before running the generator</span></strong><span class="koboSpan" id="kobo.340.1">: Displaying the input.</span></li>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.341.1">2.5. </span><span class="koboSpan" id="kobo.341.2">Installing the generative AI environment</span></strong><span class="koboSpan" id="kobo.342.1">: The installation of the generative AI model’s environment, in this case, OpenAI, can be part of another environment in the pipeline in which other team members may be working, implementing, and deploying in production independently of the retriever functionality.</span></li>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.343.1">2.6. </span><span class="koboSpan" id="kobo.343.2">Content generation</span></strong><span class="koboSpan" id="kobo.344.1">: In this section of the program, an OpenAI model will process the input and provide a response that will be evaluated by the evaluator.</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.345.1">Let’s begin by describing the adaptive RAG system.</span></p>
    <h3 id="_idParaDest-134" class="heading-3"><span class="koboSpan" id="kobo.346.1">2.1. </span><span class="koboSpan" id="kobo.346.2">Integrating HF-RAG for augmented document inputs</span></h3>
    <p class="normal"><span class="koboSpan" id="kobo.347.1">The </span><a id="_idIndexMarker325"/><span class="koboSpan" id="kobo.348.1">dynamic nature of information retrieval and the necessity for contextually relevant data augmentation in generative AI models require a flexible system capable of adapting to varying levels </span><a id="_idIndexMarker326"/><span class="koboSpan" id="kobo.349.1">of input quality. </span><span class="koboSpan" id="kobo.349.2">We introduce an </span><strong class="keyWord"><span class="koboSpan" id="kobo.350.1">adaptive RAG selection system</span></strong><span class="koboSpan" id="kobo.351.1">, which employs HF scores to determine the optimal retrieval strategy for document implementation within the RAG ecosystem. </span><span class="koboSpan" id="kobo.351.2">Adaptive functionality takes us beyond naïve RAG and constitutes a hybrid RAG system.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.352.1">Human </span><a id="_idIndexMarker327"/><span class="koboSpan" id="kobo.353.1">evaluators assign mean scores ranging from 1 to 5 to assess the relevance and quality of documents. </span><span class="koboSpan" id="kobo.353.2">These scores trigger distinct operational modes, as shown in the following figure:</span></p>
    <figure class="mediaobject"><span class="koboSpan" id="kobo.354.1"><img src="../Images/B31169_05_02.png" alt="A diagram of a system  Description automatically generated"/></span></figure>
    <p class="packt_figref"><span class="koboSpan" id="kobo.355.1">Figure 5.2: Automated RAG triggers</span></p>
    <ul>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.356.1">Scores of 1 to 2</span></strong><span class="koboSpan" id="kobo.357.1"> indicate a lack of compensatory capability by the RAG system, suggesting the need for maintenance or possibly model fine-tuning. </span><span class="koboSpan" id="kobo.357.2">RAG will be temporarily deactivated until the system is improved. </span><span class="koboSpan" id="kobo.357.3">The user input will be processed but there will be no retrieval.</span></li>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.358.1">Scores of 3 to 4</span></strong><span class="koboSpan" id="kobo.359.1"> initiate an augmentation with human-expert feedback only, utilizing flashcards or snippets to refine the output. </span><span class="koboSpan" id="kobo.359.2">Document-based RAG will be deactivated, but the human-expert feedback data will augment the input.</span></li>
      <li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.360.1">Scores of 5</span></strong><span class="koboSpan" id="kobo.361.1"> initiate keyword-search RAG enhanced by previously gathered HF when necessary, utilizing flashcards or targeted information snippets to refine the output. </span><span class="koboSpan" id="kobo.361.2">The user is not required to provide new feedback in this case.</span></li>
    </ul>
    <div class="note">
      <p class="normal"><span class="koboSpan" id="kobo.362.1">This program implements one of many scenarios. </span><span class="koboSpan" id="kobo.362.2">The scoring system, score levels, and triggers will vary from one project to another, depending on the specification goals to attain. </span><span class="koboSpan" id="kobo.362.3">It is recommended to organize workshops with a panel of users to decide how to implement this adaptive RAG system.</span></p>
    </div>
    <p class="normal"><span class="koboSpan" id="kobo.363.1">This </span><a id="_idIndexMarker328"/><span class="koboSpan" id="kobo.364.1">adaptive approach aims to optimize the balance between automated retrieval and human insight, ensuring the generative model’s outputs are of the highest possible relevance and accuracy. </span><span class="koboSpan" id="kobo.364.2">Let’s now enter the input.</span></p>
    <h3 id="_idParaDest-135" class="heading-3"><span class="koboSpan" id="kobo.365.1">2.2. </span><span class="koboSpan" id="kobo.365.2">Input</span></h3>
    <p class="normal"><span class="koboSpan" id="kobo.366.1">A user </span><a id="_idIndexMarker329"/><span class="koboSpan" id="kobo.367.1">of Company C is prompted to enter a question:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.368.1"># Request user input for keyword parsing</span></span><span class="koboSpan" id="kobo.369.1">
user_input = </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.370.1">input</span></span><span class="koboSpan" id="kobo.371.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.372.1">"Enter your query: "</span></span><span class="koboSpan" id="kobo.373.1">).lower()
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.374.1">In this example and program, we will focus on one question and topic: </span><code class="inlineCode"><span class="koboSpan" id="kobo.375.1">What is an LLM?</span></code><span class="koboSpan" id="kobo.376.1">. </span><span class="koboSpan" id="kobo.376.2">The question appears and is memorized by the model:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.377.1">Enter your query: What is an LLM?
</span></code></pre>
    <div class="note">
      <p class="normal"><span class="koboSpan" id="kobo.378.1">This program is a proof of concept with a strategy and example for the panel of users in Company C who wish to understand an LLM. </span><span class="koboSpan" id="kobo.378.2">Other topics can be added, and the program can be expanded to meet further needs. </span><span class="koboSpan" id="kobo.378.3">It is recommended to organize workshops with a panel of users to decide the next steps.</span></p>
    </div>
    <p class="normal"><span class="koboSpan" id="kobo.379.1">We have prepared the environment and will now activate a RAG scenario.</span></p>
    <h3 id="_idParaDest-136" class="heading-3"><span class="koboSpan" id="kobo.380.1">2.3. </span><span class="koboSpan" id="kobo.380.2">Mean ranking simulation scenario</span></h3>
    <p class="normal"><span class="koboSpan" id="kobo.381.1">For the sake of this program, let’s assume that the human user feedback panel has been evaluating </span><a id="_idIndexMarker330"/><span class="koboSpan" id="kobo.382.1">the hybrid adaptive RAG system for some time with the functions provided in sections </span><em class="italic"><span class="koboSpan" id="kobo.383.1">3.2. </span><span class="koboSpan" id="kobo.383.2">Human user rating</span></em><span class="koboSpan" id="kobo.384.1"> and </span><em class="italic"><span class="koboSpan" id="kobo.385.1">3.3. </span><span class="koboSpan" id="kobo.385.2">Human-expert evaluation</span></em><span class="koboSpan" id="kobo.386.1">. </span><span class="koboSpan" id="kobo.386.2">The user feedback panel ranks the responses a number of times, which automatically updates by calculating the mean of the ratings and storing it in a ranking variable named </span><code class="inlineCode"><span class="koboSpan" id="kobo.387.1">ranking</span></code><span class="koboSpan" id="kobo.388.1">. </span><span class="koboSpan" id="kobo.388.2">The </span><code class="inlineCode"><span class="koboSpan" id="kobo.389.1">ranking</span></code><span class="koboSpan" id="kobo.390.1"> score will help the management team decide whether to downgrade the rank of a document, upgrade it, or suppress documents through manual or automated functions. </span><span class="koboSpan" id="kobo.390.2">You can even simulate one of the scenarios described in the section </span><em class="italic"><span class="koboSpan" id="kobo.391.1">2.1. </span><span class="koboSpan" id="kobo.391.2">Integrating HF-RAG for augmented document inputs</span></em><span class="koboSpan" id="kobo.392.1">.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.393.1">We will begin with a 1 to 5 ranking, which will deactivate RAG so that we can see the native response of the generative model:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.394.1">#Select a score between 1 and 5 to run the simulation</span></span><span class="koboSpan" id="kobo.395.1">
ranking=</span><span class="hljs-number"><span class="koboSpan" id="kobo.396.1">1</span></span>
</code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.397.1">Then, we will modify this value to activate RAG without additional human-expert feedback with </span><code class="inlineCode"><span class="koboSpan" id="kobo.398.1">ranking=5</span></code><span class="koboSpan" id="kobo.399.1">. </span><span class="koboSpan" id="kobo.399.2">Finally, we will modify this value to activate human feedback RAG without retrieving documents with </span><code class="inlineCode"><span class="koboSpan" id="kobo.400.1">ranking=3</span></code><span class="koboSpan" id="kobo.401.1">.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.402.1">In a real-life environment, these rankings will be triggered automatically with the functionality described in sections </span><em class="italic"><span class="koboSpan" id="kobo.403.1">3.2</span></em><span class="koboSpan" id="kobo.404.1"> and </span><em class="italic"><span class="koboSpan" id="kobo.405.1">3.3</span></em><span class="koboSpan" id="kobo.406.1"> after user feedback panel workshops are organized to define the system’s expected behavior. </span><span class="koboSpan" id="kobo.406.2">If you wish to run the three scenarios described in section </span><em class="italic"><span class="koboSpan" id="kobo.407.1">2.1</span></em><span class="koboSpan" id="kobo.408.1">, make sure to initialize the </span><code class="inlineCode"><span class="koboSpan" id="kobo.409.1">text_input</span></code><span class="koboSpan" id="kobo.410.1"> variable that the generative model processes to respond:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.411.1"># initializing the text for the generative AI model simulations</span></span><span class="koboSpan" id="kobo.412.1">
text_input=[]
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.413.1">Each time you switch scenarios, make sure to come back and reinitialize </span><code class="inlineCode"><span class="koboSpan" id="kobo.414.1">text_input</span></code><span class="koboSpan" id="kobo.415.1">.</span></p>
    <div class="note">
      <p class="normal"><span class="koboSpan" id="kobo.416.1">Due to its probabilistic nature, the generative AI model’s output may vary from one run to another.</span></p>
    </div>
    <p class="normal"><span class="koboSpan" id="kobo.417.1">Let’s go through the three rating categories described in section </span><em class="italic"><span class="koboSpan" id="kobo.418.1">2.1</span></em><span class="koboSpan" id="kobo.419.1">.</span></p>
    <h4 class="heading-4"><span class="koboSpan" id="kobo.420.1">Ranking 1–2: No RAG</span></h4>
    <p class="normal"><span class="koboSpan" id="kobo.421.1">The ranking of the generative AI’s output is very low. </span><span class="koboSpan" id="kobo.421.2">All RAG functionality is deactivated until </span><a id="_idIndexMarker331"/><span class="koboSpan" id="kobo.422.1">the management team can analyze and improve the system. </span><span class="koboSpan" id="kobo.422.2">In this case, </span><code class="inlineCode"><span class="koboSpan" id="kobo.423.1">text_input</span></code><span class="koboSpan" id="kobo.424.1"> is equal to </span><code class="inlineCode"><span class="koboSpan" id="kobo.425.1">user_input</span></code><span class="koboSpan" id="kobo.426.1">:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.427.1">if</span></span><span class="koboSpan" id="kobo.428.1"> ranking&gt;=</span><span class="hljs-number"><span class="koboSpan" id="kobo.429.1">1</span></span> <span class="hljs-keyword"><span class="koboSpan" id="kobo.430.1">and</span></span><span class="koboSpan" id="kobo.431.1"> ranking&lt;</span><span class="hljs-number"><span class="koboSpan" id="kobo.432.1">3</span></span><span class="koboSpan" id="kobo.433.1">:
  text_input=user_input
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.434.1">The generative AI model, in this case, GPT-4o, will generate the following output in section </span><em class="italic"><span class="koboSpan" id="kobo.435.1">2.6. </span><span class="koboSpan" id="kobo.435.2">Content generation</span></em><span class="koboSpan" id="kobo.436.1">:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.437.1">GPT-4 Response:
---------------
It seems like you're asking about "LLM" which stands for "Language Model for Dialogue Applications" or more commonly referred to as a "Large Language Model."
</span><span class="koboSpan" id="kobo.437.2">An LLM is a type of artificial intelligence model designed to understand, generate, and interact with human language. </span><span class="koboSpan" id="kobo.437.3">These models are trained on vast amounts of text data and use this training to generate text, answer questions, summarize information, translate languages, and perform other language-related tasks. </span><span class="koboSpan" id="kobo.437.4">They are a subset of machine learning models known as transformers, which have been revolutionary in the field of natural language processing (NLP).
</span><span class="koboSpan" id="kobo.437.5">Examples of LLMs include OpenAI's GPT (Generative Pre-trained Transformer) series and Google's BERT (Bidirectional Encoder Representations from
Transformers).
</span><span class="koboSpan" id="kobo.437.6">---------------
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.438.1">This output cannot satisfy the user panel of Company C in this particular use case. </span><span class="koboSpan" id="kobo.438.2">They cannot relate this explanation to their customer service issues. </span><span class="koboSpan" id="kobo.438.3">Furthermore, many users will not bother going further since they have described their needs to the management team and expect pertinent responses. </span><span class="koboSpan" id="kobo.438.4">Let’s see what human-expert feedback RAG can provide.</span></p>
    <h4 class="heading-4"><span class="koboSpan" id="kobo.439.1">Ranking 3–4: Human-expert feedback RAG</span></h4>
    <p class="normal"><span class="koboSpan" id="kobo.440.1">In this scenario, human-expert feedback (see </span><em class="italic"><span class="koboSpan" id="kobo.441.1">section 3.4. </span><span class="koboSpan" id="kobo.441.2">Human-expert evaluation</span></em><span class="koboSpan" id="kobo.442.1">) was triggered </span><a id="_idIndexMarker332"/><span class="koboSpan" id="kobo.443.1">by poor user feedback ratings with automated RAG documents </span><code class="inlineCode"><span class="koboSpan" id="kobo.444.1">(ranking=5)</span></code><span class="koboSpan" id="kobo.445.1"> and without RAG </span><code class="inlineCode"><span class="koboSpan" id="kobo.446.1">(ranking 1-2)</span></code><span class="koboSpan" id="kobo.447.1">. </span><span class="koboSpan" id="kobo.447.2">The human-expert panel has filled in a flashcard, which has now been stored as an expert-level RAG document.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.448.1">The program first checks the ranking and activates HF retrieval:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.449.1">hf=</span><span class="hljs-literal"><span class="koboSpan" id="kobo.450.1">False</span></span>
<span class="hljs-keyword"><span class="koboSpan" id="kobo.451.1">if</span></span><span class="koboSpan" id="kobo.452.1"> ranking&gt;</span><span class="hljs-number"><span class="koboSpan" id="kobo.453.1">3</span></span> <span class="hljs-keyword"><span class="koboSpan" id="kobo.454.1">and</span></span><span class="koboSpan" id="kobo.455.1"> ranking&lt;</span><span class="hljs-number"><span class="koboSpan" id="kobo.456.1">5</span></span><span class="koboSpan" id="kobo.457.1">:
  hf=</span><span class="hljs-literal"><span class="koboSpan" id="kobo.458.1">True</span></span>
</code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.459.1">The program will then fetch the proper document from an expert panel (selected experts within a corporation) dataset based on keywords, embeddings, or other search methods that fit the goals of a project. </span><span class="koboSpan" id="kobo.459.2">In this case, we assume we have found the right flashcard and download it:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.460.1">if</span></span><span class="koboSpan" id="kobo.461.1"> hf==</span><span class="hljs-literal"><span class="koboSpan" id="kobo.462.1">True</span></span><span class="koboSpan" id="kobo.463.1">:
  </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.464.1">from</span></span><span class="koboSpan" id="kobo.465.1"> grequests </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.466.1">import</span></span><span class="koboSpan" id="kobo.467.1"> download
  directory = </span><span class="hljs-string"><span class="koboSpan" id="kobo.468.1">"Chapter05"</span></span><span class="koboSpan" id="kobo.469.1">
  filename = </span><span class="hljs-string"><span class="koboSpan" id="kobo.470.1">"human_feedback.txt"</span></span><span class="koboSpan" id="kobo.471.1">
  download(directory, filename, private_token)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.472.1">We verify if the file exists and load its content, clean it, store it in </span><code class="inlineCode"><span class="koboSpan" id="kobo.473.1">content</span></code><span class="koboSpan" id="kobo.474.1">, and assign it to </span><code class="inlineCode"><span class="koboSpan" id="kobo.475.1">text_input</span></code><span class="koboSpan" id="kobo.476.1"> for the GPT-4 model:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.477.1">if</span></span><span class="koboSpan" id="kobo.478.1"> hf==</span><span class="hljs-literal"><span class="koboSpan" id="kobo.479.1">True</span></span><span class="koboSpan" id="kobo.480.1">:
  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.481.1"># Check if 'human_feedback.txt' exists</span></span><span class="koboSpan" id="kobo.482.1">
    efile = os.path.exists(</span><span class="hljs-string"><span class="koboSpan" id="kobo.483.1">'human_feedback.txt'</span></span><span class="koboSpan" id="kobo.484.1">)
    </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.485.1">if</span></span><span class="koboSpan" id="kobo.486.1"> efile:
        </span><span class="hljs-comment"><span class="koboSpan" id="kobo.487.1"># Read and clean the file content</span></span>
        <span class="hljs-keyword"><span class="koboSpan" id="kobo.488.1">with</span></span> <span class="hljs-built_in"><span class="koboSpan" id="kobo.489.1">open</span></span><span class="koboSpan" id="kobo.490.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.491.1">'human_feedback.txt'</span></span><span class="koboSpan" id="kobo.492.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.493.1">'r'</span></span><span class="koboSpan" id="kobo.494.1">) </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.495.1">as</span></span><span class="koboSpan" id="kobo.496.1"> file:
            content = file.read().replace(</span><span class="hljs-string"><span class="koboSpan" id="kobo.497.1">'\n'</span></span><span class="koboSpan" id="kobo.498.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.499.1">' '</span></span><span class="koboSpan" id="kobo.500.1">).replace(</span><span class="hljs-string"><span class="koboSpan" id="kobo.501.1">'#'</span></span><span class="koboSpan" id="kobo.502.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.503.1">''</span></span><span class="koboSpan" id="kobo.504.1">)  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.505.1"># Removing new line and markdown characters</span></span>
            <span class="hljs-comment"><span class="koboSpan" id="kobo.506.1">#print(content)  # Uncomment for debugging or maintenance display</span></span><span class="koboSpan" id="kobo.507.1">
        text_input=content
        </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.508.1">print</span></span><span class="koboSpan" id="kobo.509.1">(text_input)
    </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.510.1">else</span></span><span class="koboSpan" id="kobo.511.1">:
      </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.512.1">print</span></span><span class="koboSpan" id="kobo.513.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.514.1">"File not found"</span></span><span class="koboSpan" id="kobo.515.1">)
      hf=</span><span class="hljs-literal"><span class="koboSpan" id="kobo.516.1">False</span></span>
</code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.517.1">The content of the file explains both what an LLM is and how it can help Company C improve customer support:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.518.1">A Large Language Model (LLM) is an advanced AI system trained on vast amounts of text data to generate human-like text responses. </span><span class="koboSpan" id="kobo.518.2">It understands and generates language based on the patterns and information it has learned during training. </span><span class="koboSpan" id="kobo.518.3">LLMs are highly effective in various language-based tasks, including answering questions, making recommendations, and facilitating conversations. </span><span class="koboSpan" id="kobo.518.4">They can be continually updated with new information and trained to understand specific domains or industries.For the C-phone series customer support, incorporating an LLM could significantly enhance service quality and efficiency. </span><span class="koboSpan" id="kobo.518.5">The conversational agent powered by an LLM can provide instant responses to customer inquiries, reducing wait times and freeing up human agents for more complex issues. </span><span class="koboSpan" id="kobo.518.6">It can be programmed to handle common technical questions about the C-phone series, troubleshoot problems, guide users through setup processes, and offer tips for optimizing device performance. </span><span class="koboSpan" id="kobo.518.7">Additionally, it can be used to gather customer feedback, providing valuable insights into user experiences and product performance. </span><span class="koboSpan" id="kobo.518.8">This feedback can then be used to improve products and services. </span><span class="koboSpan" id="kobo.518.9">Furthermore, the LLM can be designed to escalate issues to human agents when necessary, ensuring that customers receive the best possible support at all levels. </span><span class="koboSpan" id="kobo.518.10">The agent can also provide personalized recommendations for customers based on their usage patterns and preferences, enhancing user satisfaction and loyalty.
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.519.1">If you </span><a id="_idIndexMarker333"/><span class="koboSpan" id="kobo.520.1">now run sections </span><em class="italic"><span class="koboSpan" id="kobo.521.1">2.4</span></em><span class="koboSpan" id="kobo.522.1"> and </span><em class="italic"><span class="koboSpan" id="kobo.523.1">2.5</span></em><span class="koboSpan" id="kobo.524.1"> once and section </span><em class="italic"><span class="koboSpan" id="kobo.525.1">2.6</span></em><span class="koboSpan" id="kobo.526.1"> to generate the content based on this </span><code class="inlineCode"><span class="koboSpan" id="kobo.527.1">text_input</span></code><span class="koboSpan" id="kobo.528.1">, the response will be satisfactory:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.529.1">GPT-4 Response:
---------------
A Large Language Model (LLM) is a sophisticated AI system trained on extensive
text data to generate human-like text responses. </span><span class="koboSpan" id="kobo.529.2">It understands and generates
language based on patterns and information learned during training. </span><span class="koboSpan" id="kobo.529.3">LLMs are
highly effective in various language-based tasks such as answering questions,
making recommendations, and facilitating conversations. </span><span class="koboSpan" id="kobo.529.4">They can be continuously updated with new information and trained to understand specific domains or industries.  </span><span class="koboSpan" id="kobo.529.5">For the C-phone series customer support, incorporating an LLM could significantly enhance service quality and efficiency. </span><span class="koboSpan" id="kobo.529.6">The conversational agent powered by an LLM can provide instant responses to customer inquiries, reducing wait times and freeing up human agents for more complex issues. 
</span><span class="koboSpan" id="kobo.529.7">It can be programmed to handle common technical questions about the C-phone series,
troubleshoot problems, guide users through setup processes, and offer tips for
optimizing device performance. </span><span class="koboSpan" id="kobo.529.8">Additionally, it can be used to gather customer
feedback, providing valuable insights into user experiences and product
performance. </span><span class="koboSpan" id="kobo.529.9">This feedback can then be used to improve products and services.
</span><span class="koboSpan" id="kobo.529.10">Furthermore, the LLM can be designed to escalate issues to human agents when
necessary, ensuring that customers receive the best possible support at all
levels. </span><span class="koboSpan" id="kobo.529.11">The agent can also provide personalized recommendations for customers
based on their usage patterns and preferences, enhancing user satisfaction and
loyalty.
</span><span class="koboSpan" id="kobo.529.12">---------------
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.530.1">The </span><a id="_idIndexMarker334"/><span class="koboSpan" id="kobo.531.1">preceding response is now much better since it defines LLMs and also shows how to improve customer service for Company C’s C-phone series.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.532.1">We will take this further in </span><em class="chapterRef"><span class="koboSpan" id="kobo.533.1">Chapter 9</span></em><span class="koboSpan" id="kobo.534.1">, </span><em class="italic"><span class="koboSpan" id="kobo.535.1">Empowering AI Models: Fine-Tuning RAG Data and Human Feedback</span></em><span class="koboSpan" id="kobo.536.1">, in which we will fine-tune a generative model daily (or as frequently as possible) to improve its responses, thus alleviating the volume of RAG data. </span><span class="koboSpan" id="kobo.536.2">But for now, let’s see what the system can achieve without HF but with RAG documents.</span></p>
    <h4 class="heading-4"><span class="koboSpan" id="kobo.537.1">Ranking 5: RAG with no human-expert feedback documents</span></h4>
    <p class="normal"><span class="koboSpan" id="kobo.538.1">Some </span><a id="_idIndexMarker335"/><span class="koboSpan" id="kobo.539.1">users do not require RAG documents that include human-expert RAG flashcards, snippets, or documents. </span><span class="koboSpan" id="kobo.539.2">This might be the case, particularly, if software engineers are the users.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.540.1">In this case, the maximum number of words is limited to 100 to optimize API costs, but can be modified as you wish using the following code:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.541.1">if</span></span><span class="koboSpan" id="kobo.542.1"> ranking&gt;=</span><span class="hljs-number"><span class="koboSpan" id="kobo.543.1">5</span></span><span class="koboSpan" id="kobo.544.1">:
  max_words=</span><span class="hljs-number"><span class="koboSpan" id="kobo.545.1">100</span></span> <span class="hljs-comment"><span class="koboSpan" id="kobo.546.1">#Limit: the size of the data we can add to the input</span></span><span class="koboSpan" id="kobo.547.1">
  rdata=process_query(user_input,max_words)
  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.548.1">print(rdata) # for maintenance if necessary</span></span>
  <span class="hljs-keyword"><span class="koboSpan" id="kobo.549.1">if</span></span><span class="koboSpan" id="kobo.550.1"> rdata:
        rdata_clean = rdata.replace(</span><span class="hljs-string"><span class="koboSpan" id="kobo.551.1">'\n'</span></span><span class="koboSpan" id="kobo.552.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.553.1">' '</span></span><span class="koboSpan" id="kobo.554.1">).replace(</span><span class="hljs-string"><span class="koboSpan" id="kobo.555.1">'#'</span></span><span class="koboSpan" id="kobo.556.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.557.1">''</span></span><span class="koboSpan" id="kobo.558.1">)
        rdata_sentences = rdata_clean.split(</span><span class="hljs-string"><span class="koboSpan" id="kobo.559.1">'. </span><span class="koboSpan" id="kobo.559.2">'</span></span><span class="koboSpan" id="kobo.560.1">)
        </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.561.1">print</span></span><span class="koboSpan" id="kobo.562.1">(rdata)
  text_input=rdata
  </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.563.1">print</span></span><span class="koboSpan" id="kobo.564.1">(text_input)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.565.1">When we run the generative AI model, a reasonable output is produced that software engineers can relate to their business:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.566.1">GPT-4 Response:
---------------
A large language model (LLM) is a type of language model known for its
capability to perform general-purpose language generation and other natural language processing tasks such as classification. </span><span class="koboSpan" id="kobo.566.2">LLMs develop these abilities by learning statistical relationships from text documents through a computationally intensive training process that includes both self-supervised
and semi-supervised learning. </span><span class="koboSpan" id="kobo.566.3">These models can generate text, a form of
generative AI, by taking an input text and repeatedly predicting the next token or word. </span><span class="koboSpan" id="kobo.566.4">LLMs are based on artificial neural networks. </span><span class="koboSpan" id="kobo.566.5">As of March 2024, the most advanced and capable LLMs are constructed using a decoder-only transformer architecture.
</span><span class="koboSpan" id="kobo.566.6">---------------
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.567.1">We can see that the output refers to March 2024 data, although GPT-4-turbo’s training cutoff date was in December 2023, as explained in OpenAI’s documentation: </span><a href="https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4"><span class="url"><span class="koboSpan" id="kobo.568.1">https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4</span></span></a><span class="koboSpan" id="kobo.569.1">.</span></p>
    <div class="note">
      <p class="normal"><span class="koboSpan" id="kobo.570.1">In production, at the end-user level, the error in the output can come from the data retrieved or the generative AI model. </span><span class="koboSpan" id="kobo.570.2">This shows the importance of HF. </span><span class="koboSpan" id="kobo.570.3">In this case, this error will hopefully be corrected in the retrieval documents or by the generative AI model. </span><span class="koboSpan" id="kobo.570.4">But we left the error in to illustrate that HF is not an option but a necessity.</span></p>
    </div>
    <p class="normal"><span class="koboSpan" id="kobo.571.1">These temporal RAG augmentations clearly justify the need for RAG-driven generative AI. </span><span class="koboSpan" id="kobo.571.2">However, it remains up to the users to decide if these types of outputs are sufficient or require </span><a id="_idIndexMarker336"/><span class="koboSpan" id="kobo.572.1">more corporate customization in closed environments, such as within or for a company.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.573.1">For the remainder of this program, let’s assume </span><code class="inlineCode"><span class="koboSpan" id="kobo.574.1">ranking&gt;=5</span></code><span class="koboSpan" id="kobo.575.1"> for the next steps to show how the evaluator is implemented in the </span><em class="italic"><span class="koboSpan" id="kobo.576.1">Evaluator</span></em><span class="koboSpan" id="kobo.577.1"> section. </span><span class="koboSpan" id="kobo.577.2">Let’s install the generative AI environment to generate content based on the user input and the document retrieved.</span></p>
    <h3 id="_idParaDest-137" class="heading-3"><span class="koboSpan" id="kobo.578.1">2.4.–2.5. </span><span class="koboSpan" id="kobo.578.2">Installing the generative AI environment</span></h3>
    <div class="note">
      <p class="normal"><em class="italic"><span class="koboSpan" id="kobo.579.1">2.4. </span><span class="koboSpan" id="kobo.579.2">Checking the input before running the generator</span></em><span class="koboSpan" id="kobo.580.1"> displays the user input and retrieved document before augmenting the input with this information. </span><span class="koboSpan" id="kobo.580.2">Then we continue to </span><em class="italic"><span class="koboSpan" id="kobo.581.1">2.5. </span><span class="koboSpan" id="kobo.581.2">Installing the generative AI environment</span></em><span class="koboSpan" id="kobo.582.1">.</span></p>
    </div>
    <p class="normal"><span class="koboSpan" id="kobo.583.1">Only </span><a id="_idIndexMarker337"/><span class="koboSpan" id="kobo.584.1">run this section once. </span><span class="koboSpan" id="kobo.584.2">If you modified the </span><a id="_idIndexMarker338"/><span class="koboSpan" id="kobo.585.1">scenario in section </span><em class="italic"><span class="koboSpan" id="kobo.586.1">2.3</span></em><span class="koboSpan" id="kobo.587.1">, you can skip this section to run the generative AI model again. </span><span class="koboSpan" id="kobo.587.2">This installation is not at the top of this notebook because a project team may choose to run this part of the program in another environment or even another server in production.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.588.1">It is recommended to separate the retriever and generator functions as much as possible since they might be activated by different programs and possibly at different times. </span><span class="koboSpan" id="kobo.588.2">One development team might only work on the retriever functions while another team works on the generator functions.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.589.1">We first install OpenAI:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.590.1">!pip install openai==</span><span class="hljs-number"><span class="koboSpan" id="kobo.591.1">1.40.3</span></span>
</code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.592.1">Then, we retrieve the API key. </span><span class="koboSpan" id="kobo.592.2">Store your OpenAI key in a safe location. </span><span class="koboSpan" id="kobo.592.3">In this case, it is stored on Google Drive:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.593.1">#API Key</span></span>
<span class="hljs-comment"><span class="koboSpan" id="kobo.594.1">#Store your key in a file and read it(you can type it directly in the notebook but it will be visible for somebody next to you)</span></span>
<span class="hljs-keyword"><span class="koboSpan" id="kobo.595.1">from</span></span><span class="koboSpan" id="kobo.596.1"> google.colab </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.597.1">import</span></span><span class="koboSpan" id="kobo.598.1"> drive
drive.mount(</span><span class="hljs-string"><span class="koboSpan" id="kobo.599.1">'</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.600.1">/content/drive'</span></span><span class="koboSpan" id="kobo.601.1">)
f = </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.602.1">open</span></span><span class="koboSpan" id="kobo.603.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.604.1">"drive/MyDrive/files/api_key.txt"</span></span><span class="koboSpan" id="kobo.605.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.606.1">"r"</span></span><span class="koboSpan" id="kobo.607.1">)
API_KEY=f.readline().strip()
f.close()
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.608.1">#The OpenAI Key</span></span>
<span class="hljs-keyword"><span class="koboSpan" id="kobo.609.1">import</span></span><span class="koboSpan" id="kobo.610.1"> os
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.611.1">import</span></span><span class="koboSpan" id="kobo.612.1"> openai
os.environ[</span><span class="hljs-string"><span class="koboSpan" id="kobo.613.1">'OPENAI_API_KEY'</span></span><span class="koboSpan" id="kobo.614.1">] =API_KEY
openai.api_key = os.getenv(</span><span class="hljs-string"><span class="koboSpan" id="kobo.615.1">"OPENAI_API_KEY"</span></span><span class="koboSpan" id="kobo.616.1">)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.617.1">We </span><a id="_idIndexMarker339"/><span class="koboSpan" id="kobo.618.1">are now </span><a id="_idIndexMarker340"/><span class="koboSpan" id="kobo.619.1">all set for content generation.</span></p>
    <h3 id="_idParaDest-138" class="heading-3"><span class="koboSpan" id="kobo.620.1">2.6. </span><span class="koboSpan" id="kobo.620.2">Content generation</span></h3>
    <p class="normal"><span class="koboSpan" id="kobo.621.1">To generate </span><a id="_idIndexMarker341"/><span class="koboSpan" id="kobo.622.1">content, we first import and set up what we need. </span><span class="koboSpan" id="kobo.622.2">We’ve </span><a id="_idIndexMarker342"/><span class="koboSpan" id="kobo.623.1">introduced </span><code class="inlineCode"><span class="koboSpan" id="kobo.624.1">time</span></code><span class="koboSpan" id="kobo.625.1"> to measure the speed of the response and have chosen </span><code class="inlineCode"><span class="koboSpan" id="kobo.626.1">gpt-4o</span></code><span class="koboSpan" id="kobo.627.1"> as our conversational model:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.628.1">import</span></span><span class="koboSpan" id="kobo.629.1"> openai
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.630.1">from</span></span><span class="koboSpan" id="kobo.631.1"> openai </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.632.1">import</span></span><span class="koboSpan" id="kobo.633.1"> OpenAI
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.634.1">import</span></span><span class="koboSpan" id="kobo.635.1"> time
client = OpenAI()
gptmodel=</span><span class="hljs-string"><span class="koboSpan" id="kobo.636.1">"gpt-4o"</span></span><span class="koboSpan" id="kobo.637.1">
start_time = time.time()  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.638.1"># Start timing before the request</span></span>
</code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.639.1">We then define a standard Gpt-4o prompt, giving it enough information to respond and leaving the rest up to the model and RAG data:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.640.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.641.1">call_gpt4_with_full_text</span></span><span class="koboSpan" id="kobo.642.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.643.1">itext</span></span><span class="koboSpan" id="kobo.644.1">):
    </span><span class="hljs-comment"><span class="koboSpan" id="kobo.645.1"># Join all lines to form a single string</span></span><span class="koboSpan" id="kobo.646.1">
    text_input = </span><span class="hljs-string"><span class="koboSpan" id="kobo.647.1">'\n'</span></span><span class="koboSpan" id="kobo.648.1">.join(itext)
    prompt = </span><span class="hljs-string"><span class="koboSpan" id="kobo.649.1">f"Please summarize or elaborate on the following content:\n</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.650.1">{text_input}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.651.1">"</span></span>
    <span class="hljs-keyword"><span class="koboSpan" id="kobo.652.1">try</span></span><span class="koboSpan" id="kobo.653.1">:
      response = client.chat.completions.create(
         model=gptmodel,
         messages=[
            {</span><span class="hljs-string"><span class="koboSpan" id="kobo.654.1">"role"</span></span><span class="koboSpan" id="kobo.655.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.656.1">"system"</span></span><span class="koboSpan" id="kobo.657.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.658.1">"content"</span></span><span class="koboSpan" id="kobo.659.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.660.1">"You are an expert Natural Language Processing exercise expert."</span></span><span class="koboSpan" id="kobo.661.1">},
            {</span><span class="hljs-string"><span class="koboSpan" id="kobo.662.1">"</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.663.1">role"</span></span><span class="koboSpan" id="kobo.664.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.665.1">"assistant"</span></span><span class="koboSpan" id="kobo.666.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.667.1">"content"</span></span><span class="koboSpan" id="kobo.668.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.669.1">"1.You can explain read the input and answer in detail"</span></span><span class="koboSpan" id="kobo.670.1">},
            {</span><span class="hljs-string"><span class="koboSpan" id="kobo.671.1">"role"</span></span><span class="koboSpan" id="kobo.672.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.673.1">"user"</span></span><span class="koboSpan" id="kobo.674.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.675.1">"content"</span></span><span class="koboSpan" id="kobo.676.1">: prompt}
         ],
         temperature=</span><span class="hljs-number"><span class="koboSpan" id="kobo.677.1">0.1</span></span>  <span class="hljs-comment"><span class="koboSpan" id="kobo.678.1"># Add the temperature parameter here and other parameters you need</span></span><span class="koboSpan" id="kobo.679.1">
        )
      </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.680.1">return</span></span><span class="koboSpan" id="kobo.681.1"> response.choices[</span><span class="hljs-number"><span class="koboSpan" id="kobo.682.1">0</span></span><span class="koboSpan" id="kobo.683.1">].message.content.strip()
    </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.684.1">except</span></span><span class="koboSpan" id="kobo.685.1"> Exception </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.686.1">as</span></span><span class="koboSpan" id="kobo.687.1"> e:
        </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.688.1">return</span></span> <span class="hljs-built_in"><span class="koboSpan" id="kobo.689.1">str</span></span><span class="koboSpan" id="kobo.690.1">(e)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.691.1">The </span><a id="_idIndexMarker343"/><span class="koboSpan" id="kobo.692.1">code then </span><a id="_idIndexMarker344"/><span class="koboSpan" id="kobo.693.1">formats the output:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.694.1">import</span></span><span class="koboSpan" id="kobo.695.1"> textwrap
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.696.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.697.1">print_formatted_response</span></span><span class="koboSpan" id="kobo.698.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.699.1">response</span></span><span class="koboSpan" id="kobo.700.1">):
    </span><span class="hljs-comment"><span class="koboSpan" id="kobo.701.1"># Define the width for wrapping the text</span></span><span class="koboSpan" id="kobo.702.1">
    wrapper = textwrap.TextWrapper(width=</span><span class="hljs-number"><span class="koboSpan" id="kobo.703.1">80</span></span><span class="koboSpan" id="kobo.704.1">)  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.705.1"># Set to 80 columns wide, but adjust as needed</span></span><span class="koboSpan" id="kobo.706.1">
    wrapped_text = wrapper.fill(text=response)
    </span><span class="hljs-comment"><span class="koboSpan" id="kobo.707.1"># Print the formatted response with a header and footer</span></span>
    <span class="hljs-built_in"><span class="koboSpan" id="kobo.708.1">print</span></span><span class="koboSpan" id="kobo.709.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.710.1">"GPT-4 Response:"</span></span><span class="koboSpan" id="kobo.711.1">)
    </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.712.1">print</span></span><span class="koboSpan" id="kobo.713.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.714.1">"---------------"</span></span><span class="koboSpan" id="kobo.715.1">)
    </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.716.1">print</span></span><span class="koboSpan" id="kobo.717.1">(wrapped_text)
    </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.718.1">print</span></span><span class="koboSpan" id="kobo.719.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.720.1">"---------------\n"</span></span><span class="koboSpan" id="kobo.721.1">)
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.722.1"># Assuming 'gpt4_response' contains the response from the previous GPT-4 call</span></span><span class="koboSpan" id="kobo.723.1">
print_formatted_response(gpt4_response)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.724.1">The response is satisfactory in this case, as we saw in section </span><em class="italic"><span class="koboSpan" id="kobo.725.1">2.3</span></em><span class="koboSpan" id="kobo.726.1">. </span><span class="koboSpan" id="kobo.726.2">In the </span><code class="inlineCode"><span class="koboSpan" id="kobo.727.1">ranking=5</span></code><span class="koboSpan" id="kobo.728.1"> scenario, which is the one we are now evaluating, we get the following output:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.729.1">GPT-4 Response:
---------------
GPT-4 Response:
---------------
### Summary: A large language model (LLM) is a computational model known for its ability to perform general-purpose language generation and other natural language processing tasks, such as classification. </span><span class="koboSpan" id="kobo.729.2">LLMs acquire these abilities by learning statistical relationships from vast amounts of text during a computationally intensive self-supervised and semi-supervised training process.They can be used for text generation, a form of generative AI, by taking input text and repeatedly predicting the next token or word. </span><span class="koboSpan" id="kobo.729.3">LLMs are artificial neural networks that use the transformer architecture…
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.730.1">The response </span><a id="_idIndexMarker345"/><span class="koboSpan" id="kobo.731.1">looks fine, but is it really accurate? </span><span class="koboSpan" id="kobo.731.2">Let’s run </span><a id="_idIndexMarker346"/><span class="koboSpan" id="kobo.732.1">the evaluator to find out.</span></p>
    <h2 id="_idParaDest-139" class="heading-2"><span class="koboSpan" id="kobo.733.1">3. </span><span class="koboSpan" id="kobo.733.2">Evaluator</span></h2>
    <p class="normal"><span class="koboSpan" id="kobo.734.1">Depending on each project’s specifications and needs, we can implement as many mathematical </span><a id="_idIndexMarker347"/><span class="koboSpan" id="kobo.735.1">and human evaluation functions as necessary. </span><span class="koboSpan" id="kobo.735.2">In this section, we will implement two automatic metrics: response time and cosine similarity score. </span><span class="koboSpan" id="kobo.735.3">We will then implement two interactive evaluation functions: human user rating and human-expert evaluation.</span></p>
    <h3 id="_idParaDest-140" class="heading-3"><span class="koboSpan" id="kobo.736.1">3.1. </span><span class="koboSpan" id="kobo.736.2">Response time</span></h3>
    <p class="normal"><span class="koboSpan" id="kobo.737.1">The response time </span><a id="_idIndexMarker348"/><span class="koboSpan" id="kobo.738.1">was calculated and displayed in the API call with:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.739.1">import</span></span><span class="koboSpan" id="kobo.740.1"> time
…
start_time = time.time()  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.741.1"># Start timing before the request</span></span><span class="koboSpan" id="kobo.742.1">
…
response_time = time.time() - start_time  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.743.1"># Measure response time</span></span>
<span class="hljs-built_in"><span class="koboSpan" id="kobo.744.1">print</span></span><span class="koboSpan" id="kobo.745.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.746.1">f"Response Time: </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.747.1">{response_time:</span></span><span class="hljs-number"><span class="koboSpan" id="kobo.748.1">.2</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.749.1">f}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.750.1"> seconds"</span></span><span class="koboSpan" id="kobo.751.1">)  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.752.1"># Print response time</span></span>
</code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.753.1">In this case, we can display the response time without further development:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-built_in"><span class="koboSpan" id="kobo.754.1">print</span></span><span class="koboSpan" id="kobo.755.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.756.1">f"Response Time: </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.757.1">{response_time:</span></span><span class="hljs-number"><span class="koboSpan" id="kobo.758.1">.2</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.759.1">f}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.760.1"> seconds"</span></span><span class="koboSpan" id="kobo.761.1">)  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.762.1"># Print response time</span></span>
</code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.763.1">The output will vary depending on internet connectivity and the capacity of OpenAI’s servers. </span><span class="koboSpan" id="kobo.763.2">In this case, the output is:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.764.1">Response Time: 7.88 seconds
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.765.1">It seems long, but online conversational agents take some time to answer as well. </span><span class="koboSpan" id="kobo.765.2">Deciding if this performance is sufficient remains a management decision. </span><span class="koboSpan" id="kobo.765.3">Let’s run the cosine similarity score next.</span></p>
    <h3 id="_idParaDest-141" class="heading-3"><span class="koboSpan" id="kobo.766.1">3.2. </span><span class="koboSpan" id="kobo.766.2">Cosine similarity score</span></h3>
    <p class="normal"><span class="koboSpan" id="kobo.767.1">Cosine similarity measures the cosine of the angle between two non-zero vectors. </span><span class="koboSpan" id="kobo.767.2">In the context </span><a id="_idIndexMarker349"/><span class="koboSpan" id="kobo.768.1">of text analysis, these vectors are typically </span><strong class="keyWord"><span class="koboSpan" id="kobo.769.1">TF-IDF</span></strong><span class="koboSpan" id="kobo.770.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.771.1">Term Frequency-Inverse Document Frequency</span></strong><span class="koboSpan" id="kobo.772.1">) representations of the text, which </span><a id="_idIndexMarker350"/><span class="koboSpan" id="kobo.773.1">weigh terms based on their importance relative to the document and a corpus.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.774.1">GPT-4o’s input, which is </span><code class="inlineCode"><span class="koboSpan" id="kobo.775.1">text_input</span></code><span class="koboSpan" id="kobo.776.1">, and the model’s response, which is </span><code class="inlineCode"><span class="koboSpan" id="kobo.777.1">gpt4_response</span></code><span class="koboSpan" id="kobo.778.1">, are treated by TF-IDF as two separate “documents.” </span><span class="koboSpan" id="kobo.778.2">The </span><code class="inlineCode"><span class="koboSpan" id="kobo.779.1">vectorizer</span></code><span class="koboSpan" id="kobo.780.1"> transforms the documents into vectors. </span><span class="koboSpan" id="kobo.780.2">Then, vectorization considers how terms are shared and emphasized between the input and the response with the </span><code class="inlineCode"><span class="koboSpan" id="kobo.781.1">vectorizer.fit_transform([text1, text2])</span></code><span class="koboSpan" id="kobo.782.1">.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.783.1">The goal is to quantify the thematic and lexical overlap through the following function:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.784.1">from</span></span><span class="koboSpan" id="kobo.785.1"> sklearn.feature_extraction.text </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.786.1">import</span></span><span class="koboSpan" id="kobo.787.1"> TfidfVectorizer
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.788.1">from</span></span><span class="koboSpan" id="kobo.789.1"> sklearn.metrics.pairwise </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.790.1">import</span></span><span class="koboSpan" id="kobo.791.1"> cosine_similarity
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.792.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.793.1">calculate_cosine_similarity</span></span><span class="koboSpan" id="kobo.794.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.795.1">text1, text2</span></span><span class="koboSpan" id="kobo.796.1">):
    vectorizer = TfidfVectorizer()
    tfidf = vectorizer.fit_transform([text1, text2])
    similarity = cosine_similarity(tfidf[</span><span class="hljs-number"><span class="koboSpan" id="kobo.797.1">0</span></span><span class="koboSpan" id="kobo.798.1">:</span><span class="hljs-number"><span class="koboSpan" id="kobo.799.1">1</span></span><span class="koboSpan" id="kobo.800.1">], tfidf[</span><span class="hljs-number"><span class="koboSpan" id="kobo.801.1">1</span></span><span class="koboSpan" id="kobo.802.1">:</span><span class="hljs-number"><span class="koboSpan" id="kobo.803.1">2</span></span><span class="koboSpan" id="kobo.804.1">])
    </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.805.1">return</span></span><span class="koboSpan" id="kobo.806.1"> similarity[</span><span class="hljs-number"><span class="koboSpan" id="kobo.807.1">0</span></span><span class="koboSpan" id="kobo.808.1">][</span><span class="hljs-number"><span class="koboSpan" id="kobo.809.1">0</span></span><span class="koboSpan" id="kobo.810.1">]
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.811.1"># Example usage with your existing functions</span></span><span class="koboSpan" id="kobo.812.1">
similarity_score = calculate_cosine_similarity(text_input, gpt4_response)
</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.813.1">print</span></span><span class="koboSpan" id="kobo.814.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.815.1">f"Cosine Similarity Score: </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.816.1">{similarity_score:</span></span><span class="hljs-number"><span class="koboSpan" id="kobo.817.1">.3</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.818.1">f}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.819.1">"</span></span><span class="koboSpan" id="kobo.820.1">)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.821.1">Cosine similarity relies on </span><code class="inlineCode"><span class="koboSpan" id="kobo.822.1">TfidfVectorizer</span></code><span class="koboSpan" id="kobo.823.1"> to transform the two documents into TF-IDF vectors. </span><span class="koboSpan" id="kobo.823.2">The </span><code class="inlineCode"><span class="koboSpan" id="kobo.824.1">cosine_similarity</span></code><span class="koboSpan" id="kobo.825.1"> function then calculates the similarity between these vectors. </span><span class="koboSpan" id="kobo.825.2">A result of </span><code class="inlineCode"><span class="koboSpan" id="kobo.826.1">1</span></code><span class="koboSpan" id="kobo.827.1"> indicates identical texts, while </span><code class="inlineCode"><span class="koboSpan" id="kobo.828.1">0</span></code><span class="koboSpan" id="kobo.829.1"> shows no similarity. </span><span class="koboSpan" id="kobo.829.2">The output of the function is:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.830.1">Cosine Similarity Score: 0.697
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.831.1">The score shows a strong similarity between the input and the output of the model. </span><span class="koboSpan" id="kobo.831.2">But how will a human user rate this response? </span><span class="koboSpan" id="kobo.831.3">Let’s find out.</span></p>
    <h3 id="_idParaDest-142" class="heading-3"><span class="koboSpan" id="kobo.832.1">3.3. </span><span class="koboSpan" id="kobo.832.2">Human user rating</span></h3>
    <p class="normal"><span class="koboSpan" id="kobo.833.1">The human user rating interface provides human user feedback. </span><span class="koboSpan" id="kobo.833.2">As reiterated throughout </span><a id="_idIndexMarker351"/><span class="koboSpan" id="kobo.834.1">this chapter, I recommend designing this interface and process after fully understanding user needs through a workshop with them. </span><span class="koboSpan" id="kobo.834.2">In this section, we will assume that the human user panel is a group of software developers testing the system.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.835.1">The code begins with the interface’s parameters:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"><span class="koboSpan" id="kobo.836.1"># Score parameters</span></span><span class="koboSpan" id="kobo.837.1">
counter=</span><span class="hljs-number"><span class="koboSpan" id="kobo.838.1">20</span></span>                     <span class="hljs-comment"><span class="koboSpan" id="kobo.839.1"># number of feedback queries</span></span><span class="koboSpan" id="kobo.840.1">
score_history=</span><span class="hljs-number"><span class="koboSpan" id="kobo.841.1">30</span></span>               <span class="hljs-comment"><span class="koboSpan" id="kobo.842.1"># human feedback</span></span><span class="koboSpan" id="kobo.843.1">
threshold=</span><span class="hljs-number"><span class="koboSpan" id="kobo.844.1">4</span></span>                    <span class="hljs-comment"><span class="koboSpan" id="kobo.845.1"># minimum rankings to trigger human expert feedback</span></span>
</code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.846.1">In this simulation, the parameters show that the system has computed human feedback:</span></p>
    <ul>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.847.1">counter=20</span></code><span class="koboSpan" id="kobo.848.1"> shows the number of ratings already entered by the users</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.849.1">score_history=60</span></code><span class="koboSpan" id="kobo.850.1"> shows the total score of the 20 ratings</span></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.851.1">threshold=4</span></code><span class="koboSpan" id="kobo.852.1"> states the minimum mean rating, </span><code class="inlineCode"><span class="koboSpan" id="kobo.853.1">score_history/counter</span></code><span class="koboSpan" id="kobo.854.1">, to obtain without triggering a human-expert feedback request</span></li>
    </ul>
    <p class="normal"><span class="koboSpan" id="kobo.855.1">We will now run the interface to add an instance to these parameters. </span><span class="koboSpan" id="kobo.855.2">The provided Python code defines the </span><code class="inlineCode"><span class="koboSpan" id="kobo.856.1">evaluate_response</span></code><span class="koboSpan" id="kobo.857.1"> function, designed to assess the relevance and coherence of responses generated by a language model such as GPT-4. </span><span class="koboSpan" id="kobo.857.2">Users rate the generated text on a scale from </span><code class="inlineCode"><span class="koboSpan" id="kobo.858.1">1</span></code><span class="koboSpan" id="kobo.859.1"> (poor) to </span><code class="inlineCode"><span class="koboSpan" id="kobo.860.1">5</span></code><span class="koboSpan" id="kobo.861.1"> (excellent), with the function ensuring valid input through recursive checks. </span><span class="koboSpan" id="kobo.861.2">The code calculates statistical metrics like mean scores to gauge the model’s performance over multiple evaluations.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.862.1">The evaluation function is a straightforward feedback request to obtain values between </span><code class="inlineCode"><span class="koboSpan" id="kobo.863.1">1</span></code><span class="koboSpan" id="kobo.864.1"> and </span><code class="inlineCode"><span class="koboSpan" id="kobo.865.1">5</span></code><span class="koboSpan" id="kobo.866.1">:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.867.1">import</span></span><span class="koboSpan" id="kobo.868.1"> numpy </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.869.1">as</span></span><span class="koboSpan" id="kobo.870.1"> np
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.871.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.872.1">evaluate_response</span></span><span class="koboSpan" id="kobo.873.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.874.1">response</span></span><span class="koboSpan" id="kobo.875.1">):
    </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.876.1">print</span></span><span class="koboSpan" id="kobo.877.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.878.1">"\nGenerated Response:"</span></span><span class="koboSpan" id="kobo.879.1">)
    </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.880.1">print</span></span><span class="koboSpan" id="kobo.881.1">(response)
    </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.882.1">print</span></span><span class="koboSpan" id="kobo.883.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.884.1">"\nPlease evaluate the response based on the following criteria:"</span></span><span class="koboSpan" id="kobo.885.1">)
    </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.886.1">print</span></span><span class="koboSpan" id="kobo.887.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.888.1">"1 - Poor, 2 - Fair, 3 - Good, 4 - Very Good, 5 - Excellent"</span></span><span class="koboSpan" id="kobo.889.1">)
    score = </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.890.1">input</span></span><span class="koboSpan" id="kobo.891.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.892.1">"Enter the relevance and coherence score (1-5): "</span></span><span class="koboSpan" id="kobo.893.1">)
    </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.894.1">try</span></span><span class="koboSpan" id="kobo.895.1">:
        score = </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.896.1">int</span></span><span class="koboSpan" id="kobo.897.1">(score)
        </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.898.1">if</span></span> <span class="hljs-number"><span class="koboSpan" id="kobo.899.1">1</span></span><span class="koboSpan" id="kobo.900.1"> &lt;= score &lt;= </span><span class="hljs-number"><span class="koboSpan" id="kobo.901.1">5</span></span><span class="koboSpan" id="kobo.902.1">:
            </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.903.1">return</span></span><span class="koboSpan" id="kobo.904.1"> score
        </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.905.1">else</span></span><span class="koboSpan" id="kobo.906.1">:
            </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.907.1">print</span></span><span class="koboSpan" id="kobo.908.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.909.1">"Invalid score. </span><span class="koboSpan" id="kobo.909.2">Please enter a number between 1 and 5."</span></span><span class="koboSpan" id="kobo.910.1">)
            </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.911.1">return</span></span><span class="koboSpan" id="kobo.912.1"> evaluate_response(response)  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.913.1"># Recursive call if the input is invalid</span></span>
    <span class="hljs-keyword"><span class="koboSpan" id="kobo.914.1">except</span></span><span class="koboSpan" id="kobo.915.1"> ValueError:
        </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.916.1">print</span></span><span class="koboSpan" id="kobo.917.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.918.1">"Invalid input. </span><span class="koboSpan" id="kobo.918.2">Please enter a numerical value."</span></span><span class="koboSpan" id="kobo.919.1">)
        </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.920.1">return</span></span><span class="koboSpan" id="kobo.921.1"> evaluate_response(response)  </span><span class="hljs-comment"><span class="koboSpan" id="kobo.922.1"># Recursive call if the input is invalid</span></span>
</code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.923.1">We then </span><a id="_idIndexMarker352"/><span class="koboSpan" id="kobo.924.1">call the function:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.925.1">score = evaluate_response(gpt4_response)
</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.926.1">print</span></span><span class="koboSpan" id="kobo.927.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.928.1">"Evaluator Score:"</span></span><span class="koboSpan" id="kobo.929.1">, score)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.930.1">The function first displays the response, as shown in the following excerpt:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.931.1">Generated Response:
### Summary:
A large language model (LLM) is a computational model…
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.932.1">Then, the user enters an evaluation score between 1 and 5, which is </span><code class="inlineCode"><span class="koboSpan" id="kobo.933.1">1</span></code><span class="koboSpan" id="kobo.934.1"> in this case:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.935.1">Please evaluate the response based on the following criteria:
1 - Poor, 2 - Fair, 3 - Good, 4 - Very Good, 5 - Excellent
Enter the relevance and coherence score (1-5): 3
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.936.1">The code then computes the statistics:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.937.1">counter+=</span><span class="hljs-number"><span class="koboSpan" id="kobo.938.1">1</span></span><span class="koboSpan" id="kobo.939.1">
score_history+=score
mean_score=</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.940.1">round</span></span><span class="koboSpan" id="kobo.941.1">(np.mean(score_history/counter), </span><span class="hljs-number"><span class="koboSpan" id="kobo.942.1">2</span></span><span class="koboSpan" id="kobo.943.1">)
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.944.1">if</span></span><span class="koboSpan" id="kobo.945.1"> counter&gt;</span><span class="hljs-number"><span class="koboSpan" id="kobo.946.1">0</span></span><span class="koboSpan" id="kobo.947.1">:
  </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.948.1">print</span></span><span class="koboSpan" id="kobo.949.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.950.1">"Rankings      :"</span></span><span class="koboSpan" id="kobo.951.1">, counter)
  </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.952.1">print</span></span><span class="koboSpan" id="kobo.953.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.954.1">"Score history : "</span></span><span class="koboSpan" id="kobo.955.1">, mean_score)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.956.1">The output shows a relatively very low rating:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.957.1">Evaluator Score: 3
Rankings      : 21
Score history :  3.0
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.958.1">The evaluator score is </span><code class="inlineCode"><span class="koboSpan" id="kobo.959.1">3</span></code><span class="koboSpan" id="kobo.960.1">, the overall ranking is </span><code class="inlineCode"><span class="koboSpan" id="kobo.961.1">3</span></code><span class="koboSpan" id="kobo.962.1">, and the score history is </span><code class="inlineCode"><span class="koboSpan" id="kobo.963.1">3</span></code><span class="koboSpan" id="kobo.964.1"> also! </span><span class="koboSpan" id="kobo.964.2">Yet, the cosine similarity </span><a id="_idIndexMarker353"/><span class="koboSpan" id="kobo.965.1">was positive. </span><span class="koboSpan" id="kobo.965.2">The human-expert evaluation request will be triggered because we set the threshold to </span><code class="inlineCode"><span class="koboSpan" id="kobo.966.1">4</span></code><span class="koboSpan" id="kobo.967.1">:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.968.1">threshold=4                   
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.969.1">What’s going on? </span><span class="koboSpan" id="kobo.969.2">Let’s ask an expert and find out!</span></p>
    <h3 id="_idParaDest-143" class="heading-3"><span class="koboSpan" id="kobo.970.1">3.4. </span><span class="koboSpan" id="kobo.970.2">Human-expert evaluation</span></h3>
    <p class="normal"><span class="koboSpan" id="kobo.971.1">Metrics such as cosine similarity indeed measure similarity but not in-depth accuracy. </span><span class="koboSpan" id="kobo.971.2">Time </span><a id="_idIndexMarker354"/><span class="koboSpan" id="kobo.972.1">performance will not determine the accuracy of a response either. </span><span class="koboSpan" id="kobo.972.2">But if the rating is too low, why is that? </span><span class="koboSpan" id="kobo.972.3">Because the user is not satisfied with the response!</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.973.1">The code first downloads thumbs-up and thumbs-down images for the human-expert user:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.974.1">from</span></span><span class="koboSpan" id="kobo.975.1"> grequests </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.976.1">import</span></span><span class="koboSpan" id="kobo.977.1"> download
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.978.1"># Define your variables</span></span><span class="koboSpan" id="kobo.979.1">
directory = </span><span class="hljs-string"><span class="koboSpan" id="kobo.980.1">"commons"</span></span><span class="koboSpan" id="kobo.981.1">
filename = </span><span class="hljs-string"><span class="koboSpan" id="kobo.982.1">"thumbs_up.png"</span></span><span class="koboSpan" id="kobo.983.1">
download(directory, filename, private_token)
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.984.1"># Define your variables</span></span><span class="koboSpan" id="kobo.985.1">
directory = </span><span class="hljs-string"><span class="koboSpan" id="kobo.986.1">"commons"</span></span><span class="koboSpan" id="kobo.987.1">
filename = </span><span class="hljs-string"><span class="koboSpan" id="kobo.988.1">"thumbs_down.png"</span></span><span class="koboSpan" id="kobo.989.1">
download(directory, filename, private_token)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.990.1">The parameters to trigger an expert’s feedback are </span><code class="inlineCode"><span class="koboSpan" id="kobo.991.1">counter_threshold</span></code><span class="koboSpan" id="kobo.992.1"> and </span><code class="inlineCode"><span class="koboSpan" id="kobo.993.1">score_threshold</span></code><span class="koboSpan" id="kobo.994.1">. </span><span class="koboSpan" id="kobo.994.2">The number of user ratings must exceed the expert’s threshold counter, which is </span><code class="inlineCode"><span class="koboSpan" id="kobo.995.1">counter_threshold=10</span></code><span class="koboSpan" id="kobo.996.1">. </span><span class="koboSpan" id="kobo.996.2">The threshold of the mean score of the ratings is </span><code class="inlineCode"><span class="koboSpan" id="kobo.997.1">4</span></code><span class="koboSpan" id="kobo.998.1"> in this scenario: </span><code class="inlineCode"><span class="koboSpan" id="kobo.999.1">score_threshold=4</span></code><span class="koboSpan" id="kobo.1000.1">. </span><span class="koboSpan" id="kobo.1000.2">We can now simulate the triggering of an expert feedback request:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.1001.1">if</span></span><span class="koboSpan" id="kobo.1002.1"> counter&gt;counter_threshold </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1003.1">and</span></span><span class="koboSpan" id="kobo.1004.1"> score_history&lt;=score_threshold:
  </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.1005.1">print</span></span><span class="koboSpan" id="kobo.1006.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.1007.1">"Human expert evaluation is required for the feedback loop."</span></span><span class="koboSpan" id="kobo.1008.1">)
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.1009.1">In this case, the output will confirm the expert feedback loop because of the poor mean ratings and the number of times the users rated the response:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.1010.1">Human expert evaluation is required for the feedback loop.
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.1011.1">As mentioned, in a real-life project, a workshop with expert users should be organized to define the interface. </span><span class="koboSpan" id="kobo.1011.2">In this case, a standard HTML interface in a Python cell will display the </span><a id="_idIndexMarker355"/><span class="koboSpan" id="kobo.1012.1">thumbs-up and thumbs-down icons. </span><span class="koboSpan" id="kobo.1012.2">If the expert presses on the thumbs-down icon, a feedback snippet can be entered and saved in a feedback file named </span><code class="inlineCode"><span class="koboSpan" id="kobo.1013.1">expert_feedback.txt</span></code><span class="koboSpan" id="kobo.1014.1">, as shown in the following excerpt of the code:</span></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.1015.1">import</span></span><span class="koboSpan" id="kobo.1016.1"> base64
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1017.1">from</span></span><span class="koboSpan" id="kobo.1018.1"> google.colab </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1019.1">import</span></span><span class="koboSpan" id="kobo.1020.1"> output
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1021.1">from</span></span><span class="koboSpan" id="kobo.1022.1"> IPython.display </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1023.1">import</span></span><span class="koboSpan" id="kobo.1024.1"> display, HTML
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1025.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.1026.1">image_to_data_uri</span></span><span class="koboSpan" id="kobo.1027.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.1028.1">file_path</span></span><span class="koboSpan" id="kobo.1029.1">):
    </span><span class="hljs-string"><span class="koboSpan" id="kobo.1030.1">"""</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.1031.1">    Convert an image to a data URI.</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.1032.1">    """</span></span>
    <span class="hljs-keyword"><span class="koboSpan" id="kobo.1033.1">with</span></span> <span class="hljs-built_in"><span class="koboSpan" id="kobo.1034.1">open</span></span><span class="koboSpan" id="kobo.1035.1">(file_path, </span><span class="hljs-string"><span class="koboSpan" id="kobo.1036.1">'rb'</span></span><span class="koboSpan" id="kobo.1037.1">) </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1038.1">as</span></span><span class="koboSpan" id="kobo.1039.1"> image_file:
        encoded_string = base64.b64encode(image_file.read()).decode()
        </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1040.1">return</span></span> <span class="hljs-string"><span class="koboSpan" id="kobo.1041.1">f'data:image/png;base64,</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.1042.1">{encoded_string}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.1043.1">'</span></span><span class="koboSpan" id="kobo.1044.1">
thumbs_up_data_uri = image_to_data_uri(</span><span class="hljs-string"><span class="koboSpan" id="kobo.1045.1">'/content/thumbs_up.png'</span></span><span class="koboSpan" id="kobo.1046.1">)
thumbs_down_data_uri = image_to_data_uri(</span><span class="hljs-string"><span class="koboSpan" id="kobo.1047.1">'/content/thumbs_down.png'</span></span><span class="koboSpan" id="kobo.1048.1">)
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1049.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.1050.1">display_icons</span></span><span class="koboSpan" id="kobo.1051.1">():
    </span><span class="hljs-comment"><span class="koboSpan" id="kobo.1052.1"># Define the HTML content with the two clickable images</span></span><span class="koboSpan" id="kobo.1053.1">
…/…
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1054.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.1055.1">save_feedback</span></span><span class="koboSpan" id="kobo.1056.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.1057.1">feedback</span></span><span class="koboSpan" id="kobo.1058.1">):
    </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1059.1">with</span></span> <span class="hljs-built_in"><span class="koboSpan" id="kobo.1060.1">open</span></span><span class="koboSpan" id="kobo.1061.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.1062.1">'/content/expert_feedback.txt'</span></span><span class="koboSpan" id="kobo.1063.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.1064.1">'w'</span></span><span class="koboSpan" id="kobo.1065.1">) </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1066.1">as</span></span><span class="koboSpan" id="kobo.1067.1"> f:
        f.write(feedback)
    </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.1068.1">print</span></span><span class="koboSpan" id="kobo.1069.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.1070.1">"</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.1071.1">Feedback saved successfully."</span></span><span class="koboSpan" id="kobo.1072.1">)
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.1073.1"># Register the callback</span></span><span class="koboSpan" id="kobo.1074.1">
output.register_callback(</span><span class="hljs-string"><span class="koboSpan" id="kobo.1075.1">'notebook.save_feedback'</span></span><span class="koboSpan" id="kobo.1076.1">, save_feedback)
</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.1077.1">print</span></span><span class="koboSpan" id="kobo.1078.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.1079.1">"Human Expert Adaptive RAG activated"</span></span><span class="koboSpan" id="kobo.1080.1">)
</span><span class="hljs-comment"><span class="koboSpan" id="kobo.1081.1"># Display the icons with click handlers</span></span><span class="koboSpan" id="kobo.1082.1">
display_icons()
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.1083.1">The code will display the icons shown in the following figure. </span><span class="koboSpan" id="kobo.1083.2">If the expert user presses the thumbs-down icon, they will be prompted to enter feedback.</span></p>
    <figure class="mediaobject"><span class="koboSpan" id="kobo.1084.1"><img src="../Images/B31169_05_03.png" alt="A thumbs down and thumbs down  Description automatically generated"/></span></figure>
    <p class="packt_figref"><span class="koboSpan" id="kobo.1085.1">Figure 5.3: Feedback icons</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.1086.1">You can add a function for thumbs-down meaning that the response was incorrect and that the </span><a id="_idIndexMarker356"/><span class="koboSpan" id="kobo.1087.1">management team has to communicate with the user panel or add a prompt to the user feedback interface. </span><span class="koboSpan" id="kobo.1087.2">This is a management decision, of course. </span><span class="koboSpan" id="kobo.1087.3">In our scenario, the human expert pressed the thumbs-down icon and was prompted to enter a response:</span></p>
    <figure class="mediaobject"><span class="koboSpan" id="kobo.1088.1"><img src="../Images/B31169_05_04.png" alt="A screenshot of a computer  Description automatically generated"/></span></figure>
    <p class="packt_figref"><span class="koboSpan" id="kobo.1089.1">Figure 5.4: “Enter feedback” prompt</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.1090.1">The human expert provided the response, which was saved in </span><code class="inlineCode"><span class="koboSpan" id="kobo.1091.1">'/content/expert_feedback.txt'</span></code><span class="koboSpan" id="kobo.1092.1">. </span><span class="koboSpan" id="kobo.1092.2">Through this, we have finally discovered the inaccuracy, which is in the content of the file displayed in the following cell:</span></p>
    <pre class="programlisting con"><code class="hljs-con"><span class="koboSpan" id="kobo.1093.1">There is an inaccurate statement in the text:
"As of March 2024, the largest and most capable LLMs are built with a decoder-only transformer-based architecture."
</span><span class="koboSpan" id="kobo.1093.2">This statement is not accurate because the largest and most capable Large Language Models, such as Meta's Llama models, have a transformer-based architecture, but they are not "decoder-only." </span><span class="koboSpan" id="kobo.1093.3">These models use the architecture of the transformer, which includes both encoder and decoder components.
</span></code></pre>
    <p class="normal"><span class="koboSpan" id="kobo.1094.1">The preceding </span><a id="_idIndexMarker357"/><span class="koboSpan" id="kobo.1095.1">expert’s feedback can then be used to improve the RAG dataset. </span><span class="koboSpan" id="kobo.1095.2">With this, we have explored the depths of HF-RAG interactions. </span><span class="koboSpan" id="kobo.1095.3">Let’s summarize our journey and move on to the next steps.</span></p>
    <h1 id="_idParaDest-144" class="heading-1"><span class="koboSpan" id="kobo.1096.1">Summary</span></h1>
    <p class="normal"><span class="koboSpan" id="kobo.1097.1">As we wrap up our hands-on approach to pragmatic AI implementations, it’s worth reflecting on the transformative journey we’ve embarked on together, exploring the dynamic world of adaptive RAG. </span><span class="koboSpan" id="kobo.1097.2">We first examined how HF not only complements but also critically enhances generative AI, making it a more powerful tool customized to real-world needs. </span><span class="koboSpan" id="kobo.1097.3">We described the adaptive RAG ecosystem and then went hands-on, building from the ground up. </span><span class="koboSpan" id="kobo.1097.4">Starting with data collection, processing, and querying, we integrated these elements into a RAG-driven generative AI system. </span><span class="koboSpan" id="kobo.1097.5">Our approach wasn’t just about coding; it was about adding adaptability to AI through continuous HF loops.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.1098.1">By augmenting GPT-4’s capabilities with expert insights from previous sessions and end-user evaluations, we demonstrated the practical application and significant impact of HF. </span><span class="koboSpan" id="kobo.1098.2">We implemented a system where the output is not only generated but also ranked by end-users. </span><span class="koboSpan" id="kobo.1098.3">Low rankings triggered an expert feedback loop, emphasizing the importance of human intervention in refining AI responses. </span><span class="koboSpan" id="kobo.1098.4">Building an adaptive RAG program from scratch ensured a deep understanding of how integrating HF can shift a standard AI system to one that evolves and improves over time.</span></p>
    <p class="normal"><span class="koboSpan" id="kobo.1099.1">This chapter wasn’t just about learning; it was about doing, reflecting, and transforming theoretical knowledge into practical skills. </span><span class="koboSpan" id="kobo.1099.2">We are now ready to scale RAG-driven AI to production-level volumes and complexity in the next chapter.</span></p>
    <h1 id="_idParaDest-145" class="heading-1"><span class="koboSpan" id="kobo.1100.1">Questions</span></h1>
    <p class="normal"><span class="koboSpan" id="kobo.1101.1">Answer the following questions with </span><em class="italic"><span class="koboSpan" id="kobo.1102.1">Yes</span></em><span class="koboSpan" id="kobo.1103.1"> or </span><em class="italic"><span class="koboSpan" id="kobo.1104.1">No</span></em><span class="koboSpan" id="kobo.1105.1">:</span></p>
    <ol>
      <li class="numberedList" value="1"><span class="koboSpan" id="kobo.1106.1">Is human feedback essential in improving RAG-driven generative AI systems? </span></li>
      <li class="numberedList"><span class="koboSpan" id="kobo.1107.1">Can the core data in a generative AI model be changed without retraining the model? </span></li>
      <li class="numberedList"><span class="koboSpan" id="kobo.1108.1">Does Adaptive RAG involve real-time human feedback loops to improve retrieval? </span></li>
      <li class="numberedList"><span class="koboSpan" id="kobo.1109.1">Is the primary focus of Adaptive RAG to replace all human input with automated responses? </span></li>
      <li class="numberedList"><span class="koboSpan" id="kobo.1110.1">Can human feedback in Adaptive RAG trigger changes in the retrieved documents? </span></li>
      <li class="numberedList"><span class="koboSpan" id="kobo.1111.1">Does Company C use Adaptive RAG solely for customer support issues? </span></li>
      <li class="numberedList"><span class="koboSpan" id="kobo.1112.1">Is human feedback used only when the AI responses have high user ratings? </span></li>
      <li class="numberedList"><span class="koboSpan" id="kobo.1113.1">Does the program in this chapter provide only text-based retrieval outputs? </span></li>
      <li class="numberedList"><span class="koboSpan" id="kobo.1114.1">Is the Hybrid Adaptive RAG system static, meaning it cannot adjust based on feedback? </span></li>
      <li class="numberedList"><span class="koboSpan" id="kobo.1115.1">Are user rankings completely ignored in determining the relevance of AI responses?</span></li>
    </ol>
    <h1 id="_idParaDest-146" class="heading-1"><span class="koboSpan" id="kobo.1116.1">References</span></h1>
    <ul>
      <li class="bulletList"><em class="italic"><span class="koboSpan" id="kobo.1117.1">Studying Large Language Model Behaviors Under Realistic Knowledge Conflicts</span></em><span class="koboSpan" id="kobo.1118.1"> by Evgenii Kortukov, Alexander Rubinstein, Elisa Nguyen, Seong Joon Oh: </span><a href="https://arxiv.org/abs/2404.16032"><span class="url"><span class="koboSpan" id="kobo.1119.1">https://arxiv.org/abs/2404.16032</span></span></a></li>
      <li class="bulletList"><span class="koboSpan" id="kobo.1120.1">OpenAI models: </span><a href="https://platform.openai.com/docs/models"><span class="url"><span class="koboSpan" id="kobo.1121.1">https://platform.openai.com/docs/models</span></span></a></li>
    </ul>
    <h1 id="_idParaDest-147" class="heading-1"><span class="koboSpan" id="kobo.1122.1">Further reading</span></h1>
    <p class="normal"><span class="koboSpan" id="kobo.1123.1">For more information on the vectorizer and cosine similarity functionality implemented in this chapter, use the following links:</span></p>
    <ul>
      <li class="bulletList"><span class="koboSpan" id="kobo.1124.1">Feature extraction – </span><code class="inlineCode"><span class="koboSpan" id="kobo.1125.1">TfidfVectorizer</span></code><span class="koboSpan" id="kobo.1126.1">: </span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html"><span class="url"><span class="koboSpan" id="kobo.1127.1">https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html</span></span></a></li>
      <li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.1128.1">sklearn.metrics</span></code><span class="koboSpan" id="kobo.1129.1"> – </span><code class="inlineCode"><span class="koboSpan" id="kobo.1130.1">cosine_similarity</span></code><span class="koboSpan" id="kobo.1131.1">: </span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html"><span class="url"><span class="koboSpan" id="kobo.1132.1">https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html</span></span></a></li>
    </ul>
    <h1 id="_idParaDest-148" class="heading-1"><span class="koboSpan" id="kobo.1133.1">Join our community on Discord</span></h1>
    <p class="normal"><span class="koboSpan" id="kobo.1134.1">Join our community’s Discord space for discussions with the author and other readers:</span></p>
    <p class="normal"><a href="https://www.packt.link/rag"><span class="url"><span class="koboSpan" id="kobo.1135.1">https://www.packt.link/rag</span></span></a></p>
    <p class="normal"><span class="koboSpan" id="kobo.1136.1"><img src="../Images/QR_Code50409000288080484.png" alt=""/></span></p>
  </div>
</body></html>