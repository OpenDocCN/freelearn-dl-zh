- en: '10'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '10'
- en: Refining the Semantic Data Model to Improve Accuracy
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 精炼语义数据模型以提高准确性
- en: To effectively use vector search for semantic long-term memory in an intelligent
    application, you must optimize the semantic data model to the application’s needs.
    As the semantic data model uses vector embedding models and vector search, you
    must optimize the contents of the embedded data and the way the data is retrieved.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在智能应用中有效地使用向量搜索进行语义长期记忆，你必须优化语义数据模型以满足应用的需求。由于语义数据模型使用向量嵌入模型和向量搜索，你必须优化嵌入数据的内容以及数据检索的方式。
- en: Refining the semantic data model can lead to significant improvements in retrieval
    accuracy and overall application performance. In **retrieval-augmented generation**
    (**RAG**) applications, an effective semantic data model serves as the foundation
    for a robust retrieval system, which directly informs the quality of the generated
    outputs. The rest of the chapter examines different ways in which you can refine
    the semantic data model and retrieval.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 精炼语义数据模型可以提高检索准确性和整体应用性能。在**检索增强生成**（**RAG**）应用中，一个有效的语义数据模型是构建强大检索系统的基石，它直接影响到生成输出的质量。本章的其余部分将探讨你可以如何精炼语义数据模型和检索的不同方法。
- en: 'This chapter will cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Experimenting with different embedding models
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尝试不同的嵌入模型
- en: Fine-tuning embedding models
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微调嵌入模型
- en: Including metadata in the embedded content to maximize semantic relevance
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在嵌入内容中包含元数据以最大化语义相关性
- en: Various techniques to optimize RAG use cases, including query mutation, formatting
    ingested data, and advanced retrieval systems
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优化RAG用例的各种技术，包括查询变异、格式化导入数据以及高级检索系统
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'You will need the following technical requirements to run the code in this
    chapter:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 运行本章中的代码需要以下技术要求：
- en: A programming environment with Python 3.x installed
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装了Python 3.x的编程环境
- en: A programming environment capable of running the open source embedding model
    `gte-base-en-v1.5` locally
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 能够在本地运行开源嵌入模型`gte-base-en-v1.5`的编程环境
- en: An OpenAI API key. To create an API key, refer to the OpenAI documentation at
    [https://platform.openai.com/docs/quickstart/step-2-set-up-your-api-key](https://platform.openai.com/docs/quickstart/step-2-set-up-your-api-key)
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI API密钥。要创建API密钥，请参阅OpenAI文档中的[https://platform.openai.com/docs/quickstart/step-2-set-up-your-api-key](https://platform.openai.com/docs/quickstart/step-2-set-up-your-api-key)
- en: Embeddings
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 嵌入
- en: '**Vector embeddings** are the foundation of the semantic data model, serving
    as the machine-interpretable representation of ideas and relationships. Embeddings
    are mathematical representations of objects as points in a multi-dimensional space.
    They act as the glue that connects the various semantic pieces of data in an intelligent
    application. The distance between vectors correlates to semantic similarity. You
    can use this semantic similarity score to retrieve related information that would
    otherwise be difficult to connect. This concept holds true regardless of the specific
    use case, be it RAG, recommendation systems, anomaly detection, or others.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**向量嵌入**是语义数据模型的基础，作为想法和关系的机器可解释表示。嵌入是多维空间中对象的数学表示，作为连接智能应用中各种语义数据片段的粘合剂。向量之间的距离与语义相似性相关。你可以使用这个语义相似性分数来检索其他难以连接的相关信息。这个概念无论在特定用例中是否成立，无论是RAG、推荐系统、异常检测还是其他，都是正确的。'
- en: Having an embedding model better tailored to a use case can improve accuracy
    and performance. Experimenting with different embedding models and fine-tuning
    them on domain-specific data can help identify the best fit for a particular use
    case, further enhancing their effectiveness.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有一个更适合特定用例的嵌入模型可以提高准确性和性能。通过尝试不同的嵌入模型并在特定领域的数据上进行微调，可以帮助确定特定用例的最佳匹配，从而进一步增强其有效性。
- en: Experimenting with different embedding models
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 尝试不同的嵌入模型
- en: When building intelligent applications, you can experiment with different pre-trained
    embedding models. Different models have varying accuracy, cost, and efficiency.
    Their performance can vary significantly depending on the specific application
    and data. By experimenting with multiple models, developers can identify the best
    fit for their use case.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建智能应用时，你可以尝试不同的预训练嵌入模型。不同的模型在准确性、成本和效率方面有所不同。它们的性能会根据具体的应用和数据而显著变化。通过尝试多个模型，开发者可以确定最适合其用例的模型。
- en: '*Table 10.1* lists some popular embedding models as of writing in spring 2024
    that are taken from the Hugging Face **Massive Test Embedding Benchmark** (**MTEB**)
    Leaderboard:[1](B22495_10.xhtml#footnote-002)'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '*表10.1*列出了截至2024年春季的一些流行嵌入模型，这些模型来自Hugging Face的**大规模测试嵌入基准**（**MTEB**）排行榜[1](B22495_10.xhtml#footnote-002)'
- en: '[1](B22495_10.xhtml#footnote-002-backlink) The information from the MTEB Leaderboard
    was taken on April 30, 2024\. ([https://huggingface.co/spaces/mteb/leaderboard](https://huggingface.co/spaces/mteb/leaderboard))'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '[1](B22495_10.xhtml#footnote-002-backlink) MTEB排行榜上的信息是在2024年4月30日采集的。（[https://huggingface.co/spaces/mteb/leaderboard](https://huggingface.co/spaces/mteb/leaderboard)）'
- en: '| **Model name** | **Developer** | **Is it open** **source?** | **Embedding**
    **length** | **Average** **score**[2](B22495_10.xhtml#footnote-001)[2](B22495_10.xhtml#footnote-001-backlink)
    This score is calculated as an average of a variety of benchmarks. For more information
    about the evaluation metrics used in the benchmark, refer to the *MTEB: Massive
    Text Embedding Benchmark* research paper ([https://arxiv.org/abs/2210.07316](https://arxiv.org/abs/2210.07316)).
    |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| **模型名称** | **开发者** | **是否开源** | **嵌入长度** | **平均分数**[2](B22495_10.xhtml#footnote-001)[2](B22495_10.xhtml#footnote-001-backlink)
    此分数是各种基准的平均值。有关基准中使用的评估指标的更多信息，请参阅*MTEB：大规模文本嵌入基准*研究论文（[https://arxiv.org/abs/2210.07316](https://arxiv.org/abs/2210.07316)）。'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| `text-embedding-3-large` | OpenAI | No | 3072 | 64.59 |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| `text-embedding-3-large` | OpenAI | 否 | 3072 | 64.59 |'
- en: '| `cohere-embed-english-v3.0` | Cohere | No | 1024 | 64.47 |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| `cohere-embed-english-v3.0` | Cohere | 否 | 1024 | 64.47 |'
- en: '| `gte-base-en-v1.5` | Alibaba | Yes | 768 | 64.11 |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| `gte-base-en-v1.5` | 阿里巴巴 | 是 | 768 | 64.11 |'
- en: '| `sentence-t5-large` | Sentence Transformers | Yes | 768 | 57.06 |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| `sentence-t5-large` | Sentence Transformers | 是 | 768 | 57.06 |'
- en: 'Table 10.1: Selected embedding models'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 表10.1：选定的嵌入模型
- en: To properly compare different embedding models, you must have a consistent evaluation
    framework. This involves defining a set of relevant evaluation datasets and metrics.
    Use the same evaluation sets and metrics across all models for fair comparison.
    The evaluation datasets should be representative of the relevant application domain.
    An evaluation framework will help you iterate and refine the evaluation process
    over time, incorporating learnings from initial experiments to progressively improve
    the application.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 要正确比较不同的嵌入模型，你必须有一个一致的评估框架。这包括定义一组相关的评估数据集和指标。为了公平比较，所有模型应使用相同的评估集和指标。评估数据集应代表相关应用领域。评估框架将帮助你在时间上迭代和改进评估过程，结合初始实验的学习，逐步提高应用。
- en: 'The following are useful evaluation metrics for using embedding models for
    information retrieval. The metrics are taken from **Ragas**, a framework for RAG
    evaluation:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些用于使用嵌入模型进行信息检索的有用评估指标。这些指标来自Ragas，一个用于RAG评估的框架：
- en: '**Context precision**: Evaluates whether the retrieved results contain ground-truth
    facts that you would want to answer the input query. Relevant items present in
    the contexts are ranked highly in the retrieved results.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**上下文精确度**：评估检索到的结果是否包含您希望回答输入查询的地面事实。上下文中存在的相关项目在检索结果中排名较高。'
- en: '**Context entities recall**: Evaluates what fraction of the entities from a
    set of ground truths are preset in the retrieved information.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**上下文实体召回**：评估一组地面真相中的实体在检索信息中预设的比例。'
- en: Ragas supports other RAG evaluation metrics as well, which you can learn more
    about in the Ragas documentation (https://docs.ragas.io/en/stable/).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: Ragas还支持其他RAG评估指标，你可以在Ragas文档（https://docs.ragas.io/en/stable/）中了解更多信息。
- en: The following code example uses Ragas and LangChain to evaluate how different
    embedding models perform on the context entities recall metric.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码示例使用Ragas和LangChain评估不同嵌入模型在上下文实体召回指标上的表现。
- en: 'First, install the required dependencies in the terminal:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，在终端中安装所需的依赖项：
- en: '[PRE0]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The following code evaluates how the OpenAI `text-embedding-ada-002` and `text-embedding-3-large`
    embedding models perform on the Ragas context entities recall evaluation for a
    sample dataset:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码评估了OpenAI的`text-embedding-ada-002`和`text-embedding-3-large`嵌入模型在样本数据集上的Ragas上下文实体召回评估表现：
- en: '[PRE1]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'This code outputs results resembling the following to the terminal:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码将以下结果输出到终端：
- en: '[PRE2]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: As you can see from these results, `text-embedding-3-large` yields higher context
    entity recall on this evaluation. The context relevancy score is normalized between
    `0` and `1`, inclusive.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 如您从这些结果中可以看到，`text-embedding-3-large` 在这次评估中产生了更高的上下文实体召回率。上下文相关性分数在 `0` 和 `1`
    之间归一化。
- en: When creating evaluations for your own application, consider using sample data
    that’s relevant to your use case for a better comparison. Also, you will likely
    want to include a representative sample of at least 100 examples.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 当为您的应用程序创建评估时，请考虑使用与您的用例相关的样本数据以获得更好的比较。此外，您可能还想包括至少 100 个示例的代表样本。
- en: Fine-tuning embedding models
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 微调嵌入模型
- en: In addition to experimenting with different pre-trained models, you can fine-tune
    a pre-trained embedding model to optimize it for your use case.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 除了尝试不同的预训练模型外，您还可以微调预训练的嵌入模型以优化它以适应您的用例。
- en: 'Fine-tuning an embedding model can be beneficial in the following scenarios:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下场景中微调嵌入模型可能有益：
- en: '**Domain-specific data**: If the application deals with domain-specific data
    that might not be well captured using an off-the-shelf model, such as legal documents
    or medical records with specialized terminology, fine-tuning can help the model
    better understand and represent the domain-specific concepts.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特定领域的数据**：如果应用程序处理可能无法使用现成模型很好地捕捉的特定领域数据，例如带有专业术语的法律文件或医疗记录，微调可以帮助模型更好地理解和表示特定领域概念。'
- en: '**Avoiding undesirable matches**: In cases where there are seemingly similar
    concepts that should be differentiated, fine-tuning can help the model distinguish
    between them. For example, you could fine-tune the model to differentiate between
    *Apple the company* and *apple* *the fruit*.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**避免不希望的匹配**：在存在看似相似但应区分的概念的情况下，微调可以帮助模型区分它们。例如，您可以微调模型以区分 *苹果公司* 和 *苹果* *水果*。'
- en: However, off-the-shelf embedding models are often highly performant for many
    tasks, especially when combined with the metadata enrichment and RAG optimizations
    discussed later in this chapter.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，现成的嵌入模型对于许多任务来说通常表现得很出色，尤其是在结合本章后面讨论的元数据丰富化和 RAG 优化之后。
- en: The available options for fine-tuning an embedding model can vary depending
    on the model and how it is hosted. Managed model hosting providers might only
    expose certain methods for their models, whereas using an open source model can
    provide more flexibility. The **SentenceTransformers** ([https://sbert.net/](https://sbert.net/))
    framework is designed for using and fine-tuning open-source embedding models.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 微调嵌入模型的可选方法可能因模型及其托管方式而异。托管模型提供商可能只公开其模型的一些方法，而使用开源模型可以提供更多灵活性。**SentenceTransformers**
    ([https://sbert.net/](https://sbert.net/)) 框架旨在用于使用和微调开源嵌入模型。
- en: 'Generally, fine-tuning involves providing similar pairs of sentences, optionally
    including a magnitude of similarity. Alternatively, anchor, positive, and negative
    examples can be provided to guide the fine-tuning process. *Table 10.2* provides
    an overview of anchor, positive, and negative examples, that are used in the subsequent
    code example:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，微调涉及提供相似的句子对，可选地包括相似度的大小。或者，可以提供锚点、正面和负面示例来指导微调过程。*表 10.2* 提供了锚点、正面和负面示例的概述，这些示例在随后的代码示例中使用：
- en: '| **Type** | **Definition** | **Example** |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| **类型** | **定义** | **示例** |'
- en: '| --- | --- | --- |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Anchor | The reference text that serves as the starting point for identifying
    similar and dissimilar examples. |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| 锚点 | 作为识别相似和不同示例起点的参考文本。 |'
- en: '[PRE3]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '|'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Positive | Text that should be represented as similar to the anchor example.
    |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| 正面 | 应该类似于锚示例表示的文本。 |'
- en: '[PRE4]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '|'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Negative | Text that should be represented as dissimilar or different from
    the anchor example. |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| 负面 | 应该表示为与锚示例不同或不相似的文本。 |'
- en: '[PRE5]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '|'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: 'Table 10.2: Methods for fine-tuning embedding models'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 表 10.2：微调嵌入模型的方法
- en: Here’s a brief code example of using the `SentenceTransformers` and `PyTorch`
    libraries to fine-tune the open source embedding model `gte-base-en-v1.5`.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个使用 `SentenceTransformers` 和 `PyTorch` 库微调开源嵌入模型 `gte-base-en-v1.5` 的简短代码示例。
- en: 'First, install the dependencies in the terminal:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，在终端中安装依赖项：
- en: '[PRE6]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Then run the following code:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 然后运行以下代码：
- en: '[PRE7]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'This code outputs a result resembling the following to the terminal:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码将输出类似以下结果到终端：
- en: '[PRE8]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: As you can see from this example, just the small fine-tuning that was performed,
    increased the vector similarity between the related sentences.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如此例所示，仅仅进行的小幅微调就增加了相关句子之间的向量相似度。
- en: If you would like to learn more about fine-tuning embedding models, a great
    place to start is the *Train and Fine-Tune Sentence Transformers Models Hugging
    Face* blog post by Omar Espejel ([https://huggingface.co/blog/how-to-train-sentence-transformers](https://huggingface.co/blog/how-to-train-sentence-transformers)).
    This blog post includes a more detailed look at fine-tuning an embedding model
    using a similar approach to the one in the preceding code example.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想了解更多关于微调嵌入模型的信息，Omar Espejel在Hugging Face的*Train and Fine-Tune Sentence
    Transformers Models*博客文章（[https://huggingface.co/blog/how-to-train-sentence-transformers](https://huggingface.co/blog/how-to-train-sentence-transformers)）是一个很好的起点。这篇文章更详细地探讨了使用与前面代码示例类似的方法来微调嵌入模型。
- en: The following section discusses how you can further enhance the semantic data
    model after you have chosen the right data model by embedding relevant metadata
    in the text.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 以下部分讨论了在选择合适的数据模型后，如何通过在文本中嵌入相关元数据来进一步增强语义数据模型。
- en: Embedding metadata
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 嵌入元数据
- en: 'Including **metadata** in embedded content can significantly improve the quality
    of retrieval results by adding greater semantic meaning to it. Metadata creates
    a richer and more meaningful semantic representation of content. Metadata can
    include descriptors such as the type of content, tags, titles, and summaries.
    The following table contains some useful examples of metadata to include in embedded
    content:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在嵌入内容中包含**元数据**可以显著提高检索结果的质量，因为它为内容添加了更多的语义意义。元数据为内容创建了一个更丰富、更有意义的语义表示。元数据可以包括诸如内容类型、标签、标题和摘要等描述符。以下表格包含了一些在嵌入内容中包含的有用元数据示例：
- en: '| **Type** | **Example(s)** |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| **类型** | **示例** |'
- en: '| --- | --- |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Content type | Article, recipe, product review, etc. |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| 内容类型 | 文章、食谱、产品评论等 |'
- en: '| Tags | “dinner”, “Italian”, “vegetarian” |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| 标签 | “晚餐”，“意大利菜”，“素食” |'
- en: '| Title of document | Roasted Garlic and Tomato Pasta |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| 文档标题 | 烤大蒜番茄意面 |'
- en: '| Summary of document | A simple pasta dish featuring roasted garlic and cherry
    tomatoes in a light sauce |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| 文档摘要 | 一道简单的意面，以烤大蒜和樱桃番茄搭配轻柔的酱汁 |'
- en: 'Table 10.3: Useful types of embedded metadata'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 表10.3：嵌入元数据的实用类型
- en: You can also include metadata types that are specific to your application. For
    example, consider creating a RAG chatbot where users ask natural language questions
    and get generated answers on cooking and recipes.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以包含特定于您应用程序的元数据类型。例如，考虑创建一个RAG聊天机器人，用户可以提出自然语言问题，并获得关于烹饪和食谱的生成答案。
- en: 'You have the following recipe for *Roast Garlic and Tomato Pasta* to include
    in your recipe database:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 您有以下*烤大蒜番茄意面*的食谱可以包含在您的食谱数据库中：
- en: '[PRE9]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'When creating a vector embedding for the recipe, you could include the following
    metadata before the recipe text:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在为食谱创建向量嵌入时，您可以在食谱文本之前包含以下元数据：
- en: '[PRE10]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: By including this metadata with the embedded text, you imbue the text with greater
    semantic meaning making it more likely that user queries will capture the correct
    content. This makes relevant user queries have greater cosine similarity scores
    with the text.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将此元数据与嵌入文本一起包含，您为文本赋予了更多的语义意义，使其更有可能被用户查询捕获正确的内。这使得相关用户查询与文本的余弦相似度分数更高。
- en: 'The following table shows the cosine similarity scores between various queries
    and the text with and without metadata using the `BAAI/bge-large-en-v1.5` embedding
    model:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 以下表格显示了使用`BAAI/bge-large-en-v1.5`嵌入模型在各种查询与带有和不带有元数据的文本之间的余弦相似度分数：
- en: '| **Query text** | **Text without metadata** **similarity score** | **Text
    with metadata** **similarity score** | **Metadata similarity** **score improvement**
    |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| **查询文本** | **无元数据的文本** **相似度分数** | **有元数据的文本** **相似度分数** | **元数据相似度** **分数提升**
    |'
- en: '| --- | --- | --- | --- |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '|'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '[PRE11]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '| `0.7141546` | `0.7306514` | `0.016496778` |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| `0.7141546` | `0.7306514` | `0.016496778` |'
- en: '|'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '[PRE12]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '| `0.71199816` | `0.76754296` | `0.055544794` |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| `0.71199816` | `0.76754296` | `0.055544794` |'
- en: '|'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '[PRE13]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '| `0.60327804` | `0.6559261` | `0.052648067` |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| `0.60327804` | `0.6559261` | `0.052648067` |'
- en: 'Table 10.4: Comparing cosine similarity of vectors of text with and without
    embedded metadata'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 表10.4：比较带有和不带有嵌入元数据的文本向量余弦相似度
- en: As you can see in *Table 10.4*, the text with prepended metadata has a higher
    cosine similarity for a diverse set of relevant queries. This means that the relevant
    content is more likely to be surfaced and used in the RAG chatbot.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 如 *表 10.4* 所示，带有前置元数据的文本对于一系列相关查询具有更高的余弦相似度。这意味着相关内容更有可能被展示并用于 RAG 聊天机器人。
- en: Formatting metadata
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 格式化元数据
- en: When including metadata, you must consider how it is structured to optimize
    processing and interpretation. You should use a machine-readable format that is
    easy to parse and manipulate, such as YAML ([https://yaml.org/spec/1.2.2/](https://yaml.org/spec/1.2.2/)),
    JSON ([https://www.json.org/json-en.html](https://www.json.org/json-en.html)),
    or TOML ([https://toml.io/](https://toml.io/)).
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在包含元数据时，必须考虑其结构以优化处理和解释。应使用易于解析和操作的可读格式，例如 YAML ([https://yaml.org/spec/1.2.2/](https://yaml.org/spec/1.2.2/))、JSON
    ([https://www.json.org/json-en.html](https://www.json.org/json-en.html)) 或 TOML
    ([https://toml.io/](https://toml.io/))。
- en: '**YAML** is generally more token-efficient compared to other data formats such
    as **JSON**. This means that using YAML saves on the compute cost of processing
    extra tokens and also represents the same idea with fewer *distraction* tokens
    that could dilute the LLM’s ability to interpret the input and produce a high-quality
    output. YAML also has widespread adoption, so embedding models and LLMs can effectively
    work with it.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '**YAML** 通常比其他数据格式（如 **JSON**）更高效。这意味着使用 YAML 可以节省处理额外标记的计算成本，并且用更少的 *分散* 标记来表示相同的概念，这些标记可能会稀释大型语言模型（LLM）解释输入并产生高质量输出的能力。YAML
    还得到了广泛的应用，因此嵌入模型和 LLM 可以有效地与之协同工作。'
- en: 'The following table demonstrates the comparative token density for the same
    data represented in YAML and JSON using the GPT-4 tokenizer ([https://platform.openai.com/tokenizer](https://platform.openai.com/tokenizer)):'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 以下表格展示了使用 GPT-4 分词器（[https://platform.openai.com/tokenizer](https://platform.openai.com/tokenizer)）对以
    YAML 和 JSON 格式表示的相同数据进行比较的标记密度：
- en: '| **Format** | **Content** | **Token** **count** |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| **格式** | **内容** | **标记** **计数** |'
- en: '| YAML |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| YAML |'
- en: '[PRE14]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[PRE19]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '| 60 |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| 60 |'
- en: '| JSON |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| JSON |'
- en: '[PRE20]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[PRE21]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[PRE22]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[PRE23]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '[PRE24]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[PRE25]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '[PRE28]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '[PRE29]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '[PRE30]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '[PRE31]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '| 89 |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| 89 |'
- en: 'Table 10.5: Comparing token length of the same content in YAML and JSON'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 表 10.5：比较 YAML 和 JSON 中相同内容的标记长度
- en: As you can see in *Table 10.5*, YAML uses approximately two-thirds of tokens
    compared to JSON. The exact difference in token usage depends on the data and
    formatting. YAML generally proves to be a more efficient metadata format than
    JSON.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 如 *表 10.5* 所示，YAML 相比 JSON 使用了大约三分之二的标记。标记使用的确切差异取决于数据和格式。YAML 通常证明比 JSON 是一个更高效的元数据格式。
- en: If including metadata alongside additional text, consider including it as *front
    matter* ([https://jekyllrb.com/docs/front-matter/](https://jekyllrb.com/docs/front-matter/)).
    `---` before and after the metadata.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在附加文本中包含元数据，请考虑将其作为 *前文* ([https://jekyllrb.com/docs/front-matter/](https://jekyllrb.com/docs/front-matter/))
    包含。在元数据前后使用 `---`。
- en: 'Here is an example of front matter preceding Markdown ([https://commonmark.org/help/](https://commonmark.org/help/))
    text:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个前文在 Markdown ([https://commonmark.org/help/](https://commonmark.org/help/))
    文本之前的例子：
- en: '[PRE32]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The front matter specification originates from the Jekyll static site builder
    ([https://jekyllrb.com/docs/](https://jekyllrb.com/docs/)). It has since become
    widely adopted across various domains. Given its popularity, language models and
    embedding models should be able to understand its semantic context as metadata
    for the rest of the text. Additionally, libraries are available to easily manipulate
    front matter in relation to the main text content, such as the `python-frontmatter`
    in Python.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 前文规范起源于 Jekyll 静态网站构建器 ([https://jekyllrb.com/docs/](https://jekyllrb.com/docs/))。它已经广泛应用于各个领域。鉴于其流行度，语言模型和嵌入模型应该能够理解其语义上下文作为文本其余部分的元数据。此外，还有库可以轻松地操作与主文本内容相关的前文，例如
    Python 中的 `python-frontmatter`。
- en: The following code example shows how to add front matter to Markdown and print
    out the results.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码示例展示了如何向 Markdown 添加前文并打印结果。
- en: 'First, install the `python-frontmatter` package in the terminal:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，在终端中安装 `python-frontmatter` 包：
- en: '[PRE33]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Add front matter to text using the `python-frontmatter` library:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `python-frontmatter` 库向文本添加前文：
- en: '[PRE34]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'This outputs the following text with front matter to the terminal:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 这将在终端输出以下带有前文的文本：
- en: '[PRE35]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: The preceding example demonstrates the usefulness of adding front matter as
    a metadata format in your semantic retrieval.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的例子展示了在语义检索中添加元数据格式（如前文）的有用性。
- en: Including static metadata
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 包含静态元数据
- en: For certain types of content or sources, it can be beneficial to include static
    metadata that is the same across all documents. This is a computationally cheap
    and an easy way to consistently include metadata across documents.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 对于某些类型的内容或来源，包含所有文档都相同的静态元数据可能是有益的。这是一种计算成本低廉且易于在文档中一致性地包含元数据的方法。
- en: 'For a cookbook chatbot, you could include the cookbook source in the metadata.
    For example:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一个食谱聊天机器人，您可以在元数据中包含食谱来源。例如：
- en: '[PRE36]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: This ensures that every document of a particular type or from a specific source
    contains a consistent base level of metadata. You can then layer on additional
    dynamic metadata that is unique to each specific document, as discussed in the
    following sections. Including static metadata is a low-effort way to provide additional
    semantic context to your documents, aiding in retrieval and interpretation.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 这确保了特定类型或特定来源的每一份文档都包含一致的基线元数据。然后，您可以像以下章节中讨论的那样，添加额外的动态元数据，这些元数据对每个特定文档是唯一的。包括静态元数据是提供额外语义上下文的一种低效方式，有助于检索和解释。
- en: Extracting metadata programmatically
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 以编程方式提取元数据
- en: You can extract metadata from content using traditional software development
    techniques that do not rely on AI models.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用不依赖于AI模型的传统的软件开发技术从内容中提取元数据。
- en: One approach is to extract headers in a document, which can be done with **regular
    expressions** (**regex**) to match header patterns or by parsing the document’s
    **abstract syntax tree** (**AST**) to identify header elements. Extracting and
    including headings as metadata can be useful because headings frequently summarize
    or provide high-level information about the content in that section, thus aiding
    in understanding the semantic context and improving retrieval relevance.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 一种方法是从文档中提取标题，这可以通过使用**正则表达式**（**regex**）匹配标题模式或通过解析文档的**抽象语法树**（**AST**）来识别标题元素来完成。提取并包含标题作为元数据可能是有用的，因为标题通常总结或提供关于该部分内容的概述信息，从而有助于理解语义上下文并提高检索相关性。
- en: 'Extracting the headers from a Markdown document could create a document with
    metadata resembling the following:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 从Markdown文档中提取标题可以创建一个包含类似以下元数据的文档：
- en: '[PRE37]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Generating metadata with LLMs
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用LLM生成元数据
- en: 'You can use LLMs to generate metadata for your content. Some potential use
    cases for using LLMs to generate metadata include:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用LLM为您的内容生成元数据。使用LLM生成元数据的潜在用例包括：
- en: Summarizing the text
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 概括文本
- en: Extracting key phrases or terms from the text
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从文本中提取关键短语或术语
- en: Classifying the text into categories
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将文本分类到类别中
- en: Identifying the sentiment of the text
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别文本的情感
- en: Recognizing named entities
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别命名实体
- en: When selecting an LLM for metadata generation, you may be able to use smaller
    (and therefore faster and cheaper) language models compared to those used for
    other components of your intelligent application.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在选择LLM用于元数据生成时，您可能可以使用比用于您智能应用程序其他组件的语言模型更小（因此更快、更便宜）的语言模型。
- en: You can also use traditional **natural language processing** (**NLP**) techniques
    to provide additional metadata. For example, **calculating n-grams** can surface
    the most frequently occurring terms or phrases in the text. Other NLP approaches
    such as **part-of-speech tagging** and **keyword tagging** can also provide useful
    metadata. These approaches typically use small AI models.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以使用传统的**自然语言处理**（**NLP**）技术来提供额外的元数据。例如，**计算n-gram**可以揭示文本中最频繁出现的术语或短语。其他NLP方法，如**词性标注**和**关键词标注**也可以提供有用的元数据。这些方法通常使用小型AI模型。
- en: You can use the Python NLP libraries, such as `NLTK` or `spaCy`, to extract
    metadata. While using these libraries is generally more compute efficient than
    using an LLM, they generally require fine-tuning, so it’s not worthwhile to use
    them unless your application is running at a scale where the compute requirements
    of an LLM are cost or resource prohibitive.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用Python NLP库，如`NLTK`或`spaCy`来提取元数据。虽然使用这些库通常比使用LLM更高效，但它们通常需要微调，因此除非您的应用程序运行在LLM的计算需求成本或资源受限的规模上，否则不值得使用它们。
- en: The following code uses the OpenAI GPT-4o mini LLM to extract the metadata.
    It also uses Pydantic to format the response as JSON.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码使用OpenAI GPT-4o mini LLM提取元数据。它还使用Pydantic将响应格式化为JSON。
- en: 'First, install the dependencies in the terminal:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，在终端中安装依赖项：
- en: '[PRE38]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Then, execute the code:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，执行以下代码：
- en: '[PRE39]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'This code produces an output resembling the following to the terminal:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码在终端产生以下类似输出：
- en: '[PRE40]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: As you saw here, LLMs allow you to perform many forms of NLP tasks with prompt
    engineering and minimal technical overhead.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您在这里看到的，LLMs允许您通过提示工程和最小的技术开销执行许多形式的NLP任务。
- en: Including metadata with query embedding and ingested content embeddings
  id: totrans-170
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在查询嵌入和摄入内容嵌入中包含元数据
- en: In addition to including metadata with the content that you ingest into a vector
    store, you can also include metadata along with the content that you use in your
    search query. By structuring the metadata similarly on both the query and the
    retrieved content, you increase the likelihood of a relevant match using vector
    similarity search.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 除了在将内容摄入向量存储时包含元数据之外，您还可以在搜索查询中使用的内容中包含元数据。通过在查询和检索内容上以类似的方式结构化元数据，您增加了使用向量相似性搜索获得相关匹配的可能性。
- en: You can extract metadata for the query using the same strategies as those for
    extracting metadata from the data sources as discussed previously in this chapter.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用与本章先前讨论的从数据源提取元数据相同的策略来提取查询的元数据。
- en: 'For example, say you’re querying the cookbook chatbot mentioned previously.
    Given the user query `apple pie recipe`, you might want to use the following query
    for vector search:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设您正在查询之前提到的食谱聊天机器人。给定用户查询`apple pie recipe`，您可能希望使用以下查询进行向量搜索：
- en: '[PRE41]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'A query such as the above will make it more likely to match a recipe with similarly
    structured embedded metadata like the following:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 如上所述的查询将使匹配具有类似结构嵌入元数据的食谱的可能性更高，如下所示：
- en: '[PRE42]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Including structured metadata in the query can act as a kind of *semantic filter*
    to get more accurate search results. The following section examines other techniques
    for improving the accuracy of the data model in RAG applications.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在查询中包含结构化元数据可以作为一种*语义过滤器*，以获得更精确的搜索结果。下一节将探讨其他提高RAG应用中数据模型准确性的技术。
- en: Optimizing retrieval-augmented generation
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优化检索增强生成
- en: Beyond optimizing the semantic data model itself through vector embedding model
    choice and metadata enrichment, there are ways to further refine and improve RAG
    applications. This section covers strategies for optimizing different components
    and stages of the RAG pipeline.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 除了通过向量嵌入模型选择和元数据丰富来优化语义数据模型本身之外，还有方法可以进一步精炼和改进RAG应用。本节涵盖了优化RAG管道不同组件和阶段的策略。
- en: Key areas of optimization include query handling, formatting of ingested data,
    retrieval system configuration, and application-level guardrails. Effectively
    optimizing these aspects can lead to significant boosts in the accuracy, relevance,
    and overall performance of RAG applications.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 优化关键领域包括查询处理、摄入数据的格式化、检索系统配置和应用级别的防护措施。有效地优化这些方面可以提高RAG应用的准确性、相关性和整体性能。
- en: Note
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: This section covers more advanced techniques than the ones discussed in [*Chapter
    8*](B22495_08.xhtml#_idTextAnchor180), *Implementing Vector Search in* *AI Applications.*
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 本节涵盖了比第[*第8章*](B22495_08.xhtml#_idTextAnchor180)中讨论的*在AI应用中实现向量搜索*更高级的技术。
- en: Query mutation
  id: totrans-183
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 查询突变
- en: In the naive RAG approach, you use direct user input to create the embedding
    used in vector search, perhaps augmented with metadata as discussed earlier in
    the chapter. However, you can drive better search performance by mutating the
    user input using an LLM.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在原始的RAG方法中，您使用直接的用户输入来创建用于向量搜索的嵌入，可能还辅以本章前面讨论的元数据。然而，您可以通过使用LLM突变用户输入来提高搜索性能。
- en: 'Several popular techniques for query mutation include:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 查询突变的一些流行技术包括：
- en: '`My daughter is allergic to nuts. My son is allergic to dairy. What is a vegetarian
    dinner I can make for them?` the LLM-generated step-back search query could be
    *Vegetarian dinner recipe without dairy* *or nuts*.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`My daughter is allergic to nuts. My son is allergic to dairy. What is a vegetarian
    dinner I can make for them?` 由LLM生成的回溯搜索查询可能是*Vegetarian dinner recipe without
    dairy* *or nuts*。'
- en: '`sirloin steak recipe`, the LLM-generated HyDE search query could be *Preheat
    your grill or grill pan to high heat. Pat the sirloin steaks dry and season generously
    with salt and pepper. Drizzle with olive oil and use your hands to coat the steaks
    evenly. Place the steaks on the hot grill and cook for 4-5 minutes per side for
    medium-rare, flipping only once. Use an instant-read thermometer to check for
    doneness (135°F for medium-rare). Transfer the steaks to a cutting board and let
    rest for 5 minutes before slicing against the grain. Serve the juicy sirloin steaks
    with your favorite sides like roasted potatoes, grilled vegetables, or a* *fresh
    salad.*'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`西冷牛排食谱`，LLM生成的HyDE搜索查询可能是*预热您的烤架或烤盘至高温。用纸巾擦干西冷牛排，并慷慨地撒上盐和胡椒。淋上橄榄油，用双手均匀涂抹牛排。将牛排放在热烤架上，每面烤4-5分钟至五成熟，只翻一次面。使用即时读数温度计检查熟度（五成熟为135°F）。将牛排转移到切菜板上，静置5分钟后再顺着纹理切片。搭配您最喜欢的配菜，如烤土豆、烤蔬菜或*新鲜沙拉*享用多汁的西冷牛排。'
- en: '`vegan dinner party menu`, the LLM-generated multiple search queries could
    be *Vegan appetizer*, *Vegan dinner main course*, and *Vegan desert*.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`纯素食晚餐派对菜单`，LLM生成的多个搜索查询可能是*纯素食开胃菜*、*纯素食晚餐主菜*和*纯素食甜点*。'
- en: All of these techniques can be optimized for your application’s domain. You
    can even combine them or have an LLM select what is the most appropriate technique
    for a given user query.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些技术都可以针对您的应用程序领域进行优化。您甚至可以将它们结合起来，或者让LLM选择对特定用户查询最合适的技巧。
- en: However, introducing another point of AI in the application also presents challenges.
    The query mutation may not always work as expected, potentially degrading performance
    in some cases. Additionally, it introduces another component to evaluate and incurs
    the cost of additional AI usage. Any LLM-query mutations should be thoroughly
    evaluated to mitigate unexpected outcomes.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在应用程序中引入另一个AI点也带来了挑战。查询突变可能并不总是按预期工作，在某些情况下可能会降低性能。此外，它还引入了另一个需要评估的组件，并产生了额外AI使用的成本。任何LLM查询突变都应该彻底评估，以减轻意外结果。
- en: Extracting query metadata for pre-filtering
  id: totrans-191
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提取查询元数据以进行预过滤
- en: In addition to performing semantic filtering as discussed in the *Embedding
    metadata* section, you can also programmatically filter on metadata before performing
    vector search. This lets you reduce the number of embeddings that you are searching
    over to only examine the subset of total embeddings relevant to a given query.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 除了在*嵌入元数据*部分讨论的执行语义过滤之外，您还可以在执行向量搜索之前对元数据进行编程过滤。这可以让您减少搜索的嵌入数量，仅检查与给定查询相关的总嵌入子集。
- en: It is important to select a vector database that contains metadata filtering
    capabilities suitable to your application needs. Metadata filtering capabilities
    vary greatly by vector database. For example, MongoDB Atlas Vector Search supports
    a variety of pre-filter options in the `$vectorSearch` aggregation pipeline stage.
    ([https://www.mongodb.com/docs/atlas/atlas-vector-search/vector-search-stage/#atlas-vector-search-pre-filter](https://www.mongodb.com/docs/atlas/atlas-vector-search/vector-search-stage/#atlas-vector-search-pre-filter)).
    In [*Chapter 8*](B22495_08.xhtml#_idTextAnchor180), *Implementing Vector Search
    in AI Applications*, you learned how to set up these pre-filter options with Atlas
    Vector Search Index.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 选择一个包含适合您应用程序需求的元数据过滤功能的向量数据库非常重要。元数据过滤功能在向量数据库之间差异很大。例如，MongoDB Atlas Vector
    Search在`$vectorSearch`聚合管道阶段支持多种预过滤选项。（[https://www.mongodb.com/docs/atlas/atlas-vector-search/vector-search-stage/#atlas-vector-search-pre-filter](https://www.mongodb.com/docs/atlas/atlas-vector-search/vector-search-stage/#atlas-vector-search-pre-filter)）。在[*第8章*](B22495_08.xhtml#_idTextAnchor180)，*在AI应用中实现向量搜索*，你学习了如何使用Atlas
    Vector Search Index设置这些预过滤选项。
- en: You can use an LLM to extract metadata from a query to use as a filter, like
    how you extract metadata from ingested content, as discussed in the *Embedding
    metadata* section. Alternatively, you could use heuristics to determine filter
    criteria.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用LLM从查询中提取元数据作为过滤器，就像您在*嵌入元数据*部分讨论的那样从摄取的内容中提取元数据一样。或者，您可以使用启发式方法来确定过滤标准。
- en: For instance, say you are building a cooking chatbot that performs RAG over
    a vector database of recipes and general cooking information such as the popular
    spices in certain cuisines. You could add a metadata filter that only looks at
    the recipe items in the vector database if a user query contains the word `recipe`.
    You can also create so-called *smart* filters that use AI models such as LLMs
    to determine which subsets of the data to include.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设您正在构建一个烹饪聊天机器人，该机器人对食谱和一般烹饪信息（如某些菜系中流行的香料）的向量数据库执行RAG。如果您用户的查询包含单词“recipe”，则可以添加一个仅查看向量数据库中食谱项的元数据过滤器。您还可以创建所谓的*智能*过滤器，这些过滤器使用AI模型（如LLM）来确定要包含的数据子集。
- en: Here is a code example of an LLM function that determines what, if any, filter
    to apply to a search query. It also uses Pydantic to format the response as JSON.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个LLM函数的代码示例，该函数确定对搜索查询应用哪些过滤器（如果有的话）。它还使用Pydantic将响应格式化为JSON。
- en: The following Python code extracts the topic from a query using the OpenAI LLM
    GPT-4o mini. It also uses Pydantic to format the response as JSON. You can then
    use the extracted topic as a pre-filter, as described in [*Chapter 8*](B22495_08.xhtml#_idTextAnchor180),
    *Implementing Vector Search in* *AI Applications*.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 以下Python代码使用OpenAI LLM GPT-4o mini从查询中提取主题。它还使用Pydantic将响应格式化为JSON。然后，您可以使用提取的主题作为预过滤器，如[*第8章*](B22495_08.xhtml#_idTextAnchor180)中所述，*在AI应用程序中实现向量搜索*。
- en: 'First, install the required dependencies in your terminal:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，在您的终端中安装所需的依赖项：
- en: '[PRE43]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Then, run the following code:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，运行以下代码：
- en: '[PRE44]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'This outputs the following to your terminal:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 这将在您的终端中输出以下内容：
- en: '[PRE45]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: By combining metadata filtering with vector search, your RAG application can
    search more efficiently and accurately. This approach narrows down the search
    space to the most contextually appropriate data, leading to more precise and useful
    results.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 通过结合元数据过滤和向量搜索，您的RAG应用程序可以更高效、更准确地搜索。这种方法将搜索空间缩小到最符合上下文的数据，从而产生更精确和有用的结果。
- en: Formatting ingested data
  id: totrans-205
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 格式化摄取数据
- en: When ingesting data to create embeddings, you must consider the format that
    the data is in. Standardizing the data format as much as possible can lead to
    more consistent results.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在将数据摄取以创建嵌入时，您必须考虑数据的格式。尽可能标准化数据格式可以导致更一致的结果。
- en: For longer-form text data, such as technical documentation or reports, you should
    format the ingested and embedded data in a consistent format that includes appropriate
    semantic meaning in a token-dense format. Markdown is a good choice because it
    has high information density per token compared to XML-based formats such as HTML
    or PDFs.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 对于较长的文本数据，例如技术文档或报告，您应该以一致的格式格式化摄取和嵌入的数据，该格式在密集的标记格式中包含适当的语义意义。Markdown是一个不错的选择，因为它与基于XML的格式（如HTML或PDF）相比，每个标记的信息密度更高。
- en: 'For instance, see the total GPT-4 tokenizer token count for the following content
    represented in plain text, Markdown, and HTML:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，查看以下内容的总GPT-4标记器标记计数，该内容以纯文本、Markdown和HTML表示：
- en: '| **Format** | **Content** | **Token** **count** |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '| **格式** | **内容** | **标记** **计数** |'
- en: '| Plain Text |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '| 纯文本 |'
- en: '[PRE46]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '[PRE47]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '[PRE48]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: '[PRE49]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: '[PRE50]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: '[PRE51]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: '[PRE52]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: '[PRE53]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: '| 81 |'
  id: totrans-219
  prefs: []
  type: TYPE_TB
  zh: '| 81 |'
- en: '| Markdown |'
  id: totrans-220
  prefs: []
  type: TYPE_TB
  zh: '| Markdown |'
- en: '[PRE54]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: '[PRE55]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: '[PRE56]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '[PRE57]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: '[PRE58]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: '[PRE59]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: '[PRE60]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: '[PRE61]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: '| 83 |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '| 83 |'
- en: '| HTML |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '| HTML |'
- en: '[PRE62]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: '[PRE63]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: '[PRE64]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: '[PRE65]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: '[PRE66]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: '[PRE67]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: '[PRE68]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: '[PRE69]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: '[PRE70]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: '[PRE71]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: '[PRE72]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: '[PRE73]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: '| 138 |'
  id: totrans-243
  prefs: []
  type: TYPE_TB
  zh: '| 138 |'
- en: 'Table 10.6: Token count of different text formats'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 表10.6：不同文本格式的标记计数
- en: How you format ingested data can have a meaningful impact on retrieval quality
    and resource consumption. Generally, plain text or Markdown are effective formats
    for most text-based use cases.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 您格式化摄取数据的方式可以对检索质量和资源消耗产生有意义的影响。通常，纯文本或Markdown对于大多数基于文本的使用案例都是有效的格式。
- en: Advanced retrieval systems
  id: totrans-246
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 高级检索系统
- en: A variety of advanced retrieval systems have emerged that go beyond simply retrieving
    the nearest match to the query.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 已经出现了各种高级检索系统，它们不仅限于检索与查询最接近的匹配项。
- en: All of the following retrieval architectures are experimental as of writing
    in August 2024\. When developing your intelligent application, you should probably
    start with standard vector search retrieval. Optimize standard vector search retrieval
    before using techniques such as filtering and adding semantic metadata before
    you experiment with these advanced retrieval systems.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 截至2024年8月撰写时，以下所有检索架构都是实验性的。在开发您的智能应用程序时，您可能应该从标准的向量搜索检索开始。在尝试这些高级检索系统之前，先优化标准的向量搜索检索，然后再使用过滤和添加语义元数据等技术。
- en: 'Advanced retrieval systems include:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 高级检索系统包括：
- en: '**Summary retrieval**: Extract a summary from each document and store that
    summary in the vector search index. Retrieve the content of the whole document
    when the embedded version of the summary is matched.'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**摘要检索**：从每个文档中提取摘要并将其存储在向量搜索索引中。当匹配到摘要的嵌入版本时，检索整个文档的内容。'
- en: '**Knowledge graph retrieval**: During data ingestion, create a knowledge graph
    of relations between documents in the vector store. These relationships can be
    created using an LLM. During retrieval, perform an initial semantic search.'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**知识图谱检索**：在数据摄取期间，创建向量存储中文档之间关系的知识图谱。这些关系可以使用LLM创建。在检索期间，执行初始语义搜索。'
- en: '**Router retrieval**: Use a classifier to determine where a user query should
    be routed to between different data stores.'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**路由检索**：使用分类器确定用户查询应路由到不同数据存储中的哪个位置。'
- en: LlamaIndex has done an excellent job of staying on top of the latest research
    in advanced retrieval systems. To learn more about the various advanced retrieval
    patterns that LlamaIndex supports, refer to the LlamaIndex Query Engine documentation
    ([https://docs.llamaindex.ai/en/stable/examples/query_engine/knowledge_graph_rag_query_engine/](https://docs.llamaindex.ai/en/stable/examples/query_engine/knowledge_graph_rag_query_engine/)).
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: LlamaIndex在跟踪高级检索系统的最新研究方面做得非常出色。要了解更多关于LlamaIndex支持的各类高级检索模式，请参阅LlamaIndex查询引擎文档（[https://docs.llamaindex.ai/en/stable/examples/query_engine/knowledge_graph_rag_query_engine/](https://docs.llamaindex.ai/en/stable/examples/query_engine/knowledge_graph_rag_query_engine/)）。
- en: Summary
  id: totrans-254
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you explored various techniques for refining your semantic
    data model to improve retrieval accuracy for vector search and RAG. You learned
    how to improve your data model used in information retrieval and RAG. By fine-tuning
    embeddings, you can adjust pre-trained models to improve the accuracy and relevance
    of search results. With embedded metadata, you can improve the vector search quality.
    Finally, RAG optimization ensures that the retrieval process fetches the most
    relevant information.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你探索了各种技术来优化你的语义数据模型，以提高向量搜索和RAG的检索准确性。你学习了如何改进用于信息检索和RAG的数据模型。通过微调嵌入，你可以调整预训练模型以提高搜索结果的准确性和相关性。使用嵌入元数据，你可以提高向量搜索质量。最后，RAG优化确保检索过程获取最相关的信息。
- en: In the next chapter, you will examine ways to address common issues in AI application
    development.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，你将探讨解决AI应用开发中常见问题的方法。
