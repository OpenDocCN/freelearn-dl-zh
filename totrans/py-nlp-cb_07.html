<html><head></head><body>
		<div id="_idContainer038" class="calibre2">
			<h1 id="_idParaDest-173" class="chapter-number"><a id="_idTextAnchor177" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.1.1">7</span></h1>
			<h1 id="_idParaDest-174" class="calibre7"><a id="_idTextAnchor178" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.2.1">Visualizing Text Data</span></h1>
			<p class="calibre3"><span class="kobospan" id="kobo.3.1">This chapter is dedicated to creating visualizations for the different aspects of NLP work, much of which we have done in previous chapters. </span><span class="kobospan" id="kobo.3.2">Visualizations are important when working with NLP tasks, as they help us to easier see the big picture of the </span><span><span class="kobospan" id="kobo.4.1">work accomplished.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.5.1">We will create different types of visualizations, including visualizations of grammar details, parts of speech, and topic models. </span><span class="kobospan" id="kobo.5.2">After working through this chapter, you will be well equipped to create compelling images to show and explain the outputs of various </span><span><span class="kobospan" id="kobo.6.1">NLP tasks.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.7.1">These are the recipes you will find in </span><span><span class="kobospan" id="kobo.8.1">this chapter:</span></span></p>
			<ul class="calibre15">
				<li class="calibre14"><span class="kobospan" id="kobo.9.1">Visualizing the </span><span><span class="kobospan" id="kobo.10.1">dependency parse</span></span></li>
				<li class="calibre14"><span class="kobospan" id="kobo.11.1">Visualizing parts </span><span><span class="kobospan" id="kobo.12.1">of speech</span></span></li>
				<li class="calibre14"><span><span class="kobospan" id="kobo.13.1">Visualizing NER</span></span></li>
				<li class="calibre14"><span class="kobospan" id="kobo.14.1">Creating a confusion </span><span><span class="kobospan" id="kobo.15.1">matrix plot</span></span></li>
				<li class="calibre14"><span class="kobospan" id="kobo.16.1">Constructing </span><span><span class="kobospan" id="kobo.17.1">word clouds</span></span></li>
				<li class="calibre14"><span class="kobospan" id="kobo.18.1">Visualizing topics </span><span><span class="kobospan" id="kobo.19.1">from Gensim</span></span></li>
				<li class="calibre14"><span class="kobospan" id="kobo.20.1">Visualizing topics </span><span><span class="kobospan" id="kobo.21.1">from BERTopic</span></span></li>
			</ul>
			<h1 id="_idParaDest-175" class="calibre7"><a id="_idTextAnchor179" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.22.1">Technical requirements</span></h1>
			<p class="calibre3"><span class="kobospan" id="kobo.23.1">We will use the following packages in this chapter: </span><strong class="source-inline"><span class="kobospan" id="kobo.24.1">spacy</span></strong><span class="kobospan" id="kobo.25.1">, </span><strong class="source-inline"><span class="kobospan" id="kobo.26.1">matplotlib</span></strong><span class="kobospan" id="kobo.27.1">, </span><strong class="source-inline"><span class="kobospan" id="kobo.28.1">wordcloud</span></strong><span class="kobospan" id="kobo.29.1">, and </span><strong class="source-inline"><span class="kobospan" id="kobo.30.1">pyldavis</span></strong><span class="kobospan" id="kobo.31.1">. </span><span class="kobospan" id="kobo.31.2">They are part of the </span><strong class="source-inline"><span class="kobospan" id="kobo.32.1">poetry</span></strong><span class="kobospan" id="kobo.33.1"> environment and the </span><span><strong class="source-inline"><span class="kobospan" id="kobo.34.1">requirements.txt</span></strong></span><span><span class="kobospan" id="kobo.35.1"> file.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.36.1">We will be using two datasets in this chapter. </span><span class="kobospan" id="kobo.36.2">The first is the BBC news dataset, located at </span><a href="https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/tree/main/data/bbc_train.json" class="calibre6 pcalibre pcalibre1"><span class="kobospan" id="kobo.37.1">https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/tree/main/data/bbc_train.json</span></a> <span><span class="kobospan" id="kobo.38.1">and</span></span><span> </span><a href="https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/tree/main/data/bbc_test.json" class="calibre6 pcalibre pcalibre1"><span><span class="kobospan" id="kobo.39.1">https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/tree/main/data/bbc_test.json</span></span></a><span><span class="kobospan" id="kobo.40.1">.</span></span></p>
			<p class="callout-heading"><span class="kobospan" id="kobo.41.1">Note</span></p>
			<p class="callout"><span class="kobospan" id="kobo.42.1">This dataset is used in this book with permission from the researchers. </span><span class="kobospan" id="kobo.42.2">The original paper associated with this dataset is </span><span><span class="kobospan" id="kobo.43.1">as follows:</span></span></p>
			<p class="callout"><span class="kobospan" id="kobo.44.1">Derek Greene and Pádraig Cunningham. </span><span class="kobospan" id="kobo.44.2">“Practical Solutions to the Problem of Diagonal Dominance in Kernel Document Clustering,” in Proc. </span><span class="kobospan" id="kobo.44.3">23rd International Conference on Machine Learning (</span><span><span class="kobospan" id="kobo.45.1">ICML’06), 2006.</span></span></p>
			<p class="callout"><span class="kobospan" id="kobo.46.1">All rights, including copyright, in the text content of the original articles are owned by </span><span><span class="kobospan" id="kobo.47.1">the BBC.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.48.1">The second is the Sherlock Holmes text, located </span><span><span class="kobospan" id="kobo.49.1">at </span></span><a href="https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/tree/main/data/sherlock_holmes.txt" class="calibre6 pcalibre pcalibre1"><span><span class="kobospan" id="kobo.50.1">https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/tree/main/data/sherlock_holmes.txt</span></span></a><span><span class="kobospan" id="kobo.51.1">.</span></span></p>
			<h1 id="_idParaDest-176" class="calibre7"><a id="_idTextAnchor180" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.52.1">Visualizing the dependency parse</span></h1>
			<p class="calibre3"><span class="kobospan" id="kobo.53.1">In this </span><a id="_idIndexMarker394" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.54.1">recipe, we will learn how to use the </span><strong class="source-inline"><span class="kobospan" id="kobo.55.1">displaCy</span></strong><span class="kobospan" id="kobo.56.1"> library and visualize the dependency parse. </span><span class="kobospan" id="kobo.56.2">It shows us the grammatical relations between words in a piece of text, usually </span><span><span class="kobospan" id="kobo.57.1">a sentence.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.58.1">Details about how to create a dependency parse can be found in </span><a href="B18411_02.xhtml#_idTextAnchor042" class="calibre6 pcalibre pcalibre1"><span><em class="italic"><span class="kobospan" id="kobo.59.1">Chapter 2</span></em></span></a><span class="kobospan" id="kobo.60.1">, in the </span><em class="italic"><span class="kobospan" id="kobo.61.1">Getting the dependency parse</span></em><span class="kobospan" id="kobo.62.1"> recipe. </span><span class="kobospan" id="kobo.62.2">We will create two visualizations, one for a short text and another for a long </span><span><span class="kobospan" id="kobo.63.1">multi-sentence text.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.64.1">After working through this recipe, you will be able to create visualizations of grammatical structures with different options </span><span><span class="kobospan" id="kobo.65.1">for formatting.</span></span></p>
			<h2 id="_idParaDest-177" class="calibre5"><a id="_idTextAnchor181" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.66.1">Getting ready</span></h2>
			<p class="calibre3"><span class="kobospan" id="kobo.67.1">The </span><strong class="source-inline"><span class="kobospan" id="kobo.68.1">displaCy</span></strong><span class="kobospan" id="kobo.69.1"> library is part of the </span><strong class="source-inline"><span class="kobospan" id="kobo.70.1">spacy</span></strong><span class="kobospan" id="kobo.71.1"> package. </span><span class="kobospan" id="kobo.71.2">You need at least version 2.0.12 of the </span><strong class="source-inline"><span class="kobospan" id="kobo.72.1">spacy</span></strong><span class="kobospan" id="kobo.73.1"> package for </span><strong class="source-inline"><span class="kobospan" id="kobo.74.1">displaCy</span></strong><span class="kobospan" id="kobo.75.1"> to work. </span><span class="kobospan" id="kobo.75.2">The version in the </span><strong class="source-inline"><span class="kobospan" id="kobo.76.1">poetry</span></strong><span class="kobospan" id="kobo.77.1"> environment and </span><strong class="source-inline"><span class="kobospan" id="kobo.78.1">requirements.txt</span></strong> <span><span class="kobospan" id="kobo.79.1">is 3.6.1.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.80.1">The notebook is located </span><span><span class="kobospan" id="kobo.81.1">at </span></span><a href="https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter07/7.1_dependency_parse.ipynb" class="calibre6 pcalibre pcalibre1"><span><span class="kobospan" id="kobo.82.1">https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter07/7.1_dependency_parse.ipynb</span></span></a><span><span class="kobospan" id="kobo.83.1">.</span></span></p>
			<h2 id="_idParaDest-178" class="calibre5"><a id="_idTextAnchor182" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.84.1">How to do it...</span></h2>
			<p class="calibre3"><span class="kobospan" id="kobo.85.1">To visualize </span><a id="_idIndexMarker395" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.86.1">the dependency parse, we will use the functionality of the </span><strong class="source-inline"><span class="kobospan" id="kobo.87.1">displaCy</span></strong><span class="kobospan" id="kobo.88.1"> package to first show one sentence, and then two </span><span><span class="kobospan" id="kobo.89.1">sentences together:</span></span></p>
			<ol class="calibre13">
				<li class="calibre14"><span class="kobospan" id="kobo.90.1">Import the </span><span><span class="kobospan" id="kobo.91.1">necessary packages:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.92.1">
import spacy
from spacy import displacy</span></pre></li>				<li class="calibre14"><span class="kobospan" id="kobo.93.1">Run the language </span><span><span class="kobospan" id="kobo.94.1">utilities file:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.95.1">
%run -i "../util/lang_utils.ipynb"</span></pre></li>				<li class="calibre14"><span class="kobospan" id="kobo.96.1">Define the input text and process it using the </span><span><span class="kobospan" id="kobo.97.1">small model:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.98.1">
input_text = "I shot an elephant in my pajamas."
</span><span class="kobospan1" id="kobo.98.2">doc = small_model(input_text)</span></pre></li>				<li class="calibre14"><span class="kobospan" id="kobo.99.1">We will now define different visualization options. </span><span class="kobospan" id="kobo.99.2">The </span><strong class="source-inline1"><span class="kobospan" id="kobo.100.1">add_lemma</span></strong><span class="kobospan" id="kobo.101.1"> option adds the word’s lemma. </span><span class="kobospan" id="kobo.101.2">For example, the lemma of </span><em class="italic"><span class="kobospan" id="kobo.102.1">shot</span></em><span class="kobospan" id="kobo.103.1"> is </span><em class="italic"><span class="kobospan" id="kobo.104.1">shoot</span></em><span class="kobospan" id="kobo.105.1"> and that is listed under the word itself. </span><span class="kobospan" id="kobo.105.2">The </span><strong class="source-inline1"><span class="kobospan" id="kobo.106.1">compact</span></strong><span class="kobospan" id="kobo.107.1"> option pushes the words and arrows together more, so the visualization fits in a smaller space. </span><span class="kobospan" id="kobo.107.2">The </span><strong class="source-inline1"><span class="kobospan" id="kobo.108.1">color</span></strong><span class="kobospan" id="kobo.109.1"> option changes the color of the words and arrows; for the options values, you can input either color names or color values in hex code. </span><span class="kobospan" id="kobo.109.2">The </span><strong class="source-inline1"><span class="kobospan" id="kobo.110.1">collapse_punct</span></strong><span class="kobospan" id="kobo.111.1"> option, if true, adds the punctuation to the word before it. </span><span class="kobospan" id="kobo.111.2">The </span><strong class="source-inline1"><span class="kobospan" id="kobo.112.1">arrow_spacing</span></strong><span class="kobospan" id="kobo.113.1"> option sets the distance between the arrows in pixels. </span><span class="kobospan" id="kobo.113.2">The </span><strong class="source-inline1"><span class="kobospan" id="kobo.114.1">bg</span></strong><span class="kobospan" id="kobo.115.1"> option sets the color of the background, whose value should be either a color name or a color code in hex. </span><span class="kobospan" id="kobo.115.2">The </span><strong class="source-inline1"><span class="kobospan" id="kobo.116.1">font</span></strong><span class="kobospan" id="kobo.117.1"> option changes the font of the words. </span><span class="kobospan" id="kobo.117.2">The </span><strong class="source-inline1"><span class="kobospan" id="kobo.118.1">distance</span></strong><span class="kobospan" id="kobo.119.1"> option sets the distance between words </span><span><span class="kobospan" id="kobo.120.1">in pixels.</span></span><p class="calibre3"><span class="kobospan" id="kobo.121.1">When we run the </span><strong class="source-inline"><span class="kobospan" id="kobo.122.1">render</span></strong><span class="kobospan" id="kobo.123.1"> command, we provide these options as an argument. </span><span class="kobospan" id="kobo.123.2">We set the </span><strong class="source-inline"><span class="kobospan" id="kobo.124.1">jupyter</span></strong><span class="kobospan" id="kobo.125.1"> parameter to </span><strong class="source-inline"><span class="kobospan" id="kobo.126.1">True</span></strong><span class="kobospan" id="kobo.127.1"> for the visualization to work correctly in the notebook. </span><span class="kobospan" id="kobo.127.2">You can omit the argument for non-Jupyter visualizations. </span><span class="kobospan" id="kobo.127.3">We set the </span><strong class="source-inline"><span class="kobospan" id="kobo.128.1">style</span></strong><span class="kobospan" id="kobo.129.1"> parameter to </span><strong class="source-inline"><span class="kobospan" id="kobo.130.1">'dep'</span></strong><span class="kobospan" id="kobo.131.1">, as we would like to have a </span><a id="_idIndexMarker396" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.132.1">dependency parse output. </span><span class="kobospan" id="kobo.132.2">The output is a visual representation of the </span><span><span class="kobospan" id="kobo.133.1">dependency parse:</span></span></p><pre class="source-code"><span class="kobospan1" id="kobo.134.1">
options = {"add_lemma": True,
        "compact": True,
        "color": "green",
        "collapse_punct": True,
        "arrow_spacing": 20,
        "bg": "#FFFFE6",
        "font": "Times",
        "distance": 120}
displacy.render(doc, style='dep', options=options, jupyter=True)</span></pre></li>			</ol>
			<p class="calibre3"><span class="kobospan" id="kobo.135.1">The output is shown in </span><span><em class="italic"><span class="kobospan" id="kobo.136.1">Figure 7</span></em></span><span><em class="italic"><span class="kobospan" id="kobo.137.1">.1</span></em></span><span><span class="kobospan" id="kobo.138.1">.</span></span></p>
			<div class="calibre2">
				<div id="_idContainer026" class="img---figure">
					<span class="kobospan" id="kobo.139.1"><img src="image/B18411_07_01.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.140.1">Figure 7.1 – Dependency parse visualization</span></p>
			<ol class="calibre13">
				<li class="calibre14"><span class="kobospan" id="kobo.141.1">In this</span><a id="_idIndexMarker397" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.142.1"> step, we save the visualization to a file. </span><span class="kobospan" id="kobo.142.2">We first import the </span><strong class="source-inline1"><span class="kobospan" id="kobo.143.1">Path</span></strong><span class="kobospan" id="kobo.144.1"> object from the </span><strong class="source-inline1"><span class="kobospan" id="kobo.145.1">pathlib</span></strong><span class="kobospan" id="kobo.146.1"> package. </span><span class="kobospan" id="kobo.146.2">We then initialize a string with the path where we want to save the file and create a </span><strong class="source-inline1"><span class="kobospan" id="kobo.147.1">Path</span></strong><span class="kobospan" id="kobo.148.1"> object. </span><span class="kobospan" id="kobo.148.2">We use the same </span><strong class="source-inline1"><span class="kobospan" id="kobo.149.1">render</span></strong><span class="kobospan" id="kobo.150.1"> command, this time saving the output in a variable and setting the </span><strong class="source-inline1"><span class="kobospan" id="kobo.151.1">jupyter</span></strong><span class="kobospan" id="kobo.152.1"> parameter to </span><strong class="source-inline1"><span class="kobospan" id="kobo.153.1">False</span></strong><span class="kobospan" id="kobo.154.1">. </span><span class="kobospan" id="kobo.154.2">We then use the </span><strong class="source-inline1"><span class="kobospan" id="kobo.155.1">output_path</span></strong><span class="kobospan" id="kobo.156.1"> object and write the output to the </span><span><span class="kobospan" id="kobo.157.1">corresponding file:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.158.1">
from pathlib import Path
path = "../data/dep_parse_viz.svg"
output_path = Path(path)
svg = displacy.render(doc, style="dep", jupyter=False)
output_path.open("w", encoding="utf-8").write(svg)</span></pre><p class="calibre3"><span class="kobospan" id="kobo.159.1">This will create the dependency parse and save it </span><span><span class="kobospan" id="kobo.160.1">at </span></span><span><strong class="source-inline"><span class="kobospan" id="kobo.161.1">../data/dep_parse_viz.svg</span></strong></span><span><span class="kobospan" id="kobo.162.1">.</span></span></p></li>				<li class="calibre14"><span class="kobospan" id="kobo.163.1">Now, let’s define a longer text and process it using the small model. </span><span class="kobospan" id="kobo.163.2">This way, we will be able to see how </span><strong class="source-inline1"><span class="kobospan" id="kobo.164.1">displaCy</span></strong><span class="kobospan" id="kobo.165.1"> deals with </span><span><span class="kobospan" id="kobo.166.1">longer texts:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.167.1">
input_text_list = "I shot an elephant in my pajamas. </span><span class="kobospan1" id="kobo.167.2">I hate it 
    when elephants wear my pajamas."
</span><span class="kobospan1" id="kobo.167.3">doc = small_model(input_text_list)</span></pre></li>				<li class="calibre14"><span class="kobospan" id="kobo.168.1">Here, we visualize the new text. </span><span class="kobospan" id="kobo.168.2">This time, we have to input a list of sentences from the </span><a id="_idIndexMarker398" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.169.1">processed </span><strong class="source-inline1"><span class="kobospan" id="kobo.170.1">spacy</span></strong><span class="kobospan" id="kobo.171.1"> object to indicate that there is more than </span><span><span class="kobospan" id="kobo.172.1">one sentence:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.173.1">
displacy.render(list(doc.sents), style='dep', options=options, 
    jupyter=True)</span></pre><p class="calibre3"><span class="kobospan" id="kobo.174.1">The output should look like in </span><span><em class="italic"><span class="kobospan" id="kobo.175.1">Figure 7</span></em></span><em class="italic"><span class="kobospan" id="kobo.176.1">.2</span></em><span class="kobospan" id="kobo.177.1">. </span><span class="kobospan" id="kobo.177.2">We see that the output for the second sentence starts on a </span><span><span class="kobospan" id="kobo.178.1">new line.</span></span></p></li>			</ol>
			<div class="calibre2">
				<div id="_idContainer027" class="img---figure">
					<span class="kobospan" id="kobo.179.1"><img src="image/B18411_07_02.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.180.1">Figure 7.2 – Several sentences dependency parse visualization</span></p>
			<h1 id="_idParaDest-179" class="calibre7"><a id="_idTextAnchor183" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.181.1">Visualizing parts of speech</span></h1>
			<p class="calibre3"><span class="kobospan" id="kobo.182.1">In this recipe, we</span><a id="_idIndexMarker399" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.183.1"> visualize part of speech counts. </span><span class="kobospan" id="kobo.183.2">Specifically, we count the number of infinitives and past or present verbs in the book </span><em class="italic"><span class="kobospan" id="kobo.184.1">The Adventures of Sherlock Holmes</span></em><span class="kobospan" id="kobo.185.1">. </span><span class="kobospan" id="kobo.185.2">This can give us an idea about whether the text mostly talks about past or present events. </span><span class="kobospan" id="kobo.185.3">We could imagine that similar tools could be used to evaluate the quality of a text; for example, a book with very few adjectives but many nouns would not work very well as a </span><span><span class="kobospan" id="kobo.186.1">fiction book.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.187.1">After working through this recipe, you will be able to use the </span><strong class="source-inline"><span class="kobospan" id="kobo.188.1">matplotlib</span></strong><span class="kobospan" id="kobo.189.1"> package to create bar plots of different verb types, which are tagged using the </span><span><strong class="source-inline"><span class="kobospan" id="kobo.190.1">spacy</span></strong></span><span><span class="kobospan" id="kobo.191.1"> package.</span></span></p>
			<h2 id="_idParaDest-180" class="calibre5"><a id="_idTextAnchor184" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.192.1">Getting ready</span></h2>
			<p class="calibre3"><span class="kobospan" id="kobo.193.1">We will use the </span><strong class="source-inline"><span class="kobospan" id="kobo.194.1">spacy</span></strong><span class="kobospan" id="kobo.195.1"> package for text analysis and the </span><strong class="source-inline"><span class="kobospan" id="kobo.196.1">matplotlib</span></strong><span class="kobospan" id="kobo.197.1"> package to create the graph. </span><span class="kobospan" id="kobo.197.2">They are part of the </span><strong class="source-inline"><span class="kobospan" id="kobo.198.1">poetry</span></strong><span class="kobospan" id="kobo.199.1"> environment and the </span><span><strong class="source-inline"><span class="kobospan" id="kobo.200.1">requirements.txt</span></strong></span><span><span class="kobospan" id="kobo.201.1"> file.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.202.1">The notebook is located </span><span><span class="kobospan" id="kobo.203.1">at </span></span><a href="https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter07/7.2_parts_of_speech.ipynb" class="calibre6 pcalibre pcalibre1"><span><span class="kobospan" id="kobo.204.1">https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter07/7.2_parts_of_speech.ipynb</span></span></a><span><span class="kobospan" id="kobo.205.1">.</span></span></p>
			<h2 id="_idParaDest-181" class="calibre5"><a id="_idTextAnchor185" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.206.1">How to do it...</span></h2>
			<p class="calibre3"><span class="kobospan" id="kobo.207.1">We will create a function that will count the number of verbs by tense and plot each on a </span><span><span class="kobospan" id="kobo.208.1">bar graph:</span></span></p>
			<ol class="calibre13">
				<li class="calibre14"><span class="kobospan" id="kobo.209.1">Import the </span><span><span class="kobospan" id="kobo.210.1">necessary packages:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.211.1">
import spacy
import matplotlib.pyplot as plt</span></pre></li>				<li class="calibre14"><span class="kobospan" id="kobo.212.1">Run the file and language utilities files. </span><span class="kobospan" id="kobo.212.2">The language utilities notebook loads the </span><strong class="source-inline1"><span class="kobospan" id="kobo.213.1">spacy</span></strong><span class="kobospan" id="kobo.214.1"> model, and the file utilities notebook loads the </span><span><strong class="source-inline1"><span class="kobospan" id="kobo.215.1">read_text_file</span></strong></span><span><span class="kobospan" id="kobo.216.1"> function:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.217.1">
%run -i "../util/lang_utils.ipynb"
%run -i "../util/file_utils.ipynb"</span></pre></li>				<li class="calibre14"><span class="kobospan" id="kobo.218.1">Load the text of the Sherlock </span><span><span class="kobospan" id="kobo.219.1">Holmes book:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.220.1">
text_file = "../data/sherlock_holmes.txt"
text = read_text_file(text_file)</span></pre></li>				<li class="calibre14"><span class="kobospan" id="kobo.221.1">Here, we </span><a id="_idIndexMarker400" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.222.1">define the verb tag lists, one for present tense and one for past tense. </span><span class="kobospan" id="kobo.222.2">We do not define another list, but use it in the next step, and that is the infinitive verb, which only has one tag, </span><strong class="source-inline1"><span class="kobospan" id="kobo.223.1">VB</span></strong><span class="kobospan" id="kobo.224.1">. </span><span class="kobospan" id="kobo.224.2">If you went through the </span><em class="italic"><span class="kobospan" id="kobo.225.1">Part-of-speech tagging</span></em><span class="kobospan" id="kobo.226.1"> recipe in </span><a href="B18411_01.xhtml#_idTextAnchor013" class="calibre6 pcalibre pcalibre1"><span><em class="italic"><span class="kobospan" id="kobo.227.1">Chapter 1</span></em></span></a><span class="kobospan" id="kobo.228.1">, you will notice that the tags are different from the </span><strong class="source-inline1"><span class="kobospan" id="kobo.229.1">spacy</span></strong><span class="kobospan" id="kobo.230.1"> tags used there. </span><span class="kobospan" id="kobo.230.2">These tags are more detailed and use the </span><strong class="source-inline1"><span class="kobospan" id="kobo.231.1">tag_</span></strong><span class="kobospan" id="kobo.232.1"> attribute instead of the </span><strong class="source-inline1"><span class="kobospan" id="kobo.233.1">pos_</span></strong><span class="kobospan" id="kobo.234.1"> attribute that is used in the </span><span><span class="kobospan" id="kobo.235.1">simplified tagset:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.236.1">
past_tags = ["VBD", "VBN"]
present_tags = ["VBG", "VBP", "VBZ"]</span></pre></li>				<li class="calibre14"><span class="kobospan" id="kobo.237.1">In this step, we create the </span><strong class="source-inline1"><span class="kobospan" id="kobo.238.1">visualize_verbs</span></strong><span class="kobospan" id="kobo.239.1"> function. </span><span class="kobospan" id="kobo.239.2">The input to the function is the text and the </span><strong class="source-inline1"><span class="kobospan" id="kobo.240.1">spacy</span></strong><span class="kobospan" id="kobo.241.1"> model. </span><span class="kobospan" id="kobo.241.2">We check each token’s </span><strong class="source-inline1"><span class="kobospan" id="kobo.242.1">tag_</span></strong><span class="kobospan" id="kobo.243.1"> attribute and add the counts of present, past, and infinitive verbs to a dictionary. </span><span class="kobospan" id="kobo.243.2">We then use the </span><strong class="source-inline1"><span class="kobospan" id="kobo.244.1">pyplot</span></strong><span class="kobospan" id="kobo.245.1"> interface to plot those counts in a bar graph. </span><span class="kobospan" id="kobo.245.2">We use the </span><strong class="source-inline1"><span class="kobospan" id="kobo.246.1">bar</span></strong><span class="kobospan" id="kobo.247.1"> function to define the bar graph. </span><span class="kobospan" id="kobo.247.2">The first argument lists the </span><em class="italic"><span class="kobospan" id="kobo.248.1">x</span></em><span class="kobospan" id="kobo.249.1"> coordinates of the bars. </span><span class="kobospan" id="kobo.249.2">The next argument is a list of heights of the bars. </span><span class="kobospan" id="kobo.249.3">We also set the </span><strong class="source-inline1"><span class="kobospan" id="kobo.250.1">align</span></strong><span class="kobospan" id="kobo.251.1"> parameter to “center” and provide the colors for the bars using the </span><strong class="source-inline1"><span class="kobospan" id="kobo.252.1">color</span></strong><span class="kobospan" id="kobo.253.1"> parameter. </span><span class="kobospan" id="kobo.253.2">The </span><strong class="source-inline1"><span class="kobospan" id="kobo.254.1">xticks</span></strong><span class="kobospan" id="kobo.255.1"> function sets the labels for the </span><em class="italic"><span class="kobospan" id="kobo.256.1">x</span></em><span class="kobospan" id="kobo.257.1"> axis. </span><span class="kobospan" id="kobo.257.2">Finally, we use the </span><strong class="source-inline1"><span class="kobospan" id="kobo.258.1">show</span></strong><span class="kobospan" id="kobo.259.1"> function to display the </span><span><span class="kobospan" id="kobo.260.1">resulting plot:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.261.1">
def visualize_verbs(text, nlp):
    doc = nlp(text)
    verb_dict = {"Inf":0, "Past":0, "Present":0}
    for token in doc:
        if (token.tag_ == "VB"):
            verb_dict["Inf"] = verb_dict["Inf"] + 1
        if (token.tag_ in past_tags):
            verb_dict["Past"] = verb_dict["Past"] + 1
        if (token.tag_ in present_tags):
            verb_dict["Present"] = verb_dict["Present"] + 1
    plt.bar(range(len(verb_dict)),
        list(verb_dict.values()), align='center',
        color=["red", "green", "blue"])
    plt.xticks(range(len(verb_dict)),
        list(verb_dict.keys()))
    plt.show()</span></pre></li>				<li class="calibre14"><span class="kobospan" id="kobo.262.1">Run </span><a id="_idIndexMarker401" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.263.1">the </span><strong class="source-inline1"><span class="kobospan" id="kobo.264.1">visualize_verbs</span></strong><span class="kobospan" id="kobo.265.1"> function on the text of the Sherlock Holmes book using the small </span><span><strong class="source-inline1"><span class="kobospan" id="kobo.266.1">spacy</span></strong></span><span><span class="kobospan" id="kobo.267.1"> model:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.268.1">
visualize_verbs(text, small_model)</span></pre><p class="calibre3"><span class="kobospan" id="kobo.269.1">This will create the graph in </span><span><em class="italic"><span class="kobospan" id="kobo.270.1">Figure 7</span></em></span><em class="italic"><span class="kobospan" id="kobo.271.1">.3</span></em><span class="kobospan" id="kobo.272.1">. </span><span class="kobospan" id="kobo.272.2">We see that most of the verbs in the book are past tense, which makes sense for a novel. </span><span class="kobospan" id="kobo.272.3">However, there is also a sizable number of present tense verbs, which could be part of </span><span><span class="kobospan" id="kobo.273.1">direct speech.</span></span></p></li>			</ol>
			<div class="calibre2">
				<div id="_idContainer028" class="img---figure">
					<span class="kobospan" id="kobo.274.1"><img src="image/B18411_07_03.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.275.1">Figure 7.3 – Infinitive, past, and present verbs in The Adventures of Sherlock Holmes</span></p>
			<h1 id="_idParaDest-182" class="calibre7"><a id="_idTextAnchor186" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.276.1">Visualizing NER</span></h1>
			<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.277.1">Named entity recognition</span></strong><span class="kobospan" id="kobo.278.1">, or </span><strong class="bold"><span class="kobospan" id="kobo.279.1">NER</span></strong><span class="kobospan" id="kobo.280.1">, is a </span><a id="_idIndexMarker402" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.281.1">very useful tool for quickly finding people, organizations, locations, and other entities in texts. </span><span class="kobospan" id="kobo.281.2">In order to visualize them better, we can use the </span><strong class="source-inline"><span class="kobospan" id="kobo.282.1">displacy</span></strong><span class="kobospan" id="kobo.283.1"> package to create compelling and </span><span><span class="kobospan" id="kobo.284.1">easy-to-read images.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.285.1">After working through this recipe, you will be able to create visualizations of named entities in a text using different formatting options and save the results in </span><span><span class="kobospan" id="kobo.286.1">a file.</span></span></p>
			<h2 id="_idParaDest-183" class="calibre5"><a id="_idTextAnchor187" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.287.1">Getting ready</span></h2>
			<p class="calibre3"><span class="kobospan" id="kobo.288.1">The </span><strong class="source-inline"><span class="kobospan" id="kobo.289.1">displaCy</span></strong><span class="kobospan" id="kobo.290.1"> library is part of the </span><strong class="source-inline"><span class="kobospan" id="kobo.291.1">spacy</span></strong><span class="kobospan" id="kobo.292.1"> package. </span><span class="kobospan" id="kobo.292.2">You need at least version 2.0.12 of the </span><strong class="source-inline"><span class="kobospan" id="kobo.293.1">spacy</span></strong><span class="kobospan" id="kobo.294.1"> package for </span><strong class="source-inline"><span class="kobospan" id="kobo.295.1">displaCy</span></strong><span class="kobospan" id="kobo.296.1"> to work. </span><span class="kobospan" id="kobo.296.2">The version in the </span><strong class="source-inline"><span class="kobospan" id="kobo.297.1">poetry</span></strong><span class="kobospan" id="kobo.298.1"> environment and </span><strong class="source-inline"><span class="kobospan" id="kobo.299.1">requirements.txt</span></strong><span class="kobospan" id="kobo.300.1"> file </span><span><span class="kobospan" id="kobo.301.1">is 3.6.1.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.302.1">The notebook is located </span><span><span class="kobospan" id="kobo.303.1">at </span></span><a href="https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter07/7.3_ner.ipynb" class="calibre6 pcalibre pcalibre1"><span><span class="kobospan" id="kobo.304.1">https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter07/7.3_ner.ipynb</span></span></a><span><span class="kobospan" id="kobo.305.1">.</span></span></p>
			<h2 id="_idParaDest-184" class="calibre5"><a id="_idTextAnchor188" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.306.1">How to do it...</span></h2>
			<p class="calibre3"><span class="kobospan" id="kobo.307.1">We </span><a id="_idIndexMarker403" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.308.1">will use </span><strong class="source-inline"><span class="kobospan" id="kobo.309.1">spacy</span></strong><span class="kobospan" id="kobo.310.1"> to parse the sentence and then the </span><strong class="source-inline"><span class="kobospan" id="kobo.311.1">displacy</span></strong><span class="kobospan" id="kobo.312.1"> engine to visualize the </span><span><span class="kobospan" id="kobo.313.1">named entities:</span></span></p>
			<ol class="calibre13">
				<li class="calibre14"><span class="kobospan" id="kobo.314.1">Import both </span><strong class="source-inline1"><span class="kobospan" id="kobo.315.1">spacy</span></strong> <span><span class="kobospan" id="kobo.316.1">and </span></span><span><strong class="source-inline1"><span class="kobospan" id="kobo.317.1">displacy</span></strong></span><span><span class="kobospan" id="kobo.318.1">:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.319.1">
import spacy
from spacy import displacy</span></pre></li>				<li class="calibre14"><span class="kobospan" id="kobo.320.1">Run the language </span><span><span class="kobospan" id="kobo.321.1">utilities file:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.322.1">
%run -i "../util/lang_utils.ipynb"</span></pre></li>				<li class="calibre14"><span class="kobospan" id="kobo.323.1">Define the text </span><span><span class="kobospan" id="kobo.324.1">to process:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.325.1">
text = """iPhone 12: Apple makes jump to 5G
Apple has confirmed its iPhone 12 handsets will be its first to work on faster 5G networks.
</span><span class="kobospan1" id="kobo.325.2">The company has also extended the range to include a new "Mini" model that has a smaller 5.4in screen.
</span><span class="kobospan1" id="kobo.325.3">The US firm bucked a wider industry downturn by increasing its handset sales over the past year.
</span><span class="kobospan1" id="kobo.325.4">But some experts say the new features give Apple its best opportunity for growth since 2014, when it revamped its line-up with the iPhone 6.
</span><span class="kobospan1" id="kobo.325.5">"5G will bring a new level of performance for downloads and uploads, higher quality video streaming, more responsive gaming,
real-time interactivity and so much more," said chief executive Tim Cook.
</span><span class="kobospan1" id="kobo.325.6">There has also been a cosmetic refresh this time round, with the sides of the devices getting sharper, flatter edges.
</span><span class="kobospan1" id="kobo.325.7">The higher-end iPhone 12 Pro models also get bigger screens than before and a new sensor to help with low-light photography.
</span><span class="kobospan1" id="kobo.325.8">However, for the first time none of the devices will be bundled with headphones or a charger."""</span></pre></li>				<li class="calibre14"><span class="kobospan" id="kobo.326.1">In this</span><a id="_idIndexMarker404" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.327.1"> step, we process the text using the small model. </span><span class="kobospan" id="kobo.327.2">This gives us a </span><strong class="source-inline1"><span class="kobospan" id="kobo.328.1">Doc</span></strong><span class="kobospan" id="kobo.329.1"> object. </span><span class="kobospan" id="kobo.329.2">We then modify the object to contain a title. </span><span class="kobospan" id="kobo.329.3">This title will be part of the </span><span><span class="kobospan" id="kobo.330.1">NER visualization:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.331.1">
doc = small_model(text)
doc.user_data["title"] = "iPhone 12: Apple makes jump to 5G"</span></pre></li>				<li class="calibre14"><span class="kobospan" id="kobo.332.1">Here, we set up color options for the visualization display. </span><span class="kobospan" id="kobo.332.2">We set green for the </span><strong class="source-inline1"><span class="kobospan" id="kobo.333.1">ORG</span></strong><span class="kobospan" id="kobo.334.1">-labeled text and yellow for the </span><strong class="source-inline1"><span class="kobospan" id="kobo.335.1">PERSON</span></strong><span class="kobospan" id="kobo.336.1">-labeled text. </span><span class="kobospan" id="kobo.336.2">We then set the </span><strong class="source-inline1"><span class="kobospan" id="kobo.337.1">options</span></strong><span class="kobospan" id="kobo.338.1"> variable, which contains the colors. </span><span class="kobospan" id="kobo.338.2">Finally, we use the </span><strong class="source-inline1"><span class="kobospan" id="kobo.339.1">render</span></strong><span class="kobospan" id="kobo.340.1"> command to display the visualization. </span><span class="kobospan" id="kobo.340.2">As arguments, we provide the </span><strong class="source-inline1"><span class="kobospan" id="kobo.341.1">Doc</span></strong><span class="kobospan" id="kobo.342.1"> object and the options we previously defined. </span><span class="kobospan" id="kobo.342.2">We also set the </span><strong class="source-inline1"><span class="kobospan" id="kobo.343.1">style</span></strong><span class="kobospan" id="kobo.344.1"> argument to </span><strong class="source-inline1"><span class="kobospan" id="kobo.345.1">"ent"</span></strong><span class="kobospan" id="kobo.346.1">, as we would like to display just entities. </span><span class="kobospan" id="kobo.346.2">We set the </span><strong class="source-inline1"><span class="kobospan" id="kobo.347.1">jupyter</span></strong><span class="kobospan" id="kobo.348.1"> argument to </span><strong class="source-inline1"><span class="kobospan" id="kobo.349.1">True</span></strong><span class="kobospan" id="kobo.350.1"> in order to display directly in </span><span><span class="kobospan" id="kobo.351.1">the notebook:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.352.1">
colors = {"ORG": "green", "PERSON":"yellow"}
options = {"colors": colors}
displacy.render(doc, style='ent', options=options, jupyter=True)</span></pre><p class="calibre3"><span class="kobospan" id="kobo.353.1">The output should look like that in </span><span><em class="italic"><span class="kobospan" id="kobo.354.1">Figure 7</span></em></span><span><em class="italic"><span class="kobospan" id="kobo.355.1">.4</span></em></span><span><span class="kobospan" id="kobo.356.1">.</span></span></p></li>			</ol>
			<div class="calibre2">
				<div id="_idContainer029" class="img---figure">
					<span class="kobospan" id="kobo.357.1"><img src="image/B18411_07_04.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.358.1">Figure 7.4 – Named entities visualization</span></p>
			<ol class="calibre13">
				<li value="6" class="calibre14"><span class="kobospan" id="kobo.359.1">Now we </span><a id="_idIndexMarker405" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.360.1">save the visualization to an HTML file. </span><span class="kobospan" id="kobo.360.2">We first define the </span><strong class="source-inline1"><span class="kobospan" id="kobo.361.1">path</span></strong><span class="kobospan" id="kobo.362.1"> variable. </span><span class="kobospan" id="kobo.362.2">Then, we use the same </span><strong class="source-inline1"><span class="kobospan" id="kobo.363.1">render</span></strong><span class="kobospan" id="kobo.364.1"> command, but we set the </span><strong class="source-inline1"><span class="kobospan" id="kobo.365.1">jupyter</span></strong><span class="kobospan" id="kobo.366.1"> argument to </span><strong class="source-inline1"><span class="kobospan" id="kobo.367.1">False</span></strong><span class="kobospan" id="kobo.368.1"> this time and assign the output of the command to the </span><strong class="source-inline1"><span class="kobospan" id="kobo.369.1">html</span></strong><span class="kobospan" id="kobo.370.1"> variable. </span><span class="kobospan" id="kobo.370.2">We then open the file, write the HTML, and close </span><span><span class="kobospan" id="kobo.371.1">the file:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.372.1">
path = "../data/ner_vis.html"
html = displacy.render(doc, style="ent",
    options=options, jupyter=False)
html_file= open(path, "w", encoding="utf-8")
html_file.write(html)
html_file.close()</span></pre><p class="calibre3"><span class="kobospan" id="kobo.373.1">This will create an HTML file with the </span><span><span class="kobospan" id="kobo.374.1">entities visualization.</span></span></p></li>			</ol>
			<h1 id="_idParaDest-185" class="calibre7"><a id="_idTextAnchor189" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.375.1">Creating a confusion matrix plot</span></h1>
			<p class="calibre3"><span class="kobospan" id="kobo.376.1">When</span><a id="_idIndexMarker406" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.377.1"> working with machine learning models, for example, NLP classification models, creating a confusion matrix plot can be a very good tool to see the mistakes that the model makes to then further refine it. </span><span class="kobospan" id="kobo.377.2">The model “confuses” one class for another, hence the name </span><span><strong class="bold"><span class="kobospan" id="kobo.378.1">confusion matrix</span></strong></span><span><span class="kobospan" id="kobo.379.1">.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.380.1">After working through this recipe, you will be able to create an SVM model, evaluate it, and then create a confusion matrix visualization that will tell you in detail which mistakes the </span><span><span class="kobospan" id="kobo.381.1">model makes.</span></span></p>
			<h2 id="_idParaDest-186" class="calibre5"><a id="_idTextAnchor190" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.382.1">Getting ready</span></h2>
			<p class="calibre3"><span class="kobospan" id="kobo.383.1">We will create </span><a id="_idIndexMarker407" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.384.1">an SVM classifier for the BBC news dataset using the sentence transformer model as the vectorizer. </span><span class="kobospan" id="kobo.384.2">We will then use the </span><strong class="source-inline"><span class="kobospan" id="kobo.385.1">ConfusionMatrixDisplay</span></strong><span class="kobospan" id="kobo.386.1"> object to create a more informative confusion matrix. </span><span class="kobospan" id="kobo.386.2">The classifier is the same as in the </span><a href="B18411_04.xhtml#_idTextAnchor106" class="calibre6 pcalibre pcalibre1"><span><em class="italic"><span class="kobospan" id="kobo.387.1">Chapter 4</span></em></span></a><span class="kobospan" id="kobo.388.1"> recipe </span><em class="italic"><span class="kobospan" id="kobo.389.1">Using SVMs for supervised </span></em><span><em class="italic"><span class="kobospan" id="kobo.390.1">text classification</span></em></span><span><span class="kobospan" id="kobo.391.1">.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.392.1">The dataset is located at </span><a href="https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/tree/main/data/bbc_train.json" class="calibre6 pcalibre pcalibre1"><span class="kobospan" id="kobo.393.1">https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/tree/main/data/bbc_train.json</span></a> <span><span class="kobospan" id="kobo.394.1">and </span></span><a href="https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/tree/main/data/bbc_test.json" class="calibre6 pcalibre pcalibre1"><span><span class="kobospan" id="kobo.395.1">https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/tree/main/data/bbc_test.json</span></span></a><span><span class="kobospan" id="kobo.396.1">.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.397.1">The notebook is located </span><span><span class="kobospan" id="kobo.398.1">at </span></span><a href="https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter07/7.4_confusion_matrix.ipynb" class="calibre6 pcalibre pcalibre1"><span><span class="kobospan" id="kobo.399.1">https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter07/7.4_confusion_matrix.ipynb</span></span></a><span><span class="kobospan" id="kobo.400.1">.</span></span></p>
			<h2 id="_idParaDest-187" class="calibre5"><a id="_idTextAnchor191" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.401.1">How to do it...</span></h2>
			<ol class="calibre13">
				<li class="calibre14"><span class="kobospan" id="kobo.402.1">Import the necessary packages </span><span><span class="kobospan" id="kobo.403.1">and functions:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.404.1">
from sklearn.svm import SVC
from sentence_transformers import SentenceTransformer
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
from sklearn.metrics import ConfusionMatrixDisplay</span></pre></li>				<li class="calibre14"><span class="kobospan" id="kobo.405.1">Run the simple classifier </span><span><span class="kobospan" id="kobo.406.1">utilities file:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.407.1">
%run -i "../util/util_simple_classifier.ipynb"</span></pre></li>				<li class="calibre14"><span class="kobospan" id="kobo.408.1">Read in the training and test data and shuffle the training data. </span><span class="kobospan" id="kobo.408.2">We shuffle the data so that there are no long sequences of one class, which might either bias the model during training or exclude large chunks of </span><span><span class="kobospan" id="kobo.409.1">some classes:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.410.1">
train_df = pd.read_json("../data/bbc_train.json")
test_df = pd.read_json("../data/bbc_test.json")
train_df.sample(frac=1)</span></pre></li>				<li class="calibre14"><span class="kobospan" id="kobo.411.1">In this </span><a id="_idIndexMarker408" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.412.1">step, we load the transformer model and create the </span><strong class="source-inline1"><span class="kobospan" id="kobo.413.1">get_sentence_vector</span></strong><span class="kobospan" id="kobo.414.1"> function. </span><span class="kobospan" id="kobo.414.2">The function takes as arguments the text and the model, then creates and returns the vector. </span><span class="kobospan" id="kobo.414.3">The </span><strong class="source-inline1"><span class="kobospan" id="kobo.415.1">encode</span></strong><span class="kobospan" id="kobo.416.1"> method takes in a list of text, so in order to encode one piece of text, we need to put it into a list, and then get the first element of the </span><strong class="source-inline1"><span class="kobospan" id="kobo.417.1">return</span></strong><span class="kobospan" id="kobo.418.1"> object, since the model also returns a list of </span><span><span class="kobospan" id="kobo.419.1">encoding vectors:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.420.1">
model = SentenceTransformer('all-MiniLM-L6-v2')
def get_sentence_vector(text, model):
    sentence_embeddings = model.encode([text])
    return sentence_embeddings[0]</span></pre></li>				<li class="calibre14"><span class="kobospan" id="kobo.421.1">Here, we create the </span><strong class="source-inline1"><span class="kobospan" id="kobo.422.1">train_classifier</span></strong><span class="kobospan" id="kobo.423.1"> function. </span><span class="kobospan" id="kobo.423.2">The function takes in vectorized input and the correct answers. </span><span class="kobospan" id="kobo.423.3">It then creates and trains an SVC object and returns it. </span><span class="kobospan" id="kobo.423.4">It could take a few minutes to </span><span><span class="kobospan" id="kobo.424.1">finish training:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.425.1">
def train_classifier(X_train, y_train):
    clf = SVC(C=0.1, kernel='rbf')
    clf = clf.fit(X_train, y_train)
    return clf</span></pre></li>				<li class="calibre14"><span class="kobospan" id="kobo.426.1">In this step, we train and test the classifier. </span><span class="kobospan" id="kobo.426.2">First, we create a list with the target labels. </span><span class="kobospan" id="kobo.426.3">We then create a </span><strong class="source-inline1"><span class="kobospan" id="kobo.427.1">vectorize</span></strong><span class="kobospan" id="kobo.428.1"> function that uses the </span><strong class="source-inline1"><span class="kobospan" id="kobo.429.1">get_sentence_vector</span></strong><span class="kobospan" id="kobo.430.1"> function but specifies the model to use. </span><span class="kobospan" id="kobo.430.2">We then use the </span><strong class="source-inline1"><span class="kobospan" id="kobo.431.1">create_train_test_data</span></strong><span class="kobospan" id="kobo.432.1"> function from the simple classifier utilities file to get the vectorized input and labels for both the training and test sets. </span><span class="kobospan" id="kobo.432.2">This function takes in the training and test dataframes, the vectorizing method, and</span><a id="_idIndexMarker409" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.433.1"> the name of the column where the text is located. </span><span class="kobospan" id="kobo.433.2">The results are the vectorized training and test data and the true labels for both. </span><span class="kobospan" id="kobo.433.3">Then, we use the </span><strong class="source-inline1"><span class="kobospan" id="kobo.434.1">train_classifier</span></strong><span class="kobospan" id="kobo.435.1"> function to create a trained SVM classifier. </span><span class="kobospan" id="kobo.435.2">We print the classification report for the training data and use the </span><strong class="source-inline1"><span class="kobospan" id="kobo.436.1">test_classifier</span></strong><span class="kobospan" id="kobo.437.1"> function to print the classification report for the </span><span><span class="kobospan" id="kobo.438.1">test data:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.439.1">
target_names=["tech", "business", "sport",
    "entertainment", "politics"]
vectorize = lambda x: get_sentence_vector(x, model)
(X_train, X_test, y_train, y_test) = create_train_test_data(
    train_df, test_df, vectorize,
    column_name="text_clean")
clf = train_classifier(X_train, y_train)
print(classification_report(train_df["label"],
        y_train, target_names=target_names))
test_classifier(test_df, clf, target_names=target_names)</span></pre><p class="calibre3"><span class="kobospan" id="kobo.440.1">The output should be </span><span><span class="kobospan" id="kobo.441.1">as follows:</span></span></p><pre class="source-code"><span class="kobospan1" id="kobo.442.1">               precision    recall  f1-score   support
         tech       1.00      1.00      1.00       321
     business       1.00      1.00      1.00       408
        sport       1.00      1.00      1.00       409
entertainment       1.00      1.00      1.00       309
     politics       1.00      1.00      1.00       333
     accuracy                           1.00      1780
    macro avg       1.00      1.00      1.00      1780
 weighted avg       1.00      1.00      1.00      1780
               precision    recall  f1-score   support
         tech       0.97      0.95      0.96        80
     business       0.98      0.97      0.98       102
        sport       0.98      1.00      0.99       102
entertainment       0.96      0.99      0.97        77
     politics       0.98      0.96      0.97        84
     accuracy                           0.98       445
    macro avg       0.97      0.97      0.97       445
 weighted avg       0.98      0.98      0.98       445</span></pre></li>				<li class="calibre14"><span class="kobospan" id="kobo.443.1">Now, we</span><a id="_idIndexMarker410" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.444.1"> create a mapping from number labels to text labels and then create a new column in the test dataframe that shows the text </span><span><span class="kobospan" id="kobo.445.1">label prediction:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.446.1">
num_to_text_mapping = {0:"tech", 1:"business",
    2:"sport", 3:"entertainment", 4:"politics"}
test_df["pred_label"] = test_df["prediction"].apply(
    lambda x: num_to_text_mapping[x])</span></pre></li>				<li class="calibre14"><span class="kobospan" id="kobo.447.1">In this step, we create a confusion matrix using the </span><strong class="source-inline1"><span class="kobospan" id="kobo.448.1">sklearn</span></strong> <strong class="source-inline1"><span class="kobospan" id="kobo.449.1">confusion_matrix</span></strong><span class="kobospan" id="kobo.450.1"> function. </span><span class="kobospan" id="kobo.450.2">The function takes as input the true labels, the predictions, and the names of the categories. </span><span class="kobospan" id="kobo.450.3">We then create a </span><strong class="source-inline1"><span class="kobospan" id="kobo.451.1">ConfusionMatrixDisplay</span></strong><span class="kobospan" id="kobo.452.1"> object that takes in that confusion matrix and the </span><a id="_idIndexMarker411" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.453.1">names to display. </span><span class="kobospan" id="kobo.453.2">We then create the confusion matrix plot using the object and display it using the </span><span><strong class="source-inline1"><span class="kobospan" id="kobo.454.1">matplotlib</span></strong></span><span><span class="kobospan" id="kobo.455.1"> library:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.456.1">
cm = confusion_matrix(
    test_df["label_text"],
    test_df["pred_label"], labels=target_names)
disp = ConfusionMatrixDisplay(
    confusion_matrix=cm,
    display_labels=target_names)
disp.plot()
plt.show()</span></pre><p class="calibre3"><span class="kobospan" id="kobo.457.1">The result is shown in </span><span><em class="italic"><span class="kobospan" id="kobo.458.1">Figure 7</span></em></span><em class="italic"><span class="kobospan" id="kobo.459.1">.5</span></em><span class="kobospan" id="kobo.460.1">. </span><span class="kobospan" id="kobo.460.2">The resulting plot clearly shows which classes have overlaps and their number. </span><span class="kobospan" id="kobo.460.3">For example, it is easy to see that there are two examples that are predicted to be about business but are actually </span><span><span class="kobospan" id="kobo.461.1">about politics.</span></span></p></li>			</ol>
			<div class="calibre2">
				<div id="_idContainer030" class="img---figure">
					<span class="kobospan" id="kobo.462.1"><img src="image/B18411_07_05.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.463.1">Figure 7.5 – Confusion matrix visualization</span></p>
			<h1 id="_idParaDest-188" class="calibre7"><a id="_idTextAnchor192" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.464.1">Constructing word clouds</span></h1>
			<p class="calibre3"><span class="kobospan" id="kobo.465.1">Word clouds are</span><a id="_idIndexMarker412" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.466.1"> a nice visualization tool to quickly see topics that are prevalent in a text. </span><span class="kobospan" id="kobo.466.2">They can be used at the preliminary data analysis stage and for illustration purposes. </span><span class="kobospan" id="kobo.466.3">A distinguishing feature of word clouds is that larger-font words signify a more frequent topic, while smaller-font words signify less </span><span><span class="kobospan" id="kobo.467.1">frequent topics.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.468.1">After working</span><a id="_idIndexMarker413" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.469.1"> through this recipe, you will be able to create word clouds from a text and also apply a picture mask on top of the word cloud, which makes for a </span><span><span class="kobospan" id="kobo.470.1">cool image.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.471.1">We will use the text of the book </span><em class="italic"><span class="kobospan" id="kobo.472.1">The Adventures of Sherlock Holmes</span></em><span class="kobospan" id="kobo.473.1"> and the picture mask we will use is a silhouette of Sherlock </span><span><span class="kobospan" id="kobo.474.1">Holmes’ head.</span></span></p>
			<h2 id="_idParaDest-189" class="calibre5"><a id="_idTextAnchor193" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.475.1">Getting ready</span></h2>
			<p class="calibre3"><span class="kobospan" id="kobo.476.1">We will use the </span><strong class="source-inline"><span class="kobospan" id="kobo.477.1">wordcloud</span></strong><span class="kobospan" id="kobo.478.1"> package for this recipe. </span><span class="kobospan" id="kobo.478.2">In order to display the image, we need the </span><strong class="source-inline"><span class="kobospan" id="kobo.479.1">matplotlib</span></strong><span class="kobospan" id="kobo.480.1"> package as well. </span><span class="kobospan" id="kobo.480.2">They are both part of the </span><strong class="source-inline"><span class="kobospan" id="kobo.481.1">poetry</span></strong><span class="kobospan" id="kobo.482.1"> environment and the </span><span><strong class="source-inline"><span class="kobospan" id="kobo.483.1">requirements.txt</span></strong></span><span><span class="kobospan" id="kobo.484.1"> file.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.485.1">The notebook is located </span><span><span class="kobospan" id="kobo.486.1">at </span></span><a href="https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter07/7.5_word_clouds.ipynb" class="calibre6 pcalibre pcalibre1"><span><span class="kobospan" id="kobo.487.1">https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter07/7.5_word_clouds.ipynb</span></span></a><span><span class="kobospan" id="kobo.488.1">.</span></span></p>
			<h2 id="_idParaDest-190" class="calibre5"><a id="_idTextAnchor194" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.489.1">How to do it...</span></h2>
			<ol class="calibre13">
				<li class="calibre14"><span class="kobospan" id="kobo.490.1">Import </span><a id="_idIndexMarker414" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.491.1">the necessary packages </span><span><span class="kobospan" id="kobo.492.1">and functions:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.493.1">
import matplotlib.pyplot as plt
from wordcloud import WordCloud, STOPWORDS</span></pre></li>				<li class="calibre14"><span class="kobospan" id="kobo.494.1">Run the file utilities notebook. </span><span class="kobospan" id="kobo.494.2">We will use the </span><strong class="source-inline1"><span class="kobospan" id="kobo.495.1">read_text_file</span></strong><span class="kobospan" id="kobo.496.1"> function from </span><span><span class="kobospan" id="kobo.497.1">this notebook:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.498.1">
%run -i "../util/file_utils.ipynb"</span></pre></li>				<li class="calibre14"><span class="kobospan" id="kobo.499.1">Read in the </span><span><span class="kobospan" id="kobo.500.1">book text:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.501.1">
text_file = "../data/sherlock_holmes.txt"
text = read_text_file(text_file)</span></pre></li>				<li class="calibre14"><span class="kobospan" id="kobo.502.1">In this step, we define the </span><strong class="source-inline1"><span class="kobospan" id="kobo.503.1">create_wordcloud</span></strong><span class="kobospan" id="kobo.504.1"> function. </span><span class="kobospan" id="kobo.504.2">The function takes as arguments the text to be processed, stopwords, the filename of where to save the result, and whether to apply a mask over the image (</span><strong class="source-inline1"><span class="kobospan" id="kobo.505.1">None</span></strong><span class="kobospan" id="kobo.506.1"> by default). </span><span class="kobospan" id="kobo.506.2">It creates the </span><strong class="source-inline1"><span class="kobospan" id="kobo.507.1">WordCloud</span></strong><span class="kobospan" id="kobo.508.1"> object, saves it to the file, and then outputs the resulting plot. </span><span class="kobospan" id="kobo.508.2">The options that we provide to the </span><strong class="source-inline1"><span class="kobospan" id="kobo.509.1">WordCloud</span></strong><span class="kobospan" id="kobo.510.1"> object are the minimum font size, the maximum font size, the width and height, the maximum number of words, and the </span><span><span class="kobospan" id="kobo.511.1">background color:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.512.1">
def create_wordcloud(text, stopwords, filename, 
    apply_mask=None):
    if (apply_mask is not None):
        wordcloud = WordCloud(
            background_color="white", max_words=2000,
            mask=apply_mask, stopwords=stopwords,
            min_font_size=10, max_font_size=100)
        wordcloud.generate(text)
        wordcloud.to_file(filename)
        plt.figure()
        plt.imshow(wordcloud, interpolation='bilinear')
        plt.axis("off")
        plt.show()
    else:
        wordcloud = WordCloud(min_font_size=10,
            max_font_size=100, stopwords=stopwords,
            width=1000, height=1000, max_words=1000,
            background_color="white").generate(text)
        wordcloud.to_file(filename)
        plt.figure()
        plt.imshow(wordcloud, interpolation="bilinear")
        plt.axis("off")
        plt.show()</span></pre></li>				<li class="calibre14"><span class="kobospan" id="kobo.513.1">Run</span><a id="_idIndexMarker415" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.514.1"> the </span><strong class="source-inline1"><span class="kobospan" id="kobo.515.1">create_wordcloud</span></strong><span class="kobospan" id="kobo.516.1"> function on the text of the Sherlock </span><span><span class="kobospan" id="kobo.517.1">Holmes book:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.518.1">
create_wordcloud(text, set(STOPWORDS), 
    "../data/sherlock_wc.png")</span></pre></li>			</ol>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.519.1">This will save the result in the file located at </span><strong class="source-inline"><span class="kobospan" id="kobo.520.1">data/sherlock_wc.png</span></strong><span class="kobospan" id="kobo.521.1"> and create the visualization displayed in </span><em class="italic"><span class="kobospan" id="kobo.522.1">Figure 7.6</span></em><span class="kobospan" id="kobo.523.1"> (your results might look slightly different).</span></p>
			<div class="calibre2">
				<div id="_idContainer031" class="img---figure">
					<span class="kobospan" id="kobo.524.1"><img src="image/B18411_07_06.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.525.1">Figure 7.6 – Sherlock Holmes word cloud visualization</span></p>
			<h2 id="_idParaDest-191" class="calibre5"><a id="_idTextAnchor195" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.526.1">There’s more...</span></h2>
			<p class="calibre3"><span class="kobospan" id="kobo.527.1">We can also </span><a id="_idIndexMarker416" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.528.1">apply a mask to the word cloud. </span><span class="kobospan" id="kobo.528.2">Here, we will apply a Sherlock Holmes silhouette to the </span><span><span class="kobospan" id="kobo.529.1">word cloud:</span></span></p>
			<ol class="calibre13">
				<li class="calibre14"><span class="kobospan" id="kobo.530.1">Do the </span><span><span class="kobospan" id="kobo.531.1">additional imports:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.532.1">
import numpy as np
from PIL import Image</span></pre></li>				<li class="calibre14"><span class="kobospan" id="kobo.533.1">Read in the mask image and save it as a </span><span><strong class="source-inline1"><span class="kobospan" id="kobo.534.1">numpy</span></strong></span><span><span class="kobospan" id="kobo.535.1"> array:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.536.1">
sherlock_data = Image.open("../data/sherlock.png")
sherlock_mask = np.array(sherlock_data)</span></pre></li>				<li class="calibre14"><span class="kobospan" id="kobo.537.1">Run the function on the text of the Sherlock </span><span><span class="kobospan" id="kobo.538.1">Holmes book:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.539.1">
create_wordcloud(text, set(STOPWORDS),
    "../data/sherlock_mask.png",
    apply_mask=sherlock_mask)</span></pre></li>			</ol>
			<p class="calibre3"><span class="kobospan" id="kobo.540.1">This will save </span><a id="_idIndexMarker417" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.541.1">the result in the file located at </span><strong class="source-inline"><span class="kobospan" id="kobo.542.1">data/sherlock_mask.png</span></strong><span class="kobospan" id="kobo.543.1"> and create the visualization shown in </span><span><em class="italic"><span class="kobospan" id="kobo.544.1">Figure 7</span></em></span><em class="italic"><span class="kobospan" id="kobo.545.1">.7</span></em><span class="kobospan" id="kobo.546.1"> (your result might be </span><span><span class="kobospan" id="kobo.547.1">slightly different):</span></span></p>
			<div class="calibre2">
				<div id="_idContainer032" class="img---figure">
					<span class="kobospan" id="kobo.548.1"><img src="image/B18411_07_07.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.549.1">Figure 7.7 – Word cloud with mask</span></p>
			<h2 id="_idParaDest-192" class="calibre5"><a id="_idTextAnchor196" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.550.1">See also</span></h2>
			<p class="calibre3"><span class="kobospan" id="kobo.551.1">Please </span><a id="_idIndexMarker418" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.552.1">see the </span><strong class="source-inline"><span class="kobospan" id="kobo.553.1">wordcloud</span></strong><span class="kobospan" id="kobo.554.1"> docs, </span><a href="https://amueller.github.io/word_cloud/" class="calibre6 pcalibre pcalibre1"><span class="kobospan" id="kobo.555.1">https://amueller.github.io/word_cloud/</span></a><span class="kobospan" id="kobo.556.1">, for </span><span><span class="kobospan" id="kobo.557.1">more options.</span></span></p>
			<h1 id="_idParaDest-193" class="calibre7"><a id="_idTextAnchor197" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.558.1">Visualizing topics from Gensim</span></h1>
			<p class="calibre3"><span class="kobospan" id="kobo.559.1">In</span><a id="_idIndexMarker419" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.560.1"> this recipe, we will visualize the </span><strong class="bold"><span class="kobospan" id="kobo.561.1">Latent Dirichlet Allocation</span></strong><span class="kobospan" id="kobo.562.1"> (</span><strong class="bold"><span class="kobospan" id="kobo.563.1">LDA</span></strong><span class="kobospan" id="kobo.564.1">) topic model that we created in </span><a href="B18411_06.xhtml#_idTextAnchor156" class="calibre6 pcalibre pcalibre1"><span><em class="italic"><span class="kobospan" id="kobo.565.1">Chapter 6</span></em></span></a><span class="kobospan" id="kobo.566.1">. </span><span class="kobospan" id="kobo.566.2">The visualization will allow us to quickly see words that are most relevant to a topic and the distances</span><a id="_idIndexMarker420" class="calibre6 pcalibre pcalibre1"/> <span><span class="kobospan" id="kobo.567.1">between topics.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.568.1">After working through this recipe, you will be able to load an existing LDA model and create a visualization for its topics, both in Jupyter and saved as an </span><span><span class="kobospan" id="kobo.569.1">HTML file.</span></span></p>
			<h2 id="_idParaDest-194" class="calibre5"><a id="_idTextAnchor198" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.570.1">Getting ready</span></h2>
			<p class="calibre3"><span class="kobospan" id="kobo.571.1">We will use the </span><strong class="source-inline"><span class="kobospan" id="kobo.572.1">pyLDAvis</span></strong><span class="kobospan" id="kobo.573.1"> package to create the visualization. </span><span class="kobospan" id="kobo.573.2">It is available in the </span><strong class="source-inline"><span class="kobospan" id="kobo.574.1">poetry</span></strong><span class="kobospan" id="kobo.575.1"> environment and the </span><span><strong class="source-inline"><span class="kobospan" id="kobo.576.1">requirements.txt</span></strong></span><span><span class="kobospan" id="kobo.577.1"> file.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.578.1">We will load the model we created in </span><a href="B18411_06.xhtml#_idTextAnchor156" class="calibre6 pcalibre pcalibre1"><span><em class="italic"><span class="kobospan" id="kobo.579.1">Chapter 6</span></em></span></a><span class="kobospan" id="kobo.580.1"> and then use the </span><strong class="source-inline"><span class="kobospan" id="kobo.581.1">pyLDAvis</span></strong><span class="kobospan" id="kobo.582.1"> package to create the topic </span><span><span class="kobospan" id="kobo.583.1">model visualization.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.584.1">The notebook is located </span><span><span class="kobospan" id="kobo.585.1">at </span></span><a href="https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter07/7.6_topics_gensim.ipynb" class="calibre6 pcalibre pcalibre1"><span><span class="kobospan" id="kobo.586.1">https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook-Second-Edition/blob/main/Chapter07/7.6_topics_gensim.ipynb</span></span></a><span><span class="kobospan" id="kobo.587.1">.</span></span></p>
			<h2 id="_idParaDest-195" class="calibre5"><a id="_idTextAnchor199" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.588.1">How to do it...</span></h2>
			<ol class="calibre13">
				<li class="calibre14"><span class="kobospan" id="kobo.589.1">Import the necessary packages </span><span><span class="kobospan" id="kobo.590.1">and functions:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.591.1">
import gensim
import pyLDAvis.gensim</span></pre></li>				<li class="calibre14"><span class="kobospan" id="kobo.592.1">Define the paths to the model files. </span><span class="kobospan" id="kobo.592.2">The model was trained in </span><a href="B18411_06.xhtml#_idTextAnchor156" class="calibre6 pcalibre pcalibre1"><span><em class="italic"><span class="kobospan" id="kobo.593.1">Chapter 6</span></em></span></a><span><span class="kobospan" id="kobo.594.1">:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.595.1">
model_path = "../models/bbc_gensim/lda.model"
dict_path = "../models/bbc_gensim/id2word.dict"
corpus_path = "../models/bbc_gensim/corpus.mm"</span></pre></li>				<li class="calibre14"><span class="kobospan" id="kobo.596.1">In this step, we load the objects that these paths point to. </span><span class="kobospan" id="kobo.596.2">If you get a </span><strong class="source-inline1"><span class="kobospan" id="kobo.597.1">FileNotFoundError</span></strong><span class="kobospan" id="kobo.598.1"> error at this step, it means that you have not created the dictionary, corpus, and model files. </span><span class="kobospan" id="kobo.598.2">In that case, go back to </span><a href="B18411_06.xhtml#_idTextAnchor156" class="calibre6 pcalibre pcalibre1"><span><em class="italic"><span class="kobospan" id="kobo.599.1">Chapter 6</span></em></span></a><span class="kobospan" id="kobo.600.1">, the </span><em class="italic"><span class="kobospan" id="kobo.601.1">LDA topic modeling with Gensim</span></em><span class="kobospan" id="kobo.602.1"> recipe, and create the model and the </span><span><span class="kobospan" id="kobo.603.1">accompanying files:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.604.1">
dictionary = gensim.corpora.Dictionary.load(dict_path)
corpus = gensim.corpora.MmCorpus(corpus_path)
lda = gensim.models.ldamodel.LdaModel.load(model_path)</span></pre></li>				<li class="calibre14"><span class="kobospan" id="kobo.605.1">Here, we</span><a id="_idIndexMarker421" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.606.1"> create the </span><strong class="source-inline1"><span class="kobospan" id="kobo.607.1">PreparedData</span></strong><span class="kobospan" id="kobo.608.1"> object </span><a id="_idIndexMarker422" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.609.1">using the preceding files and save the visualization as HTML. </span><span class="kobospan" id="kobo.609.2">The object is required for the </span><span><span class="kobospan" id="kobo.610.1">visualization methods:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.611.1">
lda_prepared = pyLDAvis.gensim.prepare(lda, corpus, dictionary)
pyLDAvis.save_html(lda_prepared, '../data/lda-gensim.html')</span></pre></li>				<li class="calibre14"><span class="kobospan" id="kobo.612.1">Here, we enable the Jupyter </span><strong class="source-inline1"><span class="kobospan" id="kobo.613.1">display</span></strong><span class="kobospan" id="kobo.614.1"> option and display the visualization in the notebook. </span><span class="kobospan" id="kobo.614.2">You will see the topics and the words that are important for each topic. </span><span class="kobospan" id="kobo.614.3">To select a particular topic, hover over it with the mouse. </span><span class="kobospan" id="kobo.614.4">You will see the most important words for each topic change while hovering </span><span><span class="kobospan" id="kobo.615.1">over them:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.616.1">
pyLDAvis.enable_notebook()
pyLDAvis.display(lda_prepared)</span></pre><p class="calibre3"><span class="kobospan" id="kobo.617.1">This will create the visualization in </span><span><em class="italic"><span class="kobospan" id="kobo.618.1">Figure 7</span></em></span><em class="italic"><span class="kobospan" id="kobo.619.1">.8</span></em><span class="kobospan" id="kobo.620.1"> (your results </span><span><span class="kobospan" id="kobo.621.1">might vary):</span></span></p></li>			</ol>
			<div class="calibre2">
				<div id="_idContainer033" class="img---figure">
					<span class="kobospan" id="kobo.622.1"><img src="image/B18411_07_08.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.623.1">Figure 7.8 – LDA model visualization</span></p>
			<h2 id="_idParaDest-196" class="calibre5"><a id="_idTextAnchor200" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.624.1">See also</span></h2>
			<p class="calibre3"><span class="kobospan" id="kobo.625.1">Using </span><strong class="source-inline"><span class="kobospan" id="kobo.626.1">pyLDAvis</span></strong><span class="kobospan" id="kobo.627.1">, it is also possible to visualize models created using </span><strong class="source-inline"><span class="kobospan" id="kobo.628.1">sklearn</span></strong><span class="kobospan" id="kobo.629.1">. </span><span class="kobospan" id="kobo.629.2">See the package documentation for more </span><span><span class="kobospan" id="kobo.630.1">information: </span></span><a href="https://github.com/bmabey/pyLDAvis" class="calibre6 pcalibre pcalibre1"><span><span class="kobospan" id="kobo.631.1">https://github.com/bmabey/pyLDAvis</span></span></a><span><span class="kobospan" id="kobo.632.1">.</span></span></p>
			<h1 id="_idParaDest-197" class="calibre7"><a id="_idTextAnchor201" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.633.1">Visualizing topics from BERTopic</span></h1>
			<p class="calibre3"><span class="kobospan" id="kobo.634.1">In this</span><a id="_idIndexMarker423" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.635.1"> recipe, we </span><a id="_idIndexMarker424" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.636.1">will create and visualize a BERTopic model on the BBC data. </span><span class="kobospan" id="kobo.636.2">There are several visualizations available with the BERTopic package, and we will use several </span><span><span class="kobospan" id="kobo.637.1">of them.</span></span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.638.1">In this recipe, we will create a topic model in a similar fashion as in </span><a href="B18411_06.xhtml#_idTextAnchor156" class="calibre6 pcalibre pcalibre1"><span><em class="italic"><span class="kobospan" id="kobo.639.1">Chapter 6</span></em></span></a><span class="kobospan" id="kobo.640.1">, in the </span><em class="italic"><span class="kobospan" id="kobo.641.1">Topic modeling using BERTopic</span></em><span class="kobospan" id="kobo.642.1"> recipe. </span><span class="kobospan" id="kobo.642.2">However, unlike in </span><a href="B18411_06.xhtml#_idTextAnchor156" class="calibre6 pcalibre pcalibre1"><span><em class="italic"><span class="kobospan" id="kobo.643.1">Chapter 6</span></em></span></a><span class="kobospan" id="kobo.644.1">, we will not limit the number</span><a id="_idIndexMarker425" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.645.1"> of topics created, and resulting in more </span><a id="_idIndexMarker426" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.646.1">than the 5 original topics in the data. </span><span class="kobospan" id="kobo.646.2">It will allow for more </span><span><span class="kobospan" id="kobo.647.1">interesting visualizations.</span></span></p>
			<h2 id="_idParaDest-198" class="calibre5"><a id="_idTextAnchor202" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.648.1">Getting ready</span></h2>
			<p class="calibre3"><span class="kobospan" id="kobo.649.1">We will use the </span><strong class="source-inline"><span class="kobospan" id="kobo.650.1">BERTopic</span></strong><span class="kobospan" id="kobo.651.1"> package to create the visualization. </span><span class="kobospan" id="kobo.651.2">It is available in the </span><span><strong class="source-inline"><span class="kobospan" id="kobo.652.1">poetry</span></strong></span><span><span class="kobospan" id="kobo.653.1"> environment.</span></span></p>
			<h2 id="_idParaDest-199" class="calibre5"><a id="_idTextAnchor203" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.654.1">How to do it...</span></h2>
			<ol class="calibre13">
				<li class="calibre14"><span class="kobospan" id="kobo.655.1">Import the necessary packages </span><span><span class="kobospan" id="kobo.656.1">and functions:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.657.1">
import pandas as pd
import numpy as np
from bertopic import BERTopic
from bertopic.representation import KeyBERTInspired</span></pre></li>				<li class="calibre14"><span class="kobospan" id="kobo.658.1">Run the language </span><span><span class="kobospan" id="kobo.659.1">utilities file:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.660.1">
%run -i "../util/lang_utils.ipynb"</span></pre></li>				<li class="calibre14"><span class="kobospan" id="kobo.661.1">Read in </span><span><span class="kobospan" id="kobo.662.1">the data:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.663.1">
bbc_df = pd.read_csv("../data/bbc-text.csv")</span></pre></li>				<li class="calibre14"><span class="kobospan" id="kobo.664.1">Here, we </span><a id="_idIndexMarker427" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.665.1">create a list of training documents from the dataframe object. </span><span class="kobospan" id="kobo.665.2">We then initialize a representation model object. </span><span class="kobospan" id="kobo.665.3">Here, we use the </span><strong class="source-inline1"><span class="kobospan" id="kobo.666.1">KeyBERTInspired</span></strong><span class="kobospan" id="kobo.667.1"> object, which uses BERT to extract </span><span><span class="kobospan" id="kobo.668.1">the keywords.</span></span><p class="calibre3"><span class="kobospan" id="kobo.669.1">This object creates the names (representations) for the topics; it does a better job than the default version, which contains lots of stopwords. </span><span class="kobospan" id="kobo.669.2">We then create the main topic model object and fit it to the document set. </span><span class="kobospan" id="kobo.669.3">In this recipe, in contrast to the </span><em class="italic"><span class="kobospan" id="kobo.670.1">Topic modeling using BERTopic</span></em><span class="kobospan" id="kobo.671.1"> recipe in </span><a href="B18411_06.xhtml#_idTextAnchor156" class="calibre6 pcalibre pcalibre1"><span><em class="italic"><span class="kobospan" id="kobo.672.1">Chapter 6</span></em></span></a><span class="kobospan" id="kobo.673.1">, we do not place limits on the number of created topics. </span><span class="kobospan" id="kobo.673.2">This will create a lot </span><span><span class="kobospan" id="kobo.674.1">more topics:</span></span></p><pre class="source-code"><span class="kobospan1" id="kobo.675.1">
docs = bbc_df["text"].values
representation_model = KeyBERTInspired()
topic_model = BERTopic(
    representation_model=representation_model)
topics, probs = topic_model.fit_transform(docs)</span></pre></li>				<li class="calibre14"><span class="kobospan" id="kobo.676.1">In this step, we </span><a id="_idIndexMarker428" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.677.1">display the general topic </span><a id="_idIndexMarker429" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.678.1">visualization. </span><span class="kobospan" id="kobo.678.2">It shows all 42 topics created. </span><span class="kobospan" id="kobo.678.3">If you hover on each circle, you will see the topic representation or name. </span><span class="kobospan" id="kobo.678.4">The representations consist of the top five words in </span><span><span class="kobospan" id="kobo.679.1">the topic:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.680.1">
topic_model.visualize_topics()</span></pre><p class="calibre3"><span class="kobospan" id="kobo.681.1">This will create the visualization in </span><span><em class="italic"><span class="kobospan" id="kobo.682.1">Figure 7</span></em></span><em class="italic"><span class="kobospan" id="kobo.683.1">.9</span></em><span class="kobospan" id="kobo.684.1"> (your results </span><span><span class="kobospan" id="kobo.685.1">might vary).</span></span></p></li>			</ol>
			<div class="calibre2">
				<div id="_idContainer034" class="img---figure">
					<span class="kobospan" id="kobo.686.1"><img src="image/B18411_07_09.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.687.1">Figure 7.9 – BERTopic model visualization</span></p>
			<ol class="calibre13">
				<li value="6" class="calibre14"><span class="kobospan" id="kobo.688.1">Here, we</span><a id="_idIndexMarker430" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.689.1"> create a visualization of the topic hierarchy. </span><span class="kobospan" id="kobo.689.2">This</span><a id="_idIndexMarker431" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.690.1"> hierarchy clusters the different topics together if they are related. </span><span class="kobospan" id="kobo.690.2">We first create the hierarchy by using the </span><strong class="source-inline1"><span class="kobospan" id="kobo.691.1">hierarchical_topics</span></strong><span class="kobospan" id="kobo.692.1"> function of the topic model object, and then pass it into the </span><strong class="source-inline1"><span class="kobospan" id="kobo.693.1">visualize_hierarchy</span></strong><span class="kobospan" id="kobo.694.1"> function. </span><span class="kobospan" id="kobo.694.2">The nodes that combine the different topics have their own names that you can see if you hover </span><span><span class="kobospan" id="kobo.695.1">over them:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.696.1">
hierarchical_topics = topic_model.hierarchical_topics(
    bbc_df["text"])
topic_model.visualize_hierarchy(
    hierarchical_topics=hierarchical_topics)</span></pre><p class="calibre3"><span class="kobospan" id="kobo.697.1">This will create the visualization in </span><span><em class="italic"><span class="kobospan" id="kobo.698.1">Figure 7</span></em></span><span><em class="italic"><span class="kobospan" id="kobo.699.1">.10</span></em></span><span><span class="kobospan" id="kobo.700.1">.</span></span></p></li>			</ol>
			<div class="calibre2">
				<div id="_idContainer035" class="img---figure">
					<span class="kobospan" id="kobo.701.1"><img src="image/B18411_07_10.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.702.1">Figure 7.10 – BERTopic hierarchical visualization</span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.703.1">If you hover over the nodes, you will see </span><span><span class="kobospan" id="kobo.704.1">their names.</span></span></p>
			<ol class="calibre13">
				<li value="7" class="calibre14"><span class="kobospan" id="kobo.705.1">In this step, we </span><a id="_idIndexMarker432" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.706.1">create a bar chart with the top words for the topics. </span><span class="kobospan" id="kobo.706.2">We specify the </span><a id="_idIndexMarker433" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.707.1">number of topics to show by using the </span><strong class="source-inline1"><span class="kobospan" id="kobo.708.1">top_n_topics</span></strong><span class="kobospan" id="kobo.709.1"> argument that the </span><strong class="source-inline1"><span class="kobospan" id="kobo.710.1">visualize_barchart</span></strong><span class="kobospan" id="kobo.711.1"> function of the topic model </span><span><span class="kobospan" id="kobo.712.1">object takes:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.713.1">
topic_model.visualize_barchart(top_n_topics=15)</span></pre><p class="calibre3"><span class="kobospan" id="kobo.714.1">This will create a visualization similar </span><span><span class="kobospan" id="kobo.715.1">to this:</span></span></p></li>			</ol>
			<div class="calibre2">
				<div id="_idContainer036" class="img---figure">
					<span class="kobospan" id="kobo.716.1"><img src="image/B18411_07_11.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.717.1">Figure 7.11 – BERTopic word scores</span></p>
			<ol class="calibre13">
				<li value="8" class="calibre14"><span class="kobospan" id="kobo.718.1">Here, we </span><a id="_idIndexMarker434" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.719.1">create a visualization of individual </span><a id="_idIndexMarker435" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.720.1">documents in the training set. </span><span class="kobospan" id="kobo.720.2">We provide the list of documents created in </span><em class="italic"><span class="kobospan" id="kobo.721.1">step 4</span></em><span class="kobospan" id="kobo.722.1"> to the </span><strong class="source-inline1"><span class="kobospan" id="kobo.723.1">visualize_documents</span></strong><span class="kobospan" id="kobo.724.1"> function. </span><span class="kobospan" id="kobo.724.2">It clusters the documents</span><a id="_idIndexMarker436" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.725.1"> to the topics. </span><span class="kobospan" id="kobo.725.2">You can see the documents if you hover over the</span><a id="_idIndexMarker437" class="calibre6 pcalibre pcalibre1"/> <span><span class="kobospan" id="kobo.726.1">individual circles:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.727.1">
topic_model.visualize_documents(docs)</span></pre><p class="calibre3"><span class="kobospan" id="kobo.728.1">The result will be a visualization similar </span><span><span class="kobospan" id="kobo.729.1">to this:</span></span></p></li>			</ol>
			<div class="calibre2">
				<div id="_idContainer037" class="img---figure">
					<span class="kobospan" id="kobo.730.1"><img src="image/B18411_07_12.jpg" alt="" role="presentation" class="calibre4"/></span>
				</div>
			</div>
			<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.731.1">Figure 7.12 – BERTopic document visualization</span></p>
			<p class="calibre3"><span class="kobospan" id="kobo.732.1">If you hover over the nodes, you will see the text of the </span><span><span class="kobospan" id="kobo.733.1">individual documents.</span></span></p>
			<h2 id="_idParaDest-200" class="calibre5"><a id="_idTextAnchor204" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.734.1">See also</span></h2>
			<ul class="calibre15">
				<li class="calibre14"><span class="kobospan" id="kobo.735.1">There are additional </span><a id="_idIndexMarker438" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.736.1">visualization tools available through BERTopic. </span><span class="kobospan" id="kobo.736.2">See the package documentation for more </span><span><span class="kobospan" id="kobo.737.1">information: </span></span><a href="https://maartengr.github.io/BERTopic/index.html" class="calibre6 pcalibre pcalibre1"><span><span class="kobospan" id="kobo.738.1">https://maartengr.github.io/BERTopic/index.html</span></span></a><span><span class="kobospan" id="kobo.739.1">.</span></span></li>
				<li class="calibre14"><span class="kobospan" id="kobo.740.1">To learn</span><a id="_idIndexMarker439" class="calibre6 pcalibre pcalibre1"/><span class="kobospan" id="kobo.741.1"> more about </span><strong class="source-inline1"><span class="kobospan" id="kobo.742.1">KeyBERTInspired</span></strong><span class="kobospan" id="kobo.743.1">, </span><span><span class="kobospan" id="kobo.744.1">see </span></span><a href="https://maartengr.github.io/BERTopic/api/representation/keybert.html" class="calibre6 pcalibre pcalibre1"><span><span class="kobospan" id="kobo.745.1">https://maartengr.github.io/BERTopic/api/representation/keybert.html</span></span></a><span><span class="kobospan" id="kobo.746.1">.</span></span></li>
			</ul>
		</div>
	</body></html>