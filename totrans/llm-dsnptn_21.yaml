- en: '21'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Tree-of-Thoughts Prompting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Tree-of-thoughts** (**ToT**) prompting is a technique that was developed
    to enhance the problem-solving capabilities of LLMs by enabling more structured
    exploration of different reasoning paths.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The formal ToT approach was introduced in a 2023 research paper titled *Tree
    of Thoughts: Deliberate Problem Solving with Large Language Models* by Yao et
    al. (researchers from Princeton University, Google DeepMind, and Google Research).
    Also visit [https://arxiv.org/abs/2305.10601](https://arxiv.org/abs/2305.10601).'
  prefs: []
  type: TYPE_NORMAL
- en: The primary inspiration for ToT came from how humans approach complex problems—we
    often consider multiple possible solution paths, evaluate their promise, backtrack
    when necessary, and explore alternatives. Traditional prompting techniques such
    as CoT (see [*Chapter 20*](B31249_20.xhtml#_idTextAnchor305)) allowed step-by-step
    reasoning but lacked the ability to explore multiple paths or reconsider earlier
    steps.
  prefs: []
  type: TYPE_NORMAL
- en: 'ToT builds on several techniques:'
  prefs: []
  type: TYPE_NORMAL
- en: CoT prompting, which enables step-by-step reasoning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Self-consistency methods that generate multiple reasoning paths
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Human problem-solving approaches that involve exploration and backtracking
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The key innovation of ToT is treating thinking as a tree search problem, where
    at each step, the model can generate and evaluate multiple “thoughts” (intermediate
    reasoning steps) and then select the most promising paths to continue exploring.
    This allows for more sophisticated problem-solving that includes exploration,
    evaluation, and backtracking capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, you’ll learn how to implement ToT prompting to tackle complex
    reasoning tasks with your LLMs.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’ll be covering the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Designing ToT prompts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Search strategies
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pruning and evaluation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applying ToT to solve a multi-step problem
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Challenges in implementation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Future directions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Designing ToT prompts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To create effective ToT prompts, you should do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Encourage branching thoughts**: This creates a non-linear exploration process
    where multiple possible solution paths can be considered simultaneously. By explicitly
    asking the model to generate several different initial approaches or perspectives,
    you prevent it from committing too early to a single line of reasoning that might
    lead to suboptimal results.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Provide a clear problem statement**: A well-defined problem statement gives
    the model a concrete goal and constraints to work within. This clarity helps the
    model understand exactly what it needs to solve and provides the foundation for
    generating relevant thought branches. Without this, the branching process could
    become unfocused and inefficient.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Guide the model to explore alternative paths**: This ensures the model doesn’t
    prematurely converge on an apparently promising but ultimately suboptimal solution.
    By explicitly requesting the exploration of different approaches, you help the
    model overcome potential bias in its reasoning and discover novel solutions it
    might otherwise miss.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Include evaluation mechanisms**: This component enables the model to assess
    the quality of different branches and make informed decisions about which paths
    to pursue further. Without evaluation criteria, the model would have no systematic
    way to determine which branches are most promising, potentially wasting computational
    resources on unpromising paths.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: ToT is particularly powerful for complex reasoning tasks because it mimics human
    problem-solving approaches where we often mentally explore multiple possibilities
    before committing to a solution. The explicit branching and evaluation structure
    helps language models overcome limitations in their sequential reasoning abilities.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s an example of implementing a basic ToT prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: This function generates a ToT prompt for a given problem (`"What is the most
    efficient way to sort a list of a million integers?"`), providing a structure
    for exploring and evaluating multiple reasoning paths.
  prefs: []
  type: TYPE_NORMAL
- en: 'This code creates a ToT prompt template by implementing four key principles:
    it encourages branching thoughts through explicit path structures with different
    starting phrases and numbered steps, ensuring the model explores multiple distinct
    solution approaches; it provides clarity by framing the problem twice to establish
    context and refocus attention before solution generation; it guides exploration
    of alternative approaches through contrasting language and separate reasoning
    paths; and it facilitates evaluation through a dedicated comparison section with
    prompts for selecting the most promising solution. The overall structure creates
    a cognitive scaffold that helps language models overcome linear thinking tendencies
    by forcing them to generate, develop, and critically compare multiple solution
    paths before reaching a conclusion—mimicking how humans tackle complex problems
    through divergent thinking followed by critical evaluation.'
  prefs: []
  type: TYPE_NORMAL
- en: Implementing effective search strategies is crucial for navigating the ToT.
    Let’s check out two of them in the following section.
  prefs: []
  type: TYPE_NORMAL
- en: Search strategies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We have two commonly used search strategies:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Depth-first search (DFS)**: This is a graph traversal algorithm that explores
    as far as possible along each branch before backtracking. In the context of a
    tree of thoughts, DFS systematically dives deep into one path, exploring each
    thought or branch completely before moving to the next. It works by starting at
    the root, pushing each node’s children onto a stack, and then recursively exploring
    the deepest node first. This approach is particularly useful when you want to
    fully explore a line of reasoning or investigate the most profound or complex
    thoughts before branching out, making it valuable for problem-solving, decision-making,
    and understanding complex conceptual landscapes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Breadth-first search (BFS)**: In contrast to DFS, BFS explores the tree of
    thoughts by systematically examining all neighboring nodes at the present depth
    before moving to nodes at the next depth level. Using a queue data structure,
    BFS starts at the root and explores all immediate connections before going deeper.
    In the context of thought exploration, BFS is particularly effective when you
    want to get a broad, panoramic view of different ideas and their immediate interconnections.
    This strategy is ideal for understanding the width and diversity of thoughts,
    finding the shortest path between concepts, or when you need to explore multiple
    potential reasoning paths simultaneously before diving deep into any single branch
    (see *Figure 21**.1*).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 21.1 – DFS versus BFS](img/Image96457.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 21.1 – DFS versus BFS
  prefs: []
  type: TYPE_NORMAL
- en: 'As an example, let’s implement a simple DFS strategy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: This code implements a DFS algorithm to explore a ToT generated by a language
    model. It starts with an initial problem and then uses the model to generate multiple
    potential continuations (branches). The code recursively explores each branch,
    extending the “thought” until it reaches a maximum depth. At each step, generated
    text is turned into model inputs, and the model outputs are decoded back into
    text.
  prefs: []
  type: TYPE_NORMAL
- en: The `evaluate_thought` function, which is a key part of the selection process,
    is intended to score the quality of each generated thought. The code utilizes
    this scoring to decide which branches to explore further, effectively navigating
    the ToT toward a potentially optimal solution. The final result is the highest-scoring
    thought found during the DFS.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s an example usage of the preceding code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: This code snippet demonstrates how to use a pre-trained GPT-2 LLM to generate
    a solution to a given problem using the previously described `dfs_tot` function.
    First, it specifies the model to be used (`"gpt2-large"`) and loads both the model
    and its associated tokenizer using `AutoModelForCausalLM` and `AutoTokenizer`
    from the `transformers` library. This ensures the text is correctly processed
    for the model.
  prefs: []
  type: TYPE_NORMAL
- en: Then, it defines the problem as a question about the long-term effects of AI
    on employment. The `dfs_tot` function is called with the loaded model, tokenizer,
    and the problem as input, initiating the depth-first search for a solution. The
    returned `solution`, which represents the model’s generated response after exploring
    various “thoughts”, is finally printed to the console.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will discuss pruning and evaluation within the ToT framework to improve
    efficiency and focus the search. Pruning is essential for managing the computational
    cost associated with exploring numerous thought branches, while evaluation provides
    the criteria for deciding which branches to discard.
  prefs: []
  type: TYPE_NORMAL
- en: Pruning and evaluation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Pruning in the ToT approach is an effective mechanism for managing cognitive
    complexity by systematically reducing the search space. The process involves selectively
    eliminating less promising thought branches through intelligent evaluation techniques,
    using heuristic scoring methods that assess each potential path’s likelihood of
    leading to an optimal solution. By dynamically filtering out low-potential thoughts
    and focusing computational resources on the most promising reasoning trajectories,
    ToT pruning enables more efficient and targeted problem solving, balancing exploration
    breadth with reasoning depth.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s implement a basic pruning strategy by defining a simple pruning function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The core of the logic is in the `explore_and_prune` function, which handles
    the recursive search through the reasoning tree. The code works by generating
    multiple possible continuations (branches) from the current thought using LLM.
    The function is designed to explore the reasoning tree up to a specified maximum
    depth, with each level containing a controlled number of branches. When the maximum
    depth is reached, the code returns the current thought as the final result. The
    pruning mechanism is illustrative and should not be used for production.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Once we’ve defined our function, we evaluate and prune branches:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: First, the code evaluates each generated branch by pairing it with a score from
    the `evaluate_thought` function, which assesses the quality of the reasoning path.
    It then filters out low-quality branches by keeping only those scoring above the
    defined threshold. If all branches are pruned (none meet the threshold), the algorithm
    returns the current thought without further exploration. For the remaining promising
    branches, the code recursively explores each one by calling the same function
    at an increased depth level. Finally, it selects the best overall reasoning path
    by returning the result with the highest evaluation score from all explored paths.
    The outer function initializes the search with a formatted prompt containing the
    original problem statement.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Define an `evaluate_thought` function. This function evaluates a given thought
    or branch of reasoning by scoring it based on its complexity (length) and linguistic
    diversity (the number of unique words used), returning a normalized score between
    `0` and `1`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s look at an example:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This implementation adds a pruning step to remove low-quality branches, focusing
    the search on the most promising paths.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s apply ToT to solve a multi-step problem.
  prefs: []
  type: TYPE_NORMAL
- en: Applying ToT to solve a multi-step problem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'ToT can be particularly effective for complex reasoning tasks. Let’s implement
    a ToT approach for multi-step problem solving:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: This code implements a multi-step problem solver using the ToT reasoning approach.
    The `multi_step_tot` function breaks down complex problems into sequential steps
    and solves them one at a time, building upon previous solutions.
  prefs: []
  type: TYPE_NORMAL
- en: For each step in the provided problem sequence, the function creates a prompt
    that includes the current question, the accumulated solutions from previous steps,
    and instructions to use ToT reasoning. It then calls the previously defined `pruning_tot`
    function to generate a solution for that specific step. Each step’s solution is
    appended to a growing `full_solution` string, creating a comprehensive answer
    that maintains continuity of thought across the entire problem. The example demonstrates
    how this approach could be applied to analyze climate change through a sequence
    of progressively deeper questions, from identifying causes to exploring implementation
    challenges of potential solutions.
  prefs: []
  type: TYPE_NORMAL
- en: Challenges in implementation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'While powerful, ToT faces several challenges:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Computational complexity**: Exploring multiple paths can be computationally
    expensive'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Evaluation difficulty**: Determining the quality of different thought paths
    can be challenging'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Coherence across branches**: Ensuring consistency when combining insights
    from different branches'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Prompt design complexity**: Creating effective ToT prompts requires careful
    consideration'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To address the computational complexity, consider implementing a parallel processing
    approach. Parallel processing can improve the ToT reasoning approach by addressing
    its inherent computational bottlenecks. The following code implements concurrent
    exploration of multiple reasoning branches simultaneously rather than sequentially,
    which can dramatically reduce the total computation time for complex problems:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code, the implementation uses Python’s `concurrent.futures`
    module with a `ThreadPoolExecutor` to distribute the workload across multiple
    workers. Each worker independently explores a different initial branch of the
    reasoning tree, effectively searching multiple promising paths in parallel. This
    approach is particularly valuable for ToT reasoning since the branching nature
    of the algorithm creates numerous independent subproblems that can be solved concurrently
    without dependencies on each other’s intermediate results. The final step consolidates
    these parallel explorations by selecting the highest-quality solution from all
    completed branches.
  prefs: []
  type: TYPE_NORMAL
- en: This implementation uses parallel processing to explore multiple branches simultaneously,
    potentially reducing computation time for complex ToT problems.
  prefs: []
  type: TYPE_NORMAL
- en: Future directions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As ToT continues to evolve, several promising directions emerge:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Dynamic tree structures**: Adapting the tree structure based on the problem
    complexity.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Hybrid ToT-CoT approaches**: Combining the strengths of both techniques ([https://arxiv.org/html/2409.17433v1](https://arxiv.org/html/2409.17433v1)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Meta-learning for ToT**: Training LLMs to generate effective ToT structures
    automatically. This approach has not been explored by anyone yet.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Incorporating external knowledge**: Integrating domain-specific knowledge
    into ToT reasoning ([https://arxiv.org/html/2407.00653v1](https://arxiv.org/html/2407.00653v1)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here’s a conceptual implementation of a dynamic ToT structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code implements a dynamic ToT approach that adapts its exploration
    strategy based on the complexity of the current reasoning path. The core function
    `adapt_structure` recursively builds a solution by examining the complexity of
    the current thought at each step and dynamically determining how many branches
    to explore. Unlike fixed branching strategies, this adaptive approach allocates
    more computational resources (more branches) to complex reasoning paths that might
    benefit from broader exploration, while using fewer branches for simpler concepts.
    The implementation includes helper functions to assess thought complexity, determine
    the appropriate number of branches, and generate new thought continuations using
    the language model. The algorithm terminates when reaching the maximum depth and
    returns the highest-scoring complete reasoning path.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s an example of how to use the preceding code to solve a problem such
    as “`How might advancements in nanotechnology impact medicine in the` `next decade?`”:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: This dynamic ToT approach adapts the tree structure based on the assessed complexity
    of each thought, allowing the more flexible and efficient exploration of complex
    problem spaces.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned how to design and implement ToT prompts for LLMs,
    including strategies for managing the branching thought processes. We covered
    search techniques and methods for pruning and evaluating different reasoning paths.
    By implementing the strategies and considerations discussed here, you can significantly
    enhance your LLM’s ability to handle ambiguous, multi-faceted problems and generate
    more robust and insightful solutions.
  prefs: []
  type: TYPE_NORMAL
- en: Revisiting [*Chapter 20*](B31249_20.xhtml#_idTextAnchor305), which focuses on
    CoT, let’s compare CoT and ToT from a use case perspective. Use CoT prompting
    when the task involves linear, sequential reasoning that can be decomposed into
    intermediate steps with a single, dominant solution path. CoT is particularly
    effective in math word problems, deductive reasoning, basic logical puzzles, and
    step-by-step procedural tasks. It works well when the problem has low branching
    complexity and does not require exploration of multiple alternatives. CoT is computationally
    cheaper because it produces a single chain of reasoning in a forward, deterministic
    manner. This technique is most helpful when the LLM needs a scaffold to “think
    aloud” and make its intermediate steps explicit to prevent hallucinations or faulty
    leaps in logic.
  prefs: []
  type: TYPE_NORMAL
- en: Use ToT prompting when the task involves multi-step reasoning with branching
    decision points, especially where multiple solution paths are possible and need
    to be evaluated in parallel. ToT is suited for creative problem-solving, planning
    tasks, theorem proving, code synthesis, and decision-making under uncertainty.
    It becomes advantageous when the problem space can be structured as a search tree,
    where intermediate reasoning nodes can be revisited, evaluated, and compared.
    ToT often incorporates strategies such as self-consistency sampling, lookahead
    evaluation, and value-based selection among branches. It is computationally more
    intensive because it maintains and expands multiple reasoning paths in parallel,
    potentially involving rollouts, backtracking, or node scoring.
  prefs: []
  type: TYPE_NORMAL
- en: If the problem is constrained and well-formed (e.g., SAT-style questions or
    straightforward derivations), CoT is usually sufficient and more efficient. If
    the problem is open-ended, has multiple conflicting goals, or if optimal solutions
    require comparing alternative paths (as in planning routes, game moves, or formal
    proofs), ToT yields better performance by simulating exploration and deliberation.
  prefs: []
  type: TYPE_NORMAL
- en: In practice, CoT can serve as a base technique, while ToT builds on it by orchestrating
    multiple chains. For example, ToT nodes may each use CoT internally to generate
    coherent thoughts. Therefore, the two are not mutually exclusive but hierarchically
    related in terms of complexity and structure.
  prefs: []
  type: TYPE_NORMAL
- en: In the upcoming chapter, we will explore the **Reasoning and Acting** (**ReAct**)
    pattern, which is commonly used in many agentic AI applications.
  prefs: []
  type: TYPE_NORMAL
