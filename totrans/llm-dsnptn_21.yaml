- en: '21'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '21'
- en: Tree-of-Thoughts Prompting
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 思维树（Tree-of-Thoughts）提示
- en: '**Tree-of-thoughts** (**ToT**) prompting is a technique that was developed
    to enhance the problem-solving capabilities of LLMs by enabling more structured
    exploration of different reasoning paths.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**思维树（Tree-of-thoughts**）(**ToT**)提示是一种技术，旨在通过允许对不同的推理路径进行更结构化的探索来增强LLMs的解决问题能力。'
- en: 'The formal ToT approach was introduced in a 2023 research paper titled *Tree
    of Thoughts: Deliberate Problem Solving with Large Language Models* by Yao et
    al. (researchers from Princeton University, Google DeepMind, and Google Research).
    Also visit [https://arxiv.org/abs/2305.10601](https://arxiv.org/abs/2305.10601).'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '正式的ToT方法是在2023年的一篇名为《Tree of Thoughts: Deliberate Problem Solving with Large
    Language Models》的研究论文中由姚等人（来自普林斯顿大学、谷歌DeepMind和谷歌研究）提出的。也请访问[https://arxiv.org/abs/2305.10601](https://arxiv.org/abs/2305.10601)。'
- en: The primary inspiration for ToT came from how humans approach complex problems—we
    often consider multiple possible solution paths, evaluate their promise, backtrack
    when necessary, and explore alternatives. Traditional prompting techniques such
    as CoT (see [*Chapter 20*](B31249_20.xhtml#_idTextAnchor305)) allowed step-by-step
    reasoning but lacked the ability to explore multiple paths or reconsider earlier
    steps.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ToT的主要灵感来源于人类处理复杂问题的方法——我们经常考虑多个可能的解决方案路径，评估它们的可行性，在必要时回溯，并探索替代方案。传统的提示技术，如CoT（见[*第20章*](B31249_20.xhtml#_idTextAnchor305)），允许逐步推理，但缺乏探索多条路径或重新考虑早期步骤的能力。
- en: 'ToT builds on several techniques:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ToT建立在几个技术之上：
- en: CoT prompting, which enables step-by-step reasoning
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CoT提示，实现逐步推理
- en: Self-consistency methods that generate multiple reasoning paths
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成多个推理路径的自洽方法
- en: Human problem-solving approaches that involve exploration and backtracking
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 涉及探索和回溯的人类问题解决方法
- en: The key innovation of ToT is treating thinking as a tree search problem, where
    at each step, the model can generate and evaluate multiple “thoughts” (intermediate
    reasoning steps) and then select the most promising paths to continue exploring.
    This allows for more sophisticated problem-solving that includes exploration,
    evaluation, and backtracking capabilities.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ToT的关键创新是将思维视为一个树搜索问题，在每一步中，模型可以生成和评估多个“思维”（中间推理步骤），然后选择最有希望的路径继续探索。这允许更复杂的解决问题，包括探索、评估和回溯的能力。
- en: In this chapter, you’ll learn how to implement ToT prompting to tackle complex
    reasoning tasks with your LLMs.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将学习如何实现ToT提示来处理你的LLMs的复杂推理任务。
- en: 'In this chapter, we’ll be covering the following topics:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Designing ToT prompts
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计ToT提示
- en: Search strategies
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 搜索策略
- en: Pruning and evaluation
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 剪枝和评估
- en: Applying ToT to solve a multi-step problem
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将ToT应用于解决多步问题
- en: Challenges in implementation
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实施中的挑战
- en: Future directions
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 未来方向
- en: Designing ToT prompts
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设计ToT提示
- en: 'To create effective ToT prompts, you should do the following:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建有效的ToT提示，你应该做以下事情：
- en: '**Encourage branching thoughts**: This creates a non-linear exploration process
    where multiple possible solution paths can be considered simultaneously. By explicitly
    asking the model to generate several different initial approaches or perspectives,
    you prevent it from committing too early to a single line of reasoning that might
    lead to suboptimal results.'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**鼓励分支思维**：这创建了一个非线性的探索过程，其中可以同时考虑多个可能的解决方案路径。通过明确要求模型生成几个不同的初始方法或视角，你可以防止它过早地承诺于一条可能导致次优结果的推理路线。'
- en: '**Provide a clear problem statement**: A well-defined problem statement gives
    the model a concrete goal and constraints to work within. This clarity helps the
    model understand exactly what it needs to solve and provides the foundation for
    generating relevant thought branches. Without this, the branching process could
    become unfocused and inefficient.'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**提供清晰的问题陈述**：一个明确定义的问题陈述为模型提供了一个具体的目标和约束条件，使其在其中工作。这种清晰度有助于模型确切了解它需要解决的问题，并为生成相关的思维分支提供了基础。没有这个，分支过程可能会变得不集中且效率低下。'
- en: '**Guide the model to explore alternative paths**: This ensures the model doesn’t
    prematurely converge on an apparently promising but ultimately suboptimal solution.
    By explicitly requesting the exploration of different approaches, you help the
    model overcome potential bias in its reasoning and discover novel solutions it
    might otherwise miss.'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**引导模型探索替代路径**：这确保模型不会过早地收敛到一个看似有希望但实际上次优的解决方案。通过明确要求探索不同的方法，你帮助模型克服推理中的潜在偏见，并发现它可能错过的创新解决方案。'
- en: '**Include evaluation mechanisms**: This component enables the model to assess
    the quality of different branches and make informed decisions about which paths
    to pursue further. Without evaluation criteria, the model would have no systematic
    way to determine which branches are most promising, potentially wasting computational
    resources on unpromising paths.'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**包含评估机制**：这个组件使模型能够评估不同分支的质量，并就进一步追求哪些路径做出明智的决定。没有评估标准，模型将没有系统的方法来确定哪些分支最有希望，可能会在无望的路径上浪费计算资源。'
- en: ToT is particularly powerful for complex reasoning tasks because it mimics human
    problem-solving approaches where we often mentally explore multiple possibilities
    before committing to a solution. The explicit branching and evaluation structure
    helps language models overcome limitations in their sequential reasoning abilities.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: ToT对于复杂的推理任务特别强大，因为它模仿了人类解决问题的方法，我们在做出解决方案之前通常会在心理上探索多种可能性。显式的分支和评估结构有助于语言模型克服其在顺序推理能力上的局限性。
- en: 'Here’s an example of implementing a basic ToT prompt:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个实现基本ToT提示的示例：
- en: '[PRE0]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This function generates a ToT prompt for a given problem (`"What is the most
    efficient way to sort a list of a million integers?"`), providing a structure
    for exploring and evaluating multiple reasoning paths.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数为给定问题（`"What is the most efficient way to sort a list of a million integers?"`）生成一个ToT提示，为探索和评估多个推理路径提供结构。
- en: 'This code creates a ToT prompt template by implementing four key principles:
    it encourages branching thoughts through explicit path structures with different
    starting phrases and numbered steps, ensuring the model explores multiple distinct
    solution approaches; it provides clarity by framing the problem twice to establish
    context and refocus attention before solution generation; it guides exploration
    of alternative approaches through contrasting language and separate reasoning
    paths; and it facilitates evaluation through a dedicated comparison section with
    prompts for selecting the most promising solution. The overall structure creates
    a cognitive scaffold that helps language models overcome linear thinking tendencies
    by forcing them to generate, develop, and critically compare multiple solution
    paths before reaching a conclusion—mimicking how humans tackle complex problems
    through divergent thinking followed by critical evaluation.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码通过实现四个关键原则创建一个ToT提示模板：它通过具有不同起始短语和编号步骤的显式路径结构鼓励分支思维，确保模型探索多个不同的解决方案方法；它通过两次阐述问题来提供清晰度，以建立上下文并在生成解决方案之前重新聚焦注意力；它通过对比语言和独立的推理路径引导探索替代方法；并通过一个专门的比较部分以及选择最有希望解决方案的提示来促进评估。整体结构创建了一个认知支架，通过迫使模型在得出结论之前生成、发展和批判性地比较多个解决方案路径，帮助语言模型克服线性思维倾向——模仿人类通过发散性思维后进行批判性评估来解决复杂问题的方法。
- en: Implementing effective search strategies is crucial for navigating the ToT.
    Let’s check out two of them in the following section.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 实施有效的搜索策略对于导航ToT至关重要。让我们在下一节中检查其中两种策略。
- en: Search strategies
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 搜索策略
- en: 'We have two commonly used search strategies:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有两种常用的搜索策略：
- en: '**Depth-first search (DFS)**: This is a graph traversal algorithm that explores
    as far as possible along each branch before backtracking. In the context of a
    tree of thoughts, DFS systematically dives deep into one path, exploring each
    thought or branch completely before moving to the next. It works by starting at
    the root, pushing each node’s children onto a stack, and then recursively exploring
    the deepest node first. This approach is particularly useful when you want to
    fully explore a line of reasoning or investigate the most profound or complex
    thoughts before branching out, making it valuable for problem-solving, decision-making,
    and understanding complex conceptual landscapes.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**深度优先搜索 (DFS)**：这是一种图遍历算法，在回溯之前尽可能沿着每个分支进行探索。在思维树的情况下，DFS 系统性地深入一条路径，在移动到下一条路径之前，完全探索每个思想或分支。它通过从根节点开始，将每个节点的子节点推入栈中，然后递归地首先探索最深的节点来工作。这种方法在你想要全面探索一条推理线或调查最深刻或复杂的思想之前，非常适合在分支出来之前，对于问题解决、决策制定和理解复杂概念景观非常有价值。'
- en: '**Breadth-first search (BFS)**: In contrast to DFS, BFS explores the tree of
    thoughts by systematically examining all neighboring nodes at the present depth
    before moving to nodes at the next depth level. Using a queue data structure,
    BFS starts at the root and explores all immediate connections before going deeper.
    In the context of thought exploration, BFS is particularly effective when you
    want to get a broad, panoramic view of different ideas and their immediate interconnections.
    This strategy is ideal for understanding the width and diversity of thoughts,
    finding the shortest path between concepts, or when you need to explore multiple
    potential reasoning paths simultaneously before diving deep into any single branch
    (see *Figure 21**.1*).'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**广度优先搜索 (BFS)**：与 DFS 相比，BFS 通过系统地检查当前深度的所有相邻节点，然后移动到下一深度级别的节点来探索思维树。使用队列数据结构，BFS
    从根节点开始，探索所有直接连接，然后再深入。在思想探索的背景下，BFS 特别适用于你想要获得不同想法及其直接相互连接的广泛全景视图时。这种策略对于理解思想的宽度和多样性、找到概念之间的最短路径，或者在你需要深入任何单个分支之前，同时探索多个潜在的推理路径时非常理想（参见
    *图 21.1*）。'
- en: '![Figure 21.1 – DFS versus BFS](img/Image96457.jpg)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![图 21.1 – DFS 与 BFS](img/Image96457.jpg)'
- en: Figure 21.1 – DFS versus BFS
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 图 21.1 – DFS 与 BFS
- en: 'As an example, let’s implement a simple DFS strategy:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，让我们实现一个简单的 DFS 策略：
- en: '[PRE1]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This code implements a DFS algorithm to explore a ToT generated by a language
    model. It starts with an initial problem and then uses the model to generate multiple
    potential continuations (branches). The code recursively explores each branch,
    extending the “thought” until it reaches a maximum depth. At each step, generated
    text is turned into model inputs, and the model outputs are decoded back into
    text.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码实现了一个 DFS 算法来探索由语言模型生成的 ToT。它从一个初始问题开始，然后使用模型生成多个潜在的后继（分支）。代码递归地探索每个分支，扩展“思想”直到达到最大深度。在每一步，生成的文本被转换为模型输入，模型输出被解码回文本。
- en: The `evaluate_thought` function, which is a key part of the selection process,
    is intended to score the quality of each generated thought. The code utilizes
    this scoring to decide which branches to explore further, effectively navigating
    the ToT toward a potentially optimal solution. The final result is the highest-scoring
    thought found during the DFS.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '`evaluate_thought` 函数是选择过程中的关键部分，旨在评估每个生成思想的品质。代码利用这种评分来决定进一步探索哪些分支，有效地引导 ToT
    向可能的最优解导航。最终结果是 DFS 过程中找到的最高评分思想。'
- en: 'Here’s an example usage of the preceding code snippet:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个前面代码片段的示例用法：
- en: '[PRE2]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This code snippet demonstrates how to use a pre-trained GPT-2 LLM to generate
    a solution to a given problem using the previously described `dfs_tot` function.
    First, it specifies the model to be used (`"gpt2-large"`) and loads both the model
    and its associated tokenizer using `AutoModelForCausalLM` and `AutoTokenizer`
    from the `transformers` library. This ensures the text is correctly processed
    for the model.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这个代码片段展示了如何使用预训练的 GPT-2 语言模型，通过之前描述的 `dfs_tot` 函数生成给定问题的解决方案。首先，它指定要使用的模型（`"gpt2-large"`），并使用
    `transformers` 库中的 `AutoModelForCausalLM` 和 `AutoTokenizer` 加载模型及其相关的标记器。这确保了文本被正确处理以供模型使用。
- en: Then, it defines the problem as a question about the long-term effects of AI
    on employment. The `dfs_tot` function is called with the loaded model, tokenizer,
    and the problem as input, initiating the depth-first search for a solution. The
    returned `solution`, which represents the model’s generated response after exploring
    various “thoughts”, is finally printed to the console.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，它将问题定义为关于人工智能对就业的长期影响的疑问。使用加载的模型、分词器和问题作为输入调用`dfs_tot`函数，开始深度优先搜索解决方案。返回的`solution`代表模型在探索各种“思维”后生成的响应，最终打印到控制台。
- en: Next, we will discuss pruning and evaluation within the ToT framework to improve
    efficiency and focus the search. Pruning is essential for managing the computational
    cost associated with exploring numerous thought branches, while evaluation provides
    the criteria for deciding which branches to discard.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将讨论在ToT框架内进行剪枝和评估以提高效率和集中搜索。剪枝对于管理探索众多思维分支相关的计算成本至关重要，而评估提供了决定哪些分支要丢弃的标准。
- en: Pruning and evaluation
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 剪枝与评估
- en: Pruning in the ToT approach is an effective mechanism for managing cognitive
    complexity by systematically reducing the search space. The process involves selectively
    eliminating less promising thought branches through intelligent evaluation techniques,
    using heuristic scoring methods that assess each potential path’s likelihood of
    leading to an optimal solution. By dynamically filtering out low-potential thoughts
    and focusing computational resources on the most promising reasoning trajectories,
    ToT pruning enables more efficient and targeted problem solving, balancing exploration
    breadth with reasoning depth.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在ToT方法中，剪枝是一种通过系统地减少搜索空间来管理认知复杂度的有效机制。这个过程涉及通过智能评估技术选择性地消除不太有希望的思维分支，使用启发式评分方法来评估每条潜在路径导致最优解的可能性。通过动态过滤掉低潜力思维并集中计算资源在最有希望的推理轨迹上，ToT剪枝能够实现更高效和有针对性的问题解决，平衡探索广度与推理深度。
- en: 'Let’s implement a basic pruning strategy by defining a simple pruning function:'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们通过定义一个简单的剪枝函数来实现一个基本的剪枝策略：
- en: '[PRE3]'
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The core of the logic is in the `explore_and_prune` function, which handles
    the recursive search through the reasoning tree. The code works by generating
    multiple possible continuations (branches) from the current thought using LLM.
    The function is designed to explore the reasoning tree up to a specified maximum
    depth, with each level containing a controlled number of branches. When the maximum
    depth is reached, the code returns the current thought as the final result. The
    pruning mechanism is illustrative and should not be used for production.
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 逻辑的核心在于`explore_and_prune`函数，它处理推理树的递归搜索。代码通过使用LLM从当前思维生成多个可能的延续（分支）来工作。该函数旨在探索推理树直到指定的最大深度，每个级别包含受控数量的分支。当达到最大深度时，代码将当前思维作为最终结果返回。剪枝机制是说明性的，不应用于生产。
- en: 'Once we’ve defined our function, we evaluate and prune branches:'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦我们定义了我们的函数，我们就评估和剪枝分支：
- en: '[PRE4]'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: First, the code evaluates each generated branch by pairing it with a score from
    the `evaluate_thought` function, which assesses the quality of the reasoning path.
    It then filters out low-quality branches by keeping only those scoring above the
    defined threshold. If all branches are pruned (none meet the threshold), the algorithm
    returns the current thought without further exploration. For the remaining promising
    branches, the code recursively explores each one by calling the same function
    at an increased depth level. Finally, it selects the best overall reasoning path
    by returning the result with the highest evaluation score from all explored paths.
    The outer function initializes the search with a formatted prompt containing the
    original problem statement.
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 首先，代码通过将每个生成的分支与`evaluate_thought`函数的分数配对来评估每个分支，该函数评估推理路径的质量。然后，它通过仅保留得分高于定义阈值的分支来过滤掉低质量的分支。如果所有分支都被剪枝（没有达到阈值），则算法返回当前思维而不再进一步探索。对于剩余的有希望的分支，代码通过在增加的深度级别上调用相同的函数递归地探索每个分支。最后，它通过从所有探索的路径中返回具有最高评估分数的结果来选择最佳的总体推理路径。外部函数使用包含原始问题声明的格式化提示初始化搜索。
- en: 'Define an `evaluate_thought` function. This function evaluates a given thought
    or branch of reasoning by scoring it based on its complexity (length) and linguistic
    diversity (the number of unique words used), returning a normalized score between
    `0` and `1`:'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个 `evaluate_thought` 函数。此函数通过根据其复杂性（长度）和语言多样性（使用的独特单词数量）评分来评估给定的思维或推理分支，返回介于
    `0` 和 `1` 之间的归一化分数：
- en: '[PRE5]'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Let’s look at an example:'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们看看一个例子：
- en: '[PRE6]'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This implementation adds a pruning step to remove low-quality branches, focusing
    the search on the most promising paths.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 此实现添加了一个修剪步骤，以移除低质量的分支，将搜索集中在最有希望的路径上。
- en: Now, let’s apply ToT to solve a multi-step problem.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们将 ToT 应用于解决一个多步骤问题。
- en: Applying ToT to solve a multi-step problem
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将 ToT 应用于解决多步骤问题
- en: 'ToT can be particularly effective for complex reasoning tasks. Let’s implement
    a ToT approach for multi-step problem solving:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: ToT 对于复杂的推理任务特别有效。让我们实现一个用于多步骤问题解决的 ToT 方法：
- en: '[PRE7]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This code implements a multi-step problem solver using the ToT reasoning approach.
    The `multi_step_tot` function breaks down complex problems into sequential steps
    and solves them one at a time, building upon previous solutions.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码实现了一个使用 ToT 推理方法的多步骤问题求解器。`multi_step_tot` 函数将复杂问题分解成一系列步骤，并逐个解决它们，基于之前的解决方案。
- en: For each step in the provided problem sequence, the function creates a prompt
    that includes the current question, the accumulated solutions from previous steps,
    and instructions to use ToT reasoning. It then calls the previously defined `pruning_tot`
    function to generate a solution for that specific step. Each step’s solution is
    appended to a growing `full_solution` string, creating a comprehensive answer
    that maintains continuity of thought across the entire problem. The example demonstrates
    how this approach could be applied to analyze climate change through a sequence
    of progressively deeper questions, from identifying causes to exploring implementation
    challenges of potential solutions.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 对于提供的每个问题序列步骤，该函数创建一个包含当前问题、之前步骤中累积的解决方案以及使用 ToT 推理的说明的提示。然后，它调用先前定义的 `pruning_tot`
    函数来为该特定步骤生成解决方案。每个步骤的解决方案都附加到一个不断增长的 `full_solution` 字符串中，从而创建一个保持整个问题思维连贯性的综合答案。示例演示了如何通过一系列越来越深入的问题来分析气候变化，从识别原因到探索潜在解决方案的实施挑战。
- en: Challenges in implementation
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实施挑战
- en: 'While powerful, ToT faces several challenges:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 ToT 很强大，但它面临着几个挑战：
- en: '**Computational complexity**: Exploring multiple paths can be computationally
    expensive'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**计算复杂性**：探索多个路径可能非常昂贵'
- en: '**Evaluation difficulty**: Determining the quality of different thought paths
    can be challenging'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**评估难度**：确定不同思维路径的质量可能具有挑战性'
- en: '**Coherence across branches**: Ensuring consistency when combining insights
    from different branches'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分支间的连贯性**：确保结合不同分支的见解时的一致性'
- en: '**Prompt design complexity**: Creating effective ToT prompts requires careful
    consideration'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提示设计复杂性**：创建有效的 ToT 提示需要仔细考虑'
- en: 'To address the computational complexity, consider implementing a parallel processing
    approach. Parallel processing can improve the ToT reasoning approach by addressing
    its inherent computational bottlenecks. The following code implements concurrent
    exploration of multiple reasoning branches simultaneously rather than sequentially,
    which can dramatically reduce the total computation time for complex problems:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决计算复杂性，考虑实现并行处理方法。并行处理可以通过解决其固有的计算瓶颈来提高 ToT 推理方法。以下代码实现了同时而不是顺序地并发探索多个推理分支，这可以显著减少复杂问题的总计算时间：
- en: '[PRE8]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: In the preceding code, the implementation uses Python’s `concurrent.futures`
    module with a `ThreadPoolExecutor` to distribute the workload across multiple
    workers. Each worker independently explores a different initial branch of the
    reasoning tree, effectively searching multiple promising paths in parallel. This
    approach is particularly valuable for ToT reasoning since the branching nature
    of the algorithm creates numerous independent subproblems that can be solved concurrently
    without dependencies on each other’s intermediate results. The final step consolidates
    these parallel explorations by selecting the highest-quality solution from all
    completed branches.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，实现使用了Python的`concurrent.futures`模块和`ThreadPoolExecutor`来将工作负载分配到多个工作者。每个工作者独立探索推理树的不同的初始分支，有效地并行搜索多个有希望的路径。这种方法对于ToT推理特别有价值，因为算法的分支特性创建了众多独立的子问题，可以在没有相互依赖的情况下并行解决各自的中间结果。最后一步通过从所有完成的分支中选择最高质量的解决方案来整合这些并行探索。
- en: This implementation uses parallel processing to explore multiple branches simultaneously,
    potentially reducing computation time for complex ToT problems.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 此实现使用并行处理同时探索多个分支，可能减少复杂ToT问题的计算时间。
- en: Future directions
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 未来方向
- en: 'As ToT continues to evolve, several promising directions emerge:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 随着ToT的持续发展，出现了一些有前景的方向：
- en: '**Dynamic tree structures**: Adapting the tree structure based on the problem
    complexity.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**动态树结构**：根据问题复杂度调整树结构。'
- en: '**Hybrid ToT-CoT approaches**: Combining the strengths of both techniques ([https://arxiv.org/html/2409.17433v1](https://arxiv.org/html/2409.17433v1)).'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**混合ToT-CoT方法**：结合两种技术的优势([https://arxiv.org/html/2409.17433v1](https://arxiv.org/html/2409.17433v1))。'
- en: '**Meta-learning for ToT**: Training LLMs to generate effective ToT structures
    automatically. This approach has not been explored by anyone yet.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ToT的元学习**：训练LLMs自动生成有效的ToT结构。这种方法尚未被任何人探索。'
- en: '**Incorporating external knowledge**: Integrating domain-specific knowledge
    into ToT reasoning ([https://arxiv.org/html/2407.00653v1](https://arxiv.org/html/2407.00653v1)).'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**整合外部知识**：将特定领域的知识整合到ToT推理中([https://arxiv.org/html/2407.00653v1](https://arxiv.org/html/2407.00653v1))。'
- en: 'Here’s a conceptual implementation of a dynamic ToT structure:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个动态ToT结构的概念实现：
- en: '[PRE9]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The preceding code implements a dynamic ToT approach that adapts its exploration
    strategy based on the complexity of the current reasoning path. The core function
    `adapt_structure` recursively builds a solution by examining the complexity of
    the current thought at each step and dynamically determining how many branches
    to explore. Unlike fixed branching strategies, this adaptive approach allocates
    more computational resources (more branches) to complex reasoning paths that might
    benefit from broader exploration, while using fewer branches for simpler concepts.
    The implementation includes helper functions to assess thought complexity, determine
    the appropriate number of branches, and generate new thought continuations using
    the language model. The algorithm terminates when reaching the maximum depth and
    returns the highest-scoring complete reasoning path.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码实现了一个动态ToT方法，该方法根据当前推理路径的复杂度调整其探索策略。核心函数`adapt_structure`通过递归地检查每一步当前思维过程的复杂度，并动态确定要探索的分支数量来构建解决方案。与固定的分支策略不同，这种自适应方法为可能从更广泛探索中受益的复杂推理路径分配更多的计算资源（更多分支），而对于较简单的概念则使用较少的分支。实现包括辅助函数来评估思维复杂度、确定适当的分支数量以及使用语言模型生成新的思维延续。算法在达到最大深度时终止，并返回得分最高的完整推理路径。
- en: 'Here’s an example of how to use the preceding code to solve a problem such
    as “`How might advancements in nanotechnology impact medicine in the` `next decade?`”:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个示例，说明如何使用前面的代码解决诸如“`纳米技术的进步可能会在下一个十年如何影响医学？`”这样的问题：
- en: '[PRE10]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This dynamic ToT approach adapts the tree structure based on the assessed complexity
    of each thought, allowing the more flexible and efficient exploration of complex
    problem spaces.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 这种动态ToT方法根据评估的每个思维的复杂度调整树结构，允许更灵活和高效地探索复杂问题空间。
- en: Summary
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you learned how to design and implement ToT prompts for LLMs,
    including strategies for managing the branching thought processes. We covered
    search techniques and methods for pruning and evaluating different reasoning paths.
    By implementing the strategies and considerations discussed here, you can significantly
    enhance your LLM’s ability to handle ambiguous, multi-faceted problems and generate
    more robust and insightful solutions.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你学习了如何为LLM设计和实现ToT提示，包括管理分支思维过程策略。我们涵盖了搜索技术和修剪和评估不同推理路径的方法。通过实施这里讨论的策略和考虑因素，你可以显著提高LLM处理模糊、多方面问题的能力，并生成更稳健和有洞察力的解决方案。
- en: Revisiting [*Chapter 20*](B31249_20.xhtml#_idTextAnchor305), which focuses on
    CoT, let’s compare CoT and ToT from a use case perspective. Use CoT prompting
    when the task involves linear, sequential reasoning that can be decomposed into
    intermediate steps with a single, dominant solution path. CoT is particularly
    effective in math word problems, deductive reasoning, basic logical puzzles, and
    step-by-step procedural tasks. It works well when the problem has low branching
    complexity and does not require exploration of multiple alternatives. CoT is computationally
    cheaper because it produces a single chain of reasoning in a forward, deterministic
    manner. This technique is most helpful when the LLM needs a scaffold to “think
    aloud” and make its intermediate steps explicit to prevent hallucinations or faulty
    leaps in logic.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾[*第20章*](B31249_20.xhtml#_idTextAnchor305)，本章专注于CoT，让我们从用例的角度比较CoT和ToT。当任务涉及线性、顺序推理，并且可以分解为具有单一、主导解决方案路径的中间步骤时，使用CoT提示。CoT在数学文字问题、演绎推理、基本逻辑谜题和逐步程序任务中特别有效。当问题具有低分支复杂度且不需要探索多个替代方案时，它工作得很好。CoT在计算上更便宜，因为它以前向、确定性的方式产生单一的推理链。当LLM需要支架来“大声思考”并使其中间步骤明确以防止幻觉或逻辑错误时，这种技术最有帮助。
- en: Use ToT prompting when the task involves multi-step reasoning with branching
    decision points, especially where multiple solution paths are possible and need
    to be evaluated in parallel. ToT is suited for creative problem-solving, planning
    tasks, theorem proving, code synthesis, and decision-making under uncertainty.
    It becomes advantageous when the problem space can be structured as a search tree,
    where intermediate reasoning nodes can be revisited, evaluated, and compared.
    ToT often incorporates strategies such as self-consistency sampling, lookahead
    evaluation, and value-based selection among branches. It is computationally more
    intensive because it maintains and expands multiple reasoning paths in parallel,
    potentially involving rollouts, backtracking, or node scoring.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 当任务涉及具有分支决策点的多步推理时，使用ToT提示，特别是当存在多个可能的解决方案路径需要并行评估时。ToT适合创造性问题解决、规划任务、定理证明、代码合成以及在不确定性下的决策。当问题空间可以结构化为搜索树，其中中间推理节点可以重新访问、评估和比较时，它变得有利。ToT通常包含诸如自洽采样、前瞻性评估和基于价值的分支选择等策略。由于它并行维护和扩展多个推理路径，包括回滚、回溯或节点评分，因此它在计算上更密集。
- en: If the problem is constrained and well-formed (e.g., SAT-style questions or
    straightforward derivations), CoT is usually sufficient and more efficient. If
    the problem is open-ended, has multiple conflicting goals, or if optimal solutions
    require comparing alternative paths (as in planning routes, game moves, or formal
    proofs), ToT yields better performance by simulating exploration and deliberation.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 如果问题是受限制且形式良好的（例如，SAT风格的问题或直接的推导），CoT通常足够且更高效。如果问题是开放式的，具有多个冲突的目标，或者最优解需要比较替代路径（如在规划路线、游戏移动或形式证明中），ToT通过模拟探索和深思熟虑，可以提供更好的性能。
- en: In practice, CoT can serve as a base technique, while ToT builds on it by orchestrating
    multiple chains. For example, ToT nodes may each use CoT internally to generate
    coherent thoughts. Therefore, the two are not mutually exclusive but hierarchically
    related in terms of complexity and structure.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，CoT可以作为基础技术，而ToT通过协调多个链来构建在其之上。例如，ToT节点可能每个都使用CoT内部生成连贯的思想。因此，这两个不是互斥的，但在复杂性和结构方面是层次相关的。
- en: In the upcoming chapter, we will explore the **Reasoning and Acting** (**ReAct**)
    pattern, which is commonly used in many agentic AI applications.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探讨**推理和行动**（**ReAct**）模式，该模式在许多代理AI应用中普遍使用。
