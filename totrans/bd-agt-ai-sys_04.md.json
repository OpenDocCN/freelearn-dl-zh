["```py\n1  if feedback == -1:  # Negative feedback indicates dissatisfaction\n2    if destination == \"Paris\":\n3       preferences_weights[\"luxury\"] *= 0.9\n4    elif destination == \"Bangkok\":\n5       preferences_weights[\"budget\"] *= 0.9\n6    elif destination == \"New York\":\n7       preferences_weights[\"budget\"] *= 0.9\n8\n9  elif feedback == 1:  # Positive feedback indicates satisfaction\n10    if destination == \"Paris\":\n11       preferences_weights[\"luxury\"] *= 1.1\n12    elif destination == \"Bangkok\":\n13       preferences_weights[\"budget\"] *= 1.1\n14    elif destination == \"New York\":\n15       preferences_weights[\"budget\"] *= 1.1\n```", "```py\n1  from crewai import Agent\n2\n3  preference_agent = Agent(\n4      name=\"Preference Agent\",\n5      role=\"Travel destination recommender\",\n6      goal=\"Provide the best travel destination based on user\n             preferences and weights.\",\n7      backstory=\"An AI travel expert adept at understanding user\n                  preferences.\",\n8      verbose=True,\n9      llm='gpt-4o-mini',\n10     tools=[recommend_destination])\n11\n12 meta_agent = Agent(\n13     name=\"Meta-Reasoning Agent\",\n14     role=\"Preference weight adjuster\",\n15     goal=\"Reflect on feedback and adjust the preference weights to\n             improve future recommendations.\",\n16     backstory=\"An AI optimizer that learns from user experiences to\n                 fine-tune recommendation preferences.\",\n17     verbose=True,\n18     llm='gpt-4o-mini',\n19     tools=[update_weights_on_feedback])\n```", "```py\n1 from crewai import Task\n2\n3 generate_recommendation = Task(\n4      name=\"Generate Recommendation\",\n5      agent=preference_agent,\n6      description=(\n7       f\"Use the recommend_destination tool with these preferences:\n         {state['preferences']}\\n\"\n8       \"Return only the destination name as a simple string (Paris,\n         Bangkok, or New York).\"\n9      ),\n10     expected_output=\"A destination name as a string\")\n11\n12 adjust_weights = Task(\n13     name=\"Adjust Weights Based on Feedback\",\n14     agent=meta_agent,\n15     description=(\n16        \"Use the update_weights_on_feedback tool with:\\n\"\n17        \"1\\. destination: Get from first task's output\n          (context[0])\\n\"\n18        \"2\\. feedback: Get from second task's output (context[1])\\n\"\n19        \"3\\. adjustment_factor: a number between 0 and 1 that will be\n          used to adjust internal weights based on feedback\\n\\n\"\n20        \"Ensure all inputs are in their correct types (string for\n          destination, integer for feedback).\"\n21     ),\n22     expected_output=\"Updated weights as a dictionary\",\n23     context=[generate_recommendation, user_feedback])\n```", "```py\n1 from crewai import Agent, Task, Crew\n2 crew = Crew(\n3    agents=[preference_agent, meta_agent],\n4    tasks=[generate_recommendation, adjust_weights],\n5    verbose=True)\n6\n7 crew.kickoff()\n```", "```py\n# Agent: Travel destination recommender\n## Task: Use the recommend_destination tool with these preferences: {'budget': 0.04, 'luxury': 0.02, 'adventure': 0.94}\nReturn only the destination name as a simple string (Paris, Bangkok, or New York).\n# Agent: Travel destination recommender\n## Thought: I need to analyze the user's preferences which heavily favor adventure and very little for budget and luxury.\n## Using tool: Recommend travel destination based on preferences.\n## Tool Input:\n\"{\\\"user_preferences\\\": {\\\"budget\\\": 0.04, \\\"luxury\\\": 0.02, \\\"adventure\\\": 0.94}}\"\n## Tool Output:\nNew York\n# Agent: Travel destination recommender\n## Final Answer:\nNew York\n# Agent: Preference weight adjuster\n## Task: Use the update_weights_on_feedback tool with:\n1\\. destination: Get from first task's output (context[0])\n2\\. feedback: Get from user input\n3\\. adjustment_factor: a number between 0 and 1 that will be used to adjust internal weights based on feedback\nEnsure all inputs are in their correct types (string for destination, integer for feedback).\n# Agent: Preference weight adjuster\n## Thought: I need to adjust the preference weights based on the provided feedback for the destination 'New York', which received a dissatisfied feedback of -1\\. I will choose an adjustment factor between 0 and 1; for this case, I will use 0.1 for a slight adjustment.\n## Using tool: Reasoning tool to adjust preference weights based on user feedback.\n## Tool Input:\n\"{\\\"destination\\\": \\\"New York\\\", \\\"feedback\\\": 1, \\\"adjustment_factor\\\": 0.1}\"\n## Tool Output:\n{'budget': 0.33, 'luxury': 0.32, 'adventure': 0.34}\n# Agent: Preference weight adjuster\n## Final Answer:\n{'budget': 0.33, 'luxury': 0.32, 'adventure': 0.34}\n```", "```py\n1 travel_agent = Agent(\n2    role=\"Travel Advisor\",\n3    goal=\"Provide hotel recommendations with transparent reasoning.\",\n4    backstory=\"An AI travel advisor specializing in personalized\n                travel planning.\n5               You always explain the steps you take to arrive at a\n                conclusion.\",\n6    tools=[recommend_hotel]\n7   )\n8\n9 recommendation_task = Task(\n10    name=\"Recommend hotel\",\n11    description=\"\"\"\n12    Recommend a hotels based on the user's query {query}.\n13    \"\"\",\n14    agent=travel_agent,\n15    expected_output=\"The name of the hotel with explanations\"\n16   )\n```", "```py\nHotel: Hotel du Petit Moulin\nReason:\nI found several hotels in Paris, but most of them exceeded the budget of $300\\. The only suitable option is Hotel du Petit Moulin, which is priced at $300 per night. Located in the 3rd arrondissement, it offers moderate transportation convenience with the nearest metro station, Saint-Sébastien Froissart, being approximately 1.9 kilometers away. This hotel is a great choice for budget-conscious travelers who still want to enjoy the charm of Paris.\n```"]