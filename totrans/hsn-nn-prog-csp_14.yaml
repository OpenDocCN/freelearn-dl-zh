- en: Finding Optimal Parameters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will use the open source package SwarmOps, version 4.0,
    to help you better understand how you can use this tool to find optimal parameters
    for your functions. You can get the latest version of SwarmOps from the following
    location: [https://github.com/mattcolefla/SwarmOps](https://github.com/mattcolefla/SwarmOps).'
  prefs: []
  type: TYPE_NORMAL
- en: Once again, we must spend a little time on theory, where we will take you back
    to your academic days and lay a foundation so that we are all speaking the same
    language. It should be noted that SwarmOps is a highly research-oriented tool
    and should be used as such. We have worked hard to make this product open source,
    and the latest version has over 60 different optimization functions for you to
    use.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Fitness function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Constraints
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Meta-optimization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Optimization methods
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Parallelism
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ready? Here we go!
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You will be required to have a basic knowledge of .NET development using Microsoft
    Visual Studio and C#. You will need to download the code for this chapter from
    the book''s website: SwarmOps ([https://github.com/mattcolefla/SwarmOps](https://github.com/mattcolefla/SwarmOps)).'
  prefs: []
  type: TYPE_NORMAL
- en: Check out the following video to see Code in Action: [http://bit.ly/2QPddLO](http://bit.ly/2QPddLO).
  prefs: []
  type: TYPE_NORMAL
- en: Optimization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Solutions to some problems are not as cut and dry as *correct* or *incorrect*,
    but are rated in terms of quality. Such problems are known as **optimization problems** because
    the goal is to find the candidate solution with the best, that is, *optimal* quality.
  prefs: []
  type: TYPE_NORMAL
- en: What is a fitness function?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'SwarmOps works for real-valued and single-objective optimization problems,
    that is, optimization problems that map candidate solutions from ![](img/27d5e4e0-0b6f-4c24-a070-c1926d03298c.png)-dimensional
    real-valued spaces to one-dimensional real-valued spaces. Mathematically speaking,
    we consider optimization problems to be functions ![](img/ff972492-0e7b-4a6b-8c36-0f7d57f0b201.png) of
    the following form:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f66bee59-ca43-4b53-b430-1122beddd22b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In SwarmOps, it is assumed that ![](img/d71ae3ff-ae43-421d-a951-cb3ba8c1300f.png) is
    a minimization problem, meaning that we are searching for the candidate solution ![](img/03c78311-96e5-484d-8851-42ab9d21e4d1.png)with
    the smallest value ![](img/51747946-9f40-4185-9253-1cddfb223c83.png). Mathematically,
    this may be written as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Find ![](img/154be667-72da-4d84-8f6f-cfd2742596be.png), such that ![](img/b9292a90-ca0f-42ca-bc9f-c02828a84941.png).
  prefs: []
  type: TYPE_NORMAL
- en: Typically, however, it is not possible to locate the exact optimum; we must
    be satisfied with a candidate solution of sufficient quality that is perhaps not
    quite optimal. In this chapter, we refer to the optimization problem ![](img/2a5bcabc-0829-4cc1-ad19-482a4789e4b3.png) as
    the `fitness` function, but it is can also be known as the cost function, objective
    function, error function, quality measure, and so on. We may also refer to candidate
    solutions as positions, agents, or particles, and to all possible candidate solutions
    as the search-space.
  prefs: []
  type: TYPE_NORMAL
- en: Maximization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'SwarmOps can also be used with maximization problems. If ![](img/be3529dc-49fc-4781-8e46-82823aeddb0b.png) is
    a maximization problem, then the equivalent minimization problem is as follows:
    ![](img/93fe06a1-e72d-413d-b9e4-2036f0e02bcc.png).'
  prefs: []
  type: TYPE_NORMAL
- en: Gradient-based optimization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The classic way of optimizing a fitness function ![](img/f5b3e719-abbc-4f04-a45a-8b09794acaa6.png) is
    to first deduce its gradient, that is, ![](img/cddb2fb9-9dab-4bfc-a4e3-a6bbdd529ff0.png),
    which consists of the partial differentials of ![](img/5e346118-7080-4de5-afc1-761fde7db44d.png),
    that is:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e951e83d-2148-426c-89ff-0a6dec619e63.png)'
  prefs: []
  type: TYPE_IMG
- en: The gradient is then followed iteratively in the direction of the steepest descent;
    a quasi-Newton optimizer can also be used if necessary. This optimizer requires
    that not only for the fitness function ![](img/ddc2311e-3af9-4850-bf5d-4228aea941f6.png) be
    differentiable, but time and patience as well. This is because the gradient can
    be very laborious to derive, and the execution can be very time-consuming.
  prefs: []
  type: TYPE_NORMAL
- en: Heuristic optimization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An alternative to gradient-based optimization methods is to let the optimization
    be guided solely by fitness values. This kind of optimization has no explicit
    knowledge of how the fitness landscape looks, but merely considers the fitness
    function to be a black box that takes candidate solutions as input and produces
    a fitness value as output. This is known in this chapter as Derivate-free optimization,
    direct search, heuristic optimization, meta-heuristics, black-box optimization,
    and so on. We will use these terms a lot!
  prefs: []
  type: TYPE_NORMAL
- en: Constraints
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Constraints split the search-space into regions of feasible and infeasible candidate
    solutions. For instance, an engineering problem could have a mathematical model
    that should be optimized, but producing the solution in the real world puts some
    constraints on what is feasible. There are different ways of supporting and handling
    constraints in heuristic optimization.
  prefs: []
  type: TYPE_NORMAL
- en: Boundaries
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A simple form of constraint is search-space boundaries. Instead of letting
    ![](img/4b827c98-c3b5-4f2a-a2e3-22a8f3cd3d14.png) map from the entire ![](img/19fe84b2-bee4-4df9-9731-e4c5979c7344.png)-dimensional
    real-valued space, it is often practical to use only a part of this vast search-space.
    The lower and upper boundaries that constitute the search-space are denoted as
    ![](img/fd613b81-7202-46fa-a065-f4a9e7d46c66.png) and ![](img/bc508a18-3f8e-460f-994a-a9a844344e7e.png),
    so the fitness function is of the following form:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a9c3f595-e542-4b73-a111-d269ef1cfee6.png)'
  prefs: []
  type: TYPE_IMG
- en: Such boundaries are typically enforced in optimization methods by moving candidate
    solutions back to the boundary value if they have exceeded the boundaries. This
    is the default type of constraint available in SwarmOps.
  prefs: []
  type: TYPE_NORMAL
- en: Penalty functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: More complicated constraints are supported transparently by any heuristic optimizer
    by penalizing infeasible candidate solutions, that is, by adding a penalty function
    to the fitness function. Examples can be found in the penalized benchmark problems
    section of the SwarmOps source code.
  prefs: []
  type: TYPE_NORMAL
- en: General constraints
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'SwarmOps supports general constraints by taking feasibility (constraint satisfaction)
    into account when comparing candidate solutions. Normally, we determine whether
    candidate solution ![](img/b7d1afed-2b91-4ede-92ad-7d844093c95c.png) is better
    than ![](img/6815653e-4aad-427b-bc3c-42cd1411241f.png) by comparing their fitness
    with ![](img/0c872fc8-9935-4e18-bc4e-251e8c91cece.png), but it is also possible
    to take feasibility into account. Feasibility is a Boolean; either a candidate
    solution is feasible or it is infeasible. The comparison operator is as shown
    in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/06b8c937-53e5-41e6-98f1-721e4ec3c124.png)'
  prefs: []
  type: TYPE_IMG
- en: Note in the preceding diagram that the actual implementation of this comparison
    is simplified somewhat. Also note that when ![](img/0dd53fa0-41cc-4d49-bfe8-cb86d4e72111.png) is
    feasible and ![](img/606727bc-e8d5-4fcc-8c0f-e8b40205a94f.png) is infeasible,
    their fitness need not be computed. This is because ![](img/04942206-ca8b-4c51-893f-41b045d9c844.png) is
    worse than ![](img/7dd24064-e485-4ab1-a789-218fe581c80c.png) due to their mutual
    feasibility. This is used in the implementation to avoid fitness computations
    when possible.
  prefs: []
  type: TYPE_NORMAL
- en: Constrained optimization phases
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Using the earlier comparison operator means that optimization has two phases.
    First, the optimizer will likely only find infeasible candidate solutions, so
    it optimizes the fitness of infeasible solutions. Then, at some point, the optimizer
    hopefully discovers a feasible candidate solution; regardless of its fitness,
    it will then become the best-found solution of the optimizer and will form the
    basis of the further search. This is essentially the optimization of a feasible
    solution's fitness.
  prefs: []
  type: TYPE_NORMAL
- en: Constrained optimization difficulties
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While SwarmOps gives you the ability to implement any constraint imaginable,
    constraints themselves will make it increasingly difficult for the optimizer to
    find feasibly optimal solutions because constraints narrow the feasible regions
    of the search-space. You should therefore also narrow the initialization and search-space
    boundaries to be as close to the feasible region as possible.
  prefs: []
  type: TYPE_NORMAL
- en: Implementation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are two methods in the `problem` class where you can implement constraints;
    they are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`EnforceConstraints()` allows you to make repairs to a candidate solution before
    its feasibility and fitness are evaluated. For example, when search-space boundaries
    are used as constraints then the repairing would consist of moving candidate solutions
    back between boundaries if they were overstepped. This is done by default.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Feasible()` evaluates and returns the feasibility of a candidate solution
    without altering it.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Meta-optimization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Optimization methods usually have several user-defined parameters that govern
    the behavior and efficacy of the optimization method. These are called the optimizer''s
    behavioral or control parameters. Finding a good choice of these behavioral parameters
    has previously been done manually by hand-tuning, and sometimes even by using
    coarse mathematical analysis. It has also become a common belief among researchers
    that behavioral parameters can be adapted during optimization to improve overall
    optimization performance; however, this has been demonstrated to be mostly unlikely.
    Tuning behavioral parameters can be considered an optimization problem and hence
    can be solved by an overlaid optimization method. This is known here as meta-optimization,
    but is also known in the chapter as meta-evolution, super-optimization, parameter
    calibration, and so on. The success of SwarmOps when doing meta-optimization relies
    mainly on the following three factors:'
  prefs: []
  type: TYPE_NORMAL
- en: SwarmOps features an optimization method that is particularly suitable as the
    overlaid meta-optimizer because it quickly discovers well-performing behavioral
    parameters (this is the LUS method described in this chapter).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: SwarmOps employs a simple technique for reducing computational time called pre-emptive
    fitness evaluation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'SwarmOps uses the same function-interface for both optimization problems and
    optimization methods. Several scientific publications use SwarmOps for meta-optimization
    and have more elaborate descriptions than those given here, as well as having
    literature surveys and experimental results. The concept of meta-optimization
    can be illustrated schematically as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/728cfbba-e247-40f4-949f-9c6f2ca0b3fe.png)'
  prefs: []
  type: TYPE_IMG
- en: In the preceding diagram, the optimizer whose behavioral parameters are to be
    tuned is taken to the DE method, which we will look at later on in this chapter.
    The SwarmOps framework allows for parameters to be tuned regarding multiple optimization
    problems, which is sometimes necessary to make the performance of the behavioral
    parameters respond better to more general problems.
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding example, the DE parameters are tuned for two specific problems.
  prefs: []
  type: TYPE_NORMAL
- en: Fitness normalization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Fitness functions must be non-negative to work properly with meta-optimization
    in SwarmOps. This is because pre-emptive fitness evaluation works by summing fitness
    values for several optimization runs and aborting the summation when the fitness
    sum becomes worse than that needed for the new candidate solution to be considered
    an improvement. This means that fitness values must be non-negative, so the fitness
    sum is only able to grow worse and the evaluation can thus be aborted safely.
    SwarmOps for C# does this normalization automatically, provided you accurately
    implement the **MinFitness** field of the `problem` class. For example, you may
    have a fitness function ![](img/e06c6075-b237-4bd1-9991-78e53f0daf3f.png) which
    maps to, for example, ![](img/6395813e-55ae-4fe8-8fad-868fc3b68984.png). In this
    case, you would have to set **MinFitness** to ![](img/c1279116-97cc-4e9c-b33d-18fd0264cc45.png).
    It is best to make **MinFitness** accurate so that ![](img/b5f6c6b2-1db6-4603-b18f-d789f786eadc.png) for
    the optimum ![](img/4c08bc18-d933-418f-bcfe-9e672b621b2d.png), that is, **MinFitness**
    should be the fitness of the optimum. You should be able to estimate a lower fitness
    boundary for most real-world problems, and if you are unsure what the theoretical
    boundary value is, you may choose some boundary fitness value of ample—but not
    extreme—magnitude.
  prefs: []
  type: TYPE_NORMAL
- en: Fitness weights for multiple problems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you are using multiple problems in meta-optimization, you may need to experiment
    with weights on each problem to make their influence on the meta-optimization
    process more equal.
  prefs: []
  type: TYPE_NORMAL
- en: Advice
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `LUS` method is generally recommended as the overlaid meta-optimizer. The
    tutorial source code contains suggestions for experimental settings that have
    been found to work well. It is best if you perform meta-optimization regarding
    the problems you are ultimately going to use the optimization method for. However,
    if your fitness function is very expensive to evaluate, then you may try and resort
    to using benchmark problems as a temporary replacement when meta-optimizing the
    behavioral parameters of your optimizer—provided you use multiple benchmark problems
    and the optimization settings are the same as those used in a real-world application.
    In other words, you should use benchmark problems of similar dimensionality and
    with a similar number of optimization iterations to what you would use for the
    actual problem you will ultimately optimize.
  prefs: []
  type: TYPE_NORMAL
- en: Constraints and meta-optimization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Two issues regarding constraints in meta-optimization should be mentioned;
    they are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Constraints can be made on an optimizer's control parameters in the same manner
    as for an optimization problem by implementing the `EnforceConstraints()` and
    `Feasible()` methods in the optimizer's class. This means the meta-optimizer will
    search for control parameters that are feasibly optimal, allowing you to search
    for control parameters that meet certain criteria; for example, they have certain
    relationships with each other, such as one parameter being smaller than the other,
    and so on. See the source code of the MOL optimizer for an example of this.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Constraint satisfaction is ignored when determining how well an optimizer performs
    in making up the meta-fitness measure. This is an open research topic, but experiments
    suggest that an optimizer's control parameters should be meta-optimized for unconstrained
    problems. This will also yield good performance on constrained problems.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Meta-meta-optimization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When using meta-optimization to find the best performing parameters of an optimizer,
    one may naturally wonder what the best performing parameters for the meta-optimizer
    itself are. It makes good sense to find the best meta-optimizer if one is going
    to use it often. The best parameters for the meta-optimizer can be found by employing
    yet another layer of optimization, which may be termed meta-meta-optimization.
  prefs: []
  type: TYPE_NORMAL
- en: Optimization methods
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section will give you a brief description of the optimization methods that
    are supplied with SwarmOps and some recommendations for their use.
  prefs: []
  type: TYPE_NORMAL
- en: Choosing an optimizer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When faced with a new optimization problem, the first optimizer you may want
    to try is the `PS` method, which is often sufficient and has the advantage of
    converging (or stagnating) very quickly. In addition, `PS` does not have any behavioral
    parameters that need tuning, so it either works or it doesn't. If the `PS` method
    fails at optimizing your problem, you may want to try the `LUS` method. You may
    need to run both `PS` and `LUS` several times as they may converge to sub-optimal
    solutions. If `PS` and `LUS` both fail, you may try the `DE`, `MOL`, or `PSO`
    methods and experiment with their behavioral parameters.
  prefs: []
  type: TYPE_NORMAL
- en: As a rule of thumb, the `PS` and `LUS` methods stagnate rather quickly, say,
    after ![](img/9467ab0f-45fe-4278-bd10-7cfb6072cdae.png) iterations, where ![](img/47a20a43-ff5e-4135-9011-d2742eb4ef34.png) is
    the dimensionality of the search-space. On the other hand, the `DE`, `MOL`, and
    `PSO` methods require substantially more iterations, say, ![](img/b449793d-94f2-4c94-baea-87d7a69b9c6b.png) or
    ![](img/a0a7fe71-44bf-4320-b818-da90e75e0091.png), and sometimes even more than
    that.
  prefs: []
  type: TYPE_NORMAL
- en: If these optimizers fail, you either need to tune their behavioral parameters
    using meta-optimization or use another optimizer altogether.
  prefs: []
  type: TYPE_NORMAL
- en: Gradient descent (GD)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A classic way of minimizing a fitness function (![](img/94019cf0-3050-4743-9987-820903b35c25.png)) is
    to repeatedly follow the gradient in the direction of steepest descent. The gradient
    function ![](img/6097ce3d-ecec-44d0-88ad-d1a08f6e8028.png) is defined as the vector
    of the partial differentials of ![](img/91947301-c391-4a50-b1b1-d3b790d461f8.png),
    which is denoted as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1d146b75-a3cf-410f-98ef-707dab8373d4.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The position ![](img/a4e702b4-42d1-441f-bb95-a84afbda5653.png) is first chosen
    randomly from the search-space and then updated iteratively according to the following
    formula, regardless of fitness improvement:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1f01f96e-a274-489c-90ad-2b3f1e17f5d8.png)'
  prefs: []
  type: TYPE_IMG
- en: As shown in the preceding formula, ![](img/93217723-328b-470a-8e96-76d9ecc19067.png) is
    the step-size. When ![](img/4425b020-40c2-4b94-b042-ffca9b82ce33.png) is a minimization
    problem, the descent direction is followed, that is, we subtract the gradient
    from the current position instead of adding it—as we would have done for ascending
    a maximization problem.
  prefs: []
  type: TYPE_NORMAL
- en: Drawbacks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `GD` method has some drawbacks, namely that it requires the gradient ![](img/a272cd38-a583-4582-9587-029852000720.png) to
    be defined. The gradient may also be expensive to compute, and `GD` may approach
    the optimum too slowly.
  prefs: []
  type: TYPE_NORMAL
- en: Pattern Search (PS)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The optimization method known as **Pattern Search** (**PS**) was originally
    by Fermi and Metropolis, as described in [6], and is a similar method used by
    Hooke and Jeeves [7]. The implementation presented here is the variant from [4].
  prefs: []
  type: TYPE_NORMAL
- en: How it works
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`PS` uses one agent or position in the search-space that is being moved around.
    Let the position be denoted as ![](img/1c97efff-4502-4505-a525-9ef682e9cf8c.png),
    which is initially picked at random from the entire search-space. The initial
    sampling range is the entire search-space: ![](img/97452731-07d3-4a41-be58-f9e5253e99b4.png).
    The potential new position is denoted as ![](img/383a60a2-670d-4ea2-8a1d-3085a8cbdf0a.png) and
    is sampled as follows.'
  prefs: []
  type: TYPE_NORMAL
- en: First, pick an index (![](img/1f82aee5-8112-4944-bac9-1ae0cbe6ee1e.png)) at
    random and let ![](img/30e356f6-bda7-42da-84bb-84956944d5ae.png) and ![](img/a629f2c3-776e-4e6c-98a4-0c6093e7f4bf.png) for
    all ![](img/b04cd7cf-0359-4a25-8dae-87061030f16a.png). If ![](img/f2ba7f3f-82db-476d-a385-cca9ae94133e.png) improves
    on the fitness of ![](img/3b3a310c-23de-49fe-8f2d-824b19f06300.png) then move
    to ![](img/9a444349-8dc2-4be1-afc1-15b5c7eb9d11.png). Otherwise, halve and reverse
    the sampling range for the ![](img/75aab672-6214-4521-95a8-92e4894092ff.png) dimension
    with ![](img/3e7a1210-2df4-4af2-ae36-e8886b578f52.png). Repeat this several times.
  prefs: []
  type: TYPE_NORMAL
- en: Local Unimodal Sampling (LUS)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The LUS optimization method performs local sampling by moving a single agent
    around the search-space to decrease the sampling range during optimization. The
    `LUS` method was presented in [4] [8].
  prefs: []
  type: TYPE_NORMAL
- en: How it works
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The agent''s current position is denoted as ![](img/3a07dd2f-9346-48e2-aa18-8b07f1c4c4c4.png) and
    is initially picked at random from the entire search-space. The potential new
    position is denoted as ![](img/b60d3ad7-a646-4019-800c-d326b0a99c87.png) and is
    sampled from the neighborhood of ![](img/11ba00fb-61bf-4c7c-a242-8ea43cca6fbf.png) by
    letting ![](img/adb1fcb8-215c-4c9a-8398-9967987c6665.png), where ![](img/44b6af3f-efba-4a88-9092-635930f642b0.png) is
    a random vector picked uniformly from the range ![](img/f6d7b8de-7c30-490c-82e0-fcf9ee1faaa6.png),
    which is initially ![](img/f72307cb-493c-4fa1-97fe-4d16e53a2e6a.png). In other
    words, the full range of the entire search-space is defined by its upper boundaries, ![](img/e9850d5a-6c90-4d4a-ace5-f9ea998266c1.png), and
    its lower boundaries, ![](img/e4df128a-35c5-4686-83be-90ce4e6573b4.png). `LUS`
    moves from position ![](img/48b50b61-ffce-4b26-b429-e92ef7bb129a.png) to position
    ![](img/703decc9-3c80-4ccb-91d7-dae8b3ceff5f.png) in the event of any improvement
    in the fitness. Upon each failure for ![](img/44ccd04b-5c5e-4684-8ba7-aae3fe01ab0f.png) to
    improve on the fitness of ![](img/fd3d5809-f440-46e1-9203-1826d1aa23b2.png), the
    sampling range is decreased by multiplication with a factor of ![](img/b654a3b2-a26e-40b6-b22b-ede4bdbc8741.png),
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/83931e90-c652-4733-804c-0ac21eb7fd09.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, the decrease factor ![](img/c3aede74-9165-4ab2-9e02-3d275b9b7276.png) is
    then defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b05528ec-893c-422a-88e2-0ac036b8e206.png)'
  prefs: []
  type: TYPE_IMG
- en: The preceding formula denotes ![](img/2ca25f34-c60d-46ab-9506-6dd0085e3443.png) as
    the dimensionality of the search-space and ![](img/e8595bdc-ea0d-4e6c-a28e-34893412347d.png) as
    a user-defined parameter used to adjust the rate of sampling-range decrease. A
    value of ![](img/77cb6838-49db-4845-8b94-de4dd8e6926d.png) has been found to work
    well for many optimization problems.
  prefs: []
  type: TYPE_NORMAL
- en: Differential Evolution (DE)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The multi-agent optimization method known as **Differential Evolution** (DE)
    was originally devised by Storn and Price [9]. Many DE variants exist and a simple
    one is implemented in the DE class. Several different DE variants are available
    through the DE Suite and JDE classes.
  prefs: []
  type: TYPE_NORMAL
- en: How it works
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`DE` uses a population of agents. Let ![](img/84c40d14-17d8-4b04-8b86-6b56739a2e33.png) denote
    the position of an agent being updated and which has been picked at random from
    the entire population. Let ![](img/c48c1a1d-9f92-4b3b-ba0e-69da34ad03fa.png) be
    its new potential position computed as follows (this is the so-called **DE/rand/1/bin
    variant**):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6812e471-12ab-4405-98c7-e78ee13f3c5f.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, the vectors ![](img/ae2baaf5-4b25-4f9f-9d02-e386675886bb.png), ![](img/f558b5bd-2d7a-4c81-96eb-ffb62f909916.png),
    and ![](img/a488252c-4041-4699-abc4-82172389fb1e.png) are the positions of distinct
    and randomly-picked agents from the population. The index ![](img/1f764f95-e451-412a-b593-6550ec827609.png) is
    randomly-picked and ![](img/aa14b88e-bc36-43e5-941f-9d007c9b0f12.png) is also
    picked randomly for each dimension, ![](img/804bffd2-51f3-4ecd-b6a9-b3830df85450.png).
    A move is made to the new position ![](img/3bd72ce6-3032-434e-9ad5-c209d3ef88d9.png) if
    it improves on the fitness of ![](img/75b48837-90f8-4865-961c-060377b7e5a8.png).
    The user-defined parameters consist of the differential weight ![](img/836c3c67-bddf-4a17-aab4-b3bceea3bee9.png),
    the crossover probability ![](img/c376bc2b-a065-4165-b678-3ced4ae106bb.png), and
    the population-size ![](img/57e01e44-1266-402d-a06f-0ddf27caddd4.png).
  prefs: []
  type: TYPE_NORMAL
- en: Particle Swarm Optimization (PSO)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The optimization method known as **Particle Swarm Optimization** (**PSO**) was
    originally devised by Kennedy, Eberhart, and Shi [10] [11]. It works by having
    a swarm of candidate solutions called particles, with each particle having a velocity
    that is updated recurrently and added to the particle's current position to move
    it to a new one.
  prefs: []
  type: TYPE_NORMAL
- en: How it works
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let ![](img/e5496bcc-ae8f-41b5-aaa1-58182c96dc4e.png) denote the current position
    of a particle from the swarm. The particle''s velocity ![](img/418d63a9-09b6-4d2c-b685-b27fa76ef6ad.png) is
    then updated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6b429bb7-491d-4aac-a063-d2f865b17f73.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, the user-defined parameter ![](img/d9fc81cb-cc09-4278-862c-a4aa77557643.png) is
    called the inertia weight and the user-defined parameters ![](img/4e2c67e8-3aa3-44c5-8017-65b1661b373b.png) and
    ![](img/5999e90e-9f04-4f64-893f-e8d47324ecbe.png) are weights on the attraction
    toward the particle's own best-known position, ![](img/3f94cc2b-8fe8-4891-8569-23ea42d20bde.png),
    and the swarm's best-known position, ![](img/fd105a0a-c96b-4f8d-9f4d-8ee65e2edfec.png).
    These are also weighted by the random numbers ![](img/7236df76-a421-4502-9307-bb9b42bbb7cd.png).
    In addition to this, the user also determines the swarm-size, ![](img/1ccff208-31e0-4de6-a54d-9d1b8dac1f3d.png).
    In the SwarmOps implementation, the velocity is bounded to the full range of the
    search-space, so an agent cannot move further than one search space boundary to
    the other in a single move.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the agent''s velocity has been computed it is added to the agent''s position,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a0293a8a-57f7-4f10-8f0e-1aad6e37eb51.png)'
  prefs: []
  type: TYPE_IMG
- en: Many Optimizing Liaisons (MOL)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A simplification of PSO is called **Many Optimizing Liaisons** (**MOL**) and
    was originally suggested by Kennedy [12], who called it the *Social Only* PSO.
    The name MOL is used in [5], where more thorough studies were made. MOL differs
    from PSO in that it eliminates the particle's best-known position, ![](img/91413f97-6cc3-4be2-9d50-6f384ac4cfe2.png).
    This has been found to improve performance on some problems and makes it easier
    to tune behavioral parameters.
  prefs: []
  type: TYPE_NORMAL
- en: Mesh (MESH)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Fitness can be computed at regular intervals of the search-space using the `MESH`
    method. For increasing search-space dimensionality, this incurs an exponentially
    increasing number of mesh-points to retain a similar interval size. This phenomenon
    is what is known as the Curse of Dimensionality. The `MESH` method is used as
    any other optimization method in SwarmOps is and will indeed return the mesh-point
    found to have the best fitness as its solution. The quality of this solution will
    depend on how coarse or fine the mesh is. The `MESH` method is mostly used to
    make plots of the fitness landscape for simpler optimization problems, or for
    studying how different choices of behavioral parameters influence an optimization
    method's performance, that is, how the meta-fitness landscape looks.
  prefs: []
  type: TYPE_NORMAL
- en: The `MESH` method is not intended to be used as an optimizer.
  prefs: []
  type: TYPE_NORMAL
- en: Parallelism
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Computers with multiple processing units are becoming increasingly popular and
    there are different ways of using this parallelism.
  prefs: []
  type: TYPE_NORMAL
- en: Parallelizing the optimization problem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Some optimization problems can be parallelized internally. The advantage of
    this is that all optimization methods in SwarmOps can be used without modification.
    The disadvantage is that each optimization problem must be parallelized, and this
    process does not take advantage of the natural parallel structure of population-based
    optimizers.
  prefs: []
  type: TYPE_NORMAL
- en: Parallel optimization methods
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: SwarmOps provides parallelized versions of the `DE`, `PSO`, and `MOL` methods,
    all of which merely assume that the implementation of the fitness function is
    thread-safe. These parallelized optimizers are best suited for fitness functions
    that are time-consuming to compute, otherwise the parallelization overhead cancels
    out the gain.
  prefs: []
  type: TYPE_NORMAL
- en: Necessary parameter tuning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Parallel optimizer variants are implemented somewhat differently from their
    sequential versions. The typical way of parallelizing a multi-agent optimizer
    is to maintain and update the population of agents on one execution thread and
    then distribute only the computation of the fitness to multiple execution threads.
    This makes it easier to synchronize access to the data. However, this also means
    the entire population must be processed before improvements can become effective
    and be used in the computation of new candidate solutions. This changes the dynamic
    behavior of the optimizer and means it requires different behavioral parameters
    to work well, which may not necessarily work as well as the optimizer's sequential
    version.
  prefs: []
  type: TYPE_NORMAL
- en: And finally, the code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Assuming you have already downloaded the code we described at the beginning
    of the chapter, let's now take a look at what's happening. To start, let's open
    the `TestParallelMetaBenchmarks` project and open the `main.cs` file. This is
    the file we will be working with for the following code.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we need to create some very important variables which will become settings
    for the optimization layer. We have commented each so that you know what they
    are for, shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Next, we are going to create our optimizer. There are several optimizers included
    with SwarmOps, but for our purposes we will use the MOL optimizer. **MOL** stands
    for **Many Optimizing Liaisons**, which is devised as a simplification to the
    original Particle Swarm Optimization method from Eberhart et al [1][2]. The Many
    Optimizing Liaisons method does not have any attraction to the particles' own
    best-known position, and the algorithm also randomly selects which particle to
    update instead of iterating over the entire swarm. It is similar to the Social
    Only Particle Swarm Optimization suggested by Kennedy [3] and was studied more
    thoroughly by Pedersen et al [4], who found that it can outperform the standard
    Particle Swarm Optimization approach and has more easily-tunable control parameters.
    Whew, that was a mouthful, wasn't it?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Next is the problem(s) that we want to optimize. You can choose to have one
    or multiple problems solved at the same time, but it is often easier to solve
    one optimization tuning problem at a time.
  prefs: []
  type: TYPE_NORMAL
- en: 'The optimizer is having its control parameters tuned to work well on the included
    problem(s), shown as follows. The numbers are the weights that signify the mutual
    importance of the problems in tuning. The higher the weight, the more important
    it is, as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The meta-fitness aspect consists of computing optimization performance for
    the problems we listed over several optimization runs and summing the results.
    For ease of use, we wrap the optimizer in a `MetaFitness` object which takes care
    of this for us, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we need to create out meta-optimizer object, as shown in the following
    snippet. For this, we will use the **Local Unimodal Sampling** (**LUS**) optimizer
    originally created by Pedersen 1\. This object does local sampling with an exponential
    deduction of the sampling range. It works well for many optimization problems,
    especially when only short runs are used or allowed. It is particularly well-suited
    as the overlaying meta-optimizer when tuning parameters for another optimizer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we will wrap the meta-optimizer in a `Statistics` object to log our
    results. We then repeat a number of meta-optimization runs using the `MetaRepeat` object,
    shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Performing meta-optimization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you look at the project, the main method in our optimizer appears to be
    a large method that performs the meta-optimization run, but instead it only takes
    the following line of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: That's it! Everything else involves logging and printing results and information
    to the user.
  prefs: []
  type: TYPE_NORMAL
- en: Computing fitness
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The next block of code that we should look at is how we calculate our solution.
    Our main loop calls our fitness function as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let''s dive into the `Fitness` function. For ease, we have placed the entire
    function in the following snippet. We will dissect each line relative to its importance
    in the function. Our ultimate objective here is to compute the meta-fitness measure
    by passing the parameters to our optimizer. We perform optimization runs on the
    array of problem(s) until the fitness exceeds the `fitnessLimit` parameter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let''s look at our code in action, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d0ae8670-c850-492c-95da-bcc2b8167d02.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, the goal of the program is to output the most optimal parameters
    so that you can tune your network using the same function optimization.
  prefs: []
  type: TYPE_NORMAL
- en: 'But what can you do if you have a function that is not one of those included
    in SwarmOps? Luckily, you can define a custom problem of your own and use it.
    Let''s take a look at how that''s used. First, let''s look at the `TestCustomProblem` project,
    as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ad4f4bca-c395-405a-976a-da0b20ccf2b2.png)'
  prefs: []
  type: TYPE_IMG
- en: TestCustomProblem Project
  prefs: []
  type: TYPE_NORMAL
- en: Testing custom problems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we get into creating and testing our own custom problem, let's talk about
    a more general problem. We have already outlined what we define as a problem earlier
    in this chapter, but now is a good time to show you the code for our base object
    `Problem` before we design our own. So, let's move on.
  prefs: []
  type: TYPE_NORMAL
- en: Base problem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following is the base class `Problem` that is used in every optimization:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The maximum number of optimization iterations to perform is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The following command checks that the solution is feasible (that it satisfies
    constraints):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, the name of the optimization problem is returned with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'This includes an array with the names of the parameters, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'To lower the search-space boundary, use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'To increase the upper search-space boundary, use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The lower initialization boundary, if different from the search-space boundary,
    is denoted as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The upper initialization boundary, if different from the search-space boundary,
    is denoted as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The following command details the maximum (that is, the worst) fitness possible,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The following command details the minimum (that is, the best) fitness possible.
    This is especially important if using meta-optimization where fitness is assumed
    to be non-negative; this should be roughly equivalent among all the problems we
    meta-optimize:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The threshold for an acceptable fitness value is denoted as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'To return the dimensionality of the problem, that is, the number of parameters
    in a candidate solution, use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The following line checks if the gradient has been implemented:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The following command computes and returns fitness for the given parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The fitness evaluation is aborted preemptively if the fitness becomes higher
    (that is, worse) than `fitnessLimit()`, or if it is not possible for the fitness
    to improve, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'We compute and return fitness for the given parameters. The fitness evaluation
    is aborted preemptively if feasibility of the new candidate solution is the same
    as or better than that of the old candidate solution—or if the fitness becomes
    higher (that is, worse) than `fitnessLimit()` and it is not possible for the fitness
    to improve, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Compute and return fitness for the given parameters as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Compute the gradient of the fitness-function with the following command relating
    to the computation time-complexity factor. For example, if fitness takes time
    O(n) to compute and gradient takes time O(n*n) to compute, then `return n. </returns>`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Enforce constraints and evaluate feasibility with the following command. If
    you do not wish to enforce constraints, you should make the call `Feasible()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'By default, we bound the candidate solution to the search-space boundaries,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Since we know that the candidate solution is now within bounds and this is all
    that is required for feasibility, we could just return `true` here. As shown in
    the following snippet, `Feasible` is called for educational purposes, as most
    optimizers call `EnforceConstraints()`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Evaluate feasibility (constraint satisfaction) with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is called at the beginning of an optimization run:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is called at the end of an optimization run:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'To return whether optimization is allowed to continue, use the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: Creating a custom problem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have that out of the way, let's create a custom problem based upon
    our base problem class. The code will look like the following example.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the two-dimensional Rosenbrock problem with some example constraints;
    its optimal feasible solution seems to be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, the base-class overrides the name of the optimizer, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'The dimensionality of the problem is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the lower search-space boundary:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the upper search-space boundary:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'The lower initialization boundary is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'The upper initialization boundary is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'The minimum possible fitness for this problem is worked out using the following
    line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'The acceptable fitness threshold is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'The names of the parameters for the problem are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'To compute and return fitness for the given parameters, use the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'To enforce and evaluate constraints, use the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: Our Custom Problem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, create an object of the custom problem, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'The optimization settings should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Create the optimizer object as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'The control parameters for the optimizer should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Wrap the optimizer in a logger of result-statistics, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Wrap it again in the following repeater:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, initialize the parallel random number generator, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, set the maximum number of optimization iterations to perform with the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a fitness trace for tracing the progress of optimization with the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, assign the fitness trace to the optimizer as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'Perform the optimizations as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'Compute the result-statistics with the following line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'Output the best result, as well as result-statistics, with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'When we run our program, it should look like the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d844cd54-286c-4959-b6a8-14ae58f7bd46.png)'
  prefs: []
  type: TYPE_IMG
- en: The output result of our problem
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned how to use SwarmOps to help us optimize parameters
    for our function optimization. We learned how to use the built-in functions of
    SwarmOps, as well as how to define our own. In the next chapter, we will move
    on to image detection and will use the great open source package, TensorFlowSharp.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: J. Kennedy and R. Eberhart. Particle swarm optimization in Proceedings of IEEE
    International Conference on Neural Networks, volume IV, pages 1942-1948, Pert,
    Australia, 1995
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Y. Shi and R.C. Eberhart. A modified particle swarm optimizer. In Proceedings
    of the IEEE International Conference on Evolutionary Computation, pages 69-73,
    Anchorage, AK, USA, 1998.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'J. Kennedy. The particle swarm: social adaptation of knowledge. In Proceedings
    of the IEEE International Conference on Evolutionary Computation, Indianapolis,
    USA, 1997.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: M.E.H Pederson and A.J. Chipperfield. Simplified particle swarm optimization.
    Applied Soft Computing, 10, P. 618-628, 2010.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Simplifying Particle Swarm Optimization. Pedersen, M.E.H. and Chipperfield, A.J.
    s.l. : Applied Soft Computing, 2010, Vol. 10, pp. 618-628.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Variable metric method for minimization. Davidon, W.C. 1, s.l. : SIAM Journal
    on Optimization, 1991, Vol. 1, pp. 1-17.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '"Direct Search" solution for numerical and statistical problems. Hooke, R.
    and Jeeves, T.A. 2, s.l. : Journal of the Association for Computing Machinery
    (ACM), 1961, Vol. 8, pp. 212-229.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Pedersen, M.E.H. and Chipperfield, A.J.Local Unimodal Sampling. s.l. : Hvass
    Laboratories, 2008\. HL0801.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Differential evolution - a simple and efficient heuristic for global optimization
    over continuous space. Storn, R. and Price, K. s.l. : Journal of Global Optimization,
    1997, Vol. 11, pp. 341-359.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Particle Swarm Optimization. Kennedy, J. and Eberhart, R. Perth, Australia
    : IEEE Internation Conference on Neural Networks, 1995.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A Modified Particle Swarm Optimizer. Shi, Y. and Eberhart, R. Anchorage, AK,
    USA : IEEE International Conference on Evolutionary Computation, 1998.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The particle swarm: social adaptation of knowledge. Kennedy, J. Indianapolis,
    USA : Proceedings of the IEEE International Conference on Evolutionary Computation,
    1997.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
