- en: '*Chapter 16*: Diving Deeper with the IMU'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [*Chapter 12*](B15660_12_Final_ASB_ePub.xhtml#_idTextAnchor251), *IMU Programming
    with Python*, we read data from an **inertial measurement unit** (**IMU**). We've
    now learned a bit more about processing sensor data, using math and pipelines
    to make decisions.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will learn how to get calibrated data from the IMU, combine
    data from the sensors, and use this to make a robot have absolute orientation-based
    behavior. On the way, we'll see algorithms for better precision/speed or accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: By the end of the chapter, you will be able to detect a robot's absolute orientation,
    display it on a screen, and incorporate this with the **Proportional-Integral-Derivative**
    (**PID**) behaviors.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we''re going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Programming a virtual robot
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Detecting rotation with the gyroscope
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Detecting pitch and roll with the accelerometer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Detecting a heading with the magnetometer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting a rough heading from the magnetometer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Combining sensors for orientation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Driving a robot from IMU data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For this chapter, you will need the following items:'
  prefs: []
  type: TYPE_NORMAL
- en: The robot from at least [*Chapter 14*](B15660_14_Final_ASB_ePub.xhtml#_idTextAnchor315),
    *Line-Following with a Camera in Python*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The robot code from [*Chapter 14*](B15660_14_Final_ASB_ePub.xhtml#_idTextAnchor315),
    *Line-Following with a Camera in Python*, at [https://github.com/PacktPublishing/Learn-Robotics-Programming-Second-Edition/tree/master/chapter14](https://github.com/PacktPublishing/Learn-Robotics-Programming-Second-Edition/tree/master/chapter14)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The IMU code from [*Chapter 12*](B15660_12_Final_ASB_ePub.xhtml#_idTextAnchor251),
    *IMU Programming with Python*, at [https://github.com/PacktPublishing/Learn-Robotics-Programming-Second-Edition/tree/master/chapter12](https://github.com/PacktPublishing/Learn-Robotics-Programming-Second-Edition/tree/master/chapter12)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A wide driving space without many magnets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A magnetic compass
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For the complete code for this chapter, go to [https://github.com/PacktPublishing/Learn-Robotics-Programming-Second-Edition/tree/master/chapter16](https://github.com/PacktPublishing/Learn-Robotics-Programming-Second-Edition/tree/master/chapter16).
  prefs: []
  type: TYPE_NORMAL
- en: 'Check out the following video to see the Code in Action: [https://bit.ly/2LztwOO](https://bit.ly/2LztwOO)'
  prefs: []
  type: TYPE_NORMAL
- en: Programming a virtual robot
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will first detect our robot's orientation; it would be useful to show this
    as a 3D robot model. This part builds upon the *Representing coordinate and rotation
    systems* section in [*Chapter 12*](B15660_12_Final_ASB_ePub.xhtml#_idTextAnchor251),
    *IMU Programming with Python*. In this section, we will construct a simple model
    of our robot in VPython.
  prefs: []
  type: TYPE_NORMAL
- en: Modeling the robot in VPython
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We'll use shapes, known as **primitives**, to model the robot. They have a position,
    rotation, size, and color. The height-and-width parameters match the VPython-world
    coordinate system (see *Figure 12.14 – The robot body coordinate system* in [*Chapter
    12*](B15660_12_Final_ASB_ePub.xhtml#_idTextAnchor251), *IMU Programming with Python*),
    so we must rotate things to match the robot body coordinate system.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we need to collect some robot measurements. The following diagram shows
    where they are. Once the major measurements are made, estimates can be used for
    smaller measurements:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15660_16_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.1 – Measurements for the virtual robot
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 16.1* shows the measurements across the robot. A top view and a left
    view show to cover the different aspects. This includes the width and height of
    the base—note that we are treating it as a rectangle for this purpose. The wheels''
    size and position, along with the castor-wheel size and position, are needed.
    Measure or guess these for your robot. For our purposes, guesses are good enough.
    Positions come from the middle of the chassis.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s write the code to make the basic shape, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a file called `virtual_robot.py` and start it by adding in the `vpython`
    import and our robot view, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We''ll put the virtual bot in a function ready to use in a few different behaviors,
    like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We put the robot''s measurements from *Figure 16.1* in variables. I''ve used
    **millimeters** (**mm**) for all of them. The code is shown in the following snippet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The base is a box with the position defaulting to (`0`, `0`, `0`). The code
    is shown in the following snippet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Rotate this box to match the body coordinate system by 90 degrees around the
    *x* axis, putting the *z* axis up, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We''ll use two cylinders for the wheels. The distance from each wheel to the
    middle is roughly half the chassis width. Let''s use it to create the wheels''
    *y* positions, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We set wheel positions to line up with the ends of the motor axles. The left
    wheel has a *y* coordinate; `-wheel_dist` moves it left of the platform, as illustrated
    in the following code snippet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we set the right wheel, with a positive `wheel_dist` and *y* as *1* for
    the axis so that it points to the right, as illustrated in the following code
    snippet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'I''ve used a cylinder for the rear castor wheel, as illustrated in the following
    code snippet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we join all of these parts into a compound object—a single 3D object,
    like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'For testing it, let''s make a tiny `main` section. This code checks if you''ve
    launched it directly, so the following code won''t run when we import the virtual
    robot as a library:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Set the view, putting the camera just in front of the robot, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We''ll add axes to show where things are, like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'And then, we''ll draw the robot, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Upload and test this code with `vpython virtual_robot.py`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open up a browser to port `9020` on your robot to see your virtual robot. You
    should see a figure like the following:![](img/B15660_16_02.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 16.2 – Screenshot of the 3D virtual robot from VPython
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In *Figure 16.2*, we can see the *x* axis facing forward in red, the *y* axis
    going right in green, and the *z* axis going up in blue. This follows a right-hand-rule
    coordinate system. It shows the virtual robot viewed from the front, with a wheel
    on either side. It's gray, boxy, and basic, but it will do for our remaining experiments.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'You can right-click and drag this around to get another view. The mouse wheel
    will also zoom in or out. The following screenshot shows the rear castor:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B15660_16_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.3 – A different view of the virtual robot
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 16.3* shows a left-hand view of this virtual robot.'
  prefs: []
  type: TYPE_NORMAL
- en: Close the browser tab, then press *Ctrl* + *C* to finish this program when done.
    Let's just check you've been able to follow along.
  prefs: []
  type: TYPE_NORMAL
- en: Troubleshooting
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'If you haven''t got this to work, let''s check a few things, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: If you receive errors saying **no such module vpython**, ensure that VPython
    is installed. Follow the steps in [*Chapter 12*](B15660_12_Final_ASB_ePub.xhtml#_idTextAnchor251),
    *IMU Programming with Python*, in the *Reading the temperature* section. You need
    the code from the whole of [*Chapter 12*](B15660_12_Final_ASB_ePub.xhtml#_idTextAnchor251),
    *IMU Programming with Python*, for this chapter to work.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you receive errors saying **no such command vpython**, ensure you have followed
    the *Simplifying the VPython command line* section from [*Chapter 12*](B15660_12_Final_ASB_ePub.xhtml#_idTextAnchor251),
    *IMU Programming with Python*. The alias for VPython is necessary to be able to
    see a display.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you see syntax errors, please check your code for typos.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you cannot reach the display (and have checked *Step 1*), ensure you use
    port `9020` on your robot (mine is [http://myrobot.local:9020](http://myrobot.local:9020)).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Be patient—VPython can take a minute or two to start up.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now that we have a visual robot to play with, we can revisit the gyroscope and
    try to make the onscreen robot move like our real robot.
  prefs: []
  type: TYPE_NORMAL
- en: Detecting rotation with the gyroscope
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We''ve had some raw data from the gyroscope, but to use it more effectively,
    we''ll need to perform two operations, calibrating the gyroscope, and then integrating
    it, as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15660_16_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.4 – The gyroscope data flow
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 16.4* shows the data flow, and we will look closer at the concepts
    later in this section. The first operation is shown at the top, which shows the
    gyroscope data going through an offset calibration to take out errors. This gives
    us a calibrated gyroscope, with a rate of change in degrees per second (per axis)—shown
    by the arrow around the circle. The gyroscope makes a relative measurement.'
  prefs: []
  type: TYPE_NORMAL
- en: The lower part of the diagram is the second operation, combining delta time
    with the calibrated gyroscope (gyro). We need to **integrate** that to find an
    absolute measurement. An integrator multiplies an input value by delta time and
    adds this to a previous result. In this case, we multiply the gyroscope rate by
    delta time to produce a movement for that period (shown by the multiplication
    symbol in a box). The circle above it has a small slither of pie with dashed lines,
    denoting the amount moved.
  prefs: []
  type: TYPE_NORMAL
- en: We add the movement to the last value for that axis, shown by the plus symbol
    box. The circle above it shows a solid gray pie segment for the existing position
    and a new segment with dashed lines. When added, they make the total value for
    that axis—shown by the circle with a large, solid gray pie segment representing
    the addition's result. The system feeds the pitch, roll, or yaw result back into
    the next cycle.
  prefs: []
  type: TYPE_NORMAL
- en: Before we do this, we need to correct the errors in the gyroscope.
  prefs: []
  type: TYPE_NORMAL
- en: Calibrating the gyroscope
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As they come from the factory, **microelectromechanical systems** (**MEMS**)
    gyroscopes usually have minor flaws that cause them to give slightly off readings.
    These flaws will cause drift in our integration.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can make code to detect these and compensate; we call this **calibration**.
    Proceed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a file named `calibrate_gyro.py`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We need VPython for vectors, time for a little sleep, and to set up the IMU,
    as illustrated in the following code snippet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We need vectors to hold the minimum and maximum values of the gyroscope, as
    illustrated in the following code snippet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, for the loop, we''ll do a bunch of readings over time, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To calibrate, we measure for a while to get the minimum and maximum values
    for each axis. The Python `min` function returns the lower of the two values given
    to it, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We do the same for the maximum values, using the Python `max` function, as
    follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The middle of these is an estimate of how far we are from zero. We can calculate
    this by adding the vectors and dividing by 2, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Sleep a little before the next loop, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We print the values so we can use them, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This code is ready to run. Upload and run this with Python 3, leaving the robot
    still on a flat, stable surface until the program exits.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You should see console output ending with something like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'What we''ve measured here is how much the gyroscope changes, on average, when
    stationary. This is calculated as an offset for each axis. By subtracting this
    from the measurements, we will mostly offset any continuous errors from the gyroscope.
    Let''s put this somewhere we can use it, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a file called `imu_settings.py`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We''ll import the `vector` type, and then set our calibration readings. You
    probably only need to run this once, or if you change IMU device. Please use the
    readings you got from your robot. Run the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Next, we upgrade our `RobotImu` class to handle these offsets—open `robot_imu.py`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We will make our class accept offsets if we pass them, or use zero if we leave
    them. Make the highlighted changes to the `__init__` method of `RobotImu`, as
    follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We need to modify the `read_gyroscope` method to account for these too, as
    follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now, to see if this works, let's use it to move a virtual robot.
  prefs: []
  type: TYPE_NORMAL
- en: Rotating the virtual robot with the gyroscope
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We''ve mentioned how we will integrate the gyroscope measurements. Take a look
    at the following diagram to see how this will work for a single axis:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15660_16_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.5 – Integrating a gyroscope axis
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 16.5* shows a dashed circle, indicating a turning circle of an axis.
    The crosshair through the circle shows its center. A thick arrow above and to
    the left of the circle indicates the current heading. A shaded area shows the
    change in rotation in degrees over some time, which we add to the current heading
    to get to the new heading estimate—another thick arrow.'
  prefs: []
  type: TYPE_NORMAL
- en: We multiply the turning rate by time to get a movement; it is an estimate since
    we don't have intermediate values.
  prefs: []
  type: TYPE_NORMAL
- en: The concept of time-since-last-measurement is an important one, seen in the
    PID in [*Chapter 14*](B15660_14_Final_ASB_ePub.xhtml#_idTextAnchor315), *Line-Following
    with a Camera in Python*. It's more commonly known as the delta time.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can combine what we know about the gyroscope with the virtual robot and
    make it rotate on the screen. Let''s use this to rotate our virtual robot, as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new file named `visual_gyroscope.py`. We have many imports here to
    bring the components together, as can be seen in the following code snippet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This time, when we set up the `RobotImu`, we will do so with the settings we
    made, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We are going to integrate three axes: `pitch`, `roll`, and `yaw`. Let''s start
    them at zero, like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We should now set up the virtual robot and the view for it, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We are going to be tracking delta time, so we start by taking the latest time,
    like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We then start the main loop for this behavior. Since this is animating in VPython,
    we need to set the loop rate and tell it to update, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We now calculate the delta time (`dt`), storing a new latest time, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The code reads the gyroscope in the `gyro` vector, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We integrate the current rate (in degrees per second) multiplied by `dt` (in
    seconds), as illustrated in the following code snippet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We reset the model''s orientation to prepare it for rotation, like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We perform the rotations by each axis. We must convert these into radians,
    as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This code is now ready to run; this will make the virtual robot change position
    when we rotate the robot in the real world! Upload the files and run with `vpython
    visual_gyroscope.py`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: As before, wait a minute or so, and point your browser to `myrobot.local:9020`.
    You should see the following display:![](img/B15660_16_06.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 16.6 – The robot rotated
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '*Figure 16.6* shows the virtual robot rotated to an angle by having moved the
    real robot. Move your robot around a bit—try to approximate what you see here.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You'll notice that as you move the robot and return it, it won't line up correctly
    anymore—this is the accumulating errors or drift that gyroscope integration causes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: From this experiment, while seeing some great movement you've also noticed that
    a gyroscope alone can't accurately track rotations. We are going to need to leverage
    the other sensors in the IMU device to improve this.
  prefs: []
  type: TYPE_NORMAL
- en: Let's check it is working before proceeding.
  prefs: []
  type: TYPE_NORMAL
- en: Troubleshooting
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'If it is not quite working, try some of these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: This code requires the use of the `vpython` command and a browser to see the
    results.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the robot is still moving when held still, retry the calibration and offsets.
    The gyroscope's nature is that this won't be perfect—we'll fix that further on.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the robot appears to spin uncontrollably or jump around, ensure you've remembered
    to convert to radians.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the robot is rotating the wrong way (left/right instead of up/down), check
    the rotations' axis parameters.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now that you have this working, let's move on to the accelerometer so that we
    can see forces acting on our robot!
  prefs: []
  type: TYPE_NORMAL
- en: Detecting pitch and roll with the accelerometer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [*Chapter 12*](B15660_12_Final_ASB_ePub.xhtml#_idTextAnchor251), *IMU Programming
    with Python*, we were getting a vector from the accelerometer, but we need to
    calculate angles to consider using it alongside the gyroscope and magnetometer.
    To use this to rotate things, we need to turn this vector into pitch-and-roll
    angles.
  prefs: []
  type: TYPE_NORMAL
- en: Getting pitch and roll from the accelerometer vector
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The accelerometer describes what is going on in **Cartesian coordinates**. We
    need to convert these into a pair of pitch-and-roll angles perpendicular to each
    other. In [*Chapter 12*](B15660_12_Final_ASB_ePub.xhtml#_idTextAnchor251), *IMU
    Programming with Python*, the *Coordinate and rotation systems* section shows
    roll as taking place around the *x* axis, and pitch as taking place around the
    *y* axis.
  prefs: []
  type: TYPE_NORMAL
- en: 'A crude but effective way to consider this is as two planes. When rotating
    around the *x* axis, you can take a vector in the *yz* plane and find its angle.
    When turning around the *y* axis, then you consider the *xz* plane instead. Take
    a look at the next diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15660_16_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.7 – The accelerometer vector and angles
  prefs: []
  type: TYPE_NORMAL
- en: In *Figure 16.7*, the background has *x*, *y*, and *z* axes and a sphere, with
    circles around the *xz* and *yz* planes.
  prefs: []
  type: TYPE_NORMAL
- en: The accelerometer vector is shown as vector **A**. By using only the *xz* components,
    we project this vector onto an *xz* circle at point **C**; so, the angle from
    the *z* axis to **C** is the pitch. We project **A** again onto a *yz* circle
    at point **B**; this angle from the *z* axis to **B** is the roll.
  prefs: []
  type: TYPE_NORMAL
- en: 'When we have two components (*x* and *z*, for example) on a plane, they can
    be used in the `atan2` function (present in most programming languages) to get
    an angle from them. A slight quirk here is that the orientation of the different
    sensor components means we must negate the pitch. The following diagram shows
    the process:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15660_16_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.8 – Accelerometer data flow
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 16.8* shows the raw accelerometer data going into the arctangent to
    get the angles and outputting the accelerometer pitch/roll values.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s turn the accelerometer readings into pitch and roll, and then put them
    into a graph, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: First, open up `robot_imu.py`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Extend the imports to include the trigonometric functions, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'After the `read_accelerometer` method, add the following code to perform the
    required math:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Let's show these angles on a graph, which will also reveal a major flaw with
    using the accelerometer on its own. Create a `plot_pitch_and_roll.py` file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Start with imports, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We create the graphs, like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we set up a start time so that we can make a time-based graph, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can now get our new pitch-and-roll values, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'And then, we can put both sets into graphs, like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Upload both the `robot_imu.py` and `plot_pitch_and_roll.py` files. Run this
    with `vpython plot_accel_pitch_and_roll.py`, and point your browser at port `9020`
    on the robot. This should result in the following:![](img/B15660_16_09.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 16.9 – Accelerometer pitch-and-roll graph
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 16.9* shows a screenshot of the graph. The red curve in the graph represents
    pitch, around the *y* axis, while the green curve represents roll, around the
    *x* axis. Although it shows swings between +90 and -90 degrees, what is also clear
    is that the graph has a lot of noise, so much so that movements of less than a
    second are blotted out by it.'
  prefs: []
  type: TYPE_NORMAL
- en: We need to clean this up. A common way to do so is through a complementary filter,
    combining a new value with a previous value to filter out fast vibration noise.
    We will create such a filter, but it makes sampling slower.
  prefs: []
  type: TYPE_NORMAL
- en: Let's check that this is working.
  prefs: []
  type: TYPE_NORMAL
- en: Troubleshooting
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'If it''s not quite working, let''s try a few fixes, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: If it's very noisy, try a more severe turn, and try keeping your hands steady.
    This graph will be noisy due to the nature of the accelerometer alone.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you see the graph break up or misbehave outside of the 0-90-degree range,
    ensure you are using the `atan2` function—this mathematically performs the trigonometric
    CAST rule.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Notice that the `read_accelerometer_pitch_and_roll` method has a negative sign
    in front of the `atan2` function.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If things misbehave at 180 degrees—this is a known and expected problem with
    this system—try to avoid hitting this yet.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now, we have the pitch and roll, but it''s quite rough—a suitable way to fix
    this is to combine sensors through a filter. We have another sensor that is giving
    us an integrated pitch-and-roll value: the gyroscope.'
  prefs: []
  type: TYPE_NORMAL
- en: Smoothing the accelerometer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can combine what we know about integrating the gyroscope with the accelerometer
    to make a smooth combination.
  prefs: []
  type: TYPE_NORMAL
- en: Since we will use the delta-time concept more, a class to help will save us
    some work later.
  prefs: []
  type: TYPE_NORMAL
- en: Delta time
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We saw before how we tracked the elapsed time for graphing and the delta time
    between updates for integrating. Let''s create the code to help, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Make a `delta_timer.py` file and start by importing `time`, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We''ll make a `DeltaTimer` class that will keep track of things, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The central part of this is an `update` method. Every loop calls this; let''s
    start by getting the current time, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The delta time will be the difference between the current time and last time,
    as illustrated in the following code snippet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The elapsed time is the difference between the current time and the start time,
    as illustrated in the following code snippet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We now need to update the last time for the delta time and return the parts,
    as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We can use this class whenever we need a delta time and an elapsed time for
    graphing. Let's start by using it to combine the accelerometer and gyroscope.
  prefs: []
  type: TYPE_NORMAL
- en: Fusing accelerometer and gyroscope data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'By combining the sensors, we can let each of them complement the other''s weaknesses.
    The accelerometer acts as an absolute measurement for pitch and roll to counteract
    the drift seen by the gyroscope. The gyroscope does not experience the same noise
    as the accelerometer but can make fast measurements. Let''s see how to combine
    them in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15660_16_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.10 – Gyroscope and accelerometer fusion data flow
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 16.10* shows the data flow diagram, using a complementary filter to
    fuse gyroscope and accelerometer data. We''ll take pitch as an example. First,
    the system feeds gyroscope data and delta time into an integrator. The integrator
    adds this to a previous position. We can then use 95% of this term to account
    for larger movement changes. The filter''s other 5% is the accelerometer measurement.
    This 5% will drag the measurement to the average accelerometer reading while filtering
    out the chaotic noise element. The output is a filtered pitch or roll, fed back
    into the integrator for the next cycle.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s put this into code, starting with the filter, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Open up `robot_imu.py`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add the `ComplementaryFilter` class, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can construct this filter with the left side''s value, storing this and
    calculating the complement (one minus the left side) to make the right side, as
    follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This class has a `filter` method that takes the two sides and combines them
    using the filter values, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: That finishes the filter.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The next thing we''ll want is code to combine the IMU sensors via filters –
    to fuse them. We''ll add a class for this to `robot_imu.py`, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the constructor, we will store the `RobotImu` instance, create a filter,
    and seed the pitch-and-roll values, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The core part of this code is an `update` function. The function takes a `dt`
    (delta time) parameter. It will not return anything and just updates the pitch/roll
    members, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We start by taking the pitch-and-roll values from the accelerometer, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We also want the gyroscope values, so we run the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we combine the gyroscope *y* reading and accelerometer pitch to get the
    pitch value, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Notice here the multiply and addition operations from the preceding data flow.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We do the same for the roll, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we have prepared the `RobotImu` class with filters and fused the sensors.
    Let''s give this code a test drive with a graph, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the `plot_pitch_and_roll.py` file, we''ll add the `DeltaTimer`, `ImuFusion`,
    and gyroscope calibration imports. Note in the following code snippet that `import
    time` has been removed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we set up the `RobotImu` with the gyroscope settings, and then create
    the `fusion` instance, as illustrated in the following code snippet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We need a `dt` (delta time) for the fusion calculations and an elapsed time
    for the graph. The `DeltaTimer` class provides these. We put this close before
    the loop starts, replacing the assignment of `start`, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, in the loop where we calculate `elapsed`, we use the delta timer, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, replace the reading of the accelerometer with code to update the fusion
    with the delta time so that it makes its calculations, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can now fetch pitch-and-roll values from the `fusion` object, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Upload `robot_imu.py`, `delta_timer.py` and `plot_pitch_and_roll.py` to the
    robot.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run `vpython plot_pitch_and_roll.py`, again and point your browser at port `9020`
    on the robot.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Superficially, it should look similar to the accelerometer pitch-and-roll graph
    in *Figure 16.9*. However, as you move the robot around, you should notice that
    there is far less noise—the graph is smoother—and that when you place the robot
    down or hold it still, it levels off. It should quickly account for rapid turns.
    The system is smooth and accurate!
  prefs: []
  type: TYPE_NORMAL
- en: Troubleshooting
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'If you have issues, try these troubleshooting checks:'
  prefs: []
  type: TYPE_NORMAL
- en: As always, if you see syntax errors or strange behavior, check the code carefully.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If things move strangely, ensure you are using `0.95` (and not `95`) for the
    filter value.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Ensure you've uploaded all the files.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This system will need a second or two after the graph starts to settle.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You've now seen how to get an accurate and smooth pitch and roll from these
    sensors. A robot on wheels may not encounter many reasons to use pitch and roll,
    but one of them will be to make a compass work. Let's dig further into the magnetometer.
  prefs: []
  type: TYPE_NORMAL
- en: Detecting a heading with the magnetometer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We saw in [*Chapter 12*](B15660_12_Final_ASB_ePub.xhtml#_idTextAnchor251), *IMU
    Programming with Python*, how to plot a vector from the magnetometer, and how
    magnetic metal (such as bits of steel and iron) will interfere with it. Even the
    pin headers on the IMU board interfere. We can calibrate to compensate for this.
  prefs: []
  type: TYPE_NORMAL
- en: Getting *X*, *Y*, and *Z* components aren't that useful; we want a heading relative
    to a magnetic North. We can see how to use this for precise turns.
  prefs: []
  type: TYPE_NORMAL
- en: This section needs a space, with very few magnets present. Laptops, phones,
    speakers, and disk drives interfere with this sensor. Use a map compass to reveal
    magnetic fields in your space. I recommend making the standoff *stalk* on the
    robot as long as the cable allows, putting more standoffs in; the robot's motors
    have a strong magnetic field of their own.
  prefs: []
  type: TYPE_NORMAL
- en: Please avoid starting with the robot facing South—this will cause some odd results,
    which we will investigate and fix later. Starting with the robot roughly North
    is a good idea.
  prefs: []
  type: TYPE_NORMAL
- en: Calibrating the magnetometer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We are going to perform a calibration known as the **hard iron offset calculation**.
    Hard iron refers to any magnetic things near the magnetometer that move with it.
    We move the robot around to sample the field strength in each axis. We will use
    the middle of all readings for an axis to compensate, and add this to the IMU
    settings; this will seem similar to the gyroscope calibration but requires you
    to move the robot around.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s write the code, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a file named `magnetometer_calibration.py`, starting with imports and
    the `RobotImu` setup, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We will find minimum and maximum vectors, as we did for the gyroscope, as illustrated
    in the following code snippet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We are going to show the system as a set of three scatter charts with colored-dot
    clusters. Each of the three clusters is a plot combining two axes: *xy*, *yz*,
    and *xz*. Our goal is to make the sets line up by calibrating the device, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We start the main loop and read the magnetometer, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we update the minimums, in the same way we did for the gyroscope, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'And then, we update the maximums, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We then calculate the offset in the same way as we did for the gyroscope, as
    follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This `print` statement shows the current values and offsets:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we create the plots. They will guide you in getting enough calibration
    data and show where the axes do not line up. The code is shown in the following
    snippet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Upload this and run it with VPython. You should see the following screen:![](img/B15660_16_11.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 16.11 – Initial magnetometer calibration screen
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '*Figure 16.11* shows the clusters as three colored blobs—the bottom right is
    red, (for *xy*), the top is blue (for *yz*), and on the right is green (for *zx*).
    These clusters will start in a different position for you, depending on the orientation
    of your robot.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You need to move the robot around, rotating it slowly around the whole *y* axis
    (around the wheels). The green graph should be more like an ellipse, as illustrated
    in the following screenshot:![](img/B15660_16_12.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 16.12 – The magnetometer partially calibrated
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '*Figure 16.12* shows the ellipse for the green values, and more data for the
    red and blue scatter plots. The slower you are, the better the data is.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Rotate the robot around the *x* axis (the length of the robot), and then around
    the *z* axis (around its height). The more angles you move it through, the better.
    Fill in the gaps by making 3D figures of 8\. Eventually, it should look like the
    graph in the following screenshot:![](img/B15660_16_13.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 16.13 – Magnetometer calibration: a good combination'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '*Figure 16.13* shows how a good collection of data should look, with circles
    of red, green, and blue. Note that there are outliers due to waving the robot
    too close to other magnets—beware of these!'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You can close the browser now, having collected a load of calibration data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The console will show the calibration offsets, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: At the start, those offsets change a lot; however, as you collect more data,
    they will settle and stabilize, even when the magnetometer readings are changing.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: We now have some calibration numbers; my example gave `21.15, 3.15, 0.225`.
    Let's make sure that everyone has some values.
  prefs: []
  type: TYPE_NORMAL
- en: Troubleshooting
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This calibration may not have worked—let''s see why, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: If the numbers don't appear to be settling, continue moving the robot. You must
    try to do full 360-degree movements with it to get a full range.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If strange dots appear outside of the circle, move somewhere else and restart
    the calibration—this is likely to be a magnetic field where you are testing, and
    will throw your results off.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: There is a possibility your browser will get slow or run out of memory trying
    to do this—while I say move slowly, you cannot put this aside while running as
    it will continue adding dots.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you don't get circles at all—lines or small patches—double-check that you
    have the right plot combinations of *xy*, *yz*, and *zx*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You should now be getting calibration offsets. Let's use these values to line
    up the scatter plots.
  prefs: []
  type: TYPE_NORMAL
- en: Testing the calibration values
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To see if these are effective we''ll put them back into the code, and the same
    operation should show the dot clusters lining up. It starts by allowing us to
    set offsets in the `RobotImu` interface. Proceed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Open up the `robot_imu.py` file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the `__init__` method, we need to store the offsets. I''ve highlighted the
    new code, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The `read_magnetometer` method needs to subtract the magnetometer offsets,
    like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Our scripts can now include an offset for the magnetometer. We''ll put these
    in the same settings file we used for the gyroscope calibrations. Proceed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Open `imu_settings.py`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add the magnetometer calibration readings from your robot, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we can use them in our scatter plot. Open up `magnetometer_calibration.py`
    and add our settings to the imports, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'When we have created our `RobotImu` we can apply the offset, like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Send the files to the robot, and rerun `magnetometer_calibration.py`. You''ll
    need to make rotations and figures of 8 again to get many sample points at different
    orientations. When you have collected the data you should have overlapping circles,
    as depicted in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B15660_16_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.14 – Calibrated magnetometer
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 16.14* shows the red, blue, and green circles superimposed. Congratulations—you
    have calibrated your magnetometer!'
  prefs: []
  type: TYPE_NORMAL
- en: With your calibrated magnetometer, we can try further experiments with more
    useful values. But first, let's troubleshoot any problems.
  prefs: []
  type: TYPE_NORMAL
- en: What to do if the circles aren't together
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You may have reached this point, and the circles are not converging. Try these
    troubleshooting steps if this is the case:'
  prefs: []
  type: TYPE_NORMAL
- en: You will need to rerun the calibration code. Before you do so, comment out the
    line that applies (sets) the offsets on the `RobotImu` class. Running the calibration
    code when you have offsets active will cause it to offset incorrectly.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Check your calibration and IMU code carefully for errors.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Ensure there are no strong magnets or big chunks of metal near the robot—speakers
    or hard disks, for example. Try to do this about a meter away from such things.
    Even your laptop or mobile phone can interfere.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Ensure you go through each axis slowly and try the figure of 8\. Keep going
    until you can see three ellipses.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You can use the console output, rotating the robot and moving around in every
    orientation, and then seeing if the offset values output here settle.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When the outputs settle, try applying the offset again, and run the calibration
    to see if the circles converge.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After going through these, you should have the calibration values you need to
    continue. Let's put this back into the vector output we had and determine a heading.
  prefs: []
  type: TYPE_NORMAL
- en: Getting a rough heading from the magnetometer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we''ve got calibration settings, we can start using magnetometer readings
    to estimate where North is, like a compass. The words *heading* and *yaw* mean
    the same thing —which way we face relative to a reference point—in this case,
    magnetic North. Let''s see how we can do this. Have a look at the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15660_16_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.15 – Getting an approximate heading from the magnetometer
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 16.15* shows a method we will build. It takes the magnetometer with
    calibration data applied and uses `atan2`, as we did with the gyroscope to approximate
    the heading. We can also add a rough compass with it too.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s make this, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a `plot_mag_heading.py` file. Start with the imports, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can initialize the `RobotImu` with the settings, like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To make a compass display, we need a dial (cylinder) and needle (arrow) in
    red, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, let''s make a graph to show the heading, and a delta timer for elapsed
    time, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We start the main loop with a rate and fetch the elapsed time, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we read the magnetometer by running the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can take the *xy* plane and find the `atan2` function of these values of
    this to get a heading, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then, we plot this on the graph in degrees, like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can also set the needle axis to our direction, using `sin`/`cos` to convert
    it back into a unit direction, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Save, upload, and run this in VPython. Send your browser to port `9020` on the
    robot.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'If you rotate the robot around, you will see a display like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B15660_16_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.16 – Magnetometer heading estimate
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 16.16* shows a compass, with the top being what the robot perceives
    as North, and a red arrow. Below this is a blue graph, ranging between + and –180
    degrees. As you move the robot, you will see this move, with 0 degrees being North.
    You will need the robot to be on a flat surface, though.'
  prefs: []
  type: TYPE_NORMAL
- en: Note that the compass is reading where North is relative to the robot—not where
    the robot is relative to North!
  prefs: []
  type: TYPE_NORMAL
- en: This output is starting to appear reasonable. It can point North and make some
    compass measurements, and we have a heading.
  prefs: []
  type: TYPE_NORMAL
- en: It is a little chaotic, and you can make it incorrect by any pitch or roll.
    Again, by fusing this data with data from the other sensors, we can improve this.
  prefs: []
  type: TYPE_NORMAL
- en: Combining sensors for orientation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We've seen how we combined the accelerometer and gyroscope to get smooth readings
    for pitch and roll. We can combine the sensors again to correctly orient and smooth
    the magnetometer readings too. This system allows us to approximate the absolute
    orientation of the robot.
  prefs: []
  type: TYPE_NORMAL
- en: 'Take a look at the following data flow to see what we are doing—it builds on
    the previous stages:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15660_16_17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.17 – Fusing all three sensors
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 16.17* starts on the left with data from our previous stages. We have
    the filtered pitch and roll in gray because it''s also an output. There''s the
    calibrated gyroscope yaw, delta time, and also the calibrated magnetometer as
    inputs. The filtered pitch and roll go through the tilt-compensate box, where
    we rotate the magnetometer vector. The magnetometer data then goes through an
    *xy*-to-polar box, using the `atan2` function to get a heading.'
  prefs: []
  type: TYPE_NORMAL
- en: Above this, the calibrated gyroscope yaw and delta time go into an integrator,
    which adds to a previous yaw reading. The integrator and magnetometer heading
    output go into a complementary filter, with the integrator output being dominant.
    This filter output is then a heading/yaw output, which will be stable and quick
    to respond, and will return to the absolute heading. We now have three angles—pitch,
    roll, and yaw!
  prefs: []
  type: TYPE_NORMAL
- en: Let's modify the code to do this, as follows;
  prefs: []
  type: TYPE_NORMAL
- en: Open up `robot_imu.py` and head to the `ImuFusion` class.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We will need to convert back to radians, so we need to add this to the imports
    from VPython, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the `__init__` method, we should add a variable to store the yaw in, as
    follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We are going to use the same filter for now.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'In the `update` method, after calculating the pitch and roll, add the following
    line to get the magnetometer reading:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The `mag` variable is a vector. We rotate this using pitch and tilt to level
    the *xy* components, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can now calculate the magnetometer yaw from this, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To stabilize this, we can now use the complementary filter with the gyroscope,
    as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The `self.yaw` value will now have the compensated yaw (or heading) value,
    allowing this IMU to act as a compass. To make use of it, let''s visualize it
    in three ways—as a graph, a compass, and the movement of the robot. Proceed as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Put this in a new file called `visual_fusion.py`. The code will be very familiar.
    Only the magnetometer offsets and yaw values are new. The imports are shown in
    the following code snippet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Prepare the `RobotImu` with magnetometer offsets, and initialize `fusion`,
    as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We are going to use a VPython canvas for the virtual robot, and a separate
    one for the compass. Each canvas lets us contain a 3D scene. Let''s make the current
    canvas a robot view and put it on the left. The robot model will be associated
    with this. The code is shown in the following snippet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To accompany the robot view, we''ll create a `compass` canvas, using the same
    cylinder and arrow as previously. Note that the most recent canvas is associated
    with the shapes created after it. The code is shown in the following snippet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE99]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Set up graphs for pitch, roll, and yaw, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a delta timer, start the loop, and fetch the time update, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE101]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We now update `fusion` with the time (it will read the IMU and perform calculations),
    as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE102]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we need to reset the virtual robot model before we rotate it, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE103]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'And then, we need to perform three rotations—roll, pitch, and yaw, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE104]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We position the compass needle—note that our yaw is in degrees, so we convert
    it, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE105]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then, we plot the three-graph axes, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE106]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Upload `robot_imu.py` and `visual_fusion.py` to the robot. Start with `vpython
    visual_fusion.py` and point your browser at port `9020` on the robot.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You should see the visual robot, compass, and a graph for all three axes displayed,
    and each should be both relatively stable and responsive, as depicted in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15660_16_18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.18 – Pitch, roll, and yaw graph
  prefs: []
  type: TYPE_NORMAL
- en: The graph in *Figure 16.18* is a screenshot of the display. In the top left
    is the virtual robot—you can change its view by right-clicking. The top left shows
    the compass. Below that is a scrolling pitch, yaw, and roll graph. The roll is
    in red, pitch is in green, and yaw is in blue. The graphs will initially settle
    and then match your robot movements. When moving in one axis there is a small
    effect on the others, but they can move independently.
  prefs: []
  type: TYPE_NORMAL
- en: At +/-180 degrees, the graph will misbehave though. Let's see how to fix that.
  prefs: []
  type: TYPE_NORMAL
- en: Fixing the 180-degree problem
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The fundamental thing to realize is that angles on a circle are cyclical; 200
    degrees and -160 degrees are equivalent, and -180 degrees and 180 degrees are
    also equal. We've not made the filter or code aware of this, so when we reach
    the 180-degree point and the `atan2` function is flipping between -179.988 and
    179.991 (or some similar very close mark), the graph becomes chaotic, treating
    the difference of less than 1 degree as 360 degrees, and then trying to filter
    between them.
  prefs: []
  type: TYPE_NORMAL
- en: 'This problem needs some changes to fix it. First, we can state that we intend
    angles to be numerically below 180 and above -180 and constrain them this way.
    Since we intend to use the complementary filter with angles, we can specialize
    it, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'At the top of `robot_imu.py`, inside the `ComplementaryFilter` class, let''s
    add a method to format the angle, like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE107]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'If the angle is below -180, we want to wrap it around by adding `360`, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE108]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'If the angle is above 180, we wrap it around by subtracting `360`, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE109]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We will replace the inside of the `filter` function with something to constrain
    these angles more intelligently. When we filter, we start by formatting the incoming
    angles, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE110]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We also want to put the filtered angles in the same range. If there is a difference
    of more than 350 degrees, we can assume that something has wrapped around; so,
    we add 360 to the lowest one to filter them together, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE111]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This operation could leave an answer outside of the range. So, we format it
    back, like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE112]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This filter is in use already, so we can rerun `visual_fusion.py` and try turning
    back through 180 degrees again. When you point your browser at the port, after
    settling, the robot there should be rotating with yours—and settling, not drifting!
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note that this system still doesn't deal well with facing South when it starts.
    We've solved at least one problem with the system and smoothed out its flaws.
  prefs: []
  type: TYPE_NORMAL
- en: 'This behavior is exciting: you can now get a robot on screen to mirror how
    you rotate it. However, while moving on the screen is fun, we''d like to see this
    used in the real world. Let''s engage some motors!'
  prefs: []
  type: TYPE_NORMAL
- en: Driving a robot from IMU data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In previous chapters, we saw how to use the PID algorithm, and in this chapter,
    how to detect a pitch, roll, and yaw from a magnetometer. Our robot can't move
    its pitch or roll, but it can change its heading.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this demonstration, we''ll get the robot to stay on course—to try to track
    North regardless of where we turn it. Let''s see how. Have a look at the following
    diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15660_16_19.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.19 – Drive to heading behavior
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 16.19* shows the flow of data. The left of the diagram starts with
    a measured heading, and a heading setpoint going into a PID—the error value will
    be the difference between the two. The measured heading has come from the **IMU
    + Fusion** algorithm. We use the PID output to drive the motors so that they move
    at a fixed speed plus or minus the value, so the robot will turn to reduce the
    error. The robot moving will feed back into the **IMU + Fusion** algorithm, looping
    through the PID.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take the preceding flow and use it to build the code, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Start a `drive_north_behavior.py` file with the following imports:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE113]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We now initialize the `RobotImu`, `fusion`, and the `DeltaTimer`, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE114]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can then set up a PID (or PI) controller and the robot, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE115]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'And then, a couple of constants—the robot''s base speed, and the heading setpoint
    in degrees from North, as illustrated in the following code snippet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE116]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The main loop here updates the timer and IMU fusion. Note in the following
    code snippet that there''s not a visual rate here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE117]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We now calculate the error, and feed the PID with that and the delta time,
    as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE118]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We print the values to debug, and set our motor speeds, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE119]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Upload this to the robot, turn on the motors, and run with regular Python 3\.
    The robot will try to drive North. If you turn it off course it will correct back
    to North, and the more you turn it, the faster the motors will try to turn back.
    Playing with this behavior is quite fun!
  prefs: []
  type: TYPE_NORMAL
- en: Press *Ctrl* + *C* to stop this when you are done, and play with different heading
    set points.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, you've reinforced building data flow diagrams and writing code
    from them. You've further demonstrated that by converting sensor data to a number
    like this, you can build a PID-based behavior with it. You've then taken the heading
    that we've calculated and used it with the PID to create compass-based movement
    from your robot.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you've seen how to combine the IMU sensors to approximate an
    absolute orientation in space. You've seen how to render these in graphs and how
    to display them onscreen with a virtual robot. You've then seen how to hook this
    sensor system up to a PID controller and motor to get the robot to drive.
  prefs: []
  type: TYPE_NORMAL
- en: You've learned a little of the math needed to convert between vector components
    and angles, in 3D, along with how to use complementary filters to compensate for
    noise in one system and drift in another. You've started to see multiple sensors
    fused together to make inferences about the world. Your block diagram and data
    flow skills have been exercised, and you have had more practice with the PID algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will look at how you can control your robot and choose
    behaviors from a menu with a smartphone.
  prefs: []
  type: TYPE_NORMAL
- en: Exercises
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here are some ideas to further your understanding, and give you some ideas
    for more interesting things to do with the concepts from this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: A reader can use more colors and complicated shapes to make a better robot model.
    It's not the purpose of this chapter, but it is a fun and rewarding way to get
    more familiar with VPython.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Our magnetometer settings were hardcoded, going into a Python file. It is good
    practice to load settings from a data file. A good starting point can be found
    at [http://zetcode.com/python/yaml/](http://zetcode.com/python/yaml/).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Could the visual robot be used to display or debug the other sensors and integrations?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Could you combine the absolute positioning here with the encoders to make a
    square with very accurate turns?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For more information on the topics covered in this chapter, refer to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The **World Wide Web Consortium** (**W3C**) has a guide on magnetometer devices
    in browsers, which makes for interesting reading on techniques, but also on how
    code on a smartphone might be able to perform these same algorithms to get the
    phone orientation: [https://www.w3.org/TR/magnetometer](https://www.w3.org/TR/magnetometer).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'I''ve mentioned the `atan2` function a lot; this page has further information
    on it: [https://en.wikipedia.org/wiki/Atan2](https://en.wikipedia.org/wiki/Atan2).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'I recommend Paul McWhorter''s Arduino experiments with an IMU, and his introduction
    to VPython—his guide was an instrumental part in the research for this book: [https://toptechboy.com/arduino-based-9-axis-inertial-measurement-unit-imu-based-on-bno055-sensor/](https://toptechboy.com/arduino-based-9-axis-inertial-measurement-unit-imu-based-on-bno055-sensor/).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This paper takes things a bit further and introduces a **Global Positioning
    System** (**GPS**) for further sensor fusion: [https://www.researchgate.net/publication/51873462_Data_Fusion_Algorithms_for_Multiple_Inertial_Measurement_Units](https://www.researchgate.net/publication/51873462_Data_Fusion_Algorithms_for_Multiple_Inertial_Measurement_Units).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If you wish to dig deeper into sensor fusion, and algorithms to combine them
    while filtering errors, Kalman filters are the way to go. This article is a starting
    point: [https://towardsdatascience.com/sensor-fusion-part-1-kalman-filter-basics-4692a653a74c](https://towardsdatascience.com/sensor-fusion-part-1-kalman-filter-basics-4692a653a74c).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
