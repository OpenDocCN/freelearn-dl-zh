- en: '7'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '7'
- en: Useful Frameworks, Libraries, and APIs
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 有用的框架、库和API
- en: As you might expect, **Python** is the most popular programming language for
    building intelligent AI applications. This is due to its flexibility and ease
    of use, as well as for its vast number of **AI and machine learning** (**ML**)
    libraries. Python has a specialized library for nearly all the necessary tasks
    required to build a **generative AI** (**GenAI**) application.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所预期，**Python**是构建智能AI应用程序最受欢迎的编程语言。这得益于其灵活性、易用性，以及其庞大的**AI和机器学习**（**ML**）库。Python几乎为构建**生成式AI**（**GenAI**）应用程序所需的全部必要任务提供了专门的库。
- en: In [*Chapter 1*](B22495_01.xhtml#_idTextAnchor009), *Getting Started with Generative
    AI*, you read about the GenAI stack and the evolution of AI. Like the AI landscape,
    the Python library and framework space also went through an evolution phase. Earlier,
    libraries such as pandas, NumPy, and polars were used for data cleanup and transformation
    work, while PyTorch, TensorFlow, and scikit-learn were used for training ML models.
    Now, with the rise of the GenAI stack, LLMs, and vector databases, a new type
    of AI framework has emerged.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第一章*](B22495_01.xhtml#_idTextAnchor009)“开始使用生成式AI”中，您了解了生成式AI堆栈和AI的演变。就像AI景观一样，Python库和框架空间也经历了演变阶段。早期，pandas、NumPy和polars等库用于数据清理和转换工作，而PyTorch、TensorFlow和scikit-learn用于训练机器学习模型。现在，随着生成式AI堆栈、大型语言模型（LLMs）和向量数据库的兴起，一种新的AI框架已经出现。
- en: These new libraries and frameworks are designed to simplify the creation of
    new applications powered by LLMs. Since building GenAI applications requires the
    seamless integration of data from many sources and the use of diverse AI models,
    these AI frameworks provide built-in functionalities to facilitate acquiring,
    migrating, and transforming data.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 这些新的库和框架旨在简化由LLMs驱动的应用程序的创建。由于构建生成式AI应用程序需要无缝集成来自多个来源的数据和使用多种AI模型，这些AI框架提供了内置功能，以促进数据的获取、迁移和转换。
- en: This chapter delves into the world of AI/ML frameworks, exploring their importance
    and highlighting why Python has emerged as the go-to language for AI/ML development.
    By the end of this chapter, you’ll be able to understand the most popular frameworks
    and libraries, as well as how they help you—the developer—build your GenAI application.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章深入探讨了AI/ML框架的世界，探讨了它们的重要性，并强调了为什么Python成为了AI/ML开发的首选语言。到本章结束时，您将能够理解最流行的框架和库，以及它们如何帮助您——开发者——构建您的生成式AI应用程序。
- en: 'This chapter will cover the following topics:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: AI/ML frameworks
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AI/ML框架
- en: Python libraries
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python库
- en: Publicly available APIs and other tools
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 公开可用的API和其他工具
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'To perform the steps shown in this chapter, you will need the following:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 要执行本章中显示的步骤，您需要以下内容：
- en: Latest major version of Python.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python的最新主要版本。
- en: A free tier Atlas cluster running MongoDB version 6.0.11, 7.0.2, or later.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行MongoDB版本6.0.11、7.0.2或更高版本的免费层Atlas集群。
- en: Your current IP address added to your Atlas project access list.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将您的当前IP地址添加到Atlas项目访问列表中。
- en: An environment set up to run Python code in an interactive environment, such
    as Jupyter Notebook or Colab. This chapter uses Jupyter Notebook.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个用于在交互式环境中运行Python代码的环境，例如Jupyter Notebook或Colab。本章使用Jupyter Notebook。
- en: Python for AI/ML
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Python用于AI/ML
- en: Python has established itself as the go-to programming language in various fields,
    but most notably in AI, ML, and building applications powered by **large language
    models** (**LLMs**). Python offers simplicity, readability, and a robust ecosystem
    of libraries, making it an ideal choice for all kinds of users, whether they are
    developers, researchers, or even students just getting started with programming.
    Python has also emerged as the language of choice for building new LLM-powered
    applications, underscoring Python’s usefulness, popularity, and versatility.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: Python已经在各个领域确立了其作为首选编程语言的地位，但在AI、ML以及构建由**大型语言模型**（**LLMs**）驱动的应用程序方面最为显著。Python提供了简单性、可读性和强大的库生态系统，使其成为所有类型用户的理想选择，无论是开发者、研究人员，还是刚开始接触编程的学生。Python也已成为构建新的LLM驱动应用程序的首选语言，这凸显了Python的有用性、流行性和多功能性。
- en: 'In this section, you will learn some of the reasons that make Python a great
    choice for building modern AI-powered applications:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，您将了解一些使Python成为构建现代AI驱动应用程序的绝佳选择的理由：
- en: '**Simplicity and readability**: Python’s syntax is designed to be intuitive
    and clear, which is one of its core strengths. Python can represent complex algorithms
    and tasks in a few lines of code that are easily readable and understandable.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**简洁性和可读性**：Python的语法设计旨在直观且清晰，这是其核心优势之一。Python可以用几行易于阅读和理解代码来表示复杂的算法和任务。'
- en: '**Rich ecosystem of libraries and frameworks**: Python offers an extensive
    range of libraries and frameworks specifically designed for AI/ML use cases. Libraries
    such as TensorFlow, PyTorch, and scikit-learn have traditionally been popular
    for ML tasks. Hugging Face’s Transformers library has also become an indispensable
    part of the developer workflow for building modern LLM-powered applications. It
    provides pre-trained models and straightforward APIs to fine-tune models for specific
    tasks. These libraries not only accelerate development time but also provide cutting-edge
    solutions to developers across the world.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**丰富的库和框架生态系统**：Python提供了一系列专门为AI/ML用例设计的库和框架。例如，TensorFlow、PyTorch和scikit-learn等库在机器学习任务中一直很受欢迎。Hugging
    Face的Transformers库也已成为构建现代LLM应用程序的开发者工作流程中不可或缺的一部分。它提供了预训练模型和简单的API，以便针对特定任务微调模型。这些库不仅加速了开发时间，还为全球的开发者提供了前沿的解决方案。'
- en: '**Strong community and support**: Python is one of the most popular programming
    languages in the world, and hence has a huge community. According to the Stack
    Overflow survey 2023 ([https://survey.stackoverflow.co/2023/](https://survey.stackoverflow.co/2023/)),
    it’s the second most popular programming language after JavaScript (excluding
    HTML/CSS). This strong and large community provides a wealth of resources, including
    tutorials, discussion forum engagements, and open source projects, which offer
    a helpful support system for someone working on building modern applications.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**强大的社区和支持**：Python是世界上最受欢迎的编程语言之一，因此拥有庞大的社区。根据Stack Overflow 2023调查([https://survey.stackoverflow.co/2023/](https://survey.stackoverflow.co/2023/))，它是JavaScript（不包括HTML/CSS）之后的第二大受欢迎的编程语言。这个强大且庞大的社区提供了丰富的资源，包括教程、讨论论坛参与和开源项目，为那些致力于构建现代应用程序的人提供了一个有价值的支持系统。'
- en: '**Integration with other technologies**: Python’s ability to integrate seamlessly
    with other technologies and programming languages makes it a great choice for
    AI/ML tasks and building LLM-powered applications. For example, Python can easily
    interface with programming languages such as C/C++ for performance-critical tasks.
    It also interfaces well with languages such as Java and C#. This flexibility of
    Python is helpful for deploying LLM-powered applications in diverse environments,
    ensuring that Python can be part of large heterogeneous systems.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**与其他技术的集成**：Python能够无缝集成到其他技术和编程语言中，使其成为AI/ML任务和构建LLM应用程序的绝佳选择。例如，Python可以轻松与C/C++等编程语言接口，用于性能关键任务。它也与Java和C#等语言很好地接口。Python的这种灵活性有助于在多样化的环境中部署LLM应用程序，确保Python可以成为大型异构系统的一部分。'
- en: '**Rapid prototyping and experimentation**: Building a sophisticated AI/ML-powered
    application requires many iterations of tests, experiments, and fine-tuning. Python
    allows developers to quickly build prototypes in a few lines of code. Easy testing
    and debugging also help to prototype a quick solution. Python’s interactive environments,
    such as Jupyter Notebook, provide an excellent platform for this purpose. With
    Python, developers building LLM-powered applications can quickly test hypotheses,
    visualize data, and debug code in an interactive manner.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**快速原型设计和实验**：构建一个复杂的AI/ML应用程序需要多次测试、实验和微调。Python允许开发者通过几行代码快速构建原型。易于测试和调试也有助于快速原型化解决方案。Python的交互式环境，如Jupyter
    Notebook，为此提供了一个极好的平台。使用Python，构建LLM应用程序的开发者可以快速测试假设、可视化数据并以交互式方式调试代码。'
- en: Python combines speed, simplicity, specialized libraries and frameworks, and
    strong community support with easy integration with other languages and technologies,
    all of which make it an excellent choice for building modern LLM-powered applications.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: Python结合了速度、简单性、专业的库和框架以及强大的社区支持，并且易于与其他语言和技术集成，所有这些都使其成为构建现代LLM应用程序的绝佳选择。
- en: AI/ML frameworks
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AI/ML框架
- en: '**AI/ML frameworks** are essential tools that streamline the development and
    deployment of ML models, providing pre-built algorithms, optimized performance,
    and scalable solutions. They enable developers to focus on refining their models
    and GenAI applications rather than getting bogged down by low-level implementations.
    Using frameworks ensures efficiency, adaptability, and the ability to harness
    cutting-edge AI advancements. Developers should be interested in these frameworks
    as they also reduce development time and enhance the potential for breakthroughs
    in GenAI.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**AI/ML 框架**是简化 ML 模型开发和部署的必要工具，提供预构建算法、优化性能和可扩展解决方案。它们使开发者能够专注于优化他们的模型和 GenAI
    应用，而不是陷入底层实现的困境。使用框架确保效率、适应性和利用尖端 AI 进步的能力。开发者应该对这些框架感兴趣，因为它们还可以减少开发时间并提高 GenAI
    突破的潜力。'
- en: MongoDB has integrations with many AI/ML frameworks that may be familiar to
    developers, such as LangChain, LlamaIndex, Haystack, Microsoft Semantic Kernel,
    DocArray, and Flowise.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: MongoDB 与许多开发者可能熟悉的 AI/ML 框架有集成，例如 LangChain、LlamaIndex、Haystack、Microsoft Semantic
    Kernel、DocArray 和 Flowise。
- en: 'In this section, you will learn about **LangChain**, one of the most popular
    GenAI frameworks. Although it is very popular, it is certainly not the only popular
    framework. If you are interested in other frameworks, you can check out the documentation
    linked in the *Appendix: Further Reading* chapter at the end of this book or see
    the latest list of supported AI/ML frameworks for Python at [https://www.mongodb.com/docs/languages/python/](https://www.mongodb.com/docs/languages/python/).'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将了解 **LangChain**，这是最受欢迎的 GenAI 框架之一。尽管它非常受欢迎，但它绝对不是唯一受欢迎的框架。如果你对其他框架感兴趣，你可以查看本书末尾
    *附录：进一步阅读* 部分中链接的文档，或者查看 Python 支持的最新 AI/ML 框架列表 [https://www.mongodb.com/docs/languages/python/](https://www.mongodb.com/docs/languages/python/)。
- en: LangChain
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LangChain
- en: LangChain is a framework for developing applications powered by LLMs. LangChain
    simplifies every stage of the LLM application lifecycle. It enables building applications
    that connect external sources of data and computation to LLMs. The basic LLM chain
    relies solely on the information provided in the prompt template to generate a
    response, and the concept of a *LangChain* allows you to extend these chains for
    advanced processing.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 是一个用于开发由 LLM 驱动的应用的框架。LangChain 简化了 LLM 应用生命周期的每个阶段。它使构建将外部数据源和计算连接到
    LLM 的应用成为可能。基本的 LLM 链仅依赖于提示模板中提供的信息来生成响应，而 *LangChain* 的概念允许你扩展这些链以进行高级处理。
- en: In this section, you will learn how to use LangChain to perform semantic search
    on your data and build a **retrieval-augmented generation (RAG)** implementation.
    Before you begin, make sure you have all the necessary tools installed and set
    up on your computer, as listed in the *Technical requirements* section of this
    chapter.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将学习如何使用 LangChain 对你的数据进行语义搜索并构建 **检索增强生成 (RAG**) 实现。在开始之前，请确保你已经安装并设置了本章节
    *技术要求* 部分中列出的所有必要工具，作为准备工作。
- en: Getting started with LangChain
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 开始使用 LangChain
- en: 'Perform the following steps to set up your environment for LangChain:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤以设置 LangChain 的环境：
- en: 'Start by installing the necessary dependencies:'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，安装必要的依赖项：
- en: '[PRE0]'
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Run the following code to import the required packages:'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下代码以导入所需的包：
- en: '[PRE1]'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'After you have imported the necessary packages, make sure the environment variables
    are set properly. You have two important secrets to store as environment variables:
    your **OpenAI API key** and **MongoDB Atlas** **connection string**.'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在导入必要的包之后，请确保环境变量设置正确。你有两个重要的秘密需要存储为环境变量：你的 **OpenAI API 密钥** 和 **MongoDB Atlas**
    连接字符串。
- en: 'Run the following command to store your OpenAI API key as an environment variable:'
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 运行以下命令以将你的 OpenAI API 密钥存储为环境变量：
- en: '[PRE2]'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Run the following command to store your MongoDB Atlas connection string as
    an environment variable:'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 运行以下命令以将你的 MongoDB Atlas 连接字符串存储为环境变量：
- en: '[PRE3]'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: You are now ready to connect to the MongoDB Atlas cluster.
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，你已经准备好连接到 MongoDB Atlas 集群。
- en: 'Next, you’ll instantiate the `MongoClient` and pass your connection string
    to establish communications with your MongoDB Atlas database. Run the following
    code to establish the connection:'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，你需要实例化 `MongoClient` 并将你的连接字符串传递给 MongoDB Atlas 数据库以建立通信。运行以下代码以建立连接：
- en: '[PRE4]'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Next, you’ll specify the name of the database and the collection you want to
    create. In this example, you’ll create a database named `langchain_db` and a collection
    called `test`. You’ll also define the name of the vector search index to create
    and use with the following code:'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，您将指定要创建的数据库和集合的名称。在这个例子中，您将创建一个名为 `langchain_db` 的数据库和一个名为 `test` 的集合。您还将定义要创建并使用以下代码的向量搜索索引的名称：
- en: '[PRE5]'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: With these steps, you’ve set up the basics of connectivity. Now that you have
    the bare bones of your database, you’ll want to define what your application does.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这些步骤，您已设置连接的基本设置。现在，您有了数据库的骨架，您将想要定义您的应用程序做什么。
- en: 'In this case, you will do the following:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，您将执行以下操作：
- en: Fetch a publicly accessible PDF document.
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取一个公开可访问的 PDF 文档。
- en: Split it into smaller chunks of information for easy consumption by your GenAI
    application.
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将其分割成更小的信息块，以便您的 GenAI 应用程序轻松消费。
- en: Upload the data into the MongoDB database.
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据上传到 MongoDB 数据库。
- en: This functionality is not something you have to build from scratch. Instead,
    you’ll use the free, open source library integration provided by LangChain called
    `PyPDFLoader`, which you imported in *Step 2* earlier in this section.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 此功能不是您必须从头开始构建的。相反，您将使用 LangChain 提供的免费开源库集成，称为 `PyPDFLoader`，您在本文本此部分的 *步骤
    2* 中已导入。
- en: Fetching and splitting public PDF documents
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 获取和分割公开 PDF 文档
- en: 'Using `PyPDFLoader` to fetch publicly available PDFs is quite simple. In the
    following code, you will fetch a publicly accessible PDF document and split it
    into smaller chunks that you can later upload into your MongoDB database:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `PyPDFLoader` 获取公开可用的 PDF 文件相当简单。在以下代码中，您将获取一个公开可访问的 PDF 文档，并将其分割成更小的块，您可以稍后将其上传到您的
    MongoDB 数据库中：
- en: '[PRE6]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'You will then receive the following output:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，您将收到以下输出：
- en: '[PRE7]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'With this code, you first instantiated `PyPDFLoader` and then passed it the
    URL to the publicly accessible PDF file: [https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE4HkJP](https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE4HkJP).
    Next, you loaded the fetched PDF file into the `data` variable.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 使用此代码，您首先实例化了 `PyPDFLoader`，然后传递了公开可访问的 PDF 文件的 URL：[https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE4HkJP](https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE4HkJP)。接下来，您将获取的
    PDF 文件加载到 `data` 变量中。
- en: 'After that, you split the PDF file’s text into smaller chunks. For this example,
    you set the chunk size to 200 characters and allowed an overlap of 20 characters
    between chunks. The overlap maintains the context between chunks. Note that this
    number is not arbitrary, and there are many opinions about what your chunking
    strategy should be. Some of those resources are discussed in the *Appendix: Further
    Reading* chapter of this book.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，您将 PDF 文件的文本分割成更小的块。在这个例子中，您将块大小设置为 200 个字符，并在块之间允许 20 个字符的重叠。重叠保持了块之间的上下文。请注意，这个数字不是随意的，关于您的分块策略应该是什么有很多意见。本书
    *附录：进一步阅读* 章节中讨论了一些这些资源。
- en: You stored the split chunks in the `docs` variable and printed the first chunk
    of the split document. This indicates that your output request via the `print`
    command was successful, and you can easily confirm whether the information is
    correct for this entry.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 您将分割的块存储在 `docs` 变量中，并打印了分割文档的第一块。这表明您通过 `print` 命令的输出请求是成功的，您可以轻松地确认此条目中的信息是否正确。
- en: Creating the vector store
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建向量存储
- en: 'After you have split your documents into chunks, you will instantiate the vector
    store with the following code:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在您将文档分割成块之后，您将使用以下代码实例化向量存储：
- en: '[PRE8]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'In the preceding code, you created a vector store named `vector_store` using
    the `MongoDBAtlasVectorSearch.from_documents` method and specified various parameters:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，您使用 `MongoDBAtlasVectorSearch.from_documents` 方法创建了一个名为 `vector_store`
    的向量存储，并指定了各种参数：
- en: '`documents = docs`: The name of the document that you want to store in your
    vector database'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`documents = docs`: 您想要存储在向量数据库中的文档名称'
- en: '`embedding = OpenAIEmbeddings(disallowed_special=())`: The class that generates
    vector embeddings for the documents using OpenAI’s embedding model'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`embedding = OpenAIEmbeddings(disallowed_special=())`: 使用 OpenAI 的嵌入模型为文档生成向量嵌入的类'
- en: '`collection = atlas_collection`: The Atlas collection where documents will
    be stored'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`collection = atlas_collection`: 文档将存储的 Atlas 集合'
- en: '`index_name = vector_search_index`: The name of the index to use for querying
    the vector store'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`index_name = vector_search_index`: 用于查询向量存储的索引名称'
- en: 'You’ll also need to create your **Atlas Vector Search index** in the MongoDB
    database. For explicit instructions on how this is done, see [*Chapter 8*](B22495_08.xhtml#_idTextAnchor180),
    *Implementing Vector Search in AI Applications*. This must be completed before
    you can successfully run the previous code. When you are creating a Vector Search
    index, use the following index definition:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 您还需要在MongoDB数据库中创建您的**Atlas向量搜索索引**。有关如何操作的详细说明，请参阅[*第8章*](B22495_08.xhtml#_idTextAnchor180)，*在AI应用中实现向量搜索*。这必须在成功运行前面的代码之前完成。在创建向量搜索索引时，请使用以下索引定义：
- en: '[PRE9]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'This index defines two fields:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 此索引定义了两个字段：
- en: '`text-embedding-ada-002` model. It has 1,536 dimensions and uses cosine similarity
    to measure similarity. You may also want to consider other newer models from OpenAI,
    `text-embedding-3-small` and `text-embedding-3-large`, which are optimized for
    different use cases and therefore have a different number of dimensions. See [https://platform.openai.com/docs/guides/embeddings](https://platform.openai.com/docs/guides/embeddings)
    for more details as well as current options.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text-embedding-ada-002`模型。它有1,536个维度，并使用余弦相似度来衡量相似度。您还可能想考虑来自OpenAI的其他一些较新的模型，如`text-embedding-3-small`和`text-embedding-3-large`，这些模型针对不同的用例进行了优化，因此具有不同的维度数。有关更多详细信息以及当前选项，请参阅[https://platform.openai.com/docs/guides/embeddings](https://platform.openai.com/docs/guides/embeddings)。'
- en: '**Page field**: A filter type field used for pre-filtering data based on the
    page number in the PDF.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**页面字段**：一种用于根据PDF中的页面编号进行预过滤数据的过滤器类型字段。'
- en: Now, you can run your code successfully, fetch a publicly available PDF, chunk
    it into smaller portions of data, and store them in a MongoDB Atlas database.
    With these steps accomplished, you can conduct additional tasks, such as running
    queries to perform semantic search on your data. You can learn about basic semantic
    search in [*Chapter 8*](B22495_08.xhtml#_idTextAnchor180), *Implementing Vector
    Search in AI Applications*, and [*Chapter 10*](B22495_10.xhtml#_idTextAnchor214),
    *Refining the Semantic Data Model to* *Improve Accuracy*.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您可以成功运行代码，获取一个公开可用的PDF，将其分割成更小的数据部分，并将它们存储在MongoDB Atlas数据库中。完成这些步骤后，您可以执行其他任务，例如运行查询以对您的数据进行语义搜索。您可以在[*第8章*](B22495_08.xhtml#_idTextAnchor180)，*在AI应用中实现向量搜索*和[*第10章*](B22495_10.xhtml#_idTextAnchor214)，*优化语义数据模型以提高准确性*中了解基本语义搜索。
- en: For more information on this topic, you can also consult the official documentation
    from LangChain, available at [https://python.langchain.com/v0.2/docs/integrations/vectorstores/mongodb_atlas/#pre-filtering-with-similarity-search](https://python.langchain.com/v0.2/docs/integrations/vectorstores/mongodb_atlas/#pre-filtering-with-similarity-search).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 关于这个主题的更多信息，您还可以查阅LangChain的官方文档，可在[https://python.langchain.com/v0.2/docs/integrations/vectorstores/mongodb_atlas/#pre-filtering-with-similarity-search](https://python.langchain.com/v0.2/docs/integrations/vectorstores/mongodb_atlas/#pre-filtering-with-similarity-search)找到。
- en: Next, let’s cover some specific LangChain functionalities that you will find
    most useful when building GenAI applications.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们探讨一些具体的LangChain功能，这些功能在构建GenAI应用时您会发现非常有用。
- en: LangChain semantic search with score
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 带分数的LangChain语义搜索
- en: LangChain provides some particularly helpful methods to perform semantic search
    on your data and return a **score**. This score refers to the measure of relevance
    between the query and the matching documents based on their semantic content.
    You can use this score when you want to return more than one result to your users
    and also limit the number of results. For example, this score can prove useful
    in returning the top three most relevant pieces of content about a topic.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain提供了一些特别有用的方法来对您的数据进行语义搜索并返回一个**分数**。这个分数是指根据语义内容，查询与匹配文档之间的相关性度量。当您想向用户返回多个结果并限制结果数量时，可以使用这个分数。例如，这个分数在返回关于某个主题的前三个最相关内容时可能非常有用。
- en: 'The method that you will use here is `similarity_search_with_score`:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 您将在这里使用的方法是`similarity_search_with_score`：
- en: '[PRE10]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'You pass the query to the `similarity_search_with_score` function and specify
    the `k` parameter as `3` to limit the number of documents to return to 3\. Then,
    you can print the output:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 您将查询传递给`similarity_search_with_score`函数，并将`k`参数指定为`3`以限制返回的文档数量为3。然后，您可以打印输出：
- en: '[PRE11]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: As you can see in the output, three documents are returned that have the highest
    relevance score. Each returned document also has a relevance score attached to
    it that ranges between 0 and 1.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您在输出中看到的，返回了三个具有最高相关性分数的文档。每个返回的文档都附有一个介于0到1之间的相关性分数。
- en: Semantic search with pre-filtering
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 带有预过滤的语义搜索
- en: MongoDB allows you to pre-filter your data using a match expression to narrow
    down the search space before performing a more computationally intensive vector
    search. This offers several benefits to developers, such as increased performance,
    improved accuracy, and enhanced query relevancy. When pre-filtering, remember
    to index any metadata fields by which you want to filter during index creation.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: MongoDB允许你使用match表达式预过滤数据，以在执行更计算密集型的向量搜索之前缩小搜索范围。这为开发者提供了几个好处，例如提高性能、提高准确性和增强查询相关性。在预过滤时，请记住在创建索引时对任何你想要过滤的元数据字段进行索引。
- en: 'Here is a code snippet that shows how you can perform semantic search with
    pre-filtering:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个代码片段，展示了如何使用预过滤进行语义搜索：
- en: '[PRE12]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: In this code example, you have the same query string for which you performed
    a plain semantic search earlier. The `k` value is set to `3` so that it only returns
    the top three matching documents. You have also provided a `pre_filter` query,
    which is basically an MQL expression that uses the `$eq` operator to specify that
    MongoDB should only return content and chunked information that is on page `17`
    of the original PDF document.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在此代码示例中，你有与之前执行普通语义搜索相同的查询字符串。`k`值设置为`3`，因此它只返回最匹配的前三个文档。你还提供了一个`pre_filter`查询，这基本上是一个MQL表达式，使用`$eq`运算符指定MongoDB应仅返回位于原始PDF文档第`17`页的内容和分块信息。
- en: Implementing a basic RAG solution with LangChain
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用LangChain实现基本的RAG解决方案
- en: 'LangChain’s functionalities are not only limited to performing semantic search
    queries on your data stored in vector databases. It also allows you to build powerful
    GenAI applications. With the following code snippet, you will learn an easy way
    to do the following:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain的功能不仅限于在存储在向量数据库中的数据上执行语义搜索查询。它还允许你构建强大的GenAI应用程序。以下代码片段将教你一种简单的方法来完成以下操作：
- en: Set up a MongoDB Atlas Vector Search retriever for similarity-based search.
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置一个基于相似性的MongoDB Atlas Vector Search检索器。
- en: Return the 10 most relevant documents.
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 返回最相关的10个文档。
- en: 'Utilize a custom RAG prompt with an LLM to answer questions based on the retrieved
    documents:'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用带有LLM的自定义RAG提示来根据检索到的文档回答问题：
- en: '[PRE13]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The preceding code instantiates Atlas Vector Search as a `k` as `3` to search
    for only the three most relevant documents.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 上一段代码将Atlas Vector Search实例化为`k`值为`3`，以仅搜索最相关的三个文档。
- en: In the preceding code, notice the line that says `custom_rag_prompt = PromptTemplate.from_template(template)`.
    It refers to prompt templates, which are detailed in the next section.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，注意包含`custom_rag_prompt = PromptTemplate.from_template(template)`的行。它指的是提示模板，这些模板将在下一节中详细介绍。
- en: LangChain prompt templates and chains
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LangChain提示模板和链
- en: '`context` as an input variable and the original query for the LLM.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '`context`作为输入变量和LLM的原始查询。'
- en: 'Let’s set up a **chain**, a key feature of LangChain that specifies three main
    components:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们设置一个**链**，这是LangChain的一个关键特性，它指定了三个主要组件：
- en: '**Retriever**: You will use MongoDB Atlas Vector Search to find relevant documents
    that provide context for the language model'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Retriever**：你将使用MongoDB Atlas Vector Search找到为语言模型提供上下文的文档。'
- en: '**Prompt template**: This is the template you created earlier to format the
    query and the contextual information'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提示模板**：这是你之前创建的用于格式化查询和上下文的模板。'
- en: '**LLM**: You will use the OpenAI chat model to generate responses based on
    the provided context'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LLM**：你将使用OpenAI聊天模型根据提供的上下文生成响应。'
- en: 'You will use this chain to process a sample input query about MongoDB Atlas
    Security recommendations, format the query, retrieve the results of the query,
    and then return a response to the user along with the documents used as context.
    Due to LLM variability, you will likely never receive the exact same response
    twice, but here is an example showing the potential output:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 你将使用此链处理有关MongoDB Atlas安全建议的示例输入查询，格式化查询，检索查询结果，然后返回一个响应给用户，并附带用作上下文的文档。由于LLM的变异性，你很可能永远不会收到完全相同的两次响应，但以下是一个显示潜在输出的示例：
- en: '[PRE14]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: This output both answers the user’s inquiry and provides the source information,
    increasing not only user trust but also the ability of the user to follow up and
    get more details as they require.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 此输出不仅回答了用户的问题，还提供了来源信息，这不仅增加了用户的信任，还增强了用户根据需要跟进并获得更多细节的能力。
- en: This brief overview of the LangChain framework has tried to convince you of
    this framework’s utility and potential and give you a preview of its capabilities
    to save you valuable time when crafting your GenAI application.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 这个对 LangChain 框架的简要概述试图说服您这个框架的实用性和潜力，并为您提供一个其功能的预览，以便在构建您的 GenAI 应用程序时节省宝贵的时间。
- en: Key Python libraries
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关键 Python 库
- en: In addition to AI/ML frameworks, there are also many Python libraries that will
    make the experience of building your GenAI application easier. Whether you require
    assistance with data cleansing, formatting, or transformation, there are likely
    half a dozen potential Python libraries to solve every problem. The following
    subsections list some favorites and explain how they can assist you during your
    GenAI journey.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 除了 AI/ML 框架之外，还有许多 Python 库可以使构建您的 GenAI 应用程序的过程更加容易。无论您是否需要数据清理、格式化或转换的帮助，都可能有一打潜在的
    Python 库可以解决每个问题。以下小节列出了一些最受欢迎的库，并解释了它们如何在您的 GenAI 之旅中帮助您。
- en: 'For this book, you can broadly divide these libraries into three categories:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这本书，您可以将这些库大致分为三个类别：
- en: '**General-purpose scientific libraries** such as pandas, NumPy, and scikit-learn'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**通用科学库**，如 pandas、NumPy 和 scikit-learn'
- en: '**MongoDB-specific libraries** such as PyMongoArrow'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**MongoDB 特定库**，如 PyMongoArrow'
- en: '**Deep learning frameworks** such as PyTorch and TensorFlow'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**深度学习框架**，如 PyTorch 和 TensorFlow'
- en: The rest of this section covers one relevant and popular library from each of
    these categories
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 本节的其余部分涵盖了这些类别中每个相关且流行的库
- en: pandas
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: pandas
- en: The pandas library is a powerful and flexible open source data manipulation
    and analysis library for Python. It provides data structures such as DataFrames
    and Series, which are designed to handle structured data intuitively and efficiently.
    When working with tabular data stored in spreadsheets or databases, pandas is
    a great tool for data analysis. With pandas, you can perform a wide range of operations,
    including cleaning, transforming, and aggregating data.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: pandas 库是一个功能强大且灵活的开源 Python 数据操作和分析库。它提供了 DataFrame 和 Series 等数据结构，这些结构旨在直观且高效地处理结构化数据。当处理存储在电子表格或数据库中的表格数据时，pandas
    是数据分析的一个优秀工具。使用 pandas，您可以执行各种操作，包括数据清理、转换和聚合。
- en: Among many other noticeably out-of-the-box functionalities, pandas also offers
    great support for time series and has an extensive set of tools for working with
    dates, times, and time-indexed data. In addition to providing a wide range of
    methods to work with numerical data, pandas gives great support for working with
    text-based data.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多其他引人注目的开箱即用功能中，pandas 还提供了对时间序列的出色支持，并有一套广泛的工作于日期、时间和时间索引数据的工具。除了提供广泛的方法来处理数值数据外，pandas
    还为基于文本的数据提供了强大的支持。
- en: Here is a short example of how to work with the pandas library. In the following
    example, you will create a pandas DataFrame from a Python dictionary. Then, you
    will print the entire DataFrame. Next, you will select a specific column, which
    is `Age`, and print it. Then, you will filter data by row label or by the specific
    position of a row.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个如何使用 pandas 库的简短示例。在下面的示例中，您将从一个 Python 字典创建一个 pandas DataFrame。然后，您将打印整个
    DataFrame。接下来，您将选择一个特定的列，即 `Age`，并打印它。然后，您将通过行标签或行的特定位置来过滤数据。
- en: 'The next line shows how you can filter data using Boolean masking in pandas.
    Here, you will print out the DataFrame format:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个示例显示了如何在 pandas 中使用布尔掩码过滤数据。在这里，您将打印出 DataFrame 格式：
- en: '[PRE15]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Your output should be in the format of a pandas DataFrame, similar to *Figure
    7**.1*:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 您的输出应采用与 *图 7.1* 类似的 pandas DataFrame 格式：
- en: '![](img/B22495_07_01.jpg)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22495_07_01.jpg)'
- en: 'Figure 7.1: DataFrame output from pandas'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.1：pandas 的 DataFrame 输出
- en: 'You can then manipulate this data in various ways, each time outputting the
    results as you see fit, but always formatted as a pandas DataFrame. To print only
    the ages of the users, you would use the following code:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过各种方式操作这些数据，每次输出您认为合适的结果，但始终以 pandas DataFrame 的格式输出。要打印用户的年龄，您可以使用以下代码：
- en: '[PRE16]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'You’ll get the output shown in *Figure 7**.2*:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 您将得到 *图 7.2* 中所示的输出：
- en: '![](img/B22495_07_02.jpg)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22495_07_02.jpg)'
- en: 'Figure 7.2: DataFrame output of ages'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.2：年龄的 DataFrame 输出
- en: 'You can also filter the output. Here, you will filter data to show only those
    people who are older than 25, and then present the results as a DataFrame:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以过滤输出。在这里，您将过滤数据以仅显示年龄大于 25 的人，然后将结果作为 DataFrame 展示：
- en: '[PRE17]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'This code will filter the data and then output the results in DataFrame format,
    as in *Figure 7**.3*:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码将过滤数据，然后将结果以 DataFrame 格式输出，如图 *图 7**.3*：
- en: '![](img/B22495_07_03.jpg)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22495_07_03.jpg)'
- en: 'Figure 7.3: Filtered DataFrame output'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.3：过滤后的 DataFrame 输出
- en: 'You can also perform calculations with the pandas library in a straightforward
    way. To calculate the average age, for instance, you would use code such as this:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以以直接的方式使用 pandas 库进行计算。例如，要计算平均年龄，你会使用如下代码：
- en: '[PRE18]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'And your output would look like *Figure 7**.4*:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 你的输出将类似于 *图 7**.4*：
- en: '![](img/B22495_07_04.jpg)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22495_07_04.jpg)'
- en: 'Figure 7.4: Calculated field output'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.4：计算字段输出
- en: As you can see, data manipulation in pandas is fairly easy, and the outputs
    are immediately readable and well-formatted for further analysis. The intuitive
    syntax and powerful functions of pandas make it an essential tool for Python developers,
    enabling them to handle large datasets with ease and precision. For those building
    GenAI applications, pandas streamlines the data preprocessing steps, ensuring
    that data is clean, structured, and ready for model training. Additionally, its
    robust integration with other Python libraries enhances its utility, making complex
    data analysis and visualization straightforward and efficient.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，pandas 中的数据处理相当简单，输出立即可读，并且格式良好，便于进一步分析。pandas 直观的语法和强大的功能使其成为 Python 开发者的必备工具，使他们能够轻松且精确地处理大型数据集。对于构建
    GenAI 应用程序的开发者来说，pandas 简化了数据预处理步骤，确保数据干净、结构化，并准备好进行模型训练。此外，它与其他 Python 库的强大集成增强了其效用，使复杂的数据分析和可视化变得简单高效。
- en: PyMongoArrow
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PyMongoArrow
- en: '**PyMongoArrow** is a Python library built on top of the official MongoDB Python
    driver, **PyMongo**, which allows you to move data out of the MongoDB database
    into some of the most popular Python libraries, such as pandas, NumPy, PyArrow,
    and polars, and vice versa.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '**PyMongoArrow** 是一个基于官方 MongoDB Python 驱动程序 **PyMongo** 构建的 Python 库，它允许你将数据从
    MongoDB 数据库移动到一些最受欢迎的 Python 库中，如 pandas、NumPy、PyArrow 和 polars，反之亦然。'
- en: 'PyMongoArrow simplifies loading data from MongoDB into other supported data
    formats. The example covered below demonstrates how you can work with MongoDB,
    PyMongoArrow, and libraries such as pandas and NumPy. You may find this useful
    in the context of GenAI applications in the following situations:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: PyMongoArrow 简化了将数据从 MongoDB 加载到其他支持的数据格式。下面提到的示例展示了如何使用 MongoDB、PyMongoArrow
    以及 pandas 和 NumPy 等库。在以下情况下，你可能会在 GenAI 应用程序中找到这很有用：
- en: When you require data in a specific format for summarization and analysis (CSV,
    DataFrame, NumPy array, Parquet file, etc.) from MongoDB
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当你需要从 MongoDB 获取特定格式的数据（CSV、DataFrame、NumPy 数组、Parquet 文件等）进行总结和分析时
- en: If you need to merge data of various types for calculations or transformations
    that are then used for GenAI analysis
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你需要合并各种类型的数据进行计算或转换，然后用于 GenAI 分析
- en: As an example, if you have inbound financial data from *Application A*, inbound
    sales data from *Application B*, PDF files from *Team 1*, and `.txt` files from
    *Team 2*, and you’d like your GenAI application to summarize annual data from
    all these different places, you will likely get more accurate results if all types
    of data are in the same format. This will require some upfront programmatic effort,
    and PyMongoArrow simplifies transforming MongoDB JSON into other data types as
    well as ingesting those other data types and converting them into JSON.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果你有来自 *Application A* 的入境财务数据，来自 *Application B* 的入境销售数据，来自 *Team 1* 的 PDF
    文件，以及来自 *Team 2* 的 `.txt` 文件，并且你希望你的 GenAI 应用程序能够总结来自所有这些不同地方年度数据，那么如果所有类型的数据都处于相同的格式，你可能会得到更准确的结果。这将需要一些前期编程工作，而
    PyMongoArrow 简化了将 MongoDB JSON 转换为其他数据类型以及将这些其他数据类型转换为 JSON 的过程。
- en: 'Follow these steps to complete this example with PyMongoArrow:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤使用 PyMongoArrow 完成此示例：
- en: 'Start by installing and importing the latest version of PyMongoArrow:'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，安装并导入 PyMongoArrow 的最新版本：
- en: '[PRE19]'
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Now, make sure you have your Atlas cluster connection string handy:'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，请确保你手头有 Atlas 集群连接字符串：
- en: '[PRE20]'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Next, you will extend the PyMongo driver via the `pymongoarrow.monkey` module.
    This allows you to add the PyMongoArrow functionality directly to MongoDB collections
    in Atlas. By calling `patch_all()` from `pymongoarrow.monkey`, new collection
    instances will include PyMongoArrow APIs, such as `pymongoarrow.api.find_pandas_all()`.
    This is useful because you can now easily export your data from MongoDB to various
    formats such as pandas.
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，您将通过 `pymongoarrow.monkey` 模块扩展 PyMongo 驱动程序。这允许您直接将 PyMongoArrow 功能添加到
    Atlas 中的 MongoDB 集合中。通过从 `pymongoarrow.monkey` 调用 `patch_all()`，新的集合实例将包括 PyMongoArrow
    API，例如 `pymongoarrow.api.find_pandas_all()`。这很有用，因为您现在可以轻松地将数据从 MongoDB 导出为各种格式，如
    pandas。
- en: '[PRE21]'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Add some test data to your collection:'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向您的集合添加一些测试数据：
- en: '[PRE22]'
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'PyMongoArrow uses a `schema` object and mapping field names to type-specifiers:'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: PyMongoArrow 使用一个 `schema` 对象，并将字段名映射到类型指定符：
- en: '[PRE23]'
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: MongoDB’s key feature is its ability to represent nested data using embedded
    documents, along with its support for lists and nested lists. PyMongoArrow fully
    supports these features out of the box, providing first-class functionality for
    handling embedded documents, lists, and nested lists seamlessly.
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: MongoDB 的关键特性是它能够使用嵌入文档表示嵌套数据，同时支持列表和嵌套列表。PyMongoArrow 默认完全支持这些特性，为处理嵌入文档、列表和嵌套列表提供了第一级功能。
- en: 'Let’s perform some `find` operations on the data. The following code demonstrates
    querying a MongoDB collection called `data` for documents where the `amount` field
    is greater than `0`, using PyMongoArrow to convert the results into different
    data formats. A predefined schema is used for the conversion, but it’s optional.
    If you omit the schema, PyMongoArrow tries to automatically apply a schema based
    on the data contained in the first batch:'
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们在数据上执行一些 `find` 操作。以下代码演示了使用 PyMongoArrow 将查询结果转换为不同数据格式，查询名为 `data` 的 MongoDB
    集合中 `amount` 字段大于 `0` 的文档。用于转换的预定义模式是可选的。如果您省略模式，PyMongoArrow 将尝试根据第一批数据自动应用模式：
- en: '[PRE24]'
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The first line of code converts the query results into a pandas DataFrame. The
    second line of code converts the query results set into an arrow table. The third
    line converts the query results set into a polars DataFrame, and finally, the
    fourth line converts the query result set into a NumPy array.
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第一行代码将查询结果转换为 pandas DataFrame。第二行代码将查询结果集转换为 arrow 表。第三行将查询结果集转换为 polars DataFrame，最后，第四行将查询结果集转换为
    NumPy 数组。
- en: You are not limited to performing `find` operations to convert the query result
    set into other supported data formats. PyMongoArrow also allows you to use MongoDB’s
    powerful aggregation pipeline to perform complex queries on your data to filter
    out the needed data before exporting it to other data formats.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 您不仅限于执行 `find` 操作将查询结果集转换为其他支持的数据格式。PyMongoArrow 还允许您使用 MongoDB 强大的聚合管道对数据进行复杂查询，以在导出到其他数据格式之前过滤出所需的数据。
- en: 'For example, the following code performs an aggregation query on the data collection
    in a MongoDB database, grouping all documents and calculating the total sum of
    the `amount` field:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，以下代码在 MongoDB 数据库的数据集合上执行聚合查询，将所有文档分组并计算 `amount` 字段的总额：
- en: '[PRE25]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The result of this code is converted into a pandas DataFrame that would consist
    of a total sum.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码的结果被转换为包含总计的 pandas DataFrame。
- en: PyTorch
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PyTorch
- en: Now that you have learned a little bit about pandas and NumPy, it’s important
    you also have some knowledge of another popular Python ML library, PyTorch.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 既然您已经对 pandas 和 NumPy 有了一些了解，那么了解另一个流行的 Python 机器学习库 PyTorch 也是非常重要的。
- en: PyTorch, developed by Meta’s AI Research lab, is an open source deep learning
    framework known for its flexibility and ease of use. It is widely appreciated
    for its dynamic computation graph, which allows intuitive coding and immediate
    execution of code. This feature is particularly useful for researchers and developers
    who need to experiment and iterate quickly.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 由 Meta 的 AI 研究实验室开发的 PyTorch 是一个开源的深度学习框架，以其灵活性和易用性而闻名。它因其动态计算图而广受欢迎，这使得代码的直观编码和即时执行成为可能。这一特性对于需要快速实验和迭代的研发人员尤其有用。
- en: 'In the context of building a GenAI application, PyTorch serves as a powerful
    tool for the following:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建 GenAI 应用程序的情况下，PyTorch 是以下方面的强大工具：
- en: '**Model training and development**: PyTorch is utilized for developing and
    training the core generative models, such as **generative pre-trained transformer**
    (**GPT**) variants, which form the backbone of the GenAI application.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型训练和开发**：PyTorch被用于开发和训练核心生成模型，例如**生成预训练转换器**（**GPT**）变体，这些变体构成了GenAI应用的基础。'
- en: '**Flexibility and real-time experimentation**: The dynamic computation graph
    in PyTorch allows on-the-fly modifications and real-time experimentation, which
    are crucial for fine-tuning generative models to produce high-quality output.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**灵活性和实时实验**：PyTorch中的动态计算图允许即时修改和实时实验，这对于微调生成模型以产生高质量输出至关重要。'
- en: Developers who are adapting pre-trained language models to their specific requirements
    or developing their own custom model for unique tasks may be interested in using
    this library, along with some of the APIs discussed in the following section.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 正在将预训练语言模型适应其特定要求或为其独特任务开发自定义模型的开发者可能会对使用此库以及下一节中讨论的一些API感兴趣。
- en: AI/ML APIs
  id: totrans-172
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AI/ML APIs
- en: 'When developing GenAI applications, developers have access to a variety of
    APIs that can significantly enhance the capabilities and efficiency of their projects.
    As these APIs are widely used, they offer performance, stability, and consistency
    across thousands of projects, ensuring that developers don’t need to reinvent
    the wheel. Here are just some of the functionalities that these APIs offer:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发GenAI应用时，开发者可以访问各种API，这些API可以显著增强他们项目的功能和效率。由于这些API被广泛使用，它们在数千个项目中提供了性能、稳定性和一致性，确保开发者无需重新发明轮子。以下只是这些API提供的一些功能：
- en: '**Text generation and processing**: APIs such as **OpenAI**, **Hugging Face**,
    and **Google Gemini API** enable developers to generate coherent and contextually
    appropriate text, which is crucial for applications such as content creation,
    dialogue systems, and virtual assistants.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文本生成和处理**：如**OpenAI**、**Hugging Face**和**Google Gemini API**等API使开发者能够生成连贯且符合上下文的文本，这对于内容创作、对话系统和虚拟助手等应用至关重要。'
- en: '**Translation capabilities**: The **Google Cloud Translation API**, **Azure
    AI Translator**, and **Amazon Translate API** provide robust translation capabilities,
    making GenAI applications multilingual and globally accessible.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**翻译功能**：**Google Cloud Translation API**、**Azure AI Translator**和**Amazon
    Translate API**提供了强大的翻译功能，使GenAI应用能够实现多语言和全球可访问性。'
- en: '**Speech synthesis and recognition**: Services such as **Google Text-to-Speech**,
    **Amazon Polly**, and **IBM Watson Text-to-Speech** convert generated text into
    natural-sounding speech, enhancing user interaction and accessibility.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**语音合成和识别**：如**Google Text-to-Speech**、**Amazon Polly**和**IBM Watson Text-to-Speech**等服务将生成的文本转换为自然流畅的语音，从而增强用户交互和可访问性。'
- en: '**Image and video processing**: APIs from **Clarifai** and **DeepAI** allow
    GenAI applications to create, modify, and analyze visual content, enabling tasks
    such as image generation from text and object recognition.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图像和视频处理**：**Clarifai**和**DeepAI**的API允许GenAI应用创建、修改和分析视觉内容，从而实现从文本生成图像和对象识别等任务。'
- en: These APIs provide a range of capabilities that, when combined, can significantly
    accelerate the development and enhance the functionality of GenAI applications.
    Next, you’re going to dig deeper into two of these APIs, the OpenAI API and the
    Hugging Face Transformers APIs.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 这些API提供了一系列功能，当结合使用时，可以显著加速GenAI应用的开发并增强其功能。接下来，你将深入了解其中的两个API，即OpenAI API和Hugging
    Face Transformers API。
- en: OpenAI API
  id: totrans-179
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: OpenAI API
- en: As you may recall from [*Chapter 3*](B22495_03.xhtml#_idTextAnchor041), *Large
    Language Models*, OpenAI provides a foundational model trained on a broad spectrum
    of data. It offers this model via an API, which allows you to harness the power
    of advanced ML models without needing to manage the underlying infrastructure.
    The computational and financial costs of retraining or hosting a custom LLM for
    an organization or domain-specific information are very high, so most developers
    will utilize someone else’s LLM to provide GenAI capabilities to their applications.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 如您从[*第3章*](B22495_03.xhtml#_idTextAnchor041)“大型语言模型”中回忆起的那样，OpenAI提供了一个基于广泛数据集的基础模型。它通过API提供此模型，允许您利用高级机器学习模型的力量，而无需管理底层基础设施。重新训练或托管针对组织或特定领域信息定制的自定义LLM的计算和财务成本非常高，因此大多数开发者将利用他人的LLM为他们的应用提供GenAI功能。
- en: Although each API has its own strengths and weaknesses, the OpenAI API is currently
    the most widely used. It provides a simple interface for developers to create
    an intelligence layer in their applications. It is powered by OpenAI’s state-of-the-art
    models and cutting-edge **natural language processing** (**NLP**) capabilities,
    enabling applications to perform tasks such as text generation, summarization,
    translation, and conversation. The API is designed to be flexible and scalable,
    making it suitable for a wide range of use cases, from chatbots to content creation
    tools. It is also well documented, with a large community, and there are many
    tutorials available for seemingly every use case.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管每个API都有自己的优点和缺点，但OpenAI API目前是最广泛使用的。它为开发者提供了一个简单的接口，以便在他们的应用程序中创建智能层。它由OpenAI最先进的模型和前沿的**自然语言处理**（NLP）能力提供支持，使应用程序能够执行文本生成、摘要、翻译和对话等任务。该API设计得灵活且可扩展，适用于从聊天机器人到内容创作工具的广泛用例。它还拥有良好的文档记录，拥有庞大的社区，并且针对几乎每个用例都有许多教程。
- en: The OpenAI API is already somewhat of an industry standard, and many GenAI tools
    and technologies have support and seamless integrations with it. If you’d like
    to avoid a lot of unnecessary effort and costs, your best bet is to work with
    the OpenAI API.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI API已经成为了某种行业标准，许多生成式AI工具和技术都支持并与它无缝集成。如果你想避免不必要的努力和成本，最佳选择是与OpenAI API合作。
- en: 'Let’s get started with the OpenAI API in the following example:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在以下示例中开始使用OpenAI API：
- en: 'To get started, you’ll need to install `openai` from the terminal or command
    line:'
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要开始，你需要从终端或命令行安装`openai`：
- en: '[PRE26]'
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Include your API key from OpenAI in the environment variable file:'
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在环境变量文件中包含你的OpenAI API密钥：
- en: '[PRE27]'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Send your first API test request to the OpenAI API using the Python library.
    To do this, create a file named `openai-test.py` using the terminal or an IDE.
    Then, inside the file, copy and paste one of the following examples:'
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用Python库向OpenAI API发送第一个API测试请求。为此，使用终端或IDE创建一个名为`openai-test.py`的文件。然后，在文件内部，复制并粘贴以下示例之一：
- en: '[PRE28]'
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Run the code by entering `python openai-test.py` into the terminal or command
    line. This should output a creative poem about recursion. Every result is different
    because the GPT will use creativity to invent something new each time. This is
    what it created in this attempt:'
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过在终端或命令行中输入`python openai-test.py`来运行代码。这将输出一首关于递归的创意诗。每个结果都是不同的，因为GPT会每次都使用创造力来创造新的东西。这是它在这次尝试中创造的：
- en: '[PRE29]'
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: The result is surprisingly good. You should try it for yourself to see what
    new creative poem will be crafted.
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果令人惊讶地好。你应该亲自尝试一下，看看会创作出什么样的新创意诗。
- en: GPT excels at answering questions, but only on the topics it recalls from its
    training data. In most cases, you’ll want GPT to answer questions about your business
    or products or answer commonly asked questions from your users. In such cases,
    you’ll want to add the ability to search a library of your own documents for relevant
    text, and then have GPT use that text as part of its reference information for
    responses. This is referred to as RAG, which you can read more about in [*Chapter
    8*](B22495_08.xhtml#_idTextAnchor180), *Implementing Vector Search in* *AI Applications*.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: GPT擅长回答问题，但仅限于它能从其训练数据中回忆起来的主题。在大多数情况下，你希望GPT回答关于你的业务或产品的问题，或者回答用户经常提出的问题。在这种情况下，你希望添加搜索你自己的文档库中相关文本的能力，然后让GPT使用这些文本作为其响应的参考信息。这被称为RAG，你可以在[*第8章*](B22495_08.xhtml#_idTextAnchor180)，*在AI应用中实现向量搜索*中了解更多信息。
- en: Hugging Face
  id: totrans-194
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Hugging Face
- en: '**Hugging Face** is a prominent AI community and ML platform. Its ecosystem
    is the **Hugging Face Hub**, a platform designed to facilitate collaboration and
    innovation in the AI community. The Hub, located at [https://huggingface.co/docs/hub/en/index](https://huggingface.co/docs/hub/en/index),
    boasts a vast repository of over 120,000 models, 20,000 datasets, and 50,000 demonstrations
    as of writing, making it one of the largest collections of ML resources available.
    It has the following:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '**Hugging Face**是一个突出的AI社区和机器学习平台。其生态系统是**Hugging Face Hub**，一个旨在促进AI社区合作和创新的平台。该Hub位于[https://huggingface.co/docs/hub/en/index](https://huggingface.co/docs/hub/en/index)，截至编写时，拥有超过12万个模型、2万个数据集和5万个演示，是可用的最大机器学习资源集合之一。它具有以下特点：'
- en: '**Extensive model repositories**: The Hub includes pre-trained models for a
    variety of tasks, such as text classification, translation, summarization, and
    question answering, providing a wide range of options for developers.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**广泛的模型存储库**：Hub包括各种任务的预训练模型，如文本分类、翻译、摘要和问答，为开发者提供了广泛的选择。'
- en: '**Datasets**: It provides access to a diverse array of datasets that are crucial
    for training and evaluating ML models. Datasets cover multiple domains and languages,
    supporting the development of robust and versatile AI applications.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据集**：它提供了对多种数据集的访问，这些数据集对于训练和评估机器学习模型至关重要。数据集涵盖多个领域和语言，支持开发稳健和通用的AI应用。'
- en: '**Community and collaboration**: The platform supports collaboration by allowing
    users to share models, datasets, and code. Developers can contribute to the community
    by uploading their own models and datasets, fostering a collaborative environment.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**社区和协作**：该平台通过允许用户共享模型、数据集和代码来支持协作。开发者可以通过上传自己的模型和数据集来为社区做出贡献，营造一个协作的环境。'
- en: '**Integration and deployment options**: The Hugging Face Hub integrates seamlessly
    with popular ML frameworks, such as PyTorch and TensorFlow. The Hub also provides
    deployment solutions, enabling developers to deploy their models in production
    environments easily.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**集成和部署选项**：Hugging Face Hub无缝集成到流行的机器学习框架中，如PyTorch和TensorFlow。Hub还提供部署解决方案，使开发者能够轻松地将模型部署到生产环境中。'
- en: GenAI application developers can use the **Hugging Face Transformers APIs**
    to get access to thousands of pre-trained ML models on specific datasets for specific
    tasks. With transformer models, you can use pre-trained models for inference or
    fine-tune them with your own data using PyTorch and TensorFlow libraries.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: GenAI应用开发者可以使用**Hugging Face Transformers API**来访问特定数据集上针对特定任务的数千个预训练机器学习模型。使用transformer模型，您可以使用预训练模型进行推理或使用PyTorch和TensorFlow库用您自己的数据进行微调。
- en: 'To illustrate what is possible for your GenAI application, let’s see how to
    use a pre-trained transformer model for inference in order to perform two tasks:
    basic sentiment analysis and text generation. Both could be useful for your GenAI
    projects if you, for instance, want to sort customer feedback or score it based
    on sentiment and generate a response.'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明您的GenAI应用可能实现的功能，让我们看看如何使用预训练的transformer模型进行推理以执行两个任务：基本的情感分析和文本生成。如果您想对客户反馈进行排序或根据情感进行评分并生成响应，这两个任务对您的GenAI项目都可能很有用。
- en: Sentiment analysis
  id: totrans-202
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 情感分析
- en: 'You’ll use the `transformers` library to utilize shared models, then explore
    the `pipeline()` function, the core component of the `transformers` library. This
    function seamlessly integrates the model with necessary pre-processing and post-processing
    steps, enabling direct text input and generating intelligible responses:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 您将使用`transformers`库来利用共享模型，然后探索`pipeline()`函数，这是`transformers`库的核心组件。此函数无缝地将模型与必要的预处理和后处理步骤集成，允许直接输入文本并生成可理解的响应：
- en: 'First, ensure you have the necessary packages installed. Note that at least
    one of TensorFlow or PyTorch should be installed. Here, let’s use TensorFlow:'
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，确保您已安装必要的软件包。请注意，至少应安装TensorFlow或PyTorch中的一个。在这里，我们将使用TensorFlow：
- en: '[PRE30]'
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Next, import the `pipeline()` function. You’ll also create an instance of the
    `pipeline()` function and specify the task you want to use it for, that is, sentiment
    analysis:'
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，导入`pipeline()`函数。您还将创建一个`pipeline()`函数的实例，并指定您想使用它的任务，即情感分析：
- en: '[PRE31]'
  id: totrans-207
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'You’ll receive the following output:'
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您将收到以下输出：
- en: '![](img/B22495_07_05.jpg)'
  id: totrans-209
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22495_07_05.jpg)'
- en: 'Figure 7.5: Hugging Face Transformers sentiment analysis output'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.5：Hugging Face Transformers情感分析输出
- en: The model performs the analysis and outputs a label and a score. The `label`
    indicates the sentiment type as positive or negative, and the `score` indicates
    the degree of confidence in the output.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型执行分析并输出标签和分数。`标签`表示情感类型为正面或负面，而`分数`表示对输出的置信度。
- en: 'You can also pass multiple input texts as an array for sentiment classification
    to the model:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以将多个输入文本作为数组传递给模型进行情感分类：
- en: '[PRE32]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'You’ll receive the following as the output:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 您将收到以下输出：
- en: '![](img/B22495_07_06.jpg)'
  id: totrans-215
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22495_07_06.jpg)'
- en: 'Figure 7.6: Multiple input texts for sentiment classification in Hugging Face'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.6：Hugging Face中用于情感分类的多个输入文本
- en: In this case, the model outputs an array of objects. Each output object corresponds
    to the individual text inputs.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，模型输出一个对象数组。每个输出对象对应于单个文本输入。
- en: You might be holding your breath, expecting things to become more complicated—but
    they won’t. You conducted your first sentiment analysis in Hugging Face with a
    pre-trained model with just those few lines of code.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能正在屏住呼吸，期待事情变得更加复杂——但它们不会。你只需用几行代码就在Hugging Face上完成了第一次情感分析。
- en: Text generation
  id: totrans-219
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 文本生成
- en: 'In addition to sentiment analysis, you can also perform many other NLP tasks
    with Transformers libraries, such as text generation. Here, you will provide a
    prompt, and the model will auto-complete it by generating the remaining text:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 除了情感分析，你还可以使用Transformers库执行许多其他NLP任务，例如文本生成。在这里，你将提供一个提示，模型将通过生成剩余的文本来自动完成它：
- en: '[PRE33]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'You’ll get the following output for the preceding code:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 对于前面的代码，你将得到以下输出：
- en: '![](img/B22495_07_07.jpg)'
  id: totrans-223
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22495_07_07.jpg)'
- en: 'Figure 7.7: Text generation using the Hugging Face Transformers'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.7：使用Hugging Face Transformers进行文本生成
- en: Since you did not provide a model name to the pipeline instance, it decided
    to use the default, which in this case is GPT-2\. You may or may not get the same
    results as the ones here because text generation involves some randomness. Again,
    however, you can see how easy this task was.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 由于你没有为管道实例提供模型名称，它决定使用默认的，在这种情况下是GPT-2。你可能或可能不会得到这里的结果，因为文本生成涉及一些随机性。然而，你仍然可以看到这项任务是多么简单。
- en: 'Next, specify a model name to be used in the `pipeline` function at the time
    of text generation. With the following code, you provide some more custom details,
    such as the number of different sequences to be generated and the maximum length
    of the output texts:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，指定在文本生成时`pipeline`函数中要使用的模型名称。以下代码提供了更多自定义细节，例如要生成的不同序列的数量和输出文本的最大长度：
- en: '[PRE34]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'With these additional parameters provided, you’ll now receive the following
    output:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 在提供这些附加参数后，你现在将收到以下输出：
- en: '![](img/B22495_07_08.jpg)'
  id: totrans-229
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22495_07_08.jpg)'
- en: 'Figure 7.8: Hugging Face text generation output with parameters'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.8：带有参数的Hugging Face文本生成输出
- en: The preceding code outputs two different pairs of text, each having fewer than
    25 words.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码输出了两对不同对的文本，每对都少于25个单词。
- en: As you might expect, Hugging Face offers many more tools and functionalities
    that developers can use to build their GenAI applications. With its comprehensive
    library support and active community, Hugging Face continues to be a pivotal resource
    for advancing NLP and ML projects. Additionally, its seamless integration with
    various AI/ML frameworks ensures that developers can efficiently deploy and scale
    their GenAI models with minimal effort and maximum productivity.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所料，Hugging Face提供了许多更多工具和功能，开发者可以使用它们来构建他们的GenAI应用。凭借其全面的库支持和活跃的社区，Hugging
    Face继续成为推进NLP和ML项目的关键资源。此外，它与各种AI/ML框架的无缝集成确保了开发者可以以最小的努力和最大的生产力高效地部署和扩展他们的GenAI模型。
- en: Summary
  id: totrans-233
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you looked at the evolution of AI/ML frameworks in the Python
    space as LLM-powered applications have gained prominence. You also learned why
    Python remains a top choice for building modern LLM-powered applications. You
    reviewed the most popular Python frameworks, libraries, and APIs that can assist
    you in the different stages of GenAI application development.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你了解了Python空间中AI/ML框架的演变，因为LLM驱动的应用已经变得突出。你还学习了为什么Python仍然是构建现代LLM驱动应用的首选。你回顾了最流行的Python框架、库和API，这些可以帮助你在GenAI应用开发的各个阶段。
- en: The GenAI space is evolving so rapidly that by the time this book is published,
    there will probably be more libraries available, more APIs in use, and the framework’s
    capabilities will have expanded. You owe it to yourself to do your own due diligence
    about which framework is best suited for your business needs, but also make sure
    to choose one that is appropriately supported. As with any rapidly evolving technology,
    some of the tools and technologies that are in existence today will be gone tomorrow.
    This chapter has tried, therefore, to only include those that have the community,
    enablement, and feature set to ensure their longevity.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: GenAI领域正在迅速发展，到这本书出版的时候，可能会有更多的库可用，更多的API在应用中，并且框架的功能也将得到扩展。你欠自己一份责任，去深入了解哪个框架最适合你的业务需求，同时也要确保选择一个得到适当支持的框架。正如任何快速发展的技术一样，今天存在的某些工具和技术明天可能就会消失。因此，本章试图只包括那些拥有社区、支持能力和功能集，以确保其长期存在的工具。
- en: Undoubtedly there is still plenty of innovation to be done, and new tools to
    be created, even in the short term—the tools discussed in this chapter are barely
    the tip of the iceberg. So, take a deep breath and begin your own discovery. You
    will inevitably realize that there are tools you need, and that you have too many
    choices on how to fulfill those needs.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 毫无疑问，仍有大量的创新工作要做，以及新的工具需要被创造，即使在短期内——本章讨论的工具也只是冰山一角。因此，深吸一口气，开始你自己的探索之旅。你不可避免地会意识到你需要一些工具，并且你有太多的选择来满足这些需求。
- en: In the next chapter, you will explore how to leverage the vector search feature
    of MongoDB Atlas to create intelligent applications. You will learn about RAG
    architecture systems and gain a deeper understanding of various complex RAG architecture
    patterns with MongoDB Atlas.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，你将探索如何利用 MongoDB Atlas 的向量搜索功能来创建智能应用。你将了解 RAG 架构系统，并通过对 MongoDB Atlas
    的各种复杂 RAG 架构模式进行深入了解。
