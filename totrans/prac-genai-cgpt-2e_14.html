<html><head></head><body>
<div><h1 class="chapterNumber">11</h1>
<h1 class="chapterTitle" id="_idParaDest-166">Epilogue and Final Thoughts</h1>
<p class="normal">You’ve made it up to this point – congratulations! I hope you found the book interesting and that it helped you toward your goals.</p>
<p class="normal">Writing the second edition of this book gave me food for thought, as the number of changes and achievements that have occurred between the two editions is insane, considering that only a little over one year has passed.</p>
<p class="normal">Even while writing this edition, things have been changing rapidly, which makes the job of writing a final chapter very hard.</p>
<p class="normal">So, I’d like <a id="_idIndexMarker639"/>to use this chapter as a compendium of the current landscape of <strong class="keyWord">large foundation models</strong> (<strong class="keyWord">LFMs</strong>) beyond OpenAI, as well as <a id="_idIndexMarker640"/>the most promising areas of research in the field of generative <strong class="keyWord">artificial intelligence</strong> (<strong class="keyWord">AI</strong>) and the concerns that are arising around these new powerful models.</p>
<p class="normal">More specifically, we will cover the following topics:</p>
<ul>
<li class="bulletList">An overview of what we have learned so far</li>
<li class="bulletList">It’s not all about OpenAI</li>
<li class="bulletList">Ethical implications of generative AI and why we need responsible AI</li>
<li class="bulletList">What to expect in the near future</li>
</ul>
<p class="normal">By the end of this chapter, you will have a broader picture of the state-of-the-art developments within the domain of generative AI, how it is impacting industries, and what to expect in terms of new developments and social concerns.</p>
<h1 class="heading-1" id="_idParaDest-167">An overview of what we have learned so far</h1>
<p class="normal">We started this book with an introduction to the concept of generative AI and its various applications. We saw how <a id="_idIndexMarker641"/>generative AI is about not only text but also images, video, and music.</p>
<p class="normal">In <em class="italic">Chapter 2</em>, we moved on to look at the company that brought generative AI to its greatest popularity: OpenAI. Founded in 2015, OpenAI mainly focuses its research on a particular type of <a id="_idIndexMarker642"/>generative model, <strong class="keyWord">Generative Pre-trained Transformer</strong> (<strong class="keyWord">GPT</strong>). Then, in November 2022, OpenAI released ChatGPT, a free web app of a conversational assistant powered by GPT models. It gained immense popularity, reaching one million users in just five days!</p>
<p class="normal">ChatGPT has been a game-changer. Its impact on daily productivity, as well as in various industry domains, is huge. We also saw, in <em class="italic">Chapter 3</em>, how to properly design the most important element when using generative models such as ChatGPT: the prompt. Prompts are the user’s input, nothing more than instructions in natural language. Designing prompts is a pivotal <a id="_idIndexMarker643"/>step to getting the maximum value from your generative models to the point where <strong class="keyWord">prompt engineering </strong>has become a new domain of study.</p>
<p class="normal">Once we got familiar with ChatGPT and prompt design, we moved on to <em class="italic">Chapter 4</em>, where we finally got concrete examples of how ChatGPT can boost your daily productivity and become your daily assistant. From email generation to improving your writing skills, we saw how many activities can be improved thanks to the generative power of ChatGPT.</p>
<p class="normal">But we didn’t stop there. With <em class="italic">Chapters 5, 6, 7</em>, and <em class="italic">8</em>, we saw how ChatGPT can boost not only daily productivity but also domain-specific activities – for developers, from code generation and optimization to interpreting machine learning models; in the case of marketers, from new <a id="_idIndexMarker644"/>product development to improving <strong class="keyWord">search engine optimization</strong> (<strong class="keyWord">SEO</strong>); for researchers, from experiment design to the generation of a presentation based on a study; and for those needing an assistant for visual creativity, from design suggestions to images and canvas creation.</p>
<p class="normal">Furthermore, in <em class="italic">Chapter 9</em>, we explored how all the previous ChatGPT capabilities (code generation, marketing research, and so on) can be further tailored by building highly specialized assistants called GPTs, leveraging OpenAI’s GPT Store. With GPTs, users can build personal assistants that leverage the power of the model behind ChatGPT, yet benefit from a more specialized and scoped behavior, leveraging knowledge bases, plugins, and precise instructions provided by users themselves – all without writing a single line of code!</p>
<p class="normal">With <em class="italic">Chapter 10</em>, we shifted the conversation to the enterprise level, exploring how OpenAI’s models can also be consumed via APIs and embedded in custom applications. This allows both individuals and organizations to build powerful AI-infused apps, which benefit from OpenAI’s LLMs yet offer great flexibility in terms of backend application logic and frontend UI.</p>
<p class="normal">This journey was <a id="_idIndexMarker645"/>meant to provide you with greater clarity about what we are talking about when we refer to popular buzzwords such as ChatGPT, OpenAI, and LLMs.</p>
<p class="normal">However, in the next section, we will see how the incredibly fast AI developments in recent months are bringing brand-new technologies on top of what we have learned so far.</p>
<h1 class="heading-1" id="_idParaDest-168">It’s not all about OpenAI</h1>
<p class="normal">Throughout this book, we have covered “all things OpenAI.” It’s well known that OpenAI was the first entrant <a id="_idIndexMarker646"/>in the landscape of generative AI. It is hard to argue that the launch of ChatGPT was the milestone that marked the so-called paradigm shift in the AI field, from two angles:</p>
<ul>
<li class="bulletList">From a technological perspective, ChatGPT (or, more precisely, the model behind it – GPT-3.5-turbo) was the most powerful LLM out there by the time it was live (November 2022). This gave a competitive advantage to OpenAI, which was hard to benchmark for competitors.</li>
<li class="bulletList">From a behavioral perspective, ChatGPT “broke the internet” in the sense that almost everyone was shocked by its ease of use and its extraordinary capabilities. This led to a new wave of users who, even though not AI experts, became interested in the matter and started exploring the endless capabilities of the product, raising the expectation bars more and more over the months.</li>
</ul>
<p class="normal">Nevertheless, soon after November 2022, many other players entered the market and started populating the landscape of LFMs with new entries, both proprietary and open source.</p>
<p class="normal">Let’s explore some of the key players as of today.</p>
<h2 class="heading-2" id="_idParaDest-169">Mistral AI</h2>
<p class="normal">This France-based <a id="_idIndexMarker647"/>company has made significant strides in the generative AI landscape with its open-source models. Mistral AI is known for its Mistral 7B and Mixtral models, which have been praised for their performance and efficiency. The company focuses on creating highly capable models that are accessible to the broader AI community, promoting innovation through open-source contributions. Their models are designed to handle a variety of tasks, from text generation to code completion, making them versatile tools in the AI toolkit.</p>
<h2 class="heading-2" id="_idParaDest-170">Meta</h2>
<p class="normal">Meta has been a key <a id="_idIndexMarker648"/>player in advancing LLMs, particularly with its <strong class="keyWord">Large Language Model Meta AI</strong> (<strong class="keyWord">LLaMA</strong>) series. These models have been instrumental in pushing the boundaries of what LLMs can achieve, particularly in terms of scalability and efficiency. Meta’s research has focused on optimizing the infrastructure needed to train these massive models, ensuring they can be deployed effectively across various applications. Their work has also emphasized the importance of open-source models, allowing developers worldwide to build on their innovations.</p>
<h2 class="heading-2" id="_idParaDest-171">Microsoft</h2>
<p class="normal">As we covered in <em class="italic">Chapter 10</em>, Microsoft has leveraged its Azure platform to support the development and <a id="_idIndexMarker649"/>deployment of OpenAI through a multi-year partnership. Microsoft has also made an entire catalog of other LLMs available via an API (both proprietary and open source) on its Azure platform.</p>
<p class="normal">In addition to its partnerships, Microsoft has developed its own family of models known as the Phi series. The Phi-3 models, including Phi-3-mini, Phi-3-small, and Phi-3-medium, are designed to be highly efficient and cost-effective. These models excel in various benchmarks, outperforming larger models in tasks such as language understanding, reasoning, coding, and mathematics. The Phi-3-mini, for instance, supports a context window of up to 128K tokens, making it highly versatile for different applications. Microsoft’s focus on optimizing these models for deployment across various platforms, including Azure AI, Hugging Face, and local environments, ensures that they are accessible and practical for a wide range of users. This commitment to developing robust, scalable, and efficient models highlights Microsoft’s significant contributions to the field of GenAI.</p>
<h2 class="heading-2" id="_idParaDest-172">Google</h2>
<p class="normal">Google has been <a id="_idIndexMarker650"/>at the forefront of GenAI with its Gemini models, designed for multi-modal applications. These models can process and generate content across various formats, including text, images, and videos. Google’s innovations in <strong class="keyWord">retrieval-augmented generation</strong> (<strong class="keyWord">RAG</strong>) have improved the accuracy and reliability of LLM outputs by integrating real-time data from cloud databases. This approach helps mitigate issues like hallucinations, ensuring that the generated content is both relevant and accurate.</p>
<h2 class="heading-2" id="_idParaDest-173">Anthropic</h2>
<p class="normal">Anthropic has developed the Claude family of LLMs, which are known for their safety and ethical considerations. Claude models are designed to minimize biases and promote fairness, making them <a id="_idIndexMarker651"/>suitable for a wide range of applications. </p>
<p class="normal">Anthropic’s focus on responsible AI development has set a high standard in the industry, ensuring that its models are not only powerful but also aligned with ethical guidelines. This commitment to safety and transparency has made Claude a trusted name in the GenAI community.</p>
<p class="normal">The proliferation of LLMs in the market of GenAI is increasing exponentially. However, it is important to acknowledge that our choice of the “best LLM for our app” shouldn’t be routed toward the biggest (on average) highest-performing model available. As of the time of writing, there are many LLMs that have been trained in a specific domain or expertise (like mathematical reasoning, code generation, specific languages, and so on) that, on average, perform way worse than general-purpose models like OpenAI’s o1. Nevertheless, we might consider different variables when it comes to developing our application.</p>
<p class="normal">For example, we might be interested in a model that has a very specific comprehension of an industry-specific taxonomy. If this is the case, we might want to leverage LLMs that have been trained and fine-tuned for this purpose, like Microsoft’s BioGPT. Or, we might need to run our model locally, in disconnected scenarios (think about an offshore plant in the middle of the ocean); if this is the case, we couldn’t run, let’s say, GPT-4o – firstly, because it is a proprietary model and cannot be “downloaded”; secondly, would we have a supercomputer that is capable of hosting more than 100 trillion parameters?</p>
<p class="normal">There are many scenarios where models other than the “state of the art” are needed, and it’s part of the job of the new GenAI-related jobs to assess the type of model needed for specific use cases.</p>
<h1 class="heading-1" id="_idParaDest-174">Ethical implications of generative AI and why we need responsible AI</h1>
<p class="normal">The previous section highlighted how, alongside the widespread knowledge and adoption of generative <a id="_idIndexMarker652"/>AI technologies, a general concern is rising.</p>
<p class="normal">The rapid <a id="_idIndexMarker653"/>advancement of AI technologies brings forth a plethora of ethical considerations and challenges that must be carefully addressed to ensure their responsible and equitable deployment. Some of them are listed here:</p>
<ul>
<li class="bulletList"><strong class="keyWord">Data privacy and security</strong>: As AI systems rely heavily on data for their learning and decision-making processes, ensuring data privacy and security becomes paramount. In the context of generative AI, this is a topic that affects the data that is used to train the model in the first instance. Even though the knowledge base used by ChatGPT to generate responses is public, where is the threshold of the consent of involved users whose information is used to generate responses?</li>
<li class="bulletList"><strong class="keyWord">Bias and fairness</strong>: AI models often learn from historical data, which might inadvertently introduce biases. Addressing bias and fairness in AI systems involves the following:<ul>
<li class="bulletList"><strong class="keyWord">Diverse datasets</strong>: Ensuring that training data is diverse and representative of various demographics can help reduce biases in AI models</li>
<li class="bulletList"><strong class="keyWord">Algorithmic fairness</strong>: Developing algorithms that prioritize fairness and do not discriminate against specific demographic groups is essential</li>
<li class="bulletList"><strong class="keyWord">Monitoring and auditing</strong>: Regular monitoring and auditing of AI systems can help identify and rectify biases, ensuring that the outcomes are equitable</li>
</ul>
</li>
<li class="bulletList"><strong class="keyWord">Transparency and accountability</strong>: As AI systems become more complex, understanding <a id="_idIndexMarker654"/>their decision-making processes can be <a id="_idIndexMarker655"/>challenging. This involves the following two important aspects:<ul>
<li class="bulletList"><strong class="keyWord">Explainable AI</strong>: Developing AI models that can provide clear explanations for their decisions can help users understand and trust the system.</li>
<li class="bulletList"><strong class="keyWord">Responsibility and liability</strong>: Establishing clear lines of responsibility and liability for AI systems is crucial to hold developers, organizations, and users accountable for the consequences of AI-driven decisions.</li>
</ul>
</li>
<li class="bulletList"><strong class="keyWord">The future of work</strong>: AI-driven automation has the potential to displace jobs in certain sectors, raising concerns about the future of work. Throughout this book, we have seen how ChatGPT and OpenAI models are able to boost productivity for individuals and enterprises. However, it is also likely that some repetitive tasks will be definitively replaced by AI, which will impact some workers. This is part of the change and development process, and it is pivotal to embrace the change rather than fight it.</li>
</ul>
<p class="normal">Some actions in this direction could be reskilling and upskilling programs – governments, organizations, and educational institutions should invest in reskilling and upskilling programs to help workers adapt to the changing job market and acquire new skills required for emerging roles.</p>
<p class="normal">Most importantly, human-AI collaboration should be encouraged. Developing AI systems that complement and augment human capabilities can help create new job opportunities and foster collaborative work environments.</p>
<p class="normal">By addressing <a id="_idIndexMarker656"/>these ethical considerations and challenges, we can <a id="_idIndexMarker657"/>work in the right direction to ensure that AI technologies are developed and deployed responsibly, promoting a better and more equitable future for all.</p>
<p class="normal">Now, the next logical question might be: given the tremendous acceleration of AI technologies in recent months, what should we expect in the near future?</p>
<h1 class="heading-1" id="_idParaDest-175">What to expect in the near future</h1>
<p class="normal">The acceleration <a id="_idIndexMarker658"/>of AI research and developments in recent months has been incredible. From November 2022 up to the time of writing (February 2025), we have seen the following occur:</p>
<ul>
<li class="bulletList">November 2022: OpenAI releases ChatGPT, a conversational AI model based on GPT-3.5, which quickly gains widespread attention for its human-like text generation capabilities.</li>
<li class="bulletList">December 2022: ChatGPT reaches over one million users within five days of its launch, highlighting the public’s rapid adoption of AI-driven conversational tools.</li>
<li class="bulletList">January 2023: Microsoft announces a multibillion-dollar investment in OpenAI, aiming to integrate advanced AI technologies into its products and services. This is the foundation for the Copilot system.</li>
<li class="bulletList">March 2023: OpenAI unveils GPT-4, an advanced multimodal AI model capable of processing both text and image inputs, marking a significant leap in AI’s understanding and generation capabilities.</li>
<li class="bulletList">May 2023: Google introduces Gemini, a multimodal LLM developed by Google DeepMind, designed to process various data types simultaneously, including text, images, audio, and video.</li>
<li class="bulletList">December 2023: Google launches Gemini 1.0, integrating it into products like Bard and Pixel devices, and plans for broader applications across its services.</li>
<li class="bulletList">February 2024: OpenAI introduces Sora, a text-to-video model capable of generating realistic videos from textual descriptions, expanding the horizons of AI-generated content.</li>
<li class="bulletList">May 2024: OpenAI releases GPT-4o, a multimodal model that processes and generates text, images, and audio, setting new benchmarks in AI performance across various tasks.</li>
<li class="bulletList">June 2024: Anthropic unveils Claude 3.5 Sonnet, an AI model demonstrating enhanced performance in coding, multistep workflows, and image analysis, contributing to the diversification of AI applications.</li>
<li class="bulletList">July 2024: OpenAI introduces GPT-4o mini, a more accessible version of GPT-4o, aimed at making advanced AI capabilities available to a broader audience.</li>
<li class="bulletList">September 2024: OpenAI releases the o1-preview and o1-mini models, designed to enhance <a id="_idIndexMarker659"/>reasoning accuracy, particularly in scientific, coding, and complex reasoning tasks.</li>
<li class="bulletList">December 2024: OpenAI unveils o3 and o3-mini, successors to the o1 model, focusing on improved reasoning and efficiency, and begins testing these models with select users.</li>
<li class="bulletList">January 2025: Chinese AI start-up DeepSeek releases its R1 model, an open-source AI assistant that rivals leading models in performance while being significantly more cost-effective. The launch causes a substantial impact on global tech markets, leading to significant stock fluctuations among major U.S. tech companies.</li>
</ul>
<p class="normal">Plus, in January 2025, a new breakthrough initiative was announced: the Stargate Project. The project is a large-scale initiative focused on developing next-generation AI infrastructure in the U.S. Backed by OpenAI, SoftBank, Oracle, and MGX, the project is set to receive up to $500 billion in investment over the next four years. The first phase involves a $100 billion initial investment, with plans to expand as demand grows.</p>
<p class="normal">This initiative aims to build cutting-edge data centers and power facilities, ensuring the U.S. remains competitive in AI development. Major technology players like Microsoft, NVIDIA, and Arm are contributing expertise and resources. The project is expected to create hundreds of thousands of jobs and drive economic growth, with Texas selected as the first construction site and additional locations under review. Beyond the economic impact, Stargate is positioned as a strategic effort to bolster AI infrastructure and enhance national security.</p>
<p class="normal">This incredible pace makes it hard to predict what will come next. As we have seen, this velocity has also raised concerns among institutions, companies, and public figures because of the lack of regulation for these new technologies. At the same time, companies and institutions will inexorably need to adapt to this new landscape in order to keep up with competitors.</p>
<p class="normal">As we look ahead, the trajectory of generative AI points toward increasingly autonomous and collaborative systems. AI agents – autonomous entities capable of performing complex tasks without human intervention – are evolving rapidly. These agents are expected to manage intricate <a id="_idIndexMarker660"/>processes across various sectors, from automating business operations to enhancing personal productivity. The integration of multi-agent systems, where multiple AI agents collaborate to achieve shared objectives, is poised to revolutionize problem-solving by mimicking effective human teamwork.</p>
<h1 class="heading-1" id="_idParaDest-176">Summary</h1>
<p class="normal">The rapid development of generative AI technologies is ushering in a new era of innovation and transformation. With the immense potential to revolutionize industries and reshape day-to-day life, these advancements are rewriting the rules of human-machine interaction.</p>
<p class="normal">As we stand on the brink of this AI-driven future, it is our collective responsibility to ensure that these technologies are used responsibly and ethically. By embracing opportunities and addressing challenges, we can foster a world where AI empowers humanity and elevates our potential to new heights.</p>
<p class="normal">The GenAI era began “only” two years ago and, if you think about the impact it had over this timeframe, we cannot help imagine all the great achievements we might witness in the near future.</p>
<h1 class="heading-1" id="_idParaDest-177">References</h1>
<ul>
<li class="bulletList">LangChain documentation: https://python.langchain.com/v0.1/docs/get_started/quickstart/</li>
<li class="bulletList">Semantic <a href="https://learn.microsoft.com/en-us/semantic-kernel/whatissk">Kernel documentation: https://learn.microsoft.com/en-us/se</a>mantic-kernel/whatissk</li>
<li class="bulletList">Pinecone documentation: <a href="https://www.pinecone.io/">https://www.pinecone.io/</a></li>
</ul>
<h1 class="heading-1">Join our communities on Discord and Reddit</h1>
<p class="normal">Have questions about the book or want to contribute to discussions on Generative AI and LLMs? Join our Discord server at <a href="Chapter_11.xhtml">https://packt.link/I1tSU</a> and our Reddit channel at <a href="Chapter_11.xhtml">https://packt.link/jwAmA</a> to connect, share, and collaborate with like-minded enthusiasts.</p>
<p class="normal"><img alt="" src="img/Discord.png"/> <img alt="" src="img/QR_Code757615820155951000.png"/></p>
</div>
</body></html>