<html><head></head><body>
		<div id="_idContainer138">
			<h1 id="_idParaDest-225" class="chapter-number"><a id="_idTextAnchor375"/>19</h1>
			<h1 id="_idParaDest-226"><a id="_idTextAnchor376"/>Generation Data Persistence</h1>
			<p>Imagine a Python program generates images but when you go back to the image hoping to make improvements or simply generate new images based on the original prompt, you can’t find the exact prompt, inference steps, guidance scale, and the other things that actually generate <span class="No-Break">the image!</span></p>
			<p>One of the solutions to solve this problem is saving all the metadata in the generated image file. The <strong class="bold">Portable Network Graphics</strong> (<strong class="bold">PNG</strong>) [1] image format provides a mechanism for us to store a <a id="_idIndexMarker573"/>piece of metadata along with the image pixel data. We will explore <span class="No-Break">this solution.</span></p>
			<p>In this chapter, we are going to look at <span class="No-Break">the following:</span></p>
			<ul>
				<li>Exploring and understanding the PNG <span class="No-Break">file structure</span></li>
				<li>Storing the Stable Diffusion generation metadata in the <span class="No-Break">PNG file</span></li>
				<li>Extracting the Stable Diffusion generation metadata from the <span class="No-Break">PNG file</span></li>
			</ul>
			<p>By employing the solution provided by this chapter, you will be able to maintain the generation prompt and parameters in the image file, and also extract the meta information for <span class="No-Break">further usage.</span></p>
			<p><span class="No-Break">Let’s start.</span><a id="_idTextAnchor377"/></p>
			<h1 id="_idParaDest-227"><a id="_idTextAnchor378"/>Exploring and understanding the PNG file structure</h1>
			<p>Before saving the<a id="_idIndexMarker574"/> image metadata and Stable Diffusion generation parameters in the image, we’d better have an overall understanding of why we’re choosing PNG as the output image format to save the output of Stable Diffusion, and why PNG can support unlimited custom metadata, which is useful for writing a large amount of data into <span class="No-Break">the image.</span></p>
			<p>By understanding the PNG format, we can confidently write and read data into a PNG file as we are going to persist data in <span class="No-Break">the image.</span></p>
			<p>PNG is a <a id="_idIndexMarker575"/>raster graphics file format, an ideal image format for images generated by Stable Diffusion. The PNG file format was created as an improved, non-patented lossless image compression format, and is now widely used on <span class="No-Break">the internet.</span></p>
			<p>Besides PNG, several other image formats also support saving custom image metadata, such as JPEG, TIFF, RAW, DNG, and BMP. However, these formats have their problems and limitations. JPEG files can include custom Exif metadata, but JPEG is a loss compression image format, reaching its high rate of compression by sacrificing image quality. DNG is a proprietary format owned by Adobe. BMP’s custom metadata size is limited compared <span class="No-Break">with PNG.</span></p>
			<p>For the PNG format, besides the capability of storing additional metadata, there are a lot of advantages that make it an ideal <span class="No-Break">format [1]:</span></p>
			<ul>
				<li><strong class="bold">Lossless compression</strong>: PNG <a id="_idIndexMarker576"/>uses lossless compression, which means the image quality is not degraded <span class="No-Break">when compressed</span></li>
				<li><strong class="bold">Transparency support</strong>: PNG supports transparency (alpha channel), allowing images to have transparent backgrounds or <span class="No-Break">semi-transparent elements</span></li>
				<li><strong class="bold">Wide color range</strong>: PNG supports 24-bit RGB color, 32-bit RGBA color, and grayscale images, providing a wide range of <span class="No-Break">color options</span></li>
				<li><strong class="bold">Gamma correction</strong>: PNG supports gamma correction, which helps maintain consistent colors across different devices <span class="No-Break">and platforms</span></li>
				<li><strong class="bold">Progressive display</strong>: PNG supports interlacing, allowing the image to be displayed progressively as <a id="_idIndexMarker577"/>it is <span class="No-Break">being downloaded</span></li>
			</ul>
			<p>We also need to be aware that, in some cases, PNG may not be the best choice. Here, let me <span class="No-Break">list some:</span></p>
			<ul>
				<li><strong class="bold">Larger file size</strong>: Compared<a id="_idIndexMarker578"/> to other formats such as JPEG, PNG files can be larger due to its <span class="No-Break">lossless compression</span></li>
				<li><strong class="bold">No native support for animation</strong>: Unlike GIF, PNG does not support <span class="No-Break">animation natively</span></li>
				<li><strong class="bold">Not suitable for high-resolution photographs</strong>: Due to its lossless compression, PNG is not the best choice for high-resolution photographs, as the file size can be significantly larger than formats such as JPEG that use <span class="No-Break">lossy compression</span></li>
			</ul>
			<p>Despite these limitations, PNG remains a viable option for image formatting, particularly for raw images from <span class="No-Break">Stable Diffusion.</span></p>
			<p>The internal data structure of a PNG file is based on a chunk-based structure. Each chunk is a self-contained unit that stores specific information about the image or metadata. This structure allows PNG files to store additional information, such as text, copyright, or any other metadata, without affecting the image <span class="No-Break">data itself.</span></p>
			<p>A PNG file consists of a signature followed by a series of chunks. Here’s a brief overview of the main components of a <span class="No-Break">PNG file:</span></p>
			<ul>
				<li><strong class="bold">Signature</strong>: The first 8 bytes of <a id="_idIndexMarker579"/>a PNG file are a fixed signature (89 50 4E 47 0D 0A 1A 0A in hexadecimal) that identifies the file as <span class="No-Break">a PNG.</span></li>
				<li><strong class="bold">Chunks</strong>: The rest of the<a id="_idIndexMarker580"/> file is composed of chunks. Each chunk has the <span class="No-Break">following structure:</span><ul><li><strong class="bold">Length</strong> (4 bytes): An unsigned integer representing the length of the chunk’s data field <span class="No-Break">in bytes.</span></li><li><strong class="bold">Type</strong> (4 bytes): A 4-byte string that specifies the type of the chunk (e.g., IHDR, IDAT, <span class="No-Break">tEXt, etc.).</span></li><li><strong class="bold">Data</strong> (variable length): The chunk’s data, as specified by the <span class="No-Break"><strong class="source-inline">length</strong></span><span class="No-Break"> field.</span></li><li><strong class="bold">CRC</strong> (4 bytes): A <strong class="bold">cyclic redundancy check</strong> (<strong class="bold">CRC</strong>) value <a id="_idIndexMarker581"/>for error detection, calculated based on the chunk’s type and <span class="No-Break">data fields.</span></li></ul></li>
			</ul>
			<p>This structure offers both flexibility and extensibility, as it allows for the addition of new chunk types without disrupting the compatibility with existing PNG decoders. Moreover, this PNG data structure enables the insertion of nearly limitless additional metadata into <span class="No-Break">the image.</span></p>
			<p>Next, we will utilize Python to insert some text data into a PNG <span class="No-Break">ima<a id="_idTextAnchor379"/>ge file.</span></p>
			<h1 id="_idParaDest-228"><a id="_idTextAnchor380"/>Saving extra text data in a PNG image file</h1>
			<p>First and <a id="_idIndexMarker582"/>foremost, let’s use Stable Diffusion to generate an image for testing. Not like the code we used in previous chapters, this time, we are going to use a JSON object to store the <span class="No-Break">generation parameters.</span></p>
			<p>Load <span class="No-Break">the model:</span></p>
			<pre class="source-code">
import torch
from diffusers import StableDiffusionPipeline
model_id = "stablediffusionapi/deliberate-v2"
text2img_pipe = StableDiffusionPipeline.from_pretrained(
    model_id,
    torch_dtype = torch.float16
)
# Then, we define all the parameters that will be used to generate an 
# image in a JSON object:
gen_meta = {
    "model_id": model_id,
    "prompt": "high resolution, 
        a photograph of an astronaut riding a horse",
    "seed": 123,
    "inference_steps": 30,
    "height": 512,
    "width": 768,
    "guidance_scale": 7.5
}</pre>
			<p>Now, let’s<a id="_idIndexMarker583"/> use <strong class="source-inline">gen_meta</strong> in the Python <span class="No-Break"><strong class="source-inline">dict</strong></span><span class="No-Break"> type:</span></p>
			<pre class="source-code">
text2img_pipe.to("cuda:0")
input_image = text2img_pipe(
    prompt = gen_meta["prompt"],
    generator = \
        torch.Generator("cuda:0").manual_seed(gen_meta["seed"]),
    guidance_scale = gen_meta["guidance_scale"],
    height = gen_meta["height"],
    width = gen_meta["width"]
).images[0]
text2img_pipe.to("cpu")
torch.cuda.empty_cache()
input_image</pre>
			<p>We should have an image generated with the <strong class="source-inline">input_image</strong> handle – the reference to the image object in the <span class="No-Break">Python context.</span></p>
			<p>Next, let’s store the <strong class="source-inline">gen_meta</strong> data in the PNG file step <span class="No-Break">by step:</span></p>
			<ol>
				<li>Install <a id="_idIndexMarker584"/>the <strong class="source-inline">pillow</strong> library [2] if you <span class="No-Break">haven’t already:</span><pre class="source-code">
pip install pillow</pre></li>
				<li>Use the following code to add one chunk that stores <span class="No-Break">text information:</span><pre class="source-code">
from PIL import Image</pre><pre class="source-code">
from PIL import PngImagePlugin</pre><pre class="source-code">
import json</pre><pre class="source-code">
# Open the original image</pre><pre class="source-code">
image = Image.open("input_image.png")</pre><pre class="source-code">
# Define the metadata you want to add</pre><pre class="source-code">
metadata = PngImagePlugin.PngInfo()</pre><pre class="source-code">
gen_meta_str = json.dumps(gen_meta)</pre><pre class="source-code">
metadata.add_text("my_sd_gen_meta", gen_meta_str)</pre><pre class="source-code">
# Save the image with the added metadata</pre><pre class="source-code">
image.save("output_image_with_metadata.png", "PNG", </pre><pre class="source-code">
    pnginfo=metadata)</pre><p class="list-inset">Now the stringified <strong class="source-inline">gen_meta</strong> is in the <strong class="source-inline">output_image_with_metadata.png</strong> file. Please note that we need to first convert <strong class="source-inline">gen_data</strong> from an object to a string using <span class="No-Break"><strong class="source-inline">json.dumps(gen_meta)</strong></span><span class="No-Break">.</span></p><p class="list-inset">The preceding code added one chunk of data to the PNG file. As we learned at the beginning of this chapter, the PNG file is stacked in chunks, which means we should be able to add any number of text chunks to the PNG file. In the following example, we<a id="_idIndexMarker585"/> added two chunks instead of <span class="No-Break">just one:</span></p><pre class="source-code">
from PIL import Image</pre><pre class="source-code">
from PIL import PngImagePlugin</pre><pre class="source-code">
import json</pre><pre class="source-code">
# Open the original image</pre><pre class="source-code">
image = input_image#Image.open("input_image.png")</pre><pre class="source-code">
# Define the metadata you want to add</pre><pre class="source-code">
metadata = PngImagePlugin.PngInfo()</pre><pre class="source-code">
gen_meta_str = json.dumps(gen_meta)</pre><pre class="source-code">
metadata.add_text("my_sd_gen_meta", gen_meta_str)</pre><pre class="source-code">
# add a copy right json object</pre><pre class="source-code">
copyright_meta = {</pre><pre class="source-code">
    "author":"Andrew Zhu",</pre><pre class="source-code">
    "license":"free use"</pre><pre class="source-code">
}</pre><pre class="source-code">
copyright_meta_str = json.dumps(copyright_meta)</pre><pre class="source-code">
metadata.add_text("copy_right", copyright_meta_str)</pre><pre class="source-code">
# Save the image with the added metadata</pre><pre class="source-code">
image.save("output_image_with_metadata.png", "PNG", </pre><pre class="source-code">
    pnginfo=metadata)</pre><p class="list-inset">Simply by calling another <strong class="source-inline">add_text()function</strong>, we can add a second text chunk to the PNG file. Next, let’s extract the added data from the <span class="No-Break">PNG image.</span></p></li>
				<li>Extracting <a id="_idIndexMarker586"/>text data from a PNG image is straightforward. We will use the <strong class="source-inline">pillow</strong> package again for the <span class="No-Break">extraction task:</span><pre class="source-code">
from PIL import Image</pre><pre class="source-code">
image = Image.open("output_image_with_metadata.png")</pre><pre class="source-code">
metadata = image.info</pre><pre class="source-code">
# print the meta</pre><pre class="source-code">
for key, value in metadata.items():</pre><pre class="source-code">
    print(f"{key}: {value}")</pre><p class="list-inset">We should see an output <span class="No-Break">like this:</span></p><pre class="source-code">
<strong class="bold">my_sd_gen_meta: {"model_id": "stablediffusionapi/deliberate-v2", "prompt": "high resolution, a photograph of an astronaut riding a horse", "seed": 123, "inference_steps": 30, "height": 512, "width": 768, "guidance_scale": 7.5}</strong></pre><pre class="source-code">
<strong class="bold">copy_right: {"author": "Andrew Zhu", "license": "free use"}</strong></pre></li>
			</ol>
			<p>With the code provided in this section, we should be able to save and retrieve custom data to and from a PN<a id="_idTextAnchor381"/>G <span class="No-Break">image file.</span></p>
			<h1 id="_idParaDest-229"><a id="_idTextAnchor382"/>PNG extra data storage limitation</h1>
			<p>You may wonder whether<a id="_idIndexMarker587"/> there are any limitations on text data size. There is no specific limit on the amount of metadata that can be written to a PNG file. However, there are practical constraints based on the PNG file structure and the limitations of the software or libraries used to read and write <span class="No-Break">the metadata.</span></p>
			<p>A PNG file, as we discussed in the first section, is stored in chunks. Each chunk has a maximum size of <span class="_-----MathTools-_Math_Number">2</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">31</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">1</span> bytes (approximately 2 GB). While it is theoretically possible to include multiple metadata chunks within a single PNG file, storing excessive or overly large data within these chunks can lead to errors or slow loading times when attempting to open the image using <span class="No-Break">other software.</span></p>
			<p>In practice, metadata in <a id="_idIndexMarker588"/>PNG files is usually small, containing information such as copyright, author, description, or the software used to create the image. In our case, it is the Stable Diffusion parameters that are used to generate the image. It is not recommended to store large amounts of data in PNG metadata, as it may cause performance issues and compatibility problems with<a id="_idTextAnchor383"/> <span class="No-Break">some software.</span></p>
			<h1 id="_idParaDest-230"><a id="_idTextAnchor384"/>Summary</h1>
			<p>In this chapter, we introduced a solution to store the image generation prompt and relative parameters in the PNG image file, so that the generation data will go with the file wherever it goes and we can extract the parameters, using Stable Diffusion to enhance it or extend the prompt for <span class="No-Break">other usage.</span></p>
			<p>This chapter introduced the file structure of a PNG file and provided sample code to store multiple chunks of text data in a PNG file and then use Python code to extract the metadata from the <span class="No-Break">PNG file.</span></p>
			<p>With the solution’s sample code, you will be able to extract the metadata from an image generated by A1111’s Stable Diffusion web <span class="No-Break">UI too.</span></p>
			<p>In the next chapter, we will build an interactive web UI for a Stable <span class="No-Break">Diffusi<a id="_idTextAnchor385"/>on application.</span></p>
			<h1 id="_idParaDest-231"><a id="_idTextAnchor386"/>References</h1>
			<ol>
				<li>Portable Network Graphics (PNG) specification: <a href="https://www.w3.org/TR/png/">https://www.w3.org/TR/png/</a> <a href="https://www.w3.org/TR/png/&#13;"/></li>
				<li>Pillow <span class="No-Break">package: </span><a href="https://pillow.readthedocs.io/en/stable/"><span class="No-Break">https://pillow.readthedocs.io/en/stable/</span></a></li>
			</ol>
		</div>
	</body></html>