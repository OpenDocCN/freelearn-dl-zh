- en: '6'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '6'
- en: Scaling RAG Bank Customer Data with Pinecone
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Pinecone 缩放 RAG 银行客户数据
- en: Scaling up RAG documents, whether text-based or multimodal, isn’t just about
    piling on and accumulating more data—it fundamentally changes how an application
    works. Firstly, scaling is about finding the right amount of data, not just more
    of it. Secondly, as you add more data, the demands on an application can change—it
    might need new features to handle the bigger load. Finally, cost monitoring and
    speed performance will constrain our projects when scaling. Hence, this chapter
    is designed to equip you with cutting-edge techniques for leveraging AI in solving
    the real-world scaling challenges you may face in your projects. For this, we
    will be building a recommendation system based on pattern-matching using Pinecone
    to minimize bank customer churn (customers choosing to leave a bank).
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 缩放 RAG 文档，无论是基于文本的还是多模态的，不仅仅是堆积和积累更多数据——它从根本上改变了应用程序的工作方式。首先，缩放是关于找到合适的数据量，而不仅仅是更多的数据。其次，随着数据的增加，对应用程序的需求可能会改变——它可能需要新的功能来处理更大的负载。最后，成本监控和速度性能将在缩放时限制我们的项目。因此，本章旨在为您提供利用
    AI 解决您在项目中可能遇到的现实世界缩放挑战的最新技术。为此，我们将构建一个基于模式匹配的推荐系统，使用 Pinecone 来最小化银行客户流失（客户选择离开银行）。
- en: We will start with a step-by-step approach to developing the first program of
    our pipeline. Here, you will learn how to download a Kaggle bank customer dataset
    and perform **exploratory data analysis** (**EDA**). This foundational step is
    crucial as it guides and supports you in preparing your dataset and your RAG strategy
    for the next stages of processing. The second program of our pipeline introduces
    you to the powerful combination of Pinecone—a vector database suited for handling
    large-scale vector search—and OpenAI’s `text-embedding-3-small` model. Here, you’ll
    chunk and embed your data before upserting (updating or inserting records) it
    into a Pinecone index that we will scale up to 1,000,000+ vectors. We will ready
    it for complex query retrieval at a satisfactory speed. Finally, the third program
    of our pipeline will show you how to build RAG queries using Pinecone, augment
    user input, and leverage GPT-4o to generate AI-driven recommendations. The goal
    is to reduce churn in banking by offering personalized, insightful recommendations.
    By the end of this chapter, you’ll have a good understanding of how to apply the
    power of Pinecone and OpenAI technologies to your RAG projects.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将逐步介绍如何开发管道的第一个程序。在这里，您将学习如何下载 Kaggle 银行客户数据集并执行**探索性数据分析**（**EDA**）。这一基础步骤至关重要，因为它引导并支持您为下一阶段的处理准备数据集和您的
    RAG 策略。我们的管道第二个程序将向您介绍 Pinecone 的强大组合——一个适合处理大规模向量搜索的向量数据库——以及 OpenAI 的 `text-embedding-3-small`
    模型。在这里，您将在更新或插入记录之前对数据进行分块和嵌入，并将其放入我们将扩展到 1,000,000+ 向量的 Pinecone 索引中。我们将准备它以在令人满意的速度进行复杂的查询检索。最后，我们的管道第三个程序将向您展示如何使用
    Pinecone 构建 RAG 查询，增强用户输入，并利用 GPT-4o 生成 AI 驱动的推荐。目标是通过对银行提供个性化、有洞察力的推荐来减少客户流失。到本章结束时，您将很好地理解如何将
    Pinecone 和 OpenAI 技术的力量应用于您的 RAG 项目。
- en: 'To sum up, this chapter covers the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，本章涵盖了以下主题：
- en: The key aspects of scaling RAG vector stores
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缩放 RAG 向量存储的关键方面
- en: EDA for data preparation
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据准备中的 EDA（探索性数据分析）
- en: Scaling with Pinecone vector storage
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Pinecone 向量存储进行缩放
- en: Chunking strategy for customer bank information
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 客户银行信息的分块策略
- en: Embedding data with OpenAI embedding models
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 OpenAI 嵌入模型嵌入数据
- en: Upserting data
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据更新插入
- en: Using Pinecone for RAG
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Pinecone 进行 RAG 缩放
- en: Generative AI-driven recommendations with GPT-4o to reduce bank customer churn
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 GPT-4o 生成 AI 驱动的推荐以减少银行客户流失
- en: Let’s begin by defining how we will scale with Pinecone.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从定义如何使用 Pinecone 进行缩放开始。
- en: Scaling with Pinecone
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Pinecone 进行缩放
- en: We will be implementing Pinecone’s innovative vector database technology with
    OpenAI’s powerful embedding capabilities to construct data processing and querying
    systems. The goal is to build a recommendation system to encourage customers to
    continue their association with a bank. Once you understand this approach, you
    will be able to apply it to any domain requiring recommendations (leisure, medical,
    or legal). To understand and optimize the complex processes involved, we will
    build the programs from scratch with a minimal number of components. In this chapter,
    we will use the Pinecone vector database and the OpenAI LLM model.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用Pinecone的创新向量数据库技术和OpenAI强大的嵌入能力来构建数据处理和查询系统。目标是构建一个推荐系统，鼓励客户继续与银行保持联系。一旦您理解了这种方法，您就可以将其应用于任何需要推荐（休闲、医疗或法律）的领域。为了理解和优化涉及到的复杂过程，我们将从零开始构建程序，使用最少的组件。在本章中，我们将使用Pinecone向量数据库和OpenAI
    LLM模型。
- en: Selecting and designing an architecture depends on a project’s specific goals.
    Depending on your project’s needs, you can apply this methodology to other platforms.
    In this chapter and architecture, the combination of a vector store and a generative
    AI model is designed to streamline operations and facilitate scalability. With
    that context in place, let’s go through the architecture we will be building in
    Python.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 选择和设计架构取决于项目的具体目标。根据您项目的需求，您可以将此方法应用于其他平台。在本章中，我们将设计一个结合向量存储和生成式AI模型的架构，以简化操作并促进可扩展性。在明确了这一背景后，让我们来看看我们将用Python构建的架构。
- en: Architecture
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 架构
- en: In this chapter, we will implement vector-based similarity search functionality,
    as we did in *Chapter 2*, *RAG Embedding Vector Stores with Deep Lake and OpenAI*,
    and *Chapter 3*, *Building Index-Based RAG with LlamaIndex, Deep Lake, and OpenAI*.
    We will take the structure of the three pipelines we designed in those chapters
    and apply them to our recommendation system, as shown in *Figure 6.1*. If necessary,
    take the time to go through those chapters before implementing the code in this
    chapter.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将实现基于向量的相似性搜索功能，正如我们在第2章、第3章和第4章中所做的那样，这些章节分别是《使用Deep Lake和OpenAI构建RAG嵌入向量存储》、《使用LlamaIndex、Deep
    Lake和OpenAI构建基于索引的RAG》和《构建基于LlamaIndex的RAG》。我们将采用那些章节中设计的三个管道的结构，并将其应用于我们的推荐系统，如图6.1所示。如果需要，请在实现本章代码之前花时间回顾那些章节。
- en: '![A diagram of a process  Description automatically generated](img/B31169_06_01.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![一个流程图  描述自动生成](img/B31169_06_01.png)'
- en: 'Figure 6.1: Scaling RAG-driven generative AI pipelines'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.1：扩展由RAG驱动的生成式AI管道
- en: 'The key features of the scaled recommendation system we will build can be summarized
    in the three pipelines shown in the preceding figure:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要构建的扩展推荐系统的主要特性可以总结为前面图中显示的三个管道：
- en: '**Pipeline 1: Collecting and preparing the dataset**'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**管道1：收集和准备数据集**'
- en: In this pipeline, we will perform EDA on the dataset with standard queries and
    k-means clustering.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个管道中，我们将使用标准查询和k-means聚类对数据集进行EDA（探索性数据分析）。
- en: '**Pipeline 2: Scaling a Pinecone index (vector store)**'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**管道2：扩展Pinecone索引（向量存储）**'
- en: In this pipeline, we will see how to chunk, embed, and upsert 1,000,000+ documents
    to a Pinecone index (vector store).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个管道中，我们将看到如何将1,000,000+个文档分块、嵌入并更新到Pinecone索引（向量存储）。
- en: '**Pipeline 3: RAG generative AI**'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**管道3：RAG生成式AI**'
- en: This pipeline will take us to fully scaled RAG when we query a 1,000,000+ vector
    store and augment the input of a GPT-4o model to make targeted recommendations.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们查询超过1,000,000个向量的存储库并增强GPT-4o模型的输入以进行针对性推荐时，这个流程将使我们达到完全扩展的RAG（Retrieval-Augmented
    Generation）。
- en: 'The main theoretical and practical applications of the three programs we will
    explore include:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要探索的三个程序的主要理论和实际应用包括：
- en: '**Scalable and serverless infrastructure**: We begin by understanding Pinecone’s
    serverless architecture, which eliminates the complexities of server management
    and scaling. We don’t need to manage storage resources or machine usage. It’s
    a pay-as-you-go approach based on serverless indexes formed by a cloud and region,
    for example, **Amazon Web Services** (**AWS**) in `us-east-1`. Scaling and billing
    are thus simplified, although we still have to monitor and minimize the costs!'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可扩展和无服务器基础设施**：我们首先了解Pinecone的无服务器架构，它消除了服务器管理和扩展的复杂性。我们不需要管理存储资源或机器使用。这是一个基于无服务器索引的按需付费方法，例如，在`us-east-1`的**Amazon
    Web Services**（**AWS**）。因此，扩展和计费得到了简化，尽管我们仍然需要监控并最小化成本！'
- en: '**Lightweight and simplified development environment**: Our integration strategy
    will minimize the use of external libraries, maintaining a lightweight development
    stack. Directly using OpenAI to generate embeddings and Pinecone to store and
    query these embeddings simplifies the data processing pipeline and increases system
    efficiency. Although this approach can prove effective, other methods are possible
    depending on your project, as implemented in other chapters of this book.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**轻量级和简化的开发环境**：我们的集成策略将最小化外部库的使用，保持轻量级开发堆栈。直接使用OpenAI生成嵌入，并使用Pinecone存储和查询这些嵌入简化了数据处理管道，提高了系统效率。尽管这种方法可能证明是有效的，但根据您的项目，其他方法也是可能的，正如本书其他章节所实施的那样。'
- en: '**Optimized scalability and performance**: Pinecone’s vector database is engineered
    to handle large-scale datasets effectively, ensuring that application performance
    remains satisfactory as the data volume grows. As for all cloud platforms and
    APIs, examine the privacy and security constraints when implementing Pinecone
    and OpenAI. Also, continually monitor the system’s performance and costs, as we
    will see in the *Pipeline 2: Scaling a Pinecone index (vector store)* section
    of this chapter.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**优化可扩展性和性能**：Pinecone的向量数据库被设计用来有效地处理大规模数据集，确保随着数据量的增长，应用性能仍然令人满意。至于所有云平台和API，在实施Pinecone和OpenAI时，检查隐私和安全约束。此外，持续监控系统性能和成本，正如我们在本章的*管道2：扩展Pinecone索引（向量存储）*部分中所看到的。'
- en: Let’s now go to our keyboards to collect and process the `Bank Customer Churn`
    dataset.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们打开键盘来收集和处理`Bank Customer Churn`数据集。
- en: 'Pipeline 1: Collecting and preparing the dataset'
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 管道1：收集和准备数据集
- en: 'This section will focus on handling and analyzing the `Bank Customer Churn`
    dataset. We will guide you through the steps of setting up your environment, manipulating
    data, and applying **machine learning** (**ML**) techniques. It is important to
    get the “feel” of a dataset with human analysis before using algorithms as tools.
    Human insights will always remain critical because of the flexibility of human
    creativity. As such, we will implement data collection and preparation in Python
    in three main steps:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将专注于处理和分析`Bank Customer Churn`数据集。我们将引导您完成设置环境、操作数据和应用**机器学习**（**ML**）技术的步骤。在使用算法作为工具之前，通过人工分析来获得数据集的“感觉”是很重要的。由于人类创造力的灵活性，人类洞察力始终是关键的。因此，我们将以三个主要步骤在Python中实施数据收集和准备：
- en: '**Collecting and processing the dataset**:'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**收集和处理数据集**：'
- en: Setting up the Kaggle environment to authenticate and download datasets
  id: totrans-36
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置Kaggle环境以进行身份验证和下载数据集
- en: Collecting and unzipping the `Bank Customer Churn` dataset
  id: totrans-37
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 收集和解压`Bank Customer Churn`数据集
- en: Simplifying the dataset by removing unnecessary columns
  id: totrans-38
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过删除不必要的列简化数据集
- en: '**Exploratory data analysis**:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**探索性数据分析**：'
- en: Performing initial data inspections to understand the structure and type of
    data we have
  id: totrans-40
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行初步数据检查以了解我们所拥有的数据结构和类型
- en: Investigating relationships between customer complaints and churn (closing accounts)
  id: totrans-41
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调查客户投诉与流失（关闭账户）之间的关系
- en: Exploring how age and salary levels relate to customer churn
  id: totrans-42
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索年龄和薪资水平与客户流失的关系
- en: Generating a heatmap to visualize correlations between numerical features
  id: totrans-43
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成热图以可视化数值特征之间的相关性
- en: '**Training an ML model**:'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**训练ML模型**：'
- en: Preparing the data for ML
  id: totrans-45
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准备ML数据
- en: Applying clustering techniques to discover patterns in customer behavior
  id: totrans-46
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用聚类技术以发现客户行为中的模式
- en: Assessing the effectiveness of different cluster configurations
  id: totrans-47
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估不同聚类配置的有效性
- en: Concluding and moving on to RAG-driven generative AI
  id: totrans-48
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 总结并过渡到由RAG驱动的生成式AI
- en: 'Our goal is to analyze the dataset and prepare it for *Pipeline 2: Scaling
    a Pinecone index (vector store)*. To achieve that goal, we need to perform a preliminary
    EDA of the dataset. Moreover, each section is designed to be a hands-on walkthrough
    of the code from scratch, ensuring you gain practical experience and insights
    into data science workflows. Let’s get started by collecting the dataset.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标是分析数据集并为其准备*管道2：扩展Pinecone索引（向量存储）*。为了实现这一目标，我们需要对数据集进行初步的EDA。此外，每个部分都旨在从头开始进行代码的实际演练，确保您获得实际经验和洞察力，了解数据科学工作流程。让我们从收集数据集开始。
- en: 1\. Collecting and processing the dataset
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1. 收集和处理数据集
- en: 'Let’s first collect the `Bank` `Customer Churn` dataset on Kaggle and process
    it:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先在Kaggle上收集并处理`Bank` `Customer Churn`数据集：
- en: '[https://www.kaggle.com/datasets/radheshyamkollipara/bank-customer-churn](https://www.kaggle.com/datasets/radheshyamkollipara/bank-customer-churn)'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.kaggle.com/datasets/radheshyamkollipara/bank-customer-churn](https://www.kaggle.com/datasets/radheshyamkollipara/bank-customer-churn)'
- en: 'The file `Customer-Churn-Records.csv` contains data on 10,000 records of customers
    from a bank focusing on various aspects that might influence customer churn. The
    dataset was uploaded by Radheshyam Kollipara, who rightly states:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 文件`Customer-Churn-Records.csv`包含了一个银行10,000名客户记录的数据，该银行关注可能影响客户流失的各个方面。数据集由Radheshyam
    Kollipara上传，他正确地指出：
- en: As we know, it is much more expensive to sign in a new client than keeping an
    existing one. It is advantageous for banks to know what leads a client towards
    the decision to leave the company. Churn prevention allows companies to develop
    loyalty programs and retention campaigns to keep as many customers as possible.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所知，与保留现有客户相比，吸引新客户要昂贵得多。银行了解导致客户离开公司的因素是有利的。客户流失预防使公司能够开发忠诚度计划和保留活动，以尽可能多地保留客户。
- en: 'Here are the details of the columns included in the dataset that follow the
    description on Kaggle:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是数据集中包含的列的详细信息，这些详细信息遵循Kaggle上的描述：
- en: '`RowNumber—corresponds to the record (row) number and has no effect on the
    output.`'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '`RowNumber—对应记录（行）编号，对输出没有影响。`'
- en: '`CustomerId—contains random values and has no effect on customers leaving the
    bank.`'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '`CustomerId—包含随机值，对客户离开银行没有影响。`'
- en: '`Surname—the surname of a customer has no impact on their decision to leave
    the bank.`'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '`Surname—客户的姓氏对其离开银行的决定没有影响。`'
- en: '`CreditScore—can have an effect on customer churn since a customer with a higher
    credit score is less likely to leave the bank.`'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '`CreditScore—可能会影响客户流失，因为信用评分较高的客户离开银行的可能性较低。`'
- en: '`Geography—a customer''s location can affect their decision to leave the bank.`'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '`Geography—客户的位置可能影响其离开银行的决定。`'
- en: '`Gender—it''s interesting to explore whether gender plays a role in a customer
    leaving the bank.`'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '`Gender—探索性别在客户离开银行中是否起作用很有趣。`'
- en: '`Age—this is certainly relevant since older customers are less likely to leave
    their bank than younger ones.`'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '`Age—这当然很重要，因为与年轻客户相比，年长客户离开银行的可能性较低。`'
- en: '`Tenure—refers to the number of years that the customer has been a client of
    the bank. Normally, older clients are more loyal and less likely to leave a bank.`'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '`Tenure—指客户成为银行客户的时间长度。通常，老客户更忠诚，离开银行的可能性更低。`'
- en: '`Balance—is also a very good indicator of customer churn, as people with a
    higher balance in their accounts are less likely to leave the bank compared to
    those with lower balances.`'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '`Balance—也是客户流失的一个非常好的指标，因为与账户余额较低的人相比，账户余额较高的人离开银行的可能性较低。`'
- en: '`NumOfProducts—refers to the number of products that a customer has purchased
    through the bank.`'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '`NumOfProducts—指客户通过银行购买的产品数量。`'
- en: '`HasCrCard—denotes whether or not a customer has a credit card. This column
    is also relevant since people with a credit card are less likely to leave the
    bank.`'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '`HasCrCard—表示客户是否有信用卡。这一列也很相关，因为持有信用卡的人离开银行的可能性较低。`'
- en: '`IsActiveMember—active customers are less likely to leave the bank.`'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '`IsActiveMember—活跃客户离开银行的可能性较低。`'
- en: '`EstimatedSalary—as with balance, people with lower salaries are more likely
    to leave the bank compared to those with higher salaries.`'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '`EstimatedSalary—与余额一样，与高收入者相比，低收入者离开银行的可能性更高。`'
- en: '`Exited—whether or not the customer left the bank.`'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '`Exited—客户是否离开了银行。`'
- en: '`Complain—customer has complained or not.`'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '`Complain—客户是否投诉。`'
- en: '`Satisfaction Score—Score provided by the customer for their complaint resolution.`'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '`Satisfaction Score—客户对其投诉解决的评分。`'
- en: '`Card Type—the type of card held by the customer.`'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '`Card Type—客户持有的卡类型。`'
- en: '`Points Earned—the points earned by the customer for using a credit card.`'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '`Points Earned—客户使用信用卡获得的积分。`'
- en: Now that we know what the dataset contains, we need to collect it and process
    it for EDA. Let’s install the environment.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道了数据集包含的内容，我们需要收集它并对其进行EDA处理。让我们安装环境。
- en: Installing the environment for Kaggle
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 安装Kaggle的环境
- en: 'To collect datasets from Kaggle automatically, you will need to sign up and
    create an API key at [https://www.kaggle.com/](https://www.kaggle.com/). At the
    time of writing this notebook, downloading datasets is free. Follow the instructions
    to save and use your Kaggle API key. Store your key in a safe location. In this
    case, the key is in a file on Google Drive that we need to mount:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 要自动收集Kaggle数据集，您需要注册并创建一个API密钥，请访问[https://www.kaggle.com/](https://www.kaggle.com/)。在撰写此笔记本时，下载数据集是免费的。按照说明保存并使用您的Kaggle
    API密钥。请将密钥保存在安全的位置。在这种情况下，密钥存储在Google Drive上的一个文件中，我们需要将其挂载：
- en: '[PRE0]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The program now reads the JSON file and sets environment variables for Kaggle
    authentication using your username and an API key:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 程序现在读取JSON文件，并使用您的用户名和API密钥设置用于Kaggle认证的环境变量：
- en: '[PRE1]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We are now ready to install Kaggle and authenticate it:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已准备好安装Kaggle并对其进行认证：
- en: '[PRE2]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: And that’s it! That’s all we need. We are now ready to collect the `Bank Customer
    Churn` dataset.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样！这就是我们需要的所有东西。我们现在已准备好收集`银行客户流失`数据集。
- en: Collecting the dataset
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 收集数据集
- en: 'We will now download the zipped dataset, extract the CSV file, upload it into
    a pandas DataFrame, drop columns that we will not use, and display the result.
    Let’s first download the zipped dataset:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将下载压缩的数据集，提取CSV文件，将其上传到pandas DataFrame中，删除我们将不会使用的列，并显示结果。让我们首先下载压缩的数据集：
- en: '[PRE3]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The output displays the source of the data:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示了数据的来源：
- en: '[PRE4]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We can now unzip the data:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以解压数据：
- en: '[PRE5]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The output should confirm that the file is unzipped:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 输出应确认文件已解压：
- en: '[PRE6]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The CSV file is uploaded to a pandas DataFrame named `data1`:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: CSV文件已上传到名为`data1`的pandas DataFrame中：
- en: '[PRE7]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We will now drop the following four columns in this scenario:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个场景中，我们将删除以下四个列：
- en: '`RowNumber`: We don’t need these columns because we will be creating a unique
    index for each record.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`行号`: 我们不需要这些列，因为我们将为每条记录创建一个唯一的索引。'
- en: '`Surname`: The goal in this scenario is to anonymize the data and not display
    surnames. We will focus on customer profiles and behaviors, such as complaints
    and credit card consumption (points earned).'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`姓氏`: 在这个场景中，目标是匿名化数据，不显示姓氏。我们将专注于客户档案和行为，例如投诉和信用卡消费（积分）。'
- en: '`Gender`: Consumer perceptions and behavior have evolved in the 2020s. It is
    more ethical and just as efficient to leave this information out in the context
    of a sample project.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`性别`: 在2020年代，消费者的感知和行为已经发生了变化。在样本项目中省略这些信息在道德上更加合理，并且同样高效。'
- en: '`Geography`: This field might be interesting in some cases. For this scenario,
    let’s leave this feature out to avoid overfitting outputs based on cultural clichés.
    Furthermore, including this feature would require more information if we wanted
    to calculate distances for delivery services, for example:'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`地理`: 在某些情况下，这个字段可能很有趣。对于这个场景，让我们去掉这个特性，以避免基于文化陈词滥调的输出过拟合。此外，如果我们想计算例如配送服务的距离，包括这个特性将需要更多信息：'
- en: '[PRE8]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The output triggered by `data1` shows a simplified yet sufficient dataset:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 由`data1`触发的输出显示了一个简化但足够的数据集：
- en: '![A screenshot of a computer  Description automatically generated](img/B31169_06_02.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![计算机屏幕截图，自动生成描述](img/B31169_06_02.png)'
- en: 'Figure 6.2: Triggered output'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.2：触发的输出
- en: This approach’s advantage is that it optimizes the size of the data that will
    be inserted into the Pinecone index (vector store). Optimizing the data size before
    inserting data into Pinecone and reducing the dataset by removing unnecessary
    fields can be very beneficial. It reduces the amount of data that needs to be
    transferred, stored, and processed in the vector store. When scaling, smaller
    data sizes can lead to faster query performance and lower costs, as Pinecone pricing
    can depend on the amount of data stored and the computational resources used for
    queries.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的优点在于它优化了将要插入到Pinecone索引（向量存储）中的数据大小。在将数据插入Pinecone之前优化数据大小，通过删除不必要的字段来减少数据集，可以非常有好处。这减少了需要在向量存储中传输、存储和处理的
    数据量。在扩展规模时，较小的数据大小可以导致查询性能更快和成本更低，因为Pinecone的定价可能取决于存储的数据量和用于查询的计算资源。
- en: 'We can now save the new pandas DataFrame in a safe location:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以将新的pandas DataFrame保存到安全的位置：
- en: '[PRE9]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'You can save it in the location that is best for you. Just make sure to save
    it because we will use it in the *Pipeline 2: Scaling a Pinecone index (vector
    store)* section of this chapter. We will now explore the optimized dataset before
    deciding how to implement it in a vector store.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以将其保存在最适合您的位置。只需确保保存它，因为我们将在本章的“管道 2：扩展 Pinecone 索引（向量存储）”部分使用它。我们现在将探索优化后的数据集，然后再决定如何在向量存储中实现它。
- en: 2\. Exploratory data analysis
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2. 探索性数据分析
- en: In this section, we will perform EDA using the data that pandas has just defined,
    which contains customer data from a bank. EDA is a critical step before applying
    any RAG techniques with vector stores, as it helps us understand the underlying
    patterns and trends within the data.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用 pandas 刚定义的数据执行 EDA，该数据包含来自银行的客户数据。EDA 是在应用任何与向量存储相关的 RAG 技术之前的一个关键步骤，因为它有助于我们理解数据中的潜在模式和趋势。
- en: For instance, our preliminary analysis shows a direct correlation between customer
    complaints and churn rates, indicating that customers who have lodged complaints
    are more likely to leave the bank. Additionally, our data reveals that customers
    aged 50 and above are less likely to churn compared to younger customers. Interestingly,
    income levels (particularly the threshold of $100,000) do not appear to significantly
    influence churn decisions.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们的初步分析显示客户投诉与流失率之间存在直接相关性，表明提出投诉的客户更有可能离开银行。此外，我们的数据还显示，与年轻客户相比，50 岁及以上的客户不太可能流失。有趣的是，收入水平（尤其是
    10 万美元的门槛）似乎并没有显著影响流失决策。
- en: Through the careful examination of these insights, we’ll demonstrate why jumping
    straight into complex ML models, especially deep learning, may not always be necessary
    or efficient for drawing basic conclusions. In scenarios where the relationships
    within the data are evident and the patterns straightforward, simpler statistical
    methods or even basic data analysis techniques might be more appropriate and resource-efficient.
    For example, k-means clustering can be effective, and we will implement it in
    the *Training an ML model* section of this chapter.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 通过对这些洞察的仔细审查，我们将展示为什么直接跳入复杂的机器学习模型，尤其是深度学习，并不总是必要的或高效的，用于得出基本结论。在数据内部关系明显且模式直接的情况下，更简单的统计方法甚至基本的数据分析技术可能更合适且资源效率更高。例如，k-means
    聚类分析可能非常有效，我们将在本章的“训练机器学习模型”部分实现它。
- en: 'However, this is not to understate the power of advanced RAG techniques, which
    we will explore in the *Pipeline 2: Scaling a Pinecone index* *(vector store)*
    section of this chapter. In that section, we will employ deep learning within
    vector stores to uncover more subtle patterns and intricate relationships that
    are not readily apparent through classic EDA.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这并不是要低估高级 RAG 技术的力量，我们将在本章的“管道 2：扩展 Pinecone 索引（向量存储）”部分探讨这些技术。在该部分，我们将在向量存储中应用深度学习，以揭示更微妙模式和复杂关系，这些关系通过经典的
    EDA 并不明显。
- en: 'If we display the columns of the DataFrame, we can see that it is challenging
    to find patterns:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们显示 DataFrame 的列，我们可以看到找到模式是具有挑战性的：
- en: '[PRE10]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '`Age`, `EstimatedSalary`, and `Complain` are possible determining features
    that could be correlated with `Exited`. We can also display the DataFrame to gain
    insights, as shown in the excerpt of `data1` in the following figure:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '`Age`、`EstimatedSalary` 和 `Complain` 是可能与 `Exited` 相关的可能决定性特征。我们还可以显示 DataFrame
    以获得洞察，如下图中 `data1` 的摘录所示：'
- en: '![](img/B31169_06_03.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B31169_06_03.png)'
- en: 'Figure 6.3: Visualizing the strong correlation between customer complaints
    and bank churning (Exited)'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.3：可视化客户投诉与银行流失（退出）之间的强相关性
- en: 'The main feature seems to be `Complain`, which leads to `Exited` (churn), as
    shown by running a standard calculation on the DataFrame:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 主要特征似乎是 `Complain`，它导致 `Exited`（流失），如通过在 DataFrame 上运行标准计算所示：
- en: '[PRE11]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The output shows a very high 100.29% ratio between complaints and customers
    leaving the bank (churning). This means that customers who complained did in fact
    leave the bank, which is a natural market trend:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示投诉与离开银行的客户（流失）之间非常高的 100.29% 比率。这意味着确实有投诉的客户离开了银行，这是一个自然的市场趋势：
- en: '[PRE12]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: We can see that only a few exited the bank (six customers) without complaining.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，只有少数客户（六位客户）在未投诉的情况下离开了银行。
- en: 'Run the following cells from GitHub; these contain Python functions that are
    variations of the `exited` and `complain` ratios and will produce the following
    outputs:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 运行以下来自 GitHub 的单元格；这些包含 Python 函数，是 `exited` 和 `complain` 比率的变体，并将产生以下输出：
- en: '`Age` and `Exited` with a threshold of `age=50` shows that persons over 50
    seem less likely to leave a bank:'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`age=50`的阈值，`Age`和`Exited`显示，50岁以上的人似乎不太可能离开银行：
- en: '[PRE13]'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Conversely, the output shows that younger customers seem more likely to leave
    a bank if they are dissatisfied. You can explore different age thresholds to analyze
    the dataset further.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，输出结果显示，如果年轻客户不满意，他们似乎更有可能离开银行。你可以探索不同的年龄阈值来进一步分析数据集。
- en: '`Salary`and `Exited`with a threshold of `salary_threshold=100000` doesn’t seem
    to be a significant feature, as shown in this output:'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`salary_threshold=100000`的阈值，`Salary`和`Exited`似乎不是一个显著的特征，如输出所示：
- en: '[PRE14]'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Try exploring different thresholds to analyze the dataset to confirm or refute
    this trend.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试探索不同的阈值来分析数据集，以确认或反驳这一趋势。
- en: 'Let’s create a heatmap based on the `data1` pandas DataFrame:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们基于`data1` pandas DataFrame创建一个热力图：
- en: '[PRE15]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We can see that the highest correlation is between `Complain` and `Exited`:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，最高的相关性存在于`Complain`和`Exited`之间：
- en: '![A screenshot of a graph  Description automatically generated](img/B31169_06_04.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![一个图表的截图，描述自动生成](img/B31169_06_04.png)'
- en: 'Figure 6.4: Excerpt of the heatmap'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.4：热力图摘录
- en: The preceding heatmap visualizes the correlation between each pair of features
    (variables) in the dataset. It shows the correlation coefficients between each
    pair of variables, which can range from `-1`(low correlation) to `1`(high correlation),
    with `0` indicating no correlation.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的热力图显示了数据集中每对特征（变量）之间的相关性。它显示了每对变量之间的相关系数，其范围可以从`-1`（低相关性）到`1`（高相关性），`0`表示没有相关性。
- en: With that, we have explored several features. Let’s build an ML model to take
    this exploration further.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在此基础上，我们已经探索了几个特征。让我们构建一个机器学习模型来进一步探索。
- en: 3\. Training an ML model
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3. 训练机器学习模型
- en: Let’s continue our EDA and drill into the dataset further with an ML model.
    This section implements the training of an ML model using clustering techniques,
    specifically k-means clustering, to explore patterns within our dataset. We’ll
    prepare and process data for analysis, apply clustering, and then evaluate the
    results using different metrics. This approach is valuable for extracting insights
    without immediately resorting to more complex deep learning methods.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续我们的EDA，并使用机器学习模型进一步深入数据集。本节实现了使用聚类技术（特别是k-means聚类）训练机器学习模型，以探索数据集中的模式。我们将准备和处理数据以进行分析，应用聚类，然后使用不同的指标评估结果。这种方法对于提取洞察力而无需立即求助于更复杂的深度学习方法是有价值的。
- en: k-means clustering is an unsupervised ML algorithm that partitions a dataset
    into k distinct, non-overlapping clusters by minimizing the variance within each
    cluster. The algorithm iteratively assigns data points to one of the k clusters
    based on the nearest mean (centroid), which is recalculated after each iteration
    until convergence.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: k-means聚类是一种无监督的机器学习算法，通过最小化每个聚类内的方差，将数据集划分为k个不同的、不重叠的聚类。该算法通过迭代地将数据点分配给k个聚类中的一个，基于最近的均值（质心），每次迭代后重新计算，直到收敛。
- en: Now, let’s break down the code section by section.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们逐段分析代码。
- en: Data preparation and clustering
  id: totrans-140
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据准备和聚类
- en: 'We will first copy our chapter’s dataset `data1` to `data2` to be able to go
    back to `data1` if necessary if we wish to try other ML models:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先将我们章节的数据集`data1`复制到`data2`，以便在需要时能够回到`data1`，如果我们想尝试其他机器学习模型：
- en: '[PRE16]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'You can explore the data with various scenarios of feature sets. In this case,
    we will select `''``CreditScore''`, `''Age''`, `''EstimatedSalary''`, `''Exited''`,
    `''Complain''`, and `''Point Earned''`:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以用不同的特征集场景来探索数据。在这种情况下，我们将选择`'CreditScore'`、`'Age'`、`'EstimatedSalary'`、`'Exited'`、`'Complain'`和`'Point
    Earned'`：
- en: '[PRE17]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'As in standard practice, let’s scale the features before running an ML model:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 如标准实践，在运行机器学习模型之前，让我们对特征进行缩放：
- en: '[PRE18]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The credit score, estimated salary, and points earned (reflecting credit card
    spending) are good indicators of a customer’s financial standing with the bank.
    The age factor, combined with these other factors, might influence older customers
    to remain with the bank. However, the important point to note is that complaints
    may lead any market segment to consider leaving since complaints and churn are
    strongly correlated.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 信用评分、估计的薪资和赚取的点（反映信用卡消费）是衡量客户在银行财务状况的良好指标。年龄因素，结合这些其他因素，可能会影响老年客户继续留在银行。然而，需要注意的是，投诉可能导致任何市场细分考虑离开，因为投诉和流失高度相关。
- en: 'We will now try to find two to four clusters to find the optimal number of
    clusters for this set of features:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将尝试找到两个到四个簇，以确定这组特征的最佳簇数量：
- en: '[PRE19]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The output contains an evaluation of clustering performance using two metrics—the
    silhouette score and the Davies-Bouldin index—across different numbers of clusters
    (ranging from 2 to 4):'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 输出包含了对不同簇数量（从2到4）的聚类性能评估，使用了两个指标——轮廓得分和戴维斯-博尔丁指数：
- en: '[PRE20]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '**Silhouette score**: This metric measures the quality of clustering by calculating
    the mean intra-cluster distance (how close each point in one cluster is to points
    in the same cluster) and the mean nearest cluster distance (how close each point
    is to points in the next nearest cluster). The score ranges from -1 to 1, where
    a high value indicates that clusters are well-separated and internally cohesive.
    In this output, the highest silhouette score is 0.6129 for 2 clusters, suggesting
    better cluster separation and cohesion compared to 3 or 4 clusters.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '**轮廓得分**：此指标通过计算平均簇内距离（一个簇中每个点到同一簇中点的距离）和平均最近簇距离（每个点到下一个最近簇中点的距离）来衡量聚类的质量。得分范围从-1到1，高值表示簇之间分隔良好且内部凝聚力强。在此输出中，2个簇的最高轮廓得分是0.6129，表明与3个或4个簇相比，簇的分离度和凝聚力更好。'
- en: '**Davies-Bouldin index**: This index evaluates clustering quality by comparing
    the ratio of within-cluster distances to between-cluster distances. Lower values
    of this index indicate better clustering, as they suggest lower intra-cluster
    variance and higher separation between clusters. The smallest Davies-Bouldin index
    in the output is 0.6144 for 2 clusters, indicating that this configuration likely
    provides the most effective separation of data points among the evaluated options.'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '**戴维斯-博尔丁指数**：此指数通过比较簇内距离与簇间距离的比率来评估聚类质量。此指数的值越低，表示聚类越好，因为它们表明簇内方差较低，簇间分离度较高。输出中最小的戴维斯-博尔丁指数为2个簇的0.6144，表明这种配置可能在评估的选项中提供了最有效的数据点分离。'
- en: For two clusters, the silhouette score and Davies-Bouldin index both suggest
    relatively good clustering performance. But as the number of clusters increases
    to three and four, both metrics indicate a decline in clustering quality, with
    lower silhouette scores and higher Davies-Bouldin indices, pointing to less distinct
    and less cohesive clusters.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 对于两个簇，轮廓得分和戴维斯-博尔丁指数都表明聚类性能相对良好。但随着簇数量的增加至三个和四个，这两个指标都显示出聚类质量的下降，轮廓得分降低，戴维斯-博尔丁指数升高，表明簇的区分度和凝聚力较低。
- en: Implementation and evaluation of clustering
  id: totrans-155
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 聚类实现和评估
- en: 'Since two clusters seem to be the best choice for this dataset and set of features,
    let’s run the model with `n_clusters=2`:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 由于两个簇似乎是这个数据集和特征集的最佳选择，让我们用`n_clusters=2`运行模型：
- en: '[PRE21]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Once again, as shown in the *2\. Exploratory data analysis* section, the correlation
    between complaints and exiting is established, as shown in the excerpt of the
    pandas DataFrame in *Figure 6.5*:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，正如在*2. 探索性数据分析*部分所示，投诉和退出之间的相关性已建立，如*图6.5*中的pandas DataFrame摘录所示：
- en: '![A screenshot of a game  Description automatically generated](img/B31169_06_05.png)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![游戏截图  自动生成的描述](img/B31169_06_05.png)'
- en: 'Figure 6.5: Excerpt of the output of k-means clustering'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '*图6.5*：k-means聚类输出摘录'
- en: The first cluster is `class=0`, which represents customers who complained (`Complain`)
    and left (`Exited`) the bank.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个簇是`class=0`，代表投诉并离开银行的客户。
- en: 'If we count the rows for which `Sum where ''class'' == 0 and ''Exited'' ==
    1`, we will obtain a strong correlation between complaints and customers leaving
    the bank:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们计算`Sum where 'class' == 0 and 'Exited' == 1`的行数，我们将获得投诉和客户离开银行之间的强相关性：
- en: '[PRE22]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The output confirms that complaints and churn (customers leaving the bank)
    are closely related:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 输出确认了投诉和客户流失（客户离开银行）之间密切相关：
- en: '[PRE23]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The following cell for the second class where `''class'' == 1 and ''Complain''
    == 1` confirms that few customers that complain stay with the bank:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个类别的下一个单元格`'class' == 1 and 'Complain' == 1`确认了投诉的客户中很少继续留在银行：
- en: '[PRE24]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The output is consistent with the correlations we have observed:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 输出与我们观察到的相关性一致：
- en: '[PRE25]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: We saw that finding the features that could help us keep customers is challenging
    with classical methods that can be effective. However, our strategy will now be
    to transform the customer records into vectors with OpenAI and query a Pinecone
    index to find deeper patterns within the dataset with queries that don’t exactly
    match the dataset.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到，使用经典方法找到有助于我们保留客户的特征具有挑战性，这些方法可能有效。然而，我们的策略现在将是使用 OpenAI 将客户记录转换为向量，并通过查询
    Pinecone 索引来找到数据集中更深层次的模式，这些查询并不完全匹配数据集。
- en: 'Pipeline 2: Scaling a Pinecone index (vector store)'
  id: totrans-171
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 管道 2：扩展 Pinecone 索引（向量存储）
- en: The goal of this section is to build a Pinecone index with our dataset and scale
    it from 10,000 records up to 1,000,000 records. Although we are building on the
    knowledge acquired in the previous chapters, the essence of scaling is different
    from managing sample datasets.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 本节的目标是使用我们的数据集构建 Pinecone 索引，并将其从 10,000 条记录扩展到 1,000,000 条记录。尽管我们是在前几章获得的知识基础上构建的，但扩展的本质与样本数据集的管理不同。
- en: 'The clarity of each process of this pipeline is deceptively simple: data preparation,
    embedding, uploading to a vector store, and querying to retrieve documents. We
    have already gone through each of these processes in *Chapters 2* and *3*.'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 该管道每个流程的清晰度具有欺骗性的简单性：数据准备、嵌入、上传到向量存储和查询以检索文档。我们已经在 *第 2 章* 和 *第 3 章* 中详细讨论了这些流程。
- en: 'Furthermore, beyond implementing Pinecone instead of Deep Lake and using OpenAI
    models in a slightly different way, we are performing the same functions as in
    *Chapters 2*, *3*, and *4* for the vector store phase:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，除了用 Pinecone 代替 Deep Lake 并以略不同的方式使用 OpenAI 模型外，我们在向量存储阶段执行与 *第 2 章*、*第 3
    章* 和 *第 4 章* 相同的功能：
- en: '**Data preparation**: We will start by preparing our dataset using Python for
    chunking.'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**数据准备**：我们将首先使用 Python 对数据集进行分块准备。'
- en: '**Chunking and embedding**: We will chunk the prepared data and then embed
    the chunked data.'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**分块和嵌入**：我们将对准备好的数据进行分块，然后对分块数据进行嵌入。'
- en: '**Creating the Pinecone index**: We will create a Pinecone index (vector store).'
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**创建 Pinecone 索引**：我们将创建一个 Pinecone 索引（向量存储）。'
- en: '**Upserting**: We will upload the embedded documents (in this case, customer
    records) and the text of each record as metadata.'
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**更新插入**：我们将上传嵌入的文档（在这种情况下，客户记录）以及每条记录的文本作为元数据。'
- en: '**Querying the Pinecone index**: Finally, we will run a query to retrieve relevant
    documents to prepare *Pipeline 3: RAG generative AI*.'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**查询 Pinecone 索引**：最后，我们将运行查询以检索相关文档，为 *管道 3：RAG 生成式 AI* 准备。'
- en: Take all the time you need, if necessary, to go through *Chapters 2*,*3*, and
    *4* again for the data preparation, chunking, embedding, and querying functions.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要，你可以花所有需要的时间再次阅读 *第 2 章*、*第 3 章* 和 *第 4 章*，以了解数据准备、分块、嵌入和查询功能。
- en: We know how to implement each phase because we’ve already done that with Deep
    Lake, and Pinecone is a type of vector store, too. So, what’s the issue here?
    The real issue is the hidden real-life project challenges on which we will focus,
    starting with the size, cost, and operations involved.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道如何实现每个阶段，因为我们已经用 Deep Lake 和 Pinecone 做过，Pinecone 也是一种向量存储。那么问题在哪里？真正的问题是隐藏的现实项目挑战，我们将重点关注，从大小、成本和涉及的操作开始。
- en: The challenges of vector store management
  id: totrans-182
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 向量存储管理的挑战
- en: Usually, we begin a section by jumping into the code. That’s fine for small
    volumes, but scaling requires project management decisions before getting started!
    Why? When we run a program with a bad decision or an error on small datasets,
    the consequences are limited. But scaling is a different story! The fundamental
    principle and risk of scaling is that errors are scaled exponentially, too.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，我们通过跳入代码开始一个部分。对于小规模数据来说，这样做是可以的，但扩展需要在进行之前做出项目管理决策！为什么？当我们用错误的决策或小数据集上的错误运行程序时，后果是有限的。但扩展是另一回事！扩展的基本原则和风险是错误也会呈指数级放大。
- en: Let’s list the pain points you must face before running a single line of code.
    You can apply this methodology to any platform or model. However, we have limited
    the platforms in this chapter to OpenAI and Pinecone to focus on processes, not
    platform management. Using other platforms involves careful risk management, which
    isn’t the objective of this chapter.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行任何一行代码之前，你必须面对以下痛点。你可以将这种方法应用于任何平台或模型。然而，在本章中，我们将平台限制在 OpenAI 和 Pinecone，以专注于流程，而不是平台管理。使用其他平台涉及谨慎的风险管理，这不是本章的目标。
- en: 'Let’s begin with OpenAI models:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从 OpenAI 模型开始：
- en: '**OpenAI models for embedding**: OpenAI continually improves and offers new
    models for embedding. Make sure you examine the characteristics of each one before
    embedding, including speed, cost, input limits, and API call rates, at [https://platform.openai.com/docs/models/embeddings](https://platform.openai.com/docs/models/embeddings).'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**嵌入用 OpenAI 模型**：OpenAI 持续改进并提供新的嵌入模型。在嵌入之前，请确保检查每个模型的特性，包括速度、成本、输入限制和 API
    调用率，请参阅 [https://platform.openai.com/docs/models/embeddings](https://platform.openai.com/docs/models/embeddings)。'
- en: '**OpenAI models for generation**:OpenAI continually releases new models and
    abandons older ones. Google does the same. Think of these models as racing cars.
    Can you win a race today with a 1930 racing car? When scaling, you need the most
    efficient models. Check the speed, cost, input limits, output size, and API call
    rates at [https://platform.openai.com/docs/models](https://platform.openai.com/docs/models).'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生成用 OpenAI 模型**：OpenAI 持续发布新模型并淘汰旧模型。Google 也做同样的事情。将这些模型想象成赛车。你今天能用 1930
    年的赛车赢得比赛吗？在扩展规模时，你需要最有效的模型。请查看 [https://platform.openai.com/docs/models](https://platform.openai.com/docs/models)
    上的速度、成本、输入限制、输出大小和 API 调用率。'
- en: 'This means that you must continually take the evolution of models into account
    for speed and cost reasons when scaling. Then, beyond technical considerations,
    you must have a real-time view of the pay-as-you-go billing perspective and technical
    constraints, such as:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着在扩展规模时，您必须持续考虑模型演化的速度和成本原因。然后，在技术考虑之外，您必须对按量付费的计费视角和技术限制有实时了解，例如：
- en: '**Billing management**: [https://platform.openai.com/settings/organization/billing/overview](https://platform.openai.com/settings/organization/billing/overview)'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**计费管理**：[https://platform.openai.com/settings/organization/billing/overview](https://platform.openai.com/settings/organization/billing/overview)'
- en: '**Limits including rate limits**: [https://platform.openai.com/settings/organization/limits](https://platform.openai.com/settings/organization/limits)'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**包括速率限制的限制**：[https://platform.openai.com/settings/organization/limits](https://platform.openai.com/settings/organization/limits)'
- en: 'Now, let’s examine Pinecone constraints once you have created an account:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，一旦您创建了账户，让我们检查 Pinecone 的限制：
- en: '**Cloud and region**: The choice of the cloud (AWS, Google, or other) and region
    (location of the serverless storage) have pricing implications.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**云和区域**：云（AWS、Google 或其他）和区域（无服务器存储的位置）的选择会影响定价。'
- en: '**Usage**: This includes read units, write units, and storage costs, including
    cloud backups. Read more at [https://docs.pinecone.io/guides/indexes/back-up-an-index](https://docs.pinecone.io/guides/indexes/back-up-an-index).'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用**：这包括读取单元、写入单元和存储成本，包括云备份。更多信息请参阅 [https://docs.pinecone.io/guides/indexes/back-up-an-index](https://docs.pinecone.io/guides/indexes/back-up-an-index)。'
- en: 'You must continually monitor the price and usage of Pinecone as for any other
    cloud environment. You can do so using these links: [https://www.pinecone.io/pricing/](https://www.pinecone.io/pricing/)
    and [https://docs.pinecone.io/guides/operations/monitoring](https://docs.pinecone.io/guides/operations/monitoring).'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 您必须持续监控 Pinecone 的价格和使用情况，就像监控任何其他云环境一样。您可以使用以下链接进行操作：[https://www.pinecone.io/pricing/](https://www.pinecone.io/pricing/)
    和 [https://docs.pinecone.io/guides/operations/monitoring](https://docs.pinecone.io/guides/operations/monitoring)。
- en: The scenario we are implementing is one of many other ways of achieving the
    goals in this chapter with other platforms and frameworks. However, the constraints
    are invariants, including pricing, usage, speed performances, and limits.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在实施的场景是许多实现本章目标的其他平台和框架方法之一。然而，约束是不变的，包括定价、使用、速度性能和限制。
- en: Let’s now implement *Pipeline 2* by focusing on the pain points beyond the functionality
    we have already explored in previous chapters. You may open `Pipeline_2_Scaling_a_Pinecone_Index.ipynb`
    in the GitHub repository. The program begins with installing the environment.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们通过关注之前章节中已探索的功能之外的问题点来实施 *Pipeline 2*。您可以在 GitHub 仓库中打开 `Pipeline_2_Scaling_a_Pinecone_Index.ipynb`。程序从安装环境开始。
- en: Installing the environment
  id: totrans-197
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装环境
- en: 'As mentioned earlier, the program is limited to Pinecone and OpenAI, which
    has the advantage of avoiding any intermediate software, platforms, and constraints.
    Store your API keys in a safe location. In this case, the API keys are stored
    on Google Drive:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，程序仅限于 Pinecone 和 OpenAI，这有利于避免任何中间软件、平台和限制。请将您的 API 密钥存储在安全的位置。在这种情况下，API
    密钥存储在 Google Drive 上：
- en: '[PRE26]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Now, we install OpenAI and Pinecone:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们安装 OpenAI 和 Pinecone：
- en: '[PRE27]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Finally, the program initializes the API keys:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，程序初始化 API 密钥：
- en: '[PRE28]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: The program now processes the `Bank Customer Churn` dataset.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 程序现在正在处理`Bank Customer Churn`数据集。
- en: Processing the dataset
  id: totrans-205
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 处理数据集
- en: 'This section will focus on preparing the dataset for chunking, which splits
    it into optimized chunks of text to embed. The program first retrieves the `data1.csv`
    dataset that we prepared and saved in the *Pipeline 1: Collecting and preparing
    the dataset* section of this chapter:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将专注于为分块准备数据集，将其分割成优化的文本分块以进行嵌入。程序首先检索我们在本章*Pipeline 1：收集和准备数据集*部分准备并保存的`data1.csv`数据集：
- en: '[PRE29]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Then, we load the dataset in a pandas DataFrame:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将数据集加载到pandas DataFrame中：
- en: '[PRE30]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'We make sure that the 10,000 lines of the dataset are loaded:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 我们确保数据集的10,000行被加载：
- en: '[PRE31]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The output confirms that the lines are indeed present:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 输出确认这些行确实存在：
- en: '[PRE32]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The following code is important in this scenario. Each line that represents
    a customer record will become a line in the `output_lines` list:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码在此场景中非常重要。代表客户记录的每一行将变成`output_lines`列表中的一行：
- en: '[PRE33]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The output shows that each line in the `output_lines` list is a separate customer
    record text:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示`output_lines`列表中的每一行都是一个单独的客户记录文本：
- en: '[PRE34]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'We are sure that each line is a separate pre-chunk with a clearly defined customer
    record. Let’s now copy `output_lines` to `lines` for the chunking process:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 我们确信每一行都是一个单独的预分块，具有明确定义的客户记录。现在，让我们将`output_lines`复制到`lines`以进行分块过程：
- en: '[PRE35]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The program runs a quality control on the `lines` list to make sure we haven’t
    lost a line in the process:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 程序对`lines`列表进行质量控制，以确保在处理过程中没有丢失任何行：
- en: '[PRE36]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The output confirms that 10,000 lines are present:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 输出确认存在10,000行：
- en: '[PRE37]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: And just like that, the data is ready to be chunked.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样，数据已经准备好进行分块。
- en: Chunking and embedding the dataset
  id: totrans-225
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分块和嵌入数据集
- en: In this section, we will chunk and embed the pre-chunks in the `lines` list.
    Building a pre-chunks list with structured data is not possible every time, but
    when it is, it increases a model’s traceability, clarity, and querying performance.
    The chunking process is straightforward.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将对`lines`列表中的预分块进行分块和嵌入。每次构建具有结构化数据的预分块列表是不可能的，但如果是的话，它将提高模型的可追溯性、清晰度和查询性能。分块过程很简单。
- en: Chunking
  id: totrans-227
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分块
- en: 'The practice of chunking pre-chunks is important for dataset management. We
    can create our chunks from a list of pre-chunks stored as lines:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 分块预分块的做法对于数据集管理非常重要。我们可以从存储为行的预分块列表中创建我们的分块：
- en: '[PRE38]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'The output shows that we have not lost any data during the process:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示在处理过程中我们没有丢失任何数据：
- en: '[PRE39]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: So why bother creating chunks and not just use the lines directly? In many cases,
    lines may require additional quality control and processing, such as data errors
    that somehow slipped through in the previous steps. We might even have a few chunks
    that exceed the input limit (which is continually evolving) of an embedding model
    at a given time.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 那么为什么还要创建分块而不是直接使用行呢？在许多情况下，行可能需要额外的质量控制和处理，例如在之前的步骤中意外遗漏的数据错误。我们甚至可能有一些超过嵌入模型（该限制随时间不断演变）当前输入限制的分块。
- en: 'To better understand the structure of the chunked data, you can examine the
    length and content of the chunks using the following code:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解分块数据的结构，你可以使用以下代码检查分块长度和内容：
- en: '[PRE40]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The output will help a human controller visualize the chunked data, providing
    a snapshot like so:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将帮助人类控制器可视化分块数据，提供如下快照：
- en: '[PRE41]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: The chunks will now be embedded.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 分块现在将被嵌入。
- en: Embedding
  id: totrans-238
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 嵌入
- en: This section will require careful testing and consideration of the issues. We
    will realize that *scaling requires more thinking than doing*. Each project will
    require specific amounts of data through design and testing to provide effective
    responses. We must also take into account the cost and benefit of each component
    of the pipeline. For example, initializing the embedding model is no easy task!
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将需要仔细测试和考虑问题。我们将意识到*扩展需要比执行更多的思考*。每个项目都需要通过设计和测试提供特定数量的数据以提供有效的响应。我们还必须考虑管道中每个组件的成本和收益。例如，初始化嵌入模型并非易事！
- en: 'At the time of writing, OpenAI offers three embedding models that we can test:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，OpenAI提供了三个我们可以测试的嵌入模型：
- en: '[PRE42]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'In this section, we will use `text-embedding-3-small`. However, you can evaluate
    the other models by uncommenting the code. The `embedding` function will accept
    the model you select:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用`text-embedding-3-small`。然而，你可以通过取消注释代码来评估其他模型。`embedding`函数将接受你选择的模型：
- en: '[PRE43]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Make sure to check the cost and features of each embedding model before running
    one of your choice: [https://platform.openai.com/docs/guides/embeddings/embedding-models](https://platform.openai.com/docs/guides/embeddings/embedding-models).'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行您选择的任何嵌入模型之前，请确保检查每个嵌入模型的成本和功能：[https://platform.openai.com/docs/guides/embeddings/embedding-models](https://platform.openai.com/docs/guides/embeddings/embedding-models)。
- en: 'The program now embeds the chunks, but the embedding process requires strategic
    choices, particularly to manage large datasets and API rate limits effectively.
    In this case, we will create batches of chunks to embed:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 程序现在嵌入块，但嵌入过程需要战略选择，特别是为了有效地管理大型数据集和API速率限制。在这种情况下，我们将创建要嵌入的块批次：
- en: '[PRE44]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: We will embed 1,000 chunks at a time with `chunk_start = 0` and `chunk_end =
    1000`. To avoid possible OpenAI API rate limits, `pause_time = 3` was added to
    pause for 3 seconds between each batch. We will store the embeddings in `embeddings
    = []` and count the batches starting with `counter = 1.`
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将分批嵌入1,000个块，`chunk_start = 0`和`chunk_end = 1000`。为了避免可能的OpenAI API速率限制，我们在每个批次之间增加了`pause_time
    = 3`的暂停时间，暂停3秒钟。我们将存储嵌入到`embeddings = []`中，并从`counter = 1`开始计数批次。
- en: 'The code is divided into three main parts, as explained in the following excerpts:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 代码分为三个主要部分，如下摘录所述：
- en: 'Iterating through all the chunks with batches:'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过批次迭代所有块：
- en: '[PRE45]'
  id: totrans-250
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Embedding a batch of `chunks_to_embed`:'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 嵌入一批`chunks_to_embed`：
- en: '[PRE46]'
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Updating the start and end values of the chunks to embed for the next batch:'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更新嵌入下一批块的起始和结束值：
- en: '[PRE47]'
  id: totrans-254
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'A function was added in case the batches are not perfect multiples of the batch
    size:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 添加了一个函数，以防批次不是批次大小的完美倍数：
- en: '[PRE48]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'The output displays the counter and the processing time:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示计数器和处理时间：
- en: '[PRE49]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: The response time may seem long and may vary for each run, but that is what
    scaling is all about! We cannot expect to process large volumes of data in a very
    short time and not face performance challenges.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 响应时间可能看起来很长，并且每次运行都可能不同，但这正是扩展的本质！我们无法期望在非常短的时间内处理大量数据而不面临性能挑战。
- en: 'We can display an embedding if we wish to check that everything went well:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们希望检查一切是否顺利，我们可以显示一个嵌入：
- en: '[PRE50]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'The output displays the embedding:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示嵌入：
- en: '[PRE51]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Let’s verify if we have the same number of text chunks (customer records) and
    vectors (embeddings):'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们验证我们是否有相同数量的文本块（客户记录）和向量（嵌入）：
- en: '[PRE52]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'The output confirms that we are ready to move to Pinecone:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 输出确认我们已经准备好迁移到Pinecone：
- en: '[PRE53]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: We have now chunked and embedded the data. We will duplicate the data to simulate
    scaling in this notebook.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经分块并嵌入数据。我们将复制数据以模拟在此笔记本中的扩展规模。
- en: Duplicating data
  id: totrans-269
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 复制数据
- en: We will duplicate the chunked and embedded data; this way, you can simulate
    volumes without paying for the OpenAI embeddings. The cost of the embedding data
    and the time performances are linear. So we can simulate scaling with a corpus
    of 50,000 data points, for example, and extrapolate the response times and cost
    to any size we need.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将复制分块和嵌入的数据；这样，您可以模拟体积，而无需为OpenAI嵌入付费。嵌入数据的成本和时间性能是线性的。因此，我们可以使用50,000个数据点的语料库来模拟扩展，并将响应时间和成本外推到任何所需的规模。
- en: 'The code is straightforward. We first determine the number of times we want
    to duplicate the data:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 代码很简单。我们首先确定我们想要复制数据的次数：
- en: '[PRE54]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'The program will then duplicate the chunks and the embeddings:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 程序随后将复制块和嵌入：
- en: '[PRE55]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'The code then checks if the number of chunks fits the number of embeddings:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 代码随后检查块的数量是否与嵌入的数量匹配：
- en: '[PRE56]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Finally, the output confirms that we duplicated the data five times:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，输出确认我们已将数据复制了五次：
- en: '[PRE57]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 50,000 data points is a good volume to begin with, giving us the necessary data
    to populate a vector store. Let’s now create the Pinecone index.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 50,000个数据点是一个良好的起始量，为我们提供了填充向量存储所需的数据。现在，让我们创建Pinecone索引。
- en: Creating the Pinecone index
  id: totrans-280
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建Pinecone索引
- en: 'The first step is to make sure our API key is initialized with the name of
    the variable we prefer and then create a Pinecone instance:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是确保我们的API密钥以我们偏好的变量名初始化，然后创建一个Pinecone实例：
- en: '[PRE58]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'The Pinecone instance, `pc`, has been created. Now, we will choose the index
    name, our cloud, and region:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: Pinecone实例`pc`已经创建。现在，我们将选择索引名称、我们的云和区域：
- en: '[PRE59]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'We have now indicated that we want a serverless cloud instance (`spec`) with
    AWS in the `''us-east-1''` location. We are ready to create the index (the type
    of vector store) named `''bank-index-50000''` with the following code:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经指定了我们要一个位于 `'us-east-1'` 位置的 AWS 无服务器云实例 (`spec`)。我们现在可以使用以下代码创建名为 `'bank-index-50000'`
    的索引（向量存储类型）：
- en: '[PRE60]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'We added the following two parameters to `index_name` and `spec`:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 我们向 `index_name` 和 `spec` 添加了以下两个参数：
- en: '`dimension=1536` represents the length of the embeddings vector that you can
    adapt to the embedding model of your choice.'
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dimension=1536` 代表嵌入向量的长度，你可以将其适配到你选择的嵌入模型。'
- en: '`metric=''cosine''` is the metric we will use for vector similarity between
    the embedded vectors. You can also choose other metrics, such as Euclidean distance:
    [https://www.pinecone.io/learn/vector-similarity/](https://www.pinecone.io/learn/vector-similarity/).'
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`metric=''cosine''` 是我们将用于嵌入向量之间向量相似度的度量。你也可以选择其他度量，例如欧几里得距离：[https://www.pinecone.io/learn/vector-similarity/](https://www.pinecone.io/learn/vector-similarity/)。'
- en: 'When the index is created, the program displays the description of the index:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 当索引创建时，程序会显示索引的描述：
- en: '[PRE61]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: The vector count and index fullness are `0` since we haven’t been populating
    the vector store. Great, now we are ready to upsert!
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 向量计数和索引满载量都是 `0`，因为我们还没有填充向量存储。太好了，现在我们准备好 upsert 了！
- en: Upserting
  id: totrans-293
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Upserting
- en: 'The section’s goal is to populate the vector store with our 50,000 embedded
    vectors and their associated metadata (chunks). The objective is to fully understand
    the scaling process and use synthetic data to reach the 50,000+ vector level.
    You can go back to the previous section and duplicate the data up to any value
    you wish. However, bear in mind that the upserting time to a Pinecone index is
    linear. You simply need to extrapolate the performances to the size you want to
    evaluate to obtain the approximate time it would take. Check the Pinecone pricing
    before running the upserting process: [https://www.pinecone.io/pricing/](https://www.pinecone.io/pricing/).'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 该部分的目标是用我们的 50,000 个嵌入向量及其相关元数据（块）填充向量存储。目标是完全理解扩展过程，并使用合成数据达到 50,000+ 个向量的水平。你可以回到前面的部分，并将数据复制到任何你希望的价值。然而，请注意，upsert
    到 Pinecone 索引的时间是线性的。你只需将性能外推到你想要评估的大小，以获得大约需要的时间。在运行 upserting 过程之前检查 Pinecone
    定价：[https://www.pinecone.io/pricing/](https://www.pinecone.io/pricing/)。
- en: 'We will populate (upsert) the vector store with three fields:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用三个字段来填充（upsert）向量存储：
- en: '`ids`: Contains a unique identifier for each chunk, which will be a counter
    we increment as we upsert the data'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ids`: 包含每个块的唯一标识符，它将是一个计数器，我们在 upsert 数据时将其递增'
- en: '`embedding`: Contains the vectors (embedded chunks) we created'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`embedding`: 包含我们创建的向量（嵌入块）'
- en: '`chunks`: Contains the chunks in plain text, which is the metadata'
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`chunks`: 包含纯文本中的块，这是元数据'
- en: 'The code will populate the data in batches. Let’s first define the batch upserting
    function:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 代码将以批量的方式填充数据。让我们首先定义批量 upsert 函数：
- en: '[PRE62]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'We will measure the time it takes to process our corpus:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将测量处理语料库所需的时间：
- en: '[PRE63]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Now, we create a function that will calculate the size of the batches and limit
    them to 4 MB, which is close to the present Pinecone upsert batch size limit:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们创建一个函数来计算批次的尺寸并将它们限制在 4 MB，这接近当前的 Pinecone upsert 批次大小限制：
- en: '[PRE64]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'We can now create our `upsert` function:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以创建我们的 `upsert` 函数：
- en: '[PRE65]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'We need to generate unique IDs for the data we upsert:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要为我们要 upsert 的数据生成唯一的 ID：
- en: '[PRE66]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'We will create the metadata to upsert the dataset to Pinecone:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将创建元数据以将数据集 upsert 到 Pinecone：
- en: '[PRE67]'
  id: totrans-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'We now have everything we need to upsert in `data_for_upsert`:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在拥有在 `data_for_upsert` 中 upsert 所需的一切：
- en: '`"id": str(ids[i])` contains the IDs we created with the seed.'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"id": str(ids[i])` 包含了我们使用种子创建的 ID。'
- en: '`"values": emb` contains the chunks we embedded into vectors.'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"values": emb` 包含了我们嵌入到向量中的块。'
- en: '`"metadata": {"text": chunk}` contains the chunks we embedded.'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"metadata": {"text": chunk}` 包含了我们嵌入的块。'
- en: 'We now run the batch upsert process:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在运行批量 upsert 过程：
- en: '[PRE68]'
  id: totrans-316
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'Finally, we measure the response time:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们测量响应时间：
- en: '[PRE69]'
  id: totrans-318
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'The output contains useful information that shows the batch progression:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 输出包含有用的信息，显示了批次的进度：
- en: '[PRE70]'
  id: totrans-320
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: The time shows that it takes just under one minute (56 seconds) per 10,000 data
    points. You can try a larger corpus. The time should remain linear.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 时间显示，每处理 10,000 个数据点大约需要不到一分钟（56 秒）。你可以尝试更大的语料库。时间应该保持线性。
- en: 'We can also view the Pinecone index statistics to see how many vectors were
    uploaded:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以查看 Pinecone 指数统计信息，以查看上传了多少个向量：
- en: '[PRE71]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'The output confirms that the upserting process was successful:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 输出确认上传过程成功：
- en: '[PRE72]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: The upsert output shows that we upserted 50,000 data points but the output shows
    less, most probably due to duplicates within the data.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 上传输出显示我们上传了 50,000 个数据点，但输出显示较少，很可能是由于数据中的重复。
- en: Querying the Pinecone index
  id: totrans-327
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 查询 Pinecone 索引
- en: 'The task now is to verify the response times with a large Pinecone index. Let’s
    create a function to query the vector store and display the results:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 现在的任务是验证大型 Pinecone 索引的响应时间。让我们创建一个查询向量存储并显示结果的函数：
- en: '[PRE73]'
  id: totrans-329
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'We need an embedding function for the query using the same embedding model
    as we implemented to embed the chunks of the dataset:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要一个嵌入函数来查询，使用与我们实现嵌入数据集块相同的嵌入模型：
- en: '[PRE74]'
  id: totrans-331
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'We can now query the Pinecone vector store to conduct a unit test and display
    the results and response time. We first initialize the OpenAI client and start
    time:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以查询 Pinecone 向量存储库以进行单元测试并显示结果和响应时间。我们首先初始化 OpenAI 客户端并开始计时：
- en: '[PRE75]'
  id: totrans-333
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'We then query the vector store with a customer profile that does not exist
    in the dataset:'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 我们然后使用数据集中不存在的客户配置文件查询向量存储：
- en: '[PRE76]'
  id: totrans-335
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'The query is embedded with the same model as the one used to embed the dataset:'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 查询嵌入与用于嵌入数据集的相同模型：
- en: '[PRE77]'
  id: totrans-337
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'We run the query and display the output:'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 我们运行查询并显示输出：
- en: '[PRE78]'
  id: totrans-339
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'The output displays the query response and time:'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示了查询响应和时间：
- en: '[PRE79]'
  id: totrans-341
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'We can see that the response quality is satisfactory because it found a similar
    profile. The time is excellent: `0.74 seconds`. When reaching a 1,000,000 vector
    count, for example, the response time should still be constant at less than a
    second. That is the magic of the Pinecone index!'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到响应质量令人满意，因为它找到了一个相似的配置文件。时间是出色的：`0.74 秒`。例如，当达到 1,000,000 个向量计数时，响应时间应该仍然保持在不到一秒。这就是
    Pinecone 索引的魔力！
- en: 'If we go to our organization on Pinecone, [https://app.pinecone.io/organizations/](https://app.pinecone.io/organizations/),
    and click on our index, we can monitor our statistics, analyze our usage, and
    more, as illustrated here:'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们转到 Pinecone 上的我们的组织[https://app.pinecone.io/organizations/](https://app.pinecone.io/organizations/)，并点击我们的索引，我们可以监控我们的统计数据，分析我们的使用情况，等等，如图所示：
- en: '![A screenshot of a computer  Description automatically generated](img/B31169_06_06.png)'
  id: totrans-344
  prefs: []
  type: TYPE_IMG
  zh: '![计算机屏幕截图  描述由自动生成](img/B31169_06_06.png)'
- en: 'Figure 6.6: Visualizing the Pinecone index vector count in the Pinecone console'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.6：在 Pinecone 控制台中可视化 Pinecone 索引向量计数
- en: Our Pinecone index is now ready to augment inputs and generate content.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在的 Pinecone 索引已经准备好增强输入并生成内容。
- en: 'Pipeline 3: RAG generative AI'
  id: totrans-347
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 管道 3：RAG 生成式 AI
- en: In this section, we will use RAG generative AI to automate a customized and
    engaging marketing message to the customers of the bank to encourage them to remain
    loyal. We will be building on our programs on data preparation and Pinecone indexing;
    we will leverage the Pinecone vector database for advanced search functionalities.
    We will choose a target vector that represents a market segment to query the Pinecone
    index. The response will be processed to extract the top k similar vectors. We
    will then augment the user input with this target market to ask OpenAI to make
    recommendations to the market segment targeted with customized messages.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用 RAG 生成式 AI 自动化针对银行客户的定制和吸引人的营销信息，以鼓励他们保持忠诚。我们将基于我们的数据准备和 Pinecone
    索引程序；我们将利用 Pinecone 向量数据库的高级搜索功能。我们将选择一个代表市场细分的目标向量来查询 Pinecone 索引。响应将被处理以提取最相似的
    k 个向量。然后我们将用户输入与这个目标市场增强，并让 OpenAI 向目标市场发送带有定制信息的推荐。
- en: 'You may open `Pipeline-3_RAG_Generative AI.ipynb` on GitHub. The first code
    section in this notebook, *Installing the environment*, is the same as in `2-Pincone_vector_store-1M.ipynb`,
    built in the *Pipeline 2: Scaling a Pinecone index (vector store)* section earlier
    in this chapter. The *Pinecone index* in the second code section is also the same
    as in `2-Pincone_vector_store-1M.ipynb`. However, this time, the Pinecone index
    code checks whether a Pinecone index exists and connects to it if it does, rather
    than creating a new index.'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在 GitHub 上打开 `Pipeline-3_RAG_Generative AI.ipynb`。这个笔记本中的第一个代码部分，*安装环境*，与
    `2-Pincone_vector_store-1M.ipynb` 中的相同，在本书前面的 *管道 2：扩展 Pinecone 索引（向量存储）* 部分中构建。第二个代码部分的
    *Pinecone 索引* 也与 `2-Pincone_vector_store-1M.ipynb` 中的相同。然而，这次，Pinecone 索引代码检查是否存在
    Pinecone 索引，如果存在则连接到它，而不是创建一个新的索引。
- en: Let’s run an example of RAG with GPT-4o.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们运行一个使用 GPT-4o 的 RAG 示例。
- en: RAG with GPT-4o
  id: totrans-351
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RAG 与 GPT-4o
- en: 'In this section of the code, we will query the Pinecone vector store, augment
    the user input, and generate a response with GPT-4o. It is the same process as
    with Deep Lake and an OpenAI generative model in *Chapter 3*, *Building Index-Based
    RAG with LlamaIndex, Deep Lake, and OpenAI*, for example. However, the nature
    and usage of the Pinecone query is quite different in this case for the following
    reasons:'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 在这段代码中，我们将查询Pinecone向量存储，增强用户输入，并使用GPT-4o生成响应。这与*第3章*，*使用LlamaIndex、Deep Lake和OpenAI构建基于索引的RAG*中的Deep
    Lake和OpenAI生成模型的过程相同。然而，由于以下原因，在这种情况下，Pinecone查询的性质和用法相当不同：
- en: '**Target vector**: The user input is not a question in the classical sense.
    In this case, it is a target vector representing the profile of a market segment.'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**目标向量**：用户输入在经典意义上不是一个问题。在这种情况下，它是一个代表市场细分档案的目标向量。'
- en: '**Usage**:The usage isn’t to augment the generative AI in the classical dialog
    sense (questions, summaries). In this case, we expect GPT-4o to write an engaging,
    customized email to offer products and services.'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**用法**：这里的用法不是在经典对话意义上增强生成式AI（问题、摘要）。在这种情况下，我们期望GPT-4o撰写一个引人入胜、定制的电子邮件来提供产品和服务的报价。'
- en: '**Query time**:Speed is critical when scaling an application. We will measure
    the query time on the Pinecone index that contains 1,000,000+ vectors.'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**查询时间**：在扩展应用程序时，速度至关重要。我们将测量包含100万+向量的Pinecone索引的查询时间。'
- en: Querying the dataset
  id: totrans-356
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 查询数据集
- en: 'We will need an embedding function to embed the input. We will simplify and
    use the same embedding model we used in the *Embedding* section of *Pipeline 2:
    Scaling a Pinecone index (vector store)* for compatibility reasons:'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要一个嵌入函数来嵌入输入。为了兼容性，我们将简化并使用我们在*Pipeline 2：扩展Pinecone索引（向量存储）*的*嵌入*部分中使用的相同的嵌入模型：
- en: '[PRE80]'
  id: totrans-358
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: We are now ready to query the Pinecone index.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在准备好查询Pinecone索引。
- en: Querying a target vector
  id: totrans-360
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 查询目标向量
- en: A target vector represents a market segment that a marketing team wants to focus
    on for recommendations to increase customer loyalty. Your imagination and creativity
    are the only limits! Usually, the marketing team will be part of the design team
    for this pipeline. You might want to organize workshops to try various scenarios
    until the marketing team is satisfied. If you are part of the marketing team,
    then you want to help design target vectors. In any case, human insights into
    our adaptive creativity will lead to many ways of organizing target vectors and
    queries.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 目标向量代表营销团队希望专注于推荐以提高客户忠诚度的市场细分。你的想象力和创造力是唯一的限制！通常，营销团队将参与此管道的设计团队。你可能想要组织研讨会，尝试各种场景，直到营销团队满意。如果你是营销团队的一员，那么你想要帮助设计目标向量。在任何情况下，我们对自适应创造力的洞察力将导致许多组织目标向量和查询的方法。
- en: In this case, we will target a market segment of customers around the age of
    42 (`Age 42`). We don’t need the age to be strictly 42 or an age bracket. We’ll
    let AI do the work for us. We are also targeting a customer that has a 100,000+
    (`EstimatedSalary 101348.88`) estimated salary, which would be a loss for the
    bank. We’re choosing a customer who has complained (`Complain 1`) and seems to
    be exiting (`Exited 1`) the bank. Let’s suppose that `Exited 1`, in this scenario,
    means that the customer has made a request to close an account but it hasn’t been
    finalized yet. Let’s also consider that the marketing department chose the target
    vector.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们将针对大约42岁（`Age 42`）的客户市场细分。我们不需要年龄严格为42或年龄范围。我们将让AI为我们完成这项工作。我们还针对估计工资为100,000+（`EstimatedSalary
    101348.88`）的客户，这对银行来说将是一笔损失。我们选择一个已经投诉（`Complain 1`）并似乎正在退出（`Exited 1`）银行的客户。让我们假设在这种情况下，`Exited
    1`意味着客户已提出关闭账户的请求，但尚未最终确定。我们还应考虑营销部门选择了目标向量。
- en: '`query_text` represents the customer profiles we are searching for:'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: '`query_text`代表我们正在搜索的客户档案：'
- en: '[PRE81]'
  id: totrans-364
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: 'We have embedded the query. Let’s now retrieve the top-k customer profiles
    that fit the target vector and parse the result:'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经嵌入查询。现在让我们检索与目标向量匹配的前k个客户档案并解析结果：
- en: '[PRE82]'
  id: totrans-366
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'We now print the response and the metadata:'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在打印响应和元数据：
- en: '[PRE83]'
  id: totrans-368
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: 'The result is parsed to find the top-k matches to display their scores and
    content, as shown in the following output:'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 结果被解析以找到前k个匹配项以显示它们的分数和内容，如下面的输出所示：
- en: '[PRE84]'
  id: totrans-370
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: 'We have retrieved valuable information:'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经检索到了有价值的信息：
- en: '**Ranking** through the `top-k` vectors that match the target vector. From
    one to another, depending on the target vector, the ranking will be automatically
    recalculated by the OpenAI generative AI model.'
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**排名**通过匹配目标向量的`top-k`向量。根据目标向量，排名将由OpenAI生成式AI模型自动重新计算。'
- en: '**Score metric** through the score provided. A score is returned providing
    a metric for the response.'
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**评分指标**通过提供的评分。返回一个评分，提供响应的指标。'
- en: '**Content** that contains the top-ranked and best scores.'
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内容**包含排名最高和得分最好的内容。'
- en: It’s an all-in-one automated process! AI is taking us to new heights but we,
    of course, need human control to confirm the output, as described in the previous
    chapter on human feedback.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个一体化的自动化过程！AI正在将我们带到新的高度，但我们当然需要人类控制来确认输出，正如前一章中关于人类反馈所描述的。
- en: We now need to extract the relevant information to augment the input.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在需要提取相关信息以增强输入。
- en: Extracting relevant texts
  id: totrans-377
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提取相关文本
- en: 'The following code goes through the top-ranking vectors, searches for the matching
    text metadata, and combines the content to prepare the augmentation phase:'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码遍历顶级排名向量，搜索匹配的文本元数据，并将内容组合以准备增强阶段：
- en: '[PRE85]'
  id: totrans-379
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: 'The output displays `combined_text`, relevant text we need to augment the input:'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示`combined_text`，我们需要用于增强输入的相关文本：
- en: '[PRE86]'
  id: totrans-381
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: We are now ready to augment the prompt before AI generation.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在准备好在AI生成之前增强提示。
- en: Augmented prompt
  id: totrans-383
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 增强提示
- en: 'We will now engineer our prompt by adding three texts:'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将通过添加三个文本来构建我们的提示：
- en: '`query_prompt`: The instructions for the generative AI model'
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`query_prompt`: 生成式AI模型的指令'
- en: '`query_text`: The target vector containing the target profile chosen by the
    marketing team'
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`query_text`: 包含营销团队选择的目标配置文件的目标向量'
- en: '`combined_context`: The concentrated metadata text of the similar vectors selected
    by the query'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`combined_context`: 查询选择的相似向量的浓缩元文'
- en: '`itext` contains these three variables:'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: '`itext`包含这三个变量：'
- en: '[PRE87]'
  id: totrans-389
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: 'The output is the core input for the generative AI model:'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 输出是生成式AI模型的核心输入：
- en: '[PRE88]'
  id: totrans-391
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: We can now prepare the request for the generative AI model.
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以为生成式AI模型准备请求。
- en: Augmented generation
  id: totrans-393
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 增强生成
- en: In this section, we will submit the augmented input to an OpenAI generative
    AI model. The goal is to obtain a customized email to send the customers in the
    Pinecone index marketing segment we obtained through the target vector.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将提交增强输入到OpenAI生成式AI模型。目标是获得一个定制的电子邮件，发送给通过目标向量获得的Pinecone索引营销段的客户。
- en: 'We will first create an OpenAI client and choose GPT-4o as the generative AI
    model:'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先创建一个OpenAI客户端，并选择GPT-4o作为生成式AI模型：
- en: '[PRE89]'
  id: totrans-396
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: 'We then introduce a time performance measurement:'
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接下来介绍一个时间性能测量：
- en: '[PRE90]'
  id: totrans-398
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: 'The response time should be relatively constant since we are only sending one
    request at a time in this scenario. We now begin to create our completion request:'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种场景下，我们每次只发送一个请求，因此响应时间应该是相对恒定的。我们现在开始创建我们的完成请求：
- en: '[PRE91]'
  id: totrans-400
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: 'The system role provides general instructions to the model:'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 系统角色向模型提供一般指令：
- en: '[PRE92]'
  id: totrans-402
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: 'The user role contains the engineered `itext` prompt we designed:'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 用户角色包含我们设计的工程`itext`提示：
- en: '[PRE93]'
  id: totrans-404
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: 'Now, we set the parameters for the request:'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们设置请求的参数：
- en: '[PRE94]'
  id: totrans-406
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: 'The parameters are designed to obtain a low random yet “creative” output:'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 参数设计用于获得低随机性但“有创意”的输出：
- en: '`temperature=0`: Low randomness in response'
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`temperature=0`: 响应中低随机性'
- en: '`max_tokens=300`: Limits response length to 300 tokens'
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_tokens=300`: 将响应长度限制为300个标记'
- en: '`top_p=1`: Considers all possible tokens; full diversity'
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`top_p=1`: 考虑所有可能的标记；完全多样性'
- en: '`frequency_penalty=0`: No penalty for frequent word repetition to allow the
    response to remain open'
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`frequency_penalty=0`: 不会对频繁单词重复进行惩罚，以允许响应保持开放'
- en: '`presence_penalty=0`: No penalty for introducing new topics to allow the response
    to find ideas for our prompt'
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`presence_penalty=0`: 不会对引入新主题进行惩罚，以允许响应找到我们的提示想法'
- en: 'We send the request and display the response:'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 我们发送请求并显示响应：
- en: '[PRE95]'
  id: totrans-414
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: 'The output is satisfactory for this market segment:'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个市场细分，输出是令人满意的：
- en: '[PRE96]'
  id: totrans-416
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: 'Since the goal of the marketing team is to convince customers not to leave
    and to increase their loyalty to the bank, I’d say the email we received as output
    is good enough. Let’s display the time it took to obtain a response:'
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 由于营销团队的目标是说服客户不要离开并增加他们对银行的忠诚度，我认为我们收到的输出电子邮件已经足够好了。让我们显示获取响应所需的时间：
- en: '[PRE97]'
  id: totrans-418
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: 'The response time is displayed:'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 显示响应时间：
- en: '[PRE98]'
  id: totrans-420
  prefs: []
  type: TYPE_PRE
  zh: '[PRE98]'
- en: We have successfully produced a customized response based on a target vector.
    This approach might be sufficient for some projects, whatever the domain. Let’s
    summarize the RAG-driven generative recommendation system built in this chapter
    and continue our journey.
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经成功根据目标向量生成定制化响应。这种方法可能对某些项目足够，无论领域如何。让我们总结本章构建的 RAG 驱动的生成式推荐系统，并继续我们的旅程。
- en: Summary
  id: totrans-422
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter aimed to develop a scaled RAG-driven generative AI recommendation
    system using a Pinecone index and OpenAI models tailored to mitigate bank customer
    churn. Using a Kaggle dataset, we demonstrated the process of identifying and
    addressing factors leading to customer dissatisfaction and account closures. Our
    approach involved three key pipelines.
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 本章旨在开发一个使用 Pinecone 索引和针对减轻银行客户流失定制的 OpenAI 模型构建的缩放 RAG 驱动的生成式 AI 推荐系统。使用 Kaggle
    数据集，我们展示了识别和解决导致客户不满和账户关闭的因素的过程。我们的方法涉及三个关键流程。
- en: When building *Pipeline 1*, we streamlined the dataset by removing non-essential
    columns, reducing both data complexity and storage costs. Through EDA, we discovered
    a strong correlation between customer complaints and account closures, which a
    k-means clustering model further validated. We then designed *Pipeline 2* to prepare
    our RAG-driven system to generate personalized recommendations. We processed data
    chunks with an OpenAI model, embedding these into a Pinecone index. Pinecone’s
    consistent upsert capabilities ensured efficient data handling, regardless of
    volume. Finally, we built *Pipeline 3* to leverage over 1,000,000 vectors within
    Pinecone to target specific market segments with tailored offers, aiming to boost
    loyalty and reduce attrition. Using GPT-4o, we augmented our queries to generate
    compelling recommendations.
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建 *流程 1* 时，我们通过删除非必要列来简化数据集，从而降低了数据复杂性和存储成本。通过 EDA，我们发现客户投诉和账户关闭之间存在强烈的关联，k-means
    聚类模型进一步验证了这一点。然后，我们设计了 *流程 2* 来准备我们的 RAG 驱动系统以生成个性化推荐。我们使用 OpenAI 模型处理数据块，并将这些嵌入到
    Pinecone 索引中。Pinecone 的持续 upsert 功能确保了无论数据量如何，都能高效地处理数据。最后，我们构建了 *流程 3* 来利用 Pinecone
    中的超过 1,000,000 个向量，针对特定市场段提供定制化优惠，旨在提高忠诚度并减少流失。使用 GPT-4o，我们增强了查询以生成引人入胜的推荐。
- en: The successful application of a targeted vector representing a key market segment
    illustrated our system’s potential to craft impactful customer retention strategies.
    However, we can improve the recommendations by expanding the Pinecone index into
    a multimodal knowledge base, which we will implement in the next chapter.
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 一个代表关键市场段的关键向量成功应用展示了我们系统在制定有影响力的客户保留策略方面的潜力。然而，我们可以通过将 Pinecone 索引扩展到多模态知识库来改进推荐，这将在下一章中实现。
- en: Questions
  id: totrans-426
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: Does using a Kaggle dataset typically involve downloading and processing real-world
    data for analysis?
  id: totrans-427
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 Kaggle 数据集通常涉及下载和处理真实世界数据进行分析吗？
- en: Is Pinecone capable of efficiently managing large-scale vector storage for AI
    applications?
  id: totrans-428
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Pinecone 是否能够有效地管理 AI 应用的大规模向量存储？
- en: Can k-means clustering help validate relationships between features such as
    customer complaints and churn?
  id: totrans-429
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: k-means 聚类能否帮助验证客户投诉和客户流失等特征之间的关系？
- en: Does leveraging over a million vectors in a database hinder the ability to personalize
    customer interactions?
  id: totrans-430
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在数据库中使用超过一百万个向量是否会阻碍个性化客户互动的能力？
- en: Is the primary objective of using generative AI in business applications to
    automate and improve decision-making processes?
  id: totrans-431
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在商业应用中使用生成式 AI 的主要目标是否是自动化并改进决策过程？
- en: Are lightweight development environments advantageous for rapid prototyping
    and application development?
  id: totrans-432
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 轻量级开发环境对于快速原型设计和应用开发是否有优势？
- en: Can Pinecone’s architecture automatically scale to accommodate increasing data
    loads without manual intervention?
  id: totrans-433
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Pinecone 的架构是否能够自动扩展以适应不断增长的数据负载，而无需手动干预？
- en: Is generative AI typically employed to create dynamic content and recommendations
    based on user data?
  id: totrans-434
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成式 AI 通常用于根据用户数据创建动态内容和推荐吗？
- en: Does the integration of AI technologies like Pinecone and OpenAI require significant
    manual configuration and maintenance?
  id: totrans-435
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用类似 Pinecone 和 OpenAI 这样的 AI 技术是否需要大量的手动配置和维护？
- en: Are projects that use vector databases and AI expected to effectively handle
    complex queries and large datasets?
  id: totrans-436
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用向量数据库和 AI 的项目是否预期能够有效地处理复杂查询和大数据集？
- en: References
  id: totrans-437
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Pinecone documentation: [https://docs.pinecone.io/guides/get-started/quickstart](https://docs.pinecone.io/guides/get-started/quickstart)'
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pinecone 文档：[https://docs.pinecone.io/guides/get-started/quickstart](https://docs.pinecone.io/guides/get-started/quickstart)
- en: 'OpenAI embedding and generative models: [https://platform.openai.com/docs/models](https://platform.openai.com/docs/models)'
  id: totrans-439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI 嵌入和生成模型：[https://platform.openai.com/docs/models](https://platform.openai.com/docs/models)
- en: Further reading
  id: totrans-440
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'Han, Y., Liu, C., & Wang, P. (2023). *A comprehensive survey on vector database:
    Storage and retrieval technique, challenge*.'
  id: totrans-441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Han, Y., Liu, C., & Wang, P. (2023). *向量数据库的全面调查：存储和检索技术，挑战*。
- en: Join our community on Discord
  id: totrans-442
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们的 Discord 社区
- en: 'Join our community’s Discord space for discussions with the author and other
    readers:'
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 加入我们的 Discord 空间，与作者和其他读者进行讨论：
- en: '[https://www.packt.link/rag](https://www.packt.link/rag)'
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.packt.link/rag](https://www.packt.link/rag)'
- en: '![](img/QR_Code50409000288080484.png)'
  id: totrans-445
  prefs: []
  type: TYPE_IMG
  zh: '![](img/QR_Code50409000288080484.png)'
