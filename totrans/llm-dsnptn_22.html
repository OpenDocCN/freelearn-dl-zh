<html><head></head><body><div><div><div><h1 id="_idParaDest-258" class="chapter-number"><a id="_idTextAnchor325"/>22</h1>
			<h1 id="_idParaDest-259"><a id="_idTextAnchor326"/>Reasoning and Acting</h1>
			<p><strong class="bold">Reasoning and Acting</strong> (<strong class="bold">ReAct</strong>) is a prompting technique developed by researchers from Princeton <a id="_idIndexMarker1002"/>University and Google that enhances an LLM’s ability to perform reasoning and acting in simulated environments (<a href="https://arxiv.org/pdf/2210.03629">https://arxiv.org/pdf/2210.03629</a>). It allows LLMs to mimic human-like operations in the real world, where we reason verbally and take actions to gain information. ReAct combines <em class="italic">reasoning</em> and <em class="italic">acting</em> to solve complex language reasoning and decision-making tasks.</p>
			<p>While CoT prompting <a id="_idIndexMarker1003"/>enables LLMs to generate reasoning traces, its lack of access to the external world can lead to issues such as fact hallucination. ReAct addresses this by allowing LLMs to generate both <em class="italic">verbal reasoning traces</em> and <em class="italic">text actions</em> for a task. These text actions enable the model to interact with its environment (for example, by querying an external knowledge source or using a tool), gather information, and adjust its reasoning accordingly.</p>
			<p>The key <a id="_idIndexMarker1004"/>characteristics of ReAct are as follows:</p>
			<ul>
				<li><strong class="bold">Reasoning traces</strong>: LLMs generate text that explains their thought process step by step</li>
				<li><strong class="bold">Action generation</strong>: LLMs produce text actions that represent interactions with external tools or environments</li>
				<li><strong class="bold">Observation incorporation</strong>: The results of actions (observations) are fed back into the LLM’s context, influencing subsequent reasoning and actions</li>
				<li><strong class="bold">Iterative process</strong>: ReAct typically involves multiple <em class="italic">Thought</em>/<em class="italic">Action</em>/<em class="italic">Observation</em> steps, allowing for dynamic problem solving</li>
			</ul>
			<p>ReAct excels <a id="_idIndexMarker1005"/>in the following scenarios:</p>
			<ul>
				<li>When a task requires information beyond the LLM’s pre-trained knowledge (for example, multi-hop question answering or fact verification)</li>
				<li>When an LLM needs to navigate and interact with a simulated environment (for example, online shopping or text-based games)</li>
				<li>When you need to combine the power of LLMs with the capabilities of external tools (for example, search engines, calculators, and APIs)</li>
				<li>When the <a id="_idIndexMarker1006"/>task requires a problem to be broken down into smaller steps and decisions must be made based on intermediate results</li>
			</ul>
			<p>In this chapter, we’ll be covering the following topics:</p>
			<ul>
				<li>Implementing ReAct in LangChain</li>
				<li>Building ReAct agents with LangChain’s Expression Language</li>
				<li>Completing tasks and solving problems</li>
				<li>Evaluating ReAct’s performance</li>
				<li>Safety, control, and ethical considerations</li>
				<li>Limitations and future directions</li>
			</ul>
			<h1 id="_idParaDest-260"><a id="_idTextAnchor327"/>Implementing ReAct in LangChain</h1>
			<p>The open <a id="_idIndexMarker1007"/>source LLM framework LangChain (<a href="https://www.langchain.com/">https://www.langchain.com/</a>) provides a powerful and flexible implementation of the ReAct <a id="_idIndexMarker1008"/>framework through <a id="_idIndexMarker1009"/>its <code>Agent</code> class. Let’s explore how to create and use ReAct agents in LangChain:</p>
			<ol>
				<li>Install the necessary packages:<pre class="source-code">
<code>duckduckgo-search</code> and <code>youtube_search</code> integrate search engine functionalities, allowing language models to retrieve real-time information from the web and YouTube, respectively</li><li><code>wikipedia</code> enables language models to access and utilize information from Wikipedia, broadening their knowledge base</li><li><code>langchainhub</code> is a central repository for sharing and discovering LangChain assets, such as prompts, chains, and agents</li></ul></li>				<li>Initialize <a id="_idIndexMarker1010"/>the language <a id="_idIndexMarker1011"/>model and tools such as <code>wikipedia</code>, <code>ddg-search</code>, and <code>llm-math</code>. These are listed in the following code snippet:<pre class="source-code">
import os
import getpass
os.environ["OPENAI_API_KEY"] = getpass.getpass("Enter Your OpenAI API Key:")
from langchain.agents import load_tools
from langchain.chat_models import ChatOpenAI
# load the language model, you can use any model you like
llm = ChatOpenAI(model = "gpt-4o", temperature=0)
# load tools
tools = load_tools(['wikipedia', 'ddg-search','llm-math'],
    llm=llm)</pre><p class="list-inset">Here, we import the necessary modules from <code>langchain</code>. Then, a language model (<code>ChatOpenAI</code>) is initialized with the specified model (<code>gpt-4-1106-preview</code> and <code>temperature</code>. Finally, we load some tools that our agent will use.</p></li>				<li>Initialize <a id="_idIndexMarker1012"/>the ReAct <a id="_idIndexMarker1013"/>agent. Here, the <code>initialize_agent</code> function creates and initializes an agent:<pre class="source-code">
from langchain.agents import initialize_agent
from langchain.agents import AgentType
# initialize agent
agent = initialize_agent(
    tools,  
    llm,  
    agent=AgentType.ZERO_SHOT_REACT_ DESCRIPTION,  
    verbose=True  
) </pre><p class="list-inset">In the preceding code, we list <code>tools</code> and <code>llm</code>, which refers to the language model, as well as specify the agent type as <code>AgentType.ZERO_SHOT_REACT_DESCRIPTION</code>. Here, <code>verbose=True</code> enables detailed logging of the agent’s thought process.</p></li>				<li>Inspect the ReAct agent’s prompt. The following line prints the prompt template used by the ReAct agent. This prompt provides instructions to the LLM on how to use the available tools and follow the ReAct format (<em class="italic">Thought</em>, <em class="italic">Action</em>, <em class="italic">Action Input</em>, and <em class="italic">Observation</em>):<pre class="source-code">
print(agent.agent.llm_chain.prompt.template)</pre><p class="list-inset">Inspecting the ReAct agent’s prompt is important because it reveals the structure and logic that guide the behavior of the language model during tool-augmented reasoning and action. By printing the prompt template with <code>print(agent.agent.llm_chain.prompt.template)</code>, you’re not just seeing arbitrary instructions – you’re inspecting the behavioral scaffold that governs how the agent sequences its reasoning and tool use. This includes how it interprets <a id="_idIndexMarker1014"/>a user <a id="_idIndexMarker1015"/>query, chooses a tool from its available action set, constructs the input to the tool, and integrates the tool’s output (Observation) into further reasoning. If the prompt is poorly constructed, the model may misinterpret the tools, take invalid actions, or fail to chain thoughts coherently. Additionally, the template often includes few-shot examples that demonstrate how to alternate between the ReAct components properly. These examples act as implicit instructions for formatting and logic, helping the model generalize to unseen tasks. Inspecting them can reveal whether the agent was trained or instructed using general patterns or highly specific use cases. It also helps developers debug unexpected behavior or hallucinations since modifying the template directly influences the agent’s action selection, reasoning fidelity, and overall alignment with the intended ReAct cycle.</p></li>				<li>The following code block demonstrates how to customize the prompt template. You can modify the instructions, examples, and formatting to better suit your specific use case:<pre class="source-code">
prompt = """
You are an intelligent agent designed to solve complex queries by breaking them down systematically and using available tools strategically. Follow the ReAct (Reasoning and Acting) framework to approach each task.
ReAct Principles:
1. Reasoning: Always start by carefully analyzing the question and developing a clear, step-by-step thought process.
2. Tool Selection: Critically evaluate which tools will be most effective for addressing the specific query.
3. Iterative Interaction: Be prepared to cycle between reasoning and action multiple times, refining your approach as you gather more information.
4. Comprehensive Understanding: Aim to not just find an answer, but to truly comprehend the underlying context and nuances of the question.
5. Transparent Decision-Making: Clearly articulate your reasoning, actions, and thought process at each step.
Available Tools:
- Wikipedia: Retrieve factual information about people, places, historical events, and general knowledge topics.
- Google Search: Fetch current information, recent events, and up-to-date context.
- Calculator: Perform mathematical calculations and numerical analysis.
Interaction Format:
Question: The specific query to be solved
Thought: Detailed reasoning about the approach, breaking down the problem
Action: Selected tool (Wikipedia/Google Search/Calculator)
Action Input: Precise query for the selected tool
Observation: Results obtained from the tool
... (Repeat reasoning, action, and observation as needed)
Thought: Final synthesized understanding
Final Answer: Comprehensive and well-reasoned response to the original question
Important Guidelines:
- Be methodical and explicit in your reasoning
- Use tools judiciously and avoid unnecessary actions
- Integrate information from multiple sources when appropriate
- Provide a clear, concise, and informative final answer
Begin!
Question: {input}
Thought:{agent_scratchpad}
"""</pre><p class="list-inset">Here, <code>agent.agent.llm_chain.prompt.template = prompt</code> updates the agent’s prompt with the custom template.</p></li>				<li>Next, you <a id="_idIndexMarker1016"/>can modify <a id="_idIndexMarker1017"/>the descriptions of the tools to provide more specific guidance to the LLM on when and how to use each tool:<pre class="source-code">
tools[1].description = "A date retrieval tool that provides the current date and time, useful for temporal queries, scheduling, age calculations, or understanding time-sensitive contexts."
tools[2].description = "A powerful computational tool capable of performing various mathematical operations, including arithmetic calculations, algebraic computations, percentage calculations, unit conversions, and advanced mathematical functions."</pre></li>				<li>The following line executes the agent with a sample query. The agent will use the ReAct framework to perform reasoning, select tools, execute actions, and generate a final answer:<pre class="source-code">
agent.run("What is the population of the largest city in Canada? How many days would it take for that city's population to count to 1 billion if each person counts one number per second without breaks? Then, compare this time to the average lifespan of a human in years, and explain which is longer.")</pre></li>			</ol>
			<p>Next, we’ll look at an example of using ReAct for document processing that levera<a id="_idTextAnchor328"/>ges LangChain.</p>
			<h2 id="_idParaDest-261"><a id="_idTextAnchor329"/>ReAct Document Store</h2>
			<p>LangChain <a id="_idIndexMarker1018"/>also provides a <code>DocstoreExplorer</code> class for implementing ReAct logic with document stores such as Wikipedia. We’ll demonstrate an example by using <code>DocstoreExplorer</code> with Wikipedia <a id="_idIndexMarker1019"/>for document-based ReAct:</p>
			<pre class="source-code">
from langchain import Wikipedia
from langchain.agents import initialize_agent, Tool
from langchain.agents import AgentType
from langchain.agents.react.base import DocstoreExplorer
docstore = DocstoreExplorer(Wikipedia())
search_tool = Tool(name="Search",
                   func=docstore.search,
                   description="Search for latest information about any topic"
                   )
lookup_tool = Tool(name="Lookup",
                   func=docstore.lookup,
                   description="Lookup tool for get information from a keyword"
                   )
tools = [search_tool, lookup_tool]
llm = OpenAI(temperature=0)
react = initialize_agent(tools,
                         llm,
                         agent=AgentType.REACT_DOCSTORE,
                         verbose=True)
question = "Who is the current governor of Texas and when was he born ?"
react.run(question)</pre>			<p>This code <a id="_idIndexMarker1020"/>sets up a LangChain agent designed to answer questions by interacting with Wikipedia. Here’s a breakdown:</p>
			<ol>
				<li><strong class="bold">Wikipedia access</strong>: First, it initializes a connection to Wikipedia, allowing the agent to retrieve information from it.</li>
				<li><code>Search</code> and <code>Lookup</code>. The <code>Search</code> tool enables the agent to find relevant Wikipedia pages, whereas the <code>Lookup</code> tool lets it extract specific information from those pages.</li>
				<li><code>AgentType.REACT_DOCSTORE</code> explicitly configures the agent for document store interactions – in this case, those for Wikipedia.</li>
				<li><code>Search</code> tool to find relevant pages and the <code>Lookup</code> tool to e<a id="_idTextAnchor330"/>xtract the answer.</li>
			</ol>
			<h1 id="_idParaDest-262"><a id="_idTextAnchor331"/>Building ReAct agents with LangChain’s Expression Language</h1>
			<p><strong class="bold">LangChain Expression Language</strong> (<strong class="bold">LCEL</strong>) offers <a id="_idIndexMarker1021"/>a declarative <a id="_idIndexMarker1022"/>approach to constructing <a id="_idIndexMarker1023"/>ReAct agents. Instead of manually orchestrating the steps, LCEL allows you to define a processing graph that handles user input, reasoning, action selection, and final response generation. This section demonstrates how to implement a ReAct agent using this powerful framework.</p>
			<p>The core idea is to establish a data pipeline that takes a user’s query, uses an LLM to reason through a series of steps, potentially leveraging external tools, and ultimately arrives at an answer. This pipeline can be succinctly expressed using LCEL.</p>
			<p>The <a id="_idIndexMarker1024"/>following <a id="_idIndexMarker1025"/>is a Python code example demonstrating this process:</p>
			<pre class="source-code">
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import chain
from langchain.agents.format_scratchpad import format_log_to_str
from langchain.agents.output_parsers import(
    ReActSingleInputOutputParser)
from langchain.tools import DuckDuckGoSearchRun
from langchain_openai import ChatOpenAI
# 1. Define Tools: In this simple example, we are using a search tool.
tools = [DuckDuckGoSearchRun()]
# 2. Construct the Prompt:  Instead of pulling from a hub, we'll define a basic prompt template.
template = """Answer the following questions as best you can. You have access to the following tools:
{tool_descriptions}
Use the following format:
Question: the input question you must answer
Thought: you should always think about what to do
Action: the action to take, should be one of [{tool_names}]
Action Input: the input to the action
Observation: the result of the action
... (this Thought/Action/Action Input/Observation can repeat N times)
Thought: I now know the final answer
Final Answer: the final answer to the original input question
Begin!
Question: {input}
{agent_scratchpad}"""
prompt = ChatPromptTemplate.from_template(template)
prompt = prompt.partial(
    tool_names=", ".join([t.name for t in tools]),
    tool_descriptions="\n".join(
        [f"{t.name}: {t.description}" for t in tools]
    ),
)
# 3. Instantiate the LLM:  We use ChatOpenAI, but any LLM can be used.
llm = ChatOpenAI(temperature=0)
#  We also configure it to stop when it sees '\nObservation:'
llm_with_stop = llm.bind(stop=["\nObservation:"])
# 4. Construct the Agent Pipeline using LCEL:
agent = (
    {
        "input": lambda x: x["input"],
        "agent_scratchpad": lambda x:
            format_log_to_str(x["intermediate_steps"]),
    }
    | prompt
    | llm_with_stop
    | ReActSingleInputOutputParser()
)</pre>			<p>Let’s <a id="_idIndexMarker1026"/>take a closer <a id="_idIndexMarker1027"/>look at this setup:</p>
			<ol>
				<li>A custom prompt template is defined to guide the LLM’s reasoning and action selection, instead of one being fetched from a hub. This template instructs the LLM on the expected format of the interaction (<em class="italic">Question</em>, <em class="italic">Thought</em>, <em class="italic">Action</em>, <em class="italic">Observation</em>, <em class="italic">Final Answer</em>).</li>
				<li>ChatOpenAI serves as the LLM, configured to halt generation upon encountering the <code>\nObservation:</code> string. This signal indicates that the agent has completed an action and is awaiting the result.</li>
				<li>The agent <a id="_idIndexMarker1028"/>pipeline is constructed via LCEL, which is the chaining operation (<code>|</code>). This <a id="_idIndexMarker1029"/>pipeline orchestrates the flow of information:<ul><li>It formats the input and agent’s scratchpad (previous reasoning steps)</li><li>It feeds the formatted input to the prompt</li><li>The LLM, with its configured stopping criteria, processes the prompt</li><li>Finally, <code>ReActSingleInputOutputParser</code> parses the LLM’s output, distinguishing between actions to be taken and the final answer</li></ul></li>
			</ol>
			<h2 id="_idParaDest-263"><a id="_idTextAnchor332"/>Explaining ReActSingleInputOutputParser</h2>
			<p>This component <a id="_idIndexMarker1030"/>is key for interpreting the LLM’s output and determining the next step in the ReAct loop:</p>
			<ul>
				<li><strong class="bold">Instantiation</strong>: You create an instance of the parser, ready to process LLM-generated text</li>
				<li><code>AgentAction</code> object (requesting the execution of a tool) or an <code>AgentFinish</code> object (providing the final answer)<ul><li>If it detects <code>AgentAction</code>, it extracts the tool’s name and the input to be passed to the tool</li><li>If it finds <code>AgentFinish</code>, it extracts the final answer</li></ul></li>
				<li><code>AgentAction</code> or <code>AgentFinish</code></li>
				<li><code>Action:</code> or <code>Final Answer:</code>), the parser raises an exception, indicating a problem with the LLM’s reasoning or the prompt</li>
			</ul>
			<h2 id="_idParaDest-264"><a id="_idTextAnchor333"/>Running the agent with AgentExecutor</h2>
			<p>In the following code, <code>AgentExecutor</code> is a <a id="_idIndexMarker1032"/>component responsible <a id="_idIndexMarker1033"/>for managing the execution <a id="_idIndexMarker1034"/>of an agent’s actions, which are chosen based on the agent’s decision-making process. It acts as a driver for the agent, facilitating the interaction between the agent and external tools.</p>
			<p>Here’s an example:</p>
			<pre class="source-code">
from langchain.agents import AgentExecutor
agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)
response = agent_executor.invoke(
    {
        "input": "Who is the current CEO of Microsoft and what is their age squared?"
    }
)
print(response)</pre>			<p>Here, the following occurs:</p>
			<ol>
				<li>We create an <code>AgentExecutor</code> instance, providing it with the agent pipeline we defined earlier and the available tools, before setting <code>verbose=True</code> to see the agent’s thought process.</li>
				<li>The <code>agent_executor.invoke</code> method starts the process. It takes a dictionary containing the user’s input (<code>"input": "Who is the current CEO of Microsoft and what is their </code><code>age squared?"</code>).</li>
				<li>Then, <code>AgentExecutor</code> manages the ReAct loop:<ol><li class="upper-roman">It feeds <a id="_idIndexMarker1035"/>the input to the agent pipeline.</li><li class="upper-roman">The <a id="_idIndexMarker1036"/>agent (LLM and parser) decides on an action (for example, using a search tool to find the CEO’s name).</li><li class="upper-roman">The <code>AgentExecutor</code> executes the action (calls the search tool).</li><li class="upper-roman">It passes the result back to the agent as an “<code>Observation</code>.”</li><li class="upper-roman">This process repeats until the agent decides it has enough information to produce a final answer.</li></ol></li>
			</ol>
			<p>This example demonstrates the basic structure of a ReAct agent built with LCEL. It showcases how you can define a clear, modular pipeline for complex reasoning tasks by combining prompts, language models, parsers, and external tools. This approach promotes code readability, maintainability, and flexibility in designing intelligent agents. This particular example asks who the current CEO of Microsoft is and then what their age is squared, demonstrating simple multi-turn reasoning from name recall to arithmetic calculation.</p>
			<h1 id="_idParaDest-265"><a id="_idTextAnchor334"/>Completing tasks and solving problems</h1>
			<p>The <a id="_idIndexMarker1037"/>ReAct framework, with its ability to integrate reasoning and acting, is highly applicable in various task completion and problem-solving scenarios:</p>
			<ul>
				<li><strong class="bold">Question-Answering (QA) with external knowledge</strong>: ReAct can be used to create QA systems that can access and reason about external knowledge sources, such as Wikipedia or a search engine, to provide more accurate and up-to-date answers</li>
				<li><strong class="bold">Web navigation and interaction</strong>: ReAct agents can navigate websites, interact with web elements, and gather information, enabling tasks such as automated web research, data scraping, and online shopping assistance</li>
				<li><strong class="bold">Software application control</strong>: By integrating with APIs and tools, ReAct agents <a id="_idIndexMarker1038"/>can control software applications, automate workflows, and perform complex tasks that require interacting with multiple systems</li>
				<li><strong class="bold">Robotics and physical world interaction</strong>: While LLMs primarily operate in the textual domain, ReAct principles can be extended to controlling robots or other physical systems, where actions involve physical movements or interactions with the real world</li>
				<li><strong class="bold">Multi-step problem solving</strong>: ReAct is well-suited for tasks that require breaking down a complex problem into smaller steps, reasoning about each step, taking actions, and using the observations to inform subsequent steps</li>
			</ul>
			<h1 id="_idParaDest-266"><a id="_idTextAnchor335"/>Evaluating ReAct’s performance</h1>
			<p>Evaluating <a id="_idIndexMarker1039"/>ReAct agents involves assessing both the quality of the reasoning and the effectiveness of the actions taken. The following metrics can be used:</p>
			<ul>
				<li><strong class="bold">Success rate</strong>: The percentage of tasks successfully completed by the agent</li>
				<li><strong class="bold">Efficiency</strong>: The number of steps or the amount of time taken to complete a task</li>
				<li><strong class="bold">Reasoning accuracy</strong>: The correctness and relevance of the LLM’s reasoning traces</li>
				<li><strong class="bold">Action relevance</strong>: The appropriateness of the actions chosen by the agent</li>
				<li><strong class="bold">Observation utilization</strong>: How effectively the agent incorporates observations into its subsequent reasoning and actions</li>
				<li><strong class="bold">Error analysis</strong>: Identifying common failure modes or weaknesses in the agent’s performance</li>
			</ul>
			<p>Let’s <a id="_idIndexMarker1040"/>consider some evaluation techniques that can be used:</p>
			<ul>
				<li><strong class="bold">Human evaluation</strong>: Having human experts evaluate the agent’s reasoning, actions, and final outputs</li>
				<li><strong class="bold">Automated metrics</strong>: Using automated scripts or LLMs to assess specific aspects of the agent’s performance, such as the correctness of answers or the relevance of actions</li>
				<li><strong class="bold">Benchmarking</strong>: Comparing the agent’s performance against predefined benchmarks or other agents on standardized tasks</li>
				<li><strong class="bold">Ablation studies</strong>: Systematically removing or modifying components of the ReAct framework (for example, removing the reasoning steps) to understand their contribution to overall performance</li>
			</ul>
			<h1 id="_idParaDest-267"><a id="_idTextAnchor336"/>Safety, control, and ethical considerations</h1>
			<p>ReAct <a id="_idIndexMarker1041"/>systems, especially when integrated with external tools, raise several safety, control, and ethical concerns:</p>
			<ul>
				<li><strong class="bold">Unpredictable behavior</strong>: The combination of LLM reasoning and external tool use can lead to unpredictable or unintended behavior</li>
				<li><strong class="bold">Safety of actions</strong>: Actions taken by the agent may have real-world consequences, especially if the agent is connected to systems that can affect the physical world</li>
				<li><strong class="bold">Bias and fairness</strong>: ReAct agents may inherit and amplify biases present in the training data of the LLM or the external tools they use</li>
				<li><strong class="bold">Misuse potential</strong>: Malicious actors could potentially use ReAct agents for harmful purposes, such as generating misinformation or automating attacks</li>
				<li><strong class="bold">Accountability</strong>: Determining responsibility for the actions and decisions of a ReAct agent can be challenging due to the non-deterministic nature of the underlying LLM models</li>
			</ul>
			<p>The following <a id="_idIndexMarker1042"/>are some mitigation strategies for these issues:</p>
			<ul>
				<li><strong class="bold">Sandboxing</strong>: Running ReAct agents in isolated environments to limit their potential impact</li>
				<li><strong class="bold">Human oversight</strong>: Incorporating human review and approval into the ReAct process, especially for critical decisions or actions</li>
				<li><strong class="bold">Safety rules and constraints</strong>: Implementing rules and constraints to prevent the agent from taking harmful or unethical actions</li>
				<li><strong class="bold">Monitoring and auditing</strong>: Continuously monitoring the agent’s behavior and maintaining logs for auditing purposes</li>
				<li><strong class="bold">Transparency and explainability</strong>: Designing ReAct agents that can explain their reasoning and decision-making process to improve understanding and trust</li>
			</ul>
			<h1 id="_idParaDest-268"><a id="_idTextAnchor337"/>Limitations and future directions</h1>
			<p>While <a id="_idIndexMarker1043"/>ReAct is a powerful framework, it has certain limitations:</p>
			<ul>
				<li><strong class="bold">Dependency on external tools</strong>: ReAct’s effectiveness is partly dependent on the capabilities and reliability of the external tools it uses</li>
				<li><strong class="bold">Error propagation</strong>: Errors in tool use or interpretation of observations can propagate through the reasoning process, leading to incorrect conclusions or actions</li>
				<li><strong class="bold">Token limitations</strong>: The iterative nature of ReAct can lead to long sequences of text, potentially exceeding the token limits of some LLMs</li>
				<li><strong class="bold">Computational cost</strong>: Multiple rounds of reasoning, action, and observation can be <a id="_idIndexMarker1044"/>computationally expensive, especially when using LLMs or complex tools</li>
				<li><strong class="bold">Prompt engineering challenges</strong>: Designing effective ReAct prompts that properly guide the LLM’s reasoning and action selection can be challenging and may require experimentation</li>
			</ul>
			<p><em class="italic">Figure 22</em><em class="italic">.1</em> shows the limitations of ReAct pattern:</p>
			<div><div><img src="img/B31249_22_01.jpg" alt="Figure 22.1 – Limitations of the ReAct pattern" width="1343" height="672"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 22.1 – Limitations of the ReAct pattern</p>
			<p>However, by combining the power of LLMs with the ability to take actions and incorporate external information, ReAct provides new possibilities for creating more capable and versatile AI systems:</p>
			<ul>
				<li><strong class="bold">Improved tool integration</strong>: Developing more seamless and robust methods for integrating LLMs with external tools</li>
				<li><strong class="bold">Enhanced reasoning capabilities</strong>: Combining ReAct with other advanced reasoning techniques, such as ToT, to handle more complex scenarios</li>
				<li><strong class="bold">Learning from experience</strong>: Enabling ReAct agents to learn from their past interactions <a id="_idIndexMarker1045"/>and improve their performance over time</li>
				<li><strong class="bold">Multi-agent ReAct</strong>: Exploring scenarios where multiple ReAct agents collaborate or compete to solve problems</li>
				<li><strong class="bold">Real-world deployment</strong>: Moving beyond simulated environments and deploying ReAct agents in real-world applications with the appropriate safety and control mechanisms</li>
			</ul>
			<h1 id="_idParaDest-269"><a id="_idTextAnchor338"/>Summary</h1>
			<p>In this chapter, you learned about the ReAct framework, a powerful technique for prompting your LLMs to not only reason through complex scenarios but also plan and simulate the execution of actions, similar to how humans operate in the real world.</p>
			<p>The ReAct framework represents a significant advancement in the development of intelligent agents that can reason, plan, and interact with their environment. ReAct can also be considered a precursor to more advanced frameworks such as <strong class="bold">Reasoning WithOut Observation</strong> (<strong class="bold">ReWOO</strong>), something we’ll explore in the next chapter.</p>
		</div>
	</div></div></body></html>