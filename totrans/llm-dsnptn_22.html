<html><head></head><body><div id="book-content"><div id="sbo-rt-content"><div id="_idContainer046">
			<h1 id="_idParaDest-258" class="chapter-number"><a id="_idTextAnchor325"/>22</h1>
			<h1 id="_idParaDest-259"><a id="_idTextAnchor326"/>Reasoning and Acting</h1>
			<p><strong class="bold">Reasoning and Acting</strong> (<strong class="bold">ReAct</strong>) is a prompting technique developed by researchers from Princeton <a id="_idIndexMarker1002"/>University and Google that enhances an LLM’s ability to perform reasoning and acting in simulated environments (<a href="https://arxiv.org/pdf/2210.03629">https://arxiv.org/pdf/2210.03629</a>). It allows LLMs to mimic human-like operations in the real world, where we reason verbally and take actions to gain information. ReAct combines <em class="italic">reasoning</em> and <em class="italic">acting</em> to solve complex language reasoning and <span class="No-Break">decision-making tasks.</span></p>
			<p>While CoT prompting <a id="_idIndexMarker1003"/>enables LLMs to generate reasoning traces, its lack of access to the external world can lead to issues such as fact hallucination. ReAct addresses this by allowing LLMs to generate both <em class="italic">verbal reasoning traces</em> and <em class="italic">text actions</em> for a task. These text actions enable the model to interact with its environment (for example, by querying an external knowledge source or using a tool), gather information, and adjust its <span class="No-Break">reasoning accordingly.</span></p>
			<p>The key <a id="_idIndexMarker1004"/>characteristics of ReAct are <span class="No-Break">as follows:</span></p>
			<ul>
				<li><strong class="bold">Reasoning traces</strong>: LLMs generate text that explains their thought process step <span class="No-Break">by step</span></li>
				<li><strong class="bold">Action generation</strong>: LLMs produce text actions that represent interactions with external tools <span class="No-Break">or environments</span></li>
				<li><strong class="bold">Observation incorporation</strong>: The results of actions (observations) are fed back into the LLM’s context, influencing subsequent reasoning <span class="No-Break">and actions</span></li>
				<li><strong class="bold">Iterative process</strong>: ReAct typically involves multiple <em class="italic">Thought</em>/<em class="italic">Action</em>/<em class="italic">Observation</em> steps, allowing for dynamic <span class="No-Break">problem solving</span></li>
			</ul>
			<p>ReAct excels <a id="_idIndexMarker1005"/>in the <span class="No-Break">following scenarios:</span></p>
			<ul>
				<li>When a task requires information beyond the LLM’s pre-trained knowledge (for example, multi-hop question answering or <span class="No-Break">fact verification)</span></li>
				<li>When an LLM needs to navigate and interact with a simulated environment (for example, online shopping or <span class="No-Break">text-based games)</span></li>
				<li>When you need to combine the power of LLMs with the capabilities of external tools (for example, search engines, calculators, <span class="No-Break">and APIs)</span></li>
				<li>When the <a id="_idIndexMarker1006"/>task requires a problem to be broken down into smaller steps and decisions must be made based on <span class="No-Break">intermediate results</span></li>
			</ul>
			<p>In this chapter, we’ll be covering the <span class="No-Break">following topics:</span></p>
			<ul>
				<li>Implementing ReAct <span class="No-Break">in LangChain</span></li>
				<li>Building ReAct agents with LangChain’s <span class="No-Break">Expression Language</span></li>
				<li>Completing tasks and <span class="No-Break">solving problems</span></li>
				<li>Evaluating <span class="No-Break">ReAct’s performance</span></li>
				<li>Safety, control, and <span class="No-Break">ethical considerations</span></li>
				<li>Limitations and <span class="No-Break">future directions</span></li>
			</ul>
			<h1 id="_idParaDest-260"><a id="_idTextAnchor327"/>Implementing ReAct in LangChain</h1>
			<p>The open <a id="_idIndexMarker1007"/>source LLM framework LangChain (<a href="https://www.langchain.com/">https://www.langchain.com/</a>) provides a powerful and flexible implementation of the ReAct <a id="_idIndexMarker1008"/>framework through <a id="_idIndexMarker1009"/>its <strong class="source-inline">Agent</strong> class. Let’s explore how to create and use ReAct agents <span class="No-Break">in LangChain:</span></p>
			<ol>
				<li>Install the <span class="No-Break">necessary packages:</span><pre class="source-code">
<strong class="bold"># !pip install langchain openai duckduckgo-search youtube_search wikipedia langchainhub</strong></pre><p class="list-inset">These packages enhance language model capabilities within the <span class="No-Break">LangChain framework:</span></p><ul><li>LangChain serves as a framework for developing applications powered by language models, enabling them to connect to external data sources <span class="No-Break">and tools</span></li><li>OpenAI provides access to powerful language models through its API, forming the core of many <span class="No-Break">LangChain applications</span></li><li><strong class="source-inline">duckduckgo-search</strong> and <strong class="source-inline">youtube_search</strong> integrate search engine functionalities, allowing language models to retrieve real-time information from the web and <span class="No-Break">YouTube, respectively</span></li><li><strong class="source-inline">wikipedia</strong> enables language models to access and utilize information from Wikipedia, broadening their <span class="No-Break">knowledge base</span></li><li><strong class="source-inline">langchainhub</strong> is a central repository for sharing and discovering LangChain assets, such as prompts, chains, <span class="No-Break">and agents</span></li></ul></li>				<li>Initialize <a id="_idIndexMarker1010"/>the language <a id="_idIndexMarker1011"/>model and tools such as <strong class="source-inline">wikipedia</strong>, <strong class="source-inline">ddg-search</strong>, and <strong class="source-inline">llm-math</strong>. These are listed in the following <span class="No-Break">code snippet:</span><pre class="source-code">
import os
import getpass
os.environ["OPENAI_API_KEY"] = getpass.getpass("Enter Your OpenAI API Key:")
from langchain.agents import load_tools
from langchain.chat_models import ChatOpenAI
# load the language model, you can use any model you like
llm = ChatOpenAI(model = "gpt-4o", temperature=0)
# load tools
tools = load_tools(['wikipedia', 'ddg-search','llm-math'],
    llm=llm)</pre><p class="list-inset">Here, we import the necessary modules from <strong class="source-inline">langchain</strong>. Then, a language model (<strong class="source-inline">ChatOpenAI</strong>) is initialized with the specified model (<strong class="source-inline">gpt-4-1106-preview</strong> and <strong class="source-inline">temperature</strong>. Finally, we load some tools that our agent <span class="No-Break">will use.</span></p></li>				<li>Initialize <a id="_idIndexMarker1012"/>the ReAct <a id="_idIndexMarker1013"/>agent. Here, the <strong class="source-inline">initialize_agent</strong> function creates and initializes <span class="No-Break">an agent:</span><pre class="source-code">
from langchain.agents import initialize_agent
from langchain.agents import AgentType
# initialize agent
agent = initialize_agent(
    tools,  
    llm,  
    agent=AgentType.ZERO_SHOT_REACT_ DESCRIPTION,  
    verbose=True  
) </pre><p class="list-inset">In the preceding code, we list <strong class="source-inline">tools</strong> and <strong class="source-inline">llm</strong>, which refers to the language model, as well as specify the agent type as <strong class="source-inline">AgentType.ZERO_SHOT_REACT_DESCRIPTION</strong>. Here, <strong class="source-inline">verbose=True</strong> enables detailed logging of the agent’s <span class="No-Break">thought process.</span></p></li>				<li>Inspect the ReAct agent’s prompt. The following line prints the prompt template used by the ReAct agent. This prompt provides instructions to the LLM on how to use the available tools and follow the ReAct format (<em class="italic">Thought</em>, <em class="italic">Action</em>, <em class="italic">Action Input</em>, <span class="No-Break">and </span><span class="No-Break"><em class="italic">Observation</em></span><span class="No-Break">):</span><pre class="source-code">
print(agent.agent.llm_chain.prompt.template)</pre><p class="list-inset">Inspecting the ReAct agent’s prompt is important because it reveals the structure and logic that guide the behavior of the language model during tool-augmented reasoning and action. By printing the prompt template with <strong class="source-inline">print(agent.agent.llm_chain.prompt.template)</strong>, you’re not just seeing arbitrary instructions – you’re inspecting the behavioral scaffold that governs how the agent sequences its reasoning and tool use. This includes how it interprets <a id="_idIndexMarker1014"/>a user <a id="_idIndexMarker1015"/>query, chooses a tool from its available action set, constructs the input to the tool, and integrates the tool’s output (Observation) into further reasoning. If the prompt is poorly constructed, the model may misinterpret the tools, take invalid actions, or fail to chain thoughts coherently. Additionally, the template often includes few-shot examples that demonstrate how to alternate between the ReAct components properly. These examples act as implicit instructions for formatting and logic, helping the model generalize to unseen tasks. Inspecting them can reveal whether the agent was trained or instructed using general patterns or highly specific use cases. It also helps developers debug unexpected behavior or hallucinations since modifying the template directly influences the agent’s action selection, reasoning fidelity, and overall alignment with the intended <span class="No-Break">ReAct cycle.</span></p></li>				<li>The following code block demonstrates how to customize the prompt template. You can modify the instructions, examples, and formatting to better suit your specific <span class="No-Break">use case:</span><pre class="source-code">
prompt = """
You are an intelligent agent designed to solve complex queries by breaking them down systematically and using available tools strategically. Follow the ReAct (Reasoning and Acting) framework to approach each task.
ReAct Principles:
1. Reasoning: Always start by carefully analyzing the question and developing a clear, step-by-step thought process.
2. Tool Selection: Critically evaluate which tools will be most effective for addressing the specific query.
3. Iterative Interaction: Be prepared to cycle between reasoning and action multiple times, refining your approach as you gather more information.
4. Comprehensive Understanding: Aim to not just find an answer, but to truly comprehend the underlying context and nuances of the question.
5. Transparent Decision-Making: Clearly articulate your reasoning, actions, and thought process at each step.
Available Tools:
- Wikipedia: Retrieve factual information about people, places, historical events, and general knowledge topics.
- Google Search: Fetch current information, recent events, and up-to-date context.
- Calculator: Perform mathematical calculations and numerical analysis.
Interaction Format:
Question: The specific query to be solved
Thought: Detailed reasoning about the approach, breaking down the problem
Action: Selected tool (Wikipedia/Google Search/Calculator)
Action Input: Precise query for the selected tool
Observation: Results obtained from the tool
... (Repeat reasoning, action, and observation as needed)
Thought: Final synthesized understanding
Final Answer: Comprehensive and well-reasoned response to the original question
Important Guidelines:
- Be methodical and explicit in your reasoning
- Use tools judiciously and avoid unnecessary actions
- Integrate information from multiple sources when appropriate
- Provide a clear, concise, and informative final answer
Begin!
Question: {input}
Thought:{agent_scratchpad}
"""</pre><p class="list-inset">Here, <strong class="source-inline">agent.agent.llm_chain.prompt.template = prompt</strong> updates the agent’s prompt with the <span class="No-Break">custom template.</span></p></li>				<li>Next, you <a id="_idIndexMarker1016"/>can modify <a id="_idIndexMarker1017"/>the descriptions of the tools to provide more specific guidance to the LLM on when and how to use <span class="No-Break">each tool:</span><pre class="source-code">
tools[1].description = "A date retrieval tool that provides the current date and time, useful for temporal queries, scheduling, age calculations, or understanding time-sensitive contexts."
tools[2].description = "A powerful computational tool capable of performing various mathematical operations, including arithmetic calculations, algebraic computations, percentage calculations, unit conversions, and advanced mathematical functions."</pre></li>				<li>The following line executes the agent with a sample query. The agent will use the ReAct framework to perform reasoning, select tools, execute actions, and generate a <span class="No-Break">final answer:</span><pre class="source-code">
agent.run("What is the population of the largest city in Canada? How many days would it take for that city's population to count to 1 billion if each person counts one number per second without breaks? Then, compare this time to the average lifespan of a human in years, and explain which is longer.")</pre></li>			</ol>
			<p>Next, we’ll look at an example of using ReAct for document processing that <span class="No-Break">levera<a id="_idTextAnchor328"/>ges LangChain.</span></p>
			<h2 id="_idParaDest-261"><a id="_idTextAnchor329"/>ReAct Document Store</h2>
			<p>LangChain <a id="_idIndexMarker1018"/>also provides a <strong class="source-inline">DocstoreExplorer</strong> class for implementing ReAct logic with document stores such as Wikipedia. We’ll demonstrate an example by using <strong class="source-inline">DocstoreExplorer</strong> with Wikipedia <a id="_idIndexMarker1019"/>for <span class="No-Break">document-based ReAct:</span></p>
			<pre class="source-code">
from langchain import Wikipedia
from langchain.agents import initialize_agent, Tool
from langchain.agents import AgentType
from langchain.agents.react.base import DocstoreExplorer
docstore = DocstoreExplorer(Wikipedia())
search_tool = Tool(name="Search",
                   func=docstore.search,
                   description="Search for latest information about any topic"
                   )
lookup_tool = Tool(name="Lookup",
                   func=docstore.lookup,
                   description="Lookup tool for get information from a keyword"
                   )
tools = [search_tool, lookup_tool]
llm = OpenAI(temperature=0)
react = initialize_agent(tools,
                         llm,
                         agent=AgentType.REACT_DOCSTORE,
                         verbose=True)
question = "Who is the current governor of Texas and when was he born ?"
react.run(question)</pre>			<p>This code <a id="_idIndexMarker1020"/>sets up a LangChain agent designed to answer questions by interacting with Wikipedia. Here’s <span class="No-Break">a breakdown:</span></p>
			<ol>
				<li><strong class="bold">Wikipedia access</strong>: First, it initializes a connection to Wikipedia, allowing the agent to retrieve information <span class="No-Break">from it.</span></li>
				<li><strong class="bold">Tool creation</strong>: Next, it defines two tools: <strong class="source-inline">Search</strong> and <strong class="source-inline">Lookup</strong>. The <strong class="source-inline">Search</strong> tool enables the agent to find relevant Wikipedia pages, whereas the <strong class="source-inline">Lookup</strong> tool lets it extract specific information from <span class="No-Break">those pages.</span></li>
				<li><strong class="bold">Agent initialization</strong>: Then, it creates a ReAct agent. This agent is configured to use the previously defined tools and an OpenAI language model. In the preceding code, <strong class="source-inline">AgentType.REACT_DOCSTORE</strong> explicitly configures the agent for document store interactions – in this case, those <span class="No-Break">for Wikipedia.</span></li>
				<li><strong class="bold">Question execution</strong>: Finally, it runs the agent with a question that requires accessing and processing information from Wikipedia. The agent will use the <strong class="source-inline">Search</strong> tool to find relevant pages and the <strong class="source-inline">Lookup</strong> tool to e<a id="_idTextAnchor330"/>xtract <span class="No-Break">the answer.</span></li>
			</ol>
			<h1 id="_idParaDest-262"><a id="_idTextAnchor331"/>Building ReAct agents with LangChain’s Expression Language</h1>
			<p><strong class="bold">LangChain Expression Language</strong> (<strong class="bold">LCEL</strong>) offers <a id="_idIndexMarker1021"/>a declarative <a id="_idIndexMarker1022"/>approach to constructing <a id="_idIndexMarker1023"/>ReAct agents. Instead of manually orchestrating the steps, LCEL allows you to define a processing graph that handles user input, reasoning, action selection, and final response generation. This section demonstrates how to implement a ReAct agent using this <span class="No-Break">powerful framework.</span></p>
			<p>The core idea is to establish a data pipeline that takes a user’s query, uses an LLM to reason through a series of steps, potentially leveraging external tools, and ultimately arrives at an answer. This pipeline can be succinctly expressed <span class="No-Break">using LCEL.</span></p>
			<p>The <a id="_idIndexMarker1024"/>following <a id="_idIndexMarker1025"/>is a Python code example demonstrating <span class="No-Break">this process:</span></p>
			<pre class="source-code">
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import chain
from langchain.agents.format_scratchpad import format_log_to_str
from langchain.agents.output_parsers import(
    ReActSingleInputOutputParser)
from langchain.tools import DuckDuckGoSearchRun
from langchain_openai import ChatOpenAI
# 1. Define Tools: In this simple example, we are using a search tool.
tools = [DuckDuckGoSearchRun()]
# 2. Construct the Prompt:  Instead of pulling from a hub, we'll define a basic prompt template.
template = """Answer the following questions as best you can. You have access to the following tools:
{tool_descriptions}
Use the following format:
Question: the input question you must answer
Thought: you should always think about what to do
Action: the action to take, should be one of [{tool_names}]
Action Input: the input to the action
Observation: the result of the action
... (this Thought/Action/Action Input/Observation can repeat N times)
Thought: I now know the final answer
Final Answer: the final answer to the original input question
Begin!
Question: {input}
{agent_scratchpad}"""
prompt = ChatPromptTemplate.from_template(template)
prompt = prompt.partial(
    tool_names=", ".join([t.name for t in tools]),
    tool_descriptions="\n".join(
        [f"{t.name}: {t.description}" for t in tools]
    ),
)
# 3. Instantiate the LLM:  We use ChatOpenAI, but any LLM can be used.
llm = ChatOpenAI(temperature=0)
#  We also configure it to stop when it sees '\nObservation:'
llm_with_stop = llm.bind(stop=["\nObservation:"])
# 4. Construct the Agent Pipeline using LCEL:
agent = (
    {
        "input": lambda x: x["input"],
        "agent_scratchpad": lambda x:
            format_log_to_str(x["intermediate_steps"]),
    }
    | prompt
    | llm_with_stop
    | ReActSingleInputOutputParser()
)</pre>			<p>Let’s <a id="_idIndexMarker1026"/>take a closer <a id="_idIndexMarker1027"/>look at <span class="No-Break">this setup:</span></p>
			<ol>
				<li>A custom prompt template is defined to guide the LLM’s reasoning and action selection, instead of one being fetched from a hub. This template instructs the LLM on the expected format of the interaction (<em class="italic">Question</em>, <em class="italic">Thought</em>, <em class="italic">Action</em>, <em class="italic">Observation</em>, <span class="No-Break"><em class="italic">Final Answer</em></span><span class="No-Break">).</span></li>
				<li>ChatOpenAI serves as the LLM, configured to halt generation upon encountering the <strong class="source-inline">\nObservation:</strong> string. This signal indicates that the agent has completed an action and is awaiting <span class="No-Break">the result.</span></li>
				<li>The agent <a id="_idIndexMarker1028"/>pipeline is constructed via LCEL, which is the chaining operation (<strong class="source-inline">|</strong>). This <a id="_idIndexMarker1029"/>pipeline orchestrates the flow <span class="No-Break">of information:</span><ul><li>It formats the input and agent’s scratchpad (previous <span class="No-Break">reasoning steps)</span></li><li>It feeds the formatted input to <span class="No-Break">the prompt</span></li><li>The LLM, with its configured stopping criteria, processes <span class="No-Break">the prompt</span></li><li>Finally, <strong class="source-inline">ReActSingleInputOutputParser</strong> parses the LLM’s output, distinguishing between actions to be taken and the <span class="No-Break">final answer</span></li></ul></li>
			</ol>
			<h2 id="_idParaDest-263"><a id="_idTextAnchor332"/>Explaining ReActSingleInputOutputParser</h2>
			<p>This component <a id="_idIndexMarker1030"/>is key for interpreting the LLM’s output and determining the next step in the <span class="No-Break">ReAct loop:</span></p>
			<ul>
				<li><strong class="bold">Instantiation</strong>: You create an instance of the parser, ready to process <span class="No-Break">LLM-generated text</span></li>
				<li><strong class="bold">Functionality</strong>: It examines the LLM’s output for patterns that indicate either an <strong class="source-inline">AgentAction</strong> object (requesting the execution of a tool) or an <strong class="source-inline">AgentFinish</strong> object (providing the <span class="No-Break">final answer)</span><ul><li>If it detects <strong class="source-inline">AgentAction</strong>, it extracts the tool’s name and the input to be passed to <span class="No-Break">the tool</span></li><li>If it finds <strong class="source-inline">AgentFinish</strong>, it extracts the <span class="No-Break">final answer</span></li></ul></li>
				<li><strong class="bold">Usage</strong>: The parser receives the raw text output from the LLM and returns either <strong class="source-inline">AgentAction</strong> <span class="No-Break">or </span><span class="No-Break"><strong class="source-inline">AgentFinish</strong></span></li>
				<li><strong class="bold">Error handling</strong>: If the <a id="_idIndexMarker1031"/>LLM’s output doesn’t conform to the expected ReAct format (for example, it’s missing <strong class="source-inline">Action:</strong> or <strong class="source-inline">Final Answer:</strong>), the parser raises an exception, indicating a problem with the LLM’s reasoning or <span class="No-Break">the prompt</span></li>
			</ul>
			<h2 id="_idParaDest-264"><a id="_idTextAnchor333"/>Running the agent with AgentExecutor</h2>
			<p>In the following code, <strong class="source-inline">AgentExecutor</strong> is a <a id="_idIndexMarker1032"/>component responsible <a id="_idIndexMarker1033"/>for managing the execution <a id="_idIndexMarker1034"/>of an agent’s actions, which are chosen based on the agent’s decision-making process. It acts as a driver for the agent, facilitating the interaction between the agent and <span class="No-Break">external tools.</span></p>
			<p>Here’s <span class="No-Break">an example:</span></p>
			<pre class="source-code">
from langchain.agents import AgentExecutor
agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)
response = agent_executor.invoke(
    {
        "input": "Who is the current CEO of Microsoft and what is their age squared?"
    }
)
print(response)</pre>			<p>Here, the <span class="No-Break">following occurs:</span></p>
			<ol>
				<li>We create an <strong class="source-inline">AgentExecutor</strong> instance, providing it with the agent pipeline we defined earlier and the available tools, before setting <strong class="source-inline">verbose=True</strong> to see the agent’s <span class="No-Break">thought process.</span></li>
				<li>The <strong class="source-inline">agent_executor.invoke</strong> method starts the process. It takes a dictionary containing the user’s input (<strong class="source-inline">"input": "Who is the current CEO of Microsoft and what is their </strong><span class="No-Break"><strong class="source-inline">age squared?"</strong></span><span class="No-Break">).</span></li>
				<li>Then, <strong class="source-inline">AgentExecutor</strong> manages the <span class="No-Break">ReAct loop:</span><ol><li class="upper-roman">It feeds <a id="_idIndexMarker1035"/>the input to the <span class="No-Break">agent pipeline.</span></li><li class="upper-roman">The <a id="_idIndexMarker1036"/>agent (LLM and parser) decides on an action (for example, using a search tool to find the <span class="No-Break">CEO’s name).</span></li><li class="upper-roman">The <strong class="source-inline">AgentExecutor</strong> executes the action (calls the <span class="No-Break">search tool).</span></li><li class="upper-roman">It passes the result back to the agent as <span class="No-Break">an “</span><span class="No-Break"><strong class="source-inline">Observation</strong></span><span class="No-Break">.”</span></li><li class="upper-roman">This process repeats until the agent decides it has enough information to produce a <span class="No-Break">final answer.</span></li></ol></li>
			</ol>
			<p>This example demonstrates the basic structure of a ReAct agent built with LCEL. It showcases how you can define a clear, modular pipeline for complex reasoning tasks by combining prompts, language models, parsers, and external tools. This approach promotes code readability, maintainability, and flexibility in designing intelligent agents. This particular example asks who the current CEO of Microsoft is and then what their age is squared, demonstrating simple multi-turn reasoning from name recall to <span class="No-Break">arithmetic calculation.</span></p>
			<h1 id="_idParaDest-265"><a id="_idTextAnchor334"/>Completing tasks and solving problems</h1>
			<p>The <a id="_idIndexMarker1037"/>ReAct framework, with its ability to integrate reasoning and acting, is highly applicable in various task completion and <span class="No-Break">problem-solving scenarios:</span></p>
			<ul>
				<li><strong class="bold">Question-Answering (QA) with external knowledge</strong>: ReAct can be used to create QA systems that can access and reason about external knowledge sources, such as Wikipedia or a search engine, to provide more accurate and <span class="No-Break">up-to-date answers</span></li>
				<li><strong class="bold">Web navigation and interaction</strong>: ReAct agents can navigate websites, interact with web elements, and gather information, enabling tasks such as automated web research, data scraping, and online <span class="No-Break">shopping assistance</span></li>
				<li><strong class="bold">Software application control</strong>: By integrating with APIs and tools, ReAct agents <a id="_idIndexMarker1038"/>can control software applications, automate workflows, and perform complex tasks that require interacting with <span class="No-Break">multiple systems</span></li>
				<li><strong class="bold">Robotics and physical world interaction</strong>: While LLMs primarily operate in the textual domain, ReAct principles can be extended to controlling robots or other physical systems, where actions involve physical movements or interactions with the <span class="No-Break">real world</span></li>
				<li><strong class="bold">Multi-step problem solving</strong>: ReAct is well-suited for tasks that require breaking down a complex problem into smaller steps, reasoning about each step, taking actions, and using the observations to inform <span class="No-Break">subsequent steps</span></li>
			</ul>
			<h1 id="_idParaDest-266"><a id="_idTextAnchor335"/>Evaluating ReAct’s performance</h1>
			<p>Evaluating <a id="_idIndexMarker1039"/>ReAct agents involves assessing both the quality of the reasoning and the effectiveness of the actions taken. The following metrics can <span class="No-Break">be used:</span></p>
			<ul>
				<li><strong class="bold">Success rate</strong>: The percentage of tasks successfully completed by <span class="No-Break">the agent</span></li>
				<li><strong class="bold">Efficiency</strong>: The number of steps or the amount of time taken to complete <span class="No-Break">a task</span></li>
				<li><strong class="bold">Reasoning accuracy</strong>: The correctness and relevance of the LLM’s <span class="No-Break">reasoning traces</span></li>
				<li><strong class="bold">Action relevance</strong>: The appropriateness of the actions chosen by <span class="No-Break">the agent</span></li>
				<li><strong class="bold">Observation utilization</strong>: How effectively the agent incorporates observations into its subsequent reasoning <span class="No-Break">and actions</span></li>
				<li><strong class="bold">Error analysis</strong>: Identifying common failure modes or weaknesses in the <span class="No-Break">agent’s performance</span></li>
			</ul>
			<p>Let’s <a id="_idIndexMarker1040"/>consider some evaluation techniques that can <span class="No-Break">be used:</span></p>
			<ul>
				<li><strong class="bold">Human evaluation</strong>: Having human experts evaluate the agent’s reasoning, actions, and <span class="No-Break">final outputs</span></li>
				<li><strong class="bold">Automated metrics</strong>: Using automated scripts or LLMs to assess specific aspects of the agent’s performance, such as the correctness of answers or the relevance <span class="No-Break">of actions</span></li>
				<li><strong class="bold">Benchmarking</strong>: Comparing the agent’s performance against predefined benchmarks or other agents on <span class="No-Break">standardized tasks</span></li>
				<li><strong class="bold">Ablation studies</strong>: Systematically removing or modifying components of the ReAct framework (for example, removing the reasoning steps) to understand their contribution to <span class="No-Break">overall performance</span></li>
			</ul>
			<h1 id="_idParaDest-267"><a id="_idTextAnchor336"/>Safety, control, and ethical considerations</h1>
			<p>ReAct <a id="_idIndexMarker1041"/>systems, especially when integrated with external tools, raise several safety, control, and <span class="No-Break">ethical concerns:</span></p>
			<ul>
				<li><strong class="bold">Unpredictable behavior</strong>: The combination of LLM reasoning and external tool use can lead to unpredictable or <span class="No-Break">unintended behavior</span></li>
				<li><strong class="bold">Safety of actions</strong>: Actions taken by the agent may have real-world consequences, especially if the agent is connected to systems that can affect the <span class="No-Break">physical world</span></li>
				<li><strong class="bold">Bias and fairness</strong>: ReAct agents may inherit and amplify biases present in the training data of the LLM or the external tools <span class="No-Break">they use</span></li>
				<li><strong class="bold">Misuse potential</strong>: Malicious actors could potentially use ReAct agents for harmful purposes, such as generating misinformation or <span class="No-Break">automating attacks</span></li>
				<li><strong class="bold">Accountability</strong>: Determining responsibility for the actions and decisions of a ReAct agent can be challenging due to the non-deterministic nature of the underlying <span class="No-Break">LLM models</span></li>
			</ul>
			<p>The following <a id="_idIndexMarker1042"/>are some mitigation strategies for <span class="No-Break">these issues:</span></p>
			<ul>
				<li><strong class="bold">Sandboxing</strong>: Running ReAct agents in isolated environments to limit their <span class="No-Break">potential impact</span></li>
				<li><strong class="bold">Human oversight</strong>: Incorporating human review and approval into the ReAct process, especially for critical decisions <span class="No-Break">or actions</span></li>
				<li><strong class="bold">Safety rules and constraints</strong>: Implementing rules and constraints to prevent the agent from taking harmful or <span class="No-Break">unethical actions</span></li>
				<li><strong class="bold">Monitoring and auditing</strong>: Continuously monitoring the agent’s behavior and maintaining logs for <span class="No-Break">auditing purposes</span></li>
				<li><strong class="bold">Transparency and explainability</strong>: Designing ReAct agents that can explain their reasoning and decision-making process to improve understanding <span class="No-Break">and trust</span></li>
			</ul>
			<h1 id="_idParaDest-268"><a id="_idTextAnchor337"/>Limitations and future directions</h1>
			<p>While <a id="_idIndexMarker1043"/>ReAct is a powerful framework, it has <span class="No-Break">certain limitations:</span></p>
			<ul>
				<li><strong class="bold">Dependency on external tools</strong>: ReAct’s effectiveness is partly dependent on the capabilities and reliability of the external tools <span class="No-Break">it uses</span></li>
				<li><strong class="bold">Error propagation</strong>: Errors in tool use or interpretation of observations can propagate through the reasoning process, leading to incorrect conclusions <span class="No-Break">or actions</span></li>
				<li><strong class="bold">Token limitations</strong>: The iterative nature of ReAct can lead to long sequences of text, potentially exceeding the token limits of <span class="No-Break">some LLMs</span></li>
				<li><strong class="bold">Computational cost</strong>: Multiple rounds of reasoning, action, and observation can be <a id="_idIndexMarker1044"/>computationally expensive, especially when using LLMs or <span class="No-Break">complex tools</span></li>
				<li><strong class="bold">Prompt engineering challenges</strong>: Designing effective ReAct prompts that properly guide the LLM’s reasoning and action selection can be challenging and may <span class="No-Break">require experimentation</span></li>
			</ul>
			<p><span class="No-Break"><em class="italic">Figure 22</em></span><em class="italic">.1</em> shows the limitations of <span class="No-Break">ReAct pattern:</span></p>
			<div>
				<div id="_idContainer045" class="IMG---Figure">
					<img src="image/B31249_22_01.jpg" alt="Figure 22.1 – Limitations of the ReAct pattern" width="1343" height="672"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 22.1 – Limitations of the ReAct pattern</p>
			<p>However, by combining the power of LLMs with the ability to take actions and incorporate external information, ReAct provides new possibilities for creating more capable and versatile <span class="No-Break">AI systems:</span></p>
			<ul>
				<li><strong class="bold">Improved tool integration</strong>: Developing more seamless and robust methods for integrating LLMs with <span class="No-Break">external tools</span></li>
				<li><strong class="bold">Enhanced reasoning capabilities</strong>: Combining ReAct with other advanced reasoning techniques, such as ToT, to handle more <span class="No-Break">complex scenarios</span></li>
				<li><strong class="bold">Learning from experience</strong>: Enabling ReAct agents to learn from their past interactions <a id="_idIndexMarker1045"/>and improve their performance <span class="No-Break">over time</span></li>
				<li><strong class="bold">Multi-agent ReAct</strong>: Exploring scenarios where multiple ReAct agents collaborate or compete to <span class="No-Break">solve problems</span></li>
				<li><strong class="bold">Real-world deployment</strong>: Moving beyond simulated environments and deploying ReAct agents in real-world applications with the appropriate safety and <span class="No-Break">control mechanisms</span></li>
			</ul>
			<h1 id="_idParaDest-269"><a id="_idTextAnchor338"/>Summary</h1>
			<p>In this chapter, you learned about the ReAct framework, a powerful technique for prompting your LLMs to not only reason through complex scenarios but also plan and simulate the execution of actions, similar to how humans operate in the <span class="No-Break">real world.</span></p>
			<p>The ReAct framework represents a significant advancement in the development of intelligent agents that can reason, plan, and interact with their environment. ReAct can also be considered a precursor to more advanced frameworks such as <strong class="bold">Reasoning WithOut Observation</strong> (<strong class="bold">ReWOO</strong>), something we’ll explore in the <span class="No-Break">next chapter.</span></p>
		</div>
	</div></div></body></html>