- en: '11'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Common Failures of Generative AI
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you have just built your **generative AI** (**GenAI**) application, then
    you may be so fascinated by what it can do that you lose sight of answer quality
    and accuracy. Discovering how often GenAI is incorrect is a challenge in itself.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Many tend to believe that when a computer gives an answer, it gives an accurate
    answer—usually, more accurate than a human being. For example, most people feel
    relieved that machines, and not just people, fly airplanes today. Airplanes may
    be much safer now compared to 15 years ago because of this advancement, but when
    it comes to GenAI, the results are not nearly as accurate as the onboard systems
    of a flight craft.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: This chapter takes a detailed look at the top five challenges with GenAI applications
    and why they occur. Understanding these challenges is crucial for developers to
    devise effective solutions. By the end of this chapter, you will have a good understanding
    of these challenges, how they influence your outcomes, how they relate to each
    other, and why this particular set of technologies, despite these challenges,
    is still highly valuable to users.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter will cover the following topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: Hallucinations
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sycophancy
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data leakage
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cost optimization
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Performance issues
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Most of the examples in this chapter can be demonstrated by simply repeating
    the prompt or example in ChatGPT.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: Hallucinations
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the greatest challenges of working with GenAI, and perhaps the most well-known,
    is **hallucination**. Hallucination in GenAI refers to the phenomenon where the
    AI model generates content that sounds plausible but is factually incorrect, nonsensical,
    or not grounded in the provided input data. This issue is particularly prevalent
    in **natural language processing** (**NLP**) models, such as those used for text
    generation, but can also occur in other generative models such as image generation
    and LLMs such as GPT-4.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: In the worst case, both the developers and their users do not know whether the
    answer given by GenAI is correct, partially correct, mostly incorrect, or a complete
    fabrication.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: Causes of hallucinations
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Much of the data that organizations capture is either **redundant, obsolete,
    trivial** (**ROT**), or altogether unclassified. As a portion, *good* data forms
    a small fraction of the data lakes, warehouses, and databases that most companies
    have. Whenever beginning your GenAI application journey, one of the first things
    you’re likely to notice is that much of the data you’d like to use to train your
    GenAI application is poor quality. Shortly thereafter, you’ll learn that hallucinations
    are caused by **poor-quality** **training data**.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: 'Engineers can best think of this as a **garbage in, garbage out** problem.
    When training data has errors, inconsistencies, irrelevancy, outdated information,
    biased information, and other issues, the model will learn to replicate those
    problems. The accuracy of an AI model is heavily dependent on the quality of training
    data, and the following data issues are more likely to cause output problems and
    hallucinations:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: '**Inaccurate data**: Errors in the input will propagate and compound in the
    system, so it is critical to know that any automated or real-time data streaming
    to your GenAI application has accurate information. For example, if you’re ingesting
    sensor data to predict when equipment will fail but receive inaccurate sensor
    readings, then your GenAI application may not predict the failure correctly or
    in a timely way.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Incomplete data**: Training on incomplete datasets can cause the model to
    generate plausible but incorrect content to fill perceived gaps.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Outdated or obsolete data**: At its heart, obsolete data is often simply
    no longer accurate, providing AI with false information. Relevant data updates
    ensure that your GenAI application continues to provide your users with accurate
    outputs.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Irrelevant data**: It can be tempting to stuff your GenAI application with
    as much data as possible so that it can use that information for analysis; however,
    this is a way to increase costs without improving accuracy.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Misleading or misrepresentative data**: If a machine learning model is trained
    on images that are poorly labeled or unrepresentative of real-world scenarios,
    it will struggle to correctly identify or classify images when deployed.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Duplicated data**: This also includes poorly integrated datasets. Redundant
    data can give AI the impression that something is more important than it is because
    it’s repeated.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Model architecture and objectives**: Models such as GPT-4 are trained to
    predict the next word in a sequence based on context, and not necessarily to verify
    facts. This objective can lead to the model generating fluent text that is not
    factually accurate.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each of these causes slightly different issues and, in combination, can make
    your GenAI application incapable of producing satisfactory results. Therefore,
    your training data must be accurate, comprehensive, and representative of the
    diverse conditions the model will encounter in real-world applications. Much of
    GenAI is continuously self-learning, so maintaining data quality is an ongoing
    issue, not a **first-deploying-to-production** issue.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: Generative models focus on producing outputs that are coherent and contextually
    relevant, which sometimes comes at the expense of factual correctness. These models
    are also excellent at recognizing and replicating patterns in data. However, this
    can result in outputs that follow learned patterns even when those patterns do
    not align with factual reality. This is the **correlation, not** **causation**
    issue.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: Also, models are trained on static datasets and lack real-time access to updated
    information, which can lead to outdated or incorrect outputs. For instance, GPT
    and its ilk are trained on data scraped from the web several months (or even years!)
    ago. Products, insights, and world news from yesterday are not available. When
    asking questions about recent events, in the best case, the user receives an answer
    such as `I do not have this information`. In the worst case, the GenAI application
    simply hallucinates a response. Generative models may not fully understand the
    context or possess the real-world knowledge required to validate the correctness
    of generated information.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: Implications of hallucinations
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Besides just “being wrong” and “making up answers,” hallucinations can have
    other unexpected implications. Misinformation can easily be propagated to thousands
    of people, some of whom may find it difficult to turn around later. For instance,
    if today, ChatGPT (a popular GenAI model) started telling every person who asked
    that a popular open-source project has a critical vulnerability, then the news
    would spread like wildfire, making damage control difficult. It would reach many
    more people than the statement put out on the company blog about how the information
    wasn’t true. Many users trust the AI’s output without verification.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: Hallucinations undermine the reliability of AI systems, particularly in fields
    such as healthcare, legal, or financial services, where accuracy is paramount.
    Moreover, consistent hallucinations can erode user trust in AI applications, leading
    to reduced adoption and skepticism regarding AI capabilities.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: Incorrect information can lead to ethical dilemmas and potential legal liabilities,
    especially if the AI’s output influences critical decisions or public opinion.
    As GenAI is added into all sorts of applications, it becomes more and more difficult
    to both opt out of (for the users) and discern whether the answers are legitimate.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: It is worth saying also that receiving an answer that is not a hallucination
    is far different from receiving the best answer.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: Sycophancy
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A sycophant is a person who does whatever they can to win your approval, even
    at the cost of their ethics or knowledge of what is true. AI models demonstrate
    this behavior often enough for AI researchers and developers to use the same term—**sycophancy**—to
    describe how models respond to human feedback and prompting in deceptive or problematic
    ways. Human feedback is commonly utilized to fine-tune AI assistants. But human
    feedback may also encourage model responses that match user beliefs over truthful
    ones, a trait known as sycophancy. Sycophancy exists in multiple ways, such as
    mirroring feedback, easily being swayed, and changing correct answers if the user
    pushes back. If users share their beliefs and views on a topic, AI assistants
    will provide answers that align with the user’s beliefs.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: 'Sycophancy can be observed and described on multiple levels, such as the following:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: '**Feedback sycophancy**: When users express likes or dislikes about a text,
    AI assistants may provide more positive or negative feedback accordingly'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Swaying easily**: After answering a question correctly, AI assistants may
    change their answer when users challenge them, even if the original answer was
    correct'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Belief conformity**: When users share their views on a topic, AI assistants
    tend to provide answers that align with those beliefs, leading to decreased accuracy'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In testing, researchers Mrinank Sharma et al. demonstrated sycophantic answers
    generated by Claude ([https://arxiv.org/abs/2310.13548](https://arxiv.org/abs/2310.13548)),
    as shown in *Figure 11**.1*.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B22495_11_01.jpg)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.1: Example responses demonstrating sycophancy'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: It is worth noting that repeated testing of the same and similar questions in
    ChatGPT did not yield consistent results.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: Causes of sycophancy
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The exact causes of sycophancy are not well understood. This phenomenon exists
    in many LLMs because these models have been instructed to take in contextual and
    parametric information to inform their responses. GenAI applications have a *learning*
    feature where the more they interact with users, the more they learn about syntax,
    context, and providing sufficient answers. As they do so, the applications exhibit
    what can only be described as *people-pleasing behaviors*, causing them to deviate
    from a purely factual relaying of information.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: In the above research, it was found that sycophancy is a side effect of RLHF-like
    alignment training. **Reinforcement learning from human feedback** (**RLHF**)
    is a technique that is used to train LLMs to align the agent or machine with human
    preferences. This is particularly important in areas such as language models.
    To illustrate this, let’s look at some examples of what this means and why it
    matters.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the following:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: When you greet a coworker, you might say “Hello, sir/madam,” “Hello,” “Good
    morning,” “Good day,” “Hi,” “What’s up,” “Greetings,” or many other potential
    salutations. Hypothetically, all are appropriate, but there are human preferences
    as to which is more suitable.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: To further understand this, let’s begin with cultural preference. In some cultures,
    it would be shocking indeed if you did not include the coworker’s name, as in
    “Good morning, Mr. Smith.” Yet in other cultures, to address someone in this manner
    would seem exceedingly strange. The human preference on which greeting is preferred
    has some basis, part of which is cultural, part of which is situational and contextual
    (is Mr. Smith the president? Is he your 20-year-old new hire?), and part of which
    is purely you, the individual.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: Engineers decided that when people interact with GenAI, they prefer that their
    conversations and interactions feel human. To do that, the machines must consider
    cultural, situational, behavioral, and, to some extent, individual preferences.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: Training models have access to vast amounts of information, both contextual
    (passages of text from websites, books, research, etc.) and parametric (embeddings
    of nearest-neighbor words). They will use any cultural, contextual, or behavioral
    clues that the user provides to help inform their answer. That is, how the user
    phrases the question influences the answer.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: 'ChatGPT confirms this. When asked how it arrives at an answer, it states the
    following clearly:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: It is possible to request GenAI to disregard your previous interactions, personal
    preferences, syntax, and/or any data it has concluded about you before it creates
    answers to your questions, but, of course, this would require the user to know
    that this is happening in the first place.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: Implications of sycophancy
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As helpful as this functionality is, it has real-world implications for the
    outputs of GenAI applications. In the same research paper cited earlier in this
    chapter ([https://arxiv.org/abs/2310.13548](https://arxiv.org/abs/2310.13548)),
    it was determined that the consequences of sycophancy, while machine in origin,
    can result in incorrect deference to user opinion, propagation of user-created
    errors, and biased responses. Therefore, instead of helping create a more factual
    and consistent understanding of the world, GenAI perpetuates and perhaps accelerates
    the spread of misinformation.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: Researchers at Google DeepMind found that the problem grew worse as the model
    became bigger ([https://www.newscientist.com/article/2386915-ai-chatbots-become-more-sycophantic-as-they-get-more-advanced/](https://www.newscientist.com/article/2386915-ai-chatbots-become-more-sycophantic-as-they-get-more-advanced/)).
    LLMs with more parametric inputs had a greater tendency to agree with objectively
    false statements than smaller ones. This tendency held true even for mathematical
    equations, that is, questions where there is only one correct answer.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: LLMs are constantly learning, evolving, and being improved by their creators.
    In the future, perhaps LLMs will weigh the objective truth of a statement higher
    than the opinion or preferences of the user, but as of 2023, that is yet to happen.
    Ongoing research and testing will make them ever more adept at balancing user
    expectations, user opinions, and facts. Still, as of the time this book was written,
    sycophancy remains a primary concern with GenAI applications, particularly where
    the outputs consider opinions and user preferences before generating their response.
    Further testing using synthetic data and retraining models has reduced the tendency
    of sycophancy by up to 10%, which is still not 100% ([https://arxiv.org/abs/2308.03958](https://arxiv.org/abs/2308.03958)).
    This means that the tendency persists, even with fairly substantial modifications
    to the fine-tuning.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: Data leakage
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Data leakage**, in the context of GenAI, refers to situations where information
    from outside the desired training dataset is used to create the model, leading
    to overly optimistic performance metrics and potentially flawed or misleading
    predictions. This can happen at various stages of model development, from data
    collection to model evaluation, and can significantly compromise the validity
    of the AI system. There are multiple types of datasets with different purposes:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在生成式人工智能（GenAI）的背景下，**数据泄露**指的是使用来自期望训练数据集之外的信息来创建模型的情况，这可能导致过度乐观的性能指标，并可能产生有缺陷或误导性的预测。这种情况可能发生在模型开发的各个阶段，从数据收集到模型评估，可能会严重损害人工智能系统的有效性。存在多种类型的数据集，它们有不同的用途：
- en: Training datasets, which are used to train the LLM
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于训练LLM的训练数据集
- en: Fine-tuning datasets, which can be used to improve LLM responses and reduce
    hallucinations
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于改进LLM响应和减少幻觉的微调数据集
- en: Evaluation datasets, which can be useful in evaluating the accuracy of responses
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于评估响应准确性的评估数据集
- en: Causes of data leakage
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据泄露的原因
- en: 'The causes of data leakage are straightforward and easily avoided, as long
    as the developers of these applications are aware of these causes. First, let’s
    understand at a high level what leads to data leakage:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 数据泄露的原因简单明了，且易于避免，只要这些应用的开发者了解这些原因。首先，让我们从高层次上了解导致数据泄露的原因：
- en: '**Inappropriate dataset overlap**: Each dataset should be used at the appropriate
    training and evaluation stage. When this is not true, you have data leakage. For
    example, when the training dataset overlaps with the evaluation dataset, GenAI
    applications will, of course, perform better during testing because they already
    know the exact answers. In this scenario, your stock price predictor application
    would have had duplicated historical data points present in its training and evaluation
    datasets; therefore, its performance when testing its outputs will be unrealistically
    high because it has already seen the answers.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**不适当的dataset重叠**：每个数据集应适用于适当的训练和评估阶段。当这种情况不成立时，就会发生数据泄露。例如，当训练数据集与评估数据集重叠时，GenAI应用在测试期间的表现自然会更好，因为它们已经知道了确切的答案。在这种情况下，您的股价预测应用在其训练和评估数据集中会有重复的历史数据点；因此，在测试其输出性能时，其表现将不切实际地高，因为它已经看到了答案。'
- en: '**Future information**: Each dataset should only include information that would
    be available at the time of prediction. For instance, you would not include real
    or hypothetical information in your training dataset from a period in the future,
    or data that the model would not typically have access to in production.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**未来信息**：每个数据集应仅包含预测时可能可用的信息。例如，您不会在训练数据集中包含来自未来某个时期的真实或假设信息，或模型在生产中通常无法访问的数据。'
- en: '**Data normalization and transformation efforts**: When transformations or
    feature-engineering steps inadvertently introduce data from outside the training
    set, it is possible for information to leak from evaluation datasets into the
    training process. For GenAI, you want training data that is as close to *real
    life* as possible, both in terms of user interaction and whatever context the
    application will be operating within, so that your application has truly representative
    data.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据归一化和转换努力**：当转换或特征工程步骤意外地引入来自训练集之外的数据时，信息可能会从评估数据集泄露到训练过程中。对于GenAI，您希望训练数据尽可能接近*现实生活*，无论是从用户交互还是应用将运行在其内的任何上下文来看，这样您的应用就有真正代表性的数据。'
- en: To illustrate these causes, let’s use a hypothetical GenAI application that
    predicts stock prices upon request using historical data. In this scenario, it
    is May 2024, and your application is in the final testing phases. Before pushing
    to production, you’d like to determine how accurate its predictions are. You begin
    by checking your application’s response to the following user request.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明这些原因，让我们使用一个假设的GenAI应用，该应用根据请求使用历史数据预测股价。在这种情况下，现在是2024年5月，您的应用处于最终测试阶段。在推向生产之前，您想确定其预测的准确性。您首先检查应用对以下用户请求的响应。
- en: '**User request**:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**用户请求**：'
- en: '[PRE1]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '**Output answer**:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '**输出答案**：'
- en: '[PRE2]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'In this example, note the following:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，请注意以下内容：
- en: The **training** data fed to the model should **not** include any data points
    from May 2024.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型输入的**训练**数据不应包含任何来自2024年5月的数据点。
- en: The **evaluation** dataset should include all prices from May 2024 and could
    include the actual calculated value of the average stock price. This is because
    you would like to compare the model’s estimate to the actual value, and then give
    it a score for accuracy, then plot that month over month, in order to see whether
    the application consistently makes low or high estimates.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you’re trying for accuracy with your May 2024 estimate, but you’ve already
    fed it the May 2024 data in the training phase, this would be considered inappropriate
    dataset overlap. Let’s look at another example.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: '**User request**:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '**Output answer**:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: You would not provide a training dataset that already includes an annual average
    because that information is not yet available. While you could include a year-to-date
    average in the training dataset, you should not include an annual average with
    synthetic or generated forward-looking data. If you created an estimated annual
    stock price and included that in the training data, then you would be using future
    information. Now, let’s consider a final example.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: '**User request**:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '**Output answer**:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Notice how the user query is worded differently here as compared to the first
    example, though it leads to the same answer. LLMs are quite skilled at inferring
    user intention. Remember that users asking even fairly simple questions will phrase
    them in many different ways (*estimate*, *predict*, *forecast*, *imagine*, *guess*,
    and *projection* are all words they might use).
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: For your training dataset, you might include a prompt-and-answer pairing in
    the style of **frequently asked questions** (**FAQs**) for your entire support
    database. However, resist the urge to correct aspects such as wording and spelling.
    While you want to be aware of “garbage in, garbage out” problems, you do not want
    to shield your GenAI application so much that it won’t know how to respond when
    your users inevitably input garbage. This is particularly relevant for GenAI chatbots.
    Users have so many ways of asking a question. Those questions are presented usually
    without proper syntax, terminology, or contextual awareness, and their knowledge
    may also be outdated. Data normalization and transformation efforts should not
    normalize and cleanse your training data so much so that it becomes less useful.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: Implications of data leakage
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The implications of data leakage vary widely, depending on whether you’ve leaked
    a teardrop or a waterfall. If there is data leakage, then the results of your
    GenAI evaluation and testing prior to production will be wrong and misrepresentative
    of your application’s actual performance, leading to overly optimistic tests or
    misleading conclusions. In all data overlap cases, the most obvious consequence
    of overlapping the training and test datasets is that the model may learn to simply
    *memorize* the training data and perform poorly on any new data from which it
    must make predictions.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: This can give application developers and testers a false sense of confidence
    in the model’s performance. Later, when real-world data is offered and users are
    asking questions in production, the application will perform markedly worse.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: 'Avoiding data leakage is simple, and it begins with splitting your datasets
    into distinct entities, then doing the following:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: Ensure that training, validation, and test datasets are strictly separated.
    Use techniques such as time-based splitting for time-series data to prevent future
    information from leaking into the training set.
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use tools to ensure that data transformations are only applied to the training
    set during model training and applied to the test set independently during evaluation.
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Engineer features in a way that prevents future data from being used. Avoid
    using future values or aggregated future statistics as part of your training data.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Returning to the stock price prediction application, you would ideally want
    the data for your training and test sets to be based on time, ensuring that stock
    prices in the training set occur chronologically before those in the test set.
    Then, your application would only have features that were used in the historical
    stock data available up to the point of the stock price being predicted, marking
    a clear delineation between authentic prior stock prices and predicted future
    stock prices. Next, to validate your application, use time-based cross-validation
    to ensure that model performance is evaluated on data that simulates real-world
    prediction scenarios or the scenarios your application would allow.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: By rigorously managing how data is handled throughout the model development
    process, you can minimize the risk of data leakage and ensure that your GenAI
    model provides reliable and valid predictions.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: Cost
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With so many distinct, complex, and potentially expensive moving parts, it is
    critical for engineers to know the costs of their GenAI application and how to
    contain these costs. While you will learn more about cost optimization strategies
    in [*Chapter 12*](B22495_12.xhtml#_idTextAnchor253), *Correcting and Optimizing
    Your Generative AI Application*, this section will serve as an introduction to
    understanding the financial costs of GenAI applications, which are in some ways
    different from web development applications.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: Types of costs
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When using GenAI, costs can arise from several different areas. These costs
    can be broadly categorized into computational, storage, data acquisition, development,
    and maintenance costs:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: '**Training costs**: Training GenAI models requires significant computational
    resources. This is especially true for large models such as GPT-4\. These resources
    often include **graphics processing units** (**GPUs**) or **tensor processing
    units** (**TPUs**), which are optimized for parallel processing tasks. The infrastructure
    to support these setups consumes a lot of electricity and requires cooling systems
    to maintain operational temperatures. Most engineers may not be in the position
    to pay these costs and, instead, will utilize models from vendors, such as OpenAI,
    Anthropic, Google, Meta, or others.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Inference, or real-time computation**: Generating responses or outputs from
    a trained model, which is called **inference**, also incurs computational costs,
    especially for models that need to provide real-time answers. Bigger models cost
    more.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Storage costs**: Storing large datasets required for training GenAI models
    incurs costs. This includes raw data, preprocessed data, user interaction data,
    observability data, and the models themselves.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data collection**: Acquiring high-quality datasets can be expensive. This
    can include purchasing data from third-party providers or generating proprietary
    datasets.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data labeling and cleaning**: Preprocessing data to ensure it is suitable
    for training involves costs. This can include paying for human annotators to label
    data or developing algorithms to clean and prepare the data as either training
    or evaluation datasets.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Software development**: Writing and maintaining the code base for training
    and deploying GenAI applications requires skilled engineers and data analysts.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Experimentation and testing**: Developing GenAI often involves extensive
    experimentation and fine-tuning, which requires time and resources.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data updates**: Training and evaluation datasets require periodic updates
    to maintain their accuracy and relevance, which involves additional computational
    and human resources.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Monitoring and support**: The continuous monitoring of AI systems to ensure
    they are performing correctly and handling issues as they arise involves operational
    costs.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Compliance and security**: Ensuring data privacy and security and complying
    with regulations (such as GDPR) involves additional costs.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is not an exhaustive list. Therefore, estimating your expected costs is
    complex and a non-trivial endeavor. But let’s hone in on the most important cost
    driver, which is text, and therefore tokens. Next, you will learn how to estimate
    and control costs here.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: Tokens
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: LLMs process text using **tokens**, which are common sequences of characters
    found in a set of text. Tokens are the currency of the GenAI application. Each
    user input and output is a *token*, and both the question and response token count
    can be controlled. The cost per token is tiny. GenAI vendors look to make their
    money *per transaction*, which can add up quickly.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: Let’s understand this concept with an example. The statement `Hello how are
    you` is 5 tokens. A helpful rule of thumb is that one token generally corresponds
    to ~4 characters of text for common English text. This translates to roughly ¾
    of a word (so, 100 tokens ~= 75 words). The example of `Hello how are you` has
    18 characters including spaces, therefore 18/4 = 4.5, ergo 5 tokens.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: Each input and output for the GenAI application is reduced down to this simple
    unit of measurement.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: ChatGPT and other LLMs have a token limit, thus capping how much text the user
    can enter as their prompt and limiting the output response. These limits, however,
    are generous. For most use cases, it is unlikely the average consumer would hit
    these limits.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: For instance, GPT-4 has a token limit of 32,768 per interaction and an estimated
    word count of 25,000 words, whereas Claude 3 (the LLM hosted by Anthropic) has
    a token limit of 100,000+ as of the time of writing. For a simple customer service
    chatbot, it is very unlikely that you would hit this limit, but it *is* possible.
    Let’s look at two examples to explain how this might be true.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: '**Example 1**: A customer asks a GenAI chatbot a simple question.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: '**Inquiry**:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '**Response**:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The initial inquiry is 36 characters and 7 tokens. The response is 162 tokens,
    or 741 characters. If you were to have interactions limited to 300 tokens, you
    would still be well under the limit that you have allowed for your users.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: '**Example 2**: A server experiences an out-of-memory error, and the GenAI automatically
    analyzes the stack traces and logs an analysis for a human to review later.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: '**Inquiry**:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '**Response**:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This analyzer is useful to a diagnostics engineer, as the analyzer quickly reviews
    a stack trace, summarizes its findings, and generates recommendations for solving
    the issue.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: However, the prompt is 275 tokens (1,240 characters), and the response is 248
    tokens (1,205 characters). As this is a sample stack trace, the real-life implementation
    would possibly be more detailed with real information. So, if the control setting
    was still 300 tokens for input or output, you would be quite close to this limit
    already.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: Choosing the input and output token limits for your application is critically
    important. While you want to control costs, you also do not want to fundamentally
    limit functionality. If the token limit is too low, the LLM may not be able to
    generate the desired output.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: Performance issues in generative AI applications
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The most obvious failures of GenAI are performance- and reliability-related
    issues. Since you’ve learned about accuracy in [*Chapter 10*](B22495_10.xhtml#_idTextAnchor214),
    *Refining the Semantic Data Model to Improve Accuracy*, performance in this chapter’s
    context means slowness. If a user asks your AI application a question and there
    is either no response, a metered response, or a partial response, it is typically
    much more apparent than if the response was hallucinated or sycophantic.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: Several factors can contribute to the slowness of a GenAI application. Some
    of the most common causes of performance issues in GenAI are computational load,
    network latency, model serving strategies, and high **input/output** (**I/O**)
    operations.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 几个因素可能导致GenAI应用程序的缓慢。GenAI中性能问题最常见的几个原因包括计算负载、网络延迟、模型服务策略以及高**输入/输出**（**I/O**）操作。
- en: There can be many more causes, of course. The rest of this section will explain
    some of these performance killers in detail and their impact on your application
    and users.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，可能还有更多原因。本节剩余部分将详细解释一些性能杀手，以及它们对您的应用程序和用户的影响。
- en: Computational load
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 计算负载
- en: As you already know, LLMs require significant computational power. The time
    required to generate responses to queries increases with the complexity and the
    size of the model. Poorly formed requests significantly increase the computational
    load for a GenAI application. Let’s look at a few examples of this so that you’re
    able to understand how this failure mode can happen.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所知，LLMs需要大量的计算能力。生成查询响应所需的时间随着模型复杂性和规模的增加而增加。不恰当的请求会显著增加GenAI应用程序的计算负载。让我们看看几个这样的例子，以便您能够理解这种故障模式是如何发生的。
- en: Extensive data processing and calculations
  id: totrans-139
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 大量的数据处理和计算
- en: Requests that require processing large datasets or performing extensive calculations
    can be computationally demanding, as happens in the following example.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 需要处理大量数据集或执行大量计算的请求可能会带来计算上的负担，以下是一个例子。
- en: '**User request**:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '**用户请求**：'
- en: '[PRE11]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Fetching 20,000 random stock prices sounds simple, but the user does not specify
    a timeframe. For what period should the model evaluate the last 20,000 stock prices?
    Over the last month? Last year at random? The sorting of those values is computationally
    expensive and adds further processing to the returned list.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 获取20,000条随机股票价格看似简单，但用户没有指定时间范围。模型应该评估最后20,000条股票价格的哪个时间段？是过去一个月？还是去年随机选取的时间段？对这些值的排序计算成本高昂，并进一步增加了返回列表的处理负担。
- en: High-complexity requests
  id: totrans-144
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 高复杂度请求
- en: Complex requests that involve evaluating a large amount of data, summarizing,
    and then returning many results are also taxing. Often, this involves chaining
    multiple LLM calls through advanced prompting techniques, such as the ReACT pattern
    and function calling.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 涉及评估大量数据、总结并返回大量结果的复杂请求也很耗费资源。通常，这涉及到通过高级提示技术，如ReACT模式和函数调用，链式调用多个LLM。
- en: The **reasoning and acting** (**ReACT**) pattern is an advanced prompting technique
    used in GenAI models to handle complex tasks that require multiple steps of reasoning
    and interaction. This pattern involves a sequence where the model reasons about
    the task, generates intermediate actions, and then produces the final output.
    The ReACT pattern helps the model break down complex requests into manageable
    steps, improving accuracy and coherence in the final response.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '**推理和行动**（**ReACT**）模式是GenAI模型中用于处理需要多个推理和交互步骤的复杂任务的高级提示技术。这个模式涉及一个序列，其中模型对任务进行推理，生成中间动作，然后产生最终输出。ReACT模式帮助模型将复杂请求分解为可管理的步骤，提高最终响应的准确性和连贯性。'
- en: '**Function calling** in the context of LLMs involves instructing the model
    to execute specific functions or actions as part of its response generation process.
    This can be particularly useful for tasks that require structured outputs, calculations,
    data retrieval, or interactions with external systems. As an example, the developer
    specifies functions within the prompt that the model can call to perform specific
    tasks. These functions are predefined and can handle various operations, such
    as querying databases, performing calculations, or fetching external data.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在LLMs的上下文中，**函数调用**涉及指示模型在其响应生成过程中执行特定的函数或动作。这对于需要结构化输出、计算、数据检索或与外部系统交互的任务特别有用。例如，开发者可以在提示中指定模型可以调用的函数来执行特定任务。这些函数是预定义的，可以处理各种操作，如查询数据库、执行计算或获取外部数据。
- en: Let’s look at a high-complexity request to illustrate this.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个高复杂度的请求来阐述这一点。
- en: '**User request**:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '**用户请求**：'
- en: '[PRE12]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: In this scenario, the GenAI must first create the list of every US president,
    then seek information about each one, and then create a detailed summary of their
    policies and events during their terms in office. It must also retrieve content
    related to which things the presidents prioritized, identify consensus on what
    pieces of content were the top priorities, compile and summarize all that information,
    and then output it to the user. This is extensive knowledge retrieval, analysis,
    and text generation. Most likely, this information would require multiple LLM
    queries, and more queries equate to more spend.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，GenAI 必须首先创建每位美国总统的名单，然后寻找每位总统的信息，接着创建他们在任期间政策和事件的详细总结。它还必须检索与总统优先考虑的事项相关的内容，确定哪些内容是最高优先级的共识，整理并总结所有这些信息，然后输出给用户。这是广泛的知识检索、分析和文本生成。很可能会需要多个
    LLM 查询，而更多的查询意味着更多的开销。
- en: These examples illustrate how certain types of user requests can significantly
    increase the computational load for GenAI applications. Let’s now see how model
    serving strategies can impact GenAI performance.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 这些例子说明了某些类型的用户请求如何显著增加 GenAI 应用程序的计算负载。现在让我们看看模型服务策略如何影响 GenAI 的性能。
- en: Model serving strategies
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型服务策略
- en: Generating responses for every request individually can be inefficient, depending
    on volume. If the application is not designed to handle multiple requests concurrently,
    it will become slower the more users you have. If the application relies on cloud-based
    services, network latency can affect performance. Slow internet connections or
    high latency between the client and the server can cause delays. Frequent or complex
    API calls to external services can add to the response time, especially if those
    services are experiencing a high load or are geographically distant.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 根据请求量，为每个请求单独生成响应可能效率低下。如果应用程序没有设计成可以同时处理多个请求，那么随着用户数量的增加，它将变得越来越慢。如果应用程序依赖于云服务，网络延迟会影响性能。客户端和服务器之间慢速的互联网连接或高延迟会导致延迟。频繁或复杂的
    API 调用到外部服务会增加响应时间，尤其是如果这些服务正在经历高负载或地理位置遥远。
- en: Let’s return to the stock predictor application for an example.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以股票预测应用程序为例。
- en: Because your GenAI application receives some news coverage, your website experiences
    a surge in traffic, and the number of customers interacting with the application
    increases dramatically. But, since your application handles each request individually
    and cannot process multiple requests concurrently, the response time for each
    user increases as the system becomes overwhelmed. Users experience slower response
    times, leading to frustration.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 由于您的 GenAI 应用程序获得了一些新闻报道，您的网站流量激增，与应用程序互动的客户数量急剧增加。但是，由于您的应用程序逐个处理每个请求并且无法同时处理多个请求，随着系统变得不堪重负，每个用户的响应时间都会增加。用户会体验到更慢的响应时间，从而导致挫败感。
- en: The news coverage was from an influencer in Sydney, Australia, so the surge
    in users is from Asia. Your servers are in the US East region, and network latency
    due to the geographical distance between the server and the clients causes delays.
    Customers with slow internet connections experience even longer wait times, further
    degrading the user experience.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 新闻报道来自澳大利亚悉尼的一位有影响力的人物，因此用户激增来自亚洲。您的服务器位于美国东部地区，由于服务器和客户端之间的地理距离，网络延迟导致延迟。互联网连接速度慢的客户体验到的等待时间更长，进一步降低了用户体验。
- en: Your application frequently calls external APIs to fetch real-time data for
    stock prices and financial market news. If these external services are experiencing
    high load, the API calls take longer to complete.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 您的应用程序经常调用外部 API 来获取股票价格和金融市场新闻的实时数据。如果这些外部服务正在经历高负载，API 调用将需要更长的时间才能完成。
- en: High I/O operations
  id: totrans-159
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 高 I/O 操作
- en: 'Poor data-handling practices, such as reading large datasets inefficiently
    or not using appropriate data structures, can slow down performance. Frequent
    read/write operations to disk can be a bottleneck, as can poorly optimized database
    interactions and malformed queries. The example stock price predictor application
    frequently reads large historical stock price datasets to make predictions. Let’s
    walk through some potential issues with data handling that result in high I/O
    operations:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 不良的数据处理实践，如低效地读取大型数据集或未使用适当的数据结构，可能会降低性能。频繁的磁盘读写操作可能成为瓶颈，同样，数据库交互优化不良和查询格式错误也可能导致问题。示例股价预测应用程序经常读取大量历史股价数据集进行预测。让我们探讨一些数据处理问题，这些问题会导致高I/O操作：
- en: The application reads large datasets inefficiently, such as loading the entire
    dataset into memory even when only a subset is needed, which consumes excessive
    memory and processing power, slowing down performance.
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该应用程序读取大型数据集效率低下，例如，即使只需要子集，也会将整个数据集加载到内存中，这消耗了过多的内存和计算能力，降低了性能。
- en: The application saves intermediate prediction results and logs to disk after
    every prediction cycle. Frequent read/write operations to disk form a bottleneck,
    which significantly increases the time it takes to complete each prediction cycle.
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该应用程序在每次预测周期结束后将中间预测结果和日志保存到磁盘。频繁的磁盘读写操作形成瓶颈，这显著增加了完成每个预测周期所需的时间。
- en: The application queries a database to fetch recent financial news and other
    relevant data before making predictions. However, a lack of indexes means that
    query results are slowly delivered. This increases response times, making the
    application slow to respond to user requests.
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在做出预测之前，该应用程序会查询数据库以获取最近的财经新闻和其他相关数据。然而，缺乏索引意味着查询结果缓慢返回。这增加了响应时间，使得应用程序对用户请求的响应速度变慢。
- en: Assuming you have a large dataset, you’ll want to avoid these practices as they
    will affect user experience and increase costs.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你有一个大型数据集，你将想要避免这些做法，因为它们会影响用户体验并增加成本。
- en: Summary
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Now that you have navigated through these GenAI challenges, you can appreciate
    some of the complexities and nuances that accompany these powerful technologies.
    The issues of hallucinations, sycophancy, data leakage, cost, and performance
    present formidable obstacles that demand a critical eye and innovative solutions.
    Each challenge offers a unique perspective on the limitations and potential pitfalls
    inherent in GenAI applications.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经通过了这些GenAI挑战，你可以欣赏到这些强大技术所伴随的一些复杂性和细微差别。幻觉、谄媚、数据泄露、成本和性能问题构成了巨大的障碍，需要批判性的眼光和创新解决方案。每个挑战都为GenAI应用程序固有的局限性和潜在陷阱提供了独特的视角。
- en: 'Despite these hurdles, GenAI remains unequivocally valuable. It continues to
    transform industries, enhance productivity, and open new avenues for creativity
    and innovation. By understanding and addressing these challenges, developers can
    harness the full potential of GenAI, delivering robust, reliable, and responsible
    applications. At the same time, it’s also important to note that applications
    can be useful even when they are not always correct. To take ChatGPT as an example:
    it has greatly improved the productivity of millions of users already, even though
    its deficiencies are well-known (and some not so easily worked around). Your GenAI
    application could be just as useful and popular but with similar caveats.'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管存在这些障碍，GenAI仍然无可争议地具有价值。它继续改变行业，提高生产力，并为创造力和创新开辟新的途径。通过理解和解决这些挑战，开发者可以充分发挥GenAI的潜力，提供强大、可靠和负责任的应用程序。同时，也要注意，即使应用程序不总是正确，它们也可能是有用的。以ChatGPT为例：它已经极大地提高了数百万用户的效率，尽管其缺陷是众所周知的（而且有些并不容易解决）。你的GenAI应用程序也可能同样有用和受欢迎，但同样存在类似的警告。
- en: In the next chapter, you’ll look at ways to optimize your GenAI application,
    improving its outputs and performance for a better user experience as well as
    combatting some of the issues discussed here.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，你将了解优化你的GenAI应用程序的方法，提高其输出和性能，从而改善用户体验，并解决这里讨论的一些问题。
