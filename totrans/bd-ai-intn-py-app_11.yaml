- en: '11'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '11'
- en: Common Failures of Generative AI
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成式AI的常见失败
- en: If you have just built your **generative AI** (**GenAI**) application, then
    you may be so fascinated by what it can do that you lose sight of answer quality
    and accuracy. Discovering how often GenAI is incorrect is a challenge in itself.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你刚刚构建了你的**生成式AI**（**GenAI**）应用，那么你可能对它能做什么感到如此着迷，以至于你忽略了答案的质量和准确性。发现GenAI错误发生的频率本身就是一个挑战。
- en: Many tend to believe that when a computer gives an answer, it gives an accurate
    answer—usually, more accurate than a human being. For example, most people feel
    relieved that machines, and not just people, fly airplanes today. Airplanes may
    be much safer now compared to 15 years ago because of this advancement, but when
    it comes to GenAI, the results are not nearly as accurate as the onboard systems
    of a flight craft.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 许多人倾向于认为，当计算机给出答案时，它给出的是准确的答案——通常比人类更准确。例如，大多数人感到欣慰，因为现在飞机是由机器而不是人驾驶的。由于这一进步，飞机可能比15年前更安全，但当我们谈到GenAI时，结果远不如飞行器的机载系统准确。
- en: This chapter takes a detailed look at the top five challenges with GenAI applications
    and why they occur. Understanding these challenges is crucial for developers to
    devise effective solutions. By the end of this chapter, you will have a good understanding
    of these challenges, how they influence your outcomes, how they relate to each
    other, and why this particular set of technologies, despite these challenges,
    is still highly valuable to users.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章详细探讨了与GenAI应用相关的五大挑战及其发生的原因。理解这些挑战对于开发者设计有效的解决方案至关重要。到本章结束时，你将很好地理解这些挑战，它们如何影响你的结果，它们如何相互关联，以及为什么尽管存在这些挑战，这一特定技术集对用户仍然非常有价值。
- en: 'This chapter will cover the following topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Hallucinations
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 幻觉
- en: Sycophancy
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 奄媚
- en: Data leakage
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据泄露
- en: Cost optimization
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 成本优化
- en: Performance issues
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 性能问题
- en: Technical requirements
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: Most of the examples in this chapter can be demonstrated by simply repeating
    the prompt or example in ChatGPT.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的大多数示例可以通过简单地重复ChatGPT中的提示或示例来演示。
- en: Hallucinations
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 幻觉
- en: One of the greatest challenges of working with GenAI, and perhaps the most well-known,
    is **hallucination**. Hallucination in GenAI refers to the phenomenon where the
    AI model generates content that sounds plausible but is factually incorrect, nonsensical,
    or not grounded in the provided input data. This issue is particularly prevalent
    in **natural language processing** (**NLP**) models, such as those used for text
    generation, but can also occur in other generative models such as image generation
    and LLMs such as GPT-4.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 与GenAI一起工作的最大挑战之一，也许是最为人所知的，就是**幻觉**。在GenAI中，幻觉是指AI模型生成看似合理但实际上错误、无意义或与提供的输入数据不符的内容的现象。这个问题在**自然语言处理**（**NLP**）模型中尤为普遍，例如用于文本生成的模型，但也可以出现在其他生成模型中，如图像生成和LLMs（如GPT-4）。
- en: In the worst case, both the developers and their users do not know whether the
    answer given by GenAI is correct, partially correct, mostly incorrect, or a complete
    fabrication.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在最坏的情况下，开发者和他们的用户都不知道GenAI给出的答案是正确的、部分正确、大部分不正确，还是完全虚构的。
- en: Causes of hallucinations
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 幻觉的原因
- en: Much of the data that organizations capture is either **redundant, obsolete,
    trivial** (**ROT**), or altogether unclassified. As a portion, *good* data forms
    a small fraction of the data lakes, warehouses, and databases that most companies
    have. Whenever beginning your GenAI application journey, one of the first things
    you’re likely to notice is that much of the data you’d like to use to train your
    GenAI application is poor quality. Shortly thereafter, you’ll learn that hallucinations
    are caused by **poor-quality** **training data**.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 组织捕获的大部分数据要么是**冗余的、过时的、微不足道的**（**ROT**），要么根本未分类。在数据湖、仓库和数据库中，*良好*的数据只占很小一部分，这些是大多数公司拥有的。在开始你的GenAI应用之旅时，你很可能会首先注意到，你想要用于训练GenAI应用的大部分数据质量都很差。不久之后，你就会了解到幻觉是由**低质量**的**训练数据**引起的。
- en: 'Engineers can best think of this as a **garbage in, garbage out** problem.
    When training data has errors, inconsistencies, irrelevancy, outdated information,
    biased information, and other issues, the model will learn to replicate those
    problems. The accuracy of an AI model is heavily dependent on the quality of training
    data, and the following data issues are more likely to cause output problems and
    hallucinations:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 工程师可以将此视为**垃圾输入，垃圾输出**问题。当训练数据有错误、不一致、不相关、过时信息、偏见信息和其他问题时，模型将学会复制这些问题。AI 模型的准确性高度依赖于训练数据的质量，以下数据问题更有可能导致输出问题和幻觉：
- en: '**Inaccurate data**: Errors in the input will propagate and compound in the
    system, so it is critical to know that any automated or real-time data streaming
    to your GenAI application has accurate information. For example, if you’re ingesting
    sensor data to predict when equipment will fail but receive inaccurate sensor
    readings, then your GenAI application may not predict the failure correctly or
    in a timely way.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**不准确的数据**：输入中的错误会在系统中传播并累积，因此了解任何自动或实时数据流到您的 GenAI 应用程序中都有准确信息至关重要。例如，如果您正在使用传感器数据来预测设备何时会故障，但接收到的传感器读数不准确，那么您的
    GenAI 应用程序可能无法正确或及时地预测故障。'
- en: '**Incomplete data**: Training on incomplete datasets can cause the model to
    generate plausible but incorrect content to fill perceived gaps.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**不完整的数据**：在不完整的数据集上进行训练可能导致模型生成看似合理但实际上错误的内容来填补感知到的空白。'
- en: '**Outdated or obsolete data**: At its heart, obsolete data is often simply
    no longer accurate, providing AI with false information. Relevant data updates
    ensure that your GenAI application continues to provide your users with accurate
    outputs.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**过时或陈旧的数据**：从本质上讲，过时的数据通常只是不再准确，向 AI 提供错误信息。相关数据更新确保您的 GenAI 应用程序继续为用户提供准确输出。'
- en: '**Irrelevant data**: It can be tempting to stuff your GenAI application with
    as much data as possible so that it can use that information for analysis; however,
    this is a way to increase costs without improving accuracy.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无关数据**：可能会诱使您尽可能多地填充您的 GenAI 应用程序中的数据，以便它可以利用这些信息进行分析；然而，这是一种增加成本而不提高准确性的方法。'
- en: '**Misleading or misrepresentative data**: If a machine learning model is trained
    on images that are poorly labeled or unrepresentative of real-world scenarios,
    it will struggle to correctly identify or classify images when deployed.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**误导性或失实的数据**：如果机器学习模型是在标签不佳或无法代表现实场景的图像上训练的，那么在部署时它将难以正确识别或分类图像。'
- en: '**Duplicated data**: This also includes poorly integrated datasets. Redundant
    data can give AI the impression that something is more important than it is because
    it’s repeated.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**重复数据**：这也包括整合不良的数据集。冗余数据可能会给 AI 一种印象，即某些东西比它实际上更重要，因为它是重复的。'
- en: '**Model architecture and objectives**: Models such as GPT-4 are trained to
    predict the next word in a sequence based on context, and not necessarily to verify
    facts. This objective can lead to the model generating fluent text that is not
    factually accurate.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型架构和目标**：例如 GPT-4 这样的模型被训练来根据上下文预测序列中的下一个单词，而不一定是验证事实。这个目标可能导致模型生成流畅但事实不准确的文章。'
- en: Each of these causes slightly different issues and, in combination, can make
    your GenAI application incapable of producing satisfactory results. Therefore,
    your training data must be accurate, comprehensive, and representative of the
    diverse conditions the model will encounter in real-world applications. Much of
    GenAI is continuously self-learning, so maintaining data quality is an ongoing
    issue, not a **first-deploying-to-production** issue.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这些原因各自引起略微不同的问题，并且结合在一起可能会使您的 GenAI 应用程序无法产生令人满意的结果。因此，您的训练数据必须准确、全面，并代表模型将在实际应用中遇到的多样化条件。大部分
    GenAI 是持续自我学习的，因此维护数据质量是一个持续的问题，而不仅仅是**首次部署到生产**的问题。
- en: Generative models focus on producing outputs that are coherent and contextually
    relevant, which sometimes comes at the expense of factual correctness. These models
    are also excellent at recognizing and replicating patterns in data. However, this
    can result in outputs that follow learned patterns even when those patterns do
    not align with factual reality. This is the **correlation, not** **causation**
    issue.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 生成模型专注于产生连贯且上下文相关的输出，这有时是以事实准确性为代价的。这些模型在识别和复制数据中的模式方面也非常出色。然而，这可能导致输出遵循学习到的模式，即使这些模式与事实现实不符。这是**相关性而非因果关系**的问题。
- en: Also, models are trained on static datasets and lack real-time access to updated
    information, which can lead to outdated or incorrect outputs. For instance, GPT
    and its ilk are trained on data scraped from the web several months (or even years!)
    ago. Products, insights, and world news from yesterday are not available. When
    asking questions about recent events, in the best case, the user receives an answer
    such as `I do not have this information`. In the worst case, the GenAI application
    simply hallucinates a response. Generative models may not fully understand the
    context or possess the real-world knowledge required to validate the correctness
    of generated information.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，模型是在静态数据集上训练的，缺乏对更新信息的实时访问，这可能导致过时或不正确的输出。例如，GPT及其同类产品是在几个月（甚至几年！）前从网络上抓取的数据上训练的。昨天的产品、见解和世界新闻都不在可用范围内。当询问关于最近事件的问题时，在最好的情况下，用户会收到这样的回答：“我没有这个信息”。在最坏的情况下，通用人工智能应用只是胡编乱造一个回答。生成模型可能不完全理解上下文或缺乏验证生成信息正确性的现实世界知识。
- en: Implications of hallucinations
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 幻觉的后果
- en: Besides just “being wrong” and “making up answers,” hallucinations can have
    other unexpected implications. Misinformation can easily be propagated to thousands
    of people, some of whom may find it difficult to turn around later. For instance,
    if today, ChatGPT (a popular GenAI model) started telling every person who asked
    that a popular open-source project has a critical vulnerability, then the news
    would spread like wildfire, making damage control difficult. It would reach many
    more people than the statement put out on the company blog about how the information
    wasn’t true. Many users trust the AI’s output without verification.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 除了“错误”和“编造答案”之外，幻觉还可能产生其他意想不到的后果。错误信息可以轻易地传播给成千上万的人，其中一些人可能难以事后纠正。例如，如果今天，ChatGPT（一个流行的通用人工智能模型）开始告诉每个询问的人一个流行的开源项目存在一个关键漏洞，那么这个消息就会像野火一样迅速传播，使得损害控制变得困难。它将影响到比公司在博客上发表的关于信息不真实声明更多的人。许多用户在没有验证的情况下就信任人工智能的输出。
- en: Hallucinations undermine the reliability of AI systems, particularly in fields
    such as healthcare, legal, or financial services, where accuracy is paramount.
    Moreover, consistent hallucinations can erode user trust in AI applications, leading
    to reduced adoption and skepticism regarding AI capabilities.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 幻觉削弱了人工智能系统的可靠性，尤其是在医疗、法律或金融服务等领域，这些领域准确性至关重要。此外，持续的幻觉可能会侵蚀用户对人工智能应用的信任，导致采用率降低和对人工智能能力的怀疑。
- en: Incorrect information can lead to ethical dilemmas and potential legal liabilities,
    especially if the AI’s output influences critical decisions or public opinion.
    As GenAI is added into all sorts of applications, it becomes more and more difficult
    to both opt out of (for the users) and discern whether the answers are legitimate.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 错误信息可能导致道德困境和潜在的法律责任，尤其是如果人工智能的输出影响了关键决策或公众舆论。随着通用人工智能被应用于各种应用中，对于用户来说退出变得越来越困难，同时辨别答案是否合法也越来越困难。
- en: It is worth saying also that receiving an answer that is not a hallucination
    is far different from receiving the best answer.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，收到一个不是幻觉的回答与收到最佳回答大相径庭。
- en: Sycophancy
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 媚俗
- en: A sycophant is a person who does whatever they can to win your approval, even
    at the cost of their ethics or knowledge of what is true. AI models demonstrate
    this behavior often enough for AI researchers and developers to use the same term—**sycophancy**—to
    describe how models respond to human feedback and prompting in deceptive or problematic
    ways. Human feedback is commonly utilized to fine-tune AI assistants. But human
    feedback may also encourage model responses that match user beliefs over truthful
    ones, a trait known as sycophancy. Sycophancy exists in multiple ways, such as
    mirroring feedback, easily being swayed, and changing correct answers if the user
    pushes back. If users share their beliefs and views on a topic, AI assistants
    will provide answers that align with the user’s beliefs.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 媚俗者是指那些不惜一切代价赢得你赞同的人，即使是以牺牲他们的道德或对真相的了解为代价。人工智能模型经常表现出这种行为，以至于人工智能研究人员和开发者可以使用相同的术语——**媚俗**——来描述模型如何以欺骗或问题的方式对人类反馈和提示做出反应。人类反馈通常被用来微调人工智能助手。但人类反馈也可能鼓励模型产生与用户信念相符的响应，而不是真实的响应，这种特性被称为媚俗。媚俗以多种方式存在，例如镜像反馈、容易被影响，以及如果用户反驳，就会改变正确的答案。如果用户分享他们对某个主题的看法和观点，人工智能助手将提供与用户信念相符的答案。
- en: 'Sycophancy can be observed and described on multiple levels, such as the following:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 奇谄可以在多个层面上观察到和描述，如下所示：
- en: '**Feedback sycophancy**: When users express likes or dislikes about a text,
    AI assistants may provide more positive or negative feedback accordingly'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**反馈奇谄**：当用户对文本表达喜好或厌恶时，AI助手可能会相应地提供更多积极或消极的反馈。'
- en: '**Swaying easily**: After answering a question correctly, AI assistants may
    change their answer when users challenge them, even if the original answer was
    correct'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**摇摆不定**：在正确回答问题后，即使原始答案是正确的，AI助手在用户挑战时可能会改变他们的答案。'
- en: '**Belief conformity**: When users share their views on a topic, AI assistants
    tend to provide answers that align with those beliefs, leading to decreased accuracy'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**信念一致性**：当用户就某个话题分享他们的观点时，AI助手往往会提供与那些信念一致的答案，导致准确性降低。'
- en: In testing, researchers Mrinank Sharma et al. demonstrated sycophantic answers
    generated by Claude ([https://arxiv.org/abs/2310.13548](https://arxiv.org/abs/2310.13548)),
    as shown in *Figure 11**.1*.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在测试中，研究人员Mrinank Sharma等人展示了由Claude生成的奇谄答案（[https://arxiv.org/abs/2310.13548](https://arxiv.org/abs/2310.13548)），如*图11.1*所示。
- en: '![](img/B22495_11_01.jpg)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22495_11_01.jpg)'
- en: 'Figure 11.1: Example responses demonstrating sycophancy'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.1：展示奇谄的示例回答
- en: It is worth noting that repeated testing of the same and similar questions in
    ChatGPT did not yield consistent results.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，在ChatGPT中对相同和类似问题的重复测试并没有产生一致的结果。
- en: Causes of sycophancy
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 奇谄的原因
- en: The exact causes of sycophancy are not well understood. This phenomenon exists
    in many LLMs because these models have been instructed to take in contextual and
    parametric information to inform their responses. GenAI applications have a *learning*
    feature where the more they interact with users, the more they learn about syntax,
    context, and providing sufficient answers. As they do so, the applications exhibit
    what can only be described as *people-pleasing behaviors*, causing them to deviate
    from a purely factual relaying of information.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 奇谄的确切原因尚不清楚。这种现象存在于许多LLM中，因为这些模型已被指示接受上下文和参数信息以告知其回答。GenAI应用有一个*学习*功能，即它们与用户互动越多，就越能了解语法、上下文和提供充分答案。在这样做的时候，应用表现出只能描述为*取悦他人*的行为，导致它们偏离了纯粹的事实信息传递。
- en: In the above research, it was found that sycophancy is a side effect of RLHF-like
    alignment training. **Reinforcement learning from human feedback** (**RLHF**)
    is a technique that is used to train LLMs to align the agent or machine with human
    preferences. This is particularly important in areas such as language models.
    To illustrate this, let’s look at some examples of what this means and why it
    matters.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述研究中，发现奇谄是类似于RLHF的对齐训练的副作用。**从人类反馈中进行强化学习**（**RLHF**）是一种用于训练LLM以使代理或机器与人类偏好对齐的技术。这在语言模型等领域尤为重要。为了说明这一点，让我们看看一些例子以及为什么这很重要。
- en: 'Consider the following:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下内容：
- en: When you greet a coworker, you might say “Hello, sir/madam,” “Hello,” “Good
    morning,” “Good day,” “Hi,” “What’s up,” “Greetings,” or many other potential
    salutations. Hypothetically, all are appropriate, but there are human preferences
    as to which is more suitable.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 当你问候同事时，你可能会说“你好，先生/女士”，“你好”，“早上好”，“好日子”，“嗨”，“怎么了”，“问候”，或许多其他可能的问候语。假设所有这些都是合适的，但人类对哪种更合适有一定的偏好。
- en: To further understand this, let’s begin with cultural preference. In some cultures,
    it would be shocking indeed if you did not include the coworker’s name, as in
    “Good morning, Mr. Smith.” Yet in other cultures, to address someone in this manner
    would seem exceedingly strange. The human preference on which greeting is preferred
    has some basis, part of which is cultural, part of which is situational and contextual
    (is Mr. Smith the president? Is he your 20-year-old new hire?), and part of which
    is purely you, the individual.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步理解这一点，让我们从文化偏好开始。在某些文化中，如果你不包含同事的名字，比如“早上好，史密斯先生”，这确实会令人震惊。然而，在其他文化中，以这种方式称呼某人会显得极其奇怪。人类对哪种问候方式更受欢迎的偏好有一定的依据，其中一部分是文化因素，一部分是情境和语境（史密斯先生是总裁吗？他是你20岁的应届毕业生吗？），还有一部分纯粹是你个人的偏好。
- en: Engineers decided that when people interact with GenAI, they prefer that their
    conversations and interactions feel human. To do that, the machines must consider
    cultural, situational, behavioral, and, to some extent, individual preferences.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 工程师决定，当人们与GenAI互动时，他们更喜欢他们的对话和互动感觉像人。为了做到这一点，机器必须考虑文化、情境、行为，以及在某种程度上个人的偏好。
- en: Training models have access to vast amounts of information, both contextual
    (passages of text from websites, books, research, etc.) and parametric (embeddings
    of nearest-neighbor words). They will use any cultural, contextual, or behavioral
    clues that the user provides to help inform their answer. That is, how the user
    phrases the question influences the answer.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 训练模型可以访问大量信息，包括上下文信息（来自网站、书籍、研究等的文本段落）和参数信息（最近邻词的嵌入）。它们将使用用户提供的任何文化、上下文或行为线索来帮助提供答案。也就是说，用户提问的方式会影响答案。
- en: 'ChatGPT confirms this. When asked how it arrives at an answer, it states the
    following clearly:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT确认了这一点。当被问及它是如何得出答案时，它明确地陈述如下：
- en: '[PRE0]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: It is possible to request GenAI to disregard your previous interactions, personal
    preferences, syntax, and/or any data it has concluded about you before it creates
    answers to your questions, but, of course, this would require the user to know
    that this is happening in the first place.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 可以请求生成式人工智能（GenAI）在回答问题之前忽略你之前的互动、个人偏好、语法和/或它之前关于你的任何结论，但当然，这要求用户首先知道这种情况正在发生。
- en: Implications of sycophancy
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 谄媚的影响
- en: As helpful as this functionality is, it has real-world implications for the
    outputs of GenAI applications. In the same research paper cited earlier in this
    chapter ([https://arxiv.org/abs/2310.13548](https://arxiv.org/abs/2310.13548)),
    it was determined that the consequences of sycophancy, while machine in origin,
    can result in incorrect deference to user opinion, propagation of user-created
    errors, and biased responses. Therefore, instead of helping create a more factual
    and consistent understanding of the world, GenAI perpetuates and perhaps accelerates
    the spread of misinformation.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这个功能很有帮助，但它对GenAI应用的输出在现实世界中有着实际的影响。在前面章节中引用的同一篇研究论文（[https://arxiv.org/abs/2310.13548](https://arxiv.org/abs/2310.13548)）中，确定谄媚的后果，虽然起源于机器，可能导致对用户观点的不正确顺从、传播用户创建的错误和有偏见的回答。因此，GenAI并没有帮助创造一个更加事实和一致的世界理解，反而持续并可能加速了错误信息的传播。
- en: Researchers at Google DeepMind found that the problem grew worse as the model
    became bigger ([https://www.newscientist.com/article/2386915-ai-chatbots-become-more-sycophantic-as-they-get-more-advanced/](https://www.newscientist.com/article/2386915-ai-chatbots-become-more-sycophantic-as-they-get-more-advanced/)).
    LLMs with more parametric inputs had a greater tendency to agree with objectively
    false statements than smaller ones. This tendency held true even for mathematical
    equations, that is, questions where there is only one correct answer.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 谷歌DeepMind的研究人员发现，随着模型变得更大，问题变得更加严重（[https://www.newscientist.com/article/2386915-ai-chatbots-become-more-sycophantic-as-they-get-more-advanced/](https://www.newscientist.com/article/2386915-ai-chatbots-become-more-sycophantic-as-they-get-more-advanced/)）。具有更多参数输入的LLM更有可能同意客观上错误的陈述，而不是较小的LLM。这种倾向甚至适用于数学方程式，即只有一个正确答案的问题。
- en: LLMs are constantly learning, evolving, and being improved by their creators.
    In the future, perhaps LLMs will weigh the objective truth of a statement higher
    than the opinion or preferences of the user, but as of 2023, that is yet to happen.
    Ongoing research and testing will make them ever more adept at balancing user
    expectations, user opinions, and facts. Still, as of the time this book was written,
    sycophancy remains a primary concern with GenAI applications, particularly where
    the outputs consider opinions and user preferences before generating their response.
    Further testing using synthetic data and retraining models has reduced the tendency
    of sycophancy by up to 10%, which is still not 100% ([https://arxiv.org/abs/2308.03958](https://arxiv.org/abs/2308.03958)).
    This means that the tendency persists, even with fairly substantial modifications
    to the fine-tuning.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: LLM们不断学习、进化，并且被它们的创造者不断改进。在未来，也许LLM会更高地评价陈述的客观真实性，而不是用户的观点或偏好，但截至2023年，这还没有发生。持续的研究和测试将使它们在平衡用户期望、用户观点和事实方面变得更加熟练。然而，截至本书撰写时，谄媚仍然是GenAI应用的主要担忧，尤其是在输出在生成响应之前考虑用户观点和偏好的情况下。使用合成数据和重新训练模型进行的进一步测试将谄媚的倾向减少了高达10%，但这仍然不是100%（[https://arxiv.org/abs/2308.03958](https://arxiv.org/abs/2308.03958)）。这意味着即使经过相当大的微调修改，这种倾向仍然存在。
- en: Data leakage
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据泄露
- en: '**Data leakage**, in the context of GenAI, refers to situations where information
    from outside the desired training dataset is used to create the model, leading
    to overly optimistic performance metrics and potentially flawed or misleading
    predictions. This can happen at various stages of model development, from data
    collection to model evaluation, and can significantly compromise the validity
    of the AI system. There are multiple types of datasets with different purposes:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在生成式人工智能（GenAI）的背景下，**数据泄露**指的是使用来自期望训练数据集之外的信息来创建模型的情况，这可能导致过度乐观的性能指标，并可能产生有缺陷或误导性的预测。这种情况可能发生在模型开发的各个阶段，从数据收集到模型评估，可能会严重损害人工智能系统的有效性。存在多种类型的数据集，它们有不同的用途：
- en: Training datasets, which are used to train the LLM
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于训练LLM的训练数据集
- en: Fine-tuning datasets, which can be used to improve LLM responses and reduce
    hallucinations
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于改进LLM响应和减少幻觉的微调数据集
- en: Evaluation datasets, which can be useful in evaluating the accuracy of responses
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于评估响应准确性的评估数据集
- en: Causes of data leakage
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据泄露的原因
- en: 'The causes of data leakage are straightforward and easily avoided, as long
    as the developers of these applications are aware of these causes. First, let’s
    understand at a high level what leads to data leakage:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 数据泄露的原因简单明了，且易于避免，只要这些应用的开发者了解这些原因。首先，让我们从高层次上了解导致数据泄露的原因：
- en: '**Inappropriate dataset overlap**: Each dataset should be used at the appropriate
    training and evaluation stage. When this is not true, you have data leakage. For
    example, when the training dataset overlaps with the evaluation dataset, GenAI
    applications will, of course, perform better during testing because they already
    know the exact answers. In this scenario, your stock price predictor application
    would have had duplicated historical data points present in its training and evaluation
    datasets; therefore, its performance when testing its outputs will be unrealistically
    high because it has already seen the answers.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**不适当的dataset重叠**：每个数据集应适用于适当的训练和评估阶段。当这种情况不成立时，就会发生数据泄露。例如，当训练数据集与评估数据集重叠时，GenAI应用在测试期间的表现自然会更好，因为它们已经知道了确切的答案。在这种情况下，您的股价预测应用在其训练和评估数据集中会有重复的历史数据点；因此，在测试其输出性能时，其表现将不切实际地高，因为它已经看到了答案。'
- en: '**Future information**: Each dataset should only include information that would
    be available at the time of prediction. For instance, you would not include real
    or hypothetical information in your training dataset from a period in the future,
    or data that the model would not typically have access to in production.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**未来信息**：每个数据集应仅包含预测时可能可用的信息。例如，您不会在训练数据集中包含来自未来某个时期的真实或假设信息，或模型在生产中通常无法访问的数据。'
- en: '**Data normalization and transformation efforts**: When transformations or
    feature-engineering steps inadvertently introduce data from outside the training
    set, it is possible for information to leak from evaluation datasets into the
    training process. For GenAI, you want training data that is as close to *real
    life* as possible, both in terms of user interaction and whatever context the
    application will be operating within, so that your application has truly representative
    data.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据归一化和转换努力**：当转换或特征工程步骤意外地引入来自训练集之外的数据时，信息可能会从评估数据集泄露到训练过程中。对于GenAI，您希望训练数据尽可能接近*现实生活*，无论是从用户交互还是应用将运行在其内的任何上下文来看，这样您的应用就有真正代表性的数据。'
- en: To illustrate these causes, let’s use a hypothetical GenAI application that
    predicts stock prices upon request using historical data. In this scenario, it
    is May 2024, and your application is in the final testing phases. Before pushing
    to production, you’d like to determine how accurate its predictions are. You begin
    by checking your application’s response to the following user request.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明这些原因，让我们使用一个假设的GenAI应用，该应用根据请求使用历史数据预测股价。在这种情况下，现在是2024年5月，您的应用处于最终测试阶段。在推向生产之前，您想确定其预测的准确性。您首先检查应用对以下用户请求的响应。
- en: '**User request**:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**用户请求**：'
- en: '[PRE1]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '**Output answer**:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '**输出答案**：'
- en: '[PRE2]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'In this example, note the following:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，请注意以下内容：
- en: The **training** data fed to the model should **not** include any data points
    from May 2024.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型输入的**训练**数据不应包含任何来自2024年5月的数据点。
- en: The **evaluation** dataset should include all prices from May 2024 and could
    include the actual calculated value of the average stock price. This is because
    you would like to compare the model’s estimate to the actual value, and then give
    it a score for accuracy, then plot that month over month, in order to see whether
    the application consistently makes low or high estimates.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**评估**数据集应包括2024年5月的所有价格，并可能包括平均股价的实际计算值。这是因为您希望将模型的估计值与实际值进行比较，然后对其进行评分，然后按月绘制，以查看该应用程序是否始终做出低或高的估计。'
- en: If you’re trying for accuracy with your May 2024 estimate, but you’ve already
    fed it the May 2024 data in the training phase, this would be considered inappropriate
    dataset overlap. Let’s look at another example.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您试图在2024年5月的估计中追求准确性，但您已经在训练阶段提供了2024年5月的数据，这将被视为不适当的训练数据集重叠。让我们看看另一个例子。
- en: '**User request**:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '**用户请求**:'
- en: '[PRE3]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '**Output answer**:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '**输出答案**:'
- en: '[PRE4]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: You would not provide a training dataset that already includes an annual average
    because that information is not yet available. While you could include a year-to-date
    average in the training dataset, you should not include an annual average with
    synthetic or generated forward-looking data. If you created an estimated annual
    stock price and included that in the training data, then you would be using future
    information. Now, let’s consider a final example.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 您不会提供一个已经包含年度平均值的训练数据集，因为该信息尚未可用。虽然您可以在训练数据集中包含截至当年的平均数，但不应该包含带有合成或生成的前瞻性数据的年度平均值。如果您创建了一个估计的年度股价并将其包含在训练数据中，那么您就是在使用未来信息。现在，让我们考虑一个最终的例子。
- en: '**User request**:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '**用户请求**:'
- en: '[PRE5]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '**Output answer**:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '**输出答案**:'
- en: '[PRE6]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Notice how the user query is worded differently here as compared to the first
    example, though it leads to the same answer. LLMs are quite skilled at inferring
    user intention. Remember that users asking even fairly simple questions will phrase
    them in many different ways (*estimate*, *predict*, *forecast*, *imagine*, *guess*,
    and *projection* are all words they might use).
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，与第一个例子相比，这里用户查询的措辞有所不同，尽管它导致了相同的答案。LLMs在推断用户意图方面非常擅长。记住，即使是相当简单的问题，用户也会用许多不同的方式表达（*估计*、*预测*、*预测*、*想象*、*猜测*和*预测*都是他们可能使用的词语）。
- en: For your training dataset, you might include a prompt-and-answer pairing in
    the style of **frequently asked questions** (**FAQs**) for your entire support
    database. However, resist the urge to correct aspects such as wording and spelling.
    While you want to be aware of “garbage in, garbage out” problems, you do not want
    to shield your GenAI application so much that it won’t know how to respond when
    your users inevitably input garbage. This is particularly relevant for GenAI chatbots.
    Users have so many ways of asking a question. Those questions are presented usually
    without proper syntax, terminology, or contextual awareness, and their knowledge
    may also be outdated. Data normalization and transformation efforts should not
    normalize and cleanse your training data so much so that it becomes less useful.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 对于您的训练数据集，您可能包括一个针对整个支持数据库的提示-答案配对，其风格类似于**常见问题解答**（FAQs）。然而，请抵制纠正诸如措辞和拼写等方面的诱惑。虽然您希望意识到“垃圾输入，垃圾输出”的问题，但您不希望过度保护您的GenAI应用，以至于它不知道如何应对用户不可避免地输入垃圾的情况。这对于GenAI聊天机器人尤其相关。用户有无数种提问的方式。这些问题通常没有适当的语法、术语或上下文意识，他们的知识也可能过时。数据归一化和转换的努力不应使您的训练数据变得不那么有用。
- en: Implications of data leakage
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据泄露的影响
- en: The implications of data leakage vary widely, depending on whether you’ve leaked
    a teardrop or a waterfall. If there is data leakage, then the results of your
    GenAI evaluation and testing prior to production will be wrong and misrepresentative
    of your application’s actual performance, leading to overly optimistic tests or
    misleading conclusions. In all data overlap cases, the most obvious consequence
    of overlapping the training and test datasets is that the model may learn to simply
    *memorize* the training data and perform poorly on any new data from which it
    must make predictions.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 数据泄露的影响因情况而异，取决于您是否泄露了泪滴或瀑布。如果有数据泄露，那么您在生产前的GenAI评估和测试结果将是错误的，并且不能代表您应用程序的实际性能，导致过度乐观的测试或误导性的结论。在所有数据重叠的情况下，训练和测试数据集重叠的最明显后果是，模型可能会学会简单地*记忆*训练数据，并在任何必须从中做出预测的新数据上表现不佳。
- en: This can give application developers and testers a false sense of confidence
    in the model’s performance. Later, when real-world data is offered and users are
    asking questions in production, the application will perform markedly worse.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能会给应用程序开发人员和测试人员一种对模型性能的虚假自信。后来，当提供真实世界数据并且用户在生产环境中提出问题时，应用程序的表现将明显变差。
- en: 'Avoiding data leakage is simple, and it begins with splitting your datasets
    into distinct entities, then doing the following:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 避免数据泄露很简单，它从将你的数据集分割成不同的实体开始，然后执行以下操作：
- en: Ensure that training, validation, and test datasets are strictly separated.
    Use techniques such as time-based splitting for time-series data to prevent future
    information from leaking into the training set.
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保训练、验证和测试数据集严格分离。使用时间分割等技术来防止未来信息泄露到训练集中。
- en: Use tools to ensure that data transformations are only applied to the training
    set during model training and applied to the test set independently during evaluation.
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用工具确保数据转换仅在模型训练期间应用于训练集，并在评估期间独立应用于测试集。
- en: Engineer features in a way that prevents future data from being used. Avoid
    using future values or aggregated future statistics as part of your training data.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以一种防止未来数据被使用的方式来设计特征。避免将未来值或聚合的未来统计数据作为训练数据的一部分。
- en: Returning to the stock price prediction application, you would ideally want
    the data for your training and test sets to be based on time, ensuring that stock
    prices in the training set occur chronologically before those in the test set.
    Then, your application would only have features that were used in the historical
    stock data available up to the point of the stock price being predicted, marking
    a clear delineation between authentic prior stock prices and predicted future
    stock prices. Next, to validate your application, use time-based cross-validation
    to ensure that model performance is evaluated on data that simulates real-world
    prediction scenarios or the scenarios your application would allow.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 回到股价预测应用程序，理想情况下，你希望训练集和测试集中的数据基于时间，确保训练集中的股价按时间顺序发生在测试集中的股价之前。然后，你的应用程序将只具有在预测股价点之前的历史股价数据中使用的特征，这标志着真实历史股价和预测未来股价之间的明确界限。接下来，为了验证你的应用程序，使用基于时间的交叉验证来确保模型性能是在模拟真实世界预测场景或应用程序允许的场景的数据上评估的。
- en: By rigorously managing how data is handled throughout the model development
    process, you can minimize the risk of data leakage and ensure that your GenAI
    model provides reliable and valid predictions.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 通过严格管理模型开发过程中数据的处理方式，你可以最大限度地降低数据泄露的风险，并确保你的GenAI模型提供可靠和有效的预测。
- en: Cost
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 成本
- en: With so many distinct, complex, and potentially expensive moving parts, it is
    critical for engineers to know the costs of their GenAI application and how to
    contain these costs. While you will learn more about cost optimization strategies
    in [*Chapter 12*](B22495_12.xhtml#_idTextAnchor253), *Correcting and Optimizing
    Your Generative AI Application*, this section will serve as an introduction to
    understanding the financial costs of GenAI applications, which are in some ways
    different from web development applications.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 由于有如此多不同的、复杂的、可能昂贵的组成部分，工程师了解他们的GenAI应用程序的成本以及如何控制这些成本至关重要。虽然你将在[*第12章*](B22495_12.xhtml#_idTextAnchor253)“纠正和优化你的生成式AI应用程序”中学习更多关于成本优化策略，但本节将作为了解GenAI应用程序财务成本的一个介绍，这些成本在某些方面与Web开发应用程序不同。
- en: Types of costs
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 成本类型
- en: 'When using GenAI, costs can arise from several different areas. These costs
    can be broadly categorized into computational, storage, data acquisition, development,
    and maintenance costs:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用GenAI时，成本可能来自几个不同的领域。这些成本可以大致分为计算、存储、数据获取、开发和维护成本：
- en: '**Training costs**: Training GenAI models requires significant computational
    resources. This is especially true for large models such as GPT-4\. These resources
    often include **graphics processing units** (**GPUs**) or **tensor processing
    units** (**TPUs**), which are optimized for parallel processing tasks. The infrastructure
    to support these setups consumes a lot of electricity and requires cooling systems
    to maintain operational temperatures. Most engineers may not be in the position
    to pay these costs and, instead, will utilize models from vendors, such as OpenAI,
    Anthropic, Google, Meta, or others.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练成本**：训练GenAI模型需要大量的计算资源。这对于像GPT-4这样的大型模型尤其如此。这些资源通常包括**图形处理单元**（**GPU**）或**张量处理单元**（**TPU**），它们针对并行处理任务进行了优化。支持这些设置的基础设施消耗大量电力，并需要冷却系统以维持运行温度。大多数工程师可能无法承担这些费用，而是会利用来自供应商的模型，例如OpenAI、Anthropic、Google、Meta或其他。'
- en: '**Inference, or real-time computation**: Generating responses or outputs from
    a trained model, which is called **inference**, also incurs computational costs,
    especially for models that need to provide real-time answers. Bigger models cost
    more.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**推理，或实时计算**：从训练好的模型生成响应或输出，这被称为**推理**，也会产生计算成本，特别是对于需要提供实时答案的模型。更大的模型成本更高。'
- en: '**Storage costs**: Storing large datasets required for training GenAI models
    incurs costs. This includes raw data, preprocessed data, user interaction data,
    observability data, and the models themselves.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**存储成本**：存储用于训练GenAI模型的庞大数据集会产生成本。这包括原始数据、预处理数据、用户交互数据、可观察性数据以及模型本身。'
- en: '**Data collection**: Acquiring high-quality datasets can be expensive. This
    can include purchasing data from third-party providers or generating proprietary
    datasets.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据收集**：获取高质量数据集可能很昂贵。这可能包括从第三方提供商购买数据或生成专有数据集。'
- en: '**Data labeling and cleaning**: Preprocessing data to ensure it is suitable
    for training involves costs. This can include paying for human annotators to label
    data or developing algorithms to clean and prepare the data as either training
    or evaluation datasets.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据标注和清洗**：预处理数据以确保其适合训练涉及成本。这可能包括支付人工标注员对数据进行标注或开发算法以清理和准备数据作为训练或评估数据集。'
- en: '**Software development**: Writing and maintaining the code base for training
    and deploying GenAI applications requires skilled engineers and data analysts.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**软件开发**：编写和维护用于训练和部署GenAI应用的代码库需要熟练的工程师和数据分析师。'
- en: '**Experimentation and testing**: Developing GenAI often involves extensive
    experimentation and fine-tuning, which requires time and resources.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实验和测试**：开发GenAI通常涉及广泛的实验和微调，这需要时间和资源。'
- en: '**Data updates**: Training and evaluation datasets require periodic updates
    to maintain their accuracy and relevance, which involves additional computational
    and human resources.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据更新**：训练和评估数据集需要定期更新以保持其准确性和相关性，这涉及额外的计算和人力资源。'
- en: '**Monitoring and support**: The continuous monitoring of AI systems to ensure
    they are performing correctly and handling issues as they arise involves operational
    costs.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监控和支持**：持续监控AI系统以确保其正确运行并处理出现的问题涉及运营成本。'
- en: '**Compliance and security**: Ensuring data privacy and security and complying
    with regulations (such as GDPR) involves additional costs.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**合规性和安全性**：确保数据隐私和安全以及遵守法规（如GDPR）涉及额外的成本。'
- en: This is not an exhaustive list. Therefore, estimating your expected costs is
    complex and a non-trivial endeavor. But let’s hone in on the most important cost
    driver, which is text, and therefore tokens. Next, you will learn how to estimate
    and control costs here.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 这不是一个详尽的列表。因此，估计您预期的成本是复杂且非同寻常的任务。但让我们专注于最重要的成本驱动因素，即文本，因此是代币。接下来，您将学习如何在此处估计和控制成本。
- en: Tokens
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**代币**'
- en: LLMs process text using **tokens**, which are common sequences of characters
    found in a set of text. Tokens are the currency of the GenAI application. Each
    user input and output is a *token*, and both the question and response token count
    can be controlled. The cost per token is tiny. GenAI vendors look to make their
    money *per transaction*, which can add up quickly.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '**LLMs处理文本使用** **tokens**，这是在文本集中发现的常见字符序列。代币是GenAI应用的货币。每个用户输入和输出都是一个**token**，问题和响应的token计数都可以控制。每个token的成本极小。GenAI供应商寻求通过**每笔交易**赚钱，这可能会迅速累积。'
- en: Let’s understand this concept with an example. The statement `Hello how are
    you` is 5 tokens. A helpful rule of thumb is that one token generally corresponds
    to ~4 characters of text for common English text. This translates to roughly ¾
    of a word (so, 100 tokens ~= 75 words). The example of `Hello how are you` has
    18 characters including spaces, therefore 18/4 = 4.5, ergo 5 tokens.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用一个例子来理解这个概念。语句`Hello how are you`是5个token。一个有用的经验法则是，一个token通常对应于约4个字符的普通英文文本。这相当于大约3/4个单词（因此，100个token约等于75个单词）。`Hello
    how are you`这个例子包括空格在内的字符数为18个，因此18/4 = 4.5，所以是5个token。
- en: Each input and output for the GenAI application is reduced down to this simple
    unit of measurement.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: GenAI应用程序的每个输入和输出都被简化为这个简单的度量单位。
- en: ChatGPT and other LLMs have a token limit, thus capping how much text the user
    can enter as their prompt and limiting the output response. These limits, however,
    are generous. For most use cases, it is unlikely the average consumer would hit
    these limits.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT和其他LLM都有token限制，这限制了用户可以输入作为提示的文本量以及输出响应的限制。然而，这些限制是相当宽裕的。对于大多数用例，普通消费者不太可能达到这些限制。
- en: For instance, GPT-4 has a token limit of 32,768 per interaction and an estimated
    word count of 25,000 words, whereas Claude 3 (the LLM hosted by Anthropic) has
    a token limit of 100,000+ as of the time of writing. For a simple customer service
    chatbot, it is very unlikely that you would hit this limit, but it *is* possible.
    Let’s look at two examples to explain how this might be true.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，GPT-4每次交互的token限制为32,768个，估计的字数为25,000个单词，而Claude 3（Anthropic托管的大型语言模型）在撰写本文时token限制为100,000+。对于一个简单的客户服务聊天机器人，您不太可能达到这个限制，但这是可能的。让我们看看两个例子来解释这可能是如何成立的。
- en: '**Example 1**: A customer asks a GenAI chatbot a simple question.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例 1**：一位客户向GenAI聊天机器人提出一个简单的问题。'
- en: '**Inquiry**:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '**询问**:'
- en: '[PRE7]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '**Response**:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '**响应**:'
- en: '[PRE8]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The initial inquiry is 36 characters and 7 tokens. The response is 162 tokens,
    or 741 characters. If you were to have interactions limited to 300 tokens, you
    would still be well under the limit that you have allowed for your users.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 初始询问为36个字符和7个token。响应为162个token，或741个字符。如果您将交互限制在300个token以内，您仍然远远低于您为用户允许的限制。
- en: '**Example 2**: A server experiences an out-of-memory error, and the GenAI automatically
    analyzes the stack traces and logs an analysis for a human to review later.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例 2**：一个服务器遇到了内存不足错误，GenAI自动分析堆栈跟踪并记录分析供人类稍后审查。'
- en: '**Inquiry**:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '**询问**:'
- en: '[PRE9]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '**Response**:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '**响应**:'
- en: '[PRE10]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This analyzer is useful to a diagnostics engineer, as the analyzer quickly reviews
    a stack trace, summarizes its findings, and generates recommendations for solving
    the issue.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 这个分析器对诊断工程师很有用，因为它可以快速审查堆栈跟踪，总结其发现，并为解决问题提供建议。
- en: However, the prompt is 275 tokens (1,240 characters), and the response is 248
    tokens (1,205 characters). As this is a sample stack trace, the real-life implementation
    would possibly be more detailed with real information. So, if the control setting
    was still 300 tokens for input or output, you would be quite close to this limit
    already.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，提示词长度为275个token（1,240个字符），而响应长度为248个token（1,205个字符）。由于这是一个示例堆栈跟踪，实际应用中的实现可能会包含更详细的真实信息。因此，如果控制设置仍然是输入或输出300个token，那么您已经非常接近这个限制。
- en: Choosing the input and output token limits for your application is critically
    important. While you want to control costs, you also do not want to fundamentally
    limit functionality. If the token limit is too low, the LLM may not be able to
    generate the desired output.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 为您的应用程序选择输入和输出token限制至关重要。虽然您希望控制成本，但您也不希望从根本上限制功能。如果token限制太低，LLM可能无法生成所需的输出。
- en: Performance issues in generative AI applications
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成式AI应用中的性能问题
- en: The most obvious failures of GenAI are performance- and reliability-related
    issues. Since you’ve learned about accuracy in [*Chapter 10*](B22495_10.xhtml#_idTextAnchor214),
    *Refining the Semantic Data Model to Improve Accuracy*, performance in this chapter’s
    context means slowness. If a user asks your AI application a question and there
    is either no response, a metered response, or a partial response, it is typically
    much more apparent than if the response was hallucinated or sycophantic.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: GenAI最明显的失败是性能和可靠性相关的问题。既然您已经学习了关于准确性的内容[第10章](B22495_10.xhtml#_idTextAnchor214)，*通过优化语义数据模型提高准确性*，在本章的上下文中，性能意味着速度慢。如果用户向您的AI应用程序提出问题，并且没有响应、部分响应或响应缓慢，这通常比如果响应是虚构的或谄媚的更为明显。
- en: Several factors can contribute to the slowness of a GenAI application. Some
    of the most common causes of performance issues in GenAI are computational load,
    network latency, model serving strategies, and high **input/output** (**I/O**)
    operations.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 几个因素可能导致GenAI应用程序的缓慢。GenAI中性能问题最常见的几个原因包括计算负载、网络延迟、模型服务策略以及高**输入/输出**（**I/O**）操作。
- en: There can be many more causes, of course. The rest of this section will explain
    some of these performance killers in detail and their impact on your application
    and users.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，可能还有更多原因。本节剩余部分将详细解释一些性能杀手，以及它们对您的应用程序和用户的影响。
- en: Computational load
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 计算负载
- en: As you already know, LLMs require significant computational power. The time
    required to generate responses to queries increases with the complexity and the
    size of the model. Poorly formed requests significantly increase the computational
    load for a GenAI application. Let’s look at a few examples of this so that you’re
    able to understand how this failure mode can happen.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所知，LLMs需要大量的计算能力。生成查询响应所需的时间随着模型复杂性和规模的增加而增加。不恰当的请求会显著增加GenAI应用程序的计算负载。让我们看看几个这样的例子，以便您能够理解这种故障模式是如何发生的。
- en: Extensive data processing and calculations
  id: totrans-139
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 大量的数据处理和计算
- en: Requests that require processing large datasets or performing extensive calculations
    can be computationally demanding, as happens in the following example.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 需要处理大量数据集或执行大量计算的请求可能会带来计算上的负担，以下是一个例子。
- en: '**User request**:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '**用户请求**：'
- en: '[PRE11]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Fetching 20,000 random stock prices sounds simple, but the user does not specify
    a timeframe. For what period should the model evaluate the last 20,000 stock prices?
    Over the last month? Last year at random? The sorting of those values is computationally
    expensive and adds further processing to the returned list.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 获取20,000条随机股票价格看似简单，但用户没有指定时间范围。模型应该评估最后20,000条股票价格的哪个时间段？是过去一个月？还是去年随机选取的时间段？对这些值的排序计算成本高昂，并进一步增加了返回列表的处理负担。
- en: High-complexity requests
  id: totrans-144
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 高复杂度请求
- en: Complex requests that involve evaluating a large amount of data, summarizing,
    and then returning many results are also taxing. Often, this involves chaining
    multiple LLM calls through advanced prompting techniques, such as the ReACT pattern
    and function calling.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 涉及评估大量数据、总结并返回大量结果的复杂请求也很耗费资源。通常，这涉及到通过高级提示技术，如ReACT模式和函数调用，链式调用多个LLM。
- en: The **reasoning and acting** (**ReACT**) pattern is an advanced prompting technique
    used in GenAI models to handle complex tasks that require multiple steps of reasoning
    and interaction. This pattern involves a sequence where the model reasons about
    the task, generates intermediate actions, and then produces the final output.
    The ReACT pattern helps the model break down complex requests into manageable
    steps, improving accuracy and coherence in the final response.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '**推理和行动**（**ReACT**）模式是GenAI模型中用于处理需要多个推理和交互步骤的复杂任务的高级提示技术。这个模式涉及一个序列，其中模型对任务进行推理，生成中间动作，然后产生最终输出。ReACT模式帮助模型将复杂请求分解为可管理的步骤，提高最终响应的准确性和连贯性。'
- en: '**Function calling** in the context of LLMs involves instructing the model
    to execute specific functions or actions as part of its response generation process.
    This can be particularly useful for tasks that require structured outputs, calculations,
    data retrieval, or interactions with external systems. As an example, the developer
    specifies functions within the prompt that the model can call to perform specific
    tasks. These functions are predefined and can handle various operations, such
    as querying databases, performing calculations, or fetching external data.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在LLMs的上下文中，**函数调用**涉及指示模型在其响应生成过程中执行特定的函数或动作。这对于需要结构化输出、计算、数据检索或与外部系统交互的任务特别有用。例如，开发者可以在提示中指定模型可以调用的函数来执行特定任务。这些函数是预定义的，可以处理各种操作，如查询数据库、执行计算或获取外部数据。
- en: Let’s look at a high-complexity request to illustrate this.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个高复杂度的请求来阐述这一点。
- en: '**User request**:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '**用户请求**：'
- en: '[PRE12]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: In this scenario, the GenAI must first create the list of every US president,
    then seek information about each one, and then create a detailed summary of their
    policies and events during their terms in office. It must also retrieve content
    related to which things the presidents prioritized, identify consensus on what
    pieces of content were the top priorities, compile and summarize all that information,
    and then output it to the user. This is extensive knowledge retrieval, analysis,
    and text generation. Most likely, this information would require multiple LLM
    queries, and more queries equate to more spend.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，GenAI 必须首先创建每位美国总统的名单，然后寻找每位总统的信息，接着创建他们在任期间政策和事件的详细总结。它还必须检索与总统优先考虑的事项相关的内容，确定哪些内容是最高优先级的共识，整理并总结所有这些信息，然后输出给用户。这是广泛的知识检索、分析和文本生成。很可能会需要多个
    LLM 查询，而更多的查询意味着更多的开销。
- en: These examples illustrate how certain types of user requests can significantly
    increase the computational load for GenAI applications. Let’s now see how model
    serving strategies can impact GenAI performance.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 这些例子说明了某些类型的用户请求如何显著增加 GenAI 应用程序的计算负载。现在让我们看看模型服务策略如何影响 GenAI 的性能。
- en: Model serving strategies
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型服务策略
- en: Generating responses for every request individually can be inefficient, depending
    on volume. If the application is not designed to handle multiple requests concurrently,
    it will become slower the more users you have. If the application relies on cloud-based
    services, network latency can affect performance. Slow internet connections or
    high latency between the client and the server can cause delays. Frequent or complex
    API calls to external services can add to the response time, especially if those
    services are experiencing a high load or are geographically distant.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 根据请求量，为每个请求单独生成响应可能效率低下。如果应用程序没有设计成可以同时处理多个请求，那么随着用户数量的增加，它将变得越来越慢。如果应用程序依赖于云服务，网络延迟会影响性能。客户端和服务器之间慢速的互联网连接或高延迟会导致延迟。频繁或复杂的
    API 调用到外部服务会增加响应时间，尤其是如果这些服务正在经历高负载或地理位置遥远。
- en: Let’s return to the stock predictor application for an example.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以股票预测应用程序为例。
- en: Because your GenAI application receives some news coverage, your website experiences
    a surge in traffic, and the number of customers interacting with the application
    increases dramatically. But, since your application handles each request individually
    and cannot process multiple requests concurrently, the response time for each
    user increases as the system becomes overwhelmed. Users experience slower response
    times, leading to frustration.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 由于您的 GenAI 应用程序获得了一些新闻报道，您的网站流量激增，与应用程序互动的客户数量急剧增加。但是，由于您的应用程序逐个处理每个请求并且无法同时处理多个请求，随着系统变得不堪重负，每个用户的响应时间都会增加。用户会体验到更慢的响应时间，从而导致挫败感。
- en: The news coverage was from an influencer in Sydney, Australia, so the surge
    in users is from Asia. Your servers are in the US East region, and network latency
    due to the geographical distance between the server and the clients causes delays.
    Customers with slow internet connections experience even longer wait times, further
    degrading the user experience.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 新闻报道来自澳大利亚悉尼的一位有影响力的人物，因此用户激增来自亚洲。您的服务器位于美国东部地区，由于服务器和客户端之间的地理距离，网络延迟导致延迟。互联网连接速度慢的客户体验到的等待时间更长，进一步降低了用户体验。
- en: Your application frequently calls external APIs to fetch real-time data for
    stock prices and financial market news. If these external services are experiencing
    high load, the API calls take longer to complete.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 您的应用程序经常调用外部 API 来获取股票价格和金融市场新闻的实时数据。如果这些外部服务正在经历高负载，API 调用将需要更长的时间才能完成。
- en: High I/O operations
  id: totrans-159
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 高 I/O 操作
- en: 'Poor data-handling practices, such as reading large datasets inefficiently
    or not using appropriate data structures, can slow down performance. Frequent
    read/write operations to disk can be a bottleneck, as can poorly optimized database
    interactions and malformed queries. The example stock price predictor application
    frequently reads large historical stock price datasets to make predictions. Let’s
    walk through some potential issues with data handling that result in high I/O
    operations:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 不良的数据处理实践，如低效地读取大型数据集或未使用适当的数据结构，可能会降低性能。频繁的磁盘读写操作可能成为瓶颈，同样，数据库交互优化不良和查询格式错误也可能导致问题。示例股价预测应用程序经常读取大量历史股价数据集进行预测。让我们探讨一些数据处理问题，这些问题会导致高I/O操作：
- en: The application reads large datasets inefficiently, such as loading the entire
    dataset into memory even when only a subset is needed, which consumes excessive
    memory and processing power, slowing down performance.
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该应用程序读取大型数据集效率低下，例如，即使只需要子集，也会将整个数据集加载到内存中，这消耗了过多的内存和计算能力，降低了性能。
- en: The application saves intermediate prediction results and logs to disk after
    every prediction cycle. Frequent read/write operations to disk form a bottleneck,
    which significantly increases the time it takes to complete each prediction cycle.
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该应用程序在每次预测周期结束后将中间预测结果和日志保存到磁盘。频繁的磁盘读写操作形成瓶颈，这显著增加了完成每个预测周期所需的时间。
- en: The application queries a database to fetch recent financial news and other
    relevant data before making predictions. However, a lack of indexes means that
    query results are slowly delivered. This increases response times, making the
    application slow to respond to user requests.
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在做出预测之前，该应用程序会查询数据库以获取最近的财经新闻和其他相关数据。然而，缺乏索引意味着查询结果缓慢返回。这增加了响应时间，使得应用程序对用户请求的响应速度变慢。
- en: Assuming you have a large dataset, you’ll want to avoid these practices as they
    will affect user experience and increase costs.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你有一个大型数据集，你将想要避免这些做法，因为它们会影响用户体验并增加成本。
- en: Summary
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Now that you have navigated through these GenAI challenges, you can appreciate
    some of the complexities and nuances that accompany these powerful technologies.
    The issues of hallucinations, sycophancy, data leakage, cost, and performance
    present formidable obstacles that demand a critical eye and innovative solutions.
    Each challenge offers a unique perspective on the limitations and potential pitfalls
    inherent in GenAI applications.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经通过了这些GenAI挑战，你可以欣赏到这些强大技术所伴随的一些复杂性和细微差别。幻觉、谄媚、数据泄露、成本和性能问题构成了巨大的障碍，需要批判性的眼光和创新解决方案。每个挑战都为GenAI应用程序固有的局限性和潜在陷阱提供了独特的视角。
- en: 'Despite these hurdles, GenAI remains unequivocally valuable. It continues to
    transform industries, enhance productivity, and open new avenues for creativity
    and innovation. By understanding and addressing these challenges, developers can
    harness the full potential of GenAI, delivering robust, reliable, and responsible
    applications. At the same time, it’s also important to note that applications
    can be useful even when they are not always correct. To take ChatGPT as an example:
    it has greatly improved the productivity of millions of users already, even though
    its deficiencies are well-known (and some not so easily worked around). Your GenAI
    application could be just as useful and popular but with similar caveats.'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管存在这些障碍，GenAI仍然无可争议地具有价值。它继续改变行业，提高生产力，并为创造力和创新开辟新的途径。通过理解和解决这些挑战，开发者可以充分发挥GenAI的潜力，提供强大、可靠和负责任的应用程序。同时，也要注意，即使应用程序不总是正确，它们也可能是有用的。以ChatGPT为例：它已经极大地提高了数百万用户的效率，尽管其缺陷是众所周知的（而且有些并不容易解决）。你的GenAI应用程序也可能同样有用和受欢迎，但同样存在类似的警告。
- en: In the next chapter, you’ll look at ways to optimize your GenAI application,
    improving its outputs and performance for a better user experience as well as
    combatting some of the issues discussed here.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，你将了解优化你的GenAI应用程序的方法，提高其输出和性能，从而改善用户体验，并解决这里讨论的一些问题。
