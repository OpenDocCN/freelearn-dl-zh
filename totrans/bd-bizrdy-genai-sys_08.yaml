- en: '8'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: GenAISys for Trajectory Simulation and Prediction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As AI’s role continues to expand, trajectory analysis has permeated all human
    activity, from pizza deliveries to genome sequencing. This chapter introduces
    city-scale mobility prediction, highlighting how missing or noisy coordinates
    can undermine real-world applications in deliveries, disaster management, urban
    planning, and epidemic forecasting. The architecture of our mobility system draws
    inspiration from the innovative work of Tang et al. (2024).
  prefs: []
  type: TYPE_NORMAL
- en: We will first build and integrate an advanced trajectory simulation and prediction
    pipeline into our GenAISys using the `1_Trajectory_simulation_and_prediction.ipynb`
    notebook. The main objective is to address the challenge of modeling human mobility,
    both short- and long-term, by leveraging synthetic data generation and **large
    language models** (**LLMs**). We then demonstrate how to build upon this idea
    using Python-based solutions, complete with a custom synthetic grid generator
    that simulates random trajectories through a two-dimensional city map, deliberately
    inserting missing data for testing. These random trajectories could represent
    deliveries or other sequences, such as travel packages (custom bags or booklets)
    for an online travel agency.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will build a multistep orchestrator function that merges user instructions,
    the synthetic dataset, and domain-specific messages before passing them to an
    LLM-driven reasoning thread. The model will detect and predict unknown positions
    marked by placeholder values (such as `999, 999`), filling these gaps through
    contextual interpolation. This approach demonstrates the interpretability of text-based
    predictions while maintaining a systematic chain of thought, including debugging
    steps such as logging missing points before producing the final JSON output.
  prefs: []
  type: TYPE_NORMAL
- en: To support robust user interaction, we will integrate the trajectory pipeline
    into the GenAISys multihandler environment we’ve built, allowing requests for
    “mobility” instructions to trigger the creation and analysis of trajectories.
    We will implement a trajectory simulation and prediction interface. Visualization
    components are incorporated, automatically producing and displaying the resulting
    path (including direction arrows, missing data markers, and coordinate fixes)
    as a static image. The synergy between data generation, LLM inference, and the
    user interface showcases the end-to-end viability of our method, empowering users
    to apply trajectory simulation and prediction across different domains as needed.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter provides a blueprint for coupling synthetic trajectory datasets
    with a prompt-driven LLM approach in the GenAISys. By following the design patterns
    described by Tang et al., we will explore how purely text-oriented models can
    excel at spatial-temporal reasoning with minimal structural modifications. Bridging
    mobility simulation and user-friendly interfaces can provide highly interpretable,
    fine-grained predictions for a variety of mobility analytics scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter covers the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Trajectory simulations and predictions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building a trajectory simulation and prediction function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adding mobility intelligence to the GenAISys
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running the mobility-enhanced GenAISys
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s begin by defining the scope of the trajectory simulation and prediction
    framework.
  prefs: []
  type: TYPE_NORMAL
- en: Trajectory simulations and predictions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section is inspired by *Instruction-Tuning Llama-3-8B Excels in City-Scale
    Mobility Prediction* by Tang et al. (2024). We will explore the essential background
    on the challenges of human mobility prediction, the paper’s key contributions,
    and how these ideas can be translated into practical Python implementations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Human mobility prediction focuses on forecasting where and when individuals
    (or groups) will travel, and it plays a critical role in an expanding set of domains,
    including the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Disaster response**, for predicting the paths of wildfires, population movements
    during crises, or the impacts of earthquakes'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Urban planning**, for modeling short- and long-term mobility patterns to
    help city planners optimize public transport and infrastructure'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Epidemic forecasting**, for simulating and predicting the spread of infectious
    diseases in a region'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In our case, we will first apply mobility prediction to the delivery of customized
    products (e.g., bags, T-shirts, and booklets) for an online travel agency’s customers.
  prefs: []
  type: TYPE_NORMAL
- en: Traditionally, these predictions relied on specialized machine learning models,
    such as **recurrent neural networks** (**RNNs**) with attention mechanisms or
    **graph neural networks** (**GNNs**). While these techniques can be effective,
    they often require labor-intensive feature engineering and are not easily generalizable
    across diverse locations or time horizons (e.g., short-term versus long-term predictions).
  prefs: []
  type: TYPE_NORMAL
- en: Let’s now examine the key challenges motivating the use of LLMs to address these
    issues.
  prefs: []
  type: TYPE_NORMAL
- en: Challenges in large-scale mobility forecasting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Cutting-edge LLMs offer promising solutions to several challenges that have
    historically plagued traditional mobility analysis and prediction systems:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Long-term versus short-term forecasts**: Predicting the next few steps (short-term)
    often relies on temporal recurrences and immediate contextual information. However,
    extending this to multi-day, city-scale horizons introduces additional complexities,
    such as changes in user behavior, variations in daily routines, holidays, or unexpected
    events.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Generalization across cities**: A model trained on data from City A may fail
    when exposed to the unique geography, population density, or cultural travel habits
    of City B. True city-scale mobility solutions must be robust enough to handle
    these differences.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Computational constraints**: Real-world mobility datasets, especially those
    representing entire metropolitan areas, can be enormous. Training sophisticated
    deep learning models or LLMs can become computationally expensive.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data quality and missing data**: Large-scale mobility datasets often have
    noise or missing coordinates. Handling “gaps” in user trajectories (e.g., from
    GPS dropout or anonymization processes) is a significant challenge.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While LLMs are not perfect, they provide an effective alternative to traditional
    models by addressing these key obstacles with minimal manual feature engineering.
    Let’s see how.
  prefs: []
  type: TYPE_NORMAL
- en: From traditional models to LLMs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The journey from traditional approaches to LLMs can be traced through a few
    groundbreaking shifts. Traditional approaches consumed extensive human resources
    to design heuristics, engineer features, and implement complex domain-specific
    solutions. In contrast, recent breakthroughs in generative AI—such as Llama 3,
    GPT-4o, Grok 3, DeepSeek-V3, and DeepSeek-R1—have opened exciting new avenues
    in reasoning and multimodal machine intelligence. And make no mistake—this is
    just the beginning! Recent research highlights how these models can generalize
    well beyond text-based tasks, excelling in the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Time-series prediction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zero-shot or few-shot adaptation to new tasks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data preprocessing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recent research has shown that LLMs, when guided by carefully crafted prompts
    or lightweight fine-tuning, can even surpass specialized models in city-scale,
    long-horizon trajectory prediction. In this chapter, we’ll demonstrate effective
    results with zero-shot prompting—without any additional fine-tuning—using GPT-4o.
  prefs: []
  type: TYPE_NORMAL
- en: To understand this promising direction clearly, however, let’s first examine
    the key contributions of the paper that served as a basis for this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Key contributions of the paper
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It took a team consisting of Tang, P., Yang, C., Xing, T., Xu, X., Jiang, R.,
    and Sezaki, K. (2024) to take LLMs to the next level through three pivotal innovations.
  prefs: []
  type: TYPE_NORMAL
- en: Reformulating trajectory prediction as a Q&A
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Instead of passing raw coordinate sequences into a standard regression or classification
    model, the authors transform the input into a question that includes the following:'
  prefs: []
  type: TYPE_NORMAL
- en: An **instruction block** clarifying the domain context (city grid, coordinate
    definitions, day/time indexing)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A **question block** providing historical mobility data with placeholders for
    missing locations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A request to generate the prediction results in a predefined, structured JSON
    format
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This Q&A style leverages the LLM’s inherent ability to read instructions and
    produce structured outputs.
  prefs: []
  type: TYPE_NORMAL
- en: Then, they fine-tuned the LLM.
  prefs: []
  type: TYPE_NORMAL
- en: Instruction tuning for domain adaptation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Instruction tuning** is a technique where the LLM is fine-tuned with carefully
    designed prompts and answers, teaching it to produce domain-specific outputs while
    still retaining its general language reasoning capabilities. The authors showcase
    that even if you use only a fraction of the mobility dataset for fine-tuning,
    the model can still generalize to new users or new cities. In our case, we attained
    acceptable results without a dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: Surprisingly enough, as we will see when we build the Python program in the
    *Building the trajectory simulation and prediction function* section, we achieve
    strong results even with a zero-shot, no-fine-tuning approach, leveraging GPT-4o’s
    exceptional reasoning capability without needing any domain-specific fine-tuning
    data.
  prefs: []
  type: TYPE_NORMAL
- en: The mobility research team then solved the issue of missing data.
  prefs: []
  type: TYPE_NORMAL
- en: Handling missing data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A common challenge in mobility datasets is the presence of missing coordinates,
    typically marked with placeholder values such as `999`. The LLM-based system is
    tasked explicitly with filling in these gaps, effectively performing spatiotemporal
    imputation. Naturally, this approach is not without limitations, which we’ll clearly
    illustrate through practical examples when we run our mobility simulation. But
    before exploring these boundaries, let’s first dive into building our solution.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will develop a trajectory (mobility) simulation and
    analysis component using OpenAI models. We will then integrate this mobility function
    into **Layer 3** of our GenAISys, as illustrated in *Figure 8.1* with function
    **F4.1**. We will also update **Layer 2** to register the handler and ensure it
    can be activated at the IPython interface level in **Layer 1**.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.1: Integrating trajectory simulations and predictions](img/B32304_08_1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.1: Integrating trajectory simulations and predictions'
  prefs: []
  type: TYPE_NORMAL
- en: Once the trajectory simulation and prediction component is integrated into our
    GenAISys, it can be applied to deliveries and a wide range of mobility-related
    tasks. We will start by modeling the delivery of customized goodies—such as branded
    bags, T-shirts, and booklets—for customers of an online travel agency, and then
    explore other potential applications. For now, let’s build our trajectory simulation!
  prefs: []
  type: TYPE_NORMAL
- en: Building the trajectory simulation and prediction function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The goal of this section is to create a robust trajectory simulation, prepare
    the predictive functions, and run an OpenAI LLM to analyze synthetic trajectory
    data and predict missing coordinates. Later, in the *Adding mobility intelligence
    to the GenAISys* section, we’ll integrate this into our comprehensive GenAISys
    framework.
  prefs: []
  type: TYPE_NORMAL
- en: 'Open the `1_Trajectory_simulation_and_prediction.ipynb` notebook within the
    Chapter08 directory on GitHub ([https://github.com/Denis2054/Building-Business-Ready-Generative-AI-Systems/tree/main](https://github.com/Denis2054/Building-Business-Ready-Generative-AI-Systems/tree/main)).
    The initial setup mirrors the environment configuration in `Chapter07/GenAISys_DeepSeek.ipynb`
    and includes the following:'
  prefs: []
  type: TYPE_NORMAL
- en: File downloading script
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: OpenAI setup
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chain-of-thought environment setup
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We will build the program in three main steps, as shown in *Figure 8.2*:'
  prefs: []
  type: TYPE_NORMAL
- en: Creating the grid and trajectory simulation to generate real-time synthetic
    data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a mobility orchestrator that will call the trajectory simulation, import
    the messages for the OpenAI model, and call the analysis and prediction messages
    for the OpenAI model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Leveraging OpenAI’s model for trajectory analysis and predictions, called via
    the mobility orchestrator
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The mobility orchestrator will be added to the handlers registry in our GenAISys
    in the *Adding mobility intelligence to the GenAISys* section and managed by the
    handler selection mechanism when activated by the IPython interface. In this section,
    we will call the mobility orchestrator directly.
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 8.2* articulates the relationship between the mobility orchestrator,
    the trajectory simulator, and the generative AI predictor. This mixture of agents
    maintains close alignment with the framework of trajectory analysis and predictions.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.2: The functions of the mobility orchestrator](img/B32304_08_2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.2: The functions of the mobility orchestrator'
  prefs: []
  type: TYPE_NORMAL
- en: We will first begin by creating the trajectory simulation.
  prefs: []
  type: TYPE_NORMAL
- en: Creating the trajectory simulation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The reference paper by Tang et al. demonstrates how an LLM can be instruction-tuned
    to fill missing trajectory coordinates and predict future positions in a grid-based
    city map. Note that in our case, we will leverage the power of the OpenAI API
    message object to achieve an effective result with zero-shot prompts in real time,
    within the framework of the paper.
  prefs: []
  type: TYPE_NORMAL
- en: One important step in their methodology involves having *(day, timeslot, x,
    y)* records, with some coordinates possibly missing (e.g., `999, 999`) to indicate
    unknown positions.
  prefs: []
  type: TYPE_NORMAL
- en: 'The function that we will write, `create_grid_with_trajectory()`, essentially
    simulates a smaller-scale version of this scenario by doing the following:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Generate a two-dimensional grid representing a city (default: 200×200).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create random agent trajectories within the grid over a certain number of points.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Intentionally insert missing coordinates (marked as `(999, 999)`) to simulate
    real-world data gaps.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Plot and save the trajectory visualization, highlighting direction with arrows
    and labels for missing data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'This kind of synthetic generation is useful for testing or proof-of-concept
    demos, echoing the spirit of the paper:'
  prefs: []
  type: TYPE_NORMAL
- en: You have grid-based data, like the 200×200 city model used in the article
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You inject missing values (`999, 999`), which the LLM or another model can later
    attempt to fill in
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let’s now go through the trajectory simulation function step by step:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s first initialize the function with its parameters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The parameters are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`grid_size=200`: The size of the grid along one axis (so the grid is 200×200)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_points=50`: How many trajectory points (or steps) will be generated'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`missing_count=5`: How many of those points will be deliberately turned into
    missing coordinates (`999, 999`)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We now create the grid:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`grid = np.zeros((grid_size, grid_size), dtype=int)` creates a two-dimensional
    array of zeros (of the `int` type). Think of `grid[x][y]` as the status of that
    cell, initially 0.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`trajectory = []:` will hold tuples of the form *(day, timeslot, x, y)*.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: This mirrors the discretized city concept in the paper, where each *(x, y)*
    cell might represent a zone within the city.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now set the initial state of the agent:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**Random start**: The agent’s initial location *(x, y)* is chosen randomly
    anywhere on the grid.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Time setup**: A random day between 1 and 365 and a random timeslot between
    0 and 47 is selected, aligning with the paper’s time-slicing approach, where each
    day is divided into multiple discrete time slots.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We now determine the movement directions and turn probability:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This structure is a classical mobility agent framework:'
  prefs: []
  type: TYPE_NORMAL
- en: '`directions`: Represents four possible directions—up, right, down, and left.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`current_dir_index`: Picks which of the four directions the agent faces initially.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`turn_weights`: Probability distribution dictating how likely the agent is
    to turn left (`-1`), go straight (`0`), or turn right (`1`) at each step. In our
    case, there is a 15% chance of turning left, a 70% chance of continuing, and a
    15% chance of turning right. This introduces randomness in how the agent moves
    and is a simple approximation of human or agent-like mobility patterns.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We are ready to generate the trajectory:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s go through the actions of our virtual agent:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Choosing a turn**: Based on `turn_weights`, the agent randomly decides whether
    to continue in the same direction, turn left, or turn right.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Updating the coordinates**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dx`, `dy` are the increments along *x* and *y* for the chosen direction.'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The new location, `(new_x, new_y)`, is computed.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Checking the boundary conditions**: If `(new_x, new_y)` is outside `[0, grid_size-1]`,
    the code finds a valid direction or reverts to the old position to keep the agent
    inside the grid.'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Recording the trajectory**:'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`(day, timeslot, x, y)` is appended to `trajectory`.'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Mark `grid[x, y]` as `1`, signifying a visited cell.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Updating the time**: `timeslot = (timeslot + random.randint(1, 3)) % 48`:
    The timeslot jumps from 1 to 3 steps, staying in `[0, 47]`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We now need to introduce the missing data, which will be the basis for the
    generative AI predictions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The missing points are determined in two steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Selecting the missing points**: Randomly choose `missing_count` points from
    the total `num_points` of the trajectory.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Replacing the missing points with 999, 999**: For each chosen index, replace
    the valid `(x, y)` with `999, 999`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the paper, the authors define `999, 999` as the signal for unknown or missing
    coordinates that the LLM must later fill in. This code snippet simulates exactly
    that scenario—some coordinates go missing, requiring an imputation or prediction
    step.
  prefs: []
  type: TYPE_NORMAL
- en: We want to add a visualization function next that will help the user to see
    the trajectory and its missing points.
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing the trajectory simulator
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We will plot the grid and trajectory in Matplotlib:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s go through the visualization process:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Coordinates for plotting**: Converts missing `999, 999` values into `np.nan`
    so that Matplotlib will break the line and not connect them visually'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Plotting with colors, arrows, and text**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The trajectory line is drawn in blue.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Quiver arrows (`plt.quiver`) show the direction from each point to the next.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Missing data points are highlighted with an `'X'` marker in magenta.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Titles and axes**: Labeling and legend for clarity'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Save and close**: Saves the figure as `mobility.png`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Such plotting mirrors the style in the paper’s *Case Study* section (*Section
    4.4*), where the authors compare real versus predicted trajectories. Here, you’re
    simply illustrating the synthetic path as well as the visual indications of missing
    data.
  prefs: []
  type: TYPE_NORMAL
- en: Output of the simulation function
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The output of the function that we will process contains the grid and the trajectory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'These two variables will contain what our generative AI model needs to make
    a prediction:'
  prefs: []
  type: TYPE_NORMAL
- en: '`grid`: A two-dimensional array marking the visited path'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`trajectory`: A list of *(day, timeslot, x, y)* tuples, with some replaced
    with `999, 999`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This final result will be fed into an LLM-based approach (such as the one described
    in the paper) with an OpenAI generative AI model that can produce an acceptable
    output in a zero-shot process. We will now begin to process the trajectory simulation.
  prefs: []
  type: TYPE_NORMAL
- en: Creating the mobility orchestrator
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The trajectory simulation has generated the grid, the trajectory, and the missing
    coordinates in the trajectory. We will now develop the orchestrator function that
    integrates both the trajectory simulation and the predictive capabilities of the
    OpenAI model. We’ll call this orchestrator `handle_mobility_orchestrator()`.
  prefs: []
  type: TYPE_NORMAL
- en: 'This orchestrator aligns with the method outlined by Tang et al. (2024) in
    their paper *Instruction-Tuning Llama-3-8B Excels in City-Scale Mobility Prediction*.
    Its purpose is straightforward yet powerful, performing three critical functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Generating synthetic mobility data**: It invokes the `create_grid_with_trajectory
    ()` function to simulate a trajectory with possible missing points'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Preparing data for an LLM call**: It formats the new trajectory data into
    a JSON string, appends it to the user’s message, and then calls the reasoning
    function—presumably the LLM-based solution or orchestration logic (`reason.mobility_agent_reasoning_thread()`)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Returning a structured response**: It returns the final results clearly (`reasoning_steps`),
    to include both the newly generated trajectory data and the LLM reasoning steps'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This approach remains true to the *Instruction-Tuning Llama-3-8B Excels in City-Scale
    Mobility Prediction* paper, where the authors emphasize creating structured input
    data—such as trajectories with missing points—and then passing it to an LLM for
    completion or prediction.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s now go through the orchestrator step by step:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, the orchestrator function is initialized with the necessary parameters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Immediately, it invokes the trajectory simulation function we built previously:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'We now convert and process the trajectory in JSON:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This code takes care of converting the trajectory and augmenting the user message:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Converting the trajectory to JSON:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`trajectory_json` becomes a serialized version of the data so it can be embedded
    in text messages or API calls.'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Under the hood, it’s just `{"trajectory": [...list of (day, timeslot, x, y)...]}`.'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Augmenting the user message:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The function takes the original user message, `(muser_message1)`, and appends
    the newly generated trajectory data to it.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: This ensures the model (or reasoning thread) sees the complete context—*both
    the user’s original query and the synthetic data*—when generating predictions
    or completions.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: This step closely mirrors the Q&A-style interaction presented by Tang et al.
    (2024), where the trajectory data—marked clearly by placeholders (`999, 999`)—is
    delivered directly to the model.
  prefs: []
  type: TYPE_NORMAL
- en: 'With the context clearly defined, the orchestrator calls the mobility reasoning
    function (which we’ll build next):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here’s what happens behind the scenes:'
  prefs: []
  type: TYPE_NORMAL
- en: '`reason.mobility_agent_reasoning_thread(...)` processes the mobility prediction
    logic through the selected LLM (such as GPT-4o)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The provided arguments (`msystem_message_s1`, `mgeneration`, `mimcontent4`,
    and `mimcontent4b`) represent clear instructions and specific context for the
    generative AI model, guiding its reasoning and predictions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This mirrors the approach described in Tang et al.’s paper, where the model
    receives structured input data and is prompted to infer missing trajectories or
    forecast next movements.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, the trajectory is added to the reasoning steps to provide a complete
    response:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Next, let’s develop the AI reasoning function that the handler registry will
    call upon.
  prefs: []
  type: TYPE_NORMAL
- en: Preparing prediction instructions and the OpenAI function
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we’ll develop the function that allows our GenAISys to process
    mobility-related user messages. Specifically, we’ll implement a function named
    `handle_mobility(user_message)` that integrates seamlessly into the AI functions
    of our GenAISys.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll approach this task in two main parts:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Message preparation:** Clearly structuring the messages that guide the generative
    AI model'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Implementing these messages in the OpenAI API call:** Leveraging the structured
    messages in the AI reasoning thread'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This aligns closely with the trajectory completion methodology described in
    *Instruction-Tuning Llama-3-8B Excels in City-Scale Mobility Prediction*, where
    structured prompts significantly enhance predictive accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: Message preparation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We have four main message variables to send to the OpenAI function:'
  prefs: []
  type: TYPE_NORMAL
- en: '`msystem_message_s1`: System message'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mgeneration`: Generation message'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mimcontent4`: Additional context'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`muser_message1`: User message'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They each serve a distinct purpose in the final prompt that goes to the LLM
    (GPT-4o or similar) for the prediction task. The system message will set the stage
    for the task.
  prefs: []
  type: TYPE_NORMAL
- en: System message
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The system message sets the overall context and constraints for the LLM, ensuring
    the model clearly understands its main objectives. The system message is stored
    in `msystem_message_s1`. We first specify the role of the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we clearly detail the tasks expected in explicit natural language:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The output format is specified:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]json'
  prefs: []
  type: TYPE_NORMAL
- en: '{"predicted_coordinates": [[day, timeslot, x, y], ...]}'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: These instructions mirror the approach of thepaper we are implementing—the system
    message clarifies the *role* of the model and the *task instructions*, effectively
    reducing confusion or *hallucination*. The paper shows how a well-structured instruction
    block significantly boosts accuracy. Now, we can build the generation message.
  prefs: []
  type: TYPE_NORMAL
- en: Generation message
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'This secondary prompt provides generation instructions that will reinforce
    how the model should handle the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'This prompt focuses on scanning for missing values, ensuring none are skipped.
    Then, it addresses the next step: provide the corrected trajectory with inferred
    missing values.'
  prefs: []
  type: TYPE_NORMAL
- en: Additional context
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'To make sure we obtain what we wish, we will now add additional context. The
    role of this additional context is to supplement the system/generation messages
    with domain-specific context:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: This additional context further guides the generative AI model toward precise
    predictions. We will now engineer a user message to further instruct the model.
  prefs: []
  type: TYPE_NORMAL
- en: User message
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'It’s time to emphasize the instructions further to make sure we provide even
    more context to the input. The user message expresses the user’s *explicit* request.
    It references the actual dataset with missing points. Realistically, in your code,
    you’ll append or embed the actual trajectory data (with `999, 999` placeholders)
    *before* passing it to the generative AI model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Let’s fit the message together.
  prefs: []
  type: TYPE_NORMAL
- en: Fitting the messages together
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The four messages converge to direct the generative AI model:'
  prefs: []
  type: TYPE_NORMAL
- en: The system message (`msystem_message_s1`) sets the stage and enforces top-level
    policies
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The generation message (`mgeneration`) clarifies the approach for scanning,
    verifying, and predicting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The additional content (`mimcontent4`) ensures domain clarity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, the user’s message (`muser_message1`) includes the data that needs
    to be processed (the partial or missing trajectory)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Together, they form the structure of a zero-shot advanced generative model’s
    prediction.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s fit the message into the OpenAI API function. These messages are
    stored in `commons/cot_messages_c6.py` to be imported by the OpenAI API function.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing the messages into the OpenAI API function
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will now create an AI mobility function for the *AI function* section in
    our GenAISys when we integrate it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'We will now import the messages we stored in `cot_messages_c6.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'We’ll now complete the function so that we can call it further in this program
    by plugging the messages in the generative AI call and return the reasoning steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now call the mobility orchestrator and return its reasoning steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'We then create the `handle_mobility_orchestrator` function in the `reason.py`
    library we have been implementing in the previous chapters of this book. We first
    create the function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we initialize the reasoning steps to display them in `VBox`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'We then plug the messages received into the standard `make_openai_call` that
    we have been using in the previous chapters and return the steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: We are now ready to run the trajectory simulation and prediction.
  prefs: []
  type: TYPE_NORMAL
- en: Trajectory simulation, analysis, and prediction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With our mobility functions built and clearly defined, we can now run the complete
    trajectory pipeline—generating synthetic trajectory data, identifying missing
    coordinates, and predicting them with a zero-shot LLM. This section will demonstrate
    the end-to-end execution and interpretation of results.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll use a simple, generic prompt to initiate the mobility analysis:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: This triggers the entire pipeline we set up previously, from synthetic data
    generation to coordinate predictions.
  prefs: []
  type: TYPE_NORMAL
- en: 'To clearly illustrate the trajectory and missing points, the system generates
    a visual plot (`mobility.png`). We can display this image directly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'The output contains the grid, the trajectory, and the missing data, as shown
    in *Figure 8.3*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.3: Trajectory and missing data](img/B32304_08_3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.3: Trajectory and missing data'
  prefs: []
  type: TYPE_NORMAL
- en: 'The output is plotted with colors, arrows, and text as designs:'
  prefs: []
  type: TYPE_NORMAL
- en: Green is the starting point
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The trajectory line is drawn in blue
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Quiver arrows (`plt.quiver`) in red show the direction from each point to the
    next
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Missing data points are highlighted with an **x** marker in magenta
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Then, we print the raw output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'The output displayed is a single, unstructured line containing trajectory data
    and predictions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Clearly, we need to present this data more intuitively. Let’s create a function
    to display a nice, formatted response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'The code breaks the output into well-presented lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'We then call the function to obtain the formatted output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'The output contains the three-step process we built:'
  prefs: []
  type: TYPE_NORMAL
- en: Display the trajectory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Isolate the missing data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Make predictions for the missing data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The output first contains the trajectory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Note the records with missing data containing `999` for *x,y* coordinates.
    Take the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'The second step is the OpenAI GPT-4o thinking through the problem to isolate
    the missing data and display it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'The third step is for the OpenAI generative AI to predict the missing data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is displayed and the predictions with explanations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'The output also contains the predictions in JSON:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]json'
  prefs: []
  type: TYPE_NORMAL
- en: '{'
  prefs: []
  type: TYPE_NORMAL
- en: '"predicted_coordinates": ['
  prefs: []
  type: TYPE_NORMAL
- en: '[228, 6, 69, 79],'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[228, 32, 69, 72],'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[228, 9, 64, 72],'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[228, 45, 58, 81],'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[228, 47, 58, 79]'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ']'
  prefs: []
  type: TYPE_NORMAL
- en: '}'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: The results are acceptable and show that recent generative AI models have zero-shot
    capabilities to make predictions on missing data in sequences.
  prefs: []
  type: TYPE_NORMAL
- en: However, the real power lies in extending these predictions to a wide range
    of real-world applications. The next logical step is to integrate this functionality
    into our GenAISys interface, allowing users to customize prompts easily to suit
    diverse trajectory-related use cases.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s move forward to implement this user-friendly integration.
  prefs: []
  type: TYPE_NORMAL
- en: Adding mobility intelligence to the GenAISys
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will now integrate the trajectory simulation and prediction component into
    our GenAISys, allowing users to design domain-specific prompts. At the user interface
    level, we’ll simplify the terminology from “trajectory simulation and prediction”
    to the user-friendly term “**mobility**.” This shorter label is more intuitive
    for users, though technical documentation can maintain detailed terminology as
    required. Then it will be up to the users to decide what domain-specific terminology
    they wish to see in the interface.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will add the mobility function we built in `1_Trajectory_simulation_and_prediction.ipynb`
    to the GenAISys at three levels, as shown in *Figure 8.4*:'
  prefs: []
  type: TYPE_NORMAL
- en: '**IPython interface**: Adding the mobility feature to the user interface'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Handler selection mechanism**: Adding the mobility handler to the handler
    registry'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**AI functions**: Implementing the mobility feature in the AI functions library'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 8.4: Integrating the trajectory simulation and prediction pipeline
    into the GenAISys](img/B32304_08_4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.4: Integrating the trajectory simulation and prediction pipeline into
    the GenAISys'
  prefs: []
  type: TYPE_NORMAL
- en: Open the `2_GenAISys_Mobility.ipynb` notebook. If needed, review the handler
    selection mechanism described in [*Chapter 7*](Chapter_7.xhtml#_idTextAnchor191)
    before continuing here. The notebook is not designed for voice outputs of lists
    of coordinates. As such, gTTS is best deactivated by default with `use_gtts =
    False` at the top of the notebook.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s first enhance the IPython interface.
  prefs: []
  type: TYPE_NORMAL
- en: IPython interface
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The mobility option is primarily added to these parts of the IPython interface:'
  prefs: []
  type: TYPE_NORMAL
- en: To the `instruct_selector` dropdown with **Mobility** as one of its possible
    values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To the display logic inside `update_display()`, which checks whether the user
    selected **Mobility** and, if so, displays the `mobility.png` file
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To the handling logic in `handle_submission()`, where the code prints `"Thinking..."`
    if `instruct_selector.value` is `"Analysis"`, `"Generation"`, or `"Mobility"`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The mobility image (i.e., `mobility.png`) is only displayed when the **Files**
    widget is checked
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will begin by adding the option to the interface. We will create and add
    an option to `instruct_selector` and then handle the trajectory image display
    and submission code. Let’s begin with the option in the interface.
  prefs: []
  type: TYPE_NORMAL
- en: Creating the option in instruct_selector
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We will first add the **Mobility** option to the **Reasoning** drop-down list,
    as illustrated in *Figure 8.5*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: '![A screenshot of a computer  AI-generated content may be incorrect.](img/B32304_08_5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.5: Adding Mobility to the dropdown'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can then select **Mobility**, as shown in *Figure 8.6*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.6: Selecting Mobility to activate the pipeline](img/B32304_08_6.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.6: Selecting Mobility to activate the pipeline'
  prefs: []
  type: TYPE_NORMAL
- en: '**Mobility** is now selected. Notice the default model is set to **OpenAI**;
    however, you may extend this to other models, such as DeepSeek, during later phases,
    depending on your project needs.'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s now handle the “mobility” value when we update the display.
  prefs: []
  type: TYPE_NORMAL
- en: Handling the “mobility” value in update_display()
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We must ensure the generated trajectory visualization (`mobility.png`) is automatically
    shown when the **Mobility** option is selected and the **Files** checkbox is enabled:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: The image created by the trajectory simulation will be displayed. We now need
    to enhance the submission logic outputs to run the AI functions.
  prefs: []
  type: TYPE_NORMAL
- en: handle_submission() logic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `chat_with_gpt` function is called as before but it interacts directly
    with the handler selection mechanism (described in the next section*)*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'However, we will add the mobility functionality to the submission handling
    function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: We will now add the mobility function to the handler selection mechanism.
  prefs: []
  type: TYPE_NORMAL
- en: Handler selection mechanism
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The handler selection mechanism contains two main parts. The first component,
    `chat_with_gpt`, remains unchanged from previous chapters and is directly called
    by the IPython interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'The second component is the handler registry, to which we’ll now add the newly
    developed mobility handler:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: This ensures that when users select **Mobility** from the **Reasoning** dropdown
    in the interface, the appropriate handler is activated automatically. We can see
    that the handler selection mechanism can be seamlessly scaled. Let’s now add the
    functions we developed for this mobility function to the AI functions library.
  prefs: []
  type: TYPE_NORMAL
- en: AI functions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Next, we’ll integrate the trajectory simulation and prediction functions—previously
    developed in the *Building the trajectory simulation and prediction* section—into
    the AI functions library within the notebook:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: This function is added just above the beginning of the functions called by the
    handler selection mechanism.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: This function is also added just above the beginning of the functions called
    by the handler selection mechanism.
  prefs: []
  type: TYPE_NORMAL
- en: 'We now add the `handle_mobility` function we developed as well, and add `**kwargs`
    to process the arguments sent by the handler mechanism selection function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: The code will run exactly like in the *Building the trajectory simulation and
    prediction function* section. With this setup, the mobility functionality is fully
    integrated into the GenAISys ecosystem, ready to be triggered via the intuitive
    IPython interface. Let’s now get the user involved.
  prefs: []
  type: TYPE_NORMAL
- en: Running the mobility-enhanced GenAISys
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will demonstrate the mobility-enhanced GenAISys by running
    two distinct scenarios—a delivery use case and a fire disaster scenario—to illustrate
    the versatility of trajectory simulations and predictions, inspired by the work
    of Tang et al. (2024).
  prefs: []
  type: TYPE_NORMAL
- en: 'Open the `2_GenAISys_Mobility.ipynb` notebook. First, deactivate DeepSeek in
    the initial setup cell (you will only need a CPU):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: Then run the whole notebook. When it’s finished, go to the *Running the interface*
    section in the notebook. We need to activate **Agent**, **Files**, and **Mobility**,
    and leave the default model as **OpenAI**.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.7: Running a delivery check with the mobility function](img/B32304_08_7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.7: Running a delivery check with the mobility function'
  prefs: []
  type: TYPE_NORMAL
- en: The synthetic trajectory simulates real-world input data and generates new data
    each time it runs. The explanations in this section reflect just one of these
    runs. When you execute the program, you’ll obtain a new output every time, simulating
    real-time data.
  prefs: []
  type: TYPE_NORMAL
- en: '**Limit**: Currently, the trajectory file is overwritten whenever a new trajectory
    is generated. If required, this functionality can be expanded during a project
    to save multiple files instead.'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s first explore the mobility function with a delivery example.
  prefs: []
  type: TYPE_NORMAL
- en: Production-delivery verification scenario
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To run the production-delivery verification, we simply need to activate **Agent**
    and **Files**, **Mobility** as the reasoning function, and **OpenAI** as the model.
    Then, click on **SEND** and let the AI do the work. In this case, we can imagine
    that an online travel agency wants to deliver customized goodies to its customers
    before a trip, such as a personalized travel bag with their name printed on it,
    a tourist guide, and a discount booklet to visit museums.
  prefs: []
  type: TYPE_NORMAL
- en: 'The GenAISys will begin to think, as displayed at the bottom of the interface,
    as shown in *Figure 8.8*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.8: The GenAISys has begun to think](img/B32304_08_8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.8: The GenAISys has begun to think'
  prefs: []
  type: TYPE_NORMAL
- en: 'The output first displays the synthetic trajectory, which can come from any
    source, such as real-time data, databases, and sensors. The synthetic trajectory,
    in this case, is displayed under the user message that indicates the title of
    the discussion since the mobility function itself is autonomous:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, the generative AI function takes over and indicates that it is processing
    the missing data in the trajectory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'When it is finished thinking, it provides the list of missing data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'The GenAISys then provides its prediction:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'A structured JSON output is provided for integration with other systems or
    further processing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'The original trajectory is also displayed for the user to make decisions, as
    shown in *Figure 8.9*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.9: The original trajectory with missing data](img/B32304_08_9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.9: The original trajectory with missing data'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, three **subject-matter expert** (**SME**) agents can intervene:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Human user**: A person evaluates the data, validates predictions, or provides
    feedback'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**AI agent**: An additional function can be added. The trajectory grid can
    be labeled, and instructions can be provided to an AI function. The instructions
    will rely on the coordinate sections of the grid to generate further functions
    or messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Hybrid (human-user + AI-agent)**: Once a human user has created a number
    of prompts successfully, it may be beneficial to automate some of them to alleviate
    the human user’s workload if accepted within the scope of the project.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let’s now deactivate the **Mobility** function and **Files** display to put
    the cutting-edge generative AI to work, as shown in *Figure 8.10*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.10: Generative AI takes over and generates messages](img/B32304_08_10.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.10: Generative AI takes over and generates messages'
  prefs: []
  type: TYPE_NORMAL
- en: 'At this stage, a human user can interpret the AI’s output and craft a tailored
    prompt. For instance, consider this scenario:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s an example of a domain-specific prompt to address the issue:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: As demonstrated, such a prompt could easily be adapted to various domains. By
    simply adjusting the labeling of the coordinates and the intended recipient, you
    could generate a diverse array of messages. The exact scope and application depend
    entirely on the requirements of your specific project.
  prefs: []
  type: TYPE_NORMAL
- en: 'The generative AI’s response to the preceding prompt was acceptable and detailed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: Next, without restarting the session, let’s ask our GenAISys how this methodology
    could be applied to a fire disaster scenario.
  prefs: []
  type: TYPE_NORMAL
- en: Fire disaster scenario
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, let’s explore how the concepts of trajectory analysis, missing coordinates,
    and predicted coordinates can be leveraged in disaster prediction scenarios, specifically
    in cases such as forest fires. We’ll submit this scenario to the GenAISys and
    analyze its insights:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: This structured output offers valuable insights, enabling disaster response
    teams to swiftly identify and respond to potential threats based on trajectory
    analysis, pinpointed data gaps, and predictive coordinates.
  prefs: []
  type: TYPE_NORMAL
- en: This methodology demonstrates that we can craft numerous specialized prompts
    across domains. Despite inevitable limitations, the era of GenAISys is just beginning,
    continually expanding into new, uncharted applications.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we began by recognizing that robust trajectory analysis is
    essential for applications ranging from deliveries and epidemic forecasting to
    city-scale planning. Guided by the innovative approach outlined in Tang, P., Yang,
    C., Xing, T., Xu, X., Jiang, R., and Sezaki, K. (2024), we emphasized the transformative
    potential of text-based LLMs for mobility prediction. Their framework directed
    our design of a method capable of intelligently filling gaps in real-time synthetic
    datasets through carefully structured prompts.
  prefs: []
  type: TYPE_NORMAL
- en: We then built a Python-based trajectory simulator that randomizes movement on
    a grid, mirroring typical user paths. It assigns day and timeslot indices, which
    enabled us to capture the temporal aspect of mobility. Critically, we inserted
    synthetic gaps marked as `999, 999`, approximating real-world data dropouts or
    missing logs. Next, we integrated an orchestrator function that adds instructions
    with this synthetic data before directing them to an LLM, in this case, an OpenAI
    GPT-4o model. The orchestrator composes prompts that accurately reflect the trajectory
    dataset, focusing the model’s attention on flagged gaps. It employs a chain-of-thought
    routine, noting missing points for debugging prior to generating final JSON outputs.
  prefs: []
  type: TYPE_NORMAL
- en: 'We then merged this pipeline into the GenAISys environment by adding a dedicated
    mobility handler in the multihandler system. This handler streamlines the full
    process: trajectory generation, model inference, and visualization all in one
    place. Users can prompt the system to evaluate missing coordinates and instantly
    see the updated paths superimposed on a static city grid. Ultimately, we demonstrated
    that robust GenAISys forecasting need not remain abstract when grounded in purposeful,
    prompt design.'
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will open the GenAISys to the world with an external
    service that will lead us to enhance our system with security and moderation functionality.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A trajectory can only be a physical path in a city. (True or False)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Synthetic data can accelerate GenAISys simulation design (True or False)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Generative AI cannot go beyond natural language sequences. (True or False)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Only AI experts can run GenAISys. (True or False)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Generative AI can now help us with prompt design. (True or False)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Trajectory simulation and prediction cannot help with fire disasters. (True
    or False)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: GenAISys’s potential is expanding at full speed and can be applied to a growing
    number of domains and tasks. (True or False)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: P. Tang, C. Yang, T. Xing, X. Xu, R. Jiang, and K. Sezaki. 2024\. “Instruction-Tuning
    Llama-3-8B Excels in City-Scale Mobility Prediction.” *arXiv*, October 2024\.
    [https://arxiv.org/abs/2410.23692](https://arxiv.org/abs/2410.23692).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Renhe Jiang, Xuan Song, Zipei Fan, Tianqi Xia, Quanjun Chen, Satoshi Miyazawa,
    and Ryosuke Shibasaki. 2018\. “DeepUrbanMomentum: An Online Deep-Learning System
    for Short-Term Urban Mobility Prediction.” *Proceedings of the AAAI Conference
    on Artificial Intelligence* 32, no. 1: 784–791\. [https://ojs.aaai.org/index.php/AAAI/article/view/11338](https://ojs.aaai.org/index.php/AAAI/article/view/11338).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Jie Feng, Yong Li, Chao Zhang, Funing Sun, Fanchao Meng, Ang Guo, and Depeng
    Jin. 2018\. “DeepMove: Predicting Human Mobility with Attentional Recurrent Networks.”
    *Proceedings of the 2018 World Wide Web Conference*, Lyon, France, April 23–27,
    2018, 1459–1468\. [https://doi.org/10.1145/3178876.3186058](https://doi.org/10.1145/3178876.3186058).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Haru Terashima, Naoki Tamura, Kazuyuki Shoji, Shin Katayama, Kenta Urano, Takuro
    Yonezawa, and Nobuo Kawaguchi. 2023\. “Human Mobility Prediction Challenge: Next
    Location Prediction Using Spatiotemporal BERT.” *Proceedings of the 1st International
    Workshop on the Human Mobility Prediction Challenge*, Tokyo, Japan, September
    18–21, 2023, 1–6\. [https://dl.acm.org/doi/10.1145/3615894.3628498](https://dl.acm.org/doi/10.1145/3615894.3628498).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Subscribe for a Free eBook
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: New frameworks, evolving architectures, research drops, production breakdowns—*AI_Distilled*
    filters the noise into a weekly briefing for engineers and researchers working
    hands-on with LLMs and GenAI systems. Subscribe now and receive a free eBook,
    along with weekly insights that help you stay focused and informed.
  prefs: []
  type: TYPE_NORMAL
- en: Subscribe at [https://packt.link/TRO5B](Chapter_8.xhtml) or scan the QR code
    below.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Newsletter_QR_Code1.png)'
  prefs: []
  type: TYPE_IMG
