- en: '9'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Guidelines and Heuristics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter explains what makes an excellent conversational style. Some of
    what is covered may seem obvious, but exploring and understanding why something
    works or doesn’t work is valuable when applying the concepts
  prefs: []
  type: TYPE_NORMAL
- en: to new situations. ChatGPT is unique because it won’t necessarily answer the
    same question again in the same way, which is why [*Chapter 7*](B21964_07.xhtml#_idTextAnchor150),
    *Prompt Engineering*, was essential. This chapter will cover guidelines and heuristics
    to evaluate and improve the experience you are designing. We are not picky about
    what we call these, but we can use better definitions. **Guidelines** are particular
    and tend to be based on user research. **Standards** are more specific, while
    **best practices** are recommendations based on certain conditions. Vendors such
    as Apple’s **Human Interface Guidelines** (**HIG**) or Google’s **Material Design**
    are widely copied and include all of these protocols. Organizations or governments
    can mandate guidelines and standards as required. **Heuristics** are rules of
    thumb or strategies to break down a problem into elements that need attention.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The point is that there are things one should follow (guidelines, standards,
    best practices, and design recommendations), and there are strategies (heuristics)
    to figure out what to do. Some apply to the GUI encompassing the conversational
    AI, and some are for conversational text. All of this is covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Applying guidelines to design
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adapting heuristic analysis for conversational UIs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building conversational guidelines
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Case study
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All of these are for knowing what to do before doing it. We can use this knowledge
    for the next interaction if we learn what works. Design guidelines have evolved,
    but as we will see, some have been around for decades, and not only do they still
    apply, but they might even apply more than before.
  prefs: []
  type: TYPE_NORMAL
- en: Applying guidelines to design
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This book follows the order of the life cycle of conversational AI design. Why
    do guidelines and heuristics come after “building” the experience and prompt engineering?
    This is a chicken and egg problem. Many teams create generative AI experiences
    for the first time. The application of guidelines and heuristics has to be done
    with some understanding of what has previously been built. In visual experiences
    such as GUIs, previous project experience helps inform what guidelines and heuristics
    will translate into new designs. This is not the case with conversational AI.
    This advice is here to help you get started and be there as your journey unfolds.
  prefs: []
  type: TYPE_NORMAL
- en: Software tests can be crafted to evaluate whether a guideline is met. Testing
    is more challenging with a heuristic. The heuristics used for evaluation are broader
    than the precise nature of a software test case. Using the examples of standard
    to use Bold Calibri as a font in a header, each header would need its own test
    to evaluate a user experience for this condition. It is a trade-off. More expertise
    is needed to know and internalize heuristics, and it’s the same with guidelines.
    Another difference is that a heuristic will stand the test of time. They are generic
    enough to adapt as experiences evolve. Because they are generic, they are hard
    to define in code. How should the heuristic *titles should be readable* be measured?
    Because a guideline is more specific, it might only apply to a particular UI or
    use case. However, they are still valuable. In addition, understanding the underlying
    science behind a guideline can help you more effectively apply it to new experiences.
  prefs: []
  type: TYPE_NORMAL
- en: One of the first sets of guidelines I ever used was by Smith and Mosier (1986).
    The document contained 944 guidelines for software interfaces. Don’t dismiss them
    because they might be older than you. They are based on research on human behavior
    and capabilities. Human behavior hasn’t evolved to invalidate them, even with
    new contexts for their uses, such as high-resolution displays, voice interfaces,
    and hand-held devices. There are a lot of universal truths in them. Many of these
    original guidelines were associated with text-based experiences, and it seems
    like what goes around comes around, as, surprisingly, we have returned to text-based
    solutions with chat, conversational, and recommender experiences.
  prefs: []
  type: TYPE_NORMAL
- en: 'Article: [Smith and Mosier’s Guidelines for Designing User Interface Software](https://hcibib.org/sam/)
    ([https://hcibib.org/sam/](https://hcibib.org/sam/))'
  prefs: []
  type: TYPE_NORMAL
- en: However, as I mentioned, these guidelines are for **User Interfaces** (**UIs**),
    and heuristics might apply better to evaluate conversational experiences. The
    evolution of these heuristics is based on the solid scientific efforts of these
    researchers and previous ones. Before diving in, here is one more example. Bruce
    Tognazzini is a famous Apple designer and an early partner at the Nielsen Norman
    Group. He is someone the industry has respected and appreciated for years. I invited
    him to be the keynote speaker for a conference host in Blacksburg, VA. You know
    his keynote was going to be a little crazy when he asked the hotel for fire extinguishers
    to be present. That freaked out the hotel management. Being a little shocking
    applies to guidelines as well. Some will seem a little crazy, but they can be
    applied more effectively by going deeper and learning about their origins and
    scientific underpinnings. Then, they won’t seem crazy when they apply to enterprise
    use cases, nor was his reason for wanting a fire extinguisher, once you understood
    its purpose. Here is his list of principles; see how they can easily apply to
    the ChatGPT frontier.
  prefs: []
  type: TYPE_NORMAL
- en: 'Article: [First Principles of Interaction Design](https://asktog.com/atc/principles-of-interaction-design/)
    ([https://asktog.com/atc/principles-of-interaction-design/](https://asktog.com/atc/principles-of-interaction-design/))'
  prefs: []
  type: TYPE_NORMAL
- en: Adapting heuristic analysis for conversational UIs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A wide range of possible issues can be found with a good set of heuristics.
    Heuristic evaluations can range from formal to informal. The more formal approach
    is to enlist three to five usability experts as evaluators. Once provided context
    and the background of the tasks and users, they can independently evaluate the
    experience against their understanding of the heuristics. By documenting the issues,
    scoring their importance, and compiling the results from each reviewer, the team
    can prioritize the issues to be addressed. This approach can be used to look at
    UI issues, and much of this can also be used to understand conversational interactions.
  prefs: []
  type: TYPE_NORMAL
- en: 'These issues will not be found in surveys that provide a score, such as the
    **Net Promoter Score** (**NPS**) or the **Software Usability Score** (**SUS**),
    covered in the next chapter. NPS or SUS can be applied once customers are exposed
    to the product; a heuristic evaluation of a working prototype has some advantages:'
  prefs: []
  type: TYPE_NORMAL
- en: It can be done early in the design process
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is inexpensive
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: UX professionals can do it, and others can participate as well
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They are battle-tested for traditional GUI evaluations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They are adapted here to consider conversational experiences
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With unique chat and recommendation UIs
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: For hybrid UIs that use GUI components within a chat
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: For sentences, when explicitly defined in templates, with deterministic flows,
    or controlled abstractly through prompts
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: As part of prompts to instruct the LLM to value the heuristics
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'There are some issues to address as well:'
  prefs: []
  type: TYPE_NORMAL
- en: It can be biased based on the evaluator (which is why a few evaluators participate)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It depends on the evaluator having enough expertise in the evaluation and the
    feature to detect issues (evaluators can be trained, given time to practice and
    explore and be provided sample use cases, but all of this can bias a review)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is best done with three to five evaluators, who might be hard to get
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It can return issues that are not significant
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To balance the good and the bad, the following is suggested:'
  prefs: []
  type: TYPE_NORMAL
- en: Review the heuristic tools before the evaluation and coach people on a separate
    example product to reinforce the method and heuristics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Provide a printout of the heuristics to the evaluator
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Remind evaluators to put on their customer hats
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After the evaluation, use the scoring tools discussed in the earlier chapters
    to prioritize and focus on the most valuable findings
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Iterate quickly so that future evaluations can reveal new items and are not
    masked by more significant, overwhelming issues
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is reasonable to use heuristics in your daily design efforts to guide you
    to solutions that are already good before a customer sees the results
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We need a set of heuristics to provide the most significant value with the least
    cost. One set already comes to mind.
  prefs: []
  type: TYPE_NORMAL
- en: I always start and finish with Jakob Nielsen’s ten heuristics. They are broad
    enough to apply to various situations, have been revised, and used for over 30
    years, which gives them some street credibility. They cover a range of issues
    found in user experiences. Usually, but not exclusively applied to GUIs, they
    need to be put in the context of conversational AI. The articles I reference cover
    the basics of heuristics, and hundreds of other articles are out there. Sometimes,
    these guides will be spot on – for hybrid experiences that include UI components
    with conversations. The UI heuristics are well documented. The added value to
    expose is how these apply to our conversational experiences. This would be called
    color commentary to make an analogy to watching sports on TV. The play (the heuristic)
    is taken, and a discussion explains it so a layperson can understand their application
    to a conversational UI.
  prefs: []
  type: TYPE_NORMAL
- en: 'Article: [Intro to Heuristic Evaluation (HE)](https://www.interaction-design.org/literature/topics/heuristic-evaluation)
    ([https://www.interaction-design.org/literature/topics/heuristic-evaluation](https://www.interaction-design.org/literature/topics/heuristic-evaluation))'
  prefs: []
  type: TYPE_NORMAL
- en: 'Article: [How to perform a heuristic evaluation](https://www.nngroup.com/articles/how-to-conduct-a-heuristic-evaluation/)
    ([https://www.nngroup.com/articles/how-to-conduct-a-heuristic-evaluation/](https://www.nngroup.com/articles/how-to-conduct-a-heuristic-evaluation/))'
  prefs: []
  type: TYPE_NORMAL
- en: Extensive examples that support conversational flow and recommendation UIs will
    be used. This chapter won’t benefit backend experiences, as the heuristic is about
    evaluating the user experience.
  prefs: []
  type: TYPE_NORMAL
- en: Expecting a conversational AI to return exact messages might be a challenge.
    It depends on what is in control of the output. If ChatGPT controls the output,
    we have to rely on prompt engineering and fine-tuning to get it close. Suppose
    a traditional deterministic chat experience provides the front end. In that case,
    you can specify precisely the response wanted or a collection of responses to
    pick from. You can use ChatGPT to understand entities, ask questions to fill in
    gaps, or perform other language tasks to support the higher purpose. Recommender
    UIs sometimes use a text template. ChatGPT can gather input, fill in values, transcode
    details, and provide translation. Keep these in mind, as the heuristics can apply
    in different ways to each context of use.
  prefs: []
  type: TYPE_NORMAL
- en: If you want to see any of the following examples show up directly in a ChatGPT
    chat, it is hard to make it happen consistently. It comes back to instructions.
    It is possible to use the definitions in the heuristics for the instructions on
    how to formulate responses. That would be a great research project. We will use
    a new employee onboarding process example prompt incorporating critical heuristics
    to guide discussions. The heuristic influences are highlighted in **bold**.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: A callout for each heuristic will discuss the heuristic influences found in
    the instructions provided to the LLM. The following are the heuristics. Each will
    be defined and explained, along with an analysis of how they can be applied.
  prefs: []
  type: TYPE_NORMAL
- en: '*Visibility of* *system status*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Match between a system and the* *real world*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*User control* *and freedom*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Consistency* *and standards*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Error prevention*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Recognition rather* *than recall*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Flexibility and efficiency* *of use*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Aesthetic and* *minimalist design*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Help users recognize, diagnose, and recover* *from errors*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Help* *and documentation*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each heuristic follows the same model. The name of the heuristic, the exact
    definition, the analysis to apply it to conversational AI, and a callout for an
    analysis of the new hire onboarding example.
  prefs: []
  type: TYPE_NORMAL
- en: 1 – Visibility of system status
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*The design should always keep users informed about what is going on through
    appropriate feedback within a reasonable amount* *of time.*'
  prefs: []
  type: TYPE_NORMAL
- en: Analysis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In a chat experience, keeping the user informed is typically done through textual
    response. In process flows, some information will repeat to provide context when
    prompted for the next step. The user expects to see this in seconds or less. Waiting
    10 seconds to gather backend data would be odd. If providing timely information
    is a problem, give that feedback. Sometimes, it is challenging to provide estimates.
    If the user expects delays, they might feel better about it. Learn from these
    examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: It is crazy to start this section with this horrible user experience, making
    the user wait *forever*. We will explore a few more typical system status examples.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an appropriate level of feedback, confirming that the address step
    is completed with enough context for the user to pick a delivery date in the future:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'What gets provided as feedback should be limited. If the address is confirmed,
    don’t repeat it along with everything else in the order. Wait until there is a
    summary or when the user requests the address. This is the *appropriate feedback*.
    Here is an example of how to give instructions to the LLM. Recall from [*Chapter
    7*](B21964_07.xhtml#_idTextAnchor150) *– Prompt Engineering*: the instructions
    are prompts that wrap the customer conversation so that the customer prompts have
    some guidance. It is ok to refer to these as instructions or prompts if you realize
    the context is an overarching prompt, not what the user types (also called the
    user prompt).'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'It would be challenging if a calendar was full of unavailable delivery dates.
    The user would be stuck in a mindless game of picking a date. For example, in
    a voice-only solution, offer three suggestions for delivery or openings around
    a date they provide. A GUI can show a month-at-a-glance view with available delivery
    dates. It would show the next available date and offer to edit that if it doesn’t
    work. That way, the user understands what the system can do:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'If the user experience is just a recommendation and not interactive, it still
    can be good to clarify the information based on the recommendation. If they change
    something on the screen, will the recommendation update? For example, if the recommendation
    is to email the customer this week, does it know that I already emailed them today?
    Even if this information is not directly related to the recommendation, have a
    clickable affordance, like an **info** button, to explain what went into the recommendation
    and, in this example, whether the last email was accounted for. Here is what could
    be behind the **info** button:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Giving the timing information (e.g., last updated three minutes ago, or this
    recommendation is based on details updated yesterday) can help gauge the relevance
    of the recommendations.
  prefs: []
  type: TYPE_NORMAL
- en: 'There’s one last thought about system status, which can also apply to backend
    services or recommendations. If an unavailable resource impacts the data, let
    people know. Don’t just time out a connection. Integrations should support and
    communicate the edge cases of the system being down. It should mirror the style
    and tone of the service and not be a cryptic error message:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'This email link should populate the subject and body with technical information.
    To take this to the next level, in the right conditions, do this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Depending on the audience, it might link to the ticket or cc the customer. This
    message is okay to be repeatable and consistent. Please do not leave it to the
    LLM to generate the response. It should be so rare that variety won’t matter,
    and we want to be very specific about the error’s development. If exposing too
    much detail confuses the user, stick to a generic message.
  prefs: []
  type: TYPE_NORMAL
- en: Here is the first callout explaining the impact of this heuristic on the new
    employee onboarding instructions. We won’t introduce the callout each time; they
    will always be last for each heuristic.
  prefs: []
  type: TYPE_NORMAL
- en: Analysis for new employee onboarding, visibility of system status
  prefs: []
  type: TYPE_NORMAL
- en: 'Heuristic influences: *Focus on key actions*, *provide details at each step*,
    *and if there* *are errors*'
  prefs: []
  type: TYPE_NORMAL
- en: There are a few places where status should be communicated to guide the user.
    Confirming that progress is tracked and reporting on errors along will also help
    through the stressful time of starting a new job.
  prefs: []
  type: TYPE_NORMAL
- en: 2 – Match between a system and the real world
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*The design should speak the users’ language. Use words, phrases, and concepts
    familiar to the user, rather than internal jargon. Follow real-world conventions,
    making information appear in a natural and* *logical order.*'
  prefs: []
  type: TYPE_NORMAL
- en: Analysis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Style and tone go a long way when communicating in a conversational tone. It
    gets trickier with enterprise software. If the user refers to the ordering system,
    don’t reply with the *order entry and tracking system*. They might not realize
    it is the same system. Actively mirror the customer language and conventions,
    but do so in a style consistent with the organization. Recall our surf shop example.
    To confirm an order, use this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Prompt engineering and fine-tuning establish less colorful responses from a
    financial service company. The response will be in more formal business-speak:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: This is also an excellent heuristic for appreciating how to display information.
    Consider the format of content, or with lists, the order for the information provided.
    *Table 9.1* shares order and format options for displaying information. *Use prompts
    to set an order* *and format.*
  prefs: []
  type: TYPE_NORMAL
- en: '| **Order (****for lists)** | **Format (for** **complex content)** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: Alphabetical
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chronological
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Classifications
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Highest to Lowest
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Location or Distance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logical
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Most to Least Expensive
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Numeric
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Popularity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Priority
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Random
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Size or Dimensions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: Bullet List
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Calendar
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cards/Tiles (Like a Business Card)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Charts or Graphs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: File Formats (PDF, XLS, or Doc)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Image or Graphic
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Maps
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ordered List
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Spreadsheet (Downloadable)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Table
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Trees
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: Table 9.1 – Common design alternatives to display information
  prefs: []
  type: TYPE_NORMAL
- en: Analysis for new employee onboarding, match between a system and the real world
  prefs: []
  type: TYPE_NORMAL
- en: 'Heuristic influences: *clear, simple terms*, and *should be easy* *to follow*'
  prefs: []
  type: TYPE_NORMAL
- en: The intent is to get them onboarded, not to teach them jargon. The prompt emphasized
    that this is a new employee, so clarity is key.
  prefs: []
  type: TYPE_NORMAL
- en: 3 – User control and freedom
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Users often perform actions by mistake. They need a clearly marked “emergency
    exit” to leave the unwanted action without having to go through an* *extended
    process.*'
  prefs: []
  type: TYPE_NORMAL
- en: Analysis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Usually, buttons such as **Cancel** are on a dialog box or in a multiple-step
    process; the user can cancel or leave the process and pick it up later. Too many
    UIs are scary because it seems possible to lose work. How about a website that
    times out five minutes into a long form? If you sign back in, can you pick up
    where you left off? If the user accidentally closes the window or clicks the **Back**
    button on a browser, can they return without losing work? Alternatively, figuring
    out how to undo an action might be challenging. An online shopping cart has this
    issue. Sometimes, finding out how to get out of the cart or remove an item is
    (intentionally) difficult. Some carts have a distinct remove button. Others also
    include a save for later button to encourage future purchases. Others make the
    user set the quantity to zero (which is both indirect and not marked).
  prefs: []
  type: TYPE_NORMAL
- en: 'In a traditional UI design, be explicit, such as giving the user cancel and
    accept buttons for a dialog box. A textual interface or voice interface won’t
    have visual affordances. Suggest a path forward if the user needs clarification
    or guidance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Here, the control term `"submit"` is not necessarily required in a conversational
    AI. This message encourages the user to move forward; it is not written to force
    them to accept the next step. Many words/phrases might be supported, and the system
    has to decide if those words are enough to confirm the action. I asked ChatGPT
    to classify a collection of terms that might mean submit.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Not only would a conversation around submitting an order expect to understand
    these, but it could also be that the instructions for the LLM are told to confirm
    the submission if the instructions are weak. This is the type of task understanding
    that an LLM will know even without enterprise training. It should be expected
    to work. But there are a few in **bold** that are not classified well. A few should
    be more positive, and a few should be less favorable. If you had an existing chatbot,
    you likely had trained it on examples like this. These would be the same samples
    that could be used for fine-tuning to help it overcome the LLM’s problems with
    negation (Not soon enough is a strong confirmation) and ensure that simple terms,
    like *Order*, are followed. Don’t force the user to talk in a structured business
    language. Apply this mantra:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Bring the experience to the user; don’t make the user go to* *the experience.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Talk in the user’s language; don’t force them to learn the* *company’s vocabulary.*'
  prefs: []
  type: TYPE_NORMAL
- en: This heuristic also covers the freedom for users to return to a conversation
    later and pick up where they left off. This is a significant challenge for many
    platforms. If the user is in a chat conversation and returns a few hours later,
    will the service allow them to continue, or will it have timed out, causing the
    user to start over? Even if a timeout is inevitable, the user’s state should be
    maintained and restored once they authenticate. Understand typical pauses in conversational
    AI and support the continuation of the interaction. I have done data analysis
    of transactional conversational UIs and have seen plenty of data where conversational
    interactions are picked up again, even 24 hours later. This is similar to how
    we act with others on messaging platforms. The expectation is that it is okay
    to return later and resume the conversation.
  prefs: []
  type: TYPE_NORMAL
- en: As for exits, in a dialog box or even a wizard, there are marked exits, such
    as the cancel or exit button, typically in a consistent place on a platform. In
    a conversational UI, cancel buttons are avoided. Users must recognize that they
    can exit gracefully by saying, “Stop this order; I don’t want it,” or leave. There
    won’t be a visual affordance to stop in the middle of a transaction. For recommender
    UIs, the user isn’t “in” the UI; it is a secondary piece of information to assist
    the primary interaction, so no exits are expected.
  prefs: []
  type: TYPE_NORMAL
- en: There are cases in hybrid UIs where a cancel option for a long process, such
    as uploading a file or filling a form that appears as part of a conversational
    interaction, could have one. To be clear, this means exiting a process or task
    *in* a conversation. The window that contains the conversation likely has an exit
    or close button. This button might stop the conversation or close the window,
    allowing the user to pick up the thread later. The GUI component **Cancel** should
    respond to conversational interactions "I don't want to send this."It just depends
    on the use case. This heuristic about user control also supports an undo concept.
  prefs: []
  type: TYPE_NORMAL
- en: Redo as undo
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Users make errors. One error is to delete, remove, or create an unintended edit
    to a form, object, or content. In some traditional UIs, **Undo** comes to the
    rescue. It is on the **Edit** menu, web applications, messaging platforms or a
    gesture like shaking on an iPhone. For years, Adobe Photoshop has had a history
    menu that supports multiple levels of undo. Some modern email UIs allow undo when
    sending an email. There may be only 10 seconds to unsend an email, but it is a
    relief to do this when sending something too soon. I hate sending an email that
    should have an attachment, and forgot to include it. Undo! Undo! Consider how
    to support **Undo** for transactions and experiences. This applies to conversational
    experiences and not to recommendations or backend solutions.
  prefs: []
  type: TYPE_NORMAL
- en: Here is a secret tip for getting a developer to support Undo
  prefs: []
  type: TYPE_NORMAL
- en: Developers can freak out about undoing transactions. An alternative is to think
    about redoing the task programmatically – that is, the user, in almost all cases,
    doesn’t care about the state of the database; they want to undo what they did.
    An innovative developer can submit a transaction that effectively undoes it by
    keeping a copy of what was there previously and resubmitting it. Redo acts as
    an undo. The customer is none the wiser and happy. One level of undo in most use
    cases is probably 95% of the problem. Solve 95% of the problem before considering
    multiple levels of undo to solve the other 5%.
  prefs: []
  type: TYPE_NORMAL
- en: 'Undo can be supported conversationally:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: This is not about generative AI per se; this process deals with function calls
    and interacts with backends conversationally. So, undoing a mistake can require
    backend support to undo or maybe redo. In this appointment situation, as long
    as no one booked that slot, the system should support booking the new spot and
    then canceling the old spot. This way, the user isn’t in limbo if the old time
    was taken. The original booking interaction might have been hours earlier. Maybe
    they had a meeting and responded after realizing the error.
  prefs: []
  type: TYPE_NORMAL
- en: Analysis for new employee onboarding, user control and freedom
  prefs: []
  type: TYPE_NORMAL
- en: 'Heuristic influences: *explain how to fix them*, and *complete it in* *any
    order*'
  prefs: []
  type: TYPE_NORMAL
- en: The influence sighted does give the user control to solve problems, and it does
    support doing tasks in any order.
  prefs: []
  type: TYPE_NORMAL
- en: 4 – Consistency and standards
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Users should not have to wonder whether different words, situations, or actions
    mean the same thing. Follow platform and* *industry conventions.*'
  prefs: []
  type: TYPE_NORMAL
- en: Analysis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is a catch-all for the additional work covered in this and earlier chapters.
    UX guidance emphasizes speaking in the user language and learning how to handle
    variations in language. The upcoming heuristic, *6 – Recognition rather than recall*,
    offers a good example. Watch out for the use of language on the output side; be
    consistent and use the terms most appropriate for the company. However, users
    will use what they know and recall. If these terms are widely different, encourage
    and don’t demand the user to use the correct terms. This allows them to connect
    to the more modern terms without ignoring them. This heuristic could be interpreted
    as counter to heuristic *2 – Match between the system and the real world*, which
    asks to speak in the user’s language. We bridge that divide by understanding their
    language while reinforcing the new term.
  prefs: []
  type: TYPE_NORMAL
- en: For example, customers who have used a product for years can refer to it by
    its original name. When another company purchases the product and rebrands the
    product, the new name gets exclusively used after some time. But the customer
    still has the old product with the old name running just fine. It might be a physical
    device in a shop; the old name is stamped right on the side. When they call for
    support, they still use that name, a short version of the name, or even an initialism.
  prefs: []
  type: TYPE_NORMAL
- en: Oracle purchased BEA in 2008\. The BEA middleware was called WebLogic Server.
    Customers might still be running this software. They might refer to it as WLS,
    the server, WebLogic, BEA, Oracle WebLogic Server, BEA WebLogic Application Server,
    the app server, or the more modern terms Oracle Middleware or Fusion Middleware.
    The conversational AI should support all.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'This helps them connect from the old to the new term and speak in their language
    when asking for details about WLS. This example used a prompt that supported a
    more casual tone, resulting in the term *install* instead of the more formal *installation*.
    This prompt might be used:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Additional fine-tuning examples could be needed to improve the dictionary of
    terms. Consider using checklists for new tasks and actions to monitor for issues
    in conversational logs or recommendation output strings. Refine the approach using
    all the tools – prompt engineering, data cleansing, and fine-tuning.
  prefs: []
  type: TYPE_NORMAL
- en: Analysis for new employee onboarding, consistency and standards
  prefs: []
  type: TYPE_NORMAL
- en: 'Heuristic influences: *Clear,* *simple terms*'
  prefs: []
  type: TYPE_NORMAL
- en: The previous callouts cover some of the same concepts. As long as you identify
    a problem, you are doing well. Once you identify a solution, consider if it can
    cause issues with other heuristics or guidelines.
  prefs: []
  type: TYPE_NORMAL
- en: As discussed in the analysis above, use fine-tuning to support transparent,
    simple, and user terms. Additionally, the new employee might not be familiar with
    some terms. Setting up their account information via “SSO” for the first time
    might require an explanation of Single-Sign-On. There should be sufficient detail
    to explain SSO, for example. Don’t assume knowledge.
  prefs: []
  type: TYPE_NORMAL
- en: 5 – Error prevention
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Good error messages are important, but the best designs carefully prevent
    problems from occurring in the first* *place. Either eliminate error-prone conditions
    or check for them, and present users with a confirmation option before they commit
    to* *an action.*'
  prefs: []
  type: TYPE_NORMAL
- en: Analysis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let’s start by discussing how to avoid errors in the first place. This is a
    considerable challenge when dealing with conversational UIs. They can say anything;
    if misinterpreted, the conversation goes wrong. This is where product owners and
    designers need to look at thresholds for understanding. If a system isn’t confident
    in its direction, interject and guide the user. Disambiguation is standard in
    traditional conversational chat experiences. Use prompt engineering to build instructions
    so the generative AI can meet a confidence threshold. In [*Chapter 10*](B21964_10_split_000.xhtml#_idTextAnchor216)
    *– Process,* we will show more examples of chaining that can be used to evaluate
    a confidence threshold and assist in getting a better answer. If more clarification
    or confidence is needed in what the user asks, prompt the user for more details.
    Provide options that help them narrow down their problem to guide them on the
    right path, like with a prompt like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The faster the resolution, the fewer additional errors will occur. I reviewed
    many chats where the user was unaware they were in a misguided conversation. The
    user doesn’t notice context clues that the conversation isn’t working. They continue
    interacting as if they know where and what they are doing, but they do not.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Customers do not read; they skim, at best. Provide vital clues and reinforce
    with guideposts. Use redundant clues for errors that need to be fixed.
  prefs: []
  type: TYPE_NORMAL
- en: For example, there are standard patterns to fix errors in traditional forms.
    A message might say that there is an error. It should explain what field has the
    problem, and then there should be an error label or icon on the field, along with
    details on what is wrong. While writing this chapter, I experienced errors when
    submitting forms, but the website would not tell me what field had a problem or
    even highlight the field with the mistake. I was left trying to edit each field
    to see whether anything changed. And even then, in one case, I couldn’t submit
    the form. I never figured it out.
  prefs: []
  type: TYPE_NORMAL
- en: Information passed to other systems must be valid in conversational AI solutions,
    especially for transactional UIs (e.g., searching for a flight, filling out an
    expense report, or conversational versions of UI forms).
  prefs: []
  type: TYPE_NORMAL
- en: 'Conversational UIs are prone to submitting wrong data. The AI doesn’t know
    it is wrong, so it can’t prevent it, and even a traditional UI won’t typically
    catch a user typing `112,` but intended `12` if the field isn’t validated. That
    is the magic of AI. Although it might not be preventable, an AI can determine
    if something appears wrong and understand what is reasonable data. A prompt in
    your instructions might catch issues:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'This intelligence can be built into conversational AI. This is one great reason
    for making purpose-built AI models. There is flexibility in focusing on solving
    one problem well. When asked what ChatGPT thinks is *not typical*, it responded:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Use language intentionally. *Typical* in the prompt is wishy-washy; in this
    case, ChatGPT might ignore values that are considered rare, which is below 10%.
    Using specific language for expected value ranges. Prompt for well-known fields
    if the user doesn’t submit a valid value the first time. It might not be necessary
    to provide exact instructions ahead of time. Try to parse to a valid value first
    to avoid clutter in the user interaction. It is a tradeoff. For questions where
    specific values are well understood, don’t provide details; for questions without
    known values, consider asking the user for more information to avoid getting poor
    answers on the first attempt.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Alternatively, using a generative AI error checker, create a separate component
    to validate form values behind the scenes. The database won’t be happy if it needs
    a number and the AI sends it the text “three.” Use a different model designed
    to handle these situations and then pass validated results to the primary model.
    ChatGPT is very good about understanding the requirements of a function (it inspects
    something called the function signature) and typically will do the right thing,
    including transforming the data into the correct format. In the case above, if
    it knows the field is an integer, it will send “3” to the function. This also
    works as a gate for functions that do not have good validation capabilities. The
    LLM can do it. Here is an example of doing this work manually in a prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Let’s return to the expense example. An image upload feature processes scans
    of receipts to gather expense details directly from an uploaded image. Image scanning
    models must be trained and will get errors, so putting a different model validator
    before the image scanning results could catch some automation errors. Ask the
    user to confirm what was found in these cases. It is a challenge to be error-tolerant
    in conversational AI experiences. Monitor and improve. Watch for opportunities
    to catch errors, recover from mistakes, and validate behind the scenes when possible.
  prefs: []
  type: TYPE_NORMAL
- en: Analysis for new employee onboarding, Error Prevention
  prefs: []
  type: TYPE_NORMAL
- en: 'Heuristic influences: *If there are errors*, *confirm any understanding*, *provide
    details at each step* and *For less* *well-known questions*'
  prefs: []
  type: TYPE_NORMAL
- en: An onboarding process offers ample opportunity for errors. The user, terms,
    and process are all new.
  prefs: []
  type: TYPE_NORMAL
- en: 6 – Recognition rather than recall
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Minimize the user’s memory load by making elements, actions, and options visible.
    The user should not have to remember information from one part of the interface
    in another. Information required to use the design (e.g., field labels or menu
    items) should be visible or easily retrievable* *when needed.*'
  prefs: []
  type: TYPE_NORMAL
- en: Be familiar with recognition versus recall. It is easier to recognize choices
    from options (such as a menu) because the brain can recognize these values to
    know which is right, unlike recall, where the user has to search their memory
    for a cue. “Who was the 16th president of the United States?” is harder to recall
    than recognizing that “*Was Abraham Lincoln the 16th president of the United States?*”
    is true. The science of this is rather interesting.
  prefs: []
  type: TYPE_NORMAL
- en: 'Article: [Memory Recognition and Recall in User Interfaces](https://www.nngroup.com/articles/recognition-and-recall/)
    ([https://www.nngroup.com/articles/recognition-and-recall/](https://www.nngroup.com/articles/recognition-and-recall/))'
  prefs: []
  type: TYPE_NORMAL
- en: Analysis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This heuristic is essential and also challenging to address in conversational
    AI. There is a reason why software has menus and why those menus are organized
    and have some level of consistency. Although every software product can’t have
    the same menu items (e.g., a word processor is not a photo editing tool), there
    is a set of everyday tasks, and common words/features are used with consistent
    placement. However, expressing themselves can be challenging when users stare
    at an empty field. It could be because they are not vocal, have learning difficulties,
    aren’t working in their native language, can’t find the right words to express
    themselves, or are too distracted with other tasks to pin down how to ask a system
    to do their bidding. With a menu system, users can look around, go to a likely
    location (such as the **Edit** menu), and see whether the feature they want is
    there. This ability to recognize what they want by pointing at it is a universal
    truth: “*I will know it when I see it.*” Also, plenty of menu usability issues
    can hinder performance – for example, when not using words in a feature name that
    matches the user’s expectation. With conversational AI, especially chat experiences,
    fine-tune systems to understand a wide range of expressions for a common task
    or feature, as discussed in a few of the heuristics already. However, humans still
    have to recall words.'
  prefs: []
  type: TYPE_NORMAL
- en: This is one reason why menus appear in some hybrid experiences. It gives the
    user standard anchors to drive decision-making. If the system can present the
    five things a user will always do, then sharing these tasks as buttons or in a
    menu on a conversational AI helps them overcome the recognition versus recall
    problem. However, as the number of functions now approaches the hundreds in a
    conversational enterprise app, providing a menu for all of them is unreasonable.
    Giving them five items when it can do 100 can limit the customer’s ability to
    see the more considerable capabilities of the solution.
  prefs: []
  type: TYPE_NORMAL
- en: 'As discussed earlier, the problem gets more challenging in a straight voice
    interface because humans need help keeping track of many choices in their heads.
    This has been known since the dawn of computing (G.A. Miller, *The magical number
    seven, plus or minus two: Some limits on our capacity for processing information,
    Psychological Review*, 63(2), 81–97, 1953). Although our understanding has evolved,
    a human’s ability to handle choice has yet to. There is a psychological limit
    to how many options make sense in a voice menu. This is why hierarchies in phone
    trees exist; they help break down large groups of actions into well-understood
    categories. Expose the user to pick a category first and then disclose the options
    once within the category. Lotus 1-2-3, the spreadsheet app, famously invented
    this kind of progressive disclosure of menus in software. 1-2-3 was the first
    killer app for personal computers in the 1980s.'
  prefs: []
  type: TYPE_NORMAL
- en: It is common to have trouble remembering a phone number when told on a call.
    It becomes a challenge to hang up fast enough to recall the number (473-867-5309)
    and dial it without forgetting. Human memory is a problem for UIs.
  prefs: []
  type: TYPE_NORMAL
- en: 'This leaves us with a dilemma in conversational AI. Users are much better at
    recognizing choices than recalling them, yet there is a limited capability to
    resolve this in a voice channel or a chat window. More room is needed to build
    robust views into vast feature sets, even on channels that support menus and buttons.
    Some tricks can mitigate this UX problem:'
  prefs: []
  type: TYPE_NORMAL
- en: Fine-tune to allow for flexibility in understanding terms. Understand how knowledge
    refers to products, features, or services.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitor and adapt support for new terms for existing features or tasks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Disambiguate when requests are not explicit between multiple choices.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Provide hints and suggestions when the next step is likely.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Provide menus in limited approaches when valuable and popular tasks or actions
    are likely.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Help guide the user if they need help figuring out what they can do. If errors
    or multiple errors occur, it might be time to use a secondary prompt that guides
    the user more explicitly (step by step or with more detailed instructions, for
    example). If the user asks for help, then the LLM can be more supportive in the
    same way. See an example of this advice in the heuristic *5—Error prevention*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Depending on the ChatGPT implementation, there might not be much to do on screen.
    Still, the team can undoubtedly care and feed the solution to allow more understanding
    with prompt engineering, fine-tuning, and knowledge refinement. Narrow down the
    options by disambiguating common misunderstandings when there is no context to
    decide which direction to go.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: This is easier said than done in generative models, but keep it in mind when
    prompt engineering or using ChatGPT behind a deterministic experience.
  prefs: []
  type: TYPE_NORMAL
- en: Recall the different ways someone might refer to Oracle Database (RDBMS, Oracle
    Server, Enterprise Edition, DB 12, etc.…); being flexible in understanding all
    of these will make engaging the customer easier. This means being sure of the
    proper training data.
  prefs: []
  type: TYPE_NORMAL
- en: 'A critical part of this heuristic is remembering information from one part
    of a UI in another. This can mean contextual understanding. This is very important
    in conversational UIs. Continue to know who the customers are and what they are
    doing by keeping the context of previous conversations. This would be expected
    when calling a call center for product support. They have the transcripts or interactions
    of earlier calls, order history, and account information. Isn’t it expected that
    the conversational AI, no matter what the UI entails, should understand and adapt
    interactions based on this information? Absolutely. And as product leaders, we
    demand that intelligence. So, this part of the heuristic is worth checking to
    ensure the user can do more (tasks) with less (information):'
  prefs: []
  type: TYPE_NORMAL
- en: Pick up where they left off. Each LLM starts with little or no knowledge of
    prior conversations. LLMs are growing their understanding of previous conversations.
    Without enough knowledge, consider storing the last conversation and providing
    it in the context window.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Know the user’s history, behavior, and previous needs to help with current interactions
    (returns, product help, orders, shopping behavior, etc.). Use this history to
    build a prompt with the current context.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understand the sentiment of previous conversations. If this interaction is confrontational,
    adapt the style and tone.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Analysis for new employee onboarding, recognition rather than recall
  prefs: []
  type: TYPE_NORMAL
- en: 'Heuristic influences: *verify completion*, *provide the status of each step*,
    *Each step should be clear and concise*, *Do not ask the new employee to remember
    information*, *Provide details at each step*, and *well-known questions*'
  prefs: []
  type: TYPE_NORMAL
- en: There is a wide range of prompt details that help the user make decisions right
    in front of them. It explicitly calls out that the new employee should not be
    required to remember information. How this would play out in a real onboarding
    experience would have to be seen. They can recognize where they are and see the
    results of how they are doing. In the worst case, the conversation history is
    also there to help remind them of steps or status.
  prefs: []
  type: TYPE_NORMAL
- en: 7 – Flexibility and efficiency of use
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Shortcuts – hidden from novice users – may speed up the interaction for the
    expert user so that the design can cater to inexperienced and experienced users.
    Allow users to tailor* *frequent actions.*'
  prefs: []
  type: TYPE_NORMAL
- en: Analysis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In chat UIs, flexibility and efficiency can be seen as trade-offs. Conversational
    AI chat windows offer lots of flexibility; anything can be said. However, getting
    the correct answer or completing a task might not be the most efficient path.
    Let’s take an example of filling out an expense conversationally:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'However, starting that same conversation without any context can reduce the
    efficiency of the process. Here is a long-winded version to make the point:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Be efficient with interactions. A little later in the chapter are some excellent
    examples of making conversations manageable by reducing and combining questions
    that make sense. All of this sort of form-filling that is done conversationally
    requires thought. Ask questions that can fill the fields as efficiently and intelligently
    as possible. Doing conversational interactions one tiny piece of information at
    a time is annoying. It gets back to using the right tools for the job.
  prefs: []
  type: TYPE_NORMAL
- en: I saw an example of a COVID-19 screener that was built conversationally. It
    could have been more pleasant. It asked 14 questions, which required me to wait
    for each question to appear, read it, and then answer it with textual answers.
    The same experience done as a form would be three times faster and less headache
    and work. It is easier for a user to look ahead with written forms and UI wizards.
    A user can check a box while looking ahead to read the next question. There is
    also context on a well-designed form providing clues on how much is completed
    and what is left to do. With these conversational UIs, it sometimes appears that
    the questions will go on forever. Be thoughtful about the questions so that the
    process is efficient. Watch for opportunities for improvement through better questions,
    eliminating steps, and using defaults while allowing the user to edit and adjust
    responses.
  prefs: []
  type: TYPE_NORMAL
- en: Analysis for new employee onboarding, flexibility and efficiency of use
  prefs: []
  type: TYPE_NORMAL
- en: 'Heuristic influences: *Keep track of the errors*, *the user can complete steps
    in* *any order*'
  prefs: []
  type: TYPE_NORMAL
- en: It is fair to wonder how efficient a conversational AI is for onboarding. Keeping
    track of status, being reminded of tasks, being alerted to issues in some of the
    steps, guiding the user on the next steps, and being given access to sites or
    links seems reasonable. Especially on a communication channel the user already
    has and monitors. But if you asked me to fill out an employment application *in*
    a chat, that would be wrong.
  prefs: []
  type: TYPE_NORMAL
- en: 8 – Aesthetic and minimalist design
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Interfaces should not contain information that is irrelevant or rarely needed.
    Every extra unit of information in an interface competes with the relevant units
    of information and diminishes their* *relative visibility.*'
  prefs: []
  type: TYPE_NORMAL
- en: Analysis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We can only do so much to be minimalistic beyond providing an empty textbox.
    In a pure voice experience, minimalism comes into play by keeping our utterances
    brief. The same can apply to recommender experiences. Provide the headline, and
    if needed, let the user explore further. Only a few details are required most
    of the time. In traditional UIs, expanding areas, help bubbles, or drill-down
    links expose more information. Apply the same logic to recommendations or even
    chat experiences. If the user replies, “*I don’t understand,*” or “*Explain please,*”
    be prepared to draw on product help, knowledge, and context to provide relevant
    information to accommodate the user. One approach is to step back to become more
    of a guided coach. Instruct the model to change its approach:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: I am not a good source of information regarding aesthetics. Generally, these
    experiences are within a larger corporate framework with an established style
    and visual aesthetic. Only in rare cases would this impede the usability of a
    conversational design. It is easy to appreciate a well-designed and visually appealing
    experience. It would be best to design something functional over an experience
    that looks great but makes the customer bash their head against a wall because
    it lacks basic usability, as described by the other nine heuristics.
  prefs: []
  type: TYPE_NORMAL
- en: Analysis for new employee onboarding, aesthetic and minimalist design
  prefs: []
  type: TYPE_NORMAL
- en: 'Heuristic influences: *Each step should be clear and concise*, and *clear,*
    *simple terms*'
  prefs: []
  type: TYPE_NORMAL
- en: Minimalism is important in a chat flow, especially when one is expected to be
    on the phone, like in an onboarding experience. Keeping steps and messages clear
    and to the point will be best.
  prefs: []
  type: TYPE_NORMAL
- en: 9 – Help users recognize, diagnose, and recover from errors
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Error messages should be expressed in plain language (no error codes), precisely
    indicate the problem, and constructively suggest* *a solution.*'
  prefs: []
  type: TYPE_NORMAL
- en: Analysis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the next section, we reiterate this point in the examples of style and tone
    guidelines, starting with the examples coming up soon with *Figure 9**.2*, which
    says not to blame the user when things go wrong. Since almost everything in conversational
    design is about words, it stands to reason that error messages adhere to the same
    guidelines and style that the rest of the interactions contain. Users should never
    see **Error 454-24 System Overflow Buffer Failed to Execute Transaction**. Create
    checks and balances to ensure that if something goes off the rails, there is a
    way to explain it in plain language and how it should be resolved (why and then
    how, as illustrated in *Figure 9**.3*). Sorry, we don’t want to repeat the images,
    be patient; they are coming up.
  prefs: []
  type: TYPE_NORMAL
- en: Analysis for new employee onboarding, users recognize, diagnose, and recover
    from errors
  prefs: []
  type: TYPE_NORMAL
- en: 'Heuristic influences: *clear and concise*, *Keep track of the errors*, *the
    user can complete steps in any order*, and *explain how to* *fix them*.'
  prefs: []
  type: TYPE_NORMAL
- en: The prompt emphasizes style and tone and includes the importance of communicating
    status, mainly if errors occur and how to recover.
  prefs: []
  type: TYPE_NORMAL
- en: 10 – Help and documentation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*It’s best if a system doesn’t need any additional explanation. However, it
    may be necessary to provide documentation to help users understand how to complete*
    *their tasks.*'
  prefs: []
  type: TYPE_NORMAL
- en: Analysis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: How often have you read help and documentation for a mobile phone app? I suspect
    most of you will answer rarely. With tasks and features that are self-documenting
    or have a simple flow, most users follow the happy paths and are good to go. However,
    in enterprise solutions, many paths are needed, customization is typical, and
    complexity abounds, causing user confusion and needing help and documentation,
    even with the best experiences. A conversational experience that has to handle
    all of that can also be complex. Sometimes, we adopt the 80/20 rule – 80% of the
    use of a product from 20% of the UI. With modern analytics, we can learn far more
    about usage. Start by supporting the likely flows (the primary use cases) in conversational
    AI and keep the more complex interactions in the traditional UI. Handle more complex
    flows as conversational AI matures and usage warrants their inclusion. We covered
    that a few times in [*Chapter 3*](B21964_03.xhtml#_idTextAnchor058)*, Identifying
    Optimal Use Cases for ChatGPT*. This will happen slower than the rapid pace of
    AI models coming online.
  prefs: []
  type: TYPE_NORMAL
- en: Backend systems are still restrictive and expect data in a certain way. Although
    generative AI can be used in many ways (frontend understanding, translation in
    the middle, and data mapping in the backend), significant work is needed to make
    this happen. There is no magic here. But AI can also be good at providing small,
    refined answers from a robust and extensive help suite, translating it, or even
    adapting it to a different style or tone.
  prefs: []
  type: TYPE_NORMAL
- en: So, ChatGPT can help explain complexity by taking documentation and applying
    a style or tone that might be more understandable by a target user, finding insight
    deep in large help documents, or providing documentation in the user’s native
    language. Consider checks and balances here. ChatGPT better not mangle a step-by-step
    process in the documentation and return incorrect steps and procedures. This is
    where the chaining of prompts from [*Chapter 8*](B21964_08.xhtml#_idTextAnchor172),
    *Fine-Tuning,* comes into play. Chaining can be used to validate critical tasks.
  prefs: []
  type: TYPE_NORMAL
- en: There are many opportunities to advance the state of a solution by adapting
    approaches to help and documentation. This help can also be done inline. The next
    section, *Building Conversational Guidelines*, has excellent examples, starting
    with *Figure 9**.1*, where language is adapted based on the user’s expertise.
    A new user can receive more help and guidance in a process, while for an expert
    who doesn’t need this, it is better to be less chatty and more direct. This is
    similar to GUIs, where wizards walk a user through steps of a long process or
    provide an advanced experience with less context and fewer steps.
  prefs: []
  type: TYPE_NORMAL
- en: Analysis for new employee onboarding, Help and documentation
  prefs: []
  type: TYPE_NORMAL
- en: 'Heuristic influences: *Provide details at each step* and *explain how to* *fix
    them*'
  prefs: []
  type: TYPE_NORMAL
- en: The prompt ingrains the call for help. Conversational flows should typically
    self-document for details, explanations, and guidance. If not, links can be provided
    to traditional documentation. The concept of progressively increasing the level
    of the help supplied or tuning the details of inline help based on user profile
    characteristics are called adaptive messages. Examples of this will start in the
    upcoming section *Building* *conversational guidelines*.
  prefs: []
  type: TYPE_NORMAL
- en: This covers Jakob’s ten heuristics. Applying them to UI elements is well-documented
    and entrenched in the UXD world. Using them to model behavior for an LLM is new
    and untested. ChatGPT 4o behaves well with prompts like this, but it would require
    real-world data to validate this approach at scale. From testing, it seems worth
    the investment to consider the heuristics when writing enterprise instructions
    for models.
  prefs: []
  type: TYPE_NORMAL
- en: Is there an 11th possible heuristic?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I want to mention A18y again in our discussions. Jim Ekanem is a proponent of
    distinct accessibility heuristics. Much of what was discussed in the ten heuristics
    can all be considered in the context of A18y. A18y should be considered at every
    step. Jim proposes a new heuristic to follow A18y guidelines. This is not a heuristic,
    but to be fair, the concept of accessibility and inclusivity is still valid. Inclusivity
    was covered a few times, and bias in model data can affect quality.
  prefs: []
  type: TYPE_NORMAL
- en: 'Article: [Proposal to include Accessibility as the 11th Heuristic](https://uxmag.com/articles/why-we-need-11-usability-heuristics)
    ([https://uxmag.com/articles/why-we-need-11-usability-heuristics](https://uxmag.com/articles/why-we-need-11-usability-heuristics))'
  prefs: []
  type: TYPE_NORMAL
- en: '*Design for accessibility and inclusion by following guidelines and best practices
    to accommodate diverse cognitive and* *physical abilities.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Consider social identities and address systemic barriers and biases. Reflect
    on the impact of design decisions on* *marginalized communities.*'
  prefs: []
  type: TYPE_NORMAL
- en: The heuristic *4 - Consistency and standards* didn’t mention cognitive and physical
    abilities. Accessibility guidelines, discussed in an earlier chapter, should be
    part of the evaluation process for conversational AI. It won’t impact backend
    solutions and is of limited value for recommendations, but it can have significant
    implications for voice channels, for example. For a voice-only feature, what is
    the alternative for those who can’t speak or hear? Will the system work using
    a **Telecommunications Relay Service** (**TRS**)? Do requests for a selection
    or typing of a number, say a credit card number, time out too quickly? Would a
    time-out cause problems if an intermediary were relaying this communication, thus
    delaying responses by 30 seconds? If services are offered via messaging or voice,
    include viable alternatives. This is an example of accommodation; think broadly
    about inclusivity.
  prefs: []
  type: TYPE_NORMAL
- en: Bias was touched on earlier around language and cultural support for conversational
    interactions. Even in simple concepts such as expense reporting, there are cultural
    implications for inclusiveness. For example, recording an expense trained on travel
    in the US covers items such as taxis, Ubers, lifts, car services, and limos. However,
    each country has unique services, such as BlaBlaCar for carpooling in France,
    Cabify in Spain, Didi in China, and Ola in India. Being inclusive means including
    the understanding of these car services. It is not just about cultural awareness
    to deploy tools in those countries; if the customers are from the US and visit
    those countries, they might want to expense “a BlaBlaCar for 20 euros” on their
    US-based expense report. Being inclusive and thinking about cultural issues can
    also benefit the home country. However, for an A18y discussion, ensure that groups
    of people who have typically been sidelined are afforded the same opportunity
    to use LLM solutions successfully.
  prefs: []
  type: TYPE_NORMAL
- en: Language and dialect support can be a major issue. For instance, if rural villagers
    in India access government services via a phone-based LLM, even on inexpensive
    flip phones, what are the chances their language or dialect is supported? The
    2011 India census reported 121 languages spoken by at least 10,000 people, with
    22 officially recognized languages and thousands of dialects.
  prefs: []
  type: TYPE_NORMAL
- en: If the ten heuristics are followed in spirit, the 11th isn’t needed; it should
    be implicit. If the organization isn’t as advanced as it should be, the accessibility
    “heuristic” might help fill the gaps.
  prefs: []
  type: TYPE_NORMAL
- en: These heuristics can be used to evaluate any experience, including conversational
    AI. It should be clear that these are not guidelines. However, it is reasonable
    to have guidelines that developers can quickly follow. Adapt and adopt a company-wide
    set of conversational guidelines.
  prefs: []
  type: TYPE_NORMAL
- en: Building conversational guidelines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A guideline can be built into a test case. It forces people to follow a defined
    solution. The testing software can test for a specific font or size in a page
    header or a button label that doesn’t use a term an organization forbids (such
    as *abort*, *kill*, or *execute*). Doing something precisely, the same every time
    isn’t very conversational. Repeatability and consistency are crucial in enterprise
    solutions that don’t always match a conversational style, tone, and engagement.
    Consider that the LLM can understand a range of phrases while a fixed traditional
    test suite has little flexibility, although a test could look for one phrase from
    a collection of options.. The testing we did in the earlier chapters is a form
    of validation and can be used to address if the model is acting as expected for
    areas like following the ten heuristics or adhering to specific guidelines.
  prefs: []
  type: TYPE_NORMAL
- en: Develop guidelines by drawing on existing resources and consider the use cases.
    While most guidelines apply to a hybrid UI, and some will work for a conversational
    UI (text or voice), even less will apply to a standalone AI-driven recommender.
    And this makes sense; the more complex the possible experience, the more guidelines
    apply.
  prefs: []
  type: TYPE_NORMAL
- en: Then, there is the issue of getting the experience to follow the guidelines.
    Just because a prompt tells ChatGPT to follow specific instructions doesn’t mean
    it will. When using deterministic coding approaches, design is dictated. This
    is much harder with an LLM. Recall how **Temperature** and **Top P** were adjusted
    in [*Chapter 7*](B21964_07.xhtml#_idTextAnchor150), *Prompt Engineering*. There
    is some control from prompt engineering and fine-tuning to focus the LLM on how
    to speak to the customer.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are three areas to get values from conversational guidelines. Historical
    references were provided earlier in this chapter, such as the work of Smith and
    Mosier (1986); let’s get more up-to-date with the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Web guidelines
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A sample guideline set for hybrid UIs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Some specific style and tone guidelines with examples
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Web guidelines
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Conversational guidelines will adjusted emerge from a few sources. First, the
    big players will take their existing web guidelines and expand on them to include
    more generative AI components. Apple, Google, Microsoft, Amazon, and others will
    all have something to say, and most likely, they will feed off each other as they
    have in the past. Sometimes, inadequate guidelines appear because one group didn’t
    know any better and didn’t do any of their research or testing to define their
    guideline. Thus, when someone learns from a mistake and changes their guidance,
    others who copied it have to figure out why this changed and decide whether to
    adopt the new patterns. This has happened multiple times with Amazon and Google
    designs so that it can happen to anyone.
  prefs: []
  type: TYPE_NORMAL
- en: The AI players will have guidelines as they learn that design matters and how
    poor interactions impact the overall experience. They will do this to help their
    customers make successful solutions, as their models typically depend on usage.
    If customers stop using the models, their bottom line will be affected.
  prefs: []
  type: TYPE_NORMAL
- en: Use what is available today as a guide. Caveat emptor. Let the buyer beware.
    Every guideline adopted should have a reason and a solid underpinning. Apple Intelligence
    will likely have guidelines, while Microsoft’s are currently fairly high-level.
    There is little out there.
  prefs: []
  type: TYPE_NORMAL
- en: 'Article: [Microsoft Guidelines](https://learn.microsoft.com/en-us/training/modules/responsible-conversational-ai/)'
  prefs: []
  type: TYPE_NORMAL
- en: ([https://learn.microsoft.com/en-us/training/modules/responsible-conversational-ai/](https://learn.microsoft.com/en-us/training/modules/responsible-conversational-ai/))
  prefs: []
  type: TYPE_NORMAL
- en: 'Training: [Conversation Design from Salesforce](https://trailhead.salesforce.com/content/learn/modules/conversation-design)
    (free, but requires registration) ([https://trailhead.salesforce.com/content/learn/modules/conversation-design](https://trailhead.salesforce.com/content/learn/modules/conversation-design))'
  prefs: []
  type: TYPE_NORMAL
- en: After finishing this book, you could reverse-engineer some guidelines by looking
    at the conversational UI design thread and examples on Dribbble.
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples: [Dribble catalog of inspirations for conversational AI](https://dribbble.com/tags/conversational-ui)
    ( [https://dribbble.com/tags/conversational-ui](https://dribbble.com/tags/conversational-ui))'
  prefs: []
  type: TYPE_NORMAL
- en: Very few guidelines exist, but what is there is solid, if not generic, and consistent
    with what we are discussing. However, much of the content is for those building
    solutions, not for those designing experiences. Even Coursera has nothing to offer
    at this time. Hence, the reason for this book! So, it’s time to make do and create
    our own set of guidelines.
  prefs: []
  type: TYPE_NORMAL
- en: A sample guideline set for hybrid chat/GUI experiences
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One challenge is to follow existing GUI guidelines and deal with conversational
    guidelines. There are conflicts, the most common of which is with language. A
    traditional UX doesn’t use contractions, while UI language is more formal, sometimes
    abrupt, and undoubtedly less conversational. I have seen guidelines built into
    automated software testing checks that fail with conversational text.
  prefs: []
  type: TYPE_NORMAL
- en: '*On top of that, if the generative UI directly creates text, there is less
    control.* This is like telling a teenager to be home by 10 p.m. They might say
    they will but might not arrive on time. That is prompt engineering. The guardrails
    might be suitable, but they are only sometimes followed. The guidelines can help
    with prompt engineering. They can certainly be followed in a recommender template.'
  prefs: []
  type: TYPE_NORMAL
- en: On GitHub is a checklist of GUI guidelines, roughly organized by the ten heuristics.
    These were initially adapted from a list generated at MIT, but the original list
    has been lost to history. There are two sheets – a short version and a lengthy
    one on the second worksheet tab. Most apply to traditional GUI or web applications,
    while some cross over to conversational AI. Here are examples for helping users
    recognize, diagnose, and recover from errors.
  prefs: []
  type: TYPE_NORMAL
- en: 'Error messages should be expressed in plain language (no error codes), precisely
    indicate the problem, and constructively suggest a solution:'
  prefs: []
  type: TYPE_NORMAL
- en: Undo is supported, where possible
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Guidance is clear
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unusual answers to common questions are validated or confirmed
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a choice is too complex conversationally, offer suggestions if they are likely
    or examples if any of the choices are unlikely
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'GitHub: [Guidelines typical of a GUI and supporting conversational experiences](https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter9-HeuristicsChecklist.xls)
    ([https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter9-HeuristicsChecklist.xls](https://github.com/PacktPublishing/UX-for-Enterprise-ChatGPT-Solutions/blob/main/Chapter9-HeuristicsChecklist.xls))'
  prefs: []
  type: TYPE_NORMAL
- en: I suspect something similar is in every enterprise, but if not, feel free to
    adapt these. Then, consider applying the user scoring method to the issues found.
  prefs: []
  type: TYPE_NORMAL
- en: Here is one related takeaway from my Master’s thesis, *Effects of Graphical
    UI Inconsistencies on Subjective and Objective Measures of Usability*. Consistency
    from screen to screen doesn’t matter as much as matching a user’s needs to the
    experience. There are a lot of forced designs where the UX must use a specific
    component to “be consistent.” This is ostensibly for the user, but it is really
    to ease the burden on the development team. If the component is wrong, the user
    will suffer. So, be consistent with the user’s needs and expectations. Google
    search and ChatGPT are your friends here to gather guidelines. So, next, we can
    dive further into conversational-specific guidance.
  prefs: []
  type: TYPE_NORMAL
- en: Some specific style and tone guidelines with examples
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In a conversational UI, we can create prompts to control the style and tone.
    In a hybrid UI, some UI elements will have static text. With a voice interface,
    there is *only* the spoken text. At least on a chat UI screen, it is easy to review
    material, copy and paste it, or compare it to something else on the screen. Getting
    words into the proper form is so important. Here is a glimpse into some of the
    guidelines I have shared over the years; use them or adapt them as needed. In
    a conversational AI, I would convert these to prompts.
  prefs: []
  type: TYPE_NORMAL
- en: The trick is to understand how much control is available. In older chat experiences,
    a generative AI could be added to do specific tasks behind the scenes, like entity
    detection or for cases of redirection or repair. The generative AI is not having
    the conversation. The conversation is controlled by the deterministic flows designed
    in the Chat platform. In that case, the exact wording expected in a particular
    step in a task flow is scripted beforehand. Alternatively, with a recommender,
    specific templates for a response are created, and the AI fills in the details.
    But if the front end is the ChatGPT LLM, prompt engineering and fine-tuning are
    needed to communicate in a style and tone appropriate for the user.
  prefs: []
  type: TYPE_NORMAL
- en: Some of these guidelines are closer to heuristics. Each example tells a story
    about how messaging and communication can improve. Recognize that the *message
    is the interface*, especially on a voice channel. As you’ll see in the upcoming
    figures, I have color-coded each row. Yellow means it is okay and not that exciting;
    green is good, while dark green is better. Red means don’t do it!
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: An LLM can force specific wording for a task flow. Templates and traditional
    chat solutions can prompt the user in a particular way with exact wording. The
    LLM can be *guided* to answer certain questions, but this is not a scalable solution.
    For every guideline, consider how a prompt template can be used to customize the
    LLM instructions to cater to the use case, the context, and the user.
  prefs: []
  type: TYPE_NORMAL
- en: Use adaptive messages
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: People adapt their messaging over time as they become familiar with other people.
    If you are comfortable with someone, you talk in short-cuts. An LLM can work the
    same way. Customer usage data can be used to tweak prompt templates. For a new
    user, prompt for instructions to be more verbose, for someone who has done this
    task many times could be interacting with instructions that tell the LLM to “*be
    terse and to the point,*” “*only repeat the primary information,*” and so on.
  prefs: []
  type: TYPE_NORMAL
- en: As shown in *Figure 9**.1*, as the user becomes more experienced, the messages
    can adapt to acknowledge and interact with the customer. Trust must be earned,
    so don’t assume the customer trusts the system from the outset.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B21964_09_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.1 – Adapt messaging to the user’s expertise
  prefs: []
  type: TYPE_NORMAL
- en: Each of these messages is good on its own. Expect customers to need less handholding
    as they become comfortable with the conversational experience. This is similar
    to how we are with people we know and trust. Don't over-explain and they don’t
    need to mirror back to us actively. They get it.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, humans need to remember, so if the user is an expert but has not
    used the experience in months, prompt them with more context to get them started
    again. The **Got it** response is aspirational. The AI must be incredibly trustworthy
    for that to be a response. And if they get something wrong, don’t blame the user.
  prefs: []
  type: TYPE_NORMAL
- en: Don’t blame or confuse the user
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As in *Figure 9**.2*, it is not the user’s fault when things go wrong.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B21964_09_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.2 – Don’t blame the user, and don’t use jargon
  prefs: []
  type: TYPE_NORMAL
- en: Consider how many ways failure could occur in a system. Yes, the user could
    have made a mistake, but belittling them won’t help the cause. Try to speak to
    them as they want to be spoken to.
  prefs: []
  type: TYPE_NORMAL
- en: Although a **PIN** might be familiar to older adults in the US, it sometimes
    translates poorly, and few under 30 will know what that stands for (**Personal
    Identification Number**), even if they understand the meaning. They might need
    to learn the industry terms, company technical jargon, and customer shortcuts.
  prefs: []
  type: TYPE_NORMAL
- en: Let me tell a quick story about blaming the user. I called my dad and asked
    for a phone number for someone he knew. Later, I called that number, and it didn’t
    work. My first instinct was, “*My dad gave me the wrong damn number.*” That is
    just me – I needed to work on being a better human being.
  prefs: []
  type: TYPE_NORMAL
- en: So, my dad could have been given the wrong number, he could have written down
    the wrong number, he could have been given the wrong number, or even I could have
    heard it wrong and written it down incorrectly. So, why blame my dad? Similarly,
    who knows what is wrong with the user’s input? Please don’t blame the user; respect
    what was received didn’t work and prompt them for the correct information. And
    I should follow my advice and be a better person.
  prefs: []
  type: TYPE_NORMAL
- en: Why, and then how – confirm first, and then instruct
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As shown in *Figure 9**.3*, a standard structure for error messages applies
    to conversational AI. This was taught to me by a great writer at Oracle. Multiple
    guidelines can apply to one phrase, like this one. Remember, don’t use jargon.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, language is harsher than it should be. Never use terms such as *corrupt*,
    *execute*, *kill*, and *abort*, which can elicit strong customer reactions, translate
    poorly, and not help us move forward (except in rare cases like referring to the
    **Kill** command in UNIX).
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B21964_09_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.3 – Why, and then how – confirm first, and then give instructions
  prefs: []
  type: TYPE_NORMAL
- en: Control the length of messages and continue to be concise and economical. People
    often fail to read prompts entirely or skim and can miss critical information.
    Get to the point and then express what should be done about it.
  prefs: []
  type: TYPE_NORMAL
- en: 'If an LLM generates the message or recommendation, it can be told to limit
    the length and be friendly. If you don’t, you can have 300-word responses when
    30 would do. You probably think the same thing about this book: it should be 100
    pages shorter. Keep reading; we have more to cover.'
  prefs: []
  type: TYPE_NORMAL
- en: Be conversational – don’t regurgitate system descriptions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As shown in *Figure 9**.4*, just because a database has a field name doesn’t
    mean the user wants to see it. Consider how to ask questions to reduce errors
    and how concise it should be. And this example exposes a few other good ideas.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B21964_09_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.4 – Adapt your messaging to the user’s expertise
  prefs: []
  type: TYPE_NORMAL
- en: In this example, user testing resulted in two prompts being combined to form
    the **Best** option. This reduced the number of prompts required to determine
    the missing information and was clear enough that most people answered with both
    pieces of information. If they missed giving the reason, for example, we could
    still probe for that. It was also essential to be transparent about events and
    expenses, as some people thought about their guests and needed to remember to
    include themselves in the count. This might seem odd, but some companies have
    backend checks to verify the money spent per person on events. The calculation
    must include the host; otherwise, automation might flag an expense as too expensive.
  prefs: []
  type: TYPE_NORMAL
- en: 'Recall our discussion about backends. Information must be sent back in a specific
    format. ChatGPT is excellent at extracting the business purpose and the number
    of attendees using digits, as shown in our previous example. Most chat solutions
    had a lot of trouble with this logic before LLMs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Streamline-related tasks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*Figure 9**.5* is a follow-up to *Figure 9**.4*. It shows an opportunity to
    ask related questions in a way that can be done in one step instead of two. Be
    careful with generative AI solutions that can ask too much; these examples make
    the point. Combining related requests into a single question can reduce the number
    of steps and maintain intelligence and conversational expectations. If two or
    three pieces of information were unrelated, asking for it at once might need clarification
    and is likely more complex to parse and understand.'
  prefs: []
  type: TYPE_NORMAL
- en: This is where generative AI can supplement deterministic conversational tools.
    A traditional conversational chat platform might handle the forms and complex
    interactions, while ChatGPT parses and normalizes data sent to the backend. When
    applicable, prompts can ask for multiple pieces of information.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B21964_09_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.5 – Streamline-related tasks when it is conversational
  prefs: []
  type: TYPE_NORMAL
- en: Guide and nudge – don’t force an issue if it is unnecessary
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As shown in *Figure 9**.6*, the persona will likely engage the user in a coaching
    and supportive way. However, not all transactions need to be completed immediately.
    If the user must submit something, so be it, but sometimes, like with expenses,
    it is reasonable to submit all of them once the trip is complete. This is when
    nudging is likely enough.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B21964_09_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.6 – Guide and nudge users – don’t force them
  prefs: []
  type: TYPE_NORMAL
- en: Our **Bad** example is direct but is too concise, and maybe unclear to the meaning
    of the word "done.". This didn’t guide the user at all. In our **Best** example,
    it got more forceful, with some outstanding expenses for the ten days mentioned.
    It should take a firm stance when needed to force the user. To take this example
    further, if the expense report was due, the system could email the user; if the
    expense report was overdue or the company was getting expenses in for the end
    of the year, we could require it to be submitted now, if not let the user know
    it will be auto-submitted.
  prefs: []
  type: TYPE_NORMAL
- en: No dead ends – give a user a path to success
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As shown in *Figure 9**.7*, this is like wanting to lead the horse to water
    (even if we can’t make them drink it). In traditional UIs, there is a mantra –
    *no dead ends*. When we read an article on a news site and reach the end, we expect
    to see related articles that might interest us. There should be a path forward.
    The user and the business don’t want to abruptly end a conversation when there
    is an expected forward path – even if, as shown in this example, the path forward
    goes to a different UI. If the problem can’t be solved, give them a way out.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B21964_09_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.7 – Don’t allow interactions to have a dead-end
  prefs: []
  type: TYPE_NORMAL
- en: The conversational UI can’t resolve the issue directly in this example, so a
    backdoor is provided. Don’t leave them hanging with an error or abrupt dead end,
    which is hard to do with prompting, but we can try our tricks by providing the
    LLM with instructions and examples. Again, this is more directly applicable when
    writing dialogs where a chat solution is supplemented with LLM for parsing. Instruct
    the LLM to provide this kind of link when all else fails.
  prefs: []
  type: TYPE_NORMAL
- en: 'ChatGPT can do this from the prompt. It knows how to store instructions in
    memory for later in the session:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Conversational but not chatty
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*Figure 9**.8* re-explores the item from the earlier example – asking for the
    number of attendees. It’s okay to have longer messages if there is value in the
    additional words. Research found the phrase “*number of attendees*” confusing
    because the host of an event doesn’t consider themselves an attendee, so changes
    were tested to tackle this head-on by adding “*including yourself*.”'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B21964_09_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.8 – Adapt messaging to the user’s expertise
  prefs: []
  type: TYPE_NORMAL
- en: Use the right terms
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Language is tricky, as *Table 9.2* shows. When designing conversational experiences,
    consider how to communicate with users with the correct terms.
  prefs: []
  type: TYPE_NORMAL
- en: '| **Term** | **Description** | **Example** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| **Choose** | When you have free will | Choose four free toppings for your
    pizza. |'
  prefs: []
  type: TYPE_TB
- en: '| **Select** | When we force a decision | Select your age. |'
  prefs: []
  type: TYPE_TB
- en: '| **Sign-in** | To gain access to your account | Sign-in (avoid using login).
    |'
  prefs: []
  type: TYPE_TB
- en: '| **Tell** | When asking for verbal or written information | Tell me your prescription
    number (avoid using *Say*). |'
  prefs: []
  type: TYPE_TB
- en: '| **I** | When the assistant is responsible | I can’t understand the image
    you sent. |'
  prefs: []
  type: TYPE_TB
- en: '| **We** | When the assistant gets help from another service | We are reviewing
    your accident with the claims department. |'
  prefs: []
  type: TYPE_TB
- en: '| **You** **or Your** | The user, the users, or their company | Your appointment
    is now confirmed. |'
  prefs: []
  type: TYPE_TB
- en: Table 9.2 – Communicate using terms that are consistent and grounded
  prefs: []
  type: TYPE_NORMAL
- en: Some words can have meaning outside of their traditional use. People still play
    a “record,” some old-timers “dial” someone’s phone number, even though the rotary
    dial phone has been gone for decades.
  prefs: []
  type: TYPE_NORMAL
- en: Pet peeve
  prefs: []
  type: TYPE_NORMAL
- en: At least most websites ask the user to “sign-in” to their application. Incidentally,
    stop asking users to “log in.” That is a terrible word to describe what a customer
    is doing. It comes from the concept of the log file that keeps track of users
    accessing a system. It can’t be more geeky than that.
  prefs: []
  type: TYPE_NORMAL
- en: 'We covered a heuristic and a few guidelines that emphasized this: Use more
    natural and relatable words from the user’s world. Conversationally, messages
    to the user include *I*, *we*, and *you*, not *the AI*, *the system*, or *the
    user*. Create a collection of terms and define how they should and should not
    be used. I use customer and user interchangeably. As the joke goes, two careers
    have users: UX designers and drug dealers. I guess context matters when talking
    about users.'
  prefs: []
  type: TYPE_NORMAL
- en: Using context makes conversations natural
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As shown in *Figure 9**.9*, a pure generative AI solution will naturally want
    to reply, hence the reason for hallucinations. But if ChatGPT is behind the scenes,
    there are plenty of conditions where a response might need to be understood. In
    any case, guide the user to a better answer, not leave them at a dead end.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B21964_09_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.9 – Context helps make conversations more natural
  prefs: []
  type: TYPE_NORMAL
- en: Don’t create unnecessary conversation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The **Bad** example shown in *Figure 9**.10* is chatty and indirect. The UI
    asks a stupid question and then gives the user even worse choices. Sometimes,
    it is a challenge because of the recognition versus recall issue discussed in
    the *Adapting heuristic analysis for conversational UIs* section, and it makes
    sense to give the user guidance.
  prefs: []
  type: TYPE_NORMAL
- en: However, in this example, the user must digest the information shared to decide
    on their next step. Understand their context of use to make design decisions.
    Give them time to process first.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B21964_09_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.10 – Don’t create additional conversations
  prefs: []
  type: TYPE_NORMAL
- en: Don’t ask questions that shouldn’t be answered. Don’t phrase follow-up responses
    as questions, like in the chatty example.
  prefs: []
  type: TYPE_NORMAL
- en: Model user language
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*Figure 9**.11* is an excellent example of **Keep it Simple Silly** (**KISS**)
    from the expense assistant at Oracle. This example was popular with conversations
    with customers and partners and at conferences because everyone had experience
    filing expenses.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B21964_09_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.11 – Model user language
  prefs: []
  type: TYPE_NORMAL
- en: Businesses in the USA have a concept called the public sector, which refers
    to government employees. Interacting with anyone from the government requires
    different rules of engagement, especially when buying someone a meal or giving
    them a small gift. Because of ethical concerns in the US and many countries, employees
    must be careful about paying for government employees’ meals. Understanding attendees
    is essential, and the correct language can help.
  prefs: []
  type: TYPE_NORMAL
- en: The words ‘employee’ versus ‘attendee’ were tested. The word *employee* refers
    to the people the user works with at their company, while *attendee* helps to
    distinguish employees from attendees. In this example, the company’s short name,
    Alli, is used to make the tone softer. It would be the same for any employee when
    dealing with an internal tool. Everyone knows who they work for; formal names
    are not needed. And finally, both the words *public sector* and *government* were
    included. The design was a hedge to include public sector customers not directly
    employed by government entities.
  prefs: []
  type: TYPE_NORMAL
- en: Flow order can reduce interactions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Figure 9**.11* had one other trick. This shows how detailed a recommendation
    template can get and how difficult it might be to pull off with prompts and fine-tuning
    examples.'
  prefs: []
  type: TYPE_NORMAL
- en: The data revealed that most meals within a company do not have government attendees
    (almost all answer the first question "Yes" and are done). Answering “no” to the
    second question eliminated any further questions. This creates an express lane
    to simplify the flow for the happy path. Few would say “yes” and require details
    such as the attendees’ names. So, by ordering the questions correctly, the user
    isn’t asked any follow-up questions.
  prefs: []
  type: TYPE_NORMAL
- en: Maintain a consistent voice and tone across interactions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In *Figure 9**.12*, there is a trigger word, *expire*. This example concerns
    the tone and spirit of the message to convey to users. A brighter tone is warranted
    if the chat is about something upbeat and fun. We can also explain the reasoning
    behind an issue (generated links sometimes stop working), so giving context helps
    the customer.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B21964_09_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.12 – Match the tone with the situation
  prefs: []
  type: TYPE_NORMAL
- en: This example also follows the why-then-how guidance from earlier. Advice is
    cumulative; three or four guidelines can support one statement. Be careful with
    tone; it can cause an issue, like in this next guideline.
  prefs: []
  type: TYPE_NORMAL
- en: The happy path is not the only path
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Design for the happy path, the likely scenario typically seen and demoed to
    customers. But what if the user goes in a different direction? Will the system
    continue to talk in that style and tone? Here’s a funny anecdote. I used this
    example about getting married in my coaching and classes for years. Then, someone
    coded the exact situation from *Figure 9**.13*. They had not attended my training.
    When I asked them to try the not-happy path for their app that helps change marital
    status, the chat responded with that same up-tempo and inappropriate answer when
    asked about getting a divorce. Remember that when writing prompts, filling in
    recommendation templates, or feeding a prompt, *the happy path is not the* *only
    path*.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B21964_09_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.13 – The happy path is not the only path
  prefs: []
  type: TYPE_NORMAL
- en: Some might argue that there is nothing wrong with being excited about a divorce;
    who are we to judge? However, don’t pass judgments that could be offensive or
    misinterpreted in an enterprise setting. This leads us to a similar suggestion
    about being cute.
  prefs: []
  type: TYPE_NORMAL
- en: Try not to be cute – it can backfire
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To follow our previous example from *Figure 9**.13*, when trying to be friendly
    and supportive, be careful not to be too cute. Wishing users a great weekend when
    closing out a Friday afternoon interaction sounds pleasant. Still, if they are
    starting the weekend shift or work in a country where the weekend doesn’t start
    on Friday, the interaction will miss the mark by trying to be cute. Instructions
    to the LLM are limited in this interaction, but most of these examples I have
    seen come from chat UIs that build this cuteness into the flows. It can come across
    in unexpected ways and be offensive in some cases.
  prefs: []
  type: TYPE_NORMAL
- en: Try not to repeat – refrain from repeating things already said
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Avoid repeating the same language as shown in *Figure 9**.14*, as the title
    of this section whimsically suggests. It is cluttering and drags down the interaction.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B21964_09_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.14 – Try not to repeat – repeating is cluttering
  prefs: []
  type: TYPE_NORMAL
- en: Interactions that require a selection could be designed in many ways depending
    on the capabilities of the UX. Recall from our discussion about terms to use the
    word *select*, not *choose,* because the currency is required. They could be asked
    to type it in (baht, dollar, etc.), choose from a list, or even use a type-ahead
    list. However, like with our heuristic, be mindful of errors.
  prefs: []
  type: TYPE_NORMAL
- en: If someone typed in `dollars`, it sounds fine, but many major currencies are
    called a dollar – 25 worldwide. Any UI would need to know the correct currency
    – Canadian, Hong Kong, US, or one of the other dollar-based currencies. Selection
    can validate the choice. However, a follow-up question to clarify a voice channel
    could be used, and active mirroring of the input can help confirm the country.
    If it is lucky, other context clues can be used to determine the country. Assuming
    the currency is also an option. Based on the user history or other submitted expenses,
    the system can tell them, “*I think this expense is in US dollars; if not, let
    me know.*” If it can be right 90% of the time, then this approach means less work
    for the user.
  prefs: []
  type: TYPE_NORMAL
- en: Do’s and don’ts for conversational style
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*Table 9.3* summarizes some of the gotchas that work for many enterprise applications.
    Prompt engineering would be challenged to be this prescriptive in its choice of
    language. But it does a good job already with the do''s. Some of the don''t are
    a little more challenging, but if you hit an issue try to prompt engineer your
    way out of it. Just monitor and report.'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Language Do’s** | **Language Don’ts** |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: Example What type of expense is this?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Example Who’s the new legal employer?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Provide simple, direct instructions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use natural phrasing and common words.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Be consistent in phrasing.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use passive voice appropriately.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use contractions naturally.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Focus on the user benefit or value.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Write for the person the LLM is interacting with.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Be proactive. Guide users with clear calls to action.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: Expense type
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Destination Legal Employer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Don’t use jargon
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Don’t be ambiguous (such as future-ready or coming soon)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Don’t use long explanations for simple issues
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Don’t stray from the task
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Don’t be cold or overbearing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Avoid the system’s reasoning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Avoid negative words such as kill, abort, crash, dumb, fatal, execute, hit,
    master/slave, and illegal.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Avoid puns, clichés, and metaphors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: Table 9.3 – Conversational do’s and don’ts
  prefs: []
  type: TYPE_NORMAL
- en: Avoid using label names; instead, use a more natural conversational style. For
    example, **Expense Type** is a form label. But conversationally, instead of the
    harsh “*What is the expense type?*”, it can soften it by saying, “*What type of
    expense is this?*” This can work for many requests for specific types of data.
    Recent testing of ChatGPT 4o shows it performs well when writing in this natural
    way. It even uses that exact phrasing when asking about types of expenses and
    then correctly uses **Expense Type:** when showing a summary of the results. Adjust
    prompts or instructions to have generative messaging that supports these do’s
    and don’ts. Add your own do’s and don’ts.
  prefs: []
  type: TYPE_NORMAL
- en: 'Bonus tip: Write three or four variations for a recommendation template and
    randomly display one of them to catch their eye. People will read an unfamiliar
    message more carefully and internalize it, which is better than ignoring it.'
  prefs: []
  type: TYPE_NORMAL
- en: Give them news they can use
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As shown in *Figure 9**.15*, there are times when the customer needs a specific
    collection of data. Generative AI might not format it correctly and doesn’t know
    the nuances of layout and conversational style. The LLM can decide which function
    to call. An example is sending a zip code or other location details to an application
    that will return the address and contact information. Still, you have to decide
    how to format the data. Or do you…
  prefs: []
  type: TYPE_NORMAL
- en: Here is a real example from a recent chat interaction that annoyed me. I did
    some work to address the issues.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B21964_09_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.15 – Give them news they can use
  prefs: []
  type: TYPE_NORMAL
- en: 'Let me highlight the issues visible in a simple message like this:'
  prefs: []
  type: TYPE_NORMAL
- en: The store could make it more personal and thus more conversational using the
    phrase “*our address.*” This would mirror how someone on the phone would provide
    these details, and with a voice interface, it would sound more natural. It could
    also be “*our store* *is at.*”
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The experience could have more calls to action. If the business wants phone
    calls, it would be a link. Some companies want to avoid encouraging calls. This
    sounds better than displaying a name/value pair. Depending on informality guidelines,
    you might not use the colon.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Format the phone number for the country to make it easier to read. Many lazy
    systems don’t format numbers for easy reading and recall. Essential human factors
    were at work when the phone companies added an area code to the seven-digit number,
    such as (473) 867-5309.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Placing a call with “click to dial” in a mobile browser, rendering clickable
    email (to send email) or web addresses (to open) and calendar events (to add to
    a calendar) as easy next steps in conversational output.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The text “**hours**” can be more readable and would vocalize better in a speech
    solution. “**:00**” is not needed. Shorter is better. AM/PM with the hours is
    not required. Hours are evident to customers unless the open hours are unusual,
    then keep AM/PM.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Consider accessibility. The abbreviated forms of the days (M–F) would be shorter
    but require some cognitive processing on the user’s part, while Monday *to* Friday
    is natural and accessible. And *to* is short, while the more accurate *through*
    is long.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Some lines were added to separate the address from the details. This allows
    for better scanning, making it easier to see one section of the result. It is
    also easier to cut and paste pieces of data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Be mindful of the device so that messages fit on the screen. In this example,
    the rest of the message was offscreen on an iPhone message window. In newspaper
    terms, anything placed *below the fold* is less visible. It won’t attract the
    same level of attention as content displayed *above the fold*, immediately visible
    on-screen. Long messages mean that, on some platforms, only the end of the message
    is shown. This requires scrolling backward to see the start of the message and
    then scrolling down again to finish the message. **Over-scrolling** was discussed
    in [*Chapter 5*](B21964_05_split_000.xhtml#_idTextAnchor108)*, Defining the Desired
    Experience*. For this example, be aware that there is too much speech in one message
    for voice channels.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I have never found the distance from a zip code useful, and maybe only if the
    location is unexpectedly far away (more than a few miles?). Who knows where the
    city center is and, thus, where they are measuring from? So, if the system doesn’t
    know where I am, don’t bother.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can ChatGPT do better? *Figure 9**.15* shows ChatGPT is already good at providing
    the same detail in a well-formatted way, including bolding and a bulleted list.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B21964_09_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.16 –ChatGPT has basic formatting
  prefs: []
  type: TYPE_NORMAL
- en: In a follow-up question, when ChatGPT was asked about a distance, it didn’t
    use the city center but asked where I was and provided an accurate distance and
    time estimate. ChatGPT combined a web search for current knowledge with its power
    to understand and format the content cleanly. This is similar to our FAQ experiment
    early on or with the RAG discussion. It pulls in relevant details from sources
    on the Internet, extracts the information, then verifies it against multiple sources,
    and takes these results to formulate and style its answer. And do you know how
    I know how it did this? I asked it.
  prefs: []
  type: TYPE_NORMAL
- en: I suspect future releases of ChatGPT will go more toward enterprise customers
    and provide RAG-type connections more directly. I see a bright future for ChatGPT
    integration consultants for enterprise customers.
  prefs: []
  type: TYPE_NORMAL
- en: When I additionally prompted, “I am going to walk,” it updated the distance
    and time estimate for walking. Someone is doing their job at OpenAI. If your use
    cases include location details for retail, businesses, or other locations, this
    will be a pretty easy for ChatGPT, given access to the right knowledge source.
    For enterprise data, exposing your inventory control system could help customers
    locate local parts and provide a simple experience and high-quality results without
    the overhead of excessive design effort. ChatGPT has improved rapidly. I’m impressed.
  prefs: []
  type: TYPE_NORMAL
- en: Setting a persona for the assistant’s style and tone
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A persona for the assistant or recommendations can be helpful when crafting
    specific messages. Tell the generative AI solution to adopt the persona when replying.
    It will take work and testing to get it close to expectations. I learned a lot
    from Jason Fox, who introduced the first persona for our assistants at Oracle.
  prefs: []
  type: TYPE_NORMAL
- en: Based on my experience with his work, here is a persona outline to adapt. These
    instructions could have appeared before the prompt for the onboarding experience
    we outlined earlier. This would further refine the way the chat would communicate.
    However, with long prompts, the LLM might forget some of this context, especially
    the content in the middle. Recall the issues within the lost-in-the-middle problem
    from [*Chapter 7*](B21964_07.xhtml#_idTextAnchor150)*,* *Prompt Engineering*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the personalities of the assistants:'
  prefs: []
  type: TYPE_NORMAL
- en: '**The coach**: The coach provides information and leadership, encouraging and
    directing'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The faithful collaborator**: The faithful collaborator answers questions
    reliably without judgment'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The emissary**: An emissary is a go-between, trusted, in authority, and represents
    the company’s best interests'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A coach well ahead in a game differs from one behind by 10\. A faithful collaborator
    might change their tone when working on something new to you. If the interaction
    is something the user does all the time, adapt the tone, get more direct, offer
    less guidance, and allow the user to complete the task with fewer interruptions
    or interactions. It’s not that the assistant needs to be one of these; as the
    conditions change, it can change its tone, and *the assistant can adapt to any*
    *of these*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the psychographic traits of an assistant:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Thoughtful**: Considerate and understanding of the customer’s needs. It doesn’t
    waste time and gives incorrect details. If it errors, it works to correct it'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Logical**: Exhibits logical reasoning and can defend a position with insight
    and clarity.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Accurate**: Can provide details and specifics that are precise and accurate.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Flexible**: Able to guide and assist, even when the user is forgetful or
    imprecise.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Adapt traits that make sense for the customers and their interactions. Expectations
    are different for a nurse treating a wound than for a car salesperson negotiating
    a deal. The example here is for a generic enterprise experience. Adapt. Then,
    consider how the traits translate to the chaining of models, reviewing prior elements
    of conversations given new information, recommendation templates, or adjustments
    to prompts:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is an example of assistant attributes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B21964_09_No_Number.jpg)'
  prefs: []
  type: TYPE_IMG
- en: These values define the assistant persona and set the style for chat and recommendations.
    Many start-ups take a more whimsical approach with their brand and their assistants
    so that they might be a four on the funny scale. It is just that humor is hard
    to make universal, and I have seen plenty of offensive attempts at humor. A scale
    such as introvert to extrovert and direct to indirect will likely overlap. Someone
    direct is sometimes considered pushy in some cultures. However, getting to the
    point and saving customers time is essential. So, this translates into short responses
    unless prompted for more details with direct instructions and guidance. Confidence
    is a tricky one because hallucinations can derail any trust. Take extra care to
    check work before providing details. It is easy to be confident and completely
    wrong. Remember to take ownership of what the assistant says and does, so being
    right is essential. Validate that the LLM is giving correct answers so customers
    can build trust and faith in the assistance or recommendations. Don’t include
    these attributes only when writing prompts. As customer information becomes available,
    *adapt attributes* based on their profile. It is possible to *cater to an audience
    of one*. With instruction templates, data intelligence can help insert phrases
    in the instructions that match the user profile.
  prefs: []
  type: TYPE_NORMAL
- en: There are many ways of describing these attributes. Keep persona information
    readily available when writing scripts and prompt. Follow style and tone guidelines
    even in the prompts defined for the customer. Also, it is essential to remember
    that a use case or situation can change how to speak to this audience of one.
    For example, if the customer has trouble multiple times in a row, adapt the tone
    to a coaching approach, breaking down the problem into smaller steps with empathy.
    Let’s take an example and see how this example handles their conversational interactions
    and style and tone.
  prefs: []
  type: TYPE_NORMAL
- en: Case study
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Figure 9**.17* shows a customer-facing experience. It shows the store policies
    referenced in the right-hand panel. Try a little heuristic evaluation of this
    screenshot. Based on your experience and our guidance, what do you see in this
    experience that might impact the customer? It could be tiny things or interactions
    that could be annoying or helpful over time. Give yourself 10 minutes to evaluate
    this screen before reading the analysis.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B21964_09_17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.17 – How FAQ documents might be helpful in a customer-facing UI
  prefs: []
  type: TYPE_NORMAL
- en: Here are some things we noticed in this experience. Some are conversational,
    and some any GUI would need to address.
  prefs: []
  type: TYPE_NORMAL
- en: The label on the right column is called **2 references**. Based on the other
    UI elements, it should likely be *Title Case*. Is the word **references** best?
    References are generic, but the section label is **Sources**, generally used for
    the places to get things from, versus another label, which could be **Resources**,
    the things people use. Some writing help is needed for these labels. It is minor
    but can confuse people.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Heuristics**: Match between a system and the real world, plus consistency
    and standards.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In this example, each source/reference was a store policy. Classifications such
    as this can be helpful, but it is hard to tell by this example. If everything
    is a store policy at this stage of their design, then the entire area could have
    been called **Store Policies**. We have to assume they have other categories in
    mind, and knowing the category might help us understand the document title.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Heuristics**: Help and documentation, as well as consistency and standards.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The titles are in uppercase. It was already mentioned that we should not use
    this in a UI. In addition, the documents are in uppercase and truncated. Both
    issues were discussed in an earlier chapter. The titles should be in title case
    and wrapped. I don’t recall if a mouseover on the title was provided to read the
    full text. It should.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Heuristics**: Recognition rather than recall, aesthetic and minimalist design,
    consistency and standards.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Each policy item, as a document, is a positive. All FAQ files on GitHub (from
    [*Chapter 8*](B21964_08.xhtml#_idTextAnchor172), *Fine-Tuning*) are in one document,
    making referencing and linking less valuable.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Heuristics**: Match between a system and the real world, and help and documentation.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: These references give context for the customer to follow up if they need more
    detail, but they are also cluttering. Consider this for less-tuned and more technical
    content. Note how the **Sources** side panel can be collapsed. The default is
    likely collapsed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Heuristics**: User control and freedom, flexibility, and efficiency of use.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: They included policy links in the conversation, which was a nice touch. The
    customer uploaded the receipt so they could gather the details automatically.
    It used the receipt to form the answer.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Heuristics**: User control and freedom, recognition rather than recall, flexibility,
    and use efficiency.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: They also used image scanning to determine that the purchase was at full price.
    Training receipt models are much easier for a single organization with a limited
    number of receipt formats (online and in-store). In addition, they explained that
    they can handle an uploaded receipt, encouraging a good path forward.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Heuristic**s: Error prevention, visibility of system status, and recognition
    rather than recall.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Did you notice the choice of icons, text style, customer communication boxes,
    colored backgrounds, and callouts? I don’t have much to say about this; style
    is very subjective for each company. But the tone was on point. It felt like the
    virtual agent had some compassion and was helpful.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Did you see the same issues and positives? Maybe a few others? The point is
    that there are many UX considerations within a conversation. For an actual product,
    each issue would be scored to prioritize improvements.
  prefs: []
  type: TYPE_NORMAL
- en: I want to conclude our discussion of guidelines with some guidance on handling
    errors. It is easy to prevent a form from accepting words when numbers are required
    or forcing a choice with a menu instead of a field. Pure conversational UIs are
    more challenging. Time to dig into this last topic.
  prefs: []
  type: TYPE_NORMAL
- en: Handling errors – repair and disfluencies
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When providing guidance, conversational style and tone in prompts are used.
    One of the critical areas worth calling out is repair and disfluencies. **Repair**
    is about getting a user back on track or guiding them to the right path after
    an error or incomplete thought. Because an LLM always attempts an answer, or,
    as Liz mentions in the following **Conversational Design Institute** (**CDI**)
    video, it is a people-pleaser; it always wants to answer, even if it’s a poor
    answer.
  prefs: []
  type: TYPE_NORMAL
- en: 'Video: [Should Conversational User Interfaces Make Human ‘Errors’?](https://youtu.be/P3SWIdF18I4)
    ([https://youtu.be/P3SWIdF18I4](https://youtu.be/P3SWIdF18I4))'
  prefs: []
  type: TYPE_NORMAL
- en: 'Repair interactions are common, even if you are unfamiliar with the terms:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Repair handles misunderstandings (shrot) and gaps in understanding (which Jim).
  prefs: []
  type: TYPE_NORMAL
- en: '**Disfluencies** are those breaks in speech that are so common in language.
    They are expected during the repair process. Phrases like *umm*, *you know*, or
    *well* occur when someone is unsure what to say. These are common in social media
    text posts. We also see interactions such as backtracking (editing existing text
    to correct it), which can happen with humans and LLMs. Disfluencies also cover
    a collection of vocal interactions we see when someone stutters, such as repeating
    parts of words (*I w-w-w-want to go home*), prolonged sounds (*Sssssteve is my
    friend*), or long pauses (*Where is the (pause) receipt*). Although we have not
    spent much time on LLM voice output, the more natural-sounding interactions occasionally
    make these disfluencies. It would give the appearance that they are thinking about
    what they are saying. Besides trying to help understand the user, it is about
    how the LLM relates to the user. I am sure you have been in situations where you
    want to interact with an agent (live or virtual), and you either want to interrupt
    them or make a mistake and try to correct yourself. These “*uhms*,” “*umms*,”
    “*ah*,” and restatements are common.'
  prefs: []
  type: TYPE_NORMAL
- en: These issues have to be handled on both the input and output sides. Repair should
    be done according to the business’s style and tone to move the user in the right
    direction. Disfluencies can occur in the input, but the previous CDI video shows
    examples of how they can be used in generated speech to make LLM speech more natural.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s compare two examples that Cathy Pearl discussed in the video:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Which approach is better? Cathy doesn’t suggest one is known to be better than
    the other. With them, the conversation comes across with a different tone, acknowledging
    and understanding and then stopping this thread with the disfluency. Salesforce
    guidelines shared earlier in the chapter suggest not using hmm, uh, and umm. They
    say they “signify cognitive processing, and can disrupt your conversation because
    users know that machines are incapable of doing that!“ I am not sure I agree,
    but I will explain later. You decide for yourself.
  prefs: []
  type: TYPE_NORMAL
- en: 'The second example for repair is also on target:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: The user recognized the issue and repaired it by guiding the UI. The system
    was too intelligent for itself, thinking it knew the user was a vegetarian and
    thought it was being on point. We have discussed disambiguation, where the UI
    can help provide a user with a path choice. In this case, the repair can come
    from either direction!
  prefs: []
  type: TYPE_NORMAL
- en: We leave product owners with a few tasks. One is to define conversational style
    and tone when it comes to repair and the use of disfluencies. The natural approach
    with disfluencies sounds great with vocal experiences, but the enterprise might
    find it provides too much information in a written channel. I would use them in
    moderation, where it is most expected. When ChatGPT is prompted to use disfluencies
    to mimic natural patterns, it can get out of control. A human might use, um, one
    or, uh two in a phrase. But ChatGPT has to be given, uh, boundaries or it, um,
    could pepper, ah, ah, ah, an entire conversation with, umm them. Is that, uh,
    clear?
  prefs: []
  type: TYPE_NORMAL
- en: 'The second task is to monitor interactions so that you can improve and refine
    the results. The place where I would most expect it would be with disambiguation
    or follow-up questions that might not be expected. This might be hard to define
    in a prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: In this example, we interjected **Umm…** to catch their attention and naturally
    reinforce that clarification was needed. Multiple choices to repair the situation
    were provided (they could tell me to continue with what was uploaded or upload
    a new file, and the system could safely ignore the old one). A design could be
    fancy, and show them an image of the file so they can see it appears wrong to
    us. This seems to be a good use of **Umm…**
  prefs: []
  type: TYPE_NORMAL
- en: It should be evident that writers and context experts will be critical to this
    process. They will use traditional sources, such as company style guides, dictionaries,
    and the *Chicago Manual of Style*, to navigate some of these projects. There is
    a lot to learn from these sources. However, even these resources will give a different
    feeling than a natural conversation. If ChatGPT generates the text, it is better
    than almost any human at writing coherently. Introducing disfluencies is a choice.
    I value accuracy more than naturalness. And the accuracy builds trust, while most
    disfluency feels ingenuine.
  prefs: []
  type: TYPE_NORMAL
- en: 'Website: [Chicago Manual of Style](https://www.chicagomanualofstyle.org/home.html)
    ([https://www.chicagomanualofstyle.org/home.html](https://www.chicagomanualofstyle.org/home.html))'
  prefs: []
  type: TYPE_NORMAL
- en: Conversational repair is a rich area for LLMs. Rasa is an open-source platform
    for developing assistants. They have extended into generative AI with their CALM
    (Conversational AI with Language Models) approach. Explore Rasa’s collection of
    10 repair cases for conversations that deviate from the happy path. They specifically
    call out that Rasa can handle these conditions, including the examples we shared
    in this section.
  prefs: []
  type: TYPE_NORMAL
- en: 'Documentation: [Conversation Repair](https://rasa.com/docs/rasa-pro/concepts/conversation-repair/)
    ([https://rasa.com/docs/rasa-pro/concepts/conversation-repair/](https://rasa.com/docs/rasa-pro/concepts/conversation-repair/))'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covered guidelines and heuristics to support evaluating solutions
    and to address conversational style and tone. Adapt and adopt guidelines with
    some frequency until they mature—a chicken versus egg problem. Guidelines should
    be available for all projects, but they should be formed while building solutions.
  prefs: []
  type: TYPE_NORMAL
- en: We shared heuristics and guidelines that can be applied in various situations.
    Create guidelines and follow the heuristics that help evaluate GUI and hybrid
    projects. Use the examples to craft recommender templates or inject heuristics
    into prompts and instructions to create thoughtful model responses.
  prefs: []
  type: TYPE_NORMAL
- en: Traditional style guides must be updated, adapted, and adjusted to accommodate
    conversational experiences, especially for controlling style and tone. Guidelines
    must also adapt to account for hybrid UIs where traditional forms, tables, and
    UI elements don’t work and shouldn’t act as initially designed for traditional
    web and GUI frameworks. They need to be tweaked to account for the unique context
    of a conversational thread.
  prefs: []
  type: TYPE_NORMAL
- en: It should be clear that only some solutions are easy to implement. Most require
    prompt engineering and fine-tuning, and a few can be solved with form-filling,
    function calling, or even hardcoded wording. Forcing an LLM to communicate consistently
    in specific ways is challenging, so don’t try. Adapt the approach to using the
    LLM for what it is good at, and consider some of these other methods to get the
    structure or consistency needed.
  prefs: []
  type: TYPE_NORMAL
- en: This context was provided to help understand and improve product people’s engagement
    with conversational UIs and to further the quality of the customer experience.
    The team can do internal testing even before customers engage. However, once they
    engage, focus on how they use the solution, and that is all about monitoring.
    So, let’s apply our focus to monitoring conversational AI solutions in the next
    chapter.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '| ![](img/B21964_09_QR.jpg) | The links, book recommendations, and GitHub files
    in this chapter are posted on the reference page.Web Page: [Chapter 9 References](https://uxdforai.com/references#C9)
    ([https://uxdforai.com/references#C9](https://uxdforai.com/references#C9)) |'
  prefs: []
  type: TYPE_TB
