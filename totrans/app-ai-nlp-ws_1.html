<html><head></head><body>
		<div>
			<div id="_idContainer013" class="Content">
			</div>
		</div>
		<div id="_idContainer014" class="Content">
			<h1 id="_idParaDest-23"><a id="_idTextAnchor022"/>1. An Introduction to AWS</h1>
		</div>
		<div id="_idContainer060" class="Content">
			<p class="callout-heading">Overview</p>
			<p class="callout">In this chapter, we start off with the basic concepts of <strong class="bold">cloud computing</strong>, <strong class="bold">Artificial Intelligence</strong> (<strong class="bold">AI</strong>), and <strong class="bold">Machine Learning</strong> (<strong class="bold">ML</strong>). These are the foundational elements that we will be working with throughout this book. The guided instructions in this chapter will equip you with the skills necessary to store and retrieve data with Amazon Simple Storage Service (S3) while you learn the core concepts of this technology. Next, you will apply your S3 knowledge by importing and exporting text data via the management console and the <strong class="bold">Command Line Interface</strong> (<strong class="bold">CLI</strong>). By the end of the chapter, you will be able to confidently work with the management console and the CLI so that you can test AI and ML services.</p>
			<h1 id="_idParaDest-24"><a id="_idTextAnchor023"/>Introduction</h1>
			<p>We are in an era of unprecedented computing capabilities—serverless computing with autonomous functions that can scale elastically from zero to a million users and back to zero in seconds, innovative intelligent bot frameworks that can live in a contact center in the cloud that we can spin up with a small amount of configuration, and the ability to extract text from images, tables, and scanned documents such as medical records and business and tax documents. </p>
			<p>Of course, we are talking about the cloud services available at our fingertips, specifically from Amazon. In 2004, Amazon first offered cloud computing as a service, and now (according to Forbes) the cloud market is worth over $30 billion, growing at a rate of 30-50% yearly. More and more people prefer to do their computing in the cloud.</p>
			<p>So, what is cloud computing? It is a set of computing services of which you can use as much as you need and can afford and pay for on an <em class="italic">as-you-go</em> basis. So, enterprises switch from their own hosting to the cloud. Beyond that, you get not only a cost-efficient way of doing your computing, but you also get a wider and wider variety of these services.</p>
			<p>While there is a huge set of cloud services offered by Amazon, in this book, we will work with <strong class="bold">Amazon Web Services</strong> (<strong class="bold">AWS</strong>) for <strong class="bold">Artificial Intelligence</strong> (<strong class="bold">AI</strong>) and <strong class="bold">Machine Learning</strong> (<strong class="bold">ML</strong>). In the process, we will also use AWS Lambda for serverless computing, AWS Simple Storage Service, and AWS API Gateway for networking and content delivery.</p>
			<p>This chapter will introduce you to the AWS interface and will teach you how to store and retrieve data with Amazon Simple Storage Service (S3). Then, you will apply your S3 knowledge by importing and exporting text data via the management console and the CLI. Lastly, you will learn how to locate and test AI and ML services.</p>
			<p>In later chapters, you will get a chance to apply <strong class="bold">Natural Language Processing</strong> (<strong class="bold">NLP</strong>) techniques to analyze documents, program serverless computing, use AI/ML services for topic and theme extraction, construct your own fully capable contact center with its own telephone number, develop bots that answer calls in your own contact center, and finally, program image analysis with ML to extract text from images (such as street signs) and perform facial recognition. Overall, it is going to be an interesting journey that will end with us commanding an infrastructure of vast resources for AI and ML.</p>
			<h1 id="_idParaDest-25"><a id="_idTextAnchor024"/>How Is AWS Special?</h1>
			<p>Today, there are many cloud providers, with the market share breakdown as follows: as per the Canalys analysis (<a href="https://www.canalys.com/static/press_release/2020/Canalys---Cloud-market-share-Q4-2019-and-full-year-2019.pdf">https://www.canalys.com/static/press_release/2020/<span id="_idTextAnchor025"/>Canalys---Cloud-market-share-Q4-2019-and-full-year-2019.pdf</a>), as of Q4 2019, AWS is the top vendor, owning nearly a third of the overall public cloud infrastructure market (32%), leading by a wide margin over Microsoft (18%), Google (6%), and Alibaba (5%).</p>
			<p>These numbers vary depending on the source, and they may change in the future, but all agree that Amazon is the largest provider at the moment. One of the reasons for this is that Amazon offers a very large array of cloud services. In fact, one of their competitive advantages is exactly that: a very broad and deep cloud computing ecosystem. For example, in the area of ML, Amazon has thousands of use cases, with the professed goal of every imaginable ML service being provided on AWS. This explains our focus on doing ML on AWS.</p>
			<h2 id="_idParaDest-26"><a id="_idTextAnchor026"/>What Is ML?</h2>
			<p>ML and AI go hand in hand. ML is the art and science of predicting real-world outcomes based on knowledge of the world and its history. You build a model that allows you to predict the future. The model is based on a formula or a process that formulates this prediction. The model is trained using data.</p>
			<p>AI is a wider area of science, which includes, together with ML, all the ways of imitating human behavior and capabilities. However, the way people use these terms vary, depending on who you ask. People also tend to use the current most popular term, mostly for search engine optimization. In this book, we will take the liberty of using these two terms interchangeably.</p>
			<p>ML is essential to learn in today's world because it is an integral part of all industries' competitive and operational data strategies. More specifically, ML allows insights from NLP to power chatbots, ML insights are used in the financial industry; and ML applications allow efficient online recommendation engines, such as friend suggestions on Facebook, Netflix displaying movies you will probably like, and more items to consider on Amazon.</p>
			<h2 id="_idParaDest-27"><a id="_idTextAnchor027"/>What Is AI?</h2>
			<p>AI is intelligence that's demonstrated by machines. More specifically, it refers to any device that perceives its environment and takes actions that increase its chance of successfully achieving its goals. Contemporary examples are understanding human speech, competing at the highest levels of strategic games (such as Chess and Go), and autonomous cars.</p>
			<p>AI is important because it adds intelligence to existing products. Products that are currently used will be further improved with AI capabilities; for example, Siri was added to a new generation of Apple products. Conversational chatbots can be combined with large amounts of data to improve technologies at home and in the office.</p>
			<p>In this chapter, we will introduce you to the first few AWS services that will start you on the way to doing ML on AWS. Whenever we can, we will stick to the free tier of AWS. You get the free tier for 1 year, and it is limited in the number of computing resources you can use. Readers willing to invest a few dollars in learning with a regular AWS account will find the money well spent. Another alternative is to use packaged labs, such as <strong class="bold">Qwiklabs</strong>, which lets you do labs at will, with the added convenience of shutting the labs down so that you will not incur accidental charges when you leave your machines running.</p>
			<h1 id="_idParaDest-28"><a id="_idTextAnchor028"/>What Is Amazon S3?</h1>
			<p><strong class="bold">S3</strong> is an online cloud object storage and retrieval service. Instead of data being associated with a server, S3 storage is server-independent and can be accessed over the internet. Data stored in S3 is managed as objects using an <strong class="bold">Application Programming Interface</strong> (<strong class="bold">API</strong>) that is accessible via the internet (HTTPS).</p>
			<p>The benefits of using S3 are as follows:</p>
			<ul>
				<li>Amazon S3 runs on the largest global cloud infrastructure to deliver 99.99% durability.</li>
				<li>It provides the widest range of options to transfer data.</li>
				<li>It allows you to run big data analytics without moving data into a separate analytics system.</li>
				<li>It supports security standards and compliance certificates.</li>
				<li>It offers a flexible set of storage management and administration capabilities.<p class="callout-heading">Note</p><p class="callout">For more information, visit <a href="https://aws.amazon.com/s3/">https://aws.amazon.com/s3/</a>.</p></li>
			</ul>
			<h2 id="_idParaDest-29"><a id="_idTextAnchor029"/>Why Use S3?</h2>
			<p><strong class="bold">S3</strong> is a place to store and retrieve your files. It is recommended for storing static content such as text files, images, audio files, and video files. For example, S3 can be used as a static web server if the website consists exclusively of HTML and images. The website can be connected to an FTP client to serve the static files. In addition, S3 can be used to store user-generated images and text files.</p>
			<p>However, the two most important applications of S3 are as follows:</p>
			<ul>
				<li>To store static data from web pages or mobile apps</li>
				<li>To implement big data analytics</li>
			</ul>
			<p>It can easily be used in conjunction with additional AWS ML and infrastructure services. For example, text documents imported to Amazon S3 can be summarized by code running in an AWS Lambda function that is analyzed using AWS Comprehend. We will cover AWS Lambda and AWS Comprehend in <em class="italic">Chapter 2</em>, <em class="italic">Analyzing Documents and Text with Natural Language Processing</em>, and <em class="italic">Chapter 3</em>, <em class="italic">Topic Modeling and Theme Extraction</em>.</p>
			<h2 id="_idParaDest-30"><a id="_idTextAnchor030"/>The Basics of Working on AWS with S3</h2>
			<p>The first step to accessing S3 is to create an AWS free-tier account, which provides access to the AWS Management Console. The AWS Management Console is a web application that provides one method to access all AWS's powerful storage and ML/AI services.</p>
			<p>The second step is to understand the access level. AWS defines <strong class="bold">identity and access management</strong> (<strong class="bold">IAM</strong>). The same email/password is used to access IAM.</p>
			<h2 id="_idParaDest-31"><a id="_idTextAnchor031"/>AWS Free-Tier Account</h2>
			<p>AWS provides a free-tier (within their individual free usage stipulations) account, and one of the included storage services is S3. Thus, you can maximize cost savings and reduce errors before making a large investment by testing services to optimize your ML and AI workflows.</p>
			<h3 id="_idParaDest-32"><a id="_idTextAnchor032"/>AWS Account Setup and Navigation</h3>
			<p>Generally, you need an AWS account with Amazon. A good description of the steps is available at <a href="https://support.sou.edu/kb/articles/amazon-web-services-account-creation">https://support.sou.edu/kb/articles/amazon-web-services-account-creation</a>. The steps might vary a little bit, as Amazon might make changes to its processes.</p>
			<p>The general steps are:</p>
			<ol>
				<li>Create a personal account (if needed; many of you might already be Amazon customers), which might also need a security check.</li>
				<li>Create an AWS account. AWS account creation also requires credit card information. But you can also use credit codes.</li>
				<li>The AWS free tier offers limited capability for 1 year. The details are at <a href="https://aws.amazon.com/free/?all-free-tier.sort-by=item.additionalFields.SortRank&amp;all-free-tier.sort-order=asc">https://aws.amazon.com/free/?all-free-tier.sort-by=item.additionalFields.SortRank&amp;all-free-tier.sort-order=asc</a>.</li>
			</ol>
			<h2 id="_idParaDest-33"><a id="_idTextAnchor033"/>Downloading the Support Materials for This Book</h2>
			<p>In this book, you will be programming AWS APIs using Jupyter notebooks, uploading images for AI services and text files to S3, and even writing short code for Lambda functions. These files and programs are located in a GitHub repository, <a href="https://packt.live/2O67hxH">https://packt.live/2O67hxH</a>. You can download the files using the <strong class="source-inline">Download ZIP</strong> button and then unzip the file:</p>
			<div>
				<div id="_idContainer015" class="IMG---Figure">
					<img src="image/B16061_01_01.jpg" alt="Figure 1.1: Download support files from GitHub&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 1.1: Download support files from GitHub</p>
			<p>As an example, we have downloaded the files into the <strong class="source-inline">Documents/aws-book/The-Applied-AI-and-Natural-Language-Processing-with-AWS</strong> directory:</p>
			<div>
				<div id="_idContainer016" class="IMG---Figure">
					<img src="image/B16061_01_02.jpg" alt="Figure 1.2: Support files from GitHub in a local directory&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 1.2: Support files from GitHub in a local directory</p>
			<h2 id="_idParaDest-34"><a id="_idTextAnchor034"/>A Word about Jupyter Notebooks</h2>
			<p>Some of the programs in this book use Jupyter notebooks to run. You will recognize them by the <strong class="source-inline">.ipynb</strong> file extensions. If you haven't already used Jupyter notebooks, please follow the <strong class="source-inline">Installation and setup</strong> in the <em class="italic">Preface</em>.</p>
			<h2 id="_idParaDest-35"><a id="_idTextAnchor035"/>Importing and Exporting Data into S3</h2>
			<p>The way AWS handles big data is by providing the AWS Import/Export service, which allows you to transfer large amounts of data to AWS. </p>
			<p>How it works is you mail your storage device to AWS, and AWS will transfer that data using Amazon's high-speed network. Your big data will be loaded into AWS the next business day after it arrives. Once data has been loaded, the storage device is returned to the owner. This is a more cost-efficient way of transferring huge amounts of data and is much faster than transferring it via the internet.</p>
			<p>If the amount of data that you need to put into S3 is relatively small, you can simply upload it from your computer. Today, with the increasing capacity of broadband networks, "small" becomes bigger and bigger. Our guideline is 1 TB. Once you have more than this, you may need to think of faster ways to put the data in S3. One of them is the <strong class="bold">AWS Import/Export Disk Service</strong> (<a href="https://aws.amazon.com/snowball/disk/details/">https://aws.amazon.com/snowball/disk/details/</a>), where you package your data on a device provided by AWS and ship it to them. Significant amounts of data can then be loaded within a day or a few days.</p>
			<h2 id="_idParaDest-36"><a id="_idTextAnchor036"/>How S3 Differs from a Filesystem</h2>
			<p>S3 is used to store almost any type of file, thus, it can get confused with a traditional filesystem because of this similarity. However, S3 differs in a few ways from a traditional filesystem. The folders in a traditional filesystem are buckets in S3; a file in a traditional filesystem is an object in S3. S3 uses objects since you can store any data type (that is, more than files) in buckets.</p>
			<p>Another difference is how objects can be accessed. Objects stored in buckets can be accessed from a web service endpoint (such as a web browser, for example, Chrome or Firefox), so each object requires a globally unique name. The name restrictions for objects are similar to the restrictions in selecting a URL when creating a new website. You need to select a unique URL, according to the same logic that your house has a unique address.</p>
			<p>For example, if you created a bucket (with public permission settings) named <strong class="source-inline">myBucket</strong> and then uploaded a text file named <strong class="source-inline">pos_sentiment__leaves_of_grass.txt</strong> to the bucket, the object would be accessible from a web browser via the corresponding subdomain.</p>
			<h1 id="_idParaDest-37"><a id="_idTextAnchor037"/>Core S3 Concepts</h1>
			<p>The S3 hierarchy includes the following concepts:</p>
			<ul>
				<li><strong class="bold">Type of data storage</strong>: S3 is a key-value store. You provide a unique key, and AWS stores your data as a value. You retrieve the data using the key.</li>
				<li><strong class="bold">Keys</strong>: The key is the name assigned to an object that uniquely identifies it inside a bucket. All objects in a bucket have one key associated with them.</li>
				<li><strong class="bold">Objects</strong>: Objects are what you store. They are not updatable: if you need to change one byte in the value, you will have to upload the entire object again.<div id="_idContainer017" class="IMG---Figure"><img src="image/B16061_01_03.jpg" alt="Figure 1.3: Object storage using a unique key and myBucket&#13;&#10;"/></div></li>
			</ul>
			<p class="figure-caption">Figure 1.3: Object storage using a unique key and myBucket</p>
			<ul>
				<li><strong class="bold">Bucket</strong>: Just like a folder, a bucket is a container where you store objects. Buckets are created at the root level and do not have a filesystem hierarchy. More specifically, you can have multiple buckets, but you cannot have sub-buckets within a bucket. Buckets are the containers for objects, and you can control (create, delete, and list objects in the bucket) access, view access logs, and select the geographical region where Amazon S3 will store the bucket.</li>
				<li><strong class="bold">Region</strong>: Region refers to the geographical region, such as <strong class="source-inline">us-central</strong> or <strong class="source-inline">ap-south</strong>, where S3 stores a bucket, based on the user's preference. The region can be selected when creating a bucket. The location should be based on where the data will be accessed the most. Overall, specific region selection has the biggest impact if S3 is used to store files for a website that's exclusively accessed in a specific geographic region. <p>The object storage in a bucket with different forms is as follows:</p><div id="_idContainer018" class="IMG---Figure"><img src="image/B16061_01_04.jpg" alt="Figure 1.4: Object storage&#13;&#10;"/></div></li>
			</ul>
			<p class="figure-caption">Figure 1.4: Object storage</p>
			<h2 id="_idParaDest-38"><a id="_idTextAnchor038"/>S3 Operations</h2>
			<p>The S3 API is quite simple, and it includes the following operations for the entity in question:</p>
			<ul>
				<li><strong class="bold">Bucket</strong>: Create, delete, and list keys in a bucket</li>
				<li><strong class="bold">Object</strong>: Write, read, and delete</li>
			</ul>
			<p>Here's an example:</p>
			<div>
				<div id="_idContainer019" class="IMG---Figure">
					<img src="image/B16061_01_05.jpg" alt="Figure 1.5: Object stored in myBucket&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 1.5: Object stored in myBucket</p>
			<h1 id="_idParaDest-39"><a id="_idTextAnchor039"/>Data Replication</h1>
			<p>Amazon replicates data across the region in multiple servers located in Amazon's data centers. Data replication benefits include high availability and durability. More specifically, when you create a new object in S3, the data is saved in S3; however, the change needs to be replicated across the S3 regions. Overall, replication may take some time, and you might notice delays resulting from various replication mechanisms.</p>
			<p>After deleting an object, replication can cause a lag time that allows the deleted data to display until the deletion is fully replicated. Creating an object and immediately trying to display it in the object list might be delayed as a result of a replication delay.</p>
			<h2 id="_idParaDest-40"><a id="_idTextAnchor040"/>The REST Interface</h2>
			<p>S3's native interface is a <strong class="bold">Representational State Transfer</strong> (<strong class="bold">REST</strong>) API. It is recommended to always use HTTPS requests to perform any S3 operations. The two higher-level interfaces that we will use to interact with S3 are the AWS Management Console and the AWS CLI. Accessing objects with the API is quite simple and includes the following operations for the entity in question:</p>
			<ul>
				<li><strong class="bold">Bucket</strong>: Create, delete, or list keys in a bucket</li>
				<li><strong class="bold">Object</strong>: Write, read, or delete</li>
			</ul>
			<h2 id="_idParaDest-41"><a id="_idTextAnchor041"/>Exercise 1.01: Using the AWS Management Console to Create an S3 Bucket</h2>
			<p>In this exercise, we will prepare a place on AWS to store data for ML. To import a file, you need to have access to the Amazon S3 console:</p>
			<ol>
				<li value="1">You should have already completed the account setup detailed earlier in this chapter. Go to <a href="https://aws.amazon.com/">https://aws.amazon.com/</a> and click <strong class="source-inline">My Account</strong> and then <strong class="source-inline">AWS Management Console</strong> to open the AWS Management Console in a new browser tab:<div id="_idContainer020" class="IMG---Figure"><img src="image/B16061_01_06.jpg" alt="Figure 1.6: Accessing the AWS Management Console via the user’s account&#13;&#10;"/></div><p class="figure-caption">Figure 1.6: Accessing the AWS Management Console via the user's account</p></li>
				<li>Click inside the search bar located under <strong class="source-inline">AWS services</strong>, as shown here:<div id="_idContainer021" class="IMG---Figure"><img src="image/B16061_01_07.jpg" alt="Figure 1.7: Searching AWS services&#13;&#10;"/></div><p class="figure-caption">Figure 1.7: Searching AWS services</p></li>
				<li>Type <strong class="source-inline">S3</strong> into the search bar and an auto-populated list will appear. Then, click the <strong class="source-inline">S3 Scalable Storage in the Cloud</strong> option:<div id="_idContainer022" class="IMG---Figure"><img src="image/B16061_01_08.jpg" alt="Figure 1.8: Selecting the S3 service&#13;&#10;"/></div><p class="figure-caption">Figure 1.8: Selecting the S3 service</p></li>
				<li>Now we need to create an S3 bucket. In the S3 dashboard, click the <strong class="source-inline">Create bucket</strong> button. If this is the first time that you are creating a bucket, your screen will look like this:<div id="_idContainer023" class="IMG---Figure"><img src="image/B16061_01_09.jpg" alt="Figure 1.9: Creating a bucket&#13;&#10;"/></div><p class="figure-caption">Figure 1.9: Creating a bucket</p><p>If you have already created S3 buckets, your dashboard will list all the buckets you have created. <strong class="bold">Enter a unique bucket name</strong>: Bucket names must be unique across S3. If you encounter a naming issue, please refer to <a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/BucketRestrictions.html">https://docs.aws.amazon.com/AmazonS3/latest/dev/BucketRestrictions.html</a>.</p><p><strong class="bold">Region</strong>: If a default region is auto-populated, then keep the default location. If it is not auto populated, select a region near your current location.</p></li>
				<li>Click the <strong class="source-inline">Next</strong> button to continue the creation of the bucket:<div id="_idContainer024" class="IMG---Figure"><img src="image/B16061_01_10.jpg" alt="Figure 1.10: The Create bucket window&#13;&#10;"/></div><p class="figure-caption">Figure 1.10: The Create bucket window</p></li>
				<li>An S3 bucket provides the property options <strong class="source-inline">Versioning</strong>, <strong class="source-inline">Server Access Logging</strong>, <strong class="source-inline">Tags</strong>, <strong class="source-inline">Object-Level Logging</strong>, and <strong class="source-inline">Default Encryption</strong>; however, we will not enable them.</li>
				<li>Your bucket will be displayed in the bucket list, as shown here:<div id="_idContainer025" class="IMG---Figure"><img src="image/B16061_01_11.jpg" alt="Figure 1.11: The bucket has been created&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 1.11: The bucket has been created</p>
			<p>In this exercise, we have created a place for our files to be stored on the cloud. In the next exercise, we will learn the process of storing and retrieving our files from this place. </p>
			<h2 id="_idParaDest-42"><a id="_idTextAnchor042"/>Exercise 1.02: Importing and Exporting the File with Your S3 Bucket</h2>
			<p>In this exercise, we will show you how to place your data in S3 on Amazon, and how to retrieve it from there.</p>
			<p>Follow these steps to complete this exercise:</p>
			<p><strong class="bold">Importing a file:</strong></p>
			<ol>
				<li value="1">Click the bucket's name to navigate to the bucket:<div id="_idContainer026" class="IMG---Figure"><img src="image/B16061_01_12.jpg" alt="Figure 1.12: Navigate to the bucket&#13;&#10;"/></div><p class="figure-caption">Figure 1.12: Navigate to the bucket</p></li>
				<li>You are on the bucket's home page. Select <strong class="source-inline">Upload</strong>:<div id="_idContainer027" class="IMG---Figure"><img src="image/B16061_01_13.jpg" alt="Figure 1.13: Uploading a file into the bucket&#13;&#10;"/></div><p class="figure-caption">Figure 1.13: Uploading a file into the bucket</p></li>
				<li>To select a file to upload, click <strong class="source-inline">Add files</strong>:<div id="_idContainer028" class="IMG---Figure"><img src="image/B16061_01_14.jpg" alt="Figure 1.14: Adding a new file to the bucket&#13;&#10;"/></div><p class="figure-caption">Figure 1.14: Adding a new file to the bucket</p></li>
				<li>We will upload the <strong class="source-inline">pos_sentiment__leaves_of_grass.txt</strong> file from the <a href="https://packt.live/3e9lwfR">https://packt.live/3e9lwfR</a> GitHub repository. The best way is to download the repository to your local disk. Then you can select the file:<div id="_idContainer029" class="IMG---Figure"><img src="image/B16061_01_15.jpg" alt="Figure 1.15: Selecting the file to upload to the S3 bucket&#13;&#10;"/></div><p class="figure-caption">Figure 1.15: Selecting the file to upload to the S3 bucket</p></li>
				<li>After selecting a file to upload, select <strong class="source-inline">Next</strong>:<div id="_idContainer030" class="IMG---Figure"><img src="image/B16061_01_16.jpg" alt="Figure 1.16: Selecting the file to upload to the bucket&#13;&#10;"/></div><p class="figure-caption">Figure 1.16: Selecting the file to upload to the bucket</p></li>
				<li>Click the <strong class="source-inline">Next</strong> button and leave the default options selected:<div id="_idContainer031" class="IMG---Figure"><img src="image/B16061_01_17.jpg" alt="Figure 1.17: The permissions page while uploading the file&#13;&#10;"/></div><p class="figure-caption">Figure 1.17: The permissions page while uploading the file</p></li>
				<li>You can set property settings for your object, such as <strong class="source-inline">Storage class</strong>, <strong class="source-inline">Encryption</strong>, and <strong class="source-inline">Metadata</strong>. However, leave the default values as they are and then click the <strong class="source-inline">Next</strong> button:<div id="_idContainer032" class="IMG---Figure"><img src="image/B16061_01_18.jpg" alt="Figure 1.18: Setting the properties&#13;&#10;"/></div><p class="figure-caption">Figure 1.18: Setting the properties</p></li>
				<li>Click the <strong class="source-inline">Upload</strong> button to upload the files:<div id="_idContainer033" class="IMG---Figure"><img src="image/B16061_01_19.jpg" alt="Figure 1.19: Uploading the files&#13;&#10;"/></div><p class="figure-caption">Figure 1.19: Uploading the files</p></li>
				<li>You will be directed to your object on your bucket's home screen:<div id="_idContainer034" class="IMG---Figure"><img src="image/B16061_01_20.jpg" alt="Figure 1.20: Files uploaded to the bucket&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 1.20: Files uploaded to the bucket</p>
			<p><strong class="bold">Exporting a file:</strong></p>
			<ol>
				<li value="1">Select the checkbox next to the file to export (<em class="italic">Red Marker #1 – see the following screenshot</em>). This populates the file's information display screen. Click <strong class="source-inline">Download</strong> (<em class="italic">Red Marker #2 – see the following screenshot</em>) to retrieve the text file:<div id="_idContainer035" class="IMG---Figure"><img src="image/B16061_01_21.jpg" alt="Figure 1.21: Exporting the file&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 1.21: Exporting the file</p>
			<p>The file will download, as shown in the bottom left-hand corner of the screen:</p>
			<div>
				<div id="_idContainer036" class="IMG---Figure">
					<img src="image/B16061_01_22.jpg" alt="Figure 1.22: Downloading the file to export&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 1.22: Downloading the file to export</p>
			<p>In this exercise, you learned how to import a file to and export a file from your Amazon S3 bucket. As you can see, the process is quite easy thanks to the simple user interface.</p>
			<h1 id="_idParaDest-43"><a id="_idTextAnchor043"/>The AWS CLI</h1>
			<p>The CLI is an open-source tool built on the AWS SDK for Python (Boto) to perform setups, determine whether calls work as intended, verify status information, and more. The CLI provides another access tool for all AWS services, including S3. Unlike the Management Console, the CLI can be automated via scripts.</p>
			<p>To authenticate your AWS account to the CLI, you must create a configuration file to obtain your public key and secret key. Next, you will install and then configure the AWS CLI.</p>
			<h2 id="_idParaDest-44"><a id="_idTextAnchor044"/>Exercise 1.03: Configuring the CLI</h2>
			<p>In this exercise, we will configure the CLI with our AWS access key ID and AWS secret access key. Follow these steps to complete the exercise:</p>
			<ol>
				<li value="1">First, go to the <strong class="source-inline">AWS Management Console</strong> and then <strong class="source-inline">IAM</strong>. You might have to log in to the account. Then, click <strong class="source-inline">Users</strong>:<div id="_idContainer037" class="IMG---Figure"><img src="image/B16061_01_23.jpg" alt="Figure 1.23: The Management Console home page with the Users option highlighted&#13;&#10;"/></div><p class="figure-caption">Figure 1.23: The Management Console home page with the Users option highlighted</p></li>
				<li>In the upper-right corner of the signed-in AWS Management Console, click <strong class="source-inline">My Security Credentials</strong>:<div id="_idContainer038" class="IMG---Figure"><img src="image/B16061_01_24.jpg" alt="Figure 1.24: My Security Credentials&#13;&#10;"/></div><p class="figure-caption">Figure 1.24: My Security Credentials</p></li>
				<li>Next, click <strong class="source-inline">Continue to Security Credentials</strong>:<div id="_idContainer039" class="IMG---Figure"><img src="image/B16061_01_25.jpg" alt="Figure 1.25: Security Credentials&#13;&#10;"/></div><p class="figure-caption">Figure 1.25: Security Credentials</p></li>
				<li>Click the <strong class="source-inline">Access keys (access key ID and secret access key)</strong> option:<div id="_idContainer040" class="IMG---Figure"><img src="image/B16061_01_26.jpg" alt="Figure 1.26: Accessing key generation&#13;&#10;"/></div><p class="figure-caption">Figure 1.26: Accessing key generation</p></li>
				<li>Then, click <strong class="source-inline">Create New Access Key</strong>:<div id="_idContainer041" class="IMG---Figure"><img src="image/B16061_01_27.jpg" alt="Figure 1.27: Creating a new access key&#13;&#10;"/></div><p class="figure-caption">Figure 1.27: Creating a new access key</p></li>
				<li>Click <strong class="source-inline">Download Key File</strong> to download the key file:<div id="_idContainer042" class="IMG---Figure"><img src="image/B16061_01_28.jpg" alt="Figure 1.28: Downloading the key file &#13;&#10;"/></div><p class="figure-caption">Figure 1.28: Downloading the key file </p><p>The <strong class="source-inline">rootkey.csv</strong> file that contains the keys will be downloaded. You can view the details by opening the file.</p><p class="callout-heading">Note</p><p class="callout">Store the keys in a safe location. Protect your AWS account and never share, email, or store keys in a non-secure location. An AWS representative will never request your keys, so be vigilant when it comes to potential phishing scams.</p></li>
				<li>Open Command Prompt and type <strong class="source-inline">aws configure</strong>.</li>
				<li>You will be prompted for four input variables. Enter your information, then press <em class="italic">Enter</em> after each input:<p class="source-code">AWS Access Key ID</p><p class="source-code">AWS Secret Access Key </p><p class="source-code">Default region </p><p class="source-code">Default output format (json)</p></li>
				<li>The name is obtained in your console (<strong class="source-inline">Oregon</strong> is displayed here, but yours is determined by your unique location):<div id="_idContainer043" class="IMG---Figure"><img src="image/B16061_01_29.jpg" alt="Figure 1.29: Location search&#13;&#10;"/></div><p class="figure-caption">Figure 1.29: Location search</p></li>
				<li>The codes for regions are obtained from the following <strong class="source-inline">Available Regions</strong> list:<div id="_idContainer044" class="IMG---Figure"><img src="image/B16061_01_30.jpg" alt="Figure 1.30: List of available regions&#13;&#10;"/></div><p class="figure-caption">Figure 1.30: List of available regions</p></li>
				<li>The command Prompt's final input variable will look as follows. Then, press <em class="italic">Enter</em>:<div id="_idContainer045" class="IMG---Figure"><img src="image/B16061_01_31.jpg" alt="Figure 1.31: The last step in the AWS CLI configuration in Command Prompt &#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 1.31: The last step in the AWS CLI configuration in Command Prompt </p>
			<p>You can change the configuration anytime by entering the <strong class="source-inline">aws configure</strong> command.</p>
			<p>In this exercise, you configured the security credentials for your AWS account. We will use these credentials to access the AWS APIs in the rest of the book.</p>
			<h1 id="_idParaDest-45"><a id="_idTextAnchor045"/>CLI Usage</h1>
			<p>When using a command, specify at least one path argument. The two-path arguments are <strong class="bold">LocalPath</strong> and <strong class="bold">S3Uri</strong>:</p>
			<ul>
				<li><strong class="bold">LocalPath</strong>: This represents the path of a local file or directory, which can be written as an absolute or relative path.</li>
				<li><strong class="bold">S3Uri</strong>: This represents the location of an S3 object, prefix, or bucket. The command form is <strong class="source-inline">s3://myBucketName/myKey</strong>. The path argument must begin with <strong class="source-inline">s3://</strong> to indicate that the path argument refers to an S3 object.</li>
			</ul>
			<p>The overall command structure is <strong class="source-inline">aws s3 &lt;Command&gt; [&lt;Arg&gt; …]</strong>. The following table shows the different commands with a description and an example:</p>
			<div>
				<div id="_idContainer046" class="IMG---Figure">
					<img src="image/B16061_01_32.jpg" alt="Figure 1.32: Command list&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 1.32: Command list</p>
			<h1 id="_idParaDest-46"><a id="_idTextAnchor046"/>Recursion and Parameters</h1>
			<p>Importing files one at a time is time-consuming, especially if you have many files in a folder that need to be imported. A simple solution is to use a recursive procedure. A recursive procedure is one that can call itself and saves you, the user, from entering the same import command for each file.</p>
			<p>Performing a recursive CLI command requires passing a parameter to the API. This sounds complicated, but it is incredibly easy. First, a parameter is simply a name or option that is passed to a program to affect the operation of the receiving program. In our case, the parameter is <strong class="bold">recursive</strong>, and the entire command to perform the recursive command is as follows:</p>
			<p class="source-code">aws s3 cp s3://myBucket . --recursive</p>
			<p>With this command, all the S3 objects in the bucket are copied to the specified directory:</p>
			<div>
				<div id="_idContainer047" class="IMG---Figure">
					<img src="image/B16061_01_33.jpg" alt="Figure 1.33: Parameter list&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 1.33: Parameter list</p>
			<h2 id="_idParaDest-47"><a id="_idTextAnchor047"/>Activity 1.01: Putting the Data into S3 with the CLI</h2>
			<p>Let's start with a note about the terminology used in this activity. Putting data into S3 can also be called <em class="italic">uploading</em>. Getting it from there is called <em class="italic">downloading</em>. Sometimes, it is also called importing and exporting. Please do not confuse this with AWS Import/Export, which is a specific AWS service for sending a large amount of data to AWS or getting it back from AWS.</p>
			<p>In this activity, we will be using the CLI to create a bucket in S3 and import a second text file. Suppose that you are creating a chatbot. You have identified text documents that contain content that will allow your chatbot to interact with customers more effectively. Before the text documents can be parsed, they need to be uploaded to an S3 bucket. Once they are in S3, further analysis will be possible. To ensure that this has happened correctly, you will need to install Python, set up the Amazon CLI tools, and have a user authenticated with the CLI:</p>
			<ol>
				<li value="1">Configure the CLI and verify that it can successfully connect to your AWS environment.</li>
				<li>Create a new S3 bucket.</li>
				<li>Import your text file into the bucket.</li>
				<li>Export the file from the bucket and verify the exported objects.<p class="callout-heading">Note</p><p class="callout">The solution for this activity can be found on page 276.</p></li>
			</ol>
			<h1 id="_idParaDest-48"><a id="_idTextAnchor048"/>Using the AWS Console to Identify ML Services</h1>
			<p>The AWS Console provides a web-based interface to navigate, discover, and utilize AWS services for AI and ML. In this topic, we will explore two ways to use the Console to search ML services. Also, we will test an ML API with text data retrieved from a website.</p>
			<h2 id="_idParaDest-49"><a id="_idTextAnchor049"/>Exercise 1.04: Navigating the AWS Management Console</h2>
			<p>In this exercise, we will navigate the AWS Management Console to locate ML services. Starting from the console, <a href="https://console.aws.amazon.com/console/">https://console.aws.amazon.com/console/</a>, and only using console search features, let's navigate to the Amazon Lex (<a href="https://console.aws.amazon.com/lex/">https://console.aws.amazon.com/lex/</a>) service information page:</p>
			<ol>
				<li value="1">Click <a href="https://console.aws.amazon.com/console/">https://console.aws.amazon.com/console/</a> to navigate to the AWS Console. You might have to log in to your AWS account. Then, click <strong class="source-inline">Services</strong>:<div id="_idContainer048" class="IMG---Figure"><img src="image/B16061_01_34.jpg" alt="Figure 1.34: AWS Console&#13;&#10;"/></div><p class="figure-caption">Figure 1.34: AWS Console</p></li>
				<li>Scroll down the page to view all the ML services. Then, click <strong class="source-inline">Amazon Lex</strong>. If Lex is not available at your location, you may consider switching to a different one. <div id="_idContainer049" class="IMG---Figure"><img src="image/B16061_01_35.jpg" alt="Figure 1.35: Options for ML&#13;&#10;"/></div><p class="figure-caption">Figure 1.35: Options for ML</p></li>
				<li>You will be redirected to the <strong class="source-inline">Amazon Lex</strong> home screen:<div id="_idContainer050" class="IMG---Figure"><img src="image/B16061_01_36.jpg" alt="Figure 1.36: Amazon Lex home screen&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 1.36: Amazon Lex home screen</p>
			<p>You will get a chance to work with Amazon Lex in <em class="italic">Chapter 5</em>, <em class="italic">Using Speech with the Chatbot</em>. For now, you can click the different <strong class="source-inline">Learn More</strong> links to get to know Lex's features a bit better. If you're itching to try it out right away, you may click <strong class="source-inline">Get Started</strong>.</p>
			<p>Locating new AWS services is an essential skill for discovering more tools to provide solutions for your data projects. Now, let's test the API features of Amazon Comprehend.</p>
			<h2 id="_idParaDest-50"><a id="_idTextAnchor050"/>Exercise 1.05: Testing the Amazon Comprehend API Features</h2>
			<p>Now that you have mastered S3, let's do a quick exercise that extends beyond storing a file and prepares you for the rest of the chapters. In this exercise, we will display text analysis output by using a partial text file input in the API explorer. Exploring an API is a skill that saves development time by making sure that the output is in the desired format for your project. Here, we will test the AWS Comprehend text analysis features.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">You will work with Comprehend in more detail in <em class="italic">Chapter 4,</em> <em class="italic">Conversational Artificial Intelligence</em>. We will also introduce the various AWS AI services and how to work with them. Here, we are doing an exercise to get you familiar with interacting with AWS in multiple ways.</p>
			<p>Here is the user story: suppose that you are creating a chatbot. Before taking any steps, we first need to understand the business goal or statements or objectives. Then we need to select the relevant AWS services. For example, if our business goal is related to storage, we will go for the storage domain.</p>
			<p>You have identified a business topic and the corresponding text documents with content that will allow the chatbot to make your business successful. Your next step is to identify/verify an AWS service to parse the text document for sentiment, language, key phrases, and entities. Amazon's AI services include AWS Comprehend, which does this very well.</p>
			<p>Before investing time in writing a complete program, you need to test the AWS service's features via the AWS Management Console's interface. To ensure that this happens correctly, you will need to search the web for an article (written in English or Spanish) that contains the subject matter that you're interested in. You are aware that exploring APIs is a skill that can save development time by ensuring that the output is in the desired format for your project.</p>
			<p>Now that we have the user story, let's carry out this task:</p>
			<p>Similarly, to <em class="italic">Exercise 1.01</em>, <em class="italic">Using the AWS Management Console to Create an S3 Bucket</em>, you should already have done the account setup as detailed earlier in this chapter.</p>
			<ol>
				<li value="1">Go to <a href="https://aws.amazon.com/">https://aws.amazon.com/</a> and click <strong class="source-inline">My Account</strong> and then <strong class="source-inline">AWS Management Console</strong> to open the AWS Management Console in a new browser tab:<div id="_idContainer051" class="IMG---Figure"><img src="image/B16061_01_37.jpg" alt="Figure 1.37: Accessing the AWS Management Console via the user’s account&#13;&#10;"/></div><p class="figure-caption">Figure 1.37: Accessing the AWS Management Console via the user's account</p></li>
				<li>Click inside the search bar (under <strong class="source-inline">Find Services</strong>) in the AWS Management Console to search for <strong class="source-inline">Amazon Comprehend</strong> and you will be directed to the <strong class="source-inline">Amazon Comprehend Console</strong> screen as shown below:<div id="_idContainer052" class="IMG---Figure"><img src="image/B16061_01_38.jpg" alt="Figure 1.38: Searching for AWS services&#13;&#10;"/></div><p class="figure-caption">Figure 1.38: Searching for AWS services</p></li>
				<li>Type in <strong class="source-inline">amazon comp</strong>. As you type, Amazon will autocomplete and show the services that match the name typed in the search box:<div id="_idContainer053" class="IMG---Figure"><img src="image/B16061_01_39.jpg" alt="Figure 1.39: Selecting the AWS service&#13;&#10;"/></div><p class="figure-caption">Figure 1.39: Selecting the AWS service</p></li>
				<li>You will see the <strong class="source-inline">Amazon Comprehend</strong> landing page:<div id="_idContainer054" class="IMG---Figure"><img src="image/B16061_01_40.jpg" alt="Figure 1.40: The Amazon Comprehend page&#13;&#10;"/></div><p class="figure-caption">Figure 1.40: The Amazon Comprehend page</p></li>
				<li>Click <strong class="source-inline">Launch Amazon Comprehend</strong> and you will be directed to the <strong class="source-inline">Real-time analysis</strong> page. You can either use their built-in model or you can provide a custom one. We will use their built-in model:<div id="_idContainer055" class="IMG---Figure"><img src="image/B16061_01_41.jpg" alt="Figure 1.41: Real-time analysis&#13;&#10;"/></div><p class="figure-caption">Figure 1.41: Real-time analysis</p><p>You can input text and click <strong class="source-inline">Analyze</strong>. Let's copy a poem by Walt Whitman from <a href="http://www.gutenberg.org/cache/epub/1322/pg1322.txt">http://www.gutenberg.org/cache/epub/1322/pg1322.txt</a> and analyze it. Navigate to <strong class="source-inline">Topic modeling and Documentation</strong>. There is a GUI for exploring the API, and the right side provides real-time output for text input.</p></li>
				<li>Click <strong class="source-inline">Clear text</strong> to clear all default services. Navigate to open the following URL in a new tab: <a href="http://www.gutenberg.org/cache/epub/1322/pg1322.txt">http://www.gutenberg.org/cache/epub/1322/pg1322.txt</a>.</li>
				<li>Copy the first poem and paste it in the <strong class="source-inline">Input text</strong> box:<div id="_idContainer056" class="IMG---Figure"><img src="image/B16061_01_42.jpg" alt="Figure 1.42: Amazon Comprehend real-time analysis screen&#13;&#10;"/></div><p class="figure-caption">Figure 1.42: Amazon Comprehend real-time analysis screen</p></li>
				<li>Click <strong class="source-inline">Analyze</strong> to see the output:<div id="_idContainer057" class="IMG---Figure"><img src="image/B16061_01_43.jpg" alt="Figure 1.43: Analyzing the output&#13;&#10;"/></div><p class="figure-caption">Figure 1.43: Analyzing the output</p></li>
				<li>Review the <strong class="source-inline">Entities</strong>, <strong class="source-inline">Key phrases</strong>, and <strong class="source-inline">Language</strong> tabs and click the <strong class="source-inline">Sentiment</strong> tab to view the sentiment analysis:<div id="_idContainer058" class="IMG---Figure"><img src="image/B16061_01_44.jpg" alt="Figure 1.44: Sentiment tab results&#13;&#10;"/></div><p class="figure-caption">Figure 1.44: Sentiment tab results</p></li>
				<li>You can try other tabs. The language will show English with 99% confidence, and the <strong class="source-inline">Syntax</strong> tab is interesting and has lots of information. The <strong class="source-inline">Key phrases</strong> tab underlines the key phrases and lists them:<div id="_idContainer059" class="IMG---Figure"><img src="image/B16061_01_45.jpg" alt="Figure 1.45: Key phrases tab results&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 1.45: Key phrases tab results</p>
			<p>Try some other text – maybe movie comments from IMDb or comments from Amazon product reviews – and see how Amazon Comprehend handles sentiment. A cool thing to try would be sarcasm or even comments that change their polarity at the last minute, for example, "The book is really good, but the movie is dreadful" or "The screenplay and direction were done by people who couldn't fathom what was good about the novel," for interesting results.</p>
			<h2 id="_idParaDest-51"><a id="_idTextAnchor051"/>The Utility of the AWS Console Interface to AI Services</h2>
			<p>The Comprehend console interface is very useful for testing ideas. As you will see in later chapters, we can use a similar interface to Amazon Textract to see if we can extract tables and other information from forms such as tax returns, company statements such as profit and loss or balance sheets, medical forms, and so forth.</p>
			<p>While we need programming and development to develop a robotic process automation application, the console interface helps us to quickly test our business hypotheses. For example, maybe you want to automate a loan processing pipeline in which you are manually entering information from different documents. To see if any AWS AI services would fit the need, you can scan all the relevant documents and test them with the AWS Textract console. Later, in <em class="italic">Chapter 5</em>, <em class="italic">Computer Vision and Image Processing</em>, you will work with scanned documents and Amazon Textract.</p>
			<p>You can also check how accurately the AWS built-in models can extract the required information. Maybe you will need custom models, maybe the documents are not easily understandable by a machine, but you can find them earlier and plan accordingly. Maybe your application involves medical record handling, which might require more sophisticated custom models. In fact, you can upload a custom model and test it in the console as well.</p>
			<h1 id="_idParaDest-52"><a id="_idTextAnchor052"/>Summary</h1>
			<p>In this chapter, we started with understanding the basics of cloud computing, AWS, ML, and AI. We then explored S3, created buckets, and exported and imported data to and from S3. At the same time, we explored the AWS command line and its uses. Finally, we worked with the console interface of AWS Comprehend as an example of testing various ideas that relate to analyzing texts and documents.</p>
			<p>In the next chapter, you will learn more about AWS AI services, serverless computing, and how to analyze text documents using <strong class="bold">natural language processing</strong> (<strong class="bold">NLP</strong>). Researching new AWS services is essential for discovering additional solutions to solve many machine learning problems that you are working on. Additionally, as you saw, AWS has multiple ways of interacting with its services to help test business ideas, evaluate AI/ML models, and do quick prototyping.</p>
		</div>
	</body></html>