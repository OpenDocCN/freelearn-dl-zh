<html><head></head><body><div><div><div><h1 class="chapterNumber"><a id="_idTextAnchor046"/>6</h1>
    <h1 id="_idParaDest-90" class="chapterTitle">Exploring Advanced Knowledge Graph Capabilities with Neo4j</h1>
    <p class="normal">By building on the foundational knowledge from the previous chapter, where we introduced basic search functionalities, we will now explore more sophisticated techniques for knowledge exploration, graph reasoning, and performance optimization. In this chapter, we will utilize the advanced capabilities of Neo4j, focusing on integrating these capabilities with Haystack to create a more intelligent, AI-powered search system.</p>
    <p class="normal">By the end of this chapter, you will be able to unlock deeper insights from your knowledge graph, leverage advanced search functionalities, and ensure your AI-powered search system is both performant and sustainable.</p>
    <p class="normal">In this chapter, we are going to cover the following main topics: </p>
    <ul>
      <li class="bulletList">Exploring advanced Haystack functionalities for knowledge exploration</li>
      <li class="bulletList">Graph reasoning with Haystack</li>
      <li class="bulletList">Scaling your Haystack and Neo4j integration</li>
      <li class="bulletList">Best practices for maintaining and monitoring your AI-powered search system</li>
    </ul>
    <h1 id="_idParaDest-91" class="heading-1">Technical requirements</h1>
    <p class="normal">Before diving into this chapter, ensure that your development environment is set up with the necessary technologies and tools. Also, your Neo4j instance should be loaded with the data from <code class="inlineCode">Ch4</code> and embeddings from <code class="inlineCode">Ch5</code>. Here are the technical requirements for this chapter:</p>
    <ul>
      <li class="bulletList"><strong class="screenText">Neo4j (v5.x or higher)</strong>: You will need Neo4j installed and running on your local machine or server. You can download it from <a href="https://neo4j.com/download/">https://neo4j.com/download/</a>.</li>
      <li class="bulletList"><strong class="screenText">Haystack (v1.x)</strong>: We will be using the Haystack framework for integrating AI-powered search capabilities. Make sure to install Haystack by following the instructions at <a href="https://docs.haystack.deepset.ai/docs/installation">https://docs.haystack.deepset.ai/docs/installation</a>.</li>
      <li class="bulletList"><strong class="screenText">Python (v3.8 or higher)</strong>: Ensure that you have Python installed. You can download it from <a href="https://www.python.org/downloads/">https://www.python.org/downloads/</a>.</li>
      <li class="bulletList"><strong class="screenText">OpenAI API key</strong>: To successfully generate embeddings using GPT-based models, you will need an OpenAI API key:<ul>
          <li class="bulletList">Obtain the API Key by signing up for an account at OpenAI (<a href="https://platform.openai.com/signup">https://platform.openai.com/signup</a>) if you do not have one</li>
        </ul>
      </li>
    </ul>
    <div><p class="normal"><strong class="keyWord">Note</strong></p>
      <p class="normal">A free-tier API key will not work for most use cases in this project. You will need an active paid OpenAI subscription to access the necessary endpoints and usage limits.</p>
    </div>
    <ul>
      <li class="bulletList">Once logged in, navigate to the API Keys section (<a href="https://platform.openai.com/api-keys">https://platform.openai.com/api-keys</a>) in your OpenAI dashboard and generate a new API key</li>
    </ul>
    <p class="normal">If you have followed the setup from the previous chapters, you can skip these requirements, as they will have already been installed.</p>
    <p class="normal">All the code for this chapter is available in the following GitHub repository: <a href="https://github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/tree/main/ch6">https://github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/tree/main/ch6</a>.</p>
    <p class="normal">This folder contains all the necessary scripts, files, and configurations required to implement the Neo4j and Haystack integration with advanced knowledge graph capabilities.</p>
    <p class="normal">Make sure to clone or download the repository so you can follow along with the code examples throughout this chapter.</p>
    <h1 id="_idParaDest-92" class="heading-1">Exploring advanced Haystack functionalities for knowledge exploration</h1>
    <p class="normal">In this section, we will dive into more advanced search capabilities using Haystack. You integrated embeddings into your Neo4j graph in <a href="Chapter_03.xhtml#_idTextAnchor021"><em class="italic">Chapter 5</em></a>. It is now time to explore how to enhance search beyond basic similarity matching. The goal here is to move from simple retrieval-based embeddings to a more nuanced, multi-layered exploration of knowledge in your graph.</p>
    <p class="normal">We will explore techniques such as context-based reasoning and optimizing your search functionalities for specific use cases to deliver highly relevant and intelligent results.</p>
    <p class="normal">Let us first talk about context-based reasoning.</p>
    <h2 id="_idParaDest-93" class="heading-2">Context-aware search</h2>
    <p class="normal">Now, we will build on the <a id="_idIndexMarker278"/>embedding-based approach in the <em class="italic">Connecting Haystack to Neo4j for advanced vector search</em> section of the previous chapter, by integrating multi-hop reasoning across the Neo4j graph with Haystack’s similarity search capabilities. This approach allows the search engine to traverse multiple relationships between nodes while utilizing advanced AI-based retrieval methods. Instead of simply retrieving nodes or documents based on direct matches, we will leverage Haystack to explore paths between related nodes, adding layers of context and uncovering deeper insights. This combination of graph-based reasoning and similarity understanding enables more intelligent and relevant search results.</p>
    <pre>Inception</em>.</pre>
    <div><p class="normal"><strong class="keyWord">Note</strong></p>
      <p class="normal">The title is being passed as the value of the <code class="inlineCode">title</code> variable in the main program.</p>
    </div>
    <p class="normal">After retrieving these related movies, Haystack is used to analyze and rank the results based on a similar query, demonstrating a multi-hop search that combines graph-based relationships with<a id="_idIndexMarker279"/> advanced similarity retrieval:</p>
    <pre class="programlisting code"><code class="hljs-code">def fetch_multi_hop_related_movies(title):
    query = """
    MATCH (m:Movie {title: $title})&lt;-[:DIRECTED]-(d:Director)-[:DIRECTED]-&gt;(related:Movie)
    RETURN related.title AS related_movie, related.overview AS overview
    """
    with driver.session() as session:
        result = session.run(query, title=title)
        documents = [
            {
                "content": record["overview"],
                "meta": {"title": record["related_movie"]}
            }
            for record in result
        ]
    return documents
def perform_similarity_search_with_multi_hop(query, movie_title):
    # Fetch multi-hop related movies from Neo4j
    multi_hop_docs = fetch_multi_hop_related_movies(movie_title)
    if not multi_hop_docs:
        print(f"No related movies found for {movie_title}")
        return
    # Write these documents to the document store
    document_store.write_documents(multi_hop_docs)
    # Generate embedding for the search query (e.g., "time travel")
    query_embedding = text_embedder.run(query).get("embedding")
    if query_embedding is None:
        print("Query embedding not created successfully.")
        return
    # Perform vector search only on the multi-hop related movies
    similar_docs = document_store.query_by_embedding(
        query_embedding, top_k=3
    )
    if not similar_docs:
        print("No similar documents found.")
        return
    for doc in similar_docs:
        title = doc.meta.get("title", "N/A")
        overview = doc.meta.get("overview", "N/A")
        score = doc.score
        print(
            f"Title: {title}\nOverview: {overview}\n"
            f"Score: {score:.2f}\n{'-'*40}"
        )
    print("\n\n")
</code></pre>
    <p class="normal">However, since we<a id="_idIndexMarker280"/> imported only a fraction of the original dataset, it does not have one-to-many relationships. Where a director has directed multiple movies, the search wi<a id="_idTextAnchor047"/>ll likely result in output such as <code class="inlineCode">No related movies found for Inception</code>.</p>
    <p class="normal">You may try updating the script to import the entire dataset (after upgrading from AuraDB Free to AuraDB Professional or AuraDB Business Critical or in the Neo4j Desktop version) and see how multi-hop reasoning is performed.</p>
    <h2 id="_idParaDest-94" class="heading-2">Dynamic search queries with flexible search filters</h2>
    <p class="normal">One of the strengths of a <a id="_idIndexMarker281"/>knowledge graph is the ability to apply filters dynamically during search queries.</p>
    <p class="normal">In the following code snippet, we will demonstrate how to incorporate filters and constraints into your Haystack queries, allowing users to refine search results based on specific parameters (e.g., time range, categories, or relationships between entities). This flexibility is crucial for building more interactive and contextually rich search systems:</p>
    <pre class="programlisting code"><code class="hljs-code">def perform_filtered_search(query):
    pipeline = Pipeline()
    pipeline.add_component("query_embedder", text_embedder)
    # pipeline.add_component("retriever", retriever)
    pipeline.add_component(
        "retriever", 
        Neo4jEmbeddingRetriever(document_store=document_store)
    )
    pipeline.connect(
        "query_embedder.embedding", "retriever.query_embedding"
    )
    result = pipeline.run(
        data={
            "query_embedder": {"text": query},
            "retriever": {
                "top_k": 5,
                "filters": {
                    "field": "release_date", "operator": "&gt;=", 
                    "value": "1995-11-17"
                },
            },
        }
    )
    # Extracting documents from the retriever results
    documents = result["retriever"]["documents"]
    for doc in documents:
        # Extract title and overview from document metadata
        title = doc.meta.get("title", "N/A")
        overview = doc.meta.get("overview", "N/A")
        # Extract score from the document (not from meta)
        score = getattr(doc, "score", None)
        # Format score if it exists, else show "N/A"
        score_display = f"{score:.2f}" if score is not None else "N/A"
        # Print the title, overview, and score (or N/A for missing score)
        print(
            f"Title: {title}\nOverview: {overview}\n"
            f"Score: {score_display}\n{'-'*40}\n"
        )
</code>
demonstrates how to apply dynamic filters, such as <code class="inlineCode">rel<a id="_idTextAnchor048"/>ease_date</code>, to refine search results. By incorporating these filters, you can add constraints on specific fields—for instance, showing only documents from a certain date onward or filtering by specific attributes such as category or rating. This capability allows you to narrow down results to what is most relevant to them, effectively enhancing the search functionality. Using this approach, you can easily extend or modify filters to <a id="_idTextAnchor049"/>suit different needs, offering a flexible and powerful way to interact with data in the knowledge graph.</pre>
    <h2 id="_idParaDest-95" class="heading-2">Search optimization: tailoring search for specific use cases</h2>
    <p class="normal">Not all search systems are <a id="_idIndexMarker283"/>built the same. Whether you are building a recommendation engine or a domain-specific search tool, different optimizations are required. In this section, we will explore how to tailor Haystack’s search configuration for your unique use case, ensuring the best performance and relevance for your specific data. We will also cover the importance of tuning models and indexing for high-scale environments.</p>
    <p class="normal">Have a look at the following code block:</p>
    <pre class="programlisting code"><code class="hljs-code">def perform_optimized_search(query, top_k):
       optimized_results = document_store.query_by_embedding(
            query_embedding=text_embedder.run(query).get("embedding"), 
            top_k=top_k
        )
    for doc in optimized_results:
        title = doc.meta["title"]
        overview = doc.meta.get("overview", "N/A")
        print(f"Title: {title}\nOverview: {overview}\n{'-'*40}")
</code></pre>
    <p class="normal">This code shows how to adjust parameters, such as <code class="inlineCode">top_k</code>, to fine-tune the number of top results returned by the search query —not the model itself. The <code class="inlineCode">top_k</code> parameter determines how many top results are retrieved based on vector similarity.</p>
    <div><p class="normal"><strong class="keyWord">Note</strong></p>
      <p class="normal">These are just the snippets of the code. The full version is available in the GitHub repository: <a href="https://github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/blob/main/ch6/beyond_basic_search.py">https://github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/blob/main/ch6/beyond_basic_search.py</a>.</p>
    </div>
    <p class="normal">With Haystack’s similarity retrieval capabilities (such as context-aware search methods to dynamic filtering), you can now create more accurate AI-powered search systems and better search optimization. However, <em class="italic">search</em> is just the beginning.</p>
    <p class="normal">In the next section, we will move beyond search to graph-based reasoning by utilizing the reasoning power of Haystack and relationships within the Neo4j knowledge graph.</p>
    <h1 id="_idParaDest-96" class="heading-1">Graph reasoning with Haystack</h1>
    <p class="normal">In this section, we will explore how to <a id="_idIndexMarker284"/>extend Haystack’s capabilities beyond basic search by integrating it with the powerful graph reasoning features of Neo4j. While traditional search methods retrieve results based on text similarity, graph reasoning allows you to uncover deeper insights by leveraging the rich relationships between entities in your knowledge graph. By combining the similarity understanding of Haystack with the structured data in Neo4j, you can perform more complex queries that traverse multiple connections, reveal hidden patterns, and unlock contextually enriched insights.</p>
    <p class="normal">This section will guide you through the process of building these advanced reasoning capabilities, transforming your search system into an intelligent, knowledge-driven tool.</p>
    <h2 id="_idParaDest-97" class="heading-2">Traversing multiple relationships to reveal hidden insights</h2>
    <p class="normal">While graph traversal helps discover<a id="_idIndexMarker285"/> connections between entities, traversing across multiple relationsh<a id="_idTextAnchor050"/>ips and different types of relationships can reveal hidden patterns in your knowledge graph. By moving across various paths in Neo4j—whether it is between movies, actors, directors, or genres—you can generate deeper insights that go beyond direct relationships. This multi-step traversal allows you to explore data in ways that basic search cannot, revealing connections that might otherwise be overlooked.</p>
    <p class="normal">We will now explore how to use multiple relationship types and multi-hop queries to retrieve more complex results. We will then combine them with Haystack’s similarity search capabilities for refinement and ranking.</p>
    <p class="normal">Here is an example; you want to find movies that have both the same actors and director as <em class="italic">Jurassic Park</em>, allowing you to uncover not just direct collaborations but also indirect connections:</p>
    <pre class="programlisting code"><code class="hljs-code">def fetch_multi_hop_related_movies(title):
    query = """
    MATCH (m:Movie {title: $title})&lt;-[:ACTED_IN|DIRECTED]-(p)-
        [:ACTED_IN|DIRECTED]-&gt;(related:Movie)
    WITH related.title AS related_movie, p.name AS person,
         CASE
            WHEN (p)-[:ACTED_IN]-&gt;(m) AND (p)-[:ACTED_IN]-&gt;(related) THEN 'Actor'
            WHEN (p)-[:DIRECTED]-&gt;(m) AND (p)-[:DIRECTED]-&gt;(related) THEN 'Director'
            ELSE 'Unknown Role'
         END AS role,
         related.overview AS overview, related.embedding AS embedding
     RETURN related_movie, person, role, overview, embedding
    """
    with driver.session() as session:
        result = session.run(query, title=title)
        documents = []
        for record in result:
            documents.append(
                Document(
                    content=record.get("overview", "No overview available"),  # Store overview in content
                    meta={
                        "title": record.get("related_movie", "Unknown Movie"),  # Movie title
                        "person": record.get("person", "Unknown Person"),       # Actor/Director's name
                        "role": record.get("role", "Unknown Role"),              # Actor or Director
                        "embedding": record.get("embedding", "No embedding available")  # Retrieve the precomputed embedding
                    },
                )
            )
    return documents
</code></pre>
    <h2 id="_idParaDest-98" class="heading-2">Unlocking insights through path queries</h2>
    <p class="normal">Another <a id="_idIndexMarker286"/>powerful feature of graph reasoning is the ability to query for specific paths between nodes. For instance, finding out how two movies are connected through a series of collaborations can reveal surprising insights.</p>
    <p class="normal">Have a look at the following query:</p>
    <pre class="programlisting code"><code class="hljs-code">MATCH path = (m1:Movie {title: "Inception"})-[:ACTED_IN*3]-(m2:Movie)
RETURN m1.title, m2.title, path
</code></pre>
    <p class="normal">This query finds how <em class="italic">Inception</em> and another movie are connected by shared actors, spanning three levels of relationships.</p>
    <figure class="mediaobject"><img src="img/B31107_06_01.png" alt="Figure 6.1 — Illustration of a three-hop path traversal in a movie graph" width="1211" height="573"/></figure>
    <p class="packt_figref">Figure 6.1 — Illustration of a three-hop path traversal in a movie graph</p>
    <p class="normal">The<a id="_idIndexMarker287"/> illustration in this figure shows a three-hop path traversal in a movie graph, starting from the movie <em class="italic">Incep<a id="_idTextAnchor051"/>tion</em> and reaching <em class="italic">Movie C</em> through a chain of actor collaborations. This path is the result of a Cypher query that explores connections between movies using the <code class="inlineCode">ACTED_IN</code> relationship repeated three times. In the depicted example, <em class="italic">Inception</em> is connected to <em class="italic">Movie B</em> via <em class="italic">Actor A</em>, and <em class="italic">Movie B</em> is further linked to <em class="italic">Movie C</em> through <em class="italic">Actor B</em>. Each hop represents a transition from a movie to an actor, or vice versa, forming a three-hop undirected traversal. This visualization highlights how multi-hop reasoning in Neo4j can uncover deeper, indirect relationships—valuable for applications such as content discovery, recommendation systems, and collaboration network analysis.</p>
    <div><p class="normal"> <strong class="keyWord">Note</strong></p>
      <p class="normal">These are just the snippets of the code. The full version is available in the GitHub repository at <a href="https://github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/blob/main/ch6/graph_reasoning.py">https://github.com/PacktPublishing/Building-Neo4j-Powered-Applications-with-LLMs/blob/main/ch6/graph_reasoning.py</a>.</p>
    </div>
    <p class="normal">By combining Neo4j’s graph reasoning and Haystack’s similarity understanding, we have been able to capture meaningful connections in our data, such as relationships between movies and actors, understanding multi-hop director collaborations, and uncovering complex paths between entities.</p>
    <p class="normal">Next, we will explore how to optimize these processes to ensure high performance as your graph grows in complexity and scale.</p>
    <h1 id="_idParaDest-99" class="heading-1">Scaling your Haystack and Neo4j integration</h1>
    <p class="normal">As your system scales, so do the demands on both Haystack and Neo4j. Optimizing performance becomes crucial, especially when dealing with larger datasets, more complex graph structures, and advanced search capabilities.</p>
    <p class="normal">In this section, we will focus on best practices and techniques to ensure that your Haystack and Neo4j integration can handle increased loads efficiently.<a id="_idTextAnchor052"/> We will look into query optimization, caching strategies, indexing improvements, and techniques for scaling out your infrastructure to meet performance needs without sacrificing speed or accuracy in the following subsections.</p>
    <h2 id="_idParaDest-100" class="heading-2">Optimizing Neo4j queries for large graphs</h2>
    <p class="normal">As your Neo<a id="_idTextAnchor053"/>4j graph grows in size and<a id="_idIndexMarker288"/> complexity, query performance can degrade, especially when traversing multiple relationships or working with large datasets. Here are a few techniques to improve the performance of your Neo4j queries:</p>
    <ul>
      <li class="bulletList"><strong class="screenText">Use indexes and constraints</strong>: Ensure that frequently queried properties such as <code class="inlineCode">title</code> and <code class="inlineCode">name</code> are indexed. Indexing speeds up node lookups and makes traversal more efficient:
        <pre class="programlisting code"><code class="hljs-code">CREATE INDEX FOR (m:Movie) ON (m.title);
CREATE INDEX FOR (p:Person) ON (p.name);
</code></pre>
      </li>
      <li class="bulletList"><strong class="screenText">Profile and optimize queries</strong>: Use Neo4j’s <code class="inlineCode">PROFILE</code> or <code class="inlineCode">EXPLAIN</code> keywords to analyze the performance of your queries. This helps you understand which parts of the query are slowing down and where you can optimize:
        <pre class="programlisting code"><code class="hljs-code">PROFILE MATCH (m:Movie {title: "Inception"}) RETURN m;
</code></pre>
      </li>
      <li class="bulletList"><strong class="screenText">Limit Results Early</strong>: If you are dealing with large result sets, limit the number of returned nodes early in the query to avoid over-fetching data:
        <pre class="programlisting code"><code class="hljs-code">MATCH (m:Movie)-[:ACTED_IN]-&gt;(a:Actor) RETURN m.title LIMIT 10;
</code></pre>
      </li>
    </ul>
    <h2 id="_idParaDest-101" class="heading-2">Caching embeddings and query results</h2>
    <p class="normal">When scaling Haystack and Neo4j, caching can help reduce redundant computations and network calls, significantly boosting performance. By caching both embeddings and query results, you can enhance the efficiency of your search system, especially when handling high volumes of queries. Here is how these caching strategies can make a difference:</p>
    <ul>
      <li class="bulletList"><strong class="screenText">Cache embeddings</strong>: Store <a id="_idIndexMarker289"/>embeddings generated by Haystack in Neo4j or a separate cache layer (such as Redis). By caching embeddings, you avoid recomputing them for frequently asked queries:
        <pre class="programlisting code"><code class="hljs-code"># Example of caching embeddings
embedding_cache = {}  # Simple in-memory cache, replace with Redis for larger setups
def get_cached_embedding(query):
    if query in embedding_cache:
        return embedding_cache[query]
    else:
        embedding = text_embedder.run(query).get("embedding")
        embedding_cache[query] = embedding
        return embedding
</code></pre>
      </li>
      <li class="bulletList"><strong class="screenText">Cache query results</strong>: For <a id="_idIndexMarker290"/>frequently executed Neo4j queries, consider caching query results in memory or using a cache such as Redis or Memcached. This reduces the load on Neo4j by returning cached results for popular queries:
        <pre class="programlisting code"><code class="hljs-code"># Example using a Redis cache for Neo4j query results
import redis
cache = redis.Redis()
def get_cached_query_result(query):
    cached_result = cache.get(query)
    if cached_result:
        return cached_result
    else:
        # Run the query against Neo4j
        result = run_neo4j_query(query)
        cache.set(query, result)
        return result
</code></pre>
      </li>
    </ul>
    <h2 id="_idParaDest-102" class="heading-2">Efficient use of vector indexing</h2>
    <p class="normal">As your <a id="_idIndexMarker291"/>vector-based search capabilities expand, optimizing vector indexes in Neo4j is critical for maintaining performance. You can do this as follows:</p>
    <ul>
      <li class="bulletList"><strong class="screenText">Configure vector indexes for high performance</strong>: Ensure that your vector index in Neo4j is configured optimally, based on your embedding dimensions and search requirements:
        <pre class="programlisting code"><code class="hljs-code">CREATE VECTOR INDEX overview_embeddings IF NOT EXISTS
FOR (m:Movie) ON (m.embedding)
OPTIONS {
    indexConfig: {
        `vector.dimensions`: 1536, 
        `vector.similarity_function`: 'cosine'
    }
}
</code></pre>
      </li>
      <li class="bulletList"><strong class="screenText">Batch write operations</strong>: When writing many embeddings into Neo4j, use batch operations to reduce the overhead of individual writes:
        <pre class="programlisting code"><code class="hljs-code">document_store.write_documents(embeddings_list, batch_size=100)  
# Batch size optimized for performance
</code></pre>
      </li>
    </ul>
    <h2 id="_idParaDest-103" class="heading-2">Load balancing and horizontal scaling</h2>
    <p class="normal">To handle increased traffic and<a id="_idIndexMarker292"/> load on both Haystack and Neo4j, horizontal scaling and load balancing <a id="_idIndexMarker293"/>are essential. By implementing load balancing and horizontal scaling, you can ensure your system remains responsive and resilient under heavy traffic. Here is how each approach contributes to scalability:</p>
    <ul>
      <li class="bulletList"><strong class="screenText">Scale Neo4j</strong>: Leveraging Neo4j AuraDB or a Neo4j cluster enables you to distribute your database workload across multiple instances, enhancing read and write capabilities. This is especially beneficial for applications requiring fast data retrieval and<a id="_idTextAnchor054"/> processing at scale.</li>
      <li class="bulletList"> <strong class="screenText">Load balance Haystack</strong>: Distributing incoming search queries across multiple Haystack instances with a load balancer prevents any single instance from being overwhelmed. This approach maintains consistent performance and ensures high availability, even as the demand grows.</li>
      <li class="bulletList"><strong class="screenText">Use Kubernetes</strong>: Deploying Haystack on Kubernetes with containerized instances allows you to scale effortlessly by adjusting the number of replicas based on traffic. Kubernetes orchestrates these replicas dynamically, ensuring that resources align with demand and that your system can efficiently handle peaks in usage. Here is an example of a Kubernetes deployment configuration to scale Haystack, where multiple replicas are created to handle increased traffic efficiently:
        <pre class="programlisting code"><code class="hljs-code">apiVersion: apps/v1
kind: Deployment
metadata:
  name: haystack-deployment
spe<a id="_idTextAnchor055"/>c:
  replicas: 3  # Number of replicas to scale based on traffic
  selector:
    matchLabels:
      app: haystack
  template:
    metadata:
      labels:
        app: haystack
    spec:
      containers:
      - name: haystack
        image: haystack:latest
</code></pre>
      </li>
    </ul>
    <p class="normal">By implementing these optimization strategies, you can ensure that your Haystack and Neo4j integration remains performant and<a id="_idIndexMarker294"/> scalable as your data and query complexity grow. Whether through caching, efficient indexing, or scaling infrastructure horizontally, these techniques <a id="_idIndexMarker295"/>will help you maintain speed and accuracy under increasing loads. As your system grows, optimizing performance is essential, but maintaining and monitoring the health of your AI-powered search system is just as critical.</p>
    <div><p class="normal"><strong class="keyWord">Note</strong></p>
      <p class="normal">Interested in understanding how Neo4j achieves industry-leading speed and scalability, especially as your data and query complexity grow? Explore this blog post: <em class="italic">Achieve Unrivaled Speed and Scalability with Neo4j</em> (<a href="https://neo4j.com/blog/machine-learning/achieve-unrivaled-speed-and-scalability-neo4j/">https://neo4j.com/blog/machine-learning/achieve-unrivaled-speed-and-scalability-neo4j/</a>).</p>
    </div>
    <p class="normal">In the next section, we will explore best practices for keeping your system running smoothly over time, focusing on how to monitor performance, set up alerts, and ensure long-term stability and reliability beyond the code.</p>
    <h1 id="_idParaDest-104" class="heading-1">Best practices for maintaining and monitoring your AI-powered search system</h1>
    <p class="normal">Building a<a id="_idIndexMarker296"/> powerful AI-driven search system is only the beginning. To ensure its long-term success, you need to go beyond the initial setup and focus on maintaining and monitoring your system over time. Regular performance checks, proactive monitoring, and a solid logging strategy are essential for identifying bottlenecks, preventing system failures, and optimizing resource usage.</p>
    <p class="normal">We now talk about the best practices for keeping your Haystack and Neo4j integration running smoothly, including monitoring key performance metrics, setting up alerts for critical issues, and implementing a sustainable maintenance routine to ensure that your search system remains reliable and efficient, even as it scales.</p>
    <p class="normal">Performance<a id="_idIndexMarker297"/> optimization is not a one-time activity. We need to continuously monitor and collect metrics to identify bottlenecks and areas for improvement. Let us see how we can achieve this.</p>
    <h2 id="_idParaDest-105" class="heading-2">Monitoring Neo4j and Haystack performance</h2>
    <p class="normal">Regularly tracking query <a id="_idIndexMarker298"/>response times, database performance, and overall system health is essential for maintaining an AI-powered search system. Set up monitoring for Neo4j and Haystack to track key metrics, identify bottlenecks, and ensure smooth operation:</p>
    <ul>
      <li class="bulletList"><strong class="screenText">Neo4j monitoring</strong>: Leverage Neo4j’s built-in metrics and integration with tools such as Prometheus and Grafana to visualize query performance and monitor system load.</li>
      <li class="bulletList"><strong class="screenText">Haystack monitoring</strong>: Use Grafana and Prometheus to monitor query throughput, latency, and response times in Haystack.</li>
    </ul>
    <p class="normal">Here is an example of monitoring the query response time:</p>
    <pre class="programlisting code"><code class="hljs-code"># Example: Monitor response time of a query in Haystack
import time
start_time = time.time()
result = retriever.retrieve(query)
end_time = time.time()
response_time = end_time - start_time
print(f"Query response time: {response_time} seconds")
</code></pre>
    <h2 id="_idParaDest-106" class="heading-2">Setting up alerts for critical issues</h2>
    <p class="normal">Setting up automated<a id="_idIndexMarker299"/> alerts ensures you are notified when performance or system failures occur. By using Prometheus with Alertmanager or Grafana, you can set threshold-based alerts for slow queries, failed searches, or increased load.</p>
    <p class="normal">For instance, you can create alerts that trigger when Neo4j query response times exceed a certain threshold or when Haystack’s search latency increases beyond acceptable limits.</p>
    <p class="normal">You can read more on Neo4j monitoring and alerts<a id="_idIndexMarker300"/> here: <a href="https://neo4j.com/docs/operations-manual/current/monitoring/">https://neo4j.com/docs/operations-manual/current/monitoring/</a>.</p>
    <h2 id="_idParaDest-107" class="heading-2">Implementing a logging strategy</h2>
    <p class="normal">Detailed logs help <a id="_idIndexMarker301"/>troubleshoot issues and understand the root cause of failures or performance degradation. Implement logging in both Haystack and Neo4j, including logging query execution times, failures, and system resource usage.</p>
    <p class="normal">Read more on Neo4j logging<a id="_idIndexMarker302"/> at <a href="https://neo4j.com/docs/operations-manual/current/logging/">https://neo4j.com/docs/operations-manual/current/logging/</a>. For more on Haystack logging and <a id="_idIndexMarker303"/>debugging, visit <a href="https://docs.haystack.deepset.ai/docs/debug">https://docs.haystack.deepset.ai/docs/debug</a>.</p>
    <h2 id="_idParaDest-108" class="heading-2">Establishing a regular maintenance routine</h2>
    <p class="normal">Regularly scheduled maintenance<a id="_idIndexMarker304"/> ensures your AI-powered search system continues to perform optimally over time. This includes the following:</p>
    <ul>
      <li class="bulletList"><strong class="screenText">Neo4j</strong>: Perform regular index rebuilding, data consistency checks, and disk space monitoring. Read more on Neo4j maintenance<a id="_idIndexMarker305"/> here: <a href="https://neo4j.com/docs/operations-manual/current/backup-restore/maintenance/">https://neo4j.com/docs/operations-manual/current/backup-restore/maintenance/</a>.</li>
      <li class="bulletList"><strong class="screenText">Haystack</strong>: Monitor embedding<a id="_idTextAnchor056"/> quality, update models as needed, and manage document store<a id="_idIndexMarker306"/> growth to avoid performance <a id="_idIndexMarker307"/>degradation. Read more on Haystack optimization and maintenance here: <a href="https://docs.haystack.deepset.ai/docs/pipelineoptimization">https://docs.haystack.deepset.ai/docs/pipelineoptimization</a>.</li>
    </ul>
    <p class="normal">By implementing these best practices, you ensure that your AI-powered search system remains robust, reliable, and adaptable to changing demands. Proactive monitoring, effective logging, and regular maintenance allow you to identify issues before they impact performance and ensure smooth operation as your data and query loads grow. These strategies not only prevent downtime and inefficiencies but also allow your system to evolve and scale seamlessly. As you continue to build and refine your AI-driven search, ongoing attention to monitoring and maintenance will be the key to sustaining its long-term success.</p>
    <h1 id="_idParaDest-109" class="heading-1">Summary</h1>
    <p class="normal">In this chapter, we explored how to optimize the performance of your Haystack and Neo4j integration and established best practices for maintaining and monitoring your AI-powered search system. You learned about key strategies for caching, efficient indexing, query optimization, and scaling your infrastructure to handle growing data and query loads. We also emphasized the importance of monitoring system performance, setting up alerts, and implementing a solid logging strategy to keep your system running smoothly over time. This knowledge is a crucial first step to creating a fast, reliable, and scalable search system as your data and complexity increase.</p>
    <p class="normal">As we wrap up the Haystack portion of this journey, the next part of this book will shift focus to integrating Spring AI frameworks and LangChain4j with Neo4j. In the following chapters, you will explore how these technologies can come together to build sophisticated recommendation systems, further enhancing the capabilities of your AI-powered applications.</p>
  </div>
</div></div></body></html>