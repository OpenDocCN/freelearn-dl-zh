- en: '6'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Advanced Applications and Multi-Agent Systems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we defined what an agent is. But how do we design and
    build a high-performing agent? Unlike the prompt engineering techniques we’ve
    previously explored, developing effective agents involves several distinct design
    patterns every developer should be familiar with. In this chapter, we’re going
    to discuss key architectural patterns behind agentic AI. We’ll look into multi-agentic
    architectures and the ways to organize communication between agents. We will develop
    an advanced agent with self-reflection that uses tools to answer complex exam
    questions. We will learn about additional LangChain and LangGraph APIs that are
    useful when implementing agentic architectures, such as details about LangGraph
    streaming and ways to implement handoff as part of advanced control flows.
  prefs: []
  type: TYPE_NORMAL
- en: Then, we’ll briefly touch on the LangGraph platform and discuss how to develop
    adaptive systems, by including humans in the loop, and what kind of prebuilt building
    blocks LangGraph offers for this. We will also look into the **Tree-of-Thoughts**
    (**ToT**) pattern and develop a ToT agent ourselves, discussing further ways to
    improve it by implementing advanced trimming mechanisms. Finally, we’ll learn
    about advanced long-term memory mechanisms on LangChain and LangGraph, such as
    caches and stores.
  prefs: []
  type: TYPE_NORMAL
- en: 'In all, we’ll touch on the following topics in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Agentic architectures
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multi-agent architectures
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building adaptive systems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploring reasoning paths
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Agent memory
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Agentic architectures
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we learned in [*Chapter 5*](E_Chapter_5.xhtml#_idTextAnchor231), agents help
    humans solve tasks. Building an agent involves balancing two elements. On one
    side, it’s very similar to application development in the sense that you’re combining
    APIs (including calling foundational models) with production-ready quality. On
    the other side, you’re helping LLMs think and solve a task.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we discussed in [*Chapter 5*](E_Chapter_5.xhtml#_idTextAnchor231), agents
    don’t have a specific algorithm to follow. We give an LLM partial control over
    the execution flow, but to guide it, we use various tricks that help us as humans
    to reason, solve tasks, and think clearly. We should not assume that an LLM can
    magically figure everything out itself; at the current stage, we should guide
    it by creating reasoning workflows. Let’s recall the ReACT agent we learned about
    in [*Chapter 5*](E_Chapter_5.xhtml#_idTextAnchor231), an example of a tool-calling
    pattern:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.1: A prebuilt REACT workflow on LangGraph](img/B32363_06_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.1: A prebuilt REACT workflow on LangGraph'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at a few relatively simple design patterns that help with building
    well-performing agents. You will see these patterns in various combinations across
    different domains and agentic architectures:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Tool calling**: LLMs are trained to do controlled generation via tool calling.
    Hence, wrap your problem as a tool-calling problem when appropriate instead of
    creating complex prompts. Keep in mind that tools should have clear descriptions
    and property names, and experimenting with them is part of the prompt engineering
    exercise. We discussed this pattern in [*Chapter 5*](E_Chapter_5.xhtml#_idTextAnchor231).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Task decomposition**: Keep your prompts relatively simple. Provide specific
    instructions with few-shot examples and split complex tasks into smaller steps.
    You can give an LLM partial control over the task decomposition and planning process,
    managing the flow by an external orchestrator. We used this pattern in [*Chapter
    5*](E_Chapter_5.xhtml#_idTextAnchor231) when we built a plan-and-solve agent.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cooperation and diversity**: Final outputs on complex tasks can be improved
    if you introduce cooperation between multiple instances of LLM-enabled agents.
    Communicating, debating, and sharing different perspectives helps, and you can
    also benefit from various skill sets by initiating your agents with different
    system prompts, available toolsets, etc. Natural language is a native way for
    such agents to communicate since LLMs were trained on natural language tasks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reflection and adaptation**: Adding implicit loops of reflection generally
    improves the quality of end-to-end reasoning on complex tasks. LLMs get feedback
    from the external environment by calling the tools (and these calls might fail
    or produce unexpected results), but at the same time, LLMs can continue iterating
    and self-recover from their mistakes. As an exaggeration, remember that we often
    use the same LLM-as-a-judge, so adding a loop when we ask an LLM to evaluate its
    own reasoning and find errors often helps it to recover. We will learn how to
    build adaptive systems later in this chapter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Models are nondeterministic and can generate multiple candidates**: Do not
    focus on a single output; explore different reasoning paths by expanding the dimension
    of potential options to try out when an LLM interacts with the external environment
    when looking for the solution. We will investigate this pattern in more detail
    in the section below when we discuss ToT and **Language Agent Tree Search** (**LATS**)
    examples.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Code-centric problem framing**: Writing code is very natural for an LLM,
    so try to frame the problem as a code-writing problem if possible. This might
    become a very powerful way of solving the task, especially if you wrap it with
    a code-executing sandbox, a loop for improvement based on the output, access to
    various powerful libraries for data analysis or visualization, and a generation
    step afterward. We will go into more detail in [*Chapter 7*](E_Chapter_7.xhtml#_idTextAnchor327).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Two important comments: first, develop your agents aligned with the best software
    development practices, and make them agile, modular, and easily configurable.
    That would allow you to put multiple specialized agents together, and give users
    the opportunity to easily tune each agent based on their specific task.'
  prefs: []
  type: TYPE_NORMAL
- en: Second, we want to emphasize (once again!) the importance of evaluation and
    experimentation. We will talk about evaluation in more detail in [*Chapter 9*](E_Chapter_9.xhtml#_idTextAnchor448).
    But it’s important to keep in mind that there is no clear path to success. Different
    patterns work better on different types of tasks. Try things, experiment, iterate,
    and don’t forget to evaluate the results of your work. Data, such as tasks and
    expected outputs, and simulators, a safe way for LLMs to interact with tools,
    are key to building really complex and effective agents.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have created a mental map of various design patterns, we’ll look
    deeper into these principles by discussing various agentic architectures and looking
    at examples. We will start by enhancing the RAG architecture we discussed in [*Chapter
    4*](E_Chapter_4.xhtml#_idTextAnchor152) with an agentic approach.
  prefs: []
  type: TYPE_NORMAL
- en: Agentic RAG
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: LLMs enable the development of intelligent agents capable of tackling complex,
    non-repetitive tasks that defy description as deterministic workflows. By splitting
    reasoning into steps in different ways and orchestrating them in a relatively
    simple way, agents can demonstrate a significantly higher task completion rate
    on complex open tasks.
  prefs: []
  type: TYPE_NORMAL
- en: This agent-based approach can be applied across numerous domains, including
    RAG systems, which we discussed in [*Chapter 4*](E_Chapter_4.xhtml#_idTextAnchor152).
    As a reminder, what exactly is *agentic RAG*? Remember, a classic pattern for
    a RAG system is to retrieve chunks given the query, combine them into the context,
    and ask an LLM to generate an answer given a system prompt, combined context,
    and the question.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can improve each of these steps using the principles discussed above (decomposition,
    tool calling, and adaptation):'
  prefs: []
  type: TYPE_NORMAL
- en: '**Dynamic retrieval** hands over the retrieval query generation to the LLM.
    It can decide itself whether to use sparse embeddings, hybrid methods, keyword
    search, or web search. You can wrap retrievals as tools and orchestrate them as
    a LangGraph graph.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Query expansion** tasks an LLM to generate multiple queries based on initial
    ones, and then you combine search outputs based on reciprocal fusion or another
    technique.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Decomposition of reasoning on retrieved chunks** allows you to ask an LLM
    to evaluate each individual chunk given the question (and filter it out if it’s
    irrelevant) to compensate for retrieval inaccuracies. Or you can ask an LLM to
    summarize each chunk by keeping only information given for the input question.
    Anyway, instead of throwing a huge piece of context in front of an LLM, you perform
    many smaller reasoning steps in parallel first.This can not only improve the RAG
    quality by itself but also increase the amount of initially retrieved chunks (by
    decreasing the relevance threshold) or expand each individual chunk with its neighbors.
    In other words, you can overcome some retrieval challenges with LLM reasoning.
    It might increase the overall performance of your application, but of course,
    it comes with latency and potential cost implications.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reflection steps and iterations** task LLMs to dynamically iterate on retrieval
    and query expansion by evaluating the outputs after each iteration. You can also
    use additional grounding and attribution tools as a separate step in your workflow
    and, based on that, reason whether you need to continue working on the answer
    or the answer can be returned to the user.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Based on our definition from the previous chapters, RAG becomes agentic RAG
    when you have shared partial control with the LLM over the execution flow. For
    example, if the LLM decides how to retrieve, reflects on retrieved chunks, and
    adapts based on the first version of the answer, it becomes agentic RAG. From
    our perspective, at this point, it starts making sense to migrate to LangGraph
    since it’s designed specifically for building such applications, but of course,
    you can stay with LangChain or any other framework you prefer (compare how we
    implemented map-reduce video summarization with LangChain and LangGraph separately
    in [*Chapter 3*](E_Chapter_3.xhtml#_idTextAnchor107)).
  prefs: []
  type: TYPE_NORMAL
- en: Multi-agent architectures
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [*Chapter 5*](E_Chapter_5.xhtml#_idTextAnchor231), we learned that decomposing
    a complex task into simpler subtasks typically increases LLM performance. We built
    a plan-and-solve agent that goes a step further than CoT and encourages the LLM
    to generate a plan and follow it. To a certain extent, this architecture was a
    multi-agent one since the research agent (which was responsible for generating
    and following the plan) invoked another agent that focused on a different type
    of task – solving very specific tasks with provided tools. Multi-agentic workflows
    orchestrate multiple agents, allowing them to enhance each other and at the same
    time keep agents modular (which makes it easier to test and reuse them).
  prefs: []
  type: TYPE_NORMAL
- en: We will look into a few core agentic architectures in the remainder of this
    chapter, and introduce some important LangGraph interfaces (such as streaming
    details and handoffs) that are useful to develop agents. If you’re interested,
    you can find more examples and tutorials on the LangChain documentation page at
    [https://langchain-ai.github.io/langgraph/tutorials/#agent-architectures](https://langchain-ai.github.io/langgraph/tutorials/#agent-architectures).
    We’ll begin with discussing the importance of specialization in multi-agentic
    systems, including what the consensus mechanism is and the different consensus
    mechanisms.
  prefs: []
  type: TYPE_NORMAL
- en: Agent roles and specialization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When working on a complex task, we as humans know that usually, it’s beneficial
    to have a team with diverse skills and backgrounds. There is much evidence from
    research and experiments that suggests this is also true for generative AI agents.
    In fact, developing specialized agents offers several advantages for complex AI
    systems.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, specialization improves performance on specific tasks. This allows you
    to:'
  prefs: []
  type: TYPE_NORMAL
- en: Select the optimal set of tools for each task type.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Craft tailored prompts and workflows.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fine-tune hyperparameters such as temperature for specific contexts.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Second, specialized agents help manage complexity. Current LLMs struggle when
    handling too many tools at once. As a best practice, limit each agent to 5-15
    different tools, rather than overloading a single agent with all available tools.
    How to group tools is still an open question; typically, grouping them into toolkits
    to create coherent specialized agents helps.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.2: A supervisor pattern](img/B32363_06_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.2: A supervisor pattern'
  prefs: []
  type: TYPE_NORMAL
- en: Besides becoming *specialized*, keep your agents *modular*. It becomes easier
    to maintain and improve such agents. Also, by working on enterprise assistant
    use cases, you will eventually end up with many different agents available for
    users and developers within your organization that can be composed together. Hence,
    keep in mind that you should make such specialized agents configurable.
  prefs: []
  type: TYPE_NORMAL
- en: 'LangGraph allows you to easily compose graphs by including them as a subgraph
    in a larger graph. There are two ways of doing this:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Compile an agent as a graph and pass it as a callable when defining a node
    of another agent:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Wrap the child agent’s invocation with a Python function and use it within
    the definition of the parent’s node:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note, that your agents might have different schemas (since they perform different
    tasks). In the first case, the parent agent would pass the same keys in schemas
    with the child agent when invoking it. In turn, when the child agent finishes,
    it would update the parent’s state and send back the values corresponding to matching
    keys in both schemas. At the same time, the second option gives you full control
    over how you construct a state that is passed to the child agent, and how the
    state of the parent agent should be updated as a result. For more information,
    take a look at the documentation at [https://langchain-ai.github.io/langgraph/how-tos/subgraph/](https://langchain-ai.github.io/langgraph/how-tos/subgraph/).
  prefs: []
  type: TYPE_NORMAL
- en: Consensus mechanism
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can let multiple agents work on the same tasks in parallel as well. These
    agents might have a different “personality” (introduced by their system prompts;
    for example, some of them might be more curious and explorative, and others might
    be more strict and heavily grounded) or even varying architectures. Each of them
    independently works on getting a solution for the problem, and then you use a
    consensus mechanism to choose the best solution from a few drafts.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.3: A parallel execution of the task with a final consensus step](img/B32363_06_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.3: A parallel execution of the task with a final consensus step'
  prefs: []
  type: TYPE_NORMAL
- en: 'We saw an example of implementing a consensus mechanism based on majority voting
    in [*Chapter 3*](E_Chapter_3.xhtml#_idTextAnchor107). You can wrap it as a separate
    LangGraph node, and there are alternative ways of coming to a consensus across
    multiple agents:'
  prefs: []
  type: TYPE_NORMAL
- en: Let each agent see other solutions and score each of them on a scale of 0 to
    1, and then take the solution with the maximum score.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use an alternative voting mechanism.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use majority voting. It typically works for classification or similar tasks,
    but it might be difficult to implement majority voting if you have a free-text
    output. This is the fastest and the cheapest (in terms of token consumption) mechanism
    since you don’t need to run any additional prompts.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use an external oracle if it exists. For instance, when solving a mathematical
    equation, you can easily verify if the solution is feasible. Computational costs
    depend on the problem but typically are low.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use another (maybe more powerful) LLM as a judge to pick the best solution.
    You can ask an LLM to come up with a score for each solution, or you can task
    it with a multi-class classification problem by presenting all of them and asking
    it to pick the best one.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Develop another agent that excels at the task of selecting the best solution
    for a general task from a set of solutions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It’s worth mentioning that a consensus mechanism has certain latency and cost
    implications, but typically they’re negligible relative to the costs of solving
    a task itself. If you task N agents with the same task, your token consumption
    increases N times, and the consensus mechanism adds a relatively small overhead
    on top of that difference.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also implement your own consensus mechanism. When you do this, consider
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Use few-shot prompting when using an LLM as a judge.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Add examples demonstrating how to score different input-output pairs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Consider including scoring rubrics for different types of responses.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Test the mechanism on diverse outputs to ensure consistency.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: One important note on parallelization – when you let LangGraph execute nodes
    in parallel, updates are applied to the main state in the same order as you’ve
    added nodes to your graph.
  prefs: []
  type: TYPE_NORMAL
- en: Communication protocols
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The third architecture option is to let agents communicate and work collaboratively
    on a task. For example, the agents might benefit from various personalities configured
    through system prompts. Decomposition of a complex task into smaller subtasks
    also helps you retain control over your application and how your agents communicate.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.4: Reflection pattern](img/B32363_06_04.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.4: Reflection pattern'
  prefs: []
  type: TYPE_NORMAL
- en: Agents can work collaboratively on a task by providing critique and reflection.
    There are multiple reflection patterns starting from self-reflection, when the
    agent analyzes its own steps and identifies areas for improvements (but as mentioned
    above, you might initiate the reflecting agent with a slightly different system
    prompt); cross-reflection, when you use another agent (for example, using another
    foundational model); or even reflection, which includes **Human-in-the-Loop**
    (**HIL**) on critical checkpoints (we’ll see in the next section how to build
    adaptive systems of this kind).
  prefs: []
  type: TYPE_NORMAL
- en: You can keep one agent as a supervisor, allow agents to communicate in a network
    (allowing them to decide which agent to send a message or a task), introduce a
    certain hierarchy, or develop more complex flows (for inspiration, take a look
    at some diagrams on the LangGraph documentation page at [https://langchain-ai.github.io/langgraph/concepts/multi_agent/](https://langchain-ai.github.io/langgraph/concepts/multi_agent/)).
  prefs: []
  type: TYPE_NORMAL
- en: 'Designing multi-agent workflows is still an open area of research and experimentation,
    and you need to answer a lot of questions:'
  prefs: []
  type: TYPE_NORMAL
- en: What and how many agents should we include in our system?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What roles should we assign to these agents?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What tools should each agent have access to?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How should agents interact with each other and through which mechanism?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What specific parts of the workflow should we automate?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How do we evaluate our automation and how can we collect data for this evaluation?
    Additionally, what are our success criteria?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now that we’ve examined some core considerations and open questions around
    multi-agent communication, let’s explore two practical mechanisms to structure
    and facilitate agent interactions: *semantic routing*, which directs tasks intelligently
    based on their content, and *organizing interaction*, detailing the specific formats
    and structures that agents can use to effectively exchange information.'
  prefs: []
  type: TYPE_NORMAL
- en: Semantic router
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Among many different ways to organize communication between agents in a true
    multi-agent setup, an important one is a semantic router. Imagine developing an
    enterprise assistant. Typically it becomes more and more complex because it starts
    dealing with various types of questions – general questions (requiring public
    data and general knowledge), questions about the company (requiring access to
    the proprietary company-wide data sources), and questions specific to the user
    (requiring access to the data provided by the user itself). Maintaining such an
    application as a single agent becomes very difficult very soon. Again, we can
    apply our design patterns – decomposition and collaboration!
  prefs: []
  type: TYPE_NORMAL
- en: Imagine we have implemented three types of agents – one answering general questions
    grounded on public data, another one grounded on a company-wide dataset and knowing
    about company specifics, and the third one specialized on working with a small
    source of user-provided documents. Such specialization helps us to use patterns
    such as few-shot prompting and controlled generation. Now we can add a semantic
    router – the first layer that asks an LLM to classify the question and routes
    it to the corresponding agent based on classification results. Each agent (or
    some of them) might even use a self-consistency approach, as we learned in [*Chapter
    3*](E_Chapter_3.xhtml#_idTextAnchor107), to increase the LLM classification accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.5: Semantic router pattern](img/B32363_06_05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.5: Semantic router pattern'
  prefs: []
  type: TYPE_NORMAL
- en: It’s worth mentioning that a task might fall into two or more categories – for
    example, I can ask, “*What is X and how can I do Y?* “ This might not be such
    a common use case in an assistant setting, and you can decide what to do in that
    case. First of all, you might just educate the user by replying with an explanation
    that they should task your application with a single problem per turn. Sometimes
    developers tend to be too focused on trying to solve everything programmatically.
    But some product features are relatively easy to solve via the UI, and users (especially
    in the enterprise setup) are ready to provide their input. Maybe, instead of solving
    a classification problem on the prompt, just add a simple checkbox in the UI,
    or let the system double-check if the level of confidence is low.
  prefs: []
  type: TYPE_NORMAL
- en: You can also use tool calling or other controlled generation techniques we’ve
    learned about to extract both goals and route the execution to two specialized
    agents with different tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Another important aspect of semantic routing is that the performance of your
    application depends a lot on classification accuracy. You can use all the techniques
    we have discussed in the book to improve it – few-shot prompting (including dynamic
    one), incorporating user feedback, sampling, and others.
  prefs: []
  type: TYPE_NORMAL
- en: Organizing interactions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There are two ways to organize communication in multi-agent systems:'
  prefs: []
  type: TYPE_NORMAL
- en: Agents communicate via specific structures that force them to put their thoughts
    and reasoning traces in a specific form, as we saw in the *plan-and-solve* example
    in the previous chapter. We saw how our planning node communicated with the ReACT
    agent via a Pydantic model with a well-structured plan (which, in turn, was a
    result of an LLM’s controlled generation).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: On the other hand, LLMs were trained to take natural language as input and produce
    an output in the same format. Hence, it’s a very natural way for them to communicate
    via messages, and you can implement a communication mechanism by applying messages
    from different agents to the shared list of messages!.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When communicating with messages, you can share all messages via a so-called
    *scratchpad* – a shared list of messages. In that case, your context can grow
    relatively quickly and you might need to use some of the mechanisms to trim the
    chat memory (like preparing running summaries) that we discussed in [*Chapter
    3*](E_Chapter_3.xhtml#_idTextAnchor107). But as general advice, if you need to
    filter or prioritize messages in the history of communication between multiple
    agents, go with the first approach and let them communicate through a controlled
    output. It would give you more control of the state of your workflow at any given
    point in time. Also, you might end up with a situation where you have a complicated
    sequence of messages, for example, *[SystemMessage, HumanMessage, AIMessage, ToolMessage,
    AIMessage, AIMessage, SystemMessage, …]*. Depending on the foundational model
    you’re using, double-check that the model’s provider supports such sequences,
    since previously, many providers supported only relatively simple sequences –
    SystemMessages followed by alternating HumanMessage and AIMessage (maybe with
    a ToolMessage instead of a human one if a tool invocation was decided).
  prefs: []
  type: TYPE_NORMAL
- en: Another alternative is to share only the final results of each execution. This
    keeps the list of messages relatively short.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now it’s time to look at a practical example. Let’s develop a research agent
    that uses tools to answer complex multiple-choice questions based on the public
    MMLU dataset (we’ll use high school geography questions). First, we need to grab
    a dataset from Hugging Face:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'These are our answer options:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s start with a ReACT agent, but let’s deviate from a default system prompt
    and write our own prompt. Let’s focus this agent on being creative and working
    on an evidence-based solution (please note that we used elements of CoT prompting,
    which we discussed in [*Chapter 3*](E_Chapter_3.xhtml#_idTextAnchor107)):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let’s create the agent itself. Since we have a custom prompt for the agent,
    we need a prompt template that includes a system message, a template that formats
    the first user message based on a question and answers provided, and a placeholder
    for further messages to be added to the graph’s state. We also redefine the default
    agent’s state by inheriting from `AgentState` and adding additional keys to it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'We could have stopped here, but let’s go further. We used a specialized research
    agent based on the ReACT pattern (and we slightly adjusted its default configuration).
    Now let’s add a reflection step to it, and use another role profile for an agent
    who will actionably criticize our “student’s” work:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Now we need another research agent that takes not only question and answer options
    but also the previous answer and the feedback. The research agent is tasked with
    using tools to improve the answer and address the critique. We created a simplistic
    and illustrative example. You can always improve it by adding error handling,
    Pydantic validation (for example, checking that either an answer or critique is
    provided), or handling conflicting or ambiguous feedback (for example, structure
    prompts that help the agent prioritize feedback points when there are multiple
    criticisms).
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that we use a less capable LLM for our ReACT agents, just to demonstrate
    the power of the reflection approach (otherwise the graph might finish in a single
    iteration since the agent would figure out the correct answer with the first attempt):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'When defining the state of our graph, we need to keep track of the question
    and answer options, the current answer, and the critique. Also note that we track
    the amount of interaction between a *student* and a *professor* (to avoid infinite
    cycles between them) and we use a custom reducer for that (which summarizes old
    steps and new steps on each run). Let’s define the full state, nodes, and conditional
    edges:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s put it all together and create our graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure 6.6: A research agent with reflection](img/B32363_06_06.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.6: A research agent with reflection'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s run it and inspect what’s happening:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'We have omitted the full output here (you’re welcome to take the code from
    our GitHub repository and experiment with it yourself), but the first answer was
    wrong:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'After five iterations, the weaker LLM was able to figure out the correct answer
    (keep in mind that the “professor” only evaluated the reasoning itself and it
    didn’t use external tools or its own knowledge). Note that, technically speaking,
    we implemented cross-reflection and not self-reflection (since we’ve used a different
    LLM for reflection than the one we used for the reasoning). Here’s an example
    of the feedback provided during the first round:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Next, let’s discuss an alternative communication style for a multi-agent setup,
    via a shared list of messages. But before that, we should discuss the LangGraph
    handoff mechanism and dive into some details of streaming with LangGraph.
  prefs: []
  type: TYPE_NORMAL
- en: LangGraph streaming
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: LangGraph streaming might sometimes be a source of confusion. Each graph has
    not only a `stream` and a corresponding asynchronous `astream` method, but also
    an `astream_events`. Let’s dive into the difference.
  prefs: []
  type: TYPE_NORMAL
- en: The `Stream` method allows you to stream changes to the graph’s state after
    each super-step. Remember, we discussed what a super-step is in [*Chapter 3*](E_Chapter_3.xhtml#_idTextAnchor107),
    but to keep it short, it’s a single iteration over the graph where parallel nodes
    belong to a single super-step while sequential nodes belong to different super-steps.
    If you need actual streaming behavior (like in a chatbot, so that users feel like
    something is happening and the model is actually thinking), you should use `astream`
    with `messages` mode.
  prefs: []
  type: TYPE_NORMAL
- en: 'You have five modes with `stream/astream` methods (of course, you can combine
    multiple modes):'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Mode** | **Description** | **Output** |'
  prefs: []
  type: TYPE_TB
- en: '| updates | Streams only updates to the graph produced by the node | A dictionary
    where each node name maps to its corresponding state update) |'
  prefs: []
  type: TYPE_TB
- en: '| values | Streams the full state of the graph after each super-step | A dictionary
    with the entire graph’s state |'
  prefs: []
  type: TYPE_TB
- en: '| debug | Attempts to stream as much information as possible in the debug mode
    | A dictionary with a timestamp, task_type, and all the corresponding information
    for every event |'
  prefs: []
  type: TYPE_TB
- en: '| custom | Streams events emitted by the node using a StreamWriter | A dictionary
    that was written from the node to a custom writer |'
  prefs: []
  type: TYPE_TB
- en: '| messages | Streams full events (for example, ToolMessages) or its chunks
    in a streaming node if possible (e.g., AI Messages) | A tuple with token or message
    segment and a dictionary containing metadata from the node |'
  prefs: []
  type: TYPE_TB
- en: 'Table 6.1: Different streaming modes for LangGraph'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at an example. If we take the ReACT agent we used in the section
    above and stream with the `values` mode, we’ll get the full state returned after
    every super-step (you can see that the total number of messages is always increasing):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'If we switch to the `update` mode, we’ll get a dictionary where the key is
    the node’s name (remember that parallel nodes can be called within a single super-step)
    and a corresponding update to the state sent by this node:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: LangGraph `stream` always emits a tuple where the first value is a stream mode
    (since you can pass multiple modes by adding them to the list).
  prefs: []
  type: TYPE_NORMAL
- en: 'Then you need an `astream_events` method that streams back events happening
    within the nodes – not just tokens generated by the LLM but any event available
    for a callback:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: "You can find a full list of the events at [https://python.langchain.com/docs/concepts/callbacks/#callback-events](https://python.langchain.com/docs/concepts/callbacks/#callback-even\uFEFF\
    ts)."
  prefs: []
  type: TYPE_NORMAL
- en: Handoffs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So far, we have learned that a node in LangGraph does a chunk of work and sends
    updates to a common state, and an edge controls the flow – it decides which node
    to invoke next (in a deterministic manner or based on the current state). When
    implementing multi-agent architectures, your nodes can be not only functions but
    other agents, or subgraphs (with their own state). You might need to combine state
    updates and flow controls.
  prefs: []
  type: TYPE_NORMAL
- en: 'LangGraph allows you to do that with a `Command` – you can update your graph’s
    state and at the same time invoke another agent by passing a custom state to it.
    This is called a *handoff* – since an agent hands off control to another one.
    You need to pass an `update` – a dictionary with an update of the current state
    to be sent to your graph – and `goto` – a name (or list of names) of the nodes
    to hand off control to:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'A destination agent can be a node from the current or a parent (`Command.PARENT`)
    graph. In other words, you can change the control flow only within the current
    graph, or you can pass it back to the workflow that initiated this one (for example,
    you can’t pass control to any random workflow by ID). You can also invoke a `Command`
    from a tool, or wrap a `Command` as a tool, and then an LLM can decide to hand
    off control to a specific agent. In [*Chapter 3*](E_Chapter_3.xhtml#_idTextAnchor107),
    we discussed the map-reduce pattern and the `Send` class, which allowed us to
    invoke a node in the graph by passing a specific input state to it. We can use
    `Command` together with `Send` (in this example, the destination agent belongs
    to the parent graph):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Communication via a shared messages list
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A few chapters earlier, we discussed how two agents can communicate via controlled
    output (by sending each other special Pydantic instances). Now let’s go back to
    the communication topic and illustrate how agents can communicate with native
    LangChain messages. Let’s take the research agent with a cross-reflection and
    make it work with a shared list of messages. First, the research agent itself
    looks simpler – it has a default state since it gets a user’s question as a HumanMessage:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'We also need to slightly modify the reflection prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The nodes themselves also look simpler, but we add `Command` after the reflection
    node since we decide what to call next with the node itself. Also, we don’t wrap
    a ReACT research agent as a node anymore:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The graph itself also looks very simple:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: If we run it, we will see that at every stage, the graph operates on the same
    (and growing) list of messages.
  prefs: []
  type: TYPE_NORMAL
- en: LangGraph platform
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: LangGraph and LangChain, as you know, are open-source frameworks, but LangChain
    as a company offers the LangGraph platform – a commercial solution that helps
    you develop, manage, and deploy agentic applications. One component of the LangGraph
    platform is LangGraph Studio – an IDE that helps you visualize and debug your
    agents – and another is LangGraph Server.
  prefs: []
  type: TYPE_NORMAL
- en: You can read more about the LangGraph platform at the official website ([https://langchain-ai.github.io/langgraph/concepts/#langgraph-platform](https://langchain-ai.github.io/langgraph/concepts/#langgraph-platform)),
    but let’s discuss a few key concepts for a better understanding of what it means
    to develop an agent.
  prefs: []
  type: TYPE_NORMAL
- en: After you’ve developed an agent, you can wrap it as an HTTP API (using Flask,
    FastAPI, or any other web framework). The LangGraph platform offers you a native
    way to deploy agents, and it wraps them with a unified API (which makes it easier
    for your applications to use these agents). When you’ve built your agent as a
    LangGraph graph object, you deploy an *assistant* – a specific deployment that
    includes an instance of your graph coupled together with a configuration. You
    can easily version and configure assistants in the UI, but it’s important to keep
    parameters configurable (and pass them as `RunnableConfig` to your nodes and tools).
  prefs: []
  type: TYPE_NORMAL
- en: Another important concept is a *thread*. Don’t be confused, a LangGraph thread
    is a different concept from a Python thread (and when you pass a `thread_id` in
    your `RunnableConfig`, you’re passing a LangGraph thread ID). When you think about
    LangGraph threads, think about conversation or Reddit threads. A thread represents
    a session between your assistant (a graph with a specific configuration) and a
    user. You can add per-thread persistence using the checkpointing mechanism we
    discussed in [*Chapter 3*](E_Chapter_3.xhtml#_idTextAnchor107).
  prefs: []
  type: TYPE_NORMAL
- en: A *run* is an invocation of an assistant. In most cases, runs are executed on
    a thread (for persistence). LangGraph Server also allows you to schedule stateless
    runs – they are not assigned to any thread, and because of that, the history of
    interactions is not persisted. LangGraph Server allows you to schedule long-running
    runs, scheduled runs (a.k.a. crons), etc., and it also offers a rich mechanism
    for webhooks attached to runs and polling results back to the user.
  prefs: []
  type: TYPE_NORMAL
- en: We’re not going to discuss the LangGraph Server API in this book. Please take
    a look at the documentation instead.
  prefs: []
  type: TYPE_NORMAL
- en: Building adaptive systems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Adaptability is a great attribute of agents. They should adapt to external
    and user feedback and correct their actions accordingly. As we discussed in [*Chapter
    5*](E_Chapter_5.xhtml#_idTextAnchor231), generative AI agents are adaptive through:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Tool interaction**: They incorporate feedback from previous tool calls and
    their outputs (by including `ToolMessages` that represent tool-calling results)
    when planning the next steps (like our ReACT agent adjusting based on search results).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Explicit reflection**: They can be instructed to analyze current results
    and deliberately adjust their behavior.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Human feedback**: They can incorporate user input at critical decision points.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dynamic behavior adjustment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We saw how to add a reflection step to our plan-and-solve agent. Given the initial
    plan, and the output of the steps performed so far, we’ll ask the LLM to reflect
    on the plan and adjust it. Again, we continue reiterating the key idea – such
    reflection might not happen naturally; you might add it as a separate task (decomposition),
    and you keep partial control over the execution flow by designing its generic
    components.
  prefs: []
  type: TYPE_NORMAL
- en: Human-in-the-loop
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Additionally, when developing agents with complex reasoning trajectories, it
    might be beneficial to incorporate human feedback at a certain point. An agent
    can ask a human to approve or reject certain actions (for example, when it’s invoking
    a tool that is irreversible, like a tool that makes a payment), provide additional
    context to the agent, or give a specific input by modifying the graph’s state.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine we’re developing an agent that searches for job postings, generates
    an application, and sends this application. We might want to ask the user before
    submitting an application, or the logic might be more complex – the agent might
    be collecting data about the user, and for some job postings, it might be missing
    relevant context about past job experience. It should ask the user and persist
    this knowledge in long-term memory for better long-term adaptation.
  prefs: []
  type: TYPE_NORMAL
- en: LangGraph has a special `interrupt` function to implement **HIL**-type interactions.
    You should include this function in the node, and by the first execution, it would
    throw a `GraphInterrupt` exception (the value of which would be presented to the
    user). To resume the execution of the graph, a client should use the `Command`
    class, which we discussed earlier in this chapter. LangGraph would start from
    the same node, re-execute it, and return corresponding values as a result of the
    node invoking the `interrupt` function (if there are multiple `interrupts` in
    your node, LangGraph would keep an ordering). You can also use `Command` to route
    to different nodes based on the user’s input. Of course, you can use `interrupt`
    only when a checkpointer is provided to the graph since its state should be persisted.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s construct a very simple graph with only the node that asks a user for
    their home address:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'The graph returns us a special `__interrupt__` state and stops. Now our application
    (the client) should ask the user this question, and then we can resume. Please
    note that we’re providing the same `thread_id` to restore from the checkpoint:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Note that the graph continued to execute the human_input node, but this time
    the `interrupt` function returned the result, and the graph’s state was updated.
  prefs: []
  type: TYPE_NORMAL
- en: So far, we’ve discussed a few architectural patterns on how to develop an agent.
    Now let’s take a look at another interesting one that allows LLMs to run multiple
    simulations while they’re looking for a solution.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring reasoning paths
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [*Chapter 3*](E_Chapter_3.xhtml#_idTextAnchor107), we discussed CoT prompting.
    But with CoT prompting, the LLM creates a reasoning path within a single turn.
    What if we combine the decomposition pattern and the adaptation pattern by splitting
    this reasoning into pieces?
  prefs: []
  type: TYPE_NORMAL
- en: Tree of Thoughts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Researchers from Google DeepMind and Princeton University introduced **the ToT**
    technique in December 2023\. They generalize the CoT pattern and use thoughts
    as intermediate steps in the exploration process toward the global solution.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s return to the plan-and-solve agent we built in the previous chapter. Let’s
    use the non-deterministic nature of LLMs to improve it. We can generate multiple
    candidates for the next action in the plan on every step (we might need to increase
    the temperature of the underlying LLM). That would help the agent to be more adaptive
    since the next plan generated will take into account the outputs of the previous
    step.
  prefs: []
  type: TYPE_NORMAL
- en: Now we can build a tree of various options and explore this tree with the depth-for-search
    or breadth-for-search method. At the end, we’ll get multiple solutions, and we’ll
    use some of the consensus mechanisms discussed above to pick the best one (for
    example, LLM-as-a-judge).
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.7: Solution path exploration with ToT](img/B32363_06_07.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.7: Solution path exploration with ToT'
  prefs: []
  type: TYPE_NORMAL
- en: Please note that the model’s provider should support the generation of multiple
    candidates in the response (not all providers support this feature).
  prefs: []
  type: TYPE_NORMAL
- en: We would like to highlight (and we’re not tired of doing this repeatedly in
    this chapter) that there’s nothing entirely new in the ToT pattern. You take what
    algorithms and patterns have been used already in other areas, and you use them
    to build capable agents.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now it’s time to do some coding. We’ll take the same components of the plan-and-solve
    agents we developed in [*Chapter 5*](E_Chapter_5.xhtml#_idTextAnchor231) – a planner
    that creates an initial plan and `execution_agent`, which is a research agent
    with access to tools and works on a specific step in the plan. We can make our
    execution agent simpler since we don’t need a custom state:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'We also need a `replanner`component, which will take care of adjusting the
    plan based on previous observations and generating multiple candidates for the
    next action:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: This `replanner` component is crucial for our ToT approach. It takes the current
    plan state and generates multiple potential next steps, encouraging exploration
    of different solution paths rather than following a single linear sequence.
  prefs: []
  type: TYPE_NORMAL
- en: 'To track our exploration path, we need a tree data structure. The `TreeNode`
    class below helps us maintain it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Each `TreeNode` tracks its identity, current step, output, parent relationship,
    and children. We also created a method to get a formatted full plan (we’ll substitute
    it in place of the prompt’s template), and just to make debugging more convenient,
    we overrode a `__repr__` method that returns a readable description of the node.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we need to implement the core logic of our agent. We will explore our tree
    of actions in a depth-for-search mode. This is where the real power of the ToT
    pattern comes into play:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'The `_run_node` function executes the current step, while `_plan_next` generates
    new candidate steps and adds them to our exploration queue. When we reach a final
    node (one where no further steps are needed), `_get_final_response` generates
    a final solution by picking the best one from multiple candidates (originating
    from different solution paths explored). Hence, in our agent’s state, we should
    keep track of the root node, the next node, the queue of nodes to be explored,
    and the nodes we’ve already explored:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'This state structure keeps track of everything we need: the original task,
    our tree structure, exploration queue, path metadata, and candidate solutions.
    Note the special `Annotated` types that use custom reducers (like `operator.add`)
    to handle merging state values properly.'
  prefs: []
  type: TYPE_NORMAL
- en: 'One important thing to keep in mind is that LangGraph doesn’t allow you to
    modify `state` directly. In other words, if we execute something like the following
    within a node, it won’t have an effect on the actual queue in the agent’s state:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: If we want to modify the queue that belongs to the state itself, we should either
    use a custom reducer (as we discussed in [*Chapter 3*](E_Chapter_3.xhtml#_idTextAnchor107))
    or return the queue object to be replaced (since under the hood, LangGraph always
    created deep copies of the state before passing it to the node).
  prefs: []
  type: TYPE_NORMAL
- en: 'We need to define the final step now – the consensus mechanism to choose the
    final answer based on multiple generated candidates:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: This voting mechanism presents all candidate solutions to the model and asks
    it to select the best one, leveraging the model’s ability to evaluate and compare
    options.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let’s add the remaining nodes and edges of the agent. We need two nodes
    – the one that creates an initial plan and another that evaluates the final output.
    Alongside these, we define two corresponding edges that evaluate whether the agent
    should continue on its exploration and whether it’s ready to provide a final response
    to the user:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'These functions round out our implementation by defining the initial plan creation,
    final response generation, and flow control logic. The `_should_create_final_response`
    and `_should_continue` functions determine when to generate a final response and
    when to continue exploration. With all the components in place, we construct the
    final state graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'This creates our finished agent with a complete execution flow. The graph begins
    with initial planning, proceeds through execution and replanning steps, generates
    responses for completed paths, and finally selects the best solution through voting.
    We can visualize the flow using the Mermaid diagram generator, giving us a clear
    picture of our agent’s decision-making process:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.8: LATS agent](img/B32363_06_08.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.8: LATS agent'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can control the maximum number of super-steps, the maximum number of paths
    in the tree to be explored (in particular, the maximum number of candidates for
    the final solution to be generated), and the number of candidates per step. Potentially,
    we could extend our config and control the maximum depth of the tree. Let’s run
    our graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also visualize the explored tree:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.9: Example of an explored execution tree](img/B32363_06_09-01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.9: Example of an explored execution tree'
  prefs: []
  type: TYPE_NORMAL
- en: We limited the number of candidates, but we can potentially increase it and
    add additional pruning logic (which will prune the leaves that are not promising).
    We can use the same LLM-as-a-judge approach, or use some other heuristic for pruning.
    We can also explore more advanced pruning strategies; we’ll talk about one of
    them in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Trimming ToT with MCTS
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Some of you might remember AlphaGo – the first computer program that defeated
    humans in a game of Go. Google DeepMind developed it back in 2015, and it used
    **Monte Carlo Tree Search** (**MCTS**) as the core decision-making algorithm.
    Here’s a simple idea of how it works. Before taking the next move in a game, the
    algorithm builds a decision tree with potential future moves, with nodes representing
    your moves and your opponent’s potential responses (this tree expands quickly,
    as you can imagine). To keep the tree from expanding too fast, they used MCTS
    to search only through the most promising paths that lead to a better state in
    the game.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, coming back to the ToT pattern we learned about in the previous chapter.
    Think about the fact that the dimensionality of the ToT we’ve been building in
    the previous section might grow really fast. If, on every step, we’re generating
    3 candidates and there are only 5 steps in the workflow, we’ll end up with 3⁵=243
    steps to evaluate. That incurs a lot of cost and time. We can trim the dimensionality
    in different ways, for example, by using MCTS. It includes selection and simulation
    components:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Selection** helps you pick the next node when analyzing the tree. You do
    that by balancing exploration and exploitation (you estimate the most promising
    node but add some randomness to this process).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After you **expand** the tree by adding a new child to it, if it’s not a terminal
    node, you need to simulate the consequences of it. This might be done just by
    randomly playing all the next moves until the end, or using more sophisticated
    simulation approaches. After evaluating the child, you backpropagate the results
    to all the parent nodes by adjusting their probability scores for the next round
    of selection.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We’re not aiming to go into the details and teach you MCTS. We only want to
    demonstrate how you apply already-existing algorithms to agentic workflows to
    increase their performance. One such example is a **LATS** approach suggested
    by Andy Zhou and colleagues in June 2024 in their paper *Language Agent Tree Search
    Unifies Reasoning, Acting, and Planning in Language Models*. Without going into
    too much detail (you’re welcome to look at the original paper or the corresponding
    tutorials), the authors added MCTS on top of ToT, and they demonstrated an increased
    performance on complex tasks by getting number 1 on the HumanEval benchmark.
  prefs: []
  type: TYPE_NORMAL
- en: The key idea was that instead of exploring the whole tree, they use an LLM to
    evaluate the quality of the solution you get at every step (by looking at the
    sequence of all the steps on these specific reasoning steps and the outputs you’ve
    got so far).
  prefs: []
  type: TYPE_NORMAL
- en: Now, as we’ve discussed some more advanced architectures that allow us to build
    better agents, there’s one last component to briefly touch on – memory. Helping
    agents to retain and retrieve relevant information from long-term interactions
    helps us to develop more advanced and helpful agents.
  prefs: []
  type: TYPE_NORMAL
- en: Agent memory
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We discussed memory mechanisms in [*Chapter 3*](E_Chapter_3.xhtml#_idTextAnchor107).
    To recap, LangGraph has the notion of short-term memory via the `Checkpointer`
    mechanism, which saves checkpoints to persistent storage. This is the so-called
    per-thread persistence (remember, we discussed earlier in this chapter that the
    notion of a thread in LangGraph is similar to a conversation). In other words,
    the agent remembers our interactions within a given session, but it starts from
    scratch each time.
  prefs: []
  type: TYPE_NORMAL
- en: As you can imagine, for complex agents, this memory mechanism might be inefficient
    for two reasons. First, you might lose important information about the user. Second,
    during the exploration phase when looking for a solution, an agent might learn
    something important about the environment that it forgets each time – and it doesn’t
    look efficient. That’s why there’s the concept of **long-term memory**, which
    helps an agent to accumulate knowledge and gain from historical experiences, and
    enables its continuous improvement on the long horizon.
  prefs: []
  type: TYPE_NORMAL
- en: How to design and use long-term memory in practice is still an open question.
    First, you need to extract useful information (keeping in mind privacy requirements
    too; more about that in [*Chapter 9*](E_Chapter_9.xhtml#_idTextAnchor448)) that
    you want to store during the runtime and then you need to extract it during the
    next execution. Extraction is close to the retrieval problem we discussed while
    talking about RAG since we need to extract only knowledge relevant to the given
    context. The last component is the compaction of memory – you probably want to
    periodically self-reflect on what you have learned, optimize it, and forget irrelevant
    facts.
  prefs: []
  type: TYPE_NORMAL
- en: 'These are key considerations to take into account, but we haven’t seen any
    great practical implementations of long-term memory for agentic workflows yet.
    In practice, these days people typically use two components – a built-in **cache**
    (a mechanism to cache LLMs responses), a built-in **store** (a persistent key-value
    store), and a custom cache or database. Use the custom option when:'
  prefs: []
  type: TYPE_NORMAL
- en: You need additional flexibility for how you organize memory – for example, you
    would like to keep track of all memory states.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You need advanced read or write access patterns when working with this memory.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You need to keep the memory distributed and across multiple workers, and you’d
    like to use a database other than PostgreSQL.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cache
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Caching allows you to save and retrieve key values. Imagine you’re working on
    an enterprise question-answering assistance application, and in the UI, you ask
    a user whether they like the answer. If the answer is positive, or if you have
    a curated dataset of question-answer pairs for the most important topics, you
    can store these in a cache. When the same (or a similar) question is asked later,
    the system can quickly return the cached response instead of regenerating it from
    scratch.
  prefs: []
  type: TYPE_NORMAL
- en: 'LangChain allows you to set a global cache for LLM responses in the following
    way (after you have initialized the cache, the LLM’s response will be added to
    the cache, as we’ll see below):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Caching with LangChain works as follows: Each vendor’s implementation of a
    `ChatModel` inherits from the base class, and the base class first tries to look
    up a value in the cache during generation. cache is a global variable that we
    can expect (of course, only after it has been initialized). It caches responses
    based on the key that consists of a string representation of the prompt and the
    string representation of the LLM instance (produced by the `llm._get_llm_string`
    method).'
  prefs: []
  type: TYPE_NORMAL
- en: 'This means the LLM’s generation parameters (such as `stop_words` or `temperature`)
    are included in the cache key:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'LangChain supports in-memory and SQLite caches out of the box (they form part
    of `langchain_core.caches`), and there are also many vendor integrations – available
    through the `langchain_community.cache` subpackage at [https://python.langchain.com/api_reference/community/cache.html](https://python.langchain.com/api_reference/community/cache.html)
    or through specific vendor integrations (for example, `langchain-mongodb` offers
    cache integration for MongoDB: [https://langchain-mongodb.readthedocs.io/en/latest/langchain_mongodb/api_docs.html](https://langchain-mongodb.readthedocs.io/en/latest/langchain_mongodb/api_docs.html)).'
  prefs: []
  type: TYPE_NORMAL
- en: We recommend introducing a separate LangGraph node instead that hits an actual
    cache (based on Redis or another database), since it allows you to control whether
    you’d like to search for similar questions using the embedding mechanism we discussed
    in [*Chapter 4*](E_Chapter_4.xhtml#_idTextAnchor152) when we were talking about
    RAG.
  prefs: []
  type: TYPE_NORMAL
- en: Store
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we have learned before, a `Checkpointer` mechanism allows you to enhance
    your workflows with a thread-level persistent memory; by thread-level, we mean
    a conversation-level persistence. Each conversation can be started where it stops,
    and the workflow executes the previously collected context.
  prefs: []
  type: TYPE_NORMAL
- en: A `BaseStore` is a persistent key-value storage system that organizes your values
    by namespace (hierarchical tuples of string paths, similar to folders. It supports
    standard operations such as `put`, `delete` and `get` operations, as well as a
    `search` method that implements different semantic search capabilities (typically,
    based on the embedding mechanism) and accounts for a hierarchical nature of namespaces.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s initialize a store and add some values to it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'We can easily query the value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'If we query it by a partial path of the namespace, we won’t get any results
    (we need a full matching namespace). The following would return no results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'On the other side, when using `search`, we can use a partial namespace path:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, we were able to retrieve all relevant facts stored in memory
    by using a partial search.
  prefs: []
  type: TYPE_NORMAL
- en: LangGraph has built-in `InMemoryStore` and `PostgresStore` implementations.
    Agentic memory mechanisms are still evolving. You can build your own implementation
    from available components, but we should see a lot of progress in the coming years
    or even months.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we dived deep into advanced applications of LLMs and the architectural
    patterns that enable them, leveraging LangChain and LangGraph. The key takeaway
    is that effectively building complex AI systems goes beyond simply prompting an
    LLM; it requires careful architectural design of the workflow itself, tool usage,
    and giving an LLM partial control over the workflow. We also discussed different
    agentic AI design patterns and how to develop agents that leverage LLMs’ tool-calling
    abilities to solve complex tasks.
  prefs: []
  type: TYPE_NORMAL
- en: We explored how LangGraph streaming works and how to control what information
    is streamed back during execution. We discussed the difference between streaming
    state updates and partial streaming answer tokens, learned about the Command interface
    as a way to hand off execution to a specific node within or outside the current
    LangGraph workflow, looked at the LangGraph platform and its main capabilities,
    and discussed how to implement HIL with LangGraph. We discussed how a thread on
    LangGraph differs from a traditional Pythonic definition (a thread is somewhat
    similar to a conversation instance), and we learned how to add memory to our workflow
    per-thread and with cross-thread persistence. Finally, we learned how to expand
    beyond basic LLM applications and build robust, adaptive, and intelligent systems
    by leveraging the advanced capabilities of LangChain and LangGraph.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we’ll take a look at how generative AI transforms the software
    engineering industry by assisting in code development and data analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Name at least three design patterns to consider when building generative AI
    agents.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Explain the concept of “dynamic retrieval” in the context of agentic RAG.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How can cooperation between agents improve the outputs of complex tasks? How
    can you increase the diversity of cooperating agents, and what impact on performance
    might it have?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Describe examples of reaching consensus across multiple agents’ outputs.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the two main ways to organize communication in a multi-agent system
    with LangGraph?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Explain the differences between stream, astream, and astream_events in LangGraph.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is a command in LangGraph, and how is it related to handoffs?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Explain the concept of a thread in the LangGraph platform. How is it different
    from Pythonic threads?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Explain the core idea behind the Tree of Thoughts (ToT) technique. How is ToT
    related to the decomposition pattern?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Describe the difference between short-term and long-term memory in the context
    of agentic systems.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Subscribe to our weekly newsletter
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Subscribe to AI_Distilled, the go-to newsletter for AI professionals, researchers,
    and innovators, at [https://packt.link/Q5UyU](E_Chapter_6.xhtml).
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Newsletter_QRcode1.jpg)'
  prefs: []
  type: TYPE_IMG
