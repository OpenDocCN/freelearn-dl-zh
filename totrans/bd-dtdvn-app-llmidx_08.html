<html><head></head><body><html>&#13;
 <head>&#13;
  <title>&#13;
   Querying Our Data, Part 2 – Postprocessing and Response Synthesis&#13;
  </title>&#13;
 </head>&#13;
 <body>&#13;
  <div class="epub-source">&#13;
   <h1 id="_idParaDest-157">&#13;
    Querying Our Data, Part 2 – Postprocessing and Response Synthesis&#13;
   </h1>&#13;
   <div id="_idContainer077">&#13;
    <p>&#13;
     Building on the knowledge acquired in the previous chapter, we will now explore various postprocessing techniques to refine the retrieved context before covering the final query response synthesis. Afterward, we will learn how to bring all these components together into powerful query engines so that we can perform end-to-end natural language querying over documents. We’ll also get to practice our new skills by working on our&#13;
     <span class="No-Break">&#13;
      tutoring project.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     In this chapter, we’re going to cover the following&#13;
     <span class="No-Break">&#13;
      main topics:&#13;
     </span>&#13;
    </p>&#13;
    <ul>&#13;
     <li>&#13;
      Re-ranking, transforming, and filtering nodes&#13;
      <span class="No-Break">&#13;
       using postprocessors&#13;
      </span>&#13;
     </li>&#13;
     <li>&#13;
      Understanding the&#13;
      <span class="No-Break">&#13;
       response synthesizers&#13;
      </span>&#13;
     </li>&#13;
     <li>&#13;
      Implementing output&#13;
      <span class="No-Break">&#13;
       parsing techniques&#13;
      </span>&#13;
     </li>&#13;
     <li>&#13;
      Building and using&#13;
      <span class="No-Break">&#13;
       query engines&#13;
      </span>&#13;
     </li>&#13;
     <li>&#13;
      Hands-on – building quizzes&#13;
      <span class="No-Break">&#13;
       in PITS&#13;
      </span>&#13;
     </li>&#13;
    </ul>&#13;
    <a id="_idTextAnchor157">&#13;
    </a>&#13;
   </div>&#13;
  </div>&#13;
 </body>&#13;
</html>
<html>&#13;
 <head>&#13;
  <title>&#13;
   Technical requirements&#13;
  </title>&#13;
 </head>&#13;
 <body>&#13;
  <div class="epub-source">&#13;
   <h1 id="_idParaDest-158">&#13;
    Technical requirements&#13;
   </h1>&#13;
   <div id="_idContainer077">&#13;
    <p>&#13;
     For this chapter, you will need to install the following packages in&#13;
     <span class="No-Break">&#13;
      your environment:&#13;
     </span>&#13;
    </p>&#13;
    <ul>&#13;
     <li>&#13;
      <em class="italic">&#13;
       spaCy&#13;
      </em>&#13;
      :&#13;
      <a>&#13;
       <span class="No-Break">&#13;
        https://spacy.io/&#13;
       </span>&#13;
      </a>&#13;
     </li>&#13;
     <li>&#13;
      <span class="No-Break">&#13;
       <em class="italic">&#13;
        Guardrails-AI&#13;
       </em>&#13;
      </span>&#13;
      <span class="No-Break">&#13;
       :&#13;
      </span>&#13;
      <a>&#13;
       <span class="No-Break">&#13;
        https://www.guardrailsai.com/&#13;
       </span>&#13;
      </a>&#13;
     </li>&#13;
     <li>&#13;
      <span class="No-Break">&#13;
       <em class="italic">&#13;
        pandas&#13;
       </em>&#13;
      </span>&#13;
      <span class="No-Break">&#13;
       :&#13;
      </span>&#13;
      <a>&#13;
       <span class="No-Break">&#13;
        https://pandas.pydata.org/&#13;
       </span>&#13;
      </a>&#13;
     </li>&#13;
    </ul>&#13;
    <p>&#13;
     All the code samples in this chapter can be found in the&#13;
     <code class="literal">&#13;
      ch7&#13;
     </code>&#13;
     subfolder of this book’s GitHub&#13;
     <span class="No-Break">&#13;
      repository:&#13;
     </span>&#13;
     <a>&#13;
      <span class="No-Break">&#13;
       https://github.com/PacktPublishing/Building-Data-Driven-Applications-with-LlamaIndex&#13;
      </span>&#13;
     </a>&#13;
     <span class="No-Break">&#13;
      .&#13;
     </span>&#13;
    </p>&#13;
    <a id="_idTextAnchor158">&#13;
    </a>&#13;
   </div>&#13;
  </div>&#13;
 </body>&#13;
</html>
<html>&#13;
 <head>&#13;
  <title>&#13;
   Re-ranking, transforming, and filtering nodes using postprocessors&#13;
  </title>&#13;
 </head>&#13;
 <body>&#13;
  <div class="epub-source">&#13;
   <h1 id="_idParaDest-159">&#13;
    Re-ranking, transforming, and filtering nodes using postprocessors&#13;
   </h1>&#13;
   <div id="_idContainer077">&#13;
    from llama_index.core.postprocessor import SimilarityPostprocessor&#13;
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader&#13;
reader = SimpleDirectoryReader('files/other')&#13;
documents = reader.load_data()&#13;
index = VectorStoreIndex.from_documents(documents)&#13;
retriever = index.as_retriever(retriever_mode='default')&#13;
nodes = retriever.retrieve(&#13;
"What did Fluffy found in the gentle stream?"&#13;
)&#13;
    Print('Initial nodes:')&#13;
for node in nodes:&#13;
print(f"Node: {node.node_id} – Score: {node.score}")&#13;
    Pp = SimilarityPostprocessor(&#13;
    nodes=nodes,&#13;
    similarity_cutoff=0.86&#13;
)&#13;
remaining_nodes = pp.postprocess_nodes(nodes)&#13;
print('Remaining nodes:')&#13;
for node in remaining_nodes:&#13;
print(f"Node: {node.node_id} – Score: {node.score}")&#13;
    Initial nodes:&#13;
Node: da51464d-e83f-4aec-a9db-8bd839ab3a4c - Score: 0.8516122822966049&#13;
Node: f839ec27-e487-4132-b139-79e3695d5500 - Score: 0.8368901228748273&#13;
Remaining nodes:&#13;
Node: da51464d-e83f-4aec-a9db-8bd839ab3a4c - Score: 0.8516122822966049&#13;
    pip install spacy&#13;
    from llama_index.core.postprocessor import KeywordNodePostprocessor&#13;
from llama_index.core.schema import TextNode, NodeWithScore&#13;
nodes = [&#13;
    TextNode(&#13;
        text="Entry no: 1, &lt;SECRET&gt;, Attack at Dawn"&#13;
    ),&#13;
    TextNode(&#13;
        text="Entry no: 2, &lt;RESTRICTED&gt;, Go to point Bravo"&#13;
    ),&#13;
    TextNode(&#13;
        text="Entry no: 3, &lt;PUBLIC&gt;, text: Roses are Red"&#13;
    ),&#13;
]&#13;
    node_with_score_list = [&#13;
    NodeWithScore(node=node) for node in nodes&#13;
]&#13;
pp = KeywordNodePostprocessor(&#13;
    exclude_keywords=["SECRET", "RESTRICTED"]&#13;
)&#13;
remaining_nodes = pp.postprocess_nodes(&#13;
    node_with_score_list&#13;
)&#13;
print('Remaining nodes:')&#13;
for node_with_score in remaining_nodes:&#13;
    node = node_with_score.node&#13;
    print(f"Text: {node.text}")&#13;
    from llama_index.core.postprocessor import &#13;
    MetadataReplacementPostProcessor&#13;
from llama_index.core.schema import TextNode, NodeWithScore&#13;
nodes = [&#13;
    TextNode(&#13;
        text="Article 1",&#13;
        metadata={"summary": "Summary of article 1"}&#13;
    ),&#13;
    TextNode(&#13;
        text="Article 2",&#13;
        metadata={"summary": "Summary of article 2"}&#13;
    ),&#13;
]&#13;
    node_with_score_list = [&#13;
    NodeWithScore(node=node) for node in nodes&#13;
]&#13;
pp = MetadataReplacementPostProcessor(&#13;
    target_metadata_key="summary"&#13;
)&#13;
processed_nodes = pp.postprocess_nodes(&#13;
    node_with_score_list&#13;
)&#13;
for node_with_score in processed_nodes:&#13;
    print(f"Replaced Text: {node_with_score.node.text}")&#13;
    Replaced Text: Summary of article 1&#13;
Replaced Text: Summary of article 2&#13;
    from llama_index.core.postprocessor.optimizer import &#13;
    SentenceEmbeddingOptimizer&#13;
optimizer = SentenceEmbeddingOptimizer(&#13;
    percentile_cutoff=0.8,&#13;
    threshold_cutoff=0.7&#13;
)&#13;
query_engine = index.as_query_engine(&#13;
    optimizer=optimizer&#13;
)&#13;
response = query_engine.query("&lt;your_query_here&gt;")&#13;
    <p>&#13;
     In the previous chapter, we discussed the various retrieval methods that LlamaIndex offers. We extracted the necessary context to be able to enrich and improve the query we are now sending to the LLM. But is&#13;
     <span class="No-Break">&#13;
      this enough?&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     As we have already discussed,&#13;
     <em class="italic">&#13;
      naive&#13;
     </em>&#13;
     retrieval methods are unlikely to produce ideal results in any scenario. There will probably be many situations where the returned nodes will perhaps contain irrelevant information or will not be sorted in chronological order. These kinds of situations could put the LLM in difficulty, adversely affecting the quality of the prompt that our RAG&#13;
     <span class="No-Break">&#13;
      application builds.&#13;
     </span>&#13;
    </p>&#13;
    <p class="callout-heading">&#13;
     A quick side notes&#13;
    </p>&#13;
    <p class="callout">&#13;
     In case it wasn’t already obvious, the main purpose of a RAG flow is to programmatically build prompts. Instead of manually building these prompts and then inputting them into a ChatGPT-like interface, LlamaIndex dynamically assembles the prompts from our documents, which are split into nodes and then indexed and selected using retrievers. Many things could go wrong in this process. Maybe we didn’t ingest the original documents completely or correctly, or maybe we didn’t choose the right&#13;
     <code class="literal">&#13;
      chunk_size&#13;
     </code>&#13;
     value and ended up with nodes that were too granular or too loaded with irrelevant information. Maybe we didn’t index them correctly, or maybe the retriever we used simply didn’t select the nodes in the correct order or brought in more information than&#13;
     <span class="No-Break">&#13;
      we wanted.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     There are many points where errors could creep into the whole process. That doesn’t sound very encouraging,&#13;
     <span class="No-Break">&#13;
      does it?&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     The good news is that we still have an opportunity to improve this context before the final step of sending the information to the LLM. This opportunity comes in the form of&#13;
     <strong class="bold">&#13;
      node postprocessors&#13;
     </strong>&#13;
     and&#13;
     <span class="No-Break">&#13;
      <strong class="bold">&#13;
       response synthesizers&#13;
      </strong>&#13;
     </span>&#13;
     <span class="No-Break">&#13;
      .&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     But first, let’s understand how&#13;
     <span class="No-Break">&#13;
      postprocessors work.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     Node postprocessors are critical in refining the results that are obtained from the retrieval process. That is because no matter how good the retrieval step is, there is always a chance of additional, unnecessary retrieved data&#13;
     <em class="italic">&#13;
      polluting&#13;
     </em>&#13;
     our context and confusing the LLM. In other cases, the retrieved nodes might be relevant but not necessarily in the correct order, and that can also affect the quality of the&#13;
     <span class="No-Break">&#13;
      LLM’s response.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     <span class="No-Break">&#13;
      <em class="italic">&#13;
       Figure 7&#13;
      </em>&#13;
     </span>&#13;
     <em class="italic">&#13;
      .1&#13;
     </em>&#13;
     depicts the role of the postprocessors in a&#13;
     <span class="No-Break">&#13;
      RAG workflow:&#13;
     </span>&#13;
    </p>&#13;
    <div>&#13;
     <div class="IMG---Figure" id="_idContainer072">&#13;
      <img src="../Images/B21861_07_1.jpg"/>&#13;
     </div>&#13;
    </div>&#13;
    <p class="IMG---Caption" lang="en-US">&#13;
     Figure 7.1 – The role of node postprocessors in RAG&#13;
    </p>&#13;
    <p>&#13;
     These processors operate on a set of nodes, applying transformations or filters to enhance the relevance and quality of the information. They can be used on their own, to process a given set of nodes, but they are more commonly used within query engines, after the node retrieval step and before response synthesis. LlamaIndex provides various built-in processors but also the option of building custom&#13;
     <span class="No-Break">&#13;
      postprocessing logic.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     Let’s begin by understanding the different purposes and operating modes of&#13;
     <span class="No-Break">&#13;
      node postprocessors.&#13;
     </span>&#13;
    </p>&#13;
    <a id="_idTextAnchor159">&#13;
    </a>&#13;
    <h2 id="_idParaDest-160">&#13;
     Exploring how postprocessors filter, transform, and re-rank nodes&#13;
    </h2>&#13;
    <p>&#13;
     At their core, all node postprocessors work by adjusting the retrieved context before that context gets injected into a prompt and sent to the LLM for response synthesis. They operate by either filtering, transforming, or re-ranking nodes. Let’s have a look at these operating modes to get a&#13;
     <span class="No-Break">&#13;
      better understanding.&#13;
     </span>&#13;
    </p>&#13;
    <h3>&#13;
     Node filtering postprocessors&#13;
    </h3>&#13;
    <p>&#13;
     Node filtering postprocessors are designed to remove irrelevant or unnecessary nodes from the&#13;
     <a id="_idIndexMarker641">&#13;
     </a>&#13;
     set of retrieved results. They work by applying specific criteria to each node and discarding those that don’t meet the requirements. For example,&#13;
     <code class="literal">&#13;
      SimilarityPostprocessor&#13;
     </code>&#13;
     filters out nodes whose similarity score falls below a specified threshold, ensuring that only highly relevant nodes are passed to the language model for response generation. Similarly,&#13;
     <code class="literal">&#13;
      KeywordNodePostprocessor&#13;
     </code>&#13;
     keeps only the nodes that contain certain required keywords or excludes nodes with specific unwanted keywords. Node filtering helps to reduce information overload and improve the quality of the final response by focusing on the most&#13;
     <span class="No-Break">&#13;
      pertinent information.&#13;
     </span>&#13;
    </p>&#13;
    <h3>&#13;
     Node transforming postprocessors&#13;
    </h3>&#13;
    <p>&#13;
     Node transforming postprocessors modify the content of the retrieved nodes without necessarily&#13;
     <a id="_idIndexMarker642">&#13;
     </a>&#13;
     removing any of them. These postprocessors aim to enhance the relevance and usefulness of the information within each node. One example is&#13;
     <code class="literal">&#13;
      MetadataReplacementPostprocessor&#13;
     </code>&#13;
     , which replaces the content of a node with a specific field from that node’s metadata. This allows the text being used to be dynamically adjusted to represent a node based on its metadata rather than the original ingested content. Another example is&#13;
     <code class="literal">&#13;
      SentenceEmbeddingOptimizer&#13;
     </code>&#13;
     , which optimizes longer text passages by selecting the most relevant sentences within a node based on their semantic similarity to the query. By transforming the nodes’ content, these postprocessors help align the information more closely with the user’s query and improve the overall quality of the&#13;
     <span class="No-Break">&#13;
      generated response.&#13;
     </span>&#13;
    </p>&#13;
    <h3>&#13;
     Node re-ranking postprocessors&#13;
    </h3>&#13;
    <p>&#13;
     These postprocessors don’t specifically remove or change the retrieved nodes. The purpose&#13;
     <a id="_idIndexMarker643">&#13;
     </a>&#13;
     of a re-ranker is to take the initial set of nodes returned by the retriever and reorder them based on their relevance to the given query. This is particularly important when dealing with long-form queries or complex information needs as many LLMs struggle to effectively process and generate accurate responses when provided with lengthy or multi-faceted contexts. By employing a re-ranker, the RAG system can prioritize the most pertinent information and present it to the LLM in a more coherent format, thus leading to&#13;
     <span class="No-Break">&#13;
      better responses.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     Re-rankers often leverage advanced techniques such as deep learning, transformers, or LLMs themselves to assess the relevance of each retrieved document or passage. They may consider factors such as semantic similarity, context overlap, or query-document alignment to&#13;
     <a id="_idIndexMarker644">&#13;
     </a>&#13;
     assign relevance scores to the retrieved nodes. The top-ranked nodes are then fed into the LLM, which generates the final response based on this refined context, enhancing the overall performance and utility of the RAG system. By incorporating a re-ranking step into the RAG pipeline, the system can overcome the limitations of LLMs in handling long or complex queries, ultimately providing more accurate, relevant, and useful responses&#13;
     <span class="No-Break">&#13;
      to users.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     Next, we’ll explore the built-in LlamaIndex postprocessors in all&#13;
     <span class="No-Break">&#13;
      three categories.&#13;
     </span>&#13;
    </p>&#13;
    <a id="_idTextAnchor160">&#13;
    </a>&#13;
    <h2 id="_idParaDest-161">&#13;
     SimilarityPostprocessor&#13;
    </h2>&#13;
    <p>&#13;
     <code class="literal">&#13;
      SimilarityPostprocessor&#13;
     </code>&#13;
     filters nodes by comparing them to a similarity score threshold. Nodes&#13;
     <a id="_idIndexMarker645">&#13;
     </a>&#13;
     that score below this threshold are removed, ensuring only relevant and similar content to the query remains. This is particularly useful because it ensures that the nodes that are passed to the language model for response generation are relevant by having a high degree of semantic correlation with&#13;
     <span class="No-Break">&#13;
      the query.&#13;
     </span>&#13;
    </p>&#13;
    <p class="callout-heading">&#13;
     A potential use cases&#13;
    </p>&#13;
    <p class="callout">&#13;
     An e-commerce company has a customer support chatbot powered by an LLM. Let’s assume that the chatbot retrieves nodes from&#13;
     <code class="literal">&#13;
      KeywordTableIndex&#13;
     </code>&#13;
     and tries to identify all contexts based on the keywords contained in the user query. For a query such as,&#13;
     <em class="italic">&#13;
      How do I return a damaged item I received yesterday?&#13;
     </em>&#13;
     , the retrieved nodes might include general return policies, product descriptions for items ordered by the customer, shipping information, and even irrelevant product advertisements or promotions.&#13;
     <code class="literal">&#13;
      SimilarityPostprocessor&#13;
     </code>&#13;
     could filter out nodes that are not closely related to the specific context of the query. In this case, it would prioritize nodes specifically discussing return policies for damaged items and recent orders by the customer, while discarding general product advertisements and unrelated shipping details. That would greatly increase the chance of the LLM producing a more&#13;
     <span class="No-Break">&#13;
      meaningful response.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     This postprocessor takes a list of nodes, typically fetched by a retriever, as input, each with an associated similarity score. The postprocessor can be configured with a&#13;
     <code class="literal">&#13;
      similarity_cutoff&#13;
     </code>&#13;
     parameter. This threshold determines the minimum score a node must have to be considered relevant. If a node’s similarity score is&#13;
     <code class="literal">&#13;
      None&#13;
     </code>&#13;
     or if it’s lower than&#13;
     <code class="literal">&#13;
      similarity_cutoff&#13;
     </code>&#13;
     , the node is considered not to meet the threshold and is therefore excluded from the final list. Essentially, this postprocessor filters out any nodes that have a similarity score below the set threshold. This ensures that only nodes closely&#13;
     <a id="_idIndexMarker646">&#13;
     </a>&#13;
     related to the query are retained. The nodes meeting or exceeding the similarity score threshold is then passed on for further processing or response synthesis. Here’s a simple example of how we can use it&#13;
     <span class="No-Break">&#13;
      in practice:&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     In the first part of the code, we took care of the imports and then ingested a sample file into a document. Then, we created a&#13;
     <code class="literal">&#13;
      VectorStoreIndex&#13;
     </code>&#13;
     index and used the default retriever to fetch relevant nodes based on&#13;
     <span class="No-Break">&#13;
      a query:&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     Here, we printed the original list of nodes since they were fetched by the retriever. Now, let’s apply&#13;
     <span class="No-Break">&#13;
      the postprocessor.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     After building&#13;
     <a id="_idIndexMarker647">&#13;
     </a>&#13;
     and applying the postprocessor on the nodes, we print the remaining nodes. The output will be similar to&#13;
     <span class="No-Break">&#13;
      the following:&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     As we can see, the second node from the initial list was removed because it had a score below the threshold we defined –&#13;
     <span class="No-Break">&#13;
      0.85.&#13;
     </span>&#13;
    </p>&#13;
    <a id="_idTextAnchor161">&#13;
    </a>&#13;
    <h2 id="_idParaDest-162">&#13;
     KeywordNodePostprocessor&#13;
    </h2>&#13;
    <p>&#13;
     <code class="literal">&#13;
      KeywordNodePostprocessor&#13;
     </code>&#13;
     is designed to refine the selection of nodes based on specific keywords. This&#13;
     <a id="_idIndexMarker648">&#13;
     </a>&#13;
     postprocessor works by ensuring that the retrieved nodes either contain certain required keywords or exclude specific unwanted keywords. It’s a great method for aligning the content of the nodes more closely with the user’s query by focusing on&#13;
     <span class="No-Break">&#13;
      keyword relevance.&#13;
     </span>&#13;
    </p>&#13;
    <p class="callout-heading">&#13;
     Practical use case in a RAG scenario&#13;
    </p>&#13;
    <p class="callout">&#13;
     Imagine a scenario in a corporate environment where the RAG system is used to retrieve information from a vast internal database for employee queries. However, there are certain confidential files or sections of files that should not be accessible to all employees. By configuring&#13;
     <code class="literal">&#13;
      KeywordNodePostprocessor&#13;
     </code>&#13;
     with keywords that indicate sensitive content (such as&#13;
     <em class="italic">&#13;
      confidential&#13;
     </em>&#13;
     ,&#13;
     <em class="italic">&#13;
      restricted&#13;
     </em>&#13;
     , or specific project code names), the system can automatically exclude nodes containing these keywords from the retrieval results. This setup ensures that sensitive information is not inadvertently disclosed, maintaining the integrity and confidentiality of the&#13;
     <span class="No-Break">&#13;
      corporate data.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     It takes a list of nodes as input, typically fetched by a retriever, and is configured with parameters&#13;
     <a id="_idIndexMarker649">&#13;
     </a>&#13;
     for required and excluded keywords.&#13;
     <code class="literal">&#13;
      KeywordNodePostprocessor&#13;
     </code>&#13;
     then processes these nodes, keeping only those that meet the keyword criteria. This ensures that the final set of nodes is highly relevant to the specific query, leading to more accurate and useful responses in a&#13;
     <span class="No-Break">&#13;
      RAG system.&#13;
     </span>&#13;
    </p>&#13;
    <p class="callout-heading">&#13;
     Quick note&#13;
    </p>&#13;
    <p class="callout">&#13;
     The postprocessor&#13;
     <a id="_idIndexMarker650">&#13;
     </a>&#13;
     relies on the&#13;
     <code class="literal">&#13;
      spaCy&#13;
     </code>&#13;
     library (&#13;
     <a>&#13;
      https://pypi.org/project/spacy/&#13;
     </a>&#13;
     ), which you must install on your system before running the next example. This is a powerful Python library for advanced NLP. Its features include neural network models for various NLP tasks such as tagging, parsing, and NER. It’s a piece of commercial open source software available under an&#13;
     <span class="No-Break">&#13;
      MIT license.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     To use&#13;
     <code class="literal">&#13;
      KeywordNodePostprocessor&#13;
     </code>&#13;
     , make sure you install spaCy in your environment by running the&#13;
     <span class="No-Break">&#13;
      following command:&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     Here’s a basic example of how to use this postprocessor to filter out some log entries based on their&#13;
     <span class="No-Break">&#13;
      classification label:&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     In this example, we’re manually defining the nodes instead of ingesting data from external files. After we define the nodes, we have to wrap them into&#13;
     <code class="literal">&#13;
      NodeWithScore&#13;
     </code>&#13;
     because that’s&#13;
     <a id="_idIndexMarker651">&#13;
     </a>&#13;
     the expected input of&#13;
     <span class="No-Break">&#13;
      the postprocessor:&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     In this example,&#13;
     <code class="literal">&#13;
      KeywordNodePostprocessor&#13;
     </code>&#13;
     filters the nodes fetched by the retriever, excluding those that include&#13;
     <code class="literal">&#13;
      SECRET&#13;
     </code>&#13;
     <span class="No-Break">&#13;
      and&#13;
     </span>&#13;
     <span class="No-Break">&#13;
      <code class="literal">&#13;
       RESTRICTED&#13;
      </code>&#13;
     </span>&#13;
     <span class="No-Break">&#13;
      .&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     Several parameters&#13;
     <a id="_idIndexMarker652">&#13;
     </a>&#13;
     can be customized with this postprocessor. The most important ones are&#13;
     <span class="No-Break">&#13;
      as follows:&#13;
     </span>&#13;
    </p>&#13;
    <ul>&#13;
     <li>&#13;
      <code class="literal">&#13;
       required_keywords&#13;
      </code>&#13;
      : This is a list of strings, where each string represents a keyword&#13;
      <a id="_idIndexMarker653">&#13;
      </a>&#13;
      that must be present in the node for it to be included in the final output. If this list is not empty, the postprocessor will filter out any nodes that do not contain&#13;
      <span class="No-Break">&#13;
       these keywords.&#13;
      </span>&#13;
     </li>&#13;
     <li>&#13;
      <code class="literal">&#13;
       exclude_keywords&#13;
      </code>&#13;
      : Similar to&#13;
      <code class="literal">&#13;
       required_keywords&#13;
      </code>&#13;
      , this is also a list of strings. However, in this case, any node containing a keyword from this list will be excluded&#13;
      <a id="_idIndexMarker654">&#13;
      </a>&#13;
      from the final output. It’s used for filtering out nodes based on&#13;
      <span class="No-Break">&#13;
       unwanted content.&#13;
      </span>&#13;
     </li>&#13;
     <li>&#13;
      <code class="literal">&#13;
       lang&#13;
      </code>&#13;
      : This argument&#13;
      <a id="_idIndexMarker655">&#13;
      </a>&#13;
      specifies the language model to be used by the internal spaCy NLP library. The default value is&#13;
      <em class="italic">&#13;
       en&#13;
      </em>&#13;
      for English, but it can be set to other language codes supported by Spacy. The effectiveness and accuracy of keyword matching might depend on the language-specific processing of the text. For example, the way words are tokenized by Spacy can affect how keywords&#13;
      <span class="No-Break">&#13;
       are identified.&#13;
      </span>&#13;
     </li>&#13;
    </ul>&#13;
    <p>&#13;
     Keep in mind that keywords – both required and excluded – are processed in a case-sensitive way. To ensure consistent behavior regardless of case, you might consider converting both the keywords and the text in the nodes into the same case (for example, all lowercase)&#13;
     <span class="No-Break">&#13;
      before processing.&#13;
     </span>&#13;
    </p>&#13;
    <a id="_idTextAnchor162">&#13;
    </a>&#13;
    <h2 id="_idParaDest-163">&#13;
     PrevNextNodePostprocessor&#13;
    </h2>&#13;
    <p>&#13;
     <code class="literal">&#13;
      PrevNextNodePostprocessor&#13;
     </code>&#13;
     is designed to enhance node retrieval by fetching additional&#13;
     <a id="_idIndexMarker656">&#13;
     </a>&#13;
     nodes based on their relational context in the document. This postprocessor can operate in three modes –&#13;
     <code class="literal">&#13;
      previous&#13;
     </code>&#13;
     ,&#13;
     <code class="literal">&#13;
      next&#13;
     </code>&#13;
     , or&#13;
     <code class="literal">&#13;
      both&#13;
     </code>&#13;
     – allowing users to retrieve nodes that are either preceding, succeeding, or both concerning the current set&#13;
     <span class="No-Break">&#13;
      of nodes.&#13;
     </span>&#13;
    </p>&#13;
    <p class="callout-heading">&#13;
     A potential use cases&#13;
    </p>&#13;
    <p class="callout">&#13;
     Consider a legal research scenario where a user queries a RAG system about a specific legal case.&#13;
     <code class="literal">&#13;
      PrevNextNodePostprocessor&#13;
     </code>&#13;
     can be set in&#13;
     <em class="italic">&#13;
      both&#13;
     </em>&#13;
     modes to retrieve not only the nodes directly related to the case but also the preceding and succeeding nodes that might contain vital contextual information, such as related legal precedents or subsequent rulings. This ensures a comprehensive understanding of the case by providing a broader context, which is especially crucial in legal research where every&#13;
     <span class="No-Break">&#13;
      detail matters.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     The process begins by taking a list of nodes, typically fetched by a retriever. It then extends this&#13;
     <a id="_idIndexMarker657">&#13;
     </a>&#13;
     list by adding nodes that are directly preceding, succeeding, or both, based on the configured mode. This results in a more contextually enriched set of nodes, leading to responses that are more nuanced and comprehensive&#13;
     <a id="_idIndexMarker658">&#13;
     </a>&#13;
     in a RAG system. Here’s a list of the parameters for&#13;
     <span class="No-Break">&#13;
      this postprocessor:&#13;
     </span>&#13;
    </p>&#13;
    <ul>&#13;
     <li>&#13;
      <code class="literal">&#13;
       docstore&#13;
      </code>&#13;
      : The actual document store storing&#13;
      <span class="No-Break">&#13;
       the nodes.&#13;
      </span>&#13;
     </li>&#13;
     <li>&#13;
      <code class="literal">&#13;
       num_nodes&#13;
      </code>&#13;
      : This sets the number of nodes to return. By default, it returns 1 node in the&#13;
      <span class="No-Break">&#13;
       chosen direction.&#13;
      </span>&#13;
     </li>&#13;
     <li>&#13;
      <code class="literal">&#13;
       mode&#13;
      </code>&#13;
      : Can be set to previous, next,&#13;
      <span class="No-Break">&#13;
       or both.&#13;
      </span>&#13;
     </li>&#13;
    </ul>&#13;
    <p>&#13;
     Additionally, we have&#13;
     <code class="literal">&#13;
      AutoPrevNextNodePostprocessor&#13;
     </code>&#13;
     , which is an advanced variation of&#13;
     <code class="literal">&#13;
      PrevNextNodePostprocessor&#13;
     </code>&#13;
     . This one is intelligently inferring whether to fetch additional nodes based on the&#13;
     <em class="italic">&#13;
      previous&#13;
     </em>&#13;
     ,&#13;
     <em class="italic">&#13;
      next&#13;
     </em>&#13;
     , or neither relationship in response to the&#13;
     <span class="No-Break">&#13;
      query context.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     In comparison to&#13;
     <code class="literal">&#13;
      PrevNextNodePostprocessor&#13;
     </code>&#13;
     , which requires manual setting for mode selection,&#13;
     <code class="literal">&#13;
      AutoPrevNextNodePostprocessor&#13;
     </code>&#13;
     automates this process. It utilizes specific prompts to infer the direction (previous, next, or none) based on the current context and&#13;
     <span class="No-Break">&#13;
      the query.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     This inference is particularly useful in scenarios where the direction of node retrieval isn’t explicitly clear or when it needs to be dynamically determined based on the nature of the query and existing answers. For example, in a scenario where a RAG system is used for historical research,&#13;
     <code class="literal">&#13;
      AutoPrevNextNodePostprocessor&#13;
     </code>&#13;
     can automatically determine whether to fetch preceding or succeeding historical events or data points based on the query’s context, enhancing the relevance and comprehensiveness of&#13;
     <span class="No-Break">&#13;
      the response.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     This capability makes it useful in applications where the sequence of information and its contextual&#13;
     <a id="_idIndexMarker659">&#13;
     </a>&#13;
     relevance are essential for generating accurate and&#13;
     <span class="No-Break">&#13;
      useful responses.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     The prompts can be customized using the&#13;
     <code class="literal">&#13;
      infer_prev_next_tmpl&#13;
     </code>&#13;
     and&#13;
     <code class="literal">&#13;
      refine_prev_next_tmpl&#13;
     </code>&#13;
     arguments. There’s also a&#13;
     <code class="literal">&#13;
      Verbose&#13;
     </code>&#13;
     argument, which provides more visibility on the&#13;
     <span class="No-Break">&#13;
      selection process.&#13;
     </span>&#13;
    </p>&#13;
    <a id="_idTextAnchor163">&#13;
    </a>&#13;
    <h2 id="_idParaDest-164">&#13;
     LongContextReorder&#13;
    </h2>&#13;
    <p>&#13;
     <code class="literal">&#13;
      LongContextReorder&#13;
     </code>&#13;
     is specifically designed to improve the performance of LLMs in handling&#13;
     <a id="_idIndexMarker660">&#13;
     </a>&#13;
     long context scenarios. Research has shown that significant details in extended contexts are better utilized when positioned at the start or end of the input context&#13;
     <em class="italic">&#13;
      (Liu et al., Lost in the Middle: How Language Models Use Long Contexts (2023)&#13;
     </em>&#13;
     –&#13;
     <a>&#13;
      https://arxiv.org/abs/2307.03172&#13;
     </a>&#13;
     ). The&#13;
     <code class="literal">&#13;
      LongContextReorder&#13;
     </code>&#13;
     postprocessor addresses this by reordering the nodes, placing crucial information where it’s more accessible to&#13;
     <span class="No-Break">&#13;
      the model.&#13;
     </span>&#13;
    </p>&#13;
    <p class="callout-heading">&#13;
     A practical scenario&#13;
    </p>&#13;
    <p class="callout">&#13;
     In a RAG system, particularly in academic or research-oriented queries where long, detailed documents are common,&#13;
     <code class="literal">&#13;
      LongContextReorder&#13;
     </code>&#13;
     can be very useful. For instance, if a user queries about detailed historical events, the system might retrieve lengthy nodes encompassing extensive details.&#13;
     <code class="literal">&#13;
      LongContextReorder&#13;
     </code>&#13;
     would rearrange these nodes, ensuring that the most relevant details are positioned at the beginning or end, thereby enhancing the model’s ability to extract and utilize this crucial information effectively. This results in responses that are more coherent and contextually rich, significantly improving the overall quality of the output in cases involving&#13;
     <span class="No-Break">&#13;
      lengthy contexts.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     <code class="literal">&#13;
      LongContextReorder&#13;
     </code>&#13;
     takes a list of nodes, typically fetched by a retriever, and reorders them based on their relevance scores. The goal is to optimize the arrangement of information in a way that maximizes the language model’s ability to access and process significant details, especially in cases where the context length might otherwise&#13;
     <span class="No-Break">&#13;
      hinder performance.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     This postprocessor is particularly effective in scenarios where detailed and comprehensive responses are required, ensuring that the most relevant information is presented in a way that is most accessible to&#13;
     <span class="No-Break">&#13;
      the model.&#13;
     </span>&#13;
    </p>&#13;
    <a id="_idTextAnchor164">&#13;
    </a>&#13;
    <h2 id="_idParaDest-165">&#13;
     PIINodePostprocessor and NERPIINodePostprocessor&#13;
    </h2>&#13;
    <p>&#13;
     These&#13;
     <a id="_idIndexMarker661">&#13;
     </a>&#13;
     postprocessors mask&#13;
     <strong class="bold">&#13;
      personally identifiable information&#13;
     </strong>&#13;
     (&#13;
     <strong class="bold">&#13;
      PII&#13;
     </strong>&#13;
     ) in nodes, improving privacy and security.&#13;
     <code class="literal">&#13;
      PIINodePostprocessor&#13;
     </code>&#13;
     is designed to use a local model, while&#13;
     <code class="literal">&#13;
      NERPIINodePostprocessor&#13;
     </code>&#13;
     relies on a NER model from Hugging Face. We saw an example of&#13;
     <a id="_idIndexMarker662">&#13;
     </a>&#13;
     how this postprocessor works in&#13;
     <a>&#13;
      <span class="No-Break">&#13;
       <em class="italic">&#13;
        Chapter 4&#13;
       </em>&#13;
      </span>&#13;
     </a>&#13;
     ,&#13;
     <em class="italic">&#13;
      Ingesting Data into Our RAG Workflow&#13;
     </em>&#13;
     , in the&#13;
     <em class="italic">&#13;
      Scrubbing personal data and other sensitive&#13;
     </em>&#13;
     <span class="No-Break">&#13;
      <em class="italic">&#13;
       information&#13;
      </em>&#13;
     </span>&#13;
     <span class="No-Break">&#13;
      section.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     <code class="literal">&#13;
      PIINodePostprocessor&#13;
     </code>&#13;
     takes&#13;
     <a id="_idIndexMarker663">&#13;
     </a>&#13;
     the&#13;
     <span class="No-Break">&#13;
      following arguments:&#13;
     </span>&#13;
    </p>&#13;
    <ul>&#13;
     <li>&#13;
      <code class="literal">&#13;
       llm&#13;
      </code>&#13;
      : This object should contain a local model&#13;
      <span class="No-Break">&#13;
       for processing.&#13;
      </span>&#13;
     </li>&#13;
     <li>&#13;
      <code class="literal">&#13;
       pii_str_tmpl&#13;
      </code>&#13;
      : This can be used to customize the default prompt template used for masking&#13;
      <span class="No-Break">&#13;
       personal data.&#13;
      </span>&#13;
     </li>&#13;
     <li>&#13;
      <code class="literal">&#13;
       pii_node_info_key&#13;
      </code>&#13;
      : This string serves as a key in the node’s metadata to store information related to PII processing. It’s used to track and reference the PII data processed within each node. It can be used to later recompose the original information&#13;
      <span class="No-Break">&#13;
       if required.&#13;
      </span>&#13;
     </li>&#13;
    </ul>&#13;
    <p>&#13;
     <code class="literal">&#13;
      NERPIINodePostprocessor&#13;
     </code>&#13;
     can be configured with the&#13;
     <code class="literal">&#13;
      pii_node_info_key&#13;
     </code>&#13;
     parameter. Similar to&#13;
     <a id="_idIndexMarker664">&#13;
     </a>&#13;
     the previous postprocessor, this string key is used to store information related to PII processing in the node’s metadata. It’s a unique identifier within the node metadata for tracking the PII data that has&#13;
     <span class="No-Break">&#13;
      been processed.&#13;
     </span>&#13;
    </p>&#13;
    <p class="callout-heading">&#13;
     Best practice&#13;
    </p>&#13;
    <p class="callout">&#13;
     As we discussed in&#13;
     <a>&#13;
      <span class="No-Break">&#13;
       <em class="italic">&#13;
        Chapter 4&#13;
       </em>&#13;
      </span>&#13;
     </a>&#13;
     ,&#13;
     <em class="italic">&#13;
      Ingesting Data into Our RAG Workflow&#13;
     </em>&#13;
     , for maximum privacy, the best approach is to apply PII masking before the actual retrieval. This way, you ensure that no sensitive data is sent to any&#13;
     <span class="No-Break">&#13;
      external LLM.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     Let’s see what other postprocessors&#13;
     <span class="No-Break">&#13;
      we have.&#13;
     </span>&#13;
    </p>&#13;
    <a id="_idTextAnchor165">&#13;
    </a>&#13;
    <h2 id="_idParaDest-166">&#13;
     MetadataReplacementPostprocessor&#13;
    </h2>&#13;
    <p>&#13;
     <code class="literal">&#13;
      MetadataReplacementPostProcessor&#13;
     </code>&#13;
     is designed to replace the content of a node&#13;
     <a id="_idIndexMarker665">&#13;
     </a>&#13;
     with a specific field from that node’s metadata. This allows us to dynamically switch the text that’s used to represent a node based on metadata instead of the original&#13;
     <span class="No-Break">&#13;
      ingested content.&#13;
     </span>&#13;
    </p>&#13;
    <p class="callout-heading">&#13;
     A useful application for this postprocessor&#13;
    </p>&#13;
    <p class="callout">&#13;
     Imagine a workflow where files are ingested via&#13;
     <code class="literal">&#13;
      SentenceWindowNodeParser&#13;
     </code>&#13;
     , which splits text into sentence-level nodes and captures the surrounding text in metadata. By configuring the processor to swap the node’s content with the metadata field containing the&#13;
     <em class="italic">&#13;
      sentence window&#13;
     </em>&#13;
     , queries would retrieve full sentence context instead of sentence fragments. This allows the retriever to operate on sentences for higher accuracy while still exposing broader document context to the LLM. This technique can be very useful for processing large documents. You can find a complete example&#13;
     <span class="No-Break">&#13;
      here:&#13;
     </span>&#13;
     <a>&#13;
      <span class="No-Break">&#13;
       https://docs.llamaindex.ai/en/stable/examples/node_postprocessor/MetadataReplacementDemo.html&#13;
      </span>&#13;
     </a>&#13;
     <span class="No-Break">&#13;
      .&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     This postprocessor takes a list of nodes as input and is configured with the&#13;
     <code class="literal">&#13;
      target_metadata_key&#13;
     </code>&#13;
     parameter, specifying which metadata field to use for the replacement.&#13;
     <code class="literal">&#13;
      MetadataReplacementPostProcessor&#13;
     </code>&#13;
     processes the nodes by replacing the&#13;
     <code class="literal">&#13;
      text&#13;
     </code>&#13;
     attribute of each node with the contents of the given metadata key. If the key is missing, the original text is kept. This provides flexibility to transform node content on&#13;
     <span class="No-Break">&#13;
      the fly.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     Here’s another, simple example that will help you understand&#13;
     <span class="No-Break">&#13;
      its functionality:&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     First, we defined two sample nodes on which we’ll now apply the postprocessor. We’ll instruct it&#13;
     <a id="_idIndexMarker666">&#13;
     </a>&#13;
     to replace the content of each node with the values stored in the&#13;
     <code class="literal">&#13;
      summary&#13;
     </code>&#13;
     <span class="No-Break">&#13;
      metadata field:&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     After processing takes place, the output should look&#13;
     <span class="No-Break">&#13;
      like this:&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     Let’s explore the other postprocessing options that&#13;
     <span class="No-Break">&#13;
      LlamaIndex provides.&#13;
     </span>&#13;
    </p>&#13;
    <a id="_idTextAnchor166">&#13;
    </a>&#13;
    <h2 id="_idParaDest-167">&#13;
     SentenceEmbeddingOptimizer&#13;
    </h2>&#13;
    <p>&#13;
     <code class="literal">&#13;
      SentenceEmbeddingOptimizer&#13;
     </code>&#13;
     is built to optimize longer text passages by selecting&#13;
     <a id="_idIndexMarker667">&#13;
     </a>&#13;
     the most relevant sentences given a query based on semantic similarity. It uses advanced NLP techniques to score sentence relevance and discard less&#13;
     <span class="No-Break">&#13;
      useful sentences.&#13;
     </span>&#13;
    </p>&#13;
    <p class="callout-heading">&#13;
     Why and where should we use it?&#13;
    </p>&#13;
    <p class="callout">&#13;
     In a workflow that’s ingesting lengthy documents, retrieving full passages may exceed model context size limits.&#13;
     <code class="literal">&#13;
      SentenceEmbeddingOptimizer&#13;
     </code>&#13;
     allows us to send only the most&#13;
     <a id="_idIndexMarker668">&#13;
     </a>&#13;
     important sentences to the LLM while preserving enough context. This prevents wasted tokens on irrelevant text by reducing noisy content. Removing irrelevant parts of the content also improves the response time and can greatly reduce the cost associated with the final&#13;
     <span class="No-Break">&#13;
      LLM call.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     The postprocessor takes a list of nodes as input and uses embeddings to analyze the semantic similarity of each sentence to the search query. Sentences closest to the query vector are retained while distant, unrelated sentences are&#13;
     <span class="No-Break">&#13;
      stripped away.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     This is how we use it&#13;
     <span class="No-Break">&#13;
      in practice:&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     In this example,&#13;
     <code class="literal">&#13;
      SentenceEmbeddingOptimizer&#13;
     </code>&#13;
     uses a&#13;
     <code class="literal">&#13;
      percentile_cutoff&#13;
     </code>&#13;
     value of 0.8 and a&#13;
     <code class="literal">&#13;
      threshold_cutoff&#13;
     </code>&#13;
     value of&#13;
     <code class="literal">&#13;
      0.7&#13;
     </code>&#13;
     to select sentences. This means it aims to retain the top 80% of sentences by similarity score and further filters to include only those with similarity scores above&#13;
     <code class="literal">&#13;
      0.7&#13;
     </code>&#13;
     . The main parameters that can be customized&#13;
     <a id="_idIndexMarker669">&#13;
     </a>&#13;
     are&#13;
     <span class="No-Break">&#13;
      as follows:&#13;
     </span>&#13;
    </p>&#13;
    <ul>&#13;
     <li>&#13;
      <code class="literal">&#13;
       percentile_cutoff&#13;
      </code>&#13;
      : The percentage of top sentences above the similarity threshold to preserve. This allows us to compact nodes to the most relevant 75% of sentences,&#13;
      <span class="No-Break">&#13;
       for example.&#13;
      </span>&#13;
     </li>&#13;
     <li>&#13;
      <code class="literal">&#13;
       threshold_cutoff&#13;
      </code>&#13;
      : An absolute similarity score threshold where only sentences with similarity above this value are kept. This is useful for more&#13;
      <span class="No-Break">&#13;
       stringent filtering.&#13;
      </span>&#13;
     </li>&#13;
     <li>&#13;
      <code class="literal">&#13;
       context_before&#13;
      </code>&#13;
      and&#13;
      <code class="literal">&#13;
       context_after&#13;
      </code>&#13;
      : These allow us to keep several sentences before and after the matches for&#13;
      <span class="No-Break">&#13;
       more context.&#13;
      </span>&#13;
     </li>&#13;
    </ul>&#13;
    <p>&#13;
     In a similar fashion to&#13;
     <code class="literal">&#13;
      KeywordNodePostprocessor&#13;
     </code>&#13;
     , the&#13;
     <code class="literal">&#13;
      SentenceEmbeddingOptimizer&#13;
     </code>&#13;
     postprocessor removes less relevant sentences from nodes. However, in this case, it does so use vector search rather&#13;
     <span class="No-Break">&#13;
      than keywords.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     This postprocessor&#13;
     <a id="_idIndexMarker670">&#13;
     </a>&#13;
     is more about refining and shortening the content within each node for better alignment with the query. This allows for optimal information density tailored to the query while accounting for the&#13;
     <span class="No-Break">&#13;
      LLM’s limitations.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     In contrast, processors such as&#13;
     <code class="literal">&#13;
      KeywordNodePostprocessor&#13;
     </code>&#13;
     and&#13;
     <code class="literal">&#13;
      SimilarityPostprocessor&#13;
     </code>&#13;
     operate at the node level, keeping or removing entire nodes based on keywords or similarity&#13;
     <span class="No-Break">&#13;
      scores, respectively.&#13;
     </span>&#13;
    </p>&#13;
    <a id="_idTextAnchor167">&#13;
    </a>&#13;
    <h2 id="_idParaDest-168">&#13;
     Time-based postprocessors&#13;
    </h2>&#13;
    <p>&#13;
     <strong class="bold">&#13;
      Time-based postprocessors&#13;
     </strong>&#13;
     are designed to prioritize recency and provide users with the&#13;
     <a id="_idIndexMarker671">&#13;
     </a>&#13;
     latest, most up-to-date information. They achieve this goal through various techniques, such as sorting nodes by&#13;
     <code class="literal">&#13;
      date&#13;
     </code>&#13;
     metadata, filtering based on embedding similarity, or applying time-decay&#13;
     <span class="No-Break">&#13;
      scoring models.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     Let’s get an overview of&#13;
     <span class="No-Break">&#13;
      these processors.&#13;
     </span>&#13;
    </p>&#13;
    <h3>&#13;
     FixedRecencyPostprocessor&#13;
    </h3>&#13;
    <p>&#13;
     This simple postprocessor focuses results on the most recent data by sorting nodes based on their&#13;
     <code class="literal">&#13;
      date&#13;
     </code>&#13;
     metadata and then returning the&#13;
     <code class="literal">&#13;
      top_k&#13;
     </code>&#13;
     nodes sorted by date. This ensures&#13;
     <a id="_idIndexMarker672">&#13;
     </a>&#13;
     we get the latest data, which is critical for applications such as environmental monitoring, where having current&#13;
     <a id="_idIndexMarker673">&#13;
     </a>&#13;
     information is vital. For example, when querying about recent air quality metrics, the postprocessor guarantees that only the most up-to-date readings are provided. They focus the results on the&#13;
     <span class="No-Break">&#13;
      latest information.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     The two configurable parameters for this processor are&#13;
     <span class="No-Break">&#13;
      as follows:&#13;
     </span>&#13;
    </p>&#13;
    <ul>&#13;
     <li>&#13;
      <code class="literal">&#13;
       top_k&#13;
      </code>&#13;
      : The number of top recent nodes&#13;
      <span class="No-Break">&#13;
       to return&#13;
      </span>&#13;
     </li>&#13;
     <li>&#13;
      <code class="literal">&#13;
       date_key&#13;
      </code>&#13;
      : The metadata key that’s used to identify the date in&#13;
      <span class="No-Break">&#13;
       each node&#13;
      </span>&#13;
     </li>&#13;
    </ul>&#13;
    <h3>&#13;
     EmbeddingRecencyPostprocessor&#13;
    </h3>&#13;
    <p>&#13;
     This postprocessor further refines recency-sorted results by comparing node contents using embedding similarity and removing those too similar to earlier nodes. Nodes that are too&#13;
     <a id="_idIndexMarker674">&#13;
     </a>&#13;
     similar to earlier ones are filtered out, ensuring that the content is both recent and diverse. The output it&#13;
     <a id="_idIndexMarker675">&#13;
     </a>&#13;
     produces is not just recent but also diverse in terms of the information&#13;
     <span class="No-Break">&#13;
      it contains.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     <code class="literal">&#13;
      EmbeddingRecencyPostprocessor&#13;
     </code>&#13;
     sorts the nodes by date using the specified&#13;
     <code class="literal">&#13;
      date_key&#13;
     </code>&#13;
     metadata field. Then, it generates a query embedding for each node by inserting the node’s content into the&#13;
     <code class="literal">&#13;
      query_embedding_tmpl&#13;
     </code>&#13;
     template. This query embedding is used to find&#13;
     <span class="No-Break">&#13;
      similar documents.&#13;
     </span>&#13;
    </p>&#13;
    <p class="callout-heading">&#13;
     Where could that be useful?&#13;
    </p>&#13;
    <p class="callout">&#13;
     Let’s think, for example, about a news aggregation service. When users query about a recent event, the system retrieves a set of nodes (news articles, in this case) sorted by date. However, many articles might cover the same event, leading to redundant information.&#13;
     <code class="literal">&#13;
      EmbeddingRecencyPostprocessor&#13;
     </code>&#13;
     examines these articles and filters out those that are too similar in content to more recent articles. This prevents us from presenting multiple redundant articles about the same event by eliminating those whose content significantly overlaps with more&#13;
     <span class="No-Break">&#13;
      recent coverage.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     Its&#13;
     <a id="_idIndexMarker676">&#13;
     </a>&#13;
     configurable parameters are&#13;
     <span class="No-Break">&#13;
      as follows:&#13;
     </span>&#13;
    </p>&#13;
    <ul>&#13;
     <li>&#13;
      <code class="literal">&#13;
       similarity_cutoff&#13;
      </code>&#13;
      : The threshold for embedding similarity, above which nodes are considered too similar and&#13;
      <span class="No-Break">&#13;
       filtered out&#13;
      </span>&#13;
     </li>&#13;
     <li>&#13;
      <code class="literal">&#13;
       date_key&#13;
      </code>&#13;
      : This specifies the metadata key that’s used for sorting nodes&#13;
      <span class="No-Break">&#13;
       by date&#13;
      </span>&#13;
     </li>&#13;
     <li>&#13;
      <code class="literal">&#13;
       query_embedding_tmpl&#13;
      </code>&#13;
      : This is the template that’s used to generate query embeddings for&#13;
      <span class="No-Break">&#13;
       each node&#13;
      </span>&#13;
     </li>&#13;
    </ul>&#13;
    <h3>&#13;
     TimeWeightedPostprocessor&#13;
    </h3>&#13;
    <p>&#13;
     <code class="literal">&#13;
      TimeWeightedPostprocessor&#13;
     </code>&#13;
     prioritizes newer results by reranking nodes based on a&#13;
     <strong class="bold">&#13;
      time-decay function&#13;
     </strong>&#13;
     accounting&#13;
     <a id="_idIndexMarker677">&#13;
     </a>&#13;
     for how recently they were accessed. This favors fresh, less repeated content, which is critical for use cases such as trending news aggregation, where users want the latest updates rather than the&#13;
     <span class="No-Break">&#13;
      same information.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     The scoring dynamically adapts to changing access patterns over time.&#13;
     <code class="literal">&#13;
      TimeWeightedPostprocessor&#13;
     </code>&#13;
     is engineered to re-rank nodes based on their recency and&#13;
     <a id="_idIndexMarker678">&#13;
     </a>&#13;
     prior access history, applying a time-weighted scoring system. This postprocessor is particularly effective in scenarios where it’s crucial to&#13;
     <a id="_idIndexMarker679">&#13;
     </a>&#13;
     avoid repeatedly presenting the same information and where the freshness of&#13;
     <span class="No-Break">&#13;
      content matters.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     It works by adjusting the score of each node based on the last time it was accessed, applying a decay factor to prioritize less recently accessed content. This dynamic reranking ensures that the output is not just relevant but also timely and varied. This works great for applications where keeping the users updated with the most recent information&#13;
     <span class="No-Break">&#13;
      is essential.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     It also&#13;
     <a id="_idIndexMarker680">&#13;
     </a>&#13;
     has several parameters that we&#13;
     <span class="No-Break">&#13;
      can tweak:&#13;
     </span>&#13;
    </p>&#13;
    <ul>&#13;
     <li>&#13;
      <code class="literal">&#13;
       time_decay&#13;
      </code>&#13;
      : The decay factor for the&#13;
      <span class="No-Break">&#13;
       time-weighted scoring&#13;
      </span>&#13;
     </li>&#13;
     <li>&#13;
      <code class="literal">&#13;
       last_accessed_key&#13;
      </code>&#13;
      : Metadata key for tracking when a node was&#13;
      <span class="No-Break">&#13;
       last accessed&#13;
      </span>&#13;
     </li>&#13;
     <li>&#13;
      <code class="literal">&#13;
       time_access_refresh&#13;
      </code>&#13;
      : A Boolean to determine if the last accessed time should&#13;
      <span class="No-Break">&#13;
       be updated&#13;
      </span>&#13;
     </li>&#13;
     <li>&#13;
      <code class="literal">&#13;
       now&#13;
      </code>&#13;
      : An optional&#13;
      <a id="_idIndexMarker681">&#13;
      </a>&#13;
      parameter to set the current time. This is useful&#13;
      <span class="No-Break">&#13;
       for testing&#13;
      </span>&#13;
     </li>&#13;
     <li>&#13;
      <code class="literal">&#13;
       top_k&#13;
      </code>&#13;
      : The number of top nodes to return after reranking. The default value&#13;
      <span class="No-Break">&#13;
       is 1&#13;
      </span>&#13;
     </li>&#13;
    </ul>&#13;
    <p>&#13;
     With these advanced time-aware postprocessors, our RAG system transforms into a dynamic information curator, adept at navigating the temporal aspects of data. They ensure&#13;
     <a id="_idIndexMarker682">&#13;
     </a>&#13;
     that our system doesn’t just retrieve information&#13;
     <a id="_idIndexMarker683">&#13;
     </a>&#13;
     but smartly selects content that’s not only recent but also varied&#13;
     <span class="No-Break">&#13;
      and relevant.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     This makes them indispensable for scenarios where timely and diverse information is crucial, offering us a consistently fresh and&#13;
     <span class="No-Break">&#13;
      rich experience.&#13;
     </span>&#13;
    </p>&#13;
    <a id="_idTextAnchor168">&#13;
    </a>&#13;
    <h2 id="_idParaDest-169">&#13;
     Re-ranking postprocessors&#13;
    </h2>&#13;
    <p>&#13;
     Along with the basic processors we’ve discussed so far, LlamaIndex provides several more sophisticated options that make use of LLMs or embedding models for re-ranking nodes. As a&#13;
     <a id="_idIndexMarker684">&#13;
     </a>&#13;
     general principle, they work by re-ordering the nodes based on their relevance to the query, rather than removing them or altering their content. Some of these postprocessors, such as&#13;
     <code class="literal">&#13;
      SentenceTransformerRerank&#13;
     </code>&#13;
     , also update the relevance scores of the nodes to reflect their similarity to&#13;
     <span class="No-Break">&#13;
      the query.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     They all accept a&#13;
     <code class="literal">&#13;
      top_n&#13;
     </code>&#13;
     parameter, which specifies how many re-ordered nodes they should return. You can explore them in full detail by consulting the official&#13;
     <span class="No-Break">&#13;
      docs:&#13;
     </span>&#13;
     <a>&#13;
      <span class="No-Break">&#13;
       https://docs.llamaindex.ai/en/stable/module_guides/querying/node_postprocessors/&#13;
      </span>&#13;
     </a>&#13;
     <span class="No-Break">&#13;
      .&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     This section provides a quick overview of the available&#13;
     <span class="No-Break">&#13;
      LLM-based processors.&#13;
     </span>&#13;
    </p>&#13;
    <h3>&#13;
     LLMRerank&#13;
    </h3>&#13;
    <p>&#13;
     This processor re-orders nodes by asking an LLM to assign relevance scores. It selects the&#13;
     <code class="literal">&#13;
      top_n&#13;
     </code>&#13;
     most relevant nodes from a given set based on the user’s query. The prompt that’s used by this postprocessor can be customized via the&#13;
     <span class="No-Break">&#13;
      <code class="literal">&#13;
       choice_select_prompt&#13;
      </code>&#13;
     </span>&#13;
     <span class="No-Break">&#13;
      parameter.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     To increase&#13;
     <a id="_idIndexMarker685">&#13;
     </a>&#13;
     efficiency, it works in batches. The batch&#13;
     <a id="_idIndexMarker686">&#13;
     </a>&#13;
     size can also be customized by using the&#13;
     <code class="literal">&#13;
      choice_batch_size&#13;
     </code>&#13;
     argument. It requires a&#13;
     <code class="literal">&#13;
      query_bundle&#13;
     </code>&#13;
     argument for processing and uses the model configured in&#13;
     <code class="literal">&#13;
      llm&#13;
     </code>&#13;
     . Its reranking process involves formatting node contents into prompts, using the LLM to assess relevance, and then reordering nodes based on their calculated&#13;
     <span class="No-Break">&#13;
      relevance scores.&#13;
     </span>&#13;
    </p>&#13;
    <h3>&#13;
     CohereRerank&#13;
    </h3>&#13;
    <p>&#13;
     This&#13;
     <a id="_idIndexMarker687">&#13;
     </a>&#13;
     processor re-ranks nodes using Cohere’s neural models (&#13;
     <a>&#13;
      https://cohere.com/rerank&#13;
     </a>&#13;
     ) to sort&#13;
     <a id="_idIndexMarker688">&#13;
     </a>&#13;
     nodes by relevance. The default model that’s used is&#13;
     <em class="italic">&#13;
      rerank-english-v2.0&#13;
     </em>&#13;
     . The&#13;
     <code class="literal">&#13;
      top_n&#13;
     </code>&#13;
     nodes deemed&#13;
     <a id="_idIndexMarker689">&#13;
     </a>&#13;
     most relevant by the Cohere model are selected&#13;
     <span class="No-Break">&#13;
      and returned.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     This processor allows us to leverage powerful relevance algorithms provided by Cohere but requires a Cohere API key and their libraries to be installed in the&#13;
     <span class="No-Break">&#13;
      local environment.&#13;
     </span>&#13;
    </p>&#13;
    <h3>&#13;
     SentenceTransformerRerank&#13;
    </h3>&#13;
    <p>&#13;
     <code class="literal">&#13;
      SentenceTransformerRerank&#13;
     </code>&#13;
     uses sentence transformer models to re-rank nodes based&#13;
     <a id="_idIndexMarker690">&#13;
     </a>&#13;
     on their relevance to a&#13;
     <span class="No-Break">&#13;
      given query.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     This process&#13;
     <a id="_idIndexMarker691">&#13;
     </a>&#13;
     involves scoring nodes using a sentence transformer model, with the default being&#13;
     <em class="italic">&#13;
      cross-encoder/stsb-distilroberta-base&#13;
     </em>&#13;
     , and then reordering them based on these scores. It selects the top-ranked nodes to return, up to the specified&#13;
     <code class="literal">&#13;
      top_n&#13;
     </code>&#13;
     limit. You can find more information&#13;
     <span class="No-Break">&#13;
      here:&#13;
     </span>&#13;
     <span class="No-Break">&#13;
      <span class="P---URL">&#13;
      </span>&#13;
     </span>&#13;
     <a>&#13;
      <span class="No-Break">&#13;
       https://www.sbert.net/examples/applications/retrieve_rerank/README.html&#13;
      </span>&#13;
     </a>&#13;
     <span class="No-Break">&#13;
      .&#13;
     </span>&#13;
    </p>&#13;
    <h3>&#13;
     RankGPTRerank&#13;
    </h3>&#13;
    <p>&#13;
     This re-ranking&#13;
     <a id="_idIndexMarker692">&#13;
     </a>&#13;
     postprocessor is designed to&#13;
     <a id="_idIndexMarker693">&#13;
     </a>&#13;
     improve retrieval results relevance using an LLM such as GPT-3.5. It involves a process where the user’s query and content from nodes are formatted into prompts, guiding the language model to rank these nodes based&#13;
     <span class="No-Break">&#13;
      on relevance.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     The model’s output is then used to re-order the nodes, ensuring that the most relevant ones appear&#13;
     <a id="_idIndexMarker694">&#13;
     </a>&#13;
     at the top. When the context that’s retrieved is too large for the LLM’s context window,&#13;
     <code class="literal">&#13;
      RankGPTRerank&#13;
     </code>&#13;
     uses a sliding window approach to gradually re-rank a segment&#13;
     <span class="No-Break">&#13;
      of chunks.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     This method&#13;
     <a id="_idIndexMarker695">&#13;
     </a>&#13;
     is based on a paper by Sun et al. (2023),&#13;
     <em class="italic">&#13;
      Is ChatGPT Good at Search? Investigating Large Language Models as Re-Ranking&#13;
     </em>&#13;
     <span class="No-Break">&#13;
      <em class="italic">&#13;
       Agents&#13;
      </em>&#13;
     </span>&#13;
     <span class="No-Break">&#13;
      (&#13;
     </span>&#13;
     <a>&#13;
      <span class="No-Break">&#13;
       https://arxiv.org/abs/2304.09542v2&#13;
      </span>&#13;
     </a>&#13;
     <span class="No-Break">&#13;
      ).&#13;
     </span>&#13;
    </p>&#13;
    <h3>&#13;
     LongLLMLinguaPostprocessor&#13;
    </h3>&#13;
    <p>&#13;
     This very useful postprocessor is designed to optimize node texts concerning queries by compressing them. It’s based on a method described in a paper by Jiang et al. (2023),&#13;
     <em class="italic">&#13;
      LLMLingua: Compressing Prompts for Accelerated Inference of Large Language&#13;
     </em>&#13;
     <span class="No-Break">&#13;
      <em class="italic">&#13;
       Models&#13;
      </em>&#13;
     </span>&#13;
     <span class="No-Break">&#13;
      (&#13;
     </span>&#13;
     <a>&#13;
      <span class="No-Break">&#13;
       https://arxiv.org/abs/2310.05736v2&#13;
      </span>&#13;
     </a>&#13;
     <span class="No-Break">&#13;
      ).&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     <code class="literal">&#13;
      LongLLMLinguaPostprocessor&#13;
     </code>&#13;
     addresses several issues associated with LLMs, such as increased API latency, context window limit overruns, and expensive&#13;
     <span class="No-Break">&#13;
      API costs.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     The key idea&#13;
     <a id="_idIndexMarker696">&#13;
     </a>&#13;
     is to intelligently&#13;
     <a id="_idIndexMarker697">&#13;
     </a>&#13;
     compress prompts in a way that they focus on the most relevant information, enabling more efficient and accurate processing by the LLM. It offers a balance between performance and efficiency, demonstrating that prompt compression – with up to 20x achievements – can lead to substantial improvements in model inference and cost-effectiveness without considerable loss&#13;
     <span class="No-Break">&#13;
      in performance.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     The processor is designed to work with a local, well-trained language model. This setup allows for the efficient compression of prompts for use with LLMs, supporting the optimization process locally without relying on external&#13;
     <span class="No-Break">&#13;
      API calls.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     You can find a complete demo&#13;
     <span class="No-Break">&#13;
      here:&#13;
     </span>&#13;
     <a>&#13;
      <span class="No-Break">&#13;
       https://github.com/microsoft/LLMLingua/blob/main/examples/RAGLlamaIndex.ipynb&#13;
      </span>&#13;
     </a>&#13;
     <span class="No-Break">&#13;
      .&#13;
     </span>&#13;
    </p>&#13;
    <h3>&#13;
     Measuring the effectiveness of LLM-based re-ranking&#13;
    </h3>&#13;
    <p>&#13;
     A common source of concern – especially when using LLM-based re-rankers – is the quality of their output. Because LLMs are trained on vast amounts of data, they can sometimes generate results that are biased, inconsistent, or even factually incorrect. This is&#13;
     <a id="_idIndexMarker698">&#13;
     </a>&#13;
     particularly problematic when dealing with specialized domains or sensitive information. To verify that the LLM-based postprocessors are re-ranking the nodes well enough, it is important to properly evaluate their performance. Here are a few approaches you can use to gauge the quality of the&#13;
     <span class="No-Break">&#13;
      re-ranking step:&#13;
     </span>&#13;
    </p>&#13;
    <ul>&#13;
     <li>&#13;
      <strong class="bold">&#13;
       Manual relevance assessment&#13;
      </strong>&#13;
      : Manually examine the re-ranked results to check if the most relevant nodes are indeed appearing at the top. This qualitative evaluation depends on human judgment to determine if the re-ranking matches the query’s intent. While not exactly very scientific, this simple approach may suffice for simple use cases, experiments, or non-production&#13;
      <span class="No-Break">&#13;
       RAG applications.&#13;
      </span>&#13;
     </li>&#13;
     <li>&#13;
      <strong class="bold">&#13;
       Benchmark datasets&#13;
      </strong>&#13;
      : Evaluate the re-ranking performance on standard&#13;
      <strong class="bold">&#13;
       information retrieval&#13;
      </strong>&#13;
      (&#13;
      <strong class="bold">&#13;
       IR&#13;
      </strong>&#13;
      ) benchmarks&#13;
      <a id="_idIndexMarker699">&#13;
      </a>&#13;
      that have pre-defined queries and relevance judgments. This process can be time-consuming and it may require a well-prepared evaluation dataset but it will save you from troubles later in the RAG workflow. By comparing the re-ranked results against the ground truth, you can calculate metrics such as precision, recall, and others to quantify the re-ranking quality. We’ll cover the evaluation process in more detail in&#13;
      <a>&#13;
       <span class="No-Break">&#13;
        <em class="italic">&#13;
         Chapter 9&#13;
        </em>&#13;
       </span>&#13;
      </a>&#13;
      ,&#13;
      <em class="italic">&#13;
       Customizing and Deploying Our&#13;
      </em>&#13;
      <span class="No-Break">&#13;
       <em class="italic">&#13;
        LlamaIndex Project.&#13;
       </em>&#13;
      </span>&#13;
     </li>&#13;
     <li>&#13;
      <strong class="bold">&#13;
       User feedback&#13;
      </strong>&#13;
      : In real-world applications, collect user feedback on the re-ranked search results. User satisfaction scores, click-through rates, or other engagement metrics can indicate if the re-ranking enhances the user experience and provides more relevant results. There’s an inherent advantage to this method. Because it relies on human feedback directly collected in the live environment, it becomes&#13;
      <a id="_idIndexMarker700">&#13;
      </a>&#13;
      a form of&#13;
      <strong class="bold">&#13;
       continuous evaluation&#13;
      </strong>&#13;
      . This makes it useful in&#13;
      <a id="_idIndexMarker701">&#13;
      </a>&#13;
      detecting any potential&#13;
      <strong class="bold">&#13;
       model drift&#13;
      </strong>&#13;
      , thus enabling timely adjustments to our pipeline to help us avoid quality degradation&#13;
      <span class="No-Break">&#13;
       over time.&#13;
      </span>&#13;
     </li>&#13;
     <li>&#13;
      <strong class="bold">&#13;
       A/B testing&#13;
      </strong>&#13;
      : Another form of gathering user feedback would be by running controlled experiments where some users are shown the original ranking, while others see the LLM-based re-ranked results. Compare the performance metrics between the two groups to assess if the re-ranking leads to&#13;
      <span class="No-Break">&#13;
       improved outcomes.&#13;
      </span>&#13;
     </li>&#13;
     <li>&#13;
      <strong class="bold">&#13;
       Domain expert evaluation&#13;
      </strong>&#13;
      : For specialized domains, ask subject matter experts to review the re-ranked results and provide feedback on their relevance and quality. While&#13;
      <a id="_idIndexMarker702">&#13;
      </a>&#13;
      more expensive and difficult than the other options, this method could be the best solution when dealing with highly technical or niche topics that require a deep understanding of the&#13;
      <span class="No-Break">&#13;
       subject matter.&#13;
      </span>&#13;
     </li>&#13;
    </ul>&#13;
    <p>&#13;
     The evaluation method you choose will depend on your specific use case, available resources, and the level of rigor you need. Using a mix of qualitative and quantitative approaches can give you a thorough assessment of the LLM’s&#13;
     <span class="No-Break">&#13;
      re-ranking performance.&#13;
     </span>&#13;
    </p>&#13;
    <h3>&#13;
     Understanding the model drift phenomenon&#13;
    </h3>&#13;
    <p>&#13;
     While not necessarily specific to re-ranking, model drift can significantly impact the quality of&#13;
     <a id="_idIndexMarker703">&#13;
     </a>&#13;
     our RAG pipelines and it’s an important factor to consider. Our models are static representations of the snapshot datasets that are used for their training. But in time, that data changes. For example, new concepts may emerge that were not included in the training data, or the data itself may shift in distribution. This phenomenon is known as&#13;
     <em class="italic">&#13;
      model drift&#13;
     </em>&#13;
     , and it can manifest in&#13;
     <span class="No-Break">&#13;
      multiple forms:&#13;
     </span>&#13;
    </p>&#13;
    <ul>&#13;
     <li>&#13;
      <strong class="bold">&#13;
       Data drift&#13;
      </strong>&#13;
      : This occurs when the statistical properties or distribution of the input data&#13;
      <a id="_idIndexMarker704">&#13;
      </a>&#13;
      change over time. For instance, if a model&#13;
      <a id="_idIndexMarker705">&#13;
      </a>&#13;
      was trained on a dataset of customer reviews from a specific period, it may not perform as well on newer reviews that contain different language patterns, sentiments,&#13;
      <span class="No-Break">&#13;
       or topics.&#13;
      </span>&#13;
     </li>&#13;
     <li>&#13;
      <strong class="bold">&#13;
       Concept drift&#13;
      </strong>&#13;
      : This happens&#13;
      <a id="_idIndexMarker706">&#13;
      </a>&#13;
      when the relationships&#13;
      <a id="_idIndexMarker707">&#13;
      </a>&#13;
      between the input features and the target variable evolve. In a RAG system designed to assist with medical queries, the introduction of new diseases, treatments, or medical terminology can lead to concept drift. The model’s understanding of the domain becomes outdated, and its performance&#13;
      <span class="No-Break">&#13;
       may degrade.&#13;
      </span>&#13;
     </li>&#13;
     <li>&#13;
      <strong class="bold">&#13;
       Upstream data changes&#13;
      </strong>&#13;
      : This type of drift happens when the data used to train the&#13;
      <a id="_idIndexMarker708">&#13;
      </a>&#13;
      model is different from the data used in production. For example, if a RAG system is trained on a curated dataset but then applied to raw, unprocessed data in production, the model’s performance may suffer due to differences in data quality, format,&#13;
      <span class="No-Break">&#13;
       or distribution.&#13;
      </span>&#13;
     </li>&#13;
     <li>&#13;
      <strong class="bold">&#13;
       Feedback loops&#13;
      </strong>&#13;
      : In some cases, the outputs of a model can influence its future inputs, creating a feedback loop. For instance, if a RAG system is used to recommend&#13;
      <a id="_idIndexMarker709">&#13;
      </a>&#13;
      articles to users, and those recommendations are then used to update the retrieval component, the model may become biased toward its previous outputs, leading to a narrowing of the information it provides&#13;
      <span class="No-Break">&#13;
       over time.&#13;
      </span>&#13;
     </li>&#13;
     <li>&#13;
      <strong class="bold">&#13;
       Domain shift&#13;
      </strong>&#13;
      : This occurs when a model is applied to a different domain or context than&#13;
      <a id="_idIndexMarker710">&#13;
      </a>&#13;
      it was originally trained for. In a RAG workflow, if the retrieval component is trained on data from one domain (for example, legal documents) but then used to answer queries in another domain (for example, medical questions), the model’s performance may suffer due to differences in language, terminology, or&#13;
      <span class="No-Break">&#13;
       underlying concepts.&#13;
      </span>&#13;
     </li>&#13;
     <li>&#13;
      <strong class="bold">&#13;
       Temporal drift&#13;
      </strong>&#13;
      : This type of drift is related to the passage of time and can encompass&#13;
      <a id="_idIndexMarker711">&#13;
      </a>&#13;
      both data drift and concept drift. As time passes, the data and concepts relevant to a particular task may evolve, leading to a gradual decline in model performance if&#13;
      <span class="No-Break">&#13;
       not addressed.&#13;
      </span>&#13;
     </li>&#13;
    </ul>&#13;
    <p>&#13;
     To mitigate these various types of model drift, it’s important to continuously monitor the performance of a RAG system, regularly update its retrieval component with new data, and adapt it to changes in the underlying data distribution, concepts, or domain. Additionally, implementing feedback loops carefully and ensuring that the training data is representative of the production environment can help minimize the impact of upstream data changes and feedback-related drift. This helps ensure that our RAG system remains accurate, up-to-date, and aligned with the evolving needs of&#13;
     <span class="No-Break">&#13;
      the users.&#13;
     </span>&#13;
    </p>&#13;
    <a id="_idTextAnchor169">&#13;
    </a>&#13;
    <h2 id="_idParaDest-170">&#13;
     Final thoughts about node postprocessors&#13;
    </h2>&#13;
    <p>&#13;
     If the existing&#13;
     <a id="_idIndexMarker712">&#13;
     </a>&#13;
     ones are not exactly fit for our particular use case, we have the option to build our own.&#13;
     <strong class="bold">&#13;
      Custom postprocessors&#13;
     </strong>&#13;
     can be built by extending&#13;
     <code class="literal">&#13;
      BaseNodePostprocessor&#13;
     </code>&#13;
     . You can find a complete example&#13;
     <span class="No-Break">&#13;
      here:&#13;
     </span>&#13;
     <a>&#13;
      <span class="No-Break">&#13;
       https://docs.llamaindex.ai/en/stable/module_guides/querying/node_postprocessors/root.html#custom-node-postprocessor&#13;
      </span>&#13;
     </a>&#13;
     <span class="No-Break">&#13;
      .&#13;
     </span>&#13;
    </p>&#13;
    <p class="callout-heading">&#13;
     Important note&#13;
    </p>&#13;
    <p class="callout">&#13;
     In more complex scenarios, postprocessors can also be chained to apply multiple transformations to the nodes before they’re passed to the&#13;
     <span class="No-Break">&#13;
      response synthesizer.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     The key is&#13;
     <a id="_idIndexMarker713">&#13;
     </a>&#13;
     applying the right processors to remove noise, improve relevance signal, inject diversity, and handle sensitive content – leading to higher quality and more reliable&#13;
     <span class="No-Break">&#13;
      generated responses.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     For now, let’s shift our focus to the final piece of our puzzle:&#13;
     <span class="No-Break">&#13;
      <strong class="bold">&#13;
       response synthesizers&#13;
      </strong>&#13;
     </span>&#13;
     <span class="No-Break">&#13;
      .&#13;
     </span>&#13;
    </p>&#13;
    <a id="_idTextAnchor170">&#13;
    </a>&#13;
   </div>&#13;
  </div>&#13;
 </body>&#13;
</html>
<html>&#13;
 <head>&#13;
  <title>&#13;
   Understanding response synthesizers&#13;
  </title>&#13;
 </head>&#13;
 <body>&#13;
  <div class="epub-source">&#13;
   <h1 id="_idParaDest-171">&#13;
    Understanding response synthesizers&#13;
   </h1>&#13;
   <div id="_idContainer077">&#13;
    from llama_index.core.schema import TextNode, NodeWithScore&#13;
from llama_index.core import get_response_synthesizer&#13;
nodes = [&#13;
    TextNode(text=&#13;
        "The town square clock was built in 1895"&#13;
    ),&#13;
    TextNode(text=&#13;
        "A turquoise parrot lives in the Amazon"&#13;
    ),&#13;
    TextNode(text=&#13;
        "A rare orchid blooms only at midnight"&#13;
    ),&#13;
]&#13;
node_with_score_list = [NodeWithScore(node=node) for node in nodes]&#13;
    synth = get_response_synthesizer(&#13;
    response_mode="refine",&#13;
    use_async=False,&#13;
    streaming=False,&#13;
)&#13;
response = synth.synthesize(&#13;
    "When was the clock built?",&#13;
    nodes=node_with_score_list&#13;
)&#13;
print(response)&#13;
    The clock was built in 1895.&#13;
    <p>&#13;
     The final step before sending our hard-worked contextual data to the LLM is the response synthesizer. It’s the component that’s responsible for generating responses from a language&#13;
     <a id="_idIndexMarker714">&#13;
     </a>&#13;
     model using a user query and the&#13;
     <span class="No-Break">&#13;
      retrieved context.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     It simplifies the process of querying an LLM and synthesizing an answer across our proprietary data. Just like the other components of the framework, response synthesizers can be used on their own or configured in query engines to handle the final step of response generation after nodes have been retrieved&#13;
     <span class="No-Break">&#13;
      and postprocessed.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     Here’s a simple example demonstrating how to use one directly on a given set&#13;
     <span class="No-Break">&#13;
      of nodes:&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     The first part&#13;
     <a id="_idIndexMarker715">&#13;
     </a>&#13;
     of the code, we’ve defined some arbitrary nodes. That’s going to be our&#13;
     <em class="italic">&#13;
      proprietary&#13;
     </em>&#13;
     context. Next, we’ll use a response synthesizer to run an LLM query based on&#13;
     <span class="No-Break">&#13;
      our context:&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     The output is&#13;
     <span class="No-Break">&#13;
      as follows:&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     Curious to take a peek under the hood? What happened in the background here? OK, bear with me for the next few lines – once you understand this example, you’ll know exactly how a response synthesizer works. Let me show you a&#13;
     <span class="No-Break">&#13;
      diagram first:&#13;
     </span>&#13;
    </p>&#13;
    <div>&#13;
     <div class="IMG---Figure" id="_idContainer073">&#13;
      <img src="../Images/B21861_07_2.jpg"/>&#13;
     </div>&#13;
    </div>&#13;
    <p class="IMG---Caption" lang="en-US">&#13;
     Figure 7.2 – The refine response synthesizer&#13;
    </p>&#13;
    <p>&#13;
     Here’s a&#13;
     <a id="_idIndexMarker716">&#13;
     </a>&#13;
     description of&#13;
     <span class="No-Break">&#13;
      the process:&#13;
     </span>&#13;
    </p>&#13;
    <ol>&#13;
     <li>&#13;
      The synthesizer begins by building a special-purpose prompt, starting with the first node in the list as context. This prompt includes the query, specific instructions, and the context – which in this case is our first node. It uses a default value but can be customized via the&#13;
      System: "You are an expert Q&amp;A system that is trusted around the world. Always answer the query using the provided context information, and not prior knowledge. Some rules to follow: 1. Never directly reference the given context in your answer. 2. Avoid statements like 'Based on the context, ' or 'The context information ' or anything along those lines."&#13;
User: "Context information is below. The town square clock was built in 1895. Given the context information and not prior knowledge, answer the query. Query: When was the clock built? Answer: "&#13;
     <span class="No-Break">&#13;
       <code class="literal">&#13;
        text_qa_template&#13;
       </code>&#13;
      </span>&#13;
      <span class="No-Break">&#13;
       parameter:&#13;
      </span>&#13;
      </li>&#13;
     <li>&#13;
      The next step is to send this prompt to the LLM and wait for&#13;
      <span class="No-Break">&#13;
       an answer.&#13;
      </span>&#13;
     </li>&#13;
     <li>&#13;
      After the initial answer comes back, it builds the prompt for the next node while also integrating the first answer in the prompt and refining the final answer using a prompt that can be customized&#13;
      <span class="No-Break">&#13;
       with&#13;
      </span>&#13;
      <span class="No-Break">&#13;
       <code class="literal">&#13;
        refine_template&#13;
       </code>&#13;
      </span>&#13;
      <span class="No-Break">&#13;
       .&#13;
      </span>&#13;
     </li>&#13;
     <li>&#13;
      It then repeats this iterative process for all nodes while constantly refining the&#13;
      <span class="No-Break">&#13;
       final answer.&#13;
      </span>&#13;
     </li>&#13;
     <li>&#13;
      Once the nodes are exhausted, it returns the&#13;
      <em class="italic">&#13;
       refined&#13;
      </em>&#13;
      <span class="No-Break">&#13;
       final answer.&#13;
      </span>&#13;
     </li>&#13;
    </ol>&#13;
    <p>&#13;
     In this case, the&#13;
     <a id="_idIndexMarker717">&#13;
     </a>&#13;
     behavior of the synthesizer is dictated&#13;
     <span class="No-Break">&#13;
      by&#13;
     </span>&#13;
     <span class="No-Break">&#13;
      <code class="literal">&#13;
       response_mode="refine"&#13;
      </code>&#13;
     </span>&#13;
     <span class="No-Break">&#13;
      .&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     However,&#13;
     <code class="literal">&#13;
      refine&#13;
     </code>&#13;
     mode is just one of the several predefined synthesizers in LlamaIndex. Synthesizer mode can be specified using the&#13;
     <code class="literal">&#13;
      response_mode&#13;
     </code>&#13;
     parameter. Here’s a list of the available&#13;
     <a id="_idIndexMarker718">&#13;
     </a>&#13;
     <span class="No-Break">&#13;
      response modes:&#13;
     </span>&#13;
    </p>&#13;
    <ul>&#13;
     <li>&#13;
      <code class="literal">&#13;
       refine&#13;
      </code>&#13;
      : As we saw in the previous example,&#13;
      <code class="literal">&#13;
       refine&#13;
      </code>&#13;
      queries each node individually using&#13;
      <code class="literal">&#13;
       text_qa_template&#13;
      </code>&#13;
      and&#13;
      <code class="literal">&#13;
       refine_template prompts&#13;
      </code>&#13;
      to iteratively construct a detailed response. This mode is ideal for constructing detailed responses, ensuring that each piece of information is carefully considered. We can also set&#13;
      <code class="literal">&#13;
       Verbose&#13;
      </code>&#13;
      to&#13;
      <code class="literal">&#13;
       True&#13;
      </code>&#13;
      for more visibility on the inner workings of this synthesizer and use&#13;
      <code class="literal">&#13;
       output_cls&#13;
      </code>&#13;
      to specify a&#13;
      <code class="literal">&#13;
       pydantic&#13;
      </code>&#13;
      object to use as a&#13;
      <span class="No-Break">&#13;
       response template.&#13;
      </span>&#13;
     </li>&#13;
     <li>&#13;
      <code class="literal">&#13;
       compact&#13;
      </code>&#13;
      : This one is similar to&#13;
      <code class="literal">&#13;
       refine&#13;
      </code>&#13;
      but it concatenates nodes to reduce the number of required LLM queries, balancing detail,&#13;
      <span class="No-Break">&#13;
       and efficiency.&#13;
      </span>&#13;
     </li>&#13;
     <li>&#13;
      <code class="literal">&#13;
       tree_summarize&#13;
      </code>&#13;
      : This mode uses recursive summarization, processing each node with&#13;
      <code class="literal">&#13;
       summary_template&#13;
      </code>&#13;
      . It recursively summarizes and queries nodes, concatenating them in each iteration until a single final response remains. It’s very useful for summarization and best suited for creating comprehensive summaries from multiple pieces&#13;
      <span class="No-Break">&#13;
       of information.&#13;
      </span>&#13;
     </li>&#13;
     <li>&#13;
      <code class="literal">&#13;
       simple_summarize&#13;
      </code>&#13;
      : This mode truncates nodes to fit in one LLM query for basic summarization. It’s great for brief overviews as it’s quick and cheap, but it may omit&#13;
      <span class="No-Break">&#13;
       finer details.&#13;
      </span>&#13;
     </li>&#13;
     <li>&#13;
      <code class="literal">&#13;
       accumulate&#13;
      </code>&#13;
      : This mode applies the query to each node individually and accumulates&#13;
      <a id="_idIndexMarker719">&#13;
      </a>&#13;
      the responses. It’s best suited for analyzing or comparing responses from&#13;
      <span class="No-Break">&#13;
       multiple sources.&#13;
      </span>&#13;
     </li>&#13;
     <li>&#13;
      <code class="literal">&#13;
       no_text&#13;
      </code>&#13;
      : In this operating mode, the response synthesizer fetches nodes without querying the LLM. This is mainly useful for debugging, analyzing raw data, or inspecting the retrieval or&#13;
      <span class="No-Break">&#13;
       postprocessing outputs.&#13;
      </span>&#13;
     </li>&#13;
     <li>&#13;
      <code class="literal">&#13;
       compact_accumulate&#13;
      </code>&#13;
      : A blend of compact and accumulate, this mode compacts prompts, similar to&#13;
      <code class="literal">&#13;
       compact&#13;
      </code>&#13;
      mode, and applies the query across nodes. This is especially suitable for efficiently processing&#13;
      <span class="No-Break">&#13;
       multiple sources.&#13;
      </span>&#13;
     </li>&#13;
    </ul>&#13;
    <p>&#13;
     In addition to&#13;
     <a id="_idIndexMarker720">&#13;
     </a>&#13;
     these predefined modes, custom response synthesizers can be created by subclassing&#13;
     <code class="literal">&#13;
      BaseSynthesizer&#13;
     </code>&#13;
     and implementing the&#13;
     <code class="literal">&#13;
      get_response&#13;
     </code>&#13;
     method. You can find a complete example in the official documentation:&#13;
     <a>&#13;
      https://docs.llamaindex.ai/en/stable/module_guides/querying/response_synthesizers/root.html#custom-response-synthesizers&#13;
     </a>&#13;
     . This provides you with the flexibility to design specialized response&#13;
     <span class="No-Break">&#13;
      generation approaches.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     Features such as&#13;
     <code class="literal">&#13;
      structured_answer_filtering&#13;
     </code>&#13;
     can also be enabled on the&#13;
     <em class="italic">&#13;
      refine&#13;
     </em>&#13;
     and&#13;
     <em class="italic">&#13;
      compact&#13;
     </em>&#13;
     synthesizers. It uses the LLM to filter out retrieved nodes that are irrelevant to the question, improving&#13;
     <span class="No-Break">&#13;
      response quality.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     Prompt templates such as&#13;
     <code class="literal">&#13;
      text_qa_template&#13;
     </code>&#13;
     and&#13;
     <code class="literal">&#13;
      refine_template&#13;
     </code>&#13;
     allow us to customize the prompts that are used at different stages of response synthesis. Additional variables can also be passed to influence&#13;
     <span class="No-Break">&#13;
      response generation.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     Overall, response synthesizers handle the critical task of querying nodes and producing a final response, providing options to balance performance, customizability,&#13;
     <span class="No-Break">&#13;
      and accuracy.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     But guess what? We’re not out of the&#13;
     <span class="No-Break">&#13;
      woods yet.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     Let’s talk about another challenge in&#13;
     <span class="No-Break">&#13;
      our path.&#13;
     </span>&#13;
    </p>&#13;
    <a id="_idTextAnchor171">&#13;
    </a>&#13;
   </div>&#13;
  </div>&#13;
 </body>&#13;
</html>
<html>&#13;
 <head>&#13;
  <title>&#13;
   Implementing output parsing techniques&#13;
  </title>&#13;
 </head>&#13;
 <body>&#13;
  <div class="epub-source">&#13;
   <h1 id="_idParaDest-172">&#13;
    Implementing output parsing techniques&#13;
   </h1>&#13;
   <div id="_idContainer077">&#13;
    pip install guardrails-ai&#13;
    from langchain.output_parsers import (&#13;
    StructuredOutputParser, ResponseSchema)&#13;
from llama_index.core.output_parsers import LangchainOutputParser&#13;
from llama_index.llms.openai import OpenAI&#13;
from llama_index.core.schema import TextNode&#13;
from llama_index.core import VectorStoreIndex&#13;
from pydantic import BaseModel&#13;
from typing import List&#13;
nodes = [&#13;
    TextNode(&#13;
        text="Roses have vibrant colors and smell nice."),&#13;
    TextNode(&#13;
        text="Oak trees are tall and have green leaves."),&#13;
]&#13;
    schemas = [&#13;
    ResponseSchema(&#13;
        name="answer",&#13;
        description=(&#13;
            "answer to the user's question"&#13;
        )&#13;
    ),&#13;
    ResponseSchema(&#13;
        name="source",&#13;
        description=(&#13;
            "the source text used to answer the user's question, "&#13;
            "should be a quote from the original prompt."&#13;
        )&#13;
    )&#13;
]&#13;
    lc_parser = StructuredOutputParser.from_response_schemas(schemas)&#13;
output_parser = LangchainOutputParser(lc_parser)&#13;
llm = OpenAI(output_parser=output_parser)&#13;
    index = VectorStoreIndex(nodes=nodes)&#13;
query_engine = index.as_query_engine(llm=llm)&#13;
response = query_engine.query(&#13;
    "Are oak trees small? yes or no",&#13;
)&#13;
print(response)&#13;
    {'answer': 'no', 'source': 'Oak trees are tall and have green leaves.'}&#13;
    <p>&#13;
     Our next topic addresses a common problem that’s encountered in RAG applications that rely on&#13;
     <a id="_idIndexMarker721">&#13;
     </a>&#13;
     structured outputs produced by an LLM. When those outputs are to become inputs in the next processing steps of the application, their structure becomes&#13;
     <span class="No-Break">&#13;
      very important.&#13;
     </span>&#13;
    </p>&#13;
    <p class="callout-heading">&#13;
     A bit of background&#13;
    </p>&#13;
    <p class="callout">&#13;
     Due to their non-deterministic nature, LLMs have the bad habit of sometimes producing responses in a format other than the requested one, adding unsolicited comments or descriptions – just like humans if you think about it. Simply relying on clever prompting techniques may not be enough to completely avoid&#13;
     <span class="No-Break">&#13;
      this behavior.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     Even models specifically trained to follow precise instructions occasionally deviate from the structure we’ve requested. In cases where that output is simply returned to the user, this doesn’t matter much – it might even create a more&#13;
     <span class="No-Break">&#13;
      natural experience.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     The problems arise when the structure of the response matters – for example, when we are going to store that output in a set of variables and then send it to further processing. Have a look at&#13;
     <span class="No-Break">&#13;
      <em class="italic">&#13;
       Figure 7&#13;
      </em>&#13;
     </span>&#13;
     <em class="italic">&#13;
      .3&#13;
     </em>&#13;
     for a&#13;
     <span class="No-Break">&#13;
      better understanding:&#13;
     </span>&#13;
    </p>&#13;
    <div>&#13;
     <div class="IMG---Figure" id="_idContainer074">&#13;
      <img src="../Images/B21861_07_3.jpg"/>&#13;
     </div>&#13;
    </div>&#13;
    <p class="IMG---Caption" lang="en-US">&#13;
     Figure 7.3 – LLMs may produce unpredictable outputs&#13;
    </p>&#13;
    <p>&#13;
     So, how can we make sure that we receive a structured and predictable output from an LLM? As usual, LlamaIndex comes to our rescue – this time in the form of the&#13;
     <strong class="bold">&#13;
      output parsers&#13;
     </strong>&#13;
     and&#13;
     <strong class="bold">&#13;
      Pydantic programs&#13;
     </strong>&#13;
     . Here’s an&#13;
     <a id="_idIndexMarker722">&#13;
     </a>&#13;
     overview of the methods that are used to ensure a&#13;
     <span class="No-Break">&#13;
      structured output.&#13;
     </span>&#13;
    </p>&#13;
    <a id="_idTextAnchor172">&#13;
    </a>&#13;
    <h2 id="_idParaDest-173">&#13;
     Extracting structured outputs using output parsers&#13;
    </h2>&#13;
    <p>&#13;
     Output parsers&#13;
     <a id="_idIndexMarker723">&#13;
     </a>&#13;
     are essential for managing the unpredictability of LLM&#13;
     <a id="_idIndexMarker724">&#13;
     </a>&#13;
     responses. They ensure that&#13;
     <a id="_idIndexMarker725">&#13;
     </a>&#13;
     outputs from LLMs are structured and formatted correctly for subsequent steps in an application. These parsers come in various forms, each with a unique approach to handling and refining&#13;
     <span class="No-Break">&#13;
      the output.&#13;
     </span>&#13;
    </p>&#13;
    <h3>&#13;
     GuardrailsOutputParser&#13;
    </h3>&#13;
    <p>&#13;
     This particular&#13;
     <a id="_idIndexMarker726">&#13;
     </a>&#13;
     one is based on the&#13;
     <strong class="bold">&#13;
      Guardrails&#13;
     </strong>&#13;
     library provided by Guardrails AI:&#13;
     <a>&#13;
      https://www.guardrailsai.com/&#13;
     </a>&#13;
     . Guardrails ensures the outputs from LLMs adhere to specified structures and types. This is particularly useful in RAG applications, where outputs need to be consistent and structured for&#13;
     <span class="No-Break">&#13;
      further processing.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     Guardrails does&#13;
     <a id="_idIndexMarker727">&#13;
     </a>&#13;
     this by validating the LLM outputs against a&#13;
     <a id="_idIndexMarker728">&#13;
     </a>&#13;
     defined format and can take corrective actions such as re-asking the LLM if the outputs don’t meet the specified standards. This feature is essential for maintaining the integrity and usability of LLM outputs in&#13;
     <span class="No-Break">&#13;
      automated processes.&#13;
     </span>&#13;
    </p>&#13;
    <p class="callout-heading">&#13;
     Under the hood&#13;
    </p>&#13;
    <p class="callout">&#13;
     At the core of how Guardrails works, we find the notion of&#13;
     <strong class="bold">&#13;
      rails&#13;
     </strong>&#13;
     . In the Guardrails library, a rail serves as a specification tool for LLM outputs. It is used to enforce specific structures, types, and validation criteria on these outputs. Rails can be defined using either&#13;
     <a id="_idIndexMarker729">&#13;
     </a>&#13;
     the&#13;
     <strong class="bold">&#13;
      Reliable AI Markup Language&#13;
     </strong>&#13;
     (&#13;
     <strong class="bold">&#13;
      RAIL&#13;
     </strong>&#13;
     ) for structured outputs or directly in Python&#13;
     <span class="No-Break">&#13;
      Pydantic structures.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     The purpose of a rail is to ensure that the LLM outputs adhere to predefined quality and format standards, which includes setting validators and corrective actions if the output deviates from&#13;
     <span class="No-Break">&#13;
      these standards.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     This parser operates based on the&#13;
     <span class="No-Break">&#13;
      following logic:&#13;
     </span>&#13;
    </p>&#13;
    <ol>&#13;
     <li>&#13;
      First, it takes the initial prompt and an output format specification&#13;
      <span class="No-Break">&#13;
       as input.&#13;
      </span>&#13;
     </li>&#13;
     <li>&#13;
      Based on the output format specification, it re-formats the prompt, adapting it for the&#13;
      <span class="No-Break">&#13;
       target LLM.&#13;
      </span>&#13;
     </li>&#13;
     <li>&#13;
      It can also verify the output received from the LLM. If the specification is not validated, it can regenerate the output until the structure&#13;
      <span class="No-Break">&#13;
       is valid.&#13;
      </span>&#13;
     </li>&#13;
    </ol>&#13;
    <p>&#13;
     This parser&#13;
     <a id="_idIndexMarker730">&#13;
     </a>&#13;
     can be configured with the&#13;
     <span class="No-Break">&#13;
      following parameters:&#13;
     </span>&#13;
    </p>&#13;
    <ul>&#13;
     <li>&#13;
      <code class="literal">&#13;
       guard&#13;
      </code>&#13;
      : An instance of the&#13;
      <code class="literal">&#13;
       Guard&#13;
      </code>&#13;
      class from the Guardrails library. This class encapsulates the core functionality of the Guardrails system. It is responsible for enforcing the specifications defined in a&#13;
      <span class="No-Break">&#13;
       RAIL structure&#13;
      </span>&#13;
     </li>&#13;
     <li>&#13;
      <code class="literal">&#13;
       llm&#13;
      </code>&#13;
      : This parameter is optional and is used to select the language model that’s used in conjunction with the&#13;
      <span class="No-Break">&#13;
       Guardrails parser&#13;
      </span>&#13;
     </li>&#13;
     <li>&#13;
      <code class="literal">&#13;
       format_key&#13;
      </code>&#13;
      : This optional parameter is useful when you want to inject specific formatting instructions into the query based on the output&#13;
      <span class="No-Break">&#13;
       format required&#13;
      </span>&#13;
     </li>&#13;
    </ul>&#13;
    <p>&#13;
     You can find a complete example of using this method&#13;
     <span class="No-Break">&#13;
      here:&#13;
     </span>&#13;
     <a>&#13;
      <span class="No-Break">&#13;
       https://docs.llamaindex.ai/en/stable/module_guides/querying/structured_outputs/output_parser.html#guardrails&#13;
      </span>&#13;
     </a>&#13;
     <span class="No-Break">&#13;
      .&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     Once you’ve&#13;
     <a id="_idIndexMarker731">&#13;
     </a>&#13;
     familiarized yourself with the RAIL language, the Guardrails library becomes an easy-to-use parsing solution for&#13;
     <span class="No-Break">&#13;
      your apps.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     Just make sure you install the Guardrails library in your environment first by running the&#13;
     <span class="No-Break">&#13;
      following command:&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     In case you’re wondering how you could build an output parser and implement any custom guard rail logic in it, you can find a complete example&#13;
     <span class="No-Break">&#13;
      here:&#13;
     </span>&#13;
     <a href="https://docs.llamaindex.ai/en/latest/examples/output_parsing/llm_program/#define-a-custom-output-parser" target="_blank">&#13;
      <span class="No-Break">&#13;
       https://docs.llamaindex.ai/en/latest/examples/output_parsing/llm_program/#define-a-custom-output-parser&#13;
      </span>&#13;
     </a>&#13;
     <span class="No-Break">&#13;
      .&#13;
     </span>&#13;
    </p>&#13;
    <h3>&#13;
     LangchainOutputParser&#13;
    </h3>&#13;
    <p>&#13;
     Apart from&#13;
     <code class="literal">&#13;
      GuardrailsOutputParser&#13;
     </code>&#13;
     , LlamaIndex also supports the output parsers provided&#13;
     <span class="No-Break">&#13;
      by Langchain.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     Instead of&#13;
     <a id="_idIndexMarker732">&#13;
     </a>&#13;
     using the more complex RAIL language to define validation criteria and corrective actions,&#13;
     <code class="literal">&#13;
      LangchainOutputParser&#13;
     </code>&#13;
     relies on a simpler&#13;
     <a id="_idIndexMarker733">&#13;
     </a>&#13;
     concept called a&#13;
     <span class="No-Break">&#13;
      <strong class="bold">&#13;
       response schema&#13;
      </strong>&#13;
     </span>&#13;
     <span class="No-Break">&#13;
      .&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     Response&#13;
     <a id="_idIndexMarker734">&#13;
     </a>&#13;
     schemas in Langchain are primarily used for structuring the output and focus on defining specific fields that the output should contain. These schemas guide the Langchain system to ensure that the output matches the&#13;
     <span class="No-Break">&#13;
      expected format.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     This approach is less about enforcing stringent validation rules or corrective actions and more about organizing the output data in a coherent and&#13;
     <span class="No-Break">&#13;
      predictable structure.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     Here’s an example that implements a very simple quotation system based on&#13;
     <span class="No-Break">&#13;
      this method:&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     In the first part of our code, we took care of the necessary imports and then defined some random&#13;
     <em class="italic">&#13;
      proprietary data&#13;
     </em>&#13;
     contained in two nodes. Next, we must define the response&#13;
     <a id="_idIndexMarker735">&#13;
     </a>&#13;
     schemas that will be used to structure&#13;
     <a id="_idIndexMarker736">&#13;
     </a>&#13;
     the&#13;
     <span class="No-Break">&#13;
      LLM’s output:&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     As you can see, the schema defines the expected output structure. Now, we can define the Langchain parser and an OpenAI&#13;
     <code class="literal">&#13;
      llm&#13;
     </code>&#13;
     object that’s been configured to&#13;
     <span class="No-Break">&#13;
      use it:&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     Now, it’s time to build an index and&#13;
     <code class="literal">&#13;
      QueryEngine&#13;
     </code>&#13;
     from our Nodes.&#13;
     <code class="literal">&#13;
      QueryEngine&#13;
     </code>&#13;
     will be configured to use the Langchain parser so that it can structure&#13;
     <span class="No-Break">&#13;
      the output:&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     The output is&#13;
     <span class="No-Break">&#13;
      as follows:&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     Neat,&#13;
     <span class="No-Break">&#13;
      isn’t it?&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     Note that&#13;
     <a id="_idIndexMarker737">&#13;
     </a>&#13;
     citations are useful in a RAG system as they increase&#13;
     <a id="_idIndexMarker738">&#13;
     </a>&#13;
     transparency and allow the answers to be validated against our&#13;
     <span class="No-Break">&#13;
      proprietary data.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     The Langchain&#13;
     <a id="_idIndexMarker739">&#13;
     </a>&#13;
     parser has two&#13;
     <span class="No-Break">&#13;
      configurable parameters:&#13;
     </span>&#13;
    </p>&#13;
    <ul>&#13;
     <li>&#13;
      <code class="literal">&#13;
       output_parser&#13;
      </code>&#13;
      : This parameter accepts an instance of a Langchain output parser (&#13;
      <code class="literal">&#13;
       LCOutputParser&#13;
      </code>&#13;
      ). This is where the primary logic for parsing and structuring the output is defined. As seen in the previous example, the parser provided here determines how the output from the LLM is processed&#13;
      <span class="No-Break">&#13;
       and formatted&#13;
      </span>&#13;
     </li>&#13;
     <li>&#13;
      <code class="literal">&#13;
       format_key&#13;
      </code>&#13;
      : This is an optional parameter that, if provided, is used to insert additional format instructions into the query. This can be particularly useful when the query needs to be formatted with specific instructions that guide the output generation of the&#13;
      <span class="No-Break">&#13;
       language model&#13;
      </span>&#13;
     </li>&#13;
    </ul>&#13;
    <p>&#13;
     While both&#13;
     <code class="literal">&#13;
      GuardrailsOutputParser&#13;
     </code>&#13;
     and&#13;
     <code class="literal">&#13;
      LangchainOutputParser&#13;
     </code>&#13;
     aim to structure and validate LLM outputs, their specific mechanisms and extent of control over the output format vary. The Langchain parser is more focused on processing the LLM output, while the Guardrails parser has a more proactive role in shaping the query and output format. We’ll talk about the other&#13;
     <span class="No-Break">&#13;
      method next.&#13;
     </span>&#13;
    </p>&#13;
    <a id="_idTextAnchor173">&#13;
    </a>&#13;
    <h2 id="_idParaDest-174">&#13;
     Extracting structured outputs using Pydantic programs&#13;
    </h2>&#13;
    <p>&#13;
     Pydantic programs represent another way to generate structured outputs. Pydantic programs&#13;
     <a id="_idIndexMarker740">&#13;
     </a>&#13;
     are a form of abstraction in LLM workflows that convert input strings into structured pydantic object types. They&#13;
     <a id="_idIndexMarker741">&#13;
     </a>&#13;
     can either call functions or rely on text completions, along with&#13;
     <span class="No-Break">&#13;
      output parsers.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     They are highly versatile and can be used for various applications, being both composable and adaptable for general or specific use cases. There are multiple programs available for various&#13;
     <span class="No-Break">&#13;
      use cases.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     You can find an overview and working examples&#13;
     <span class="No-Break">&#13;
      here:&#13;
     </span>&#13;
     <a>&#13;
      <span class="No-Break">&#13;
       https://docs.llamaindex.ai/en/stable/module_guides/querying/structured_outputs/pydantic_program.html&#13;
      </span>&#13;
     </a>&#13;
     <span class="No-Break">&#13;
      .&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     You’ll learn how to use a Pydantic program – in this case,&#13;
     <code class="literal">&#13;
      OpenAIPydanticProgram&#13;
     </code>&#13;
     , later in this chapter, when we continue working on our PITS&#13;
     <span class="No-Break">&#13;
      tutoring app.&#13;
     </span>&#13;
    </p>&#13;
    <a id="_idTextAnchor174">&#13;
    </a>&#13;
   </div>&#13;
  </div>&#13;
 </body>&#13;
</html>
<html>&#13;
 <head>&#13;
  <title>&#13;
   Building and using query engines&#13;
  </title>&#13;
 </head>&#13;
 <body>&#13;
  <div class="epub-source">&#13;
   <h1 id="_idParaDest-175">&#13;
    Building and using query engines&#13;
   </h1>&#13;
   <div id="_idContainer077">&#13;
    query_engine = index.as_query_engine()&#13;
    from llama_index.core.retrievers import SummaryIndexEmbeddingRetriever&#13;
from llama_index.core.postprocessor import SimilarityPostprocessor&#13;
from llama_index.core.query_engine import RetrieverQueryEngine&#13;
from llama_index.core import (&#13;
    SummaryIndex, SimpleDirectoryReader, get_response_synthesizer)&#13;
    documents = SimpleDirectoryReader("files").load_data()&#13;
index = SummaryIndex.from_documents(documents)&#13;
    retriever = SummaryIndexEmbeddingRetriever(&#13;
    index=index,&#13;
    similarity_top_k=3,&#13;
)&#13;
response_synthesizer = get_response_synthesizer(&#13;
    response_mode="tree_summarize",&#13;
    verbose=True&#13;
)&#13;
pp = SimilarityPostprocessor(similarity_cutoff=0.7)&#13;
    query_engine = RetrieverQueryEngine(&#13;
    retriever=retriever,&#13;
    response_synthesizer=response_synthesizer,&#13;
    node_postprocessors=[pp]&#13;
)&#13;
response = query_engine.query(&#13;
    "Enumerate iconic buildings in ancient Rome"&#13;
)&#13;
print(response)&#13;
    The iconic buildings in ancient Rome included the Colosseum and the Pantheon.&#13;
    from llama_index.core.tools import QueryEngineTool&#13;
from llama_index.core.query_engine import RouterQueryEngine&#13;
from llama_index.core.selectors import PydanticMultiSelector&#13;
from llama_index.core import SummaryIndex, SimpleDirectoryReader&#13;
from llama_index.core.extractors import TitleExtractor&#13;
documents = SimpleDirectoryReader("files").load_data()&#13;
    title_extractor = TitleExtractor()&#13;
for doc in documents:&#13;
    title_metadata = title_extractor.extract([doc])&#13;
    doc.metadata.update(title_metadata[0])&#13;
    indexes = []&#13;
query_engines = []&#13;
tools = []&#13;
for doc in documents:&#13;
    document_title = doc.metadata['document_title']&#13;
    index = SummaryIndex.from_documents([doc])&#13;
    query_engine = index.as_query_engine(&#13;
        response_mode="tree_summarize",&#13;
        use_async=True,&#13;
    )&#13;
    tool = QueryEngineTool.from_defaults(&#13;
        query_engine=query_engine,&#13;
        description=f"Contains data about {document_title}",&#13;
    )&#13;
    indexes.append(index)&#13;
    query_engines.append(query_engine)&#13;
    tools.append(tool)&#13;
    qe = RouterQueryEngine(&#13;
    selector=PydanticMultiSelector.from_defaults(),&#13;
    query_engine_tools=tools&#13;
)&#13;
    response = qe.query(&#13;
    "Tell me about Rome and dogs"&#13;
)&#13;
print(response)&#13;
    from llama_index.core.tools import QueryEngineTool&#13;
from llama_index.core.query_engine import RouterQueryEngine&#13;
from llama_index.core.query_engine import SubQuestionQueryEngine&#13;
from llama_index.core.selectors import PydanticMultiSelector&#13;
from llama_index.core.extractors import TitleExtractor&#13;
from llama_index.core import SummaryIndex, SimpleDirectoryReader&#13;
    documents = SimpleDirectoryReader("files/sample").load_data()&#13;
title_extractor = TitleExtractor()&#13;
for doc in documents:&#13;
    title_metadata = title_extractor.extract([doc])&#13;
    doc.metadata.update(title_metadata[0])&#13;
indexes = []&#13;
query_engines = []&#13;
tools = []&#13;
    for doc in documents:&#13;
    document_title = doc.metadata['document_title']&#13;
    file_name = doc.metadata['file_name']&#13;
    index = SummaryIndex.from_documents([doc])&#13;
    query_engine = index.as_query_engine(&#13;
        response_mode="tree_summarize",&#13;
        use_async=True,&#13;
    )&#13;
    tool = QueryEngineTool.from_defaults(&#13;
        query_engine=query_engine,&#13;
        name=file_name,&#13;
        description=f"Contains data about {document_title}",&#13;
    )&#13;
    indexes.append(index)&#13;
    query_engines.append(query_engine)&#13;
    tools.append(tool)&#13;
    qe = SubQuestionQueryEngine.from_defaults(&#13;
    query_engine_tools=tools,&#13;
    use_async=True&#13;
)&#13;
    response = qe.query(&#13;
    "Compare buildings from ancient Athens and ancient Rome"&#13;
)&#13;
print(response)&#13;
    <p>&#13;
     Our puzzle is now complete. Throughout the previous chapters, we’ve gradually learned about the key&#13;
     <a id="_idIndexMarker742">&#13;
     </a>&#13;
     ingredients in a RAG setup. Now, it’s time to bring everything together: the nodes, indexes, retrievers, postprocessors, response synthesizers, and&#13;
     <span class="No-Break">&#13;
      output parsers.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     In this chapter, we’ll focus on blending these elements into a complex construct: the query engine. We’ll learn about how query engines work and the neat tricks they have up&#13;
     <span class="No-Break">&#13;
      their sleeves.&#13;
     </span>&#13;
    </p>&#13;
    <a id="_idTextAnchor175">&#13;
    </a>&#13;
    <h2 id="_idParaDest-176">&#13;
     Exploring different methods of building query engines&#13;
    </h2>&#13;
    <p>&#13;
     At its core,&#13;
     <code class="literal">&#13;
      QueryEngine&#13;
     </code>&#13;
     is an&#13;
     <a id="_idIndexMarker743">&#13;
     </a>&#13;
     interface that processes natural language queries to generate rich responses. It often relies on one or more indexes through retrievers and can also be combined with other query engines for&#13;
     <span class="No-Break">&#13;
      enhanced capabilities.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     The easiest&#13;
     <a id="_idIndexMarker744">&#13;
     </a>&#13;
     way to define&#13;
     <code class="literal">&#13;
      QueryEngine&#13;
     </code>&#13;
     is using the&#13;
     <strong class="bold">&#13;
      high-level API&#13;
     </strong>&#13;
     provided by LlamaIndex,&#13;
     <span class="No-Break">&#13;
      like this:&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     With just a single line of code, we’ve built a simple query engine from an existing index. Although fast, this method uses&#13;
     <code class="literal">&#13;
      RetrieverQueryEngine&#13;
     </code>&#13;
     under the hood with the default settings and does not provide many opportunities&#13;
     <span class="No-Break">&#13;
      for customization.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     If we want&#13;
     <a id="_idIndexMarker745">&#13;
     </a>&#13;
     to have complete control over its parameters and full customization options, we can use the&#13;
     <strong class="bold">&#13;
      low-level API&#13;
     </strong>&#13;
     to explicitly build the&#13;
     <span class="No-Break">&#13;
      query engine.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     Let’s have&#13;
     <a id="_idIndexMarker746">&#13;
     </a>&#13;
     a look at&#13;
     <span class="No-Break">&#13;
      an example:&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     As usual, we start by handling the imports. Next, we ingest our demo files and build a&#13;
     <span class="No-Break">&#13;
      simple&#13;
     </span>&#13;
     <span class="No-Break">&#13;
      <code class="literal">&#13;
       SummaryIndex&#13;
      </code>&#13;
     </span>&#13;
     <span class="No-Break">&#13;
      :&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     Then, we throw in a retriever, a response synthesizer, and a node postprocessor. Building a query engine with this low-level API approach allows us to fully customize&#13;
     <span class="No-Break">&#13;
      each component:&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     Now, it’s time&#13;
     <a id="_idIndexMarker747">&#13;
     </a>&#13;
     to bring them all together and assemble&#13;
     <span class="No-Break">&#13;
      our&#13;
     </span>&#13;
     <span class="No-Break">&#13;
      <code class="literal">&#13;
       QueryEngine&#13;
      </code>&#13;
     </span>&#13;
     <span class="No-Break">&#13;
      :&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     The output should look similar to&#13;
     <span class="No-Break">&#13;
      the following:&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     Now that we’ve built a simple query engine, let’s take a look at some more&#13;
     <span class="No-Break">&#13;
      advanced scenarios.&#13;
     </span>&#13;
    </p>&#13;
    <a id="_idTextAnchor176">&#13;
    </a>&#13;
    <h2 id="_idParaDest-177">&#13;
     Advanced uses of the QueryEngine interface&#13;
    </h2>&#13;
    <p>&#13;
     The LlamaIndex&#13;
     <a id="_idIndexMarker748">&#13;
     </a>&#13;
     community has gradually developed – and continues to develop – various advanced query methods while using&#13;
     <code class="literal">&#13;
      QueryEngine&#13;
     </code>&#13;
     as a&#13;
     <span class="No-Break">&#13;
      main component.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     Apart from the query engines that I’m already covering in this book,&#13;
     <em class="italic">&#13;
      Table 7.1&#13;
     </em>&#13;
     provides an overview&#13;
     <a id="_idIndexMarker749">&#13;
     </a>&#13;
     of other available engines at the time&#13;
     <span class="No-Break">&#13;
      of writing:&#13;
     </span>&#13;
    </p>&#13;
    <table class="No-Table-Style _idGenTablePara-1" id="table001-2">&#13;
     <colgroup>&#13;
      <col/>&#13;
      <col/>&#13;
     </colgroup>&#13;
     <thead>&#13;
      <tr class="No-Table-Style">&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         <span class="No-Break">&#13;
          <strong class="bold">&#13;
           QueryEngine Class&#13;
          </strong>&#13;
         </span>&#13;
        </p>&#13;
       </td>&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         <strong class="bold">&#13;
          Short Description and&#13;
         </strong>&#13;
         <span class="No-Break">&#13;
          <strong class="bold">&#13;
           Use Cases&#13;
          </strong>&#13;
         </span>&#13;
        </p>&#13;
       </td>&#13;
      </tr>&#13;
     </thead>&#13;
     <tbody>&#13;
      <tr class="No-Table-Style">&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         <span class="No-Break">&#13;
          <code class="literal">&#13;
           CitationQueryEngine&#13;
          </code>&#13;
         </span>&#13;
        </p>&#13;
       </td>&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         Designed for situations requiring citations from multiple sources to support answers. It is especially useful in academic research, legal analysis, or any context where validated, source-based information is important. When generating responses, this query engine incorporates and cites relevant sources, ensuring answers are not only accurate but also verifiably supported by&#13;
         <span class="No-Break">&#13;
          documented evidence.&#13;
         </span>&#13;
        </p>&#13;
       </td>&#13;
      </tr>&#13;
      <tr class="No-Table-Style">&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         <span class="No-Break">&#13;
          <code class="literal">&#13;
           CogniswitchQueryEngine&#13;
          </code>&#13;
         </span>&#13;
        </p>&#13;
       </td>&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         Integrates with the Cogniswitch service (&#13;
         <a>&#13;
          https://www.cogniswitch.ai/&#13;
         </a>&#13;
         ) to answer queries using a combination of Cogniswitch’s knowledge processing capabilities and&#13;
         <span class="No-Break">&#13;
          OpenAI’s models.&#13;
         </span>&#13;
        </p>&#13;
       </td>&#13;
      </tr>&#13;
      <tr class="No-Table-Style">&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         <span class="No-Break">&#13;
          <code class="literal">&#13;
           ComposableGraphQueryEngine&#13;
          </code>&#13;
         </span>&#13;
        </p>&#13;
       </td>&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         Designed to operate within a composable graph structure, enabling flexible, modular querying across different data sources and indices. It is ideal for complex data ecosystems where different types of information&#13;
         <span class="No-Break">&#13;
          are interconnected.&#13;
         </span>&#13;
        </p>&#13;
       </td>&#13;
      </tr>&#13;
      <tr class="No-Table-Style">&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         <span class="No-Break">&#13;
          <code class="literal">&#13;
           QASummaryQueryEngineBuilder&#13;
          </code>&#13;
         </span>&#13;
        </p>&#13;
       </td>&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         Combines&#13;
         <code class="literal">&#13;
          SummaryIndex&#13;
         </code>&#13;
         and&#13;
         <code class="literal">&#13;
          VectorStoreIndex&#13;
         </code>&#13;
         . This is useful both to retrieve specific information from documents and to get concise summaries&#13;
         <span class="No-Break">&#13;
          of content.&#13;
         </span>&#13;
        </p>&#13;
       </td>&#13;
      </tr>&#13;
      <tr class="No-Table-Style">&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         <span class="No-Break">&#13;
          <code class="literal">&#13;
           TransformQueryEngine&#13;
          </code>&#13;
         </span>&#13;
        </p>&#13;
       </td>&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         Designed to preprocess queries using a specific transformation before they are submitted to an underlying query engine. When queries vary greatly in format or clarity, applying a transformation to normalize or enhance them can greatly&#13;
         <span class="No-Break">&#13;
          improve retrieval.&#13;
         </span>&#13;
        </p>&#13;
       </td>&#13;
      </tr>&#13;
      <tr class="No-Table-Style">&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         <span class="No-Break">&#13;
          <code class="literal">&#13;
           MultiStepQueryEngine&#13;
          </code>&#13;
         </span>&#13;
        </p>&#13;
       </td>&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         Works by decomposing complex queries into simpler, sequential steps. It can be useful for handling complex or multi-faceted questions that require a series of&#13;
         <span class="No-Break">&#13;
          logical steps.&#13;
         </span>&#13;
        </p>&#13;
       </td>&#13;
      </tr>&#13;
      <tr class="No-Table-Style">&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         <span class="No-Break">&#13;
          <code class="literal">&#13;
           ToolRetrieverRouterQueryEngine&#13;
          </code>&#13;
         </span>&#13;
        </p>&#13;
       </td>&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         Can dynamically choose from multiple candidate query engines based on the query’s context. It uses the most appropriate query engine tool for each&#13;
         <span class="No-Break">&#13;
          specific query.&#13;
         </span>&#13;
        </p>&#13;
       </td>&#13;
      </tr>&#13;
      <tr class="No-Table-Style">&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         <span class="No-Break">&#13;
          <code class="literal">&#13;
           SQLJoinQueryEngine&#13;
          </code>&#13;
         </span>&#13;
        </p>&#13;
       </td>&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         Designed for cases that require a combination of SQL database queries and additional information retrieval or processing. This is especially useful when the SQL query results need to be augmented or refined using&#13;
         <span class="No-Break">&#13;
          further queries.&#13;
         </span>&#13;
        </p>&#13;
       </td>&#13;
      </tr>&#13;
      <tr class="No-Table-Style">&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         <span class="No-Break">&#13;
          <code class="literal">&#13;
           SQLAutoVectorQueryEngine&#13;
          </code>&#13;
         </span>&#13;
        </p>&#13;
       </td>&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         Integrates SQL database queries with vector-based retrieval, enabling a two-step process where a query can be executed against a SQL database. Based on those results, further information can be fetched from a&#13;
         <span class="No-Break">&#13;
          vector store.&#13;
         </span>&#13;
        </p>&#13;
       </td>&#13;
      </tr>&#13;
      <tr class="No-Table-Style">&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         <span class="No-Break">&#13;
          <code class="literal">&#13;
           RetryQueryEngine&#13;
          </code>&#13;
         </span>&#13;
        </p>&#13;
       </td>&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         When the initial response to a query does not meet certain evaluation criteria, it automatically retries the query if it&#13;
         <span class="No-Break">&#13;
          fails evaluation.&#13;
         </span>&#13;
        </p>&#13;
       </td>&#13;
      </tr>&#13;
      <tr class="No-Table-Style">&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         <span class="No-Break">&#13;
          <code class="literal">&#13;
           RetrySourceQueryEngine&#13;
          </code>&#13;
         </span>&#13;
        </p>&#13;
       </td>&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         Designed to perform retries on a query with different source nodes based on evaluation criteria. If the initial response from the query engine does not pass the evaluator’s criteria, it attempts to find alternative source nodes that may yield a&#13;
         <span class="No-Break">&#13;
          better response.&#13;
         </span>&#13;
        </p>&#13;
       </td>&#13;
      </tr>&#13;
      <tr class="No-Table-Style">&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         <span class="No-Break">&#13;
          <code class="literal">&#13;
           RetryGuidelineQueryEngine&#13;
          </code>&#13;
         </span>&#13;
        </p>&#13;
       </td>&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         Similar to&#13;
         <code class="literal">&#13;
          RetryQueryEngine&#13;
         </code>&#13;
         , this one also transforms the query on each retry, based on feedback from the&#13;
         <span class="No-Break">&#13;
          evaluation process.&#13;
         </span>&#13;
        </p>&#13;
       </td>&#13;
      </tr>&#13;
      <tr class="No-Table-Style">&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         <span class="No-Break">&#13;
          <code class="literal">&#13;
           PandasQueryEngine&#13;
          </code>&#13;
         </span>&#13;
        </p>&#13;
       </td>&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         Converts natural language queries into executable pandas Python code, allowing for data manipulation and analysis over&#13;
         <span class="No-Break">&#13;
          pandas DataFrames.&#13;
         </span>&#13;
        </p>&#13;
       </td>&#13;
      </tr>&#13;
      <tr class="No-Table-Style">&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         <span class="No-Break">&#13;
          <code class="literal">&#13;
           JSONalyzeQueryEngine&#13;
          </code>&#13;
         </span>&#13;
        </p>&#13;
       </td>&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         Designed to analyze JSON list-shaped data by converting natural language queries into SQL queries that are executed within an in-memory&#13;
         <span class="No-Break">&#13;
          SQLite database.&#13;
         </span>&#13;
        </p>&#13;
       </td>&#13;
      </tr>&#13;
      <tr class="No-Table-Style">&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         <span class="No-Break">&#13;
          <code class="literal">&#13;
           KnowledgeGraphQueryEngine&#13;
          </code>&#13;
         </span>&#13;
        </p>&#13;
       </td>&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         Generates and processes queries for knowledge graphs, translating natural language queries into graph-specific queries and synthesizing responses based on graph query results. This is useful for applications requiring interaction with&#13;
         <span class="No-Break">&#13;
          knowledge graphs.&#13;
         </span>&#13;
        </p>&#13;
       </td>&#13;
      </tr>&#13;
      <tr class="No-Table-Style">&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         <span class="No-Break">&#13;
          <code class="literal">&#13;
           FLAREInstructQueryEngine&#13;
          </code>&#13;
         </span>&#13;
        </p>&#13;
       </td>&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         Implementing the&#13;
         <strong class="bold">&#13;
          Forward-Looking Active REtrieval&#13;
         </strong>&#13;
         (&#13;
         <strong class="bold">&#13;
          FLARE&#13;
         </strong>&#13;
         ) method, this query engine allows the model to continually access and incorporate external knowledge as it generates content. This is particularly useful for generating long, knowledge-intensive texts. By actively predicting future content needs and retrieving information accordingly, FLARE aims to reduce hallucinations and improve the factual accuracy of generated responses. It’s based on a paper by&#13;
         <span lang="en-US">&#13;
          Jiang et al. (2023),&#13;
         </span>&#13;
         <em class="italic">&#13;
          Active Retrieval Augmented&#13;
         </em>&#13;
         <span class="No-Break">&#13;
          <em class="italic">&#13;
           Generation&#13;
          </em>&#13;
         </span>&#13;
         <span class="No-Break" lang="en-US">&#13;
          (&#13;
         </span>&#13;
         <span class="No-Break">&#13;
          https://arxiv.org/abs/2305.06983v2&#13;
         </span>&#13;
         <span class="No-Break">&#13;
          ).&#13;
         </span>&#13;
        </p>&#13;
       </td>&#13;
      </tr>&#13;
      <tr class="No-Table-Style">&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         <span class="No-Break">&#13;
          <code class="literal">&#13;
           SimpleMultiModalQueryEngine&#13;
          </code>&#13;
         </span>&#13;
        </p>&#13;
       </td>&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         A multi-modal query engine that can process queries involving both text and images, assuming that the retrieved text and images can fit within the LLM’s context window. It retrieves relevant text and images based on the query and then synthesizes a response using a&#13;
         <span class="No-Break">&#13;
          multi-modal LLM.&#13;
         </span>&#13;
        </p>&#13;
       </td>&#13;
      </tr>&#13;
      <tr class="No-Table-Style">&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         <span class="No-Break">&#13;
          <code class="literal">&#13;
           SQLTableRetrieverQueryEngine&#13;
          </code>&#13;
         </span>&#13;
        </p>&#13;
       </td>&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         Converts natural language queries into SQL queries but also synthesizes responses from the query results, making the responses more understandable and relevant to the user’s natural&#13;
         <span class="No-Break">&#13;
          language query.&#13;
         </span>&#13;
        </p>&#13;
       </td>&#13;
      </tr>&#13;
      <tr class="No-Table-Style">&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         <span class="No-Break">&#13;
          <code class="literal">&#13;
           PGVectorSQLQueryEngine&#13;
          </code>&#13;
         </span>&#13;
        </p>&#13;
       </td>&#13;
       <td class="No-Table-Style">&#13;
        <p>&#13;
         Designed to work with PGvector (https://github.com/pgvector/pgvector), an extension for PostgreSQL that allows vectors to be stored and embedded directly within&#13;
         <span class="No-Break">&#13;
          the database.&#13;
         </span>&#13;
        </p>&#13;
       </td>&#13;
      </tr>&#13;
     </tbody>&#13;
    </table>&#13;
    <p class="IMG---Caption" lang="en-US">&#13;
     Table 7.1 – Different query engine modules available in LlamaIndex&#13;
    </p>&#13;
    <p>&#13;
     The list of advanced implementations has already become so long that it could probably be the subject&#13;
     <a id="_idIndexMarker750">&#13;
     </a>&#13;
     of a separate book. Consequently, I did not set out to give a detailed presentation of each method. Instead, I encourage you to consult the official project documentation on the subject and discover how these building blocks can be used in various&#13;
     <span class="No-Break">&#13;
      scenarios:&#13;
     </span>&#13;
     <span class="No-Break">&#13;
      https://docs.llamaindex.ai/en/stable/module_guides/deploying/query_engine/modules.html&#13;
     </span>&#13;
     <span class="No-Break">&#13;
      .&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     There, you will find detailed explanations, use cases for each module, and, most importantly, code examples with which you can understand the operation and implementation of&#13;
     <span class="No-Break">&#13;
      each method.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     However, we cannot end this chapter without introducing you to at least a few essential modules in a RAG scenario. So, that’s what we are going to&#13;
     <span class="No-Break">&#13;
      cover next.&#13;
     </span>&#13;
    </p>&#13;
    <h3>&#13;
     Implementing advanced routing with RouterQueryEngine&#13;
    </h3>&#13;
    <p>&#13;
     Remember&#13;
     <a id="_idIndexMarker751">&#13;
     </a>&#13;
     when we talked&#13;
     <a id="_idIndexMarker752">&#13;
     </a>&#13;
     about routing retrievers in&#13;
     <a>&#13;
      <span class="No-Break">&#13;
       <em class="italic">&#13;
        Chapter 6&#13;
       </em>&#13;
      </span>&#13;
     </a>&#13;
     ,&#13;
     <em class="italic">&#13;
      Querying Our Data, Part 1 – Context Retrieval&#13;
     </em>&#13;
     ? It’s time to see a more advanced routing mechanism, this time implemented at the query&#13;
     <span class="No-Break">&#13;
      engine level.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     <span class="No-Break">&#13;
      <em class="italic">&#13;
       Figure 7&#13;
      </em>&#13;
     </span>&#13;
     <em class="italic">&#13;
      .4&#13;
     </em>&#13;
     summarizes the operation&#13;
     <span class="No-Break">&#13;
      of&#13;
     </span>&#13;
     <span class="No-Break">&#13;
      <code class="literal">&#13;
       RouterQueryEngine&#13;
      </code>&#13;
     </span>&#13;
     <span class="No-Break">&#13;
      :&#13;
     </span>&#13;
    </p>&#13;
    <div>&#13;
     <div class="IMG---Figure" id="_idContainer075">&#13;
      <img src="../Images/B21861_07_4.jpg"/>&#13;
     </div>&#13;
    </div>&#13;
    <p class="IMG---Caption" lang="en-US">&#13;
     Figure 7.4 – How RouterQueryEngine works&#13;
    </p>&#13;
    <p>&#13;
     <code class="literal">&#13;
      RouterQueryEngine&#13;
     </code>&#13;
     is capable of choosing between different tools it has available. Depending&#13;
     <a id="_idIndexMarker753">&#13;
     </a>&#13;
     on the user&#13;
     <a id="_idIndexMarker754">&#13;
     </a>&#13;
     query, the router will decide which&#13;
     <code class="literal">&#13;
      QueryEngineTool&#13;
     </code>&#13;
     should be used to generate&#13;
     <span class="No-Break">&#13;
      an answer.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     Just like in the case of retrievers, we can use&#13;
     <code class="literal">&#13;
      PydanticMultiSelector&#13;
     </code>&#13;
     or&#13;
     <code class="literal">&#13;
      PydanticSingleSelector&#13;
     </code>&#13;
     to configure its behavior. The multi-selector combines multiple options and can handle a broader spectrum of&#13;
     <span class="No-Break">&#13;
      user queries.&#13;
     </span>&#13;
    </p>&#13;
    <p class="callout-heading">&#13;
     Potential use case&#13;
    </p>&#13;
    <p class="callout">&#13;
     Imagine a real-life scenario where an organization has its knowledge split into multiple individual documents. Such a router would allow for general queries over the entire knowledge base, while still enabling and precisely pinpointing the source data used to generate&#13;
     <span class="No-Break">&#13;
      the answer.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     In the following example, we’re building a&#13;
     <code class="literal">&#13;
      RouterQueryEngine&#13;
     </code>&#13;
     engine that operates different query engine tools – each one built over a different document. Here’s&#13;
     <span class="No-Break">&#13;
      the code:&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     The first part of the code handles the imports and ingests our sample data. As before, we are&#13;
     <a id="_idIndexMarker755">&#13;
     </a>&#13;
     using two simple&#13;
     <a id="_idIndexMarker756">&#13;
     </a>&#13;
     text files: one containing information about ancient Rome and another containing a generic text about dogs. In the next part, we’ll go through each document and use&#13;
     <code class="literal">&#13;
      TitleExtractor&#13;
     </code>&#13;
     to extract a title and store it as a&#13;
     <span class="No-Break">&#13;
      <code class="literal">&#13;
       metadata&#13;
      </code>&#13;
     </span>&#13;
     <span class="No-Break">&#13;
      field:&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     Once the files have been ingested and we have generated document titles, we can define&#13;
     <code class="literal">&#13;
      SummaryIndex&#13;
     </code>&#13;
     ,&#13;
     <code class="literal">&#13;
      QueryEngine&#13;
     </code>&#13;
     , and&#13;
     <code class="literal">&#13;
      QueryEngineTool&#13;
     </code>&#13;
     for each of the documents. We use the document title to provide the selector with a description of&#13;
     <span class="No-Break">&#13;
      each tool:&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     Now&#13;
     <a id="_idIndexMarker757">&#13;
     </a>&#13;
     that we have a list&#13;
     <a id="_idIndexMarker758">&#13;
     </a>&#13;
     of available tools, we can build our&#13;
     <code class="literal">&#13;
      RouterQueryEngine&#13;
     </code>&#13;
     based&#13;
     <span class="No-Break">&#13;
      on&#13;
     </span>&#13;
     <span class="No-Break">&#13;
      <code class="literal">&#13;
       PydanticMultiSelector&#13;
      </code>&#13;
     </span>&#13;
     <span class="No-Break">&#13;
      .&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     To do this, we must pass the query engine tools as an argument. These will be the options that are available for&#13;
     <span class="No-Break">&#13;
      the selector:&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     Depending on the query, the selector will decide which tools to use to gather responses. After each tool has responded, the query engine will synthesize and return a&#13;
     <span class="No-Break">&#13;
      final response:&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     For relatively small documents, this method will probably work just fine. So long as the text is short enough to be properly summarized into a title, this query engine will handle most user queries pretty well. In a real-life scenario, though, it’s highly unlikely that we could&#13;
     <a id="_idIndexMarker759">&#13;
     </a>&#13;
     fully summarize&#13;
     <a id="_idIndexMarker760">&#13;
     </a>&#13;
     the whole content in a title. In that case, using a document summary instead of the title would&#13;
     <span class="No-Break">&#13;
      be preferable.&#13;
     </span>&#13;
    </p>&#13;
    <h3>&#13;
     Querying multiple documents with SubQuestionQueryEngine&#13;
    </h3>&#13;
    <p>&#13;
     In a real-life scenario involving multiple data sources, as in the previous example, users may&#13;
     <a id="_idIndexMarker761">&#13;
     </a>&#13;
     come up with more complex queries – for example, they may ask for comparisons between different subjects&#13;
     <a id="_idIndexMarker762">&#13;
     </a>&#13;
     documented in different files. For this kind of situation, we can use&#13;
     <code class="literal">&#13;
      SubQuestionQueryEngine&#13;
     </code>&#13;
     . It is designed to handle complex queries by breaking them down into&#13;
     <span class="No-Break">&#13;
      smaller sub-questions.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     Each sub-question is processed by its designated query engine and the individual responses are then combined. A response synthesizer is used to compile these into a coherent final response, effectively managing queries that require a multi-faceted approach.&#13;
     <span class="No-Break">&#13;
      <em class="italic">&#13;
       Figure 7&#13;
      </em>&#13;
     </span>&#13;
     <em class="italic">&#13;
      .5&#13;
     </em>&#13;
     describes&#13;
     <span class="No-Break">&#13;
      its operation:&#13;
     </span>&#13;
    </p>&#13;
    <div>&#13;
     <div class="IMG---Figure" id="_idContainer076">&#13;
      <img src="../Images/B21861_07_5.jpg"/>&#13;
     </div>&#13;
    </div>&#13;
    <p class="IMG---Caption" lang="en-US">&#13;
     Figure 7.5 – How SubQuestionQueryEngine works&#13;
    </p>&#13;
    <p>&#13;
     Let’s have a look at the code. The first part is very similar to our previous example&#13;
     <span class="No-Break">&#13;
      regarding&#13;
     </span>&#13;
     <span class="No-Break">&#13;
      <code class="literal">&#13;
       RouterQueryEngine&#13;
      </code>&#13;
     </span>&#13;
     <span class="No-Break">&#13;
      :&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     After&#13;
     <a id="_idIndexMarker763">&#13;
     </a>&#13;
     importing the necessary&#13;
     <a id="_idIndexMarker764">&#13;
     </a>&#13;
     modules, we load the files and extract&#13;
     <span class="No-Break">&#13;
      their titles:&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     So far, we have completed the same steps that we did for&#13;
     <code class="literal">&#13;
      RouterQueryEngine&#13;
     </code>&#13;
     . One notable change in the next part is that we also extract&#13;
     <code class="literal">&#13;
      file_name&#13;
     </code>&#13;
     from the metadata and use it as a name for the corresponding tool. This way, we’ll be able to tell exactly where each answer is&#13;
     <span class="No-Break">&#13;
      coming from:&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     Next, let’s&#13;
     <a id="_idIndexMarker765">&#13;
     </a>&#13;
     build&#13;
     <span class="No-Break">&#13;
      our&#13;
     </span>&#13;
     <span class="No-Break">&#13;
      <code class="literal">&#13;
       SubQuestionQueryEngine&#13;
      </code>&#13;
     </span>&#13;
     <span class="No-Break">&#13;
      :&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     At this&#13;
     <a id="_idIndexMarker766">&#13;
     </a>&#13;
     point, we’re ready to generate&#13;
     <span class="No-Break">&#13;
      the output:&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     Along with the final response, we’ll be able to see each sub-question generated and its corresponding query engine tool name. In our case, the tool name will correspond to the filename of each&#13;
     <span class="No-Break">&#13;
      source text.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     <code class="literal">&#13;
      SubQuestionQueryEngine&#13;
     </code>&#13;
     is particularly useful for complex queries that cannot be&#13;
     <a id="_idIndexMarker767">&#13;
     </a>&#13;
     addressed directly&#13;
     <a id="_idIndexMarker768">&#13;
     </a>&#13;
     in a single step. It produces great results in cases such as&#13;
     <span class="No-Break">&#13;
      the following:&#13;
     </span>&#13;
    </p>&#13;
    <ul>&#13;
     <li>&#13;
      <strong class="bold">&#13;
       Comparative analysis&#13;
      </strong>&#13;
      : For queries that require comparing and contrasting different subjects, the engine can divide the query into smaller, focused sub-questions to gather detailed information about each subject before synthesizing a comparative response. Here’s a sample question:&#13;
      <em class="italic">&#13;
       Compare and contrast the economic policies of Country A and Country B in the&#13;
      </em>&#13;
      <span class="No-Break">&#13;
       <em class="italic">&#13;
        last decade.&#13;
       </em>&#13;
      </span>&#13;
     </li>&#13;
     <li>&#13;
      <strong class="bold">&#13;
       Multi-faceted questions&#13;
      </strong>&#13;
      : In cases where a query involves multiple aspects or criteria, this engine can break down the query into individual components, handle each separately, and then combine the results for a comprehensive answer. That means questions such as&#13;
      <em class="italic">&#13;
       What are the environmental, economic, and social impacts of deforestation in the&#13;
      </em>&#13;
      <span class="No-Break">&#13;
       <em class="italic">&#13;
        Amazon rainforest?&#13;
       </em>&#13;
      </span>&#13;
     </li>&#13;
     <li>&#13;
      <strong class="bold">&#13;
       Complex research tasks&#13;
      </strong>&#13;
      : For research-oriented queries that require information to be gathered from various sources or perspectives, this engine can efficiently handle the task by segmenting it into more manageable sub-questions. Here’s the type of query it could answer:&#13;
      <em class="italic">&#13;
       Investigate the historical development of renewable energy technologies and their adoption across&#13;
      </em>&#13;
      <span class="No-Break">&#13;
       <em class="italic">&#13;
        different continents.&#13;
       </em>&#13;
      </span>&#13;
     </li>&#13;
    </ul>&#13;
    <p>&#13;
     Now that you’ve got a general understanding of how query engines work, I’ll let you explore the different possibilities and experiment with all the existing query&#13;
     <span class="No-Break">&#13;
      engine modules.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     In case you’re wondering whether you can create custom ones, that option is&#13;
     <span class="No-Break">&#13;
      also available.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     You can find an example&#13;
     <span class="No-Break">&#13;
      here:&#13;
     </span>&#13;
     <span class="No-Break">&#13;
      https://docs.llamaindex.ai/en/stable/examples/query_engine/custom_query_engine.html#option-1-ragqueryengine&#13;
     </span>&#13;
     <span class="No-Break">&#13;
      .&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     Now that we’ve got some fresh knowledge, it’s about time we built some new components into our&#13;
     <span class="No-Break">&#13;
      tutoring project.&#13;
     </span>&#13;
    </p>&#13;
    <a id="_idTextAnchor177">&#13;
    </a>&#13;
   </div>&#13;
  </div>&#13;
 </body>&#13;
</html>
<html>&#13;
 <head>&#13;
  <title>&#13;
   Hands-on – building quizzes in PITS&#13;
  </title>&#13;
 </head>&#13;
 <body>&#13;
  <div class="epub-source">&#13;
   <h1 id="_idParaDest-178">&#13;
    Hands-on – building quizzes in PITS&#13;
   </h1>&#13;
   <div id="_idContainer077">&#13;
    from llama_index.core import load_index_from_storage, StorageContext&#13;
from llama_index.program.evaporate.df import DFRowsProgram&#13;
from llama_index.program.openai import OpenAIPydanticProgram&#13;
from global_settings import INDEX_STORAGE, QUIZ_SIZE, QUIZ_FILE&#13;
import pandas as pd&#13;
    pip install pandas&#13;
    def build_quiz(topic):&#13;
    df = pd.DataFrame({&#13;
        "Question_no": pd.Series(dtype="int"),&#13;
        "Question_text": pd.Series(dtype="str"),&#13;
        "Option1": pd.Series(dtype="str"),&#13;
        "Option2": pd.Series(dtype="str"),&#13;
        "Option3": pd.Series(dtype="str"),&#13;
        "Option4": pd.Series(dtype="str"),&#13;
        "Correct_answer": pd.Series(dtype="str"),&#13;
        "Rationale": pd.Series(dtype="str"),&#13;
    })&#13;
    <p>&#13;
     One of the features we are building in our PITS project is the ability to generate quizzes based on the learning material uploaded by&#13;
     <span class="No-Break">&#13;
      the user.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     These quizzes&#13;
     <a id="_idIndexMarker769">&#13;
     </a>&#13;
     will initially be used to gauge the overall knowledge of the user on the topic. Based on that assessment, the training slides and narration will be adjusted to the level of&#13;
     <span class="No-Break">&#13;
      the learner.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     The same mechanism can also be used to generate intermediate quizzes at the end of each section to test the user’s current knowledge. Let’s see how we can easily implement the quiz&#13;
     <span class="No-Break">&#13;
      builder feature.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     We’ll be using one of the LlamaIndex pre-packaged pydantic programs: the DataFrame Pydantic extractor. This is designed to extract tabular DataFrames from&#13;
     <span class="No-Break">&#13;
      raw text.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     Let’s have a look at the code&#13;
     <span class="No-Break">&#13;
      in&#13;
     </span>&#13;
     <span class="No-Break">&#13;
      <code class="literal">&#13;
       quiz_builder.py&#13;
      </code>&#13;
     </span>&#13;
     <span class="No-Break">&#13;
      :&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     First, we imported all the necessary modules, including our global variables defined&#13;
     <span class="No-Break">&#13;
      in&#13;
     </span>&#13;
     <span class="No-Break">&#13;
      <code class="literal">&#13;
       global_settings.py&#13;
      </code>&#13;
     </span>&#13;
     <span class="No-Break">&#13;
      :&#13;
     </span>&#13;
    </p>&#13;
    <ul>&#13;
     <li>&#13;
      <code class="literal">&#13;
       INDEX_STORAGE&#13;
      </code>&#13;
      : The index’s&#13;
      <span class="No-Break">&#13;
       storage location&#13;
      </span>&#13;
     </li>&#13;
     <li>&#13;
      <code class="literal">&#13;
       QUIZ_SIZE&#13;
      </code>&#13;
      : The number of questions to be included in&#13;
      <span class="No-Break">&#13;
       a quiz&#13;
      </span>&#13;
     </li>&#13;
     <li>&#13;
      <code class="literal">&#13;
       QUIZ_FILE&#13;
      </code>&#13;
      : The path where the quiz will be saved as&#13;
      <span class="No-Break">&#13;
       a CSV&#13;
      </span>&#13;
     </li>&#13;
    </ul>&#13;
    <p>&#13;
     We’re also importing the&#13;
     <code class="literal">&#13;
      load_index_from_storage&#13;
     </code>&#13;
     function, which we will use to fetch our indexes from storage to avoid the cost and time of&#13;
     <span class="No-Break">&#13;
      rebuilding them.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     Because we’re using DataFrames, we’ll also need to import the pandas library. If you don’t have it already installed in your environment, make sure you run&#13;
     <span class="No-Break">&#13;
      this first:&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     OK – let’s build&#13;
     <a id="_idIndexMarker770">&#13;
     </a>&#13;
     our main function. The&#13;
     <code class="literal">&#13;
      build_quiz&#13;
     </code>&#13;
     function will be responsible for generating the quiz and saving the questions in a&#13;
     <code class="literal">&#13;
      CSV&#13;
     </code>&#13;
     file for&#13;
     <span class="No-Break">&#13;
      further use:&#13;
     </span>&#13;
    </p>&#13;
    <ol>&#13;
     <li>&#13;
      First, we set up a DataFrame to structure the quiz questions and their associated options and answers. This DataFrame will serve as the foundation for our quiz. It includes columns for the question number, question text, four answer options, the correct answer, and a rationale for the answer. The use of a pandas DataFrame will make handling and manipulating the quiz data&#13;
      <span class="No-Break">&#13;
       much easier.&#13;
      </span>&#13;
     </li>&#13;
     <li>&#13;
      Next, we need to load our vector index from storage. To do this, we must define a&#13;
      <code class="literal">&#13;
       StorageContext&#13;
      </code>&#13;
      object while using the&#13;
      <code class="literal">&#13;
       INDEX_STORAGE&#13;
      </code>&#13;
      folder as&#13;
      <span class="No-Break">&#13;
       a parameter:&#13;
      </span>&#13;
      <pre class="source-code">    storage_context = StorageContext.from_defaults(&#13;
        persist_dir=INDEX_STORAGE&#13;
    )&#13;
    vector_index = load_index_from_storage(&#13;
        storage_context, index_id="vector"&#13;
    )</pre>&#13;
     </li>&#13;
     <li>&#13;
      Here, we used&#13;
      <code class="literal">&#13;
       index_id&#13;
      </code>&#13;
      to identify the&#13;
      <em class="italic">&#13;
       vector&#13;
      </em>&#13;
      index because there’s also a&#13;
      <code class="literal">&#13;
       TreeIndex&#13;
      </code>&#13;
      index in that storage that we won’t be using for now. It’s time to initialize our&#13;
      <span class="No-Break">&#13;
       <code class="literal">&#13;
        DataFrame&#13;
       </code>&#13;
      </span>&#13;
      <span class="No-Break">&#13;
       extractor:&#13;
      </span>&#13;
      <pre class="source-code">    df_rows_program = DFRowsProgram.from_defaults(&#13;
        pydantic_program_cls=OpenAIPydanticProgram,&#13;
        df=df&#13;
    )</pre>&#13;
     </li>&#13;
     <li>&#13;
      Now, we can&#13;
      <a id="_idIndexMarker771">&#13;
      </a>&#13;
      define our query engine and craft a prompt that will generate the&#13;
      <span class="No-Break">&#13;
       quiz questions:&#13;
      </span>&#13;
      <pre class="source-code">    query_engine = vector_index.as_query_engine()&#13;
    quiz_query = (&#13;
        f"Create {QUIZ_SIZE} different quiz "&#13;
        "questions relevant for testing "&#13;
        "a candidate's knowledge about "&#13;
        f"{topic}. Each question will have 4 "&#13;
        "answer options. Questions must be "&#13;
        "general topic-related, not specific "&#13;
        "to the provided text. For each "&#13;
        "question, provide also the correct "&#13;
        "answer and the answer rationale. "&#13;
        "The rationale must not make any "&#13;
        "reference to the provided context, "&#13;
        "any exams or the topic name. Only "&#13;
        "one answer option should be correct."&#13;
    )&#13;
    response = query_engine.query(quiz_query)</pre>&#13;
     </li>&#13;
     <li>&#13;
      Next, the prompt&#13;
      <a id="_idIndexMarker772">&#13;
      </a>&#13;
      is passed to the query engine, and the response is then processed by&#13;
      <code class="literal">&#13;
       DFRowsProgram&#13;
      </code>&#13;
      to convert it into a structured&#13;
      <span class="No-Break">&#13;
       DataFrame format:&#13;
      </span>&#13;
      <pre class="source-code">    result_obj = df_rows_program(input_str=response)&#13;
    new_df = result_obj.to_df(existing_df=df)&#13;
    new_df.to_csv(QUIZ_FILE, index=False)&#13;
    return new_df</pre>&#13;
     </li>&#13;
     <li>&#13;
      Finally, the new DataFrame containing the quiz questions is saved as a CSV file in the path defined by&#13;
      <code class="literal">&#13;
       QUIZ_FILE&#13;
      </code>&#13;
      . The function returns the new DataFrame for&#13;
      <span class="No-Break">&#13;
       further use.&#13;
      </span>&#13;
     </li>&#13;
    </ol>&#13;
    <p>&#13;
     This serves as a simple demonstration of how to leverage a combination of LlamaIndex features, Pydantic programs, and DataFrame manipulation to create a dynamic quiz generator. We’ll continue working on the rest of the features in&#13;
     <span class="No-Break">&#13;
      future chapters.&#13;
     </span>&#13;
    </p>&#13;
    <a id="_idTextAnchor178">&#13;
    </a>&#13;
   </div>&#13;
  </div>&#13;
 </body>&#13;
</html>
<html>&#13;
 <head>&#13;
  <title>&#13;
   Summary&#13;
  </title>&#13;
 </head>&#13;
 <body>&#13;
  <div class="epub-source">&#13;
   <h1 id="_idParaDest-179">&#13;
    Summary&#13;
   </h1>&#13;
   <div id="_idContainer077">&#13;
    <p>&#13;
     This chapter explored how to refine search results with various postprocessors, generate responses using different synthesizers, and ensure structured outputs with&#13;
     <span class="No-Break">&#13;
      specific parsers.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     We also explored how to construct query engines while integrating the various components that we discussed in the&#13;
     <span class="No-Break">&#13;
      previous chapters.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     This chapter also covered handling diverse data sources with&#13;
     <code class="literal">&#13;
      RouterQueryEngine&#13;
     </code>&#13;
     and decomposing complex queries with&#13;
     <code class="literal">&#13;
      SubQuestionQueryEngine&#13;
     </code>&#13;
     , and also demonstrated quiz creation in our&#13;
     <span class="No-Break">&#13;
      tutoring app.&#13;
     </span>&#13;
    </p>&#13;
    <p>&#13;
     See you in the next chapter, where we’ll talk about chatbots, agents, and conversation tracking&#13;
     <span class="No-Break">&#13;
      with LlamaIndex.&#13;
     </span>&#13;
    </p>&#13;
   </div>&#13;
  </div>&#13;
 </body>&#13;
</html></body></html>