- en: '9'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '9'
- en: Managing Safety and Ethical Considerations
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 管理安全和伦理考量
- en: In the previous chapter, we explored the pivotal role of trust in facilitating
    the successful adoption and acceptance of generative AI systems. We examined ways
    to foster trust, highlighting the role of transparency, explainability, addressing
    biases and uncertainties, and clear communication of AI outputs to improve user
    understanding and confidence. As generative AI technologies rapidly advance, fueled
    by immense interest and excitement across diverse domains from creative industries
    to healthcare, a sense of urgency has arisen to address the safety and ethical
    implications of these powerful systems. The discussion now turns to potential
    risks and challenges associated with generative AI, strategies for safe and responsible
    deployment, ethical guidelines, and considerations regarding privacy and security.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们探讨了信任在促进生成式人工智能系统成功采用和接受中的关键作用。我们研究了培养信任的方法，强调了透明度、可解释性、解决偏见和不确定性以及清晰传达人工智能输出以提升用户理解和信心的作用。随着生成式人工智能技术的快速发展，受到从创意产业到医疗保健等众多领域的巨大兴趣和热情的推动，迫切需要解决这些强大系统的安全和伦理影响。现在的讨论转向了与生成式人工智能相关的潜在风险和挑战，包括安全且负责任部署的策略、伦理指南以及关于隐私和安全的考虑。
- en: 'The remarkable capabilities of generative AI systems have sparked both awe
    and concern, highlighting the need for a proactive approach to mitigating potential
    risks and ensuring responsible development and deployment. While these technologies
    hold immense potential for driving innovation and positive change, their misuse
    or unintended consequences could have far-reaching implications. This chapter
    is divided into the following main sections:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式人工智能系统的非凡能力既引发了敬畏，也引发了担忧，突显了采取积极措施减轻潜在风险和确保负责任开发和部署的必要性。虽然这些技术具有推动创新和积极变革的巨大潜力，但它们的误用或意外后果可能产生深远的影响。本章分为以下主要部分：
- en: Understanding potential risks and challenges
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解潜在风险和挑战
- en: Ensuring safe and responsible AI
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保安全且负责任的人工智能
- en: Exploring ethical guidelines and frameworks
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索伦理指南和框架
- en: Addressing privacy and security concerns
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解决隐私和安全问题
- en: By the end of this chapter, you will understand the key risks and challenges
    of generative AI, including misinformation and bias concerns, know strategies
    for safe deployment, and have gained insight into crucial ethical considerations
    around privacy and data protection. You will also discover frameworks and guidelines
    for responsible AI development that balance innovation with societal well-being.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将了解生成式人工智能的关键风险和挑战，包括虚假信息和偏见问题，了解安全部署的策略，并深入了解关于隐私和数据保护的至关重要伦理考量。你还将发现平衡创新与社会福祉的负责任人工智能开发的框架和指南。
- en: Understanding potential risks and challenges
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解潜在风险和挑战
- en: The landscape of AI has evolved significantly with the emergence of **large
    language models** ( **LLMs** ) that power both generative AI and agentic systems.
    While generative AI focuses primarily on creating content based on prompts and
    patterns, agentic systems built on these same LLMs take this capability further
    by incorporating decision-making, planning, and goal-oriented behavior. This combination
    of generative capabilities with agency creates a powerful but potentially risky
    synergy.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 随着大型语言模型（LLMs）的出现，人工智能的格局发生了显著变化，这些模型既推动了生成式人工智能，也推动了代理系统的发展。虽然生成式人工智能主要关注根据提示和模式创建内容，但建立在相同LLMs之上的代理系统通过融入决策、规划和目标导向的行为，将这一能力进一步扩展。这种生成能力与代理的结合创造了一种强大但可能具有风险的协同效应。
- en: Agentic systems leverage the generative capabilities of LLMs to not just produce
    content but also to actively analyze situations, formulate strategies, and take
    action toward specific objectives. This means that any inherent risks in generative
    AI systems – such as biases, hallucinations, or the generation of misleading information
    – become particularly critical when the system is empowered to act autonomously
    or semi-autonomously based on this generated content.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 代理系统利用大型语言模型（LLMs）的生成能力，不仅能够生成内容，还能主动分析情况、制定策略并采取行动以实现特定目标。这意味着生成式人工智能系统内固有的风险，如偏见、幻觉或生成误导性信息，当系统根据这些生成内容自主或半自主地行动时，变得尤为重要。
- en: Generative AI systems are powered by massive language models, which, while incredibly
    powerful, also exhibit a range of vulnerabilities and risks. These risks can be
    broadly classified into the following key areas.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式人工智能系统由大规模语言模型驱动，虽然功能强大，但也表现出各种漏洞和风险。这些风险可以大致分为以下关键领域。
- en: Adversarial attacks
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对抗性攻击
- en: One of the significant risks associated with generative AI systems is their
    susceptibility to adversarial attacks. Malicious individuals can exploit flaws
    in these systems by crafting carefully designed inputs or perturbations that corrupt
    the data in a way that leads to harmful outputs or extracts confidential information.
    These adversarial attacks can have serious consequences, such as data breaches,
    unauthorized access to sensitive information, or the generation of malicious or
    misleading content.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 与生成式人工智能系统相关的一个显著风险是它们容易受到对抗性攻击。恶意个人可以通过精心设计的输入或扰动来利用这些系统的缺陷，以破坏数据，导致有害的输出或提取机密信息。这些对抗性攻击可能产生严重的后果，如数据泄露、未经授权访问敏感信息或生成恶意或误导性内容。
- en: When these vulnerabilities extend to agentic systems, the risks become even
    more pronounced as these systems not only generate responses but also execute
    actions based on their understanding. An adversarial attack on an agentic system
    could potentially manipulate its decision-making process, causing it to take harmful
    actions or make dangerous choices autonomously. For instance, an agentic system
    managing supply chain operations could be tricked into making catastrophic inventory
    decisions, or a trading agent could be manipulated into executing harmful financial
    transactions.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 当这些漏洞扩展到代理系统时，风险变得更加明显，因为这些系统不仅生成响应，而且根据其理解执行行动。对代理系统的对抗性攻击可能会操纵其决策过程，导致其自主采取有害行动或做出危险选择。例如，管理供应链运营的代理系统可能会被诱骗做出灾难性的库存决策，或者交易代理可能会被操纵执行有害的金融交易。
- en: In the travel industry, consider a scenario where an agentic AI system is used
    by a travel agency to not only provide personalized travel recommendations but
    also to automatically book flights, hotels, and activities. An adversarial attack
    on such a system could potentially lead to disastrous consequences. Beyond just
    recommending unsafe destinations, the system could actively make bookings in dangerous
    areas, confirm reservations with fraudulent providers, or execute financial transactions
    that compromise clients’ security.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在旅游行业中，考虑这样一个场景：一家旅行社使用一个代理人工智能系统，不仅提供个性化的旅游推荐，还能自动预订航班、酒店和活动。对这样一个系统进行对抗性攻击可能会带来灾难性的后果。除了推荐不安全的旅游目的地外，该系统可能会主动在危险地区进行预订，与欺诈性供应商确认预订，或者执行可能损害客户安全的金融交易。
- en: Additionally, adversarial attacks could be used to extract sensitive information,
    such as customer travel histories, credit card details, or personal preferences,
    from the system. This risk is amplified in agentic systems because they often
    have broader access to execute transactions and make decisions, potentially exposing
    more sensitive data and control points to attackers.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，对抗性攻击还可以用来从系统中提取敏感信息，例如客户旅游历史、信用卡详情或个人偏好。在代理系统中，这种风险被放大，因为它们通常有更广泛的访问权限来执行交易和做出决策，可能将更多敏感数据和控制点暴露给攻击者。
- en: Real-world examples of adversarial attacks on AI systems have already been documented.
    In 2017, researchers demonstrated how minor perturbations to images could fool
    state-of-the-art computer vision models into misclassifying objects, such as a
    stop sign being recognized as a speed limit sign. Similarly, in the natural language
    processing domain, researchers have shown how carefully crafted input sequences
    can cause language models to generate harmful or inappropriate content. When these
    vulnerabilities are exploited in agentic systems, the impact could extend beyond
    content generation to actual real-world actions and decisions.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 已经有关于对人工智能系统进行对抗性攻击的实际情况被记录下来。2017年，研究人员展示了如何对图像进行微小的扰动，使最先进的计算机视觉模型误分类对象，例如将停车标志识别为限速标志。同样，在自然语言处理领域，研究人员已经展示了精心设计的输入序列如何导致语言模型生成有害或不适当的内容。当这些漏洞在代理系统中被利用时，影响可能会从内容生成扩展到实际的现实世界行动和决策。
- en: Similarly, in a medical context, an adversarial attack on an agentic AI system
    used for diagnosis or treatment recommendations could potentially lead to life-threatening
    errors or data leaks. Imagine a scenario where an adversarial input causes the
    AI to not only misdiagnose a condition but also automatically schedule incorrect
    treatments, order wrong medications, or make dangerous adjustments to medical
    devices under its control.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，在医疗环境中，对用于诊断或治疗建议的代理人工智能系统的对抗性攻击可能导致危及生命的安全错误或数据泄露。想象一下这样的场景：一个对抗性输入不仅导致AI误诊某种状况，还自动安排错误的治疗方案，订购错误的药物，或对其控制的医疗设备进行危险调整。
- en: These examples highlight the severe consequences that adversarial attacks can
    have on both generative and agentic AI systems, underscoring the importance of
    robust security measures and ongoing research into defense mechanisms against
    such attacks. Techniques such as adversarial training, input sanitization, and
    anomaly detection can help mitigate the risks, but it is an ongoing challenge
    that requires vigilance and collaboration within the AI community. For agentic
    systems, additional safeguards such as action verification, decision auditing,
    and multi-step authentication processes become crucial to prevent malicious exploitation
    of their autonomous capabilities.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这些例子突出了对抗性攻击对生成式和代理人工智能系统可能产生的严重后果，强调了采取强大安全措施和持续研究防御机制的重要性。如对抗性训练、输入净化和异常检测等技术可以帮助减轻风险，但这是一个需要警惕和AI社区内协作的持续挑战。对于代理系统，采取额外的安全措施，如行动验证、决策审计和多步骤身份验证过程，对于防止恶意利用其自主能力至关重要。
- en: Bias and discrimination
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 偏见与歧视
- en: We are aware that generative AI models are trained on vast datasets that may
    carry inherent biases and historical prejudices. When these models form the foundation
    for agentic systems, the implications of bias become even more critical as these
    systems not only generate content but also make autonomous decisions that can
    directly impact people’s lives.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道，生成式人工智能模型是在可能包含固有偏见和历史偏见的庞大数据集上训练的。当这些模型成为代理系统的基础时，偏见的含义变得更加关键，因为这些系统不仅生成内容，还做出可能直接影响人们生活的自主决策。
- en: The issue of bias in AI systems has been a long-standing concern, and both generative
    AI models and the agentic systems built upon them are susceptible to this challenge.
    These models learn from their training data, and if that data contains biases
    or reflects societal prejudices, the AI will inevitably absorb and perpetuate
    those biases not just in its outputs but in its decision-making processes and
    actions too.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能系统中的偏见问题一直是长期关注的问题，生成式人工智能模型以及建立在它们之上的代理系统都容易受到这一挑战。这些模型从其训练数据中学习，如果这些数据包含偏见或反映社会偏见，AI不可避免地会吸收并延续这些偏见，不仅在其输出中，也在其决策过程和行动中。
- en: For instance, consider an agentic AI system used not just for screening job
    candidates but also for making autonomous hiring decisions, scheduling interviews,
    and managing employee assignments. If biased, such a system could systematically
    discriminate against certain demographic groups throughout the entire employment
    life cycle, from initial screening to promotion decisions. This automated perpetuation
    of bias could be particularly harmful as it operates at scale and may be harder
    to detect than human bias.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑一个不仅用于筛选求职候选人，还用于做出自主招聘决策、安排面试和管理员工分配的代理人工智能系统。如果存在偏见，这样的系统可能会在整个就业生命周期中系统地歧视某些人口群体，从最初的筛选到晋升决策。这种自动化的偏见延续可能特别有害，因为它在规模上运作，可能比人类偏见更难检测。
- en: In the travel industry, bias in agentic AI systems could manifest beyond mere
    recommendations to actual booking decisions and resource allocations. An autonomous
    travel management system might systematically direct certain demographic groups
    to specific neighborhoods or price ranges, effectively implementing digital redlining.
    It might also autonomously negotiate different rates or terms for different users
    based on biased assumptions, creating a form of algorithmic discrimination in
    pricing and service delivery.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在旅游行业中，代理人工智能系统中的偏见可能不仅体现在简单的推荐上，还可能体现在实际的预订决策和资源分配上。一个自主的旅游管理系统可能会系统地引导某些人口群体前往特定的社区或价格区间，实际上实施数字红线政策。它还可能根据有偏见的假设，为不同的用户自动协商不同的费率或条款，从而在定价和服务交付中创造一种算法歧视形式。
- en: In 2018, researchers found that commercial facial recognition systems exhibited
    higher error rates for identifying women and people with darker skin tones. When
    such biased systems are integrated into agentic AI that controls access to buildings,
    financial services, or healthcare resources, these technical shortcomings transform
    into systemic barriers that actively restrict opportunities and services for certain
    groups.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 2018年，研究人员发现，商业面部识别系统在识别女性和肤色较深的人时表现出更高的错误率。当这样的有偏系统被集成到控制建筑、金融服务或医疗资源访问的代理式AI中时，这些技术缺陷转变为系统性的障碍，积极限制某些群体的机会和服务。
- en: Addressing bias in agentic AI systems requires an expanded approach beyond what’s
    needed for traditional generative AI. While diverse training data and debiasing
    algorithms remain important, additional measures are needed to ensure fairness
    in autonomous decision-making. This includes implementing decision auditing systems,
    creating accountability frameworks for autonomous actions, and developing real-time
    bias detection mechanisms that can intervene before discriminatory actions are
    taken.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 解决代理式AI系统中的偏见需要一种超越传统生成式AI所需方法的扩展方法。虽然多样化的训练数据和去偏算法仍然很重要，但仍需要采取额外措施来确保自主决策的公平性。这包括实施决策审计系统、创建自主行动的责任框架，以及开发能够在采取歧视性行动之前进行干预的实时偏见检测机制。
- en: Moreover, involving diverse stakeholders becomes even more crucial when developing
    agentic systems, as these stakeholders can help identify potential negative impacts
    across the full range of autonomous actions the system might take. Regular audits
    of not just the system’s outputs but also its decision-making patterns and action
    histories are essential for detecting and correcting systematic biases.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，在开发代理式系统时，涉及多样化的利益相关者变得更加关键，因为这些利益相关者可以帮助识别系统可能采取的全面自主行动中的潜在负面影响。不仅对系统的输出进行定期审计，还要对其决策模式和行动历史进行审计，这对于检测和纠正系统性偏见至关重要。
- en: By proactively addressing biases in both generative and agentic AI systems,
    organizations can ensure these technologies serve as tools for promoting equity
    rather than reinforcing discrimination. This is particularly critical for agentic
    systems, as their ability to autonomously act on biased assumptions can multiply
    the harmful effects of discrimination and create self-reinforcing cycles of inequity.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 通过积极解决生成式和代理式AI系统中的偏见，组织可以确保这些技术作为促进公平的工具，而不是强化歧视的手段。这对于代理式系统尤其关键，因为它们自主行动于有偏见的假设的能力可能会放大歧视的有害影响，并创造自我强化的不平等循环。
- en: Misinformation and hallucinations
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 错误信息和幻觉
- en: Generative AI systems have a tendency to produce information that may be factually
    incorrect or inconsistent with reality, a phenomenon known as **hallucination**
    . When these systems are integrated into autonomous agents, the implications become
    even more serious, as hallucinated information can directly influence real-world
    decisions and actions taken by the agent. The hallucination problem in both generative
    and agentic AI systems stems from their underlying architecture. While incredibly
    powerful, these models lack a true understanding of the world and cannot reliably
    distinguish between factual information and fabricated content. In agentic systems,
    this limitation is particularly concerning because the agent may act upon hallucinated
    information without human verification, potentially causing cascading errors or
    harmful decisions.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI系统倾向于产生可能事实错误或与现实不符的信息，这种现象被称为**幻觉**。当这些系统被集成到自主代理中时，其影响变得更加严重，因为幻觉信息可以直接影响代理在现实世界中的决策和行动。生成式和代理式AI系统中的幻觉问题源于其底层架构。虽然这些模型非常强大，但它们缺乏对世界的真正理解，无法可靠地区分事实信息和虚构内容。在代理式系统中，这种限制尤其令人担忧，因为代理可能会在没有人类验证的情况下根据幻觉信息采取行动，可能导致连锁错误或有害决策。
- en: In the realm of autonomous decision-making, an agentic system that hallucinates
    could take actions based on non-existent information or false assumptions. For
    instance, an autonomous trading agent might execute large financial transactions
    based on hallucinated market trends, or a healthcare management agent might schedule
    treatments based on incorrectly generated medical histories. These scenarios are
    far more dangerous than simple content generation errors, as they involve direct
    real-world consequences.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在自主决策领域，一个产生幻觉的代理系统可能会基于不存在的信息或错误的假设采取行动。例如，一个自主交易代理可能会根据幻觉的市场趋势执行大规模的金融交易，或者一个医疗管理代理可能会根据错误生成的医疗历史安排治疗。这些场景比简单的内容生成错误危险得多，因为它们涉及直接的现实世界后果。
- en: For example, consider an agentic AI system deployed in emergency response management.
    If the system hallucinates information about the severity or location of an emergency,
    it could autonomously dispatch resources to the wrong location or make inappropriate
    response decisions, potentially putting lives at risk. Unlike a generative system
    that merely produces incorrect text, an agentic system’s hallucinations can lead
    to immediate, real-world actions with serious consequences.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑一个部署在应急响应管理中的代理AI系统。如果系统幻觉有关紧急情况的严重性或位置的信息，它可能会自动将资源派遣到错误的位置或做出不适当的响应决策，这可能会危及生命。与仅产生错误文本的生成式系统不同，代理系统的幻觉可能导致立即的、具有严重后果的现实世界行动。
- en: In the travel industry, hallucinations in agentic AI systems could go beyond
    just providing incorrect information – they could result in actual bookings being
    made based on non-existent flights or hotels, autonomous rerouting of travelers
    based on hallucinated weather conditions, or emergency evacuations triggered by
    fabricated security threats.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在旅游行业中，具有代理能力的AI系统中的幻觉可能不仅仅提供错误信息——它们可能导致基于不存在的航班或酒店的预订，根据幻觉的天气条件自动重新规划旅客路线，或者由虚构的安全威胁触发的紧急疏散。
- en: Real-world examples of hallucinations in AI systems have been documented across
    various domains. In 2022, researchers found that large language models such as
    GPT-3 can produce *hallucinated* scientific claims that sound plausible but are
    entirely fabricated. For agentic systems built on these models, such hallucinations
    could lead to automated decisions in research resource allocation, experimental
    design, or data analysis that could compromise scientific integrity.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: AI系统中幻觉的现实世界例子已经在各个领域得到记录。2022年，研究人员发现，像GPT-3这样的大型语言模型可以产生听起来合理但实际上是虚构的*幻觉*科学主张。对于建立在这些模型之上的代理系统，这种幻觉可能导致在研究资源分配、实验设计或数据分析中的自动化决策，这可能会损害科学诚信。
- en: Addressing hallucinations in agentic AI systems requires additional safeguards
    beyond those used for generative AI. While fact-checking and knowledge grounding
    remain important, agentic systems also need real-time verification mechanisms,
    action validation protocols, and fallback procedures for cases where information
    reliability is uncertain. Moreover, implementing *uncertainty-aware* decision-making
    processes that can appropriately handle cases where the agent is not confident
    about its information is crucial.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理具有代理能力的AI系统中的幻觉问题时，需要比用于生成式AI的额外安全措施。尽管事实核查和知识扎根仍然很重要，但代理系统还需要实时验证机制、行动验证协议以及信息可靠性不确定情况下的回退程序。此外，实施*不确定性感知*的决策过程，以便适当地处理代理对其信息缺乏信心的情况是至关重要的。
- en: When deploying agentic systems, organizations must implement robust monitoring
    systems that can detect and prevent actions based on hallucinated information
    before they occur. This might include multi-step verification processes for critical
    decisions, confidence thresholds for autonomous actions, and human oversight mechanisms
    for high-stakes situations. By proactively addressing hallucinations in agentic
    AI systems, organizations can better ensure that autonomous agents make decisions
    based on reliable information. This is particularly critical as these systems
    become more prevalent in domains where incorrect actions could have significant
    consequences for safety, security, or business operations.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 当部署代理系统时，组织必须实施强大的监控系统，能够在发生之前检测和预防基于幻觉信息的行为。这可能包括对关键决策的多步骤验证流程、自主行动的置信度阈值以及用于高风险情况的人类监督机制。通过积极解决代理AI系统中的幻觉，组织可以更好地确保自主代理基于可靠信息做出决策。这对于这些系统在错误行动可能对安全、安全或业务运营产生重大后果的领域变得更加普遍尤为重要。
- en: Data privacy violations
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据隐私违规
- en: Generative AI models are trained on vast amounts of data, which may inadvertently
    include **personally identifiable information** ( **PII** ) or sensitive data.
    In agentic systems, this risk is compounded because these systems not only process
    and generate information but also actively access, manipulate, and make decisions
    about personal data as part of their autonomous operations.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI模型在大量数据上进行训练，这些数据可能无意中包括**个人可识别信息**（**PII**）或敏感数据。在代理系统中，这种风险被放大，因为这些系统不仅处理和生成信息，还作为其自主操作的一部分，积极访问、操作和做出关于个人数据的决策。
- en: The sheer volume of data required to train and operate these systems increases
    the likelihood of privacy violations. For agentic systems, this risk extends beyond
    training data to include operational data that they actively collect and use,
    such as user interactions, transaction histories, and real-time behavioral data
    that helps them make decisions.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 训练和运行这些系统所需的数据量巨大，增加了隐私违规的可能性。对于代理系统，这种风险不仅限于训练数据，还包括它们积极收集和使用的数据，例如用户交互、交易历史和帮助它们做出决策的实时行为数据。
- en: For example, an agentic AI system in healthcare might not only have access to
    historical medical records for training but also actively manage patient scheduling,
    treatment plans, and medical device settings. If such a system mishandles private
    information, it could autonomously share sensitive medical details with unauthorized
    parties, schedule appointments that reveal confidential conditions, or make treatment
    decisions that inadvertently expose protected health information.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，一个医疗保健领域的代理AI系统可能不仅能够访问用于训练的历史医疗记录，还可能积极管理患者预约、治疗方案和医疗设备设置。如果这样的系统处理不当私人信息，它可能会自主地将敏感医疗细节与未经授权的第三方共享，安排泄露机密状况的预约，或做出无意中暴露受保护健康信息的治疗决策。
- en: In the travel industry, privacy violations could occur when agentic systems
    go beyond simple data exposure to actively making privacy-compromising decisions.
    An autonomous travel assistant might not just leak travel itineraries but could
    also make bookings that reveal sensitive personal information, automatically share
    location data with third parties, or create patterns of behavior that expose confidential
    business travel or personal relationships. The risks became evident in 2019 when
    OpenAI’s language model was found to have memorized and reproduced portions of
    its training data such as personal information like emails, home addresses, and
    phone numbers. For agentic systems, similar issues could lead to automated decisions
    being made based on memorized private information, potentially causing systematic
    privacy violations at scale.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在旅游行业，当代理系统超越简单的数据暴露并积极做出损害隐私的决策时，可能会发生隐私违规。一个自主旅行助手不仅可能泄露旅行计划，还可能做出泄露敏感个人信息的预订，自动与第三方共享位置数据，或创建暴露机密商务旅行或个人关系的模式。这种风险在2019年变得明显，当时OpenAI的语言模型被发现记住了并重新产生了其训练数据的一部分，如电子邮件、家庭地址和电话号码等个人信息。对于代理系统，类似的问题可能导致基于记忆的私人信息的自动化决策，可能在大规模上导致系统性的隐私违规。
- en: Addressing data privacy violations in agentic AI systems requires an enhanced
    approach beyond traditional generative AI safeguards. While robust data governance
    and sanitization remain crucial, agentic systems also need real-time privacy monitoring,
    decision auditing systems, and automatic privacy-preserving mechanisms that prevent
    unauthorized data access or sharing during autonomous operations. Additionally,
    techniques such as differential privacy must be adapted for dynamic decision-making
    scenarios. Organizations need to implement privacy-aware decision protocols that
    ensure autonomous actions don’t inadvertently reveal sensitive information through
    patterns of behavior or chains of decisions, even when individual actions appear
    privacy-compliant.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 解决代理人工智能系统中的数据隐私违规问题需要超越传统生成式人工智能保障的增强方法。虽然稳健的数据治理和净化仍然至关重要，但代理系统还需要实时隐私监控、决策审计系统和自动隐私保护机制，以防止在自主操作期间未经授权的数据访问或共享。此外，差分隐私等技术必须适应动态决策场景。组织需要实施隐私感知决策协议，确保自主行动不会无意中通过行为模式或决策链泄露敏感信息，即使个别行动看似符合隐私合规。
- en: 'To safeguard privacy in these systems, new frameworks must extend beyond traditional
    data protection measures. Teams deploying agentic AI need to scrutinize how autonomous
    decisions could compromise privacy across time – watching for subtle patterns
    that might reveal sensitive information through a series of seemingly innocent
    actions. This means rethinking privacy from the ground up: privacy isn’t just
    about protecting data anymore, but about understanding how chains of autonomous
    decisions could inadvertently reveal what should stay hidden.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 为了保护这些系统中的隐私，新的框架必须超越传统的数据保护措施。部署代理人工智能的团队需要仔细审查自主决策如何随着时间的推移损害隐私——寻找可能通过一系列看似无辜的行为揭示敏感信息的微妙模式。这意味着从根本上重新思考隐私：隐私不再仅仅是保护数据，而是理解如何通过一系列自主决策无意中揭示本应保持隐藏的信息。
- en: The most successful deployments of agentic AI will likely be those that make
    privacy an integral part of their system’s “nervous system” rather than an afterthought.
    This means building systems that instinctively protect privacy at every decision
    point, much like how humans naturally modulate their behavior to protect sensitive
    information in different contexts. When privacy becomes part of the agent’s core
    decision-making process rather than just a compliance checkbox, we can better
    ensure these powerful systems enhance rather than endanger our privacy rights
    in an increasingly automated world.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 最成功的代理人工智能部署可能是那些将隐私视为其系统“神经系统”不可或缺部分的部署，而不是事后考虑。这意味着构建在每一个决策点本能地保护隐私的系统，就像人类在不同的情境下自然调节自己的行为以保护敏感信息一样。当隐私成为代理的核心决策过程的一部分，而不仅仅是合规的勾选框时，我们才能更好地确保这些强大的系统在日益自动化的世界中增强而不是危害我们的隐私权。
- en: Intellectual property risks
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 知识产权风险
- en: The integration of generative AI capabilities into agentic systems introduces
    complex intellectual property challenges that go far beyond traditional content
    generation concerns. When autonomous agents are empowered to not only create content
    but also make decisions about how to use, modify, and deploy intellectual property,
    the stakes become significantly higher.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 将生成式人工智能能力集成到代理系统中引入了复杂的知识产权挑战，这些挑战远远超出了传统内容生成问题的范畴。当自主代理不仅能够创建内容，还能够就如何使用、修改和部署知识产权做出决策时，风险显著增加。
- en: The increasing use of autonomous agents in content generation raises significant
    concerns about **intellectual property** ( **IP** ) infringement, necessitating
    robust detection and mitigation strategies. AI-generated content tracking systems
    such as *Copyleaks* for plagiarism detection, Google’s *SynthID* for watermarking
    AI-generated images, and *Truepic* for verifying digital authenticity help identify
    unauthorized use of copyrighted material. Dataset auditing tools such as Hugging
    Face’s *Dataset Card Standard* , LAION’s transparency efforts, and Adobe’s **Content
    Authenticity Initiative** ( **CAI** ) ensure that datasets used by autonomous
    agents comply with licensing and provenance requirements. Automated copyright
    violation detection services, including Microsoft’s *Azure Content Moderator*
    , *Amazon Rekognition* for identifying copyrighted images and logos, and Meta’s
    *Rights Manager* for monitoring IP violations across social platforms, further
    enhance compliance efforts. Additionally, legal and policy compliance frameworks,
    such as *WIPO PROOF* for timestamping IP ownership (now discontinued), IBM’s *AI
    Governance Toolkit* for assessing infringement risks, and OpenAI’s licensing agreements
    that impose API-level restrictions, provide structured safeguards against IP violations.
    By integrating these methodologies, organizations can ensure that autonomous agents
    operate within ethical and legal boundaries, minimizing the risks associated with
    unauthorized content generation and distribution.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在内容生成中越来越多地使用自主代理引发了关于**知识产权**（**IP**）侵权的重要担忧，需要强大的检测和缓解策略。如用于抄袭检测的*Copyleaks*、用于水印AI生成图像的谷歌的*SynthID*和用于验证数字真实性的*Truepic*等AI生成内容跟踪系统有助于识别未经授权使用受版权保护的材料。如Hugging
    Face的*Dataset Card Standard*、LAION的透明度努力和Adobe的**内容真实性倡议**（**CAI**）等数据集审计工具确保自主代理使用的数据集符合许可和来源要求。包括微软的*Azure内容审核器*、用于识别受版权保护图像和标志的*Amazon
    Rekognition*和Meta的*版权经理*等用于监控社交平台上的知识产权违规行为的自动版权违规检测服务进一步增强了合规性工作。此外，如用于时间戳知识产权所有权的*WIPO
    PROOF*（现已停用）、用于评估侵权风险的IBM的*AI治理工具包*和OpenAI的施加API级别限制的许可协议等法律和政策合规框架，为知识产权违规提供了结构化的保障措施。通过整合这些方法，组织可以确保自主代理在道德和法律边界内运行，最大限度地降低未经授权的内容生成和分发相关的风险。
- en: The fundamental challenge stems from both the training and operational aspects
    of these systems. During training, agentic AI systems, like their generative counterparts,
    ingest vast amounts of potentially copyrighted material – from code and design
    files to creative works and proprietary business processes. But unlike purely
    generative systems, agents can actively implement this learned information in
    ways that could systematically violate intellectual property rights at scale and
    at machine speed.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 基本挑战源于这些系统的训练和运营方面。在训练过程中，像其生成性对应物一样，代理人工智能系统会摄取大量可能受版权保护的材料——从代码和设计文件到创意作品和专有商业流程。但与纯粹生成性系统不同，代理可以主动以可能系统性地违反知识产权的方式实施所学习的信息，并且以机器速度进行大规模操作。
- en: Consider an autonomous software development agent that doesn’t just suggest
    code snippets but actively writes and deploys applications. Such a system might
    inadvertently incorporate proprietary algorithms or protected code patterns across
    thousands of projects before any violation is detected. Similarly, in creative
    industries, an agentic system managing content production could autonomously remix
    and repurpose copyrighted materials in ways that create complex chains of derivative
    works, each with its own potential infringement issues.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个不仅建议代码片段，而且积极编写和部署应用的自主软件开发代理。这样的系统可能在任何违规被发现之前，意外地将专有算法或受保护的代码模式整合到数千个项目中。同样，在创意产业中，管理内容生产的代理系统可以自主地混搭和重新使用受版权保护的材料，从而创建复杂的派生作品链，每个作品都有其潜在的侵权问题。
- en: The real-world implications are already emerging. The 2022 lawsuit against Stability
    AI’s Stable Diffusion image generator highlighted concerns about training data
    usage ( [https://jipel.law.nyu.edu/andersen-v-stability-ai-the-landmark-case-unpacking-the-copyright-risks-of-ai-image-generators/](https://jipel.law.nyu.edu/andersen-v-stability-ai-the-landmark-case-unpacking-the-copyright-risks-of-ai-image-generators/)
    ), but agentic systems raise even thornier questions. What happens when an AI
    agent autonomously creates and executes marketing campaigns using style elements
    it learned from copyrighted works? Or when it modifies and redistributes protected
    content based on its understanding of fair use?
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 实际影响已经显现。2022年对Stability AI的Stable Diffusion图像生成器的诉讼突显了对训练数据使用的担忧（[https://jipel.law.nyu.edu/andersen-v-stability-ai-the-landmark-case-unpacking-the-copyright-risks-of-ai-image-generators/](https://jipel.law.nyu.edu/andersen-v-stability-ai-the-landmark-case-unpacking-the-copyright-risks-of-ai-image-generators/)），但代理系统提出了更加棘手的问题。当人工智能代理自主地使用从受版权作品中学到的风格元素来创建和执行营销活动时会发生什么？或者当它根据对合理使用的理解修改和重新分配受保护的内容时呢？
- en: Addressing these challenges requires a radical rethinking of intellectual property
    protection in an age of autonomous systems. Organizations must develop new frameworks
    that can anticipate and prevent potential IP violations before they occur, rather
    than just detecting them after the fact. This means implementing real-time monitoring
    systems that can track the provenance of agent-generated content and decision
    trees that can evaluate IP implications before autonomous actions are taken.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 面对这些挑战，需要在自主系统时代对知识产权保护进行根本性的重新思考。组织必须开发新的框架，能够在潜在知识产权侵权发生之前预见并预防，而不仅仅是事后检测。这意味着实施实时监控系统，能够追踪代理生成内容的来源，以及能够在自主行动之前评估知识产权影响的决策树。
- en: Technical innovation will play a crucial role in this evolution. We’re seeing
    the emergence of new approaches such as blockchain-based content tracking, automated
    license verification systems, and AI agents specifically designed to audit other
    agents for potential IP violations. These tools, combined with traditional legal
    safeguards, form the foundation of a new approach to IP protection in the age
    of autonomous systems.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 技术创新将在这一演变中发挥关键作用。我们正在看到新方法的出现，如基于区块链的内容跟踪、自动许可验证系统和专门设计用于审计其他代理以识别潜在知识产权违规的人工智能代理。这些工具与传统法律保障相结合，构成了自主系统时代知识产权保护新方法的基础。
- en: As we navigate this complex landscape, flexibility and adaptation will be key.
    The legal frameworks governing intellectual property were designed for a world
    of human creators and human decision-makers. As agentic AI systems become more
    prevalent, these frameworks will need to evolve – not just to protect existing
    rights but also to foster innovation in a world where machines are increasingly
    active participants in the creative process.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们导航这个复杂的地形时，灵活性和适应性将是关键。管理知识产权的法律框架是为人类创作者和决策者设计的。随着代理人工智能系统的日益普及，这些框架将需要发展——不仅为了保护现有权利，还为了在机器越来越多地参与创作过程的世界中促进创新。
- en: Ensuring safe and responsible AI
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 确保安全和负责任的AI
- en: 'The deployment of LLM-based agentic systems introduces unique safety and responsibility
    challenges that go beyond those of traditional generative AI. While generative
    AI primarily focuses on content creation, agentic systems can autonomously plan,
    decide, and act, making their safe deployment significantly more complex and critical.
    Core safety considerations for agentic systems include the following:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 基于LLM的代理系统的部署引入了超越传统生成人工智能的独特安全和责任挑战。虽然生成人工智能主要关注内容创作，但代理系统可以自主地规划、决策和行动，这使得它们的安全部署变得更加复杂和关键。代理系统的核心安全考虑包括以下方面：
- en: '**Action boundaries** : Defining strict action boundaries is critical to ensuring
    that agentic systems operate within safe and ethical constraints. These boundaries
    can be enforced using policy-based governance frameworks such as OpenAI’s Function
    Calling API and Amazon Bedrock Guardrails, which allow agents to interact with
    external systems while adhering to predefined operational limits. Additionally,
    **role-based access control** ( **RBAC** ) and context-aware permissions can be
    implemented to restrict agents from taking unauthorized actions, particularly
    in high-risk domains such as finance and healthcare.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**行动边界**：定义严格的行为边界对于确保代理系统在安全和伦理约束内运行至关重要。这些边界可以通过基于策略的治理框架如OpenAI的函数调用API和Amazon
    Bedrock Guardrails来强制执行，这些框架允许代理在遵守预定义的操作限制的同时与外部系统交互。此外，可以实施**基于角色的访问控制**（**RBAC**）和上下文感知权限，以限制代理执行未经授权的行为，特别是在金融和医疗保健等高风险领域。'
- en: '**Decision verification** : Agentic systems must incorporate multi-step validation
    processes for critical decisions, ensuring robustness and alignment with human
    oversight. This can be achieved using neural-symbolic reasoning, constraint satisfaction
    models, and logical verification techniques that validate each decision against
    predefined ethical and operational constraints before execution. Techniques such
    as tree search algorithms and Monte Carlo simulations can be applied to evaluate
    multiple possible outcomes and ensure optimal decision-making in real time.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**决策验证**：代理系统必须包含多步骤验证过程以进行关键决策，确保其稳健性和与人类监督的一致性。这可以通过使用神经符号推理、约束满足模型和逻辑验证技术来实现，这些技术可以在执行前验证每个决策是否符合预定义的伦理和操作约束。可以应用如树搜索算法和蒙特卡洛模拟等技术来评估多种可能的后果，并确保实时最优决策。'
- en: '**Rollback capabilities** : The ability to undo or reverse autonomous actions
    is essential for mitigating unintended consequences. This can be implemented through
    event sourcing and state management frameworks such as Apache Kafka and Temporal.io,
    which maintain an immutable log of agent actions, enabling controlled rollbacks.
    Version control for decision states, combined with checkpointing mechanisms, can
    allow systems to revert to a stable state when anomalies or failures are detected.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**回滚能力**：能够撤销或反转自主行为对于减轻意外后果至关重要。这可以通过事件源和状态管理框架如Apache Kafka和Temporal.io来实现，这些框架维护代理行为的不可变日志，从而实现可控的回滚。决策状态的版本控制，结合检查点机制，可以在检测到异常或故障时使系统恢复到稳定状态。'
- en: '**Real-time monitoring** : Continuous monitoring of agent behavior is crucial
    for detecting deviations and preventing harmful actions. Anomaly detection models
    such as Facebook’s AI Anomaly Detection Pipeline and Amazon CloudWatch anomaly
    detection use machine learning-based pattern recognition to track behavioral shifts
    in real time. Additionally, drift detection algorithms can identify when an agent’s
    behavior diverges from expected patterns, triggering alerts or initiating corrective
    actions. **Explainable AI** ( **XAI** ) techniques further enhance monitoring
    by providing human-readable insights into why an agent made a particular decision.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实时监控**：持续监控代理行为对于检测偏差和防止有害行为至关重要。例如，Facebook的AI异常检测管道和Amazon CloudWatch异常检测使用基于机器学习的模式识别来实时跟踪行为变化。此外，漂移检测算法可以识别代理行为何时偏离预期模式，从而触发警报或启动纠正措施。**可解释人工智能**（**XAI**）技术通过提供人类可读的见解来进一步增强监控，说明代理为何做出特定决策。'
- en: '**Reinforcement learning feedback loops** : Incorporating human-in-the-loop
    oversight through **reinforcement learning from human feedback** ( **RLHF** )
    helps fine-tune agentic decision-making. By continuously integrating feedback
    from human reviewers, agents can improve their behavior over time while maintaining
    safety and ethical alignment. In high-stakes environments, hybrid AI-human workflows
    can be used to escalate decisions that require human judgment.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**强化学习反馈循环**：通过**从人类反馈中进行强化学习**（**RLHF**）引入人类在环监督有助于微调代理决策。通过持续整合来自人类审查员的反馈，代理可以在保持安全和伦理一致性的同时随着时间的推移改进其行为。在高风险环境中，可以使用混合AI-人类工作流程来提升需要人类判断的决策。'
- en: '**Performance metrics** : Evaluating agentic systems requires more than just
    output quality; it must also assess decision consistency, ethical alignment, risk
    assessment, and adaptability. AI auditing tools such as IBM’s AI Fairness 360
    and Google’s Explainable AI provide comprehensive evaluation frameworks that measure
    not only accuracy but also transparency, robustness, and fairness. Additionally,
    causal inference models can help quantify the impact of agent decisions, ensuring
    alignment with ethical and regulatory standards.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**性能指标**：评估代理系统不仅需要输出质量；还必须评估决策一致性、道德一致性、风险评估和适应性。IBM的AI公平360和谷歌的可解释AI等AI审计工具提供了全面的评估框架，不仅衡量准确性，还衡量透明度、鲁棒性和公平性。此外，因果推断模型可以帮助量化代理决策的影响，确保与道德和监管标准保持一致。'
- en: By integrating these technologies and methodologies, organizations can deploy
    agentic systems that are *safe* , *transparent* , and *aligned with regulatory
    and ethical considerations* , reducing the risks associated with autonomous decision-making
    while maintaining operational efficiency.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 通过整合这些技术和方法，组织可以部署既**安全**、**透明**，又**符合监管和伦理考量**的代理系统，降低与自主决策相关的风险，同时保持运营效率。
- en: 'Let’s examine how these safety measures manifest in practical deployments.
    Consider an agentic system managing a corporate travel program – beyond just generating
    recommendations, it actively books flights, adjusts schedules, and manages expenses.
    A system like this demands layered safety protocols that address both its generative
    and autonomous aspects, as highlighted here:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看这些安全措施在实际部署中的体现。考虑一个管理企业差旅计划的代理系统——除了生成推荐之外，它还积极预订航班、调整日程和管理费用。这样的系统需要分层的安全协议，以解决其生成和自主方面的各个方面，如以下所示：
- en: Action boundaries might include financial limits on booking changes without
    approval, restrictions on booking destinations flagged as high risk, and rules
    about when schedule changes can be made autonomously
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 行动边界可能包括未经批准的预订变更的财务限制、对标记为高风险目的地的预订限制以及关于何时可以自主调整日程的规则。
- en: Decision verification could involve multi-step checks before finalizing expensive
    bookings – perhaps requiring human approval for transactions above certain thresholds
    or automated cross-verification with company travel policies
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 决策验证可能涉及在最终确定昂贵预订之前的多个步骤检查——可能需要对于超过一定阈值的交易进行人工审批或与公司差旅政策进行自动化交叉验证。
- en: The system’s rollback capabilities would need to account for real-world constraints,
    such as airline cancellation policies or hotel booking deadlines, ensuring that
    autonomous actions don’t incur unnecessary penalties
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 系统的回滚能力需要考虑现实世界的限制，例如航空公司的取消政策或酒店预订截止日期，确保自主行动不会产生不必要的罚款。
- en: Real-time monitoring in this context would track patterns of bookings and expenses,
    flagging unusual activities such as multiple booking changes in short succession
    or deviations from typical corporate travel patterns
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在这个背景下，实时监控将跟踪预订和支出的模式，标记出异常活动，例如短时间内连续多次预订变更或偏离典型的企业差旅模式。
- en: Performance metrics would go beyond simple measures such as successful bookings
    to evaluate decision quality – for instance, assessing whether the system consistently
    makes cost-effective choices while respecting traveler preferences and company
    policies
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 性能指标将超越简单的预订成功等度量，以评估决策质量——例如，评估系统是否始终做出成本效益的选择，同时尊重旅行者的偏好和公司政策。
- en: 'This travel management example demonstrates how safety measures must be carefully
    tailored to both protect against potential risks and ensure efficient operation.
    The system needs to balance autonomy (such as automatically rebooking disrupted
    flights) with appropriate caution (such as requiring approval for significant
    itinerary changes), all while maintaining clear audit trails and explanation capabilities
    for its decisions. *Figure 9* *.1* shows the safety measures for this agentic
    travel management system:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这个差旅管理示例展示了安全措施必须仔细调整，既要防止潜在风险，又要确保高效运营。系统需要在自主性（如自动重新预订中断的航班）和适当的谨慎（如对重大行程变更要求审批）之间取得平衡，同时保持其决策的清晰审计轨迹和解释能力。*图9.1*展示了这个代理差旅管理系统的安全措施：
- en: '![img](img/B31483_09_01.jpg)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![img](img/B31483_09_01.jpg)'
- en: Figure 9.1 – Safety measures for agentic travel management system
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.1 – 代理差旅管理系统的安全措施
- en: Testing for agentic systems must be more comprehensive than traditional generative
    AI testing. While generative AI testing focuses on output quality, agentic system
    testing must evaluate entire decision chains and action sequences. This includes
    simulating complex scenarios where the agent must make interconnected decisions,
    handle unexpected situations, and maintain safety constraints across multiple
    actions.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 代理系统的测试必须比传统的生成式AI测试更全面。虽然生成式AI测试侧重于输出质量，但代理系统测试必须评估整个决策链和行动序列。这包括模拟复杂场景，其中代理必须做出相互关联的决策，处理意外情况，并在多个行动中保持安全约束。
- en: Human oversight takes on new dimensions with agentic systems. Rather than simply
    reviewing generated content, humans must monitor decision patterns, intervene
    in complex situations, and help refine the system’s understanding of acceptable
    actions. This creates a need for new oversight tools and frameworks that can track
    and evaluate autonomous behavior in real time.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 代理系统带来了人类监督的新维度。人类不仅需要审查生成的内容，还必须监控决策模式，在复杂情况下进行干预，并帮助细化系统对可接受行动的理解。这需要新的监督工具和框架，能够实时跟踪和评估自主行为。
- en: 'The concept of *safe learning* becomes crucial for agentic systems. These systems
    must be able to learn from experience without compromising safety during operation.
    This might involve creating sandboxed environments where agents can safely explore
    new strategies or implementing gradual automation where human oversight is reduced
    as the system proves its reliability. Critical implementation strategies include
    the following:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 对于代理系统来说，*安全学习*的概念变得至关重要。这些系统必须在操作过程中不损害安全的前提下从经验中学习。这可能包括创建沙盒环境，让代理可以安全地探索新的策略，或者实施逐步自动化，随着系统证明其可靠性，减少人类监督。关键的实施策略包括以下内容：
- en: '**Progressive autonomy** : Starting with heavily restricted action capabilities
    and gradually expanding them based on demonstrated reliability'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**渐进式自主性**：从高度受限的行动能力开始，并根据已证明的可靠性逐步扩展'
- en: '**Contextual safety bounds** : Implementing different safety protocols based
    on the risk level of specific actions'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**上下文安全边界**：根据特定行动的风险水平实施不同的安全协议'
- en: '**Continuous validation** : Regular assessment of decision patterns to identify
    potential safety risks'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**持续验证**：定期评估决策模式以识别潜在的安全风险'
- en: '**Emergency protocols** : Clear procedures for rapid human intervention when
    needed'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**紧急协议**：在需要时进行快速人工干预的明确程序'
- en: Trust building with agentic systems requires more than just transparency – it
    needs demonstrable reliability in autonomous operation. Organizations must develop
    clear frameworks for communicating both the capabilities and limitations of their
    agentic systems, helping stakeholders understand when and how to rely on autonomous
    decisions.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 与代理系统建立信任不仅需要透明度，还需要在自主操作中展现出可证明的可靠性。组织必须制定明确的框架来沟通其代理系统的能力和局限性，帮助利益相关者了解何时以及如何依赖自主决策。
- en: The ethical deployment of agentic systems also requires careful consideration
    of societal impact. These systems must be designed to respect not just individual
    privacy and rights but also broader social values and norms. Implementing explicit
    ethical constraints in the decision-making process involves encoding predefined
    ethical rules, fairness constraints, and compliance policies into the system’s
    logic using techniques such as constraint programming, rule-based ethics engines,
    and reinforcement learning with ethical reward models. For example, symbolic AI
    approaches can integrate formal ethics rules (e.g., Asimov’s laws of robotics
    and GDPR privacy requirements) directly into decision-making pipelines, ensuring
    that agents adhere to predefined ethical boundaries. Additionally, differential
    privacy mechanisms and bias mitigation algorithms (such as IBM’s AI Fairness 360)
    can enforce fairness and privacy compliance at runtime.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 代理系统的道德部署还要求仔细考虑社会影响。这些系统必须被设计成不仅尊重个人隐私和权利，还要尊重更广泛的社会价值观和规范。在决策过程中实施明确的道德约束，涉及使用约束编程、基于规则的道德引擎和具有道德奖励模型的强化学习等技术将预定义的道德规则、公平约束和合规政策编码到系统的逻辑中。例如，符号人工智能方法可以将正式的道德规则（例如，阿西莫夫的机器人定律和GDPR隐私要求）直接集成到决策管道中，确保代理遵守预定义的道德边界。此外，差分隐私机制和偏差缓解算法（如IBM的AI公平360）可以在运行时强制执行公平性和隐私合规性。
- en: To ensure ethical adaptability, organizations can implement community feedback
    loops using **human-in-the-loop** ( **HITL** ) systems, where flagged decisions
    are reviewed and incorporated into future model refinements. Additionally, governance
    frameworks should include periodic ethical audits, the establishment of red-teaming
    exercises to stress-test decision-making under edge cases, and mechanisms for
    incorporating stakeholder feedback into system improvements. As agentic systems
    become more prevalent, these comprehensive governance measures will be critical
    in balancing automation with ethical responsibility, ensuring that AI-driven decisions
    align with societal expectations and regulatory requirements.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保伦理适应性，组织可以实施使用**人机协作系统**（**HITL**）的社区反馈循环，在这些系统中，标记的决策将被审查并纳入未来的模型改进。此外，治理框架应包括定期的伦理审计、建立红队演练以测试边缘情况下的决策，以及将利益相关者反馈纳入系统改进的机制。随着代理系统的普及，这些全面的治理措施对于在自动化与伦理责任之间取得平衡至关重要，确保人工智能驱动的决策符合社会期望和监管要求。
- en: By understanding and addressing these unique challenges of agentic systems,
    organizations can work toward deployments that not only leverage the power of
    autonomous operation but do so in a way that prioritizes safety, responsibility,
    and ethical considerations throughout the system’s life cycle.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 通过理解和解决这些代理系统的独特挑战，组织可以朝着部署努力，不仅利用自主操作的力量，而且在整个系统生命周期中优先考虑安全、责任和伦理考量。
- en: Exploring ethical guidelines and frameworks
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索伦理指南和框架
- en: As generative AI systems become increasingly sophisticated and integrated into
    various aspects of society, it is crucial to establish robust ethical guidelines
    and frameworks to ensure their responsible development and deployment. A sound
    ethical framework should encompass a range of principles and guidelines that prioritize
    human well-being, accountability, privacy protection, and inclusive governance.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 随着生成式人工智能系统变得越来越复杂并融入社会的各个方面，建立稳健的伦理指南和框架对于确保其负责任的发展和部署至关重要。一个健全的伦理框架应包括一系列原则和指南，这些原则和指南优先考虑人类福祉、问责制、隐私保护和包容性治理。
- en: Human-centric design
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 以人为中心的设计
- en: At the core of ethical AI development lies the principle of human-centric design.
    Generative AI systems should be designed with a focus on enhancing human well-being
    and delivering positive experiences. This requires developing intuitive, accessible,
    and inclusive solutions that are aligned with human values, such as fairness,
    dignity, and respect for individual autonomy.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 以人为本的伦理人工智能开发的核心原则是以人为中心的设计。生成式人工智能系统应设计成专注于增强人类福祉和提供积极的体验。这需要开发直观、易于访问和包容的解决方案，这些解决方案与人类价值观一致，如公平、尊严和对个人自主权的尊重。
- en: For example, in the context of a travel agency, a human-centric generative AI
    system would prioritize personalized recommendations that cater to diverse preferences,
    cultural sensitivities, and accessibility needs, ensuring that all users can benefit
    from the technology in a meaningful and respectful manner.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在旅行社的背景下，以人为中心生成式人工智能系统将优先考虑满足多样化偏好、文化敏感性和可访问性需求的个性化推荐，确保所有用户都能以有意义和尊重的方式从这项技术中受益。
- en: Accountability and responsibility
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问责制和责任
- en: Organizations developing and deploying generative AI systems must be held accountable
    for the outputs and potential impacts of these technologies. This involves establishing
    clear lines of responsibility, comprehensive documentation of decision-making
    processes, and mechanisms for reviewing and addressing ethical implications.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 开发和部署生成式人工智能系统的组织必须对其输出的技术和潜在影响负责。这包括建立清晰的职责界限、全面记录决策过程，以及审查和解决伦理影响的机制。
- en: Implementing review boards or advisory committees comprising interdisciplinary
    experts, including ethicists, legal professionals, and representatives from potentially
    affected communities, can help organizations navigate complex ethical challenges
    and ensure responsible decision-making.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 实施由跨学科专家组成的审查委员会或咨询委员会，包括伦理学家、法律专业人士和可能受影响的社区的代表，可以帮助组织应对复杂的伦理挑战并确保负责任的决策。
- en: Privacy and data protection
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 隐私和数据保护
- en: User privacy and data protection should be embedded as foundational principles
    in the development of generative AI systems. Organizations must adopt a **privacy-by-design**
    approach, practicing data minimization, anonymizing sensitive data, and ensuring
    that data handling practices comply with relevant privacy laws and regulations.
    A privacy-by-design approach ensures that AI systems embed privacy protections
    at every stage, minimizing risks while complying with laws such as **General Data
    Protection Regulation** ( **GDPR** ), **California Consumer Privacy Act** ( **CCPA**
    ), and **Health Insurance Portability and Accountability Act** ( **HIPAA** ).
    This includes data minimization (collecting only essential information), anonymization
    (using techniques such as k-anonymity and pseudonymization), and **privacy-preserving
    machine learning** ( **PPML** ) methods such as federated learning, homomorphic
    encryption, and **secure multi-party computation** ( **SMPC** ). For example,
    in a healthcare AI assistant, patient data can be encrypted and processed locally
    using federated learning, while **role-based access control** ( **RBAC** ) ensures
    that only authorized personnel can access sensitive data. Additionally, automated
    audit logs and explainability tools track decisions for accountability. These
    techniques help organizations deploy AI responsibly, ensuring privacy without
    sacrificing functionality.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在生成式人工智能系统的开发中，用户隐私和数据保护应作为基础原则嵌入。组织必须采用**隐私设计**方法，实践数据最小化、匿名化敏感数据，并确保数据处理实践符合相关隐私法律和法规。隐私设计方法确保AI系统在每个阶段都嵌入隐私保护措施，最小化风险同时遵守如**通用数据保护条例**（**GDPR**）、**加州消费者隐私法案**（**CCPA**）和**健康保险可携带性和问责法案**（**HIPAA**）等法律。这包括数据最小化（仅收集必要信息）、匿名化（使用如k-匿名化和匿名化等技术）以及**隐私保护机器学习**（**PPML**）方法，如联邦学习、同态加密和**安全多方计算**（**SMPC**）。例如，在医疗保健人工智能助手的情况下，患者数据可以使用联邦学习加密并在本地处理，而**基于角色的访问控制**（**RBAC**）确保只有授权人员可以访问敏感数据。此外，自动审计日志和可解释性工具跟踪决策以实现问责制。这些技术帮助组织负责任地部署AI，确保隐私而不牺牲功能。
- en: In the travel industry, this could involve implementing robust data governance
    frameworks, obtaining explicit consent from users for data collection and usage,
    and implementing secure data storage and processing mechanisms to protect sensitive
    information such as travel histories, preferences, and payment details.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在旅游行业，这可能包括实施稳健的数据治理框架，从用户那里获得数据收集和使用的明确同意，并实施安全的数据存储和处理机制，以保护敏感信息，如旅行历史、偏好和支付详情。
- en: Involvement of diverse stakeholders
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多元利益相关者的参与
- en: Ethical AI development requires the involvement of diverse stakeholders, including
    ethicists, technologists, policymakers, and representatives from potentially affected
    communities. This collaborative approach fosters inclusive dialogue, identifies
    potential blind spots or unintended consequences, and promotes more equitable
    and socially responsible approaches to AI governance.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 伦理人工智能开发需要多元利益相关者的参与，包括伦理学家、技术专家、政策制定者和可能受影响的社区的代表。这种协作方法促进了包容性对话，识别了潜在的盲点或意外后果，并促进了更公平和负责任的人工智能治理方法。
- en: For instance, in the development of a generative AI system for travel recommendations,
    engaging with stakeholders from diverse cultural backgrounds, disability rights
    advocates, and environmental organizations could help identify potential biases,
    accessibility barriers, or sustainability concerns, leading to more inclusive
    and responsible solutions.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在开发用于旅行推荐的生成式人工智能系统中，与来自不同文化背景的利益相关者、残疾人权利倡导者和环境组织进行互动，可以帮助识别潜在的偏见、可访问性障碍或可持续性担忧，从而引领更包容和负责任解决方案的产生。
- en: By adhering to these ethical guidelines and frameworks, organizations can foster
    trust, accountability, and responsible innovation in the development and deployment
    of generative AI technologies. This approach not only mitigates potential risks
    and unintended consequences but also unlocks the full potential of these powerful
    technologies to drive positive societal impact while upholding fundamental human
    rights and values.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 通过遵守这些伦理指南和框架，组织可以在生成式人工智能技术的开发和部署中培养信任、问责制和负责任创新。这种方法不仅减轻了潜在风险和意外后果，而且释放了这些强大技术的全部潜力，以推动积极的社会影响，同时维护基本的人权和价值观。
- en: Addressing privacy and security concerns
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解决隐私和安全问题
- en: As generative AI systems become increasingly prevalent across various domains,
    addressing privacy and security concerns is of utmost importance. Organizations
    must take proactive measures to safeguard sensitive data, protect against potential
    breaches, and ensure the resilience of their AI systems against malicious attacks.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 随着生成式人工智能系统在各个领域的日益普及，解决隐私和安全问题至关重要。组织必须采取主动措施来保护敏感数据，防范潜在的违规行为，并确保其人工智能系统对恶意攻击具有弹性。
- en: In the context of a travel agency employing a generative AI system for personalized
    recommendations and itinerary planning, implementing a comprehensive data governance
    framework is crucial. This framework should outline data handling practices, access
    controls, and compliance measures to protect private information within the organization,
    such as customer travel histories, preferences, and payment details.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在旅行社使用生成式人工智能系统进行个性化推荐和行程规划的情况下，实施全面的数据治理框架至关重要。该框架应概述数据处理实践、访问控制和合规措施，以保护组织内部的私人信息，例如客户旅行历史、偏好和支付详情。
- en: Access controls and role-based permissions can help ensure that only authorized
    personnel can access and modify sensitive data used for training or generating
    recommendations. Additionally, adhering to relevant data protection laws and industry-specific
    regulations, such as the GDPR or the **Payment Card Industry Data Security Standard**
    ( **PCI DSS** ), is essential to maintain compliance and avoid potential legal
    liabilities.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 访问控制和基于角色的权限可以帮助确保只有授权人员才能访问和修改用于培训或生成推荐意见的敏感数据。此外，遵守相关的数据保护法律和行业特定法规，例如GDPR或**支付卡行业数据安全标准**（**PCI
    DSS**），对于维持合规性和避免潜在的法律责任至关重要。
- en: Incorporating security considerations into the AI development life cycle is
    also vital. This includes conducting regular security risk assessments to identify
    potential vulnerabilities, implementing secure coding standards to mitigate coding
    errors or vulnerabilities, and performing regular testing and audits to detect
    and address any security weaknesses in the AI system. For example, the travel
    agency could employ penetration testing techniques to simulate potential attack
    scenarios and assess the resilience of their generative AI system against adversarial
    attacks or data breaches. This proactive approach can help identify and address
    security gaps before they are exploited by malicious actors.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 将安全考虑纳入人工智能开发生命周期同样至关重要。这包括定期进行安全风险评估以识别潜在漏洞，实施安全的编码标准以减轻编码错误或漏洞，以及进行定期的测试和审计以检测和解决人工智能系统中的任何安全弱点。例如，旅行社可以采用渗透测试技术来模拟潜在的攻击场景，并评估其生成式人工智能系统对对抗性攻击或数据泄露的弹性。这种主动方法可以帮助在恶意行为者利用之前识别和解决安全漏洞。
- en: Educating users about the potential risks associated with generative AI and
    providing training on safe usage practices can empower them to make informed decisions
    and recognize potential threats. In the travel agency scenario, this could involve
    educating customers about the importance of safeguarding their personal information,
    recognizing phishing attempts or suspicious communications, and reporting any
    concerns or incidents promptly.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 教育用户关于生成式人工智能相关的潜在风险，并提供安全使用实践的培训，可以赋予他们做出明智决定和识别潜在威胁的能力。在旅行社场景中，这可能包括教育客户保护其个人信息的重要性，识别钓鱼尝试或可疑通信，并迅速报告任何担忧或事件。
- en: Organizations should also establish robust incident response plans to deal with
    potential security breaches or data leaks effectively. These plans should outline
    clear protocols for rapid response, containment, investigation, and mitigation
    strategies to limit the damage and protect affected individuals or entities.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 组织还应建立强大的事件响应计划，以有效应对潜在的安全违规或数据泄露。这些计划应概述快速响应、控制、调查和缓解策略的明确协议，以限制损害并保护受影响的个人或实体。
- en: In the event of a data breach involving customer information, the travel agency
    should be prepared to swiftly notify affected individuals, regulatory authorities,
    and stakeholders, while implementing measures to secure the compromised systems
    and prevent further data loss.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在涉及客户信息的数据泄露事件中，旅行社应准备好迅速通知受影响的个人、监管机构和利益相关者，同时实施措施以保护受损害的系统并防止进一步的数据丢失。
- en: Additionally, techniques such as adversarial training and anomaly detection
    can help improve the resilience of generative AI systems against adversarial attacks
    specifically. Adversarial training involves exposing the AI model to carefully
    crafted adversarial examples during the training process, enhancing its ability
    to recognize and defend against such attacks. Anomaly detection algorithms can
    identify and flag suspicious or anomalous inputs or outputs, enabling timely intervention
    and mitigation efforts. By prioritizing privacy and security considerations throughout
    the AI development and deployment life cycle, organizations can foster trust and
    confidence in their generative AI systems, while ensuring compliance with relevant
    regulations and safeguarding sensitive data and intellectual property.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，诸如对抗性训练和异常检测等技术可以帮助提高生成式人工智能系统对特定对抗性攻击的弹性。对抗性训练涉及在训练过程中将精心制作的对抗性示例暴露给人工智能模型，增强其识别和防御此类攻击的能力。异常检测算法可以识别并标记可疑或异常的输入或输出，使及时干预和缓解工作成为可能。通过在整个人工智能开发和部署生命周期中优先考虑隐私和安全考虑，组织可以培养对其生成式人工智能系统的信任和信心，同时确保遵守相关法规并保护敏感数据和知识产权。
- en: Summary
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we discovered that while advanced intelligent agentic systems
    hold immense potential to drive innovation, enhance creativity, and revolutionize
    various industries, their deployment and development must be approached with utmost
    care and responsibility. Armed with awareness of the potential risks and challenges
    associated with generative AI, organizations and stakeholders can proactively
    implement measures to ensure safety, uphold ethical principles, and address privacy
    and security concerns. By doing so, they can harness the transformative power
    of these technologies in a trustworthy and accountable manner, fostering confidence
    among users and stakeholders. Embracing a proactive and responsible approach to
    generative AI development involves implementing robust testing and monitoring
    frameworks, adhering to ethical guidelines and frameworks that prioritize human
    well-being, accountability, and inclusive governance, and establishing comprehensive
    data governance and security protocols to safeguard sensitive information and
    intellectual property.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们发现虽然高级智能代理系统具有推动创新、增强创造力和变革各个行业的巨大潜力，但它们的部署和发展必须以极高的谨慎和责任感来对待。在了解与生成式人工智能相关的潜在风险和挑战后，组织和个人可以主动采取措施确保安全、维护伦理原则并解决隐私和安全问题。通过这样做，他们可以以可信赖和负责任的方式利用这些技术的变革力量，在用户和利益相关者中培养信心。采取积极主动和负责任的方法来开发生成式人工智能涉及实施强大的测试和监控框架，遵守优先考虑人类福祉、责任和包容性治理的伦理指南和框架，并建立全面的数据治理和安全协议，以保护敏感信息和知识产权。
- en: It is crucial to address the uncertainties and biases in AI systems. By employing
    techniques such as probabilistic modeling, uncertainty quantification, and debiasing
    algorithms, developers can improve the reliability and fairness of generative
    AI models, fostering trust and responsible adoption. Collaboration among stakeholders,
    including developers, researchers, policymakers, and ethicists, is essential for
    navigating the challenges and ethical implications of generative AI. An inclusive,
    multidisciplinary approach helps identify blind spots, mitigate unintended consequences,
    and align solutions with human values. Agentic systems heighten AI risks by autonomously
    acting on biased or compromised information, making robust safety measures, including
    action boundaries, decision verification, and real-time monitoring, critical.
    Effective deployment requires balancing autonomy with appropriate human oversight,
    especially for high-stake decisions. Privacy protection must extend beyond data
    safeguards to account for the potential exposure of sensitive information through
    autonomous decisions. Additionally, intellectual property frameworks must evolve
    to handle AI agents as active creators, with real-time monitoring and verification
    systems in place.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 解决AI系统中的不确定性和偏差至关重要。通过采用概率建模、不确定性量化以及去偏差算法等技术，开发者可以提高生成式AI模型的可靠性和公平性，促进信任和负责任的采用。包括开发者、研究人员、政策制定者和伦理学家在内的利益相关者之间的合作对于应对生成式AI的挑战和伦理影响至关重要。包容性和多学科的方法有助于识别盲点、减轻意外后果，并将解决方案与人类价值观相一致。代理系统通过自主行动于有偏差或受损的信息，增加了AI风险，因此，包括行动边界、决策验证和实时监控在内的稳健安全措施至关重要。有效的部署需要平衡自主性与适当的人类监督，尤其是在高风险决策方面。隐私保护必须超越数据保护，以考虑到通过自主决策可能暴露的敏感信息。此外，知识产权框架必须发展，以处理作为积极创造者的AI代理，并建立实时监控和验证系统。
- en: In the next chapter, we will explore some of the common use cases and applications
    of LLM-based intelligent agents using various patterns and techniques that we’ve
    learned so far.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探讨一些基于LLM（大型语言模型）的智能代理的常见用例和应用，这些用例和应用使用了我们迄今为止学到的各种模式和技巧。
- en: Questions
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: How do the risks of hallucination differ between generative AI and agentic systems?
    Why are hallucinations potentially more dangerous in agentic systems?
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成式AI和代理系统之间幻觉的风险有何不同？为什么在代理系统中幻觉可能更加危险？
- en: What are the core safety considerations that need to be implemented when deploying
    LLM-based agentic systems, and how do they manifest in a practical example such
    as a travel management system?
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在部署基于LLM的代理系统时，需要实施哪些核心安全考虑因素，它们如何在旅行管理系统等实际示例中体现？
- en: How does bias in agentic AI systems differ from bias in traditional generative
    AI systems, and what additional measures are needed to address it?
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 代理AI系统中的偏差与传统生成式AI系统中的偏差有何不同，需要采取哪些额外措施来解决它？
- en: What unique challenges do agentic systems pose for data privacy compared to
    traditional generative AI systems, and how should organizations address these
    challenges?
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 与传统的生成式AI系统相比，代理系统对数据隐私提出了哪些独特的挑战，组织应该如何应对这些挑战？
- en: How do intellectual property risks evolve when moving from generative AI to
    agentic systems, and what new approaches are needed to address these risks?
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当从生成式AI转向代理系统时，知识产权风险如何演变，需要采取哪些新方法来解决这些风险？
- en: Answers
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 答案
- en: In generative AI, hallucinations primarily result in incorrect content generation,
    but in agentic systems, hallucinated information can directly influence real-world
    decisions and actions. For example, while a generative AI might simply produce
    incorrect text, an agentic system might execute financial transactions based on
    hallucinated market trends or make medical decisions based on fabricated patient
    histories. This is more dangerous because it leads to immediate real-world consequences
    without human verification.
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在生成式AI中，幻觉主要导致内容生成错误，但在代理系统中，幻觉信息可以直接影响现实世界的决策和行动。例如，一个生成式AI可能只是简单地生成错误文本，而一个代理系统可能会根据幻觉的市场趋势执行金融交易，或者根据虚构的患者病史做出医疗决策。这更加危险，因为它在没有人类验证的情况下直接导致现实世界的后果。
- en: Core safety considerations include action boundaries, decision verification,
    rollback capabilities, real-time monitoring, and performance metrics. In a travel
    management system, they manifest as financial limits on booking changes, multi-step
    checks for expensive bookings, mechanisms to handle cancellation policies, tracking
    of booking patterns for anomalies, and evaluation of decision quality against
    company policies and traveler preferences. These measures ensure both protection
    against risks and efficient operation.
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 核心安全考虑因素包括行动边界、决策验证、回滚能力、实时监控和性能指标。在一个旅行管理系统内，这些因素表现为对预订变更的财务限制、对昂贵预订的多步骤检查、处理取消政策的机制、对预订模式的异常跟踪，以及根据公司政策和旅客偏好对决策质量的评估。这些措施确保了既防范风险又高效运作。
- en: Bias in agentic systems goes beyond generating biased content to actively making
    biased decisions that affect people’s lives. For example, while a generative AI
    might produce biased text, an agentic system could systematically discriminate
    in hiring decisions or resource allocations. Additional measures needed include
    decision auditing systems, accountability frameworks for autonomous actions, real-time
    bias detection mechanisms, and regular audits of decision-making patterns and
    action histories.
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 代理系统中的偏见不仅限于生成有偏见的内容，还主动做出影响人们生活的有偏见决策。例如，虽然生成式人工智能可能会产生有偏见文本，但代理系统可能在招聘决策或资源分配中系统性地进行歧视。需要的额外措施包括决策审计系统、自主行动的责任框架、实时偏见检测机制以及对决策模式和行动历史的定期审计。
- en: Agentic systems not only process and generate information but actively access,
    manipulate, and make decisions about personal data during operations. They need
    enhanced safeguards including real-time privacy monitoring, decision auditing
    systems, and privacy-aware decision protocols. Organizations must scrutinize how
    chains of autonomous decisions could reveal sensitive information over time, even
    when individual actions appear privacy-compliant, and make privacy an integral
    part of the system’s decision-making process.
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 代理系统不仅处理和生成信息，还在操作过程中主动访问、操作和做出关于个人数据的决策。它们需要加强保障措施，包括实时隐私监控、决策审计系统和隐私感知决策协议。组织必须仔细审查自主决策链如何随着时间的推移揭示敏感信息，即使个别行动看似符合隐私规定，也要将隐私作为系统决策过程的一个组成部分。
- en: Agentic systems can actively implement learned information and make decisions
    about intellectual property use at machine speed and scale. For example, they
    might autonomously incorporate proprietary code across thousands of projects or
    create complex chains of derivative works. New approaches needed include real-time
    monitoring systems for content provenance, decision trees for evaluating IP implications
    before actions, blockchain-based content tracking, and automated license verification
    systems. Legal frameworks need to evolve to handle machines as active participants
    in the creative process.
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 代理系统可以主动实施所学信息，并在机器速度和规模上做出关于知识产权使用的决策。例如，它们可能自主地将专有代码集成到数千个项目中，或创建复杂的衍生作品链。需要的新方法包括内容来源的实时监控系统、在行动之前评估知识产权影响的决策树、基于区块链的内容跟踪和自动许可验证系统。法律框架需要发展以处理机器作为创意过程中的积极参与者。
- en: Join our communities on Discord and Reddit
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们的 Discord 和 Reddit 社区
- en: Have questions about the book or want to contribute to discussions on Generative
    AI and LLMs? Join our Discord server at [https://packt.link/I1tSU](https://packt.link/I1tSU)
    and our Reddit channel at [https://packt.link/ugMW0](https://packt.link/ugMW0)
    to connect, share, and collaborate with like-minded enthusiasts.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 对这本书有疑问或想参与关于生成式人工智能和大型语言模型的讨论？加入我们的 Discord 服务器[https://packt.link/I1tSU](https://packt.link/I1tSU)和
    Reddit 频道[https://packt.link/ugMW0](https://packt.link/ugMW0)，与志同道合的爱好者建立联系、分享和协作。
- en: '![img](img/B31483_Discord_QR_new.jpg)![img](img/qrcode_Reddit_Channel.jpg)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![img](img/B31483_Discord_QR_new.jpg)![img](img/qrcode_Reddit_Channel.jpg)'
