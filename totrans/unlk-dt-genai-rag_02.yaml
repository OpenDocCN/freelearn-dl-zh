- en: <st c="0">2</st>
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2<st c="0">
- en: <st c="2">Code Lab – An Entire RAG Pipeline</st>
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 代码实验室 – 整个RAG管道<st c="2">
- en: <st c="35">This code lab lays the foundation for the rest of the code in this
    book.</st> <st c="109">We will spend this entire chapter giving you an entire</st>
    **<st c="164">retrieval-augmented generation</st>** <st c="194">(</st>**<st c="196">RAG</st>**<st
    c="199">) pipeline.</st> <st c="212">Then, as we step through the book, we will
    look at different parts of the code, adding enhancements along the way so that
    you have a comprehensive understanding of how your code can evolve to tackle more
    and more</st> <st c="425">difficult problems.</st>
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本代码实验室为本书中其余代码奠定了基础。<st c="35"> <st c="109">我们将花费整个章节的时间，为您提供整个</st> **<st c="164">检索增强生成</st>**
    <st c="194">(</st>**<st c="196">RAG</st>**<st c="199">**)管道。<st c="212">然后，随着我们逐步阅读本书，我们将查看代码的不同部分，并在过程中添加增强功能，以便您全面了解代码如何演变以解决更多和更复杂的难题。</st>
    <st c="425">
- en: <st c="444">We will spend this chapter walking through each component of the
    RAG pipeline, including the</st> <st c="538">following aspects:</st>
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将花费这一章的时间，逐一介绍RAG管道的每个组件，包括以下方面：<st c="444"> <st c="538">
- en: <st c="556">No interface</st>
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无界面<st c="556">
- en: <st c="569">Setting up a large language model (LLM) account</st> <st c="618">with
    OpenAI</st>
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在OpenAI上设置一个大型语言模型（LLM）账户<st c="569"> <st c="618">
- en: <st c="629">Installing the required</st> <st c="654">Python packages</st>
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装所需的<st c="629">Python包</st> <st c="654">
- en: <st c="669">Indexing data by web crawling, splitting documents, and embedding</st>
    <st c="736">the chunks</st>
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过网络爬虫、分割文档和嵌入块<st c="669">来索引数据</st> <st c="736">
- en: <st c="746">Retrieving relevant documents using vector</st> <st c="790">similarity
    search</st>
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用向量相似度搜索检索相关文档<st c="746">
- en: <st c="807">Generating responses by integrating retrieved context into</st>
    <st c="867">LLM prompts</st>
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过将检索到的上下文整合到LLM提示中生成响应<st c="807">
- en: <st c="878">As we step through the code, you will gain a comprehensive understanding
    of each step in the RAG process programmatically by using tools such as LangChain,
    Chroma DB, and OpenAI’s APIs.</st> <st c="1065">This will provide you with a strong
    foundation that we will build upon in subsequent chapters, enhancing and evolving
    the code to tackle increasingly</st> <st c="1215">complex problems.</st>
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们逐步分析代码，您将通过使用LangChain、Chroma DB和OpenAI的API等工具，以编程方式全面理解RAG过程中的每一步。<st c="878">这将为您提供一个坚实的基础，我们将在后续章节中在此基础上构建，增强和改进代码，以解决越来越复杂的难题。</st>
    <st c="1065">这将为您提供一个坚实的基础，我们将在后续章节中在此基础上构建，增强和改进代码，以解决越来越复杂的难题。</st> <st c="1215">
- en: <st c="1232">In later chapters, we will explore techniques that can help improve
    and customize the pipeline for different use cases and overcome common challenges
    that arise when building RAG-powered applications.</st> <st c="1434">Let’s dive
    in and</st> <st c="1452">start building!</st>
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在后续章节中，我们将探讨可以帮助改进和定制管道以适应不同用例的技术，并克服在构建由RAG驱动的应用程序时出现的常见挑战。</st> <st c="1232">让我们深入其中，<st
    c="1434">开始构建！</st>
- en: <st c="1467">Technical requirements</st>
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求<st c="1467">
- en: <st c="1490">The code for this chapter is available</st> <st c="1530">here:</st>
    [<st c="1536">https://github.com/PacktPublishing/Unlocking-Data-with-Generative-AI-and-RAG/tree/main/Chapter_02</st>](https://github.com/PacktPublishing/Unlocking-Data-with-Generative-AI-and-RAG/tree/main/Chapter_02
    )
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码可在以下位置找到：<st c="1490"> <st c="1530">[https://github.com/PacktPublishing/Unlocking-Data-with-Generative-AI-and-RAG/tree/main/Chapter_02](https://github.com/PacktPublishing/Unlocking-Data-with-Generative-AI-and-RAG/tree/main/Chapter_02)</st>
    <st c="1536">](https://github.com/PacktPublishing/Unlocking-Data-with-Generative-AI-and-RAG/tree/main/Chapter_02)
- en: <st c="1633">You will need to run this chapter’s code in an environment that’s
    been set up to run Jupyter notebooks.</st> <st c="1738">Experience with Jupyter
    notebooks is a prerequisite for using this book, and it is too difficult to cover
    it in a short amount of text.</st> <st c="1874">There are numerous ways to set
    up a notebook environment.</st> <st c="1932">There are online versions, versions
    you can download, notebook environments that universities provide students, and
    different interfaces you can use.</st> <st c="2082">If you are doing this at a
    company, they will likely have an environment you will want to get familiar with.</st>
    <st c="2191">Each of these options takes very different instructions to set up,
    and those instructions change often.</st> <st c="2295">If you need to brush up
    on your knowledge about this type of environment, you can start on the Jupyter
    website:</st> [<st c="2407">https://docs.jupyter.org/en/latest/</st>](https://docs.jupyter.org/en/latest/)<st
    c="2442">. Start here, then ask your favorite LLM for more help to get your environment</st>
    <st c="2521">set up.</st>
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="1633">您需要在已配置为运行 Jupyter 笔记本的环境下运行本章的代码。</st> <st c="1738">熟悉 Jupyter
    笔记本是使用本书的先决条件，而且很难在简短的文字中涵盖。</st> <st c="1874">设置笔记本环境有众多方法。</st> <st c="1932">有在线版本，可以下载的版本，大学为学生提供的笔记本环境，以及您可以使用的不同界面。</st>
    <st c="2082">如果您在公司进行这项操作，他们可能有一个您需要熟悉的环境。</st> <st c="2191">这些选项的设置指令各不相同，而且这些指令经常变化。</st>
    <st c="2295">如果您需要更新关于此类环境的知识，可以从 Jupyter 网站（[<st c="2407">https://docs.jupyter.org/en/latest/</st>](https://docs.jupyter.org/en/latest/)）开始。</st>
    <st c="2442">从这里开始，然后向您最喜欢的语言模型请求更多帮助以设置您的环境。</st> <st c="2521">。</st>
- en: <st c="2528">What do I use?</st> <st c="2544">When I use my Chromebook, often
    when I am traveling, I use a notebook set up in one of the cloud environments.</st>
    <st c="2655">I prefer Google Colab or their Colab Enterprise notebooks, which
    you can find in the Vertex AI section of Google Cloud Platform.</st> <st c="2784">But
    these environments cost money, often exceeding $20 a month if you are active.</st>
    <st c="2866">If you are as active as me, it can exceed $1,000</st> <st c="2915">per
    month!</st>
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="2528">我该使用什么？</st> <st c="2544">当我使用我的 Chromebook，通常在旅行时，我会在云环境中设置一个笔记本。</st>
    <st c="2655">我更喜欢 Google Colab 或他们的 Colab Enterprise 笔记本，您可以在 Google Cloud Platform
    的 Vertex AI 部分找到。</st> <st c="2784">但这些环境需要付费，如果您活跃使用，通常每月超过 20 美元。</st> <st c="2866">如果您的活跃程度像我一样，每月可能超过
    1000 美元！</st>
- en: <st c="2925">As a cost-effective alternative for when I am that active, I use
    Docker Desktop on my Mac, which hosts a Kubernetes cluster locally, and set up
    my notebook environment in the cluster.</st> <st c="3110">All these approaches
    have several environmental requirements that are often changing.</st> <st c="3196">It
    is best to do a little research and figure out what works best for your situation.</st>
    <st c="3282">There are similar solutions for</st> <st c="3314">Windows-based computers.</st>
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="2925">作为一个成本效益的替代方案，当我很活跃时，我会在我的 Mac 上使用 Docker Desktop，它本地托管一个 Kubernetes
    集群，并在集群中设置我的笔记本环境。</st> <st c="3110">所有这些方法都有一些环境要求，这些要求经常变化。</st> <st c="3196">最好做一点研究，找出最适合您情况的方法。</st>
    <st c="3282">对于基于 Windows 的计算机也有类似的解决方案。</st>
- en: <st c="3338">Ultimately, the primary requirement is to find an environment in
    which you can run a Jupyter notebook using Python 3\.</st> <st c="3457">The code
    we will provide will indicate what other packages you will need</st> <st c="3530">to
    install.</st>
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="3338">最终，主要要求是找到一个您可以使用 Python 3 运行 Jupyter 笔记本的环境。</st> <st c="3457">我们将提供的代码将指示您需要安装的其他包。</st>
- en: <st c="3541">Note</st>
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="3541">注意</st>
- en: <st c="3546">All of this code assumes you are working in a Jupyter notebook.</st>
    <st c="3611">You could do this directly in a Python file (</st>`<st c="3656">.py</st>`<st
    c="3659">), but you may have to change some of it.</st> <st c="3702">Running this
    in a notebook gives you the ability to step through it cell by cell and see what
    happens at each point to better understand the</st> <st c="3843">entire process.</st>
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="3546">所有这些代码都假设您正在 Jupyter 笔记本中工作。</st> <st c="3611">您可以直接在 Python 文件（</st>`<st
    c="3656">.py</st>`<st c="3659">）中这样做，但您可能需要对其进行一些修改。</st> <st c="3702">在笔记本中运行它允许您逐个单元格地执行，并查看每个点发生的情况，以便更好地理解整个过程。</st>
    <st c="3843">。</st>
- en: <st c="3858">No interface!</st>
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: <st c="3858">没有界面！</st>
- en: <st c="3872">In the following coding example, we are not going to work with
    interfaces; we will cover that in</st> [*<st c="3970">Chapter 6</st>*](B22475_06.xhtml#_idTextAnchor114)<st
    c="3979">. In the meantime, we will simply create a string variable that represents
    the prompt users would enter and use that as a fill-in for a full-fledged</st>
    <st c="4128">interface input.</st>
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="3872">在下面的编码示例中，我们不会处理接口；我们将在</st> [*<st c="3970">第6章</st>*](B22475_06.xhtml#_idTextAnchor114)<st
    c="3979">中介绍这一点。同时，我们将创建一个表示用户会输入的提示字符串变量，并将其用作完整接口输入的占位符。</st>
- en: <st c="4144">Setting up a large language model (LLM) account</st>
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: <st c="4144">设置大型语言模型（LLM）账户</st>
- en: <st c="4192">For the</st> <st c="4200">general public, OpenAI’s ChatGPT models</st>
    <st c="4240">are currently the most popular and well-known LLMs.</st> <st c="4293">However,
    there are many other LLMs available in the market that fit a myriad of purposes.</st>
    <st c="4383">You do not always need to use the most expensive, most powerful LLM.</st>
    <st c="4452">Some LLMs focus on one area, such as the Meditron LLMs, which are
    medical research-focused fine-tuned versions of Llama 2\.</st> <st c="4575">If
    you are in the medical area, you may want to use that LLM instead as it may do
    better than a big general LLM in your domain.</st> <st c="4703">Often, LLMs can
    be used to double-check other LLMs, so you have to have more than one in those
    cases.</st> <st c="4805">I strongly encourage you to not just use the first LLM
    you have worked with and to look for the LLM that best suits your needs.</st>
    <st c="4933">But to keep things simpler this early in this book, I am going to
    talk about setting up</st> <st c="5021">OpenAI’s ChatGPT:</st>
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="4192">对于</st> <st c="4200">公众，OpenAI的ChatGPT模型</st> <st c="4240">目前是最受欢迎和最知名的LLM。</st>
    <st c="4293">然而，市场上还有许多其他LLM，适用于各种用途。</st> <st c="4383">您并不总是需要使用最昂贵、最强大的LLM。</st>
    <st c="4452">一些LLM专注于一个领域，例如Meditron LLM，它是Llama 2的专注于医学研究的微调版本。</st> <st c="4575">如果您在医学领域，您可能想使用该LLM，因为它可能在您的领域内比大型通用LLM表现得更好。</st>
    <st c="4703">通常，LLM可以用作其他LLM的二次检查，因此在这些情况下您可能需要不止一个。</st> <st c="4805">我强烈建议您不要只使用您已经使用过的第一个LLM，而要寻找最适合您需求的LLM。</st>
    <st c="4933">但为了使本书早期内容更简单，我将讨论如何设置</st> <st c="5021">OpenAI的ChatGPT：</st>
- en: <st c="5038">Go to the</st> **<st c="5049">API</st>** <st c="5052">section of
    the OpenAI</st> <st c="5075">website:</st> [<st c="5084">https://openai.com/api/</st>](https://openai.com/api/)<st
    c="5107">.</st>
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="5038">访问OpenAI</st> **<st c="5049">API</st>** <st c="5052">部分：</st> [<st
    c="5084">https://openai.com/api/</st>](https://openai.com/api/)<st c="5107">。</st>
- en: <st c="5108">If you have not set up an account yet, do so now.</st> <st c="5159">The
    web page can change often, but look for where to</st> <st c="5212">sign up.</st>
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="5108">如果您尚未设置账户，请现在就设置。</st> <st c="5159">网页可能会经常更改，但请查找注册位置。</st>
- en: <st c="5220">Warning</st>
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="5220">警告</st>
- en: <st c="5228">Using OpenAI’s API costs money!</st> <st c="5261">Use</st> <st
    c="5265">it sparingly!</st>
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="5228">使用OpenAI的API需要付费！</st> <st c="5261">请谨慎使用！</st>
- en: <st c="5278">Once you’ve signed up, go to the documentation at</st> [<st c="5329">https://platform.openai.com/docs/quickstart</st>](https://platform.openai.com/docs/quickstart)
    <st c="5372">and follow the instructions to set up your first</st> <st c="5422">API
    key.</st>
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="5278">一旦您完成注册，请访问以下文档</st> [<st c="5329">https://platform.openai.com/docs/quickstart</st>](https://platform.openai.com/docs/quickstart)
    <st c="5372">并按照说明设置您的第一个</st> <st c="5422">API密钥。</st>
- en: <st c="5430">When creating an API key, give it a memorable name and select the
    type of permissions you want to implement (</st>**<st c="5540">All</st>**<st c="5544">,</st>
    **<st c="5546">Restricted</st>**<st c="5556">, or</st> **<st c="5561">Read Only</st>**<st
    c="5570">).</st> <st c="5574">If you do not know what option to select, it is
    best to go with</st> **<st c="5638">All</st>** <st c="5641">for now.</st> <st
    c="5651">However, be aware of the other options – you may want to share various
    responsibilities with other team members but restrict certain types</st> <st c="5790">of
    access:</st>
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="5430">在创建API密钥时，请给它一个容易记住的名字，并选择您想要实施的权限类型（</st>**<st c="5540">全部</st>**<st
    c="5544">、**<st c="5546">受限</st>**<st c="5556">或</st> **<st c="5561">只读</st>**<st
    c="5570">）。</st> <st c="5574">如果您不知道选择哪个选项，目前最好选择**<st c="5638">全部</st>** <st
    c="5641">。</st> <st c="5651">然而，请注意其他选项——您可能希望与其他团队成员分担各种责任，但限制某些类型的访问：</st>
- en: '**<st c="5800">All</st>**<st c="5804">: This key will have read/write access
    to all of the</st> <st c="5858">OpenAI APIs.</st>'
  id: totrans-30
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**<st c="5800">全部</st>**<st c="5804">：此密钥将具有对所有</st> <st c="5858">OpenAI API的读写访问权限。</st>'
- en: '**<st c="5870">Restricted</st>**<st c="5881">: A list of available APIs will
    appear, providing you with granular control over which APIs the key has access
    to.</st> <st c="5997">You have the option of giving just read or write access
    to each API.</st> <st c="6066">Make sure you have at least enabled the models
    and embedding APIs you will use in</st> <st c="6148">these demos.</st>'
  id: totrans-31
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**<st c="5870">受限</st>**<st c="5881">：将显示可用API列表，为您提供对密钥可以访问哪些API的细粒度控制。</st>
    <st c="5997">您可以选择为每个API提供只读或写入访问权限。</st> <st c="6066">请确保您至少已启用在这些演示中将使用的模型和嵌入API。</st>'
- en: '**<st c="6160">Read Only</st>**<st c="6170">: This option gives you read-only
    access to</st> <st c="6215">all APIs.</st>'
  id: totrans-32
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**<st c="6160">只读</st>**<st c="6170">：此选项为您提供对所有API的只读访问权限。</st>'
- en: <st c="6224">Copy the key provided.</st> <st c="6248">You will add this to your
    code shortly.</st> <st c="6288">In the meantime, keep in mind that if this key
    is shared with anyone else, whomever you provide this key can use it and you will
    be charged.</st> <st c="6429">So, this is a key that you want to consider top
    secret and take the proper precautions to prevent unauthorized use</st> <st c="6544">of
    it.</st>
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="6224">复制提供的密钥。</st> <st c="6248">您将很快将其添加到代码中。</st> <st c="6288">在此期间，请记住，如果此密钥与他人共享，任何获得此密钥的人都可以使用它，并且您将付费。</st>
    <st c="6429">因此，这是一个您希望视为绝密并采取适当预防措施以防止未经授权使用的密钥。</st>
- en: <st c="6550">The OpenAI API requires you to buy credits in advance to use the
    API.</st> <st c="6621">Buy what you are comfortable with, and then for more safety,
    make sure the</st> **<st c="6696">Enable auto recharge</st>** <st c="6716">option
    is off.</st> <st c="6732">This</st> <st c="6737">will ensure you</st> <st c="6753">are
    only spending what you intend</st> <st c="6787">to spend.</st>
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="6550">OpenAI API要求您提前购买积分才能使用API。</st> <st c="6621">购买您感到舒适的金额，并且为了更安全，请确保</st>
    **<st c="6696">启用自动充值</st>** <st c="6716">选项已关闭。</st> <st c="6732">这将确保您</st>
    <st c="6737">只花费您打算花费的金额。</st>
- en: '<st c="6796">With that, you have set up the key component that will serve as
    the</st> *<st c="6865">brains</st>* <st c="6871">in your RAG pipeline: the LLM!</st>
    <st c="6903">Next, we will set up your development environment so that you can
    connect to</st> <st c="6980">the LLM.</st>'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="6796">有了这些，您已经设置了将作为您RAG管道</st> *<st c="6865">大脑</st> <st c="6871">的关键组件：LLM！</st>
    <st c="6903">接下来，我们将设置您的开发环境，以便您可以连接到</st> <st c="6980">LLM。</st>
- en: <st c="6988">Installing the necessary packages</st>
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: <st c="6988">安装必要的软件包</st>
- en: <st c="7022">Make sure these packages are installed in your Python environment.</st>
    <st c="7090">Add the following lines of code in the first cell of</st> <st c="7143">your
    notebook:</st>
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="7022">确保这些软件包已安装到您的Python环境中。</st> <st c="7090">在笔记本的第一个单元中添加以下代码行：</st>
- en: '[PRE0]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: <st c="7355">The preceding code installs several Python libraries using the</st>
    `<st c="7419">pip</st>` <st c="7422">package manager, something you will need
    to run the code I am providing.</st> <st c="7496">Here’s a breakdown of</st> <st
    c="7518">each library:</st>
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="7355">前面的代码使用</st> `<st c="7419">pip</st>` <st c="7422">包管理器安装了几个Python库，这是运行我提供的代码所必需的。</st>
    <st c="7496">以下是每个库的</st> <st c="7518">分解：</st>
- en: '`<st c="7531">langchain_community</st>`<st c="7551">: This is a</st> <st c="7563">community-driven
    package for the LangChain library, which is an open source framework for building
    applications with LLMs.</st> <st c="7687">It provides a set of tools and components
    for working with LLMs and integrating them into</st> <st c="7777">various applications.</st>'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<st c="7531">langchain_community</st>`<st c="7551">：这是一个</st> <st c="7563">由社区驱动的LangChain库的软件包，LangChain是一个用于构建具有LLMs应用程序的开源框架。</st>
    <st c="7687">它提供了一套工具和组件，用于与LLMs协同工作并将它们集成到</st> <st c="7777">各种应用程序中。</st>'
- en: '`<st c="7798">langchain_experimental</st>`<st c="7821">: The</st> `<st c="7828">langchain_experimental</st>`
    <st c="7850">library</st> <st c="7858">offers additional capabilities and tools
    beyond the core LangChain library that are not yet fully stable or production-ready
    but are still available for experimentation</st> <st c="8028">and exploration.</st>'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<st c="7798">langchain_experimental</st>`<st c="7821">：</st> `<st c="7828">langchain_experimental</st>`
    <st c="7850">库</st> <st c="7858">提供了核心LangChain库之外的一些额外功能和工具，这些功能和工具尚未完全稳定或适用于生产，但仍可用于实验</st>
    <st c="8028">和探索。</st>'
- en: '`<st c="8044">langchain-openai</st>`<st c="8061">: This</st> <st c="8069">package
    provides integration between LangChain and OpenAI’s language models.</st> <st
    c="8146">It allows you to easily incorporate OpenAI’s models, such as ChatGPT
    4 or the OpenAI embeddings service, into your</st> <st c="8261">LangChain applications.</st>'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<st c="8044">langchain-openai</st>`<st c="8061">：这个</st> <st c="8069">包提供了LangChain与OpenAI语言模型之间的集成。</st>
    <st c="8146">它允许你轻松地将OpenAI的模型，如ChatGPT 4或OpenAI嵌入服务，集成到你的</st> <st c="8261">LangChain应用程序中。</st>'
- en: '`<st c="8284">langchainhub</st>`<st c="8297">: This</st> <st c="8305">package
    provides a collection of pre-built components and templates for LangChain applications.</st>
    <st c="8401">It includes various agents, memory components, and utility functions
    that can be used to accelerate the development of</st> <st c="8520">LangChain-based
    applications.</st>'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<st c="8284">langchainhub</st>`<st c="8297">：这个</st> <st c="8305">包提供了一组预构建的组件和模板，用于LangChain应用程序。</st>
    <st c="8401">它包括各种代理、内存组件和实用函数，可用于加速基于LangChain的应用程序的开发。</st>'
- en: '`<st c="8549">chromadb</st>`<st c="8558">: This is the</st> <st c="8573">package
    name for Chroma DB, a high-performance embedding/vector database designed for
    efficient similarity search</st> <st c="8687">and retrieval.</st>'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<st c="8549">chromadb</st>`<st c="8558">：这是Chroma DB的</st> <st c="8573">包名，Chroma
    DB是一个高性能的嵌入/向量数据库，旨在进行高效的相似性搜索和检索。</st>'
- en: '`<st c="8701">langchain</st>`<st c="8711">: This is the</st> <st c="8725">core
    LangChain library itself.</st> <st c="8757">It provides a framework and a set
    of abstractions for building applications with LLMs.</st> <st c="8844">LangChain
    includes the components needed for an effective RAG pipeline, including prompting,
    memory management, agents, and other integrations with various external tools</st>
    <st c="9015">and services.</st>'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<st c="8701">langchain</st>`<st c="8711">：这是</st> <st c="8725">核心LangChain库本身。</st>
    <st c="8757">它提供了一个框架和一系列抽象，用于构建基于LLM的应用程序。</st> <st c="8844">LangChain包括构建有效的RAG管道所需的所有组件，包括提示、内存管理、代理以及与其他各种外部工具和服务集成。</st>'
- en: <st c="9028">After running the preceding first line, you will need to restart
    your kernel to be able to access all of the new packages you just installed in
    the environment.</st> <st c="9190">Depending on what environment you are in, this
    can be done in a variety of ways.</st> <st c="9271">Typically, you will see a
    refresh button you can use or a</st> **<st c="9329">Restart kernel</st>** <st
    c="9343">option in</st> <st c="9354">the menu.</st>
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="9028">在运行前面的第一行之后，你需要重启内核才能访问你刚刚在环境中安装的所有新包。</st> <st c="9190">根据你所在的环境，这可以通过多种方式完成。</st>
    <st c="9271">通常，你会看到一个可以使用的刷新按钮，或者菜单中的</st> **<st c="9329">重启内核</st>** <st c="9343">选项。</st>
- en: <st c="9363">If you have trouble finding a way to restart the kernel, add this
    cell and</st> <st c="9439">run it:</st>
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="9363">如果你找不到重启内核的方法，请添加此单元格并</st> <st c="9439">运行它：</st>
- en: '[PRE1]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: <st c="9527">This is a code version for performing a kernel restart in an IPython
    environment (notebooks).</st> <st c="9622">You shouldn’t need it, but it is here
    for you just</st> <st c="9673">in case!</st>
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="9527">这是一个在IPython环境（笔记本）中执行内核重启的代码版本（注意：通常不需要它，但这里提供以备不时之需）。</st> <st
    c="9622">你不应该需要它，但它在这里供你使用。</st> <st c="9673">以防万一！</st>
- en: <st c="9681">Once you have installed these packages and restarted your kernel,
    you are ready to start coding!</st> <st c="9779">Let’s start with importing many
    of the packages you just installed in</st> <st c="9849">your environment.</st>
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="9681">一旦安装了这些包并重启了你的内核，你就可以开始编码了！</st> <st c="9779">让我们从导入你环境中刚刚安装的许多包开始。</st>
- en: <st c="9866">Imports</st>
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="9866">导入</st>
- en: <st c="9874">Now, let’s import all of the libraries needed to</st> <st c="9923">perform
    the RAG-related tasks.</st> <st c="9955">I have provided comments at the top of
    each group of imports to indicate what area of RAG the imports are relevant to.</st>
    <st c="10074">This, combined with the description in the following list, provides
    a basic introduction to everything you need for your first</st> <st c="10201">RAG
    pipeline:</st>
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="9874">现在，让我们导入所有执行RAG相关任务所需的</st> <st c="9923">库。</st> <st c="9955">我在每个导入组顶部提供了注释，以指示这些导入与RAG的哪个领域相关。</st>
    <st c="10074">结合以下列表中的描述，这为你的第一个</st> <st c="10201">RAG管道</st>提供了基本介绍：
- en: '[PRE2]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: <st c="10644">Let’s step through each of</st> <st c="10672">these imports:</st>
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="10644">让我们逐一查看</st> <st c="10672">这些导入：</st>
- en: '`<st c="10686">import os</st>`<st c="10696">: This</st> <st c="10703">provides
    a way to interact with the operating system.</st> <st c="10758">It is useful for
    performing operations such as accessing environment variables and working with</st>
    <st c="10854">file paths.</st>'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<st c="10686">import os</st>`<st c="10696">: 这</st> <st c="10703">提供了一种与操作系统交互的方式。</st>
    <st c="10758">这对于执行诸如访问环境变量和操作</st> <st c="10854">文件路径等操作非常有用。</st>'
- en: '`<st c="10865">from langchain_community.document_loaders import WebBaseLoader</st>`<st
    c="10928">: The</st> `<st c="10935">WebBaseLoader</st>` <st c="10948">class is
    a document loader that can fetch and load web pages</st> <st c="11010">as documents.</st>'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<st c="10865">from langchain_community.document_loaders import WebBaseLoader</st>`<st
    c="10928">: `<st c="10935">WebBaseLoader</st>` <st c="10948">类是一个文档加载器，可以获取并加载网页</st>
    <st c="11010">作为文档。</st>'
- en: '`<st c="11023">import bs4</st>`<st c="11034">: The</st> `<st c="11041">bs4</st>`
    <st c="11044">module, which stands for</st> **<st c="11070">Beautiful Soup 4</st>**<st
    c="11086">, is a popular library for web scraping and parsing HTML</st> <st c="11143">or
    XML documents.</st> <st c="11161">Since we will be working with a web page, this
    gives us a simple way to pull out the title, content, and</st> <st c="11266">headers
    separately.</st>'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<st c="11023">import bs4</st>`<st c="11034">: `<st c="11041">bs4</st>` <st
    c="11044">模块，代表</st> **<st c="11070">Beautiful Soup 4</st>**<st c="11086">，是一个流行的网络抓取和解析HTML</st>
    <st c="11143">或XML文档的库。</st> <st c="11161">由于我们将处理网页，这为我们提供了一个简单的方法来分别提取标题、内容和</st>
    <st c="11266">头部信息。</st>'
- en: '`<st c="11285">import openai</st>`<st c="11299">: This provides an interface
    to interact with OpenAI’s language models</st> <st c="11371">and APIs.</st>'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<st c="11285">import openai</st>`<st c="11299">: 这提供了与OpenAI语言模型和API交互的接口。</st>
    <st c="11371">它允许我们使用OpenAI的模型与LangChain直接交互。</st>'
- en: '`<st c="11380">from langchain_openai import ChatOpenAI, OpenAIEmbeddings</st>`<st
    c="11438">: This imports both</st> `<st c="11459">ChatOpenAI</st>` <st c="11469">(for
    the LLM) and</st> `<st c="11488">OpenAIEmbeddings</st>` <st c="11504">(for the
    embeddings), which are specific implementations of language models and embeddings
    that use OpenAI’s models that work directly</st> <st c="11640">with LangChain.</st>'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<st c="11380">from langchain_openai import ChatOpenAI, OpenAIEmbeddings</st>`<st
    c="11438">: 这导入了</st> `<st c="11459">ChatOpenAI</st>` <st c="11469">(用于LLM) 和</st>
    `<st c="11488">OpenAIEmbeddings</st>` <st c="11504">(用于嵌入)，它们是使用OpenAI模型并直接与LangChain工作的特定语言模型和嵌入的实现。</st>'
- en: '`<st c="11655">from langchain import hub</st>`<st c="11681">: The</st> `<st
    c="11688">hub</st>` <st c="11691">component provides access to various pre-built
    components and utilities for working with</st> <st c="11781">language models.</st>'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<st c="11655">from langchain import hub</st>`<st c="11681">: `<st c="11688">hub</st>`
    <st c="11691">组件提供了访问各种预构建组件和工具的途径，用于与</st> <st c="11781">语言模型一起工作。</st>'
- en: '`<st c="11797">from langchain_core.output_parsers import StrOutputParser</st>`<st
    c="11855">: This component parses the output generated by the language model and
    extracts the relevant information.</st> <st c="11962">In this case, it assumes
    that the language model’s output is a string and returns</st> <st c="12044">it
    as-is.</st>'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<st c="11797">from langchain_core.output_parsers import StrOutputParser</st>`<st
    c="11855">: 此组件解析语言模型生成的输出并提取相关信息。</st> <st c="11962">在这种情况下，它假定语言模型的输出是一个字符串，并返回</st>
    <st c="12044">它本身。</st>'
- en: '`<st c="12053">from langchain_core.runnables import RunnablePassthrough</st>`<st
    c="12110">: This component passes through the question or query without any modifications.</st>
    <st c="12192">It allows the question to be used as-is in the subsequent steps
    of</st> <st c="12259">the chain.</st>'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<st c="12053">from langchain_core.runnables import RunnablePassthrough</st>`<st
    c="12110">: 此组件将问题或查询直接传递，不进行任何修改。</st> <st c="12192">它允许将问题直接用于链的后续步骤。</st>'
- en: '`<st c="12269">Import chromadb</st>`<st c="12285">: As mentioned previously,</st>
    `<st c="12313">chromadb</st>` <st c="12321">imports the Chroma DB vector store,
    a high-performance embedding/vector database designed for efficient similarity
    search</st> <st c="12444">and retrieval.</st>'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<st c="12269">Import chromadb</st>`<st c="12285">: 如前所述，</st> `<st c="12313">chromadb</st>`
    <st c="12321">导入Chroma DB向量存储库，这是一个为高效相似性搜索和检索而设计的高性能嵌入/向量数据库。</st>'
- en: '`<st c="12458">from langchain_community.vectorstores import Chroma</st>`<st
    c="12510">: This provides an interface to interact with the Chroma vector database</st>
    <st c="12584">using LangChain.</st>'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<st c="12458">from langchain_community.vectorstores import Chroma</st>`<st
    c="12510">: 这提供了使用LangChain与Chroma向量数据库交互的接口。</st> <st c="12584">Chroma是一个高性能的嵌入/向量数据库，专为高效的相似性搜索和检索而设计。</st>'
- en: '`<st c="12600">from langchain_experimental.text_splitter import SemanticChunker</st>`<st
    c="12665">: A text splitter is typically a function that we use to split the text
    into small chunks based on a specified chunk size and overlap.</st> <st c="12801">This
    splitter is called</st> `<st c="12825">SemanticChunker</st>`<st c="12840">, an
    experimental text-splitting utility provided by the</st> `<st c="12897">Langchain_experimental</st>`
    <st c="12919">library.</st> <st c="12929">The main purpose of</st> `<st c="12949">SemanticChunker</st>`
    <st c="12964">is to break down long text into more manageable pieces while preserving
    the</st> <st c="13040">semantic coherence and context of</st> <st c="13075">each
    chunk.</st>'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<st c="12600">from langchain_experimental.text_splitter import SemanticChunker</st>`<st
    c="12665">：文本分割器通常是一个函数，我们使用它根据指定的块大小和重叠来将文本分割成小块。</st> <st c="12801">这个分割器被称为</st>
    `<st c="12825">SemanticChunker</st>`<st c="12840">，是Langchain_experimental</st>
    <st c="12897">库提供的一个实验性文本分割工具。</st> <st c="12929">SemanticChunker</st> <st c="12949">的主要目的是将长文本分解成更易于管理的片段，同时保留每个片段的</st>
    <st c="13040">语义连贯性和上下文。</st>'
- en: <st c="13086">These imports provide the essential Python packages that will
    be needed to set up your RAG pipeline.</st> <st c="13188">Your next step will
    be to connect your environment to</st> <st c="13242">OpenAI’s API.</st>
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="13086">这些导入提供了设置您的RAG管道所需的Python基本包。</st> <st c="13188">您的下一步将是将您的环境连接到</st>
    <st c="13242">OpenAI的API。</st>
- en: <st c="13255">OpenAI connection</st>
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="13255">OpenAI连接</st>
- en: <st c="13273">The following line of code is a very</st> <st c="13310">simple
    demonstration of how your API key will be ingested into the system.</st> <st c="13386">However,
    this is not a secure way to use an API key.</st> <st c="13439">There are many
    ways to do this more securely.</st> <st c="13485">If you have a preference, go
    ahead and implement it now, but otherwise, we will cover a popular way to make
    this more secure in</st> [*<st c="13613">Chapter 5</st>*](B22475_05.xhtml#_idTextAnchor095)*<st
    c="13622">.</st>*
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="13273">以下代码行是一个非常</st> <st c="13310">简单的示例，展示了您的API密钥如何被系统接收。</st> <st
    c="13386">然而，这不是使用API密钥的安全方式。</st> <st c="13439">有许多更安全的方式来完成这项任务。</st> <st c="13485">如果您有偏好，现在就实施它，否则，我们将在</st>
    [*<st c="13613">第五章</st>*](B22475_05.xhtml#_idTextAnchor095)*<st c="13622">中介绍一种流行的更安全的方法。</st>*
- en: <st c="13623">You are going to need replace</st> `<st c="13654">sk-###################</st>`
    <st c="13676">with your actual OpenAI</st> <st c="13701">API key:</st>
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="13623">您需要将</st> `<st c="13654">sk-###################</st>` <st c="13676">替换为您实际的OpenAI</st>
    <st c="13701">API密钥：</st>
- en: '[PRE3]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: <st c="13811">Important</st>
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="13811">重要</st>
- en: <st c="13821">This is just a simple example; please use a secure approach to
    hide your</st> <st c="13895">API key!</st>
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="13821">这只是一个简单的示例；请使用安全的方法来隐藏您的</st> <st c="13895">API密钥！</st>
- en: <st c="13903">You have probably guessed that this OpenAI API key will be used
    to connect to the ChatGPT LLM.</st> <st c="13999">But ChatGPT is not the only
    service we will use from OpenAI.</st> <st c="14060">This API key is also used
    to access the OpenAI embedding service.</st> <st c="14126">In the next section,
    which focuses on coding the indexing stage of the RAG process, we will utilize
    the OpenAI embedding service to convert your content into vector embeddings, a
    key aspect of the</st> <st c="14323">RAG pipeline.</st>
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="13903">您可能已经猜到了，这个OpenAI API密钥将被用来连接到ChatGPT LLM。</st> <st c="13999">但ChatGPT并不是我们将从OpenAI使用的唯一服务。</st>
    <st c="14060">这个API密钥也用于访问OpenAI嵌入服务。</st> <st c="14126">在下一节中，我们将专注于RAG过程的索引阶段编码，我们将利用OpenAI嵌入服务将您的内容转换为向量嵌入，这是RAG管道的关键方面。</st>
- en: <st c="14336">Indexing</st>
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: <st c="14336">索引</st>
- en: <st c="14345">The next few steps represent the</st> *<st c="14379">indexing</st>*
    <st c="14387">stage, where we obtain our target data, pre-process it, and vectorize
    it.</st> <st c="14462">These</st> <st c="14467">steps are often done</st> *<st
    c="14489">offline</st>*<st c="14496">, meaning they are done to</st> <st c="14523">prepare
    the application for usage later.</st> <st c="14564">But in some cases, it may
    make sense to do this all in real time, such as in rapidly changing data environments
    where the data that is used is relatively small.</st> <st c="14725">In this particular
    example, the steps are</st> <st c="14767">as follows:</st>
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 下几个步骤代表的是<st c="14345">索引</st> <st c="14379">阶段，在这个阶段我们获取目标数据，对其进行预处理，并将其矢量化。</st>
    <st c="14462">这些</st> <st c="14467">步骤通常是在</st> <st c="14489">离线</st> <st c="14496">完成的，这意味着它们是为了</st>
    <st c="14523">为后续的应用使用做准备。</st> <st c="14564">但在某些情况下，实时完成所有这些步骤可能是有意义的，例如在数据变化迅速的环境中，所使用的数据相对较小。</st>
    <st c="14725">在这个特定的例子中，步骤如下：</st> <st c="14767">。
- en: <st c="14778">Web loading</st> <st c="14791">and crawling.</st>
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="14778">网页加载</st> <st c="14791">和抓取。</st>
- en: <st c="14804">Splitting the data into digestible chunks for the Chroma DB</st>
    <st c="14865">vectorizing algorithm.</st>
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据分割成Chroma DB<st c="14804">向量化算法</st> <st c="14865">可消化的块。</st>
- en: <st c="14887">Embedding and indexing</st> <st c="14911">those chunks.</st>
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="14887">嵌入和索引</st> <st c="14911">这些块。</st>
- en: <st c="14924">Adding those chunks and embeddings to the Chroma DB</st> <st c="14977">vector
    store.</st>
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将这些块和嵌入添加到Chroma DB<st c="14924">向量存储。</st> <st c="14977">。
- en: '<st c="14990">Let’s start with the first step: web loading</st> <st c="15036">and
    crawling.</st>'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从第一步开始：网页加载<st c="14990">和抓取。</st> <st c="15036">。
- en: <st c="15049">Web loading and crawling</st>
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="15049">网页加载和抓取</st>
- en: <st c="15074">To start, we need to pull</st> <st c="15101">in our data.</st>
    <st c="15114">This could be anything of</st> <st c="15140">course, but we have
    to</st> <st c="15163">start somewhere!</st>
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要<st c="15074">拉取</st> <st c="15101">我们的数据。</st> <st c="15114">这当然可以是任何东西，但我们必须</st>
    <st c="15140">从某个地方开始！</st>
- en: <st c="15179">For our example, I am providing a web page example based on some
    of the content from</st> [*<st c="15265">Chapter 1</st>*](B22475_01.xhtml#_idTextAnchor015)<st
    c="15274">. I have adopted the original structure from an example provided by
    LangChain</st> <st c="15352">at</st> [<st c="15355">https://lilianweng.github.io/posts/2023-06-23-agent/</st>](https://lilianweng.github.io/posts/2023-06-23-agent/)<st
    c="15407">.</st>
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的例子，我提供了一个基于LangChain提供的某些内容的网页示例。</st> <st c="15179">我采用了LangChain在</st>
    [<st c="15265">第一章</st>](B22475_01.xhtml#_idTextAnchor015)<st c="15274">中提供的原始结构。</st>
    <st c="15352">在</st> [<st c="15355">https://lilianweng.github.io/posts/2023-06-23-agent/</st>](https://lilianweng.github.io/posts/2023-06-23-agent/)<st
    c="15407">。</st>
- en: <st c="15408">You can try that web page as well if it is still available when
    you read this, but be sure to change the question you use to query the content
    to a question more suitable to the content on that page.</st> <st c="15609">You
    also need to restart your kernel if you change web pages; otherwise, it will include
    content from both web pages if you rerun the loader.</st> <st c="15751">That may
    be what you want, but I’m just letting</st> <st c="15799">you know!</st>
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在阅读时该网页仍然可用，你也可以尝试那个网页，但务必将你用于查询内容的提问改为更适合该页面上内容的提问。</st> <st c="15609">如果你更改网页，你还需要重新启动你的内核；否则，如果你重新运行加载器，它将包含两个网页的内容。</st>
    <st c="15751">这可能正是你想要的，但我只是让你知道！</st> <st c="15799">。
- en: <st c="15808">I also encourage you to try this with other web pages and see
    what challenges these other pages present.</st> <st c="15914">This example involves
    a very clean piece of data compared to most web pages, which tend to be rife with
    ads and other content you do not want showing up.</st> <st c="16068">But maybe
    you can find a relatively clean blog post and pull that in?</st> <st c="16138">Maybe
    you can create your own?</st> <st c="16169">Try different web pages</st> <st c="16193">and
    see!</st>
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我还鼓励你尝试使用其他网页，看看这些其他网页会带来什么挑战。</st> <st c="15808">与大多数网页相比，这个例子涉及的数据非常干净，而大多数网页通常充满了你不想看到的广告和其他内容。</st>
    <st c="15914">但也许你可以找到一个相对干净的博客文章并将其拉取进来？</st> <st c="16068">也许你可以自己创建一个？</st>
    <st c="16138">尝试不同的网页</st> <st c="16169">并看看结果！</st>
- en: '[PRE4]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: <st c="16407">The preceding</st> <st c="16421">code starts with using the</st>
    `<st c="16449">WebBaseLoader</st>` <st c="16462">class from the</st> `<st c="16478">langchain_community
    document_loaders</st>` <st c="16514">module</st> <st c="16521">to load web pages
    as documents.</st> <st c="16554">Let’s break</st> <st c="16566">it down:</st>
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="16407">前面的</st> <st c="16421">代码开始使用</st> `<st c="16449">WebBaseLoader</st>`
    <st c="16462">类从</st> `<st c="16478">langchain_community document_loaders</st>`
    <st c="16514">模块</st> <st c="16521">加载网页作为文档。</st> <st c="16554">让我们分解一下：</st>
- en: '<st c="16574">Creating the</st> `<st c="16588">WebBaseLoader</st>` <st c="16601">instance:
    The</st> `<st c="16616">WebBaseLoader</st>` <st c="16629">class is instantiated
    with the</st> <st c="16661">following parameters:</st>'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="16574">创建</st> `<st c="16588">WebBaseLoader</st>` <st c="16601">实例：The</st>
    `<st c="16616">WebBaseLoader</st>` <st c="16629">类使用以下参数实例化：</st>
- en: '`<st c="16682">web_paths</st>`<st c="16692">: A tuple containing the URLs of
    the web pages to be loaded.</st> <st c="16754">In this case, it contains a single</st>
    <st c="16789">URL:</st> `<st c="16794">https://kbourne.github.io/chapter1.html</st>`<st
    c="16833">.</st>'
  id: totrans-89
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<st c="16682">web_paths</st>`<st c="16692">：一个包含要加载的网页URL的元组。</st> <st c="16754">在这种情况下，它包含一个单独的</st>
    <st c="16789">URL：</st> `<st c="16794">https://kbourne.github.io/chapter1.html</st>`<st
    c="16833">。</st>'
- en: '`<st c="16834">bs_kwargs</st>`<st c="16844">: A dictionary of keyword arguments
    to be passed to the</st> `<st c="16901">BeautifulSoup</st>` <st c="16914">parser.</st>'
  id: totrans-90
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<st c="16834">bs_kwargs</st>`<st c="16844">：一个字典，包含要传递给</st> `<st c="16901">BeautifulSoup</st>`
    <st c="16914">解析器的关键字参数。</st>'
- en: '`<st c="16922">parse_only</st>`<st c="16933">: A</st> `<st c="16938">bs4.SoupStrainer</st>`
    <st c="16954">object specifies the HTML elements to parse.</st> <st c="17000">In
    this case, it is set to parse only the elements with the CSS classes, such as</st>
    `<st c="17081">post-content</st>`<st c="17093">,</st> `<st c="17095">post-title</st>`<st
    c="17105">,</st> <st c="17107">and</st> `<st c="17111">post-header</st>`<st c="17122">.</st>'
  id: totrans-91
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<st c="16922">parse_only</st>`<st c="16933">：一个</st> `<st c="16938">bs4.SoupStrainer</st>`
    <st c="16954">对象指定了要解析的HTML元素。</st> <st c="17000">在这种情况下，它被设置为仅解析具有CSS类别的元素，例如</st>
    `<st c="17081">post-content</st>`<st c="17093">,</st> `<st c="17095">post-title</st>`<st
    c="17105">,</st> <st c="17107">和</st> `<st c="17111">post-header</st>`<st c="17122">。</st>'
- en: '<st c="17123">The</st> `<st c="17128">WebBaseLoader</st>` <st c="17141">instance
    initiates a series of steps that represent the loading of the document into your
    environment: The load method is called on</st> `<st c="17274">loader</st>`<st
    c="17280">, the</st> `<st c="17286">WebBaseLoader</st>` <st c="17299">instance
    that fetches and loads the specified web pages as documents.</st> <st c="17370">Internally,</st>
    `<st c="17382">loader</st>` <st c="17388">is doing</st> <st c="17398">a lot!</st>'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="17123">The</st> `<st c="17128">WebBaseLoader</st>` <st c="17141">实例启动一系列步骤，代表将文档加载到您的环境中：在</st>
    `<st c="17274">loader</st>`<st c="17280">上调用load方法，这是</st> `<st c="17286">WebBaseLoader</st>`
    <st c="17299">实例，它将指定的网页作为文档获取和加载。</st> <st c="17370">内部，</st> `<st c="17382">loader</st>`
    <st c="17388">做了很多工作！</st>
- en: <st c="17404">Here are the steps it performs just based on this small amount</st>
    <st c="17468">of code:</st>
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: <st c="17404">以下是基于这段小代码所执行的步骤：</st>
- en: <st c="17476">Makes HTTP requests to the specified URLs to fetch the</st> <st
    c="17532">web pages.</st>
  id: totrans-94
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="17476">向指定的URL发送HTTP请求以获取</st> <st c="17532">网页。</st>
- en: <st c="17542">Parses the HTML content of the web pages using</st> `<st c="17590">BeautifulSoup</st>`<st
    c="17603">, considering only the elements specified by the</st> `<st c="17652">parse_only</st>`
    <st c="17662">parameter.</st>
  id: totrans-95
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="17542">使用</st> `<st c="17590">BeautifulSoup</st>`<st c="17603">解析网页的HTML内容，仅考虑由</st>
    `<st c="17652">parse_only</st>` <st c="17662">参数指定的元素。</st>
- en: <st c="17673">Extracts the relevant text content from the parsed</st> <st c="17725">HTML
    elements.</st>
  id: totrans-96
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="17673">从解析的</st> <st c="17725">HTML元素中提取相关文本内容。</st>
- en: <st c="17739">Creates</st> `<st c="17748">Document</st>` <st c="17756">objects
    for each web page that contain the extracted text content, along with metadata
    such as the</st> <st c="17856">source URL.</st>
  id: totrans-97
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="17739">为包含提取的文本内容和元数据（如</st> <st c="17856">源URL）的每个网页创建</st> <st c="17748">Document</st>
    <st c="17756">对象。</st>
- en: <st c="17867">The resulting</st> `<st c="17882">Document</st>` <st c="17890">objects
    are stored in the</st> `<st c="17917">docs</st>` <st c="17921">variable for further
    use in</st> <st c="17950">our code!</st>
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="17867">生成的</st> `<st c="17882">Document</st>` <st c="17890">对象存储在</st>
    `<st c="17917">docs</st>` <st c="17921">变量中，以便在</st> <st c="17950">我们的代码中进一步使用！</st>
- en: <st c="17959">The classes that</st> <st c="17977">we are passing to</st> `<st
    c="17995">bs4</st>` <st c="17998">(</st>`<st c="18000">post-content</st>`<st c="18012">,</st>
    `<st c="18014">post-title</st>`<st c="18024">, and</st> `<st c="18030">post-header</st>`<st
    c="18041">) are CSS classes.</st> <st c="18061">If you are using an HTML page</st>
    <st c="18090">that does not have those CSS classes, this will not work.</st> <st
    c="18149">So, if you are using a different URL and are not getting data, take
    a look at what the CSS tags are in the HTML you are crawling.</st> <st c="18279">Many
    web pages do use this pattern, but not all!</st> <st c="18328">Crawling web pages
    presents many challenges</st> <st c="18372">like this.</st>
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="17959">我们传递给</st> `<st c="17995">bs4</st>` <st c="17998">(</st>`<st c="18000">post-content</st>`<st
    c="18012">,</st> `<st c="18014">post-title</st>`<st c="18024">, 和</st> `<st c="18030">post-header</st>`<st
    c="18041">) 的类是CSS类。</st> <st c="18061">如果您正在使用没有这些CSS类的HTML页面，这将不起作用。</st> <st
    c="18149">因此，如果您使用不同的URL并且没有获取数据，请查看您正在爬取的HTML中的CSS标签。</st> <st c="18279">许多网页确实使用这种模式，但并非所有！</st>
    <st c="18328">爬取网页会带来许多挑战</st> <st c="18372">，就像这样。</st>
- en: <st c="18382">Once you have collected the documents from your data source, you
    need to pre-process them.</st> <st c="18474">In this case, this</st> <st c="18493">involves
    splitting.</st>
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="18382">一旦您从数据源收集了文档，您需要对其进行预处理。</st> <st c="18474">在这种情况下，这</st> <st
    c="18493">涉及到分割。</st>
- en: <st c="18512">Splitting</st>
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="18512">分割</st>
- en: <st c="18522">If you are using the provided URL, you</st> <st c="18562">will
    only parse the elements with the</st> `<st c="18600">post-content</st>`<st c="18612">,</st>
    `<st c="18614">post-title</st>`<st c="18624">, and</st> `<st c="18630">post-header</st>`
    <st c="18641">CSS classes.</st> <st c="18655">This will extract the text content
    from the main article body (usually identified by the</st> `<st c="18744">post-content</st>`
    <st c="18756">class), the title of the blog post (usually identified by the</st>
    `<st c="18819">post-title</st>` <st c="18829">class), and any header information
    (usually identified by the</st> `<st c="18892">post-header</st>` <st c="18903">class).</st>
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="18522">如果您正在使用提供的URL，您</st> <st c="18562">将只会解析具有</st> `<st c="18600">post-content</st>`<st
    c="18612">,</st> `<st c="18614">post-title</st>`<st c="18624">, 和</st> `<st c="18630">post-header</st>`
    <st c="18641">CSS类</st> <st c="18655">的元素。</st> <st c="18655">这将从主要文章主体（通常通过</st>
    `<st c="18744">post-content</st>` <st c="18756">类）提取文本内容，博客文章的标题（通常通过</st> `<st
    c="18819">post-title</st>` <st c="18829">类）以及任何标题信息（通常通过</st> `<st c="18892">post-header</st>`
    <st c="18903">类）。</st>
- en: <st c="18911">In case you were curious, this is what this document looks like
    on the web (</st>*<st c="18988">Figure 2</st>**<st c="18997">.1</st>*<st c="18999">):</st>
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="18911">如果您好奇，这是该文档在网页上的样子（</st>*<st c="18988">Figure 2</st>**<st c="18997">.1</st>*<st
    c="18999">）：</st>
- en: '![Figure 2.1 – A web page that we will process](img/B22475_02_01.jpg)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![Figure 2.1 – A web page that we will process](img/B22475_02_01.jpg)'
- en: <st c="21860">Figure 2.1 – A web page that we will process</st>
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="21860">Figure 2.1 – A web page that we will process</st>
- en: <st c="21904">It goes down many pages too!</st> <st c="21934">There</st> <st
    c="21939">is a lot of content here, too much for an LLM to process directly.</st>
    <st c="22007">So, we will need to split the document into</st> <st c="22051">digestible
    chunks:</st>
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="21904">它也涉及到很多页面！</st> <st c="21934">这里的内容也很多，对于LLM直接处理来说太多了。</st> <st
    c="22007">因此，我们需要将文档分割成</st> <st c="22051">可消化的块：</st>
- en: '[PRE5]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: <st c="22166">There are many text splitters available in LangChain, but I chose
    to start with an experimental, but very interesting, option called</st> `<st c="22300">SemanticChunker</st>`<st
    c="22315">. As I mentioned previously, when talking about the imports,</st> `<st
    c="22376">SemanticChunker</st>` <st c="22391">focuses on breaking down long text
    into more manageable pieces while preserving the semantic coherence and context
    of</st> <st c="22510">each chunk.</st>
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="22166">LangChain中有很多文本分割器可用，但我选择从一种实验性但非常有趣的选项开始，称为</st> `<st c="22300">SemanticChunker</st>`<st
    c="22315">。正如我之前提到的，当谈到导入时，</st> `<st c="22376">SemanticChunker</st>` <st c="22391">专注于将长文本分解成更易于管理的片段，同时保留每个片段的语义连贯性和上下文。</st>
- en: <st c="22521">Other text splitters typically take an arbitrary chunk length
    that is not context-aware, something that creates issues when important content
    gets split by the chunker.</st> <st c="22691">There are ways to address this that
    we will talk about in</st> [*<st c="22749">Chapter 11</st>*](B22475_11.xhtml#_idTextAnchor229)<st
    c="22759">, but for now, just know that</st> `<st c="22789">SemanticChunker</st>`
    <st c="22804">focuses on accounting for context rather than just arbitrary length
    in your chunks.</st> <st c="22889">It should also be noted that it is still considered
    experimental and it is under continual development.</st> <st c="22993">In</st>
    [*<st c="22996">Chapter 11</st>*](B22475_11.xhtml#_idTextAnchor229)<st c="23006">,
    we will put it to the test against probably the other most important text splitter,</st>
    `<st c="23092">RecursiveCharacter TextSplitter</st>`<st c="23123">, and see which
    splitter works best with</st> <st c="23164">this content.</st>
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="22521">其他文本分割器通常采用任意长度的块，这不是上下文感知的，当重要内容被分割器分割时，这会引发问题。</st> <st c="22691">有方法可以解决这个问题，我们将在</st>
    [*<st c="22749">第11章</st>*](B22475_11.xhtml#_idTextAnchor229)<st c="22759">中讨论，但到目前为止，只需知道</st>
    `<st c="22789">SemanticChunker</st>` <st c="22804">专注于考虑上下文，而不仅仅是块中的任意长度。</st>
    <st c="22889">还应注意的是，它仍然被视为实验性的，并且正在持续开发中。</st> <st c="22993">在第</st> [*<st c="22996">第11章</st>*](B22475_11.xhtml#_idTextAnchor229)<st
    c="23006">中，我们将对其进行测试，与可能的其他最重要的文本分割器</st> `<st c="23092">RecursiveCharacter TextSplitter</st>`<st
    c="23123">进行比较，看看哪个分割器与</st> <st c="23164">此内容配合得最好。</st>
- en: <st c="23177">It should also be noted that the</st> `<st c="23211">SemanticChunker</st>`
    <st c="23226">splitter you use in this code uses</st> `<st c="23262">OpenAIEmbeddings</st>`<st
    c="23278">, and it costs money to process the embeddings.</st> <st c="23326">The
    OpenAI embedding models currently cost between $0.02 and $0.13 per million tokens,
    depending on what model you use.</st> <st c="23446">At the time of writing, if
    do not designate an embedding model, OpenAI will use the</st> `<st c="23530">text-embedding-ada-002</st>`
    <st c="23552">model by default, which costs $0.02 per million tokens.</st> <st
    c="23609">If you want to avoid the cost, fall back to</st> `<st c="23653">RecursiveCharacter
    TextSplitter</st>`<st c="23684">, something we will cover in</st> [*<st c="23713">Chapter
    11</st>*](B22475_11.xhtml#_idTextAnchor229)<st c="23723">.</st>
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="23177">还应注意的是，你在这段代码中使用的</st> `<st c="23211">SemanticChunker</st>` <st
    c="23226">分割器使用的是</st> `<st c="23262">OpenAIEmbeddings</st>`<st c="23278">，处理嵌入需要付费。</st>
    <st c="23326">目前，OpenAI的嵌入模型每百万个标记的成本在0.02美元到0.13美元之间，具体取决于你使用的模型。</st> <st c="23446">在撰写本文时，如果你没有指定嵌入模型，OpenAI将默认使用</st>
    `<st c="23530">text-embedding-ada-002</st>` <st c="23552">模型，每百万个标记的成本为0.02美元。</st>
    <st c="23609">如果你想避免成本，可以回退到</st> `<st c="23653">RecursiveCharacter TextSplitter</st>`<st
    c="23684">，我们将在</st> [*<st c="23713">第11章</st>*](B22475_11.xhtml#_idTextAnchor229)<st
    c="23723">中介绍。</st>
- en: <st c="23724">I encourage you to go ahead and try different splitters and see
    what happens!</st> <st c="23803">For example, do you think you get better results
    from</st> `<st c="23857">RecursiveCharacter TextSplitter</st>` <st c="23888">than
    from</st> `<st c="23899">SemanticChunker</st>`<st c="23914">, which we are using
    here?</st> <st c="23941">Maybe speed is more important</st> <st c="23971">than
    quality in your particular case – which one</st> <st c="24020">is faster?</st>
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="23724">我鼓励你尝试不同的分割器，看看会发生什么！</st> <st c="23803">例如，你认为你从</st> `<st c="23857">RecursiveCharacter
    TextSplitter</st>` <st c="23888">》中获得的结果比从</st> `<st c="23899">SemanticChunker</st>`<st
    c="23914">》获得的结果更好吗？</st> <st c="23941">也许在你的特定情况下，速度比质量更重要——哪一个更快？</st>
- en: <st c="24030">Once you have chunked up your content, the next step is to convert
    it into the vector embeddings we have talked so</st> <st c="24146">much about!</st>
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="24030">一旦将内容分块，下一步就是将其转换为我们已经讨论了很多的向量嵌入！</st> <st c="24146">！</st>
- en: <st c="24157">Embedding and indexing the chunks</st>
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="24157">嵌入和索引块</st>
- en: <st c="24191">The next few steps</st> <st c="24211">represent the retrieval
    and generation steps, where we will use Chroma DB</st> <st c="24284">as the vector
    database.</st> <st c="24309">As mentioned multiple times now, Chroma DB is a great
    vector store!</st> <st c="24377">I selected this vector store because it is easy
    to run locally and it works well for demos like this, but it is a fairly powerful
    vector store.</st> <st c="24521">As you may recall when we talked about vocabulary
    and the difference between vector stores and vector databases, Chroma DB is indeed
    both!</st> <st c="24660">Chroma is one of many options for your vector store though.</st>
    <st c="24720">In</st> [*<st c="24723">Chapter 7</st>*](B22475_07.xhtml#_idTextAnchor122)<st
    c="24732">, we will discuss many of the vector store options and reasons to choose
    one over the other.</st> <st c="24825">Some of these options even provide free
    vector</st> <st c="24872">embedding generation.</st>
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="24191">接下来的几个步骤</st> <st c="24211">代表检索和生成步骤，我们将使用Chroma DB作为向量数据库。</st>
    <st c="24284">正如之前多次提到的，Chroma DB是一个非常好的向量存储！</st> <st c="24309">我选择这个向量存储是因为它易于本地运行，并且对于此类演示效果良好，但它确实是一个相当强大的向量存储。</st>
    <st c="24377">如您所回忆的，当我们讨论词汇和向量存储与向量数据库之间的区别时，Chroma DB确实既是！</st> <st c="24521">尽管如此，Chroma只是您向量存储的许多选项之一。</st>
    <st c="24660">在第</st> [*<st c="24723">7章</st>*](B22475_07.xhtml#_idTextAnchor122)<st
    c="24732">中，我们将讨论许多向量存储选项以及选择其中一个而不是另一个的原因。</st> <st c="24825">其中一些选项甚至提供免费的向量</st>
    <st c="24872">嵌入生成。</st>
- en: <st c="24893">We are using OpenAI embeddings here as well, which will use your
    OpenAI key to send your chunks of data to the OpenAI API, convert them into embeddings,
    and then send them back in their mathematical form.</st> <st c="25099">Note that
    this</st> *<st c="25114">does</st>* <st c="25118">cost money!</st> <st c="25131">It
    is a fraction of a penny for each embedding, but it is worth noting.</st> <st
    c="25203">So, please use caution when using this code if you are doing this on
    a tight budget!</st> <st c="25288">In</st> [*<st c="25291">Chapter 7</st>*](B22475_07.xhtml#_idTextAnchor122)<st
    c="25300">, we will review some ways to use free vectorization services to generate
    these embeddings</st> <st c="25391">for free:</st>
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="24893">我们在这里也使用OpenAI嵌入，它将使用您的OpenAI密钥将您的数据块发送到OpenAI API，将它们转换为嵌入，并以数学形式发送回来。</st>
    <st c="25099">请注意，这</st> *<st c="25114">确实</st>* <st c="25118">需要付费！</st> <st
    c="25131">每个嵌入的费用是几分之一便士，但这是值得注意的。</st> <st c="25203">因此，如果您预算紧张，请谨慎使用此代码！</st>
    <st c="25288">在第</st> [*<st c="25291">7章</st>*](B22475_07.xhtml#_idTextAnchor122)<st
    c="25300">中，我们将回顾一些使用免费向量服务免费生成这些嵌入的方法</st> <st c="25391">的方法：</st>
- en: '[PRE6]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: <st c="25524">First, we create</st> <st c="25542">the Chroma vector store with
    the</st> `<st c="25575">Chroma.from_documents</st>` <st c="25596">method, which
    is called to create a Chroma vector store from the split documents.</st> <st c="25679">This
    is one of many methods we can use to create a Chroma database.</st> <st c="25747">This
    typically depends on the source, but for this particular method, it takes the</st>
    <st c="25830">following parameters:</st>
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="25524">首先，我们使用</st> `<st c="25542">Chroma.from_documents</st>` <st c="25596">方法创建Chroma向量存储，该方法用于从分割文档创建Chroma向量存储。</st>
    <st c="25679">这是我们创建Chroma数据库的许多方法之一。</st> <st c="25747">这通常取决于来源，但针对这种方法，它需要以下参数：</st>
    <st c="25830">以下参数：</st>
- en: '`<st c="25851">documents</st>`<st c="25861">: The list of split documents (splits)
    obtained from the previous</st> <st c="25928">code snippet</st>'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<st c="25851">文档</st>`<st c="25861">：从上一个代码片段中获得的分割文档（分割）列表</st>'
- en: '`<st c="25940">embedding</st>`<st c="25950">: An instance of the</st> `<st
    c="25972">OpenAIEmbeddings</st>` <st c="25988">class, which is used to generate
    embeddings for</st> <st c="26037">the documents</st>'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<st c="25940">嵌入</st>`<st c="25950">：OpenAIEmbeddings类的实例，用于生成文档的嵌入</st>'
- en: <st c="26050">Internally, the method is doing a</st> <st c="26085">few things:</st>
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="26050">在内部，该方法执行以下操作：</st>
- en: <st c="26096">It iterates over each</st> `<st c="26119">Document</st>` <st c="26127">object
    in the</st> <st c="26142">splits list.</st>
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="26096">它遍历分割列表中的每个</st> `<st c="26119">Document</st>` <st c="26127">对象。</st>
- en: <st c="26154">For each</st> `<st c="26164">Document</st>` <st c="26172">object,
    it uses the provided</st> `<st c="26202">OpenAIEmbeddings</st>` <st c="26218">instance
    to generate an</st> <st c="26243">embedding vector.</st>
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="26154">对于每个</st> `<st c="26164">Document</st>` <st c="26172">对象，它使用提供的</st>
    `<st c="26202">OpenAIEmbeddings</st>` <st c="26218">实例生成一个</st> `<st c="26243">嵌入向量</st>`。</st>
- en: <st c="26260">It stores the document text and its corresponding embedding vector
    in the Chroma</st> <st c="26342">vector database.</st>
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="26260">它将文档文本及其对应的嵌入向量存储在Chroma</st> <st c="26342">向量数据库中。</st>
- en: <st c="26358">At this point, you now have a vector database called</st> `<st
    c="26412">vectorstore</st>`<st c="26423">, and it is full of embeddings, which
    are…?</st> <st c="26467">That’s right – mathematical representations of all of
    the content from the web page you just crawled!</st> <st c="26569">So cool!</st>
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="26358">在这个阶段，你现在有一个名为</st> `<st c="26412">vectorstore</st>`<st c="26423">的向量数据库，里面充满了嵌入，这些是…？</st>
    <st c="26467">没错——是你刚刚爬取的网页上所有内容的数学表示！</st> <st c="26569">太酷了！</st>
- en: <st c="26577">But what is this next part – a retriever?</st> <st c="26620">Is
    this of the canine variety?</st> <st c="26651">Nope.</st> <st c="26657">This is
    creating the mechanism that you will use to perform vector similarity searches
    on your new vector database.</st> <st c="26773">You call the</st> `<st c="26786">as_retriever</st>`
    <st c="26798">method right on the</st> `<st c="26819">vectorstore</st>` <st c="26830">instance
    to create the retriever.</st> <st c="26865">The retriever is an object that provides
    a convenient interface for performing these similarity searches and retrieving
    the relevant documents from the vector database based on</st> <st c="27042">those
    searches.</st>
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="26577">但下一部分是什么——一个检索器？</st> <st c="26620">这是狗类的吗？</st> <st c="26651">不是。</st>
    <st c="26657">这是创建你将用于在新向量数据库上执行向量相似性搜索的机制。</st> <st c="26773">你直接在</st> `<st
    c="26786">as_retriever</st>` <st c="26798">方法上调用</st> `<st c="26819">vectorstore</st>`
    <st c="26830">实例来创建检索器。</st> <st c="26865">检索器是一个提供方便接口以执行这些相似性搜索，并根据</st> <st
    c="27042">这些搜索从向量数据库中检索相关文档的对象。</st>
- en: <st c="27057">If you just want to perform the document retrieval process, you
    can.</st> <st c="27127">This is not officially part of the code, but if you want
    to test this out, add this in an extra cell and</st> <st c="27232">run it:</st>
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="27057">如果你只想执行文档检索过程，你可以。</st> <st c="27127">这并不是代码的官方部分，但如果你想测试这个，请在一个额外的单元中添加它并</st>
    <st c="27232">运行它：</st>
- en: '[PRE7]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: <st c="27358">The output</st> <st c="27370">should be what I list later in this
    code when I indicate what is passed to the LLM, but it is essentially a list of
    the content stored in the</st> `<st c="27512">vectorstore</st>` <st c="27523">vector
    database that is most similar to</st> <st c="27564">the query.</st>
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="27358">输出</st> <st c="27370">应该是我在此代码中稍后列出当我指出传递给LLM的内容时，但它本质上是一个存储在</st>
    `<st c="27512">vectorstore</st>` <st c="27523">向量数据库中的内容列表，该数据库与</st> <st c="27564">查询最相似。</st>
- en: <st c="27574">Aren’t you impressed?</st> <st c="27597">This is a simple example
    of course, but this is the foundation for much more powerful tools that you can
    use to access your data and supercharge generative AI applications for</st> <st
    c="27773">your organization!</st>
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="27574">你不觉得印象深刻吗？</st> <st c="27597">这是一个简单的例子，但这是你用来访问数据和为你的组织超级充电生成式AI应用的基础工具！</st>
- en: <st c="27791">However, at this point in the application, you have only created
    the receiver.</st> <st c="27871">You have not used it within the RAG pipeline
    yet.</st> <st c="27921">We will review how to do</st> <st c="27946">that next!</st>
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="27791">然而，在这个应用阶段，你只创建了接收器。</st> <st c="27871">你还没有在RAG管道中使用它。</st> <st
    c="27921">我们将在下一部分回顾如何做到这一点！</st>
- en: <st c="27956">Retrieval and generation</st>
  id: totrans-131
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: <st c="27956">检索和生成</st>
- en: <st c="27981">In the code, the retrieval and generation stages</st> <st c="28030">are
    combined within the chain we set up to represent the entire RAG process.</st>
    <st c="28108">This leverages pre-built components from the</st> **<st c="28153">LangChain
    Hub</st>**<st c="28166">, such as</st> **<st c="28176">prompt templates</st>**<st
    c="28192">, and</st> <st c="28197">integrates them with a selected LLM.</st> <st
    c="28235">We will also</st> <st c="28247">utilize the</st> **<st c="28260">LangChain
    Expression Language</st>** <st c="28289">(</st>**<st c="28291">LCEL</st>**<st
    c="28295">) to</st> <st c="28301">define a chain of operations that retrieves
    relevant documents based on an input question, formats the retrieved content,
    and feeds it into the LLM to generate a response.</st> <st c="28473">Overall,
    the steps we take in retrieval and generation are</st> <st c="28532">as follows:</st>
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="27981">在代码中，检索和生成阶段</st> <st c="28030">被组合在我们设置的链中，以表示整个 RAG 流程。</st>
    <st c="28108">这利用了来自</st> **<st c="28153">LangChain Hub</st>**<st c="28166">的预构建组件，例如</st>
    **<st c="28176">提示模板</st>**<st c="28192">，并将它们与选定的 LLM 集成。</st> <st c="28235">我们还将</st>
    <st c="28247">利用</st> **<st c="28260">LangChain 表达式语言</st>** <st c="28289">(</st>**<st
    c="28291">LCEL</st>**<st c="28295">) 来</st> <st c="28301">定义一个操作链，根据输入问题检索相关文档，格式化检索内容，并将其输入到
    LLM 以生成响应。</st> <st c="28473">总的来说，我们在检索和生成中采取的步骤</st> <st c="28532">如下：</st>
- en: <st c="28543">Take in a</st> <st c="28554">user query.</st>
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="28543">接收一个</st> <st c="28554">用户查询。</st>
- en: <st c="28565">Vectorize that</st> <st c="28581">user query.</st>
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="28565">将那个</st> <st c="28581">用户查询向量化。</st>
- en: <st c="28592">Perform a similarity search of the vector store to find the closest
    vectors to the user query vector, as well as their</st> <st c="28712">associated
    content.</st>
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="28592">对向量存储执行相似度搜索，以找到与用户查询向量最接近的向量及其</st> <st c="28712">相关内容。</st>
- en: <st c="28731">Pass the</st> <st c="28740">retrieved content into a prompt template,
    a process known</st> <st c="28799">as</st> **<st c="28802">hydrating</st>**<st
    c="28811">.</st>
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="28731">将检索到的内容传递给一个提示模板，这个过程被称为</st> <st c="28799">激活</st> <st c="28811">。</st>
- en: <st c="28812">Pass that</st> *<st c="28823">hydrated</st>* <st c="28831">prompt
    to</st> <st c="28842">the LLM.</st>
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="28812">将那个</st> *<st c="28823">激活的</st>* <st c="28831">提示传递给</st> <st
    c="28842">LLM。</st>
- en: <st c="28850">Once you</st> <st c="28859">receive a response from the LLM, present
    it to</st> <st c="28907">the user.</st>
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="28850">一旦你</st> <st c="28859">从 LLM 收到响应，将其呈现给</st> <st c="28907">用户。</st>
- en: <st c="28916">From a coding standpoint, we will start by defining the prompt
    template so that we have something to hydrate when we receive the user query.</st>
    <st c="29058">We will cover this in the</st> <st c="29084">next section.</st>
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="28916">从编码的角度来看，我们将首先定义提示模板，以便在接收到用户查询时有所依据。</st> <st c="29058">我们将在下一节中介绍这一点。</st>
- en: <st c="29097">Prompt templates from the LangChain Hub</st>
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="29097">来自 LangChain Hub 的提示模板</st>
- en: <st c="29137">The LangChain Hub</st> <st c="29155">is a collection of pre-built
    components and templates that can be easily integrated into LangChain applications.</st>
    <st c="29269">It provides a centralized repository for</st> <st c="29310">sharing
    and discovering reusable components, such as prompts, agents, and utilities.</st>
    <st c="29395">Here, we are calling a prompt template from the LangChain Hub and
    assigning it to</st> `<st c="29477">prompt</st>`<st c="29483">, a prompt template
    representing what we will pass to</st> <st c="29537">the LLM:</st>
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="29137">LangChain Hub</st> <st c="29155">是一个包含预构建组件和模板的集合，可以轻松集成到 LangChain
    应用程序中。</st> <st c="29269">它提供了一个集中式存储库，用于</st> <st c="29310">共享和发现可重用组件，例如提示、代理和实用工具。</st>
    <st c="29395">在此，我们从 LangChain Hub 调用一个提示模板，并将其分配给</st> `<st c="29477">prompt</st>`<st
    c="29483">，这是一个表示我们将传递给</st> <st c="29537">LLM</st> 的提示模板：
- en: '[PRE8]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: <st c="29602">This code retrieves a pre-built prompt template from the LangChain
    Hub using the</st> `<st c="29684">pull</st>` <st c="29688">method of the</st>
    `<st c="29703">hub</st>` <st c="29706">module.</st> <st c="29715">The prompt template
    is identified by the</st> `<st c="29756">jclemens24/rag-prompt</st>` <st c="29777">string.</st>
    <st c="29786">This identifier follows the</st> *<st c="29814">repository/component</st>*
    <st c="29834">convention, where</st> *<st c="29853">repository</st>* <st c="29863">represents
    the organization or user hosting the component, and</st> *<st c="29927">component</st>*
    <st c="29936">represents the specific component being pulled.</st> <st c="29985">The</st>
    `<st c="29989">rag-prompt</st>` <st c="29999">component indicates it is a prompt
    designed for</st> <st c="30048">RAG applications.</st>
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="29602">此代码使用 LangChain 中心的</st> `<st c="29684">pull</st>` <st c="29688">方法从</st>
    `<st c="29703">hub</st>` <st c="29706">模块中检索预构建的提示模板。</st> <st c="29715">提示模板通过</st>
    `<st c="29756">jclemens24/rag-prompt</st>` <st c="29777">字符串进行标识。</st> <st c="29786">此标识符遵循</st>
    *<st c="29814">仓库/组件</st> <st c="29834">约定，其中</st> *<st c="29853">仓库</st> <st
    c="29863">代表托管组件的组织或用户，而</st> *<st c="29927">组件</st> <st c="29936">代表被拉取的具体组件。</st>
    <st c="29985">`<st c="29989">rag-prompt</st>` <st c="29999">组件表明它是一个为</st> <st
    c="30048">RAG应用</st>设计的提示。</st>
- en: <st c="30065">If you print out the prompt with</st> `<st c="30099">print(prompt)</st>`<st
    c="30112">, you can see what is used here, as well as what the</st> <st c="30165">inputs
    are:</st>
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="30065">如果你使用</st> `<st c="30099">print(prompt)</st>`<st c="30112">打印提示信息，你可以看到这里使用了什么，以及</st>
    <st c="30165">输入的内容：</st>
- en: '[PRE9]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: <st c="30564">This is the initial part of the prompt that gets passed to the
    LLM, which in this case, tells</st> <st c="30659">it this:</st>
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="30564">这是传递给 LLM 的提示信息的初始部分，它在这个例子中告诉</st> <st c="30659">它：</st>
- en: '[PRE10]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: <st c="30898">Later, you add</st> <st c="30913">the</st> `<st c="30918">question</st>`
    <st c="30926">and</st> `<st c="30931">context</st>` <st c="30938">variables to</st>
    *<st c="30952">hydrate</st>* <st c="30959">the prompt, but starting with this
    format optimizes it to work better for</st> <st c="31034">RAG applications.</st>
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="30898">稍后，你将添加</st> <st c="30913">问题</st> <st c="30926">和</st> `<st c="30931">上下文</st>`
    <st c="30938">变量来</st> *<st c="30952">填充</st> <st c="30959">提示信息，但以这种格式开始可以优化它以更好地适用于</st>
    <st c="31034">RAG应用。</st>
- en: <st c="31051">Note</st>
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="31051">注意</st>
- en: <st c="31056">The</st> `<st c="31061">jclemens24/rag-prompt</st>` <st c="31082">string
    is one version of the predefined starting prompts.</st> <st c="31141">Visit the
    LangChain Hub to find many more – you may even find one that better fits your</st>
    <st c="31229">needs:</st> [<st c="31236">https://smith.langchain.com/hub/search?q=rag-prompt</st>](https://smith.langchain.com/hub/search?q=rag-prompt)<st
    c="31287">.</st>
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="31056">`<st c="31061">jclemens24/rag-prompt</st>` <st c="31082">字符串是预定义起始提示信息的一个版本。</st>
    <st c="31141">访问 LangChain 中心以找到更多选项——你甚至可能找到一个更适合你</st> <st c="31229">需求</st>的：[<st
    c="31236">https://smith.langchain.com/hub/search?q=rag-prompt</st>](https://smith.langchain.com/hub/search?q=rag-prompt)<st
    c="31287">。</st>
- en: <st c="31288">You can also use your own!</st> <st c="31316">I can count over
    30 options at the time</st> <st c="31356">of writing!</st>
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="31288">你也可以使用自己的！</st> <st c="31316">在撰写本文时，我可以数出超过30个选项！</st>
- en: <st c="31367">The prompt template is a key part of the RAG pipeline as it represents
    how you communicate with the LLM to receive the response you are seeking.</st>
    <st c="31513">But in most RAG pipelines, getting the prompt into a format so that
    it can work with the prompt template is not as straightforward as just passing
    it a string.</st> <st c="31673">In this example, the</st> `<st c="31694">context</st>`
    <st c="31701">variable represents the content we get from the retriever and that
    is not in a string format</st> <st c="31795">yet!</st> <st c="31800">We will walk
    through how to convert our retrieved content into the proper string format we</st>
    <st c="31891">need next.</st>
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="31367">提示模板是 RAG 管道的关键部分，因为它代表了如何与 LLM 通信以获取你寻求的响应。</st> <st c="31513">但在大多数
    RAG 管道中，将提示信息转换为可以与提示模板一起工作的格式并不像只是传递一个字符串那样简单。</st> <st c="31673">在这个例子中，</st>
    `<st c="31694">上下文</st>` <st c="31701">变量代表我们从检索器获取的内容，但还不是字符串格式</st> <st c="31795">！</st>
    <st c="31800">我们将逐步说明如何将检索到的内容转换为所需的正确字符串格式。</st>
- en: <st c="31901">Formatting a function so that it matches the next step’s input</st>
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="31901">格式化函数以匹配下一步输入</st>
- en: <st c="31964">First, we will set up a</st> <st c="31988">function that takes
    the list of retrieved documents (docs)</st> <st c="32048">as input:</st>
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="31964">首先，我们将设置一个</st> <st c="31988">函数，该函数接受检索到的文档列表（docs）</st> <st
    c="32048">作为输入：</st>
- en: '[PRE11]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: <st c="32133">Inside this function, a generator expression,</st> `<st c="32180">(doc.page_content
    for doc in docs)</st>`<st c="32214">, is used to extract the</st> `<st c="32239">page_content</st>`
    <st c="32251">attribute from each document object.</st> <st c="32289">The</st>
    `<st c="32293">page_content</st>` <st c="32305">attribute represents the text
    content of</st> <st c="32347">each document.</st>
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="32133">在这个函数内部，使用了一个生成器表达式，</st> `<st c="32180">(doc.page_content for
    doc in docs)</st>`<st c="32214">，用于从每个文档对象中提取</st> `<st c="32239">page_content</st>`
    <st c="32251">属性。</st> <st c="32289">`<st c="32293">page_content</st>` <st c="32305">属性代表每个文档的</st>
    `<st c="32347">文本内容。</st>
- en: <st c="32361">Note</st>
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="32361">注意</st>
- en: <st c="32366">In this case, a</st> *<st c="32383">document</st>* <st c="32391">is
    not the entire document that you crawled earlier.</st> <st c="32445">It is just
    one small section of it, but we generally call</st> <st c="32503">these documents.</st>
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="32366">在这种情况下，一个</st> *<st c="32383">文档</st>* <st c="32391">并不是你之前爬取的整个文档。</st>
    <st c="32445">它只是其中的一小部分，但我们通常称</st> <st c="32503">这些文档。</st>
- en: <st c="32519">The</st> `<st c="32524">join</st>` <st c="32528">method is called
    on the</st> `<st c="32553">\n\n</st>` <st c="32557">string to concatenate</st>
    `<st c="32580">page_content</st>` <st c="32592">of each document with two newline
    characters between each document’s content.</st> <st c="32671">The formatted string
    is returned by the</st> `<st c="32711">format_docs</st>` <st c="32722">function
    to represent the</st> `<st c="32749">context</st>` <st c="32756">key in the dictionary
    that is piped into the</st> <st c="32802">prompt object.</st>
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="32519">`<st c="32524">join</st>` <st c="32528">方法被调用在</st> `<st c="32553">\n\n</st>`
    <st c="32557">字符串上，用于将每个文档的内容之间插入两个换行符来连接</st> `<st c="32580">page_content</st>`
    <st c="32592">。</st> <st c="32671">格式化的字符串由`<st c="32711">format_docs</st>` <st
    c="32722">函数返回，以表示字典中通过管道输入到提示对象中的`<st c="32749">context</st>` <st c="32756">键。</st>
- en: <st c="32816">The purpose of this function is to format the output of the retriever
    into the string format that it will need to be in for the next step in the chain,
    after the retriever step.</st> <st c="32995">We will explain this further in a
    moment, but short functions like this are often necessary for LangChain chains
    to match up inputs and outputs across the</st> <st c="33150">entire chain.</st>
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="32816">此函数的目的是将检索器的输出格式化为字符串格式，以便在检索器步骤之后，在链中的下一步中使用。</st> <st c="32995">我们稍后会进一步解释这一点，但像这样的简短函数对于LangChain链来说通常是必要的，以便在整个</st>
    <st c="33150">链中匹配输入和输出。</st>
- en: <st c="33163">Next, we will review the last step before we can create our LangChain
    chain – that is, defining the LLM we will use in</st> <st c="33283">that chain.</st>
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="33163">接下来，在我们能够创建我们的LangChain链之前，我们将回顾最后一步 – 那就是定义我们将要在</st> <st c="33283">该链中使用的LLM。</st>
- en: <st c="33294">Defining your LLM</st>
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="33294">定义你的LLM</st>
- en: <st c="33312">Let’s set up the</st> <st c="33329">LLM model you</st> <st c="33344">will
    use:</st>
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="33312">让我们设置你将使用的</st> <st c="33329">LLM模型：</st>
- en: '[PRE12]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: <st c="33411">The preceding code creates an instance of the</st> `<st c="33458">ChatOpenAI</st>`
    <st c="33468">class from the</st> `<st c="33484">langchain_openai</st>` <st c="33500">module,
    which serves as an interface to OpenAI’s language models, specifically the</st>
    <st c="33583">GPT-4o mini model.</st> <st c="33603">Even though this model is
    newer, it was released at a significant discount to the older models.</st> <st
    c="33699">Using this model will help keep your inference costs down while still
    allowing you to use a recent model!</st> <st c="33805">If you would like to try
    a different version of ChatGPT, such as</st> `<st c="33870">gpt-4</st>`<st c="33875">,
    you can just change the model name.</st> <st c="33913">Look up the newest models
    on the OpenAI API website – they add</st> <st c="33976">them often!</st>
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="33411">前面的代码创建了一个来自</st> `<st c="33484">langchain_openai</st>` <st c="33500">模块的</st>
    `<st c="33458">ChatOpenAI</st>` <st c="33468">类的实例，该模块作为OpenAI语言模型的接口，具体是</st>
    `<st c="33583">GPT-4o mini</st>` <st c="33583">模型。</st> <st c="33603">尽管这个模型较新，但它以比旧模型大幅折扣的价格发布。</st>
    <st c="33699">使用这个模型可以帮助你降低推理成本，同时仍然允许你使用最新的模型！</st> <st c="33805">如果你想尝试ChatGPT的不同版本，例如</st>
    `<st c="33870">gpt-4</st>`<st c="33875">，你只需更改模型名称。</st> <st c="33913">在OpenAI
    API网站上查找最新的模型 – 他们经常添加！</st>
- en: <st c="33987">Setting up a LangChain chain using LCEL</st>
  id: totrans-166
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="33987">使用LCEL设置LangChain链</st>
- en: <st c="34027">This</st> *<st c="34033">chain</st>* <st c="34038">is in</st>
    <st c="34045">a code format specific to LangChain called</st> <st c="34087">LCEL.</st>
    <st c="34094">You will see me using LCEL throughout the code from here on out.</st>
    <st c="34159">Not only does it make the code easier to read and more concise,
    but it opens up new techniques focused on improving the speed and efficiency of
    your</st> <st c="34308">LangChain code.</st>
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="34027">这个</st> *<st c="34033">链</st>* <st c="34038">是以</st> <st c="34045">LangChain特有的代码格式</st>
    <st c="34087">LCEL</st> <st c="34094">编写的。</st> <st c="34159">从现在开始，你将看到我会在代码中一直使用LCEL。</st>
    <st c="34159">这不仅使代码更容易阅读和更简洁，而且开辟了专注于提高你</st> <st c="34308">LangChain代码的速度和效率的新技术。</st>
- en: <st c="34323">If you walk through this chain, you’ll see it provides a great
    representation of the entire</st> <st c="34416">RAG process:</st>
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="34323">如果你遍历这个链，你会看到它提供了整个</st> <st c="34416">RAG过程</st>的绝佳表示：
- en: '[PRE13]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: <st c="34551">All of these components have already been described, but to summarize,
    the</st> `<st c="34627">rag_chain</st>` <st c="34636">variable represents a chain
    of operations using the LangChain framework.</st> <st c="34710">Let’s walk through
    each step of the chain, digging into what is happening at</st> <st c="34787">each
    point:</st>
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="34551">所有这些组件都已经描述过了，但为了总结，</st> `<st c="34627">rag_chain</st>` <st c="34636">变量代表了一个使用LangChain框架的操作链。</st>
    <st c="34710">让我们遍历链的每一步，深入挖掘每个点正在发生的事情：</st> <st c="34787">：</st>
- en: '`<st c="34990">rag_chain</st>` <st c="34999">variable in a moment, we will
    pass it a “question.” As shown in the preceding code, the chain starts with a
    dictionary that defines two keys:</st> `<st c="35142">"context"</st>` <st c="35151">and</st>
    `<st c="35156">"question"</st>`<st c="35166">. The question part is pretty straightforward,
    but where does the context come from?</st> <st c="35251">The</st> `<st c="35255">"context"</st>`
    <st c="35264">key assigned is the result of the</st> `<st c="35299">retriever</st>`
    <st c="35308">|</st> `<st c="35311">format_docs</st>` <st c="35322">operation.</st>'
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`<st c="34990">rag_chain</st>` <st c="34999">变量稍后我们将传递一个“问题”。如前述代码所示，链从定义了两个键的字典开始：</st>
    `<st c="35142">"context"</st>` <st c="35151">和</st> `<st c="35156">"question"</st>`<st
    c="35166">。问题部分相当直接，但上下文从何而来？</st> <st c="35251">“</st> `<st c="35255">"context"</st>`
    <st c="35264">键分配的结果是</st> `<st c="35299">retriever</st>` <st c="35308">|</st>
    `<st c="35311">format_docs</st>` <st c="35322">操作的结果。</st>'
- en: <st c="35333">Does</st> `<st c="35339">format_docs</st>` <st c="35350">sound
    familiar?</st> <st c="35367">Yes!</st> <st c="35372">That’s because we just set
    up that function previously.</st> <st c="35428">Here, we use that function alongside</st>
    `<st c="35465">retriever</st>`<st c="35474">. The</st> `<st c="35480">|</st>`
    <st c="35481">operator, called a pipe, between the retriever and</st> `<st c="35533">format_docs</st>`
    <st c="35544">indicates that we are chaining these operations together.</st> <st
    c="35603">So, in this case, the</st> `<st c="35625">retriever</st>` <st c="35634">object
    is</st> *<st c="35645">piped</st>* <st c="35650">into the</st> `<st c="35660">format_docs</st>`
    <st c="35671">function.</st> <st c="35682">We are running the</st> `<st c="35701">retriever</st>`
    <st c="35710">operation here, which is the vector similarity search.</st> <st
    c="35766">The similarity search should return a set of matches; that set of matches
    is what is passed to the function.</st> <st c="35875">Our</st> `<st c="35879">format_docs</st>`
    <st c="35890">function, as described earlier, is then used on the content provided
    by the retriever to format all the results of that retriever into a single string.</st>
    <st c="36043">That complete string is then assigned to the</st> *<st c="36088">context</st>*<st
    c="36095">, which as you may remember is a variable in our prompt.</st> <st c="36152">The
    expected input format of the next step is a dictionary with two keys – that is,</st>
    `<st c="36236">"context"</st>` <st c="36245">and</st> `<st c="36250">"question"</st>`<st
    c="36260">. The values that are assigned to these keys are expected to be strings.</st>
    <st c="36333">So, we can’t just pass retriever output, which is a list of objects.</st>
    <st c="36402">This is why we use the</st> `<st c="36425">format_docs</st>` <st
    c="36436">function – to convert the retriever results into the string we need
    for the next step.</st> <st c="36524">Let’s go back to the</st> *<st c="36545">question</st>*
    <st c="36553">that was passed into the chain, which is already in the string format
    we require.</st> <st c="36636">We don’t need any formatting!</st> <st c="36666">So,
    we use the</st> `<st c="36681">RunnablePassthrough()</st>` <st c="36702">object
    to just let that input (the</st> *<st c="36738">question</st>* <st c="36746">provided)
    pass through as the string that it is already formatted as.</st> <st c="36817">That
    object takes the</st> *<st c="36839">question</st>* <st c="36847">we pass into
    the</st> `<st c="36865">rag_chain</st>` <st c="36874">variable and passes it through
    without any modification.</st> <st c="36932">We now have our first step in the
    chain, which is defining the two variables that the prompt in the next</st> <st
    c="37037">step accepts.</st>
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: <st c="37050">We can see another pipe (</st>`<st c="37076">|</st>`<st c="37078">)
    followed by the</st> `<st c="37096">prompt</st>` <st c="37102">object, and we</st>
    *<st c="37118">pipe</st>* <st c="37122">the variables (in a dictionary) into that
    prompt object.</st> <st c="37180">This is known as hydrating the prompt.</st>
    <st c="37219">As mentioned previously, the</st> `<st c="37248">prompt</st>` <st
    c="37254">object is a prompt template that defines what we will pass to the LLM,
    and it typically includes input variables (context and question) that are filled/hydrated
    first.</st> <st c="37423">The result of this second step is the full prompt text
    as a string, with the variables filling in the placeholders for context and question.</st>
    <st c="37564">Then, we have another pipe (</st>`<st c="37592">|</st>`<st c="37594">)
    and the</st> `<st c="37604">llm</st>` <st c="37607">object that we defined earlier.</st>
    <st c="37640">As we have seen already, this step in the chain takes the output
    from the previous step, which is the prompt string that includes all the information
    from previous steps.</st> <st c="37811">The</st> `<st c="37815">llm</st>` <st
    c="37818">object represents the language model</st> <st c="37855">we set up, which
    in this case is</st> `<st c="37889">ChatGPT 4o</st>`<st c="37899">. The formatted
    prompt string is passed as input to the language model, which generates a response
    based on the provided context</st> <st c="38028">and question.</st>*   <st c="38041">It
    almost seems like this would be enough, but when you use an LLM API, it is not
    just sending you the text you might see when you type something into ChatGPT.</st>
    <st c="38202">It is in a JSON format and has a lot of other data included with
    it.</st> <st c="38271">So, to keep things simple, we are going to</st> *<st c="38314">pipe</st>*
    <st c="38318">the LLM’s output to the next step and use LangChain’s</st> `<st
    c="38373">StrOutputParser()</st>` <st c="38390">object.</st> <st c="38399">Note
    that</st> `<st c="38409">StrOutputParser()</st>` <st c="38426">is a utility class
    in LangChain that parses the key output of the language model into a string format.</st>
    <st c="38530">Not only does it strip away all the information you did not want
    to deal with right now, but it ensures that the generated response is returned
    as</st> <st c="38677">a string.</st>
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="37050">我们可以看到另一个管道（</st>`<st c="37076">|</st>`<st c="37078">）后面跟着</st>
    `<st c="37096">提示</st>` <st c="37102">对象，我们将</st> *<st c="37118">管道</st>* <st
    c="37122">变量（在一个字典中）放入那个提示对象。</st> <st c="37180">这被称为提示的填充。</st> <st c="37219">如前所述，</st>
    `<st c="37248">提示</st>` <st c="37254">对象是一个提示模板，它定义了我们将要传递给LLM的内容，并且通常包括首先填充/填充的输入变量（上下文和问题）。</st>
    <st c="37423">这一步骤的结果是完整的提示文本，作为字符串，变量填充了上下文和问题的占位符。</st> <st c="37564">然后，我们又有另一个管道（</st>`<st
    c="37592">|</st>`<st c="37594">）和</st> `<st c="37604">llm</st>` <st c="37607">对象，这是我们之前定义的。</st>
    <st c="37640">正如我们已经看到的，链中的这一步取前一步的输出，即包含前几步所有信息的提示字符串。</st> <st c="37811"></st>
    `<st c="37815">llm</st>` <st c="37818">对象代表我们设置的</st> `<st c="37855">语言模型</st>`
    <st c="37889">ChatGPT 4o</st>`<st c="37899">。格式化的提示字符串作为输入传递给语言模型，根据提供的上下文</st>
    `<st c="38028">和问题</st>` <st c="38041">生成响应。</st> *   <st c="38041">这似乎已经足够了，但当你使用LLM
    API时，它不仅仅发送你可能在ChatGPT中输入文本时看到的文本。</st> <st c="38202">它是以JSON格式发送的，并包含很多其他数据。</st>
    <st c="38271">因此，为了使事情简单，我们将</st> *<st c="38314">管道</st>* <st c="38318">LLM的输出传递到下一步，并使用LangChain的</st>
    `<st c="38373">StrOutputParser()</st>` <st c="38390">对象。</st> <st c="38399">请注意，</st>
    `<st c="38409">StrOutputParser()</st>` <st c="38426">是LangChain中的一个实用类，它将语言模型的关键输出解析为字符串格式。</st>
    <st c="38530">它不仅去除了你现在不想处理的所有信息，而且还确保生成的响应以</st> `<st c="38677">字符串</st>` <st
    c="38686">的形式返回。</st>
- en: <st c="38686">Let’s take a moment to appreciate everything we just did here.</st>
    <st c="38750">This</st> *<st c="38755">chain</st>* <st c="38760">we created using
    LangChain represents the core code for our entire RAG pipeline, and it is just
    a few</st> <st c="38863">strings long!</st>
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="38686">让我们花点时间来欣赏我们刚才所做的一切。</st> <st c="38750">我们使用LangChain创建的这个</st>
    *<st c="38755">链</st>* <st c="38760">代表了整个RAG管道的核心代码，而且它只有几个</st> `<st c="38863">字符串</st>`
    <st c="38863">那么长！</st>
- en: <st c="38876">When the user uses your application, it will start with the user
    query.</st> <st c="38949">But from a coding standpoint, we set up everything else
    so that we can process the query properly.</st> <st c="39048">At this point, we
    are ready to accept the user query, so let’s review this last step in</st> <st
    c="39136">our code.</st>
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="38876">当用户使用您的应用程序时，它将从用户查询开始。</st> <st c="38949">但从编程的角度来看，我们设置了所有其他内容，以便我们可以正确处理查询。</st>
    <st c="39048">此时，我们已经准备好接受用户查询，所以让我们回顾一下我们代码中的最后一步。</st>
- en: <st c="39145">Submitting a question for RAG</st>
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '`<st c="39145">提交RAG问题</st>`'
- en: <st c="39175">So far, you have</st> <st c="39192">defined the chain, but you
    haven’t run it.</st> <st c="39236">So, let’s run the entire RAG pipeline in this
    one line, using a query you are</st> <st c="39314">feeding in:</st>
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '`<st c="39175">到目前为止，你已经</st>` `<st c="39192">定义了链，但你还没有运行它。</st>` `<st c="39236">所以，让我们用你输入的查询运行整个RAG管道，一行代码即可：</st>`
    `<st c="39314"></st>`'
- en: '[PRE14]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: <st c="39383">As mentioned when stepping through what happens in the chain,</st>
    `<st c="39446">"What are the advantages of using RAG?"</st>` <st c="39485">is
    the string we are going to pass into the chain to begin with.</st> <st c="39551">The
    first step in the chain expects this string as the</st> *<st c="39606">question</st>*
    <st c="39614">we discussed in the previous section as one of the two expected
    variables.</st> <st c="39690">In some applications, this may not be in the proper
    format and will need an extra function to prepare it, but for this application,
    it is already in the string format we are expecting, so we pass it right into
    that</st> `<st c="39905">RunnablePassThrough()</st>` <st c="39926">object.</st>
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 如同在遍历链中发生的事情时提到的，`<st c="39383">"使用RAG的优势是什么?"</st>` `<st c="39446">是我们一开始要传递给链的字符串。</st>`
    `<st c="39485">链中的第一步期望这个字符串作为</st> *<st c="39606">问题</st>* `<st c="39614">我们在上一节讨论的作为两个期望变量之一。</st>`
    `<st c="39690">在某些应用中，这可能不是正确的格式，需要额外的函数来准备，但在这个应用中，它已经是我们期望的字符串格式，所以我们直接传递给那个</st>`
    `<st c="39905">RunnablePassThrough()</st>` `<st c="39926">对象。</st>`
- en: <st c="39934">In the future, this prompt will include a query from a user interface,
    but for now, we will represent it as this variable string.</st> <st c="40065">Keep
    in mind that this is not the only text the LLM will see; you added a more robust
    prompt defined by</st> `<st c="40169">prompt</st>` <st c="40175">previously, hydrated
    by the</st> `<st c="40204">"context"</st>` <st c="40213">and</st> `<st c="40218">"</st>``<st
    c="40219">question"</st>` <st c="40228">variables.</st>
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '`<st c="39934">将来，这个提示将包括来自用户界面的查询，但现在，我们将它表示为这个变量字符串。</st>` `<st c="40065">请记住，这不仅仅是LLM会看到的唯一文本；你之前添加了一个更健壮的提示，由</st>`
    `<st c="40169">prompt</st>` `<st c="40175">定义，并通过</st>` `<st c="40204">"context"</st>`
    `<st c="40213">和</st>` `<st c="40218">"</st>``<st c="40219">question"</st>` `<st
    c="40228">变量来填充。</st>`'
- en: <st c="40239">And that is it from a coding standpoint!</st> <st c="40281">But
    what happens when you run the code?</st> <st c="40321">Let’s review the output
    you can expect from this RAG</st> <st c="40374">pipeline code.</st>
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '`<st c="40239">这就是从编程角度的全部内容了！</st>` `<st c="40281">但当你运行代码时会发生什么呢？</st>` `<st
    c="40321">让我们回顾一下从这个RAG</st>` `<st c="40374">管道代码中可以预期的输出。</st>`'
- en: <st c="40388">Final output</st>
  id: totrans-182
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '`<st c="40388">最终输出</st>`'
- en: <st c="40401">The</st> <st c="40405">final output will look something</st> <st
    c="40439">like this:</st>
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '`<st c="40401">最终的输出将看起来像这样：</st>` `<st c="40405"></st>` `<st c="40439"></st>`'
- en: '[PRE15]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: <st c="41649">This has some</st> <st c="41664">basic formatting in it, so when
    it’s displayed, it will look like this (including the bullets and</st> <st c="41762">bolded
    text):</st>
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '`<st c="41649">这包含了一些</st>` `<st c="41664">基本的格式化，所以当它显示时，它将看起来像这样（包括项目符号和</st>`
    `<st c="41762">粗体文本）：</st>`'
- en: '`<st c="41775">The advantages of using Retrieval Augmented Generation (</st>``<st
    c="41832">RAG) include:</st>`'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '`<st c="41775">使用检索增强生成（</st>``<st c="41832">RAG）的优势包括：</st>`'
- en: '`<st c="41846">Improved Accuracy and Relevance: RAG enhances the accuracy and
    relevance of responses generated by large language models (LLMs) by fetching and
    incorporating specific information from databases or datasets in real time.</st>
    <st c="42067">This ensures outputs are based on both the model''s pre-existing
    knowledge and the most current and relevant</st>` `<st c="42175">data provided.</st>`'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<st c="41846">提高准确性和相关性：RAG通过实时从数据库或数据集中检索并整合特定信息，增强了大型语言模型（LLM）生成的响应的准确性和相关性。</st>`
    `<st c="42067">这确保了输出基于模型预先存在的知识和最新且相关的</st>` `<st c="42175">数据。</st>`'
- en: '`<st c="42189">Customization and Flexibility: RAG allows for the customization
    of responses based on domain-specific needs by integrating a company''s internal
    databases into the model''s response generation process.</st> <st c="42390">This
    level of customization is invaluable for creating personalized experiences and
    for applications requiring high specificity</st>` `<st c="42518">and detail.</st>`'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<st c="42189">定制和灵活性：通过将公司的内部数据库集成到模型的响应生成过程中，RAG允许根据特定领域的需求定制响应。</st>` `<st
    c="42390">这种程度的定制对于创建个性化的体验以及需要高度特定性和详细的应用程序来说是无价的。</st>`'
- en: '`<st c="42529">Expanding Model Knowledge Beyond Training Data: RAG overcomes
    the limitations of LLMs, which are bound by the scope of their training data.</st>
    <st c="42670">By enabling models to access and utilize information not included
    in their initial training sets, RAG effectively expands the knowledge base of
    the model without the need for retraining.</st> <st c="42857">This makes LLMs
    more versatile and adaptable to new domains or rapidly</st>` `<st c="42928">evolving
    topics.</st>`'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<st c="42529">扩展模型知识超越训练数据：RAG克服了LLMs的限制，LLMs受限于其训练数据的范围。</st> <st c="42670">通过使模型能够访问和利用其初始训练集之外的信息，RAG有效地扩展了模型的知识库，而无需重新训练。</st>
    <st c="42857">这使得LLMs更加灵活，能够适应新的领域或快速</st>` `<st c="42928">发展的主题。</st>`'
- en: <st c="42944">In your use cases, you will need to make decisions by asking questions
    such as, could a less expensive model do a good enough job at a significantly
    reduced cost?</st> <st c="43108">Or do I need to spend the extra money to get
    more robust responses?</st> <st c="43176">Your prompt may have said to keep it
    very brief and you end up with the same shorter response as a less expensive model
    anyway, so why spend the extra money?</st> <st c="43334">This is a common consideration
    when using these models, and in many cases, the largest, most expensive models
    are not always what is needed to meet the requirements of</st> <st c="43502">the
    application.</st>
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="42944">在你的用例中，你需要通过提出诸如，一个更便宜的模式能否以显著降低的成本完成足够好的工作等问题来做出决策？</st> <st
    c="43108">或者我需要额外花钱以获得更稳健的响应？</st> <st c="43176">你的提示可能要求非常简短，但你最终得到的响应与较便宜的模式一样短，那么为什么还要额外花钱呢？</st>
    <st c="43334">这在使用这些模型时是一个常见的考虑因素，在许多情况下，最大的、最昂贵的模型并不总是满足应用需求所必需的。</st>
- en: <st c="43518">Here’s what the LLM will</st> <st c="43544">see when you combine
    this with the RAG-focused prompt</st> <st c="43598">from earlier:</st>
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="43518">以下是LLM在结合之前RAG重点提示时将看到的内容：</st> <st c="43544">如下：</st> <st c="43598">（提示内容）</st>
- en: '[PRE16]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: <st c="45116">As you can see, the context is quite large—it returns all of the
    most relevant information from the original document to help the LLM determine
    how to answer the new question.</st> <st c="45293">The context</st> <st c="45304">is
    what was returned by the vector similarity search, something we will talk about
    in more depth in</st> [*<st c="45405">Chapter 8</st>*](B22475_08.xhtml#_idTextAnchor152)<st
    c="45414">.</st>
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="45116">正如你所见，上下文相当大——它返回了原始文档中最相关的所有信息，以帮助LLM确定如何回答新问题。</st> <st c="45293">上下文</st>
    <st c="45304">是向量相似度搜索返回的内容，我们将在第8章中更深入地讨论这一点。</st>
- en: <st c="45415">Complete code</st>
  id: totrans-194
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: <st c="45415">完整代码</st>
- en: <st c="45429">Here is the code in</st> <st c="45450">its entirety:</st>
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="45429">以下是代码的完整内容：</st> <st c="45450">如下：</st>
- en: '[PRE17]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: <st c="45661">Restart the kernel before running the</st> <st c="45700">following
    code:</st>
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="45661">在运行以下代码之前，请重新启动内核：</st> <st c="45700">如下：</st>
- en: '[PRE18]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: <st c="47070">Summary</st>
  id: totrans-199
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: <st c="47070">摘要</st>
- en: <st c="47078">This chapter provided a comprehensive code lab that walked through
    the implementation of a complete RAG pipeline.</st> <st c="47193">We began by
    installing the necessary Python packages, including LangChain, Chroma DB, and
    various LangChain extensions.</st> <st c="47313">Then, we learned how to set up
    an OpenAI API key, load documents from a web page using</st> `<st c="47400">WebBaseLoader</st>`<st
    c="47413">, and preprocess the HTML content with BeautifulSoup to extract</st>
    <st c="47477">relevant sections.</st>
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="47078">本章提供了一个全面的代码实验室，介绍了完整RAG管道的实现过程。</st> <st c="47193">我们首先安装了必要的Python包，包括LangChain、Chroma
    DB以及各种LangChain扩展。</st> <st c="47313">然后，我们学习了如何设置OpenAI API密钥，使用</st> `<st c="47400">WebBaseLoader</st>`<st
    c="47413">从网页中加载文档，并使用BeautifulSoup预处理HTML内容以提取</st> <st c="47477">相关部分。</st>
- en: <st c="47495">Next, the loaded documents were split into manageable chunks using</st>
    `<st c="47563">SemanticChunker</st>` <st c="47578">from LangChain’s experimental
    module.</st> <st c="47617">These chunks were then embedded into vector representations
    using OpenAI’s embedding model and stored in a Chroma DB</st> <st c="47734">vector
    database.</st>
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="47495">接下来，使用LangChain实验模块中的</st> `<st c="47563">SemanticChunker</st>`
    <st c="47578">将加载的文档分成可管理的块。</st> <st c="47617">然后，这些块被嵌入到OpenAI的嵌入模型中，并存储在Chroma
    DB</st> <st c="47734">向量数据库中。</st>
- en: <st c="47750">Next, we introduced the concept of a retriever, which is used
    to perform a vector similarity search on the embedded documents based on a given
    query.</st> <st c="47901">We stepped through the retrieval and generation stages
    of RAG, which in this case are combined into a LangChain chain using the LCEL.</st>
    <st c="48035">The chain integrates pre-built prompt templates from the LangChain
    Hub, a selected LLM, and utility functions for formatting retrieved documents
    and parsing</st> <st c="48192">LLM outputs.</st>
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="47750">接下来，我们介绍了检索器的概念，它用于根据给定的查询在嵌入的文档上执行向量相似度搜索。</st> <st c="47901">我们逐步了解了RAG的检索和生成阶段，在这个案例中，它们通过LCEL结合成一个LangChain链。</st>
    <st c="48035">该链集成了来自LangChain Hub的预构建提示模板、选定的LLM以及用于格式化检索文档和解析</st> <st c="48192">LLM输出的实用函数。</st>
- en: <st c="48204">Finally, we learned how to submit a question to the RAG pipeline
    and receive a generated response that incorporates the retrieved context.</st>
    <st c="48344">We saw the output from the LLM model and discussed key considerations
    for choosing the appropriate model based on accuracy, depth,</st> <st c="48475">and
    cost.</st>
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="48204">最后，我们学习了如何向RAG流水线提交问题，并接收一个包含检索上下文的生成响应。</st> <st c="48344">我们看到了LLM模型的输出，并讨论了基于准确性、深度和成本选择适当模型的关键考虑因素。</st>
- en: <st c="48484">Finally, the complete code for a RAG pipeline was provided!</st>
    <st c="48545">That’s it – you can close this book for now and still be able to
    build an entire RAG application.</st> <st c="48643">Good luck!</st> <st c="48654">But
    before you go, there are still many concepts to review so that you can optimize
    your RAG pipeline.</st> <st c="48757">If you do a quick search of the web for</st>
    `<st c="48797">trouble with RAG</st>` <st c="48813">or something similar, you
    will likely find millions of questions and problems highlighted where RAG applications
    have issues with all but the simplest of applications.</st> <st c="48982">There
    are also many other solutions that RAG can solve that need the code just provided
    to be adjusted.</st> <st c="49086">The rest of this book is dedicated to helping
    you build up knowledge that will help you get past any of these problems and form
    many new solutions.</st> <st c="49234">If you hit a similar challenge, don’t despair!</st>
    <st c="49281">There is a solution!</st> <st c="49302">It just might take the time
    to go beyond</st> [*<st c="49343">Chapter 2</st>*](B22475_02.xhtml#_idTextAnchor035)<st
    c="49352">!</st>
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="48484">最后，RAG流水线的完整代码已经提供！</st> <st c="48545">这就完了——你现在可以关闭这本书，仍然能够构建一个完整的RAG应用程序。</st>
    <st c="48643">祝你好运！</st> <st c="48654">但在你离开之前，还有许多概念需要复习，以便你能够优化你的RAG流水线。</st>
    <st c="48757">如果你在网上快速搜索</st> `<st c="48797">RAG问题</st>` <st c="48813">或类似的内容，你可能会发现数百万个问题和问题被突出显示，其中RAG应用程序在除了最简单的应用程序之外的所有应用程序中都存在问题。</st>
    <st c="48982">还有许多其他RAG可以解决的问题需要调整刚刚提供的代码。</st> <st c="49086">本书的其余部分致力于帮助你建立知识，这将帮助你克服任何这些问题，并形成许多新的解决方案。</st>
    <st c="49234">如果你遇到类似的挑战，不要绝望！</st> <st c="49281">有一个解决方案！</st> <st c="49302">这可能会需要花费时间去超越</st>
    [*<st c="49343">第二章</st>*](B22475_02.xhtml#_idTextAnchor035)<st c="49352">！</st>
- en: '<st c="49353">In the next chapter, we will take some of the practical applications
    we discussed in</st> [*<st c="49438">Chapter 1</st>*](B22475_01.xhtml#_idTextAnchor015)
    <st c="49447">and dive much deeper into how they are being implemented in various
    organizations.</st> <st c="49531">We will also provide some hands-on code related
    to one of the most common practical applications of RAG: providing the sources
    of the content that the RAG application is quoting</st> <st c="49709">to you.</st>'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="49353">在下一章中，我们将讨论我们在</st> [*<st c="49438">第一章</st>*](B22475_01.xhtml#_idTextAnchor015)
    <st c="49447">中讨论的一些实际应用，并深入探讨它们在各个组织中的实现方式。</st> <st c="49531">我们还将提供一些与RAG最常见实际应用之一相关的动手代码：提供RAG应用程序引用的内容来源</st>
    <st c="49709">给你。</st>
