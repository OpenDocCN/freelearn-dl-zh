- en: '6'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Text Classification Reimagined: Delving Deep into Deep Learning Language Models'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we delve into the realm of **deep learning** (**DL**) and its
    application in **natural language processing** (**NLP**), specifically focusing
    on the groundbreaking transformer-based models such as **Bidirectional Encoder
    Representations from Transformers** (**BERT**) and **generative pretrained transformer**
    (**GPT**). We begin by introducing the fundamentals of DL, elucidating its powerful
    capability to learn intricate patterns from large amounts of data, making it the
    cornerstone of state-of-the-art NLP systems.
  prefs: []
  type: TYPE_NORMAL
- en: Following this, we delve into transformers, a novel architecture that has revolutionized
    NLP by offering a more effective method of handling sequence data compared to
    traditional **recurrent neural networks** (**RNNs**) and **convolutional neural
    networks** (**CNNs**). We unpack the transformer’s unique characteristics, including
    its attention mechanisms, which allow it to focus on different parts of the input
    sequence to better understand the context.
  prefs: []
  type: TYPE_NORMAL
- en: Then, we turn our attention to BERT and GPT, transformer-based language models
    that leverage these strengths to create highly nuanced language representations.
    We provide a detailed breakdown of the BERT architecture, discussing its innovative
    use of bidirectional training to generate contextually rich word embeddings. We
    will demystify the inner workings of BERT and explore its pretraining process,
    which leverages a large corpus of text to learn language semantics.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we discuss how BERT can be fine-tuned for specific tasks, such as text
    classification. We walk you through the steps, from data preprocessing and model
    configuration to training and evaluation, providing a hands-on understanding of
    how to leverage BERT’s power for text classification.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter provides a thorough exploration of DL in NLP, moving from foundational
    concepts to practical applications, equipping you with the knowledge to harness
    the capabilities of BERT and transformer models for your text classification tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics are covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding deep learning basics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The architecture of different neural networks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transformers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Language models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The challenges of training neural networks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: BERT
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GPT
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to use language models for classification
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: NLP-ML system design example
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To successfully navigate through this chapter, certain technical prerequisites
    are necessary, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Programming knowledge**: A strong understanding of Python is essential, as
    it’s the primary language used for most DL and NLP libraries.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Machine learning fundamentals**: A good grasp of basic ML concepts such as
    training/testing data, overfitting, underfitting, accuracy, precision, recall,
    and F1 score will be valuable.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**DL basics**: Familiarity with **DL** concepts and architectures, including
    neural networks, backpropagation, activation functions, and loss functions, will
    be essential. Knowledge of RNNs and CNNs would be advantageous but not strictly
    necessary as we will focus more on transformer architectures.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**NLP basics**: Some understanding of basic NLP concepts such as tokenization,
    stemming, lemmatization, and word embeddings (such as **Word2Vec** or **GloVe**)
    would be beneficial.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Libraries and frameworks**: Experience with libraries such as **TensorFlow**
    and **PyTorch** for building and training neural models is crucial. Familiarity
    with NLP libraries such as **NLTK** or **SpaCy** can also be beneficial. For working
    with BERT specifically, knowledge of the **transformers** library from **Hugging
    Face** would be very helpful.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Hardware requirements**: DL models, especially transformer-based models such
    as BERT, are computationally intensive and typically require a modern **graphics
    processing unit** (**GPU)** to train in a reasonable amount of time. Access to
    a high-performance computer or cloud-based solutions with GPU capabilities is
    highly recommended.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Mathematics**: A good understanding of linear algebra, calculus, and probability
    is helpful for understanding the inner workings of these models, but most of the
    chapter can be understood without in-depth mathematical knowledge.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These prerequisites are intended to equip you with the necessary background
    to understand and implement the concepts discussed in the chapter. With these
    in place, you should be well-prepared to delve into the fascinating world of DL
    for text classification using **BERT**.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding deep learning basics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this part, we explain what neural network and deep neural networks are, what
    is the motivation for using them, and the different types (architectures) of deep
    learning models.
  prefs: []
  type: TYPE_NORMAL
- en: What is a neural network?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Neural networks are a subfield of **artificial intelligence** (**AI**) and ML
    that focuses on algorithms inspired by the structure and function of the brain.
    It is also known as “deep” learning because these neural networks often consist
    of many repetitive layers, creating a deep architecture.
  prefs: []
  type: TYPE_NORMAL
- en: These DL models are capable of “learning” from large volumes of complex, high-dimensional,
    and unstructured data. The term “learning” refers to the ability of the model
    to automatically learn and improve from experience without being explicitly programmed
    to do so for any one particular task of the tasks it learns.
  prefs: []
  type: TYPE_NORMAL
- en: DL can be supervised, semi-supervised, or unsupervised. It’s used in numerous
    applications, including NLP, speech recognition, image recognition, and even playing
    games. The models can identify patterns and make data-driven predictions or decisions.
  prefs: []
  type: TYPE_NORMAL
- en: One of the critical advantages of DL is its ability to process and model data
    of various types, including text, images, sound, and more. This versatility has
    led to a vast range of applications, from self-driving cars to sophisticated web
    search algorithms and highly responsive speech recognition systems.
  prefs: []
  type: TYPE_NORMAL
- en: It’s worth noting that DL, despite its high potential, also requires significant
    computational power and large amounts of high-quality data to train effectively,
    which can be a challenge.
  prefs: []
  type: TYPE_NORMAL
- en: In essence, DL is a powerful and transformative technology that is at the forefront
    of many of today’s technological advancements.
  prefs: []
  type: TYPE_NORMAL
- en: The motivation for using neural networks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Neural networks are used for a variety of reasons in the field of ML and artificial
    intelligence. Here are some of the key motivations:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Nonlinearity**: Neural networks, with their intricate structure and use of
    activation functions, can capture nonlinear relationships in data. Many real-world
    phenomena are nonlinear in nature, and neural networks offer a way to model these
    complexities.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Universal approximation theorem**: This theorem states that a neural network
    with enough hidden units can approximate virtually any function with a high degree
    of accuracy. This makes them highly flexible and adaptable to a wide range of
    tasks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Ability to handle high dimensional data**: Neural networks can handle data
    with a large number of features or dimensions effectively, which makes them useful
    for tasks such as image or speech recognition, where data is highly dimensional.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Pattern recognition and prediction**: Neural networks excel at identifying
    patterns and trends within large datasets, making them especially useful for prediction
    tasks, such as forecasting sales or predicting stock market trends.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Parallel processing**: Neural networks’ architecture allows them to perform
    many operations simultaneously, making them highly efficient when implemented
    on modern hardware.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Learning from data**: Neural networks can improve their performance as they
    are exposed to more data. This ability to learn from data makes them highly effective
    for tasks where large amounts of data are available.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Robustness**: Neural networks can handle noise in the input data and are
    robust to small variations in the input.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Additionally, neural networks are extensively used in NLP tasks due to several
    reasons. Here are some of the primary motivations:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Handling sequential data**: Natural language is inherently sequential (words
    follow one another to make coherent sentences). RNNs and their advanced versions,
    such as **long short-term memory** (**LSTM**) and **gated recurrent units** (**GRUs**),
    are types of neural networks that are capable of processing sequential data by
    maintaining a form of internal state or memory about the previous steps in the
    sequence.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Context understanding**: Neural networks, especially recurrent types, are
    capable of understanding the context in a sentence by taking into account the
    surrounding words or even previous sentences, which is crucial in NLP tasks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Semantic hashing**: Neural networks, through the use of word embeddings (such
    as Word2Vec and GloVe), can encode words in a way that preserves their semantic
    meaning. Words with similar meanings are placed closer together in the vector
    space, which is highly valuable for many NLP tasks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**End-to-end learning**: Neural networks can learn directly from raw data.
    For example, in image classification, a neural network can learn features from
    the pixel level without needing any manual feature extraction steps. This is a
    significant advantage, as the feature extraction process can be time-consuming
    and require domain expertise.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Similarly, neural networks can learn to perform NLP tasks from raw text data
    without the need for manual feature extraction. This is a big advantage in NLP,
    where creating hand-engineered features can be challenging and time-consuming.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Performance**: Neural networks, especially with the advent of transformer-based
    architectures such as BERT, GPT, and so on., have been shown to achieve state-of-the-art
    results in many NLP tasks, including but not limited to machine translation, text
    summarization, sentiment analysis, and question answering.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Handling large vocabularies**: Neural networks can effectively handle large
    vocabularies and continuous text streams, which is typical in many **NLP** problems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Learning hierarchical features**: Deep neural networks can learn hierarchical
    representations. In the context of NLP, lower layers often learn to represent
    simple things such as n-grams, whereas higher layers can represent complex concepts
    such as sentiment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Despite these advantages, it’s worth noting that neural networks also have their
    challenges, including their “black box” nature, which makes their decision-making
    process difficult to interpret, and their need for large amounts of data and computational
    resources for training. However, the benefits they provide in terms of performance
    and their ability to learn from raw text data and model complex relationships
    make them a go-to choice for many NLP tasks.
  prefs: []
  type: TYPE_NORMAL
- en: The basic design of a neural network
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A neural network consists of multiple layers of interconnected nodes, or “neurons,”
    each of which performs a simple computation on the data it receives, passing its
    output to the neurons of the next layer. Each connection between neurons has an
    associated weight that is adjusted during the learning process.
  prefs: []
  type: TYPE_NORMAL
- en: 'The architecture of a basic neural network consists of three types of layers,
    as shown in *Figure 6**.1*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.1 – Basic architecture of neural networks](img/B18949_06_001.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.1 – Basic architecture of neural networks
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following list, we explain each layer of the model in more detail:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Input layer**: This is where the network receives its input. If the network
    is designed to process an image with dimensions of 28x28 pixels, for instance,
    there would be 784 neurons in the input layer, each representing the value of
    one pixel.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Hidden layer(s)**: These are the layers between the input and output layers.
    Each neuron in a hidden layer takes the outputs of the neurons from the previous
    layer, multiplies each of these by the weight of the respective connection, and
    sums these values up. This sum is then passed through an “activation function”
    to introduce nonlinearity into the model, which helps the network learn complex
    patterns. There can be any number of hidden layers in a neural network, and a
    network with many hidden layers is often referred to as a “deep” neural network.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Output layer**: This is the final layer in the network. The neurons in this
    layer produce the final output of the network. For a classification problem, for
    instance, you might design the network to have one output neuron for each class
    in the problem, with each neuron outputting a value indicating the probability
    that the input belongs to its respective class.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The neurons in the network are interconnected. The weights of these connections,
    which are initially set to random values, represent what the network has learned
    once it has been trained on data.
  prefs: []
  type: TYPE_NORMAL
- en: During the training process, an algorithm such as backpropagation is used to
    adjust the weights of the connections in the network in response to the difference
    between the network’s output and the desired output. This process is repeated
    many times, and the network gradually improves its performance on the training
    data.
  prefs: []
  type: TYPE_NORMAL
- en: To provide a simple visual idea, imagine three sets of circles (representing
    neurons) arranged in columns (representing layers). The first column is the input
    layer, the last column is the output layer and any columns in between are the
    hidden layers. Then, imagine lines connecting every circle in each column to every
    circle in the next column, representing the weighted connections between neurons.
    That’s a basic visual representation of a neural network.
  prefs: []
  type: TYPE_NORMAL
- en: In the next part, we are going to describe the common terms related to neural
    networks.
  prefs: []
  type: TYPE_NORMAL
- en: Neural network common terms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the following subsections, we'll look at some of the most commonly used terms
    in the context of neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: Neuron (or node)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is the basic unit of computation in a neural network; typically, a simple
    computation involves inputs, weights, a bias, and an activation function. A neuron,
    also known as a node or unit, is a fundamental element in a neural network. It
    receives input from some other nodes or from an external source if the neuron
    is in the input layer. The neuron then computes an output based on this input.
  prefs: []
  type: TYPE_NORMAL
- en: Each input has an associated weight (*w*), which is assigned based on its relative
    importance to other inputs. The neuron applies a weight to the inputs, sums them
    up, and then applies an activation function to the sum plus a bias value (*b*).
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s a step-by-step breakdown:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Weighted sum**: Each input (*x*) to the neuron is multiplied by a corresponding
    weight (*w*). These weighted inputs are then summed together with a bias term
    (*b*). The bias term allows for the activation function to be shifted to the left
    or the right, helping the neuron model a wider range of patterns. Mathematically,
    this step can be represented as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>z</mi><mo>=</mo><mi>w</mi><mn>1</mn><mi
    mathvariant="normal">*</mi><mi>x</mi><mn>1</mn><mo>+</mo><mi>w</mi><mn>2</mn><mi
    mathvariant="normal">*</mi><mi>x</mi><mn>2</mn><mo>+</mo><mo>…</mo><mo>+</mo><mi>w</mi><mi
    mathvariant="normal">n</mi><mi mathvariant="normal">*</mi><mi>x</mi><mi mathvariant="normal">n</mi><mo>+</mo><mi>b</mi></mrow></mrow></math>](img/297.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: '**Activation function**: The result of the weighted sum is then passed through
    an activation function. The purpose of the activation function is to introduce
    nonlinearity into the output of a neuron. This nonlinearity allows the network
    to learn from errors and make adjustments, which is essential when it comes to
    performing complex tasks such as language translation or image recognition. Common
    choices for activation functions include the sigmoid function, hyperbolic **tangent**
    (**tanh**), and **rectified linear unit** (**ReLU**), among others.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The output of the neuron is the result of the activation function. It serves
    as the input to the neurons in the next layer of the network.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The weights and bias in the neuron are learnable parameters. In other words,
    their values are learned over time as the neural network is trained on data:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Weights**: The strength or amplitude of the connection between two neurons.
    During the training phase, the neural network learns the correct weights that
    better map inputs to outputs. Weight is used in the neuron, as explained previously.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Bias**: An additional parameter in the neuron that allows for the activation
    function to be shifted to the left or right, which can be critical for successful
    learning (also used in the neuron).'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Activation function
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The function (in each neuron) that determines the output a neuron should produce
    given its input is called an activation function. Common examples include sigmoid,
    ReLU and tanh.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some of the most common types of activation functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Sigmoid function**: This is where we’re essentially classifying the input
    as either 0 or 1\. The sigmoid function takes a real-valued input and squashes
    it to range between 0 and 1\. It’s often used in the output layer of a binary
    classification network:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><mi>f</mi><mo>(</mo><mi>x</mi><mo>)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mo>(</mo><mn>1</mn><mo>+</mo><mi>e</mi><mi>x</mi><mi>p</mi><mo>(</mo><mo>−</mo><mi>x</mi><mo>)</mo><mo>)</mo></mrow></mfrac></mrow></mrow></mrow></math>](img/298.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'However, it has two major drawbacks: **the vanishing gradients problem** (gradients
    are very small for large positive or negative inputs, which can slow down learning
    during backpropagation) and the **outputs are** **not zero-centered**.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Hyperbolic tanh function**: The tanh function also takes a real-valued input
    and squashes it to range between -1 and 1\. Unlike the sigmoid function, its output
    is zero-centered because its range is symmetric around the origin:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><mi>f</mi><mo>(</mo><mi>x</mi><mo>)</mo><mo>=</mo><mfrac><mrow><mo>(</mo><mi>e</mi><mi>x</mi><mi>p</mi><mo>(</mo><mi>x</mi><mo>)</mo><mo>−</mo><mi>e</mi><mi>x</mi><mi>p</mi><mo>(</mo><mo>−</mo><mi>x</mi><mo>)</mo><mo>)</mo></mrow><mrow><mo>(</mo><mi>e</mi><mi>x</mi><mi>p</mi><mo>(</mo><mi>x</mi><mo>)</mo><mo>+</mo><mi>e</mi><mi>x</mi><mi>p</mi><mo>(</mo><mo>−</mo><mi>x</mi><mo>)</mo><mo>)</mo></mrow></mfrac></mrow></mrow></mrow></math>](img/299.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: It also suffers from the vanishing gradients problem, as does the sigmoid function.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**ReLU function**: The ReLU function has become very popular in recent years.
    It computes the function as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><mi>f</mi><mo>(</mo><mi>x</mi><mo>)</mo><mo>=</mo><mi>m</mi><mi>a</mi><mi>x</mi><mo>(</mo><mn>0</mn><mo>,</mo><mi>x</mi><mo>)</mo></mrow></mrow></mrow></math>](img/300.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: In other words, the activation is simply the input if the input is positive;
    otherwise, it’s zero.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: It doesn’t activate all the neurons at the same time, meaning that the neurons
    will only be deactivated if the output of the linear transformation is less than
    0\. This makes the network sparse and efficient. However, ReLU units can be fragile
    during training and can “die” (they stop learning completely) if a large gradient
    flows through them.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Leaky ReLU**: Leaky ReLU is a variant of ReLU that addresses the “dying ReLU”
    problem. Instead of defining the function as *0* for negative *x*, we define it
    as a small linear component of *x*:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mrow><mi>f</mi><mo>(</mo><mi>x</mi><mo>)</mo><mo>=</mo><mi>m</mi><mi>a</mi><mi>x</mi><mo>(</mo><mn>0.01</mn><mi>x</mi><mo>,</mo><mi>x</mi><mo>)</mo></mrow></mrow></mrow></math>](img/301.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: This allows the function to “leak” some information when the input is negative
    and helps to mitigate the dying ReLU problem.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Exponential linear unit (ELU)**: ELU is also a variant of ReLU that modifies
    the function to be a non-zero value for negative *x*, which can help the learning
    process:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: f(x) = x if x > 0, else
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: α(exp(x) − 1)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Here alpha (*α*) is a constant that defines function smoothness when inputs
    are negative. ELU tends to converge cost to zero faster and produce more accurate
    results. However, it can be slower to compute because of the use of the exponential
    operation.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Softmax function**: The softmax function is often used in the output layer
    of a classifier where we’re trying to assign the input to one of several classes.
    It gives the probability that any given input belongs to each of the possible
    classes:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>f</mi><mfenced
    open="(" close=")"><msub><mi>x</mi><mi>i</mi></msub></mfenced><mo>=</mo><mfrac><msup><mi>e</mi><msub><mi>x</mi><mi>i</mi></msub></msup><mrow><msub><mo>∑</mo><mi>j</mi></msub><msup><mi>e</mi><msub><mi>x</mi><mi>j</mi></msub></msup></mrow></mfrac></mrow></mrow></math>](img/302.png)'
  prefs: []
  type: TYPE_IMG
- en: The denominator normalizes the probabilities, so they all sum up to 1 across
    all classes. The softmax function is also used in multinomial logistical regression.
  prefs: []
  type: TYPE_NORMAL
- en: Each of these activation functions has pros and cons, and the choice of activation
    function can depend on the specific application and context of the problem at
    hand.
  prefs: []
  type: TYPE_NORMAL
- en: Layer
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: A set of neurons that process signals at the same level of abstraction. The
    first layer is the input layer, the last layer is the output layer, and all layers
    in between are called hidden layers.
  prefs: []
  type: TYPE_NORMAL
- en: Epoch
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the context of training a neural network, an epoch is a term used to denote
    one complete pass through the entire training dataset. During an epoch, the neural
    network’s weights are updated in an attempt to minimize the loss function.
  prefs: []
  type: TYPE_NORMAL
- en: The number of epochs hyperparameter sets how many times the deep learning algorithm
    processes the entire training dataset. Too many epochs can cause overfitting,
    where the model performs well on training data but poorly on new data. Conversely,
    training for too few epochs may mean the model is underfitting—it could improve
    with further training.
  prefs: []
  type: TYPE_NORMAL
- en: It’s also important to note that the concept of an epoch is more relevant in
    the batch and mini-batch variants of gradient descent. In stochastic gradient
    descent, the model’s weights are updated after seeing each individual example,
    so the concept of an epoch is less straightforward.
  prefs: []
  type: TYPE_NORMAL
- en: Batch size
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The number of training instances used in one iteration. Batch size refers to
    the number of training examples used in one iteration.
  prefs: []
  type: TYPE_NORMAL
- en: 'When you start training a neural network, you have a couple of options for
    how you feed your data into the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Batch gradient descent**: Here, the entire training dataset is used to compute
    the gradient of the loss function for each iteration of the optimizer (as with
    gradient descent). In this case, the batch size is equal to the total number of
    examples in the training dataset.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Stochastic gradient descent (SGD)**: SGD uses a single example at each iteration
    of the optimizer. Therefore, the batch size for SGD is *1*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Mini-batch gradient descent**: This is a compromise between batch gradient
    descent and SGD. In mini-batch gradient descent, the batch size is usually between
    10 and 1,000 and is chosen depending on the computational resources you have.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The batch size can significantly impact the learning process. Larger batch sizes
    result in faster progress in training but don’t always converge as fast. Smaller
    batch sizes update the model frequently but the progress in training is slower.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, smaller batch sizes have a regularizing effect and can help the model
    generalize better, leading to better performance on unseen data. However, using
    a batch size that is too small can lead to unstable training, less accurate estimates
    of the gradient, and, ultimately, a model with worse performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Choosing the right batch size is a matter of trial and error and depends on
    the specific problem and the computational resources at hand:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Iterations**: The number of batches of data the algorithm has seen (or the
    number of passes it has made on the dataset).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Learning rate**: A hyperparameter that controls the speed of convergence
    of the learning algorithm by adjusting the weight update rate based on the loss
    gradient.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Loss function (cost function)**: The loss function evaluates the neural network’s
    performance on the dataset. Higher deviations between predictions and actual results
    result in a larger output from the loss function. The goal is to minimize this
    output, which will give the model more accurate predictions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Backpropagation**: The primary algorithm for performing gradient descent
    on neural networks. It calculates the gradient of the loss function at the output
    layer and distributes it back through the layers of the network, updating the
    weights and biases in a way that minimizes the loss.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Overfitting**: A situation where a model learns the detail and noise in the
    training data to the extent that it performs poorly on new, unseen data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Underfitting**: A situation where a model is too simple to learn the underlying
    structure of the data and, thus, performs poorly on both training and new data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Regularization**: A technique used to prevent overfitting by adding a penalty
    term to the loss function, which, in turn, constrains the weights of the network.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Dropout**: A regularization technique where randomly selected neurons are
    ignored during training, which helps to prevent overfitting.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**CNN**: A type of neural network well-suited to image processing and computer
    vision tasks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**RNN**: A type of neural network designed to recognize patterns in sequences
    of data, such as time series or text.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s move on to the architecture of different neural networks next.
  prefs: []
  type: TYPE_NORMAL
- en: The architecture of different neural networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Neural networks come in various types, each with a specific architecture suited
    to a different kind of task. The following list contains general descriptions
    of some of the most common types:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Feedforward neural network (FNN)**: This is the most straightforward type
    of neural network. Information in this network moves in one direction only, from
    the input layer through any hidden layers to the output layer. There are no cycles
    or loops in the network; it’s a straight, “feedforward” path.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 6.2 – Feedforward neural network](img/B18949_06_002.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.2 – Feedforward neural network
  prefs: []
  type: TYPE_NORMAL
- en: '**Multilayer perceptron (MLP)**: An MLP is a type of feedforward network that
    has at least one hidden layer in addition to its input and output layers. The
    layers are fully connected, meaning each neuron in a layer connects with every
    neuron in the next layer. MLPs can model complex patterns and are widely used
    for tasks such as image recognition, classification, speech recognition, and other
    types of machine learning tasks. The MLP is a feedforward network with layers
    of neurons arranged sequentially. Information flows from the input layer through
    hidden layers to the output layer in one direction:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 6.3 – Multilayer perceptron](img/B18949_06_003.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.3 – Multilayer perceptron
  prefs: []
  type: TYPE_NORMAL
- en: '**CNN**: A CNN is particularly well-suited to tasks involving spatial data,
    such as images. Its architecture includes three main types of layers: convolutional
    layers, pooling layers, and fully connected layers. The convolutional layers apply
    a series of filters to the input, which allows the network to automatically and
    adaptively learn spatial hierarchies of features. Pooling layers decrease the
    spatial size of the representation, thereby reducing parameters and computation
    in the network to control overfitting and decrease the computation cost in the
    following layers. Fully connected layers get the output of the pooling layer and
    conduct high-level reasoning on the output.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: "![Figure 6.4 – \uFEFFConvolutional neural network](img/B18949_06_004.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 6.4 – Convolutional neural network
  prefs: []
  type: TYPE_NORMAL
- en: '**Recurrent neural network (RNN)**: Unlike feedforward networks, RNNs have
    connections that form directed cycles. This architecture allows them to use information
    from their previous outputs as inputs, making them ideal for tasks involving sequential
    data, such as time series prediction or NLP. A significant variation of RNNs is
    the LSTM network, which uses special units in addition to standard units. RNN
    units include a "memory cell" that can maintain information in memory for long
    periods of time, a feature that is particularly useful for tasks that require
    learning from long-distance dependencies in the data, such as handwriting or speech
    recognition.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 6.5 – Recurrent neural network](img/B18949_06_005.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.5 – Recurrent neural network
  prefs: []
  type: TYPE_NORMAL
- en: '**Autoencoder (AE)**: An AE is a type of neural network used to learn the efficient
    coding of input data. It has a symmetrical architecture and is designed to apply
    backpropagation, setting the target values to be equal to the inputs. Autoencoders
    are typically used for feature extraction, learning representations of data, and
    dimensionality reduction. They’re also used in generative models, noise removal,
    and recommendation systems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 6.6 – Autoencoder architecture](img/B18949_06_006.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.6 – Autoencoder architecture
  prefs: []
  type: TYPE_NORMAL
- en: '**Generative adversarial network (GAN)**: A GAN consists of two parts, a generator
    and a discriminator, which are both neural networks. The generator creates data
    instances that aim to come from the same distribution as the training dataset.
    The discriminator’s goal is to distinguish between instances from the true distribution
    and instances from the generator. The generator and the discriminator are trained
    together, with the goal that the generator produces better instances as training
    progresses, whereas the discriminator becomes better at distinguishing true instances
    from generated ones.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 6.7 – Generative adversarial network in computer vision](img/B18949_06_007.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.7 – Generative adversarial network in computer vision
  prefs: []
  type: TYPE_NORMAL
- en: These are just a few examples of neural network architectures, and many variations
    and combinations exist. The architecture you choose for a task will depend on
    the specific requirements and constraints of your task.
  prefs: []
  type: TYPE_NORMAL
- en: The challenges of training neural networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Training neural networks is a complex task and comes with challenges during
    the training, such as local minima and vanishing/exploding gradients, as well
    as computational costs and interpretability. All challenges are explained in detail
    in the following points:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Local minima**: The objective of training a neural network is to find the
    set of weights that minimizes the loss function. This is a high-dimensional optimization
    problem, and there are many points (sets of weights) where the loss function has
    local minima. A suboptimal local minimum is a point where the loss is lower than
    for the nearby points but higher than the global minimum, which is the overall
    lowest possible loss. The training process can get stuck in such suboptimal local
    minima. It’s important to remember that the local minima problem exists even in
    convex loss functions due to the discrete representation that is a part of digital
    computation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Vanishing/exploding gradients**: This is a difficulty encountered, especially
    when training deep neural networks. The gradients of the loss function may become
    very small (vanish) or very large (explode) in deeper layers of the network during
    the backpropagation process. Vanishing gradients make it hard for the network
    to learn from the data because the weight updates become very small. Exploding
    gradients can cause the training process to fail because weight updates become
    too large, and the loss becomes undefined (e.g., NaN).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Overfitting**: One of the common problems in training machine learning models
    is when our model is too complex, and we train it too much. In this case, the
    model learns even the noises in the training data and works very well on training
    data but poorly on the unseen test data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Underfitting**: Conversely, underfitting occurs when the model is too simple
    and can’t capture the underlying structure of the data. Both overfitting and underfitting
    can be mitigated by using proper model complexity, regularization techniques,
    and a sufficient amount of training data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Computational resources**: Training neural networks, particularly deep networks,
    requires significant computational resources (CPU/GPU power and memory). They
    also often require a large amount of training data to perform well, which can
    be a problem when such data are not available.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Lack of interpretability**: While not strictly a training issue, the lack
    of interpretability of neural networks is a significant problem. They are often
    referred to as “black boxes” because it is challenging to understand why they
    are making the predictions they do.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Difficulty in selecting appropriate architecture and hyperparameters**: There
    are many types of neural network architectures to choose from (such as CNN and
    RNN), and each has a set of hyperparameters that need to be tuned (such as learning
    rate, batch size, number of layers, and number of units per layer). Selecting
    the best architecture and tuning these hyperparameters for a given problem can
    be a challenging and time-consuming task.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data preprocessing**: Neural networks often require the input data to be
    in a specific format. For instance, data might need to be normalized, categorical
    variables might need to be one-hot encoded, and missing values might need to be
    imputed. This preprocessing can be a complex and time-consuming step.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These challenges make training neural networks a non-trivial task, often requiring
    a combination of technical expertise, computational resources, and trial and error.
  prefs: []
  type: TYPE_NORMAL
- en: Language models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A language model is a statistical model in NLP that is designed to learn and
    understand the structure of human language. More specifically, it is a probabilistic
    model that is trained to estimate the likelihood of words when provided with a
    given word scenario. For instance, a language model could be trained to predict
    the next word in a sentence, given the previous words.
  prefs: []
  type: TYPE_NORMAL
- en: Language models are fundamental to many NLP tasks. They are used in machine
    translation, speech recognition, part-of-speech tagging, and named entity recognition,
    among other things. More recently, they have been used to create conversational
    AI models such as chatbots and personal assistants and to generate human-like
    text.
  prefs: []
  type: TYPE_NORMAL
- en: Traditional language models were often based on explicitly statistical methods,
    such as n-gram models, which consider only the previous n words when predicting
    the next word, or **hidden Markov** **models** (**HMMs**).
  prefs: []
  type: TYPE_NORMAL
- en: More recently, neural networks have become popular for creating language models,
    leading to the rise of neural language models. These models use the power of neural
    networks to consider the context of each word when making predictions, resulting
    in higher accuracy and fluency. Examples of neural language models include RNNs,
    the transformer model, and various transformer-based architectures such as BERT
    and GPT.
  prefs: []
  type: TYPE_NORMAL
- en: Language models are essential for understanding, generating, and interpreting
    human language in a computational setting, and they play a vital role in many
    applications of NLP.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are several motivations for using language models:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Machine translation**: Language models are a crucial component in systems
    that translate text from one language to another. They can assess the fluency
    of translated sentences and help choose between multiple possible translations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Speech recognition**: Language models are used in speech recognition systems
    to help distinguish between words and phrases that sound similar. By predicting
    what word is likely to come next in a sentence, they can improve the accuracy
    of transcription.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Information retrieval**: When you search for something on the internet, language
    models help to determine what documents are relevant to your query. They can understand
    the semantic similarity between your search terms and potential results.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Text generation**: Language models can generate human-like text, which is
    useful in various applications such as chatbots, writing assistants, and content
    creation tools. For example, a chatbot can use a language model to generate appropriate
    responses to user queries.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sentiment analysis**: By understanding the structure of language, language
    models can help determine whether the sentiment of a piece of text is positive,
    negative, or neutral. This is useful in areas such as social media monitoring,
    product reviews, and customer feedback.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Grammar checking**: Language models can predict what word should come next
    in a sentence, which can help identify grammatical errors or awkward phrasing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Named entity recognition**: Language models can help identify named entities
    in text, such as people, organizations, locations, and more. This can be useful
    for tasks such as information extraction and automated summarization.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Understanding context**: Language models, especially recent models based
    on **DL**, such as transformers, are excellent at understanding the context of
    words and sentences. This capability is vital for many **NLP** tasks, such as
    question answering, summarization, and dialogue systems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'All these motivations stem from a central theme: language models help machines
    understand and generate human language more effectively, which is crucial for
    many applications in today’s data-driven world.'
  prefs: []
  type: TYPE_NORMAL
- en: In the following section, we introduce the different types of learning and then
    explain how one can use self-supervised learning to train language models.
  prefs: []
  type: TYPE_NORMAL
- en: Semi-supervised learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Semi-supervised learning is a type of ML approach that utilizes both labeled
    and unlabeled data for training. It is particularly useful when you have a small
    amount of labeled data and a large amount of unlabeled data. The strategy here
    is to use the labeled data to train an initial model and then use this model to
    predict labels for the unlabeled data. The model is then retrained using the newly
    labeled data, improving its accuracy in the process.
  prefs: []
  type: TYPE_NORMAL
- en: Unsupervised learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Unsupervised learning, on the other hand, involves training models entirely
    on unlabeled data. The goal here is to find underlying patterns or structures
    in the data. Unsupervised learning includes techniques such as clustering (where
    the aim is to group similar instances together) and dimensionality reduction (where
    the aim is to simplify the data without losing too much information).
  prefs: []
  type: TYPE_NORMAL
- en: Using self-supervised learning to train language models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Self-supervised learning is a form of unsupervised learning where the data provides
    the supervision. In other words, the model learns to predict certain parts of
    the input data from other parts of the same input data. It does not require explicit
    labels provided by humans, hence the term “self-supervised.”
  prefs: []
  type: TYPE_NORMAL
- en: In the context of language models, self-supervision is typically implemented
    by predicting parts of a sentence when given other parts. For example, given the
    sentence “The cat is on the __,” the model would be trained to predict the missing
    word (“mat,” in this case).
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at a couple of popular self-supervised learning strategies for training
    language models next.
  prefs: []
  type: TYPE_NORMAL
- en: Masked language modeling (MLM)
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: This strategy, used in the training of BERT, randomly masks some percentage
    of the input tokens and tasks the model with predicting the masked words based
    on the context provided by the unmasked words. For instance, in the sentence “The
    cat is on the mat,” we could mask “cat,” and the model’s job would be to predict
    this word. Please note that more than one word can also be masked.
  prefs: []
  type: TYPE_NORMAL
- en: 'Mathematically, the objective of an MLM is to maximize the following likelihood:'
  prefs: []
  type: TYPE_NORMAL
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:munder><mml:mo
    stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mrow><mml:mrow><mml:mi
    mathvariant="normal">log</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mfenced
    separators="|"><mml:mrow><mml:mi>P</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:mi>θ</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math>](img/303.png)'
  prefs: []
  type: TYPE_IMG
- en: where *w*_i is a masked word, *w*_{-i} are the non-masked words, and *θ* represents
    the model parameters.
  prefs: []
  type: TYPE_NORMAL
- en: Autoregressive language modeling
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In autoregressive language modeling, which is used in models such as GPT, the
    model predicts the next word in a sentence given all the preceding words. It’s
    trained to maximize the likelihood of a word given its previous words in the sentence.
  prefs: []
  type: TYPE_NORMAL
- en: The objective of an autoregressive language model is to maximize
  prefs: []
  type: TYPE_NORMAL
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>L</mi><mo>=</mo><mrow><munder><mo>∑</mo><mi>i</mi></munder><mrow><mi>log</mi><mfenced
    open="(" close=")"><mrow><mi>P</mi><mo>(</mo><msub><mi>w</mi><mi>i</mi></msub><mo>|</mo><msub><mi>w</mi><mn>1</mn></msub><mo>,</mo><mo>…</mo><mo>,</mo><msub><mi>w</mi><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>;</mo><mi>θ</mi><mo>)</mo></mrow></mfenced></mrow></mrow></mrow></mrow></math>](img/304.png)'
  prefs: []
  type: TYPE_IMG
- en: where *w_*i is the current word, ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math>](img/305.png)
    are the previous words, and *θ* represents the model parameters.
  prefs: []
  type: TYPE_NORMAL
- en: These strategies enable language models to obtain a rich understanding of language
    syntax and semantics directly from raw text without the need for explicit labels.
    The models can then be fine-tuned for various tasks such as text classification,
    sentiment analysis, and more, leveraging the language understanding gained from
    the self-supervised pretraining phase.
  prefs: []
  type: TYPE_NORMAL
- en: Transfer learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Transfer learning is an ML technique where a pretrained model is reused as the
    starting point for a different but related problem. Compared to traditional ML
    approaches, where you start with initializing your model with random weights,
    transfer learning has the advantage of kick-starting the learning process from
    patterns that have been learned from a related task, which can both speed up the
    training process and improve the performance of the model, especially when you
    have limited labeled training data.
  prefs: []
  type: TYPE_NORMAL
- en: In transfer learning, a model is typically trained on a large-scale task, and
    then parts of the model are used as a starting point for another task. The large-scale
    task is often chosen to be broad enough that the learned representations are useful
    for many different tasks. This process works particularly well when the input
    data for both tasks are of the same type and the tasks are related.
  prefs: []
  type: TYPE_NORMAL
- en: There are several ways to apply transfer learning, and the best approach can
    depend on how much data you have for your task and how similar your task is to
    the original task the model was trained on.
  prefs: []
  type: TYPE_NORMAL
- en: Feature extraction
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The pretrained model acts as a feature extractor. You remove the last layer
    or several layers of the model, leaving the rest of the network intact. Then,
    you pass your data through this truncated model and use the output as input to
    a new, smaller model that is trained for your specific task.
  prefs: []
  type: TYPE_NORMAL
- en: Fine-tuning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You use the pretrained model as a starting point and update all or some of the
    model’s parameters for your new task. In other words, you continue the training
    where it left off, allowing the model to adjust from generic feature extraction
    to features more specific to your task. Often, a lower learning rate is used during
    fine-tuning to avoid overwriting the prelearned features entirely during training.
  prefs: []
  type: TYPE_NORMAL
- en: Transfer learning is a powerful technique that can be used to improve the performance
    of ML models. It is particularly useful for tasks where there are limited labeled
    data available. It is commonly used in DL applications. For instance, it’s almost
    a standard in image classification problems where pretrained models on ImageNet,
    a large-scale annotated image dataset (ResNet, VGG, Inception, and so on), are
    used as the starting point. The features learned by these models are generic for
    image classification and can be fine-tuned on a specific image classification
    task with a smaller amount of data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some examples of how transfer learning can be used:'
  prefs: []
  type: TYPE_NORMAL
- en: A model trained to classify images of cats and dogs can be used to fine-tune
    a model to classify images of other animals, such as birds or fish
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A model trained to translate text from English to Spanish can be used to fine-tune
    a model to translate text from Spanish to French
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A model trained to predict the price of a house can be used to fine-tune a model
    to predict the price of a car
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Similarly, in natural language processing, large pretrained models, such as
    BERT or GPT, are often used as the starting point for a wide range of tasks. These
    models are pretrained on a large corpus of text and learn a rich representation
    of language that can be fine-tuned for specific tasks such as text classification,
    sentiment analysis, question answering, and more.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding transformers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Transformers are a type of neural network architecture that was introduced in
    a paper called *Attention is All You Need* by Ashish Vaswani, Noam Shazeer, Niki
    Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, and Illia
    Polosukhin (*Advances in neural information processing systems 30* (2017), Harvard).
    They have been very influential in the field of NLP and have formed the basis
    for state-of-the-art models such as BERT and GPT.
  prefs: []
  type: TYPE_NORMAL
- en: The key innovation in transformers is the self-attention mechanism, which allows
    the model to weigh the relevance of each word in the input when producing an output,
    thereby considering the context of each word. This is unlike previous models such
    as RNNs or RNNs, which process the input sequentially and, therefore, have a harder
    time capturing the long-range dependencies between words.
  prefs: []
  type: TYPE_NORMAL
- en: Architecture of transformers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A transformer is composed of an encoder and a decoder, both of which are made
    up of several identical layers, as shown in *Figure 6**.8*. Each layer in the
    encoder contains two sub-layers: a self-attention mechanism and a position-wise
    fully connected feedforward network. A residual connection is employed around
    each of the two sub-layers, followed by layer normalization:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.8 – Self-attention mechanism](img/B18949_06_008.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.8 – Self-attention mechanism
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, each layer in the decoder has three sub-layers. The first is a self-attention
    layer, the second is a cross-attention layer that attends to the output of the
    encoder stack, and the third is a position-wise fully connected feedforward network.
    Like the encoder, each of these sub-layers has a residual connection around it,
    followed by layer normalization. Please note that in the figure, just one head
    is being shown, and we can have multiple heads working in parallel (*N* heads).
  prefs: []
  type: TYPE_NORMAL
- en: Self-attention mechanism
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The self-attention mechanism, or scaled dot-product attention, calculates the
    relevance of each word in the sequence to the current word being processed. The
    input to the self-attention layer is a sequence of word embeddings, each of which
    is split into a **query** (*Q*), a **key** (*K*), and a **value** (*V*) using
    separately learned linear transformations.
  prefs: []
  type: TYPE_NORMAL
- en: 'The attention score for each word is then calculated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: "![<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mrow><mrow><mrow><mi>A</mi><mi>t</mi><mi>t</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>(</mo><mi>Q</mi><mo>,</mo><mi>K</mi><mo>,</mo><mi>V</mi><mo>)</mo><mo>=</mo><mi>s</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mo>(</mo><mi>Q</mi><mi>K</mi><mi\
    \ mathvariant=\"normal\">\uFEFF</mi><mi mathvariant=\"normal\">T</mi><mo>/</mo><mi>s</mi><mi>q</mi><mi>r</mi><mi>t</mi><mo>(</mo><mi>d</mi><mo>_</mo><mi\
    \ mathvariant=\"normal\">k</mi><mo>)</mo><mo>)</mo><mi>V</mi></mrow></mrow></mrow></math>](img/306.png)"
  prefs: []
  type: TYPE_IMG
- en: Where *d_k* is the dimensionality of the queries and keys, which is used to
    scale the dot product to prevent it from growing too large. The softmax operation
    ensures that the attention scores are normalized and sum to 1\. These scores represent
    the weight given to each word’s value when producing the output for the current
    word.
  prefs: []
  type: TYPE_NORMAL
- en: The output of the self-attention layer is a new sequence of vectors, where the
    output for each word is a weighted sum of all the input values, with the weights
    determined by the attention scores.
  prefs: []
  type: TYPE_NORMAL
- en: Positional encoding
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Since the self-attention mechanism does not take into account the position of
    the words in the sequence, the transformer adds a positional encoding to the input
    embeddings at the bottom of the encoder and decoder stacks. This encoding is a
    fixed function of the position and allows the model to learn to use the order
    of the words.
  prefs: []
  type: TYPE_NORMAL
- en: In the original transformer paper, positional encoding is a sinusoidal function
    of the position and the dimension, although learned positional encodings have
    also been used effectively.
  prefs: []
  type: TYPE_NORMAL
- en: Applications of transformers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Since their introduction, transformers have been used to achieve state-of-the-art
    results on a wide range of NLP tasks, including machine translation, text summarization,
    sentiment analysis, and more. They have also been adapted for other domains, such
    as computer vision and reinforcement learning.
  prefs: []
  type: TYPE_NORMAL
- en: The introduction of transformers has led to a shift in the NLP field towards
    pretraining large transformer models on a large corpus of text and then fine-tuning
    them on specific tasks, which is an effective form of transfer learning. This
    approach has been used in models such as BERT, GPT-2, GPT-3, and GPT-4.
  prefs: []
  type: TYPE_NORMAL
- en: Learning more about large language models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Large language models are a class of ML models that have been trained on a broad
    range of internet text.
  prefs: []
  type: TYPE_NORMAL
- en: The term “large” in “large language models” refers to the number of parameters
    that these models have. For example, GPT-3 has 175 billion parameters. These models
    are trained using self-supervised learning on a large corpus of text, which means
    they predict the next word in a sentence (such as GPT) or a word based on surrounding
    words (such as BERT, which is also trained to predict whether a pair of sentences
    is sequential). Because they are exposed to such a large amount of text, these
    models learn grammar, facts about the world, reasoning abilities, and also biases
    in the data they’re trained on.
  prefs: []
  type: TYPE_NORMAL
- en: These models are transformer-based, meaning they leverage the transformer architecture,
    which uses self-attention mechanisms to weigh the importance of words in input
    data. This architecture allows these models to process long-range dependencies
    in text, making them very effective for a wide range of NLP tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Large language models can be fine-tuned on specific tasks to achieve high performance.
    Fine-tuning involves additional training on a smaller, task-specific dataset and
    allows the model to adapt its general language understanding abilities to the
    specifics of the task. This approach has been used to achieve state-of-the-art
    results on many NLP benchmarks.
  prefs: []
  type: TYPE_NORMAL
- en: While large language models have demonstrated impressive abilities, they also
    raise important challenges. For example, because they’re trained on internet text,
    they can reproduce and amplify biases present in the data. They can also generate
    outputs that are harmful or misleading. Additionally, due to their size, these
    models require significant computational resources to train and deploy, which
    raises issues around cost and environmental impact.
  prefs: []
  type: TYPE_NORMAL
- en: Despite these challenges, large language models represent a significant advance
    in the field of AI and are a powerful tool for a wide range of applications, including
    translation, summarization, content creation, question answering, and more.
  prefs: []
  type: TYPE_NORMAL
- en: The challenges of training language models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Training large language models is a complex and resource-intensive task that
    poses several challenges. Here are some of the key issues:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Computational resources**: The training of large language models requires
    substantial computational resources. These models have billions of parameters
    that need to be updated during training, which involves performing a large amount
    of computation over an extensive dataset. This computation is usually carried
    out on high-performance GPUs or **tensor processing units** (**TPUs**), and the
    costs associated can be prohibitive.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Memory limitations**: As the size of the model increases, the amount of memory
    required to store the model parameters, intermediate activations, and gradients
    during training also increases. This can lead to memory issues on even the most
    advanced hardware. Techniques such as model parallelism, gradient checkpointing,
    and offloading can be used to mitigate these issues, but they add complexity to
    the training process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Dataset size and quality**: Large language models are trained on extensive
    text corpora. Finding, cleaning, and structurally organizing such massive datasets
    can be challenging. Moreover, the quality of the dataset directly impacts the
    performance of the model. Since these models learn from the data they’re trained
    on, biases or errors in the data can lead to a biased or error-prone model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Overfitting**: While large models have a high capacity to learn complex patterns,
    they can also be overfitted to the training data, especially when the amount of
    available data is limited compared to the size of the model. Overfitting leads
    to poor generalization of unseen data. Regularization techniques, such as weight
    decay, dropout, and early stopping, can be used to combat overfitting.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Training stability**: As models get larger, stably training them becomes
    more difficult. The challenges include managing learning rates and batch sizes
    and dealing with issues such as vanishing or exploding gradients.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Evaluation and fine-tuning**: Evaluating the performance of these models
    can also be challenging due to their size. Moreover, fine-tuning these models
    on a specific task can be tricky, as it can lead to “catastrophic forgetting,”
    where the model forgets the pretraining knowledge.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Ethical and safety concerns**: Large language models can generate content
    that is harmful or inappropriate. They can also propagate and amplify biases present
    in the training data. These issues necessitate the development of robust methods
    to control the behavior of the model, both during training and at runtime.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Despite these challenges, progress continues in the field of large language
    models. Researchers are developing new strategies to mitigate these issues and
    to train large models more effectively and responsibly.
  prefs: []
  type: TYPE_NORMAL
- en: Specific designs of language models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Here, we are going to explain two popular architectures of language models,
    BERT and GPT, in detail.
  prefs: []
  type: TYPE_NORMAL
- en: BERT
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'BERT, which we mentioned already and will now expand on, is a transformer-based
    ML technique for NLP tasks. It was developed by Google and introduced in a paper
    by Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova titled *Bert:
    Pre-training of deep bidirectional transformers for language understanding*, arXiv
    preprint arXiv:1810.04805 (2018).'
  prefs: []
  type: TYPE_NORMAL
- en: BERT is designed to pretrain deep bidirectional representations from the unlabeled
    text by joint conditioning on both left and right contexts in all layers. This
    is in contrast to previous methods, such as GPT and ELMo, which pretrain text
    representations from only the left context or from left and right contexts separately.
    This bi-directionality allows BERT to understand the context and the semantic
    meaning of a word more accurately.
  prefs: []
  type: TYPE_NORMAL
- en: BERT’s design
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: BERT is based on the transformer model architecture, which is shown in *Figure
    6**.8*, originally introduced by Vaswani et al. in the paper *Attention is All
    You Need*. The model architecture consists of stacked self-attention and point-wise
    fully connected layers.
  prefs: []
  type: TYPE_NORMAL
- en: 'BERT comes in two sizes: **BERT Base** and **BERT Large**. BERT Base is composed
    of 12 transformer layers, each with 12 self-attention heads, and a total of 110
    million parameters. BERT Large is much bigger and has 24 transformer layers, each
    with 16 self-attention heads, for a total of 340 million parameters.'
  prefs: []
  type: TYPE_NORMAL
- en: 'BERT’s training process involves two steps: **pretraining** and **fine-tuning**.'
  prefs: []
  type: TYPE_NORMAL
- en: The very first step in training or using a language model is to create or load
    its dictionary. We usually use a tokenizer to achieve this goal.
  prefs: []
  type: TYPE_NORMAL
- en: Tokenizer
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In order to use the language models efficiently, we need to use a tokenizer
    that converts the input text into a limited number of tokens. Subword tokenization
    algorithms, such as **byte pair encoding** (**BPE**), **unigram language model**
    (**ULM**), and **WordPiece**, split words into smaller subword units. This is
    useful for handling out-of-vocabulary words and allows the model to learn meaningful
    representations for subword parts that often carry semantic meaning.
  prefs: []
  type: TYPE_NORMAL
- en: The BERT tokenizer is a critical component of the BERT model, performing the
    initial preprocessing of text data necessary for input into the model. BERT uses
    WordPiece tokenization, a subword tokenization algorithm that breaks words into
    smaller parts, allowing BERT to handle out-of-vocabulary words, reduce the size
    of the vocabulary, and deal with the richness and diversity of languages.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s a detailed breakdown of how the BERT tokenizer works:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Basic tokenization**: First, the BERT tokenizer performs basic tokenization,
    breaking text into individual words by splitting on whitespace and punctuation.
    This is similar to what you might find in other tokenization methods.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**WordPiece tokenization**: After basic tokenization, the BERT tokenizer applies
    WordPiece tokenization. This step breaks words into smaller subword units or “WordPieces.”
    If a word isn’t in the BERT vocabulary, the tokenizer will iteratively break the
    word down into smaller sub words until it finds a match in the vocabulary or until
    it has to resort to character-level representation.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For example, the word “unhappiness” might be broken down into two WordPieces:
    “un” and “##happiness”. The “##” symbol is used to denote sub-words that are part
    of a larger word and not a whole word on their own.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Special tokens addition**: The **BERT** tokenizer then adds special tokens
    necessary for specific **BERT** functionalities. The [**CLS**] token is appended
    at the beginning of each sentence, serving as an aggregate representation for
    classification tasks. The [**SEP**] token is added at the end of each sentence
    to signify sentence boundaries. If two sentences are inputted (for tasks that
    require sentence pairs), they are separated by this [**SEP**] token.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Token to ID conversion**: Finally, each token is mapped to an integer ID
    corresponding to its index in the **BERT** vocabulary. These IDs are what the
    **BERT** model actually uses as input.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: So, in summary, the BERT tokenizer works by first tokenizing the text into words,
    then further breaking these words down into WordPieces (if necessary), adding
    special tokens, and finally converting these tokens into IDs. This process allows
    the model to understand and generate meaningful representations for a wide variety
    of words and sub-words, contributing to BERT’s powerful performance on various
    NLP tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Pretraining
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'During pretraining, **BERT** was trained on a large corpus of text (the entire
    English Wikipedia and BooksCorpus are used in the original paper). The model was
    trained to predict masked words in a sentence (masked language model) and to distinguish
    whether two sentences come in order in the text (next sentence prediction), as
    explained here:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Masked language model**: In this task, 15% of the words in a sentence are
    replaced by a [**MASK**] token, and the model is trained to predict the original
    word from the context provided by the non-masked words.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Next sentence prediction**: When the model is given a pair of two sentences,
    it is also trained to predict whether sentence *B* is the next sentence following
    sentence *A*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fine-tuning
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: After pretraining, BERT can be fine-tuned on a specific task with a significantly
    smaller amount of training data. Fine-tuning involves adding an additional output
    layer to BERT and training the entire model end-to-end on the specific task. This
    approach has been shown to achieve state-of-the-art results on a wide range of
    NLP tasks, including question answering, named entity recognition, sentiment analysis,
    and more.
  prefs: []
  type: TYPE_NORMAL
- en: BERT’s design and its pretraining/fine-tuning approach revolutionized the field
    of NLP and have led to a shift toward training large models on a broad range of
    data and then fine-tuning them on specific tasks.
  prefs: []
  type: TYPE_NORMAL
- en: How to fine-tune BERT for text classification
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'As mentioned, BERT has been pretrained on a large corpus of text data, and
    the learned representations can be fine-tuned for specific tasks, including text
    classification. Here is a step-by-step process on how to fine-tune BERT for text
    classification:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Preprocessing input data**: BERT requires a specific format for input data.
    The sentences need to be tokenized into sub-words using BERT’s own tokenizer,
    and special tokens such as [CLS] (classification) and [SEP] (separation) need
    to be added. The [CLS] token is added at the beginning of each example and is
    used as the aggregate sequence representation for classification tasks. The [SEP]
    token is added at the end of each sentence to denote sentence boundaries. All
    sequences are then padded to a fixed length to form a uniform input.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Loading the pretrained BERT model**: BERT has several pretrained models,
    and the right one should be chosen based on the task at hand. The models differ
    in terms of the size of the model and the language of the pretraining data. Once
    the pretrained BERT model is loaded, it can be used to create contextualized word
    embeddings for the input data.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Adding a classification layer**: A classification layer, also known as the
    classification head, is added on top of the pretrained BERT model. This layer
    will be trained to make predictions for the text classification task. Usually,
    this layer is a fully connected neural network layer that takes the representation
    corresponding to the [CLS] token as input and outputs the probability distribution
    over the classes.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Fine-tuning the model**: Fine-tuning involves training the model on the specific
    task (in this case, text classification) using the labeled data. This process
    can be done in multiple ways. The more common approach is to update the weights
    of the pretrained BERT model and the newly added classification layer to minimize
    a loss function, typically the cross-entropy loss for classification tasks. It
    is important to use a lower learning rate during fine-tuning, as larger rates
    can destabilize the prelearned weights. Additionally, the number of recommended
    epochs is two to four, so the model learns the task but does not overfit. The
    benefit of this approach is that the model weights will be adjusted to perform
    well on specific tasks. Alternatively, we can freeze BERT layers and just update
    the classifier layer weights.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Evaluating the model**: Once the model has been fine-tuned, it can be evaluated
    on a validation set to assess its performance. This involves calculating metrics
    such as accuracy, precision, recall, and F1 score. During the training and evaluation
    task, similar to other ML and DL models, we can perform hyperparameter tuning.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Applying the model**: The fine-tuned model can now be used to make predictions
    on new, unseen text data. As with the training data, this new data also need to
    be preprocessed into the format that BERT expects.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Note that working with **BERT** requires considerable computational resources,
    as the model has a large number of parameters. A GPU is typically recommended
    for fine-tuning and applying BERT models. There are some models that are lighter
    than BERT with slightly lower performance, such as DistilBERT, that we can use
    in the case of being constrained by the computation or memory resources. Additionally,
    BERT is able to process 512 tokens, which limits the length of our input text.
    If we want to process longer text, Longformer or BigBird are good choices. What
    we explained here works for similar language models such as RoBERTa, XLNet, and
    so on.
  prefs: []
  type: TYPE_NORMAL
- en: In summary, fine-tuning BERT for text classification involves preprocessing
    the input data, loading the pretrained BERT model, adding a classification layer,
    fine-tuning the model on the labeled data, and then evaluating and applying the
    model.
  prefs: []
  type: TYPE_NORMAL
- en: We will demonstrate the preceding paradigm of fine-tuning BERT and then apply
    it at the end of this chapter. You will have the opportunity to employ it firsthand
    and adjust it to your needs.
  prefs: []
  type: TYPE_NORMAL
- en: GPT-3
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**GPT-3**, short for **generative** **pretrained transformer 3**, is an autoregressive
    language model developed by OpenAI that uses DL techniques to generate human-like
    text. It is the third version of the GPT series. The GPT versions that followed
    it, GPT-3.5 and GPT-4, will be covered in the next chapter, as we will expand
    on large language models.'
  prefs: []
  type: TYPE_NORMAL
- en: Design and architecture of GPT-3
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: GPT-3 extends the transformer model architecture used by its predecessors. The
    architecture is based on a transformer model that uses layers of transformer blocks,
    where each block is composed of self-attention and feedforward neural network
    layers.
  prefs: []
  type: TYPE_NORMAL
- en: GPT-3 is massive compared to the previous versions. It consists of 175 billion
    ML parameters. These parameters are learned during the training phase, where the
    model learns to predict the next word in a sequence of words.
  prefs: []
  type: TYPE_NORMAL
- en: GPT-3’s transformer model is designed to process sequences of data (in this
    case, sequences of words or tokens in text), making it well-suited for language
    tasks. It processes input data sequentially from left to right and generates predictions
    for the next item in the sequence. This is the difference between BERT and GPT,
    where, in BERT, words from both sides are used to predict masked words, but in
    GPT, just the previous words are used for prediction, which makes it a good choice
    for generative tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Pretraining and fine-tuning
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Similar to BERT and other transformer-based models, GPT-3 also involves a two-step
    process: **pretraining** and **fine-tuning**.'
  prefs: []
  type: TYPE_NORMAL
- en: Pretraining
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In this phase, GPT-3 is trained on a large corpus of text data. It learns to
    predict the next word in a sentence. However, unlike BERT, which uses a bidirectional
    context for prediction, GPT-3 only uses the left context (i.e., the previous words
    in the sentence).
  prefs: []
  type: TYPE_NORMAL
- en: Fine-tuning
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: After the pretraining phase, GPT-3 can be fine-tuned on a specific task using
    a smaller amount of task-specific training data. This could be any NLP task, such
    as text completion, translation, summarization, question answering, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Zero-shot, one-shot, and few-shot learning
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: One of the impressive features of GPT-3 is its capability to perform few-shot
    learning. When given a task and a few examples of that task, GPT-3 can often learn
    to perform the task accurately.
  prefs: []
  type: TYPE_NORMAL
- en: In the zero-shot setting, the model is given a task without any prior examples.
    In the one-shot setting, it’s given one example, and in the few-shot setting,
    it’s given a few examples to learn from.
  prefs: []
  type: TYPE_NORMAL
- en: Challenges of using GPT-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Despite its impressive capabilities, GPT-3 also presents some challenges. Due
    to its large size, it requires substantial computational resources to train. It
    can sometimes generate incorrect or nonsensical responses, and it can reflect
    biases present in the training data. It also struggles with tasks that require
    a deep understanding of the world or common sense reasoning beyond what can be
    learned from text.
  prefs: []
  type: TYPE_NORMAL
- en: Reviewing our use case – ML/DL system design for NLP classification in a Jupyter
    Notebook
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we are going to work on a real-world problem and see how we
    can use an NLP pipeline to solve it. The code for this part is shared as a Google
    Colab notebook at [Ch6_Text_Classification_DL.ipynb](https://colab.research.google.com/drive/1HVD2fvxHup6OsPi2mKxNS_nfCRZ0iGCw?usp=sharing).
  prefs: []
  type: TYPE_NORMAL
- en: The business objective
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this scenario, we are in the healthcare sector. Our objective is to develop
    a general medical knowledge engine that is very up to date with recent findings
    in the world of healthcare.
  prefs: []
  type: TYPE_NORMAL
- en: The technical objective
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The CTO derives several technical objectives from the business objective. One
    objective is for the ML team: given the growing collection of conclusions that
    correspond to medical publications, identify the ones that represent advice. This
    will allow us to identify the medical advice that stems from the underlying research.'
  prefs: []
  type: TYPE_NORMAL
- en: The pipeline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s review the parts of the pipeline, as depicted in *Figure 6**.9*:'
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 6.9 – The structure of a typical exploration and model pipeline\uFEFF\
    ](img/B18949_06_009.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 6.9 – The structure of a typical exploration and model pipeline
  prefs: []
  type: TYPE_NORMAL
- en: Notice how this design is different from the design we saw in *Figure 5**.2*.
    There, the exploration and evaluation parts leverage the same feature engineering
    technique that is later used by the ML models. Here, with LMs, feature engineering
    is not a part of the preparation for the modeling. The pretrained model, and particularly
    the tokenizer, performs feature engineering, which yields very different and less
    interpretable features than the binary, BoW, or TF-IDF features.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'Code parts: From “Settings” through “Generating Results of the Traditional
    ML Models.”'
  prefs: []
  type: TYPE_NORMAL
- en: These parts are identical in their nature to the analog parts discussed in [*Chapter
    5*](B18949_05_split_000.xhtml#_idTextAnchor130). The only differences relate to
    the differences in the data.
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this part of the code, we employ a deep learning language model.
  prefs: []
  type: TYPE_NORMAL
- en: When looking to apply transfer learning via LMs and fine-tuning them per our
    objective and data, there are several stacks to choose from. The ones that stand
    out the most are Google’s TensorFlow, and Meta’s PyTorch. A package called **Transformers**
    was built as a wrapper around these stacks to allow for a simpler implementation
    of the code. In this example, we leverage the simplicity and richness of transformers
    models.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is worth highlighting the company that built and supports the Transformers
    package: Hugging Face. Hugging Face took it upon themselves to create an entire
    ecosystem around the collection and sharing of free, open source DL models, which
    includes the many components that accommodate for implementing these models. The
    most actionable tool is the Transformers package, which is a Python package dedicated
    to picking, importing, training, and employing a large and growing set of DL models.'
  prefs: []
  type: TYPE_NORMAL
- en: The code we are reviewing here provides more than just an example of ML/DL system
    design in the real world; it also showcases Hugging Face’s Transformers.
  prefs: []
  type: TYPE_NORMAL
- en: Formatting the data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Here, we set the data up in a format that suits the Transformers library. The
    column names must be very specific.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluation metric
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We decided which metric we wished to optimize and plugged it into the training
    process. For this problem of binary classification, we optimized for accuracy
    and evaluated our result in comparison to the dataset’s baseline accuracy, also
    known as the prior.
  prefs: []
  type: TYPE_NORMAL
- en: Trainer object
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This is the core object for training the LM in Transformers. It holds a set
    of predefined configurations. Some of the key training configurations are the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The neural net’s mathematical learning hyperparameters, such the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The learning rate
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The gradient decent settings
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The number of training epochs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The computation hardware usage
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logging setting for capturing the progression of the objective metric throughout
    the training process
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fine-tuning the neural network parameters
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The fundamental concept around fine-tuning LMs is transfer learning. Neural
    networks lend themselves so well to transfer learning because one can simply strip
    any number of layers from the end of the structure and replace them with untrained
    layers that would be trained based on the underlying problem. The rest of the
    layers that weren’t removed and aren’t trained continue to operate exactly in
    the same way they did when the LM was originally trained (when it was originally
    built). If we replace the last layer but leave the rest of the original layers,
    then we could view those layers as supervised feature engineering or, conversely,
    as an embedding mechanism. This trait reflects the concept of transfer learning.
    Ideally, the model is expected to lend itself well to our underlying problem so
    that we will choose to keep the vast majority of the original layers, and only
    a small minority would be replaced and trained. In this way, a large DL model
    that took many weeks to be pretrained can be transferred and adapted to a new
    problem in minutes.
  prefs: []
  type: TYPE_NORMAL
- en: In our code, we set the model up in a way that we dictate exactly which of its
    layers we are looking to fine-tune. It is a design choice for us for this to be
    based on performance and also computation resources. One choice is to fine-tune
    the last layer right before the final output, also known as the classification
    head. The alternative is to fine-tune all the layers. In our code, we explicitly
    call the model’s configuration, which controls which layer is fine-tuned, so the
    code can be changed in any way that suits the design.
  prefs: []
  type: TYPE_NORMAL
- en: We configure the trainer to log the performance of the training in real time.
    It prints those logs out for us in a table so we can observe and monitor them.
    When the training is complete, we plot the progress of the training and the evaluation.
    This helps us see the relation between the evolution of the training results and
    the evaluation results. Since the evaluation set that the trainer uses can be
    viewed as a held-out set in the context of the trainer, this plot allows us to
    investigate underfitting and overfitting.
  prefs: []
  type: TYPE_NORMAL
- en: Generating the training results – used for design choices
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We reviewed the results of the training set, along with the logs that the trainer
    printed out. We compared them to the baseline accuracy and observed an increase
    in accuracy. We learned about the quality of our design by iterating over several
    different design choices and comparing them. That process of iterating over many
    sets of design parameters would be automated into code to allow for a systematic
    evaluation of the optimal setting. We didn’t do that in our notebook just to keep
    things simple in the example. Once we believed we had found the optimal setting,
    we could say that the process was finished.
  prefs: []
  type: TYPE_NORMAL
- en: Generating the testing results – used for presenting performance
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: As with the code in [*Chapter 5*](B18949_05_split_000.xhtml#_idTextAnchor130),
    here, too, we finished by reviewing the test results. It is worth noting the difference
    between the evaluation set and the test set. One could suggest that since the
    trainer doesn’t use the evaluation set for training, it could be used as a held-out
    test set, thus saving the need to exclude so many observations from training and
    supplying the model with more labeled data. However, while the trainer didn’t
    use the evaluation set, we did use it to make our design decisions. For instance,
    we observed the plot from the preceding section and judged which number of epochs
    is optimal to achieve optimal fitting. In [*Chapter 5*](B18949_05_split_000.xhtml#_idTextAnchor130),
    an evaluation set was used too, but we didn’t need to explicitly define it; it
    was carried out as a part of the K-fold cross-validation mechanism.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this enlightening chapter, we embarked on a comprehensive exploration of
    DL and its remarkable application to text classification tasks through language
    models. We began with an overview of DL, revealing its profound ability to learn
    complex patterns from vast amounts of data and its indisputable role in advancing
    state-of-the-art NLP systems.
  prefs: []
  type: TYPE_NORMAL
- en: We then delved into the transformative world of transformer models, which have
    revolutionized NLP by providing an effective alternative to traditional RNNs and
    CNNs for processing sequence data. By unpacking the attention mechanism—a key
    feature in transformers—we highlighted its capacity to focus on different parts
    of the input sequence, hence facilitating a better understanding of context.
  prefs: []
  type: TYPE_NORMAL
- en: Our journey continued with an in-depth exploration of the BERT model. We detailed
    its architecture, emphasizing its pioneering use of bidirectional training to
    generate contextually rich word embeddings, and we highlighted its pretraining
    process, which learns language semantics from a large text corpus.
  prefs: []
  type: TYPE_NORMAL
- en: However, our exploration did not end there; we also introduced GPT, another
    transformative model that leverages the power of transformers in a slightly different
    way—focusing on generating human-like text. By comparing BERT and GPT, we shed
    light on their distinct strengths and use cases.
  prefs: []
  type: TYPE_NORMAL
- en: The chapter culminated in a practical guide on how to design and implement a
    text classification model using these advanced models. We walked you through all
    the stages of this process, from data preprocessing and model configuration to
    training, evaluation, and finally, making predictions on unseen data.
  prefs: []
  type: TYPE_NORMAL
- en: In essence, this chapter provided a well-rounded understanding of DL in NLP,
    transitioning from fundamental principles to hands-on applications. With this
    knowledge, you are now equipped to leverage the capabilities of transformer models,
    BERT, and GPT for your text classification tasks. Whether you are looking to delve
    further into the world of NLP or apply these skills in a practical setting, this
    chapter has equipped you with a firm foundation on which to build.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we introduced you to large language models. In the next chapter,
    we dive deeper into these models to learn more about them.
  prefs: []
  type: TYPE_NORMAL
