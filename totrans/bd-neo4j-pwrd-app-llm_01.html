<html><head></head><body><div id="book-content"><div id="sbo-rt-content"><div id="_idContainer014">
    <h1 class="chapterNumber"><a id="_idTextAnchor013"/>1</h1>
    <h1 id="_idParaDest-20" class="chapterTitle">Introducing LLMs, RAGs, and Neo4j Knowledge Graphs</h1>
    <p class="normal"><strong class="keyWord">Artificial Intelligence</strong> (<strong class="keyWord">AI</strong>) is evolving beyond niche and specialized fields to become more accessible and able to assist with day-to-day tasks. One of the best examples is the explosive advent of <strong class="keyWord">Generative AI</strong> (<strong class="keyWord">GenAI</strong>). In the last few years, GenAI has created a lot of excitement both for technology builders and regular users with its ease of use and ability to understand and answer questions the way humans can. The breakthroughs in <strong class="keyWord">Large Language Models</strong> (<strong class="keyWord">LLMs</strong>) have propelled GenAI to the forefront. This has opened up a lot of opportunities for businesses to change how they interact with their customers. Customers can ask a question in natural language and get an answer without needing a human to be available to understand the question or understand the data to extract intelligence from it. While GenAI has taken big strides in different fields with different modalities, such as text, audio, and video, our focus throughout this book remains on LLMs and their applications in business and industry use cases.</p>
    <p class="normal">In this chapter, we will take a look at GenAI through the lens of LLMs, its impact, pitfalls, and ethical concerns. To set the stage for this book, we will briefly introduce techniques that can augment LLMs to make them more effective.</p>
    <p class="normal">In this chapter, we are going to cover the following main topics:</p>
    <ul>
      <li class="bulletList">Outlining the evolution of GenAI through the lens of LLMs</li>
      <li class="bulletList">Understanding the importance of RAGs and knowledge graphs in LLMs</li>
      <li class="bulletList">Introducing Neo4j knowledge graphs</li>
    </ul>
    <h1 id="_idParaDest-21" class="heading-1">Outlining the evolution of GenAI through the lens of LLMs</h1>
    <p class="normal">In late 2022, OpenAI took the world by storm by releasing an AI <a id="_idIndexMarker000"/>engine called ChatGPT that could understand language like <a id="_idIndexMarker001"/>humans and interact with users in natural language. This was the best representation of GenAI in a long time. AI concepts started as rules-based systems and evolved into machine learning algorithms in the ‘90s. With the rise of deep learning and LLMs, the concept of GenAI became more popular. These AI systems could generate new content after being trained using existing content. OpenAI’s GPT-3 LLM model was one of the first LLMs that captured the interest of the masses. GenAI can be used to get answers in a manner that feels like human interaction and it can also be used to generate images by providing a text description, describe an image as text content, generate videos using text content, and many other things. It can enhance creativity, accelerate research and development, enable a simple understanding of complex concepts, and improve personalization.</p>
    <p class="normal">The evolution of LLMs is at the heart of GenAI’s popularity. Let’s take a look at LLMs and how they have propelled GenAI.</p>
    <h2 id="_idParaDest-22" class="heading-2">Introducing LLMs</h2>
    <p class="normal">An LLM is a machine learning model <a id="_idIndexMarker002"/>that is built for natural language processing and can understand language constructs and generate content in that language based on the training.</p>
    <p class="normal">Before the popularity of GPT-3, a considerable amount of research had been conducted <a id="_idIndexMarker003"/>on LLMs fover several years. Some of the notable works that pioneered LLMs include Google’s <strong class="keyWord">Bidirectional Encoder Representations from Transformers</strong> (<strong class="keyWord">BERT</strong> (<span class="url">https://github.com/google-research/bert))</span> and <strong class="keyWord">Generative Pre-trained Transformer</strong> (<strong class="keyWord">GPT</strong>) from OpenAI. LLM training<a id="_idIndexMarker004"/> requires a lot of parameters and computing power.</p>
    <p class="normal">At their core, LLMs are a<a id="_idIndexMarker005"/> type of <strong class="keyWord">Recurrent Neural Network</strong> (<strong class="keyWord">RNN</strong>) architecture. Traditional RNNs struggle with long-term dependencies in sequential data. To address this, LLMs <a id="_idIndexMarker006"/>often leverage architectures such as <strong class="keyWord">Long Short-Term Memory</strong> (<strong class="keyWord">LSTM</strong>) networks or transformers. These architectures allow the model to learn complex relationships between words, even words that are separated by large distances within the training text.</p>
    <p class="normal">Here is a simple illustration of a basic LLM architecture:</p>
    <figure class="mediaobject"><img src="../Images/B31107_01_1-01.png" alt="Figure 1.1 — Flowchart explaining a basic LLM architecture" width="1650" height="569"/></figure>
    <p class="packt_figref">Figure 1.1 — Flowchart explaining a basic LLM architecture</p>
    <p class="normal">Let’s dissect this architecture</p>
    <ul>
      <li class="bulletList"><strong class="screenText">Input layer</strong>: This layer receives the initial text prompt or sequence</li>
      <li class="bulletList"><strong class="screenText">Embedding layer</strong>: Words in the input sequence are converted into numerical vectors, capturing their semantic meaning</li>
      <li class="bulletList"><strong class="screenText">Encoder</strong>: This is a multi-layered RNN (e.g., LSTM) or transformer that processes the sequence of embedded words, capturing contextual information</li>
      <li class="bulletList"><strong class="screenText">Decoder</strong>: The decoder utilizes the encoded representation to generate the output sequence one word at a time</li>
    </ul>
    <p class="normal">You can read more about <a id="_idIndexMarker007"/>LLMs in this paper: <span class="url">https://arxiv.org/pdf/2307.06435.</span></p>
    <p class="normal">Building an LLM requires a lot of<a id="_idIndexMarker008"/> effort and resources. Let’s look at the number of parameters used by OpenAI to train each GPT model:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">GPT-1</strong>: This is the first model and used 117 million parameters.</li>
      <li class="bulletList"><strong class="keyWord">GPT-2</strong>: This model used 1.5 billion parameters to train.</li>
      <li class="bulletList"><strong class="keyWord">GPT-3</strong>: This model was the first general-purpose model released. 175 billion parameters were used to train this model.</li>
      <li class="bulletList"><strong class="keyWord">GPT-4 series</strong>: This is the latest model released by OpenAI. 170 trillion parameters were used to train this model.</li>
    </ul>
    <p class="normal">These training figures demonstrate that with each new version, the number of parameters increased by several orders of magnitude. This means more and more computing power is needed to train these models. Similar training numbers can be observed for other LLM models too.</p>
    <p class="normal">While GenAI is a great technology, there are <a id="_idIndexMarker009"/>pitfalls as well as legal and ethical concerns about the application of this technology. We will take a look at them next.</p>
    <h2 id="_idParaDest-23" class="heading-2">Understanding GenAI’s pitfalls and ethical concerns</h2>
    <p class="normal">While LLMs are great at summarizing, generating context, and other use cases, they still do not understand the language per se. They recognize patterns based on the training text to generate new text. They also don’t <a id="_idIndexMarker010"/>understand facts or understand emotions or ethics. They are simply predicting the next token and generating text. Because of these pitfalls, content generated by GenAI can have huge consequences.</p>
    <p class="normal">To understand and address these aspects, we need to first identify any harmful or inaccurate content that is being generated and address it either by retraining the model or adding separate checks and balances to make sure this content is not used as output.</p>
    <p class="normal">For example, there have been recent cases about using LLMs to generate legal briefs, where LLMs have created non-existent cases and generated a legal brief based on these cases. While technically it might have generated a solution that is requested, this is legally not correct. There have also been cases where LLMs are used to generate offensive images and videos and shared on the internet. Since it is difficult to identify content generated by AI, it is easy to be fooled by this content. This is neither socially, legally, or ethically acceptable. There are quite a few examples where LLMs simply make up facts.</p>
    <p class="normal">This tutorial on the Microsoft site (<span class="url">https://learn.microsoft.com/en-us/training/modules/responsible-ai-studio/)</span> provides a detailed explanation of these concerns and how we can identify them.</p>
    <p class="normal"><strong class="keyWord">Retrieval-Augmented Generation</strong> (<strong class="keyWord">RAG</strong>) and <strong class="keyWord">knowledge graphs</strong> together can help address these issues, which we discuss next.</p>
    <h1 id="_idParaDest-24" class="heading-1">Understanding the importance of RAGs and knowledge graphs in LLMs</h1>
    <p class="normal">To address the pitfalls of GenAI, we <a id="_idIndexMarker011"/>can either fine-tune the model or ground the responses using other sources.</p>
    <p class="normal"><strong class="keyWord">Fine-tuning</strong> involves training an existing <a id="_idIndexMarker012"/>model with additional<a id="_idIndexMarker013"/> information, which <a id="_idIndexMarker014"/>can result in high-quality<a id="_idIndexMarker015"/> responses. But this can be a complex and time-consuming process.</p>
    <p class="normal">The <strong class="keyWord">RAG approach</strong> involves providing <a id="_idIndexMarker016"/>extra information when we are asking the LLM a question. </p>
    <p class="normal">With this approach, you can integrate knowledge repositories into the generative process. In this scenario, LLM can leverage the extra information retrieved from other sources and tune the response to match the information provided, thus grounding the results.</p>
    <p class="normal">These repositories and sources can<a id="_idIndexMarker017"/> include the following:</p>
    <ul>
      <li class="bulletList"><strong class="screenText">Publicly available structured datasets</strong> (e.g., scientific databases such as PubMed or publicly accessible encyclopedic resources such<a id="_idIndexMarker018"/> as Wikipedia)</li>
      <li class="bulletList"><strong class="screenText">Enterprise knowledge bases</strong> (e.g., internal company documentation, product catalogs, or <a id="_idIndexMarker019"/>compliance-related content with <a id="_idIndexMarker020"/>strict privacy and security requirements)</li>
      <li class="bulletList"><strong class="screenText">Domain-specific sources</strong> (e.g., legal case records, medical guidelines, or technical manuals tailored to specific industries)</li>
    </ul>
    <p class="normal">By incorporating relevant information from these repositories and sources, RAG empowers LLMs to generate output that is not only factually accurate but also contextually aligned with the task at hand. Unlike the static knowledge encoded in the LLM’s training data, these additional data sources allow real-time retrieval of up-to-date and specialized information, addressing challenges such as data freshness, accuracy, and specificity. We will cover RAG in detail in <a href="Preface.xhtml#_idTextAnchor011"><em class="italic">Chapter 2</em></a>.</p>
    <p class="normal">Another source of information to enable RAG is knowledge graphs. Let’s briefly talk about them and their role in the LLM landscape.</p>
    <h2 id="_idParaDest-25" class="heading-2">The role of knowledge graphs in LLMs</h2>
    <p class="normal">Knowledge graphs play a huge role in generating creative and contextually rich content for LLMs. They provide a <a id="_idIndexMarker021"/>structured, interconnected foundation <a id="_idIndexMarker022"/>and make information retrieval more <br/>relevant and insightful by grounding the AI results in a complex and multi-layered understanding of the data.</p>
    <p class="normal">Representing the data as a graph opens up more avenues to understand the data. At the same time, a knowledge graph cannot be a static entity that represents data in only one dimension that’s fixed. Its true power lies in its ability to be dynamic and multi-dimensional. It can capture temporal, spatial, or contextual information in real time through live data feeds.</p>
    <p class="normal">Apart from being an important tool for storing information, knowledge graphs are the backbone of intelligent, context-aware AI.</p>
    <p class="normal">There are several reasons why knowledge graphs are essential for GenAI:</p>
    <ul>
      <li class="bulletList"><strong class="screenText">Enhanced contextual understanding</strong>: Knowledge graphs allow GenAI systems to retrieve relevant information based on relationships, not just isolated facts. For example, in healthcare, a knowledge graph could link symptoms, diseases, and treatments, enabling GenAI to suggest more accurate diagnostic insights based on interconnected medical knowledge.</li>
      <li class="bulletList"><strong class="screenText">Efficient data retrieval</strong>: Unlike traditional databases, knowledge graphs allow multi-hop reasoning, from which GenAI can draw insights across several degrees of separation. This is invaluable in fields such as finance, where GenAI can use knowledge graphs<a id="_idIndexMarker023"/> to reveal hidden relationships between entities such as customers, transactions, and market trends.</li>
      <li class="bulletList"><strong class="screenText">Integration of vector embeddings</strong>: When combined with vector embeddings, knowledge graphs enable <a id="_idIndexMarker024"/>GenAI to understand and respond to more nuanced queries. Vector embeddings capture semantic similarities between data points, which knowledge graphs then contextualize, creating a powerful blend of accuracy and relevance in responses.</li>
      <li class="bulletList"><strong class="screenText">Real-world impact</strong>: Major organizations are already harnessing the power of knowledge graphs to enhance GenAI applications. For instance, companies in e-commerce use knowledge graphs to provide product recommendations that are not just relevant but contextually rich, drawing from diverse data sources such as customer reviews, purchase history, and product features.</li>
    </ul>
    <p class="normal">By integrating knowledge graphs, GenAI models transcend traditional data limitations, helping to create smarter, more reliable applications across different fields.</p>
    <p class="normal">Let’s now talk about <strong class="keyWord">Neo4j knowledge graphs</strong>.</p>
    <h1 id="_idParaDest-26" class="heading-1">Introducing Neo4j knowledge graphs</h1>
    <p class="normal">A knowledge graph is dynamic and continues to evolve based on how data and relationships within the data evolve with time. </p>
    <p class="normal">Neo4j is a database that excels<a id="_idIndexMarker025"/> with its ability to store data in graphs. For example, in a store, most products are laid out in a certain grouping and stay in those groups. But there is an exception to this arrangement. When a store wants to promote some products, they are placed at the front of the store. This kind of flexible thought process should be adapted for our knowledge graph implementation. As the semantics of data evolves the knowledge graph should be able to capture this change.</p>
    <p class="normal">Neo4j, with its multiple labels for nodes and its optional schema approach, makes it easy to keep our graph relevant by helping us to persist (retain) our understanding of data as an extra label on the node, or a specific relationship that provides more relevant context between the nodes. We will take a deeper look at how we can build a Neo4j knowledge graph from the ground up in the upcoming chapters.</p>
    <p class="normal">For now, let’s see how a Neo4j knowledge graph works to enhance an LLM’s response.</p>
    <h2 id="_idParaDest-27" class="heading-2">Using Neo4j knowledge graphs with LLMs</h2>
    <p class="normal">Suppose there is an LLM-based <a id="_idIndexMarker026"/>chatbot integrated with a Neo4j knowledge graph. This GenAI chatbot is designed to answer medical queries. <em class="italic">Figure 1.2</em> illustrates how a Neo4j knowledge graph can enhance this chatbot’s medical reasoning by linking structured <a id="_idIndexMarker027"/>patient symptom records with unstructured insights from medical research papers and clinical trials.</p>
    <p class="normal">The unstructured text undergoes embedding-based processing using models from providers such as <strong class="screenText">Ollama</strong>, <strong class="screenText">OpenAI</strong>, and <strong class="screenText">Hugging Face</strong>, followed<a id="_idIndexMarker028"/> by <strong class="keyWord">Named Entity Recognition </strong>(<strong class="keyWord">NER</strong>), to extract key entities such as symptoms and treatments. This data is integrated into a Neo4j knowledge graph, where documents mention symptoms and treatments, patients show symptoms, and symptoms are linked to potential treatments. This enables <strong class="keyWord">multi-hop reasoning</strong>, allowing a <a id="_idIndexMarker029"/>chatbot to efficiently answer complex queries <a id="_idIndexMarker030"/>such as the following:</p>
    <p class="normal"><em class="italic">Which patients are showing symptoms similar to flu and also showed symptoms of COVID-19 in the past?</em></p>
    <figure class="mediaobject"><img src="../Images/B31107_01_2.png" alt="Figure 1.2 — Neo4j knowledge graph driven Gen-AI for healthcare" width="1506" height="847"/></figure>
    <p class="packt_figref">Figure 1.2 — Neo4j knowledge graph driven Gen-AI for healthcare</p>
    <p class="normal">To retrieve the result of this <a id="_idIndexMarker031"/>query, a <strong class="keyWord">multi-hop knowledge graph query path</strong> (<em class="italic">Figure 1.2</em>) will be followed in this order:</p>
    <ol>
      <li class="numberedList" value="1">Retrieve symptoms linked to flu from research documents.</li>
      <li class="numberedList">Identify patients currently showing those symptoms.</li>
      <li class="numberedList">Cross-reference past patient records for COVID-19 symptoms.</li>
      <li class="numberedList">Return patients who match both conditions with supporting document sources.</li>
    </ol>
    <p class="normal">With this approach, the<a id="_idIndexMarker032"/> LLM response can be grounded to generate factually correct, relevant, and up-to-date results to support medical decision-making.</p>
    <p class="normal">A similar approach can be <a id="_idIndexMarker033"/>used to augment LLMs that support other applications.</p>
    <p class="normal">We have now looked at how knowledge graphs enhance GenAI’s ability to provide contextually rich, accurate insights. But how does this transformative power translate into concrete benefits in real life? We will continue this journey in the rest of the book.</p>
    <h1 id="_idParaDest-28" class="heading-1">Summary</h1>
    <p class="normal">In this chapter, we discussed the evolution of GenAI in the context of LLMs. We also looked at how RAG and knowledge graphs are key enablers of this transformation and help provide structure and context, improving an LLM’s accuracy and reasoning.</p>
    <p class="normal">Looking ahead, the next chapter dives deep into RAG — a technique that significantly enhances GenAI’s accuracy by grounding responses in retrieved, verified information.</p>
  </div>
</div></div></body></html>