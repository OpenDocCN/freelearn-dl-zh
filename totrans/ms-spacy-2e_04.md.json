["```py\n\"Barack Obama\"\n\"Barack Obama\"\n\"Barack Hussein Obama\"\nreg = r\"Barack\\s(Hussein\\s)?Obama\"\n```", "```py\n    import spacy\n    from spacy.matcher import Matcher\n    from spacy.tokens import Span\n    nlp = spacy.load(\"en_core_web_sm\")\n    ```", "```py\n    matcher = Matcher(nlp.vocab)\n    pattern = [{\"LOWER\": \"good\"}, {\"LOWER\": \"morning\"}, \n               {\"IS_PUNCT\": True}]\n    matcher.add(\"morningGreeting\", [pattern])\n    ```", "```py\n    doc = nlp(\"Good morning, I want to reserve a ticket.\")\n    matches = matcher(doc)\n    spans = []\n    for match_id, start, end in matches:\n        spans.append(Span(doc, start, end, \n                          nlp.vocab.strings[match_id]))\n    doc.spans[\"sc\"] = spans\n    ```", "```py\n    from spacy import displacy\n    displacy.render(doc, style=\"span\")\n    ```", "```py\npattern = [{\"LOWER\": \"good\"}, {\"LOWER\": \"morning\"},\n           {\"IS_PUNCT\": True}]\n```", "```py\n    import spacy\n    from spacy.matcher import Matcher\n    from spacy.tokens import Span\n    nlp = spacy.load(\"en_core_web_sm\")\n    matcher = Matcher(nlp.vocab)\n    ```", "```py\n    pattern1 = [{\"LOWER\": \"good\"}, {\"LOWER\": \"morning\"}, \n    {\"IS_PUNCT\": True}]\n    matcher.add(\"morningGreeting\", [pattern1])\n    pattern2 = [{\"LOWER\": \"good\"}, {\"LOWER\": \"evening\"}, \n    {\"IS_PUNCT\": True}]\n    matcher.add(\"eveningGreeting\", [pattern2])\n    ```", "```py\n    doc = nlp(\"Good morning, I want to reserve a ticket. I will then say good evening!\")\n    matches = matcher(doc)\n    spans = []\n    for match_id, start, end in matches:\n        pattern_name = nlp.vocab.strings[match_id]\n        spans.append(Span(doc, start, end, pattern_name))\n    doc.spans[\"sc\"] = spans\n    ```", "```py\n    from spacy import displacy\n    displacy.render(doc, style=\"span\")\n    ```", "```py\npattern = [{\"LOWER\": \"good\"},\n           {\"LOWER\": {\"IN\": [\"morning\", \"evening\"]}},\n           {\"IS_PUNCT\": True}]\nmatcher.add(\"greetings\",  [pattern])\ndoc = nlp(\"Good morning, I'm here. I'll say good evening!!\")\nmatches = matcher(doc)\nspans = []\nfor match_id, start, end in matches:\n    pattern_name = nlp.vocab.strings[match_id]\n    spans.append(Span(doc, start, end, pattern_name))\ndoc.spans[\"sc\"] = spans\n```", "```py\npattern = [{\"LENGTH\": {\">=\" : 10}}]\nmatcher.add(\"longWords\",  [pattern])\ndoc = nlp(\"I suffered from Trichotillomania when I was in college. The doctor prescribed me Psychosomatic medicine.\")\nmatches = matcher(doc)\nspans = []\nfor match_id, start, end in matches:\n    pattern_name = nlp.vocab.strings[match_id]\n    spans.append(Span(doc, start, end, pattern_name))\ndoc.spans[\"sc\"] = spans\n```", "```py\npattern = [{\"TEXT\": \"Bill\"}]\n```", "```py\npattern = [{\"IS_DIGIT\": True},{\"IS_ALPHA\": True}]\nmatcher.add(\"numberAndPlainWord\",  [pattern])\ndoc1 = nlp(\"I met him at 2 o'clock.\")\nmatches = matcher(doc1)\nspans = []\nfor match_id, start, end in matches:\n    pattern_name = nlp.vocab.strings[match_id]\n    spans.append(Span(doc1, start, end, pattern_name))\ndoc1.spans[\"sc\"] = spans\ndisplacy.render(doc1, style=\"span\")\n```", "```py\ndoc2 = nlp(\"He brought me 2 apples.\")\nmatches = matcher(doc2)\nspans = []\nfor match_id, start, end in matches:\n    pattern_name = nlp.vocab.strings[match_id]\n    spans.append(Span(doc2, start, end, pattern_name))\ndoc2.spans[\"sc\"] = spans\ndisplacy.render(doc2, style=\"span\")\n```", "```py\npattern = [{\"IS_UPPER\": True}]\nmatcher.add(\"capitals\",  [pattern])\ndoc = nlp(\"Take me out of your SPAM list. We never asked you to contact me. If you write again we'll SUE!!!!\")\nmatches = matcher(doc)\nspans = []\nfor match_id, start, end in matches:\n    pattern_name = nlp.vocab.strings[match_id]\n    spans.append(Span(doc, start, end, pattern_name))\ndoc.spans[\"sc\"] = spans\ndisplacy.render(doc, style=\"span\")\n```", "```py\n    pattern = [{\"IS_SENT_START\": True, \"LOWER\": \"can\"}, {\"IS_TITLE\": True}]\n    matcher.add(\"canThenCapitalized\", [pattern])\n    ```", "```py\n    doc2 = nlp(\"Can Sally swim?\")\n    matches = matcher(doc2)\n    spans = []\n    for match_id, start, end in matches:\n        pattern_name = nlp.vocab.strings[match_id]\n        spans.append(Span(doc2, start, end, pattern_name))\n    doc2.spans[\"sc\"] = spans\n    displacy.render(doc2, style=\"span\")\n    ```", "```py\npattern = [{\"IS_SENT_START\": True, \"TAG\": \"MD\"}]\nmatcher.add(\"sentStartAuxBVerb\", [pattern])\ndoc = nlp(\"Will you go there?\")\nmatches = matcher(doc)\n```", "```py\nR\"Barack\\s(Hussein\\s)?Obama\n```", "```py\npattern = [{\"LOWER\": \"barack\"},\n           {\"LOWER\": \"hussein\", \"OP\": \"?\"},\n           {\"LOWER\": \"obama\"}]\nmatcher.add(\"obamaNames\",  [pattern])\ndoc1 = nlp(\"Barack Obama visited France.\")\ndoc2 = nlp(\"Barack Hussein Obama visited France.\")\n```", "```py\npattern = [{\"LOWER\": {\"IN\": [\"hello\", \"hi\", \"hallo\"]}, \"OP\":\"+\"}, \n           {\"IS_PUNCT\": True}]\nmatcher.add(\"greetings\",  [pattern])\ndoc1 = nlp(\"Hello hello hello, how are you?\")\ndoc2 = nlp(\"Hi, how are you?\")\ndoc3 = nlp(\"How are you?\")\nfor doc in [doc1, doc2, doc3]:\n    spans = []\n    matches = matcher(doc)\n    for match_id, start, end in matches:\n        pattern_name = nlp.vocab.strings[match_id]\n        spans.append(Span(doc, start, end, pattern_name))\n    doc.spans[\"sc\"] = spans\n    displacy.render(doc, style=\"span\")\n```", "```py\npattern = [{\"LOWER\": {\"IN\": [\"hello\", \"hi\", \"hallo\"]},\n            \"OP\": \"*\"}, {\"IS_PUNCT\": True}]\nmatcher.add(\"greetings\",  [pattern])\ndoc1 = nlp(\"Hello hello hello, how are you?\")\ndoc2 = nlp(\"Hello, how are you?\")\ndoc3 = nlp(\"How are you?\")\nfor doc in [doc1, doc2, doc3]:\n    spans = []\n    matches = matcher(doc)\n    for match_id, start, end in matches:\n        pattern_name = nlp.vocab.strings[match_id]\n        spans.append(Span(doc, start, end, pattern_name))\n    doc.spans[\"sc\"] = spans\n    displacy.render(doc, style=\"span\")\n```", "```py\nmatcher = Matcher(nlp.vocab)\npattern = [{\"LOWER\": \"name\"},{\"LEMMA\": \"be\"},{}]\nmatcher.add(\"pickName\", [pattern])\ndoc = nlp(\"My name is Alice and his name was Elliot.\")\nmatches = matcher(doc)\nspans = []\nfor match_id, start, end in matches:\n    pattern_name = nlp.vocab.strings[match_id]\n    spans.append(Span(doc, start, end, pattern_name))\ndoc.spans[\"sc\"] = spans\ndisplacy.render(doc, style=\"span\")\n```", "```py\npattern = [{\"LEMMA\": \"forward\"}, {}, {\"LOWER\": \"email\"}]\nmatcher.add(\"forwardMail\",  [pattern])\ndoc1 = nlp(\"I forwarded his email to you.\")\ndoc2 = nlp(\"I forwarded an email to you.\")\ndoc3 = nlp(\"I forwarded the email to you.\")\nfor doc in [doc1, doc2, doc3]:\n    spans = []\n    matches = matcher(doc)\n    for match_id, start, end in matches:\n        pattern_name = nlp.vocab.strings[match_id]\n        spans.append(Span(doc, start, end, pattern_name))\n    doc.spans[\"sc\"] = spans\n    displacy.render(doc, style=\"span\")\n```", "```py\npattern = [{\"POS\": \"PRON\"},\n           {\"TEXT\": {\"REGEX\": \"[Tt]ravell?ed\"}}]\nmatcher.add(\"regex\", [pattern])\ndoc1 = nlp(\"I travelled by bus.\")\ndoc2 = nlp(\"She traveled by bike.\")\nfor doc in [doc1, doc2]:\n    spans = []\n    matches = matcher(doc)\n    for match_id, start, end in matches:\n        pattern_name = nlp.vocab.strings[match_id]\n        spans.append(Span(doc, start, end, pattern_name))\n    doc.spans[\"sc\"] = spans\n    displacy.render(doc, style=\"span\")\n```", "```py\npattern = [{\"TAG\": {\"REGEX\": \"^V\"}}]\nmatcher.add(\"verbs\",  [pattern])\ndoc = nlp(\"I went to Italy; he has been there too. His mother also has told me she wants to visit Rome.\")\nspans = []\nfor match_id, start, end in matches:\n    pattern_name = nlp.vocab.strings[match_id]\n    spans.append(Span(doc, start, end, pattern_name))\ndoc.spans[\"sc\"] = spans\ndisplacy.render(doc, style=\"span\")\n```", "```py\n    import spacy\n    from spacy.matcher import PhraseMatcher\n    nlp = spacy.load(\"en_core_web_sm\")\n    ```", "```py\n    matcher = PhraseMatcher(nlp.vocab)\n    terms = [\"Angela Merkel\", \"Donald Trump\", \"Alexis Tsipras\"]\n    patterns = [nlp.make_doc(term) for term in terms]\n    matcher.add(\"politiciansList\", patterns)\n    ```", "```py\n    doc = nlp(\"3 EU leaders met in Berlin. German chancellor Angela Merkel first welcomed the US president Donald Trump. The following day Alexis Tsipras joined them in Brandenburg.\")\n    matches = matcher(doc)\n    spans = []\n    for match_id, start, end in matches:\n        pattern_name = nlp.vocab.strings[match_id]\n        spans.append(Span(doc, start, end, pattern_name))\n    doc.spans[\"sc\"] = spans\n    displacy.render(doc, style=\"span\")\n    ```", "```py\nmatcher = PhraseMatcher(nlp.vocab, attr=\"LOWER\")\nterms = [\"Asset\", \"Investment\", \"Derivatives\", \"Demand\", \"Market\"]\npatterns = [nlp.make_doc(term) for term in terms]\nmatcher.add(\"financeTerms\", patterns)\n```", "```py\ndoc = nlp(\"During the last decade, derivatives market became an asset class of their own and influenced the financial landscape strongly.\")\nmatches = matcher(doc)\nspans = []\nfor match_id, start, end in matches:\n    pattern_name = nlp.vocab.strings[match_id]\n    spans.append(Span(doc, start, end, pattern_name))\ndoc.spans[\"sc\"] = spans\ndisplacy.render(doc, style=\"span\")\n```", "```py\nmatcher = PhraseMatcher(nlp.vocab, attr=\"SHAPE\")\nip_nums = [\"127.0.0.0\", \"127.256.0.0\"]\npatterns = [nlp.make_doc(ip) for ip in ip_nums]\nmatcher.add(\"IPNums\", patterns)\ndoc = nlp(\"This log contains the following IP addresses: 192.1.1.1 and 192.160.1.1 .\")\nmatches = matcher(doc)\nspans = []\nfor match_id, start, end in matches:\n    pattern_name = nlp.vocab.strings[match_id]\n    spans.append(Span(doc, start, end, pattern_name))\ndoc.spans[\"sc\"] = spans\ndisplacy.render(doc, style=\"span\")\n```", "```py\n    patterns = [{\"label\": \"ORG\",\n                \"pattern\": [{\"LOWER\": \"chime\"}]}]\n    ```", "```py\n    span_ruler = nlp.add_pipe(\n        \"span_ruler\", config={\"annotate_ents\":True})\n    ```", "```py\n    span_ruler.add_patterns(patterns)\n    doc = nlp(\"I have an acccount with chime since 2017\")\n    displacy.render(doc, style=\"ent\")\n    ```", "```py\nnlp.remove_pipe(\"span_ruler\")\npatterns = [{\"label\": \"ORG\",\n            \"pattern\": [{\"LOWER\": \"chime\"}]}]\nspan_ruler = nlp.add_pipe(\n    \"span_ruler\", config={\"annotate_ents\":True, \"overwrite\":False})\nspan_ruler.add_patterns(patterns)\ndoc = nlp(\"I have an acccount with chime since 2017\")\ndisplacy.render(doc, style=\"ent\")\n```", "```py\n{\"SHAPE\": \"XXdd\"}\n```", "```py\n{\"TEXT\": {\"REGEX\": \"\\d{1,4}\"}}\n```", "```py\n{\"TEXT\": {\"REGEX\": \"\\d{1,4}\"}, \"OP\": \"+\"}\n```", "```py\n    pattern = [{\"SHAPE\": \"XXdd\"},\n               {\"TEXT\": {\"REGEX\": \"\\d{1,4}\"}, \"OP\":\"+\"}]\n    matcher = Matcher(nlp.vocab)\n    matcher.add(\"ibanNum\",  [pattern])\n    ```", "```py\n    doc = nlp(\"My IBAN number is BE71 0961 2345 6769, please send the money there.\")\n    doc1 = nlp(\"My IBAN number is FR76 3000 6000 0112 3456 7890 189, please send the money there.\")\n    for doc in [doc, doc1]:\n        spans = []\n        matches = matcher(doc)\n        for match_id, start, end in matches:\n            pattern_name = nlp.vocab.strings[match_id]\n            spans.append(Span(doc, start, end, pattern_name))\n        doc.spans[\"sc\"] = spans\n        displacy.render(doc, style=\"span\")\n    ```", "```py\n{\"TEXT\": \"+1\", \"OP\": \"?\"}, {\"TEXT\": \"(\"}, {\"SHAPE\": \"ddd\"}, {\"TEXT\": \")\"}, {\"SHAPE\": \"ddd\"}, {\"TEXT\": \"-\", \"OP\": \"?\"}, {\"SHAPE\": \"dddd\"}\n```", "```py\npattern = [{\"TEXT\": \"+1\", \"OP\": \"?\"}, {\"TEXT\": \"(\"},\n           {\"SHAPE\": \"ddd\"}, {\"TEXT\": \")\"},\n           {\"SHAPE\": \"ddd\"}, {\"TEXT\": \"-\", \"OP\": \"?\"},\n           {\"SHAPE\": \"dddd\"}]\nmatcher = Matcher(nlp.vocab)\nmatcher.add(\"usPhonNum\",  [pattern])\n```", "```py\ndoc1 = nlp(\"You can call my office on +1 (221) 102-2423 or email me directly.\")\ndoc2 = nlp(\"You can call me on (221) 102 2423 or text me.\")\nfor doc in [doc1, doc2]:\n    spans = []\n    matches = matcher(doc)\n    for match_id, start, end in matches:\n        pattern_name = nlp.vocab.strings[match_id]\n        spans.append(Span(doc, start, end, pattern_name))\n    doc.spans[\"sc\"] = spans\n    displacy.render(doc, style=\"span\")\n```", "```py\nCafeA is very generous with the portions.\nCafeB is horrible, we waited for mins for a table.\nRestaurantA is terribly expensive, stay away!\nRestaurantB is pretty amazing, we recommend.\n```", "```py\n[{\"ENT_TYPE\": \"ORG\"}, {\"LEMMA\": \"be\"}, {\"POS\": \"ADV\", \"OP\": \"*\"}, {\"POS\": \"ADJ\"}]\n```", "```py\n[{\"LOWER\": \"acme\"}, {\"LEMMA\": \"be\"}, {\"POS\": \"ADV\", \"OP\": \"*\"}, {\"POS\": \"ADJ\"}]\n```", "```py\ndoc = nlp(\"#MySpace\")\nprint([token.text for token in doc])\n>>> ['#', 'MySpace']\n```", "```py\n{\"TEXT\": \"#\"}, {\"IS_ASCII\": True}\n```", "```py\npattern = [{\"TEXT\": \"#\"}, {\"IS_ASCII\": True}]\nmatcher = Matcher(nlp.vocab)\nmatcher.add(\"hashTag\",  [pattern])\n```", "```py\ndoc = nlp(\"Start working out now #WeekendShred\")\nmatches = matcher(doc)\nspans = []\nfor match_id, start, end in matches:\n    pattern_name = nlp.vocab.strings[match_id]\n    spans.append(Span(doc, start, end, pattern_name))\ndoc.spans[\"sc\"] = spans\ndisplacy.render(doc, style=\"span\")\n```", "```py\ndoc = nlp(\"Ms. Smith left her house 2 hours ago.\")\nprint(doc.ents)\n>>> (Smith, 2 hours ago)\n```", "```py\nnlp.remove_pipe(\"span_ruler\")\npatterns = [{\"label\": \"TITLE\",\n             \"pattern\": [{\"LOWER\": {\"IN\": [\n                 \"ms.\", \"mr.\", \"mrs.\", \"prof.\", \"dr.\"]}}]}]\nruler = nlp.add_pipe(\"span_ruler\", \n                     config={\"annotate_ents\":True, \"overwrite\":False})\nruler.add_patterns(patterns)\n```", "```py\ndoc = nlp(\"Ms. Smith left her house\")\ndisplacy.render(doc, style=\"ent\")\n```"]