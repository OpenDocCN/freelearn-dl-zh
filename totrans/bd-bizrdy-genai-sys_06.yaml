- en: '6'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Reasoning E-Marketing AI Agents
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The foundational concept of a successful advertising campaign is *memory*. Think
    about the advertisements you saw yesterday. What about those from one year ago
    or even several years ago? The ads you remember most vividly are the ones most
    effective for you, but perhaps not for someone else. The primary challenge for
    any advertising agency is designing promotional content that triggers positive
    reactions in diverse individuals. More crucially, successful marketing campaigns
    strive to make consumers remember brands, products, and services.
  prefs: []
  type: TYPE_NORMAL
- en: The Nielsen Neuroscience team (Brandt & Nieuwenhuis, 2017) explains why memory
    is so important in advertising. They demonstrate that memory decays significantly
    after just 24 hours, making it difficult for advertisements to have lasting effects.
    Several factors, including repetition and the emotional or intellectual impact
    of the content, can enhance memory retention. The emergence of agentic systems
    such as the GenAISys has reshaped the marketing landscape because these systems
    can replicate human-like expert marketing reasoning.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will enhance the GenAISys we’ve been building throughout
    previous chapters. First, we’ll design a **consumer memory agent** tailored to
    a specific market segment. The goal of this agent is to analyze how consumers
    encode promotional messages. We’ll begin by exploring why memory matters and how
    it is structured, examining key memory categories such as short-term, long-term,
    explicit, and implicit memory, as well as important dimensions such as intellectual
    and emotional encoding. Next, we’ll expand the architecture of the GenAISys by
    integrating a deeper understanding of consumer memory into its knowledge base.
    We’ll then develop a strategic consumer memory agent leveraging the multimodal
    capabilities introduced in earlier chapters. This agent will employ a neuroscience-inspired
    approach to craft customized marketing messages. By introducing **meta-cognition**
    through OpenAI’s advanced **o3 reasoning model**, we will enable the agent to
    perform sophisticated, near-human self-reflection within its multistep CoT reasoning
    process.
  prefs: []
  type: TYPE_NORMAL
- en: Further, we will transform our generative AI model into a neuroscientific-like
    agent capable of analytic reasoning rather than mere content generation. Complex
    systems—like the human brain—are more than the sum of their parts, and the same
    applies to machine intelligence. The strategic consumer memory agent using OpenAI’s
    o3 reasoning model will apply complex neuroscience-informed prompts to analyze
    consumer memory encoding patterns in hotel reviews. The resulting insights will
    feed into a multimodal **thread-of-reasoning pipeline**, building upon the CoT
    framework introduced in [*Chapter 5*](Chapter_5.xhtml#_idTextAnchor140)*, Adding
    Multimodal, Multifunctional Reasoning with Chain of Thought*. Ultimately, the
    GenAISys will leverage this detailed memory analysis to produce tailored marketing
    content using GPT-4o, accompanied by images generated by DALL-E.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we’ll further enhance the IPython interactive interface by adding new
    features, including a widget capable of triggering agentic meta-cognition for
    memory analysis and customer service tasks. Users will have the option to analyze
    various types of content for memory-related insights or initiate customer-service-oriented
    CoT interactions.
  prefs: []
  type: TYPE_NORMAL
- en: By the end of this chapter, you will have learned how to build a customized,
    reasoning-driven GenAISys applicable to any domain based on the architecture of
    our consumer memory agent. We’ll construct it step by step.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter covers the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: The importance of consumer memory in marketing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The high-level structure of human memory
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building a strategic CoT consumer memory agent
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Analyzing hotel reviews with CoT
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Designing neuroscientific-like complex prompts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using o3, OpenAI’s reasoning model that can analyze content in depth
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using OpenAI’s GPT-4o to generate content and DALL-E to generate images
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Assembling reasoning and generation in a thread-of-reasoning function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generalizing the consumer memory agent CoT to any content
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enhancing the IPython interactive interface
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s begin by designing the enhanced GenAISys interface and its AI-driven functionalities.
  prefs: []
  type: TYPE_NORMAL
- en: Designing the consumer GenAISys memory agent
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Consumer neuroscience can significantly enhance brand memorability through emotionally
    resonant, personalized messaging. In this chapter, we begin by analyzing how consumers
    encode memories. Nicks and Carriou (2016) demonstrate that effective consumer
    neuroscience leverages storytelling through narrative transportation, where consumers
    become emotionally engaged and vividly remember promotional messages.
  prefs: []
  type: TYPE_NORMAL
- en: In our implementation, we’ll deeply analyze how consumers encode memories, maintaining
    an authentic approach. If a consumer expresses dissatisfaction with a service,
    our system will tailor messages to emphasize improved offerings. Our goal is to
    create genuine connections through memorable, emotionally resonant messages.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we will describe how we enhance the GenAISys we have been
    building in the previous chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Consumer-memory agent use case**: Shows how an AI-driven agent can apply
    memory principles—drawn from short-term and **long-term memory** (**LTM**) frameworks—to
    interpret consumer feedback.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Defining memory structures**: This extends beyond the basic categories of
    **short-term memory** (**STM**), LTM, episodic memory, and semantic memory that
    we previously examined and introduces new categories and dimensions, providing
    a deeper analysis of the input.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Enhancing the architecture of the GenAISys**: This adds new functionality
    to trigger the AI agent and integrates a new CoT scenario.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s first explore the consumer memory agent use case.
  prefs: []
  type: TYPE_NORMAL
- en: Consumer-memory agent use case
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The use case in this chapter demonstrates how the GenAISys can be enhanced with
    a CoT consumer memory agent. Our goal is to understand a specific consumer’s needs
    when selecting a hotel, using detailed analyses of hotel reviews. The system we
    develop performs comprehensive content analysis, evaluates sentiment, and generates
    personalized marketing content. The CoT agent initiates this process with a detailed
    memory and sentiment analysis of a hotel review. It identifies psychological features,
    emotional markers, and specific memory tags, assigning a sentiment score to each
    analyzed segment. These scores are combined to produce an overall sentiment score
    and a scaled rating (0–5). Through this approach, the agent effectively captures
    how particular hotel experiences are perceived, emotionally processed, and retained
    in a consumer’s memory.
  prefs: []
  type: TYPE_NORMAL
- en: Based on these extracted insights and the resulting cognitive profile, the agent
    uses the scaled rating to determine the appropriate marketing strategy. Ultimately,
    the consumer memory agent produces tailored promotional content, including a customized
    message accompanied by a relevant image. For instance, if the analysis reveals
    a customer who generally dislikes hotels, the travel agency can emphasize alternative
    accommodations or improved services that the customer has previously mentioned
    positively. In such cases, the agent generates a personalized message with an
    engaging image, as illustrated in *Figure 6.1*.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.1: Custom content-based image generated by DALL-E](img/B32304_06_1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.1: Custom content-based image generated by DALL-E'
  prefs: []
  type: TYPE_NORMAL
- en: 'The agent crafts a warm, personalized message by analyzing the cognitive profile
    identified from customer hotel reviews:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Generative AI is stochastic, so the same input will not necessarily generate
    the same output. The response may thus change from one run to another.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s now define the memory structure that the consumer memory agent will use.
  prefs: []
  type: TYPE_NORMAL
- en: Defining memory structures
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s now expand upon the memory categories introduced in [*Chapter 1*](Chapter_1.xhtml#_idTextAnchor021)
    by outlining the human memory structures essential for building our consumer memory
    agent. Human memory is multifaceted: **STM** temporarily captures the information
    necessary for immediate tasks or emotional processing, quickly fading without
    reinforcement; **LTM** stores significant events, knowledge, and experiences over
    extended periods; **semantic memory** stores general knowledge and facts, independent
    of personal experience; **episodic memory** captures personally experienced events
    with context and detail; **procedural memory** enables unconscious retrieval of
    tasks, such as walking or driving; **emotional memory** categorizes experiences
    based on emotional intensity—positive or negative; and **explicit memory** involves
    conscious recall, whereas **implicit memory** operates unconsciously.'
  prefs: []
  type: TYPE_NORMAL
- en: Our consumer memory agent will analyze consumer content using a flexible combination
    of these memory categories, as shown in *Figure 6.2*. The categorization provides
    the o3 OpenAI reasoning model sufficient freedom to interpret consumer data effectively.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.2: The memory categories of the memory agent](img/B32304_06_2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.2: The memory categories of the memory agent'
  prefs: []
  type: TYPE_NORMAL
- en: 'The main categories at the upper level are the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Memoryless** for systems or humans that do not remember information from
    a past event. These are events that we most forget, such as how many times we
    blinked yesterday.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Short-Term Memory** for the temporary storage of information to perform a
    task or the process of emotion. This memory decays rapidly if no event stimulates
    it again. It could be the working memory of reading a long text.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Long-Term Memory** for information we store over long periods, from days
    to years. This is a vital memory, such as knowing which country we are in, our
    age, and who our family members are.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reality Memory** is what we know for sure related to actual events or facts,
    and the external world.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fiction Memory** includes imagined or hypothetical internal events or narratives.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Time Memory** is critical to distinguish past, present, and future events.
    Otherwise, we would think that we had already eaten what we were going to eat
    for lunch tomorrow.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Notice how memoryless, short-term, and long-term memory form a subset (light
    green), and reality, fiction, and time memory (light orange) are all connected.
    These categories aren’t isolated; they interconnect dynamically in real life.
    Our memory, in other words, doesn’t function in subsets but with what we can call
    *tags* in AI. A memory can be a combination of multiple tags:'
  prefs: []
  type: TYPE_NORMAL
- en: A memoryless fiction, such as a dream
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A short-term reality, such as reading the news
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A long-term fiction, such as a novel we read a long time ago
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When examining these memory subcategories, we quickly realize the vast number
    of possible tag combinations with the main memory categories—such as semantic
    STM or episodic LTM. Additionally, memories can seamlessly blend subcategories;
    for instance, the phrase “I visited Rome last year” combines episodic, semantic,
    and temporal memory tags simultaneously. Moreover, our memories range from implicit
    (subconsciously blinking our eyes all day) to explicit (intentionally blinking
    due to an irritation).
  prefs: []
  type: TYPE_NORMAL
- en: 'In our consumer memory agent, we will request a thorough analysis of content,
    assigning appropriate memory tags to each text segment. However, even this detailed
    tagging is not sufficient by itself. To effectively capture consumer experiences,
    we will enrich each memory tag with three analytical dimensions:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Intellectual dimension**: Identifies thoughts, logic, and reasoning within
    the text.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Emotional dimension**: Pinpoints emotions, feelings, and overall mood—critical
    for effective consumer engagement—and provides a quantifiable sentiment score
    ranging from 0 to 1, scalable to a familiar 1–5 rating used in customer satisfaction
    forms.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Physical dimension**: Highlights sensory experiences and physical sensations,
    such as “it was too cold to go swimming” or “my back hurt after sleeping in that
    hotel bed.”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With these enhancements in mind, let’s now explore how we’ll integrate them
    into the architecture of our evolving GenAISys.
  prefs: []
  type: TYPE_NORMAL
- en: Enhancing the architecture of the GenAISys
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this chapter, we will build upon the existing three-layer architecture of
    the GenAISys, as illustrated previously in *Figure 5.3* and reproduced here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.3: The three layers of the event-driven GenAISys](img/B32304_06_3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.3: The three layers of the event-driven GenAISys'
  prefs: []
  type: TYPE_NORMAL
- en: 'Our approach will be bottom-up, starting from the foundational functions and
    proceeding upward through the AI agent to the GenAISys interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Layer 3 (functions and agents)**: Here, we will introduce additional functionalities
    into our custom OpenAI library (`reason.py`), specifically tailored for the consumer
    memory agent and CoT reasoning. We will also develop a standalone memory analysis
    function that provides neuroscientific-like analyses applicable to any content.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Layer 2 (AI agent)**: This layer manages the behavior and decisions of our
    GenAISys. We will establish clear input triggers and naming conventions to activate
    and control the AI agent effectively.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Layer 1 (IPython interface)**: The interactive interface will be expanded
    to facilitate user interaction. We will add a new widget, allowing users to conveniently
    select how the consumer memory agent is invoked. Initially, we will focus on hotel
    reviews and subsequently generalize to any form of input.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s now begin building the consumer memory agent.
  prefs: []
  type: TYPE_NORMAL
- en: Building the consumer memory agent
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we take our GenAISys to the next level by equipping it with
    neuroscientific capabilities for analyzing hotel reviews. The consumer memory
    agent will capture a user’s cognitive, emotional, and physical mindset, decoding
    each review segment through a six-step CoT process, as illustrated in *Figure
    6.4*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.4: Chain-of-thought process of the memory agent](img/B32304_06_4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.4: Chain-of-thought process of the memory agent'
  prefs: []
  type: TYPE_NORMAL
- en: 'The consumer memory agent’s CoT will use OpenAI’s o3, GPT-4o, and DALL-E to
    run its six steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 1: Memory and Sentiment Analysis**: The agent will analyze the content
    of the hotel review with a complex memory structure system message. It will analyze
    and tag the content segment by segment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Step 2: Extract Scores**: The agent processes the output of *Step 1* to extract
    the sentiment scores of each content segment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Step 3: Statistical Analysis**:The agent uses the scores of all the tagged
    segments to produce an overall cognitive score for the content.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Step 4: Creating Content**:The agent now has a decision to make based on
    the score. If the score exceeds a positive threshold, it will generate a message
    encouraging the consumer to select hotels. However, if the score is negative,
    a guest house message will be created. Once the decision is made, the agent will
    use the consumer’s memory tags to create a tailored promotional message.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Step 5: Image Creation**: The agent now uses the output of *Step 4* to create
    an image that will fit the consumer’s mindset.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Step 6: Message Creation**: The agent now has all the information necessary
    to generate a custom message for the consumer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'After developing these steps individually, we’ll integrate them fully in the
    upcoming section, *GenAISys interface: From complexity to simplicity*, aiming
    to generalize the CoT functionality beyond hotel reviews.'
  prefs: []
  type: TYPE_NORMAL
- en: To begin our journey, open the `1_Building_the_Consumer_Memory_Agent.ipynb`
    notebook, which reuses previously built functionality, within the Chapter06 directory
    on GitHub ([https://github.com/Denis2054/Building-Business-Ready-Generative-AI-Systems/tree/main](https://github.com/Denis2054/Building-Business-Ready-Generative-AI-Systems/tree/main)).
    We will first download a dataset of hotel reviews to provide inputs to the AI
    agent.
  prefs: []
  type: TYPE_NORMAL
- en: 'The dataset: Hotel reviews'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will be using synthetic hotel reviews to build the memory agent. In this
    chapter, we will process hotel reviews but also generalize the memory structure
    of the agent to other content we wish to analyze. For copyright reasons, the dataset
    we are using is a synthetic dataset of reviews created manually and with a generative
    AI copilot.
  prefs: []
  type: TYPE_NORMAL
- en: If you wish to explore more datasets, you can use a similar dataset containing
    TripAdvisor hotel reviews available on Kaggle for non-commercial private implementations
    at [https://www.kaggle.com/datasets/andrewmvd/trip-advisor-hotel-reviews](https://www.kaggle.com/datasets/andrewmvd/trip-advisor-hotel-reviews).
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the *Setting up the Environment* section on GitHub, identical to [*Chapter
    5*](Chapter_5.xhtml#_idTextAnchor140), and download the dataset directly from
    the GitHub repository:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/3-PPMUMLAP0325.png)**Quick tip**: Enhance your coding experience with
    the **AI Code Explainer** and **Quick Copy** features. Open this book in the next-gen
    Packt Reader. Click the **Copy** button'
  prefs: []
  type: TYPE_NORMAL
- en: (**1**) to quickly copy code into your coding environment, or click the **Explain**
    button
  prefs: []
  type: TYPE_NORMAL
- en: (**2**) to get the AI assistant to explain a block of code to you.
  prefs: []
  type: TYPE_NORMAL
- en: '![A white background with a black text  AI-generated content may be incorrect.](img/image_%282%29.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/4.png)**The next-gen Packt Reader** is included for free with the purchase
    of this book. Scan the QR code OR visit [packtpub.com/unlock](http://packtpub.com/unlock),
    then use the search bar to find this book by name. Double-check the edition shown
    to make sure you get the right one.'
  prefs: []
  type: TYPE_NORMAL
- en: '![A qr code on a white background  AI-generated content may be incorrect.](img/Unlock_Code1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We will process the dataset with a pandas DataFrame. The program now loads
    the CSV file and displays the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'This dataset contains two primary columns: `Review` and `Rating`. For instance,
    record 0 has a relatively constructive rating of 3, while record 1 shows a clearly
    positive rating of 5:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.5: Excerpt of the hotel review dataset](img/B32304_06_5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.5: Excerpt of the hotel review dataset'
  prefs: []
  type: TYPE_NORMAL
- en: 'Ratings alone, however, don’t provide sufficient depth—we require a nuanced
    sentiment analysis to fully grasp why a customer was satisfied or dissatisfied.
    We will choose a challenging review to begin our analysis:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The program now extracts the review and its rating:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The output displays the review and its rating:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'We have chosen a difficult review because it contains both negative and positive
    sentiment. The negative aspect of the review will challenge the agent to generate
    constructive solutions. Before continuing, analyze the memory tags, sentiment
    scores, and dimensions of each review segment yourself. This exercise clarifies
    memory category usage and provides a benchmark for comparing your insights to
    the agent’s analysis. Set the extracted review as the initial input:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: We will now design a complex system message for *Step 1* for `input1`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 1: Memory and sentiment analysis'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This step introduces advanced reasoning to our consumer memory agent by incorporating
    meta-cognition and meta-reasoning through the OpenAI o3 reasoning model. In other
    words, the agent won’t simply process text—it will actively reflect on its internal
    reasoning, performing a segment-by-segment analysis to categorize memory types
    and assign sentiment scores.
  prefs: []
  type: TYPE_NORMAL
- en: Specifically, the o3 model will operate within our carefully structured system
    message, which we will design in detail. This system message guides the model
    clearly, prompting deep reasoning and ensuring it assigns memory tags accurately
    based on human-like cognitive processes. We are definitely in the era of reasoning
    and self-reflecting AI!
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we will do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Design a complex system message that incorporates the detailed memory structures
    defined earlier. This message, called `system_message_s1`, will be stored separately
    in a Python file for modularity.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rely on the reasoning abilities of OpenAI’s o3 to do the heavy lifting and execute
    detailed segment-level analysis, relieving us from manual interpretation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that we use o1 as an umbrella term to signal to the LLM its role as a reasoning
    model. Additionally, the LLM may refer to o1 itself in responses though we call
    o3 as much as possible in the API.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s now construct this detailed system message step by step.
  prefs: []
  type: TYPE_NORMAL
- en: Designing a complex system message for Step 1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We must design a system message comprehensive enough for the model to deeply
    understand and execute a neuroscience-inspired memory analysis. To achieve this,
    we carefully structure the message into clearly labeled sections, each guiding
    the agent through different aspects of the analysis.
  prefs: []
  type: TYPE_NORMAL
- en: 0\. Model introduction and role of the agent
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The first line sets the tone for the agent at two levels. The first level provides
    the agent with the necessary concepts to understand advanced memory analysis for
    this task. The second level describes the role of the agent in detail:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let’s go through the instructions to grasp what the agent is learning
    through this first part of the message:'
  prefs: []
  type: TYPE_NORMAL
- en: '`generative AI model, an advanced memory-analysis model`: We are setting the
    role of the system in a special way. We are asking the model to think, not just
    to generate text. For this task, we don’t want the model to be created but to
    analyze and reason.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`examine **each segment**`: We are teaching the model to replicate a neuroscience
    approach. Our brain encodes information in discrete packages. In this case, we
    are asking the model to mimic human memory processes. Each segment of text can
    be a sentence, a sentence piece, or a paragraph. This way, the model will analyze
    the text in a manner similar to how a human brain encodes information in independent
    packages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`generate a set of "memory encoding tags," similar to how the human brain encodes
    memories`: Human brains encode memories with *tags*, a term we can use at a high
    level without going into the biological process. Our brains apply tags to every
    bit of information that they encode to differentiate a past event from a future
    event, for example, from semantic data or personal emotional experiences. These
    tags represent the categories of memory we are looking for in human-generated
    text.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`discuss the rationale, and assign additional metadata`: The model must explain
    the rationale behind the category of memory it tags. Each category, such as STM
    or LTM, must be explained. We need to know why a memory tag was attributed to
    the segment. The model is asked to add dimensions to its description, including
    intellectual and emotional reasons.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You might notice a Markdown divider (`---`) in the code. It shows the model
    that we are now moving to another topic. This may seem unimportant, but we need
    to emphasize topic changes as we do when giving instructions to humans. Now, we
    will give the model a purpose.
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Purpose
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Line 3 is a header that shows the model that we are entering the first significant
    section of the message:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Line 4 defines the goal of o3, OpenAI’s reasoning model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that the message contains “o1,” which is used as an umbrella term for
    OpenAI’s reasoning models here. The main idea is for the API to understand that
    we expect reasoning. This instruction will activate reasoning no matter which
    reasoning model you select. The key parts of this *Purpose* section insist on
    what we expect:'
  prefs: []
  type: TYPE_NORMAL
- en: '`in-depth memory analysis`: We do not want a classical analysis but a reflection
    that goes into the details of each segment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Classify and label each segment you find using specific memory categories`:
    This is a strong indicator of the memory categories the model is expected to tag.
    Once again, we remind the agent that we don’t want to generate text but to classify
    and label segments.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`provides insight into how different parts of the text might be encoded in
    human memory`: This is an explicit indication that we expect human-like thinking
    and replicates the way a brain encodes memories.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We now need to give the agent the heading it needs to learn the categories.
    The first lines provide clear instructions. Now, we have reached section 2 of
    the message.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Memory encoding tags
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We now teach the agent how to recognize different categories of human encoding
    tags. We are getting to the core of human memory encoding. The memory categories
    are those discussed in the *Defining memory structures* section of this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'This heading is vital as the agent will learn the tags we expect by taking
    a hint from this heading. Now, the agent has absorbed the heading. We then give
    the model a clear explanation of what actions we expect:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s focus on the key parts of this message:'
  prefs: []
  type: TYPE_NORMAL
- en: '`tagging schema`: Aligns the model with the way the human brain encodes different
    categories of memory, distinguishing the past from the present using *tags*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`A single segment may exhibit one or more categories`: Explains to the model
    that a memory can be encoded in more than one category, just like in a human brain'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`If no category seems relevant … memoryless`: Tells the model that it should
    assign a memoryless tag if it cannot determine a category of a memory'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We then clearly define the categories (e.g., STM, LTM, episodic memory, semantic
    memory, time memory, reality memory, fiction memory, memoryless), as previously
    discussed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The memory tags have been described but are insufficient to capture human memory,
    which relies on other dimensions to encode events.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Dimensions
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The dimensions section adds intellectual, emotional, and physical features
    to the agent’s investigation. The descriptions of these dimensions in the following
    message were described in the *Defining memory structures* section earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: With that, we have defined the memory categories and additional dimensions.
    However, we also need a more refined analysis of emotions.
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Sentiment score
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'As defined in the *Defining memory structures* section, the sentiment score
    measures the emotional value of a segment. It provides a numerical score between
    0 (negative) and 1 (positive), or 0.5 (neutral) if no sentiment can be detected:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Note that each section in the message begins and ends with clear Markdown indicators
    that show a change in topic.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we are going to ask for a specific response format.
  prefs: []
  type: TYPE_NORMAL
- en: 5\. Response format
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We need the response to clearly display each segment of the original text,
    provide memory tags for each segment, determine the dimension (intellectual, emotional,
    or physical) of each segment, provide a sentiment score, and provide a brief explanation
    to justify the analysis:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'To make sure the model understands what we are asking for, we provide an example
    format:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: If we were writing a traditional generative AI model message, we could stop
    here. However, this is a complex message, so we need to add instructions to *insist
    on* what we expect.
  prefs: []
  type: TYPE_NORMAL
- en: 6\. Additional instructions
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We avoided overloading the previous sections of the message. If we try to squeeze
    too many instructions in, the model might get confused. Let’s remind the system
    that we always want a segment-by-segment analysis. We insist that if the model
    doesn’t find a category, we want a “memoryless” tag and not a hallucination. Additionally,
    we only want short and clear explanations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Now comes the tricky part. We told the model that if it didn’t find a category
    at all, to use a “memoryless” tag. However, if the model has an idea but is not
    100% sure, then it is allowed to pick the most probable memory tag along with
    a mandatory sentiment score:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: At this point, we have provided the model with numerous instructions. Let’s
    make sure it remembers its primary task.
  prefs: []
  type: TYPE_NORMAL
- en: 7\. Primary task recall
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'After all the instructions we have given the model, we will remind the model
    that its primary task is a memory tag analysis of text segments. We also expect
    the format of the output to be structured as defined:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Note that we added `[End of System Prompt]` to make sure that the model understands
    that the message part of the global prompt is now completely defined. We use the
    term `prompt` to make sure that it understands it as a set of instructions, not
    just a general message.
  prefs: []
  type: TYPE_NORMAL
- en: We are now ready to run the memory analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Running the memory analysis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The complex system message we designed is stored in a variable named `system_message_s1`
    in `cot_message_c6.py` in the `commons` directory of the GitHub repository. The
    goal is to keep this message and those for other steps separate from the function
    calls so that the AI agent of the GenAISys can repurpose the function in this
    step or other steps for different tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'We first download the file that contains the messages:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we import the `system_message_s1` message and the messages we will need
    for *Step 4*, which we will discuss later:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The `print` function is uncommented and will display the message we just created.
    It can be commented and used at any time to verify whether the message is correctly
    imported. We now prepare the messages for o3:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '`mrole` is `system_message_s1`, the system message we designed'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`user_text` is `review`, the review selected from the hotel reviews dataset'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We now call o3 and store the result in a variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '`make_openai_reasoning_call` is located in `reason`, the AI library of the
    GenAISys. It takes the two arguments we just defined, creates an OpenAI client,
    makes the request, and returns the response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'For this call, we chose the `o3-mini` version of the `o3` reasoning model series.
    Other versions and reasoning models can be chosen. The program displays the output
    received in `retres`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: The output shows the depth of the system message and the o3 reasoning model.
    The AI model has broken the content down into segments and decoded the memory
    tags subconsciously used by the human reviewer, as shown in the first segment.
  prefs: []
  type: TYPE_NORMAL
- en: 'The model first provides the segment number and the content of that segment.
    Let’s focus on segment 7, which requires our attention:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'It also provides the memory tags that encoded this segment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'It continues by providing the dimension, which is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'It then gives a sentiment score, which is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, it produces an explanation that sums up its analysis:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: The model then continues its analysis for all the segments of the review.We
    have now performed a complex memory analysis that sets the stage for the subsequent
    steps. Let’s proceed to extract the sentiment scores.
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 2: Extract sentiment scores'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'From this point on, the original input stored in `review` is not used again.
    The CoT process relies on the output of the previous step, which will continually
    vary depending on the context. The next step involves extracting the sentiment
    scores for all segments produced in *Step 1: Memory and sentiment analysis*. We
    will need this information to make decisions for *Step 4: Content creation*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To extract the scores, we first create an `extraction` function and provide
    detailed instructions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'We have clearly instructed our GenAISys to provide the sentiment scores in
    a clean format only. We will now call GPT-4o with `reason.make_openai_api_call`,
    defined previously, and add `reason.py`, the AI library we began building in the
    previous chapters. The input to the API call is the output of the last step, `retres`,
    appended to the instruction message, `umessage`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'The `system` role reminds the agent of its psychological marketing function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'The `user` role introduces the user message, `umessage`, and the API call is
    made:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'The agent returns `task_response`, from which we will extract the memory sentiment
    scores, process, and verify:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is the list of scores per segment we expected for each memory tag:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: We now need to consolidate these scores to use them for decision-making.
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 3: Statistics'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will use a simple non-AI **regular expressions** (**re**) module for this
    function for pattern matching and extraction. This shows that a GenAISys CoT can
    contain non-AI functions that expand its scope beyond generative AI models.
  prefs: []
  type: TYPE_NORMAL
- en: 'The text to analyze is the output of the previous step:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'We are looking for decimals:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'We then display the scores:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'The output contains the scores:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'We first calculate an overall score if the function returned scores:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we scale the score from 1 to 5:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we display the overall score and the scaled score:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is what we expected:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'The output requires some human analysis:'
  prefs: []
  type: TYPE_NORMAL
- en: In real-life projects, this process might not go so smoothly! Maybe the AI agent
    will not produce what we expect at all; perhaps it will for one step but not for
    the scores. When that occurs, we have to work on alternative steps. Building a
    GenAISys, as with any AI system, is an iterative process.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The original rating in the hotel dataset for this review was 3, and we obtained
    3.14, which is more refined. Online ratings are subjective and may not accurately
    reflect the content of the review. An AI agent will provide a more nuanced rating
    through advanced analysis processes similar to the one in this section. We could
    average the hotel review and ours. However, our goal is to generate a tailored
    message for the consumer. In a real-life project, we would reach out to consumers
    in marketing panels, utilizing the consumer memory agent, and obtain real-time
    feedback.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For now, however, we have the information we need to determine the content to
    create.
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 4: Content creation'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before deciding on the content to create, the agent reads the information messages.
    The first message is `umessage4`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: The message contains instructions on how to create a promotional campaign. We
    are keeping the message in a variable so that the function can be called with
    different prompts depending on the task.
  prefs: []
  type: TYPE_NORMAL
- en: 'The agent must first use the memory tags analyzed to generate, not analyze,
    a text:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, the agent receives instructions on the sentiment analysis:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, the agent receives final instructions on the content to generate:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'We now create the input by adding the scaled rating we obtained and the memory
    tags the agent found:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'The agent now has a complete representation of the task expected. We explain
    the agent’s role with `imcontent4`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'The agent is now ready to run the generation with the `make_openai_api_call`
    call:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'The response is a `pre_creation_response` response that is empathetic if the
    sentiment is negative or adapts it to the tone of the review otherwise:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is in a cognitive format. We’re going to run the same call but with
    a message to clean up and prepare the content for image generation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is a clear instruction to create an image with an exciting *luxurious*
    offer that is always appreciated:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: The output of the message may vary each time we run the requests, but the tone
    should remain the same. Also, we can adapt the instructions to other content to
    generate. In this case, the agent is all set to use this instruction to create
    an image.
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 5: Creating an image'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'At this stage, the consumer memory agent uses the instructions (`creation_response`)
    generated during *Step 4: Content creation* to create a tailored promotional image
    using OpenAI’s DALL-E:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'The `generate_image(prompt)` function is reused from the previous chapter.
    By consistently reusing functions, we reduce the development overhead and ensure
    code maintainability. As in[*Chapter 5*](Chapter_5.xhtml#_idTextAnchor140), the
    image is generated and stored in a file as `c_image.png`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: The image is now ready to accompany our final personalized message. We will
    display the image at the end of the process.
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 6: Creating a custom message'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'With the promotional image prepared, we now generate a concise and engaging
    customer message. First, we confirm that `creation_response` from *Step 5: Creating
    an image* is available:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'The output from the agent provides a polished message, suitable for customer
    communication:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now display the output in another format if we wish to, with Python’s
    `textwrap`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'The displayed message is clear, professional, and suitable for direct customer
    outreach:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: To enhance this message, you might adjust the prompt to omit references to AI
    or any internal system details, focusing purely on customer-oriented language.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, the system displays the generated image alongside the message to create
    an appealing, personalized promotional package:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting visual emphasizes the hotel’s upgraded, luxurious offering, perfectly
    aligned with the customer’s expectations based on their review analysis:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.6: An upgrade for a stay in the hotel for a customer](img/B32304_06_6.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.6: An upgrade for a stay in the hotel for a customer'
  prefs: []
  type: TYPE_NORMAL
- en: You can now experiment with additional reviews, testing the depth and flexibility
    of the agent. We have successfully developed a sophisticated, neuroscience-inspired
    CoT consumer memory agent. In the next section, we’ll integrate this full process
    into the `reason.py` AI library and further enhance our GenAISys framework.
  prefs: []
  type: TYPE_NORMAL
- en: 'GenAISys interface: From complexity to simplicity'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Our journey in this chapter has taken us deeper into the era of self-reflecting,
    reasoning, and meta-cognitive agentic AI. In this final section, we shift from
    the intricate inner workings of our consumer-memory CoT to a clean, intuitive
    user experience. We’ll add a CoT widget that lets any user trigger memory analysis
    or full content generation on arbitrary text. We’ll then extend the AI agent so
    it reacts to that widget’s options. Finally, we’ll demonstrate the generalized
    workflow on a flight review to show how the same memory logic applies to new domains.
  prefs: []
  type: TYPE_NORMAL
- en: Open the `2_Running_the_Reasoning_GenAISys.ipynb` notebook on GitHub. Then run
    the *Setting up the Environment* section, which is identical to the notebook in
    [*Chapter 5*](Chapter_5.xhtml#_idTextAnchor140). We will begin by adding a CoT
    widget to the IPython interface.
  prefs: []
  type: TYPE_NORMAL
- en: Adding the CoT widget
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To make the memory agent simple and intuitive, we introduce a straightforward
    drop-down menu (*Figure 6.6*). Users can effortlessly select the task they wish
    the GenAISys agent to perform:'
  prefs: []
  type: TYPE_NORMAL
- en: '**None** (default): No reasoning task is activated'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Analysis**: Activates a standalone memory-analysis function'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Generation**: Executes the full consumer memory agent workflow (*Steps 1–6*),
    including sentiment analysis, content generation, and custom message creation'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This streamlined user interaction significantly reduces complexity for the end
    user, shifting the sophisticated internal operations into the background.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.7: Choosing the reasoning task](img/B32304_06_7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.7: Choosing the reasoning task'
  prefs: []
  type: TYPE_NORMAL
- en: 'The widget is implemented in three steps—adding the widget, adding an observer,
    and sending the options to the AI agent:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Adding the widget is done in a few lines. We define the drop-down menu (`instruct_selector`)
    within the IPython interface:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The dropdown provides clear options, ensuring users easily understand their
    choices: **None**, **Analysis**, or **Generation**. Next, we incorporate `instruct_selector`
    into the existing interface layout (`VBox`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'When the user submits their choice, a handler updates the output messages for
    the user to see that the choice has been taken into account using standard submission
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: We want “Thinking…” to be displayed to signal to the user that the system is
    working.
  prefs: []
  type: TYPE_NORMAL
- en: 'The second step is to insert an observer that will detect a change the user
    makes and update the display. The `instruct_selector` is called by `instruct_selector.observe`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, we forward the user’s selection seamlessly into the AI agent call.
    The chosen reasoning mode (`active_instruct`) is integrated into the agent’s execution
    path:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: By clearly integrating these few lines, the AI agent dynamically activates the
    appropriate reasoning mode without additional user complexity. We can now enhance
    the AI agent.
  prefs: []
  type: TYPE_NORMAL
- en: Enhancing the AI agent
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The AI agent will now receive the user’s widget selection in a new argument
    named `active_instruct` that will trigger its decisions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'When the user selects **Analysis**, the AI agent triggers the previously built
    reasoning function, `make_openai_reasoning_call`, to perform memory analysis:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'Similarly, when **Generation** is selected, the agent runs the complete memory
    agent workflow using the custom `memory_reasoning_thread` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: With these straightforward integrations, the GenAISys interface now provides
    powerful reasoning capabilities transparently.
  prefs: []
  type: TYPE_NORMAL
- en: Generalizing the GenAISys capabilities
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'With the enhanced interface, users can easily apply memory agent reasoning
    to diverse content beyond hotel reviews. Let’s illustrate this flexibility with
    a general user comment regarding a flight. The user simply selects **Analysis**,
    then submits a flight review without additional instructions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: 'The GenAISys instantly returns a detailed, segment-by-segment memory analysis:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'The user then reenters the sentence, but this time with the **Generation**
    option and the **Files** option checked, so that the image generated with the
    text will be displayed. All the user has to do is select the option, enter the
    text, and submit it. Once again, the experience is seamless, no additional instructions
    are required on the part of the user, and the response is complete: the fully
    analysis, process, and final customer message as we designed in the previous section—beginning
    with memory analysis, proceeding to sentiment scoring, content generation, and
    concluding with a tailored customer message and an engaging image (see *Figure
    6.8*) that will be displayed if `Files` is checked in the interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure 6.8: An engaging customer image to match the personalized message](img/B32304_06_8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.8: An engaging customer image to match the personalized message'
  prefs: []
  type: TYPE_NORMAL
- en: We can see that from a user perspective, our GenAISys is running seamlessly.
    We are giving the user the illusion that everything in generative AI is simple.
    Of course, in a real-life project, we would have to spend resources trying all
    types of texts, finding the limitations, and solving the issues to cover edge
    cases and refine outputs. Let’s now sum up our journey in this chapter and take
    the GenAISys to yet another level.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter pushed our GenAISys far beyond classical AI, into the realm of
    meta-cognitive, self-reflective reasoning. We defined a pragmatic memory model
    combining primary categories (short-term, long-term, reality, fiction, and time)
    with semantic and episodic tags, then layered intellectual, emotional, and physical
    dimensions on top. Using this framework, we built a six-step CoT agent that decodes
    each review segment, tags memory categories, quantifies sentiment, and produces
    an overall cognitive score. Based on the cognitive profile and sentiment score,
    the agent generated personalized promotional text and created a matching DALL-E
    image—then wrapped everything into a polished customer message.
  prefs: []
  type: TYPE_NORMAL
- en: A new drop-down widget now lets users choose **None**, **Analysis**, or **Generation**,
    making sophisticated reasoning tasks a single-click experience. Behind the scenes,
    the AI agent routes requests to either a standalone memory analysis or the full
    consumer-memory workflow. We finally demonstrated the agent on a flight review,
    showing it can analyze, score, and respond to any text—extending GenAISys from
    hospitality into broader customer service scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: With these advances, the GenAISys is ready for real-time, production-grade decision-making.
    The next chapter will focus on scaling the functionality of our GenAISys architecture
    for immediate, high-throughput AI operations.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Emotional memory is a key factor in e-marketing. (True or False)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: OpenAI’s o3 is a reasoning model that can perform complex tasks. (True or False)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Long-term memory does not include emotional factors. (True or False)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A generative AI model cannot analyze complex memory structures. (True or False)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A generative AI model can not only analyze sentiments but also provide numerical
    scores between 0 and 1\. (True or False)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A Pinecone index can produce complex instructions based on system queries. (True
    or False)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A thread-of-reasoning agent can think through complex prompts and perform multiple
    coordinated tasks. (True or False)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A thread-of-reasoning scenario can be triggered with a user input. (True or
    False)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A reasoning agent can process reviews from sites such as TripAdvisor and generate
    custom messages. (True or False)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A generative AI system cannot process thread-of-reasoning agents. (True or False)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Brandt, Denise, and Ilja Nieuwenhuis. 2017\. Understanding Memory in Advertising.
    Nielsen. February. [https://www.nielsen.com/insights/2017/understanding-memory-in-advertising/](https://www.nielsen.com/insights/2017/understanding-memory-in-advertising/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nielsen Homepage: [https://www.nielsen.com/](https://www.nielsen.com/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Nicks, Guillaume, and Yannick Carriou. 2016\. Emotion, Attention and Memory
    in Advertising. Ipsos Knowledge Centre. [https://www.ipsos.com/sites/default/files/2017-07/Emotion-Attention-and-Memory-in-Ads.pdf](https://www.ipsos.com/sites/default/files/2017-07/Emotion-Attention-and-Memory-in-Ads.pdf)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ipsos Homepage: [https://www.ipsos.com/](https://www.ipsos.com/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'OpenAI. 2024\. OpenAI o3 System Card: A Comprehensive Evaluation of the o3
    Model Series, Outlining Advancements in Safety, Reasoning, and Robustness. OpenAI.
    [https://openai.com/index/o3-mini-system-card/](https://openai.com/index/o3-mini-system-card/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Woodside, Arch G., Sanjay Sood, and Kimberly E. Miller. 2008\. “When Consumers
    and Brands Talk: Storytelling Theory and Research in Psychology and Marketing.”
    Psychology & Marketing 25 (2): 97–145\. [https://www.researchgate.net/publication/229889043_When_consumers_and_brands_talk_Storytelling_theory_and_research_in_psychology_and_marketing](https://www.researchgate.net/publication/229889043_When_consumers_and_brands_talk_Storytelling_theory_and_research_in_psychology_and_marketing)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Subscribe for a Free eBook
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: New frameworks, evolving architectures, research drops, production breakdowns—*AI_Distilled*
    filters the noise into a weekly briefing for engineers and researchers working
    hands-on with LLMs and GenAI systems. Subscribe now and receive a free eBook,
    along with weekly insights that help you stay focused and informed.
  prefs: []
  type: TYPE_NORMAL
- en: Subscribe at [https://packt.link/TRO5B](Chapter_6.xhtml) or scan the QR code
    below.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Newsletter_QR_Code1.png)'
  prefs: []
  type: TYPE_IMG
