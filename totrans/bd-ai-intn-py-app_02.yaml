- en: '2'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '2'
- en: Building Blocks of Intelligent Applications
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 智能应用的基本构建块
- en: 'In the rapidly evolving landscape of software development, a new class of applications
    is emerging: intelligent applications. **Intelligent applications** are a superset
    of traditional full stack applications. These applications use **artificial intelligence**
    (**AI**) to deliver highly personalized, context-aware experiences that go beyond
    the capabilities of traditional software.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在软件开发快速发展的环境中，一类新的应用正在兴起：智能应用。**智能应用**是传统全栈应用的超集。这些应用利用**人工智能**（**AI**）提供高度个性化、上下文感知的体验，超越了传统软件的能力。
- en: Intelligent applications understand complex, unstructured data and use this
    understanding to make decisions and create natural, adaptive interactions.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 智能应用能够理解复杂、非结构化的数据，并利用这种理解来做出决策并创建自然、自适应的交互。
- en: The goal of this chapter is to provide you with an overview of the logical and
    technical building blocks of intelligent applications. The chapter explores how
    intelligent applications extend the capability of traditional full-stack applications,
    the core structures that define them, and how these components function to create
    dynamic, context-aware experiences. By the end of this chapter, you will understand
    how these components fit together to form an intelligent application.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的目标是向您提供一个关于智能应用逻辑和技术构建块的概述。本章探讨了智能应用如何扩展传统全栈应用的能力，定义它们的核心理念，以及这些组件如何协同工作以创建动态、上下文感知的体验。到本章结束时，您将了解这些组件如何组合在一起形成一个智能应用。
- en: 'This chapter covers the following topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖以下主题：
- en: The building blocks of intelligent applications
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 智能应用的基本构建块
- en: LLMs as reasoning engines for intelligent applications
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作为智能应用推理引擎的LLMs
- en: Vector embedding models and vector databases as semantic long-term memory
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向量嵌入模型和向量数据库作为语义长期记忆
- en: Model hosting infrastructure
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型托管基础设施
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: This chapter is theoretical. It covers the logical components of intelligent
    applications and how they fit together.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章是理论性的。它涵盖了智能应用的逻辑组件以及它们如何相互配合。
- en: This chapter assumes fundamental knowledge of traditional full stack application
    development components, such as servers, clients, databases, and APIs.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本章假设读者对传统全栈应用开发组件的基本知识有所了解，例如服务器、客户端、数据库和API。
- en: Defining intelligent applications
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义智能应用
- en: Traditional applications typically consist of a client-side user interface,
    a server-side backend, and a database for data storage and retrieval. They perform
    tasks following a strict set of instructions. Intelligent applications require
    a client, server, and database as well, but they augment the traditional stack
    with AI components.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 传统应用通常由客户端用户界面、服务器端后端以及用于数据存储和检索的数据库组成。它们按照严格的指令集执行任务。智能应用也需要客户端、服务器和数据库，但它们通过增加AI组件来增强传统的技术栈。
- en: Intelligent applications stand out by understanding complex, unstructured data
    to enable natural, adaptive interactions and decision-making. Intelligent applications
    can engage in open-ended interactions, generate novel content, and make autonomous
    decisions.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 智能应用通过理解复杂、非结构化的数据来脱颖而出，从而实现自然、自适应的交互和决策。智能应用可以参与开放式的交互，生成新颖的内容，并做出自主的决策。
- en: 'Examples of intelligent applications include the following:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 智能应用的例子包括以下内容：
- en: Chatbots that provide natural language responses based on external data using
    **retrieval-augmented generation** (**RAG**). For example, Perplexity.ai ([https://www.perplexity.ai/](https://www.perplexity.ai/))
    is an AI-powered search engine and chatbot that provides users with AI-generated
    answers to their queries based on sources retrieved from the web.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于外部数据使用**检索增强生成**（**RAG**）提供自然语言响应的聊天机器人。例如，Perplexity.ai ([https://www.perplexity.ai/](https://www.perplexity.ai/))
    是一个由AI驱动的搜索引擎和聊天机器人，它根据从网络检索到的来源为用户提供基于AI生成的答案。
- en: Content generators that let you use natural language prompts to create media
    such as images, video, and audio. There are a variety of intelligent content generators
    focusing on different media types, such as Suno ([https://suno.com/](https://suno.com/))
    for text-to-song, Midjourney ([https://www.midjourney.com/home](https://www.midjourney.com/home))
    for text-to-image, and Runway ([https://runwayml.com/](https://runwayml.com/))
    for text-to-video.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 允许您使用自然语言提示创建媒体内容（如图像、视频和音频）的内容生成器。有各种智能内容生成器专注于不同的媒体类型，例如Suno（[https://suno.com/](https://suno.com/)）提供文本转歌曲，Midjourney（[https://www.midjourney.com/home](https://www.midjourney.com/home)）提供文本转图像，以及Runway（[https://runwayml.com/](https://runwayml.com/)）提供文本转视频。
- en: Recommendation systems that use customer data to provide personalized suggestions
    based on their preferences and history. These suggestions can be augmented with
    natural language to further personalize the customer experience. An example of
    this is Spotify’s AI DJ ([https://support.spotify.com/us/article/dj/](https://support.spotify.com/us/article/dj/)),
    which creates a personalized radio station, including LLM-generated DJ interludes,
    based on your listening history.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用客户数据提供基于其偏好和历史记录的个性化建议的推荐系统。这些建议可以通过自然语言进一步个性化客户体验。例如，Spotify的AI DJ（[https://support.spotify.com/us/article/dj/](https://support.spotify.com/us/article/dj/））根据您的收听历史创建个性化的电台，包括由LLM生成的DJ插曲。
- en: These examples are a few early glances at the new categories of intelligent
    applications that developers have only started to build. In the next section,
    you will learn more about the core components of intelligent applications.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这些例子只是对开发者刚开始构建的新类别智能应用的初步探索。在下一节中，您将了解智能应用的核心组件。
- en: The building blocks of intelligent applications
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 智能应用的基本构建块
- en: 'At the heart of intelligent applications are two key building blocks:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 智能应用的核心是两个关键构建块：
- en: '**The reasoning engine**: The reasoning engine is the brain of an intelligent
    application, responsible for understanding user input, generating appropriate
    responses, and making decisions based on available information. The reasoning
    engine is typically powered by **large language models** (**LLMs**)—AI models
    that perform text completion. LLMs can understand user intent, generate human-like
    responses, and perform complex cognitive tasks.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**推理引擎**：推理引擎是智能应用的头脑，负责理解用户输入、生成适当的响应，并根据可用信息做出决策。推理引擎通常由**大型语言模型**（**LLMs**）驱动——这些是执行文本补全的AI模型。LLMs可以理解用户意图，生成类似人类的响应，并执行复杂的认知任务。'
- en: '**Semantic memory**: Semantic memory refers to the application’s ability to
    store and retrieve information in a way that preserves its meaning and relationships,
    enabling the reasoning engine to access relevant context as needed.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**语义记忆**：语义记忆指的是应用存储和检索信息的方式，能够保留其意义和关系，使推理引擎能够根据需要访问相关上下文。'
- en: 'Semantic memory consists of two core components:'
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 语义记忆由两个核心组件组成：
- en: '**AI vector embedding model**: AI vector embedding models represent the semantic
    meaning of unstructured data, such as text or images, in large arrays of numbers.'
  id: totrans-26
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AI向量嵌入模型**：AI向量嵌入模型将非结构化数据（如文本或图像）的语义意义表示为大量数字数组。'
- en: '**Vector database**: Vector databases efficiently store and retrieve vectors
    to support semantic search and context retrieval.'
  id: totrans-27
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**向量数据库**：向量数据库高效地存储和检索向量，以支持语义搜索和上下文检索。'
- en: The reasoning engine can retrieve and store relevant information from the semantic
    memory, using unstructured data to inform its outputs.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 推理引擎可以从语义记忆中检索和存储相关信息，使用非结构化数据来告知其输出。
- en: The LLMs and embedding models that power intelligent applications have different
    hardware requirements than traditional applications, especially at scale. Intelligent
    applications require specialized model hosting infrastructure that can handle
    the unique hardware and scalability requirements of AI workloads. Intelligent
    applications also incorporate continuous learning, safety monitoring, and human
    feedback to ensure quality and integrity.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 驱动智能应用的LLMs和嵌入模型与传统应用相比有不同的硬件要求，尤其是在规模上。智能应用需要专门的模型托管基础设施，能够处理AI工作负载的独特硬件和可扩展性要求。智能应用还结合了持续学习、安全监控和人工反馈，以确保质量和完整性。
- en: LLMs are the vital organ for intelligent applications. The next section will
    provide a deeper understanding of the role of LLMs in intelligent applications.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs是智能应用的重要器官。下一节将更深入地了解LLMs在智能应用中的作用。
- en: LLMs – reasoning engines for intelligent apps
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLMs – 智能应用的推理引擎
- en: LLMs are the key technology of intelligent applications, unlocking whole new
    classes of AI-powered systems. These models are trained on vast amounts of text
    data to understand language, generate human-like text, answer questions, and engage
    in dialogue.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs是智能应用的关键技术，解锁了全新类别的AI驱动系统。这些模型在大量文本数据上训练，以理解语言、生成类似人类的文本、回答问题和进行对话。
- en: LLMs undergo continuous improvement with the release of new models. featuring
    billions or trillions of parameters and enhanced reasoning, memory, and multi-modal
    capabilities.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 随着新模型的发布，LLMs不断改进，具有数十亿或数万亿参数，并增强了推理、记忆和多模态能力。
- en: Use cases for LLM reasoning engines
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LLM推理引擎的应用案例
- en: LLMs have emerged as a powerful general-purpose technology for AI systems, analogous
    to the **central processing unit** (**CPU**) in traditional computing. Much like
    CPUs, LLMs serve as general-purpose computational engines that can be programmed
    for many tasks and play a similar role in language-based reasoning and generation.
    The general-purpose nature of LLMs lets developers use their capabilities for
    a wide range of reasoning tasks.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs（大型语言模型）已成为人工智能系统的一种强大通用技术，类似于传统计算中的**中央处理器**（**CPU**）。与CPU类似，LLMs作为通用计算引擎，可以被编程执行许多任务，并在基于语言的推理和生成中扮演相似的角色。LLMs的通用性质使得开发者能够利用其能力进行广泛的推理任务。
- en: 'A crop of techniques to leverage the diverse abilities of LLMs have emerged,
    such as:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 一些技术已经出现，以利用LLMs的多样化能力，例如：
- en: '**Prompt engineering**: Using carefully crafted prompts, developers can steer
    LLMs to perform a wide range of language tasks. A key advantage of prompt engineering
    is its iterative nature. Since prompts are fundamentally just text, it’s easy
    to rapidly experiment with different prompts and see the results. Advanced prompt
    engineering techniques, such as chain-of-thought prompting (which encourages the
    model to break down its reasoning into a series of steps) and multi-shot prompting
    (which provides the model with example input/output pairs), can further enhance
    the quality and reliability of LLM-generated text.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提示工程**：通过精心设计的提示，开发者可以引导LLMs执行广泛的语言任务。提示工程的一个关键优势是其迭代性。由于提示本质上只是文本，因此可以快速尝试不同的提示并查看结果。高级提示工程技术，如思维链提示（鼓励模型将推理分解为一系列步骤）和多轮提示（为模型提供示例输入/输出对），可以进一步提高LLM生成文本的质量和可靠性。'
- en: '**Fine-tuning**: Fine-tuning involves starting with a pre-trained general-purpose
    model and further training it on a smaller dataset relevant to the target task.
    This can yield better results than prompt engineering alone, but it comes with
    certain caveats, such as being more expensive and time-consuming. You should only
    fine-tune after exhausting what you can achieve through prompt engineering.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**微调**：微调涉及从预训练的通用模型开始，并在与目标任务相关的较小数据集上进行进一步训练。这可以比单独的提示工程产生更好的结果，但也有一些缺点，如成本更高、耗时更长。你应该在用尽提示工程所能达到的效果后再进行微调。'
- en: '**Retrieval augmentation**: Retrieval augmentation interfaces LLMs with external
    knowledge, allowing them to draw on up-to-date, domain-specific information. In
    this approach, relevant information is retrieved from a knowledge base and injected
    into the prompt, enabling the LLM to generate contextually relevant outputs. Retrieval
    augmentation mitigates the limitations of the static pre-training of LLMs, keeping
    their knowledge updated and reducing the likelihood of the model hallucinating
    incorrect information.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**检索增强**：检索增强将LLMs与外部知识库接口连接起来，使其能够利用最新的、特定领域的知识。在这种方法中，相关信息从知识库中检索出来并注入到提示中，使LLM能够生成上下文相关的输出。检索增强减轻了LLMs静态预训练的限制，保持其知识更新，并减少模型产生错误信息的可能性。'
- en: With these techniques, you can use LLMs for a diverse array of tasks. The next
    section explores current use cases for LLMs.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 利用这些技术，你可以使用LLMs执行各种任务。下一节将探讨LLMs的当前应用案例。
- en: Diverse capabilities of LLMs
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LLMs的多样化能力
- en: 'While fundamentally *just* language models, LLMs have shown surprising emergent
    capabilities ([https://arxiv.org/pdf/2307.06435](https://arxiv.org/pdf/2307.06435)).
    As of writing in spring 2024, state-of-the-art language models are capable of
    performing tasks of the following categories:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管本质上只是语言模型，但LLM展现出了令人惊讶的涌现能力([https://arxiv.org/pdf/2307.06435](https://arxiv.org/pdf/2307.06435))。截至2024年春季，最先进的语言模型能够执行以下类别的任务：
- en: '**Text generation and completion**: Given a prompt, LLMs can generate coherent
    continuations, making them useful for tasks such as content creation, text summarization,
    and code completion.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文本生成和补全**：给定一个提示，LLM可以生成连贯的后续内容，这使得它们在内容创作、文本摘要和代码补全等任务中非常有用。'
- en: '**Open-ended dialogue and chat**: LLMs can engage in back-and-forth conversations,
    maintaining context and handling open-ended user queries and follow-up questions.
    This capability is foundational for chatbots, virtual assistants, tutoring systems,
    and similar applications.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**开放式对话和聊天**：LLM可以进行双向对话，保持上下文并处理开放式用户查询和后续问题。这种能力是聊天机器人、虚拟助手、辅导系统等应用的基石。'
- en: '**Question answering**: LLMs can provide direct answers to user questions,
    perform research, and synthesize information to address queries.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**问答**：LLM可以提供直接答案，进行研究和综合信息以回答查询。'
- en: '**Classification and sentiment analysis**: LLMs can classify text into predefined
    categories and assess sentiment, emotion, and opinion. This enables applications
    such as content moderation and customer feedback analysis.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分类和情感分析**：LLM可以将文本分类到预定义的类别，并评估情感、情绪和观点。这使得LLM在内容审核和客户反馈分析等应用中变得非常有用。'
- en: '**Data transformation and extraction**: LLMs can map unstructured text into
    structured formats and extract key information, such as named entities, relationships,
    and events. This makes LLMs valuable for tasks such as data mining, knowledge
    graph construction, and **robotic process** **automation** (**RPA**).'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据转换和提取**：LLM可以将非结构化文本映射到结构化格式，并提取关键信息，如命名实体、关系和事件。这使得LLM在数据挖掘、知识图谱构建和**机器人流程自动化**（RPA）等任务中非常有价值。'
- en: As LLMs continue to grow in scale and sophistication, new capabilities are constantly
    emerging, often in surprising ways that were not directly intended by the original
    training objective.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 随着LLM在规模和复杂性上的持续增长，新的能力不断涌现，通常以令人惊讶的方式出现，这些方式并非原始训练目标直接意图。
- en: For example, the ability of GPT-3 to generate functioning code was an unexpected
    discovery. With advancements in the field of LLMs, we can expect to see more impressive
    and versatile capabilities emerge, further expanding the potential of intelligent
    applications.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，GPT-3生成功能代码的能力是一个意外的发现。随着LLM（大型语言模型）领域的进步，我们可以期待看到更多令人印象深刻且功能多样的能力出现，进一步扩展智能应用的潜力。
- en: Multi-modal language models
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多模态语言模型
- en: '**Multi-modal language models** hold particular promise for expanding the capabilities
    of language models. Multi-modal models can process and generate images, speech,
    and video in addition to text, and have become an important component of intelligent
    applications.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**多模态语言模型**在扩展语言模型能力方面具有特别的前景。多模态模型可以处理和生成图像、语音和视频，除了文本之外，已成为智能应用的重要组成部分。'
- en: 'Examples of new application categories made possible with multi-modal models
    include the following:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 多模态模型使得以下新的应用类别成为可能：
- en: Creating content based on multiple input types, such as a chatbot where users
    can provide both images and text as inputs.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于多种输入类型创建内容，例如用户可以提供图像和文本作为输入的聊天机器人。
- en: Advanced data analysis, such as a medical diagnosis tool that analyzes X-rays
    along with medical records.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高级数据分析，例如分析X光片和医疗记录的医疗诊断工具。
- en: Real-time translation, taking audio or images of one language and translating
    it to another language.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实时翻译，将一种语言的音频或图像翻译成另一种语言。
- en: Such examples highlight how multi-modal language models can enhance the possible
    use cases for language models.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这样的例子突显了多模态语言模型如何增强语言模型的可能用例。
- en: A paradigm shift in AI development
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 人工智能发展的范式转变
- en: The rise of LLMs represents a paradigm shift in the development of AI-powered
    applications. Previously, many reasoning tasks required specially trained models,
    which were time-intensive and computationally expensive to create. Developing
    these models often necessitated dedicated **machine learning** (**ML**) engineering
    teams with specialized expertise.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs的兴起代表了AI应用开发中的范式转变。以前，许多推理任务需要专门训练的模型，这些模型的创建既耗时又计算量大。开发这些模型通常需要专门的**机器学习**（**ML**）工程团队和专业知识。
- en: In contrast, the general-purpose nature of LLMs allows most software engineers
    to leverage their capabilities through simple API calls and prompt engineering.
    While there is still an art and science to optimizing LLM-based workflows for
    production deployability, the process is significantly faster and more accessible
    compared to traditional ML approaches.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，LLMs的通用性质允许大多数软件工程师通过简单的API调用和提示工程利用其功能。虽然优化基于LLMs的工作流程以实现生产部署仍有一定的艺术性和科学性，但与传统的ML方法相比，这个过程要快得多，也更容易访问。
- en: This shift has dramatically reduced the total cost of ownership and development
    timelines for AI-powered applications. NLP tasks that previously could take months
    of work by a sophisticated ML engineering team can now be achieved by a single
    software engineer with access to an LLM API and some prompt engineering skills.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这种转变显著降低了AI应用的总拥有成本和开发时间表。以前可能需要复杂ML工程团队数月工作的NLP任务，现在可以通过单个软件工程师实现，该工程师可以访问LLM
    API并具备一些提示工程技能。
- en: Moreover, LLMs have unlocked entirely new classes of applications that were
    previously not possible or practical to develop. The ability of LLMs to understand
    and generate human-like text, engage in open-ended dialogue, and perform complex
    reasoning tasks has opened up a wide range of possibilities for intelligent applications
    across industries.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，LLMs解锁了之前无法或难以开发的新类别应用。LLMs理解和生成类似人类文本、参与开放式对话以及执行复杂推理任务的能力，为跨行业智能应用开辟了广泛的可能性。
- en: You’ll learn more about LLMs in [*Chapter 3*](B22495_03.xhtml#_idTextAnchor041),
    *Large Language Models*, which discusses their history and how they operate.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 你将在[*第3章*](B22495_03.xhtml#_idTextAnchor041)“大型语言模型”中了解更多关于LLMs的内容，该章节讨论了它们的历史和运作方式。
- en: Embedding models and vector databases – semantic long-term memory
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 嵌入模型和向量数据库——语义长期记忆
- en: In addition to the reasoning capabilities provided by LLMs, intelligent applications
    require semantic long-term memory for storing and retrieving information.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 除了LLMs提供的推理能力外，智能应用还需要语义长期记忆来存储和检索信息。
- en: Semantic memory typically consists of two core components—AI vector embedding
    models and vector databases. Vector embedding models represent the semantic meaning
    of unstructured data, such as text or images, in large arrays of numbers. Vector
    databases efficiently store and retrieve these vectors to support semantic search
    and context retrieval. These components work together to enable the reasoning
    engine to access relevant context and information as needed.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 语义记忆通常由两个核心组件组成——AI向量嵌入模型和向量数据库。向量嵌入模型将非结构化数据（如文本或图像）的语义意义表示为大量数字的大数组。向量数据库有效地存储和检索这些向量，以支持语义搜索和上下文检索。这些组件协同工作，使推理引擎能够根据需要访问相关上下文和信息。
- en: Embedding models
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 嵌入模型
- en: '**Embedding models** are AI models that map text and other data types, such
    as images and audio, into high-dimensional vector representations. These vector
    representations capture the semantic meaning of the input data, allowing for efficient
    similarity comparisons and semantic search, typically using cosine similarity
    as the distance metric.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '**嵌入模型**是AI模型，将文本和其他数据类型（如图像和音频）映射到高维向量表示。这些向量表示捕获输入数据的语义意义，允许进行高效的相似性比较和语义搜索，通常使用余弦相似度作为距离度量。'
- en: Embedding models encode semantic meaning into a machine-interpretable format.
    By representing similar concepts as nearby points in the vector space, embedding
    models let us measure the semantic similarity between pieces of unstructured data
    and perform semantic search across a large corpus.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入模型将语义意义编码成机器可解释的格式。通过将类似的概念表示为向量空间中的邻近点，嵌入模型使我们能够测量非结构化数据片段之间的语义相似性，并在大型语料库中执行语义搜索。
- en: Pre-trained embedding models are widely available and can be fine-tuned for
    specific domains or use cases. Compared to LLMs, embedding models tend to be more
    affordable and can run on limited hardware, making them accessible to a wider
    range of applications.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 预训练的嵌入模型广泛可用，并且可以针对特定领域或用例进行微调。与LLMs相比，嵌入模型通常更经济实惠，并且可以在有限的硬件上运行，这使得它们适用于更广泛的应用。
- en: 'Some common applications of embedding models include the following:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入模型的一些常见应用包括以下内容：
- en: '**Semantic search and retrieval**: Embedding models can be used as a component
    in larger AI systems to retrieve relevant context for LLMs, especially in RAG
    architectures. RAG is a particularly important use case for the intelligent applications
    discussed in this book and will be covered in more detail in [*Chapter 8*](B22495_08.xhtml#_idTextAnchor180),
    *Implementing Vector Search in* *AI Applications*.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**语义搜索和检索**：嵌入模型可以用作更大AI系统的一个组件，以检索LLMs的相关上下文，特别是在RAG架构中。RAG是本书中讨论的智能应用的一个重要用例，将在第8章[*第8章*](B22495_08.xhtml#_idTextAnchor180)，*在AI应用中实现向量搜索*中更详细地介绍。'
- en: '**Recommendation systems**: By representing items and user preferences as embeddings,
    recommendation systems can identify similar items and generate personalized recommendations.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**推荐系统**：通过将项目和用户偏好表示为嵌入，推荐系统可以识别相似的项目并生成个性化的推荐。'
- en: '**Clustering and topic modeling**: Embedding models can help discover latent
    topics and themes in large datasets, which can be useful for analyzing user interactions
    with intelligent applications, such as identifying frequently asked questions
    in a chatbot.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**聚类和主题建模**：嵌入模型可以帮助在大数据集中发现潜在的论题和主题，这对于分析用户与智能应用（如识别聊天机器人中的常见问题）的交互非常有用。'
- en: '**Anomaly** **detection**: By identifying outlier vectors that are semantically
    distant from the norm, embedding models can be used for anomaly detection in various
    domains.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**异常检测**：通过识别与正常情况在语义上距离较远的异常向量，嵌入模型可以用于各种领域的异常检测。'
- en: '**Analyzing relationships between entities**: Embedding models can uncover
    hidden relationships and connections between entities based on their semantic
    similarity.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分析实体之间的关系**：嵌入模型可以根据实体的语义相似性揭示实体之间隐藏的关系和联系。'
- en: You will explore the technical details and practical considerations of embedding
    models in [*Chapter 4*](B22495_04.xhtml#_idTextAnchor061), *Embedding Models*.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 你将在[*第4章*](B22495_04.xhtml#_idTextAnchor061)，*嵌入模型*中探索嵌入模型的技术细节和实际考虑。
- en: Vector databases
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 向量数据库
- en: '**Vector databases** are specialized data stores optimized for storing and
    searching high-dimensional vectors. They provide fast, **approximate nearest neighbor**
    (**ANN**) search capabilities that allow intelligent applications to quickly store
    and retrieve relevant information based on spatial proximity.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '**向量数据库**是针对存储和搜索高维向量进行优化的专用数据存储。它们提供了快速、**近似最近邻**（**ANN**）搜索功能，允许智能应用根据空间邻近性快速存储和检索相关信息。'
- en: ANN search is necessary because performing exact similarity calculations against
    every vector in the database becomes computationally expensive as the database
    grows in size. Vector databases use algorithms, such as **hierarchical navigable
    small worlds** (**HNSW**), to efficiently find approximate nearest neighbors,
    making vector search feasible at scale.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: ANN搜索是必要的，因为随着数据库规模的增加，对数据库中每个向量进行精确相似度计算的计算成本变得很高。向量数据库使用诸如**层次可导航小世界**（**HNSW**）之类的算法来有效地找到近似最近邻，使得大规模的向量搜索成为可能。
- en: In addition to ANN search, vector databases typically support filtering and
    exact search on metadata associated with the vectors. The exact functionality
    and performance of these features vary across different vector database products.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 除了ANN搜索外，向量数据库通常支持对与向量关联的元数据进行过滤和精确搜索。这些功能的精确功能和性能在不同向量数据库产品中有所不同。
- en: Vector databases provide an intelligent application with low-latency retrieval
    of relevant information given a query. Using the semantic meaning of the content
    for search, vector databases align with the way LLMs reason about information,
    enabling the application to apply the same unstructured data format for long-term
    memory as it does for reasoning.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 向量数据库在给定查询的情况下为智能应用提供低延迟的相关信息检索。使用内容的语义意义进行搜索，向量数据库与LLMs推理信息的方式相一致，使应用能够将相同的不结构化数据格式应用于长期记忆和推理。
- en: In applications that use RAG, the vector database plays a crucial role. The
    application generates a query embedding, which is used to retrieve relevant context
    from the vector database. Multiple relevant chunks are then provided as context
    to the LLM, which uses this information to generate informed and relevant responses.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用RAG的应用中，向量数据库扮演着至关重要的角色。应用生成一个查询嵌入，用于从向量数据库中检索相关上下文。然后，将多个相关片段作为上下文提供给LLM，LLM使用这些信息生成有见地和相关的响应。
- en: You will learn about the technical details and practical considerations of vector
    databases in [*Chapter 5*](B22495_05.xhtml#_idTextAnchor115), *Vector Databases*.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 您将在[*第5章*](B22495_05.xhtml#_idTextAnchor115) *向量数据库*中了解向量数据库的技术细节和实际考虑。
- en: Model hosting
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型托管
- en: To implement AI models in your intelligent application, you must host them on
    computers, either in a data center or the cloud. This process is known as **model
    hosting**. Hosting AI models for applications presents a different set of requirements
    compared to hosting traditional software. Running AI models at scale requires
    powerful **graphics processing units** (**GPUs**) and configuring the software
    environment to load and execute the model efficiently.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 要在您的智能应用中实现AI模型，您必须在计算机上托管它们，无论是在数据中心还是云中。这个过程被称为**模型托管**。为应用托管AI模型与托管传统软件相比，有一套不同的要求。大规模运行AI模型需要强大的**图形处理单元**（**GPUs**）并配置软件环境以高效地加载和执行模型。
- en: The key challenges in model hosting include high computational requirements
    and hardware costs, limited availability of GPU resources, complexity in managing
    and scaling the hosting infrastructure, and potential vendor lock-in or limited
    flexibility when using proprietary solutions. As a result, hardware and cost constraints
    must be factored into the application design process more than ever.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 模型托管的关键挑战包括高计算需求和硬件成本、GPU资源的有限可用性、管理和扩展托管基础设施的复杂性，以及使用专有解决方案时可能出现的供应商锁定或灵活性有限。因此，硬件和成本限制必须比以往任何时候都更多地纳入应用设计过程。
- en: Self-hosting models
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 自托管模型
- en: The term **self-hosting models** refers to the practice of deploying and running
    AI models, such as LLMs, on an organization’s own infrastructure and hardware
    resources. In this approach, the organization is responsible for setting up and
    maintaining the necessary computational resources, software environment, and infrastructure
    required to load and execute the models.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '**自托管模型**这一术语指的是在组织自己的基础设施和硬件资源上部署和运行AI模型（如LLMs）的做法。在这种方法中，组织负责设置和维护加载和执行模型所需的所有必要的计算资源、软件环境和基础设施。'
- en: Self-hosting AI models requires a significant upfront investment in specialized
    hardware, which can be cost-prohibitive for many organizations. Managing the model
    infrastructure also imposes an operational burden that requires ML expertise,
    which many software teams lack. This can divert the focus from the core application
    and business logic.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 自托管AI模型需要大量前期投资于专用硬件，这对许多组织来说可能是成本高昂的。管理模型基础设施也带来运营负担，这需要ML专业知识，而许多软件团队缺乏这种知识。这可能会分散对核心应用和业务逻辑的注意力。
- en: Scaling self-hosted models to ensure availability can be challenging, as models
    can be large and take time to load into memory. Organizations may need to provision
    significant excess capacity to handle peak loads. Additionally, maintaining and
    updating models is a complex task, as models can go stale over time and require
    retraining or fine-tuning. With the active research in the field, new models and
    techniques constantly emerge, making it difficult for organizations to keep up.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 将自托管模型扩展以确保可用性可能具有挑战性，因为模型可能很大，并且需要时间加载到内存中。组织可能需要预留大量额外容量来处理峰值负载。此外，维护和更新模型是一项复杂的工作，因为模型可能会随着时间的推移而变得过时，需要重新训练或微调。随着该领域的积极研究，新的模型和技术不断涌现，这使得组织难以跟上。
- en: Model hosting providers
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型托管提供商
- en: The challenges associated with self-hosting have made model hosting providers
    a popular choice for intelligent application development.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 与自托管相关的挑战使得模型托管提供商成为智能应用开发的流行选择。
- en: '**Model hosting providers** are cloud-based services that offer a platform
    for deploying, running, and managing AI models, such as LLMs, on their infrastructure.
    These providers handle the complexities of setting up, maintaining, and scaling
    the infrastructure required to load and execute the models.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型托管提供商** 是基于云的服务，提供在其基础设施上部署、运行和管理 AI 模型（如 LLMs）的平台。这些提供商处理设置、维护和扩展加载和执行模型所需基础设施的复杂性。'
- en: 'Model hosting providers offer several benefits:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 模型托管提供商提供以下好处：
- en: '**Outsourced hardware and infrastructure management**: Model hosting providers
    handle provisioning, scaling, availability, security, and other infrastructure
    concerns, allowing application teams to focus on their core product.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**外包硬件和基础设施管理**：模型托管提供商处理配置、扩展、可用性、安全性和其他基础设施问题，使应用团队能够专注于其核心产品。'
- en: '**Cost efficiency and flexible pricing**: With model hosting providers, organizations
    pay only for what they use and can scale resources up and down as needed, reducing
    upfront investment.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**成本效益和灵活定价**：通过模型托管提供商，组织只需为其使用的部分付费，并根据需要调整资源，从而减少前期投资。'
- en: '**Access to a wide range of models**: Providers curate and host many state-of-the-art
    models, continuously integrating the latest research. They often add additional
    features and optimizations to the raw models.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**访问广泛的模型**：提供商精选并托管许多最先进的模型，持续集成最新研究。他们通常在原始模型上添加额外的功能和优化。'
- en: '**Support and expertise**: Providers can offer consultation on model selection,
    prompt engineering, application architecture, and assistance with fine-tuning,
    data preparation, evaluation, and other aspects of AI development.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**支持和专业知识**：提供商可以就模型选择、提示工程、应用架构提供咨询，并在微调、数据准备、评估和其他 AI 开发方面提供帮助。'
- en: '**Rapid prototyping and experimentation**: Model hosting providers enable developers
    to quickly test different models and approaches, adapting to new developments
    in the fast-moving AI/ML space.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**快速原型设计和实验**：模型托管提供商使开发者能够快速测试不同的模型和方法，适应快速发展的 AI/ML 领域的新进展。'
- en: '**Scalability and reliability**: Providers build robust, highly available,
    and auto-scaling infrastructure to meet the demands of production-scale intelligent
    applications.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可扩展性和可靠性**：提供商构建强大、高度可用和自动扩展的基础设施，以满足生产规模智能应用的需求。'
- en: Examples of model hosting providers include those from model developers such
    as OpenAI, Anthropic, and Cohere, as well as offerings from cloud providers such
    as AWS Bedrock, Google Vertex AI, and Azure AI Studio.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 模型托管提供商的例子包括来自模型开发者如 OpenAI、Anthropic 和 Cohere 的服务，以及来自云提供商如 AWS Bedrock、Google
    Vertex AI 和 Azure AI Studio 的产品。
- en: Your (soon-to-be) intelligent app
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 您（即将成为的）智能应用
- en: 'With LLMs, embedding models, vector databases, and model hosting, you have
    the key building blocks for creating intelligent applications. While the specific
    architecture will vary depending on your use case, a common pattern emerges:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 LLMs、嵌入模型、向量数据库和模型托管，您拥有创建智能应用的关键构建块。虽然具体架构将根据您的用例而有所不同，但一个常见的模式出现：
- en: '**LLMs** for reasoning and generation'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LLMs** 用于推理和生成'
- en: '**Embeddings** and **vector search** for retrieval and memory'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**嵌入** 和 **向量搜索** 用于检索和记忆'
- en: '**Model hosting** to serve these components at scale'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型托管** 以大规模提供这些组件'
- en: This AI stack is integrated with traditional application components, such as
    backend services, APIs, frontend user interfaces, databases, and data pipelines.
    Additionally, intelligent applications often include components for AI-specific
    concerns, such as prompt management and optimization, data preparation and embedding
    generation, and AI safety, testing, and monitoring.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 此 AI 堆栈与传统应用组件集成，例如后端服务、API、前端用户界面、数据库和数据管道。此外，智能应用通常包括针对 AI 特定关注点的组件，例如提示管理和优化、数据准备和嵌入生成，以及
    AI 安全性、测试和监控。
- en: The rest of this section walks through an example architecture for a RAG-powered
    chatbot, showcasing how these components work together. The subsequent chapters
    will dive deeper into the end-to-end process of building production-grade intelligent
    applications.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 本节剩余部分将介绍一个由 RAG 驱动的聊天机器人示例架构，展示这些组件如何协同工作。后续章节将更深入地探讨构建生产级智能应用的端到端流程。
- en: Sample application – RAG chatbot
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 样例应用 – RAG 聊天机器人
- en: Consider a simple chatbot application that leverages RAG that lets users talk
    to some documentation.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个简单的聊天机器人应用，该应用利用 RAG 允许用户与某些文档进行交流。
- en: 'There are seven key components of this application:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 该应用程序有七个关键组件：
- en: '**Chatbot UI**: A website with a simple chatbot UI that communicates with the
    web server'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**聊天机器人 UI**：一个具有简单聊天机器人 UI 的网站，与网页服务器通信'
- en: '**Web server**: A Python Flask server to manage conversations between the user
    and the LLM'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Web 服务器**：一个 Python Flask 服务器，用于管理用户和 LLM 之间的对话'
- en: '**Data ingestion extract, transform, load (ETL) pipeline**: A Python script
    that ingests data from the data sources'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据摄取提取、转换、加载（ETL）管道**：一个 Python 脚本，用于从数据源摄取数据'
- en: '`text-embedding-3-small` model, hosted by OpenAI'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由 OpenAI 托管的 `text-embedding-3-small` 模型
- en: '`gpt-4-turbo` model, hosted by OpenAI'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由 OpenAI 托管的 `gpt-4-turbo` 模型
- en: '**Vector store**: MongoDB Atlas Vector Search'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**向量存储**：MongoDB Atlas 向量搜索'
- en: '**MongoDB Atlas**: A database-as-a-service for persisting conversations'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**MongoDB Atlas**：用于持久化对话的数据库即服务'
- en: Note
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: This simple example application does not include evaluation or observability
    modules.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这个简单的示例应用程序不包括评估或可观察性模块。
- en: 'In this architecture, there are two key data flows:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在此架构中，有两个关键的数据流：
- en: '**Chat interaction**: The user communicates with the chatbot with RAG'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**聊天交互**：用户使用 RAG 与聊天机器人进行交流'
- en: '**Data ingestion**: Bringing data from its original sources into the vector
    database'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据摄取**：将数据从其原始来源引入向量数据库'
- en: 'In the chat interaction, the chatbot UI communicates with the chatbot web server,
    which in turn interacts with the LLM, embedding model, and vector store. This
    occurs for every message that the user sends to the chatbot. *Figure 2**.1* shows
    the data flow for the chatbot application:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在聊天交互中，聊天机器人 UI 与聊天机器人网页服务器通信，该服务器随后与 LLM、嵌入模型和向量存储进行交互。这发生在用户向聊天机器人发送的每条消息时。*图
    2.1* 展示了聊天机器人应用程序的数据流：
- en: '![](img/B22495_02_01.jpg)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B22495_02_01.jpg)'
- en: 'Figure 2.1: An example of a basic RAG chatbot conversation data flow'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.1：基本 RAG 聊天机器人对话数据流示例
- en: 'The data flow illustrated in *Figure 2**.1* can be described as follows:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 2.1* 中所示的数据流可以描述如下：'
- en: The user sends a message to the chatbot from the web UI.
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用户从网页 UI 向聊天机器人发送消息。
- en: The web UI creates a request to the server with the user’s message.
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 网页用户界面向服务器发送包含用户消息的请求。
- en: The web server sends a request to the embedding model API to create a vector
    embedding for the user query. The embedding model API responds with the corresponding
    vector embedding.
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 网页服务器向嵌入模型 API 发送请求以创建用户查询的向量嵌入。嵌入模型 API 返回相应的向量嵌入。
- en: The web server performs a vector search in the vector database using the query
    vector embedding. The vector store responds with the matching vector search results.
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 网页服务器使用查询向量嵌入在向量数据库中执行向量搜索。向量存储返回匹配的向量搜索结果。
- en: The server constructs a message that the LLM will respond to. This message consists
    of a system prompt and a new message that includes the user’s original message
    and the content retrieved from the vector search. The LLM then responds to the
    user message.
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 服务器构建一个 LLM 将会回复的消息。这个消息由系统提示和一个包含用户原始消息和从向量搜索中检索的内容的新消息组成。然后 LLM 回复用户消息。
- en: The server saves the conversation state to the database.
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 服务器将对话状态保存到数据库中。
- en: The server returns the LLM-generated message to the user in a response to the
    original request from the web UI.
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 服务器将 LLM 生成的消息作为对网页 UI 原始请求的响应返回给用户。
- en: 'A data ingestion pipeline prepares and enriches data, generates embeddings
    using the embedding model, and populates the vector store and traditional database.
    This pipeline runs as a batch job every 24 hours. *Figure 2**.2* shows an example
    of a data ingestion pipeline:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 数据摄取管道准备和丰富数据，使用嵌入模型生成嵌入，并填充向量存储和传统数据库。此管道每 24 小时作为批处理作业运行。*图 2.2* 展示了数据摄取管道的示例：
- en: '![](img/B22495_02_02.jpg)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B22495_02_02.jpg)'
- en: 'Figure 2.2: An example of a RAG chatbot data ingestion ETL pipeline'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.2：RAG 聊天机器人数据摄取 ETL 管道示例
- en: 'Let’s look at the data flow shown in *Figure 2**.2*:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看 *图 2.2* 中所示的数据流：
- en: The data ingestion ETL pipeline pulls in data from various data sources.
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据摄取 ETL 管道从各种数据源中提取数据。
- en: The ETL pipeline cleans the data into a consistent format. It also breaks the
    data into chunks of data.
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ETL 管道将数据清理成一致格式。它还将数据分成数据块。
- en: The ETL pipeline calls the embedding model API to generate a vector embedding
    for each data chunk.
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ETL 管道调用嵌入模型 API 为每个数据块生成向量嵌入。
- en: The ETL pipeline stores the chunks along with their vector embeddings in a vector
    database.
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ETL 管道将数据块及其向量嵌入存储在向量数据库中。
- en: The vector database indexes the embeddings for use with vector search.
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向量数据库为向量搜索索引嵌入。
- en: 'While a simple architecture like this can be used to build compelling prototypes,
    transitioning from prototype to production and continuously iterating on the application
    requires addressing many additional considerations:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这种简单的架构可以用来构建引人注目的原型，但从原型过渡到生产并持续迭代应用需要解决许多额外的考虑因素：
- en: '**Data ingestion strategy**: Acquiring, cleaning, and preparing the data that
    will be ingested into the vector store or database for retrieval.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据摄取策略**：获取、清理和准备将被摄取到向量存储或数据库中以供检索的数据。'
- en: '**Advanced retrieval patterns**: Incorporating techniques for efficient and
    accurate retrieval of relevant information from the vector store or database,
    such as combining semantic search with traditional filtering, AI-based reranking,
    and query mutation.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高级检索模式**：结合从向量存储或数据库中高效准确地检索相关信息的技术，例如将语义搜索与传统过滤、基于AI的重新排序和查询变异相结合。'
- en: '**Evaluation and testing**: Adding modules for evaluating model outputs, testing
    end-to-end application flows, and monitoring for potential biases or errors.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**评估和测试**：添加评估模型输出、测试端到端应用流程和监控潜在偏差或错误的模块。'
- en: '**Scalability and performance optimization**: Implementing optimizations such
    as caching, load balancing, and efficient resource management to handle increasing
    workloads and ensure consistent responsiveness.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可扩展性和性能优化**：实施优化措施，如缓存、负载均衡和高效资源管理，以处理不断增长的工作负载并确保一致的响应性。'
- en: '**Security and privacy**: Securing the application to ensure that users can
    only interact with data that they have permission to, so that user data is handled
    in accordance with relevant policies, standards, and laws.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全和隐私**：确保应用的安全性，以便用户只能与他们有权限交互的数据进行交互，从而确保用户数据按照相关政策、标准和法律进行处理。'
- en: '**User experience and interaction design**: Incorporating new generative AI
    interfaces and interaction patterns, such as streaming responses, answer confidence,
    and source citation.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**用户体验和交互设计**：结合新的生成式AI界面和交互模式，例如流式响应、答案置信度和来源引用。'
- en: '**Continuous improvement and model updates**: Building processes and systems
    to update AI models safely and reliably and hyperparameters in the intelligent
    application.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**持续改进和模型更新**：建立流程和系统以安全可靠地更新智能应用中的AI模型和超参数。'
- en: Implications of intelligent applications for software engineering
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 智能应用对软件工程的影响
- en: The rise of intelligent applications has significant implications for how software
    is made. Developing these intelligent applications requires an extension of traditional
    development skills. The AI engineer must possess an understanding of prompt engineering,
    vector search, and evaluation, as well as familiarity with the latest AI techniques
    and architectures. While a complete understanding of the underlying neural networks
    is not necessary, basic knowledge of **natural language processing** (**NLP**)
    is helpful.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 智能应用的出现对软件制作方式产生了重大影响。开发这些智能应用需要扩展传统开发技能。AI工程师必须了解提示工程、向量搜索和评估，以及熟悉最新的AI技术和架构。虽然不需要完全理解底层神经网络，但了解**自然语言处理**（**NLP**）的基本知识是有帮助的。
- en: Intelligent application development also introduces new challenges and considerations,
    such as data management and integration with AI components, testing and debugging
    of AI-driven functionality, and addressing the ethical, safety, and security implications
    of AI outputs. The compute-heavy nature of AI workloads also necessitates focusing
    on scalability and cost optimization. Developers building traditional software
    generally do not need to face such concerns.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 智能应用开发也引入了新的挑战和考虑因素，例如数据管理、与AI组件的集成、AI驱动功能的测试和调试，以及解决AI输出的伦理、安全和隐私影响。AI工作负载的计算密集型特性也要求关注可扩展性和成本优化。构建传统软件的开发人员通常不需要面对这样的担忧。
- en: To address these challenges, software development teams must adapt their processes
    and adopt novel approaches and best practices. This entails implementing AI governance,
    bridging the gap between software and ML/AI teams, and adjusting the development
    lifecycle for intelligent app needs.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 为了应对这些挑战，软件开发团队必须调整其流程并采用新颖的方法和最佳实践。这包括实施AI治理、弥合软件与ML/AI团队之间的差距，并调整智能应用需求的发展生命周期。
- en: Summary
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Intelligent applications represent a new paradigm in software development, combining
    AI with traditional application components to deliver highly personalized, context-aware
    experiences. This chapter details the core components of intelligent applications,
    highlighting the pivotal role of LLMs as reasoning engines. LLMs serve as versatile
    computational tools capable of performing diverse tasks, including chat, summarization,
    and classification, due to their general-purpose design.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 智能应用代表了软件开发的新范式，将人工智能与传统的应用组件相结合，以提供高度个性化、上下文感知的体验。本章详细介绍了智能应用的核心组件，突出了LLMs作为推理引擎的关键作用。LLMs作为通用设计工具，能够执行各种任务，包括聊天、摘要和分类。
- en: Complementing these reasoning engines are embedding models and vector databases,
    which function as the semantic memory of intelligent applications. These components
    enable the reasoning engine to retrieve pertinent context and information as needed.
    Additionally, the hosting of AI models demands dedicated infrastructure, as their
    unique hardware requirements differ significantly from traditional software needs.
    Using building blocks such as LLMs, embedding models, vector databases, and model
    hosting infrastructure, developers can create applications that understand complex,
    unstructured data, engage in open-ended interactions, generate novel content,
    and make autonomous decisions. Building these intelligent applications demands
    a new set of tools, approaches, and best practices.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 补充这些推理引擎的是嵌入模型和向量数据库，它们作为智能应用的语义记忆。这些组件使推理引擎能够根据需要检索相关的上下文和信息。此外，托管AI模型需要专用基础设施，因为它们的独特硬件需求与传统软件需求差异很大。使用LLMs、嵌入模型、向量数据库和模型托管基础设施等构建块，开发者可以创建能够理解复杂、非结构化数据、进行开放式交互、生成新颖内容并做出自主决策的应用程序。构建这些智能应用需要一套新的工具、方法和最佳实践。
- en: The next chapter will examine how LLMs work and the role they play in building
    intelligent applications.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章将探讨大型语言模型（LLMs）的工作原理以及它们在构建智能应用中的作用。
- en: Part 1
  id: totrans-160
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第一部分
- en: 'Foundations of AI: LLMs, Embedding Models, Vector Databases, and Application
    Design'
  id: totrans-161
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人工智能基础：LLMs、嵌入模型、向量数据库和应用设计
- en: This set of chapters provides in-depth and practical knowledge on the techniques
    and principles underpinning AI-intensive applications. You will progress quickly
    from fundamental concepts to real-world use cases and learn best practices for
    building your AI solution.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 这套章节提供了关于支撑AI密集型应用的技术和原理的深入和实践知识。您将迅速从基本概念进步到实际用例，并学习构建您AI解决方案的最佳实践。
- en: 'This part of the book includes the following chapters:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 本书这部分包括以下章节：
- en: '[*Chapter 3*](B22495_03.xhtml#_idTextAnchor041), *Large Language Models*'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第3章*](B22495_03.xhtml#_idTextAnchor041), *大型语言模型*'
- en: '[*Chapter 4*](B22495_04.xhtml#_idTextAnchor061), *Embedding Models*'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第4章*](B22495_04.xhtml#_idTextAnchor061), *嵌入模型*'
- en: '[*Chapter 5*](B22495_05.xhtml#_idTextAnchor115), *Vector Databases*'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第5章*](B22495_05.xhtml#_idTextAnchor115), *向量数据库*'
- en: '[*Chapter 6*](B22495_06.xhtml#_idTextAnchor137), *AI/ML Application Design*'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第6章*](B22495_06.xhtml#_idTextAnchor137), *AI/ML应用设计*'
