["```py\ntar –xvzf lingpipeCookbook.tgz\n\n```", "```py\n    java -cp lingpipe-cookbook.1.0.jar:lib/lingpipe-4.1.0.jar com.lingpipe.cookbook.chapter1.RunClassifierFromDisk\n\n    ```", "```py\n    java -cp \"lingpipe-cookbook.1.0.jar;lib\\lingpipe-4.1.0.jar\" com.lingpipe.cookbook.chapter1.RunClassifierFromDisk\n\n    ```", "```py\n    Loading: models/3LangId.LMClassifier\n    Type a string to be classified. Empty string to quit.\n    The rain in Spain falls mainly on the plain.\n    english\n    Type a string to be classified. Empty string to quit.\n    la lluvia en España cae principalmente en el llano.\n    spanish\n    Type a string to be classified. Empty string to quit.\n    スペインの雨は主に平野に落ちる。\n    japanese\n\n    ```", "```py\n    Type a string to be classified. Empty string to quit.\n    المطر في اسبانيا يقع أساسا على سهل.\n    japanese\n\n    ```", "```py\npackage com.lingpipe.cookbook.chapter1;\nimport java.io.File;\nimport java.io.IOException;\n\nimport com.aliasi.classify.BaseClassifier;\nimport com.aliasi.util.AbstractExternalizable;\nimport com.lingpipe.cookbook.Util;\npublic class RunClassifierFromDisk {\n  public static void main(String[] args) throws\n  IOException, ClassNotFoundException {\n```", "```py\nString classifierPath = args.length > 0 ? args[0] :  \"models/3LangId.LMClassifier\";\nSystem.out.println(\"Loading: \" + classifierPath);\n```", "```py\nFile serializedClassifier = new File(classifierPath);\n@SuppressWarnings(\"unchecked\")\nBaseClassifier<String> classifier\n  = (BaseClassifier<String>)\n  AbstractExternalizable.readObject(serializedClassifier);\n```", "```py\nAbstractExternalizable.readObject method.\n```", "```py\nUtil.consoleInputBestCategory(classifier);\n```", "```py\npublic static void consoleInputBestCategory(\nBaseClassifier<CharSequence> classifier) throws IOException {\n  BufferedReader reader = new BufferedReader(new InputStreamReader(System.in));\n  while (true) {\n    System.out.println(\"\\nType a string to be classified. \" + \" Empty string to quit.\");\n    String data = reader.readLine();\n    if (data.equals(\"\")) {\n      return;\n    }\n    Classification classification = classifier.classify(data);\n    System.out.println(\"Best Category: \" + classification.bestCategory());\n  }\n}\n```", "```py\nLMClassifier<CompiledNGramBoundaryLM, MultivariateDistribution> classifier = (LMClassifier <CompiledNGramBoundaryLM, MultivariateDistribution>) AbstractExternalizable.readObject(new File(args[0]));\n```", "```py\nJointClassifier<String> classifier = (JointClassifier<String>) AbstractExternalizable.readObject(new File(classifierPath));\n```", "```py\n    java -cp lingpipe-cookbook.1.0.jar:lib/lingpipe-4.1.0.jar: com.lingpipe.cookbook.chapter1.RunClassifierJoint \n\n    ```", "```py\n    Type a string to be classified. Empty string to quit.\n    The rain in Spain falls mainly on the plain.\n    Rank Categ Score   P(Category|Input) log2 P(Category,Input)\n    0=english -3.60092 0.9999999999         -165.64233893156052\n    1=spanish -4.50479 3.04549412621E-13    -207.2207276413206\n    2=japanese -14.369 7.6855682344E-150    -660.989401136873\n\n    ```", "```py\npublic static void main(String[] args) throws IOException, ClassNotFoundException {\n  String classifierPath  = args.length > 0 ? args[0] : \"models/3LangId.LMClassifier\";\n  @SuppressWarnings(\"unchecked\")\n    JointClassifier<CharSequence> classifier = (JointClassifier<CharSequence>) AbstractExternalizable.readObject(new File(classifierPath));\n  Util.consoleInputPrintClassification(classifier);\n}\n```", "```py\npublic static void consoleInputPrintClassification(BaseClassifier<CharSequence> classifier) throws IOException {\n  BufferedReader reader = new BufferedReader(new InputStreamReader(System.in));\n  while (true) {\n    System.out.println(\"\\nType a string to be classified.\" + Empty string to quit.\");\n    String data = reader.readLine();\n    if (data.equals(\"\")) {\n      return;\n    }\n    Classification classification = classifier.classify(data);\n    System.out.println(classification);\n  }\n}\n```", "```py\n    debug=false\n    oauth.consumerKey=ehUOExampleEwQLQpPQ\n    oauth.consumerSecret=aTHUGTBgExampleaW3yLvwdJYlhWY74\n    oauth.accessToken=1934528880-fiMQBJCBExamplegK6otBG3XXazLv\n    oauth.accessTokenSecret=y0XExampleGEHdhCQGcn46F8Vx2E\n    ```", "```py\n    java -cp lingpipe-cookbook.1.0.jar:lib/twitter4j-core-4.0.1.jar:lib/opencsv-2.4.jar:lib/lingpipe-4.1.0.jar com.lingpipe.cookbook.chapter1.TwitterSearch\n\n    ```", "```py\n    Writing output to data/twitterSearch.csv\n    Enter Twitter Query:disney\n\n    ```", "```py\n    Tweets Accumulated: 100\n    Tweets Accumulated: 200\n    …\n    Tweets Accumulated: 1500\n    writing to disk 1500 tweets at data/twitterSearch.csv \n\n    ```", "```py\nString outFilePath = args.length > 0 ? args[0] : \"data/twitterSearch.csv\";\nFile outFile = new File(outFilePath);\nSystem.out.println(\"Writing output to \" + outFile);\nBufferedReader reader = new BufferedReader(new InputStreamReader(System.in));\nSystem.out.print(\"Enter Twitter Query:\");\nString queryString = reader.readLine();\n```", "```py\nTwitter twitter = new TwitterFactory().getInstance();\nQuery query = new Query(queryString + \" -filter:retweets\"); query.setLang(\"en\");//English\nquery.setCount(TWEETS_PER_PAGE);\nquery.setResultType(Query.RECENT);\n```", "```py\nList<String[]> csvRows = new ArrayList<String[]>();\nwhile(csvRows.size() < MAX_TWEETS) {\n  QueryResult result = twitter.search(query);\n  List<Status> resultTweets = result.getTweets();\n  for (Status tweetStatus : resultTweets) {\n    String row[] = new String[Util.ROW_LENGTH];\n    row[Util.TEXT_OFFSET] = tweetStatus.getText();\n    csvRows.add(row);\n  }\n  System.out.println(\"Tweets Accumulated: \" + csvRows.size());\n  if ((query = result.nextQuery()) == null) {\n    break;\n  }\n}\n```", "```py\nquery to handle paging through the search results—it returns null when no more pages are available. The current Twitter API allows a maximum of 100 results per page, so in order to get 1500 results, we need to rerun the search until there are no more results, or until we get 1500 tweets. The next step involves a bit of reporting and writing:\n```", "```py\nSystem.out.println(\"writing to disk \" + csvRows.size() + \" tweets at \" + outFilePath);\nUtil.writeCsvAddHeader(csvRows, outFile);\n```", "```py\npublic static void writeCsvAddHeader(List<String[]> data, File file) throws IOException {\n  CSVWriter csvWriter = new CSVWriter(new OutputStreamWriter(new FileOutputStream(file),Strings.UTF8));\n  csvWriter.writeNext(ANNOTATION_HEADER_ROW);\n  csvWriter.writeAll(data);\n  csvWriter.close();\n}\n```", "```py\n    java -cp lingpipe-cookbook.1.0.jar:lib/lingpipe-4.1.0.jar:lib/twitter4j-core-4.0.1.jar:lib/opencsv-2.4.jar com.lingpipe.cookbook.chapter1.ReadClassifierRunOnCsv\n\n    ```", "```py\n    InputText: When all else fails #Disney\n    Best Classified Language: english\n    InputText: ES INSUPERABLE DISNEY !! QUIERO VOLVER:(\n    Best Classified Language: Spanish\n\n    ```", "```py\nString inputPath = args.length > 0 ? args[0] : \"data/disney.csv\";\nString classifierPath = args.length > 1 ? args[1] : \"models/3LangId.LMClassifier\";\n@SuppressWarnings(\"unchecked\") BaseClassifier<CharSequence> classifier = (BaseClassifier<CharSequence>) AbstractExternalizable.readObject(new File(classifierPath));\nList<String[]> lines = Util.readCsvRemoveHeader(new File(inputPath));\nfor(String [] line: lines) {\n  String text = line[Util.TEXT_OFFSET];\n  Classification classified = classifier.classify(text);\n  System.out.println(\"InputText: \" + text);\n  System.out.println(\"Best Classified Language: \" + classified.bestCategory());\n}\n```", "```py\npublic static List<String[]> readCsvRemoveHeader(File file) throws IOException {\n  FileInputStream fileIn = new FileInputStream(file);\n  InputStreamReader inputStreamReader = new InputStreamReader(fileIn,Strings.UTF8);\n  CSVReader csvReader = new CSVReader(inputStreamReader);\n  csvReader.readNext();  //skip headers\n  List<String[]> rows = new ArrayList<String[]>();\n  String[] row;\n  while ((row = csvReader.readNext()) != null) {\n    if (row[TEXT_OFFSET] == null || row[TEXT_OFFSET].equals(\"\")) {\n      continue;\n    }\n    rows.add(row);\n  }\n  csvReader.close();\n  return rows;\n}\n```", "```py\n    java -cp lingpipe-cookbook.1.0.jar:lib/opencsv-2.4.jar:lib/lingpipe-4.1.0.jar com.lingpipe.cookbook.chapter1.RunConfusionMatrix\n\n    ```", "```py\n    reference\\response\n     \\e,n,\n     e 11,0,\n     n 1,9,\n\n    ```", "```py\n@SuppressWarnings(\"unchecked\")\nBaseClassifier<CharSequence> classifier = (BaseClassifier<CharSequence>) AbstractExternalizable.readObject(new File(classifierPath));\n\nList<String[]> rows = Util.readAnnotatedCsvRemoveHeader(new File(inputPath));\n```", "```py\nString[] categories = Util.getCategories(rows);\n```", "```py\npublic static String[] getCategories(List<String[]> data) {\n  Set<String> categories = new HashSet<String>();\n  for (String[] csvData : data) {\n    if (!csvData[ANNOTATION_OFFSET].equals(\"\")) {\n      categories.add(csvData[ANNOTATION_OFFSET]);\n    }\n  }\n  return categories.toArray(new String[0]);\n}\n```", "```py\nboolean storeInputs = false;\nBaseClassifierEvaluator<CharSequence> evaluator = new BaseClassifierEvaluator<CharSequence>(classifier, categories, storeInputs);\n```", "```py\nfor (String[] row : rows) {\n  String truth = row[Util.ANNOTATION_OFFSET];\n  String text = row[Util.TEXT_OFFSET];\n  Classification classification = new Classification(truth);\n  Classified<CharSequence> classified = new Classified<CharSequence>(text,classification);\n  evaluator.handle(classified);\n}\n```", "```py\nSystem.out.println(Util.confusionMatrixToString(evaluator.confusionMatrix()));\n```", "```py\n    java -cp lingpipe-cookbook.1.0.jar:lib/opencsv-2.4.jar:lib/lingpipe-4.1.0.jar com.lingpipe.cookbook.chapter1.TrainAndRunLMClassifier\n\n    ```", "```py\n    Type a string to be classified. Empty string to quit.\n    So it goes.\n    Rank Categ Score  P(Category|Input)  log2 P(Category,Input)\n    0=e -4.24592987919 0.9999933712053  -55.19708842949149\n    1=n -5.56922173547 6.62884502334E-6 -72.39988256112824\n\n    ```", "```py\n    Type a string to be classified. Empty string to quit.\n    El Jardín de senderos que se bifurcan \n    Rank Categ Score  P(Category|Input)  log2 P(Category,Input)\n    0=n -5.6612148689 0.999989087229795 -226.44859475801326\n    1=e -6.0733050528 1.091277041753E-5 -242.93220211249715\n\n    ```", "```py\nString dataPath = args.length > 0 ? args[0] : \"data/disney_e_n.csv\";\nList<String[]> annotatedData = Util.readAnnotatedCsvRemoveHeader(new File(dataPath));\nString[] categories = Util.getCategories(annotatedData);\n```", "```py\nint maxCharNGram = 3;\nDynamicLMClassifier<NGramBoundaryLM> classifier = DynamicLMClassifier.createNGramBoundary(categories,maxCharNGram);\n```", "```py\nfor (String[] row: annotatedData) {\n  String truth = row[Util.ANNOTATION_OFFSET];\n  String text = row[Util.TEXT_OFFSET];\n  Classification classification \n    = new Classification(truth);\n  Classified<CharSequence> classified = new Classified<CharSequence>(text,classification);\n  classifier.handle(classified);\n}\n```", "```py\nUtil.consoleInputPrintClassification(classifier);\n```", "```py\nClassification classification = new Classification(truth);\nClassified<CharSequence> classified = new Classified<CharSequence>(text,classification);\nclassifier.handle(classified);\n```", "```py\nint count = 1;\nclassifier.train(truth,text,count);\n```", "```py\n    java -cp lingpipe-cookbook.1.0.jar:lib/opencsv-2.4.jar:lib/lingpipe-4.1.0.jar com.lingpipe.cookbook.chapter1.RunXValidate\n\n    ```", "```py\n    Training data is: data/disney_e_n.csv\n    Training on fold 0\n    Testing on fold 0\n    Training on fold 1\n    Testing on fold 1\n    Training on fold 2\n    Testing on fold 2\n    Training on fold 3\n    Testing on fold 3\n    reference\\response\n        \\e,n,\n        e 10,1,\n        n 6,4,\n    ```", "```py\nString inputPath = args.length > 0 ? args[0] : \"data/disney_e_n.csv\";\nSystem.out.println(\"Training data is: \" + inputPath);\nList<String[]> truthData = Util.readAnnotatedCsvRemoveHeader(new File(inputPath));\n```", "```py\nint numFolds = 4;\nXValidatingObjectCorpus<Classified<CharSequence>> corpus = Util.loadXValCorpus(truthData, numFolds);\n```", "```py\npublic static XValidatingObjectCorpus<Classified<CharSequence>> loadXValCorpus(List<String[]> rows, int numFolds) throws IOException {\n  XValidatingObjectCorpus<Classified<CharSequence>> corpus = new XValidatingObjectCorpus<Classified<CharSequence>>(numFolds);\n  for (String[] row : rows) {\n    Classification classification = new Classification(row[ANNOTATION_OFFSET]);\n    Classified<CharSequence> classified = new Classified<CharSequence>(row[TEXT_OFFSET],classification);\n    corpus.handle(classified);\n  }\n  return corpus;\n}\n```", "```py\ncorpus.permuteCorpus(new Random(123413));\nString[] categories = Util.getCategories(truthData);\nboolean storeInputs = false;\nBaseClassifierEvaluator<CharSequence> evaluator = new BaseClassifierEvaluator<CharSequence>(null, categories, storeInputs);\n```", "```py\nint maxCharNGram = 3;\nfor (int i = 0; i < numFolds; ++i) {\n  corpus.setFold(i);\n  DynamicLMClassifier<NGramBoundaryLM> classifier = DynamicLMClassifier.createNGramBoundary(categories, maxCharNGram);\n  System.out.println(\"Training on fold \" + i);\n  corpus.visitTrain(classifier);\n  evaluator.setClassifier(classifier);\n  System.out.println(\"Testing on fold \" + i);\n  corpus.visitTest(evaluator);\n}\n```", "```py\nSystem.out.println(\n  Util.confusionMatrixToString(evaluator.confusionMatrix()));\n```", "```py\nSystem.out.println(\"Training on fold \" + i);\ncorpus.visitTrain(Util.corpusPrinter());\ncorpus.visitTrain(classifier);\nevaluator.setClassifier(classifier);\nSystem.out.println(\"Testing on fold \" + i);\ncorpus.visitTest(Util.corpusPrinter());\n```", "```py\nTraining on fold 0\nMalis?mos los nuevos dibujitos de disney, nickelodeon, cartoon, etc, no me gustannn:n\n@meeelp mas que venha um filhinho mais fofo que o pr?prio pai, com covinha e amando a Disney kkkkkkkkkkkkkkkkk:n\n@HedyHAMIDI au quartier pas a Disney moi:n\nI fully love the Disney Channel I do not care ?:e\n\n```", "```py\npublic static ObjectHandler<Classified<CharSequence>> corpusPrinter () {\n  return new ObjectHandler<Classified<CharSequence>>() {\n    @Override\n    public void handle(Classified<CharSequence> e) {\n      System.out.println(e.toString());\n    }\n  };\n}\n```", "```py\n    java -cp lingpipe-cookbook.1.0.jar:lib/opencsv-2.4.jar:lib/lingpipe-4.1.0.jar com.lingpipe.cookbook.chapter1.ReportFalsePositivesOverXValidation\n\n    ```", "```py\n    Training data is: data/disney_e_n.csv\n    reference\\response\n     \\e,n,\n     e 10,1,\n     n 6,4,\n    False Positives for e\n    Malisímos los nuevos dibujitos de disney, nickelodeon, cartoon, etc, no me gustannn : n\n    @meeelp mas que venha um filhinho mais fofo que o próprio pai, com covinha e amando a Disney kkkkkkkkkkkkkkkkk : n\n    @HedyHAMIDI au quartier pas a Disney moi : n\n    @greenath_ t'as de la chance d'aller a Disney putain j'y ai jamais été moi. : n\n    Prefiro gastar uma baba de dinheiro pra ir pra cancun doq pra Disney por exemplo : n\n    ES INSUPERABLE DISNEY !! QUIERO VOLVER:( : n\n    False Positives for n\n    request now \"let's get tricky\" by @bellathorne and @ROSHON on @radiodisney!!! just call 1-877-870-5678 or at http://t.co/cbne5yRKhQ!! <3 : e\n\n    ```", "```py\nboolean storeInputs = true;\nBaseClassifierEvaluator<CharSequence> evaluator = new BaseClassifierEvaluator<CharSequence>(null, categories, storeInputs);\n```", "```py\nfor (String category : categories) {\n  Util.printFalsePositives(category, evaluator, corpus);\n}\n```", "```py\npublic static <E> void printFalsePositives(String category, BaseClassifierEvaluator<E> evaluator, Corpus<ObjectHandler<Classified<E>>> corpus) throws IOException {\n  final Map<E,Classification> truthMap = new HashMap<E,Classification>();\n  corpus.visitCorpus(new ObjectHandler<Classified<E>>() {\n    @Override\n    public void handle(Classified<E> data) {\n      truthMap.put(data.getObject(),data.getClassification());\n    }\n  });\n```", "```py\nList<Classified<E>> falsePositives = evaluator.falsePositives(category);\nSystem.out.println(\"False Positives for \" + category);\nfor (Classified<E> classified : falsePositives) {\n  E data = classified.getObject();\n  Classification truthClassification = truthMap.get(data);\n  System.out.println(data + \" : \" + truthClassification.bestCategory());\n  }\n}\n```", "```py\n    java -cp lingpipe-cookbook.1.0.jar:lib/opencsv-2.4.jar:lib/lingpipe-4.1.0.jar com.lingpipe.cookbook.chapter1.TrainAndWriteClassifierToDisk\n\n    ```", "```py\n    Training on data/disney_e_n.csv\n    Wrote model to models/my_disney_e_n.LMClassifier\n\n    ```", "```py\n    java -cp lingpipe-cookbook.1.0.jar:lib/lingpipe-4.1.0.jar com.lingpipe.cookbook.chapter1.LoadClassifierRunOnCommandLine models/my_disney_e_n.LMClassifier\n\n    ```", "```py\n    Type a string to be classified. Empty string to quit.\n    The rain in Spain\n    Best Category: e \n\n    ```", "```py\nAbstractExternalizable.compileTo(classifier,outFile);\n```", "```py\nFileOutputStream fos = new FileOutputStream(outFile);\nObjectOutputStream oos = new ObjectOutputStream(fos);\nclassifier.compileTo(oos);\noos.close();\nfos.close();\n```", "```py\n@SuppressWarnings(\"unchecked\")\nLMClassifier<LanguageModel, MultivariateDistribution> compiledLM = (LMClassifier<LanguageModel, MultivariateDistribution>) AbstractExternalizable.compile(classifier);\n```", "```py\n    java -cp lingpipe-cookbook.1.0.jar:lib/opencsv-2.4.jar:lib/lingpipe-4.1.0.jar com.lingpipe.cookbook.chapter1.DeduplicateCsvData\n\n    ```", "```py\n    Tweets too close, proximity 1.00\n     @britneyspears do you ever miss the Disney days? and iilysm   please follow me. kiss from Turkey #AskBritneyJean ??\n     @britneyspears do you ever miss the Disney days? and iilysm please follow me. kiss from Turkey #AskBritneyJean ??? \n    Tweets too close, proximity 0.50\n     Sooo, I want to have a Disney Princess movie night....\n     I just want to be a Disney Princess\n\n    ```", "```py\nString inputPath = args.length > 0 ? args[0] : \"data/disney.csv\";\nString outputPath = args.length > 1 ? args[1] : \"data/disneyDeduped.csv\";  \nList<String[]> data = Util.readCsvRemoveHeader(new File(inputPath));\nSystem.out.println(data.size());\n```", "```py\nTokenizerFactory:\n```", "```py\nTokenizerFactory tokenizerFactory = new RegExTokenizerFactory(\"\\\\w+\");\n```", "```py\ndouble cutoff = .5;\nList<String[]> dedupedData = Util.filterJaccard(data, tokenizerFactory, cutoff);\nSystem.out.println(dedupedData.size());\nUtil.writeCsvAddHeader(dedupedData, new File(outputPath));\n}\n```", "```py\npublic static List<String[]> filterJaccard(List<String[]> texts, TokenizerFactory tokFactory, double cutoff) {\n  JaccardDistance jaccardD = new JaccardDistance(tokFactory);\n```", "```py\nJaccardDistance class is constructed with a tokenizer factory. The Jaccard distance divides the intersection of tokens from the two strings over the union of tokens from both strings. Look at the Javadoc for more information.\n```", "```py\nList<String[]> filteredTexts = new ArrayList<String[]>();\nfor (int i = 0; i < texts.size(); ++i) {\n  String targetText = texts.get(i)[TEXT_OFFSET];\n  boolean addText = true;\n  for (int j = i + 1; j < texts.size(); ++j ) {\n    String comparisionText = texts.get(j)[TEXT_OFFSET];\n    double proximity = jaccardD.proximity(targetText,comparisionText);\n    if (proximity >= cutoff) {\n      addText = false;\n      System.out.printf(\" Tweets too close, proximity %.2f\\n\", proximity);\n      System.out.println(\"\\t\" + targetText);\n      System.out.println(\"\\t\" + comparisionText);\n      break;\n    }\n  }\n  if (addText) {\n    filteredTexts.add(texts.get(i));\n  }\n}\nreturn filteredTexts;\n}\n```", "```py\n    java -cp lingpipe-cookbook.1.0.jar:lib/lingpipe-4.1.0.jar:lib/opencsv-2.4.jar com.lingpipe.cookbook.chapter1.RunXValidate data/disneyDedupedSentiment.csv\n\n    ```", "```py\n    Training on fold 0\n    Testing on fold 0\n    Training on fold 1\n    Testing on fold 1\n    Training on fold 2\n    Testing on fold 2\n    Training on fold 3\n    Testing on fold 3\n    reference\\response\n     \\p,n,o,\n     p 14,0,10,\n     n 6,0,4,\n     o 7,1,37,\n\n    ```"]