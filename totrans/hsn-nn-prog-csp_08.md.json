["```py\nmodel.Save(() => StreamWriter(@\"C:\\randomforest.xml\"));\n```", "```py\nvarloadedModel = RegressionForestModel.Load(() => newStreamReader(@\"C:\\randomforest.xml\"));\n```", "```py\nvarxmlSerializer = new GenericXmlDataContractSerializer();\nxmlSerializer.Serialize<IPredictorModel<double>>(model, \n () => new StreamWriter(@\"C:\\randomforest.xml\"));\nvar loadedModelXml = xmlSerializer\n.Deserialize<IPredictorModel<double>>(() => new StreamReader(@\"C:\\randomforest.xml\"));\n```", "```py\n// create learner with default parameters\nvar learner = new RegressionSquareLossGradientBoostLearner(runParallel: false);\n// learn model with found parameters\nvar model = learner.Learn(trainSet.Observations, trainSet.Targets);\n// predict the training and test set.\nvar trainPredictions = model.Predict(trainSet.Observations);\nvar testPredictions = model.Predict(testSet.Observations);\n// since this is a regression problem we are using square error as metric\n// for evaluating how well the model performs.\nvar metric = new MeanSquaredErrorRegressionMetric();\n// measure the error on the test set.\nvar testError = metric.Error(testSet.Targets, testPredictions);\n```", "```py\nvar parameters = new ParameterBounds[]\n{\n new ParameterBounds(min: 80, max: 300, \n transform: Transform.Linear, parameterType: ParameterType.Discrete), \n new ParameterBounds(min: 0.02, max: 0.2, \n transform: Transform.Logarithmic, parameterType: ParameterType.Continuous), \n new ParameterBounds(min: 8, max: 15, \n transform: Transform.Linear, parameterType: ParameterType.Discrete), \n new ParameterBounds(min: 0.5, max: 0.9, \n transform: Transform.Linear, parameterType: ParameterType.Continuous), \n new ParameterBounds(min: 1, max: numberOfFeatures, \n transform: Transform.Linear, parameterType: ParameterType.Discrete), \n};\n```", "```py\nvar validationSplit = new RandomTrainingTestIndexSplitter<double>(trainingPercentage: 0.7, seed: 24)\n.SplitSet(trainSet.Observations, trainSet.Targets);\n```", "```py\nFunc<double[], OptimizerResult> minimize = p =>\n {\n var candidateLearner = new RegressionSquareLossGradientBoostLearner(\n iterations: (int)p[0],\nlearningRate: p[1], \nmaximumTreeDepth: (int)p[2], \nsubSampleRatio: p[3], \nfeaturesPrSplit: (int)p[4],\nrunParallel: false);\n var candidateModel = candidateLearner.Learn(validationSplit.TrainingSet.Observations,\nvalidationSplit.TrainingSet.Targets);\n var validationPredictions = candidateModel.Predict(validationSplit.TestSet.Observations);\n var candidateError = metric.Error(validationSplit.TestSet.Targets, validationPredictions);\n return new OptimizerResult(p, candidateError);\n};\n```", "```py\n// create our optimizer\nvar optimizer = new RandomSearchOptimizer(parameters, iterations: 30, runParallel: true);\n// find the best hyperparameters for use\nvar result = optimizer.OptimizeBest(minimize);\nvar best = result.ParameterSet;\n```", "```py\nvar learner = new RegressionSquareLossGradientBoostLearner(\n iterations: (int)best[0],\nlearningRate: best[1], \nmaximumTreeDepth: (int)best[2], \nsubSampleRatio: best[3],\nfeaturesPrSplit: (int)best[4], \nrunParallel: false);\nvar model = learner.Learn(trainSet.Observations, trainSet.Targets);\n```", "```py\nvar parser = new CsvParser(() =>new StringReader(Resources.AptitudeData));\nvar observations = parser.EnumerateRows(v => v != \"Pass\").ToF64Matrix();\nvar targets = parser.EnumerateRows(\"Pass\").ToF64Vector();\nvar rows = targets.Length;\nvar learner = new ClassificationDecisionTreeLearner(100, 1, 2, 0.001, 42);\nvarsut = learner.Learn(observations, targets);\nvar predictions = sut.Predict(observations);\nvar evaluator = new TotalErrorClassificationMetric<double>();\nvar error = evaluator.Error(targets, predictions);\nAssert.AreEqual(0.038461538461538464, error, 0.0000001);\n```", "```py\nvar parser = new CsvParser(() =>new StringReader(Resources.AptitudeData));\nvar observations = parser.EnumerateRows(v => v != \"Pass\").ToF64Matrix();\nvar targets = parser.EnumerateRows(\"Pass\").ToF64Vector();\nvar learner = new ClassificationDecisionTreeLearner(2);\nvar sut = learner.Learn(observations, targets);\nvar writer = new StringWriter();\nsut.Save(() => writer);\n```", "```py\nvar targets = new double[] { 1.0, 2.3, 3.1, 4.4, 5.8 };\nvar predictions = new double[] { 1.0, 2.0, 3.0, 4.0, 5.0 };\nvar sut = new MeanSquaredErrorRegressionMetric();\nvar actual = sut.Error(targets, predictions);\n```", "```py\nvar targets = new double[] { 0, 1, 1 };\nvar predictions = new double[] { 0, 1, 1 };\nvar sut = new F1ScoreMetric<double>(1);\nvar actual = sut.Error(targets, predictions);\nAssert.AreEqual(0.0, actual);\n```", "```py\nvar parameters = new ParameterBounds[]\n{\nnew ParameterBounds(-10.0, 10.0, Transform.Linear),\nnew ParameterBounds(-10.0, 10.0, Transform.Linear),\nnew ParameterBounds(-10.0, 10.0, Transform.Linear),\n}; \nvar sut = new ParticleSwarmOptimizer(parameters, 100);\nvar actual = sut.OptimizeBest(Minimize);\n```", "```py\nvar parameters = new double[][] { new double[]{ 10.0, 20.0, 30.0, 35.0, 37.5, 40.0, 50.0, 60.0 } };\nvar sut = new GridSearchOptimizer(parameters);\nvar actual = sut.OptimizeBest(Minimize);\n```", "```py\nvar parameters = new ParameterBounds[] \n{\nnew ParameterBounds(0.0, 100.0, Transform.Linear)\n};\nvar sut = new RandomSearchOptimizer(parameters, 100);\nvar actual = sut.OptimizeBest(Minimize);\n```", "```py\nvar parser = new CsvParser(() =>new StringReader(Resources.Glass));\nvar observations = parser.EnumerateRows(v => v != \"Target\").ToF64Matrix();\nvar targets = parser.EnumerateRows(\"Target\").ToF64Vector();\nint trees = 1000;\nvar sut = new RegressionExtremelyRandomizedTreesLearner(trees, 1, 100, 1, 0.0001, 1.0, 42, false);\nvar indices = Enumerable.Range(0, targets.Length).ToArray();\nindices.Shuffle(new Random(42));\nindices = indices.Take((int)(targets.Length * 0.7)).ToArray();\nvar model = sut.Learn(observations, targets, indices);\nvar predictions = model.Predict(observations);\nvar evaluator = new MeanSquaredErrorRegressionMetric();\nvar error = evaluator.Error(targets, predictions);\nConsole.WriteLine(\"Error: \" + error);\n```", "```py\nvar parser = new CsvParser(() =>new StreamReader(Application.StartupPath + \"\\\\winequality-white.csv\"));\nvar targetName = \"quality\";\n// read in our feature matrix\nvar observations = parser.EnumerateRows(c => c != targetName).ToF64Matrix();\n// read in our regression targets\nvar targets = parser.EnumerateRows(targetName).ToF64Vector();\n// Since this is a regression problem, we use the random training/test set splitter. 30 % of the data is used for the test set. \nvar splitter = new RandomTrainingTestIndexSplitter<double>(trainingPercentage: 0.7, seed: 24);\nvar trainingTestSplit = splitter.SplitSet(observations, targets);\nvar trainSet = trainingTestSplit.TrainingSet;\nvar testSet = trainingTestSplit.TestSet;\nvar learner = new RegressionRandomForestLearner(trees: 100);\nvar model = learner.Learn(trainSet.Observations, trainSet.Targets);\nvar trainPredictions = model.Predict(trainSet.Observations);\nvar testPredictions = model.Predict(testSet.Observations);\n// since this is a regression problem we are using squared error as the metric\n// for evaluating how well the model performs.\nvar metric = new MeanSquaredErrorRegressionMetric();\nvar trainError = metric.Error(trainSet.Targets, trainPredictions);\nvar testError = metric.Error(testSet.Targets, testPredictions);\nTrace.WriteLine($\"Train error: {trainError:0.0000} - Test error: {testError:0.0000}\");\nSystem.Console.WriteLine($\"Train error: {trainError:0.0000} - Test error: {testError:0.0000}\");\n\n// the variable importance requires the featureNameToIndex from the dataset. \n// This mapping describes the relation from the column name to the associated \n// index in the feature matrix.\nvar featureNameToIndex = parser.EnumerateRows(c => c != targetName).First().ColumnNameToIndex;\n\nvar importances = model.GetVariableImportance(featureNameToIndex);\n\nvar importanceCsv = new StringBuilder();\nimportanceCsv.Append(\"FeatureName;Importance\");\nSystem.Console.WriteLine(\"FeatureName\\tImportance\");\nforeach (var feature in importances)\n{\nimportanceCsv.AppendLine();\nimportanceCsv.Append($\"{feature.Key};{feature.Value:0.00}\");\nSystem.Console.WriteLine($\"{feature.Key}\\t{feature.Value:0.00}\");\n}\nTrace.WriteLine(importanceCsv);\n```"]