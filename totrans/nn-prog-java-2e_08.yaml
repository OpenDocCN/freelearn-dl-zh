- en: Chapter 8. Text Recognition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We all know that humans can read and recognize images faster than any supercomputer.
    However, we have seen so far that neural networks show amazing capabilities of
    learning through data in both a supervised and an unsupervised way. In this chapter,
    we present an additional case of pattern recognition involving an example of optical
    character recognition. Neural networks can be trained to strictly recognize digits
    written in an image file. The topics of this chapter are:'
  prefs: []
  type: TYPE_NORMAL
- en: Pattern recognition
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Defined classes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Undefined classes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Neural networks in pattern recognition
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: MLP
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The OCR problem
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Preprocessing and classes definition
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementation in Java
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Digit recognition
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pattern recognition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Patterns are a bunch of data and elements that look similar to each other, in
    such a way that they can occur systematically and repeat from time to time. This
    is a task that can be solved mainly by unsupervised learning by clustering; however,
    when there is labelled data or there are defined classes of data, this task can
    be solved by supervised methods. We, as humans, perform this task more often than
    we can imagine. When we see objects and recognise them as belonging to a certain
    class, we are indeed recognising a pattern. Also, when we analyse charts, discrete
    events, and time series, we might find evidence of some sequence of events that
    repeat systematically under certain conditions. In summary, patterns can be learned
    by data observations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples of pattern recognition tasks include, but are not limited to:'
  prefs: []
  type: TYPE_NORMAL
- en: Shape recognition
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Object classification
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Behavior clustering
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Voice recognition
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: OCR
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chemical reaction taxonomy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Defined classes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In a list of classes that has been predefined for a specific domain, each class
    is considered to be a pattern; therefore every data record or occurrence is assigned
    one of these predefined classes.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The predefinition of classes can usually be performed by an expert or based
    on previous knowledge of the application domain. Also, it is desirable to apply
    defined classes when we want the data to be classified strictly into one of the
    predefined classes.
  prefs: []
  type: TYPE_NORMAL
- en: 'One illustrated example of pattern recognition using defined classes is animal
    recognition by image, shown in the figure below. The pattern recogniser, however,
    should be trained to catch all the characteristics that formally define the classes.
    In the example, eight figures of animals are shown, belonging to two classes:
    mammals and birds. Since this is a supervised mode of learning, the neural network
    should be provided with a sufficient number of images to allow it to properly
    classify new images.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Defined classes](img/B04971_08_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Of course, sometimes the classification may fail, mainly due to similar hidden
    patterns in the images that neural networks may catch and also due to small nuances
    present in the shapes. For example, the dolphin has flippers but it is still a
    mammal. Sometimes, in order to obtain a more accurate classification, it is necessary
    to apply preprocessing and ensure that the neural network will receive the appropriate
    data that will allow for classification.
  prefs: []
  type: TYPE_NORMAL
- en: Undefined classes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When data is unlabelled and there is no predefined set of classes, it is an
    unsupervised learning scenario. Shape recognition is a good example, since the
    shapes may be flexible and have an infinite number of edges, vertices, or bindings.
  prefs: []
  type: TYPE_NORMAL
- en: '![Undefined classes](img/B04971_08_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In the image above, we can see some sorts of shapes and we want to arrange them,
    so that similar ones can be grouped into the same cluster. Based on the shape
    information that is present in the images, it is likely that the pattern recognizer
    will classify the rectangle, the square and the, triangle into the same group.
    However, if the information were presented to the pattern recognizer, not as an
    image, but as a graph with edges and vertices coordinates, the classification
    might change a little.
  prefs: []
  type: TYPE_NORMAL
- en: In summary, the pattern recognition task may use both supervised and unsupervised
    modes of learning, basically depending of the objective of recognition.
  prefs: []
  type: TYPE_NORMAL
- en: Neural networks in pattern recognition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For pattern recognition, the neural network architectures that can be applied
    are MLPs (supervised) and the Kohonen Network (unsupervised). In the first case,
    the problem should be set up as a classification problem, that is, the data should
    be transformed into the *X-Y* dataset, where for every data record in *X* there
    should be a corresponding class in *Y*. As stated in [Chapter 3](ch03.xhtml "Chapter 3. Perceptrons
    and Supervised Learning"), *Perceptrons and Supervised Learning* and [Chapter
    6](ch06.xhtml "Chapter 6. Classifying Disease Diagnosis"), *Classifying Disease
    Diagnosis* the output of the neural network for classification problems should
    have all of the possible classes, and this may require preprocessing of the output
    records.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the other case, unsupervised learning, there is no need to apply labels
    to the output, but the input data should be properly structured. To remind you,
    the schema of both neural networks are shown in the next figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Neural networks in pattern recognition](img/B04971_08_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Data pre-processing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As previously seen in [Chapter 6](ch06.xhtml "Chapter 6. Classifying Disease
    Diagnosis"), *Classifying Disease Diagnosis* and [Chapter 7](ch07.xhtml "Chapter 7. Clustering
    Customer Profiles"), *Clustering Customer Profiles* we have to deal with all possible
    types of data, i.e., numerical (continuous and discrete) and categorical (ordinal
    or unscaled).
  prefs: []
  type: TYPE_NORMAL
- en: However, here we have the possibility of performing pattern recognition on multimedia
    content, such as images and videos. So, can multimedia could be handled? The answer
    to this question lies in the way these contents are stored in files. Images, for
    example, are written with a representation of small colored points called pixels.
    Each color can be coded in an RGB notation where the intensity of red, green,
    and blue define every color the human eye is able to see. Therefore an image of
    dimension 100x100 would have 10,000 pixels, each one having three values for red,
    green and blue, yielding a total of 30,000 points. That is the challenge for image
    processing in neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: Some methods, which we'll review in the next chapter, may reduce this huge number
    of dimensions. Afterwards an image can be treated as big matrix of numerical continuous
    values.
  prefs: []
  type: TYPE_NORMAL
- en: For simplicity, we are applying only gray-scale images with small dimensions
    in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Text recognition (optical character recognition)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Many documents are now being scanned and stored as images, making it necessary
    to convert these documents back into text, for a computer to apply edition and
    text processing. However, this feature involves a number of challenges:'
  prefs: []
  type: TYPE_NORMAL
- en: Variety of text font
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Text size
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Image noise
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Manuscripts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In spite of that, humans can easily interpret and read even texts produced in
    a bad quality image. This can be explained by the fact that humans are already
    familiar with text characters and the words in their language. Somehow the algorithm
    must become acquainted with these elements (characters, digits, signalization,
    and so on), in order to successfully recognize texts in images.
  prefs: []
  type: TYPE_NORMAL
- en: Digit recognition
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Although there are a variety of tools available on the market for OCR, it still
    remains a big challenge for an algorithm to properly recognize texts in images.
    So, we will be restricting our application to in a smaller domain, so that we'll
    face simpler problems. Therefore, in this chapter, we are going to implement a
    neural network to recognize digits from 0 to 9 represented on images. Also, the
    images will have standardized and small dimensions, for the sake of simplicity.
  prefs: []
  type: TYPE_NORMAL
- en: Digit representation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We applied the standard dimension of 10x10 (100 pixels) in gray scaled images,
    resulting in 100 values of gray scale for each image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Digit representation](img/B04971_08_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In the preceding image we have a sketch representing the digit 3 at the left
    and a corresponding matrix with gray values for the same digit, in gray scale.
  prefs: []
  type: TYPE_NORMAL
- en: We apply this preprocessing in order to represent all ten digits in this application.
  prefs: []
  type: TYPE_NORMAL
- en: Implementation in Java
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To recognize optical characters, data to train and to test neural network was
    produced by us. In this example, digits from 0 (super black) to 255 (super white)
    were considered. According to pixel disposal, two versions of each digit data
    were created: one to train and another to test. Classification techniques presented
    in [Chapter 3](ch03.xhtml "Chapter 3. Perceptrons and Supervised Learning"), *Perceptrons
    and Supervised Learning* and [Chapter 6](ch06.xhtml "Chapter 6. Classifying Disease
    Diagnosis"), *Classifying Disease Diagnosis* will be used here.'
  prefs: []
  type: TYPE_NORMAL
- en: Generating data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Numbers from zero to nine were drawn in the Microsoft Paint ®. The images have
    been converted into matrices, from which some examples are shown in the following
    image. All pixel values between zero and nine are grayscale:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Generating data](img/B04971_08_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: For each digit we generated five variations, where one is the perfect digit,
    and the others contain noise, either by the drawing, or by the image quality.
  prefs: []
  type: TYPE_NORMAL
- en: Each matrix row was merged into vectors (D[train] and D[test]) to form a pattern
    that will be used to train and test the neural network. Therefore, the input layer
    of the neural network will be composed of 101 neurons.
  prefs: []
  type: TYPE_NORMAL
- en: The output dataset was represented by ten patterns. Each one has a more expressive
    value (one) and the rest of the values are zero. Therefore, the output layer of
    the neural network will have ten neurons.
  prefs: []
  type: TYPE_NORMAL
- en: Neural architecture
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'So, in this application our neural network will have 100 inputs (for images
    that have a 10x10 pixel size) and ten outputs, the number of hidden neurons remaining
    unrestricted. We created a class called `DigitExample` in the package examples.chapter08
    to handle this application. The neural network architecture was chosen with these
    parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Neural network type**: MLP'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Training algorithm**: Backpropagation'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Number of hidden layers**: 1'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Number of neurons in the hidden layer**: 18'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Number of epochs**: 1000'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Minimum overall error**: 0.001'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Neural architecture](img/B04971_08_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Experiments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, as has been done in other cases previously presented, let''s find the
    best neural network topology training several nets. The strategy to do that is
    summarized in the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Experiment | Learning rate | Activation Functions |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| #1 | 0.3 | Hidden Layer: SIGLOG |'
  prefs: []
  type: TYPE_TB
- en: '| Output Layer: LINEAR |'
  prefs: []
  type: TYPE_TB
- en: '| #2 | 0.5 | Hidden Layer: SIGLOG |'
  prefs: []
  type: TYPE_TB
- en: '| Output Layer: LINEAR |'
  prefs: []
  type: TYPE_TB
- en: '| #3 | 0.8 | Hidden Layer: SIGLOG |'
  prefs: []
  type: TYPE_TB
- en: '| Output Layer: LINEAR |'
  prefs: []
  type: TYPE_TB
- en: '| #4 | 0.3 | Hidden Layer: HYPERTAN |'
  prefs: []
  type: TYPE_TB
- en: '| Output Layer: LINEAR |'
  prefs: []
  type: TYPE_TB
- en: '| #5 | 0.5 | Hidden Layer: SIGLOG |'
  prefs: []
  type: TYPE_TB
- en: '| Output Layer: LINEAR |'
  prefs: []
  type: TYPE_TB
- en: '| #6 | 0.8 | Hidden Layer: SIGLOG |'
  prefs: []
  type: TYPE_TB
- en: '| Output Layer: LINEAR |'
  prefs: []
  type: TYPE_TB
- en: '| #7 | 0.3 | Hidden Layer: HYPERTAN |'
  prefs: []
  type: TYPE_TB
- en: '| Output Layer: SIGLOG |'
  prefs: []
  type: TYPE_TB
- en: '| #8 | 0.5 | Hidden Layer: HYPERTAN |'
  prefs: []
  type: TYPE_TB
- en: '| Output Layer: SIGLOG |'
  prefs: []
  type: TYPE_TB
- en: '| #9 | 0.8 | Hidden Layer: HYPERTAN |'
  prefs: []
  type: TYPE_TB
- en: '| Output Layer: SIGLOG |'
  prefs: []
  type: TYPE_TB
- en: 'The following `DigitExample` class code defines how to create a neural network
    to read from digit data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Results
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'After running each experiment using the `DigitExample` class, excluding training
    and testing overall errors and the quantity of right number classifications using
    the test data (table above), it is possible observe that experiments #2 and #4
    have the lowest MSE values. The differences between these two experiments are
    learning rate and activation function used in the output layer.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Experiment | Training overall error | Testing overall error | # Right number
    classifications |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| #1 | 9.99918E-4 | 0.01221 | 2 by 10 |'
  prefs: []
  type: TYPE_TB
- en: '| **#2** | **9.99384E-4** | **0.00140** | **5 by 10** |'
  prefs: []
  type: TYPE_TB
- en: '| #3 | 9.85974E-4 | 0.00621 | 4 by 10 |'
  prefs: []
  type: TYPE_TB
- en: '| #4 | 9.83387E-4 | 0.02491 | 3 by 10 |'
  prefs: []
  type: TYPE_TB
- en: '| #5 | 9.99349E-4 | 0.00382 | 3 by 10 |'
  prefs: []
  type: TYPE_TB
- en: '| #6 | 273.70 | 319.74 | 2 by 10 |'
  prefs: []
  type: TYPE_TB
- en: '| #7 | 1.32070 | 6.35136 | 5 by 10 |'
  prefs: []
  type: TYPE_TB
- en: '| **#8** | **1.24012** | **4.87290** | **7 by 10** |'
  prefs: []
  type: TYPE_TB
- en: '| #9 | 1.51045 | 4.35602 | 3 by 10 |'
  prefs: []
  type: TYPE_TB
- en: 'The figure above shows the MSE evolution (train and test) by each epoch graphically
    by experiment #2\. It is interesting to notice the curve stabilizes near the 30th
    epoch:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Results](img/B04971_08_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The same graphic analysis was performed for experiment #8\. It is possible
    to check the MSE curve stabilizes near the 200th epoch.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Results](img/B04971_08_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'As already explained, only MSE values might not be considered to attest neural
    net quality. Accordingly, the test dataset has verified the neural network generalization
    capacity. The next table shows the comparison between real output with noise and
    the neural net estimated output of experiment #2 and #8\. It is possible to conclude
    that the neural network weights by experiment #8 can recognize seven digits patterns
    better than #2''s:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Output comparison** |'
  prefs: []
  type: TYPE_TB
- en: '| --- |'
  prefs: []
  type: TYPE_TB
- en: '| **Real output (test dataset)** | **Digit** |'
  prefs: []
  type: TYPE_TB
- en: '| 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.00.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0
    0.00.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.00.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
    0.00.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.00.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0
    0.00.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.00.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0
    0.00.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.01.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
    0.0 | 0123456789 |'
  prefs: []
  type: TYPE_TB
- en: '| **Estimated output (test dataset) – Experiment #2** | **Digit** |'
  prefs: []
  type: TYPE_TB
- en: '| 0.20 0.26 0.09 -0.09 0.39 0.24 0.35 0.30 0.24 1.020.42 -0.23 0.39 0.06 0.11
    0.16 0.43 0.25 0.17 -0.260.51 0.84 -0.17 0.02 0.16 0.27 -0.15 0.14 -0.34 -0.12-0.20
    -0.05 -0.58 0.20 -0.16 0.27 0.83 -0.56 0.42 0.350.24 0.05 0.72 -0.05 -0.25 -0.38
    -0.33 0.66 0.05 -0.630.08 0.41 -0.21 0.41 0.59 -0.12 -0.54 0.27 0.38 0.00-0.76
    -0.35 -0.09 1.25 -0.78 0.55 -0.22 0.61 0.51 0.27-0.15 0.11 0.54 -0.53 0.55 0.17
    0.09 -0.72 0.03 0.120.03 0.41 0.49 -0.44 -0.01 0.05 -0.05 -0.03 -0.32 -0.300.63
    -0.47 -0.15 0.17 0.38 -0.24 0.58 0.07 -0.16 0.54 | 0 (OK)1 (ERR)2 (ERR)3 (OK)4
    (ERR)5 (OK)6 (OK)7 (ERR)8 (ERR)9 (OK) |'
  prefs: []
  type: TYPE_TB
- en: '| **Estimated output (test dataset) – Experiment #8** | **Digit** |'
  prefs: []
  type: TYPE_TB
- en: '| 0.10 0.10 0.12 0.10 0.12 0.13 0.13 0.26 0.17 0.390.13 0.10 0.11 0.10 0.11
    0.10 0.29 0.23 0.32 0.100.26 0.38 0.10 0.10 0.12 0.10 0.10 0.17 0.10 0.100.10
    0.10 0.10 0.10 0.10 0.17 0.39 0.10 0.38 0.100.15 0.10 0.24 0.10 0.10 0.10 0.10
    0.39 0.37 0.100.20 0.12 0.10 0.10 0.37 0.10 0.10 0.10 0.17 0.120.10 0.10 0.10
    0.39 0.10 0.16 0.11 0.30 0.14 0.100.10 0.11 0.39 0.10 0.10 0.15 0.10 0.10 0.17
    0.100.10 0.25 0.34 0.10 0.10 0.10 0.10 0.10 0.10 0.100.39 0.10 0.10 0.10 0.28
    0.10 0.27 0.11 0.10 0.21 | 0 (OK)1 (OK)2 (OK)3 (ERR)4 (OK)5 (ERR)6 (OK)7 (OK)8
    (ERR)9 (OK) |'
  prefs: []
  type: TYPE_TB
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The experiments showed in this chapter have taken in consideration 10x10 pixel
    information images. We recommend that you try to use 20x20 pixel datasets to build
    a neural net able to classify digit images of this size.
  prefs: []
  type: TYPE_NORMAL
- en: You should also change the training parameters of the neural net to achieve
    better classifications.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter we've seen the power of neural networks in recognizing digits
    from 0 to 9 in images. Although the coding of the digits was very small in 10x10
    images, it was important to understand the concept in practice. Neural networks
    are capable of learning from data, and provided that real-world representations
    can be transformed into data, it is reasonable to take into account that character
    recognition can be a very good example of the application in pattern recognition.
    The application here can be extended to any type of characters, under the condition
    that the neural network should all be presented with the predefined characters.
  prefs: []
  type: TYPE_NORMAL
