- en: Chapter 8. Text Recognition
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第8章 文本识别
- en: 'We all know that humans can read and recognize images faster than any supercomputer.
    However, we have seen so far that neural networks show amazing capabilities of
    learning through data in both a supervised and an unsupervised way. In this chapter,
    we present an additional case of pattern recognition involving an example of optical
    character recognition. Neural networks can be trained to strictly recognize digits
    written in an image file. The topics of this chapter are:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 我们都知道人类阅读和识别图像的速度比任何超级计算机都快。然而，到目前为止，我们已经看到神经网络在监督学习和非监督学习两种方式下都表现出惊人的学习能力。在本章中，我们提出了一个涉及光学字符识别示例的额外模式识别案例。神经网络可以被训练来严格识别图像文件中写下的数字。本章的主题包括：
- en: Pattern recognition
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模式识别
- en: Defined classes
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义好的类
- en: Undefined classes
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 未定义的类
- en: Neural networks in pattern recognition
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模式识别中的神经网络
- en: MLP
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MLP
- en: The OCR problem
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OCR问题
- en: Preprocessing and classes definition
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预处理和类定义
- en: Implementation in Java
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Java实现
- en: Digit recognition
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数字识别
- en: Pattern recognition
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模式识别
- en: Patterns are a bunch of data and elements that look similar to each other, in
    such a way that they can occur systematically and repeat from time to time. This
    is a task that can be solved mainly by unsupervised learning by clustering; however,
    when there is labelled data or there are defined classes of data, this task can
    be solved by supervised methods. We, as humans, perform this task more often than
    we can imagine. When we see objects and recognise them as belonging to a certain
    class, we are indeed recognising a pattern. Also, when we analyse charts, discrete
    events, and time series, we might find evidence of some sequence of events that
    repeat systematically under certain conditions. In summary, patterns can be learned
    by data observations.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 模式是一组看起来彼此相似的数据和元素，它们可以系统地发生并时不时地重复。这是一个可以通过聚类进行无监督学习解决的问题；然而，当存在标记数据或数据有定义好的类别时，这个问题可以通过监督方法解决。我们作为人类，比我们想象的更经常地执行这个任务。当我们看到物体并将它们识别为属于某个类别时，我们实际上是在识别一个模式。此外，当我们分析图表、离散事件和时间序列时，我们可能会发现某些事件序列在特定条件下系统性地重复的证据。总之，模式可以通过数据观察来学习。
- en: 'Examples of pattern recognition tasks include, but are not limited to:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 模式识别任务的例子包括但不限于：
- en: Shape recognition
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 形状识别
- en: Object classification
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 物体分类
- en: Behavior clustering
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 行为聚类
- en: Voice recognition
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语音识别
- en: OCR
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OCR
- en: Chemical reaction taxonomy
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 化学反应分类法
- en: Defined classes
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义好的类
- en: In a list of classes that has been predefined for a specific domain, each class
    is considered to be a pattern; therefore every data record or occurrence is assigned
    one of these predefined classes.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个为特定领域预定义的类列表中，每个类都被视为一个模式；因此，每个数据记录或发生的事件都被分配了这些预定义类中的一个。
- en: Tip
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: The predefinition of classes can usually be performed by an expert or based
    on previous knowledge of the application domain. Also, it is desirable to apply
    defined classes when we want the data to be classified strictly into one of the
    predefined classes.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 类的预定义通常可以由专家执行或基于应用领域的先前知识。此外，当我们希望数据严格分类到预定义的类别之一时，我们希望应用定义好的类。
- en: 'One illustrated example of pattern recognition using defined classes is animal
    recognition by image, shown in the figure below. The pattern recogniser, however,
    should be trained to catch all the characteristics that formally define the classes.
    In the example, eight figures of animals are shown, belonging to two classes:
    mammals and birds. Since this is a supervised mode of learning, the neural network
    should be provided with a sufficient number of images to allow it to properly
    classify new images.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 一个使用定义好的类的模式识别示例是图像中的动物识别，如图下所示。然而，模式识别器应该被训练来捕捉所有正式定义类的特征。在示例中，展示了八种动物图像，属于两个类别：哺乳动物和鸟类。由于这是一个监督学习模式，神经网络应该提供足够多的图像，以便它能够正确地分类新的图像。
- en: '![Defined classes](img/B04971_08_01.jpg)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![定义好的类](img/B04971_08_01.jpg)'
- en: Of course, sometimes the classification may fail, mainly due to similar hidden
    patterns in the images that neural networks may catch and also due to small nuances
    present in the shapes. For example, the dolphin has flippers but it is still a
    mammal. Sometimes, in order to obtain a more accurate classification, it is necessary
    to apply preprocessing and ensure that the neural network will receive the appropriate
    data that will allow for classification.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，有时分类可能会失败，主要是因为图像中可能被神经网络捕捉到的相似隐藏模式，以及形状中存在的小细节。例如，海豚有鳍，但它仍然是一种哺乳动物。有时，为了获得更准确的分类，有必要应用预处理并确保神经网络将接收允许进行分类的适当数据。
- en: Undefined classes
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 未定义的类
- en: When data is unlabelled and there is no predefined set of classes, it is an
    unsupervised learning scenario. Shape recognition is a good example, since the
    shapes may be flexible and have an infinite number of edges, vertices, or bindings.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据未标记且没有预定义的类别集时，这是一个无监督学习场景。形状识别是一个很好的例子，因为形状可能是灵活的，并且具有无限数量的边、顶点或绑定。
- en: '![Undefined classes](img/B04971_08_02.jpg)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![未定义的类](img/B04971_08_02.jpg)'
- en: In the image above, we can see some sorts of shapes and we want to arrange them,
    so that similar ones can be grouped into the same cluster. Based on the shape
    information that is present in the images, it is likely that the pattern recognizer
    will classify the rectangle, the square and the, triangle into the same group.
    However, if the information were presented to the pattern recognizer, not as an
    image, but as a graph with edges and vertices coordinates, the classification
    might change a little.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的图像中，我们可以看到一些形状，我们想要将它们排列，以便相似的形状可以分组到同一个簇中。基于图像中存在的形状信息，模式识别器很可能会将矩形、正方形和三角形分类到同一个组。然而，如果信息以图形的形式呈现给模式识别器，而不是图像，而是带有边和顶点坐标的图形，分类可能会略有变化。
- en: In summary, the pattern recognition task may use both supervised and unsupervised
    modes of learning, basically depending of the objective of recognition.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，模式识别任务可能使用监督学习和无监督学习模式，这基本上取决于识别的目标。
- en: Neural networks in pattern recognition
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模式识别中的神经网络
- en: For pattern recognition, the neural network architectures that can be applied
    are MLPs (supervised) and the Kohonen Network (unsupervised). In the first case,
    the problem should be set up as a classification problem, that is, the data should
    be transformed into the *X-Y* dataset, where for every data record in *X* there
    should be a corresponding class in *Y*. As stated in [Chapter 3](ch03.xhtml "Chapter 3. Perceptrons
    and Supervised Learning"), *Perceptrons and Supervised Learning* and [Chapter
    6](ch06.xhtml "Chapter 6. Classifying Disease Diagnosis"), *Classifying Disease
    Diagnosis* the output of the neural network for classification problems should
    have all of the possible classes, and this may require preprocessing of the output
    records.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 对于模式识别，可以应用的神经网络架构有MLPs（监督学习）和Kohonen网络（无监督学习）。在第一种情况下，问题应设置为一个分类问题，即数据应转换为*X-Y*数据集，其中对于*X*中的每个数据记录，在*Y*中应有相应的类别。如[第3章](ch03.xhtml
    "第3章。感知器和监督学习")中所述，*感知器和监督学习*和[第6章](ch06.xhtml "第6章。疾病诊断分类")中所述，*疾病诊断分类*，对于分类问题，神经网络的输出应包含所有可能的类别，这可能需要预处理输出记录。
- en: 'For the other case, unsupervised learning, there is no need to apply labels
    to the output, but the input data should be properly structured. To remind you,
    the schema of both neural networks are shown in the next figure:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 对于其他情况，无监督学习，不需要对输出应用标签，但输入数据应该适当结构化。为了提醒您，以下图中展示了两种神经网络的架构：
- en: '![Neural networks in pattern recognition](img/B04971_08_03.jpg)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![模式识别中的神经网络](img/B04971_08_03.jpg)'
- en: Data pre-processing
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据预处理
- en: As previously seen in [Chapter 6](ch06.xhtml "Chapter 6. Classifying Disease
    Diagnosis"), *Classifying Disease Diagnosis* and [Chapter 7](ch07.xhtml "Chapter 7. Clustering
    Customer Profiles"), *Clustering Customer Profiles* we have to deal with all possible
    types of data, i.e., numerical (continuous and discrete) and categorical (ordinal
    or unscaled).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，在[第6章](ch06.xhtml "第6章。疾病诊断分类")中，*疾病诊断分类*和[第7章](ch07.xhtml "第7章。客户档案聚类")中，*客户档案聚类*，我们必须处理所有可能类型的数据，即数值（连续和离散）和分类（有序或未缩放的）。
- en: However, here we have the possibility of performing pattern recognition on multimedia
    content, such as images and videos. So, can multimedia could be handled? The answer
    to this question lies in the way these contents are stored in files. Images, for
    example, are written with a representation of small colored points called pixels.
    Each color can be coded in an RGB notation where the intensity of red, green,
    and blue define every color the human eye is able to see. Therefore an image of
    dimension 100x100 would have 10,000 pixels, each one having three values for red,
    green and blue, yielding a total of 30,000 points. That is the challenge for image
    processing in neural networks.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在这里我们有在多媒体内容上执行模式识别的可能性，例如图像和视频。那么，多媒体能否被处理？这个问题的答案在于这些内容在文件中的存储方式。例如，图像是用称为像素的小彩色点表示的。每种颜色都可以用RGB表示法编码，其中红色、绿色和蓝色的强度定义了人眼能看到的所有颜色。因此，一个100x100像素的图像将会有10,000个像素，每个像素有红色、绿色和蓝色的三个值，总共30,000个点。这就是神经网络中图像处理的挑战。
- en: Some methods, which we'll review in the next chapter, may reduce this huge number
    of dimensions. Afterwards an image can be treated as big matrix of numerical continuous
    values.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 一些方法，我们将在下一章中回顾，可以减少这个巨大的维度数。之后，图像可以被视为一个由数值连续值组成的大矩阵。
- en: For simplicity, we are applying only gray-scale images with small dimensions
    in this chapter.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化，我们将在本章中仅应用小尺寸的灰度图像。
- en: Text recognition (optical character recognition)
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 文本识别（光学字符识别）
- en: 'Many documents are now being scanned and stored as images, making it necessary
    to convert these documents back into text, for a computer to apply edition and
    text processing. However, this feature involves a number of challenges:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 许多文档现在正被扫描并存储为图像，这使得将文档转换回文本成为必要，以便计算机应用编辑和文本处理。然而，这一功能涉及许多挑战：
- en: Variety of text font
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文本字体的多样性
- en: Text size
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文本大小
- en: Image noise
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像噪声
- en: Manuscripts
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 手稿
- en: In spite of that, humans can easily interpret and read even texts produced in
    a bad quality image. This can be explained by the fact that humans are already
    familiar with text characters and the words in their language. Somehow the algorithm
    must become acquainted with these elements (characters, digits, signalization,
    and so on), in order to successfully recognize texts in images.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，人类可以轻松地解释和阅读即使在质量较差的图像中产生的文本。这可以解释为人类已经熟悉文本字符和他们的语言中的单词。某种方式，算法必须熟悉这些元素（字符、数字、信号等），以便在图像中成功识别文本。
- en: Digit recognition
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数字识别
- en: Although there are a variety of tools available on the market for OCR, it still
    remains a big challenge for an algorithm to properly recognize texts in images.
    So, we will be restricting our application to in a smaller domain, so that we'll
    face simpler problems. Therefore, in this chapter, we are going to implement a
    neural network to recognize digits from 0 to 9 represented on images. Also, the
    images will have standardized and small dimensions, for the sake of simplicity.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管市场上有很多OCR工具，但算法正确识别图像中的文本仍然是一个巨大的挑战。因此，我们将限制我们的应用在一个更小的领域，这样我们会面临更简单的问题。因此，在本章中，我们将实现一个神经网络来识别图像上表示的0到9的数字。此外，为了简化，图像将具有标准化的和小尺寸。
- en: Digit representation
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数字表示
- en: 'We applied the standard dimension of 10x10 (100 pixels) in gray scaled images,
    resulting in 100 values of gray scale for each image:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在灰度图像中应用了标准的10x10（100像素）尺寸，每个图像有100个灰度值：
- en: '![Digit representation](img/B04971_08_04.jpg)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![数字表示](img/B04971_08_04.jpg)'
- en: In the preceding image we have a sketch representing the digit 3 at the left
    and a corresponding matrix with gray values for the same digit, in gray scale.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的图像中，我们有一个表示左侧数字3的草图以及对应相同数字的灰度值矩阵，以灰度形式呈现。
- en: We apply this preprocessing in order to represent all ten digits in this application.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应用这种预处理是为了在这个应用中表示所有十个数字。
- en: Implementation in Java
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Java实现
- en: 'To recognize optical characters, data to train and to test neural network was
    produced by us. In this example, digits from 0 (super black) to 255 (super white)
    were considered. According to pixel disposal, two versions of each digit data
    were created: one to train and another to test. Classification techniques presented
    in [Chapter 3](ch03.xhtml "Chapter 3. Perceptrons and Supervised Learning"), *Perceptrons
    and Supervised Learning* and [Chapter 6](ch06.xhtml "Chapter 6. Classifying Disease
    Diagnosis"), *Classifying Disease Diagnosis* will be used here.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 为了识别光学字符，我们产生了用于训练和测试神经网络的训练数据。在这个例子中，考虑了从0（超级黑色）到255（超级白色）的数字。根据像素分布，为每个数字数据创建了两个版本：一个用于训练，另一个用于测试。这里将使用第3章中介绍的分类技术，*感知器和监督学习*和第6章中介绍的分类技术，*疾病诊断分类*。
- en: Generating data
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成数据
- en: 'Numbers from zero to nine were drawn in the Microsoft Paint ®. The images have
    been converted into matrices, from which some examples are shown in the following
    image. All pixel values between zero and nine are grayscale:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Microsoft Paint®绘制了从零到九的数字。这些图像已被转换为矩阵，以下图像显示了其中的一些示例。所有介于零到九之间的像素值都是灰度值：
- en: '![Generating data](img/B04971_08_05.jpg)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![生成数据](img/B04971_08_05.jpg)'
- en: For each digit we generated five variations, where one is the perfect digit,
    and the others contain noise, either by the drawing, or by the image quality.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个数字，我们生成了五个变体，其中一个是完美的数字，其余的包含噪声，无论是通过绘制还是通过图像质量。
- en: Each matrix row was merged into vectors (D[train] and D[test]) to form a pattern
    that will be used to train and test the neural network. Therefore, the input layer
    of the neural network will be composed of 101 neurons.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 将每个矩阵行合并成向量（D[train]和D[test]），形成用于训练和测试神经网络的模式。因此，神经网络的输入层将由101个神经元组成。
- en: The output dataset was represented by ten patterns. Each one has a more expressive
    value (one) and the rest of the values are zero. Therefore, the output layer of
    the neural network will have ten neurons.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 输出数据集由十个模式表示。每个模式都有一个更具有表达力的值（一个）其余的值都是零。因此，神经网络的输出层将有十个神经元。
- en: Neural architecture
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 神经网络架构
- en: 'So, in this application our neural network will have 100 inputs (for images
    that have a 10x10 pixel size) and ten outputs, the number of hidden neurons remaining
    unrestricted. We created a class called `DigitExample` in the package examples.chapter08
    to handle this application. The neural network architecture was chosen with these
    parameters:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在这个应用中，我们的神经网络将有100个输入（对于10x10像素大小的图像）和十个输出，隐藏神经元的数量不受限制。我们在包examples.chapter08中创建了一个名为`DigitExample`的类来处理这个应用。神经网络架构是根据以下参数选择的：
- en: '**Neural network type**: MLP'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**神经网络类型**：MLP'
- en: '**Training algorithm**: Backpropagation'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练算法**：反向传播'
- en: '**Number of hidden layers**: 1'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**隐藏层数量**：1'
- en: '**Number of neurons in the hidden layer**: 18'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**隐藏层中的神经元数量**：18'
- en: '**Number of epochs**: 1000'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**迭代次数**：1000'
- en: '**Minimum overall error**: 0.001'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最小总体误差**：0.001'
- en: '![Neural architecture](img/B04971_08_06.jpg)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![神经网络架构](img/B04971_08_06.jpg)'
- en: Experiments
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实验
- en: 'Now, as has been done in other cases previously presented, let''s find the
    best neural network topology training several nets. The strategy to do that is
    summarized in the following table:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，就像之前展示的其他情况一样，让我们找到最佳神经网络拓扑结构，通过训练多个网络来实现。实现这一目标的策略总结在下表中：
- en: '| Experiment | Learning rate | Activation Functions |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| 实验 | 学习率 | 激活函数 |'
- en: '| --- | --- | --- |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| #1 | 0.3 | Hidden Layer: SIGLOG |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| #1 | 0.3 | 隐藏层：SIGLOG |'
- en: '| Output Layer: LINEAR |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| 输出层：LINEAR |'
- en: '| #2 | 0.5 | Hidden Layer: SIGLOG |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| #2 | 0.5 | 隐藏层：SIGLOG |'
- en: '| Output Layer: LINEAR |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| 输出层：LINEAR |'
- en: '| #3 | 0.8 | Hidden Layer: SIGLOG |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| #3 | 0.8 | 隐藏层：SIGLOG |'
- en: '| Output Layer: LINEAR |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| 输出层：LINEAR |'
- en: '| #4 | 0.3 | Hidden Layer: HYPERTAN |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| #4 | 0.3 | 隐藏层：HYPERTAN |'
- en: '| Output Layer: LINEAR |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| 输出层：LINEAR |'
- en: '| #5 | 0.5 | Hidden Layer: SIGLOG |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| #5 | 0.5 | 隐藏层：SIGLOG |'
- en: '| Output Layer: LINEAR |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| 输出层：LINEAR |'
- en: '| #6 | 0.8 | Hidden Layer: SIGLOG |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| #6 | 0.8 | 隐藏层：SIGLOG |'
- en: '| Output Layer: LINEAR |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| 输出层：LINEAR |'
- en: '| #7 | 0.3 | Hidden Layer: HYPERTAN |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| #7 | 0.3 | 隐藏层：HYPERTAN |'
- en: '| Output Layer: SIGLOG |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| 输出层：SIGLOG |'
- en: '| #8 | 0.5 | Hidden Layer: HYPERTAN |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| #8 | 0.5 | 隐藏层：HYPERTAN |'
- en: '| Output Layer: SIGLOG |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| 输出层：SIGLOG |'
- en: '| #9 | 0.8 | Hidden Layer: HYPERTAN |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| #9 | 0.8 | 隐藏层：HYPERTAN |'
- en: '| Output Layer: SIGLOG |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| 输出层：SIGLOG |'
- en: 'The following `DigitExample` class code defines how to create a neural network
    to read from digit data:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 以下`DigitExample`类代码定义了如何创建一个从数字数据读取的神经网络：
- en: '[PRE0]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Results
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结果
- en: 'After running each experiment using the `DigitExample` class, excluding training
    and testing overall errors and the quantity of right number classifications using
    the test data (table above), it is possible observe that experiments #2 and #4
    have the lowest MSE values. The differences between these two experiments are
    learning rate and activation function used in the output layer.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '在使用`DigitExample`类运行每个实验后，除了使用测试数据（上表）排除训练和测试总体误差以及正确数字分类的数量外，可以观察到实验 #2 和
    #4 具有最低的MSE值。这两个实验之间的区别在于输出层使用的学习率和激活函数。'
- en: '| Experiment | Training overall error | Testing overall error | # Right number
    classifications |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| 实验 | 训练总体误差 | 测试总体误差 | 正确数字分类数量 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| #1 | 9.99918E-4 | 0.01221 | 2 by 10 |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| #1 | 9.99918E-4 | 0.01221 | 2 x 10 |'
- en: '| **#2** | **9.99384E-4** | **0.00140** | **5 by 10** |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| **#2** | **9.99384E-4** | **0.00140** | **5 x 10** |'
- en: '| #3 | 9.85974E-4 | 0.00621 | 4 by 10 |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| #3 | 9.85974E-4 | 0.00621 | 4 x 10 |'
- en: '| #4 | 9.83387E-4 | 0.02491 | 3 by 10 |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| #4 | 9.83387E-4 | 0.02491 | 3 x 10 |'
- en: '| #5 | 9.99349E-4 | 0.00382 | 3 by 10 |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| #5 | 9.99349E-4 | 0.00382 | 3 x 10 |'
- en: '| #6 | 273.70 | 319.74 | 2 by 10 |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| #6 | 273.70 | 319.74 | 2 x 10 |'
- en: '| #7 | 1.32070 | 6.35136 | 5 by 10 |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| #7 | 1.32070 | 6.35136 | 5 x 10 |'
- en: '| **#8** | **1.24012** | **4.87290** | **7 by 10** |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| **#8** | **1.24012** | **4.87290** | **7 x 10** |'
- en: '| #9 | 1.51045 | 4.35602 | 3 by 10 |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| #9 | 1.51045 | 4.35602 | 3 x 10 |'
- en: 'The figure above shows the MSE evolution (train and test) by each epoch graphically
    by experiment #2\. It is interesting to notice the curve stabilizes near the 30th
    epoch:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '上图显示了通过实验 #2 图形化地展示了每个epoch的均方误差（MSE）演变（训练和测试）。值得注意的是，曲线在第30个epoch附近稳定：'
- en: '![Results](img/B04971_08_07.jpg)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![结果](img/B04971_08_07.jpg)'
- en: 'The same graphic analysis was performed for experiment #8\. It is possible
    to check the MSE curve stabilizes near the 200th epoch.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '对实验 #8 也进行了相同的图形分析。可以检查到MSE曲线在第200个epoch附近稳定。'
- en: '![Results](img/B04971_08_08.jpg)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![结果](img/B04971_08_08.jpg)'
- en: 'As already explained, only MSE values might not be considered to attest neural
    net quality. Accordingly, the test dataset has verified the neural network generalization
    capacity. The next table shows the comparison between real output with noise and
    the neural net estimated output of experiment #2 and #8\. It is possible to conclude
    that the neural network weights by experiment #8 can recognize seven digits patterns
    better than #2''s:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '如前所述，仅MSE值可能不足以证明神经网络的质量。因此，测试数据集已验证了神经网络的泛化能力。下表显示了实验 #2 和 #8 的实际输出（含噪声）与神经网络估计输出的比较。可以得出结论，实验
    #8 的神经网络权重比 #2 的更能识别七个数字模式：'
- en: '| **Output comparison** |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| **输出比较** |'
- en: '| --- |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| **Real output (test dataset)** | **Digit** |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| **实际输出（测试数据集）** | **数字** |'
- en: '| 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.00.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0
    0.00.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.00.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
    0.00.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.00.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0
    0.00.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.00.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0
    0.00.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.01.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
    0.0 | 0123456789 |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0
    0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0
    0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
    0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0
    0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 | 0123456789 |'
- en: '| **Estimated output (test dataset) – Experiment #2** | **Digit** |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| **估计输出（测试数据集）- 实验 #2** | **数字** |'
- en: '| 0.20 0.26 0.09 -0.09 0.39 0.24 0.35 0.30 0.24 1.020.42 -0.23 0.39 0.06 0.11
    0.16 0.43 0.25 0.17 -0.260.51 0.84 -0.17 0.02 0.16 0.27 -0.15 0.14 -0.34 -0.12-0.20
    -0.05 -0.58 0.20 -0.16 0.27 0.83 -0.56 0.42 0.350.24 0.05 0.72 -0.05 -0.25 -0.38
    -0.33 0.66 0.05 -0.630.08 0.41 -0.21 0.41 0.59 -0.12 -0.54 0.27 0.38 0.00-0.76
    -0.35 -0.09 1.25 -0.78 0.55 -0.22 0.61 0.51 0.27-0.15 0.11 0.54 -0.53 0.55 0.17
    0.09 -0.72 0.03 0.120.03 0.41 0.49 -0.44 -0.01 0.05 -0.05 -0.03 -0.32 -0.300.63
    -0.47 -0.15 0.17 0.38 -0.24 0.58 0.07 -0.16 0.54 | 0 (OK)1 (ERR)2 (ERR)3 (OK)4
    (ERR)5 (OK)6 (OK)7 (ERR)8 (ERR)9 (OK) |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| 0.20 0.26 0.09 -0.09 0.39 0.24 0.35 0.30 0.24 1.02 0.42 -0.23 0.39 0.06 0.11
    0.16 0.43 0.25 0.17 -0.26 0.51 0.84 -0.17 0.02 0.16 0.27 -0.15 0.14 -0.34 -0.12
    -0.20 -0.05 -0.58 0.20 -0.16 0.27 0.83 -0.56 0.42 0.35 0.24 0.05 0.72 -0.05 -0.25
    -0.38 -0.33 0.66 0.05 -0.63 0.08 0.41 -0.21 0.41 0.59 -0.12 -0.54 0.27 0.38 0.00
    -0.76 -0.35 -0.09 1.25 -0.78 0.55 -0.22 0.61 0.51 0.27 -0.15 0.11 0.54 -0.53 0.55
    0.17 0.09 -0.72 0.03 0.12 0.03 0.41 0.49 -0.44 -0.01 0.05 -0.05 -0.03 -0.32 -0.30
    0.63 -0.47 -0.15 0.17 0.38 -0.24 0.58 0.07 -0.16 0.54 | 0 (OK)1 (ERR)2 (ERR)3
    (OK)4 (ERR)5 (OK)6 (OK)7 (ERR)8 (ERR)9 (OK) |'
- en: '| **Estimated output (test dataset) – Experiment #8** | **Digit** |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| **估计输出（测试数据集）- 实验 #8** | **数字** |'
- en: '| 0.10 0.10 0.12 0.10 0.12 0.13 0.13 0.26 0.17 0.390.13 0.10 0.11 0.10 0.11
    0.10 0.29 0.23 0.32 0.100.26 0.38 0.10 0.10 0.12 0.10 0.10 0.17 0.10 0.100.10
    0.10 0.10 0.10 0.10 0.17 0.39 0.10 0.38 0.100.15 0.10 0.24 0.10 0.10 0.10 0.10
    0.39 0.37 0.100.20 0.12 0.10 0.10 0.37 0.10 0.10 0.10 0.17 0.120.10 0.10 0.10
    0.39 0.10 0.16 0.11 0.30 0.14 0.100.10 0.11 0.39 0.10 0.10 0.15 0.10 0.10 0.17
    0.100.10 0.25 0.34 0.10 0.10 0.10 0.10 0.10 0.10 0.100.39 0.10 0.10 0.10 0.28
    0.10 0.27 0.11 0.10 0.21 | 0 (OK)1 (OK)2 (OK)3 (ERR)4 (OK)5 (ERR)6 (OK)7 (OK)8
    (ERR)9 (OK) |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| 0.10 0.10 0.12 0.10 0.12 0.13 0.13 0.26 0.17 0.39 0.13 0.10 0.11 0.10 0.11
    0.10 0.29 0.23 0.32 0.10 0.26 0.38 0.10 0.10 0.12 0.10 0.10 0.17 0.10 0.10 0.10
    0.10 0.17 0.39 0.10 0.38 0.10 0.15 0.10 0.24 0.10 0.10 0.10 0.10 0.39 0.37 0.10
    0.20 0.12 0.10 0.10 0.37 0.10 0.10 0.10 0.10 0.10 0.10 0.10 0.10 0.39 0.10 0.10
    0.10 0.28 0.10 0.27 0.11 0.10 0.21 | 0 (OK)1 (OK)2 (OK)3 (ERR)4 (OK)5 (ERR)6 (OK)7
    (OK)8 (ERR)9 (OK) |'
- en: Tip
  id: totrans-122
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: The experiments showed in this chapter have taken in consideration 10x10 pixel
    information images. We recommend that you try to use 20x20 pixel datasets to build
    a neural net able to classify digit images of this size.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中展示的实验已经考虑了10x10像素信息图像。我们建议你尝试使用20x20像素的数据集来构建一个能够分类这种尺寸数字图像的神经网络。
- en: You should also change the training parameters of the neural net to achieve
    better classifications.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 你还应该更改神经网络的训练参数以实现更好的分类。
- en: Summary
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter we've seen the power of neural networks in recognizing digits
    from 0 to 9 in images. Although the coding of the digits was very small in 10x10
    images, it was important to understand the concept in practice. Neural networks
    are capable of learning from data, and provided that real-world representations
    can be transformed into data, it is reasonable to take into account that character
    recognition can be a very good example of the application in pattern recognition.
    The application here can be extended to any type of characters, under the condition
    that the neural network should all be presented with the predefined characters.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们看到了神经网络在识别图像中0到9数字的强大能力。尽管在10x10的图像中数字的编码非常小，但在实践中理解这一概念是很重要的。神经网络能够从数据中学习，并且只要现实世界的表示可以转化为数据，考虑字符识别可以作为模式识别应用的一个非常好的例子是合理的。这里的应用可以扩展到任何类型的字符，前提是神经网络都应该展示预定义的字符。
