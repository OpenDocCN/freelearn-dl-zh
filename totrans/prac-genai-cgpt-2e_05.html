<html><head></head><body>
<div class="Basic-Text-Frame" id="_idContainer078">
<h1 class="chapterNumber"><span class="koboSpan" id="kobo.1.1">3</span></h1>
<h1 class="chapterTitle" id="_idParaDest-49"><span class="koboSpan" id="kobo.2.1">Understanding Prompt Engineering</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.3.1">In the previous chapters, we</span><a id="_idIndexMarker138"/><span class="koboSpan" id="kobo.4.1"> mentioned the term </span><strong class="keyWord"><span class="koboSpan" id="kobo.5.1">prompt</span></strong><span class="koboSpan" id="kobo.6.1"> several times while referring to user input in ChatGPT and </span><strong class="keyWord"><span class="koboSpan" id="kobo.7.1">large language models</span></strong><span class="koboSpan" id="kobo.8.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.9.1">LLMs</span></strong><span class="koboSpan" id="kobo.10.1">) in general.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.11.1">Since prompts have a massive impact on LLMs’ performance, prompt engineering is a crucial activity to get the most out of your GenAI tool. </span><span class="koboSpan" id="kobo.11.2">In fact, there are several techniques that can be implemented not only to refine your LLMs’ responses but also to reduce risks associated with hallucinations and biases.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.12.1">In this chapter, we are going to cover the emerging techniques in the field of prompt engineering, starting from basic approaches up to advanced frameworks. </span><span class="koboSpan" id="kobo.12.2">More specifically, we will go through the following topics:</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.13.1">What is prompt engineering?</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.14.1">Exploring zero-, one-, and few-shot learning</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.15.1">Principles of prompt engineering</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.16.1">Looking at some advanced techniques</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.17.1">Ethical considerations to avoid bias</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.18.1">By the end of this chapter, you will have the foundations to build functional and solid prompts to interact with ChatGPT and, more broadly, with GenAI applications.</span></p>
<h1 class="heading-1" id="_idParaDest-50"><span class="koboSpan" id="kobo.19.1">Technical requirements</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.20.1">You’ll need an OpenAI account. </span><span class="koboSpan" id="kobo.20.2">You can use the free ChatGPT version to run this chapter’s examples.</span></p>
<h1 class="heading-1" id="_idParaDest-51"><span class="koboSpan" id="kobo.21.1">What is prompt engineering?</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.22.1">Before explaining what prompt engineering is, let’s start by defining a prompt.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.23.1">A </span><strong class="keyWord"><span class="koboSpan" id="kobo.24.1">prompt</span></strong><span class="koboSpan" id="kobo.25.1"> is </span><a id="_idIndexMarker139"/><span class="koboSpan" id="kobo.26.1">text input that guides the behavior of an LLM to generate an output. </span><span class="koboSpan" id="kobo.26.2">For example, whenever we interact with ChatGPT, asking a question or giving an instruction, that input text is a prompt. </span><span class="koboSpan" id="kobo.26.3">In the context of LLMs and LLM-powered applications, we can distinguish two types of prompts:</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.27.1">The </span><a id="_idIndexMarker140"/><span class="koboSpan" id="kobo.28.1">first type is a prompt that the user writes and sends to the LLM. </span><span class="koboSpan" id="kobo.28.2">For example, a prompt might be “Give me the recipe for Lasagna Bolognese,” or “Generate a workout plan to run a marathon.”</span></li>
</ul>
<figure class="mediaobject"><span class="koboSpan" id="kobo.29.1"><img alt="A screenshot of a chat  Description automatically generated" src="../Images/B31559_03_01.png"/></span><span class="koboSpan" id="kobo.30.1"><img alt="" src="../Images/B31559_03_02.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.31.1">Figure 3.1: An example of a user’s prompt</span></p>
<p class="normal"><span class="koboSpan" id="kobo.32.1">You will hear this referred to simply as a </span><strong class="keyWord"><span class="koboSpan" id="kobo.33.1">prompt</span></strong><span class="koboSpan" id="kobo.34.1">, a </span><strong class="keyWord"><span class="koboSpan" id="kobo.35.1">query</span></strong><span class="koboSpan" id="kobo.36.1">, or </span><strong class="keyWord"><span class="koboSpan" id="kobo.37.1">user input</span></strong><span class="koboSpan" id="kobo.38.1">.</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.39.1">The </span><a id="_idIndexMarker141"/><span class="koboSpan" id="kobo.40.1">second type is a prompt that instructs the model to behave in a certain way regardless of the user’s query. </span><span class="koboSpan" id="kobo.40.2">This refers to the set of instructions in natural language that the model is provided with so that it behaves in a certain way when interacting with end users. </span><span class="koboSpan" id="kobo.40.3">You can think about that as a sort of “backend” of your LLM, something that will be handled by the application developers rather than the final users.</span></li>
</ul>
<figure class="mediaobject"><span class="koboSpan" id="kobo.41.1"><img alt="A screenshot of a computer  Description automatically generated" src="../Images/B31559_03_03.png"/></span><span class="koboSpan" id="kobo.42.1"><img alt="" src="../Images/B31559_03_04.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.43.1">Figure 3.2: An example of a system message</span></p>
<p class="normal"><span class="koboSpan" id="kobo.44.1">We refer to this type of prompt as a </span><strong class="keyWord"><span class="koboSpan" id="kobo.45.1">system message</span></strong><span class="koboSpan" id="kobo.46.1">.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.47.1">Prompt engineering </span><a id="_idIndexMarker142"/><span class="koboSpan" id="kobo.48.1">is the process of designing effective prompts that elicit high-quality and relevant outputs from LLMs. </span><span class="koboSpan" id="kobo.48.2">Prompt engineering requires creativity, an understanding of the LLM, and a clear understanding of the objective you want to achieve.</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.49.1"><img alt="" src="../Images/B31559_03_05.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.50.1">Figure 3.3: Example of prompt engineering to specialize LLMs</span></p>
<p class="normal"><span class="koboSpan" id="kobo.51.1">Over the last few years, prompt engineering has become a brand-new discipline in itself, and this is a demonstration of the fact that interacting with those models requires a new set of skills and capabilities that did not exist before. </span></p>
<p class="normal"><span class="koboSpan" id="kobo.52.1">The </span><em class="italic"><span class="koboSpan" id="kobo.53.1">art of prompting</span></em><span class="koboSpan" id="kobo.54.1"> has become a top skill when it comes to building GenAI applications in enterprise scenarios; however, it can also be extremely useful for individual users who use ChatGPT or similar AI assistants in daily tasks, as it dramatically improves the quality and accuracy of results.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.55.1">In the next sections, we are going to see some examples of how to build efficient, robust prompts leveraging ChatGPT.</span></p>
<h1 class="heading-1" id="_idParaDest-52"><span class="koboSpan" id="kobo.56.1">Understanding zero-, one-, and few-shot learning</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.57.1">In the previous chapters, we mentioned how LLMs typically come in a pre-trained format. </span><span class="koboSpan" id="kobo.57.2">They have been trained on a huge amount of data and have had their (billions of) parameters configured accordingly.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.58.1">However, this doesn’t mean that those LLMs can’t learn anymore. </span><span class="koboSpan" id="kobo.58.2">In </span><em class="italic"><span class="koboSpan" id="kobo.59.1">Chapter 2</span></em><span class="koboSpan" id="kobo.60.1">, we learned the concept of fine-tuning. </span><span class="koboSpan" id="kobo.60.2">In the </span><em class="italic"><span class="koboSpan" id="kobo.61.1">Appendix</span></em><span class="koboSpan" id="kobo.62.1">, too, we will see that one way to customize an OpenAI model and make it more capable of addressing specific tasks is </span><a id="_idIndexMarker143"/><span class="koboSpan" id="kobo.63.1">by </span><strong class="keyWord"><span class="koboSpan" id="kobo.64.1">fine-tuning</span></strong><span class="koboSpan" id="kobo.65.1">.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.66.1">Fine-tuning is a proper training process that requires a training dataset, compute power, and some training time (depending on the amount of data and compute instances).</span></p>
<p class="normal"><span class="koboSpan" id="kobo.67.1">That is why it is worth testing another method for our LLMs to become more skilled in specific </span><a id="_idIndexMarker144"/><span class="koboSpan" id="kobo.68.1">tasks: </span><strong class="keyWord"><span class="koboSpan" id="kobo.69.1">shot learning.</span></strong></p>
<div class="note">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.70.1">Definition</span></strong></p>
<p class="normal"><span class="koboSpan" id="kobo.71.1">In the context of LLMs, </span><strong class="keyWord"><span class="koboSpan" id="kobo.72.1">shot learning</span></strong><span class="koboSpan" id="kobo.73.1"> refers to</span><a id="_idIndexMarker145"/><span class="koboSpan" id="kobo.74.1"> the model’s ability to perform tasks with varying amounts of task-specific examples provided during inference. </span><span class="koboSpan" id="kobo.74.2">These shot-learning paradigms enable LLMs to adapt to new tasks with minimal to no additional training, enhancing their versatility and efficiency in natural language processing applications.</span></p>
</div>
<p class="normal"><span class="koboSpan" id="kobo.75.1">The idea is to let the model learn from simple examples rather than the entire dataset. </span><span class="koboSpan" id="kobo.75.2">Those examples are samples of the way we would like the model to respond so that the model not only learns the content but also the format, style, and taxonomy to use in its response.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.76.1">Furthermore, shot learning occurs directly via the prompt (as we will see in the following scenarios), so the whole experience is less time-consuming and easier to perform.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.77.1">The number of examples provided determines the level of shot learning we are referring to. </span><span class="koboSpan" id="kobo.77.2">In other words, we refer to zero-shot if no example is provided, one-shot if one example is provided, and few-shot if more than two examples are provided.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.78.1">Let’s focus on each of those scenarios.</span></p>
<h2 class="heading-2" id="_idParaDest-53"><span class="koboSpan" id="kobo.79.1">Zero-shot learning</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.80.1">In this </span><a id="_idIndexMarker146"/><span class="koboSpan" id="kobo.81.1">type of learning, the model is asked to perform a task for which it </span><a id="_idIndexMarker147"/><span class="koboSpan" id="kobo.82.1">has not seen any training examples. </span><span class="koboSpan" id="kobo.82.2">The model must rely on prior knowledge or general information about the task to complete it. </span><span class="koboSpan" id="kobo.82.3">For example, a zero-shot-learning approach could be that of asking the model to generate a description, as defined in my prompt:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.83.1"><img alt="" src="../Images/B31559_03_06.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.84.1">Figure 3.4: Example of zero-shot learning</span></p>
<h2 class="heading-2" id="_idParaDest-54"><span class="koboSpan" id="kobo.85.1">One-shot learning</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.86.1">In this type of</span><a id="_idIndexMarker148"/><span class="koboSpan" id="kobo.87.1"> learning, the model is given a single example of each new task it is asked to </span><a id="_idIndexMarker149"/><span class="koboSpan" id="kobo.88.1">perform. </span><span class="koboSpan" id="kobo.88.2">The model must use its prior knowledge to generalize from this single example to perform the task. </span><span class="koboSpan" id="kobo.88.3">If we consider the preceding example, I could provide my model with a prompt-completion example before asking it to generate a new one:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.89.1"><img alt="" src="../Images/B31559_03_07.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.90.1">Figure 3.5: Example of one-shot learning</span></p>
<p class="normal"><span class="koboSpan" id="kobo.91.1">As you can see</span><a id="_idIndexMarker150"/><span class="koboSpan" id="kobo.92.1"> from the previous screenshot, the model was able to generate an answer that mirrors</span><a id="_idIndexMarker151"/><span class="koboSpan" id="kobo.93.1"> the style and template of the example provided. </span><span class="koboSpan" id="kobo.93.2">The same reasoning applies when we provide multiple examples, as described in the next section.</span></p>
<h2 class="heading-2" id="_idParaDest-55"><span class="koboSpan" id="kobo.94.1">Few-shot learning</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.95.1">In this type of learning, the</span><a id="_idIndexMarker152"/><span class="koboSpan" id="kobo.96.1"> model is given a small number of </span><a id="_idIndexMarker153"/><span class="koboSpan" id="kobo.97.1">examples (typically between 2 and 5) of each new task it is asked to perform. </span><span class="koboSpan" id="kobo.97.2">The model must use its prior knowledge to generalize from these examples to perform the task. </span><span class="koboSpan" id="kobo.97.3">Let’s continue with our example and provide the model with further examples:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.98.1"><img alt="" src="../Images/B31559_03_08.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.99.1">Figure 3.6: Example of few-shot learning with three examples</span></p>
<p class="normal"><span class="koboSpan" id="kobo.100.1">As mentioned </span><a id="_idIndexMarker154"/><span class="koboSpan" id="kobo.101.1">previously, it is important to remember that these forms of learning are different from traditional supervised learning, as well as fine-tuning. </span><span class="koboSpan" id="kobo.101.2">In few-shot learning, the goal is to enable the model to learn from very few examples, and to generalize from those examples to new tasks. </span><span class="koboSpan" id="kobo.101.3">Plus, we are not modifying the architecture and knowledge of the model itself, meaning that the</span><a id="_idIndexMarker155"/><span class="koboSpan" id="kobo.102.1"> moment the user starts a new conversation, and the previous prompt is out of the context window, the model will “forget” about it.</span></p>
<div class="note">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.103.1">Definition</span></strong></p>
<p class="normal"><span class="koboSpan" id="kobo.104.1">Supervised learning</span><a id="_idIndexMarker156"/><span class="koboSpan" id="kobo.105.1"> is a type of machine learning where a model is trained on a labeled dataset, meaning the input data is paired with corresponding correct outputs (labels). </span><span class="koboSpan" id="kobo.105.2">The goal is for the model to learn the relationship between inputs and outputs so it can accurately predict the output for new, unseen data.</span></p>
</div>
<p class="normal"><span class="koboSpan" id="kobo.106.1">Now that we’ve learned how to let OpenAI models learn from examples, let’s focus on how to properly define our prompt to make the model’s response as accurate as possible.</span></p>
<h1 class="heading-1" id="_idParaDest-56"><span class="koboSpan" id="kobo.107.1">Principles of prompt engineering</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.108.1">Traditionally, in the context of </span><a id="_idIndexMarker157"/><span class="koboSpan" id="kobo.109.1">computing and data processing, the expression </span><em class="italic"><span class="koboSpan" id="kobo.110.1">garbage in, garbage out </span></em><span class="koboSpan" id="kobo.111.1">has been used, meaning that the quality of output is determined by the quality of the input. </span><span class="koboSpan" id="kobo.111.2">If incorrect or poor-quality input (garbage) is entered into a system, the output will also be flawed or nonsensical (garbage).</span></p>
<p class="normal"><span class="koboSpan" id="kobo.112.1">When it comes to prompting, the story is similar: if we want accurate and relevant results from our LLMs, we need to provide high-quality input. </span><span class="koboSpan" id="kobo.112.2">However, building good prompts is not just about the quality of the response. </span><span class="koboSpan" id="kobo.112.3">In fact, we can construct good prompts to:</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.113.1">Maximize the relevancy of an LLM’s responses.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.114.1">Specify the type formatting and style of responses.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.115.1">Provide conversational context.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.116.1">Reduce inner LLMs’ biases and improve fairness and inclusivity.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.117.1">Reduce hallucination.</span><div class="note">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.118.1">Definition</span></strong></p>
<p class="normal"><span class="koboSpan" id="kobo.119.1">In the context of LLMs, </span><strong class="keyWord"><span class="koboSpan" id="kobo.120.1">hallucination</span></strong><span class="koboSpan" id="kobo.121.1"> refers </span><a id="_idIndexMarker158"/><span class="koboSpan" id="kobo.122.1">to the generation of text or responses that are factually incorrect, nonsensical, or not grounded in the training data. </span><span class="koboSpan" id="kobo.122.2">This occurs when an LLM produces confident-sounding but erroneous or fabricated information. </span><span class="koboSpan" id="kobo.122.3">For example, a user could ask an LLM: </span><em class="italic"><span class="koboSpan" id="kobo.123.1">“Who is the author of the book Invisible Cities?”</span></em><span class="koboSpan" id="kobo.124.1"> If the model responds with something like: </span><em class="italic"><span class="koboSpan" id="kobo.125.1">“Invisible Cities was written by Gabriel García Márquez.”,</span></em><span class="koboSpan" id="kobo.126.1"> this is a hallucination because the correct author is </span><em class="italic"><span class="koboSpan" id="kobo.127.1">Italo Calvino</span></em><span class="koboSpan" id="kobo.128.1">. </span><span class="koboSpan" id="kobo.128.2">The model generated an answer that sounds plausible but is factually incorrect.</span></p>
</div>
</li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.129.1">Let’s see some basic prompt engineering techniques in the following sections to achieve these results.</span></p>
<h2 class="heading-2" id="_idParaDest-57"><span class="koboSpan" id="kobo.130.1">Clear instructions</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.131.1">The principle of giving</span><a id="_idIndexMarker159"/><span class="koboSpan" id="kobo.132.1"> clear instructions is to provide the model with enough information and guidance to perform the task correctly and efficiently. </span><span class="koboSpan" id="kobo.132.2">Clear instructions should include the following elements:</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.133.1">The goal or objective of the task, such as “write a poem” or “summarize an article.”</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.134.1">The format or structure of the expected output, such as “use four lines with rhyming words” or “use bullet points with no more than 10 words each.”</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.135.1">The constraints or limitations of the task, such as “do not use any profanity” or “do not copy any text from the source.”</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.136.1">The context or background of the task, such as “the poem is about autumn” or “the article is from a scientific journal.”</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.137.1">Let’s say, for example, that we want our model to fetch any kind of instructions from text and return to us a tutorial in a bullet list. </span><span class="koboSpan" id="kobo.137.2">If there are no instructions in the provided text, the model should inform us about that. </span><span class="koboSpan" id="kobo.137.3">Let’s see an example in ChatGPT:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.138.1"><img alt="" src="../Images/B31559_03_09.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.139.1">Figure 3.7: Example of clear instructions in ChatGPT</span></p>
<p class="normal"><span class="koboSpan" id="kobo.140.1">Note that, if we pass the </span><a id="_idIndexMarker160"/><span class="koboSpan" id="kobo.141.1">model other text that does not contain any instructions, it will be able to respond as we instructed it:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.142.1"><img alt="" src="../Images/B31559_03_10.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.143.1">Figure 3.8: Example of chat model following instructions</span></p>
<div class="note">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.144.1">Note</span></strong></p>
<p class="normal"><span class="koboSpan" id="kobo.145.1">In the previous figure, we saw ChatGPT keeping in mind the instructions we prompted it with at the beginning of the conversation. </span><span class="koboSpan" id="kobo.145.2">This happens because ChatGPT has a so-called context window, which is equal to a single chat: everything we input in the chat session will be part of ChatGPT’s context and henceforth part of its knowledge; the moment we start a new session from scratch, ChatGPT will not remember any previous instructions.</span></p>
</div>
<p class="normal"><span class="koboSpan" id="kobo.146.1">By giving clear instructions, you </span><a id="_idIndexMarker161"/><span class="koboSpan" id="kobo.147.1">can help the model understand what you want it to do and how you want it to do it. </span><span class="koboSpan" id="kobo.147.2">This can improve the quality and relevance of the model’s output, and reduce the need for further revisions or corrections.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.148.1">However, sometimes there are scenarios where clarity is not enough. </span><span class="koboSpan" id="kobo.148.2">We might need to infer the way of thinking of our LLM to make it more robust with respect to its task. </span><span class="koboSpan" id="kobo.148.3">In the next subsection, we are going to examine a technique to do this – one that is very useful in cases of solving complex tasks.</span></p>
<h2 class="heading-2" id="_idParaDest-58"><span class="koboSpan" id="kobo.149.1">Split complex tasks into subtasks</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.150.1">When we interact with </span><a id="_idIndexMarker162"/><span class="koboSpan" id="kobo.151.1">LLMs to let them solve some tasks, sometimes those tasks are too complex or ambiguous for a single prompt to handle, and it is better to split them into simpler subtasks that can be solved by different prompts.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.152.1">Here are some examples of splitting complex tasks into subtasks:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.153.1">Text summarization</span></strong><span class="koboSpan" id="kobo.154.1">: A </span><a id="_idIndexMarker163"/><span class="koboSpan" id="kobo.155.1">complex task that involves generating a concise and accurate summary of a long text. </span><span class="koboSpan" id="kobo.155.2">This task can be split into subtasks such as:</span><ul>
<li class="bulletList"><span class="koboSpan" id="kobo.156.1">Extracting the main points or keywords from the text.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.157.1">Rewriting the main points or keywords in a coherent way.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.158.1">Trimming the</span><a id="_idIndexMarker164"/><span class="koboSpan" id="kobo.159.1"> summary to fit a desired length or format.</span></li>
</ul>
</li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.160.1">Poem generation</span></strong><span class="koboSpan" id="kobo.161.1">: A </span><a id="_idIndexMarker165"/><span class="koboSpan" id="kobo.162.1">creative task that involves producing a poem that follows a certain style, theme, or mood. </span><span class="koboSpan" id="kobo.162.2">This</span><a id="_idIndexMarker166"/><span class="koboSpan" id="kobo.163.1"> task can be split into subtasks such as:</span><ul>
<li class="bulletList"><span class="koboSpan" id="kobo.164.1">Choosing a poetic form (such as sonnet, haiku, limerick, etc.) and a rhyme scheme (such as ABAB, AABB, ABCB, etc.) for the poem.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.165.1">Generating a title and a topic for the poem based on the user’s input or preference.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.166.1">Generating the lines or verses of the poem that match the chosen form, rhyme scheme, and topic.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.167.1">Refining and polishing the poem to ensure coherence, fluency, and originality.</span></li>
</ul>
</li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.168.1">Code generation</span></strong><span class="koboSpan" id="kobo.169.1">: A technical</span><a id="_idIndexMarker167"/><span class="koboSpan" id="kobo.170.1"> task that involves producing working code for a video game. </span><span class="koboSpan" id="kobo.170.2">This task can be split into subtasks such as:</span><ul>
<li class="bulletList"><span class="koboSpan" id="kobo.171.1">Create basic movements and integrate their logic into the game engine’s loop.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.172.1">Add advanced movement features like printing or jumping logic with gravity.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.173.1">Ensure physics and collision handling are enabled.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.174.1">Enable debugging and optimization by generating testing procedures.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.175.1">Generate documentation for future reference.</span></li>
</ul>
</li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.176.1">Let’s consider the following example. </span><span class="koboSpan" id="kobo.176.2">We will provide the model with a short article and ask it to summarize it following these instructions:</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.177.1">You are an AI assistant that summarizes articles.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.178.1">To complete this task, do the following subtasks:</span><ul>
<li class="bulletList"><span class="koboSpan" id="kobo.179.1">Read the provided article context comprehensively and identify the main topic and key points.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.180.1">Generate a paragraph summary of the current article context that captures the essential information and conveys the main idea.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.181.1">Print each step of the process.</span></li>
</ul>
</li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.182.1">This is the short article we will provide:</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.183.1">Large Language Models (LLMs), a subset of artificial intelligence, have revolutionized the field of natural language processing by demonstrating an unprecedented ability to understand and generate human-like text. </span><span class="koboSpan" id="kobo.183.2">These models are trained on vast datasets comprising diverse linguistic inputs, enabling them to produce coherent and contextually relevant responses across a wide range of topics. </span><span class="koboSpan" id="kobo.183.3">By leveraging architectures such as transformers, LLMs like GPT-3 and its successors can complete text, answer questions, perform translations, and even engage in complex dialogue. </span><span class="koboSpan" id="kobo.183.4">Their applications span from automated customer support and content creation to advanced research and education tools. </span><span class="koboSpan" id="kobo.183.5">Despite their incredible capabilities, LLMs also pose challenges, including the potential for biases inherent in training data and the risk of generating misleading or false information. </span><span class="koboSpan" id="kobo.183.6">As the development of LLMs continues to advance, ongoing efforts in ethical AI research and deployment strategies are crucial to harness their benefits responsibly and effectively.
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.184.1">Let’s see </span><a id="_idIndexMarker168"/><span class="koboSpan" id="kobo.185.1">how the model works:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.186.1"><img alt="" src="../Images/B31559_03_11.png"/></span></figure>
<figure class="mediaobject"><span class="koboSpan" id="kobo.187.1">Figure 3.9: Example of OpenAI GPT-4o splitting a task into subtasks to generate a summary</span></figure>
<p class="normal"><span class="koboSpan" id="kobo.188.1">Splitting </span><a id="_idIndexMarker169"/><span class="koboSpan" id="kobo.189.1">complex tasks into easier sub tasks is a powerful technique. </span><span class="koboSpan" id="kobo.189.2">Nevertheless, it does not address one of the main risks of LLM-generated content, that is, having an incorrect output. </span><span class="koboSpan" id="kobo.189.3">In the next two subsections, we are going to see some techniques that are mainly aimed at addressing this risk.</span></p>
<h2 class="heading-2" id="_idParaDest-59"><span class="koboSpan" id="kobo.190.1">Ask for justification</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.191.1">In prompt </span><a id="_idIndexMarker170"/><span class="koboSpan" id="kobo.192.1">engineering, requesting that a model provides justifications for its responses enhances transparency and reliability. </span><span class="koboSpan" id="kobo.192.2">This practice allows users to assess the reasoning behind the model’s answers, ensuring they are logical and grounded in relevant information (</span><a href="https://arxiv.org/abs/2303.08769"><span class="url"><span class="koboSpan" id="kobo.193.1">https://arxiv.org/abs/2303.08769</span></span></a><span class="koboSpan" id="kobo.194.1">). </span><span class="koboSpan" id="kobo.194.2">By understanding the model’s thought process, users can identify potential biases or inaccuracies, leading to more informed decisions and effective utilization of AI systems.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.195.1">For instance, when an AI model suggests a medical diagnosis, asking for its reasoning can reveal whether the suggestion is based on pertinent symptoms and medical history or if it’s influenced by irrelevant data. </span><span class="koboSpan" id="kobo.195.2">Similarly, in legal contexts, if an AI system provides case recommendations, understanding its justification helps ensure the advice is based on appropriate legal precedents. </span><span class="koboSpan" id="kobo.195.3">This level of insight is crucial for building trust in AI applications and for </span><a id="_idIndexMarker171"/><span class="koboSpan" id="kobo.196.1">refining prompts to elicit more accurate and contextually appropriate responses.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.197.1">Let’s consider the following example. </span><span class="koboSpan" id="kobo.197.2">We want our LLM to solve riddles and we prompt it with the following set of instructions:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.198.1"><img alt="" src="../Images/B31559_03_12.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.199.1">Figure 3.10: Example of OpenAI’s GPT-4o providing justification after solving a riddle</span></p>
<p class="normal"><span class="koboSpan" id="kobo.200.1">With a similar</span><a id="_idIndexMarker172"/><span class="koboSpan" id="kobo.201.1"> approach, we could also intervene at different prompt levels to improve our LLM’s performance. </span><span class="koboSpan" id="kobo.201.2">For example, we might discover that the model is systematically tackling a mathematical problem in the wrong way, hence we might want to suggest the right approach directly at the meta-prompt level.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.202.1">Another example might be that of asking the model to generate multiple outputs – along with their justifications – to evaluate different reasoning techniques and prompt the best one in the meta-prompt. </span><span class="koboSpan" id="kobo.202.2">We’ll focus on this in the next subsection.</span></p>
<h2 class="heading-2" id="_idParaDest-60"><span class="koboSpan" id="kobo.203.1">Generate many outputs, then use the model to pick the best one</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.204.1">In prompt</span><a id="_idIndexMarker173"/><span class="koboSpan" id="kobo.205.1"> engineering, instructing a model to generate multiple responses to a single prompt is a technique known as self-consistency. </span><span class="koboSpan" id="kobo.205.2">This approach involves directing the model to produce several outputs for a given input, which are then evaluated to identify the most consistent or accurate response. </span><span class="koboSpan" id="kobo.205.3">By comparing these multiple outputs, users can discern common themes or solutions, enhancing the reliability of the LLM’s performance.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.206.1">Let’s see an example, following up with the riddles examined in the previous section:</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.207.1">You are an AI assistant specialized in solving riddles.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.208.1">Given a riddle, you have to generate three answers to the riddle.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.209.1">For each answer, be specific about the reasoning you made.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.210.1">Then, among the three answers, select the one which is most plausible given the riddle.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.211.1">In this case, I’ve prompted the model to generate three answers to the riddle, then to give me the most likely, justifying why. </span><span class="koboSpan" id="kobo.211.2">Let’s see the result:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.212.1"><img alt="" src="../Images/B31559_03_13.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.213.1">Figure 3.11: Example of GPT-4o generating three plausible answers and picking the most likely one, providing justification</span></p>
<p class="normal"><span class="koboSpan" id="kobo.214.1">As previously mentioned, forcing</span><a id="_idIndexMarker174"/><span class="koboSpan" id="kobo.215.1"> the model to tackle a problem with different approaches is a way to collect multiple samples of reasonings, which might serve as further instructions in the meta-prompt. </span><span class="koboSpan" id="kobo.215.2">For example, if we want the model to always propose something that is not the most straightforward solution to a problem – in other words, if we want it to “think differently” – we might force it to solve a problem in N ways and then use the most creative reasoning as the </span><a id="_idIndexMarker175"/><span class="koboSpan" id="kobo.216.1">framework in the meta-prompt.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.217.1">The last element we are going to examine is the overall structure we want to give to our meta-prompt.</span></p>
<h2 class="heading-2" id="_idParaDest-61"><span class="koboSpan" id="kobo.218.1">Use delimiters</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.219.1">The </span><a id="_idIndexMarker176"/><span class="koboSpan" id="kobo.220.1">last principle to be covered is related to the format we want to give to our meta prompt. </span><span class="koboSpan" id="kobo.220.2">This helps our LLM to better understand its intents as well as to make connections among sections and paragraphs.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.221.1">To achieve this, we can use delimiters within our prompt. </span><span class="koboSpan" id="kobo.221.2">A delimiter can be any sequence of characters or symbols that is clearly mapping a schema rather than a concept. </span><span class="koboSpan" id="kobo.221.3">For example, we can consider the following sequence delimiters:</span></p>
<ul>
<li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.222.1">&gt;&gt;&gt;&gt;</span></code></li>
<li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.223.1">====</span></code></li>
<li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.224.1">------</span></code></li>
<li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.225.1">####</span></code></li>
<li class="bulletList"><code class="inlineCode"><span class="koboSpan" id="kobo.226.1">` ` ` ` `</span></code></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.227.1">Let’s consider, for example, a meta-prompt that aims at instructing the model to translate a user’s tasks into Python code, also providing an example of doing so:</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.228.1">You are a Python expert that produces Python code as per the user's request.
</span><span class="koboSpan" id="kobo.228.2">===&gt;START EXAMPLE
---User Query---
Give me a function to print a string of text.
</span><span class="koboSpan" id="kobo.228.3">---User Output---
Below you can find the described function:
```def my_print(text):
     #returning the printed text
     return print(text)
```
&lt;===END EXAMPLE
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.229.1">Let’s see how it works:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.230.1"><img alt="" src="../Images/B31559_03_14.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.231.1">Figure 3.12: Sample output of a model using delimiters in the system message</span></p>
<p class="normal"><span class="koboSpan" id="kobo.232.1">As you can see, it </span><a id="_idIndexMarker177"/><span class="koboSpan" id="kobo.233.1">also printed the code in backticks as shown within the system message.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.234.1">All the principles examined up to this point are general rules that can make your interaction with ChatGPT and, more broadly, GenAI tools more meaningful to your goal. </span><span class="koboSpan" id="kobo.234.2">In the next section, we are going to see some advanced techniques for prompt engineering that address the way the model reasons </span><a id="_idIndexMarker178"/><span class="koboSpan" id="kobo.235.1">and thinks about the answer, before providing it to the final user.</span></p>
<h2 class="heading-2" id="_idParaDest-62"><span class="koboSpan" id="kobo.236.1">Meta-prompting</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.237.1">In </span><a id="_idIndexMarker179"/><span class="koboSpan" id="kobo.238.1">prompt engineering, instructing a model to refine its own prompts – also </span><a id="_idIndexMarker180"/><span class="koboSpan" id="kobo.239.1">known as meta-prompting (</span><a href="https://arxiv.org/abs/2401.12954"><span class="url"><span class="koboSpan" id="kobo.240.1">https://arxiv.org/abs/2401.12954</span></span></a><span class="koboSpan" id="kobo.241.1">) – is an effective technique to enhance prompt quality and, consequently, the relevance of generated outputs. </span><span class="koboSpan" id="kobo.241.2">By engaging the model in the iterative process of prompt refinement, users can leverage the model’s language understanding to identify ambiguities or areas for improvement within the initial prompt. </span><span class="koboSpan" id="kobo.241.3">This self-improvement loop leads to more precise and contextually appropriate prompts, which in turn elicit more accurate and useful responses from the model.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.242.1">For instance, let’s say we want to generate an elevator pitch for our new sustainable brand of running shoes. </span><span class="koboSpan" id="kobo.242.2">How would you ask the LLM to do that? </span><span class="koboSpan" id="kobo.242.3">Well, you might leverage some of the above techniques, like clear instructions or splitting the task into sub tasks; alternatively (or additionally), you could ask the LLM itself to refine your prompt to make it more relevant to your goal.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.243.1">To do that, we can initially instruct the model to refine the prompt as follows:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.244.1"><img alt="" src="../Images/B31559_03_15.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.245.1">Figure 3.13: Example of a user asking ChatGPT to refine a prompt</span></p>
<p class="normal"><span class="koboSpan" id="kobo.246.1">Now, let’s send our prompt:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.247.1"><img alt="" src="../Images/B31559_03_16.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.248.1">Figure 3.14: Example of ChatGPT refining the user’s prompt</span></p>
<p class="normal"><span class="koboSpan" id="kobo.249.1">As you can see, ChatGPT</span><a id="_idIndexMarker181"/><span class="koboSpan" id="kobo.250.1"> was able to refine our prompt and </span><a id="_idIndexMarker182"/><span class="koboSpan" id="kobo.251.1">make it more tailored to our goal. </span><span class="koboSpan" id="kobo.251.2">Note that, in the above example, we only asked for one refinement; however, this can be an iterative process to not only enhance the clarity and precision of the prompt but also ensure that the model’s outputs are more aligned with the user’s specific requirements, making interactions more efficient and productive.</span></p>
<h1 class="heading-1" id="_idParaDest-63"><span class="koboSpan" id="kobo.252.1">Exploring some advanced techniques</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.253.1">In previous sections, we covered some basic techniques of prompt engineering that can improve your LLM’s response regardless of the type of task you are trying to accomplish.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.254.1">On the other hand, there are some advanced techniques that might be implemented for specific scenarios that we are going to cover in this section.</span></p>
<div class="note">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.255.1">Note</span></strong></p>
<p class="normal"><span class="koboSpan" id="kobo.256.1">Some advanced prompt engineering techniques like </span><strong class="keyWord"><span class="koboSpan" id="kobo.257.1">chain-of-thought</span></strong><span class="koboSpan" id="kobo.258.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.259.1">CoT</span></strong><span class="koboSpan" id="kobo.260.1">) prompting are integrated into modern models such as OpenAI’s o1 series. </span><span class="koboSpan" id="kobo.260.2">These models are designed to internally process complex reasoning tasks by generating step-by-step logical sequences before arriving at a final answer, enhancing their problem-solving capabilities. </span><span class="koboSpan" id="kobo.260.3">This internal reasoning process allows o1 models to handle intricate queries more effectively without requiring explicit CoT prompts from users. </span><span class="koboSpan" id="kobo.260.4">However, employing CoT prompting can still be beneficial in guiding the model’s reasoning process for specific tasks and, more broadly, is a good practice whenever we interact with models of previous versions that do not exhibit advanced reasoning capabilities.</span></p>
</div>
<h2 class="heading-2" id="_idParaDest-64"><span class="koboSpan" id="kobo.261.1">Chain of thought</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.262.1">Introduced in the paper </span><em class="italic"><span class="koboSpan" id="kobo.263.1">Chain-of-Thought Prompting Elicits Reasoning in Large Language Models</span></em><span class="koboSpan" id="kobo.264.1"> by Wei et al., CoT is a </span><a id="_idIndexMarker183"/><span class="koboSpan" id="kobo.265.1">technique that enables complex reasoning capabilities through intermediate reasoning steps. </span><span class="koboSpan" id="kobo.265.2">It also encourages the model to explain its reasoning, “forcing” it not to be too fast and risk giving the wrong response (as we saw in previous sections).</span></p>
<p class="normal"><span class="koboSpan" id="kobo.266.1">Let’s say that we want to prompt our LLM to solve first-degree equations. </span><span class="koboSpan" id="kobo.266.2">To do so, we are going to provide it with a generic reasoning list as a meta-prompt:</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.267.1">To solve a generic first-degree equation, follow these steps:
1. </span><span class="koboSpan" id="kobo.267.2">**Identify the Equation:** Start by identifying the equation you want to solve. </span><span class="koboSpan" id="kobo.267.3">It should be in the form of "ax + b = c," where 'a' is the coefficient of the variable, 'x' is the variable, 'b' is a constant, and 'c' is another constant.
</span><span class="koboSpan" id="kobo.267.4">2. </span><span class="koboSpan" id="kobo.267.5">**Isolate the Variable:** Your goal is to isolate the variable 'x' on one side of the equation. </span><span class="koboSpan" id="kobo.267.6">To do this, perform the following steps:
 
   a. </span><span class="koboSpan" id="kobo.267.7">**Add or Subtract Constants:** Add or subtract 'b' from both sides of the equation to move constants to one side.
 
   </span><span class="koboSpan" id="kobo.267.8">b. </span><span class="koboSpan" id="kobo.267.9">**Divide by the Coefficient:** Divide both sides by 'a' to isolate 'x'. </span><span class="koboSpan" id="kobo.267.10">If 'a' is zero, the equation may not have a unique solution.
</span><span class="koboSpan" id="kobo.267.11">3. </span><span class="koboSpan" id="kobo.267.12">**Simplify:** Simplify both sides of the equation as much as possible.
</span><span class="koboSpan" id="kobo.267.13">4. </span><span class="koboSpan" id="kobo.267.14">**Solve for 'x':** Once 'x' is isolated on one side, you have the solution. </span><span class="koboSpan" id="kobo.267.15">It will be in the form of 'x = value.'
</span><span class="koboSpan" id="kobo.267.16">5. </span><span class="koboSpan" id="kobo.267.17">**Check Your Solution:** Plug the found value of 'x' back into the original equation to ensure it satisfies the equation. </span><span class="koboSpan" id="kobo.267.18">If it does, you've found the correct solution.
</span><span class="koboSpan" id="kobo.267.19">6. </span><span class="koboSpan" id="kobo.267.20">**Express the Solution:** Write down the solution in a clear and concise form.
</span><span class="koboSpan" id="kobo.267.21">7. </span><span class="koboSpan" id="kobo.267.22">**Consider Special Cases:** Be aware of special cases where there may be no solution or infinitely many solutions, especially if 'a' equals zero.
</span><span class="koboSpan" id="kobo.267.23">Equation:
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.268.1">Let’s see how it</span><a id="_idIndexMarker184"/><span class="koboSpan" id="kobo.269.1"> works:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.270.1"><img alt="" src="../Images/B31559_03_17.png"/></span><span class="koboSpan" id="kobo.271.1"><img alt="" src="../Images/B31559_03_18.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.272.1">Figure 3.15: Output of the model solving an equation with the CoT approach</span></p>
<p class="normal"><span class="koboSpan" id="kobo.273.1">This methodical approach</span><a id="_idIndexMarker185"/><span class="koboSpan" id="kobo.274.1"> mirrors human problem-solving by decomposing the task into manageable steps, enhancing clarity and reducing errors.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.275.1">With CoT, we are prompting the model to generate intermediate reasoning steps. </span><span class="koboSpan" id="kobo.275.2">This is also a component of another reasoning technique that we are going to examine next.</span></p>
<h2 class="heading-2" id="_idParaDest-65"><span class="koboSpan" id="kobo.276.1">ReAct</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.277.1">Introduced in the paper </span><em class="italic"><span class="koboSpan" id="kobo.278.1">ReAct: Synergizing Reasoning and Acting in Language Models </span></em><span class="koboSpan" id="kobo.279.1">by Yao et al., </span><strong class="keyWord"><span class="koboSpan" id="kobo.280.1">Reason and Act</span></strong><span class="koboSpan" id="kobo.281.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.282.1">ReAct</span></strong><span class="koboSpan" id="kobo.283.1">) is a </span><a id="_idIndexMarker186"/><span class="koboSpan" id="kobo.284.1">general paradigm that combines reasoning and acting with LLMs. </span><span class="koboSpan" id="kobo.284.2">ReAct prompts the language model to generate verbal reasoning traces and actions for a task, and also receive observations from external sources such as web searches or databases. </span><span class="koboSpan" id="kobo.284.3">This allows the language model to perform dynamic reasoning and quickly adapt its action plan based on external information. </span><span class="koboSpan" id="kobo.284.4">For example, you can prompt the language model to answer a question by first reasoning about the question, then performing an action to send a query to the web, then receiving an observation from the search results, and then continuing with this thought, action, observation loop until it reaches a conclusion.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.285.1">The difference between CoT and ReAct approaches is that CoT prompts the language model to generate intermediate reasoning steps for a task, while ReAct prompts the language model to generate intermediate reasoning steps, actions, and observations for a task.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.286.1">Note that the “action” phase is generally related to the possibility of our LLM interacting with external tools, such as web search. </span><span class="koboSpan" id="kobo.286.2">However, in the following example, we won’t use tools but rather refer to the term “action” for any task we ask the model to do for us.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.287.1">This is how the ReAct meta-prompt might look:</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.288.1">Answer the following questions as best you can.
</span><span class="koboSpan" id="kobo.288.2">Use the following format:
 ---------------
Question: the input question you must answer
Thought: you should always think about what to do
Action: the action to take
Action Input: the input to the action
Observation: the result of the action
... </span><span class="koboSpan" id="kobo.288.3">(this Thought/Action/Action Input/Observation can repeat N times)
Thought: I now know the final answer
Final Answer: the final answer to the original input question
-----------------
This is my question: Who won the climbing Olympics in 2024?
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.289.1">Let’s see how it works with a simple user query:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.290.1"><img alt="" src="../Images/B31559_03_19.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.291.1">Figure 3.16: Example of ReAct prompting</span></p>
<p class="normal"><span class="koboSpan" id="kobo.292.1">As you can see, in this scenario, the</span><a id="_idIndexMarker187"/><span class="koboSpan" id="kobo.293.1"> model leveraged the web tool at the action input.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.294.1">This is a great example of how prompting a model to think step by step and explicitly detail each step of the reasoning makes it “wiser” and more cautious before answering. </span><span class="koboSpan" id="kobo.294.2">It is also a great technique to prevent hallucination.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.295.1">Overall, prompt engineering is a powerful discipline, still in its emerging phase yet already widely adopted within LLM-powered applications. </span><span class="koboSpan" id="kobo.295.2">In the following chapters, we are going to see concrete applications of these techniques.</span></p>
<h1 class="heading-1" id="_idParaDest-66"><span class="koboSpan" id="kobo.296.1">Ethical considerations to avoid bias</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.297.1">Whenever we deal with AI </span><a id="_idIndexMarker188"/><span class="koboSpan" id="kobo.298.1">systems like LLMs, we must be aware of their associated risk of </span><strong class="keyWord"><span class="koboSpan" id="kobo.299.1">hidden bias</span></strong><span class="koboSpan" id="kobo.300.1">, which derives directly from the knowledge base the model has been trained on.</span></p>
<div class="note">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.301.1">Definition</span></strong></p>
<p class="normal"><span class="koboSpan" id="kobo.302.1">Hidden bias, also </span><a id="_idIndexMarker189"/><span class="koboSpan" id="kobo.303.1">known as implicit or unconscious bias, refers to the subtle and unintentional attitudes, stereotypes, or associations that influence a person’s perceptions and actions without their conscious awareness. </span><span class="koboSpan" id="kobo.303.2">These biases can shape behaviors and decisions in ways that reflect societal stereotypes, often leading to unintended discrimination. </span><span class="koboSpan" id="kobo.303.3">For example, someone might unknowingly associate leadership roles with men over women, which could impact hiring or promotion choices. </span><span class="koboSpan" id="kobo.303.4">In the context of LLM, hidden bias manifests in the model’s outputs when it reproduces or amplifies biases present in its training data, potentially leading to skewed or unfair responses. </span><span class="koboSpan" id="kobo.303.5">Addressing hidden bias is essential to fostering fairness and reducing systemic inequities.</span></p>
</div>
<p class="normal"><span class="koboSpan" id="kobo.304.1">For example, concerning the main chunk of training </span><a id="_idIndexMarker190"/><span class="koboSpan" id="kobo.305.1">data of GPT-3, known as the </span><strong class="keyWord"><span class="koboSpan" id="kobo.306.1">Common Crawl</span></strong><span class="koboSpan" id="kobo.307.1">, a 2012 study (</span><a href="https://commoncrawl.org/blog/a-look-inside-common-crawls-210tb-2012-web-corpus"><span class="url"><span class="koboSpan" id="kobo.308.1">https://commoncrawl.org/blog/a-look-inside-common-crawls-210tb-2012-web-corpus</span></span></a><span class="koboSpan" id="kobo.309.1">) revealed that over 55% of the corpus originated from .</span><em class="italic"><span class="koboSpan" id="kobo.310.1">com</span></em><span class="koboSpan" id="kobo.311.1"> domains, with twelve top-level domains each representing more than 1% of the data.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.312.1">Given that </span><em class="italic"><span class="koboSpan" id="kobo.313.1">.com</span></em><span class="koboSpan" id="kobo.314.1"> domains are heavily utilized by Western entities, this concentration suggests a significant Western influence in the dataset. </span><span class="koboSpan" id="kobo.314.2">Additionally, the prevalence of English-language content within Common Crawl further indicates a Western-centric bias, as English is predominantly spoken in Western nations.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.315.1">If this is the case, we are already facing a hidden bias of the model (more specifically, a racial and linguistic bias), which will inevitably mimic a limited and unrepresentative category of human beings.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.316.1">In their paper </span><em class="italic"><span class="koboSpan" id="kobo.317.1">Language Models are Few-Shots Learners</span></em><span class="koboSpan" id="kobo.318.1"> (</span><a href="https://arxiv.org/abs/2005.14165"><span class="url"><span class="koboSpan" id="kobo.319.1">https://arxiv.org/abs/2005.14165</span></span></a><span class="koboSpan" id="kobo.320.1">), OpenAI’s researchers Tom Brown et al. </span><span class="koboSpan" id="kobo.320.2">created an experimental setup to investigate racial bias in GPT-3. </span><span class="koboSpan" id="kobo.320.3">The model was prompted with phrases containing racial categories and 800 samples were generated for each category. </span><span class="koboSpan" id="kobo.320.4">The sentiment of the generated text was measured using Senti WordNet based on word co-occurrences on a scale ranging from -100 to 100 (with positive scores indicating positive words and vice versa).</span></p>
<p class="normal"><span class="koboSpan" id="kobo.321.1">The results showed that the sentiment associated with each racial category varied across different models, with </span><em class="italic"><span class="koboSpan" id="kobo.322.1">Asian </span></em><span class="koboSpan" id="kobo.323.1">consistently having a high sentiment (meaning a lot of positive words) and </span><em class="italic"><span class="koboSpan" id="kobo.324.1">Black </span></em><span class="koboSpan" id="kobo.325.1">consistently having a low sentiment (meaning a lot of negative words). </span><span class="koboSpan" id="kobo.325.2">The authors caution that the results reflect the experimental setup and that socio-historical factors may influence the sentiment associated with different demographics.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.326.1">This hidden bias could generate harmful responses not in line with responsible AI principles.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.327.1">However, it is worth noting how ChatGPT, as well as all OpenAI models, are subject to continuous improvements. </span><span class="koboSpan" id="kobo.327.2">This is also consistent with OpenAI’s AI alignment (</span><a href="https://openai.com/index/our-approach-to-alignment-research/"><span class="url"><span class="koboSpan" id="kobo.328.1">https://openai.com/index/our-approach-to-alignment-research/</span></span></a><span class="koboSpan" id="kobo.329.1">), whose research focuses on training AI systems to </span><a id="_idIndexMarker191"/><span class="koboSpan" id="kobo.330.1">be helpful, truthful, and safe.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.331.1">For example, if we ask GPT-4o to formulate guesses based on people’s gender and age, it will not accommodate the exact request, but rather provide us with a hypothetical function as well as a huge disclaimer:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.332.1"><img alt="" src="../Images/B31559_03_20.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.333.1">Figure 3.17: Example of GPT-4o improving over time since it gives an unbiased response</span></p>
<p class="normal"><span class="koboSpan" id="kobo.334.1">Overall, despite the continuous</span><a id="_idIndexMarker192"/><span class="koboSpan" id="kobo.335.1"> improvement in the domain of ethical principles, while using ChatGPT, we should always make sure that the output is in line with those principles. </span><span class="koboSpan" id="kobo.335.2">The concepts of bias and ethics within ChatGPT and OpenAI models have a wider connotation within the whole topic of responsible AI, which we are going to focus on in the last chapter of this book.</span></p>
<h1 class="heading-1" id="_idParaDest-67"><span class="koboSpan" id="kobo.336.1">Summary</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.337.1">In this chapter, we have dived into the concept of prompt engineering since it’s a key component to control the output of ChatGPT and LLMs in general. </span><span class="koboSpan" id="kobo.337.2">We learned how to leverage different levels of shot learning to make LLMs more tailored to our objectives.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.338.1">We started with an introduction to the concept of prompt engineering and why it is important, then moving toward the basic principles – including clear instructions, asking for justification, etc.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.339.1">Then, we moved toward more advanced techniques, which are meant to shape the reasoning approach of our LLMs: few-shot learning, CoT, and ReAct.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.340.1">Prompt engineering is an emerging discipline that is paving the way for a new category of applications, infused with LLMs.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.341.1">Starting from the next chapter, we will explore different domains where ChatGPT can boost productivity and have a disruptive impact on the way we work today.</span></p>
<h1 class="heading-1" id="_idParaDest-68"><span class="koboSpan" id="kobo.342.1">References</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.343.1">The following are the references for this chapter:</span></p>
<ul>
<li class="bulletList"><em class="italic"><span class="koboSpan" id="kobo.344.1">Language Models are Few-Shot Learners</span></em><span class="koboSpan" id="kobo.345.1">: </span><a href="https://arxiv.org/abs/2005.14165"><span class="url"><span class="koboSpan" id="kobo.346.1">https://arxiv.org/abs/2005.14165</span></span></a></li>
<li class="bulletList"><em class="italic"><span class="koboSpan" id="kobo.347.1">On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?</span></em><span class="koboSpan" id="kobo.348.1">: </span><a href="https://dl.acm.org/doi/10.1145/3442188.3445922"><span class="url"><span class="koboSpan" id="kobo.349.1">https://dl.acm.org/doi/10.1145/3442188.3445922</span></span></a></li>
<li class="bulletList"><span class="koboSpan" id="kobo.350.1">ReAct approach: </span><a href="https://arxiv.org/abs/2210.03629"><span class="url"><span class="koboSpan" id="kobo.351.1">https://arxiv.org/abs/2210.03629</span></span></a></li>
<li class="bulletList"><span class="koboSpan" id="kobo.352.1">Chain-of-thought approach: </span><a href="https://arxiv.org/abs/2201.11903"><span class="url"><span class="koboSpan" id="kobo.353.1">https://arxiv.org/abs/2201.11903</span></span></a></li>
<li class="bulletList"><em class="italic"><span class="koboSpan" id="kobo.354.1">What is prompt engineering?</span></em><span class="koboSpan" id="kobo.355.1">: </span><a href="https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-prompt-engineering"><span class="url"><span class="koboSpan" id="kobo.356.1">https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-prompt-engineering</span></span></a></li>
<li class="bulletList"><span class="koboSpan" id="kobo.357.1">Prompt engineering principles: </span><a href="https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/advanced-prompt-engineering?pivots=programming-language-chat-completions"><span class="url"><span class="koboSpan" id="kobo.358.1">https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/advanced-prompt-engineering?pivots=programming-language-chat-completions</span></span></a></li>
</ul>
</div>
</body></html>