["```py\nList<HaarCascadeStage> stages = new List<HaarCascadeStage>();\nList<HaarFeatureNode[]> nodes;\nHaarCascadeStage stage;\nstage = new HaarCascadeStage(0.822689414024353); nodes = new List<HaarFeatureNode[]>();\nnodes.Add(new[] { new HaarFeatureNode(0.004014195874333382, 0.0337941907346249, 0.8378106951713562, new int[] { 3, 7, 14, 4, -1 }, new int[] { 3, 9, 14, 2, 2 }) });\nnodes.Add(new[] { new HaarFeatureNode(0.0151513395830989, 0.1514132022857666, 0.7488812208175659, new int[] { 1, 2, 18, 4, -1 }, new int[] { 7, 2, 6, 4, 3 }) });\nnodes.Add(new[] { new HaarFeatureNode(0.004210993181914091, 0.0900492817163467, 0.6374819874763489, new int[] { 1, 7, 15, 9, -1 }, new int[] { 1, 10, 15, 3, 3 }) });\nstage.Trees = nodes.ToArray(); stages.Add(stage);\n```", "```py\nHaarCascade cascade = new FaceHaarCascade();\ndetector = new HaarObjectDetector(cascade, 25, ObjectDetectorSearchMode.Single, 1.2f,\nObjectDetectorScalingMode.GreaterToSmaller);\n```", "```py\nforeach (var cap in device?.VideoCapabilities)\n {\nif (cap.FrameSize.Height == 240)\nreturn cap;\nif (cap.FrameSize.Width == 320)\nreturn cap;\n }\nreturn device?.VideoCapabilities.Last();\n```", "```py\nthis.videoSourcePlayer.NewFrameReceived += new Accord.Video.NewFrameEventHandler(this.videoSourcePlayer_NewFrame);\n```", "```py\nResizeNearestNeighbor resize = new ResizeNearestNeighbor(160, 120);\nUnmanagedImagedownsample = resize.Apply(im);\n```", "```py\nif (regions != null&&regions.Length>0)\n {\ntracker?.Reset();\n// Will track the first face found\nRectangle face = regions[0];\n// Reduce the face size to avoid tracking background\nRectangle window = new Rectangle((int)((regions[0].X + regions[0].Width / 2f) * xscale),\n (int)((regions[0].Y + regions[0].Height / 2f) * yscale), 1, 1);\nwindow.Inflate((int)(0.2f * regions[0].Width * xscale), (int)(0.4f * regions[0].Height * yscale));\nif (tracker != null)\n {\ntracker.SearchWindow = window;\ntracker.ProcessFrame(im);\n }\nmarker = new RectanglesMarker(window);\nmarker.ApplyInPlace(im);\nargs.Frame = im.ToManagedImage();\ntracking = true;\n }\nelse\n {\ndetecting = true;\n }\n```", "```py\n// create motion detector\nMotionDetector detector = new MotionDetector(\n new SimpleBackgroundModelingDetector( ),\n new MotionAreaHighlighting( ) );\n// continuously feed video frames to motion detector\nwhile ( ... )\n{\n // process new video frame and check motion level\n if ( detector.ProcessFrame( videoFrame ) > 0.02 )\n {\n // ring alarm or do something else\n }\n}\n```", "```py\nvideoSourcePlayer.VideoSource = new AsyncVideoSource(source);\n```", "```py\nprivate void videoSourcePlayer_NewFrame(object sender, NewFrameEventArgsargs)\n {\nlock (this)\n {\nif (detector != null)\n {\nfloatmotionLevel = detector.ProcessFrame(args.Frame);\nif (motionLevel > motionAlarmLevel)\n {\n// flash for 2 seconds\nflash = (int)(2 * (1000 / alarmTimer.Interval));\n }\n// check objects' count\nif (detector.MotionProcessingAlgorithm is BlobCountingObjectsProcessing)\n {\nBlobCountingObjectsProcessing countingDetector = (BlobCountingObjectsProcessing)detector.MotionProcessingAlgorithm;\ndetectedObjectsCount = countingDetector.ObjectsCount;\n }\nelse\n {\ndetectedObjectsCount = -1;\n }\n// accumulate history\nmotionHistory.Add(motionLevel);\nif (motionHistory.Count> 300)\n                    {\nmotionHistory.RemoveAt(0);\n                    }\n\nif (showMotionHistoryToolStripMenuItem.Checked)\nDrawMotionHistory(args.Frame);\n                }\n            }\n```", "```py\nfloat motionLevel = detector.ProcessFrame(args.Frame);\nif (motionLevel > motionAlarmLevel)\n{\n// flash for 2 seconds\nflash = (int)(2 * (1000 / alarmTimer.Interval));\n}\n```"]