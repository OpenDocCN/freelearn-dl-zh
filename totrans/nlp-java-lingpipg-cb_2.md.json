["```py\n    java -cp \"lingpipe-cookbook.1.0.jar:lib/lingpipe-4.1.0.jar\" com.lingpipe.cookbook.chapter2.RunBaseTokenizerFactory\n\n    ```", "```py\n    type a sentence to see tokens and white spaces\n\n    ```", "```py\n    It's no use growing older if you only learn new ways of misbehaving yourself. \n    Token:'It'\n    WhiteSpace:''\n    Token:'''\n    WhiteSpace:''\n    Token:'s'\n    WhiteSpace:' '\n    Token:'no'\n    WhiteSpace:' '\n    Token:'use'\n    WhiteSpace:' '\n    Token:'growing'\n    WhiteSpace:' '\n    Token:'older'\n    WhiteSpace:' '\n    Token:'if'\n    WhiteSpace:' '\n    Token:'you'\n    WhiteSpace:' '\n    Token:'only'\n    WhiteSpace:' '\n    Token:'learn'\n    WhiteSpace:' '\n    Token:'new'\n    WhiteSpace:' '\n    Token:'ways'\n    WhiteSpace:' '\n    Token:'of'\n    WhiteSpace:' '\n    Token:'misbehaving'\n    WhiteSpace:' '\n    Token:'yourself'\n    WhiteSpace:''\n    Token:'.'\n    WhiteSpace:' '\n\n    ```", "```py\npackage com.lingpipe.cookbook.chapter2;\n\nimport java.io.BufferedReader;\nimport java.io.IOException;\nimport java.io.InputStreamReader;\n\nimport com.aliasi.tokenizer.IndoEuropeanTokenizerFactory;\nimport com.aliasi.tokenizer.Tokenizer;\nimport com.aliasi.tokenizer.TokenizerFactory;\n\npublic class RunBaseTokenizerFactory {\n\n  public static void main(String[] args) throws IOException {\n    TokenizerFactory tokFactory = IndoEuropeanTokenizerFactory.INSTANCE;\n    BufferedReader reader = new BufferedReader(new InputStreamReader(System.in));\n\n    while (true) {\n      System.out.println(\"type a sentence to \" + \"see the tokens and white spaces\");\n      String input = reader.readLine();\n      Tokenizer tokenizer = tokFactory.tokenizer(input.toCharArray(), 0, input.length());\n      String token = null;\n      while ((token = tokenizer.nextToken()) != null) {\n        System.out.println(\"Token:'\" + token + \"'\");\n        System.out.println(\"WhiteSpace:'\" + tokenizer.nextWhitespace() + \"'\");\n\n      }\n    }\n  }\n}\n```", "```py\n    java -cp \"lingpipe-cookbook.1.0.jar:lib/lingpipe-4.1.0.jar\" com.lingpipe.cookbook.chapter2.RunLowerCaseTokenizerFactory.\n\n    ```", "```py\n    type a sentence below to see the tokens and white spaces are:\n    This is an UPPERCASE word and these are numbers 1 2 3 4.5.\n    Token:'this'\n    WhiteSpace:' '\n    Token:'is'\n    WhiteSpace:' '\n    Token:'an'\n    WhiteSpace:' '\n    Token:'uppercase'\n    WhiteSpace:' '\n    Token:'word'\n    WhiteSpace:' '\n    Token:'and'\n    WhiteSpace:' '\n    Token:'these'\n    WhiteSpace:' '\n    Token:'are'\n    WhiteSpace:' '\n    Token:'numbers'\n    WhiteSpace:' '\n    Token:'1'\n    WhiteSpace:' '\n    Token:'2'\n    WhiteSpace:' '\n    Token:'3'\n    WhiteSpace:' '\n    Token:'4.5'\n    WhiteSpace:''\n    Token:'.'\n    WhiteSpace:''\n\n    ```", "```py\npublic static void main(String[] args) throws IOException {\n\n  TokenizerFactory tokFactory = IndoEuropeanTokenizerFactory.INSTANCE;\n  tokFactory = new LowerCaseTokenizerFactory(tokFactory);\n  tokFactory = new WhitespaceNormTokenizerFactory(tokFactory);\n\n  BufferedReader reader = new BufferedReader(new InputStreamReader(System.in));\n\n  while (true) {\n    System.out.println(\"type a sentence below to see the tokens and white spaces are:\");\n    String input = reader.readLine();\n    Tokenizer tokenizer = tokFactory.tokenizer(input.toCharArray(), 0, input.length());\n    String token = null;\n    while ((token = tokenizer.nextToken()) != null) {\n      System.out.println(\"Token:'\" + token + \"'\");\n      System.out.println(\"WhiteSpace:'\" + tokenizer.nextWhitespace() + \"'\");\n    }\n  }\n}\n```", "```py\n    java -cp \"lingpipe-cookbook.1.0.jar:lib/lingpipe-4.1.0.jar\" com.lingpipe.cookbook.chapter2.RunStopTokenizerFactory\n\n    ```", "```py\n    type a sentence below to see the tokens and white spaces:\n    the quick brown fox is jumping\n    Token:'quick'\n    WhiteSpace:' '\n    Token:'brown'\n    WhiteSpace:' '\n    Token:'fox'\n    WhiteSpace:' '\n    Token:'jumping'\n    WhiteSpace:''\n\n    ```", "```py\nTokenizerFactory tokFactory = IndoEuropeanTokenizerFactory.INSTANCE;\ntokFactory = new LowerCaseTokenizerFactory(tokFactory);\nSet<String> stopWords = new HashSet<String>();\nstopWords.add(\"the\");\nstopWords.add(\"of\");\nstopWords.add(\"to\");\nstopWords.add(\"is\");\n\ntokFactory = new StopTokenizerFactory(tokFactory, stopWords);\n```", "```py\n    java -cp lingpipe-cookbook.1.0.jar:lib/lucene-analyzers-common-4.6.0.jar:lib/lucene-core-4.6.0.jar com.lingpipe.cookbook.chapter2.RunLuceneTokenize\n\n    ```", "```py\n    the quick BROWN fox jumped\n    type a sentence below to see the tokens and white spaces:\n    The rain in Spain.\n    Token:'the' Start: 0 End:3\n    Token:'rain' Start: 4 End:8\n    Token:'in' Start: 9 End:11\n    Token:'spain' Start: 12 End:17\n\n    ```", "```py\nBufferedReader reader = new BufferedReader(new InputStreamReader(System.in));\n\nwhile (true) {\n```", "```py\nBufferedReader from the command line and starts a perpetual while() loop. Next, the prompt is provided, the input is read, and it is used to construct a Reader object:\n```", "```py\nSystem.out.println(\"type a sentence below to see the tokens and white spaces:\");\nString input = reader.readLine();\nReader stringReader = new StringReader(input);\n```", "```py\nTokenStream tokenStream = new StandardTokenizer(Version.LUCENE_46,stringReader);\n\ntokenStream = new LowerCaseFilter(Version.LUCENE_46,tokenStream);\n```", "```py\nCharTermAttribute terms = tokenStream.addAttribute(CharTermAttribute.class);\nOffsetAttribute offset = tokenStream.addAttribute(OffsetAttribute.class);\ntokenStream.reset();\n```", "```py\nwhile (tokenStream.incrementToken()) {\n  String token = terms.toString();\n  int start = offset.startOffset();\n  int end = offset.endOffset();\n  System.out.println(\"Token:'\" + token + \"'\" + \" Start: \" + start + \" End:\" + end);\n}\n```", "```py\ntokenStream.end();\ntokenStream.close();\n```", "```py\n    java -cp lingpipe-cookbook.1.0.jar:lib/lucene-analyzers-common-4.6.0.jar:lib/lucene-core-4.6.0.jar:lib/lingpipe-4.1.0.jar com.lingpipe.cookbook.chapter2.LuceneAnalyzerTokenizerFactory\n\n    ```", "```py\n    String text = \"Hi how are you? \" + \"Are the numbers 1 2 3 4.5 all integers?\";\n    Analyzer analyzer = new StandardAnalyzer(Version.LUCENE_46);\n    TokenizerFactory tokFactory = new LuceneAnalyzerTokenizerFactory(analyzer, \"DEFAULT\");\n    Tokenizer tokenizer = tokFactory.tokenizer(text.toCharArray(), 0, text.length());\n\n    String token = null;\n    while ((token = tokenizer.nextToken()) != null) {\n      String ws = tokenizer.nextWhitespace();\n      System.out.println(\"Token:'\" + token + \"'\");\n      System.out.println(\"WhiteSpace:'\" + ws + \"'\");\n    }\n    ```", "```py\n    Token:'hi'\n    WhiteSpace:'default'\n    Token:'how'\n    WhiteSpace:'default'\n    Token:'you'\n    WhiteSpace:'default'\n    Token:'numbers'\n    WhiteSpace:'default'\n\n    ```", "```py\npublic class LuceneAnalyzerTokenizerFactory implements TokenizerFactory, Serializable {\n\n  private static final long serialVersionUID = 8376017491713196935L;\n  private Analyzer analyzer;\n  private String field;\n  public LuceneAnalyzerTokenizerFactory(Analyzer analyzer, String field) {\n    super();\n    this.analyzer = analyzer;\n    this.field = field;\n  }\n```", "```py\npublic Tokenizer tokenizer(char[] charSeq , int start, int length) {\n  Reader reader = new CharArrayReader(charSeq,start,length);\n  TokenStream tokenStream = analyzer.tokenStream(field,reader);\n  return new LuceneTokenStreamTokenizer(tokenStream);\n}\n```", "```py\nstatic class LuceneTokenStreamTokenizer extends Tokenizer {\n  private TokenStream tokenStream;\n  private CharTermAttribute termAttribute;\n  private OffsetAttribute offsetAttribute;\n\n  private int lastTokenStartPosition = -1;\n  private int lastTokenEndPosition = -1;\n\n  public LuceneTokenStreamTokenizer(TokenStream ts) {\n    tokenStream = ts;\n    termAttribute = tokenStream.addAttribute(\n      CharTermAttribute.class);\n    offsetAttribute = tokenStream.addAttribute(OffsetAttribute.class);\n  }\n```", "```py\n@Override\npublic String nextToken() {\n  try {\n    if (tokenStream.incrementToken()){\n      lastTokenStartPosition = offsetAttribute.startOffset();\n      lastTokenEndPosition = offsetAttribute.endOffset();\n      return termAttribute.toString();\n    } else {\n      endAndClose();\n      return null;\n    }\n  } catch (IOException e) {\n    endAndClose();\n    return null;\n  }\n}\n```", "```py\n@Override\npublic String nextWhitespace() {â€©  return \"default\";\n}\n```", "```py\n    Token:'3.14'\n    WhiteSpace:' '\n    Token:'is'\n    WhiteSpace:' '\n    Token:'pi'\n    WhiteSpace:''\n    Token:'.'\n    WhiteSpace:''.\n\n    ```", "```py\n    public static void main(String[] args) {\n      String pattern = \"[a-zA-Z]+|[0-9]+|\\\\S\";\n      TokenizerFactory tokFactory = new RegExTokenizerFactory(pattern);\n      String[] tokens = {\"Tokenizers\",\"need\",\"unit\",\"tests\",\".\"};\n      String text = \"Tokenizers need unit tests.\";\n      checkTokens(tokFactory,text,tokens);\n      String[] whiteSpaces = {\" \",\" \",\" \",\"\",\"\"};\n      checkTokensAndWhiteSpaces(tokFactory,text,tokens,whiteSpaces);\n      System.out.println(\"All tests passed!\");\n    }\n    ```", "```py\n    static void checkTokens(TokenizerFactory tokFactory, String string, String[] correctTokens) {\n      Tokenizer tokenizer = tokFactory.tokenizer(input.toCharArray(),0,input.length());\n      String[] tokens = tokenizer.tokenize();\n      if (tokens.length != correctTokens.length) {\n        System.out.println(\"Token list lengths do not match\");\n        System.exit(-1);\n      }\n      for (int i = 0; i < tokens.length; ++i) {\n        if (!correctTokens[i].equals(tokens[i])) {\n          System.out.println(\"Token mismatch: got |\" + tokens[i] + \"|\");\n          System.out.println(\" expected |\" + correctTokens[i] + \"|\" );\n          System.exit(-1);\n        }\n      }\n    ```", "```py\njava -cp \"lingpipe-cookbook.1.0.jar:lib/lingpipe-4.1.0.jar\" com.lingpipe.cookbook.chapter2.Rot13TokenizerFactory\n\ntype a sentence below to see the tokens and white spaces:\nMove along, nothing to see here.\nToken:'zbir'\nToken:'nybat'\nToken:','\nToken:'abguvat'\nToken:'gb'\nToken:'frr'\nToken:'urer'\nToken:'.'\nModified Output: zbir nybat, abguvat gb frr urer.\ntype a sentence below to see the tokens and white spaces:\nzbir nybat, abguvat gb frr urer.\nToken:'move'\nToken:'along'\nToken:','\nToken:'nothing'\nToken:'to'\nToken:'see'\nToken:'here'\nToken:'.'\nModified Output: move along, nothing to see here.\n\n```", "```py\npublic class Rot13TokenizerFactory extends ModifyTokenTokenizerFactory{\n\n  public Rot13TokenizerFactory(TokenizerFactory f) {\n    super(f);\n  }\n\n  @Override\n  public String modifyToken(String tok) {\n    return rot13(tok);\n  }\n\n  public static void main(String[] args) throws IOException {\n\n  TokenizerFactory tokFactory = IndoEuropeanTokenizerFactory.INSTANCE;\n  tokFactory = new LowerCaseTokenizerFactory(tokFactory);\n  tokFactory = new Rot13TokenizerFactory(tokFactory);\n```", "```py\npublic static String rot13(String input) {\n  StringBuilder sb = new StringBuilder();\n  for (int i = 0; i < input.length(); i++) {\n    char c = input.charAt(i);\n    if       (c >= 'a' && c <= 'm') c += 13;\n    else if  (c >= 'A' && c <= 'M') c += 13;\n    else if  (c >= 'n' && c <= 'z') c -= 13;\n    else if  (c >= 'N' && c <= 'Z') c -= 13;\n    sb.append(c);\n  }\n  return sb.toString();\n}\n```", "```py\n    java -cp lingpipe-cookbook.1.0.jar:lib/lingpipe-4.1.0.jar com.lingpipe.cookbook.chapter2.TokenizeWithoutWhiteSpaces\n    Type an Englese sentence (English without spaces like Chinese):\n    TheraininSpainfallsmainlyontheplain\n\n    ```", "```py\n    The rain in Spain falls mainly on the plain\n    ```", "```py\n    type an Englese sentence (English without spaces like Chinese)\n    NGramProcessLMlm=newNGramProcessLM(nGram);\n    NGram Process L Mlm=new NGram Process L M(n Gram);\n\n    ```", "```py\n    java -cp lingpipe-cookbook.1.0.jar:lib/lingpipe-4.1.0.jar com.lingpipe.cookbook.chapter2.TokenizeWithoutWhiteSpaces data/cookbookSource.txt\n    Compiling Spell Checker\n    type an Englese sentence (English without spaces like Chinese)\n    NGramProcessLMlm=newNGramProcessLM(nGram);\n    NGramProcessLM lm = new NGramProcessLM(nGram);\n\n    ```", "```py\npublic static void main (String[] args) throws IOException, ClassNotFoundException {\n  int nGram = 5;\n  NGramProcessLM lm = new NGramProcessLM(nGram);\n  WeightedEditDistance spaceInsertingEditDistance\n    = CompiledSpellChecker.TOKENIZING;\n  TrainSpellChecker trainer = new TrainSpellChecker(lm, spaceInsertingEditDistance);\n```", "```py\nFile trainingFile = new File(args[0]);\nString training = Files.readFromFile(trainingFile, Strings.UTF8);\ntraining = training.replaceAll(\"\\\\s+\", \" \");\ntrainer.handle(training);\n```", "```py\nSystem.out.println(\"Compiling Spell Checker\");\nCompiledSpellChecker spellChecker = (CompiledSpellChecker)AbstractExternalizable.compile(trainer);\n\nspellChecker.setAllowInsert(true);\nspellChecker.setAllowMatch(true);\nspellChecker.setAllowDelete(false);\nspellChecker.setAllowSubstitute(false);\nspellChecker.setAllowTranspose(false);\nspellChecker.setNumConsecutiveInsertionsAllowed(1);\n```", "```py\nBufferedReader reader = new BufferedReader(new InputStreamReader(System.in));\nwhile (true) {\n  System.out.println(\"type an Englese sentence (English \" + \"without spaces like Chinese)\"));\n  String input = reader.readLine();\n  String result = spellChecker.didYouMean(input);\n  System.out.println(result);\n}\n```"]