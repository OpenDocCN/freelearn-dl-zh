["```py\n#You can retrieve your API key from a file(1)\n# or enter it manually(2)\n#Comment this cell if you want to enter your key manually.\n#(1)Retrieve the API Key from a file\n#Store you key in a file and read it(you can type it directly in the notebook but it will be visible for somebody next to you)\nfrom google.colab import drive\ndrive.mount('/content/drive')\nf = open(\"drive/MyDrive/files/api_key.txt\", \"r\")\nAPI_KEY=f.readline()\nf.close() \n```", "```py\ntry:\n  import openai\nexcept:\n  !pip install openai==1.42.0\n  import openai\n#(2) Enter your manually by\n# replacing API_KEY by your key.\n#The OpenAI Key\nimport os\nos.environ['OPENAI_API_KEY'] =API_KEY\nopenai.api_key = os.getenv(\"OPENAI_API_KEY\") \n```", "```py\n!pip install jsonlines==4.0.0 \n```", "```py\n!pip install datasets==2.20.0 \n```", "```py\n# Import required libraries\nfrom datasets import load_dataset\nimport pandas as pd\n# Load the SciQ dataset from HuggingFace\ndataset_view = load_dataset(\"sciq\", split=\"train\")\n# Filter the dataset to include only questions with support and correct answer\nfiltered_dataset = dataset_view.filter(lambda x: x[\"support\"] != \"\" and x[\"correct_answer\"] != \"\")\n# Print the number of questions with support\nprint(\"Number of questions with support: \", len(filtered_dataset)) \n```", "```py\nNumber of questions with support:  10481 \n```", "```py\n# Convert the filtered dataset to a pandas DataFrame\ndf_view = pd.DataFrame(filtered_dataset)\n# Columns to drop\ncolumns_to_drop = ['distractor3', 'distractor1', 'distractor2']\n# Dropping the columns from the DataFrame\ndf_view = df.drop(columns=columns_to_drop)\n# Display the DataFrame\ndf_view.head() \n```", "```py\n# Prepare the data items for JSON lines file\nitems = []\nfor idx, row in df.iterrows():\n    detailed_answer = row['correct_answer'] + \" Explanation: \" + row['support']\n    items.append({\n        \"messages\": [\n            {\"role\": \"system\", \"content\": \"Given a science question, provide the correct answer with a detailed explanation.\"},\n            {\"role\": \"user\", \"content\": row['question']},\n            {\"role\": \"assistant\", \"content\": detailed_answer}\n        ]\n    }) \n```", "```py\n# Write to JSON lines file\nwith jsonlines.open('/content/QA_prompts_and_completions.json', 'w') as writer:\n    writer.write_all(items) \n```", "```py\ndfile=\"/content/QA_prompts_and_completions.json\"\nimport pandas as pd\n# Load the data\ndf = pd.read_json(dfile, lines=True)\ndf \n```", "```py\nfrom openai import OpenAI\nimport jsonlines\nclient = OpenAI() \n```", "```py\n# Uploading the training file\nresult_file = client.files.create(\n  file=open(\"QA_prompts_and_completions.json\", \"rb\"),\n  purpose=\"fine-tune\"\n) \n```", "```py\nprint(result_file)\nparam_training_file_name = result_file.id\nprint(param_training_file_name) \n```", "```py\n# Creating the fine-tuning job\n\nft_job = client.fine_tuning.jobs.create(\n  training_file=param_training_file_name,\n  model=\"gpt-4o-mini-2024-07-18\"\n)\n# Printing the fine-tuning job\nprint(ft_job) \n```", "```py\nFileObject(id='file-EUPGmm1yAd3axrQ0pyoeAKuE', bytes=8062970, created_at=1725289249, filename='QA_prompts_and_completions.json', object='file', purpose='fine-tune', status='processed', status_details=None) file-EUPGmm1yAd3axrQ0pyoeAKuE \n```", "```py\nFineTuningJob(id='ftjob-O1OEE7eEyFNJsO2Eu5otzWA8', created_at=1725289250, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-h2Kjmcir4wyGtqq1mJALLGIb', result_files=[], seed=1103096818, status='validating_files', trained_tokens=None, training_file='file-EUPGmm1yAd3axrQ0pyoeAKuE', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None) \n```", "```py\nimport pandas as pd\nfrom openai import OpenAI\nclient = OpenAI()\n# Assume client is already set up and authenticated\nresponse = client.fine_tuning.jobs.list(limit=3) # increase to include your history \n```", "```py\n# Initialize lists to store the extracted data\njob_ids = []\ncreated_ats = []\nstatuses = []\nmodels = []\ntraining_files = []\nerror_messages = []\nfine_tuned_models = [] # List to store the fine-tuned model names \n```", "```py\n# Iterate over the jobs in the response\nfor job in response.data:\n    job_ids.append(job.id)\n    created_ats.append(job.created_at)\n    statuses.append(job.status)\n    models.append(job.model)\n    training_files.append(job.training_file)\n    error_message = job.error.message if job.error else None\n    error_messages.append(error_message)\n# Append the fine-tuned model name\n    fine_tuned_model = job.fine_tuned_model if hasattr(job, 'fine_tuned_model')\n    else None\n    fine_tuned_models.append(fine_tuned_model) \n```", "```py\nimport pandas as pd\n# Assume client is already set up and authenticated\nresponse = client.fine_tuning.jobs.list(limit=3)\n# Create a DataFrame\ndf = pd.DataFrame({\n    'Job ID': job_ids,\n    'Created At': created_ats,\n    'Status': statuses,\n    'Model': models,\n    'Training File': training_files,\n    'Error Message': error_messages,\n    'Fine-Tuned Model': fine_tuned_models # Include the fine-tuned model names\n}) \n```", "```py\n# Convert timestamps to readable format\ndf['Created At'] = pd.to_datetime(df['Created At'], unit='s')\ndf = df.sort_values(by='Created At', ascending=False)\n# Display the DataFrame\ndf \n```", "```py\nimport pandas as pd\ngeneration=False  # until the current model is fine-tuned\n# Attempt to find the first non-empty Fine-Tuned Model\nnon_empty_models = df[df['Fine-Tuned Model'].notna() & (df['Fine-Tuned Model'] != '')]\nif not non_empty_models.empty:\n    first_non_empty_model = non_empty_models['Fine-Tuned Model'].iloc[0]\n    print(\"The latest fine-tuned model is:\", first_non_empty_model)\n    generation=True\nelse:\n    first_non_empty_model='None'\n    print(\"No fine-tuned models found.\")\n# Display the first non-empty Fine-Tuned Model in the DataFrame\nfirst_non_empty_model = df[df['Fine-Tuned Model'].notna() & (df['Fine-Tuned Model'] != '')]['Fine-Tuned Model'].iloc[0]\nprint(\"The lastest fine-tuned model is:\", first_non_empty_model) \n```", "```py\nThe latest fine-tuned model is: ft:gpt-4o-mini-2024-07-18:personal::A32VfYIz \n```", "```py\n# Define the prompt\nprompt = \"What phenomenon makes global winds blow northeast to southwest or the reverse in the northern hemisphere and northwest to southeast or the reverse in the southern hemisphere?\" \n```", "```py\n# Assume first_non_empty_model is defined above this snippet\nif generation==True:\n    response = client.chat.completions.create(\n        model=first_non_empty_model,\n        temperature=0.0,  # Adjust as needed for variability\n        messages=[\n            {\"role\": \"system\", \"content\": \"Given a question, reply with a complete explanation for students.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n    )\nelse:\n    print(\"Error: Model is None, cannot proceed with the API request.\") \n```", "```py\nif generation==True:\n  print(response) \n```", "```py\nChatCompletion(id='chatcmpl-A32pvH9wLvNsSRmB1sUjxOW4Z6Xr6',… \n```", "```py\nif (generation==True):\n  # Access the response from the first choice\n  response_text = response.choices[0].message.content\n  # Print the response\n  print(response_text) \n```", "```py\nCoriolis effect Explanation: The Coriolis effect is… \n```", "```py\nimport textwrap\nif generation==True:\nwrapped_text = textwrap.fill(response_text.strip(), 60)\nprint(wrapped_text) \n```", "```py\nCoriolis effect Explanation: The Coriolis effect is a\nphenomenon that causes moving objects, such as air and\nwater, to turn and twist in response to the rotation of the\nEarth. It is responsible for the rotation of large weather\nsystems, such as hurricanes, and the direction of trade\nwinds and ocean currents. In the Northern Hemisphere, the\neffect causes moving objects to turn to the right, while in\nthe Southern Hemisphere, objects turn to the left. The\nCoriolis effect is proportional to the speed of the moving\nobject and the strength of the Earth's rotation, and it is\nnegligible for small-scale movements, such as water flowing\nin a sink. \n```"]