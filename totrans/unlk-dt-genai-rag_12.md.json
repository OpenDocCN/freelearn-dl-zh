["```py\n    <st c=\"11004\">%pip install tiktoken</st>\n    ```", "```py\n    <st c=\"11084\">tiktoken</st> package, which is an OpenAI package used for tokenizing text data before feeding it into language models. Last, we pull in the <st c=\"11220\">langgraph</st> package we have been discussing.\n    ```", "```py\n    <st c=\"11325\">llm = ChatOpenAI(model_name=\"gpt-4o-mini\",</st>\n    ```", "```py\n     <st c=\"11368\">temperature=0, streaming=True)</st>\n    ```", "```py\n    <st c=\"11399\">agent_llm = ChatOpenAI(model_name=\"gpt-4o-mini\",</st>\n    ```", "```py\n     <st c=\"11448\">temperature=0, streaming=True)</st>\n    ```", "```py\n from langchain_community.tools.tavily_search import TavilySearchResults\n_ = load_dotenv(dotenv_path='env.txt')\nos.environ['TAVILY_API_KEY'] = os.getenv('TAVILY_API_KEY')\n!export TAVILY_API_KEY=os.environ['TAVILY_API_KEY']\nweb_search = TavilySearchResults(max_results=4)\nweb_search_name = web_search.name\n```", "```py\n web_search.invoke(user_query)\n```", "```py\n [{'url': 'http://sustainability.google/',\n  'content': \"Google Maps\\nChoose the most fuel-efficient route\\nGoogle Shopping\\nShop for more efficient appliances for your home\\nGoogle Flights\\nFind a flight with lower per-traveler carbon emissions\\nGoogle Nest\\...[TRUNCATED HERE]\"},\nâ€¦\n  'content': \"2023 Environmental Report. Google's 2023 Environmental Report outlines how we're driving positive environmental outcomes throughout our business in three key ways: developing products and technology that empower individuals on their journey to a more sustainable life, working together with partners and organizations everywhere to transition to resilient, low-carbon systems, and operating ...\"}]\n```", "```py\n from langchain.tools.retriever import create_retriever_tool\nretriever_tool = create_retriever_tool(\n    ensemble_retriever,\n    \"retrieve_google_environmental_question_answers\",\n    \"Extensive information about Google environmental\n     efforts from 2023.\",\n)\nretriever_tool_name = retriever_tool.name\n```", "```py\n tools = [web_search, retriever_tool]\n```", "```py\n from typing import Annotated, Literal, Sequence, TypedDict\nfrom langchain_core.messages import BaseMessage\nfrom langgraph.graph.message import add_messages\nclass AgentState(TypedDict):\n    messages: Annotated[Sequence[BaseMessage],\n                        add_messages]\n```", "```py\n from langchain_core.messages import HumanMessage\nfrom langchain_core.pydantic_v1 import BaseModel, Field\nfrom langgraph.prebuilt import tools_condition\n```", "```py\n generation_prompt = PromptTemplate.from_template(\n    \"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer\n    the question. If you don't know the answer, just say\n    that you don't know. Provide a thorough description to\n    fully answer the question, utilizing any relevant\n    information you find. Question: {question}\n    Context: {context}\n    Answer:\"\"\"\n)\n```", "```py\n prompt = hub.pull(\"jclemens24/rag-prompt\")\n```", "```py\n     def score_documents(state) -> Literal[\n    ```", "```py\n     \"generate\", \"improve\"]:\n    ```", "```py\n     class scoring(BaseModel):\n    ```", "```py\n     binary_score: str = Field(\n    ```", "```py\n     description=\"Relevance score 'yes' or 'no'\")\n    ```", "```py\n     llm_with_tool = llm.with_structured_output(\n    ```", "```py\n     scoring)\n    ```", "```py\n     prompt = PromptTemplate(\n    ```", "```py\n     template=\"\"\"You are assessing relevance of a retrieved document to a user question with a binary grade. Here is the retrieved document:\n    ```", "```py\n     {context}\n    ```", "```py\n     Here is the user question: {question}\n    ```", "```py\n     If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\",\n    ```", "```py\n     input_variables=[\"context\", \"question\"],\n    ```", "```py\n     )\n    ```", "```py\n     chain = prompt | llm_with_tool\n    ```", "```py\n     messages = state[\"messages\"]\n    ```", "```py\n     last_message = messages[-1]\n    ```", "```py\n     question = messages[0].content\n    ```", "```py\n     docs = last_message.content\n    ```", "```py\n     scored_result = chain.invoke({\"question\":\n    ```", "```py\n     question, \"context\": docs})\n    ```", "```py\n     score = scored_result.binary_score\n    ```", "```py\n     if score == \"yes\":\n    ```", "```py\n     print(\"---DECISION: DOCS RELEVANT---\")\n    ```", "```py\n     return \"generate\"\n    ```", "```py\n     else:\n    ```", "```py\n     print(\"---DECISION: DOCS NOT RELEVANT---\")\n    ```", "```py\n     print(score)\n    ```", "```py\n     return \"improve\"\n    ```", "```py\n     def agent(state):\n    ```", "```py\n     print(\"---CALL AGENT---\")\n    ```", "```py\n     messages = state[\"messages\"]\n    ```", "```py\n     llm = llm.bind_tools(tools)\n    ```", "```py\n     response = llm.invoke(messages)\n    ```", "```py\n     return {\"messages\": [response]}\n    ```", "```py\n     def improve(state):\n    ```", "```py\n     print(\"---TRANSFORM QUERY---\")\n    ```", "```py\n     messages = state[\"messages\"]\n    ```", "```py\n     question = messages[0].content\n    ```", "```py\n     msg = [\n    ```", "```py\n     HumanMessage(content=f\"\"\"\\n\n    ```", "```py\n     Look at the input and try to reason about\n    ```", "```py\n     the underlying semantic intent / meaning.\n    ```", "```py\n     \\n\n    ```", "```py\n     Here is the initial question:\n    ```", "```py\n     \\n ------- \\n\n    ```", "```py\n     {question}\n    ```", "```py\n     \\n ------- \\n\n    ```", "```py\n     Formulate an improved question:\n    ```", "```py\n     \"\"\",\n    ```", "```py\n     )\n    ```", "```py\n     ]\n    ```", "```py\n     response = llm.invoke(msg)\n    ```", "```py\n     return {\"messages\": [response]}\n    ```", "```py\n     def generate(state):\n    ```", "```py\n     print(\"---GENERATE---\")\n    ```", "```py\n     messages = state[\"messages\"]\n    ```", "```py\n     question = messages[0].content\n    ```", "```py\n     last_message = messages[-1]\n    ```", "```py\n     question = messages[0].content\n    ```", "```py\n     docs = last_message.content\n    ```", "```py\n     rag_chain = generation_prompt | llm |\n    ```", "```py\n     str_output_parser\n    ```", "```py\n     response = rag_chain.invoke({\"context\": docs,\n    ```", "```py\n     \"question\": question})\n    ```", "```py\n     return {\"messages\": [response]}\n    ```", "```py\n     from langgraph.graph import END, StateGraph\n    ```", "```py\n     from langgraph.prebuilt import ToolNode\n    ```", "```py\n     workflow = StateGraph(AgentState)\n    ```", "```py\n     workflow.add_node(\"agent\", agent)  # agent\n    ```", "```py\n     retrieve = ToolNode(tools)\n    ```", "```py\n     workflow.add_node(\"retrieve\", retrieve)\n    ```", "```py\n     # retrieval from web and or retriever\n    ```", "```py\n     workflow.add_node(\"improve\", improve)\n    ```", "```py\n     # Improving the question for better retrieval\n    ```", "```py\n     workflow.add_node(\"generate\", generate)  # Generating a response after we know the documents are relevant\n    ```", "```py\n     workflow.set_entry_point(\"agent\")\n    ```", "```py\n     workflow.add_conditional_edges(\"agent\", tools_condition,\n    ```", "```py\n     {\n    ```", "```py\n     \"tools\": \"retrieve\",\n    ```", "```py\n     END: END,\n    ```", "```py\n     },\n    ```", "```py\n     )\n    ```", "```py\n     workflow.add_conditional_edges(\"retrieve\",\n    ```", "```py\n     score_documents)\n    ```", "```py\n     workflow.add_edge(\"generate\", END)\n    ```", "```py\n     workflow.add_edge(\"improve\", \"agent\")\n    ```", "```py\n     graph = workflow.compile()\n    ```", "```py\n     from IPython.display import Image, display\n    ```", "```py\n     try:\n    ```", "```py\n     display(Image(graph.get_graph(\n    ```", "```py\n     xray=True).draw_mermaid_png()))\n    ```", "```py\n     except:\n    ```", "```py\n     pass\n    ```", "```py\n     import pprint\n    ```", "```py\n     inputs = {\n    ```", "```py\n     \"messages\": [\n    ```", "```py\n     (\"user\", user_query),\n    ```", "```py\n     ]\n    ```", "```py\n     }\n    ```", "```py\n     final_answer = ''\n    ```", "```py\n     for output in graph.stream(inputs):\n    ```", "```py\n     for key, value in output.items():\n    ```", "```py\n     pprint.pprint(f\"Output from node '{key}':\")\n    ```", "```py\n     pprint.pprint(\"---\")\n    ```", "```py\n     pprint.pprint(value, indent=2, width=80,\n    ```", "```py\n     depth=None)\n    ```", "```py\n     final_answer = value\n    ```", "```py\n     ---CALL AGENT---\n    ```", "```py\n     \"Output from node 'agent':\"\n    ```", "```py\n     '---'\n    ```", "```py\n     { 'messages': [ AIMessage(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_46NqZuz3gN2F9IR5jq0MRdVm', 'function': {'arguments': '{\"query\":\"Google\\'s environmental initiatives\"}', 'name': 'retrieve_google_environmental_question_answers'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls'}, id='run-eba27f1e-1c32-4ffc-a161-55a32d645498-0', tool_calls=[{'name': 'retrieve_google_environmental_question_answers', 'args': {'query': \"Google's environmental initiatives\"}, 'id': 'call_46NqZuz3gN2F9IR5jq0MRdVm'}])]}\n    ```", "```py\n     '\\n---\\n'\n    ```", "```py\n     ---CHECK RELEVANCE---\n    ```", "```py\n     ---DECISION: DOCS RELEVANT---\n    ```", "```py\n     \"Output from node 'retrieve':\"\n    ```", "```py\n     '---'\n    ```", "```py\n     { 'messages': [ ToolMessage(content='iMasons Climate AccordGoogle is a founding member and part of the governing body of the iMasons Climate Accord, a coalition united on carbon reduction in digital infrastructure.\\nReFEDIn 2022, to activate industry-wide changeâ€¦[TRUNCATED]', tool_call_id='call_46NqZuz3gN2F9IR5jq0MRdVm')]}\n    ```", "```py\n     '\\n---\\n'\n    ```", "```py\n     ---GENERATE---\n    ```", "```py\n     \"Output from node 'generate':\"\n    ```", "```py\n     '---'\n    ```", "```py\n     { 'messages': [ 'Google has a comprehensive and multifaceted approach to '\n    ```", "```py\n     'environmental sustainability, encompassing various '\n    ```", "```py\n     'initiatives aimed at reducing carbon emissions, promoting'\n    ```", "```py\n     'sustainable practices, and leveraging technology for '\n    ```", "```py\n     \"environmental benefits. Here are some key aspects of Google's \"\n    ```", "```py\n     'environmental initiatives:\\n''\\n'\n    ```", "```py\n     '1\\. **Carbon Reduction and Renewable Energy**â€¦']}\n    ```", "```py\n     '\\n---\\n'\n    ```", "```py\n     final_answer['messages'][0]\n    ```", "```py\n    <st c=\"43288\">\"Google has a comprehensive and multifaceted approach to environmental sustainability, encompassing various initiatives aimed at reducing carbon emissions, promoting sustainable practices, and leveraging technology for environmental benefits.</st> <st c=\"43532\">Here are some key aspects of Google's environmental initiatives:\\n\\n1\\.</st> <st c=\"43603\">**Carbon Reduction and Renewable Energy**:\\n   - **iMasons Climate Accord**: Google is a founding member and part of the governing body of this coalition focused on reducing carbon emissions in digital infrastructure.\\n   - **Net-Zero Carbon**: Google is committed to operating sustainably with a focus on achieving net-zero carbon emissions.</st> <st c=\"43942\">This includes investments in carbon-free energy and energy-efficient facilities, such as their all-electric, net water-positive Bay View campus...\"</st>\n    ```"]