<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Section 2: Exploiting the Knowledge</h1>
                </header>
            
            <article>
                
<p class="mce-root"><span>After exploring the basics of RL and using it in toy environments, it is time to take our agents to the next level with the addition of deep learning and several other advanced methods.</span></p>
<p>This section contains the following chapters:</p>
<ul>
<li><a href="a9e9aefb-40af-4886-9b4f-94e725dd2f92.xhtml">Chapter 6</a>, <em>Going Deep with DQN</em></li>
<li><a href="42d53358-6f57-4f67-96ce-d8587cbe7cc5.xhtml">Chapter 7</a>, <em>Going Deeper with DDQN</em></li>
<li><a href="42626cbd-87b8-428c-8f2a-ecc06f5e387c.xhtml">Chapter 8</a>, <em>Policy Gradient Methods</em></li>
<li><a href="2f6812c0-fd1f-4eda-9df2-6c67c8077aec.xhtml">Chapter 9</a>, <em>Optimizing for Continuous Control</em></li>
<li><a href="1fbfb255-7fd9-44ea-8d02-f385e95d88d2.xhtml">Chapter 10</a>, <em>All Together Rainbow DQN</em></li>
<li><a href="ab9a7f4f-60d8-4643-8627-199cf95bcf55.xhtml">Chapter 11</a>, <em>Exploiting ML-Agents</em></li>
<li><a href="6d061d35-176a-421a-9b62-aed35f48a6b7.xhtml">Chapter 12</a>, <em>DRL Frameworks</em></li>
</ul>


            </article>

            
        </section>
    </body></html>