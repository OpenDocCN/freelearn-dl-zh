- en: '11'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Image Restore and Super-Resolution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While both Stable Diffusion V1.5 and Stable Diffusion XL have demonstrated abilities
    in generating images, our initial creations might not yet exhibit their utmost
    quality. This chapter aims to explore various techniques and strategies that can
    elevate image restoration, amplify image resolution, and introduce intricate details
    to produced visuals.
  prefs: []
  type: TYPE_NORMAL
- en: The primary focus of this chapter lies in leveraging the potential of Stable
    Diffusion as an effective tool to enhance and upscale images. Furthermore, we
    will briefly introduce you to complementary cutting-edge **Artificial Intelligence**
    (**AI**) methodologies to boost image resolutions, which are distinct from diffusion-based
    processes.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the terminologies
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Upscaling images using an image-to-image diffusion pipeline
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Upscaling images using ControlNet Tile
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s start!
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the terminologies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before we begin using Stable Diffusion to enhance image quality, it is beneficial
    to understand the common terminologies associated with this process. Three related
    terms you may encounter in articles or books on Stable Diffusion are **image interpolation**,
    **image upscale**, and **image super-resolution**. These techniques aim to improve
    the resolution of an image, but they differ in their methods and outcomes. Familiarizing
    yourself with these terms will help you better understand how Stable Diffusion
    and other image enhancement tools work:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Image interpolation** stands out as the simplest and most prevalent method
    to upscale images. It functions by approximating new pixel values based on the
    existing pixels within an image. Various interpolation methods exist, each with
    its strengths and weaknesses. Some of the most commonly used interpolation methods
    include nearest-neighbor interpolation [6], bilinear interpolation [7], bicubic
    interpolation [8], and Lanczos resampling [9].'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Image upscale** is a broader term encompassing any technique that augments
    an image’s resolution. This category includes interpolation methods, as well as
    more sophisticated approaches such as super-resolution.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Image super-resolution** represents a specific subset of image upscaling
    aimed at enhancing an image’s resolution and finer details beyond its original
    dimensions while minimizing quality loss and preventing artifacts. In contrast
    to conventional image upscaling methods, which rely on basic interpolation, image
    super-resolution employs advanced algorithms, often based on deep learning techniques.
    These algorithms learn high-frequency patterns and details from a dataset of high-resolution
    images. Subsequently, these learned patterns are employed to upscale low-resolution
    images, producing superior-quality results.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A solution to the aforementioned tasks (image interpolation, image upscale,
    and image super-resolution) is commonly referred to as an **upscaler** or a **high-res
    fixer**. We will use the term *upscaler* throughout the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Among the deep learning-based solutions for super-resolution, various types
    of upscalers exist. Super-resolution solutions can be broadly classified into
    three types:'
  prefs: []
  type: TYPE_NORMAL
- en: GAN-based solutions such as ESRGAN [10]
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Swin Transformer-based solutions such as SwinIR [11],
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stable Diffusion-based solutions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this chapter, our primary focus will be on the Stable Diffusion upscaler.
    This choice is driven not only by the book’s emphasis on the diffusion model but
    also by the potential of Stable Diffusion to provide enhanced upscale results
    and superior control flexibility. For instance, it allows us to direct the super-resolution
    process with prompts and fill in additional details. We will implement this using
    Python code in the latter part of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: You might be eager to start utilizing the Latent Upscaler and Stable Diffusion
    Upscale pipeline [1] from Diffusers. However, it’s worth noting that the current
    Latent Upscaler and Upscale pipeline are not optimal. Both rely heavily on a specific
    pre-trained model, consume a substantial amount of VRAM, and exhibit relatively
    slower performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter will introduce two alternative solutions based on the Stable Diffusion
    approach:'
  prefs: []
  type: TYPE_NORMAL
- en: '`StableDiffusionPipeline` class. It also retains support for lengthy prompts
    and incorporates Textual Inversion, as introduced in previous chapters.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ControlNet` model, it becomes possible to achieve image super-resolution with
    remarkable enhancements in detail.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With this background, let’s delve into the intricate details of these two super-resolution
    methods.
  prefs: []
  type: TYPE_NORMAL
- en: Upscaling images using Img2img diffusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we discussed in [*Chapter 5*](B21263_05.xhtml#_idTextAnchor097), Stable Diffusion
    doesn’t solely rely on text as its initial guidance; it is also capable of utilizing
    an image as the starting point. We implemented a custom pipeline that employs
    an image as the foundation for image generation.
  prefs: []
  type: TYPE_NORMAL
- en: By reducing the denoising strength to a certain threshold, such as `0.3`, the
    features and style of the initial image persist in the final generated image.
    This property can be exploited to employ Stable Diffusion as an image upscaler,
    thereby enabling image super-resolution. Let’s explore this process step by step.
  prefs: []
  type: TYPE_NORMAL
- en: We will begin by introducing the concept of one-step super-resolution, followed
    by an exploration of multiple-step super-resolution.
  prefs: []
  type: TYPE_NORMAL
- en: One-step super-resolution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we will cover a solution to upscale images using image-to-image
    diffusion once. Here are the step-by-step instructions to implement it:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s start by generating a 256x256 start image using Stable Diffusion. Instead
    of downloading an image from the internet or utilizing an external image as the
    input, let’s leverage Stable Diffusion to generate one. After all, this is the
    area where Stable Diffusion excels:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The preceding code will generate an image, as shown in *Figure 11**.1*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 11.1: A photo of a woman’s face sized 256x256, generated by Stable
    Diffusion](img/B21263_11_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.1: A photo of a woman’s face sized 256x256, generated by Stable Diffusion'
  prefs: []
  type: TYPE_NORMAL
- en: You may not be able to see the noise and blur in the image if you view it in
    a printed form (e.g., a paper book). However, if you run the preceding code and
    enlarge the image, you can easily notice the *blur* and *noise* in the generated
    image.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s save the image for further processing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Resize the image to the target size. Initially, we need to establish a function
    for image adjustment, ensuring that the image’s width and height are both divisible
    by `8`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, resize it to the target size using image interpolation:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The following code employs the `resize_img` function to resize an image threefold:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Feel free to input any floating-point number greater than `1.0` into the function.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create an img-to-img pipeline as the upscaler. To enable guided image super-resolution,
    we need to provide a guided prompt, as shown here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`sr_prompt` means **super-resolution prompt** and can be resused without changing
    the same for any super-resolution tasks. Next, call the pipeline to upscale the
    image:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note that the `strength` parameter is set to `0.3`, meaning that each denoising
    step applies 30% Gaussian noise to the latent. When utilizing the plain text-to-image
    pipeline, the strength is set to `1.0` by default. By increasing the `strength`
    value here, more `new` elements will be introduced to the initial image. From
    my testing, `0.3` seems to strike a well-balanced point. However, you have the
    flexibility to adjust it to values such as `0.25` or elevate it to `0.4`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: For an img-to-img pipeline from Diffusers, the actual denoising steps will be
    a multiplication of `num_inference_steps` by `strength`. The total denoising steps
    will be 80 × 0.3 = 24\. This is not a rule enforced by Stable Diffusion; it is
    sourced from the implementation of Diffusers’ Stable Diffusion pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: As explained in [*Chapter 3*](B21263_03.xhtml#_idTextAnchor064), the `guidance_scale`
    parameter governs how closely the result aligns with the provided `prompt` and
    `neg_prompt`. In practice, a higher `guidance_scale` will yield a slightly clearer
    image but may also alter the image elements more, while a lower `guidance_scale`
    will lead to a more blurred image while preserving more original image elements.
    If you’re uncertain about the value, opt for something between 7 and 8.
  prefs: []
  type: TYPE_NORMAL
- en: Once you run the preceding code, you’ll observe that not only does the size
    of the original image upscale to 768x768 but the image quality also experiences
    a significant enhancement.
  prefs: []
  type: TYPE_NORMAL
- en: However, this is not the end; we can reuse the preceding process to further
    improve image resolution and quality.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s save the image for further usage:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: Next, let’s upscale the image using multiple image-to-image steps.
  prefs: []
  type: TYPE_NORMAL
- en: Multiple-step super-resolution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Using the one-step resolution, the code upscales the image from 256x256 to 768x768\.
    In this section, we’re taking the process a step further by increasing the image
    size to double its current dimensions.
  prefs: []
  type: TYPE_NORMAL
- en: Note that before progressing to an even higher resolution image, you need to
    ensure that the utilization of VRAM might necessitate more than 8 GB.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will primarily be reusing the code from the one-step super-resolution process:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Double the size of the image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE58]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Further image super-resolution code can be applied to increase the resolution
    of an image by six times (256x256 to 1,536x1,536), which can significantly enhance
    the clarity and details of the image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE60]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE61]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE63]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE64]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE65]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE66]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE67]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE68]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE69]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE70]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE71]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE72]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE73]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE74]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The preceding code will produce an image that is six times the size of the original,
    greatly enhancing its quality.
  prefs: []
  type: TYPE_NORMAL
- en: A super-resolution result comparison
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now, let’s examine the six-times-upscaled image and compare it with the original
    image to see how much the image quality has improved.
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 11**.2* provides a side-by-side comparison of the original image and
    the six-times-upscaled super-resolution image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.2: Left – the original raw image, and right – the image with the
    six-times-upscaled super-resolution](img/B21263_11_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.2: Left – the original raw image, and right – the image with the
    six-times-upscaled super-resolution'
  prefs: []
  type: TYPE_NORMAL
- en: 'Kindly check out the ebook version to easily discern the finer enhancements.
    *Figure 11**.3* provides a clear depiction of the improvements in the mouth area:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.3: Left – the mouth from the original raw image, and right – the
    mouth from the image with six-times-upscaled super-resolution](img/B21263_11_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.3: Left – the mouth from the original raw image, and right – the
    mouth from the image with six-times-upscaled super-resolution'
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 11**.4* shows the improvements to the eyes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.4: Above – the eyes from the original raw image, and below – the
    eyes from the image with six-times-upscaled super-resolution](img/B21263_11_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.4: Above – the eyes from the original raw image, and below – the
    eyes from the image with six-times-upscaled super-resolution'
  prefs: []
  type: TYPE_NORMAL
- en: Stable Diffusion enhances nearly every aspect of the image – from the eyebrows
    and eyelashes to the pupils – resulting in substantial improvements over the original
    raw image.
  prefs: []
  type: TYPE_NORMAL
- en: Img-to-Img limitations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `deliberate-v2` Stable Diffusion model is a checkpoint model built on SD
    v1.5, and it’s trained using 512x512 images. As a result, the img-to-img pipeline
    inherits all the constraints of this model. When attempting to upscale an image
    from 1,024x1,024 to an even higher resolution, the model might not be as efficient
    as it is with lower-resolution images.
  prefs: []
  type: TYPE_NORMAL
- en: However, img-to-img is not the only available solution to generate exceptionally
    high-quality images. Next, we will explore another technique that can upscale
    images with even greater detail.
  prefs: []
  type: TYPE_NORMAL
- en: ControlNet Tile image upscaling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Stable Diffusion ControlNet is a neural network architecture designed to enhance
    diffusion models through the incorporation of additional conditions. The concept
    behind this model stems from a paper titled *Adding Conditional Control to Text-to-Image
    Diffusion Models* [3], authored by Lvmin Zhang and Maneesh Agrawala in 2023\.
    For more details about ControlNet, refer to [*Chapter 13*](B21263_13.xhtml#_idTextAnchor257).
  prefs: []
  type: TYPE_NORMAL
- en: ControlNet bears similarities to the image-to-image Stable Diffusion pipeline
    but boasts significantly greater potency.
  prefs: []
  type: TYPE_NORMAL
- en: When utilizing the img2img pipeline, we input the initial image, along with
    conditional text, to generate an image similar to the starting guidance image.
    In contrast, ControlNet employs one or more supplementary UNet models that work
    alongside the Stable Diffusion model. These UNet models process both the input
    prompt and the image concurrently, with results being merged back in each step
    of the UNet up-stage. A comprehensive exploration of ControlNet is provided in
    [*Chapter 13*](B21263_13.xhtml#_idTextAnchor257).
  prefs: []
  type: TYPE_NORMAL
- en: Compared with the image-to-image pipeline, ControlNet yields superior outcomes.
    Among the ControlNet models, ControlNet Tile stands out for its ability to upscale
    images by introducing substantial detail information to the original image.
  prefs: []
  type: TYPE_NORMAL
- en: In the subsequent code, we will employ the latest ControlNet version, 1.1\.
    The authors of the paper and model affirm that they will maintain the architecture
    consistently up until ControlNet V1.5\. At the time of reading, the most recent
    ControlNet iteration might surpass v1.1\. There’s a likelihood that you can repurpose
    the v1.1 code for later versions of ControlNet.
  prefs: []
  type: TYPE_NORMAL
- en: Steps to use ControlNet Tile to upscale an image
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Next, let’s use ControlNet Tile to upscale an image step by step:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Initialize ControlNet Tile model. The following code will start a ControlNet
    v1.1 model. Note that when ControlNet starts from v1.1, the sub-type of ControlNet
    is specified by `subfolder = ''``control_v11f1e_sd15_tile''`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE76]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE77]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE78]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE79]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE80]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE81]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We can’t simply use ControlNet itself to do anything; we will need to spin up
    a Stable Diffusion V1.5 pipeline to work together with the ControlNet model.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Initialize a Stable Diffusion v1.5 model pipeline. The primary advantage of
    using ControlNet lies in its compatibility with any checkpoint model that has
    been fine-tuned from the Stable Diffusion base model. We will continue to use
    the Stable Diffusion V1.5-based model due to its outstanding quality and relatively
    low VRAM requirements. Given these attributes, Stable Diffusion v1.5 is expected
    to retain its relevance for a considerable period:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE83]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE84]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE85]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE86]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE87]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE88]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE89]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE90]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In the provided code, we furnish `controlnet` which we initialized in *step
    1* as a parameter for the `StableDiffusionControlNetImg2ImgPipeline` pipeline.
    Additionally, the code closely resembles that of a standard Stable Diffusion pipeline.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Resize the image. This is the same step we took in the image-to-image pipeline;
    we need to enlarge the image to the target size:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE92]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE93]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE94]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The preceding code upsizes the image three times using the `LANCZOS` interpolation:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE96]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE97]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE98]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE99]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE100]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE101]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE102]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE103]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE104]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE105]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE106]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE107]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE108]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE109]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE110]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE111]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE112]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE113]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE114]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We reuse the positive prompt and negative prompt from the image-to-image upscaler.
    The distinctions are outlined here:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: We assign the raw upscaled image to both the initial diffusion image, denoted
    as `image = resized_raw_image`, and the ControlNet start image, marked as `control_image
    =` `resized_raw_image`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The strength is configured to `0.8` in order to leverage the influence of ControlNet
    on denoising, thereby enhancing the generation process.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that we can lower the strength parameter to preserve as much original image
    as possible.
  prefs: []
  type: TYPE_NORMAL
- en: The ControlNet Tile upscaling result
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'With just a single round of three-fold super-resolution, we can significantly
    enhance our image by introducing an abundance of intricate details:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.5: Left – the original raw image, and right – the ControlNet Tile
    three-times-upscaled super-resolution](img/B21263_11_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.5: Left – the original raw image, and right – the ControlNet Tile
    three-times-upscaled super-resolution'
  prefs: []
  type: TYPE_NORMAL
- en: When compared to the image-to-image upscaler, ControlNet Tile incorporates even
    more details. Upon zooming into the image, you can observe the addition of individual
    hair strands, leading to an overall improvement in image quality.
  prefs: []
  type: TYPE_NORMAL
- en: To achieve a comparable outcome, the image-to-image approach would require multiple
    steps to upscale the image sixfold. In contrast, ControlNet Tile accomplishes
    the same outcome with a single round of threefold upscaling.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, ControlNet Tile offers the advantage of relatively lower VRAM usage
    compared to the image-to-image solution.
  prefs: []
  type: TYPE_NORMAL
- en: Additional ControlNet Tile upscaling samples
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The ControlNet Tile super-resolution can produce remarkable results for a wide
    array of photos and images. Here are a few additional samples achieved by using
    just a few lines of code to generate, resize, and upscale images, capturing intricate
    details:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Man’s face**: The code to generate, resize, and upscale this image is as
    follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE115]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE116]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE117]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE118]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE119]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE120]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE121]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE122]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE123]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE124]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE125]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE126]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE127]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE128]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE129]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE130]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE131]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE132]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE133]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE134]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE135]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE136]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE137]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE138]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE139]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE140]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE141]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE142]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE143]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE144]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE145]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE146]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE147]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE148]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE149]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE150]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE151]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE152]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The result is shown in *Figure 11**.6*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 11.6: Left – the original raw image, and right – the ControlNet Tile
    three-times-upscaled super-resolution](img/B21263_11_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.6: Left – the original raw image, and right – the ControlNet Tile
    three-times-upscaled super-resolution'
  prefs: []
  type: TYPE_NORMAL
- en: '**Old man**: Here is the code to generate, resize, and upscale the image:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE153]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE154]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE155]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE156]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE157]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE158]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE159]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE160]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE161]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE162]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE163]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE164]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE165]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE166]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE167]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE168]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE169]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE170]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE171]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE172]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE173]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE174]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE175]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE176]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE177]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE178]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE179]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE180]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE181]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE182]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE183]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE184]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE185]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE186]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE187]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE188]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE189]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The result is shown in *Figure 11**.7*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 11.7: Left – the original raw image of the old man, and right – the
    ControlNet Tile four-times-upscaled super-resolution](img/B21263_11_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.7: Left – the original raw image of the old man, and right – the
    ControlNet Tile four-times-upscaled super-resolution'
  prefs: []
  type: TYPE_NORMAL
- en: '**Royal female**: Here is the code to generate, resize, and upscale the image:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE190]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE191]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE192]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE193]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE194]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE195]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE196]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE197]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE198]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE199]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE200]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE201]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE202]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE203]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE204]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE205]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE206]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE207]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE208]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE209]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE210]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE211]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE212]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE213]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE214]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE215]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE216]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE217]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE218]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE219]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE220]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE221]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE222]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE223]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE224]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE225]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE226]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE227]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE228]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The result is shown in *Figure 11**.8*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: "![Figure 11.8: Left – the original raw royal female, and right – the ControlNet\
    \ Tile four- times\uFEFF-upscaled super-resolution](img/B21263_11_08.jpg)"
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.8: Left – the original raw royal female, and right – the ControlNet
    Tile four- times-upscaled super-resolution'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This chapter offered a summary of contemporary image upscaling and super-resolution
    methodologies, emphasizing their unique characteristics. The primary focus of
    the chapter was on two super-resolution techniques that leverage the capabilities
    of Stable Diffusion:'
  prefs: []
  type: TYPE_NORMAL
- en: Utilizing the Stable Diffusion image-to-image pipeline
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing ControlNet Tile to upscale images while enhancing details
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Furthermore, we showcased additional examples of the ControlNet Tile super-resolution
    technique.
  prefs: []
  type: TYPE_NORMAL
- en: If your goal is to preserve as many aspects of the original image as possible
    during upscaling, we recommend the image-to-image pipeline. Conversely, if you
    prefer an AI-driven approach that generates a wealth of detail, ControlNet Tile
    is the more appropriate option.
  prefs: []
  type: TYPE_NORMAL
- en: In [*Chapter 12*](B21263_12.xhtml#_idTextAnchor240), we will develop a scheduled
    prompt parser to allow us more accurate control over image generation.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Hugging Face – Super-Resolution: [https://huggingface.co/docs/diffusers/v0.13.0/en/api/pipelines/stable_diffusion/upscale](https://huggingface.co/docs/diffusers/v0.13.0/en/api/pipelines/stable_diffusion/upscale'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: )
  prefs: []
  type: TYPE_NORMAL
- en: 'Hugging Face – Ultra-fast ControlNet with Diffusers: [https://huggingface.co/blog/controlnet](https://huggingface.co/blog/controlnet'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: )
  prefs: []
  type: TYPE_NORMAL
- en: 'Lvmin Zhang, Maneesh Agrawala, Adding Conditional Control to Text-to-Image
    Diffusion Models: [https://arxiv.org/abs/2302.05543](https://arxiv.org/abs/2302.05543'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: )
  prefs: []
  type: TYPE_NORMAL
- en: 'Lvmin Zhang, ControlNet original implementation code: [https://github.com/lllyasviel](https://github.com/lllyasviel'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: )
  prefs: []
  type: TYPE_NORMAL
- en: 'Lvmin Zhang, ControlNet 1.1 Tile: [https://github.com/lllyasviel/ControlNet-v1-1-nightly#controlnet-11-tile](https://github.com/lllyasviel/ControlNet-v1-1-nightly#controlnet-11-tile'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: )
  prefs: []
  type: TYPE_NORMAL
- en: 'Nearest-neighbor interpolation: [https://en.wikipedia.org/wiki/Nearest-neighbor_interpolation](https://en.wikipedia.org/wiki/Nearest-neighbor_interpolation'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: )
  prefs: []
  type: TYPE_NORMAL
- en: 'Bilinear interpolation: [https://en.wikipedia.org/wiki/Bilinear_interpolation](https://en.wikipedia.org/wiki/Bilinear_interpolation'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: )
  prefs: []
  type: TYPE_NORMAL
- en: 'Bicubic interpolation: [https://en.wikipedia.org/wiki/Bicubic_interpolation](https://en.wikipedia.org/wiki/Bicubic_interpolation'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: )
  prefs: []
  type: TYPE_NORMAL
- en: 'Lanczos resampling: [https://en.wikipedia.org/wiki/Lanczos_resampling](https://en.wikipedia.org/wiki/Lanczos_resampling'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: )
  prefs: []
  type: TYPE_NORMAL
- en: 'ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks: [https://arxiv.org/abs/1809.00219](https://arxiv.org/abs/1809.00219'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: )
  prefs: []
  type: TYPE_NORMAL
- en: 'SwinIR: Image Restoration Using Swin Transformer: [https://arxiv.org/abs/2108.10257](https://arxiv.org/abs/2108.10257'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: )
  prefs: []
  type: TYPE_NORMAL
- en: 'Python Pillow package: [https://github.com/python-pillow/Pillow](https://github.com/python-pillow/Pillow)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
