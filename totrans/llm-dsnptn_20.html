<html><head></head><body><div><div><div><h1 id="_idParaDest-240" class="chapter-number"><a id="_idTextAnchor305"/>20</h1>
			<h1 id="_idParaDest-241"><a id="_idTextAnchor306"/>Chain-of-Thought Prompting</h1>
			<p><strong class="bold">Chain-of-thought</strong> (<strong class="bold">CoT</strong>) <strong class="bold">prompting</strong> originated from a research paper titled <em class="italic">Chain-of-Thought Prompting Elicits Reasoning in Large Language Models</em>, published by Google <a id="_idIndexMarker948"/>researchers Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, and Denny Zhou in 2022.</p>
			<p>The key innovation of CoT prompting was encouraging language models to break down complex reasoning problems into intermediate steps before arriving at a final answer. This was done by including demonstrations where the model is shown examples of step-by-step reasoning.</p>
			<p>The researchers demonstrated that by prompting LLMs with a few examples of reasoning chains (such as “Let’s think step by step”), the models could significantly improve their performance on complex tasks requiring multi-step reasoning, such as arithmetic, commonsense, and symbolic reasoning problems.</p>
			<p>Before CoT, most prompting techniques focused on getting direct answers. CoT showed that explicitly encouraging models to demonstrate their reasoning process led to more accurate results, especially for problems requiring several logical steps. CoT is beneficial in promoting transparency and ensuring accuracy by guiding the model through logical steps, whereas direct answering, while quicker, can miss intermediate steps that could clarify or validate the reasoning behind the answer.</p>
			<p>This research was particularly significant because it showed that reasoning abilities could emerge primarily through scale and prompting rather than requiring architectural changes to the models.</p>
			<p>In this chapter, you’ll learn to leverage CoT prompting to improve your LLM’s performance on complex reasoning tasks.</p>
			<p>In this chapter, we’ll be covering the following topics:</p>
			<ul>
				<li>Designing effective CoT prompts</li>
				<li>Using CoT prompting for problem solving</li>
				<li>Combining CoT prompting with other techniques</li>
				<li>Evaluating CoT prompting outputs</li>
				<li>Limitations of CoT prompting</li>
				<li>Future directions</li>
			</ul>
			<h1 id="_idParaDest-242"><a id="_idTextAnchor307"/>Designing effective CoT prompts</h1>
			<p>The process of creating effective CoT prompts helps in fostering clarity, logical progression, and structured reasoning, which in turn ensures more accurate and coherent <a id="_idIndexMarker949"/>outputs. By providing a well-defined problem statement, breaking the task into smaller steps, using explicit markers to guide the reasoning, and including a sample CoT response, the model is better equipped to follow a systematic approach that aligns with human problem-solving methods, leading to clear and rational conclusions:</p>
			<ol>
				<li><strong class="bold">Provide a clear problem statement</strong>: A precise problem statement directs the reasoning toward a specific goal, eliminating ambiguity and ensuring that the model understands exactly what is being asked. This helps prevent misinterpretations and guides the entire reasoning process in the right direction.</li>
				<li><strong class="bold">Break down the problem into logical steps</strong>: Dividing a complex task into smaller, manageable steps helps in organizing the reasoning and makes the overall problem easier to tackle. This breakdown aids in focusing on one aspect at a time, promoting clarity and reducing the risk of missing important details.</li>
				<li><strong class="bold">Use explicit reasoning markers</strong>: Markers such as “First,” “Next,” and “Finally” act as signposts for the logical flow of the reasoning process. They help structure the thought process in a clear sequence, ensuring that each part of the problem is addressed in the right order, which increases the overall coherence of the response.</li>
				<li><strong class="bold">Include a sample CoT response in the prompt</strong>: Providing an example helps establish a standard for the reasoning format and sets clear expectations for the process. It also serves as a reference point, guiding the model in how to structure its response and making it easier to generate consistent and logically sound outputs.</li>
			</ol>
			<p>Here’s <a id="_idIndexMarker950"/>an example of implementing a CoT prompt:</p>
			<pre class="source-code">
def cot_prompt(question):
    return f"""Solve the following problem step by step:
Problem: {question}
Let's approach this step by step:
1) First, we need to...
2) Next, we should...
3) Then, we can...
4) Finally, we...
Therefore, the answer is...
Now, solve this new problem using the same step-by-step approach:
Problem: If a train travels 120 km in 2 hours, what is its average speed in km/h?
Let's solve this step by step:
"""
# Example usage
problem = "If a train travels 120 km in 2 hours, what is its average speed in km/h?"
prompt = cot_prompt(problem)
print(prompt)</pre>			<p>This function <a id="_idIndexMarker951"/>generates a CoT prompt for a given problem (<code>If a train travels 120 km in 2 hours, what is its average speed in km/h?</code>), providing a structure for step-by-step reasoning. Here are the sample steps using CoT:</p>
			<pre class="source-code">
Solve the following problem step by step:
Problem: If a train travels 120 km in 2 hours, what is its average speed in km/h?
Let's approach this step by step:
1) First, we need to recall the formula for average speed, which is:
   Average Speed = Total Distance / Total Time.
2) Next, we should identify the total distance traveled, which is 120 km.
3) Then, we can identify the total time taken, which is 2 hours.
4) Now, we will apply the formula:
   Average Speed = 120 km / 2 hours.
5) Finally, we calculate the result:
   Average Speed = 60 km/h.</pre>			<p>Therefore, the answer is 60 km/h.</p>
			<p>CoT prompting can be applied to various problem-solving scenarios. Let’s see one such scenario next.</p>
			<h1 id="_idParaDest-243"><a id="_idTextAnchor308"/>Using CoT prompting for problem solving</h1>
			<p>Let’s <a id="_idIndexMarker952"/>implement a function that uses CoT for mathematical word problems:</p>
			<pre class="source-code">
from transformers import AutoModelForCausalLM, AutoTokenizer
def solve_math_problem(model, tokenizer, problem):
    prompt = cot_prompt(problem)
    inputs = tokenizer(prompt, return_tensors="pt")
    outputs = model.generate(
        inputs, max_length=500, num_return_sequences=1
    )
    solution = tokenizer.decode(
        outputs[0], skip_special_tokens=True
    )
    return solution
# Example usage
model_name = "gpt2-large"  # Replace with your preferred model
model = AutoModelForCausalLM.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)
problem = "If a recipe calls for 2 cups of flour for 8 servings, how many cups of flour are needed for 12 servings?"
solution = solve_math_problem(model, tokenizer, problem)
print(solution)</pre>			<p>This <a id="_idIndexMarker953"/>function applies CoT prompting to solve a mathematical word problem (for example, <code>If a recipe calls for 2 cups of flour for 8 servings, how many cups of flour are needed for 12 servings?</code>), guiding the LLM through a step-by-step reasoning process.</p>
			<p>In addition to using CoT prompting for problem solving, we can also combine it with other techniques to improve LLM performance.</p>
			<h1 id="_idParaDest-244"><a id="_idTextAnchor309"/>Combining CoT prompting with other techniques</h1>
			<p>CoT can <a id="_idIndexMarker954"/>be combined with other prompting techniques to further enhance LLM performance. Let’s implement <a id="_idIndexMarker955"/>a function that combines CoT with <strong class="bold">few-shot </strong><strong class="bold">learning</strong> (<strong class="bold">FSL</strong>):</p>
			<pre class="source-code">
def few_shot_cot_prompt(question, examples):
    prompt = "Solve the following problems step by step:\n\n"
    for example in examples:
        prompt += f"Problem: {example['question']}\n\n"
        prompt += f"Solution: {example['solution']}\n\n"
    prompt += f"Problem: {question}\n\nSolution:"
    return prompt
def solve_with_few_shot_cot(model, tokenizer, problem, examples):
    prompt = few_shot_cot_prompt(problem, examples)
    inputs = tokenizer(prompt, return_tensors="pt")
    outputs = model.generate(inputs, max_length=500,
        num_return_sequences=1)
    solution = tokenizer.decode(outputs[0], skip_special_tokens=True)
    return solution
# Example usage
examples = [
    {
        "question": "If a car travels 60 miles in 2 hours, what is its average speed?",
        "solution": "1) First, we identify the given information:\n   - Distance traveled = 60 miles\n   - Time taken = 2 hours\n\n2) We know that average speed is calculated by dividing distance by time:\n   Average Speed = Distance / Time\n\n3) Let's plug in the values:\n   Average Speed = 60 miles / 2 hours\n\n4) Perform the division:\n   Average Speed = 30 miles per hour\n\nTherefore, the car's average speed is 30 miles per hour."
    }
]
problem = "If a train travels 180 km in 3 hours, what is its average speed in km/h?"
solution = solve_with_few_shot_cot(model, tokenizer, problem,
    examples)
print(solution)</pre>			<p>This function combines FSL with CoT prompting, providing examples of step-by-step solutions to guide the LLM in solving a new problem (see the code example for <code>If a train travels 180 km in 3 hours, what is its average speed in km/h?</code>). Combining methods such as CoT + FSL has been shown to improve performance <a id="_idIndexMarker956"/>in recent benchmarks (<a href="https://aclanthology.org/2023.emnlp-main.782.pdf">https://aclanthology.org/2023.emnlp-main.782.pdf</a>).</p>
			<p>Next, let’s see how we can evaluate the quality of CoT prompts.</p>
			<h1 id="_idParaDest-245"><a id="_idTextAnchor310"/>Evaluating CoT prompting outputs</h1>
			<p>Evaluating <a id="_idIndexMarker957"/>the outputs of CoT prompts involves assessing both the final answer and the reasoning process. Let’s implement a simple evaluation function:</p>
			<pre class="source-code">
def evaluate_cot_output(output, correct_answer):
    # Extract the final answer from the CoT output
    final_answer = extract_final_answer(output)
    # Check if the final answer is correct
    answer_correct = final_answer == correct_answer
    # Evaluate the reasoning steps
    reasoning_score = evaluate_reasoning_steps(output)
    return {
        "answer_correct": answer_correct,
        "reasoning_score": reasoning_score
    }
def extract_final_answer(output):
    # Implement logic to extract the final answer from the CoT output
    # This could involve parsing the last line or looking for specific phrases
    pass
def evaluate_reasoning_steps(output):
    # Implement logic to evaluate the quality of the reasoning steps
    # This could involve checking for logical consistency, completeness, etc.
    pass
# Example usage
problem = "If a train travels 180 km in 3 hours, what is its average speed in km/h?"
correct_answer = 60
cot_output = solve_math_problem(model, tokenizer, problem)
evaluation = evaluate_cot_output(cot_output, correct_answer)
print(evaluation)</pre>			<p>This <a id="_idIndexMarker958"/>evaluation function assesses both the correctness of the final answer and the quality of the reasoning steps in the CoT output.</p>
			<h1 id="_idParaDest-246"><a id="_idTextAnchor311"/>Limitations of CoT prompting</h1>
			<p>While <a id="_idIndexMarker959"/>CoT prompting is powerful, it has some limitations:</p>
			<ul>
				<li>High token usage and computation time</li>
				<li>Potential for error propagation in multi-step reasoning</li>
				<li>Dependence on the quality of the initial prompt</li>
				<li>May not be suitable for all types of problems</li>
			</ul>
			<p>To address some of these limitations, consider implementing a dynamic CoT approach:</p>
			<pre class="source-code">
def dynamic_cot(model, tokenizer, problem, max_steps=5):
    prompt = f"Problem: {problem}\n\nLet's solve this step by step:"
    for step in range(1, max_steps + 1):
        prompt += f"\n\nStep {step}:"
        inputs = tokenizer(prompt, return_tensors="pt")
        outputs = model.generate(
            inputs, max_length=len(prompt) + 100,
            num_return_sequences=1
        )
        new_step = tokenizer.decode(
            outputs[0][len(inputs['input_ids'][0]):],
            skip_special_tokens=True
        )
        prompt += new_step
        if "Therefore, the final answer is" in new_step:
            break
    return prompt
# Example usage
problem = "If a recipe calls for 2 cups of flour for 8 servings, how many cups of flour are needed for 12 servings?"
solution = dynamic_cot(model, tokenizer, problem)
print(solution)</pre>			<p>The <code>dynamic_cot</code> function <a id="_idIndexMarker960"/>implements a dynamic CoT approach to break down and solve a problem step by step using a language model. It starts by creating an initial prompt that introduces the problem and instructs the model to solve it incrementally. The function then enters a loop, iterating up to <code>max_steps</code> times (default is <code>5</code>), where in each iteration, it feeds the model a growing prompt that includes all <a id="_idIndexMarker961"/>the steps generated so far. The model processes this prompt, generates the next step in the reasoning process, and appends it to the prompt. The new step is decoded from tokenized outputs and added to the prompt string. The function checks for the phrase <code>Therefore, the final answer is</code> in the generated step, signaling that the model has reached a conclusion and should stop. If this phrase is found, the loop breaks early; otherwise, it continues until the maximum steps are reached. Finally, the function returns the complete prompt, which includes all the reasoning steps leading to the solution. However, in real-world use, token limitations of the model may impact long multi-step prompts. As the prompt grows with each new step, it might exceed the model’s maximum token limit, which could result in truncated inputs, loss of earlier context, or failure to generate accurate steps, especially in complex or lengthy problems. This is a significant consideration when dealing with problems requiring many steps or substantial context.</p>
			<h1 id="_idParaDest-247"><a id="_idTextAnchor312"/>Future directions</h1>
			<p>As CoT <a id="_idIndexMarker962"/>prompting continues to evolve, several promising directions emerge:</p>
			<ul>
				<li><strong class="bold">Adaptive CoT</strong>: Dynamically <a id="_idIndexMarker963"/>adjusting the reasoning process based on problem complexity</li>
				<li><strong class="bold">Multi-modal CoT</strong>: Incorporating <a id="_idIndexMarker964"/>visual or auditory information in the reasoning process (<a href="https://arxiv.org/abs/2302.00923">https://arxiv.org/abs/2302.00923</a>)</li>
				<li><strong class="bold">Collaborative CoT</strong>: Combining <a id="_idIndexMarker965"/>insights from multiple LLMs or human-AI collaboration (<a href="https://arxiv.org/html/2409.07355v1">https://arxiv.org/html/2409.07355v1</a>)</li>
				<li><strong class="bold">Meta-learning for CoT</strong>: Meta-learning <a id="_idIndexMarker966"/>and CoT approaches have emerged as powerful techniques for addressing the challenges of few-shot relation extraction (<a href="https://arxiv.org/abs/2311.05922">https://arxiv.org/abs/2311.05922</a>)</li>
			</ul>
			<p>Here’s a conceptual implementation of adaptive CoT:</p>
			<pre class="source-code">
def adaptive_cot(
    model, tokenizer, problem, complexity_threshold=0.7
):
    # Assess problem complexity
    complexity = assess_problem_complexity(problem)
    if complexity &gt; complexity_threshold:
        # Use detailed CoT for complex problems
        return detailed_cot(model, tokenizer, problem)
    else:
        # Use simple direct approach for simpler problems
        return simple_solve(model, tokenizer, problem)
def assess_problem_complexity(problem):
    # Implement logic to assess problem complexity
    # This could involve keyword analysis, sentence structure, etc.
    pass
def detailed_cot(model, tokenizer, problem):
    # Implement detailed Chain-of-Thought approach
    pass
def simple_solve(model, tokenizer, problem):
    # Implement simple direct solving approach
    pass
# Example usage
problem = "What is the result of 25 divided by 5?"
solution = adaptive_cot(model, tokenizer, problem)
print(solution)</pre>			<p>This adaptive <a id="_idIndexMarker967"/>CoT approach assesses problem complexity and chooses an appropriate solving strategy, balancing efficiency and reasoning depth.</p>
			<p>The <code>adaptive_cot</code> function adapts <a id="_idIndexMarker968"/>the CoT approach based on the complexity of the problem. It first assesses the problem’s complexity by calling the <code>assess_problem_complexity</code> function, which could involve analyzing keywords, sentence structure, or other features to determine how complex the problem is (though the logic for this is yet to be implemented). If the complexity score exceeds a predefined threshold (<code>complexity_threshold</code>), the function uses a detailed CoT approach <a id="_idIndexMarker969"/>via the <code>detailed_cot</code> function, which would generate a more elaborate, step-by-step solution. For simpler problems, it uses a straightforward <a id="_idIndexMarker970"/>solving method via the <code>simple_solve</code> function, which provides a direct answer without breaking down the problem into multiple <a id="_idIndexMarker971"/>steps. The result is returned based on which approach is deemed appropriate for the given problem. This dynamic approach allows the model to choose the most efficient method of solving a problem b<a id="_idTextAnchor313"/>ased on its complexity.</p>
			<h1 id="_idParaDest-248"><a id="_idTextAnchor314"/>Summary</h1>
			<p>In this chapter, you learned how to design effective CoT prompts that guide LLMs through step-by-step reasoning processes. We covered applications of this technique in various problem-solving scenarios and discussed how to combine it with other prompting strategies. You also learned how to evaluate the quality of CoT outputs and understood the limitations of this approach.</p>
			<p>By implementing the strategies and considerations discussed in this chapter, you can significantly improve your LLM’s performance on complex problem-solving tasks, while also gaining insights into the model’s reasoning process.</p>
			<p>In the next chapter, we will investigate <strong class="bold">tree-of-thoughts</strong> (<strong class="bold">ToT</strong>) prompting, an advanced technique that extends the concepts of CoT to create even more sophisticated reasoning structures.</p>
		</div>
	</div></div></body></html>