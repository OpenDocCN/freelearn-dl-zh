<html><head></head><body><div id="book-content"><div id="sbo-rt-content"><div id="_idContainer042">
			<h1 id="_idParaDest-240" class="chapter-number"><a id="_idTextAnchor305"/>20</h1>
			<h1 id="_idParaDest-241"><a id="_idTextAnchor306"/>Chain-of-Thought Prompting</h1>
			<p><strong class="bold">Chain-of-thought</strong> (<strong class="bold">CoT</strong>) <strong class="bold">prompting</strong> originated from a research paper titled <em class="italic">Chain-of-Thought Prompting Elicits Reasoning in Large Language Models</em>, published by Google <a id="_idIndexMarker948"/>researchers Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, and Denny Zhou <span class="No-Break">in 2022.</span></p>
			<p>The key innovation of CoT prompting was encouraging language models to break down complex reasoning problems into intermediate steps before arriving at a final answer. This was done by including demonstrations where the model is shown examples of <span class="No-Break">step-by-step reasoning.</span></p>
			<p>The researchers demonstrated that by prompting LLMs with a few examples of reasoning chains (such as “Let’s think step by step”), the models could significantly improve their performance on complex tasks requiring multi-step reasoning, such as arithmetic, commonsense, and symbolic <span class="No-Break">reasoning problems.</span></p>
			<p>Before CoT, most prompting techniques focused on getting direct answers. CoT showed that explicitly encouraging models to demonstrate their reasoning process led to more accurate results, especially for problems requiring several logical steps. CoT is beneficial in promoting transparency and ensuring accuracy by guiding the model through logical steps, whereas direct answering, while quicker, can miss intermediate steps that could clarify or validate the reasoning behind <span class="No-Break">the answer.</span></p>
			<p>This research was particularly significant because it showed that reasoning abilities could emerge primarily through scale and prompting rather than requiring architectural changes to <span class="No-Break">the models.</span></p>
			<p>In this chapter, you’ll learn to leverage CoT prompting to improve your LLM’s performance on complex <span class="No-Break">reasoning tasks.</span></p>
			<p>In this chapter, we’ll be covering the <span class="No-Break">following topics:</span></p>
			<ul>
				<li>Designing effective <span class="No-Break">CoT prompts</span></li>
				<li>Using CoT prompting for <span class="No-Break">problem solving</span></li>
				<li>Combining CoT prompting with <span class="No-Break">other techniques</span></li>
				<li>Evaluating CoT <span class="No-Break">prompting outputs</span></li>
				<li>Limitations of <span class="No-Break">CoT prompting</span></li>
				<li><span class="No-Break">Future directions</span></li>
			</ul>
			<h1 id="_idParaDest-242"><a id="_idTextAnchor307"/>Designing effective CoT prompts</h1>
			<p>The process of creating effective CoT prompts helps in fostering clarity, logical progression, and structured reasoning, which in turn ensures more accurate and coherent <a id="_idIndexMarker949"/>outputs. By providing a well-defined problem statement, breaking the task into smaller steps, using explicit markers to guide the reasoning, and including a sample CoT response, the model is better equipped to follow a systematic approach that aligns with human problem-solving methods, leading to clear and <span class="No-Break">rational conclusions:</span></p>
			<ol>
				<li><strong class="bold">Provide a clear problem statement</strong>: A precise problem statement directs the reasoning toward a specific goal, eliminating ambiguity and ensuring that the model understands exactly what is being asked. This helps prevent misinterpretations and guides the entire reasoning process in the <span class="No-Break">right direction.</span></li>
				<li><strong class="bold">Break down the problem into logical steps</strong>: Dividing a complex task into smaller, manageable steps helps in organizing the reasoning and makes the overall problem easier to tackle. This breakdown aids in focusing on one aspect at a time, promoting clarity and reducing the risk of missing <span class="No-Break">important details.</span></li>
				<li><strong class="bold">Use explicit reasoning markers</strong>: Markers such as “First,” “Next,” and “Finally” act as signposts for the logical flow of the reasoning process. They help structure the thought process in a clear sequence, ensuring that each part of the problem is addressed in the right order, which increases the overall coherence of <span class="No-Break">the response.</span></li>
				<li><strong class="bold">Include a sample CoT response in the prompt</strong>: Providing an example helps establish a standard for the reasoning format and sets clear expectations for the process. It also serves as a reference point, guiding the model in how to structure its response and making it easier to generate consistent and logically <span class="No-Break">sound outputs.</span></li>
			</ol>
			<p>Here’s <a id="_idIndexMarker950"/>an example of implementing a <span class="No-Break">CoT prompt:</span></p>
			<pre class="source-code">
def cot_prompt(question):
    return f"""Solve the following problem step by step:
Problem: {question}
Let's approach this step by step:
1) First, we need to...
2) Next, we should...
3) Then, we can...
4) Finally, we...
Therefore, the answer is...
Now, solve this new problem using the same step-by-step approach:
Problem: If a train travels 120 km in 2 hours, what is its average speed in km/h?
Let's solve this step by step:
"""
# Example usage
problem = "If a train travels 120 km in 2 hours, what is its average speed in km/h?"
prompt = cot_prompt(problem)
print(prompt)</pre>			<p>This function <a id="_idIndexMarker951"/>generates a CoT prompt for a given problem (<strong class="source-inline">If a train travels 120 km in 2 hours, what is its average speed in km/h?</strong>), providing a structure for step-by-step reasoning. Here are the sample steps <span class="No-Break">using CoT:</span></p>
			<pre class="source-code">
Solve the following problem step by step:
Problem: If a train travels 120 km in 2 hours, what is its average speed in km/h?
Let's approach this step by step:
1) First, we need to recall the formula for average speed, which is:
   Average Speed = Total Distance / Total Time.
2) Next, we should identify the total distance traveled, which is 120 km.
3) Then, we can identify the total time taken, which is 2 hours.
4) Now, we will apply the formula:
   Average Speed = 120 km / 2 hours.
5) Finally, we calculate the result:
   Average Speed = 60 km/h.</pre>			<p>Therefore, the answer is <span class="No-Break">60 km/h.</span></p>
			<p>CoT prompting can be applied to various problem-solving scenarios. Let’s see one such <span class="No-Break">scenario next.</span></p>
			<h1 id="_idParaDest-243"><a id="_idTextAnchor308"/>Using CoT prompting for problem solving</h1>
			<p>Let’s <a id="_idIndexMarker952"/>implement a function that uses CoT for mathematical <span class="No-Break">word problems:</span></p>
			<pre class="source-code">
from transformers import AutoModelForCausalLM, AutoTokenizer
def solve_math_problem(model, tokenizer, problem):
    prompt = cot_prompt(problem)
    inputs = tokenizer(prompt, return_tensors="pt")
    outputs = model.generate(
        inputs, max_length=500, num_return_sequences=1
    )
    solution = tokenizer.decode(
        outputs[0], skip_special_tokens=True
    )
    return solution
# Example usage
model_name = "gpt2-large"  # Replace with your preferred model
model = AutoModelForCausalLM.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)
problem = "If a recipe calls for 2 cups of flour for 8 servings, how many cups of flour are needed for 12 servings?"
solution = solve_math_problem(model, tokenizer, problem)
print(solution)</pre>			<p>This <a id="_idIndexMarker953"/>function applies CoT prompting to solve a mathematical word problem (for example, <strong class="source-inline">If a recipe calls for 2 cups of flour for 8 servings, how many cups of flour are needed for 12 servings?</strong>), guiding the LLM through a step-by-step <span class="No-Break">reasoning process.</span></p>
			<p>In addition to using CoT prompting for problem solving, we can also combine it with other techniques to improve <span class="No-Break">LLM performance.</span></p>
			<h1 id="_idParaDest-244"><a id="_idTextAnchor309"/>Combining CoT prompting with other techniques</h1>
			<p>CoT can <a id="_idIndexMarker954"/>be combined with other prompting techniques to further enhance LLM performance. Let’s implement <a id="_idIndexMarker955"/>a function that combines CoT with <strong class="bold">few-shot </strong><span class="No-Break"><strong class="bold">learning</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">FSL</strong></span><span class="No-Break">):</span></p>
			<pre class="source-code">
def few_shot_cot_prompt(question, examples):
    prompt = "Solve the following problems step by step:\n\n"
    for example in examples:
        prompt += f"Problem: {example['question']}\n\n"
        prompt += f"Solution: {example['solution']}\n\n"
    prompt += f"Problem: {question}\n\nSolution:"
    return prompt
def solve_with_few_shot_cot(model, tokenizer, problem, examples):
    prompt = few_shot_cot_prompt(problem, examples)
    inputs = tokenizer(prompt, return_tensors="pt")
    outputs = model.generate(inputs, max_length=500,
        num_return_sequences=1)
    solution = tokenizer.decode(outputs[0], skip_special_tokens=True)
    return solution
# Example usage
examples = [
    {
        "question": "If a car travels 60 miles in 2 hours, what is its average speed?",
        "solution": "1) First, we identify the given information:\n   - Distance traveled = 60 miles\n   - Time taken = 2 hours\n\n2) We know that average speed is calculated by dividing distance by time:\n   Average Speed = Distance / Time\n\n3) Let's plug in the values:\n   Average Speed = 60 miles / 2 hours\n\n4) Perform the division:\n   Average Speed = 30 miles per hour\n\nTherefore, the car's average speed is 30 miles per hour."
    }
]
problem = "If a train travels 180 km in 3 hours, what is its average speed in km/h?"
solution = solve_with_few_shot_cot(model, tokenizer, problem,
    examples)
print(solution)</pre>			<p>This function combines FSL with CoT prompting, providing examples of step-by-step solutions to guide the LLM in solving a new problem (see the code example for <strong class="source-inline">If a train travels 180 km in 3 hours, what is its average speed in km/h?</strong>). Combining methods such as CoT + FSL has been shown to improve performance <a id="_idIndexMarker956"/>in recent <span class="No-Break">benchmarks (</span><a href="https://aclanthology.org/2023.emnlp-main.782.pdf"><span class="No-Break">https://aclanthology.org/2023.emnlp-main.782.pdf</span></a><span class="No-Break">).</span></p>
			<p>Next, let’s see how we can evaluate the quality of <span class="No-Break">CoT prompts.</span></p>
			<h1 id="_idParaDest-245"><a id="_idTextAnchor310"/>Evaluating CoT prompting outputs</h1>
			<p>Evaluating <a id="_idIndexMarker957"/>the outputs of CoT prompts involves assessing both the final answer and the reasoning process. Let’s implement a simple <span class="No-Break">evaluation function:</span></p>
			<pre class="source-code">
def evaluate_cot_output(output, correct_answer):
    # Extract the final answer from the CoT output
    final_answer = extract_final_answer(output)
    # Check if the final answer is correct
    answer_correct = final_answer == correct_answer
    # Evaluate the reasoning steps
    reasoning_score = evaluate_reasoning_steps(output)
    return {
        "answer_correct": answer_correct,
        "reasoning_score": reasoning_score
    }
def extract_final_answer(output):
    # Implement logic to extract the final answer from the CoT output
    # This could involve parsing the last line or looking for specific phrases
    pass
def evaluate_reasoning_steps(output):
    # Implement logic to evaluate the quality of the reasoning steps
    # This could involve checking for logical consistency, completeness, etc.
    pass
# Example usage
problem = "If a train travels 180 km in 3 hours, what is its average speed in km/h?"
correct_answer = 60
cot_output = solve_math_problem(model, tokenizer, problem)
evaluation = evaluate_cot_output(cot_output, correct_answer)
print(evaluation)</pre>			<p>This <a id="_idIndexMarker958"/>evaluation function assesses both the correctness of the final answer and the quality of the reasoning steps in the <span class="No-Break">CoT output.</span></p>
			<h1 id="_idParaDest-246"><a id="_idTextAnchor311"/>Limitations of CoT prompting</h1>
			<p>While <a id="_idIndexMarker959"/>CoT prompting is powerful, it has <span class="No-Break">some limitations:</span></p>
			<ul>
				<li>High token usage and <span class="No-Break">computation time</span></li>
				<li>Potential for error propagation in <span class="No-Break">multi-step reasoning</span></li>
				<li>Dependence on the quality of the <span class="No-Break">initial prompt</span></li>
				<li>May not be suitable for all types <span class="No-Break">of problems</span></li>
			</ul>
			<p>To address some of these limitations, consider implementing a dynamic <span class="No-Break">CoT approach:</span></p>
			<pre class="source-code">
def dynamic_cot(model, tokenizer, problem, max_steps=5):
    prompt = f"Problem: {problem}\n\nLet's solve this step by step:"
    for step in range(1, max_steps + 1):
        prompt += f"\n\nStep {step}:"
        inputs = tokenizer(prompt, return_tensors="pt")
        outputs = model.generate(
            inputs, max_length=len(prompt) + 100,
            num_return_sequences=1
        )
        new_step = tokenizer.decode(
            outputs[0][len(inputs['input_ids'][0]):],
            skip_special_tokens=True
        )
        prompt += new_step
        if "Therefore, the final answer is" in new_step:
            break
    return prompt
# Example usage
problem = "If a recipe calls for 2 cups of flour for 8 servings, how many cups of flour are needed for 12 servings?"
solution = dynamic_cot(model, tokenizer, problem)
print(solution)</pre>			<p>The <strong class="source-inline">dynamic_cot</strong> function <a id="_idIndexMarker960"/>implements a dynamic CoT approach to break down and solve a problem step by step using a language model. It starts by creating an initial prompt that introduces the problem and instructs the model to solve it incrementally. The function then enters a loop, iterating up to <strong class="source-inline">max_steps</strong> times (default is <strong class="source-inline">5</strong>), where in each iteration, it feeds the model a growing prompt that includes all <a id="_idIndexMarker961"/>the steps generated so far. The model processes this prompt, generates the next step in the reasoning process, and appends it to the prompt. The new step is decoded from tokenized outputs and added to the prompt string. The function checks for the phrase <strong class="source-inline">Therefore, the final answer is</strong> in the generated step, signaling that the model has reached a conclusion and should stop. If this phrase is found, the loop breaks early; otherwise, it continues until the maximum steps are reached. Finally, the function returns the complete prompt, which includes all the reasoning steps leading to the solution. However, in real-world use, token limitations of the model may impact long multi-step prompts. As the prompt grows with each new step, it might exceed the model’s maximum token limit, which could result in truncated inputs, loss of earlier context, or failure to generate accurate steps, especially in complex or lengthy problems. This is a significant consideration when dealing with problems requiring many steps or <span class="No-Break">substantial context.</span></p>
			<h1 id="_idParaDest-247"><a id="_idTextAnchor312"/>Future directions</h1>
			<p>As CoT <a id="_idIndexMarker962"/>prompting continues to evolve, several promising <span class="No-Break">directions emerge:</span></p>
			<ul>
				<li><strong class="bold">Adaptive CoT</strong>: Dynamically <a id="_idIndexMarker963"/>adjusting the reasoning process based on <span class="No-Break">problem complexity</span></li>
				<li><strong class="bold">Multi-modal CoT</strong>: Incorporating <a id="_idIndexMarker964"/>visual or auditory information in the reasoning <span class="No-Break">process (</span><a href="https://arxiv.org/abs/2302.00923"><span class="No-Break">https://arxiv.org/abs/2302.00923</span></a><span class="No-Break">)</span></li>
				<li><strong class="bold">Collaborative CoT</strong>: Combining <a id="_idIndexMarker965"/>insights from multiple LLMs or human-AI <span class="No-Break">collaboration (</span><a href="https://arxiv.org/html/2409.07355v1"><span class="No-Break">https://arxiv.org/html/2409.07355v1</span></a><span class="No-Break">)</span></li>
				<li><strong class="bold">Meta-learning for CoT</strong>: Meta-learning <a id="_idIndexMarker966"/>and CoT approaches have emerged as powerful techniques for addressing the challenges of few-shot relation <span class="No-Break">extraction (</span><a href="https://arxiv.org/abs/2311.05922"><span class="No-Break">https://arxiv.org/abs/2311.05922</span></a><span class="No-Break">)</span></li>
			</ul>
			<p>Here’s a conceptual implementation of <span class="No-Break">adaptive CoT:</span></p>
			<pre class="source-code">
def adaptive_cot(
    model, tokenizer, problem, complexity_threshold=0.7
):
    # Assess problem complexity
    complexity = assess_problem_complexity(problem)
    if complexity &gt; complexity_threshold:
        # Use detailed CoT for complex problems
        return detailed_cot(model, tokenizer, problem)
    else:
        # Use simple direct approach for simpler problems
        return simple_solve(model, tokenizer, problem)
def assess_problem_complexity(problem):
    # Implement logic to assess problem complexity
    # This could involve keyword analysis, sentence structure, etc.
    pass
def detailed_cot(model, tokenizer, problem):
    # Implement detailed Chain-of-Thought approach
    pass
def simple_solve(model, tokenizer, problem):
    # Implement simple direct solving approach
    pass
# Example usage
problem = "What is the result of 25 divided by 5?"
solution = adaptive_cot(model, tokenizer, problem)
print(solution)</pre>			<p>This adaptive <a id="_idIndexMarker967"/>CoT approach assesses problem complexity and chooses an appropriate solving strategy, balancing efficiency and <span class="No-Break">reasoning depth.</span></p>
			<p>The <strong class="source-inline">adaptive_cot</strong> function adapts <a id="_idIndexMarker968"/>the CoT approach based on the complexity of the problem. It first assesses the problem’s complexity by calling the <strong class="source-inline">assess_problem_complexity</strong> function, which could involve analyzing keywords, sentence structure, or other features to determine how complex the problem is (though the logic for this is yet to be implemented). If the complexity score exceeds a predefined threshold (<strong class="source-inline">complexity_threshold</strong>), the function uses a detailed CoT approach <a id="_idIndexMarker969"/>via the <strong class="source-inline">detailed_cot</strong> function, which would generate a more elaborate, step-by-step solution. For simpler problems, it uses a straightforward <a id="_idIndexMarker970"/>solving method via the <strong class="source-inline">simple_solve</strong> function, which provides a direct answer without breaking down the problem into multiple <a id="_idIndexMarker971"/>steps. The result is returned based on which approach is deemed appropriate for the given problem. This dynamic approach allows the model to choose the most efficient method of solving a problem b<a id="_idTextAnchor313"/>ased on <span class="No-Break">its complexity.</span></p>
			<h1 id="_idParaDest-248"><a id="_idTextAnchor314"/>Summary</h1>
			<p>In this chapter, you learned how to design effective CoT prompts that guide LLMs through step-by-step reasoning processes. We covered applications of this technique in various problem-solving scenarios and discussed how to combine it with other prompting strategies. You also learned how to evaluate the quality of CoT outputs and understood the limitations of <span class="No-Break">this approach.</span></p>
			<p>By implementing the strategies and considerations discussed in this chapter, you can significantly improve your LLM’s performance on complex problem-solving tasks, while also gaining insights into the model’s <span class="No-Break">reasoning process.</span></p>
			<p>In the next chapter, we will investigate <strong class="bold">tree-of-thoughts</strong> (<strong class="bold">ToT</strong>) prompting, an advanced technique that extends the concepts of CoT to create even more sophisticated <span class="No-Break">reasoning structures.</span></p>
		</div>
	</div></div></body></html>