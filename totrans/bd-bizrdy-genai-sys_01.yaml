- en: '1'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '1'
- en: Defining a Business-Ready Generative AI System
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义一个适合商业应用的生成性AI系统
- en: Implementing a **generative AI system** (**GenAISys**) in an organization doesn’t
    stop at simply integrating a standalone model such as GPT, Grok, Llama, or Gemini
    via an API. While this is often a starting point, we often mistake it as the finish
    line. The rising demand for AI, as it expands across all domains, calls for the
    implementation of advanced AI systems that go beyond simply integrating a prebuilt
    model.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在组织中实施**生成性AI系统**（**GenAISys**）不仅仅是通过API集成一个独立的模型，如GPT、Grok、Llama或Gemini。虽然这通常是起点，但我们常常错误地将其视为终点。随着AI在所有领域的扩展，对AI的需求不断上升，需要实施超越简单集成预建模型的先进AI系统。
- en: A business-ready GenAISys should provide ChatGPT-grade functionality in an organization,
    but also go well beyond it. Its capabilities and features must include **natural
    language understanding** (**NLU**), contextual awareness through memory retention
    across dialogues in a chat session, and agentic functions such as autonomous image,
    audio, and document analysis and generation. Think of a generative AI model as
    an entity with a wide range of functions, including AI agents as agentic co-workers.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 一个适合商业应用的GenAISys应在组织中提供ChatGPT级别的功能，但也要超越它。其能力和功能必须包括**自然语言理解**（**NLU**）、通过对话中的记忆保持实现情境意识，以及自主图像、音频和文档分析和生成的代理功能。将生成性AI模型视为一个具有广泛功能的实体，包括作为代理同事的AI代理。
- en: 'We will begin the chapter by defining what a business-ready GenAISys is. From
    there, we’ll focus on the central role of a generative AI model, such as GPT-4o,
    that can both orchestrate and execute tasks. Building on that, we will lay the
    groundwork for contextual awareness and memory retention, discussing four types
    of generative AI memory: memoryless, short-term, long-term, and multiple sessions.
    We will also define a new approach to **retrieval-augmented generation** (**RAG**)
    that introduces an additional dimension to data retrieval: instruction and agentic
    reasoning scenarios. Adding instructions stored in a vector store takes RAG to
    another level by retrieving instructions that we can add to a prompt. In parallel,
    we will examine a critical component of a GenAISys: human roles. We will see how,
    throughout its life cycle, an AI system requires human expertise. Additionally,
    we will define several levels of implementation to adapt the scope and scale of
    a GenAISys, not only to business requirements but also to available budgets and
    resources.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先定义什么是适合商业应用的GenAISys。从那里，我们将关注生成性AI模型（如GPT-4o）的核心作用，这种模型既能协调也能执行任务。在此基础上，我们将为情境意识和记忆保持奠定基础，讨论四种生成性AI记忆类型：无记忆、短期、长期和多会话。我们还将定义一种新的**检索增强生成**（**RAG**）方法，它为数据检索引入了一个额外的维度：指令和代理推理场景。通过检索存储在向量存储中的指令，将RAG提升到另一个层次，我们可以将这些指令添加到提示中。同时，我们将检查GenAISys的一个关键组件：人类角色。我们将看到在其生命周期中，一个AI系统如何需要人类的专业知识。此外，我们还将定义几个实施级别，以适应GenAISys的范围和规模，不仅适应商业需求，还要适应可用的预算和资源。
- en: Finally, we’ll illustrate how contextual awareness and memory retention can
    be implemented using OpenAI’s LLM and multimodal API. A GenAISys cannot work without
    solid memory retention functionality—without memory, there’s no context, and without
    context, there’s no sustainable generation. Throughout this book, we will create
    modules for memoryless, short-term, long-term, and multisession types depending
    on the task at hand. By the end of this chapter, you will have acquired a clear
    conceptual framework for what makes an AI system business-ready and practical
    experience in building the first bricks of an AI controller.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将通过OpenAI的LLM和多功能API展示如何实现情境意识和记忆保持。一个GenAISys系统如果没有坚实的记忆保持功能是无法工作的——没有记忆就没有情境，没有情境就没有可持续的生成。在本章中，我们将根据任务需求创建无记忆、短期、长期和多会话类型的模块。到本章结束时，你将获得一个清晰的框架，了解什么使AI系统适合商业应用，并在构建AI控制器的第一块砖石方面获得实践经验。
- en: 'In a nutshell, this chapter covers the following topics:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，本章涵盖了以下主题：
- en: Components of a business-ready GenAISys
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 适合商业应用的GenAISys组件
- en: AI controllers and agentic functionality (model-agnostic)
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AI控制器和代理功能（模型无关）
- en: Hybrid human roles and collaboration with AI
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 混合人类角色与AI协作
- en: Business opportunities and scope
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 商业机会和范围
- en: Contextual awareness through memory retention
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过记忆保持实现情境意识
- en: Let’s begin by defining what a business-ready GenAISys is.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从定义什么是适合商业应用的GenAISys开始。
- en: Components of a business-ready GenAISys
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 商业就绪的 GenAISys 的组成部分
- en: A business-ready GenAISys is a modular orchestrator that seamlessly integrates
    standard AI models with multifunctional frameworks to deliver hybrid intelligence.
    By combining generative AI with agentic functionality, RAG, **machine learning**
    (**ML**), web search, non-AI operations, and multiple-session memory systems,
    we are able to deliver scalable and adaptive solutions for diverse and complex
    tasks. Take ChatGPT, for example; people use the name “ChatGPT” interchangeably
    for the generative AI model as well as for the application itself. However, behind
    the chat interface, tools such as ChatGPT and Gemini are part of larger systems—online
    copilots—that are fully integrated and managed by intelligent AI controllers to
    provide a smooth user experience.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 一个商业就绪的 GenAISys 是一个模块化的编排器，它无缝地将标准人工智能模型与多功能框架集成，以提供混合智能。通过结合生成式人工智能与代理功能、RAG、**机器学习**（**ML**）、网络搜索、非人工智能操作和多个会话记忆系统，我们能够为各种复杂任务提供可扩展和自适应的解决方案。以
    ChatGPT 为例；人们将“ChatGPT”这个名称交替用于生成式人工智能模型以及该应用程序本身。然而，在聊天界面背后，ChatGPT 和 Gemini
    等工具是更大系统——在线副驾驶的一部分，这些系统由智能人工智能控制器完全集成和管理，以提供流畅的用户体验。
- en: 'It was Tomczak (2024) who took us from thinking of generative AI models as
    a collective entity to considering complex GenAISys architectures. His paper uses
    the term “GenAISys” to describe these more complex platforms. Our approach in
    this book will be to expand the horizon of a GenAISys to include advanced AI controller
    functionality and human roles in a business-ready ecosystem. There is no single
    silver-bullet architecture for a GenAISys. However, in this section, we’ll define
    the main components necessary to attain ChatGPT-level functionality. These include
    a generative AI model, memory retention functions, modular RAG, and multifunctional
    capabilities. How each component contributes to the GenAISys framework is illustrated
    in *Figure 1.1*:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 是 Tomczak（2024）将我们从将生成式人工智能模型视为一个集体实体转变为考虑复杂的 GenAISys 架构。他的论文使用“GenAISys”这个术语来描述这些更复杂的平台。本书中的方法将扩展
    GenAISys 的视野，包括商业就绪生态系统中高级人工智能控制器功能和人类角色。GenAISys 没有单一的银弹架构。然而，在本节中，我们将定义实现 ChatGPT
    级别功能所需的主要组件。这些包括生成式人工智能模型、记忆保持功能、模块化 RAG 和多功能能力。每个组件如何贡献于 GenAISys 框架在 *图 1.1*
    中得到了说明：
- en: '![Figure 1.1: GenAISys, the AI controller, and human roles](img/B32304_01_1.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.1：GenAISys，人工智能控制器和人类角色](img/B32304_01_1.png)'
- en: 'Figure 1.1: GenAISys, the AI controller, and human roles'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.1：GenAISys，人工智能控制器和人类角色
- en: Let’s now define the architecture of the AI controllers and human roles that
    make up a GenAISys.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来定义构成 GenAISys 的 AI 控制器和人类角色的架构。
- en: AI controllers
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 人工智能控制器
- en: At the heart of a business-ready GenAISys is an **AI controller** that activates
    custom ChatGPT-level features based on the context of the input. Unlike traditional
    pipelines with predetermined task sequences, the AI controller operates without
    a fixed order, dynamically adapting tasks—such as web search, image analysis,
    and text generation—based on the specific context of each input. This agentic
    context-driven approach enables the AI controller to orchestrate various components
    seamlessly, ensuring effective and coherent performance of the generative AI model.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 商业就绪的 GenAISys 的核心是一个 **人工智能控制器**，它根据输入上下文激活定制的 ChatGPT 级别功能。与传统具有预定任务序列的管道不同，人工智能控制器没有固定的顺序，根据每个输入的具体上下文动态地调整任务——如网络搜索、图像分析和文本生成。这种代理上下文驱动的方法使人工智能控制器能够无缝地编排各种组件，确保生成式人工智能模型的有效和连贯性能。
- en: 'A lot of work is required to achieve effective results with a custom ChatGPT-grade
    AI controller. However, the payoff is a new class of AI systems that can withstand
    real-world pressure and produce tangible business results. A solid AI controller
    ecosystem can support use cases across multiple domains: customer support automation,
    sales lead generation, production optimization (services and manufacturing), healthcare
    response support, supply chain optimization, and any other domain the market will
    take you! A GenAISys, thus, requires an AI controller to orchestrate multiple
    pipelines, such as contextual awareness to understand the intent of the prompt
    and memory retention to support continuity across sessions.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 要实现有效的结果，需要大量工作来定制ChatGPT级别的AI控制器。然而，回报是能够承受现实世界压力并产生实际业务成果的新一代AI系统。一个稳固的AI控制器生态系统可以支持多个领域的用例：客户支持自动化、销售线索生成、生产优化（服务和制造）、医疗响应支持、供应链优化以及市场将带你去到的任何其他领域！因此，GenAISys需要一个AI控制器来协调多个管道，例如上下文感知来理解提示的意图和记忆保持以支持会话间的连续性。
- en: The GenAISys must also define human roles, which determine which functions and
    data can be accessed. Before we move on to human roles, however, let’s first break
    down the key components that power the AI controller. As shown in *Figure 1.1*,
    the generative AI model, memory, modular RAG, and multifunctional capabilities
    each play vital roles in enabling flexible, context-driven orchestration. Let’s
    explore how these elements work together to build a business-ready GenAISys. We
    will first define the role of the generative AI model.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: GenAISys还必须定义人类角色，这些角色决定了哪些功能和数据可以访问。然而，在我们继续讨论人类角色之前，让我们首先分解驱动AI控制器的关键组件。如图*1.1*所示，生成式AI模型、记忆、模块化RAG和多功能能力在实现灵活、上下文驱动的协调中发挥着至关重要的作用。让我们探索这些元素如何协同工作来构建一个业务就绪的GenAISys。我们首先定义生成式AI模型的角色。
- en: Model-agnostic approach to generative AI
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 生成式AI的无模型方法
- en: When we build a sustainable GenAISys, we need model *interchangeability*—the
    flexibility to swap out the underlying model as needed. A generative AI model
    should serve as a component within the system, not as the core that the system
    is built around. That way, if our model is deprecated or requires updating, or
    we simply find a better-performing one, we can simply replace it with another
    that better fits our project.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们构建一个可持续的GenAISys时，我们需要模型*互操作性*——根据需要替换底层模型的灵活性。生成式AI模型应作为系统中的一个组件，而不是作为系统围绕其构建的核心。这样，如果我们的模型被弃用或需要更新，或者我们只是找到一个性能更好的模型，我们可以简单地用另一个更适合我们项目的模型来替换它。
- en: As such, the generative AI model can be OpenAI’s GPT, Google’s Gemini, Meta’s
    Llama, xAI’s Grok, or any Hugging Face model, as long as it supports the required
    tasks. Ideally, we should choose a multipurpose, multimodal model that encompasses
    text, vision, and reasoning abilities. Bommasani et al. (2021) provide a comprehensive
    analysis of such foundation models, whose scope reaches beyond LLMs.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，生成式AI模型可以是OpenAI的GPT、Google的Gemini、Meta的Llama、xAI的Grok或任何Hugging Face模型，只要它支持所需的任务。理想情况下，我们应该选择一个多用途、多模态模型，它包括文本、视觉和推理能力。Bommasani等人（2021年）对这些基础模型进行了全面分析，其范围超越了LLMs。
- en: 'A generative AI model has two main functions, as shown in *Figure 1.2*:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI模型有两个主要功能，如图*1.2*所示：
- en: '**Orchestrates** by determining which tasks need to be triggered based on the
    input. This input can be a user prompt or a system request from another function
    in the pipeline. The orchestration function agent can trigger web search, document
    parsing, image generation, RAG, ML functions, non-AI functions, and any other
    function integrated into the GenAISys.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**协调**通过确定基于输入需要触发哪些任务。这个输入可以是一个用户提示或来自管道中另一个功能的系统请求。协调功能代理可以触发网络搜索、文档解析、图像生成、RAG、ML函数、非AI函数以及任何集成到GenAISys中的其他功能。'
- en: '**Executes** the tasks requested by the orchestration layer or executes a task
    directly based on the input. For example, a simple query such as requesting the
    capital of the US will not necessarily require complex functionality. However,
    a request for document analysis might require several functions (chunking, embedding,
    storing, and retrieving).'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**执行**协调层请求的任务或直接根据输入执行任务。例如，一个简单的查询，如请求美国的首都，可能不需要复杂的功能。然而，对文档分析的要求可能需要几个功能（分块、嵌入、存储和检索）。'
- en: '![Figure 1.2: A generative AI model to orchestrate or execute tasks](img/B32304_01_2.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![图1.2：一个生成式AI模型来协调或执行任务](img/B32304_01_2.png)'
- en: 'Figure 1.2: A generative AI model to orchestrate or execute tasks'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.2：一个用于协调或执行任务的生成式AI模型
- en: Notice that *Figure 1.2* has a unique feature. There are no arrows directing
    the input, orchestration, and execution components. Unlike traditional hardcoded
    linear pipelines, a flexible GenAISys has its components unordered. We build the
    components and then let automated scenarios selected by the orchestration function
    order the tasks dynamically.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到*图1.2*有一个独特功能。没有箭头指向输入、协调和执行组件。与传统硬编码的线性管道不同，灵活的GenAISys组件是无序的。我们构建组件，然后让由协调函数选定的自动化场景动态排序任务。
- en: 'This flexibility ensures the system’s adaptability to a wide range of tasks.
    We will not be able to build a system that solves every task, but we can build
    one that satisfies a wide range of tasks within a company. Here are two example
    workflows that illustrate how a GenAISys can dynamically sequence tasks based
    on the roles involved:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这种灵活性确保了系统对各种任务的适应性。我们可能无法构建一个解决所有任务的系统，但我们可以构建一个满足公司内广泛任务需求的系统。以下两个示例工作流程说明了GenAISys如何根据涉及的角色动态排序任务：
- en: Human roles can be configured so that, in some cases, the user input executes
    a simple API call to provide a straightforward response, such as requesting the
    capital of a country. In this case, the generative AI model executes a request
    directly.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以配置人类角色，在某些情况下，用户输入执行一个简单的API调用以提供直接响应，例如请求一个国家的首都。在这种情况下，生成式AI模型直接执行请求。
- en: System roles can be configured dynamically to orchestrate a set of instructions,
    such as searching the web first and then summarizing the web page. In this case,
    the system goes through an orchestration process to produce an output.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 系统角色可以动态配置，以协调一系列指令，例如先搜索网页，然后总结网页内容。在这种情况下，系统会经过协调过程以生成输出。
- en: The possibilities are unlimited; however, all the scenarios will rely on the
    memory to ensure consistent, context-aware behavior. Let’s look at memory next.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 可能性无限；然而，所有场景都将依赖于记忆以确保一致、上下文感知的行为。让我们看看记忆。
- en: Building the memory of a GenAISys
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 构建GenAISys的记忆
- en: 'Advanced generative AI models such as OpenAI’s GPT, Meta’s Llama, xAI’s Grok,
    Google’s Gemini, and many Hugging Face variants are *context-driven* regardless
    of their specific version or performance level. You will choose the model based
    on your project, but the basic rule remains simple:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 高级生成式AI模型，如OpenAI的GPT、Meta的Llama、xAI的Grok、Google的Gemini以及许多Hugging Face变体，无论其具体版本或性能水平如何，都是*以上下文驱动的*。您将根据您的项目选择模型，但基本规则仍然简单：
- en: No-context => No meaningful generation
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 无上下文 => 无意义生成
- en: When we use ChatGPT or any other copilot, we have nothing to worry about as
    contextual memory is handled for us. We just start a dialogue, and things run
    smoothly as we adapt our prompt to the level of responses we are obtaining. However,
    when we develop a system with a generative AI API from scratch, we have to explicitly
    build contextual awareness and memory retention.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们使用ChatGPT或任何其他合作者时，我们无需担心，因为上下文记忆由我们处理。我们只需开始对话，然后根据我们获得的响应级别调整提示，事情就会顺利运行。然而，当我们从头开始开发一个使用生成式AI
    API的系统时，我们必须明确构建上下文意识和记忆保留。
- en: 'Four approaches stand out among the wide range of possible memory retention
    strategies with an API:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在众多可能的记忆保留策略中，有四种方法脱颖而出：
- en: '**Stateless and memoryless session**: A request is sent to the API, and a response
    is returned with no memory retention functionality.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无状态和无记忆会话**：向API发送请求，并返回响应，没有记忆保留功能。'
- en: '**Short-term memory session**: The exchanges between the requests and responses
    are stored in memory during the session but not beyond.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**短期记忆会话**：在会话期间，请求和响应之间的交换存储在记忆中，但不会超出会话范围。'
- en: '**Long-term memory of multiple sessions**: The exchanges between the requests
    and responses are stored in memory and memorized even after the session ends.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多个会话的长期记忆**：请求和响应之间的交换存储在记忆中，并在会话结束后被记住。'
- en: '**Long-term memory of multiple cross-topic sessions**: This feature links the
    long-term memory of multiple sessions to other sessions. Each session is assigned
    a role: a system or multiple users. This feature is not standard in platforms
    such as ChatGPT but is essential for workflow management within organizations.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多个跨主题会话的长期记忆**：此功能将多个会话的长期记忆链接到其他会话。每个会话都分配了一个角色：系统或多个用户。此功能在ChatGPT等平台上不是标准功能，但在组织内部的流程管理中至关重要。'
- en: '*Figure 1.3* sums up these four memory architectures. We’ll demonstrate each
    configuration in Python using GPT-4o in the upcoming section, *Contextual awareness
    and memory retention*.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '*图1.3*总结了这四种记忆架构。我们将在接下来的章节*上下文意识和记忆保持*中，使用GPT-4o在Python中演示每个配置。'
- en: '![Figure 1.3: Four different GenAISys memory configurations](img/B32304_01_3.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![图1.3：四种不同的GenAISys内存配置](img/B32304_01_3.png)'
- en: 'Figure 1.3: Four different GenAISys memory configurations'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.3：四种不同的GenAISys内存配置
- en: 'These four memory types serve as a starting point that can be expanded as necessary
    when developing a GenAISys. However, practical implementations often require additional
    functionality, including the following:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这四种记忆类型可以作为开发GenAISys时的起点，根据需要可以进一步扩展。然而，实际实现通常需要额外的功能，包括以下内容：
- en: '**Human roles** to define users or groups of users that can access session
    history or sets of sessions on multiple topics. This will take us beyond ChatGPT-level
    platforms. We will introduce this aspect in [*Chapter 2*](Chapter_2.xhtml#_idTextAnchor055),
    *Building the Generative AI Controller*.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**人类角色**来定义可以访问会话历史或多个主题的会话集的用户或用户组。这将使我们超越ChatGPT级别的平台。我们将在[*第2章*](Chapter_2.xhtml#_idTextAnchor055)中介绍这一方面，*构建生成式AI控制器*。'
- en: '**Storage strategies** to define what we need to store and what we need to
    discard. We will introduce storage strategies and take this concept further with
    a Pinecone vector store in [*Chapter 3*](Chapter_3.xhtml#_idTextAnchor085), *Integrating
    Dynamic RAG into the GenAISys*.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**存储策略**来定义我们需要存储什么，以及我们需要丢弃什么。我们将在第[*第3章*](Chapter_3.xhtml#_idTextAnchor085)中介绍存储策略，并在[*第3章*](Chapter_3.xhtml#_idTextAnchor085)中进一步探讨这个概念，即*将动态RAG集成到GenAISys中*。'
- en: 'There are native distinctions between two key categories of memorization in
    generative models:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在生成模型中，两种关键的记忆类别之间有本地的区别：
- en: '**Semantic memory**, which contains facts such as hard science'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**语义记忆**，包含如硬科学等事实'
- en: '**Episodic memory**, which contains personal timestamped memories such as personal
    events in time and business meetings'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**情景记忆**，包含个人时间戳记忆，如时间中的个人事件和商务会议'
- en: We can see that building a GenAISys’s memory requires careful design and deliberate
    development to implement ChatGPT-grade memory and additional memory configurations,
    such as long-term, cross-topic sessions. The ultimate goal, however, of this advanced
    memory system is to enhance the model’s contextual awareness. While generative
    AI models such as GPT-4o have inbuilt contextual awareness, to expand the scope
    of a context-driven system such as the GenAISys we’re building, we need to integrate
    advanced RAG functionality.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，构建GenAISys的内存需要仔细的设计和深思熟虑的开发来实现ChatGPT级别的记忆和额外的内存配置，如长期、跨主题会话。然而，这个高级记忆系统的最终目标却是增强模型的上下文意识。虽然像GPT-4o这样的生成式AI模型具有内置的上下文意识，但要扩展我们正在构建的以上下文驱动的系统（如GenAISys）的范围，我们需要集成高级RAG功能。
- en: RAG as an agentic multifunction co-orchestrator
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: RAG作为一个多功能的代理协同调度器
- en: 'In this section, we explain the motivations for using RAG for three core functions
    within a GenAISys:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们解释了在GenAISys内部使用RAG进行三个核心功能的动机：
- en: '**Knowledge retrieval:** Retrieving targeted, nuanced information'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**知识检索**：检索有针对性的、细微的信息'
- en: '**Context window optimization:** Engineering optimized prompts'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**上下文窗口优化**：工程优化的提示'
- en: '**Agentic orchestration of multifunctional capabilities**: Triggering functions
    dynamically'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多功能能力的代理调度**：动态触发功能'
- en: Let’s begin with knowledge retrieval.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从知识检索开始。
- en: 1\. Knowledge retrieval
  id: totrans-61
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 1. 知识检索
- en: 'Generative AI models excel when it comes to revealing parametric knowledge
    that they have learned, which is embedded in their weights. This knowledge is
    learned during training and embedded in models such as GPT, Llama, Grok, and Gemini.
    However, that knowledge stops at the cutoff date when no additional data is fed
    to the model. At that point, to update or supplement it, we have two options:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI模型在揭示它们所学习的参数化知识方面表现出色，这些知识嵌入在其权重中。这种知识是在训练期间学习的，并嵌入到GPT、Llama、Grok和Gemini等模型中。然而，当没有向模型提供更多数据时，这种知识就停止在截止日期。在那个时刻，为了更新或补充它，我们有两个选择：
- en: '**Implicit knowledge**: Fine-tune the model so that more trained knowledge
    is added to its weights (parametric). This process can be challenging if you are
    working with dynamic data that changes daily, such as weather forecasts, newsfeeds,
    or social media messages. It also comes with costs and risks if the fine-tuning
    process doesn’t work that well for your data.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**隐式知识**：微调模型，以便将更多训练知识添加到其权重（参数化）。如果你正在处理每天都会变化的数据，如天气预报、新闻源或社交媒体消息，这个过程可能会很具挑战性。如果微调过程对你的数据效果不佳，这也伴随着成本和风险。'
- en: '**Explicit knowledge**: Store the data in files or embed data in vector stores.
    The knowledge will then be structured, accessible, traceable, and updated. We
    can then retrieve the information with advanced queries.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**显式知识**：将数据存储在文件中或将数据嵌入到向量存储中。知识将因此结构化、可访问、可追溯和更新。然后我们可以使用高级查询检索信息。'
- en: It’s important to note here that static implicit knowledge cannot scale effectively
    without dynamic explicit knowledge. More on that in the upcoming chapters.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这里需要特别注意的是，没有动态显式知识的支持，静态隐式知识无法有效扩展。更多内容将在后续章节中介绍。
- en: 2\. Context window optimization
  id: totrans-66
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2. 上下文窗口优化
- en: 'Generative AI models are expanding the boundaries of context windows. For example,
    at the time of writing, the following are the supported context lengths:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式 AI 模型正在扩展上下文窗口的边界。例如，在撰写本文时，以下为支持的上下文长度：
- en: 'Llama 4 Scout: 10 million tokens'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Llama 4 Scout：1,000 万个标记
- en: 'Gemini 2.0 Pro Experimental: 2 million tokens'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gemini 2.0 Pro 实验：2,000,000 个标记
- en: 'Claude 3.7 Sonnet: 200,000 tokens'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Claude 3.7 诗篇：200,000 个标记
- en: 'GPT-4o: 128,000 tokens'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPT-4o：128,000 个标记
- en: While impressive, these large context windows can be expensive in terms of token
    costs and compute. Furthermore, the main issue is that their precision diminishes
    when the context becomes too large. Also, we don’t need the largest context window
    but only the one that best fits our project. This can justify implementing RAG
    if necessary to optimize a project.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这些大的上下文窗口令人印象深刻，但在标记成本和计算方面可能会很昂贵。此外，主要问题是当上下文变得过大时，它们的精度会降低。而且，我们不需要最大的上下文窗口，只需要最适合我们项目的那个。这可以证明在必要时实施
    RAG 以优化项目是有道理的。
- en: The chunking process of RAG splits large content into more nuanced groups of
    tokens. When we embed these chunks, they become vectors that can be stored and
    efficiently retrieved from vector stores. This approach ensures we use only the
    most relevant context per task, minimizing token usage and maximizing response
    quality. Thus, we can rely on generative AI capabilities for parametric implicit
    knowledge and RAG for large volumes of explicit non-parametric data in vector
    stores. We can take RAG further and use the method as an orchestrator.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: RAG 的分块过程将大型内容拆分为更细致的标记组。当我们嵌入这些块时，它们变成了可以存储和从向量存储中高效检索的向量。这种方法确保我们只为每个任务使用最相关的上下文，最小化标记使用并最大化响应质量。因此，我们可以依赖生成式
    AI 的参数化隐式知识能力，以及 RAG 在向量存储中的大量显式非参数数据。我们可以进一步扩展 RAG 并将其用作编排者。
- en: 3\. Agentic orchestrator of multifunctional capabilities
  id: totrans-74
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3. 多功能能力的代理编排者
- en: The AI controller bridges with RAG through the generative AI model. RAG is used
    to augment the model’s input with a flexible range of instructions. Now, using
    RAG to retrieve instructions might seem counterintuitive at first—but think about
    it. If we store instructions as vectors and retrieve the best set for a task,
    we get a fast, adaptable way to enable agentic functionality, generate effective
    results, and avoid the need to fine-tune the model every time we change our instruction
    strategies for how we want it to behave.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: AI 控制器通过生成式 AI 模型与 RAG 互通。RAG 用于通过灵活的指令范围增强模型的输入。现在，使用 RAG 检索指令可能一开始看起来有些反直觉——但想想看。如果我们把指令存储为向量，并为一项任务检索最佳集合，我们就能得到一种快速、灵活的方法来启用代理功能，生成有效结果，并避免每次更改我们希望其表现的行为的指令策略时都需要微调模型。
- en: 'These instructions act as optimized prompts, tailored to the task at hand.
    In this sense, RAG becomes part of the orchestration layer of the AI system. A
    vector store such as Pinecone can store and return this functional information,
    as illustrated in *Figure 1.4*:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这些指令作为优化的提示，针对当前任务量身定制。从这个意义上说，RAG 成为了 AI 系统编排层的一部分。如 *图 1.4* 所示，Pinecone 这样的向量存储可以存储并返回此功能信息：
- en: '![Figure 1.4: RAG orchestration functionality](img/B32304_01_4.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.4：RAG 编排功能](img/B32304_01_4.png)'
- en: 'Figure 1.4: RAG orchestration functionality'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.4：RAG 编排功能
- en: 'The orchestration of these scenarios is performed through the following:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这些场景的编排通过以下方式执行：
- en: '**Scenario retrieval**: The AI controller will receive structure instructions
    (scenarios) from a vector database, such as Pinecone, adapted to the user’s query'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**场景检索**：AI 控制器将从向量数据库（如 Pinecone）接收结构化指令（场景），这些指令是根据用户的查询进行适配的'
- en: '**Dynamic task activation**: Each scenario specifies a series of tasks, such
    as web search, ML algorithms, standard SQL queries, or any function we need'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**动态任务激活**：每个场景指定了一系列任务，例如网络搜索、机器学习算法、标准 SQL 查询或我们需要的任何功能'
- en: 'Adding classical functions and ML functionality to the GenAISys enhances its
    capabilities dramatically. The modular architecture of a GenAISys makes this multifunctional
    approach effective, as in the following use cases:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 将经典功能和机器学习功能添加到 GenAISys 中，可以显著增强其功能。GenAISys 的模块化架构使得这种多功能方法有效，如下面的用例所示：
- en: '**Web search** to perform real-time searches to augment inputs'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**网络搜索**进行实时搜索以增强输入'
- en: '**Document analysis** to process documents and populate the vector store'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文档分析**以处理文档并填充向量存储库'
- en: '**Document search** to retrieve parts of the processed documents from the vector
    store'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文档搜索**从向量存储库中检索处理过的文档的部分'
- en: '**ML** such as **K-means clustering** (**KMC**) to group data and **k-nearest
    neighbors** (**KNN**) for similarity searches'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**机器学习**，例如 **K-means 聚类**（**KMC**）用于分组数据，以及 **k 近邻**（**KNN**）用于相似性搜索'
- en: '**SQL queries** to execute rule-based retrieval on structured datasets'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**SQL 查询**以在结构化数据集上执行基于规则的检索'
- en: Any other function required for your project or workflow
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您项目或工作流程所需的其他任何功能
- en: RAG remains a critical component of a GenAISys, which we will build into our
    GenAISys in [*Chapter 3*](Chapter_3.xhtml#_idTextAnchor085), *Integrating Dynamic
    RAG into the GenAISys*. In [*Chapter 3*](Chapter_3.xhtml#_idTextAnchor085)*, Integrating
    Dynamic RAG into the GenAISys*, we will also enhance the system with multifunctional
    features.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: RAG 仍然是 GenAISys 的一个关键组件，我们将在 [*第 3 章*](Chapter_3.xhtml#_idTextAnchor085) 中将其构建到我们的
    GenAISys 中，*将动态 RAG 集成到 GenAISys 中*。在 [*第 3 章*](Chapter_3.xhtml#_idTextAnchor085)*将动态
    RAG 集成到 GenAISys 中* 中，我们还将增强系统的多功能特性。
- en: We’ll now move on to the human roles, which form the backbone of any GenAISys.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将转向人类角色，它们是任何 GenAISys 的骨架。
- en: Human roles
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 人类角色
- en: Contrary to popular belief, the successful deployment and operation of a GenAISys—such
    as the ChatGPT platform—relies heavily on human involvement throughout its entire
    life cycle. While these tools may seem to handle complex tasks effortlessly, behind
    the scenes are multiple layers of human expertise, oversight, and coordination
    that make their smooth operation possible.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 与公众普遍的看法相反，GenAISys（如 ChatGPT 平台）的成功部署和运营在其整个生命周期中高度依赖于人类参与。虽然这些工具可能看起来可以轻松处理复杂任务，但在幕后有多个层次的人类专业知识、监督和协调，使得它们能够平稳运行。
- en: Software professionals must first design the architecture, process massive datasets,
    and fine-tune the system on million-dollar servers equipped with cutting-edge
    compute resources. After deployment, large teams are required to monitor, validate,
    and interpret system outputs—continuously adapting them in response to errors,
    emerging technologies, and regulatory changes. On top of that, when it comes to
    deploying these systems within organizations—whether inside corporate intranets,
    public-facing websites, research environments, or learning management systems—it
    takes cross-functional coordination efforts across multiple domains.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 软件专业人员必须首先设计架构，处理大量数据集，并在配备尖端计算资源的百万美元服务器上微调系统。部署后，需要大型团队来监控、验证和解释系统输出——持续适应错误、新兴技术和监管变化。此外，当涉及到在组织内部部署这些系统时——无论是在企业内部网、面向公众的网站、研究环境还是学习管理系统——需要跨多个领域的跨职能协调努力。
- en: These tasks require high levels of expertise and qualified teams. Humans are,
    therefore, not just irreplaceable; they are critical! They are architects, supervisors,
    curators, and guardians of the AI systems they create and maintain.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 这些任务需要高水平的专业知识和合格的团队。因此，人类不仅不可替代，而且是至关重要的！他们是他们创建和维护的 AI 系统的建筑师、监督者、馆长和守护者。
- en: GenAISys implementation and governance teams
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: GenAISys 的实施和管理团队
- en: 'Implementing a GenAISys requires technical skills and teamwork to gain the
    support of end users. It’s a collaborative challenge between AI controller design,
    user roles, and expectations. To anyone who thinks that deploying a real-world
    AI system is just about getting access to a model—such as the latest GPT, Llama,
    or Gemini—a close look at the resources required will reveal the true challenges.
    A massive number of human resources might be involved in the development, deployment,
    and maintenance of an AI system. Of course, not every organization will need all
    of these roles, but we must recognize the range of skills involved, such as the
    following:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 实施GenAISys需要技术技能和团队合作来获得最终用户的支持。这是AI控制器设计、用户角色和期望之间的协作挑战。对于任何认为部署现实世界AI系统只是获取模型——如最新的GPT、Llama或Gemini——的人来说，仔细查看所需资源将揭示真正的挑战。可能需要大量的人力资源来开发、部署和维护AI系统。当然，并非每个组织都需要所有这些角色，但我们必须认识到涉及的技能范围，如下所示：
- en: '**Project manager** (**PM**)'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**项目经理**（**PM**）'
- en: Product manager
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 产品经理
- en: Program manager
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 项目经理
- en: '**ML engineer** (**MLE**)/data scientist'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**机器学习工程师**（**MLE**）/数据科学家'
- en: Software developer/**backend engineer** (**BE**)
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 软件开发员/**后端工程师**（**BE**）
- en: '**Cloud engineer** (**CE**)'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**云工程师**（**CE**）'
- en: '**Data engineer** (**DE**) and privacy manager'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据工程师**（**DE**）和隐私经理'
- en: UI/UX designer
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: UI/UX设计师
- en: Compliance and regulatory officer
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 合规和监管官员
- en: Legal counsel
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 法律顾问
- en: '**Security engineer** (**SE**) and security officer'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全工程师**（**SE**）和安全官'
- en: Subject-matter experts for each domain-specific deployment
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个特定部署领域的主题专家
- en: '**Quality assurance engineer** (**QAE**) and tester'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**质量保证工程师**（**QAE**）和测试员'
- en: Technical documentation writer
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 技术文档编写员
- en: System maintenance and support technician
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 系统维护和支持技术人员
- en: User support
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户支持
- en: Trainer
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练员
- en: These are just examples—just enough to show how many different roles are involved
    in building and operating a full-scale GenAISys. *Figure 1.5* shows that designing
    and implementing a GenAISys is a continual process, where human resources are
    needed at every stage.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 这些只是例子——仅足够展示在构建和运营一个全规模GenAISys中涉及多少不同的角色。*图1.5*显示，设计和实施GenAISys是一个持续的过程，每个阶段都需要人力资源。
- en: '![Figure 1.5: A GenAISys life cycle](img/B32304_01_5.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![图1.5：GenAISys生命周期](img/B32304_01_5.png)'
- en: 'Figure 1.5: A GenAISys life cycle'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.5：GenAISys生命周期
- en: 'We can see that a GenAISys life cycle is a never-ending process:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，GenAISys生命周期是一个永无止境的过程：
- en: '**Business requirements** will continually evolve with market constraints'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**业务需求**将随着市场约束不断演变'
- en: '**GenAISys** design will have to adapt with each business shift'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GenAISys**的设计必须随着每个业务转变而适应'
- en: '**AI controller** specifications must adapt to technological progress'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AI控制器**规范必须适应技术进步'
- en: '**Implementation** must adapt to ever-changing business specifications'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实施**必须适应不断变化的企业规范'
- en: '**User feedback** will drive continual improvement'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**用户反馈**将推动持续改进'
- en: Real-world AI relies heavily on human abilities—the kind of contextual and technical
    understanding that AI alone cannot replicate. AI can automate a wide range of
    tasks effectively. But it’s humans who bring the deep insight needed to align
    those systems with real business goals.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 现实世界的AI严重依赖人类能力——那种AI本身无法复制的情境和技术理解。AI可以有效地自动化广泛的任务。但正是人类带来了与真实业务目标对齐所需的深刻洞察。
- en: Let’s take this further and look at a RACI heatmap to show why humans are a
    critical component of a GenAISys.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们进一步探讨，看看RACI热图来展示为什么人类是GenAISys的一个关键组成部分。
- en: GenAISys RACI
  id: totrans-125
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: GenAISys RACI
- en: Organizing a GenAISys project requires human resources that go far beyond what
    AI automation alone can provide. **RACI** is a responsibility assignment matrix
    that helps define roles and responsibilities for each task or decision by identifying
    who is **Responsible**, **Accountable**, **Consulted**, and **Informed**. RACI
    is ideal for managing the complexity of building a GenAISys. It adds structure
    to the growing list of human roles required during the system’s life cycle and
    provides a pragmatic framework for coordinating their involvement.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 组织GenAISys项目需要的人力资源远远超出了仅靠AI自动化所能提供的。**RACI**是一个责任分配矩阵，通过确定谁负责（**Responsible**）、负责（**Accountable**）、咨询（**Consulted**）和通知（**Informed**），帮助定义每个任务或决策的角色和责任。RACI非常适合管理构建GenAISys的复杂性。它为系统生命周期中所需的人类角色增长列表增添了结构，并为协调他们的参与提供了一个实用框架。
- en: 'As in any complex project, teams working on a GenAISys need to collaborate
    across disciplines, and RACI helps define who does what. Each letter in RACI stands
    for a specific type of role:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 与任何复杂项目一样，在 GenAISys 上工作的团队需要在多个学科之间进行协作，RACI 有助于定义谁做什么。RACI 中的每个字母代表一种特定的角色类型：
- en: '**R (Responsible):** The person(s) who works actively on the task. They are
    responsible for the proper completion of the work. For example, an MLE may be
    responsible for processing datasets with ML algorithms.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**R（责任人）**：积极从事任务的人。他们负责工作的适当完成。例如，MLE 可能负责使用机器学习算法处理数据集。'
- en: '**A (Accountable):** The person(s) answerable for the success or failure of
    a task. They oversee the task that somebody else is responsible for carrying out.
    For example, the **product owner** (**PO**) will have to make sure that the MLE’s
    task is done on time and in compliance with the specifications. If not, the PO
    will be accountable for the failure.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**A（问责人）**：对任务的成功或失败负责的人。他们监督其他人负责执行的任务。例如，**产品负责人**（**PO**）必须确保 MLE 的任务按时并符合规格完成。如果没有，PO
    将对失败负责。'
- en: '**C (Consulted)**: The person(s) providing input, advice, and feedback to help
    the others in a team. They are not responsible for executing the work. For example,
    a subject-matter expert in retail may help the MLE understand the goal of an ML
    algorithm.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**C（咨询者）**：向团队中的其他人提供输入、建议和反馈以帮助他们的人。他们不负责执行工作。例如，零售领域的专家可能帮助 MLE 理解机器学习算法的目标。'
- en: '**I (Informed)**: The person(s) kept in the loop about the progress or outcome
    of a task. They don’t participate in the task but want to be simply informed or
    need to make decisions. For example, a **data privacy officer** (**DPO**) would
    like to be informed about a system’s security functionality.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**I（知情者）**：被保持在任务进度或结果循环中的人。他们不参与任务，但只想简单地了解或需要做出决定。例如，**数据隐私官**（**DPO**）可能希望了解系统的安全功能。'
- en: 'A RACI heatmap typically contains legends for each human role in a project.
    Let’s build a heatmap with the following roles:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: RACI 热图通常包含项目中每个人类角色的图例。让我们构建一个包含以下角色的热图：
- en: The **MLE** develops and integrates AI models
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**MLE** 开发和集成 AI 模型'
- en: The **DE** designs data management pipelines
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据工程师**（**DE**）设计数据管理管道'
- en: The **BE** builds API interactions
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**BE** 构建 API 交互'
- en: The **frontend engineer** (**FE**) develops end user features
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**前端工程师**（**FE**）开发面向最终用户的功能'
- en: The **UI/UX designer** designs user interfaces
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**UI/UX 设计师**设计用户界面'
- en: The **CE/DevOps engineer** manages cloud infrastructure
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**CE/DevOps 工程师**管理云基础设施'
- en: The **prompt engineer** (**PE**) designs optimal prompts
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提示工程师**（**PE**）设计最佳提示'
- en: The **SE** handles secure data and access
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**SE** 处理安全数据和访问'
- en: The **DPO** manages data governance and regulation compliance
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**DPO** 管理数据治理和法规遵从性'
- en: The **legal/compliance officer** (**LC**) reviews the legal scope of a project
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**法律/合规官**（**LC**）审查项目的法律范围'
- en: The **QAE** tests the GenAISys
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**QAE** 测试 GenAISys'
- en: The **PO** defines the scope and scale of a product
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**产品负责人**（**PO**）定义产品的范围和规模'
- en: The **PM** coordinates resources and timelines
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**项目经理**（**PM**）协调资源和时间表'
- en: The **technical writer** (**TW**) produces documentation
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**技术文档编写者**（**TW**）制作文档'
- en: The **vendor manager** (**VM**) communicates with external vendors and service
    providers
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**供应商经理**（**VM**）与外部供应商和服务提供商沟通'
- en: 'Not every GenAISys project will include all of these roles, but depending on
    the scope and scale of the project, many of them will be critical. Now, let’s
    list the key responsibilities of the roles defined above in a typical generative
    AI project:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 并非每个 GenAISys 项目都会包含所有这些角色，但根据项目的范围和规模，其中许多角色将是关键的。现在，让我们列出在典型的生成式 AI 项目中定义的角色的关键职责：
- en: '**Model**: AI model development'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型**：AI 模型开发'
- en: '**Controller**: Orchestration of APIs and multimodal components'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**控制器**：API 和多模态组件的编排'
- en: '**Pipelines**: Data processing and integration workflows'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**管道**：数据处理和集成工作流程'
- en: '**UI/UX**: User interface and experience design'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**UI/UX**：用户界面和体验设计'
- en: '**Security**: Data protection and access control'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全**：数据保护和访问控制'
- en: '**DevOps**: Infrastructure, scaling, and monitoring'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**DevOps**：基础设施、扩展和监控'
- en: '**Prompts**: Designing and optimizing model interactions'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提示**：设计和优化模型交互'
- en: '**QA**: Testing and quality assurance'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**QA**：测试和质量保证'
- en: We’ve defined the roles and the tasks. Now, we can show how they can be mapped
    to a real-world scenario. *Figure 1.6* illustrates an example RACI heatmap for
    a GenAISys.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经定义了角色和任务。现在，我们可以展示它们如何映射到现实世界场景。*图1.6*展示了GenAISys的一个示例RACI热图。
- en: '![Figure 1.6: Example of a RACI heatmap](img/B32304_01_6.png)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![图1.6：RACI热图示例](img/B32304_01_6.png)'
- en: 'Figure 1.6: Example of a RACI heatmap'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.6：RACI热图示例
- en: 'For example, in this heatmap, the MLE has the following responsibilities:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在这个热图中，MLE有以下职责：
- en: (**R**)esponsible and (**A**)ccountable for the model, which could be GPT-4o.
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: （**R**）对模型负责，该模型可能是GPT-4o。
- en: (**R**)esponsible and (**A**)ccountable for the prompts for the model
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: （**R**）对模型的提示负责和（**A**）负责
- en: (**C**)onsulted as an expert for the controller, the pipeline, and testing (QA)
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: （**C**）作为控制器、管道和测试（QA）的专家咨询
- en: (**I**)nformed about the UI/UX, security, and DevOps
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: （**I**）了解UI/UX、安全和DevOps
- en: 'We can sum it up with one simple rule for a GenAISys:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以用一条简单的规则来总结GenAISys：
- en: No humans -> no system!
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 没有人 -> 没有系统！
- en: We can see that *we* are necessary during the whole life cycle of a GenAISys,
    from design to maintenance and support, including continual evolutions to keep
    up with user feedback. Humans have been and will be here for a long time! Next,
    let’s explore the business opportunities that a GenAISys can unlock.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，*我们*在整个GenAISys的生命周期中都是必要的，从设计到维护和支持，包括持续进化以跟上用户反馈。人类已经在这里，并将长期存在！接下来，让我们探索GenAISys可以解锁的商业机会。
- en: Business opportunities and scope
  id: totrans-168
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 商业机会和范围
- en: More often than not, we will not have access to the incredible billion-dollar
    resources of OpenAI, Meta, xAI, or Microsoft Azure to build ChatGPT-like platforms.
    The previous section showed that beneath a ChatGPT-like, seemingly simple, seamless
    interface, there is a complex layer of expensive infrastructure, rare talent,
    and continuous improvement and evolution that absorb resources only large corporations
    can afford. Therefore, a smarter path from the start is to determine which project
    category we are in and leverage the power of existing modules and libraries to
    build our GenAISys. Whatever the use case, such as marketing, finance, production,
    or support, we need to find the right scope and scale to implement a realistic
    GenAISys.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 更多的时候，我们无法获得OpenAI、Meta、xAI或Microsoft Azure等不可思议的数十亿美元资源来构建类似ChatGPT的平台。上一节展示了，在类似ChatGPT的看似简单、无缝的界面之下，有一个复杂的、昂贵的基础设施层、罕见的人才以及持续改进和演变，这些都需要只有大公司才能负担的资源。因此，从一开始就选择一条更聪明的路径，确定我们处于哪个项目类别，并利用现有模块和库的力量来构建我们的GenAISys。无论用例如何，如营销、金融、生产或支持，我们都需要找到合适的范围和规模来实现一个现实的GenAISys。
- en: The first step of any GenAISys is to define the project’s goal (opportunity),
    including its scope and scale, as we mentioned. During this step, you will assess
    the risks, such as costs, confidentiality, and resource availability (risk management).
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 任何GenAISys的第一步是定义项目的目标（机会），包括其范围和规模，正如我们提到的。在这一步中，你将评估风险，如成本、机密性和资源可用性（风险管理）。
- en: 'We can classify GenAISys projects into three main business implementation types
    depending on our resources, our objectives, the complexity of our use case, and
    our budget. These are illustrated in *Figure 1.7*:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以根据我们的资源、我们的目标、用例的复杂性和我们的预算，将GenAISys项目分为三种主要业务实现类型。这些在*图1.7*中展示：
- en: '**Hybrid approach**: Leveraging existing AI platforms'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**混合方法**：利用现有的AI平台'
- en: '**Small scope and scale**: A focused GenAISys'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**小范围和规模**：一个专注的GenAISys'
- en: '**Full-scale generative multi-agent AI system**: A complete ChatGPT-level generative
    AI platform'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**全面生成式多智能体AI系统**：一个完整的ChatGPT级生成式AI平台'
- en: '![Figure 1.7: The three main GenAISys business implementations](img/B32304_01_7.png)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![图1.7：三个主要的GenAISys业务实现](img/B32304_01_7.png)'
- en: 'Figure 1.7: The three main GenAISys business implementations'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.7：三个主要的GenAISys业务实现
- en: Let’s begin with a hybrid approach, a practical way to deliver business results
    without overbuilding.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从混合方法开始，这是一种在不过度建设的情况下实现业务成果的实用方法。
- en: Hybrid approach
  id: totrans-178
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 混合方法
- en: A hybrid framework enables you to minimize development costs and time by combining
    ready-to-use SaaS platforms with custom-built components developed only when necessary,
    such as web search and data cleansing. This way, you can leverage the power of
    generative AI without developing everything from scratch. Let’s go through the
    key characteristics and a few example use cases.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 混合框架允许你通过结合现成的SaaS平台和仅在必要时定制的组件（如网络搜索和数据清洗）来最小化开发成本和时间。这样，你可以在不从头开始开发一切的情况下利用生成式AI的力量。让我们通过关键特性和一些示例用例来探讨。
- en: Key characteristics
  id: totrans-180
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 关键特性
- en: Relying on proven web services such as OpenAI’s GPT API, AWS, Google AI, or
    Microsoft Azure. These platforms provide the core generative functionality.
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 依赖于经过验证的云服务，如OpenAI的GPT API、AWS、Google AI或Microsoft Azure。这些平台提供了核心的生成功能。
- en: Customizing your project by integrating domain-specific vector stores and your
    organization’s proprietary datasets.
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过整合特定领域的向量存储和你的组织专有的数据集来定制你的项目。
- en: Focusing development on targeted functionality, such as customer support automation
    or marketing campaign generation.
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 专注于开发目标功能，例如客户支持自动化或营销活动生成。
- en: Use case examples
  id: totrans-184
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 用例示例
- en: Implementing a domain-specific vector store to handle legal, medical, or product-related
    customer queries
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实施特定领域的向量存储以处理法律、医疗或产品相关的客户查询。
- en: Building customer support on a social media platform with real-time capabilities
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在社交媒体平台上构建具有实时功能的客户支持系统。
- en: This category offers the ability to do more with less—in terms of both cost
    and development effort. A hybrid system can be a standalone GenAISys or a subsystem
    within a larger generative AI platform where full-scale development isn’t necessary.
    Let’s now look at how a small-scope, small-scale GenAISys can take us even further.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类别提供了以更少的成本和开发努力做更多的事情的能力——在成本和开发努力方面。一个混合系统可以是独立的GenAISys，也可以是更大生成式AI平台内的子系统，其中不需要全面开发。现在让我们看看一个小范围、小规模的GenAISys如何能带我们更进一步。
- en: Small scope and scale
  id: totrans-188
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 小范围和规模
- en: A small-scale GenAISys might include an intelligent, GenAI-driven AI controller
    connected to a vector store. This setup allows the system to retrieve data, trigger
    instructions, and call additional functionality such as web search or ML—without
    needing full-scale infrastructure.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 一个小规模的GenAISys可能包括一个智能的、由GenAI驱动的AI控制器，连接到向量存储。这种配置允许系统检索数据、触发指令并调用额外的功能，如网络搜索或机器学习——而不需要全规模的基础设施。
- en: Key characteristics
  id: totrans-190
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 关键特性
- en: A clearly defined profitable system designed to achieve reasonable objectives
    with optimal development time and cost
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个明确定义的盈利系统，旨在通过最优的开发时间和成本实现合理的目标。
- en: The AI controller orchestrates instruction scenarios that, in turn, trigger
    RAG, web search, image analysis, and additional custom tasks that fit your needs
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人工智能控制器协调指令场景，进而触发RAG、网络搜索、图像分析和符合你需求的额外自定义任务。
- en: The focus is on high-priority, productive features
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重点是高优先级、高效能的特性
- en: Use case examples
  id: totrans-194
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 用例示例
- en: A GenAISys for document retrieval and summarization for any type of document
    with nuanced analysis through chunked and embedded content
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个用于文档检索和摘要的GenAISys，可以对任何类型的文档进行细微的分析，通过分块和嵌入的内容进行。
- en: Augmenting a model such as GPT or Llama with real-time web search to bypass
    its data cutoff date—ideal for applications such as weather forecasting or news
    monitoring that don’t need continual fine-tuning
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过实时网络搜索增强GPT或Llama等模型，以绕过其数据截止日期——非常适合需要不断微调的应用，如天气预报或新闻监控。
- en: This category takes us a step beyond the hybrid approach, while still staying
    realistic and manageable for small to mid-sized businesses or even individual
    departments within large organizations.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类别将我们带入了混合方法的更高层次，同时仍然保持对中小型企业或大型组织内部部门来说既现实又可管理的状态。
- en: Full-scale GenAISys
  id: totrans-198
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 全规模GenAISys
- en: If you’re working in a team of experts within an organization that has a large
    budget and advanced infrastructure, this category is for you. Your team can build
    a full-scale GenAISys that begins to approach the capabilities of ChatGPT-grade
    platforms.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在一个拥有大量预算和先进基础设施的组织中的专家团队工作，这个类别适合你。你的团队可以构建一个全规模的GenAISys，开始接近ChatGPT级平台的性能。
- en: Key characteristics
  id: totrans-200
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 关键特性
- en: A full-blown AI controller that manages and orchestrates complex automated workflows,
    including RAG, instruction scenarios, multimodal functionality, and real-time
    data
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个完整的AI控制器，可以管理和协调复杂的自动化工作流程，包括RAG、指令场景、多模态功能和实时数据。
- en: Requires significant computing resources and highly skilled development teams
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要大量的计算资源和高度熟练的开发团队
- en: Think of the GenAISys we’re building in this book as an alpha version—a template
    that can be cloned, configured, and deployed anywhere in the organization as often
    as needed.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 将本书中构建的GenAISys视为一个alpha版本——一个可以克隆、配置并在组织中的任何地方按需部署的模板。
- en: Use case examples
  id: totrans-204
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 用例示例
- en: 'GenAISys is already present in healthcare to assist with patient diagnosis
    and disease prevention. The Institut Curie in Paris, for example, has a very advanced
    AI research team: [https://institut-curie.org/](https://institut-curie.org/).'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GenAISys 已经在医疗保健领域出现，用于协助患者诊断和疾病预防。例如，巴黎的居里研究所拥有一个非常先进的AI研究团队：[https://institut-curie.org/](https://institut-curie.org/).
- en: Many large organizations have begun implementing GenAISys for fraud detection,
    weather predictions, and legal expertise.
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 许多大型组织已经开始实施GenAISys用于欺诈检测、天气预报和法律专业知识。
- en: You can join one of these large organizations that have the resources to build
    a sustainable GenAISys, whether it be on a cloud platform, local servers, or both.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以加入这些大型组织之一，它们拥有构建可持续GenAISys的资源，无论是在云平台上、本地服务器上还是在两者上。
- en: The three categories—hybrid, small scale, and full scale—offer distinct paths
    for building a GenAISys, depending on your organization’s goals, budget, and technical
    capabilities. In this book, we’ll explore the critical components that make up
    a GenAISys. By the end, you’ll be equipped to contribute to any of these categories
    and offer realistic, technically grounded recommendations for the projects you
    work on.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 这三个类别——混合型、小规模和大规模——为构建GenAISys提供了不同的路径，具体取决于您组织的目标、预算和技术能力。在本书中，我们将探讨构成GenAISys的关键组件。到结束时，您将能够为这些类别中的任何一个做出贡献，并为您正在工作的项目提供现实、技术基础的建议。
- en: Let’s now lift the hood and begin building contextual awareness and memory retention
    in code.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们揭开盖子，开始构建代码中的情境意识和记忆保持。
- en: Contextual awareness and memory retention
  id: totrans-210
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 情境意识和记忆保持
- en: In this section, we’ll begin implementing simulations of contextual awareness
    and memory retention in Python to illustrate the concepts introduced in the *Building
    the memory of a GenAISys* section. The goal is to demonstrate practical ways to
    manage context and memory—two features that are becoming increasingly critical
    as generative AI platforms evolve.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将开始使用Python实现情境意识和记忆保持的模拟，以说明在 *构建GenAISys的记忆* 部分中引入的概念。目标是展示管理情境和记忆的实用方法——这两个功能随着生成式AI平台的演变变得越来越重要。
- en: 'Open the `Contextual_Awareness_and_Memory_Retention.ipynb` file located in
    the `chapter01` folder of the GitHub repository ([https://github.com/Denis2054/Building-Business-Ready-Generative-AI-Systems/tree/main](https://github.com/Denis2054/Building-Business-Ready-Generative-AI-Systems/tree/main)).
    You’ll see that the notebook is divided into five main sections:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 打开位于GitHub存储库 `chapter01` 文件夹中的 `Contextual_Awareness_and_Memory_Retention.ipynb`
    文件([https://github.com/Denis2054/Building-Business-Ready-Generative-AI-Systems/tree/main](https://github.com/Denis2054/Building-Business-Ready-Generative-AI-Systems/tree/main))。您会看到笔记本被分为五个主要部分：
- en: '**Setting up the environment**, building reusable functions, and storing them
    in the `commons` directory of the repository, so we can reuse them when necessary
    throughout the book'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**设置环境**，构建可重用函数，并将它们存储在存储库的 `commons` 目录中，这样我们就可以在整本书中必要时重复使用它们'
- en: '**Stateless and memoryless session** with semantic and episodic memory'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无状态和无记忆会话**具有语义和情景记忆'
- en: '**Short-term memory session** for context awareness during a session'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**短期记忆会话**用于会话期间的情境意识'
- en: '**Long-term memory across multiple sessions** for context retention across
    different sessions'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**跨多个会话的长期记忆**用于跨不同会话的情境保留'
- en: '**Long-term memory of multiple cross-topic sessions**, expanding long-term
    memory over formerly separate sessions'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多个跨主题会话的长期记忆**，扩展长期记忆覆盖以前分开的会话'
- en: The goal is to illustrate each type of memory in an explicit process. These
    examples are intentionally kept manual for now, but they will be automated and
    managed by the AI controller we will begin to build in the next chapter.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是明确地展示每种记忆类型的过程。这些示例目前故意保持手动，但它们将被自动化并由我们在下一章开始构建的AI控制器管理。
- en: Due to the probabilistic nature of generative models, you may observe different
    outputs for the same prompt across runs. Make sure to run the entire notebook
    in a single session, as memory retention in this notebook is explicit in different
    cells. In [*Chapter 2*](Chapter_2.xhtml#_idTextAnchor055), this functionality
    will become persistent and fully managed by the AI controller
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 由于生成模型的概率性质，您可能会在不同的运行中观察到相同的提示符产生不同的输出。请确保在单个会话中运行整个笔记本，因为在这个笔记本中，内存保留在不同单元格中是明确的。在[*第2章*](Chapter_2.xhtml#_idTextAnchor055)中，此功能将变得持久并由AI控制器完全管理
- en: The first step is to install the environment.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是安装环境。
- en: Setting up the environment
  id: totrans-221
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置环境
- en: We will need a `commons` directory for our GenAISys project. This directory
    will contain the main modules and libraries needed across all notebooks in this
    book’s GitHub repository. The motivation is to focus on designing the system for
    maintenance and support. As such, by grouping the main modules and libraries in
    one directory, we can zero in on a resource that requires our attention instead
    of repeating the setup steps in every notebook. Furthermore, this section will
    serve as a reference point for all the notebooks in this book’s GitHub repository.
    We’ll only describe the downloading of each resource once and then reuse them
    throughout the book to build our educational GenAISys.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要一个`commons`目录来存放我们的GenAISys项目。此目录将包含本书GitHub存储库中所有笔记本所需的主要模块和库。动机是专注于设计维护和支持的系统。因此，通过将主要模块和库分组在一个目录中，我们可以专注于需要我们注意的资源，而不是在每个笔记本中重复设置步骤。此外，本节将作为本书GitHub存储库中所有笔记本的参考点。我们将只描述下载每个资源一次，然后在全书各处重用它们来构建我们的教育GenAISys。
- en: Thus, we can download the notebook resources from the `commons` directory and
    install the requirements.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们可以从`commons`目录下载笔记本资源并安装需求。
- en: 'The first step is to download `grequests.py`, a utility script we will use
    throughout the book. It contains a function to download the files we need directly
    from GitHub:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是下载`grequests.py`，这是一个我们将全书使用的实用脚本。它包含一个函数，可以直接从GitHub下载我们需要的文件：
- en: '[PRE0]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '![](img/3-PPMUMLAP0325.png)**Quick tip**: Enhance your coding experience with
    the **AI Code Explainer** and **Quick Copy** features. Open this book in the next-gen
    Packt Reader. Click the **Copy** button'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/3-PPMUMLAP0325.png)**快速提示**：使用**AI代码解释器**和**快速复制**功能增强您的编码体验。在下一代Packt
    Reader中打开此书。点击**复制**按钮'
- en: (**1**) to quickly copy code into your coding environment, or click the **Explain**
    button
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: （**1**）快速将代码复制到您的编码环境，或点击**解释**按钮
- en: (**2**) to get the AI assistant to explain a block of code to you.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: （**2**）让AI助手为您解释代码块。
- en: '![A white background with a black text  AI-generated content may be incorrect.](img/image_%282%29.png)'
  id: totrans-229
  prefs: []
  type: TYPE_IMG
  zh: '![一个白色背景上带有黑色文字的AI生成内容可能不正确。](img/image_%282%29.png)'
- en: '![](img/4.png)**The next-gen Packt Reader** is included for free with the purchase
    of this book. Scan the QR code OR visit [packtpub.com/unlock](http://packtpub.com/unlock),
    then use the search bar to find this book by name. Double-check the edition shown
    to make sure you get the right one.'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/4.png)**下一代Packt Reader**随本书免费赠送。扫描二维码或访问[packtpub.com/unlock](http://packtpub.com/unlock)，然后使用搜索栏通过名称查找此书。请仔细检查显示的版本，以确保您获得正确的版本。'
- en: '![A qr code on a white background  AI-generated content may be incorrect.](img/Unlock_Code1.png)'
  id: totrans-231
  prefs: []
  type: TYPE_IMG
  zh: '![一个白色背景上的二维码AI生成内容可能不正确。](img/Unlock_Code1.png)'
- en: 'The goal of this script is to download a file from any directory of the repository
    by calling the `download` function from `grequests`:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 该脚本的目的是通过调用`grequests`中的`download`函数从存储库的任何目录下载文件：
- en: '[PRE1]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This function uses a `curl` command to download files from a specified directory
    and filename. It also includes basic error handling in case of command execution
    failures.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数使用`curl`命令从指定的目录和文件名下载文件。它还包括基本的错误处理，以防命令执行失败。
- en: 'The code begins by importing `subprocess` to handle paths and commands. The
    `download` function contains two parameters:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 代码首先导入`subprocess`来处理路径和命令。`download`函数包含两个参数：
- en: '[PRE2]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '`directory`: The subdirectory of the GitHub repository where the file is stored'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`directory`：存储文件的GitHub存储库子目录'
- en: '`filename`: The name of the file to download'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`filename`：要下载的文件名'
- en: 'The base URL for the GitHub repository is then defined, pointing to the raw
    files we will need:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 然后定义GitHub存储库的基本URL，指向我们将需要的原始文件：
- en: '[PRE3]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We now need to define the file’s full URL with the `directory` and `filename`
    parameters:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在需要使用`directory`和`filename`参数定义文件的完整URL：
- en: '[PRE4]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The function now defines the `curl` command:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 函数现在定义了`curl`命令：
- en: '[PRE5]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Finally, the `download` command is executed:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，执行`download`命令：
- en: '[PRE6]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '`check=True` activates an exception if the `curl` command fails'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`check=True`在`curl`命令失败时激活异常'
- en: '`shell=True` runs the command through the shell'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`shell=True`通过shell运行命令'
- en: 'The `try-except` block is used to handle errors:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`try-except`块来处理错误：
- en: '[PRE7]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We now have a standalone download script that we’ll use throughout the book.
    Let’s go ahead and download the resources we need for this program.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在有一个独立的下载脚本，将在整本书中使用。让我们继续下载本程序所需的资源。
- en: Downloading OpenAI resources
  id: totrans-252
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 下载 OpenAI 资源
- en: 'We need three resources for this notebook:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 本笔记本需要三个资源：
- en: '`requirements01.py` to install the precise OpenAI version we want'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`requirements01.py`用于安装我们想要的精确的 OpenAI 版本'
- en: '`openai_setup.py` to initialize the OpenAI API key'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`openai_setup.py`用于初始化 OpenAI API 密钥'
- en: '`openai_api_py` contains a reusable function for calling the GPT-4o model,
    so you don’t need to rewrite the same code across multiple cells or notebooks'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`openai_api_py`包含一个可重用的函数来调用 GPT-4o 模型，因此你不需要在多个单元格或笔记本中重写相同的代码'
- en: We will be reusing the same functions throughout the book for standard OpenAI
    API calls. You can come back to this section any time you want to revisit the
    installation process. Other scenarios will be added to the `commons` directory
    when necessary.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在整本书中重复使用相同的函数来执行标准的 OpenAI API 调用。如果你想重新访问安装过程，可以随时回到这一节。当需要时，其他场景将被添加到`commons`目录中。
- en: 'We can download these files with the `download()` function:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`download()`函数下载这些文件：
- en: '[PRE8]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The first resource is `requirements01.py`.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 第一资源是`requirements01.py`。
- en: Installing OpenAI
  id: totrans-261
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 安装 OpenAI
- en: '`requirements01.py` makes sure that a specific version of the OpenAI library
    is installed to avoid conflicts with other installed libraries. The code thus
    uninstalls existing versions, force-installs the specified version requested,
    and verifies the result. The function executes the installation with error handling:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: '`requirements01.py`确保安装了特定的 OpenAI 库版本，以避免与其他已安装库冲突。因此，代码会卸载现有版本，强制安装请求的指定版本，并验证结果。该函数执行安装并带有错误处理：'
- en: '[PRE9]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The first step for the function is to uninstall the current OpenAI library,
    if there is one:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 函数的第一步是卸载当前存在的 OpenAI 库（如果有的话）：
- en: '[PRE10]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The function then installs a specific version of OpenAI:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 函数随后安装 OpenAI 的特定版本：
- en: '[PRE11]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Finally, the function verifies that OpenAI is properly installed:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，函数会验证 OpenAI 是否正确安装：
- en: '[PRE12]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The output at the end of the function should be as follows:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 函数末尾的输出应如下所示：
- en: '[PRE13]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: We can now initialize the OpenAI API key.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以初始化 OpenAI API 密钥。
- en: OpenAI API key initialization
  id: totrans-273
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: OpenAI API 密钥初始化
- en: 'There are two methods to initialize the OpenAI API key in the notebook:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 在笔记本中初始化 OpenAI API 密钥有两种方法：
- en: '**Using Google Colab secrets**: Click on the key icon in the left pane in Google
    Colab, as shown in *Figure 1.8*, then click on **Add new secret** and add your
    key with the name of the key variable you will use in the notebook:'
  id: totrans-275
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**使用 Google Colab secrets**：在 Google Colab 的左侧面板中点击密钥图标，如图1.8所示，然后点击**添加新密钥**，并添加你将在笔记本中使用的密钥变量名称：'
- en: '![Figure 1.8: Add a new Google secret key](img/B32304_01_8.png)'
  id: totrans-276
  prefs: []
  type: TYPE_IMG
  zh: '![图1.8：添加新的 Google 密钥](img/B32304_01_8.png)'
- en: 'Figure 1.8: Add a new Google secret key'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.8：添加新的 Google 密钥
- en: 'Then, we can use Google’s function to initialize the key by calling it in our
    `openai_setup` function in `openai_setup.py`:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以在`openai_setup.py`中的`openai_setup`函数中调用它来使用 Google 的函数初始化密钥：
- en: '[PRE14]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'This method is activated if `google_secrets` is set to `True`:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`google_secrets`设置为`True`，则激活此方法：
- en: '[PRE15]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '**Custom secure method**: You can also choose a custom method or enter the
    key in the code by setting `google_secrets` to `False`, uncommenting the following
    code, and entering your API key directly, or any method of your choice:'
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自定义安全方法**：你也可以选择自定义方法，或者通过设置`google_secrets`为`False`，取消注释以下代码，并直接输入你的API密钥，或者任何你选择的方法：'
- en: '[PRE16]'
  id: totrans-283
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'In both cases, the code will create an environment variable:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两种情况下，代码将创建一个环境变量：
- en: '[PRE17]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The OpenAI API key is initialized. We will now import a custom OpenAI API call.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI API 密钥已初始化。我们现在将导入一个自定义的 OpenAI API 调用。
- en: OpenAI API call
  id: totrans-287
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: OpenAI API 调用
- en: 'The goal next is to create an OpenAI API call function in `openai_api.py` that
    we can import in two lines:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的目标是创建一个在`openai_api.py`中的 OpenAI API 调用函数，我们可以在两行中导入它：
- en: '[PRE18]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The function is thus built to receive four variables when making the call and
    display them seamlessly:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，该函数在调用时构建以接收四个变量并无缝显示它们：
- en: '[PRE19]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The parameters in this function are the following:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数中的参数如下：
- en: '`input`: Contains the input (user or system), for example, `Where is Hawaii?`'
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input`: 包含输入（用户或系统），例如，`夏威夷在哪里？`'
- en: '`mrole`: Defines the system’s role, for example, `You are a geology expert.`
    or simply `System.`'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mrole`: 定义系统的角色，例如，`你是一位地质学专家。` 或简单地 `系统。`'
- en: '`mcontent`: Is what we expect the system to be, for example, `You are a geology
    expert.`'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mcontent`: 是我们期望系统成为的内容，例如，`你是一位地质学专家。`'
- en: '`user_role`: Defines the role of the user, for example, `user`'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`user_role`: 定义用户的角色，例如，`用户`'
- en: 'The first part of the code in the function defines the model we will be using
    in this notebook and creates a message object for the API call with the parameters
    we sent:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 函数中的代码的第一部分定义了我们将在此笔记本中使用的模型，并创建了一个带有我们发送的参数的 API 调用消息对象：
- en: '[PRE20]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'We then define the API call parameters in a dictionary for this notebook:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们为这个笔记本定义 API 调用参数的字典：
- en: '[PRE21]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The dictionary parameters are the following:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 字典参数如下：
- en: '`temperature`: Controls the randomness of a response. `0` will produce deterministic
    responses. Higher values(e.g., `0.7`) will produce more creative responses.'
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`temperature`: 控制响应的随机性。`0` 将产生确定性响应。更高的值（例如，`0.7`）将产生更具创造性的响应。'
- en: '`max_tokens`: Limits the maximum number of tokens of a response.'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_tokens`: 限制响应的最大标记数。'
- en: '`top_p`: Produces nucleus sampling. It controls the diversity of a response
    by sampling from the top tokens with a cumulative probability of 1.'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`top_p`: 产生核采样。它通过从累积概率为 1 的顶部标记中进行采样来控制响应的多样性。'
- en: '`frequency_penalty`: Reduces the repetition of tokens to avoid redundancies.
    `0` will apply no penalty, and `2` a strong penalty. In this case, `0` is sufficient
    because of the high performance of the OpenAI model.'
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`frequency_penalty`: 通过减少标记的重复来避免冗余。`0` 将不应用任何惩罚，而 `2` 则应用强烈的惩罚。在这种情况下，由于 OpenAI
    模型的高性能，`0` 已经足够了。'
- en: '`presence_penalty`: Encourages new content by penalizing existing content to
    avoid redundancies. It applies to the same values as for the frequency penalty.
    In this case, due to the high performance of the OpenAI model, it doesn’t require
    this control.'
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`presence_penalty`: 通过惩罚现有内容来鼓励新内容，以避免冗余。它适用于与频率惩罚相同的值。在这种情况下，由于 OpenAI 模型的高性能，它不需要这种控制。'
- en: 'We then initialize the OpenAI client to create an instance for the API calls:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们初始化 OpenAI 客户端以创建 API 调用的实例：
- en: '[PRE22]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Finally, we make the API call by sending the model, the message object, and
    the unpacked parameters:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们通过发送模型、消息对象和展开的参数来执行 API 调用：
- en: '[PRE23]'
  id: totrans-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The function ends by returning the content of the API’s response that we need:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 函数通过返回我们需要的 API 响应内容结束：
- en: '[PRE24]'
  id: totrans-312
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: This function will help us focus on the GenAISys architecture without having
    to overload the notebook with repetitive libraries and functions.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数将帮助我们专注于 GenAISys 架构，而无需在笔记本中加载重复的库和函数。
- en: 'In the notebook, we have the following:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 在笔记本中，我们有以下内容：
- en: The program provides the input, roles, and message content to the function
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 程序将输入、角色和消息内容提供给函数
- en: '`messages_obj` contains the conversation history'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`messages_obj` 包含对话历史'
- en: The parameters for the API’s behavior are defined in the `params` dictionary
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: API 行为的参数定义在 `params` 字典中
- en: An API call is made to the OpenAI model using the OpenAI client
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 OpenAI 客户端对 OpenAI 模型进行 API 调用
- en: The function returns only the AI’s response content
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 函数仅返回 AI 的响应内容
- en: A GenAISys will contain many components—including a generative model. You can
    choose the one that fits your project. In this book, the models are used for educational
    purposes only, not as endorsements or recommendations.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: GenAISys 将包含许多组件——包括一个生成模型。你可以选择适合你项目的模型。在这本书中，模型仅用于教育目的，不作为认可或推荐。
- en: Let’s now build and run a stateless and memoryless session.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们构建并运行一个无状态和无记忆的会话。
- en: 1\. Stateless and memoryless session
  id: totrans-322
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1. 无状态和无记忆会话
- en: 'A stateless and memoryless session is useful if we only want a single and temporary
    exchange with no stored information between requests. The examples in this section
    are both stateless and memoryless:'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们只想进行一次性和临时的交换，且请求之间没有存储信息，那么无状态和无记忆的会话是有用的。本节中的示例既无状态又无记忆：
- en: '*Stateless* indicates that each request will be processed independently'
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*无状态* 表示每个请求都将独立处理'
- en: '*Memoryless* means that there is no mechanism to remember past exchanges'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*无记忆*意味着没有机制来记住过去的交流'
- en: Let’s begin with a semantic query.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从语义查询开始。
- en: Semantic query
  id: totrans-327
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 语义查询
- en: 'This request expects a purely semantic, factual response:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 这个请求期望一个纯粹语义、事实性的响应：
- en: '[PRE25]'
  id: totrans-329
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Now, we call the OpenAI API function:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们调用 OpenAI API 函数：
- en: '[PRE26]'
  id: totrans-331
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'As you can see, the response is purely semantic:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，响应完全是语义性的：
- en: '[PRE27]'
  id: totrans-333
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: The next query is episodic.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个查询是情景式的。
- en: Episodic query with a semantic undertone
  id: totrans-335
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 情景查询带有语义背景
- en: 'The query in this example is episodic and draws on personal experience. However,
    there is a semantic undertone because of the description of Hawaii. Here’s the
    message, which is rather poetic:'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 本例中的查询是情景式的，并借鉴了个人经验。然而，由于对夏威夷的描述，存在语义背景。以下是一条相当诗意的消息：
- en: '[PRE28]'
  id: totrans-337
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '`mcontent` is reused from the semantic query example (“You are an expert in
    geology”), but in this case, it doesn’t significantly influence the response.
    Since the user input is highly personal and narrative-driven, the system prompt
    plays a minimal role.'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: '`mcontent` 从语义查询示例（“你是地质学专家”）中重用，但在这个案例中，它对响应的影响并不大。由于用户输入非常个人化和叙事驱动，系统提示的作用很小。'
- en: 'We could insert external information before the function call if necessary.
    For example, we could add some information from another source, such as a text
    message received that day from a family member:'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要，我们可以在函数调用之前插入外部信息。例如，我们可以添加来自另一个来源的信息，比如当天从家庭成员那里收到的短信：
- en: '[PRE29]'
  id: totrans-340
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Now, we call the function:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们调用函数：
- en: '[PRE30]'
  id: totrans-342
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'We see that the response is mostly episodic with some semantic information:'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到响应主要是情景式的，并包含一些语义信息：
- en: '[PRE31]'
  id: totrans-344
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Stateless and memoryless verification
  id: totrans-345
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 无状态和无记忆验证
- en: 'We added no memory retention functionality earlier, making the dialogue stateless.
    Let’s check:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前没有添加任何记忆保留功能，使得对话无状态。让我们检查一下：
- en: '[PRE32]'
  id: totrans-347
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'When we call the function, our dialogue will be forgotten:'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们调用函数时，我们的对话将被遗忘：
- en: '[PRE33]'
  id: totrans-349
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The output confirms that the session is memoryless:'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 输出确认会话是无记忆的：
- en: '[PRE34]'
  id: totrans-351
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The API call is stateless because the OpenAI API does not retain memory between
    requests. If we were using ChatGPT directly, the exchanges would be memorized
    within that session. This has a critical impact on implementation. It means we
    have to build our own memory mechanisms to give GenAISys stateful behavior. Let’s
    start with the first layer: short-term memory.'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: API 调用是无状态的，因为 OpenAI API 不会在请求之间保留记忆。如果我们直接使用 ChatGPT，交换会被保存在那个会话中。这对实现有重大影响。这意味着我们必须构建自己的记忆机制，以赋予
    GenAISys 有状态的行为。让我们从第一层：短期记忆开始。
- en: 2\. Short-term memory session
  id: totrans-353
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2. 短期记忆会话
- en: 'The goal of this section is to emulate a short-term memory session using a
    two-step process:'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 本节的目标是使用两步过程模拟短期记忆会话：
- en: 'First, we initiate a session that goes from user input to a response:'
  id: totrans-355
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们从一个用户输入到一个响应的会话：
- en: User input => Generative model API call => Response
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 用户输入 => 生成模型 API 调用 => 响应
- en: 'To achieve this first step, we run the session up to the response:'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这一第一步，我们将会话运行到响应：
- en: '[PRE35]'
  id: totrans-358
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The response’s output is stored in `response`:'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 响应的输出存储在 `response` 中：
- en: '[PRE36]'
  id: totrans-360
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The next step is to feed the previous interaction into the next prompt, along
    with a follow-up question:'
  id: totrans-361
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是将之前的交互输入到下一个提示中，并附带一个后续问题：
- en: 'Explain the situation: `The current dialog session is:`'
  id: totrans-362
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释情况：`当前对话会话为：`
- en: 'Add the user’s initial input: `Hawai is on a geological volcano system. Explain:`'
  id: totrans-363
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加用户的初始输入：`夏威夷位于一个地质火山系统。解释：`
- en: Add the response we obtained in the previous call
  id: totrans-364
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加我们在上一个调用中获得的响应
- en: 'Add the user’s new input: `Sum up your previous response in a short sentence
    in a maximum of 20 words.`'
  id: totrans-365
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加用户的新的输入：`用最多20个字总结你之前的回答。`
- en: The goal here is to compress the session log. We won’t always need to compress
    dialogues, but in longer sessions, large context windows can pile up quickly.
    This technique helps keep the token count low, which matters for both cost and
    performance. In this particular case, we’re only managing one response, so we
    could keep the entire interaction in memory if we wanted to. Still, this example
    introduces a useful habit for scaling up.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的目标是压缩会话日志。我们并不总是需要压缩对话，但在较长的会话中，大的上下文窗口会迅速堆积。这项技术有助于保持令牌计数低，这对成本和性能都很重要。在这个特定案例中，我们只管理一个响应，如果我们想的话，可以保留整个交互在内存中。不过，这个例子介绍了一个有用的习惯，有助于扩展。
- en: 'Once the prompt is assembled:'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦提示被组装：
- en: Call the API function
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调用 API 函数
- en: Display the response
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 显示响应
- en: 'The scenario is illustrated in the code:'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 场景在代码中得到了说明：
- en: '[PRE37]'
  id: totrans-371
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The output provides a nice, short summary of the dialogue:'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 输出提供了一个很好的、简短的对话摘要：
- en: '[PRE38]'
  id: totrans-373
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: This functionality wasn’t strictly necessary here, but it sets us up for the
    longer dialogues we’ll encounter later in the book. Next, let’s build a long-term
    simulation of multiple sessions.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 这个功能在这里并不是严格必要的，但它为我们设置了在书中稍后遇到的更长时间对话的基础。接下来，让我们构建一个多个会话的长期模拟。
- en: 'Keep in mind: Since the session is still in-memory only, the conversation would
    be lost if the notebook disconnects. Nothing is stored on disk or in a database
    yet.'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住：由于会话目前只保存在内存中，如果笔记本断开连接，对话就会丢失。目前还没有任何内容存储在磁盘或数据库中。
- en: 3\. Long-term memory of multiple sessions
  id: totrans-376
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3. 多个会话的长期记忆
- en: In this section, we’re simulating long-term memory by continuing a conversation
    from an earlier session. The difference here is that we’re not just *remembering*
    a dialogue from a single session—we’re *reusing* content from a past session to
    extend the conversation. At this point, the term “session” takes on a broader
    meaning. In a traditional copilot scenario, one user interacts with one model
    in one self-contained session. Here, we’re blending sessions and supporting multiple
    sub-sessions. Multiple users can interact with the model in a shared environment,
    effectively creating a single global session with branching memory threads. Think
    of the model as a guest in an ongoing Zoom or Teams meeting. You can ask the AI
    guest to participate or stay quiet—and when it joins, it may need a recap.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们通过从早期会话继续对话来模拟长期记忆。这里的区别在于，我们不仅仅是“记住”单个会话中的对话——我们正在“重用”过去会话的内容来扩展对话。在这个时候，“会话”这个词有了更广泛的意义。在传统的副驾驶场景中，一个用户在一个自包含的会话中与一个模型交互。在这里，我们正在混合会话并支持多个子会话。多个用户可以在共享环境中与模型交互，有效地创建一个具有分支记忆线程的单个全局会话。想象一下，模型就像一个正在进行的Zoom或Teams会议中的客人。你可以要求AI客人参与或保持安静——当它加入时，它可能需要回顾。
- en: 'To avoid repeating the first steps of the past conversation, we’re reusing
    the content from the short-term memory session we just ran. Let’s assume the previous
    session is over, but we still want to continue from where we left off:'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免重复过去对话的第一步，我们正在重用我们刚刚运行的短期记忆会话的内容。让我们假设之前的会话已经结束，但我们仍然想从我们离开的地方继续：
- en: '[PRE39]'
  id: totrans-379
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The output contains the final response from our short-term memory session:'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 输出包含了我们短期记忆会话的最终响应：
- en: '[PRE40]'
  id: totrans-381
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The process in this section will build on the previous session, similar to
    how you’d revisit a conversation with an online copilot after some time away:'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 本节中的过程将在之前的会话基础上构建，类似于你离开一段时间后再次与在线副驾驶进行对话的方式：
- en: Save previous session => Load previous session => Add it to the new session’s
    scenario
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 保存上一个会话 => 加载上一个会话 => 将其添加到新会话的场景中
- en: 'Let’s first test whether the API remembers anything on its own:'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先测试一下API是否能够自己记住一些东西：
- en: '[PRE41]'
  id: totrans-385
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'The output shows that it forgot the conversation we were in:'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示它忘记了我们正在进行的对话：
- en: '[PRE42]'
  id: totrans-387
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'The API forgot the previous call because stateless APIs don’t retain past dialogue.
    It’s up to us to decide what to include in the prompt. We have a few choices:'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: API忘记了之前的调用，因为无状态API不会保留过去的对话。这取决于我们决定在提示中包含什么。我们有几个选择：
- en: Do we want to remember everything with a large consumption of tokens?
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们是否希望以大量消耗令牌的方式记住所有内容？
- en: Do we want to summarize parts or all of the previous conversations?
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们是想总结之前的部分对话还是全部对话？
- en: 'In a real GenAISys, when an input triggers a request, the AI controller decides
    which is the best strategy to apply to a task. The code now associates the previous
    session’s context and memory with a new request:'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个真实的GenAISys中，当输入触发请求时，AI控制器会决定应用任务的最佳策略。现在的代码将之前会话的上下文和记忆与新的请求关联起来：
- en: '[PRE43]'
  id: totrans-392
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'The response shows that the system now remembers the past session and has enough
    information to provide an acceptable output:'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 响应显示系统现在记住了过去的会话，并且有足够的信息提供可接受的输出：
- en: '[PRE44]'
  id: totrans-394
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Let’s now build a long-term simulation of multiple sessions across different
    topics.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将构建一个跨不同主题的多个会话的长期模拟。
- en: 4\. Long-term memory of multiple cross-topic sessions
  id: totrans-396
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4. 多个跨主题会话的长期记忆
- en: This section illustrates how to merge two separate sessions into one. This isn’t
    something standard ChatGPT-like platforms offer. Typically, when we start a new
    topic, the copilot only remembers what’s happened in the current session. But
    in a corporate environment, we may need more flexibility—especially when multiple
    users are collaborating. In such cases, the AI controller can be configured to
    allow groups of users to view and merge sessions generated by others in the same
    group.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 本节说明了如何将两个单独的会话合并为一个。这不是标准ChatGPT-like平台提供的东西。通常，当我们开始一个新的主题时，共乘者只记得当前会话中发生的事情。但在企业环境中，我们可能需要更多的灵活性——特别是在多个用户协作时。在这种情况下，AI控制器可以被配置为允许用户组查看和合并同一组中其他人生成的会话。
- en: 'Let’s say we want to sum up two separate conversations—one about Hawaii’s volcanic
    systems, and another about organizing a geological field trip to Arizona. We begin
    by saving the previous long-term memory session:'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要总结两个单独的对话——一个关于夏威夷的火山系统，另一个关于组织到亚利桑那州的地质野外考察。我们首先保存先前的长期记忆会话：
- en: '[PRE45]'
  id: totrans-399
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Then we can start a separate multi-user sub-session from another location,
    Arizona:'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以从另一个位置，即亚利桑那州，开始一个单独的多用户子会话：
- en: '[PRE46]'
  id: totrans-401
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'We now expect a response on Arizona, leaving Hawaii out:'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在期望对亚利桑那州有响应，而夏威夷则被排除在外：
- en: '[PRE47]'
  id: totrans-403
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'The response is acceptable. Now, let’s simulate long-term memory across multiple
    topics by combining both sessions and prompting the system to summarize them:'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 响应是可以接受的。现在，让我们通过结合两个会话并提示系统总结它们来模拟跨多个主题的长期记忆：
- en: '[PRE48]'
  id: totrans-405
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'The system’s output shows that the long-term memory of the system is effective.
    We see that the first part is about Hawaii:'
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 系统的输出显示，系统的长期记忆是有效的。我们看到第一部分是关于夏威夷的：
- en: '[PRE49]'
  id: totrans-407
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Then the response continues to the part about Arizona:'
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 然后响应继续到关于亚利桑那州的段落：
- en: '[PRE50]'
  id: totrans-409
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: We’ve now covered the core memory modes of GenAISys—from stateless and short-term
    memory to multi-user, multi-topic long-term memory. Let’s now summarize the chapter’s
    journey and move to the next level!
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经涵盖了GenAISys的核心记忆模式——从无状态和短期记忆到多用户、多主题的长期记忆。现在，让我们总结本章的旅程，并进入下一个层次！
- en: Summary
  id: totrans-411
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: A business-ready GenAISys offers functionality on par with ChatGPT-like platforms.
    It brings together generative AI models, agentic features, RAG, memory retention,
    and a range of ML and non-AI functions—all coordinated by an AI controller. Unlike
    traditional pipelines, the controller doesn’t follow a fixed sequence of steps.
    Instead, it orchestrates tasks dynamically, adapting to the context.
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 一个商业就绪的GenAISys提供了与ChatGPT-like平台相当的功能。它汇集了生成式AI模型、代理功能、RAG、记忆保持以及一系列ML和非AI功能——所有这些都由一个AI控制器协调。与传统管道不同，控制器不遵循固定的步骤序列。相反，它动态地编排任务，适应上下文。
- en: A GenAISys typically runs on a model such as GPT-4o—or whichever model best
    fits your use case. But as we’ve seen, just having access to an API isn’t enough.
    Contextual awareness and memory retention are essential. While ChatGPT-like tools
    offer these features by default, we have to build them ourselves when creating
    custom systems.
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: GenAISys通常在GPT-4o或最适合您用例的任何模型上运行。但正如我们所见，仅仅访问API是不够的。上下文意识和记忆保持是必不可少的。虽然ChatGPT-like工具默认提供这些功能，但当我们创建定制系统时，我们必须自己构建它们。
- en: 'We explored four types of memory: memoryless, short-term, long-term, and cross-topic.
    We also distinguished semantic memory (facts) from episodic memory (personal,
    time-stamped information). Context awareness depends heavily on memory—but context
    windows have limits. Even if we increase the window size, models can still miss
    the nuance in complex tasks. That’s where advanced RAG comes in—breaking down
    content into smaller chunks, embedding them, and storing them in vector stores
    such as Pinecone. This expands what the system can “remember” and use for reasoning.'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 我们探索了四种类型的记忆：无记忆、短期记忆、长期记忆和跨主题记忆。我们还区分了语义记忆（事实）和情景记忆（个人、带时间戳的信息）。上下文意识在很大程度上依赖于记忆——但上下文窗口有局限性。即使我们增加窗口大小，模型仍然可能错过复杂任务中的细微差别。这就是高级RAG发挥作用的地方——将内容分解成更小的块，嵌入它们，并将它们存储在Pinecone等向量存储中。这扩大了系统可以“记住”并用于推理的内容。
- en: 'We also saw that no matter how advanced GenAISys becomes, it can’t function
    without human expertise. From design to deployment, maintenance, and iteration,
    people remain critical throughout the system’s life cycle. We then outlined three
    real-world implementation models based on available resources and goals: hybrid
    systems that leverage existing AI platforms, small-scale systems for targeted
    business needs, and full-scale systems built for ChatGPT-grade performance.'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还看到，无论 GenAISys 如何先进，没有人类专业知识它就无法运行。从设计到部署、维护和迭代，人在整个系统生命周期中始终至关重要。然后，我们根据可用资源和目标概述了三种现实世界的实施模型：利用现有
    AI 平台的混合系统、针对特定商业需求的小规模系统以及为 ChatGPT 级别性能构建的全规模系统。
- en: 'Finally, we got hands-on—building a series of memory simulation modules in
    Python using GPT-4o. These examples laid the groundwork for what comes next: the
    AI controller that will manage memory, context, and orchestration across your
    GenAISys. We are now ready to build a GenAISys AI controller!'
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们亲自动手——使用 GPT-4o 在 Python 中构建了一系列内存模拟模块。这些示例为下一步奠定了基础：将管理 GenAISys 中的内存、上下文和编排的
    AI 控制器。我们现在准备好构建 GenAISys AI 控制器了！
- en: Questions
  id: totrans-417
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: Is an API generative AI model such as GPT an AI controller? (Yes or No)
  id: totrans-418
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: API 生成式 AI 模型如 GPT 是否是 AI 控制器？（是或否）
- en: Does a memoryless session remember the last exchange(s)? (Yes or No)
  id: totrans-419
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 无记忆的会话是否记得最后的交流？（是或否）
- en: Is RAG used to optimize context windows? (Yes or No)
  id: totrans-420
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: RAG 是否用于优化上下文窗口？（是或否）
- en: Are human roles important for the entire life cycle of a GenAISys? (Yes or No)
  id: totrans-421
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: GenAISys 的整个生命周期中人类角色是否重要？（是或否）
- en: Can an AI controller run tasks dynamically? (Yes or No)
  id: totrans-422
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: AI 控制器能否动态运行任务？（是或否）
- en: Is a small-scale GenAISys built with a limited number of key features? (Yes
    or No)
  id: totrans-423
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用有限数量的关键特性构建的小规模 GenAISys 是否？（是或否）
- en: Does a full-scale ChatGPT-like system require huge resources? (Yes or No)
  id: totrans-424
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 全规模的类似 ChatGPT 的系统是否需要大量资源？（是或否）
- en: Is long-term memory necessary across multiple sessions? (Yes or No)
  id: totrans-425
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在多个会话中是否需要长期记忆？（是或否）
- en: Do vector stores such as Pinecone support knowledge and AI controller functions?
    (Yes or No)
  id: totrans-426
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向量存储如 Pinecone 是否支持知识和 AI 控制器功能？（是或否）
- en: Can a GenAISys function without contextual awareness? (Yes or No)
  id: totrans-427
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: GenAISys 是否可以在没有上下文意识的情况下运行？（是或否）
- en: References
  id: totrans-428
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Tomczak, J. M. (2024). *Generative AI Systems: A Systems-based Perspective
    on Generative AI.* [https://arxiv.org/pdf/2407.11001](https://arxiv.org/pdf/2407.11001)'
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tomczak, J. M. (2024). *生成式人工智能系统：生成式人工智能的系统视角*。[https://arxiv.org/pdf/2407.11001](https://arxiv.org/pdf/2407.11001)
- en: 'Zewe, A. (2023, November 9). *Explained: Generative AI.* MIT News. Retrieved
    from [https://news.mit.edu/2023/explained-generative-ai-1109](https://news.mit.edu/2023/explained-generative-ai-1109)'
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zewe, A. (2023, November 9). *解释：生成式人工智能*。MIT News。从 [https://news.mit.edu/2023/explained-generative-ai-1109](https://news.mit.edu/2023/explained-generative-ai-1109)
    获取。
- en: 'OpenAI models: [https://platform.openai.com/docs/models](https://platform.openai.com/docs/models)'
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI 模型：[https://platform.openai.com/docs/models](https://platform.openai.com/docs/models)
- en: Bommasani, R., Hudson, D. A., Adeli, E., Altman, R., Arora, S., von Arx, S.,
    ... & Liang, P. (2021). *On the Opportunities and Risks of Foundation Models.*
    arXiv preprint arXiv:2108.07258\. Retrieved from [https://arxiv.org/abs/2108.07258](https://arxiv.org/abs/2108.07258)
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bommasani, R.，Hudson, D. A.，Adeli, E.，Altman, R.，Arora, S.，von Arx, S.，... &
    Liang, P. (2021). *关于基础模型的机会与风险*。arXiv 预印本 arXiv:2108.07258。从 [https://arxiv.org/abs/2108.07258](https://arxiv.org/abs/2108.07258)
    获取。
- en: Further reading
  id: totrans-433
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: Feuerriegel, S., Hartmann, J., Janiesch, C., & Zschech, P. (2023). *Generative
    AI. Business & Information Systems Engineering*. [https://doi.org/10.1007/s12599-023-00834-7](https://doi.org/10.1007/s12599-023-00834-7
    )
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Feuerriegel, S.，Hartmann, J.，Janiesch, C.，& Zschech, P. (2023). *生成式人工智能。商业与信息系统工程*。[https://doi.org/10.1007/s12599-023-00834-7](https://doi.org/10.1007/s12599-023-00834-7)
- en: 'Eloundou et al. (2023). *GPTs are GPTs: An Early Look at the Labor Market Impact
    Potential of Large Language Models.* [https://arxiv.org/abs/2303.10130](https://arxiv.org/abs/2303.10130)'
  id: totrans-435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Eloundou 等人 (2023)。*GPTs 是 GPTs：大型语言模型对劳动力市场影响潜力的早期观察*。[https://arxiv.org/abs/2303.10130](https://arxiv.org/abs/2303.10130)
- en: '|'
  id: totrans-436
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '|'
- en: Unlock this book’s exclusive benefits now
  id: totrans-437
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 现在解锁此书的独家优惠
- en: Scan this QR code or go to [packtpub.com/unlock](http://packtpub.com/unlock),
    then search for this book by name. | ![A qr code on a white background  AI-generated
    content may be incorrect.](img/Unlock.png) |
  id: totrans-438
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 扫描此二维码或访问 [packtpub.com/unlock](http://packtpub.com/unlock)，然后通过书名搜索此书。 | ![白色背景上的二维码
    AI生成的内容可能不正确。](img/Unlock.png) |
- en: '| *Note: Keep your purchase invoice ready before you start.* |'
  id: totrans-439
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| *注意：在开始之前，请准备好您的购买发票。* |'
