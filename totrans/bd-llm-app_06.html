<html><head></head><body>
<div><h1 class="chapterNumber">6</h1>
<h1 class="chapterTitle" id="_idParaDest-86">Building Conversational Applications</h1>
<p class="normal">With this chapter, we embark on the hands-on section of this book, with our first concrete implementation of LLM-powered applications. Throughout this chapter, we will cover a step-by-step implementation of a conversational application, using LangChain and its components, building on the knowledge you’ve gained from the previous chapters. By the end of this chapter, you will be able to set up your own conversational application project with just a few lines of code.</p>
<p class="normal">We will cover the following key topics:</p>
<ul>
<li class="bulletList">Configuring the schema of a simple chatbot</li>
<li class="bulletList">Adding the memory component</li>
<li class="bulletList">Adding non-parametric knowledge</li>
<li class="bulletList">Adding tools and making the chatbot “agentic”</li>
<li class="bulletList">Developing the front-end with Streamlit</li>
</ul>
<h1 class="heading-1" id="_idParaDest-87">Technical requirements</h1>
<p class="normal">To complete the tasks in this chapter, you will need the following:</p>
<ul>
<li class="bulletList">A Hugging Face account and user access token.</li>
<li class="bulletList">An OpenAI account and user access token.</li>
<li class="bulletList">Python 3.7.1 or a later version.</li>
<li class="bulletList">Python packages – make sure to have the following Python packages installed: <code class="inlineCode">langchain</code>, <code class="inlineCode">python-dotenv</code>, <code class="inlineCode">huggingface_hub, streamlit</code>, <code class="inlineCode">openai</code>, <code class="inlineCode">pypdf</code>, <code class="inlineCode">tiktoken</code>, <code class="inlineCode">faiss-cpu</code>, and <code class="inlineCode">google-search-results.</code> They can be easily installed via <code class="inlineCode">pip install</code> in your terminal.</li>
</ul>
<p class="normal">You’ll find the code for this chapter in the book’s GitHub repository at <a href="Chapter_06.xhtml">https://github.com/PacktPublishing/Building-LLM-Powered-Applications</a>.</p>
<h1 class="heading-1" id="_idParaDest-88">Getting started with conversational applications</h1>
<p class="normal">A conversational application<a id="_idIndexMarker420"/> is a type of software that can interact with users using natural language. It can be used for various purposes, such as providing information, assistance, entertainment, or transactions. Generally speaking, a conversational application can use different modes of communication, such as text, voice, graphics, or even touch. A conversational application can also use different platforms, such as messaging apps, websites, mobile devices, or smart speakers.</p>
<p class="normal">Today, conversational applications are being taken to the next level thanks to LLMs. Let’s look at some of the benefits<a id="_idIndexMarker421"/> that they provide:</p>
<ul>
<li class="bulletList">Not only do LLMs provide a new level of natural language interactions, but they can also enable applications to perform reasoning based on the best responses, given users’ preferences.</li>
<li class="bulletList">As we saw in previous chapters, LLMs can leverage their parametric knowledge, but are also enriched with non-parametric knowledge, thanks to embeddings and plug-ins.</li>
<li class="bulletList">Finally, LLMs are also able to keep track of the conversation thanks to different types of memory.</li>
</ul>
<p class="normal">The following image shows what the architecture of a conversational bot might look like:</p>
<figure class="mediaobject"><img alt="A diagram of a computer program  Description automatically generated" src="img/B21714_06_01.png"/></figure>
<p class="packt_figref">Figure 6.1: Sample architecture of a conversational bot</p>
<p class="normal">Throughout this chapter, we will build from scratch a text conversational application that is able to help users plan their vacations. We will call this app GlobeBotter. We will add incremental layers of complexity<a id="_idIndexMarker422"/> to make the app as enjoyable as possible for the end user.</p>
<p class="normal">So, let’s start with the basics behind a conversational app architecture.</p>
<h2 class="heading-2" id="_idParaDest-89">Creating a plain vanilla bot</h2>
<p class="normal">To start with, let’s initialize<a id="_idIndexMarker423"/> our LLM and set the schema for our bot. The schema refers to the type<a id="_idIndexMarker424"/> of messages the bot is able to receive. In our case, we will have three types of messages:</p>
<ul>
<li class="bulletList"><strong class="keyWord">System message</strong>:<strong class="keyWord"> </strong>The instructions we give the bot so that it behaves as a travel assistant.</li>
<li class="bulletList"><strong class="keyWord">AI Message</strong>:<strong class="keyWord"> </strong>The message generated by the LLM</li>
<li class="bulletList"><strong class="keyWord">Human Message</strong>: The user’s query</li>
</ul>
<p class="normal">Let’s start with a simple configuration:</p>
<pre class="programlisting code"><code class="hljs-code">from langchain.schema import (
    AIMessage,
    HumanMessage,
    SystemMessage
)
from langchain.chains import LLMChain, ConversationChain
from langchain.chat_models import ChatOpenAI
from langchain.chat_models import ChatOpenAI
chat = ChatOpenAI()
messages = [
    SystemMessage(content="You are a helpful assistant that help the user to plan an optimized itinerary."),
    HumanMessage(content="I'm going to Rome for 2 days, what can I visit?")]
</code></pre>
<p class="normal">We can then save and print<a id="_idIndexMarker425"/> the output as follows:</p>
<pre class="programlisting code"><code class="hljs-code">output = chat(messages)
print(output.content)
</code></pre>
<p class="normal">Here is the output:</p>
<pre class="programlisting con"><code class="hljs-con">In Rome, there are many famous attractions to visit. Here's an optimized itinerary for your two-day trip:
Day 1:
 1. Start your day by visiting the Colosseum, one of the world's most iconic ancient landmarks.
 2. Next, explore the nearby Roman Forum, an ancient Roman marketplace.
 3. Afterward, head to the Pantheon, a well-preserved Roman temple with a stunning dome.
4. Take a stroll through the historic district of Trastevere, known for its charming streets and authentic Roman atmosphere.
5. In the evening, visit the Trevi Fountain and toss a coin to ensure your return to Rome.
Day 2:
1. Begin your day at Vatican City, the smallest independent state in the world. Visit St. Peter's Basilica and admire Michelangelo's masterpiece, the Sistine Chapel.
2. Explore the Vatican Museums, home to an extensive collection of art and historical artifacts.
3. Enjoy a leisurely walk along the Tiber River and cross over to the picturesque neighborhood of Castel Sant'Angelo.
4. Visit the Spanish Steps, a popular meeting point with a beautiful view of the city.
5. End your day by exploring the charming neighborhood of Piazza Navona, known for its baroque architecture and lively atmosphere.
Remember to check the opening hours and availability of tickets for the attractions in advance. Enjoy your trip to Rome!
</code></pre>
<p class="normal">As you can see, the model was pretty good at generating an itinerary in Rome with only one piece of information from our side, the number of days.</p>
<p class="normal">However, we might want to keep interacting<a id="_idIndexMarker426"/> with the bot, so that we can further optimize the itinerary, providing more information about our preferences and habits. To achieve that, we need to add memory to our bot.</p>
<h2 class="heading-2" id="_idParaDest-90">Adding memory</h2>
<p class="normal">As we’re creating a conversational bot<a id="_idIndexMarker427"/> with relatively short messages, in this scenario, a <code class="inlineCode">ConversationBufferMemory</code> could be suitable. To make the configuration easier, let’s also initialize a <code class="inlineCode">ConversationChain</code> to combine the LLM and the memory components.</p>
<p class="normal">Let’s first initialize our memory and chain (I’m keeping <code class="inlineCode">verbose = True</code> so that you can see the bot keeping track of previous messages):</p>
<pre class="programlisting code"><code class="hljs-code">from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationChain
memory = ConversationBufferMemory()
conversation = ConversationChain(
    llm=chat, verbose=True, memory=memory
)
</code></pre>
<p class="normal">Great, now let’s have some interactions with our bot:</p>
<pre class="programlisting code"><code class="hljs-code">conversation.run("Hi there!")
</code></pre>
<p class="normal">The following is the output:</p>
<pre class="programlisting con"><code class="hljs-con">&gt; Entering new ConversationChain chain...
Prompt after formatting:
The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.
Current conversation:
Human: Hi there!
AI:
&gt; Finished chain.
'Hello! How can I assist you today?'
</code></pre>
<p class="normal">Next, we provide<a id="_idIndexMarker428"/> the following input:</p>
<pre class="programlisting code"><code class="hljs-code">conversation.run("what is the most iconic place in Rome?")
</code></pre>
<p class="normal">Here is the corresponding output:</p>
<pre class="programlisting con"><code class="hljs-con">&gt; Entering new ConversationChain chain...
Prompt after formatting:
The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.
Current conversation:
Human: Hi there!
AI: Hello! How can I assist you today?
Human: what is the most iconic place in Rome?
AI:
&gt; Finished chain.
'The most iconic place in Rome is probably the Colosseum. It is a magnificent amphitheater that was built in the first century AD and is one of the most recognizable symbols of ancient Rome. The Colosseum was used for gladiatorial contests, public spectacles, and other events. Today, it is a major tourist attraction and a UNESCO World Heritage site.'
</code></pre>
<p class="normal">As you can see from the chain, it is keeping track of the previous interactions. Let’s challenge it and ask something related to the previous context:</p>
<pre class="programlisting code"><code class="hljs-code">conversation.run("What kind of other events?")
</code></pre>
<p class="normal">The following is the output that we receive:</p>
<pre class="programlisting con"><code class="hljs-con">&gt; Entering new ConversationChain chain...
Prompt after formatting:
The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.
Current conversation:
Human: Hi there!
AI: Hello! How can I assist you today?
Human: what is the most iconic place in Rome?
AI: The most iconic place in Rome is probably the Colosseum. It is a magnificent amphitheater that was built in the first century AD and is one of the most recognizable symbols of ancient Rome. The Colosseum was used for gladiatorial contests, public spectacles, and other events. Today, it is a major tourist attraction and a UNESCO World Heritage site.
Human: What kind of other events?
AI:
&gt; Finished chain.
'Other events that took place at the Colosseum include mock sea battles, animal hunts, and reenactments of famous battles. The Colosseum was also used for executions and religious ceremonies. It was a versatile venue that could accommodate a variety of events and entertainments.'
</code></pre>
<p class="normal">The bot was able to understand<a id="_idIndexMarker429"/> that our request was related to its previous answer. We can also retrieve the message history with the <code class="inlineCode">memory.load_memory_variables()</code> method (you can see the full output in the GitHub repository). Here is a snippet of the output:</p>
<pre class="programlisting con"><code class="hljs-con">{'history': 'Human: Hi there!\nAI: Hello! How can I assist you today?\nHuman: what is the most iconic place in Rome?....
</code></pre>
<p class="normal">Rather than running the conversation.run method at every interaction, I’ve coded a <code class="inlineCode">while</code> cycle to make it interactive. The following is a snapshot of the whole conversation (you can find it in the book’s GitHub repository):</p>
<pre class="programlisting code"><code class="hljs-code">while True:
    query = input('you: ')
    if query == 'q':
        break
    output = conversation({"input": query})
    print('User: ', query)
    print('AI system: ', output['response'])
</code></pre>
<p class="normal">The following is a truncated sample from the output (you can find the whole output in the book’s GitHub repository):</p>
<pre class="programlisting con"><code class="hljs-con">User:  hello
AI system:  Hello! How can I assist you today?
User:  I'm planning a 1-day trip in Venice. What should I visit?
AI system:  That sounds like a wonderful plan! In Venice, there are several must-visit attractions that you can explore in a day. Here's a suggested itinerary for your 1-day trip in Venice:
1. St. Mark's Square (Piazza San Marco): [...] Enjoy your trip to Venice!
User:  thanks! I'm planning to be around also the next day, and I love hiking. Do you have any suggestion nearby?
AI system:  Certainly! If you enjoy hiking and want to explore the natural beauty around Venice, there are a few options you can consider for the next day:
1. The Dolomites: [...]
User:  which one is closer to Milan?
AI system:  If you're looking for a hiking destination closer to Milan, the best option would be the Lombardy region [...]
</code></pre>
<p class="normal">As you can see, now the AI assistant<a id="_idIndexMarker430"/> is capable of keeping track of the whole conversation. In the next section, we are going to add yet another layer of complexity: an external knowledge base.</p>
<h2 class="heading-2" id="_idParaDest-91">Adding non-parametric knowledge</h2>
<p class="normal">Imagine that you also want your GlobeBotter<a id="_idIndexMarker431"/> to have access to exclusive documentation about itineraries that are not part of its parametric knowledge.</p>
<p class="normal">To do so, we can either embed the documentation in a VectorDB or directly use a retriever to do the job. In this case, we will use a vector-store-backed retriever using a particular chain, <code class="inlineCode">ConversationalRetrievalChain.</code> This type of chain leverages a retriever over the provided knowledge base that has the chat history, which can be passed as a parameter using the desired type of memory previously seen.</p>
<p class="normal">With this goal in mind, we will use a sample Italy travel guide PDF downloaded from <a href="https://www.minube.net/guides/italy">https://www.minube.net/guides/italy</a>.</p>
<p class="normal">The following Python code<a id="_idIndexMarker432"/> shows how to initialize all the ingredients we need, which are:</p>
<ul>
<li class="bulletList"><strong class="keyWord">Document Loader</strong>:<strong class="keyWord"> </strong>Since the document is in PDF format, we will use <code class="inlineCode">PyPDFLoader</code>.</li>
<li class="bulletList"><strong class="keyWord">Text splitter</strong>:<strong class="keyWord"> </strong>We will use a <code class="inlineCode">RecursiveCharacterTextSplitter</code>, which splits text by recursively looking at characters to find one that works.</li>
<li class="bulletList"><strong class="keyWord">Vector store</strong>:<strong class="keyWord"> </strong>We will use the <code class="inlineCode">FAISS</code> VectorDB.</li>
<li class="bulletList"><strong class="keyWord">Memory</strong>:<strong class="keyWord"> </strong>We will use a <code class="inlineCode">ConversationBufferMemory</code>.</li>
<li class="bulletList"><strong class="keyWord">LLMs</strong>:<strong class="keyWord"> </strong>We will use the <code class="inlineCode">gpt-3.5-turbo</code> model for conversations.</li>
<li class="bulletList"><strong class="keyWord">Embeddings</strong>:<strong class="keyWord"> </strong>We will use the <code class="inlineCode">text-embedding-ada-002</code>.</li>
</ul>
<p class="normal">Let’s take a look at the code:</p>
<pre class="programlisting code"><code class="hljs-code">from langchain.llms import OpenAI
from langchain.chat_models import ChatOpenAI
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain.document_loaders import PyPDFLoader
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1500,
            chunk_overlap=200
        )
raw_documents = PyPDFLoader('italy_travel.pdf').load()
documents = text_splitter.split_documents(raw_documents)
db = FAISS.from_documents(documents, OpenAIEmbeddings())
memory = ConversationBufferMemory(
            memory_key='chat_history',
            return_messages=True
        )
llm = ChatOpenAI()
</code></pre>
<p class="normal">Let’s now interact with the chain:</p>
<pre class="programlisting code"><code class="hljs-code">qa_chain = ConversationalRetrievalChain.from_llm(llm, retriever=db.as_retriever(), memory=memory, verbose=True)
qa_chain.run({'question':'Give me some review about the Pantheon'})
</code></pre>
<p class="normal">The following is the output (I’m reporting a truncated version. You can<a id="_idIndexMarker433"/> see the whole output in the book’s GitHub repository):</p>
<pre class="programlisting con"><code class="hljs-con">&gt; Entering new StuffDocumentsChain chain...
&gt; Entering new LLMChain chain...
Prompt after formatting:
System: Use the following pieces of context to answer the users question.
If you don't know the answer, just say that you don't know, don't try to make up an answer.
----------------
cafes in the square. The most famous are the Quadri and
Florian.
Piazza San Marco,
Venice
4
Historical Monuments
Pantheon
Miskita:
"Angelic and non-human design," was how
Michelangelo described the Pantheon 14 centuries after its
construction. The highlights are the gigantic dome, the upper
eye, the sheer size of the place, and the harmony of the
whole building. We visited with a Roman guide which is
...
&gt; Finished chain.
'Miskita:\n"Angelic and non-human design," was how Michelangelo described the Pantheon 14 centuries after its construction. The highlights
</code></pre>
<p class="normal">Note that, by default, the <code class="inlineCode">ConversationalRetrievalChain</code> uses a prompt template called <code class="inlineCode">CONDENSE_QUESTION_PROMPT</code>, which merges the last user’s query with the chat history, so that it results as just one query to the retriever. If you want to pass a custom prompt, you can do so using the <code class="inlineCode">condense_question_prompt</code> parameter in the <code class="inlineCode">ConversationalRetrievalChain.from_llm</code> module.</p>
<p class="normal">Even though the bot was able<a id="_idIndexMarker434"/> to provide an answer based on the documentation, we still have a limitation. In fact, with such a configuration, our GlobeBotter will only look at the provided documentation, but what if we want it to also use its parametric knowledge? For example, we might want the bot to be able to understand whether it could integrate with the provided documentation or simply answer <em class="italic">freely</em>. To do so, we need to make our GlobeBotter <em class="italic">agentic</em>, meaning that we want to leverage the LLM’s reasoning capabilities to orchestrate and invoke the available tools without a fixed order, but rather following the best approach given the user’s query.</p>
<p class="normal">To do so, we will use two main components:</p>
<ul>
<li class="bulletList"><code class="inlineCode">create_retriever_tool</code>: This method creates a custom tool that acts as a retriever for an agent. It will need a database to retrieve from, a name, and a short description, so that the model can understand when to use it.</li>
<li class="bulletList"><code class="inlineCode">create_conversational_retrieval_agent</code>: This method initializes a conversational agent that is configured to work with retrievers and chat models. It will need an LLM, a list of tools (in our case, the retriever), and a memory key to keep track of the previous chat history.</li>
</ul>
<p class="normal">The following code illustrates how to initialize the agent:</p>
<pre class="programlisting code"><code class="hljs-code">from langchain.agents.agent_toolkits import create_retriever_tool
tool = create_retriever_tool(
    db.as_retriever(),
    "italy_travel",
    "Searches and returns documents regarding Italy."
)
tools = [tool]
memory = ConversationBufferMemory(
            memory_key='chat_history',
            return_messages=True
        )
from langchain.agents.agent_toolkits import create_conversational_retrieval_agent
from langchain.chat_models import ChatOpenAI
llm = ChatOpenAI(temperature = 0)
agent_executor = create_conversational_retrieval_agent(llm, tools, memory_key='chat_history', verbose=True)
</code></pre>
<p class="normal">Great, now let’s see the thought process <a id="_idIndexMarker435"/>of the agent with two different questions (I will report only the chain of thoughts and truncate the output, but you can find the whole code in the GitHub repo):</p>
<pre class="programlisting code"><code class="hljs-code">agent_executor({"input": "Tell me something about Pantheon"})
</code></pre>
<p class="normal">Here is the output:</p>
<pre class="programlisting con"><code class="hljs-con">&gt; Entering new AgentExecutor chain...
Invoking: `italy_travel` with `Pantheon`
[Document(page_content='cafes in the square. The most famous are the Quadri and\nFlorian. […]
&gt; Finished chain.
</code></pre>
<p class="normal">Let’s now try with a question not related to the document:</p>
<pre class="programlisting code"><code class="hljs-code">output = agent_executor({"input": "what can I visit in India in 3 days?"})
</code></pre>
<p class="normal">The following is the output that we receive:</p>
<pre class="programlisting con"><code class="hljs-con">&gt; Entering new AgentExecutor chain...
In India, there are numerous incredible places to visit, each with its own unique attractions and cultural experiences. While three days is a relatively short time to explore such a vast and diverse country, here are a few suggestions for places you can visit:
1. Delhi: Start your trip in the capital city of India, Delhi. […]
&gt; Finished chain.
</code></pre>
<p class="normal">As you can see, when I asked the agent something about Italy, it immediately invoked the provided document, while this was not done in the last question.</p>
<p class="normal">The last thing we want to add to our GlobeBotter<a id="_idIndexMarker436"/> is the capability to navigate the web, since, as travelers, we want to have up-to-date information about the country we are traveling to. Let’s implement it with LangChain’s tools.</p>
<h2 class="heading-2" id="_idParaDest-92">Adding external tools</h2>
<p class="normal">The tool we are going<a id="_idIndexMarker437"/> to add here is the Google SerpApi tool, so that our bot will be able to navigate the internet.</p>
<div><p class="normal"><strong class="keyWord">Note</strong></p>
<p class="normal">SerpApi is a real-time API<a id="_idIndexMarker438"/> designed to access Google search results. It simplifies the process of data scraping by handling complexities such as managing proxies, solving CAPTCHAs, and parsing structured data from search engine results pages.</p>
<p class="normal">LangChain offers a pre-built tool that wraps SerpApi to make it easier to integrate it within your agents. To enable<a id="_idIndexMarker439"/> SerpApi, you need to sign in at <a href="https://serpapi.com/users/sign_up">https://serpapi.com/users/sign_up</a>, then go to the dashboard under the tab <strong class="keyWord">API key</strong>.</p>
</div>
<p class="normal">Since we don’t want our GlobeBotter to be focused only on the web, we will add the SerpApi tool to the previous one, so that the agent will be able to pick the most useful tool to answer the question – or use no tool if not necessary.</p>
<p class="normal">Let’s initialize our tools and agent (you learned about this and other LangChain components in <em class="chapterRef">Chapter 5</em>):</p>
<pre class="programlisting code"><code class="hljs-code">from langchain import SerpAPIWrapper
import os
from dotenv import load_dotenv
load_dotenv()
os.environ["SERPAPI_API_KEY"]
search = SerpAPIWrapper()
tools = [
    Tool.from_function(
        func=search.run,
        name="Search",
        description="useful for when you need to answer questions about current events"
    ),
    create_retriever_tool(
        db.as_retriever(),
        "italy_travel",
        "Searches and returns documents regarding Italy."
    )
    ]
agent_executor = create_conversational_retrieval_agent(llm, tools, memory_key='chat_history', verbose=True)
</code></pre>
<p class="normal">Great, now let’s test<a id="_idIndexMarker440"/> it with three different questions (here, again, the output has been truncated):</p>
<ul>
<li class="bulletList">“What can I visit in India in 3 days?”
        <pre class="programlisting con-one"><code class="hljs-con">&gt; Entering new AgentExecutor chain...
India is a vast and diverse country with numerous attractions to explore. While it may be challenging to cover all the highlights in just three days, here are some popular destinations that you can consider visiting:
1. Delhi: Start your trip in the capital city of India, Delhi. […]
&gt; Finished chain.
</code></pre>
</li>
</ul>
<p class="normal-one">In this case, the model doesn’t need external knowledge to answer the question, hence it is responding without invoking any tool.</p>
<ul>
<li class="bulletList">“What is the weather currently in Delhi?”
        <pre class="programlisting con-one"><code class="hljs-con">&gt; Entering new AgentExecutor chain...
Invoking: `Search` with `{'query': 'current weather in Delhi'}`
Current Weather · 95°F Mostly sunny · RealFeel® 105°. Very Hot. RealFeel Guide. Very Hot. 101° to 107°. Caution advised. Danger of dehydration, heat stroke, heat ...The current weather in Delhi is 95°F (35°C) with mostly sunny conditions. The RealFeel® temperature is 105°F (41°C), indicating that it feels very hot. Caution is advised as there is a danger of dehydration, heat stroke, and heat-related issues. It is important to stay hydrated and take necessary precautions if you are in Delhi or planning to visit.
&gt; Finished chain.
</code></pre>
</li>
</ul>
<p class="normal-one">Note how the agent is invoking<a id="_idIndexMarker441"/> the search tool; this is due to the reasoning capability of the underlying gpt-3.5-turbo model, which captures the user’s intent and dynamically understands which tool to use to accomplish the request.</p>
<ul>
<li class="bulletList">“I’m traveling to Italy. Can you give me some suggestions for the main attractions to visit?”
        <pre class="programlisting con-one"><code class="hljs-con">&gt; Entering new AgentExecutor chain...
Invoking: `italy_travel` with `{'query': 'main attractions in Italy'}`
[Document(page_content='ITALY\nMINUBE TRAVEL GUIDE\nThe best must-see places for your travels, […]
Here are some suggestions for main attractions in Italy:
1. Parco Sempione, Milan: This is one of the most important parks in Milan. It offers a green space in the city where you can relax, workout, or take a leisurely walk. […]
&gt; Finished chain.
</code></pre>
</li>
</ul>
<p class="normal-one">Note how the agent is invoking the document retriever to provide the preceding output.</p>
<p class="normal">Overall, our GlobeBotter<a id="_idIndexMarker442"/> is now able to provide up-to-date information, as well as retrieving specific knowledge from curated documentation. The next step will be that of building a front-end. We will do so by building a web app using Streamlit.</p>
<h1 class="heading-1" id="_idParaDest-93">Developing the front-end with Streamlit</h1>
<p class="normal">Streamlit is a Python library that allows <a id="_idIndexMarker443"/>you to create<a id="_idIndexMarker444"/> and share web apps. It is designed to be easy and fast to use, without requiring any front-end experience or knowledge. You can write your app in pure Python, using simple commands to add widgets, charts, tables, and other elements.</p>
<p class="normal">In addition to its native capabilities, in July 2023, Streamlit announced an initial integration and its future plans with LangChain. At the core of this initial integration, there is the ambition of making it easier to build a GUI for conversational applications, as well as showing all the steps LangChain’s agents take before producing the final response.</p>
<p class="normal">To achieve this goal, the main module that Streamlit introduced is the Streamlit callback handler. This module provides a class called <code class="inlineCode">StreamlitCallbackHandler</code> that implements the <code class="inlineCode">BaseCallbackHandler</code> interface from LangChain. This class can handle various events that occur during the execution of a LangChain pipeline, such as tool start, tool end, tool error, LLM token, agent action, agent finish, etc.</p>
<p class="normal">The class can also create and update Streamlit elements, such as containers, expanders, text, progress bars, etc., to display the output of the pipeline in a user-friendly way. You can use the Streamlit callback handler to create Streamlit apps that showcase the capabilities of LangChain and interact with the user through natural language. For example, you can create an app that takes a user prompt and runs it through an agent that uses different tools and models to generate a response. You can use the Streamlit callback handler to show the agent’s thought process and the results of each tool in real time.</p>
<p class="normal">To start building your application, you need to create a <code class="inlineCode">.py</code> file to run in your terminal via <code class="inlineCode">streamlit run file.py</code>. In our case, the file will be named <code class="inlineCode">globebotter.py</code>.</p>
<p class="normal">The following are the main building blocks of the application:</p>
<ol>
<li class="numberedList" value="1">Setting the configuration of the webpage:
        <pre class="programlisting code-one"><code class="hljs-code">import streamlit as st
st.set_page_config(page_title="GlobeBotter", page_icon="<img alt="" role="presentation" src="img/Globe.png"/>")
st.header('<img alt="" role="presentation" src="img/Globe.png"/> Welcome to Globebotter, your travel assistant with Internet access. What are you planning for your next trip?')
</code></pre>
</li>
<li class="numberedList">Initializing the LangChain<a id="_idIndexMarker445"/> backbone components<a id="_idIndexMarker446"/> we need. The code is the same as the one in the previous section, so I will share here only the initialization code, without all the preliminary steps:
        <pre class="programlisting code-one"><code class="hljs-code">search = SerpAPIWrapper()
text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1500,
            chunk_overlap=200
        )
raw_documents = PyPDFLoader('italy_travel.pdf').load()
documents = text_splitter.split_documents(raw_documents)
db = FAISS.from_documents(documents, OpenAIEmbeddings())
memory = ConversationBufferMemory(
    return_messages=True,
    memory_key="chat_history",
    output_key="output"
)
llm = ChatOpenAI()
tools = [
    Tool.from_function(
        func=search.run,
        name="Search",
        description="useful for when you need to answer questions about current events"
    ),
    create_retriever_tool(
        db.as_retriever(),
        "italy_travel",
        "Searches and returns documents regarding Italy."
    )
    ]
agent = create_conversational_retrieval_agent(llm, tools, memory_key='chat_history', verbose=True)
</code></pre>
</li>
<li class="numberedList">Setting the input box for the user with a placeholder question:
        <pre class="programlisting code-one"><code class="hljs-code">user_query = st.text_input(
    "**Where are you planning your next vacation?**",
    placeholder="Ask me anything!"
)
</code></pre>
</li>
<li class="numberedList">Setting Streamlit’s session<a id="_idIndexMarker447"/> states. Session state<a id="_idIndexMarker448"/> is a way to share variables between reruns, for each user session. In addition to the ability to store and persist state, Streamlit also exposes the ability to manipulate state using callbacks. Session state also persists across apps inside a multipage app. You can use the session state API to initialize, read, update, and delete variables in the session state. In the case of our GlobeBotter, we want two main states: <code class="inlineCode">messages</code> and <code class="inlineCode">memory</code>:
        <pre class="programlisting code-one"><code class="hljs-code">if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "assistant", "content": "How can I help you?"}]
if "memory" not in st.session_state:
    st.session_state['memory'] = memory
</code></pre>
</li>
<li class="numberedList">Making sure to display the whole conversation. To do so, I created a for loop that iterates over the list of messages stored in <code class="inlineCode">st.session_state["messages"].</code> For each message, it creates a Streamlit element called <code class="inlineCode">st.chat_message</code> that displays a chat message in a nice format:
        <pre class="programlisting code-one"><code class="hljs-code">for msg in st.session_state["messages"]:
    st.chat_message(msg["role"]).write(msg["content"])
</code></pre>
</li>
<li class="numberedList">Configuring the AI assistant to respond when given a user’s query. In this first example, we will keep the whole chain visible and printed to the screen:
        <pre class="programlisting code-one"><code class="hljs-code">if user_query:
    st.session_state.messages.append({"role": "user", "content": user_query})
    st.chat_message("user").write(user_query)
    with st.chat_message("assistant"):
        st_cb = StreamlitCallbackHandler(st.container())
        response = agent(user_query, callbacks=[st_cb])
        st.session_state.messages.append({"role": "assistant", "content": response})
        st.write(response)
</code></pre>
</li>
<li class="numberedList">Finally, adding a button<a id="_idIndexMarker449"/> to clear the history of the conversation<a id="_idIndexMarker450"/> and start from scratch:
        <pre class="programlisting code-one"><code class="hljs-code">if st.sidebar.button("Reset chat history"):
    st.session_state.messages = []
</code></pre>
</li>
</ol>
<p class="normal">The final product looks as follows:</p>
<figure class="mediaobject"><img alt="A screenshot of a computer  Description automatically generated" src="img/B21714_06_02.png"/></figure>
<p class="packt_figref">Figure 6.2: Front-end of GlobeBotter with Streamlit</p>
<p class="normal">From the expander, we can see<a id="_idIndexMarker451"/> that the agent used<a id="_idIndexMarker452"/> the <code class="inlineCode">Search</code> tool (provided with the SerpApi). We can also expand <code class="inlineCode">chat_history</code> or <code class="inlineCode">intermediate_steps</code> as follows:</p>
<figure class="mediaobject"><img alt="A screenshot of a computer  Description automatically generated" src="img/B21714_06_03.png"/></figure>
<p class="packt_figref">Figure 6.3: Example of Streamlit expander</p>
<p class="normal">Of course, we can also decide<a id="_idIndexMarker453"/> to only show the output rather than the whole<a id="_idIndexMarker454"/> chain of thoughts, by specifying in the code to return only <code class="inlineCode">response['output']</code>. You can see the whole code in the book’s GitHub repository.</p>
<p class="normal">Before we wrap up, let’s discuss how you can give your users a streaming experience while interacting with your chatbot. You can leverage the <code class="inlineCode">BaseCallbackHandler</code> class to create a custom callback handler in your Streamlit app:</p>
<pre class="programlisting code"><code class="hljs-code">from langchain.callbacks.base import BaseCallbackHandler
from langchain.schema import ChatMessage
from langchain_openai import ChatOpenAI
import streamlit as st
class StreamHandler(BaseCallbackHandler):
    def __init__(self, container, initial_text=""):
        self.container = container
        self.text = initial_text
    def on_llm_new_token(self, token: str, **kwargs) -&gt; None:
        self.text += token
        self.container.markdown(self.text)
</code></pre>
<p class="normal">The <code class="inlineCode">StreamHandler</code> is designed to capture and display streaming data, such as text or other content, in a designated container. Then, you can use it as follows in your Streamlit app, making sure to set <code class="inlineCode">streaming=True</code> while initializing your OpenAI LLM.</p>
<pre class="programlisting code"><code class="hljs-code"> with st.chat_message("assistant"):
        stream_handler = StreamHandler(st.empty())
        llm = ChatOpenAI(streaming=True, callbacks=[stream_handler])
        response = llm.invoke(st.session_state.messages)
        st.session_state.messages.append(ChatMessage(role="assistant", content=response.content))
</code></pre>
<p class="normal">You can refer<a id="_idIndexMarker455"/> to the original code on LangChain’s GitHub<a id="_idIndexMarker456"/> repo at <a href="https://github.com/langchain-ai/streamlit-agent/blob/main/streamlit_agent/basic_streaming.py">https://github.com/langchain-ai/streamlit-agent/blob/main/streamlit_agent/basic_streaming.py</a>.</p>
<h1 class="heading-1" id="_idParaDest-94">Summary</h1>
<p class="normal">In this chapter, we approached the end-to-end implementation of a conversational application, leveraging LangChain’s modules and progressively adding layers of complexity. We started with a plain vanilla chatbot with no memory, then moved on to more complex systems with the ability to keep traces of past interactions. We’ve also seen how to add non-parametric knowledge to our application with external tools, making it more “agentic” so that it is able to determine which tool to use, depending on the user’s query. Finally, we introduced Streamlit as the front-end framework to build the web app for our GlobeBotter.</p>
<p class="normal">In the next chapter, we will focus on a more specific domain where LLMs add value and demonstrate emerging behaviors, that is, recommendation systems.</p>
<h1 class="heading-1" id="_idParaDest-95">References</h1>
<ul>
<li class="bulletList">Example of a context-aware chatbot. <a href="https://github.com/shashankdeshpande/langchain-chatbot/blob/master/pages/2_%E2%AD%90_context_aware_chatbot.py">https://github.com/shashankdeshpande/langchain-chatbot/blob/master/pages/2_%E2%AD%90_context_aware_chatbot.py</a></li>
<li class="bulletList">Knowledge base for the AI travel assistant. <a href="https://www.minube.net/guides/italy">https://www.minube.net/guides/italy</a></li>
<li class="bulletList">LangChain repository. <a href="https://github.com/langchain-ai ">https://github.com/langchain-ai</a></li>
</ul>
<h1 class="heading-1">Join our community on Discord</h1>
<p class="normal">Join our community’s Discord space for discussions with the author and other readers:</p>
<p class="normal"><a href="https://packt.link/llm ">https://packt.link/llm</a></p>
<p class="normal"><img alt="" role="presentation" src="img/QR_Code214329708533108046.png"/></p>
</div>
</body></html>